{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking into the titles of individual articles with certain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus, textcorpus\n",
    "import numpy as np\n",
    "from gensim.matutils import hellinger\n",
    "import time\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['terms', 'docnames', 'term_topic', 'doc_topic', 'docs_per_year'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_new = pickle.load(open('output/dtm_processed_output.p', 'rb'))\n",
    "alldata_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "doc_year=alldata_new['docs_per_year']\n",
    "doc_ids =[0]+list(np.cumsum(doc_year))\n",
    "\n",
    "term_topic = alldata_new['term_topic']# term_topic is n_years*n_topics*n_terms\n",
    "terms = alldata_new['terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sequence', 'face', 'reasoning', 'text', 'color', 'decision', 'sentence', 'causal', 'concept', 'child', 'spatial', 'error', 'category', 'english', 'student', 'network', 'speaker', 'probability', 'agent', 'visual']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"with open('output/all_visdtm.p','br') as f:\\n    allvisdtm=pickle.load(f)\\nfor visdtm in allvisdtm:\\n\\n    visdtm[0]['topiclabel']=topic_labels\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topicyrs = alldata_new['doc_topic']\n",
    "\n",
    "doc_topic = []\n",
    "for year in range(len(term_topic)):    \n",
    "    doc_topic.append(alldata_new['doc_topic'][doc_ids[year]:doc_ids[year+1]])# doc_topic is nyear*n_docs given year*n_topics\n",
    "    \n",
    "# rename topics by their top freq word\n",
    "topics = range(term_topic.shape[1])\n",
    "\n",
    "def topic_label(topic, term_topic, terms):\n",
    "    term_freqs = np.sum(term_topic[:,topic,:], axis = 0)\n",
    "    max_term = np.argsort(-term_freqs)[0]\n",
    "    return(terms[max_term])\n",
    "\n",
    "\n",
    "topic_labels = [topic_label(topic, term_topic, terms) for topic in topics]\n",
    "print(topic_labels)\n",
    "\"\"\"with open('output/all_visdtm.p','br') as f:\n",
    "    allvisdtm=pickle.load(f)\n",
    "for visdtm in allvisdtm:\n",
    "\n",
    "    visdtm[0]['topiclabel']=topic_labels\"\"\"\n",
    "#topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 159,\n",
       " 347,\n",
       " 492,\n",
       " 693,\n",
       " 937,\n",
       " 1334,\n",
       " 1711,\n",
       " 1980,\n",
       " 2153,\n",
       " 2667,\n",
       " 3110,\n",
       " 3663,\n",
       " 4094,\n",
       " 4770,\n",
       " 5267,\n",
       " 5864,\n",
       " 6328,\n",
       " 6920]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltitles=alldata_new['docnames']\n",
    "doctitle = []\n",
    "for year in range(len(doc_year)):\n",
    "    doctitle.append(alltitles[doc_ids[year]:doc_ids[year+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature1: most typical article of each topics\n",
    "with open('highest_freq.txt','w') as f:\n",
    "    for kt in range(len(topic_labels)):\n",
    "        f.write('\\ntopic '+str(kt)+': '+topic_labels[kt]+'\\n')        \n",
    "        for year in range(len(doc_topic)):  \n",
    "            topicfreq=np.array(doc_topic[year]).T[kt]\n",
    "            idx=np.argmax(topicfreq)\n",
    "            title=doctitle[year][idx]\n",
    "            \n",
    "            f.write(str(year+2000)+': '+title+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pickle' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d0e943bd88e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtopicnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sequential learning'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Face and emotion perception'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Reasoning'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Text processing and creativity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Mathematical cognition'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Decision making'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Language: syntax'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Causal reasoning'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Knowledge structure'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Developmental psychology'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Spatial cognition and embodied cognition'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Memory'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Categorization'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Language: semantics'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Educational psychology'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Network models for cognition and Neuroscience'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'non-verbal communication'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Probabilistic modeling'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Consciousness and identity'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Visual attention'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'topicnames.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopicnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pickle' is not defined"
     ]
    }
   ],
   "source": [
    "# we read the titles and give names for each topic. then store it.\n",
    "topicnames=['Sequential learning','Face and emotion perception','Reasoning','Text processing and creativity','Mathematical cognition','Decision making','Language: syntax','Causal reasoning','Knowledge structure','Developmental psychology','Spatial cognition and embodied cognition','Memory','Categorization','Language: semantics','Educational psychology','Network models for cognition and Neuroscience','non-verbal communication','Probabilistic modeling','Consciousness and identity','Visual attention']\n",
    "with open('topicnames.p','wb') as f:\n",
    "    pickle.dump(topicnames,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature2: \"purest\" / \"most chaotic paper\" \n",
    "maxen=0\n",
    "with open('maxmin_entropy.txt','w') as f:\n",
    "    for year in range(len(doc_topic)):  \n",
    "        f.writelines('\\n'+str(year+2000)+':\\n')\n",
    "        alldocs = doc_topic[year]\n",
    "        allentrop=[]\n",
    "        for d in alldocs:\n",
    "            allentrop.append(entropy(d))\n",
    "        # rank them\n",
    "        maxE = np.argmax(allentrop)\n",
    "        minE = np.argmin(allentrop)\n",
    "        f.writelines('max:'+gettitle(year,maxE)+'\\n')\n",
    "        f.writelines('min:'+gettitle(year,minE)+'\\n')\n",
    "        \n",
    "        # max entropy across years?\n",
    "        if maxE>maxen:\n",
    "            maxen=maxE\n",
    "            maxtitle=gettitle(year,maxE)\n",
    "print(maxtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# does entropy correlate with length of title?\n",
    "alltitlen=[]\n",
    "allentrop=[]\n",
    "for year in range(len(doc_topic)):  \n",
    "    alldocs = doc_topic[year]\n",
    "    for d in alldocs:\n",
    "        allentrop.append(entropy(d))\n",
    "    for idx in range(len(alldocs)):\n",
    "        alltitlen.append(len(gettitle(year,idx)))\n",
    "plt.plot(alltitlen,allentrop,'.')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for kt in range(len(topic_labels)):\n",
    "    print(len(doc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
