{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking into the titles of individual articles with certain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models import ldaseqmodel\n",
    "from gensim.corpora import Dictionary, bleicorpus, textcorpus\n",
    "import numpy as np\n",
    "from gensim.matutils import hellinger\n",
    "import time\n",
    "import pickle\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import entropy\n",
    "\n",
    "from IPython.core.debugger import set_trace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['terms', 'docnames', 'term_topic', 'doc_topic', 'docs_per_year'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldata_new = pickle.load(open('output/dtm_processed_output.p', 'rb'))\n",
    "alldata_new.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "doc_year=alldata_new['docs_per_year']\n",
    "doc_ids =[0]+list(np.cumsum(doc_year))\n",
    "\n",
    "term_topic = alldata_new['term_topic']# term_topic is n_years*n_topics*n_terms\n",
    "terms = alldata_new['terms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sequence', 'face', 'reasoning', 'text', 'color', 'decision', 'sentence', 'causal', 'concept', 'child', 'spatial', 'error', 'category', 'english', 'student', 'network', 'speaker', 'probability', 'agent', 'visual']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"with open('output/all_visdtm.p','br') as f:\\n    allvisdtm=pickle.load(f)\\nfor visdtm in allvisdtm:\\n\\n    visdtm[0]['topiclabel']=topic_labels\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_topicyrs = alldata_new['doc_topic']\n",
    "\n",
    "doc_topic = []\n",
    "for year in range(len(term_topic)):    \n",
    "    doc_topic.append(alldata_new['doc_topic'][doc_ids[year]:doc_ids[year+1]])# doc_topic is nyear*n_docs given year*n_topics\n",
    "    \n",
    "# rename topics by their top freq word\n",
    "topics = range(term_topic.shape[1])\n",
    "\n",
    "def topic_label(topic, term_topic, terms):\n",
    "    term_freqs = np.sum(term_topic[:,topic,:], axis = 0)\n",
    "    max_term = np.argsort(-term_freqs)[0]\n",
    "    return(terms[max_term])\n",
    "\n",
    "\n",
    "topic_labels = [topic_label(topic, term_topic, terms) for topic in topics]\n",
    "print(topic_labels)\n",
    "\"\"\"with open('output/all_visdtm.p','br') as f:\n",
    "    allvisdtm=pickle.load(f)\n",
    "for visdtm in allvisdtm:\n",
    "\n",
    "    visdtm[0]['topiclabel']=topic_labels\"\"\"\n",
    "#topic_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 159,\n",
       " 347,\n",
       " 492,\n",
       " 693,\n",
       " 937,\n",
       " 1334,\n",
       " 1711,\n",
       " 1980,\n",
       " 2153,\n",
       " 2667,\n",
       " 3110,\n",
       " 3663,\n",
       " 4094,\n",
       " 4770,\n",
       " 5267,\n",
       " 5864,\n",
       " 6328,\n",
       " 6920]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alltitles=alldata_new['docnames']\n",
    "doctitle = []\n",
    "for year in range(len(doc_year)):\n",
    "    doctitle.append(alltitles[doc_ids[year]:doc_ids[year+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature1: most typical article of each topics\n",
    "with open('highest_freq.txt','w') as f:\n",
    "    for kt in range(len(topic_labels)):\n",
    "        f.write('\\ntopic '+str(kt)+': '+topic_labels[kt]+'\\n')        \n",
    "        for year in range(len(doc_topic)):  \n",
    "            topicfreq=np.array(doc_topic[year]).T[kt]\n",
    "            idx=np.argmax(topicfreq)\n",
    "            title=doctitle[year][idx]\n",
    "            \n",
    "            f.write(str(year+2000)+': '+title+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature2: \"purest\" / \"most chaotic paper\" \n",
    "maxen=0\n",
    "with open('maxmin_entropy.txt','w') as f:\n",
    "    for year in range(len(doc_topic)):  \n",
    "        f.writelines('\\n'+str(year+2000)+':\\n')\n",
    "        alldocs = doc_topic[year]\n",
    "        allentrop=[]\n",
    "        for d in alldocs:\n",
    "            allentrop.append(entropy(d))\n",
    "        # rank them\n",
    "        maxE = np.argmax(allentrop)\n",
    "        minE = np.argmin(allentrop)\n",
    "        f.writelines('max:'+gettitle(year,maxE)+'\\n')\n",
    "        f.writelines('min:'+gettitle(year,minE)+'\\n')\n",
    "        \n",
    "        # max entropy across years?\n",
    "        if maxE>maxen:\n",
    "            maxen=maxE\n",
    "            maxtitle=gettitle(year,maxE)\n",
    "print(maxtitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# does entropy correlate with length of title?\n",
    "alltitlen=[]\n",
    "allentrop=[]\n",
    "for year in range(len(doc_topic)):  \n",
    "    alldocs = doc_topic[year]\n",
    "    for d in alldocs:\n",
    "        allentrop.append(entropy(d))\n",
    "    for idx in range(len(alldocs)):\n",
    "        alltitlen.append(len(gettitle(year,idx)))\n",
    "plt.plot(alltitlen,allentrop,'.')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for kt in range(len(topic_labels)):\n",
    "    print(len(doc))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
