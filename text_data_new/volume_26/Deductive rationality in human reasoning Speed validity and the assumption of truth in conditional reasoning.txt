UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Deductive rationality in human reasoning: Speed, validity and the assumption of truth in
conditional reasoning

Permalink
https://escholarship.org/uc/item/2033m86b

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)

Author
Schroyens, Walter J.

Publication Date
2004-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Deductive rationality in human reasoning: Speed, validity and the assumption of
truth in conditional reasoning
Walter J. Schroyens (Walter.Schroyens@psy.kuleuven.ac.be)
Laboratory of Experimental Psychology, University of Leuven
Tiensestraat 102, Leuven, B-3000, Belgium

Abstract
We proffer the thesis that, in the process of defeating an
inference on the basis of a factual truth that falsifies it, people
move from a hypothetical truth-value to a factual truth-value of the
conclusion. We will present evidence that shows (a) that some
people spontaneously make a truth assumption and constrain their
inferences to logically valid inferences, (b) that people tend to
abandon the truth-assumption when they have factual evidence to
the contrary, (c) that people, however, can and do in fact reason
logically when they are informed about the rules of the language
game (i.e., the truth-assumption) and (d) that adhering to the truthassumption in the face of conflicting evidence to the contrary
requires an investment of time and effort. The findings are
discussed in relation to contemporary theories of human reasoning.

General Introduction
We all reason: We draw inferences from the multiple
sources of information we are confronted with and make
decisions based on them. This allows us to move around in a
changing world where the capability to comprehend the
contingent nature of our environment determines for a large
part our successes as an individual, as well as a species. The
study of human reasoning is therefore important to advance
our understanding of the general mechanisms of thought.
The turn of the century has provided the stage of a
paradigm shift in human reasoning research. The nineties
provided the scene for polemical debates as regards basic
human reasoning competence. This basic reasoning
competence (i.e., the basic machinery that allows us to draw
inferences) was mostly studied by means of abstract
knowledge-lean inference problem. By using arbitrary
relations (e.g., ‘if the letter is an A, then the number is a 2")
no content-specific background knowledge would be
triggered to influence the reasoning process towards
accepting or rejecting the conclusion. Abstraction was made
of the specific content of that about which people were
reasoning. It is within this research milieu that theories
became specified as regards human deduction. In the study
of human deduction one studies necessary inferences
derived from certain premises. One asks people to draw
logically valid inferences, and these are defined as
inferences that must be necessarily true if the premises are
true. Presently there is an increasingly prominent body of
evidence that shows the pervasive influence of content and
belief (Cummins et al., 1991). Our beliefs are uncertain (i.e.,
they are true to a certain degree: e.g., even Newton’s
mechanics are not universally applicable). This observation
induced a shift towards the study of the subjective
probabilistic properties of that about which we are reasoning
as well as commonsense reasoning or reasoning under

uncertainty.
The present research is situated within this timely clash
between experimental paradigms and associated theoretical
approaches. Theorists sometimes like to boost the polemics
between dichotomized opposites (it does make for simpler,
and hence more easily publishable reading). For instance, it
is claimed that theories that have focused on reasoning
under certainty (i.e., deductive reasoning) are incapable of
being extended to reasoning under uncertainty (i.e.,
probabilistic reasoning). The ‘core argument’ (Oaksford &
Chater, 1998) is that common-sense reasoning is nonmonotonic, whereas logic systems are monotonic: valid
inferences cannot be invalidated; they remain valid. The
validity of everyday inferences however would be revisable.
For instance, when being given the argument:
‘If it is a bird, then it flies;
Tweety is a bird who, thus, can fly”
almost everybody will accept it. At the same time, when
subsequently being told that Tweety is an ostrich, almost
everybody will reject the original inference and will state
that Tweety cannot fly.
The rationality debate in the cognitive science of human
reasoning is partly muddled by a failure to distinguish the
defeasibility of a conclusion from the non-monotonicity of
an inference. For instance, Oaksford and Chater’s (1998)
core argument is subverted when taking count of the
distinction between truth and validity. Monotonicity
concerns the validity of inferences; defeasibility concerns
the truth of conclusions and this “distinction between
validity and truth … is basic to deductive logic [and] many
people find the distinction difficult to grasp” (Glass &
Holyoak, 1986, p. 338). The abovementioned definition of
logical validity use the notion of truth but the truth of a valid
conclusion is always hypothetical (if the premises are true,
then the conclusion must also be true). The truth-value of a
defeated inference however is not hypothetical. It is factual:
it hinges on a factual truth (i.e., our belief, at a particular
moment in time and space that something is true in the
‘real’ world).
The present study intends to show the importance of the
truth-assumption and by consequence the hypothetical
nature of the truth of logically valid inferences. We proffer
the thesis that in the process of defeating an inference
people move from a hypothetical to a factual truth-value of
this conclusion. I present evidence showing (a) that at least
some people make the truth-assumption and spontaneously
constrain their inferences to logically valid inferences, (b)
that people abandon a truth-assumption when they have
factual evidence to the contrary, (c) that people, however,
can and do in fact reason logically when they are informed
about the rules of the language game (i.e., the truthassumption) and (d) that adhering to the truth-assumption in

1225

the face of conflicting evidence to the contrary requires an
investment of time and effort. In the general discussion we
will then return to the theoretical and conceptual issues that
are touched by the evidence for people’s propensity to
exhibit deductive rationality in reasoning hypothetically on

is not satisfied. When the conditional enunciates a causal
statement, such [p and not-q]-cases reflect disabling
conditions. For instance, when we ask people to generate
alternative causes for conditionals (1) and (3), they
generally have little difficulty coming up with a relatively

Table 1
Formal representation and standard nomenclature of the four basic conditional inference problems and their default
conclusions.

Premises
Major
Minor
Conclusion

Logically valid
Affirmation
Denial
Modus Ponens:MP Modus Tollens:MT
[If p then q]
[if p then q]
[p]
[not-q]
[q]
[not-p]

the basis of a truth-assumption.

Experiment
To investigate the truth-assumption in representing the
information with which we are confronted and about which
we reason, and its import apropos validity and deductive
rationality in human reasoning we will make use of wellknown content effects in conditional reasoning. In the
following I first introduce these effects. Next, I present them
within a dual-processing framework. This yields some
additional predictions concerning the functional and
temporal relations of two conceptually distinct types of
reasoning (and the corresponding distinction between
hypothetical versus factual truth).
Content Effects. Table 1 presents the most commonly
studied conditional inference problems. These problems are
formed by an affirmation or denial of the antecedent [p] or
consequent [q] of a conditional of the form [if p then q]. The
content of the conditional utterance can be almost anything,
e.g.:
(1) If you turn the key, then the car will start.
(2) If you heat water to 100°C, then it will boil.
(3) If you push the brake, then the car will stop.
(4) If you jump into the swimming pool, then you’ll get wet.
The content effects that are observed with such realistic
conditional-inference problems show that the reasoning
process is strongly affected by the factual truth of the
premises and/or conclusion (Politzer & Bourmaud, 2002).
At a general level the content effects are summarized as
an effect of the number of factual counter-examples. For
instance, the conclusions for AC and DA are falsified by
situations that reflect the possibility that the antecedent is
false [not-p] while the consequent is nonetheless observed
[p]. When the conditional captures a causal statement, such
[not-p and q]-cases reflect alternative causes. For instance,
when we ask people to generate alternative causes for
conditionals (1) and (2), they generally come up with
relatively few as compared to the number of alternative
causes they can generate for conditionals (3) and (4). The
conclusions of MP and MT are countered by situations that
represent the contingency where [p] is satisfied whereas [q]

Logically Invalid
Affirmation
Denial
Affirm consequent: AC Denial Antecedent: DA
[if p then q]
[if p then q]
[q]
[not-p]
[p]
[not-q]
high number of factors that might prevent the effect from
occurring. For conditionals (2) and (4) people can only
come up with few disabling conditions. The most robust
finding in reasoning with conditionals like (1), (2), (3) and
(4) above, is that people are less likely to accept MP/MT
when there are many (vs. few) disablers and are less likely
to accept AC/DA when there are many (vs. few)
alternatives.
We proffer the thesis that belief effects in conditional
reasoning and the presumed problematical nature of these
effects for systems of deduction are due to a failure to play
the language game of deduction. When one does not ask
people to assume that the premises are true, people are not
asked to reason deductively. Studies that investigate
content-effects in conditional reasoning often do not even
mention the truth-assumption. This implies that no
implications can be drawn as regards people’s deductive
rationality (i.e., their propensity or capability to infer
logically valid inferences). To demonstrate the importance
of the truth-assumption in deduction reasoning, we decided
to stress the truth-assumption and its implication that any
inference made under this assumption is hypothetically true.
The experiment was set up so we could compare
performance on problems that did not stress the truthassumption with problems that did stress the truthassumption.
Expectations are relatively straightforward. When people
are reasoning on the basis of the truth-assumption they will
exhibit more deductive rationality as compared to situations
where they reason in an unconstraint context. Deductive
rationality in the present study is measured by the
proportion of inferences that are valid relative to the norm
of classic logic. That is, when people reason in a stressed
truth-assumption context, they will endorse more logically
valid MP and MT inferences. The logically invalid AC/DA
arguments would not be affected by an increased impetus
the hypothetical nature of inferences made under the truth
assumption. Indeed, the counterexamples to MP/MT would
be excluded or impossible, if the conditional were true.
However, the counter-examples to AC/DA (i.e., alternative
causes) are consistent with a conditional utterance of the
form [if p then q]. Indeed, the utterance “If you jump into

1226

the swimming pool, then you’ll get wet” does not say ‘if and
only if you jump into the swimming pool, then you’ll get
wet”. In sum, there should be an interaction between the
logical-validity of the inference and the impetus that is
placed on the truth-assumption.
Dual Processing. We noted that the present research is
situated within the timely clash between experimental
paradigms and associated theoretical approaches. Being
faced with the task of reconciling the ‘old’ (deductive
certainty) and the new (probabilistic uncertainty), there is an
increasing popularity of so-called dual processing
frameworks. There presently seems to be a growing
consensus that a distinction can be made between two types
of rationality, or systems of reasoning (see, e.g., Evans &
Over, 1996; Johnson-Laird, 1983; Stanovich & West, 2000).
Dual-process theories of reasoning draw on the distinction
between, on the one hand, highly contextualized associative,
heuristic, tacit, intuitive or implicit processes that are
holistic, automatic, experiential in nature, and relatively
undemanding of cognitive capacity and, on the other hand,
de-contextualised, rule-based, analytic, explicit processes
that are relatively slow, and demanding of cognitive
capacity.
There is a commonality in almost all dual-processing
theories. About the functional relation between the two
reasoning systems it has been argued that there is a primacy
of System 1 processes (Stanovich & West, 2000). Evans and
Over (1996) similarly discussed the override function of
System 2 (Explicit, Rationality-2 in their terminology). This
functional relation parallels the distinction and relation
between generate and test procedures (Chater & Oaksford,
1999) or, analogously, the conclusion formulation and
validation stages proffered in the highly influential mental
models approach to reasoning (Johnson-Laird, 1983;
Johnson-Laird & Byrne, 1991, 2002). We can associate
factual/probabilistic reasoning and hypothetical/deductive
reasoning with respectively System-1 and System-2
thinking. The override function of System-2 as regards the
output of System-1 consequently allows us to specify some
additional expectations concerning the potential effect of
stressing the truth-assumption.
In the dual-processing framework it is assumed that
System-2 processes are secondary to the workings of
System-1 processes. This implies that if we can inhibit
system-2 thinking, the effects of its functionality will be
reduced. That is, we would expect the effect of stressing the
truth-assumption to be reduced under conditions that are not
conducive to system-2 thinking. We can expect, the other
way round, that when we can instigate system-2 thinking,
the effect of its potential override function would be
increased. This means that the effect of stressing the truthassumption would be strongest under conditions that allow
people to engage in the resource-dependent and timeconsuming system-2 type of thinking.
We asked one group to reason as quickly as possible,
thereby reducing the potential import of the system-2
thinking (see Schroyens, Schaeken, & Handley, 2003) and
the expected effect of stressing the truth-assumption. A
second group was asked to think carefully. Given that

people are less likely to engage in system-2 thinking under
speeded inference conditions (as compared to the standardinference conditions), we can expect that the inhibitory
effect of stressing the truth-assumption will be annulled.
That is, the other way around, only people who have the
time and motivation to engage in system-2 type thinking
will exhibit the effect of stressing the truth-assumption.

Method
Design. Participants served as their own control as regards
inference type (logically valid: MP/MT vs. logically invalid:
AC/DA), the number of alternative causes (few vs. many),
the number of disabling conditions (few vs. many), and the
impetus that was placed on the truth-assumption (no vs.
strong). A between-groups factor was formed by the
impetus that was placed on speed vs. accuracy.
Materials. We collected 16 conditionals utterances for
which people in a pre-test were able to generate few or
many alternatives and few or many disablers (see, e.g.,
items 1-4 presented above). The set contained four items for
each of these four types of conditionals with few/many
alternatives/disablers. Each conditional served as the major
premise for each of the four types of inference problems
(MP/MT/AC/DA, see Table 1).
The inference problems were cast into two booklets. A
first booklet contained the 32 items that did not mention the
truth-assumption and a second booklet with 32 other items
that stressed the truth-assumption. (The specific item
content was counter-balanced across the two truthassumption conditions). Each counterbalancing set
contained two items of an MP/AC/DA/MT argument about
a conditional with few/many alternatives/disablers
(2x4x2x2=32). The non-stressed condition presented the
problems as follows.
If you turn the key, then the car will start.
You turn the key.
It follows:
The car will start.
Participants marked their evaluation of this conclusion on
a 7-point scale ranging from (1) very uncertain that the
conclusion follows to (7) very certain that the conclusion
follows. In the stressed truth-assumption condition the
problem was presented in the following format:
If you assume that it would always be true that:
If you turn the key, then the car will start.
And you know for sure:
You turn the key.
Then it would follow:
The car will start.
Participants marked their evaluation of this conclusion on
a 7-point scale ranging from (1) very uncertain that the
conclusion follows if one assumes that the rule is true to (7)
very certain that the conclusion follows if one assumes that
the rule is true.
The instructions to the speeded inference conditions
mentioned that they were to evaluate the problems fast and
should not stay too long with any particular problem. After
the 3rd and the 6th sheet of paper, with four problems per
page, an extra page was inserted which reminded them that

1227

they were to make their judgment ‘as quickly as
possible’. In the accuracy conditions this reminder
said that they were to ‘think carefully’ and that their
evaluations of the conclusions should be ‘as
accurate as possible’.

Figure 1

Procedure. Participants received both problem
booklets at the beginning of the session (the
standard problems first; the truth-assumption
problems second). About half the students in each of
two 11th and two 12th grade classes received the
problems with speeded-inference instructions,
whereas the other half received the accuracy
instructions. The students in accuracy groups were
told that the one who generated the most correct
conclusions of a predetermined subset would
receive 10 Euro. To the speeded groups it was said
that the person who solved the problems fastest (at a
minimum accuracy level) would also receive 10
Euro.

0.95

th

th

Participants. Participants were 72 11 and 12
grade student from a Belgian, Flemish high school.
Thirty-four students received the speeded-inference
instructions; the remaining 38 pupils ended up in the
accuracy conditions.

Results

Certainty ratings of the logically valid and invalid arguments under
standard conditions that do not mention the truth assumption.
1.00

Speeded Conditions
Accuracy Conditions

0.90

Certainty Ratings

0.85
0.80
0.75
0.70
0.65
0.60
0.55
0.50
0.45
0.40
Counter- Few
Many
examples
Logically Valid

Counter- Few
Many
examples Logically Invalid

Figure 2
Counterexample effects on the logically valid and invalid arguments as a
function of a timing constraint and the explicit presence of the truth
assumption.

Counterexample effect (Few - Many)

Certainty ratings (1-7) were transformed to the [0,1]
probability interval and submitted to analyses of
variance. Figure 1 presents the effect of alternatives
on the logically invalid inferences (AC/DA), and the
effect of disablers on the logically valid inferences
(MP/MT) in the standard conditions that do not
mention the truth assumption. These standard
problems replicate the standard findings. First, the
number of disablers affected the certainty ratings of
the logically valid inferences: Participants are more
certain that the conclusion follows when there are
few counterexamples, .81 vs. .69; F(1,70) = 53.06, p
< .01. Second, the invalid inferences also showed the
standard counterexample effect of few vs. many
alternatives: Participants rate the conclusions less
certain when more counterexamples can be found for
it, .81 vs. .60; F(1,70) = 153.75, p < .01. Figure 1
also shows that the counterexample effect is larger on
the logically invalid inference, as compared to the
logically valid inferences; F(1,70) = 21.38 p < .01.
Figure 2 shows the size of the counterexample
effect (few vs. many) as a function of the timing constraint,
logically validity and the assumption of truth. Figure 2
clearly shows that the counterexample effect on the
logically valid inferences is reduced when people make the
truth-assumption, F(1,70) = 14.21, p < .001, but only so
when individuals reason without a timing constraint and
focus on accuracy, F(1,70) = 19.67, p < .01. The
counterexample effect does not approach significance in this
condition, .866 vs. .853. The interaction between speed and
truth at the level of the valid inferences was significant,
F(1,70) = 5.41, p < .05. No such interaction was observed at

0.30

Without Truth Assumption
With Truth Assumption

0.25
0.20
0.15
0.10
0.05
0.00

Accuracy
Speed
Logically Valid

Accuracy
Speed
Logically Invalid

the level of the invalid inferences (F = .003), and the thirdlevel interaction indeed tended to approach statistical
significance, F(1,70) = 2.85, p < .10. Specific comparisons
showed that, as expected, the counterexample effect on the
valid inferences re-appears when people evaluate the
conclusions as fast as possible, .873 vs. .808: F(1,70) =
9.66, p < .01. That is, stressing the truth-assumption does
not reduce the counterexample effect on the logically valid
inferences when people are reasoning under a timing
constraint (F < 1). At the level of the logically invalid
inferences, we see an overall reduction of the
counterexample effects, F(1,70) = 13.22, p < .01. This
might suggest that stressing the truth-assumption tends to

1228

induce an overall inhibition of background knowledge. The
fact that the truth-assumption effect on the valid inferences
depends on the timing constraint tells us that this is not the
entire story. Also, as noted before, the counterexample
effects on the valid inferences are completely annulled when
the truth-assumption is stressed (under accuracy conditions),
whereas Figure 2 shows that they are still very much present
on the invalid inferences under the same conditions. The
reduced counterexample effects on the invalid inferences
presented under truth conditions concurs with the idea that
some people adopt a bi-conditional interpretation of ‘if’.
The alternative causes are then theoretically or
hypothetically (i.e., under the assumption of the truth of the
utterance) impossible.

Discussion
Our findings corroborate several of the claims we have
made regarding deductive rationality in human reasoning.
First, in order to reason deductively one has to make and
adhere to the truth-assumption. We observed that the
counter-example effect on the logically valid inferences is
indeed smaller than that on the logically invalid inferences.
The counter-examples to logically valid inferences are
indeed (hypothetically) impossible – this is actually why
these inferences are logically valid. Second, though we have
evidence that some people spontaneously exhibit deductive
rationality in adhering to the truth-assumption, other people
clearly abandon the truth-assumption in the light of factual
evidence to the contrary. The probabilistic counterexample
effects on the logically valid inferences attest to this.
The speed/accuracy manipulation and the effects of
stressing the truth-assumption provide strong support to our
analyses of deductive rationality within a dual processing
scheme. First, the overall increase in deductive rationality
(as measured by the increase in the certainty ratings of the
logically valid inferences) under conditions that stress the
truth-assumption lends support the centrality of the truthassumption in the notion of logically validity and human
deductive reasoning. Second, the annulment of the counterexample effects on the logically valid inferences under
conditions that make it clear that the truth of inferences
about factually false utterances is a hypothetical truth, is
also in agreement with the thesis that people inhibit factual
knowledge that conflicts with the hypothetical truth of the
utterances people reason about. Third, the dependency of
the counter-example effect annulment on the time and effort
people take to provide an evaluation of the conditional
inferences, concurs with (and was predicted on the basis of)
the thesis that probabilistic content-driven reasoning is
primary to the effortful abstract, analytic hypothetical
reasoning processes that can serve to override the output of
the fast and frugal heuristic processes.

General Discussion
Our study shows the import and importance of the truthassumption as regards deductive rationality in human
reasoning. In the current general discussion we will touch
upon some wider theoretical and conceptual issues. We will
first consider the rational basis for the truth-assumption.
Next, we will consider the import and importance of the

truth-assumption as regards arguments that have been made
in discussions of the non-monotonic and/or defeasible
nature of human reasoning.
An Implicit vs. Explicit Truth-Assumption. We found
support for thesis that at least some people make the truthassumption and actually stick to it. It remains the case,
however, that the majority of people will abandon the truthassumption. The sizable counterexample effects on the
logically valid inferences evidence this. One can only claim
that the truth-assumption is abandoned when it is made in
the first place. The question that then arises is whether those
people who do not follow the truth-assumption (by taking
count of factual knowledge to the contrary) actually made it
in the first place.
It is our contention that when people form a
representation of the utterances they are confronted with,
they initially and implicitly make the assumption that the
proposition expressed by it is true. This is in accordance
with the Gricean maxims of conversation (which by
themselves are related to Kant’s four a priori categories of
quantity, quality, relevance and modality): we generally
assume/ensure that our or the speaker’s contribution is
truthful, relevant and as informative as possible, though not
more detailed than required by the context (Grice, 1975).
The truth-assumption is an implicit assumption (see, e.g.,
Schroyens, Schaeken, & d’Ydewalle, 1999). It is partly
because it is an implicit assumption (at least to start with)
that it is easily abandoned. The rational basis of the truthassumption can be found in the idea of bounded rationality
or cognitive economy. There is a representational cost
attached to considering all possibilities, both true and false.
Most current theories presume the truth-assumption. This
is not very surprising when one considers that truth is
ontologically primordial to falsity: Non-truth presumes truth
– as non-being presumes being. The mental-models theory
(Johnson-Laird & Byrne, 2002) is the single one theory that
is most explicit in invoking the truth-assumption. Indeed, it
forms the basis of the truth-principle as regards the
representation of the meaning of conditionals of the form [if
p then q]. This principle states that people initially represent
only represent true possibilities. Oaksford, Chater, & Larkin
(2000) seems to have the only theory for which it is difficult
to see whether it incorporates the truth-assumption. They do
not seem to distinguish true from false utterances. There are
only degrees of truth (i.e., probabilities). This restriction to
factual truth (verisimilitude) is problematical because there
is plenty of evidence that shows that people can reason
hypothetically and deductively.
Truth, Validity and Non-Monotonic Reasoning. We
situated the present study within the timely clash between
paradigms focusing on deductive or probabilistic reasoning
and presented the core argument that is made against logic
theories. Theories of human deduction would not be capable
to cope with the defeasible nature of human reasoning.
Our introductory analyses of the core argument against
mental logic have shown that the issues are more complex:
The defeasibility of a conclusion does not necessarily imply
the non-monotonicity of an inference. Let us reiterate our

1229

arguments against the claim that logic is in trouble because
it is monotonic, while commonsense reasoning would not be
Indeed, we have come to the somewhat controversial
conclusion that it remains an open question whether
commonsense reasoning is non-monotonic (even though we
know it is defeasible).
We know that the counterexamples to the Modus Ponens
argument (MP: if p then q, p, therefore q) are cases that
naive reasoners (as opposed to logicians) consider
impossible if the conditional utterance is true (Evans, Ellis,
& Newstead, 1996). When they assume that [if p then q] is
true, most people generally judge that it would be
impossible that there are [p and not-q]-contingencies:
situations wherein the consequent does not follow from the
antecedent. In short, when people defeat a logically valid
inference this simply indicates that peoples’ intuitive notion
of validity does not match that of logical validity. The
pervasive ‘belief effects’ show that reasoners are much
more concerned with the factual truth of a conclusion
(Tweety the ostrich does not fly), as compared to the
hypothetical truth of such conclusions (if it were true that all
birds fly then Tweety the ostrich would fly).
Since logical validity encompasses the truth assumption,
defeating a necessary inference marks the abandonment of
this truth-assumption. By consequence it remains
undetermined whether people have reasoned nonmonotonically (i.e., revised a judgment of logical validity
into a judgment of logical invalidity). When we assume, for
arguments sake, that people actually aim to derive logically
valid inferences, the defeasibility of inferred inferences
shows that people shift from one notion of validity (i.e.,
logical validity, which includes the truth-assumption) to
another notion of validity (let us call it ‘psychological
validity’, which gives more weight to factual truth and
allows a truth-assumption to be annulled). It seems one
succumbs to the fallacy of equivocating two distinct
concepts (logical and psychological validity), when
defeasibility of an inference is taken to indicate nonmonotonicity of human reasoning.
Because classic logic is monotonic while everyday
reasoning is presumably non-monotonic (or at least
defeasible), it has been stated that neither mental-models
theories nor mental-logic theories are capable of explaining
common-sense reasoning. It is hard to see why polemics
have been created when defeating inferences is actually at
the heart of mental models theory. Mental-models theory
holds to a three-stage processing scheme. People first
generate initial (incomplete) representations of what they
think is possible if the premise are true (modelconstruction); they then integrate the representation of the
multiple source of information that form a reasoning
problem (model-integration). This allows them to generate a
putative conclusion, which, third and most importantly, at
least some people at least sometimes attempt to test by
looking for a counterexample. A conclusion is rejected
and/or modified in the light of conflicting information. That
is, defeasible reasoning is in no way beyond the reach of
mental-models theory, quite on the contrary:
“It is worth given up, not the thesis that human beings are
capable of rational thought, but the idea that what underlies

this ability is a mental logic. There can be reasoning without
logic. More surprisingly, perhaps, there can be valid
reasoning without logic” (Johnson-Laird, 1983, p. 40).

Acknowledgments
The present research was done with the support of the
Flanders (Belgium) Fund for Scientific Research and the
Research Council of the University of Leuven. We also like
to express our grateful acknowledgments to Sunile Maes
and Lieven Brebels for their help in collecting the data.

References
Chater, N., & Oaksford, M. (1999). The probabilistic
heuristics model of syllogistic reasoning. Cognitive
Psychology, 38(2), 191-258.
Cummins, D. D., Lubart, T., Alksnis, O., & Rist, R. (1991).
Conditional reasoning and causation. Memory &
Cognition, 19, 274-282.
Evans, J. St. B. T., Ellis, C. E., & Newstead, S. E. (1996).
On the mental representation of conditional sentences.
Quarterly Journal of Experimental Psychology, 49A,
1086-1114.
Evans, J. St. B. T., & Over, D. E. (1996). Rationality in
reasoning. Hove, UK: Psychology Press.
Grice, H. P. (1975). Logic and conversation. In P. Cole, &
J. L. Morgan (Eds.), Studies in syntax: Speech acts,Vol. 3,
(pp. pp. 41-58 ).New York: Academic Press.
Johnson-Laird, P. N. (1983). Mental models: Towards a
cognitive science of language, inference, and
consciousness. Cambridge: Cambridge University Press.
Johnson-Laird, P. N., & Byrne, R. M. J. (2002).
Conditionals: A theory of meaning, pragmatics, and
inference. Psychological Review, 109(4), 646-678.
Oaksford, M., & Chater, N. (1998). Rationality in an
uncertain world. Hove, UK: Psychology Press.
Oaksford, M., Chater, N., & Larkin, J. (2000). Probabilities
and polarity biases in conditional inference. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 26, 883-899.
Politzer, G., & Bourmaud, G. (2002). Deductive reasoning
from uncertain conditionals. British Journal of
Psychology, 93, 345-381.
Schroyens, W., Schaeken, W., & d'Ydewalle, G. (1999).
Error and bias in meta-propositional reasoning: A case of
the mental model theory. Thinking and Reasoning, 5(1),
29-65.
Schroyens, W., Schaeken, W., & Handley, S. (2003). In
Search of Counter Examples: Deductive Rationality in
Human Reasoning. Quarterly Journal of Experimental
Psychology, 56A(7), 1129-1145.
Stanovich, K. E., & West, R. F. (2000). Individual
differences in reasoning: Implications for the rationality
debate? Behavioral and Brain Sciences, 23, 645-726.

1230

