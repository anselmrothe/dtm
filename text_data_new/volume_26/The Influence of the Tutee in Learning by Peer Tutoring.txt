UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Influence of the Tutee in Learning by Peer Tutoring

Permalink
https://escholarship.org/uc/item/3g30r749

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)

Authors
Roscoe, Rod D.
Chi, Michelene T.H.

Publication Date
2004-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Influence of the Tutee in Learning by Peer Tutoring
Rod D. Roscoe (roscoe@pitt.edu)

Michelene T. H. Chi (chi@pitt.edu)

Learning Research and Development Center, 3939 O’Hara Street
Department of Psychology, University of Pittsburgh
Pittsburgh, PA 15260 USA
Abstract
Previous research has demonstrated that students can learn by
tutoring other students. Tutors are thought to learn because
they generate instructional explanations and monitor their
own understanding while teaching. We analyzed verbal data
from tutorial sessions to explore how the tutees influence this
process. We found that tutors were primarily responsible for
introducing topics, but the tutees stimulated more thorough
discussions of topics. We also found that tutee questions
influenced tutor explanations and metacognition. Tutor
responses to “deep” questions were more likely to contain
inferences and self-monitoring than responses to “shallow”
questions. In sum, tutees had a significant and positive
influence on the tutors’ learning activities and opportunities.

Introduction
Peer tutoring and cross-age tutoring are popular and costefficient educational interventions in which students provide
instruction for other students.
One reason for the
widespread use of these interventions is their effectiveness –
with training, students seem quite capable of successfully
teaching each other and younger pupils (e.g. Cohen, Kulik,
& Kulik, 1982; Greenwood, Carta, & Hall, 1988). Another
reason for the popularity of peer and cross-age tutoring
programs is the robust finding that the tutors also benefit
academically from the teaching experience (e.g. Allen &
Feldman, 1973; Annis, 1983; Cloward, 1967; Cohen et al.,
1982; Greenwood et al., 1998; Morgan & Toy, 1970;
Rekrut, 1992). Based on such findings, some researchers
have advocated reciprocal tutoring programs in which the
participating students take turns being the tutor and tutee. In
general, these programs are educationally effective (e.g.
Fantuzzo, King, & Heller, 1992; Fantuzzo et al., 1989;
Fuchs et al., 1997; King, Staffieri, & Adelgais, 1998;
Palincsar & Brown, 1984).
Why do students learn by tutoring? Some evidence
suggests that tutors learn by generating instructional
explanations, which facilitates integration and organization
of knowledge. For example, Coleman, Brown, & Rivkin
(1997) found that when students were told to teach a peer by
explaining, they learned better than students told to teach by
summarizing and better than students who did not teach.
Similarly, Fuchs et al. (1997) showed that training students
to give each other conceptually-rich explanations during
reciprocal tutoring was more effective than classroom
instruction and reciprocal tutoring without such
explanations. Additional evidence indicates that tutoring
may also encourage students to engage in metacognitive

self-monitoring, which helps learners to detect and repair
missing knowledge and misconceptions. For example, King
et al. (1998) trained reciprocal tutors to give quality
explanations and to ask each other questions that stimulated
critical thinking and self-monitoring. They found that these
explaining and metacognitive activities resulted in better
learning than explaining activities alone. Explaining and
self-monitoring have also been shown to improve learning
in solo studying (e.g. Chi, 2000; Chi, deLeeuw, Chiu, &
LaVancher, 1994) and collaborative learning (e.g. Coleman,
1998; Webb, Troper, & Fall, 1995), which further highlights
the efficacy of these activities.
In this paper, we explore the hypothesis that tutees
influence the learning activities of the tutors in important
ways. In other words, tutors might be able to learn by
explaining and self-monitoring, but tutees may affect how
and whether these activities occur. One way that tutees may
guide the tutorial session is by choosing which topics are
discussed and in how much detail, thus creating or limiting
opportunities to think about the underlying ideas. Another
powerful way in which tutees may influence the learning
activities of the tutor is through the kinds of questions they
ask. As described above, King (e.g. King, 1994; King et al.,
1998) has shown that when students construct and ask each
other questions based on high-level question stems (i.e.
questions prompting for comparisons, justifications, causesand-effects, evaluations, etc.), they produce better
explanations and learn more effectively. Coleman (1998)
has demonstrated very similar findings in collaborative
learning settings with students using high-level explanation
prompts. Research on naturalistic tutoring has shown that
tutees do occasionally ask “deep” questions in tutoring
sessions, although the majority of questions are “shallow”
(Graesser & Person, 1994). These deep questions, although
they may be rare, should stimulate deeper responses.
In order to address these hypotheses about the influence
of the tutee on tutor learning, we analyzed tutor learning in a
non-reciprocal and naturalistic (i.e. little or no training)
tutoring context. This design allowed us to be more
sensitive to the benefits and processes of tutoring. In
reciprocal tutoring, by definition, students learn from both
teaching and being taught, and thus it is almost impossible
to assess the specific contribution of tutoring activities to
learning in these settings. Similarly, it is possible that when
tutoring programs are highly structured (i.e. training on
when and how to explain, ask and answer questions, etc.),
important aspects of spontaneous tutoring behaviors that
positively or negatively impact learning may be obscured.

1179

Method
Background
In a larger study, we compared learning by self-explaining
to learning by explaining-to-others. Overall, we found that
self-explaining was superior to explaining-to-others on
measures of both deep and shallow learning.
Selfexplaining also seemed to more naturally foster productive
learning activities. However, the focus of the current
analyses is on the learning outcomes and activities
associated with providing instruction for other students.

Conditions
The data we analyze here was obtained from two tutoring
conditions. In one condition, a student who had read and
studied a text about the human eye and retina (the tutor)
taught this information to another undergraduate (the tutee)
in a face-to-face setting. In a second condition, a student
who had read and studied the human visual system test (the
tutor) produced a videotaped explanatory lesson that could
be later used by a different student to learn the material (an
“anticipated” tutee). The face-to-face tutoring condition can
be conceptualized as an “instructional dialogue” whereas the
videotape condition can be thought of as an “instructional
monologue.” The participants received no formal training
for the tutoring task. The tutors were simply instructed to
explain the text information by “going beyond what the text
says.” Students in the instructional dialogue condition were
encouraged to try to answer the tutees’ questions.

Participants
Twenty-four college undergraduate students participated in
the instructional dialogue (n = 7 tutor/tutee pairs) and
instructional monologue conditions (n = 10 tutors) of the
original study. In order to ensure that all participants had
low prior knowledge about the learning domain (the human
eye and retina), students who had taken certain biology,
physiology, and neuroscience courses were not eligible to
participate. Participants were paid for their time.

Materials
Human Visual System Text All tutors initially read and
studied a short text describing the structure and functions of
the human eye and retina. The text was divided into topicbased sections, with each topic presented on a separate page.
These topics included both familiar, everyday concepts (e.g.
the pupil) and unfamiliar, technical ideas (e.g. refractive
properties of the vitreous humor), thereby providing ample
opportunities to make connections with prior knowledge
and explore new ideas. However, the text itself provided
few examples or analogies. The text was accompanied by a
labeled cross-section diagram of the whole eye and a
schematic diagram of the retina. Prior research has shown
that the availability of diagrams can support and stimulate
effective explaining (Ainsworth & Loizou, 2003).

Learning Assessments Learning outcomes were assessed
using two written measures. For the Definition Test,
students provided definitions of key terms. For the
Question Test, students responded to short-answer questions
testing recall, integration, and application of information.
The Definition Test can be viewed as a measure of the
students’ shallow learning, and the Question Test can be
considered a measure of deeper learning. Both measures
were scored by tabulating the number of correct and
relevant ideas produced.

Procedure
The study was divided into two sessions in order to facilitate
recruitment and scheduling of participants. In the first
session, the tutors read and studied the text for 30 minutes
and then completed both learning assessments (tutor pretest). It should be noted that the tutors studied the text
without foreknowledge of their future teaching task. The
purpose of this design was to bypass complications due to
preparation-to-teach effects (Bargh & Schul, 1980; Renkl,
1995). The tutees also completed both learning assessments
in this phase, but did not have the opportunity to read about
the visual system (tutee pre-test). In the second session, the
tutors either taught an actual tutee or produced a videotaped
lesson (30 minutes duration). Afterwards, the tutors and
tutees completed the learning assessments again (post-test).

Coding of Tutor Activities
The tutorial sessions of the dialogue and monologue
conditions were transcribed and segmented according to
changes in the topic of discussion. These segments formed
the boundaries of episodes, which were categorized by the
type of learning activity that occurred. Several different
activities were observed and are briefly described below.
Summary In “basic” summaries, the tutor paraphrased the
current contents of the text without elaborating on the text
ideas. In “elaborated” summaries, the tutor paraphrased the
text, but also provided additional information or inferences
not contained in the text. Neither type of summary was
significantly correlated with learning outcomes.
Review In “basic” reviews, the tutor reviewed previously
discussed information without elaboration. In “elaborated”
reviews, the tutor reviewed previously covered material, but
also provided new information and inferences. Elaborated
reviews were highly metacognitive (i.e. students monitored
themselves for understanding and accuracy) and positively
correlated with learning outcomes.
Sense-Making In sense-making episodes, the tutor
generated inferences and integrated text concepts in order to
address a perceived misconception or one’s own curiosity.
Sense-making episodes were highly metacognitive (i.e.
students monitored themselves for understanding and
accuracy) and positively correlated with learning outcomes.

1180

Analyses and Results
Tutor and Tutee Learning
Our results indicated that the two tutoring conditions were
not equally effective for learning (Table 1). Tutors in the
instructional dialogue condition performed better than tutors
in the instructional monologue condition on post-test
measures of shallow learning (Definition Test) and deeper
learning (Question Test), although only the Definition Test
difference was statistically significant after controlling for
pre-test differences, F(1,14) = 9.22, p = .009.
In order to establish that the dialogue tutors were effective
instructors, we compared the tutors’ final scores to their
tutee’s final scores. For both tests, the tutees performed
almost as well as their tutors, suggesting that the tutors were
mostly successful in teaching their pupils (Table 1). Neither
difference was significant. Although the tutees learned
somewhat less than the tutors, it is still quite impressive
given that the tutees were exposed to the material only once
(the tutoring session) and never read the text.
Table 1: Mean Definition Test and Question Test scores.
Measure
Definition Test
Question Test

Monologue
Tutors
21.3
20.2

Dialogue
Tutors
33.0
28.0

Dialogue
Tutees
27.5
25.4

Spontaneous and Elicited Tutor Activities
These learning outcome differences were paralleled by the
extent to which the tutors engaged in episodes of integrative
and metacognitive activity (Table 2). Overall, the dialogue
tutors produced more elaborated review and sense-making
episodes than monologue tutors, F(1,14) = 5.47, p = .035
and F(1,15) = 16.22, p = .001, respectively. No other
differences were significant.
Table 2: Overall mean frequency of episodes.
Episode Category
Summary
Basic
Elaborated
Review
Basic
Elaborated
Sense-making

Monologue
Tutors

Dialogue
Tutors

10.5
4.4

13.0
5.4

3.1
0.2
0.4

6.3
1.7
3.7

In order to examine this finding more closely, we further
distinguished between activities that the tutors self-initiated
and activities that were elicited by the tutee. An episode
was coded as “tutee-initiated” if the tutee selected the topic
or asked a question leading the tutor to engage in some
activity. All other episodes were categorized as “tutorinitiated”. All of the monologue tutors’ activities were
counted as tutor-initiated because no tutee was present.

The pattern of episode frequencies (Table 3) suggests that
tutors in both conditions preferred to summarize the text,
while tutees in the dialogue condition elicited most of the
reviewing activities. Direct comparisons of the mean
frequencies of tutor and tutee-initiated activities confirmed
this impression. Dialogue tutors initiated significantly more
basic and elaborated summaries than dialogue tutees;
F(1,12) = 8.2, p < .05 and F(1,12) = 8.3, p < .05,
respectively. However, the tutees initiated significantly
more basic and elaborated reviews; F(1,12) = 7.5, p < .05
and F(1,12) = 5.3, p < .05, respectively.
Table 3: Mean frequency of tutor-initiated and tuteeinitiated episodes.
Episode
Category
Summary
Basic
Elaborated
Review
Basic
Elaborated
Sense-Making

Monologue
TutorInitiated

Dialogue
TutorInitiated

Dialogue
TuteeInitiated

10.5
4.4

9.7
4.7

3.3
0.7

3.1
0.2
0.4

1.3
0.2
2.3

5.3
1.5
1.4

The critical difference between the monologue tutors’
activities and the tutor-initiated activities of the dialogue
tutors was in the occurrence of sense-making episodes;
F(1,15) = 4.5, p < .05. No other difference was significant.
Tutors engaged in sense-making when they realized that
they had a flawed or incomplete understanding of some
concept and needed to revise their own knowledge. Thus, in
addition to eliciting productive reviewing of the material,
the tutees seem to also directly and indirectly facilitate the
tutors’ recognition and repair of their own misconceptions.
Perhaps the tutee’s misunderstandings and questions served
as a signal to the tutor that the tutor’s explanations were
incorrect or unclear, and this realization spurred the tutor to
engage in sense-making in order to understand the material
better and to be a more effective teacher.
In sum, these results provide evidence that tutors in nonreciprocal tutoring settings, and with minimal training, can
learn from generating instructional explanations and selfmonitoring. However, when tutors provided instruction to
an actual tutee, they learned and explained more effectively.
Thus, it appeared the tutees did in fact contribute to the
tutors’ learning activities in meaningful ways. In the next
sections, we explore two hypothesized mechanisms for this
influence, topic selection and tutee questions.

Topic Coverage
One way that tutees may guide the tutorial session is by
choosing which topics are covered and how much time is
spent on those topics. Topics that receive more thorough
consideration should be better learned. To examine the
coverage of topics in the tutoring sessions, each episode was
coded by whether it contained a novel topic (i.e. topic was

1181

introduced in that episode) or whether it contained a
continuation of a previous topic. A continuation episode
could contain a review or elaboration of the topic, and thus
represents a deeper or more thorough discussion (Table 4).
Overall, we observed a clear pattern in which the tutors
were primarily responsible for introducing new topics in the
tutoring session (76% of novel episodes were tutorinitiated), whereas tutees stimulated much of the subsequent
discussion of topics (61% of continuation episodes were
tutee-initiated). This pattern was statistically significant;
χ2(1,N=349 episodes) = 50.0, p < .001, and indicates that
tutees directly influenced opportunities for tutors to delve
more deeply into the text information by selecting topics for
review or elaboration.
Table 4: Introduction and continuation of topics of
discussion by tutors and tutees.
Topic
Selector
Tutor
Tutee
Totals

Novel
Topic
134 (76%)
42 (24%)
176

questions were equally likely to elicit a deep or shallow
response (Table 5). In other words, deep questions were
more likely to receive a deep response (41%) than were
shallow questions (14%). It was fairly rare for a question to
be ignored (receive no response). The overall pattern was
significant; χ2(2,N=240 questions) = 26.1, p<.001.
Table 5: Tutee questions and subsequent shallow or deep
tutor responses.
Question
Depth
Shallow
Deep

No
Response
15 (10%)
12 (14%)

Shallow
Response
116 (76%)
40 (46%)

Deep
Response
21 (14%)
36 (41%)

Totals
152
88

Analyses of self-monitoring in tutor responses to tutee
questions showed a similar pattern (Table 6). Shallow tutee
questions tended to elicit non-metacognitive responses.
However, the tutees’ deep questions elicited metacognitive
responses from the tutors about half the time. This pattern
was significant; χ2(1,N=240 questions) = 20.8, p<.001.

Continued
Topic
67 (39%)
106 (61%)
173

Table 6: Tutee questions and subsequent metacognitive or
non-metacognitive tutor responses.

Tutee Questions and Tutor Responses
Another important mechanism by which tutees might
influence the learning activities of the tutor is through
asking questions. By asking deeper questions, tutees may
stimulate a more enriched discussion and higher quality
tutor explanations, which should facilitate learning.
Because the episodes used in previous analyses could
contain multiple tutee questions, we re-segmented the
dialogue tutoring protocol data using “question-response
exchanges” as the unit of analysis. A “question” was
defined as an interrogative statement in which the tutee
requested information (or verification of information). For
the purposes of this paper, we excluded questions that were
not directly relevant to the content (i.e. questions about task
procedures or off-topic issues were not counted). A
“response” was defined as any information or feedback (or
lack thereof) provided by the tutor in answer to the question.
Tutee questions were then labeled as either “shallow” or
“deep.” A deep question was one that either required the
tutor to generate an inference or contained a tutee-generated
inference that the tutor had to evaluate. A shallow question
was one that did not contain or require any information
beyond the text contents. Tutor responses to these questions
were similarly coded as “shallow” or “deep,” depending on
whether they contained inferences or novel elaborations of
the text. Tutor responses were further classified as being
“metacognitive” or “non-metacognitive,” based on whether
they contained self-monitoring statements (a statement such
as “I don’t know that” or “This is easy to remember”).
Out of a total of 240 content-relevant questions asked
across the seven dialogue tutoring pairs, 37% (88 questions)
were classified as deep and 63% (152 questions) were
shallow. Our results indicated that shallow questions were
much more likely to receive a shallow response, but deep

Question
Depth
Shallow
Deep

Metacognitive
Response
32 (21%)
42 (48%)

NonMetacognitive
Response
120 (79%)
45 (52%)

Totals
152
88

In order to confirm that tutor responses to deep questions
were both deep and metacognitive (rather than one or the
other), we cross-tabulated tutors’ shallow versus deep and
metacognitive versus non-metacognitive responses (Table
7). This analysis generally confirmed that deep, inferential
responses were more likely to contain self-monitoring
statements. Shallow responses were more likely to be nonmetacognitive. This pattern was significant; χ2(1,N=212
responses) = 43.3, p<.001.
Table 7: Tutors’ deep and metacognitive responses
Response
Type
Shallow
Deep

Metacognitive
Response
29 (19%)
37 (66%)

NonMetacognitive
Response
127 (81%)
19 (34%)

Totals
156
56

In summary, the nature of the tutees’ questions had an
substantial impact on the subsequent integrative and
metacognitive activities of the tutors. When tutees asked
shallow questions, the tutors responses were frequently
shallow and non-metacognitive. However, when tutees
asked deep questions that contained or required an
inference, the tutors were more likely to respond with a deep
and metacognitive response.

1182

Examples of Question-Response Exchanges
The following excerpts demonstrate how these processes
occurred in a tutorial session. In the first example, a tutor
and tutee are discussing the blind spot in the retina. The
tutor summarizes background information and the tutee
follows up with a deep question that leads the tutor to
generate a novel analogy. The text provided only a
structural description of the blind spot with no analogies.
Tutor: This is the blind spot [points to diagram]. You can’t see
anything there because that’s where the optic nerve
leaves the eye. So there aren’t receptors right there.
(paraphrase)
Tutee: Okay, wait. The blind spot is where all the nerves are
located? (shallow question)
Tutor: Yeah. Like, that’s where all of the optic nerves come
together. They go all around and that’s where they all
pull together and go back to the eye. Or back to the
brain. So right there, there aren’t any receptors.
(shallow, text-based response)
Tutee: So how does that affect your vision? (deep question)
Tutor: If something comes in and your lens refracts it to that
point then you don’t see it. (new inference)
Tutee: Oh, okay.
Tutor: So, it’s just like when you’re driving and there’s that
little spot in the mirror where you just won’t see the
person behind you. It’s like that, except for the eyes.
(deep response; novel analogy)

In the second example, a tutor and tutee are talking about
the relationship between the iris and the pupil. The tutee’s
deep question causes the tutor to engage in sense-making
activity, drawing on her prior knowledge in order to
visualize and better understand these eye components. The
text only discussed how the iris/pupil regulates the amount
of light that can enter the eye, but did not describe how the
iris reacts to light.
Tutor: The iris is the colored part of your eye. And it can
expand or contract radially or circularly (paraphrase).
Tutee: What’s radially? Like outward? (shallow question)
Tutor: Um. It explains that on the next page [skims text].
Yeah. That’s outward. And when the radial muscles
contract, the pupil gets larger. (shallow, text-based
response)
Tutee: Okay. So, pretty much… contract is to make it smaller.
So wouldn’t the iris get smaller? (deep question)
Tutor: Oh. That makes so much sense now. Yeah. Like when
your iris gets smaller, your pupil gets bigger. Like
when someone’s coming out of dark room or they get
surprised. Your pupil gets really big and your iris gets
really small. (new inference; draws on prior
knowledge to visualize)
Tutee: Mm hmm.

Missed Opportunities for the Tutors
It is important to note that the mapping between tutee
question quality and tutor response quality was far from
perfect. About half of the tutees’ deep questions failed to
elicit a deep, metacognitive response from the tutor.

There are several potential explanations for this problem.
One explanation is that the tutee’s deep question contained
an obvious inference and the tutor did not feel it was
necessary to elaborate. Another explanation is that the tutor
evaded the question because he or she did not have the
requisite knowledge to answer it. A third reason might be
that the tutor did not recognize the depth of the tutee’s
question. Chi, Siler, & Jeong (in press), have shown that
even adult, non-peer, tutors often fail to diagnose a tutee’s
understanding. In all cases, the tutors miss out on an chance
to build on their existing knowledge, fill knowledge gaps, or
remediate errors – to learn, in other words.
The following excerpt provides an example of one of
these missed opportunities. In this example, a tutor and
tutee are discussing light refraction and the role of the
cornea and lens in that process. The tutee asks two deep
questions about the function of the cornea. Unfortunately,
the tutor cuts this potentially productive exchange short
rather than attempting to repair his knowledge gap.
Tutor: I’m going to talk about refraction, which is bending of
the light. Most of it is done with the cornea [points to
diagram]. But there’s additional light bending done
through the pupil. Or through the lens, I mean. And
this is changed by altering the thickness of the lens.
(paraphrase)
Tutee: The cornea doesn’t change at all? (deep question)
Tutor: The cornea just stays the same. (new inference)
Tutee: Okay. Then how is it responsible for 70% of the
focusing power? (deep question)
Tutor: I don’t know. It doesn’t say. (expresses ignorance and
misses opportunity to repair this knowledge gap)

Conclusion
Previous research has established that students benefit
academically from teaching other students. These learning
outcomes have most often been attributed to the tutors’
generation of instructional explanations and metacognitive
self-monitoring while teaching.
However, these
mechanisms have been relatively understudied outside of
reciprocal tutoring settings, which confound the benefits and
processes of tutoring and being tutored. The analyses
presented in this paper provide some converging evidence
from a non-reciprocal tutoring setting that students learn by
teaching due to explaining and self-monitoring activities. In
addition, these behaviors were unstructured, indicating that
tutors can learn even without a great deal of support and
training (although well-structured interventions probably
support more efficient and consistent learning behaviors).
Our findings show that the tutees played a very important
role in shaping the learning activities and learning
opportunities of the tutors. Although tutors paraphrased the
text and introduced many of the topics discussed in the
tutoring sessions, tutees stimulated much of the reviewing
activity in which topics were covered more thoroughly.
Tutees also directly and indirectly facilitated sense-making
activities in which the tutors became aware of their own
misconceptions and then attempted to repair them. These

1183

elaborated reviewing and sense-making activities were
likely guided by the kinds of questions that the tutees asked.
Shallow questions tended to receive shallow and nonmetacognitive responses from the tutors. However, deep
questions asked by the tutees provided an important (if not
always consistent) impetus for integrating ideas, generating
inferences, and self-monitoring. More research is needed
to understand how and why “missed opportunities” occur.

Acknowledgments
Funding for this research was provided by a grant awarded
to Rod Roscoe by the University of Pittsburgh, FAS Office
of Graduate Studies, and in part by the National Science
Foundation, Grant Number NSF (LIS): 9720359, to the
Center for Interdisciplinary Research on Constructive
Learning Environments (CIRCLE, www.pitt.edu/~circle).
The authors would like to thank Marguerite Roy, Robert
G. M. Hausmann, and several anonymous reviewers for
their feedback and advice.

References
Ainsworth, S. & Loizou, A. T. (2003). The effects of selfexplaining when learning with text or diagrams.
Cognitive Science, 27, 669-681.
Allen, V. L. & Feldman, R. S. (1973). Learning through
tutoring: Low-achieving children as tutors. Journal of
Experimental Education, 42(1), 1-5.
Annis, L. F. (1983). The processes and effects of peer
tutoring. Human Learning, 2, 39-47.
Bargh, J. A. & Schul, Y. (1980). On the cognitive benefits
of teaching. Journal of Educational Psychology, 72(5),
593-604.
Chi, M. T. H. (2000). Self-explaining expository texts: The
dual process of generating inferences and repairing
mental models.
In R. Glaser (Ed.), Advances in
instructional psychology. Mahwah, NJ: Erlbaum.
Chi, M. T. H., deLeeuw, N., Chiu, M., & Lavancher, C.
(1994). Eliciting self-explanation improves understanding.
Cognitive Science, 18, 439-477.
Chi, M. T. H., Siler, S. A., & Jeong, H. (in press). Can
tutors monitor students’ understanding accurate? To
appear in Cognition and Instruction.
Chi, M. T. H., Siler, S. A., Jeong, H., Yamauchi, T., &
Hausmann, R. G. (2001). Learning from human tutoring.
Cognitive Science, 25, 471-533.
Cloward, R. D. (1967). Studies in tutoring. Journal of
Experimental Education, 36(1), 14-25.
Cohen, P. A., Kulik, J. A., & Kulik, C. C. (1982).
Educational outcomes of tutoring: A meta-analysis of
findings. American Educational Research Journal, 19(2),
237-248.
Coleman, E. B. (1998). Using explanatory knowledge
during collaborative problem-solving in science. Journal
of the Learning Sciences, 7(3), 387-427.
Coleman, E. B., Brown, A. L., & Rivkin, I. D. (1997). The
effect of instructional explanations on learning from
scientific texts. Journal of the Learning Sciences, 6(4),
347-365.

Fantuzzo, J. W., King, J. A., & Heller, L. R. (1992). Effects
of reciprocal peer tutoring on mathematics and school
adjustment: A component analysis.
Journal of
Educational Psychology, 84, 331-339.
Fantuzzo, J. W., Riggio, R. E., Connelly, S., & Dimeff, L.
A. (1989). Effects of reciprocal peer tutoring on
academic achievement and psychological adjustment: A
component analysis. Journal of Educational Psychology,
81(2), 173-177.
Fuchs, L. S., Fuchs, D., Hamlett, C. L., Phillips, N. B.,
Karns, K., & Dutka, S. (1997). Enhancing students’
helping behavior during peer-mediated instruction with
conceptual mathematics explanations. Elementary School
Journal, 97(3), 223-249.
Graesser, A. C. & Person, N. K. (1994). Question asking
during tutoring. American Educational Research Journal,
31(1), 104-137.
Greenwood, C. R., Carta, J. J., & Hall, R. V. (1988). The
use of peer tutoring strategies in classroom management
and educational instruction. School Psychology Review,
17(2), 258-275.
King, A. (1994). Guiding knowledge construction in the
classroom: Effects of teaching children how to question
and how to explain. American Educational Research
Journal, 31(2), 338-368.
King, A., Staffieri, A., & Adelgais, A. (1998). Mutual peer
tutoring: Effects of structuring interaction to scaffold peer
learning. Journal of Educational Psychology, 90(1), 134152.
Morgan, R. F. & Toy, T. B. (1970). Learning by teaching:
A student-to-student compensatory tutoring program in a
rural school system and its relevance to the educational
cooperative. Psychological Record, 20, 159-169.
Palincsar, A. S. & Brown, A. L. (1984). Reciprocal
teaching of comprehension-fostering and comprehensionmonitoring activities. Cognition and Instruction, 1(2),
117-175.
Rekrut, M. D. (1992). Teaching to learn: Cross-age tutoring
to enhance strategy instruction. Paper presented at the
Annual Meeting of the American Educational Research
Association. San Francisco, CA, April.
Renkl, A. (1995).
Learning for later teaching: An
exploration of mediational links between teaching
expectancy and learning results.
Learning and
Instruction, 5, 21-36.
Webb, N., Troper, J. D., & Fall, R. (1995). Constructive
activity and learning in collaborative small groups.
Journal of Educational Psychology, 87(3), 406-423.

1184

