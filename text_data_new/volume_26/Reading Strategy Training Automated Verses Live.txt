UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reading Strategy Training: Automated Verses Live

Permalink
https://escholarship.org/uc/item/5j25c7m4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 26(26)

Authors
O'Reilly, Tenaha
Sinclair, Grant P.
McNamara, Danielle S.

Publication Date
2004-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Reading Strategy Training: Automated Verses Live
Tenaha O’Reilly (t.oreilly@mail.psyc.memphis.edu)
Grant P. Sinclair (gsinclair@mail.psyc.memphis.edu)
Danielle S. McNamara (d.mcnamara@ mail.psyc.memphis.edu)
Psychology Department, University of Memphis
Memphis, TN 38152 USA

Abstract
This study examined the effectiveness of SelfExplanation Reading Training (SERT) and an automated
version of this intervention called Interactive Strategy
Training for Active Reading and Thinking (iSTART) in
improving science text comprehension. College students
(N=297) were assigned to one of three conditions: SERT
(trained by a human instructor), iSTART (trained by a
computer), or no treatment control. Participants read a
text on cell mitosis and answered text-based and bridging
inference questions. There was a significant overall
effect of condition indicating that both iSTART and
SERT out performed controls on comprehension.
However, this effect was modulated by question type:
both SERT and iSTART significantly enhanced
comprehension for text-based questions, but the effect
was not reliable for bridging inference questions.

Introduction
Many students have difficulty understanding what
they read; in particular, many students have trouble
comprehending science texts (Bowen, 1999; Snow,
2002). Problems associated with comprehension are
augmented by the lack of strategic reading interventions
in classrooms: students seldom use high-level
comprehension strategies that promote deep
comprehension (Cox, 1997; Garner, 1990).
One way to improve comprehension is to teach
reading strategies that encourage deeper processing of
the text. Interventions that promote deeper processing
such as self-explanation and elaborative interrogation
have been successful in improving student
comprehension (e.g., Chi, De Leeuw, Chiu, &
LaVancher, 1994; Pressley, Wood, Woloshyn, Martin,
King, & Menke, 1992). For example, McNamara (in
press) has reported positive learning gains for her Self–
Explanation Reading Training (SERT). SERT is a
modified version of the self-explanation learning
strategy (e.g., Chi et al., 1994). The SERT training
program helps improve comprehension by encouraging
students to utilize various sub-strategies to build strong
connections between the reader’s knowledge and the
text. SERT teaches students various reading strategies,

including comprehension monitoring, logic and
common sense/elaboration, paraphrasing, bridging
inferences, and prediction to improve their ability to
explain text and understand it at a deeper level.
McNamara (in press) examined the effectiveness of
SERT with college students who varied in prior
knowledge of science. Half of the participants learned
to self-explain and use reading strategies while reading
four science texts. The other half of the participants
read aloud the texts and answered questions concerning
them. After the training phase, the two groups’ ability
to self-explain was compared. They also answered
text-based and bridging-inference questions about the
text that they had all self-explained. The results
indicated that low-knowledge readers who were trained
to use SERT outperformed control participants on
measures of text comprehension.
However, this
advantage only occurred for text-based questions. In
addition, protocol analyses of the readers’ selfexplanation indicated that the low-knowledge readers
improved in terms of their ability to paraphrase the text,
and more importantly, in their ability to use domaingeneral knowledge (or logic and common sense) to
make sense of the text. Not having the requisite
knowledge, they were not able to make inferences
requiring domain specific knowledge while reading.
Nonetheless, they showed the same level of
comprehension on the text-based measures as did the
high-knowledge readers, and substantially greater
performance than their low-knowledge counterparts.
These findings are particularly encouraging because it
demonstrates improvement for the students who need
the training the most: the low-knowledge students.
The present study compares the effectiveness of
SERT and a similar, but automated version of the
training, called Interactive Strategy Training for Active
Reading and Thinking (iSTART; McNamara,
Levinstein, & Boonthum, in press). Automating the
core aspects of SERT training has several advantages
including self-paced learning and standardized training.
iSTART is a computer program that uses automated
agents to provide SERT-based training to students. The
program, like SERT, has three sections, introduction,

1059

demonstration, and practice. The program has both
vicarious and interactive components to enhance
learning. The students learn vicariously by watching
“agent students” interact and learn strategies taught by a
“teacher agent.” Later the student interacts with the
program, and the system provides feedback on the
student’s performance.
While automating the SERT intervention has several
advantages, one potential problem is that automation
may influence the effectiveness of SERT. For example,
during live SERT training, students practice with a
partner while self-explaining. In iSTART, human peer
interaction does not occur. In light of the work on
reciprocal teaching (e.g. Palincar & Brown, 1984),
removing human peer interaction may diminish the
effectiveness of the training. The goal of this study was
to examine whether the automated iSTART was as
effective at improving comprehension as the live SERT
training. Participants were assigned to one of three
conditions: live SERT (trained by a human instructor),
iSTART (trained by the computer program) and a
control condition which had no training (and instead
read a text and answered questions concerning it). One
week after the training phase, participants read a
passage on cell mitosis (see McNamara, 2001;
McNamara, in press). The dependent measure was the
total proportion of correct answers (both text-based and
bridging-inference questions) based on the passage. It
was expected that SERT would out perform controls
because previous research showed a facilitative effect
of SERT on comprehension (McNamara, in press). It
was expected that iSTART training would also improve
comprehension compared to controls. This prediction
was made based on research that has shown the benefits
of automated agents on learning (e.g., Anderson,
Corbett, Koedinger, & Pelletier, 1995; Du Boulay,
2000; Graesser & Person, 1994).
Finally, we were also interested in uncovering any
spontaneous strategies used by control students in our
study. Prior research has indicated that the average
student is not particularly strategic when learning from
text (Cox, 1997; Garner, 1990). After reading the
passage on mitosis, participants in all three conditions
were asked to indicate what strategies they used to help
them understand what they read. We predicted that
both the SERT and iSTART conditions would indicate
strategies such as those taught in the training session.
A higher reported use of SERT strategies in the training
condition serves as a manipulation check for whether
the trained participants actually used the strategies to
comprehend the text. Moreover, our secondary goal
was to examine what, if any, strategies would be
reported by the untrained participants.

Method
Participants
The sample consisted of 297 biology college students
from Old Dominion University. There were 87 males
and 210 females and the average age was 21 years old
(SD=4.58).
The students participated during the
laboratory sessions of their Introductory Biology
Course. Each lab was randomly assigned to one of the
three conditions. The students received extra credit in
the course for participation.

Materials
Two sets of individual difference measures were used
to gauge students’ cognitive ability: reading skill and
prior knowledge. Reading skill was measured by
Nelson-Denny Reading Skills Test. The test consisted
of 38 multiple-choice questions designed to assess
comprehension on several short text passages. Prior
knowledge was measured by a 54-item multiple-choice
test on general science knowledge and the humanities.
The test consisted of questions drawn from biology, art,
literature, history, geology, political science, and
psychology.
Participants in the SERT condition were given a short
list of five reading strategies (i.e., comprehension
monitoring, paraphrasing, elaboration, prediction, and
bridging), a video transcript and note sheet (used during
the video segment of training), and a booklet with more
detailed descriptions of the strategies and examples of
their use in self-explanations. Participants in the
iSTART condition were given written instructions on
how to use the iSTART system, and a short list of the
reading strategies.
A passage on cell mitosis described the sequential
stages involved in cell division, and included all the
information required to subsequently answer a set of
comprehension questions. The text was 650 words in
length and had a Flesch Reading Ease 52 and a FleschKincaid Grade Level 9.1. Comprehension was assessed
using a set of 12 open-ended questions: six text-based
and six bridging-inference questions. The answers to
the text-based questions could be found in a single
sentence within the passage, while the bridginginference questions required the reader to integrate
information from two or more sentences within the
passage. Participants were also given a sheet of paper
which asked if they had finished reading the text and
which, if any, strategies they used to help them
understand the text. Finally, participants were given a
260 word text on thunderstorms with a Flesch Kincaid
Grade level of 8.6 and a Flesch Reading Ease 56. For
control participants the text was accompanied by 8
open-ended questions.

1060

Design and Procedure
The experiment had three phases: pre-testing, training
and post-testing. All participants were given the
individual difference measures during the pre-test
phase. Participants first took the prior knowledge test
(20 minutes) followed by the Nelson-Denny reading
skill test (15 minutes).
The following day the
experimental training and control phases were
conducted in a 2-hour session. The post-test phase
occurred after a one-week retention period, during
which all participants read and answered questions for
the mitosis passage. Participants were given 30
minutes to read the passage and answer the questions.
Students did not have the text available to help them
once they began answering the questions.
Training
SERT: The SERT training session was conducted in
a 2-hour session. SERT participants were told that the
purpose of the study was to teach them strategies that
would help them to better understand and remember
what they read. Participants were first provided with a
description and examples of self-explanation. The
instructor then defined and provided examples for five
reading
strategies:
comprehension
monitoring,
paraphrasing, elaboration, prediction, and bridging.
Participants then watched a video depicting a student
reading and self-explaining a text about forest fires.
Participants could refer to the accompanying video
transcript during viewing. The video was paused at
various points, and participants identified and discussed
the strategies being used by the reader in the video.
Finally, the participants worked in pairs to practice
self-explanation while reading the thunderstorms text.
The participants took turns self-explaining, alternating
after each paragraph. At the end of each paragraph, the
partner who was listening (and not self-explaining)
summarized the student’s self-explanation.
iSTART: The iSTART training session was
conducted in a 2-hour session. Participants in the
iSTART condition were told that the purpose of the
study was to teach them strategies that would help them
to better understand and remember what they read.
Participants were then given instructions on how to use
the iSTART system, and they proceeded to go through
the three sections of the program: introduction,
demonstration, and practice. The practice section
involved reading and self-explaining a text about
thunderstorms one sentence at a time. Participants
typed their self-explanations into the computer.
Control: Participants were told that the purpose of the
study was to determine the types of strategies students
use when they read.
Participants read the
thunderstorms text and indicated the strategies they
used while reading.
The participants answered
corresponding questions to assess comprehension.

Testing
One week following training, all three groups of
participants were asked to read the science text about
cell mitosis (i.e., the low-coherence version used in
McNamara, 2001). The participants were asked to use
the strategies that they had learned or talked about the
previous week. After reading the text, participants were
asked to indicate what strategies they used to help them
understand the text. They were then given the 12 openended questions to assess comprehension. Participants
were given 30 minutes to read the text and answer the
questions. The text was not available to the students
once they began answering the questions.

Results
The effect of training on reported strategy use.
Our first question was whether training condition
affected students’ reported use of strategies one week
after training when reading the cell mitosis text. Table
1 lists the percent of participants who indicated using
SERT strategies, while Table 2 indicates the percent of
participants who reported using non-SERT strategies.
Students’ self-reports of strategy use during reading
were tabulated into 17 categories. The categories were
devised based on a combination of a priori strategies
reported in the literature, and strategies that were
frequently mentioned in the students’ responses. It is
important to note that category membership is not
mutually exclusive. That is, a participant could have
listed more than one strategy, and therefore the
percentages per condition will not sum to 100%.
Strategy
Bridging
Prior
Knowledge
Elaboration
Prediction
Selfexplanation
Paraphrase

Control
0%

iSTART
39.8%

SERT
38.5%

7.3%
0%
0%

15.1%
17.2%
14%

17.7%
21.9%
13.5%

0.9%
0%

23.7%
46.2%

19.8%
46.9%

Table 1 Percent of self-reported SERT/iSTART
strategies by condition
Further calculations revealed that 77.2% of iSTART
and 72.9% SERT participants reported using at least
one of the reading strategies taught by the
iSTART/SERT, whereas only 8.3% of control
participants
reported
using
these
strategies
(χ(2,297)=123.30, p<0.05). A chi-square also revealed
that more control participants (58.9%) indicated using
more non-SERT strategies (i.e., 10 strategies listed in
table 1 other than the six SERT strategies) than
iSTART (10.9%) or SERT (30.25%) participants
(χ(2,297)=60.79, p<0.05). Although this measure does

1061

not indicate whether they actually used these strategies
(nor whether their self reports were all inclusive, i.e.,
they may not have reported some strategies) it does
reveal that iSTART and SERT participants become
sensitive to the notion of active reading strategies
through training, and that this was retained one week
later.
Strategy
Imagery
Re-Read to
understand
Summarize
Mnemonics
Skim text
Note taking
Memorization
Repetition
Focus
Key points
No Strategy

Control
7.3%

iSTART
0%

SERT
4.2%

11.9%
1.8%
6.4%
4.6%
5.5%
3.7%
30.3%
9.2%
14.7%
16.5%

1.1%
0%
1.1%
2.2%
0%
0%
8.6%
0%
1.1%
4.3%

1.0%
2.1%
4.2%
2,1%
1.0%
2.1%
25%
2.1%
7.3%
1.0%

Table 2 Percent of self-reported non-SERT/iSTART
strategies by condition.
The effect of strategy training on comprehension.
Our second question was whether SERT and iSTART
training successfully improved comprehension for those
students who reported using the strategies. All control
participants (N=109) were included in this analysis.
However, in the iSTART and SERT conditions, only
participants who explicitly stated that they used one or
more of the SERT strategies (comprehension
monitoring, self-explanation, paraphrasing, prediction,
bridging, elaboration, and prior knowledge use) were
included in the analysis. We restricted this analysis to
training participants who reported using the strategies
after training because our question regarded the effects
of training for those participants who attempted to use
the SERT strategies to read and understand the cell
mitosis text.
Therefore, this manipulation check
reduced the number of participants in the iSTART
condition from N=92 to N=71, and reduced the number
of participants in the SERT condition from N=96 to
N=70. While it is interesting in itself that about 25% of
the training participants did not attempt to use the
reading strategies after training, there are many reasons
why they might not (e.g., lack of motivation in the
laboratory setting, lack of sufficient learning of the
strategies, preference for other strategies). However,
we cannot identify these reasons and those participants
are not the focus of this particular analysis. The
exclusion of participants who did not report any SERT
strategies is a conservative effort. The self-report
measure includes both participants who actually used
the SERT strategies and those who said they used them,

but did not use them in practice. In a similar vein, by
retaining all the control participants, the control
condition has an advantage because the analysis
includes the participants who may use higher-level
strategies and who may, therefore, be expected to score
as well as the trained participants. A similar set of
analyses which also excluded control participants who
did not report any strategies produced a similar pattern
of results as the analysis used here that did not exclude
any control participants. Hence, the analyses reported
below included all control participants
Differences in pre-test abilities
A one-way between-participants ANOVA was
conducted on the student’s pre-test level of prior
knowledge to determine whether the groups differed as
a function of pre-treatment knowledge. The results
indicated that there were no differences between
conditions, F(2,233)= 1.47, MSE= 72.25, p>.05,
indicating that any difference between the conditions
are unlikely due to pre-treatment levels of knowledge.
Likewise, a between-participants analysis was
conducted on the students’ reading skill scores to
determine whether the pre-treatment reading skill
differed as a function of condition. The analysis
revealed that there was no significant effect of pre-test
reading skill, F(2,233)= 2.05, MSE= 71.31, p>.05, and
thus, differences among the conditions are unlikely due
to pre-treatment differences in reading skill.
Effects of condition
A repeated measures analysis of variance was
conducted on comprehension scores including the
within-participants variable of question type (textbased, bridging inference) and the between-participants
variables of training condition and knowledge with
reading skill as a covariate. There was a significant
effect of question type, F(1,229)= 23.57, MSE= 0.602,
p<.05, indicating that more text-based questions
(M=0.52, SD=0.26) were answered correctly than
bridging questions (M=0.22, SD=0.17). There was also
an effect of knowledge, F(1,229)= 35.14, MSE= 1.85,
p<.05) indicating that high-knowledge students
(M=0.28, SD=0.15) scored higher than low-knowledge
students (M=0.45, SD=0.17). The analyses revealed a
significant effect for training condition, F(2,229)= 3.94,
MSE= 0.207, p<.05) indicating that both iSTART
(M=0.39, SD=0.21) and SERT (M=0.39, SD=0.19)
participants scored higher than controls (M=0.33,
SD=0.22). This effect was qualified by a significant
interaction of question type and condition, F(2,229)=
2.98, MSE= 0.076, p<.05). Post hoc Least Significant
difference tests revealed that SERT (M=0.55, SD=0.23,
p<.05) and iSTART (M=0.54, SD=0.24, p<.05)
participants scored higher than controls (M=0.45,
SD=0.27) on text-base questions, but not bridging

1062

questions (see Figure 1).
significant.

No other effects were

0 .7

Control

0 .6

SERT

0 .5

iSTART

0 .4
0 .3
0 .2
0 .1
0

Text-based

Bridging
Inference
Question Type

Figure 1. Proportion correct on the mitosis passage
score as a function of condition and question type
To examine effects of reading skill, a second repeated
measures analysis of variance was conducted on
comprehension including the within-participants
variable of question type (text-based, bridginginference) and the between-participants variables of
training condition and reading skill, with knowledge as
a covariate. The analysis revealed a significant effect
for question type, F(1,229)=5.07, MSE=0.147 p<.05,
indicating that more text-based questions (M=0.52,
SD=0.26) were answered correctly than bridging
questions (M=0.23, SD=0.17). The main effect of
training condition was reliable, F(2,229)=4.69,
MSE=0.239 p<.05, indicting that iSTART (M=0.39,
SD=0.21) and SERT (M=0.41, SD=0.19) participants
scored higher than control participants (M=0.33,
SD=0.22). This main effect was qualified by a
significant
interaction
with
question
type,
F(2,229)=2.98, MSE=0.076 p<.05. Post hoc Least
Significant Difference tests revealed that iSTART
(M=0.54, SD=0.24, p<.05) and SERT (M=0.58,
SD=0.23, p<.05) participants scored higher on textbased questions compared to control participants
(M=0.46, SD=0.27). But this effect was not found for
bridging-inference questions. In sum, both SERT and
iSTART improved students’ comprehension compared
to controls, particularly at the textbase level of
understanding.
Finally, correlations between each of the 18 selfreported strategies and the total proportion correct on
the mitosis passage. Six strategies were significantly
correlated to comprehension. Five of the strategies
were taught by the SERT/iSTART technique bridging,
r=.25, self-explanation, r=.19, elaboration, r= .14,
paraphrasing, r=. .25, predictions, r=.12, and one nonSERT/iSTART strategy, reread to understand, r=.15.

Discussion

The results of the present study are congruent with
research demonstrating beneficial effects of readingstrategy training on understanding and learning (Chi et
al., 1994; Pressley et al., 1992). First, the majority of
SERT and iSTART participants reported the use of
SERT strategies such as elaboration, using prior
knowledge and making bridging inferences. Research
has shown that high-level strategies such as prior
knowledge use (Spilich, Vesonder, Chiesi, & Voss,
1979) and elaboration (Pressley et al., 1992) are much
more effective than low-level strategies such as
repetition. The current results suggest that both SERT
and iSTART training encourage the use of higher-level
strategies during reading, and that the self reported use
of these strategies correlates with comprehension. The
present findings also seem to support the views of Cox
(1997) and Garner (1990): average untrained students
are spontaneously unlikely to use higher-level strategies
to help them better understand what they read.
In a related study, Best, Ozuru, and McNamara
(2004) analyzed the content of students’ selfexplanations while interacting with iSTART. The
researchers found that several of the participants
indicated the use of high quality elaborations including
logic/common sense and scientific reasoning. Many of
these elaborations were knowledge building, which
helps the reader more effectively explain the current
sentence. However, the quality of the elaborations
depended upon both the sentence difficulty and
individual differences. In short, iSTART seems to
promote the use of both high-level and high-quality
comprehension strategies.
Second, and more importantly, the self-report data is
bolstered by the findings from the comprehension data.
Participants in both the SERT and iSTART conditions
answered more text-based questions correctly than did
control participants. Hence, the current study suggests
that SERT and iSTART training encouraged many of
the learners to use higher-level strategies, and when
they did, comprehension for text-based information was
facilitated. These findings are congruent with results
reported by McNamara (in press) showing positive
learning gains for students who were given SERT
training. In that study, McNamara (in press) found
evidence that SERT helped participants by encouraging
them to use logic, common sense and general world
knowledge. Moreover, the beneficial effects of training
were most prominent for low-knowledge readers; that
is, for the readers who need the training the most.
As in McNamara (in press), the facilitative effect of
training in the current study did not extend to bridginginference questions. One possible explanation is that
participants did not have the specific domain
knowledge required to make effective bridging
inferences (cf., McNamara, in press).
This
interpretation is in accordance with the finding that

1063

prior knowledge is important in generating inferences
(e.g., Singer & Ritchot, 1996), particularly when text
cohesion (the degree to which relations are made
explicit) is low (McNamara, 2001). The mitosis text
used here was taken from McNamara (2001), who
manipulated text cohesion as an independent variable.
The current study utilized the low-cohesion version of
the mitosis text. Because text cohesion was low,
readers require a greater degree of specific domain
knowledge to generate the necessary inferences.
As found in previous studies (e.g., Anderson et al.,
1995; Du Boulay, 2000; Graesser & Person, 1994), this
research also confirms the effectiveness of
computerized training, particularly those using
automated agents as tutors. The benefits of automated
tutors include self-paced learning, standardized
training, and feedback tailored to the individual’s
progress. The results of the present work support the
effectiveness of an automated tutoring system by
showing that a computerized presentation of the SERT
strategies (iSTART) was as effective as a presentation
of the strategies by a human instructor. Given the
current trend towards increasing classroom size and
cutbacks in educational funding, this result suggests
that automated trainers may provide a means for
reducing the load on resource-strained educators.
In sum, this study adds to the literature by
demonstrating that SERT and iSTART training increase
the reported use of higher-level strategies during
reading, and when used, the SERT and iSTART
strategies enhance comprehension, at least for textbased information. More encouraging is the finding
that the self-paced computer version of the training is as
effective as the human delivered training.

Acknowledgements
This project was supported the NSF (Award number:
0241144). Any opinions, findings and conclusions or
recommendations expressed in this material are those of
the authors and do not necessarily reflect the views of
the NSF.

References
Anderson, J.R., Corbett, A. Koedinger, K. & Pelletier,
R. (1995). Cognitive tutors: Lessons learned. The
Journal of the Learning Sciences, 4, 167-207.
Beck, I., McKeown, M., & Gromoll, E. (1989).
Learning from social studies texts. Cognition and
Instruction, 6, 99-158.
Best, R., Ozuru, Y., & McNamara, D.S. (2004). Selfexplaining Science Texts: Strategies, Knowledge and
Reading Skill. Proceedings of the Sixth International
Conference of the Learning Sciences, Monica, CA.
Bowen, B. A. (1999). Four puzzles in adult literacy:
Reflections on the national adult literacy survey.

Journal of Adolescent and Adult Literacy, 42, 314323.
Chi, M. T. H., De Leeuw, N., Chiu, M., & LaVancher,
C. (1994). Eliciting self-explanations improves
understanding. Cognitive Science, 18, 439-477.
Cornoldi, C., & Oakhill, J. (1996). In C. Cornoldi and
J. Oakhill (Eds.), Reading comprehension difficulties,
New Jersey: Lawrence Erlbaum Associates,
Publishers.
Cox, B. (1997). The rediscovery of the active learner in
adaptive contexts: A developmental-historical
analysis of transfer of training. Educational
Psychologist, 32, 41-55.
Du Boulay, B. (2000). Can we learn from ITS?
International Journal of Artifical Intelligence in
Education, 11, 1040-1049.
Garner, R. (1990). When children and adults do not use
learning strategies: Toward a theory of settings.
Review of Educational Psychology, 60, 517-529.
Graesser, A. & Person, N (1994). Question asking
during tutoring. American Educational Research
Journal, 31, 104-137.
McNamara, D. S. (2001). Reading both high-coherence
and low-coherence texts: Effects of text sequence and
prior knowledge. Canadian Journal of Experimental
Psychology, 55, 51-62.
McNamara, D.S. (in press). SERT: Self-Explanation
Reading Training. Text and Discourse.
McNamara, D. S., Levinstein, I. B., & Boonthum, C.
(2003). iSTART: Interactive Strategy Trainer for
Active Reading and Thinking. Submitted to
Behavioral Research Methods, Instruments, and
Computers.
Palinscar, A. S., & Brown, A. L. (1984). Reciprocal
teaching of comprehension-fostering and monitoring
activities. Cognition and Instruction, 2, 117-175.
Perfetti, C. (1985). Reading ability. New York: Oxford
University Press.
Pressley, M., Wood, E., Woloshyn, V. E., Martin, V.,
King, A., & Menke, D. (1992). Encouraging mindful
use of prior knowledge: Attempting to construct
explanatory answers facilitates learning. Educational
Psychologist, 27 (1), 91-109.
Singer, M., & Ritchot, K. (1996). The role of working
memory capacity and knowledge access in text
inference processing. Memory & Cognition, 24, 733743.
Snow, C. (2002). Reading for understanding: Toward
an R&D program in reading comprehension. Santa
Monica, CA: RAND
Spilich, G., Vesonder, G., Chiesi, H., & Voss, J. (1979).
Text processing of domain-related information for
individuals with high and low domain knowledge.
Journal of Verbal Learning and Verbal Behavior, 18,
275-290.

1064

