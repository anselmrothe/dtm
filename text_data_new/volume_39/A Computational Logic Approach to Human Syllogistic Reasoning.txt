A Computational Logic Approach to Human Syllogistic Reasoning
∗

Ana Oliveira da Costa∗ and Emmanuelle-Anna Dietz Saldanha∗ and Steffen Hölldobler∗ and Marco Ragni∗∗1
International Center for Computational Logic, TU Dresden, Germany, ana.oli.costa@gmail.com, {dietz,sh}@iccl.tu-dresden.de
∗∗ Cognitive Computation lab, University of Freiburg, Germany, ragni@cs.uni-freiburg.de
Table 1: The four moods and their logical formalization.

Abstract

Mood

A recent meta-analysis (Khemlani & Johnson-Laird, 2012)
about psychological experiments of syllogistic reasoning
demonstrates that the conclusions drawn by human reasoners
strongly deviate from conclusions of classical logic. Moreover,
none of the current cognitive theories predictions fit reliably
the empirical data. In this paper, we show how human
syllogistic reasoning can be modeled under a new cognitive
theory, the Weak Completion Semantics. Our analysis based
on computational logics identifies seven principles necessary
to draw the inferences. Hence, this work contributes to a
computational foundation of cognitive reasoning processes.
Keywords: Human Reasoning; Syllogistic Reasoning; Logic
Programming; Three-valued Łukasiewicz Logic; Abduction

First Premise
Second Premise

Short
Aab
Iab
Eab
Oab

a-b
b-c

b-a
c-b

a-b
c-b

b-a
b-c

Recently, a new cognitive
theory based on the Weak
c
Completion Semantics (WCS)
has been developed (Hölldobler,
2015). It has its roots in the
a
b
ideas first expressed by Stenning
X
and van Lambalgen (2008),
which unfortunately had some
technical mistakes. These were
Figure 1: ‘some a are
corrected by Hölldobler and
not c’ follows from IE4.
Kencana Ramli (2009a), by
using the three-valued Łukasiewicz (1920) logic. WCS
has been successfully applied – among others – to the
suppression task (Dietz, Hölldobler, & Ragni, 2012), the
selection task (Dietz, Hölldobler, & Ragni, 2013), the
belief-bias effect (Pereira, Dietz, & Hölldobler, 2014a,
2014b; Dietz, 2017), to reasoning about conditionals (Dietz
& Hölldobler, 2015; Dietz, Hölldobler, & Pereira, 2015)
and to spatial reasoning (Dietz, Hölldobler, & Höps, 2015).
Hence, it was natural to ask whether WCS can also model
syllogistic reasoning.
We introduce seven principles motivated by findings made
in Cognitive Science and Computational Logic, and show
how syllogisms together with these principles can be encoded
in logic programs. After that we compare the predictions
under WCS with the results of FOL, the syntactic rule
based theory PSYCOP (Rips, 1994), the Verbal Model
Theory (Polk & Newell, 1995) and the Mental Model
Theory (Johnson-Laird, 1983).3 The two model-based
theories performed best in the meta-analysis (Khemlani &
Johnson-Laird, 2012).
The predictions of the theories FOL, PSYCOP, Verbal,
and Mental Models for the syllogisms OA4, IE4, and IA2
and those of a significant percentage of the participants
are depicted in Table 3, where the participants were 156

(IE4)

No b are c
In experiments, participants are normally expected to
complete the syllogism by drawing a logical consequence
from the first two premises, e.g. in this example ‘some a are
not c’. The response of the participant – the conclusion – is
evaluated as true if it can be derived in classical first-order
logic (FOL), otherwise as false. The four quantifiers and
their formalization in FOL are given in Table 1. The entities
can appear in four different orders called figures as shown in
Table 2. Hence, a problem can be completely specified by the
quantifiers of the first and second premise and the figure. The
example discussed above is denoted by IE4.
Altogether, there are 64 syllogisms and, if formalized
in FOL, we can compute their logical consequence in
classical logic. However, a meta-analysis by Khemlani
and Johnson-Laird (2012) based on six experiments has
shown that humans do not only systematically deviate
from the predictions of FOL but from any other of 12
cognitive theories. In the case of IE4, besides the above
mentioned logical consequence, a significant number of
humans answered ‘no valid conclusion’, which does not
follow from IE4 in FOL, as ‘some a are not c’ follows from
IE4 as can be seen in the Venn diagram in Figure 1: X has the
property a but not the property c.
2 We

∀X(a(X) → b(X))
∃X(a(X) ∧ b(X))
∀X(a(X) → ¬b(X))
∃X(a(X) ∧ ¬b(X))

Figure 1 Figure 2 Figure 3 Figure 4

The way of how humans ought to reason correctly about
syllogisms has already been investigated by Aristotle (Smith,
1989).
A syllogism consists of two premises and a
conclusion. Each of them is a quantified statement using
one of the four quantifiers all (A), no (E), some (I), and some
are not (O)2 about sets of entities which we denote in the
following by a, b, and c. An example of a syllogism is:

1 The

all a are b
some a are b
no a are b
some a are not b

Table 2: The four figures used in syllogistic reasoning.

Introduction

Some b are a

Natural language First-order logic

affirmative universal
affirmative existential
negative universal
negative existential

authors are mentioned in alphabetical order.
are using the classical abbreviations.

3 http://mentalmodels.princeton.edu/models/mreasoner/

883

Table 4: The truth tables for the connectives under
three-valued Łukasiewicz logic. Note that for the unknown
holds: (U ← U) = >.

Table 3: Conclusions drawn by a significant percentage of
participants are highlighted in gray and compared to the
predictions of FOL, PSYCOP, Verbal, and Mental Models
theory for OA4, IE4 and IA2. NVC denotes no valid
conclusion.
Participtants FOL PSYCOP Verbal Models Mental Models
OA4

IE4

Oca

Oca

Oac,

Oac

NVC
IA2

Iac, Ica

NVC

Oca,

Oca,

Oca,

Ica, Iac

NVC

Oac, NVC

Oac,

NVC,

Oac, NVC

Iac, Ica

Oac

Eac, Eca, Oca

NVC

NVC, Ica

Iac, Ica, NVC

F

¬F

∧

>

U

⊥

←

>

U

⊥

>
⊥
U

⊥
>
U

>
U
⊥

>
U
⊥

U
U
⊥

⊥
⊥
⊥

>
U
⊥

>
U
⊥

>
>
U

>
>
>

The second and the third clause is a fact and an assumption,
respectively. gPex is as follows:
p(a) ← q(a) ∧ ¬r(a) ∧ s(a).

q(a) ← >.

r(a) ← ⊥.

p(a), q(a), r(a) are defined and s(a) is undefined in gPex .
Classical logic and logic programs are discussed in detail in
e.g. (Hölldober, 2009; Lloyd, 1984).

high school or university students. A conclusion is drawn
by a significant number of participants, if the number of
participants chosing this particular conclusion is statistically
too high for the conclusion to be chosen at random. The
interested reader is referred to Khemlani and Johnson-Laird
(2012) for more details.
FOL and the other three cognitive theories make different
predictions. Each theory provides at least one prediction
which is correct with respect to FOL and provides an
additional prediction which is false with respect to FOL.
Currently, the best results are achieved by the Verbal Models
Theory which predicts 84% of the participants responses,
closely followed by the Mental Model Theory with 83%,
whereas PSYCOP predicts 77% of the participants responses.

Three-Valued Łukasiewicz Logic
We consider the three-valued Łukasiewicz (1920) logic for
which the corresponding truth values are true (>), false
(⊥) and unknown (U). A three-valued interpretation I is a
mapping from the set of formulas to the set {>, ⊥, U}. The
truth value of a given formula under I is determined according
to the truth tables in Table 4. We represent an interpretation as
a pair I = hI > , I ⊥ i of disjoint sets of ground atoms, where I >
is the set of all atoms that are mapped to > by I, and I ⊥ is the
set of all atoms that are mapped to ⊥ by I. Atoms which do
not occur in I > ∪ I ⊥ are mapped to U. Let I = hI > , I ⊥ i and
J = hJ > , J ⊥ i be two interpretations: I ⊆ J iff I > ⊆ J > and
I ⊥ ⊆ J ⊥ . I(F) = > means that formula F is mapped to true
under I. M is a model of P if it is an interpretation, which
maps each clause occurring in gP to >. I is the least model
of P iff for any other model J of P it holds that I ⊆ J.

Weak Completion Semantics
Logic Programs
A (logic) program P is a finite set of clauses of the form
A ← >, A ← ⊥ or A ← B1 ∧ . . . ∧ Bn , n > 0, where A is
an atom, Bi , 1 ≤ i ≤ n, are literals, and > and ⊥ denote
truth and falsehood, respectively. Clauses are assumed to
be universally closed. A is called head and >, ⊥ as well
as B1 ∧ . . . ∧ Bn are called body of the corresponding clause.
Clauses of the form A ← > and A ← ⊥ are called facts and
assumptions, respectively.4 ¬A is assumed in P iff P contains
an assumption with head A and no other clause with head A
occurs in P . We restrict terms to be constants and variables.
We assume for each program P that the underlying alphabet
consists precisely of the symbols occurring in P and that
non-propositional programs contain at least one constant.
gP denotes the set of all ground instances of clauses
occurring in P , where a ground instance of clause C is
obtained from C by replacing each variable occurring in C by
a constant. A ground atom A is defined in gP iff gP contains
a clause whose head is A; otherwise A is said to be undefined.
def (A, P ) = {A ← Body | A ← Body ∈ gP } is called definition
of A in P . To clarify the definitions, consider Pex :

Least Models under the Weak Completion
For a given program P , consider the following
transformation: (1) For each ground atom A which
is defined in gP , replace all clauses of the form
A ← Body1 , . . . , A ← Bodym occurring in gP by
A ← Body1 ∨ . . . ∨ Bodym . (2) Replace all occurrences
of ← by ↔. The obtained set of formulas is called weak
completion of P or wcP .5
It has been shown by Hölldobler and Kencana Ramli
(2009b) that programs as well as their weak completions
admit a least model under three-valued Łukasiewicz logic.
Moreover, the least model of wcP can be obtained as the
least fixed point of the semantic operator Φ, which is due to
Stenning and van Lambalgen (2008). Let I = hI > , I ⊥ i be an
interpretation, then ΦP (I) = hJ > , J ⊥ i, is defined by:
J>
J⊥

=
=

{A | A ← Body ∈ def (A, P ) and I(Body) = >},
{A | def (A, P ) 6= 0/ and
I(Body) = ⊥ for all A ← Body ∈ def (A, P )}.

r(a) ← ⊥.

Weak Completion Semantics (WCS) is the approach to
consider weakly completed programs, to compute their least

4 A ← ⊥ is called an assumption because it can be overwritten
under the Weak Completion Semantics, as we will discuss later.

5 If P = {A ← ⊥, A ← >} then wcP = {A ↔ ⊥ ∨ >}. This is
semantically equivalent to wcP = {A ↔ >}. A ← ⊥ is overwritten.

p(X) ← q(X) ∧ ¬r(X) ∧ s(X).

q(a) ← >.

884

clause states that for all X, q(X) holds if p(X) and ¬ab(X)
holds, i.e. nothing abnormal for X is known. This in turn
is stated by the second clause. Clauses are assumed to be
universally closed and, hence, the universal quantifier can be
omitted.

models, and to reason with respect to these models.
We write P |=wcs F iff formula F holds in the least model
/ 0i,
/ we obtain:
of wcP . Consider again Pex . Starting with h0,
/ 0i)
/
ΦPex (h0,

=

h{q(a)}, {r(a)}i

=

I1

=

ΦPex (I1 ).

I1 is the least model of wcPex .

Existential Import and Gricean Implicature (import)

Integrity Constraints

Humans seem to understand quantifiers differently due to
a pragmatic understanding of language. For instance, in
natural language we normally do not quantify over things
that do not exist. Consequently, for all implies there exists.
This appears to be in line with human reasoning and has
been called the Gricean Implicature (Grice, 1975). Several
theories like the theory of mental models (Johnson-Laird,
1983) or mental logic (Rips, 1994) assume that the sets
we quantify over are not empty. Likewise, Stenning and
van Lambalgen (2008) have shown that humans require
existential import for a conditional to be true. Furthermore,
as mentioned in Khemlani and Johnson-Laird (2012), the
quantifier ‘some a are b’ often implies that ‘some a are not
b’, which again can be explained by assuming the Gricean
Implicature: Someone would not state ‘some a are b’ if that
person knew that ‘all a are b’. As the person does not say ‘all
a are b’ but instead ‘some a are b’, we have to assume that
‘not all a are b’, which in turn implies ‘some a are not b’.

An integrity constraint is an expression of the form U ←
Body, where Body is a conjunction of literals and U
denotes the unknown. An interpretation I maps an integrity
constraint U ← Body to > iff I(Body) ⊆ {⊥, U}. Given an
interpretation I and a finite set IC of integrity constraints, I
satisfies IC iff all clauses occurring in IC are true under I.

Abductive Logic Programming
In Logic Programming, abduction is the reasoning process
of searching for explanations given a program and some
observations, which do not follow from the program (Peirce,
Hartshorne, & Weiss, 1974). Explanations are usually
restricted to certain formulas called abducibles. Let P be a
ground program. The set of abducibles of P is
AP = {A ← > | A is undefined or ¬A is assumed in P }
∪ {A ← ⊥ | A is undefined in P }.
An abductive framework consists of a program P , a finite
set A of abducibles, a finite set IC of integrity constraints, and
an entailment relation. Let hP , A , IC, |=wcs i be an abductive
framework, E ⊆ A , and O a non-empty set of literals called
observation. An observation O = {o1 , . . . , on } is explained
by E given P and IC iff P ∪ E |=wcs o1 ∧ . . . ∧ on and
P ∪ E |=wcs IC. O is explained given P and IC iff there
exists an E such that O is explained by E given P and IC.
We prefer subset-minimal explanations. An explanation E is
minimal iff there is no explanation E 0 such that E 0 ⊂ E .
Consider the program P = {w ← g, w ← s, g ← r}.6
Suppose we observe O = {w}. Because the least model of
/ 0i
/ the observation does not follow. However, O
wc P is h0,
can be explained by E = {s ← >}. Starting with the empty
interpretation we obtain:
/ 0i)
/
ΦP ∪E (h0,
/
ΦP ∪E (h{s}, 0i)

=
=

/
h{s}, 0i
/
h{s, w}, 0i

=

Unknown Generalization (unknownGen)
Humans seem to distinguish between ‘some y are z’ and
‘all y are z’, as we have already explained in the previous
paragraph. Accordingly, if we observe that an object o
belongs to y and z then we do not want to conclude both,
‘some y are z’ and ‘all y are z’. In order to prevent such
unwanted conclusions we introduce the following principle:
if we know that ‘some y are z’ then there must not only be an
object o1 which belongs to y and z (by Gricean implicature)
but there must be another object o2 which belongs to y and
for which it is unknown whether it belongs to z.

Converse Interpretation (converse)
Although there appears to be some evidence that humans
seem to distinguish between ‘some y are z’ and ‘some z are y’
(see the results reported in Khemlani & Johnson-Laird, 2012)
we propose that premises of the form Iab imply Iba and vice
versa. If there is an object which belongs to y and z, then
there is also an object which belongs to z and y.

/
ΦP ∪E (h{s, w}, 0i).

/ is the least model of wc(P ∪ E ). It entails O . E is
h{s, w}, 0i
minimal, whereas E 0 = {s ← >, r ← >} is not.

Seven Principles in Reasoning with Quantifiers

Block Conclusions by Double Negation (doubleNeg)

We will apply seven principles in developing a logical form
for the representation of syllogisms.

Consider the following two negative sentences (i.e. including
negation) and the positive one: ‘ If not a, then b. If
not b then c. a is true.’ The program representing these
sentences is P = {b ← ¬a, c ← ¬b, a ← >}. The weak
completion of P is wc P = {b ↔ ¬a, c ↔ ¬b, a ↔ >}. Its
least model is h{a, c}, {b}i, and thus a and c are true: a
is true because it is a fact and c is true by the negation
of b. b is derived to be false because the negation
of a is false. This example shows that under WCS, a

Licenses for Inferences (licenses)
Stenning and van Lambalgen (2008) propose to formalize
conditionals by licenses for inferences. For example, the
conditional for all X, if p(X) then q(X) is represented by
the program {q(X) ← p(X) ∧ ¬ab(X), ab(X) ← ⊥}. Its first
6 The wheels of a lawnmower are wet if the gras is wet; the
wheels are wet if the sprinkler is on; the gras is wet if it is raining.

885

b(X) ← a(X) ∧ ¬abab (X).
(converse&licenses)
abab (o3 ) ← ⊥.
(converse&licenses&unknownGen)
a(o3 ) ← >.
(converse&import)
a(o4 ) ← >.
(converse&unknownGen)

positive conclusion (c being true) can be derived from two
clauses, which include negation. Considering the results of
the participants’ responses in (Khemlani & Johnson-Laird,
2012), they seem not to draw conclusions through double
negation. Accordingly, we block them through abnormalities.

c0 (X) ← b(X) ∧ ¬abbnc (X).
abbnc (X) ← ⊥.
c(X) ← ¬c0 (X) ∧ ¬abncc (X).
b(o5 ) ← >.
abncc (o5 ) ← ⊥.

Search Alternative Conclusions to NVC (abduction)
Our hypothesis is that when participants are faced with a
NVC conclusion (‘no valid conclusion’), they might not want
to accept this conclusion and proceed to check whether
there exists unknown information that is relevant. This
information may be explanations to facts in our program,
and we model such repair mechanism using abduction. Facts
in our programs come either from an existential import or
from unknown generalization. We use only the first as source
for observations, since they are used directly to infer new
information.

(transformation &licenses)
(licenses)
(transformation &licenses)
(import)
(licenses&doubleNeg)

In addition, we have the following integrity constraint:
U ← c(X) ∧ c0 (X).
IA2

(transformation)

The two syllogistic premises of IA2 are as follows:

Some b are a. (Iba)

all c are b. (Acb)

Program PIA2 consists of the following clauses:
a(X) ← b(X) ∧ ¬abba (X).
abba (o1 ) ← ⊥.
b(o1 ) ← >.
b(o2 ) ← >.

Negation by Transformation (transformation)

(licenses)
(licenses&unknownGen)
(import)
(unknownGen)

A negative literal cannot be the head of a clause
in a program.
In order to represent a negative
conclusion ¬p(X) an auxiliary atom p0 (X) is introduced
together with a clause p(X) ← ¬p0 (X) and the integrity
constraint U ← p(X) ∧ p0 (X).
This is a widely used
technique in logic programming.
Together with the
principle licences for inferences, the additional clause is
p(X) ← ¬p0 (X) ∧ ¬ab(X).

b(X) ← a(X) ∧ ¬abab (X).
(converse&licenses)
abab (o3 ) ← ⊥.
(converse&licenses&unknownGen)
a(o3 ) ← >.
(converse&import)
a(o4 ) ← >.
(converse&unknownGen)

Representation of Quantified Statements

Khemlani and Johnson-Laird (2012) do not report a formal
definition for the entailment of syllogisms. They use FOL
as a normative theory and test if the conclusions drawn
by the participants are correct with respect to a first-order
representation of a syllogism. In FOL, a set of formulas
K entails a formula F (K |= F) if all interpretations which
map K to true map F to true as well. We believe that the
entailment relation should reflect the principles on which
the representation is based. In the following, an entailment
relation regarding WCS is presented, where yz is to be
replaced by ac or ca.

b(X) ← c(X) ∧ ¬abcb (X).
abcb (X) ← ⊥.
c(o5 ) ← >.

Entailment of Syllogisms

Based on the principles presented in the previous section, we
discuss the representation of three examples.
OA4

The two syllogistic premises of OA4 are as follows:

Some b are not a. (Oba)

all b are c. (Abc)

The program POA4 representing OA4 consists of:
a0 (X) ← b(X) ∧ ¬abbna (X).
abbna (o1 ) ← ⊥.
a(X) ← ¬a0 (X) ∧ ¬abnaa (X).
b(o1 ) ← >.
b(o2 ) ← >.
abnaa (o1 ) ← ⊥.
abnaa (o2 ) ← ⊥.

(transformation &licenses)
(unknownGen & licenses)
(transformation & licenses)
(import)
(unknownGen)
(doubleNeg & licenses)
(doubleNeg & licenses)

c(X) ← b(X) ∧ ¬abbc (X).
abbc (X) ← ⊥.
b(o3 ) ← >.

• P |= Ayz iff there exists an object o such that P |=wcs y(o)
and for all o we find that if P |=wcs y(o) then P |=wcs z(o).

(licenses)
(licenses)
(import)

• P |= Eyz iff there exists an object o such that P |=wcs z(o)
and for all o we find that if P |=wcs z(o) then P |=wcs ¬y(o).

In addition, we have the following integrity constraint:
U ← a(X) ∧ a0 (X).
IE4

• P |= Iyz iff there exists an object o1 such that
P |=wcs y(o1 ) ∧ z(o1 ) and there exists an object o2 such that
P |=wcs y(o2 ) and P 6|=wcs z(o2 ) and there exists an object
o3 such that P |=wcs z(o3 ) and P 6|=wcs y(o3 ).

(transformation)

The two syllogistic premises of IE4 are as follows:

Some b are a. (Iba)

no b are c. (Ebc)

• P |= Oyz iff there exists an object o1 such that
P |=wcs y(o1 ) ∧ ¬z(o1 ) and there exists an object o2 such
that P |=wcs y(o2 ) and P 6|=wcs ¬z(o2 ).

The program PIE4 representing IE4 consists of:
a(X) ← b(X) ∧ ¬abba (X).
abba (o1 ) ← ⊥.
b(o1 ) ← >.
b(o2 ) ← >.

(licenses)
(licenses&unknownGen)
(import)

(licenses)
(licenses&unknownGen)
(import)
(unknownGen)

In case we can not conclude any of these moods, then no valid
conclusion is entailed, denoted as P |= NVC.

886

Accuracy of Predictions

For each observation and each of its minimal explanations
we compute the least model of the weak completion of
the program extended with the explanation and collect all
entailed syllogistic conclusions. Observations that cannot
be explained are filtered out. The set Answers consists
of all entailed conclusions for the observations left. For
the final conclusions, we apply skeptical reasoning, i.e.,
the final answer to the current syllogism is given by
T
FinalAnswer =
A∈Answers A. In the case that FinalAnswer
is empty, we entail the NVC conclusion.
Reconsider IA2, where the observations are O1 = {b(o1 )},
O2 = {a(o3 )} and O3 = {c(o5 )}. If we examine Oi = { o }
with i ∈ {1, 2, 3}, then we will try to find an explanation for
Oi with respect to PIA2 \ {o ← >}.7 The set of abducibles is:
APIA2 = {abba (oi ) ← >, abba (oi ) ← ⊥ | i ∈ {2, 3, 4, 5}}

We evaluate our approach the same way as the other theories
have been evaluated (Khemlani & Johnson-Laird, 2012):
There are nine different answers for each of the 64 syllogisms
that can be ordered in a list: Aac, Eac, Iac, Oac, Aca, Eca,
Ica, Oca, and NVC. We consider two lists: a list for WCS
predictions and a list for participants’ answers. In the WCS
list, we assign 1 to an answer if it is predicted under WCS;
else we assign 0. In the list with the participants’ answers
we use a threshold function and assign 1 to answers that were
drawn by more than 16% of the participants; else we assign 0.
Both lists can then be compared for their congruence as
follows, where i is the ith element of both lists:

1
if both have the same value for ith element,
COMP(i) =
0

otherwise.

∪
∪
∪
∪

The matching percentage of this syllogism is then computed
by ∑9i=1 COMP(i)/9. Note that the percentage of the match
does not only take into account when WCS correctly predicts
a conclusion, but also whenever it correctly rejected a
conclusion. The average percentage of accuracy is then the
average of the matching percentage of all 64 syllogisms.

{abab (oi ) ← >, abab (oi ) ← ⊥
{c(oi ) ← >,
c(oi ) ← ⊥
{abcb (o5 ) ← >
{abba (o1 ) ← >, abab (o3 ) ← >

| i ∈ {1, 2, 4, 5}}
| i ∈ {1, 2, 3, 4}}
| i ∈ {1, 2, 3, 4, 5}}
}.

E1 = {c(o1 ) ← >} and E2 = {c(o3 ) ← >, abba (o3 ) ← ⊥}
are the minimal explanations for O1 and O2 , respectively.
Note that for O3 there is no explanation.
Consider the observation O1 = {b(o1 )} and the program
PIA1 2 = (PIA2 \ {b(o1 ) ← >}) ∪ E1 . The least model of wc PIA1 2

OA4 - Perfect Match (100%)
Consider POA4 . The least model of wc POA4 , I = hI > , I ⊥ i, is:

is hI > ∪ {c(o1 )}, I ⊥ i where hI > , I ⊥ i is the least model
of wc PIA2 , as defined before. Thus, c(o1 ) is newly entailed
to be true after applying abduction. This model entails
what participants concluded, namely Iac and Ica. Iac
is entailed as there exists an object, viz. o1 , such that
PIA1 2 |=wcs a(o1 ) ∧ c(o1 ) and there exists another object, viz.
o4 , such that PIA1 2 |=wcs a(o4 ) and PIA1 2 6|=wcs c(o4 ), and there
exists another object ,viz. o5 , such that PIA1 2 |=wcs c(o5 ) and
PIA1 2 6|=wcs a(o5 ). Analogously, ‘some c are a’ (Ica) holds.
For the observation O2 = {a(o3 )} we consider the program
PIA2 2 = (PIA2 \ {a(o3 ) ← >}) ∪ E2 . The least model of PIA2 2
also entails the conclusions Iac and Ica.
Answers(PIA2 ) = {{Iac, Ica} , {Iac, Ica}} is the collection
of all conclusions. FinalAnswer(PIA2 ) = {Iac, Ica} consists of
the skeptically entailed conclusions, i.e. it is the intersection
of all conclusions, which in this case are ‘some a are c’ (Iac)
and ‘some c are a’ (Ica).

I > = {b(o1 ), b(o2 ), b(o3 ), abca (o1 ), a0 (o1 ), c(o1 ), c(o2 ), c(o3 )},
I ⊥ = {abbna (o1 ), abnaa (o1 ), abbc (o1 ), abbc (o2 ), abbc (o3 ), a(o1 )}.

This model entails only the conclusion ‘some c are not
a’ (Oca): There exists an object, viz. o1 , such that
POA4 |=wcs c(o1 ) ∧ ¬a(o1 ) and there exists another object,
viz. o2 , such that POA4 |=wcs c(o2 ) and POA4 6|=wcs ¬a(o2 ).
IE4 - Partial Match (89%)
Consider PIE4 . The least model of wc PIE4 , I = hI > , I ⊥ i, is
I > = {a(oi ) | i ∈ {1, 3, 4}} ∪ {b(oi ) | i ∈ {1, 2, 3, 5}}
∪ {c0 (oi ) | i ∈ {1, 2, 3, 5}}
I ⊥ = {abba (o1 ), abab (o3 ), abncc (o5 ), abbnc (o5 )}
∪ {abbnc (oi ) | i ∈ {1, 2, 3, 4, 5}} ∪ {c(oi ) | i ∈ {1, 2, 3, 5}}.

This model entails only ‘Some a are not c’ (Oac).
IA2 - Explain NVC: Perfect Match (100%)
Consider PIA2 . The least model of wc PIA2 , I = hI > , I ⊥ i, is

Overall Accuracy of 89%
The results of the three examples formalized under WCS
are summarized and compared to FOL, PSYCOP, the Verbal,
and the Mental Model Theory in Table 5. For some
syllogisms the conclusions drawn by the participants and
WCS are identical and for some syllogisms the conclusions
drawn by the participants and WCS overlap. Combining the
syllogistic premises representation and entailment rules for
all 64 syllogistic premises and applying abduction when NVC
was entailed (which happened in 43 cases), we accomplished
an average of 89% accuracy in our predictions. In 18 cases
we have a perfect match, in 30 cases the match is 89%, in 13

I > = {a(o

1 ), a(o3 ), a(o4 ), b(o1 ), b(o2 ), b(o3 ), b(o5 ), c(o5 )},
I ⊥ = {abba (o1 ), abab (o3 )} ∪ {abcb (oi ) | i ∈ {1, 2, 3, 4, 5}}.

This model entails ‘no valid conclusion’ (NVC). However, a
significant percentage of participants answered Iac and Ica,
despite IA2 being an invalid syllogism in classical FOL.
According to the sixth principle, abduction, we believe
that these participants might have searched for alternatives
to NVC. We model this by applying skeptical abductive
reasoning.
Each head of an existential import generates a single
observation. We apply abduction sequentially to each of
them. To prevent empty explanations we remove from
the current program the fact that generated the observation.

7 We remove the fact from the program that generated the
observation, because otherwise the explanation would be empty.

887

Table 5: The conclusions drawn by a significant percentage
of participants are highlighted in gray and compared to the
predictions of the theories FOL, PSYCOP, Verbal, and Mental
Models as well as WCS for the syllogisms OA4, IE4, and IA2.

of the 34th annual conference of the Cognitive Science
Society (pp. 1500–1505).
Dietz, E.-A., Hölldobler, S., & Ragni, M. (2013). A
computational logic approach to the abstract and the
social case of the selection task. In 11th int. symposium
on logical formalizations of commonsense reasoning.
Grice, H. P. (1975). Logic and conversation. In P. Cole
& J. L. Morgan (Eds.), Syntax and semantics (Vol. 3).
Academic Press.
Hölldober, S. (2009). Logik und Logikprogrammierung (Vol.
1: Grundlagen). Synchron Publishers.
Hölldobler, S. (2015). Weak completion semantics and its
applications in human reasoning. In U. Furbach &
C. Schon (Eds.), CEUR WS proc. on bridging the gap
between human and automated reasoning (pp. 2–16).
Hölldobler, S., & Kencana Ramli, C. D. (2009a). Logic
programs under three-valued Łukasiewicz semantics.
In P. M. Hill & D. S. Warren (Eds.), 25th int.
conference on logic programming, LNCS 5649 (pp.
464–478). Springer.
Hölldobler, S., & Kencana Ramli, C. D. (2009b). Logics
and networks for human reasoning. In int. conference
on artificial neural networks, LNCS, 5769 (pp. 85–94).
Springer.
Johnson-Laird, P. N. (1983). Mental models: Towards
a cognitive science of language, inference, and
consciousness. Harvard University Press.
Khemlani, S., & Johnson-Laird, P. N. (2012). Theories of the
syllogism: A meta-analysis. Psychological Bulletin,
427-457.
Lloyd, J. W. (1984). Foundations of logic programming.
Springer.
Łukasiewicz, J. (1920). O logice trójwartościowej. Ruch
Filozoficzny, 5, 169–171.
Peirce, C., Hartshorne, C., & Weiss, P. (1974). Collected
papers of charles sanders peirce. Belknap Press of
Harvard University Press.
Pereira, L. M., Dietz, E.-A., & Hölldobler, S. (2014a).
An abductive reasoning approach to the belief-bias
effect. In C. Baral, G. D. Giacomo, & T. Eiter (Eds.),
Principles of knowledge representation and reasoning:
Proc. of the 14th int. conference (p. 653-656). AAAI
Press.
Pereira, L. M., Dietz, E.-A., & Hölldobler, S. (2014b).
Contextual abductive reasoning with side-effects. In
I. Niemelä (Ed.), Theory and practice of logic
programming, 14 (p. 633-648). Cambridge University
Press.
Polk, T. A., & Newell, A. (1995). Deduction as verbal
reasoning. Psychological Review, 102(3), 533.
Rips, L. J. (1994). The psychology of proof: Deductive
reasoning in human thinking. MIT Press.
Smith, R. (1989). Aristotle’s prior analytics. Hackett.
Stenning, K., & van Lambalgen, M. (2008). Human
reasoning and cognitive science. MIT Press.

Part. FOL PSYCOP Verbal Models Mental Models WCS
OA4 Oca

Oca,

Oca,

Oca,

Ica, Iac

NVC

Oac, NVC

IE4 Oac, Oac

Oac,

Oac,

Oac, NVC

NVC

Iac, Ica

NVC

Eac, Eca, Oca

NVC

Ica

Iac, Ica,

Iac

NVC

NVC

Ica

IA2 Iac,
Ica

Oca

NVC

Oca
Oac

cases the match is 78%, and in the remaining three cases the
match is 67%. We achieve the best performance compared to
the other state-of-the-art cognitive theories with the current
best performance of 84 % (Verbal Model Theory).

Conclusions
We developed seven principles for modeling a logical form
for the representation of quantified statements in human
reasoning, mostly motivated from findings in Cognitive
Science. We show how these principles can be encoded
within a computational logic approach, the Weak Completion
Semantics. After that we discuss the predictions of three
examples under WCS and compare them to the conclusions
humans draw from in (Khemlani & Johnson-Laird, 2012).
The result with respect to all 64 syllogistic premises under
WCS shows that we achieve the best results with a prediction
of 89%, compared to the results of other cognitive theories.

References
Dietz, E.-A. (2017). A computational logic approach to
the belief bias in human syllogistic reasoning. In
P. Brézillon, R. Turner, & C. Penco (Eds.), 10th int. and
interdisciplinary conference on modeling and using
context LNAI (Vol. 10257, p. 691-707). Springer.
Dietz, E.-A., & Hölldobler, S. (2015). A new computational
logic approach to reason with conditionals.
In
F. Calimeri, G. Ianni, & M. Truszczynski (Eds.), Logic
programming and nonmonotonic reasoning - 13th int.
conference, LNAI (Vol. 9345, pp. 265–278). Springer.
Dietz, E.-A., Hölldobler, S., & Höps, R.
(2015).
A computational logic approach to human spatial
reasoning. In IEEE symposium series on computational
intelligence (pp. 1627–1634). IEEE.
Dietz, E.-A., Hölldobler, S., & Pereira, L. M. (2015).
On conditionals. In G. Gottlob, G. Sutcliffe, &
A. Voronkov (Eds.), Global conference on artificial
intelligence, Epic Series in Computing, 36 (pp. 79–92).
EasyChair.
Dietz, E.-A., Hölldobler, S., & Ragni, M. (2012). A
computational logic approach to the suppression task.
In N. Miyake, D. Peebles, & R. P. Cooper (Eds.), Proc.

888

