Does banana spontaneously activate yellow color? Color-related concepts help with
color discrimination
Lionel Brunel (lionel.brunel@univ-montp3.fr) &Philippe Servajean (philippe.servajean@univ-montp3.fr)
Department of Psychology, Epsylon Laboratory, University Paul Valéry
Montpellier, France

Loic Heurley (heurleyloic@yahoo.fr)
Department STAPS, CeRSM Laboratory, University Paris X,
Nanterre, France

Nicolas Vermeulen (nicolas.vermeulen@uclouvain.be)
Research Institute for Psychological Sciences, Université catholique de Louvain,
Louvain-la-Neuve, Belgium
Abstract
Color is a critical part of objects representation as well as
critical cue for recognizing objects. However, it is less clear
how people represent color in memory. The present study
aimed at investigating this issue. We designed a procedure
based on short-term sensory memory load procedure mixed
with a color-priming paradigm. Participants learned three
visual stimuli (either non-words – lexical load condition - or
visual-shapes – visual-shape load condition). Then, they
performed a color discrimination task on colored patch (e.g.,
a yellow patch). Each target was preceded by a color-related
concept word either congruent (e.g., word “banana”) or not
(e.g., word “lettuce”). Finally, they performed a recognition
task either on non-words or on visual-shapes depending on
the memory load condition). We showed that color-priming
effect was selectively disrupted in visual-shape load
condition. We interpreted this finding as an evidence that
automatic modal simulations occur during access to the
meaning of color-related concept.
Keywords: Color knowledge, perceptual simulation, priming
effect, visual memory

Introduction
Color knowledge about object is an important part of
conceptual representation. Indeed, color is often a critical
cue for recognizing object (Tanaka & Presnell, 1999) or
natural scene (Oliva & Schyns, 2000) in everyday life.
Hansen, Olkkonen, Walter, and Gegenfurtner (2006)
suggested that research about color should investigate how
people represent color rather than how people perceive color
because color of an environment is never stable over the
time (i.e., dependent of the objects’ illumination) and, as a
consequence, dependent from color knowledge. The
question is how do people represent color knowledge?
First, color knowledge could be considered as stored in
an amodal format within conceptual representation of an
object. In that view, meaning of an object is distributed
across semantic features (see Masson, 1995) and
relationships between concepts are explained in term of

overlapping between semantic features. As soon as two
concepts share the same semantic color feature, one can
prime the other. For instance, hearing the word “lips” could
facilitate the detection of the picture of a strawberry
(Huettig & Altmann, 2011). However, several studies
suggest that access to color knowledge depend on the nature
of the stimuli (i.e., lexical vs. visual, see Nijboer, Zandvoort
& Haan, 2006). Indeed, because the word “banana” and
“yellow” co-occurs frequently in everyday language, color
knowledge could also be stored in a lexical format: a color
label (see Landauer & Dumais, 1997). In that case, as soon
as two concepts share the same color label, one can prime
the other. For instance, hearing the word “pea” could
facilitate the detection of the picture of a green blouse (see
Huettig & Altamann, 2011) because both objects share the
label “green”. In the same vein, Roberson and Davidoff
(2000) have showed a loss of the categorical perception
(i.e., better discrimination across color categories than
within the same color category) when participants had to
simultaneous discriminate between colors and maintain
words in memory. This effect was not observed when they
had to follow a curved line with the eyes. Accordingly, it
seems that lexical access interferes with categorical
perception, while visual interference does not. This result
suggests the implication of lexical units during access to
color knowledge. Moreover Nijboer and collaborators
(2006) demonstrated that color-priming effect (from objectword or object-picture to colored-patch) is dependent of the
nature of the prime (either picture or word, see also Heurley,
et al., 2013). This result suggests the existence of both a
semantic-based and lexical-based representation of color.
These two formats of color knowledge are not necessary
incompatible and authors suggested a time-based access
distinction for accounting existence of both level of
representation (Heurley et al., 2013).
Alternatively, theories of embodied or grounded cognition
(see Barsalou, 2008) assume that access to a representation
is linked with perceptual sensory simulations. In other
words, performing a conceptual task like verifying that a

1684

“banana” is “yellow” is associated with the automatic
simulation of a former visual experience associated with the
banana (Pecher, Zeelenberg, & Barsalou, 2003, 2004; Van
Dantzig, Pecher, Zeelenberg, & Barsalou, 2008; Vermeulen,
Chang, Corneille, Pleyers, & Mermillod, 2013; Vermeulen,
Corneille, & Niedenthal, 2008). Thus, access to the meaning
of concept involves automatic perceptual simulation in
several sensory modalities and, as a consequence, influences
processing of stimuli presented in the same modality than
the simulated one (see Brunel, Goldstone, Vallet, Riou, &
Versace, 2013; Brunel, Labeye, Lesourd, & Versace, 2009;
Brunel, Lesourd, Labeye, & Versace, 2010; Vallet, Brunel,
& Versace, 2010; for a review see Versace, Labeye, Badard,
& Rose, 2009). In that case, color knowledge could be
defined as perceptual or modal rather than semantic or
lexical. Indeed, neuroimagery studies showed that either
perceiving or conceiving color involves common neural
substrates (Simmons et al., 2007). Moreover, Richter and
Zwaan (2009) showed that processing color words (e.g.,
word “red”) involves perceptual simulation of the color.
They showed that participants were faster at discriminating
between targets colored-square displayed in the same
category color (e.g., light red vs. dark red) when the prime
color word and the targets colored squares match on their
color rather than mismatch. According to the authors, their
results ruled out an explanation based on a lexical
competition since the prime word and the target squares
shared the same color label. Finally, Yee, Ahmed and
Thompson-Schill (2012) found a contextual-based color
priming effect using a semantic priming procedure. Indeed
they found that color-priming effect is observed only when
color was sensitized before the priming procedure.
According to the authors, this result seemed to indicate that
color knowledge is context dependent rather than stable
over the time that is consistent with an embodied approach
but not with a semantic approach (see also Connell, 2007;
Connell & Lynott, 2009 for a similar conclusion)
Given existence of empirical evidence for both
approaches (embodied vs. semantic or lexical), this article
aims at addressing the issue about the representational
format of color knowledge in memory. In the present study,
we designed a single paradigm in order to test
simultaneously each assumption regarding the nature of
color knowledge (i.e., perceptual/modal vs. lexical/amodal).
To do so, we adapted the procedure of Vermeulen and coworkers (2008, see also Vermeulen, Chang, Mermillod,
Pleyers & Corneille, in press, Experiment 2). In their
experiment, they combined a short-term memory task (i.e.,
memory load) with a property verification task.
Consequently, they manipulated both the nature of the
memory load (i.e., visual or auditory) and the nature of the
property (i.e., visual or auditory) during the property

verification task. First, participants had to learn items
visually or auditory displayed. Then they had to perform a
property verification task like verifying that a banana could
be yellow. After that, they had to recognize the previously
learnt items from a new list displayed in the same modality.
The main results of their study is that participants were
significantly slower at verifying visual properties preceded
by a visual-shape load than an auditory load and conversely
for auditory properties. Authors concluded that sensory
memory and conceptual memory share the same modal
properties. In our procedure, we changed the nature of the
items in the short-term memory task and replaced the
property verification task by a color priming procedure
(Heurley, et al., 2013). As a consequence, participants
firstly maintained three stimuli in visual memory either
meaningless lexical stimuli (i.e., non-words) or meaningless
visual-shapes (i.e., Gaussian blobs) before performing a
color discrimination task on colored patches. Each target
colored patch (e.g., a yellow patch) was preceded by a word
prime that could represent a color-related concept (e.g., the
word “banana”) or not (e.g., the word “lettuce”). Heurley
and collaborators (2013, see also Nijboer et al., 2006) found
that participant were faster at discriminating the color of the
patch when prime was congruent rather than incongruent,
attesting a color-priming effect from color-related concept
primes to colored targets patches. Finally, participants
completed a recognition task on the previously learnt
elements.
Our procedure should let us to directly test different
assumptions about the format of the color knowledge. First,
if accessing to color knowledge from a color-related concept
involves semantic amodal knowledge about color, we
should find a significant interaction between Prime Type
(yellow or green color related concept) and Color Target
(yellow or green patches) irrespective the nature of the
memory load. A given word activates its conceptual
semantic representation in memory (see, Masson, 1995)
which include diagnostic feature about the concept. Since
this representation is activated at a semantic level, it should
not interact with any of the item of the load conditions
because each item for these conditions is meaningless. This
result would be a direct replication of Heurley and coworkers (2013) Experiments. Then, if accessing color from
a color-related concept involves lexical knowledge (such as
verbal label), we should find an interaction between Prime
Type and Color Target and the Nature of the Memory Load.
In that case, the word prime activates the color
representation at a lexical level and should interact
specifically with the items of the lexical load condition. As
a consequence, we might predict a diminution (or a lost) of
color-priming effect consecutive to the lexical load
condition while the color-priming effect should be observed

1685

Figure 1: Trial overview for both training and test phase in the visual-shape load condition. Note: The colored patch is represented into
grey scale but was displayed either in yellow or green during the experiment.

with the visual-shape load condition. Finally, if accessing
color from a color-related concept involves visual
simulation, we should observe the opposite pattern. In that
case, processing the word automatically simulates former
visual experiences associated with the concept and those
simulations should interact with the items of the visualshape load condition. As a consequence, we might predict a
diminution (or a lost) of color-priming effect consecutive to
the visual-shape load condition while the color-priming
effect should be observed with the lexical load condition.

Experiment
Participant – Twenty-Four native French speakers (student
from Université Paul-Valery, Montpellier, France) were
recruited and received courses credits for their participation.
All have a normal or corrected to the normal vision and
none of them reported having atypical color perception
(Daltonism or synesthesia)
Stimuli & Material – We created 12 Gaussian blobs (6 for
training and 6 for test) that were equilibrated in term of
surface, number of angles and of peaks in both sides
regarding a vertical symmetric axis. We created also 12
CVC-CVC non-words (6 for training and 6 for test)
following Reinitz, Lammers, and Cochran (1992)
methodology. These stimuli were used in the short-term
memory task, respectively in the visual-shape load and
lexical load conditions. For the priming phase, we used the
same material than Heurley and co-workers (2013; see also
Reilhac & Jiménez, 2006). The 16 priming words (4 for
training and 12 for test) depicted either animal or vegetable
typically associated with the color green (e.g., lettuce) or
yellow (e.g., banana). The target stimuli were yellow (R =
255; G = 255; B = 0) or green patches (R = 34; G = 163; B
= 13) according to the RGB color model. We also used a

mask that was a white screen with 17 lines of 60 black stars
(i.e., *).
Procedure – After filling out a consent form, participants
were tested individually in a computer room. Each trial
started with a fixation-cross lasting on the screen during
500ms followed by three successive visual stimuli (either
non-words or visual-shapes depending on the memory load
condition), each lasting 500ms. Participants were informed
that they have to learn these stimuli in order to perform a
later recognition task. Then a prime word was prompted on
the screen (150ms) and was immediately replaced by a
visual mask (100ms) itself replaced by a blank screen
(100ms). A target colored patch followed and participants
had to judge as quickly and accurately as possible its color.
After 1500ms blank screen, 3 stimuli (non-words or visualshapes) were successively displayed and participants have to
judge for each stimuli if it corresponded or not to a
previously learnt stimulus. We set the inter-trial interval at
1500ms (see Figure 1). Participant indicated their responses
by pressing different keyboard’s keys for the color
discrimination task and for the recognition task. The
responses keys were counterbalanced between participants.
The experiment started with a training phase (16 trials)
followed by a test phase composed by 48 trials randomly
presented: 24 in the visual-shape-load and 24 in lexical-load
condition. Each prime was seen followed by each target
patch and for each load condition. For the short-term
memory task, we have controlled that the number of “same”
and “different” was identical for each position during test
compared to the learning and for each conditions: visualshape-load and lexical-load.

1686

Results
Table 1. Mean correct RT and correct response rates for each experimental condition. Note: Priming effect was calculated by
subtracting incongruent experimental conditions (e.g., “yellow” prime / green target condition) to the congruent ones (e.g.,
“yellow” prime / yellow target condition). A negative value indicates facilitation (i.e., a gain toward the congruent condition)
whereas a positive value indicates a cost.
Lexical
"Yellow" Prime
RT(ms)
Target
Color

CR

Visual-shape
"Green" Prime

RT(ms)

CR

"Yellow" Prime
RT(ms)

CR

"Green" Prime
RT(ms)

CR

Yellow

493 (21)

0.965 (.018)

531 (26)

0.971 (.013)

518 (28)

0.978 (.012)

525 (27)

0.942 (.021)

Green

529 (24)

0.965 (.017)

490 (28)

0.976 (.013)

517 (27)

0.962 (.013)

528 (29)

0.957 (.018)

Priming effect

-36

-42

1

Color Discrimination Task - The mean correct response
latencies and mean percentages of correct responses were
calculated across subjects for each experimental condition.
Latencies below 250 ms and above 1,250 ms were removed
(this cut-off resulted in the exclusion of 2.95% of the data,
see Brunel et al., 2009). The participants performed the test
color categorization task accurately (overall correct
response rate of 96.45%, see Table 1). Practice trials were
removed from the analysis.
A repeated analysis of variance was performed with
subjects as random variable, Nature of Memory Load
(Lexical vs. Visual-shape), Prime Type (yellow-related
concept vs. a green-related concept) and Target Color
(Yellow vs. Green) as within-subjects variables.
Analysis revealed neither significant main effects of the
Nature of Memory Load, F(1, 23) = 1.79, p = .19, η2p = .07,
Prime Type, F < 1, Target Color, F < 1 nor interaction
between Nature of Memory Load and Prime Type, F < 1,
and between Nature of memory Load and Target Color, F <
1. Analysis showed a significant interaction between Prime
Type and Target Color, F(1, 23) = 7.14, p < .05, η2 p = .24.
However, the Nature of Memory Load modulates this
interaction. Indeed analysis revealed a significant three way
interaction between Nature of the Memory Load, Prime
Type and Target Color, F(1, 23) = 7.33, p < .05 , η2 p =.24.
This interaction is depicted in Figure 2.

Figure 2: Mean correct RT for each experimental condition.
Error bar represents standard error.

2

As can be appreciated in Figure 2, the interaction between
Prime Type and Target Color was observed in the lexical
load condition, but not in the visual-shape load condition.
Regarding the lexical load condition, participants were
significantly faster at judging the green patch preceded by a
congruent prime (i.e., a green-related concept like a lettuce)
than an incongruent prime (i.e., a yellow-related concept
like a banana), F(1, 23) = 7.60, p < .05. The reverse was
observed for the yellow patch, F(1, 23) = 4.61 , p < . 0.5.
Regarding the visual-shape load condition. The Prime
Type did not modulate color discrimination. The difference
between the primes was not significant for the yellow patch,
F < 1, as well for the green patch, F < 1.
Recognition Task – A t-test conducted between the correct
recognition rates of the different memory load conditions
revealed that participants were significantly worst for the
memory test in the visual-shape load condition (M = .672,
SE = .021) than in lexical condition (M = .729, SE = .015),
t(23) = 3.25 , p < .05.
Correlation Analysis - We also tested the correlation
between the memory test accuracy and the priming effect
size (RT congruent – RT incongruent)1 for both condition of
memory load and each participant. Indeed, Vermeulen and
collaborators (2008) showed that memory performances
were selectively influenced by the relation between the
nature of the load (i.e., visual or auditory) and the nature of
the to be verified property (i.e., visual or auditory).
Accordingly, we might expect a negative correlation
between the priming effect size and the memory
performance in the visual-shape load condition. In other
words, less the visual-shape load is efficient (attesting by a
high recognition rate) the higher is the probability to
observe a priming effect. Conversely, we should not observe
any correlation for the lexical load condition.
1
We collapsed congruent RTs (Yellow prime/Yellow target and
Green prime/Green target) and we did the same for the incongruent
RTs (Yellow prime/Green target and Green prime/Yellow target.

1687

We found a significant negative correlation (Spearman
Correlation) between the priming effect size and the
memory performance for the visual-shape load condition,
r(22) = -.46, p < .05, but not for lexical load condition, r(22)
= +.02.

a concept in a given modality involves perceptual
simulation in the same sensory modality and in the other
related sensory (Brunel, Lesourd, et al., 2010) or motor
modalities (Brouillet, Heurley, Martin, & Brouillet, 2010).

Discussion

References

The aim of this study was to propose a procedure for
disentangling between several conceptions about nature of
color knowledge in memory. To do so, we combined a
color-priming paradigm (Heurley, et al., 2013) with a shortterm memory load procedure (Vermeulen, et al., 2008).
First, participants had to learn three visual elements (either
non-words or shapes). Then, they had to perform a color
discrimination task where each colored-target (e.g., yellow
patch) was preceded by a congruent color-related word
concept (e.g., “banana”) or not (e.g., “lettuce”). Finally, they
performed a recognition task on either non-words or visualshapes depending on the memory load condition. Our
results seem to indicate that access to color knowledge
involves perceptual simulation rather than lexical or
semantic activation. Indeed, we found that color-priming
effect (i.e., shorter RTs when the color of the patch was
congruent with color-related concept word rather than
incongruent) was incurred in the visual-shape load condition
while it was observed in the lexical load condition. This
should be due to a competition for same visual resources
between the short-term storage of shapes in memory and the
simulation of the color-related concepts (see Vermeulen,
Corneille et al., 2008; Vermeulen, Chang et al., in press, for
a similar conclusion). Moreover, the fact that we found a
significant negative correlation between priming size effect
and the accuracy in short-term memory task in the visualshape load condition (while the same correlation was not
significant in the lexical load condition) is consistent with
our interpretation. Moreover, this result is in accordance
with Yee and co-workers’ (2012) experiment. Indeed, they
found a positive correlation between Stroop interference and
color-priming gain only when the Stroop task was presented
before the priming procedure. This result attested that colorpriming effect was modulated by the Stroop task. Taken
together, these results indicate that access to color
information related to object is not only contextually
dependent but also sensory-based. Finally, our results bring
direct evidence that access to an object concept using words
involved automatic modal simulation (see also Vermeulen
et al., in press). Indeed, this paper showed that words
representing modal concept spontaneously involve
perceptual simulations (without engaging participant in a
property verification task) so that a perceptual load (in the
same modality than the modal concept) selectively incurs
memory for these words.
In conclusion, our study provides a strong argument in
favor of the idea that access to conceptual knowledge is
linked to the simulation of the sensory dimension captured
within the concept (see Barsalou, 2008) so that experiencing

Barsalou, L. W. (2008). Grounded cognition. Annual
Review
of
Psychology,
59,
617-645.
doi:
10.1146/annurev.psych.59.103006.093639
Brouillet, T., Heurley, L., Martin, S., & Brouillet, D. (2010).
The embodied cognition theory and the motor component
of “yes” and “no” verbal responses. Acta Psychologica,
134, 310-317. doi: 10.1016/j.actpsy.2010.03.003
Brunel, L., Goldstone, R. L., Vallet, G., Riou, B., &
Versace, R. (2013). When seeing a dog activates the bark:
multisensory generalization and distinctiveness effects.
Experimental
Psychology,
60,
100-112.
doi:
10.1027/1618-3169/a000176
Brunel, L., Labeye, E., Lesourd, M., & Versace, R. (2009).
The sensory nature of episodic memory: sensory priming
effects due to memory trace activation. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 35, 1081-1088. doi: 10.1037/a0015537
Brunel, L., Lesourd, M., Labeye, E., & Versace, R. (2010).
The sensory nature of knowledge: Sensory priming
effects in semantic categorization. Quartely Journal of
Experimental
Psychology,
63,
955-954.
doi:
10.1080/17470210903134369
Connell, L. (2007). Representing object color in language
comprehension.
Cognition,
102,
476-485.
doi:
10.1016/j.cognition.2006.02.009
Connell, L., & Lynott, D. (2009). Is bear is white in the
woods? Parallel representation of implied object color
during language comprehension. Psychonomic, Bulletin &
Review, 16, 573-577. doi: 10.3758/PBR.16.3.573
Hansen, T., Olkkonen, M., Walter, S., & Gegenfurtner, K.
R. (2006). Memory modulates color appearance. Nature
Neuroscience, 9, 1367-1368. doi: 10.1038/nn1794
Heurley, L. P., Brouillet, T., Chesnoy, G., & Brouillet, D.
(2013). Color perception involves color representations
firstly at a semantic level and then at a lexical level.
Cognitive Processes, 14, 19-29. doi: 10.1007/s10339-0120527-z
Huettig, F., & Altmann, G.T.M. (2011). Looking at
anything that is green when hearing ‘frog’ - How object
surface color and stored object color knowledge influence
language- mediated overt attention. The Quarterly
Journal of Experimental Psychology, 64, 122-145. doi:
10.1080/17470218.2010.481474
Landauer, I. K., & Dumais, S. T. (1997). A solution to
Plato's problem: The latent semantic analysis theory of
acquisition, induction and representation of knowledge.
Psychological Review, 104, 211-240.

1688

Masson, M.E.J. (1995). A distributed memory model of
semantic priming. Journal of Experimental Psychology:
Learning, Memory and Cognition, 21, 3-23.
Nijboer, T. C. W., van Zandvoort, M. J. E., & de Haan, E.
H. F. (2006b). Seeing red primes tomato: Evidence for
comparable priming from color and color name primes to
semantically related word targets. Cognitive Processes, 7,
269-274. doi: 10.1007/s10339-006-0153-8.
Oliva, A., & Schyns, P. G. (2000). Diagnostic colors
mediate scene recognition. Cognitive Psychology, 41,
176-210
Pecher, D., Zeelenberg, R., & Barsalou, L. W. (2003).
Verifying different-modality properties for concepts
produces switching costs. Psychological Science, 14, 119124.
Pecher, D., Zeelenberg, R., & Barsalou, L. W. (2004).
Sensorimotor
simulations
underlie
conceptual
representations: modality-specific effects of prior
activation. Psychonomic Bulletin & Review, 11, 164-167.
Reilhac, G., & Jiménez, M. (2006). Amorçage de la couleur
typique d’un objet lors d’une tâche de catégorisation.
Canadian Journal of Experimental Psychology, 60, 285293
Reinitz, M. T., Lammers, W. J., & Cochran, B. P. (1992).
Memory-conjunction errors: miscombination of stored
stimulus features can produce illusions of memory.
Memory & Cognition, 20, 1-11.
Richter, T., & Zwaan, R. A. (2009). Processing of color
words activates color representations. Cognition, 111,
383-389. doi: 10.1016/j.cognition.2009.02.011
Roberson, D., & Davidoff, J. (2000). The categorical
perception of colors and facial expressions: The effect of
verbal interference. Memory & Cognition, 28, 977-986.
Simmons, W. K., Ramjee, V., Beauchamp, M. S., Mcrae,
K., Martin, A., & Barsalou, L. W. (2007). A common
neural substrate for perceiving and knowing about color.
Neuropsychologia,
45,
2802-2810.
doi:
10.1016/j.neuropsychologia.2007.05.002
Tanaka, J. W., & Presnell, L. M. (1999). Color diagnosticity
in object recognition. Perception & Psychophysics, 61,
1140-1153.
Vallet, G., Brunel, L., & Versace, R. (2010). The perceptual
nature of the cross-modal priming effect: arguments in
favor of a sensory-based conception of memory.
Experimental
Psychology,
57,
376-382.
doi:
10.1027/1618-3169/a000045
Van Dantzig, S., Pecher, D., Zeelenberg, R., & Barsalou, L.
(2008). Perceptual Processing Affects Conceptual
Processing. Cognitive Science: A Multidisciplinary
Journal, 32, 579-590. doi: 10.1080/03640210802035365
Vermeulen, N., Chang, B., Corneille, O., Pleyers, G., &
Mermillod, M. (2013). Verifying properties of concepts
spontaneously requires sharing resources with samemodality percept. Cognitive Processes, 14, 81-87. doi:
10.1007/s10339-012-0533-1
Vermeulen, N., Chang, B., Mermillod, M., Pleyers, G., &
Corneille, O. (2013). Memory for words representing

modal concepts: resource sharing with same-modality
percepts is spontaneously required. Experimental
Psychology,
60,
293-301.
doi:
10.1027/16183169/a000199
Vermeulen, N., Corneille, O., & Niedenthal, P. M. (2008).
Sensory load incurs conceptual processing costs.
Cognition,
109,
287-294.
doi:
10.1016/j.cognition.2008.09.004
Versace, R., Labeye, E., Badard, G., & Rose, M. (2009).
The contents of long-term memory and the emergence of
knowledge. European journal of cognitive psychology,
21, 522-560.
Yee, E., Ahmed, S. Z., Thompson-Schill, S. L. (2012).
Colorless green ideas (can) prime furiously.
Psychological
Science,
23,
364-369.
doi:
10.1177/0956797611430691

1689

