Empirical tests of large-scale collaborative recall
Monica A. Gates (mgates@berkeley.edu)
Jordan W. Suchow (suchow@berkeley.edu)
Thomas L. Griffiths (tom_griffiths@berkeley.edu)
Department of Psychology, University of California, Berkeley, Berkeley, USA
Abstract

organize hundreds of online participants into real-time interactive chatrooms. Moreover, by considering participants as
“nodes” in a network graph, we can assemble participants
into arbitrary network structures.
The plan of the paper is as follows. We first validate our
approach by replicating established collaborative memory effects in small groups, then investigate collaborative memory
at unprecedented scale (Experiment 1). We then explore how
memories spread beyond direct communication by examining
memory transmission across networks (Experiment 2). We
compare our human results to those predicted by agent-based
modeling (Luhmann & Rajaram, 2015) to determine the models’ accuracy in describing behavior. We find that participants
show memory effects not predicted by the model, illustrating the difficulty of extrapolating findings to larger groups.
Within networks, participants also diverge from model predictions, showing reduced similarity in the words they recall
beyond direct interactions. These results highlight the importance of large-scale studies in developing predictive models
of human interaction, and further our understanding of the
complexity of real-world network transmission and memory.

Much of our knowledge is transmitted socially rather than
through firsthand experience. Even our memories depend on
recollections of those around us. Surprisingly, when people recall memories with others, they do not reach the potential number of items they could have recalled alone. This phenomenon
is called collaborative inhibition. Recently, Luhmann and Rajaram (2015) analyzed the dynamics of collaborative inhibition
at scale with an agent-based model, extrapolating from previous small-scale laboratory experiments. We tested their model
against human data collected in a large-scale experiment and
found that participants demonstrate non-monotonicities not evident in these predictions. We next analyzed memory transmission beyond directly interacting agents by placing agents into
networks. Contrary to model predictions, we observed high
similarity only within directly interacting pairs. By comparing
behavior to model predictions in large-scale experiments, we
reveal unexpected results that motivate future work in elucidating the algorithms underlying collaborative memory.
Keywords: collaborative memory; collaborative inhibition;
network transmission; crowdsourcing; agent-based modeling

Our memories often rely on the people around us: every
day we communicate with our colleagues and friends, forming and editing memories in each interchange. People learn
to access each other’s memories within long-term couples
(Wegner, Erber, & Raymond, 1991), and groups collectively
form memories that define their values (e.g., Hirst & Echterhoff, 2012). As people connect within increasingly larger networks, collaborative memory becomes ever more relevant.
In psychology, collaborative memory has historically been
investigated in small-scale, lab-based experiments. Much
work on group memory has thus focused on dyads or triads.
However, our worlds are more richly connected than can be
replicated in a lab setting, and many of the findings from this
work may not be applicable to the larger systems of our everyday lives. To address this lack of understanding of large
groups, recent efforts have focused on investigating memory
abilities using agent-based modeling (Luhmann & Rajaram,
2015). By analyzing human performance in past memory experiments, researchers can derive putative algorithms that describe human memory recall and embed these algorithms in
artificial agents. These “agents” can then participate in novel
memory paradigms with hundreds of agents interacting at a
time. Agent-based modeling provided a solution to the difficulty of recruiting large numbers of participants and arranging them in the networks required by memory experiments.
However, we have recently developed a novel approach
that allows us to overcome the previous impossibility of analyzing collaborative memory abilities at scale. Using new
technology interfacing with web-based crowdsourcing tools
such as Amazon Mechanical Turk, we can now recruit and

Collaborative Inhibition
Imagine a group of people recalling a list of words collaboratively. The group would generate more words than any
individual trying alone. However, the key comparison is not
between the number of words on the group’s list and the number of words on any one individual’s list— it is between the
group’s list, and the cumulative list of what all the individuals could have done had they worked alone. This comparison
is often made in the well-established “collaborative memory”
task. In this task, participants listen to a long list of items (often words) and then recall as many items as possible, either
as a group or individually. The number of words recalled by
the group is compared to the number of words recalled by the
“nominal group”: the summed list of an equivalent number of
individuals (redundant words removed). In the collaborative
memory paradigm, nominal groups routinely outperform collaborative groups, a finding called collaborative inhibition.
This effect has been replicated across many studies and variations on the paradigm (see Rajaram & Pereira-Pasarin, 2010).
The leading theory describing collaborative inhibition is
the retrieval disruption hypothesis (e.g., Basden, Basden,
Bryner, & Thomas, 1997; Rajaram & Pereira-Pasarin, 2010).
This hypothesis states that when initially listening to a
wordlist, people form idiosyncratic representations of the
words. When recalling words alone, participants effectively
use their idiosyncratic organizations to recall the words.

403

However, when placed in groups, other participants can disrupt a participant’s recall, leading to reduced performance.
This hypothesis predicts that when participants are encouraged to organize information in similar ways, collaborative
inhibition will disappear. In fact, when participants are experts in their domain (Meade, Nokes, & Morrow, 2009) or
are exposed to similarly ordered information (Finlay, Hitch,
& Meudell, 2000), inhibition does not occur. In generating
model predictions, Luhmann and Rajaram (2015) incorporated the assumptions of the retrieval disruption hypothesis.
In Experiments 1 and 2, we design empirical studies to compare behavioral results to these predictions.

to Equation 1, and the activations of items semantically associated with the maximally active item according to Equation
2. Item i is then encoded according to Equation 3. A is then
normalized such that ∑i Ai = 1. Just as the retrieving agent encodes the item after retrieving it, “listening” agents also then
encode the item according to the encoding process described
previously. Luhmann and Rajaram (2015) used the following
parameter settings: α = 0.2, β = 0.05, and γ = 0.75.
In the first set of simulations in Luhmann and Rajaram
(2015) comparing collaborative and nominal recall (our Experiment 1), model predictions were generated by presenting
agents with wordlists and then having agents recall words via
the described procedure. When an agent generated a word, it
was shared with every other agent in the network. Agents participated in 20 rounds of retrieval within each simulation. A
total of 1000 simulations (comparing 1000 collaborative and
1000 nominal results) were run for each group size.
In their second set of simulations analyzing agent interaction over networks (our Experiment 2), agents participated
in 800 “timesteps” rather than rounds. In contrast with the
large-scale collaborative simulations, in each timestep, every
agent interacted with one other randomly chosen agent who
was directly connected to them in the network. These interactions were pairwise, in contrast to previous simulations,
during which the agent and their partner both had the opportunity to retrieve a word. This pattern of one-on-one interaction
captures a form of organic social interaction in which someone may run into a friend and chat, and then continue on until
they happen upon someone new.
Agents were placed in two types of networks: one empirically derived network, Zachary’s karate club (Zachary, 1977),
and one algorithmically derived network, a small-world network (Watts & Strogatz, 1998). The karate club network describes the 78 links between 34 members of a club. Smallworld networks are based on the 6-degrees-of-separation phenomenon, the theory that it often takes around 6 links to connect any two individuals (Travers & Milgram, 1969). To generate small-world networks, Luhmann and Rajaram (2015)
used the Watts-Strogatz algorithm with the following parameters: 100 nodes, an average degree of 4 (participants were on
average connected to four others), and a rewiring probability
of 0.1. A total of 1000 simulations were run for each network type. Small-world networks were randomly generated
for each simulation.
In the network experiments, the measure of interest was
similarity across agents. Agent similarity was compared by
computing correlations across participants’ activation vectors
A. To capture the notion that agent similarity should be high
both when agents mutually forgot or remembered a word, the
absolute value of Pearson’s correlation coefficient was used.

Agent-Based Model
In the model described by Luhmann and Rajaram (2015),
agents encode N items (words), where N = 40. Agents have
two representations. The first is an activation vector A of
length N. Each entry A j gives the probability that the given
item j will be retrieved. The second representation is an
inter-item association matrix S of size N × N. Each entry Si j
gives item j’s association with item i (associations were not
necessarily reciprocal). This matrix would normally contain
agents’ prior knowledge about word associations; however,
Luhmann and Rajaram (2015) assigned values of S randomly
between -2 and 2 to reflect agnosticism about the semantic
relationships between words. (The S matrix was not used in
our empirical studies.)
Each agent in this model has two behaviors. The first is
encoding an item i. The first step in encoding an item is to
reduce the activation of the maximally active item in vector
A, where β is the learning rate:
∆Amax = −βAmax .

(1)

Next, the agent reduces the activations of items semantically
associated with the maximally active item:
∆A j = −βS j,max A j .

(2)

Finally, the agent increases the activation of the to-beencoded item i, with α acting as the learning rate:


∆Ai = α 1 − Ai .
(3)
The activation A vector is then normalized to ensure that its
entries can be interpreted as probabilities: ∑i Ai = 1.
An agent can also retrieve (and “orally state”) an item.
Agents take turns retrieving items, and on each turn, an agent
retrieves an item with probability γ. The item i that is retrieved is chosen according to the proportions in A, such that
items with higher activations are more likely to be retrieved.
Then the activation vector is modified. First, the agent decreases activation of items semantically associated with the
retrieved item i, in line with the theory of retrieval disruption:
∆A j = βS ji A j .

Testing Model Predictions at Large Scale
In Experiments 1 and 2, we design empirical behavioral experiments that align with the specifications of the modeling
work as closely as possible. However, the modeling work
differed in that agents were allowed to submit any word that

(4)

Next, if i is not the maximally activated item, the agent reduces the activation of the maximally active item according

404

± 0.7 for groups of size 16, 7.6 ± 0.7 for groups of size 8,
4.0 ± 0 for groups of size 4, 3.0 ± 0 for groups of size 3, and
2.0 ± 0 for groups of size 2.

they had not previously retrieved, whereas in the behavioral
work, participants were not allowed to recall words that they
or any other group members had previously recalled.
In Experiment 1, we first replicate findings from smallgroup experiments, then empirically explore the impact of
large group size on collaborative inhibition. Previous work
has suggested that collaborative inhibition increases as group
size increases from 1 to 4 participants (Basden, Basden, &
Henry, 2000; Thorley & Dewhurst, 2007), but Luhmann and
Rajaram (2015) were the first to scale up to a hundred agents
with their agent-based model. Their model predicts that collaborative inhibition rises with group size, peaks at around 8
individuals, and then begins decreasing (Figure 1a). Specifically, collaborative recall continues increasing with group
size, but nominal recall hits ceiling at around 8 people as the
disruption of idiosyncratic recall strategies is compensated by
sheer group size. Since collaborative inhibition is the difference between nominal and collaborative recall, from this
point collaborative inhibition begins to decrease. This prediction represents an extrapolation of results from small group
sizes, and we tested the assumptions underlying this agentbased model by comparing human performance in the collaborative memory experiment to the model predictions.
In Experiment 2, we turn to memory transmission across
networks. One person’s behavior can have effects far beyond
their direct connections, and viruses, information, and behaviors like smoking can spread over social networks. This transfer of information beyond direct interactions is called “hyperdyadic spread” (Christakis & Fowler, 2009). Consistent with
hyperdyadic spread, memory researchers have found that indirectly connected pairs have more similar memories than
unconnected pairs (Yamashiro & Hirst, 2014) and that distal
partners can influence word recall (Choi, Blumen, Congleton,
& Rajaram, 2014). The model from Luhmann and Rajaram
(2015) accordingly predicts that agents who never directly
interacted, but share neighbors, will be similar (Figure 2a).
Moreover, the model also predicts that agent similarity will
depend on the networks that agents participate in. Agents in
small-world networks were expected to be more similar than
agents in karate club networks if they had directly interacted,
but the opposite was expected for agents further apart. In Experiment 2, we implemented the agent-based network models
with real participants to test these predictions.

Participants would occasionally repeat the task, as they
could choose to complete the task again on Amazon Mechanical Turk despite written advisement against this. Of the
participant data included in this paper (other pilot task versions were also executed), in Experiment 1, 134 participants
repeated the experiment more than once (14.6% of participants), and 30.03% of the data was generated by these participants. Participants participated an average of 1.22 times. The
mean proportion of repeaters across group sizes (both nominal and collaborative) was as follows: group size of 2: 0.33 ±
0.35 (SD), group size of 3: 0.39 ± 0.31, group size of 4: 0.27
± 0.21, group size of 8: 0.27 ± 0.20, and group size of 16:
0.27 ± 0.09. The participants who repeated the nominal experiments did not show improvement over time, despite having seen the same wordlists: the correlation between number
of repetitions and number of words recalled was r = -0.03 (91
data points). Participants did improve across repetitions in
the collaborative experiments (r = .47, 89 data points). However, the proportion of repeaters within experiments was anticorrelated with group size: the correlation between experiments of group sizes 2, 3, 4, 8, and 16 and the proportion of
repeaters was r = -0.086.
Stimuli Participants saw 60 unrelated words, each selected
from a different category from Overschelde, Rawson, and
Dunlosky (2004). In collaborative experiments, words were
presented roughly simultaneously across all participants. The
average time (± SD) between presentation of a wordlist to the
first participant compared to the last participant was as follows: 0.4±0.5 seconds for groups of size 2, 0.2±0.3 secs for
groups of size 3, 0.9 ± 0.9 secs for groups of size 4, 2.5 ± 1.1
secs for groups of size 8, 4.2 ± 2.6 secs for groups of size 16.
Procedure Participants observed wordlists: each word was
presented for two seconds. After seeing the list, participants completed a 30-second-long arithmetic filler task before advancing to the recall task. Participants were placed
in chatrooms alone or with other participants, and were encouraged to type as many of the words they had seen as
possible. Participants were not told how many other participants were in the chatroom: their responses appeared in
blue font, and responses from all others appeared in black.
They saw all previous words entered and were not permitted
to submit any word that had already been submitted. This
choice— that any words already present on the group list
were not redisplayed— was made to encourage participants
to read others’ submitted words, and because it more closely
matched the lab-based version of the collaborative memory
paradigm, where verbal recall creates social pressure to not
repeat words. There was no time limit for the recall task.
Experiments contained group sizes of 2, 3, 4, 8, or 16 participants. For each recall method (nominal or collaborative),

Experiment 1: Small and Large Groups
Methods
Participants 1138 participants were recruited through
Amazon Mechanical Turk. Participants were excluded from
the experiment if they did not complete the pre-experiment
arithmetic task and they did not contribute words in the
main experiment. Sixteen participants were removed from
the collaborative experiments for a total of 561 participants.
Nominal groups were matched; thus 561 participants participated in the nominal experiments. The average (± SD)
number of participants in collaborative experiments was 15.2

405

Figure 1: Effect of group size on collaborative inhibition. (a) Model results, reproduced from Luhmann and Rajaram (2015).
(b) Behavioral results. The mean proportion of words (± SE) recalled in the nominal (red) and collaborative (blue) conditions
are shown; collaborative inhibition (yellow) is the subtraction of these two values. Note that the horizontal axis is logarithmic.
ceiling effects.
Overall, using a between-participants two-way unbalanced
ANOVA , we surprisingly failed to observe a main effect of recall method (F(1,246) = 2.03, p = 0.16, η2 = .0045): nominal
and collaborative groups did not recall significantly different
numbers of words when results from all groups were combined (Figure 1b). We did observe the expected main effect
of group size, F(4,246) = 49.08, p < 0.0001, η2 = .44, in that
larger group sizes increased word recall. There was no interaction effect between recall method and group size (F(4,246)
= 1.15, p = 0.33, η2 = .010).
Contrary to the model predictions from Luhmann and Rajaram (2015), the collaborative inhibition effect became less
strong at group sizes greater than 3. This observation motivates the use of large-scale studies and further experiments
testing whether the retrieval disruption and related hypotheses
are enough to explain these results, or whether new models of
human collaborative recall are necessary.

48 groups of 2 were analyzed; 32 groups of 3 were analyzed;
24 groups of 4 were analyzed, and 12 groups of 8 and 16 were
analyzed. This was a 2×5 design, crossing recall method
by group size. In the nominal recall condition, participants
recalled words alone, and their recall lists (with redundant
words removed) were added together according to the appropriate group size. In the collaborative recall condition,
groups of participants were placed in chatrooms and recalled
together. Recalled words that had not been on the original
lists were marked as incorrect and not included.

Results
The collaborative inhibition effect is most reliably observed
in triads (Rajaram & Pereira-Pasarin, 2010), and we replicated this effect in our behavioral data at group size 3: t(62)
= 2.34, p = 0.02, d = .60, independent 2-sample t-test. (α =
.05 for all planned comparisons to follow. Unlike previous
studies, we investigate the collaborative inhibition effect at
multiple group sizes. Had we run separate studies, we would
have used α = .05, justifying its use here.) Collaborative inhibition in the literature is frequently but not always observed
in pairs (Rajaram & Pereira-Pasarin, 2010), but we did not
observe this effect in this group size (t(94) = 0.78, p = 0.44,
d = .16). In the two studies known to the authors examining
tetrads (Thorley & Dewhurst, 2007; Basden et al., 2000), a
collaborative inhibition effect was observed, but we did not
observe this effect at group size of 4 (t(46) = -0.42, p = 0.67,
d = .13).
Given previous results at group sizes of 2, 3, and 4, it is
reasonable to extrapolate and hypothesize that the trend of
collaborative inhibition may be expected to continue or even
widen at larger group sizes (Luhmann & Rajaram, 2015). Intriguingly, this was not the pattern of results observed: participants did not show a collaborative inhibition effect at group
size of 4, and continued to not show a collaborative inhibition
effect at group size of 8 (t(22) = 0.25, p = 0.80, d = .11), contrary to model predictions. A collaborative inhibition effect
did reoccur at group size 16 (t(22) = 2.17, p = 0.04, d = .93),
but variance for the nominal group is likely decreased due to

Experiment 2: Networks
While people occasionally come together to work in shortterm groups, we often function in long-lasting social networks, communicating occasionally with far-flung friends.
These networks are complex and can spread information at a
prodigious rate: a secret you tell a close friend one day might
be known by the whole community the next. In Experiment
2, we sought to investigate how people share and generate
information when communicating across complex networks.

Methods
Participants After removing inattentive participants, 383
participants were sorted into one of 12 karate club networks;
the mean number of participants per network was 31.9 ± 1.4
(SD). 390 participants were sorted into 12 different smallworld networks; the mean number of participants per network was 32.5 ± 0.7. Removing participants changed the
structure of the networks, and path lengths increased accordingly. 81 participants repeated the network experiments more
than once (12.7% of participants), and 27.8% of the data was

406

Figure 2: Similarity of agents within networks. (a) Model results, reproduced from Luhmann and Rajaram (2015). (b) Behavioral results. Mean similarity (± SE) across agents is plotted as a function of the minimum distance between each agent node.
Participants were arranged in karate club networks (red) or small-world networks (yellow).
link an agent node to another. If agents were connected and
could directly communicate with each other, they were separated by a hop distance of 1. If the closest path between
agents included one other node, they were separated by a hop
distance of 2. In this study, hyperdyadic spread would be observed if there was a non-zero similarity between agents at a
hop distance of 2 or greater.
Though modeling predictions suggest agents will show hyperdyadic spread, participants who did not interact (participants separated by more than 1 hop) did not show evidence
of hyperdyadic spread. We may have expected agents with
shared neighbors to be similar, analogous to the spread of
smoking habits (Christakis & Fowler, 2009). However, habits
develop over long time periods and are perhaps more transmissible than individual words, especially in social networks
crafted from personal relationships. The advantage of using
simplistic stimuli like wordlists is that if effective, we gain
access to a reductionist, explainable system for investigation:
in this case how memory representations are related. To this
end, perhaps if semantically related words had been selected
(rather than an unrelated wordlist presented in random order),
we would have observed hyperdyadic spread in a new model
system. This result highlights the effectiveness of iterating on
model-based predictions and behavioral comparison.

generated by these participants. Participants participated an
average of 1.21 times. The mean proportion of repeaters in
the karate club experiments was 0.23 ± 0.10 (SD) and in the
smallworld experiments was 0.32 ± 0.11. The participants
who repeated the network experiments did not improve in the
task: the correlation between number of repetitions and words
recalled was r = -0.18 (159 data points).
Small-world networks were randomly generated for each
experiment. The average time (± SD) between presentation
of a wordlist to the first participant compared to the last participant was as follows: 6.9 ± 7.4 secs for the karate networks
and 3.3 ± 1.2 secs for the small-world networks.
Procedure To compare our results with model predictions,
we sought to replicate the model’s paradigm as closely as
possible with human participants. Each participant was assigned as a node in a graph with the option to communicate
only with individual neighbors, where “neighbor” is defined
as nodes participants were directly connected to. Every time
a participant generated a word, their word was shared with a
randomly chosen neighbor, rather than broadcast to the entire
group as in Experiment 1. Networks were generated as described in the model, except that 34 agents were included in
the small-world network, to match the karate club numbers.

Results

Network Structure We next asked whether choice of network affects agent-pair similarity. In this case the model predictions closely align with behavioral results at a distance of 1
hop, though at greater distances the behavioral results exhibit
unpredicted non-monotonicities. Specifically, at a distance of
1 hop, participants in small-world networks were more similar than in karate club networks (t(22) = -6.24, p < 0.0001, d
= 2.66, independent t-test), likely due to the increased local
connections in small-world networks compared to the karate
club network. Behavior at hop distances greater than 1 exhibited non-monotonicity: networks did not affect agent similarity (2 hops: t(22) = -2.42, p = 0.024, d = 1.03; 3 hops: t(22)
= -1.17, p = 0.26, d = .50; 4 hops: t(22) = -0.84, p = 0.41, d

Hyperdyadic Spread We first asked whether participants
would show evidence of hyperdyadic spread. Luhmann and
Rajaram (2015) computed agent similarity by comparing
their agents’ activation vectors A, but in the non-modeling
world we were restricted to externally observable correlates
of participants’ representations. Thus, we computed the absolute value of correlations for the list of words that participants
recalled in the task as our measure of hyperdyadic spread.
Using recalled lists of words, we calculated the similarity
between every two agents, and sorted the correlations based
on agents’ proximity in the network. Specifically, we used
“hops” to describe how many connections were necessary to

407

= .36; 5 hops: t(22) = 1.45, p = 0.16, d = .62; 6 hops: t(12)
= 1.04, p = 0.49, d = 1.45; α = .008 to account for multiple
comparisons).
Accordingly, the behavioral results did not show a main
effect of network type across hop distance 1-6 (F(1,122) =
1.44, p = 0.23, η2 = 0.0014, between-participants 2-way unbalanced ANOVA), indicating that overall similarity between
agents in karate club networks compared to small-world networks was not significantly different across all hop distances
(Figure 2b). We observed an expected main effect of hop distance (F(5,122) = 163.86, p < 0.0001, η2 = 0.81), describing
that agents were less similar when they were further apart.
There was an interaction effect between recall method and
hop distance (F(5,122) = 15.01, p < 0.0001, η2 = 0.075), describing the non-uniform decrease in agent similarity as hop
distance increased. In sum, though behavioral results failed
to show hyperdyadic spread, similarity between directly interacting agents was dependent on the network structure.

failure to observe hyperdyadic spread could perhaps be improved if semantically related wordlists were used or if a
more sensitive measure than “words recalled” were used as
the comparison metric. Moreover, if the behavioral task had
been structured such that agents could re-submit words that
their neighbors had submitted to other neighbors, we likely
would have observed greater spread: future work will have
to determine which paradigm structures will best inform our
understanding of collaborative recall.
The unexpected results from these studies, in extrapolation
to larger group sizes and in network structure, motivate and
can inform future models describing the mechanisms underlying memory representations and collaborative interaction.

General Discussion

Basden, B., Basden, D., Bryner, S., & Thomas, R. (1997). A comparison of group and individual remembering: does collaboration
disrupt retrieval strategies? Journal of Experimental Psychology:
Learning, Memory, and Cognition, 23(5), 1176.
Basden, B., Basden, D., & Henry, S. (2000). Costs and benefits of
collaborative remembering. Applied Cognitive Psychology, 14(6),
497–507.
Choi, H.-Y., Blumen, H., Congleton, A., & Rajaram, S. (2014). The
role of group configuration in the social transmission of memory:
evidence from identical and reconfigured groups. Journal of Cognitive Psychology, 26(1), 65–80.
Christakis, N. & Fowler, J. (2009). Connected: the surprising power
of our social networks and how they shape our lives. Little,
Brown.
Finlay, F., Hitch, G., & Meudell, P. (2000). Mutual inhibition in collaborative recall: evidence for a retrieval-based account. Journal
of Experimental Psychology: Learning, Memory, and Cognition,
26(6), 1556.
Hirst, W. & Echterhoff, G. (2012). Remembering in conversations:
the social sharing and reshaping of memories. Psychology, 63(1),
55.
Luhmann, C. & Rajaram, S. (2015). Memory transmission in small
groups and large networks an agent-based model. Psychological
Science, 26, 1909–1917.
Meade, M., Nokes, T., & Morrow, D. (2009). Expertise promotes
facilitation on a collaborative memory task. Memory, 17(1), 39–
48.
Overschelde, J. V., Rawson, K., & Dunlosky, J. (2004). Category
norms: an updated and expanded version of the norms. Journal of
Memory and Language, 50(3), 289–335.
Rajaram, S. & Pereira-Pasarin, L. (2010). Collaborative memory:
cognitive research and theory. Perspectives on psychological science, 5(6), 649–663.
Thorley, C. & Dewhurst, S. (2007). Collaborative false recall in the
drm procedure: effects of group size and group pressure. European Journal of Cognitive Psychology, 19(6), 867–881.
Travers, J. & Milgram, S. (1969). An experimental study of the small
world problem. Sociometry, 425–443.
Watts, D. & Strogatz, S. (1998). Collective dynamics of ‘smallworld’ networks. Nature, 393(6684), 440–442.
Wegner, D., Erber, R., & Raymond, P. (1991). Transactive memory
in close relationships. Journal of personality and social psychology, 61(6), 923.
Yamashiro, J. & Hirst, W. (2014). Mnemonic convergence in a social
network: collective memory and extended influence. Journal of
Applied Research in Memory and Cognition, 3(4), 272–279.
Zachary, W. (1977). An information flow model for conflict and fission in small groups. Journal of anthropological research, 452–
473.

Acknowledgments. This work was funded in part by NSF grant
1456709 to T.L.G., DARPA Cooperative Agreement D17AC00004
to T.L.G and J.W.S., and N.I.H. U.C. Berkeley Neuroscience Training Program Grant to M.A.G.

References

In an increasingly interconnected world, understanding how
our memories are impacted by interacting with others will
influence how we organize ourselves, think and remember.
In two studies, we examined collaborative memory: how remembering words in groups changes performance compared
to recalling alone. We investigated collaborative memory in
small and large groups and across network structures, comparing empirical results to the agent-based model predictions
developed by Luhmann and Rajaram (2015).
We first replicated the collaborative inhibition effect in triads, the most reliable group size in exhibiting this effect. We
then observed that in real participants, collaborative inhibition does not uniformly persevere at larger group sizes, despite what was suggested from small-scale studies (Luhmann
& Rajaram, 2015). One suggestion for why this could be
is that factors outside of retrieval disruption affected participants. For example, post-experiment questionnaires indicated
that in large groups where participants raced to submit nonrepeated words, some participants felt competitive pressure
rather than the cooperation evident in smaller groups. While
this issue might have been reduced by using a turn-taking
structure rather than free recall, waiting for each participant in
a large group to take a turn would introduce a new set of problems. Future models of collaborative memory should incorporate the intrinsic difficulties of organizing large groups of
people, especially as people perhaps develop different strategies and algorithms to cope. To this end, large-scale quantitative work would be well complemented by fine-grained analysis of individual differences in strategies, and closer study of
the interactions between individual cognition and the medium
of interaction.
Model predictions suggested that the collaborative memory paradigm would be a good candidate for examining hyperdyadic spread, but empirically only participants who had
directly interacted showed increased similarity. However, this

408

