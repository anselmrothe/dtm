Cake or Hat? Words Change How Young Children Process Visual Objects
Catarina Vales (cvales@andrew.cmu.edu)
Carnegie Mellon University, Department of Psychology, 5000 Forbes Avenue
Pittsburgh, PA 15214 USA

Linda B. Smith (smith4@indiana.edu)

Department of Psychological and Brain Sciences, 1101 E 10th St
Bloomington, IN 47405 USA
Abstract
A large literature shows that language influences cognition.
Yet, we know very little about when and how linguistic
influences on cognition become important in development.
Here we test the proposal that one pathway by which
language affects cognition is by activating category
information which influences visual processing, and that this
influence starts early. Across two experiments, we show that
category information affects visual processing and that words
can activate category information in young children.
Keywords: language; attention; cognitive development;
vision.

Introduction
A large literature has documented that linguistic information
changes other cognitive processes. Evidence for this comes
from laboratory tasks in which people perform differently if
they experience the same event associated with different
kinds of linguistic information (Feist & Gentner, 2007;
Loftus & Palmer, 1974) or associated with linguistic
information vs. information presented in another modality
(Lupyan & Spivey, 2010; Lupyan & Thompson-Schill,
2012), and from cross-linguistic research that shows
influences of language on presumably non-linguistic
processes (Fausey & Boroditsky, 2011; Levinson &
Haviland, 1994). Taken together, these results show that
language – and words, in particular – changes how adults
perform on a wide variety of tasks, and that these cognitive
processes are permeable to linguistic information.
Despite this wealth of evidence, we know very little about
when and how linguistic influences on cognition become
important in development. Understanding the development
of linguistic effects on cognition is essential to understand
the development of human cognition and the nature of
individual differences in cognitive abilities – differences
that start early and have downstream consequences into later
development (Morgan, et al., 2015; Stanovich, 1986). One
possibility is that language influences cognition by
activating information about the objects or events to which
it refers, and this information changes how visual
information is processed. This hypothesis is plausible for
three reasons. First, there is evidence supporting the link
between language and visual processing. For example,
adults listening to spoken sentences look at possible visual
referents even when the visual array is irrelevant to the task
(see Huettig, Rommers & Meyer, 2011), and when adults

hear a word (e.g. “snake”) they are likely to look at objects
that share aspects with the referent of the word (e.g. a rope,
similar shape, Huettig & Altmann, 2007). Similarly, adults’
ability to detect a visual item is boosted by labeling the item
(Lupyan & Spivey, 2008), and children’s ability to find a
target in a cluttered display is boosted by hearing the spoken
name of the target object (Vales & Smith, 2015).
Second, word learning and object recognition are two
related developmental achievements. Children’s ability to
identify visually degraded objects (Pereira & Smith, 2009),
to attend to the configuration among the parts of a novel
object (Augustine, et al., 2011), and to recognize sparse
versions of known object categories (Smith, 2003), all are
positively related to the number of words a child knows.
Object recognition continues to be coordinated with word
comprehension into adulthood (Huettig et al., 2011).
Third, there is evidence suggesting that words activate
knowledge about the categories to which they refer. Words
– object names in particular – do not refer to a specific item
but rather to more abstract knowledge. Empirical results
have shown that, relative to other cues (e.g. environmental
sounds), words activate more decontextualized, categorical
knowledge (Edmiston & Lupyan, 2015; Lupyan, 2008).
Taken together, this evidence supports our proposal that
one pathway by which language affects human cognition is
by activating category information which then influences
visual processing, and that this pathway likely starts in early
childhood. To directly test this proposal, in Experiment 1
we asked whether visual processing can be influenced by
visual category information, and in Experiment 2 we
examined whether category information activated by words
can also influence visual processing. We tested 3-year-old
children, who know several hundreds of object names and
are at the start of the long developmental course in visual
object recognition and in language development.

Rationale for the experiments
A large literature on categorical perception suggests that
categorical information activated through visual means can
change how adults process visual stimuli (Beale & Keil,
1995; Daoutis, Pilling & Davies, 2006; Goldstone, 1995;
Goldstone, Lippa & Shiffrin, 2001; Livingston, Andrews &
Harnad, 1998). By hypothesis, having learned that items
belong to the same category changes in-task perceived
similarity, making within-category discriminations harder
than between-category discriminations. This idea that

1236

within-category comparisons are more difficult than
between-category comparisons has been conceptually
replicated with multiple kinds of tasks and stimuli (Jonides
& Gleitman, 1972; MacKain, Best & Strange, 1981; Newell
& Bülthoff, 2002), including some with infants and children
(Eimas, Siqueland, Jusczyk & Vigorito, 1971; Jusczyk,
Rosner, Cutting, Foard & Smith, 1977; Massaro, 1984).
To test if categorical information influences visual
processing in young children, the present experiments tested
children’s ability to find a target in a cluttered array. The
visual arrays were composed of items of the same category
as the target (Within-Category search) or items of a different
category than the target (Between-Category search). In
Experiment 1, the category information was instantiated via
visual information, and in Experiment 2, the category
information was instantiated via linguistic information. In
both experiments, we used two categories that share visual
similarity but minimal conceptual similarity, and that
children are likely to be familiar with: cakes and hats.

each trial, children were asked to select the picture that
matched the heard word (e.g. “Where is the cake?”). Each
child was asked to recognize all the items in the stimulus set
twice, with target category (hat vs. cake) blocked, order of
block presentation counterbalanced across children, and
items presented in random order. On average, children
selected the correct item on 81% of the trials (SD=0.22).
No differences in accuracy were found across the two
category of items (t(11)=1.11, p=0.29), or time taken to
respond to cakes vs. hats items (t(11)=1.92, p=0.08).
A.

B.
hat

cake

ambiguous

Within-Category Search:

Between-Category Search:

pair 1

pair 2

pair 3

pair 4

Experiment 1
If categorical information instantiated by visual information
changes children’s ability to visually process a visual array,
then searching for a target amidst items of the same visual
category should be more difficult than searching for that
target amidst items of a distinct visual category.

Methods
Participants. Thirty-two children (15 females, Mage=36
months, SD=1.92) were randomly assigned to either the
Within- or the Between-Category condition. Children had
no developmental disorders, and English was the main or
only language spoken by all families. Two additional
children were recruited but not included due to experimenter
error and being unable to follow task instructions during the
familiarization phase. Parental consent was obtained for all
participants, and all children received a toy for participating.
Apparatus and Stimuli. Stimuli were presented on a 17”
touchscreen monitor. E-Prime (PST, Pittsburgh, PA) was
used to present the stimuli and to record participants’
responses. The stimuli were placed in 16 possible locations.
The stimulus set is depicted in Figure 1A; four hats and four
cakes were selected in pairs and recolored in red scale, such
that a hat and a cake in the same pair were similar to each
other in color appearance, overall shape, and details (e.g. in
pair 1, both items have stripes and a smaller component at
the top). The Within- vs. Between-Category manipulation
was realized by changing target/distractor assignments; for
instance, for pair 2, the Within-Category search array was
composed of hat 2 as the target and hats 1, 3, and 4 as
distractors; for the Between-Category search, cake 2 served
as the target amidst the same (i.e. 1, 3, and 4) hat distractors.
To ensure that young children could recognize the items
used, 12 children who did not participate in the main
experiments (7 females, Mage=36 months, SD=2.67) were
tested in a 4-alternative forced choice recognition task; on

Figure 1, A: Full stimulus set. The hat and cake stimuli
were used as targets and distractors in Experiment 1. The
ambiguous items were used as targets in Experiment 2.
B: Experiment 1, Trial structure.
Because the visual search task requires participants to
discriminate the items in the search array from each other, 8
additional children (2 females, Mage=36 months, SD=1.04)
were tested in an immediate match-to-sample task that
probed their ability to discriminate pairs of stimuli. On each
trial, children were presented with a sample object at the top
center of the screen and then asked to indicate which of two
options at the bottom matched the sample; if children could
discriminate the two stimulus pictures, then they should be
able to correctly select the option that matched the sample.
All possible combinations of items that would be presented
as targets and distractors in the visual search were tested.
Each child was asked to discriminate one hat and one cake
from the remaining items; this was done so that, for each
child, a foil never became a target and vice-versa. The target
category (hat vs. cake) was blocked, order of block
presentation was counterbalanced across children, and items
were presented in random order. Each child was tested on a
given contrast (e.g. hat 1 vs. hat 2) twice. On average,
children selected the correct option on 89% of the trials
(SD=0.19). No differences were found in children’s ability
to discriminate Between- vs. Within-category items
(t(7)=1.07, p=0.32) or time taken to respond to cakes vs.
hats items (t(7)=0.41, p=0.69).
Design and Procedure. Each trial started with a “fixation”
slide that encouraged children to rest their hands on the
table. The experimenter made sure the child was looking at
the screen before displaying a preview of the target. After
1s, the search array was automatically displayed and the
child was asked to find the target picture and touch it; the
trial ended once a manual response was detected (see Figure

1237

1B). Children had up to 15 secs to make a response, and
were encouraged to find the picture as fast as possible.
Across test trials, the target was displayed equally often on
the left and right side of the screen. Prior to the test phase,
children were familiarized with using the touch screen and
with the idea of searching for the object that matched the
visual preview as fast as possible. Each child was assigned
to one target, and searched for that target for 24 trials. None
of the objects were labeled. The experimenter gave general
encouragement (e.g. “thanks for your help finding the
pictures”) but no feedback was provided. Children received
stickers to maintain their interest in the task.

A. Experiment 1

Figure 2, Mean proportion of correct responses per
Reaction Time quantiles. Dashed line: Between-Category,
Solid line: Within-Category.

Results and Discussion
Initial inspection of the data suggested that participants
were, on average, both faster and more accurate in the
Between-Category condition than in the Within-Category
condition. Traditional analysis of variance would require
analyzing response time and accuracy separately, which
implicitly assumes that these two variables are independent
(e.g. Davidson & Martin, 2013). Instead, we analyzed RT
and accuracy together by comparing the relationship
between RT and accuracy across the two conditions. Figure
2A depicts this relation and shows that the two conditions
differ in how time taken to respond (plotted as quantiles)
influences the likelihood of correctly identifying the target;
accuracy in the Between-Category condition was overall
higher and less influenced by response time. A generalized
linear mixed effects analysis was performed using the
geepack package (Højsgaard, Halekoh & Yan, 2006) in the
R environment. The model was fit with a logit link function,
a binomial variance function, a scale parameter fixed at 1,
and an independent correlation structure. The variables
Condition (Between-Category vs. Within-Category) and RT
(as a continuous variable) were included as fixed effects
with the interaction term, and participant was included as a
random effect; RT was centered to decrease the differences
in the scales of the model parameters. Odds Ratios were
calculated by exponentiating the model estimates.
The model showed that Condition (Odds Ratio, OR=0.2,
p<0.001) and the interaction between condition and RT
(OR=0.43, p<0.05) were significant predictors of accuracy.
RT was marginally predictive of accuracy, OR=1.8, p=0.08.
This suggests that processing the visual information in the
within-category condition is challenging, and when children
are asked to find a target amidst distractors of the same
visual category they either cannot maintain the target active
for more than a few seconds, or they disengage with the task
if they fail to find the target within a few seconds. Notice
that visual category information affected visual processing
even though children could discriminate pairwise
presentations of within- and between-category items equally
well in the calibration study, even though children searched
for the same visual target across all trials and thus should be
able to remember the particular visual target, and even
though the visual properties of the items were equated as
best as possible across the two conditions.

B. Experiment 2

These results show that category information presented
through visual means influences visual processing in young
children; this is, to the best of our knowledge, the first
demonstration that visual categories directly influence
visual processing in young children. This result adds to past
research showing that infants, children, and adults (e.g.
Eimas, Siqueland, Jusczyk & Vigorito, 1971; Goldstone,
Lippa & Shiffrin, 2001; Massaro, 1984) are sensitive to
category information, showing that category information
matters for how children visually process a scene. When
children encoded, for example, a hat target and saw the
other hats in the within-category search array, that samecategory information seems to have disrupted their ability to
find the target hat. In sum, Experiment 1 shows that
categorical information perceived in a visual scene can
directly influence visual processing, as predicted by our
proposal. In Experiment 2 we test the hypothesis that words,
through activating categorical information, should also
change the perceived target-distractor similarity, and
therefore change visual processing.

Experiment 2
The goal of Experiment 2 was to test the hypothesis that
hearing the spoken name of an object activates information
about that object’s category, which influences visual
processing. This hypothesis predicts that, for example, if an
ambiguous target is labeled as a hat and is placed amidst
other hat distractors, it should be more difficult to find than
when that target is labeled as a cake and is placed amidst the
same hat distractors. In other words, when presented with
the same visual information in the search array, children
should be better able to find a target if it was labeled as a
category other than the distractors.

Methods
Participants. Thirty-two children (18 females, Mage=36
months, SD=2.12) were randomly assigned to either the
Within-Category or the Between-Category condition. These
children did not participate in Experiment 1. Four additional
children were recruited but not included due to refusal to
participate (N=3) and failure to follow task instructions.
Stimuli and Procedure. Four ambiguous items were
created by blending together the two items (cake and hat) of

1238

each pair (see Figure 7, rightmost column); the ambiguous
items included aspects of both the cake and the hat of the
pair (e.g. the frosting and the ribbon), and were edited to
look like a plausible visual object (e.g. smooth surface, even
coloring, even edges). The Within- vs. Between-Category
manipulation was realized by changing how the target
object was labeled during the visual preview. For instance,
in the Within-Category condition, children would preview
the ambiguous item #2 and hear it labeled as hat, and then
be asked to find it amidst hats 1, 3, and 4. In the BetweenCategory condition, children would preview the same
ambiguous item #2, but hear it labeled as cake and then be
asked to find it amidst hats 1, 3, and 4. Notice that the
visual information presented in the preview and in the
search array is exactly the same in both conditions – the
difference between the two conditions is whether the
ambiguous target is labeled a member of the same vs. a
different category as the distractors while it is previewed
prior to search. All other aspects of the procedure for the
visual search were the same as Experiment 1.
To ensure that the ambiguous stimulus pictures were
equally likely to be recognized as hats and cakes, 8
additional children (6 females, Mage= 36 months, SD=2.62)
were tested in a 4-alternative forced choice recognition task
similar to the one used in Experiment 1. Each child was
tested with all the ambiguous items, two of them as “cake”
and the other two as “hat”; across children, each ambiguous
item was equally likely to be tested as “hat” and as “cake”.
The target category (hat vs. cake) was blocked for each
child, the order of block presentation was counterbalanced
across children, and the presentation order of the items was
randomized within each block. On average, children
selected the ambiguous items as “cake” on 81% (SD=0.40)
of the trials, and as “hat” on 84% (SD=0.35) of the trials
(paired t(7)=0.16, p=0.88) – suggesting that the ambiguous
items were equally likely to be recognized as hats and cakes.
Children took a similar amount of time to respond to cakes
vs. hats trials (t(7)=0.45, p=0.67). In addition, to ensure that
children were not selecting the ambiguous items merely
because they looked more unfamiliar or novel than any of
the foils, children were presented with 4 “catch” trials (2
after each block) where they were asked to find a balloon;
on these “catch” trials, one of the foils was a novel-shaped
object and the other two foils were known objects. Children
correctly identified the balloon on 91% (SD=0.18) of the
trials, suggesting that they were not relying on novelty to
respond in this task.

Results and Discussion
Similar to Experiment 1, initial data inspection suggested
that participants were both faster and more accurate in the
Between-Category condition than in the Within-Category
condition. Figure 2B shows that the relationship between
RT and accuracy is the same across conditions, in that
participants’ accuracy does not depend on time taken to
respond, but participants in the Between-Category condition
were more accurate than participants in the Within-Category

condition. A generalized linear mixed effects model (fit in
the same way as in Experiment 1) showed that Condition
was the only significant predictor of accuracy, OR= 0.12,
p<0.001. Time taken to respond [OR=1.1, p=0.8] and the
interaction between Condition and RT [OR=0.8, p=0.4]
were not predictive of accuracy. This suggests that hearing
the name of an object activates visual information about that
objects’ category, which affects visual processing. When
presented with the same visual information, children’s
ability to find a visual target in a cluttered array depended
on how that visual target had been labeled while it was
being previewed. This is a robust demonstration of the
effect of language on visual processing – encoding an
ambiguous object as a hat or as a cake changed children’s
ability to find that object amidst the same set of distractors.

General Discussion
The experiments presented here support our proposal that
language affects human cognition by activating category
information, which in turn influences visual processing. In
Experiment 1, children’s ability to find a visual target was
hindered by the presence of same-category distractors; this
influence of categorical information on visual processing
was instantiated through visual means. Experiment 2
extended those results by showing that words can also
activate categorical information which influences visual
processing. Together, these results show that visual
processing is influenced by categorical information, and that
heard words can instantiate categorical information.
How does categorical information – through visual or
linguistic means – influence visual processing? Past
research on categorical perception suggests that categorical
information changes the perceived similarity among the
items, with items that belong to the same category being
perceived as more similar to one another than items that
belong to different categories (Goldstone & Hendrickson,
2010; see also Sloutsky & Fisher, 2004 for a related
developmental model). This perceived similarity could
influence visual processing in multiple ways. One
possibility is that perceiving an item as a member of the
same category as the distractors – and consequently as more
similar to the distractors – lowers the threshold for
accepting an item in the array as the target (e.g. Elman,
1979). Another possibility is that perceiving all the items as
items of the same category influences children’s ability to
bind all the features of the target object together (Treisman
& Schmidt, 1982); there is evidence that object feature
binding is still developing in late childhood (Lorsbach &
Reimer, 2005) and that children are prone to making
conjunction errors (Dessalegn & Landau, 2008). Through
increasing the perceived similarity between the target and
the distractors, category information might lead children to
incorrectly bind features of the target and the distractors,
increasing the likelihood of making an incorrect selection.
Interestingly, language has been suggested to play a role in
the binding of visual features in young children (Dessalegn

1239

& Landau, 2008; 2013), perhaps through the activation of
categorical information.
These are empirically testable possibilities that merit
future research. But notwithstanding the specific process by
which children’s ability to find a target was impaired by the
presence of distractor items of the same category as the
target, the point is that it was impaired – both when the
categorical information was presented through visual means
(Experiment 1) and through language (Experiment 2). The
current results support the idea that words influence visual
processing by highlighting information about the objects’
category. This idea has important consequences to
conceptualize the pathway by which words change visual
object processing in young children, proposing that words
activate categorical information that may change how
objects are perceived and processed. Future research should
examine what specific aspects of the objects’ category are
being activated when a word is heard. The ability to
recognize the components of an object, and how those
components relate to each other, is one critical aspect of
visual object recognition (Tarr & Bülthoff, 1998), and the
developmental literature on visual object recognition
suggests a long and protracted development on the ability to
use configural information (Augustine et al., 2011: Jüttner et
al., 2013). Given the strong links between word learning and
visual object recognition in early childhood (Augustine, et
al., 2011; Pereira & Smith, 2009; Smith, 2003), it is possible
that language comes to change what aspects of the objects
children attend to.
These results also highlight the importance of
understanding the nature of visual processing in young
children. Contemporary accounts of visual processing in
adults propose a reciprocal interaction between the shortterm encoding of visual information and long-term visual
representations (e.g. Brady, Konkle, & Alvarez, 2011).
Research across levels of analysis suggest that both
processes might be permeable to top-down influences (e.g.
Hemmer & Steyvers, 2009; Olsson & Poom, 2005), but we
have very little understanding of how these develop. That is,
what information do children use to visually process objects
in the moment, what do those visual representations include,
and what factors influence the long-term encoding and
fidelity of those visual representations? All these processes
are likely to mature and improve with age (e.g. Burnett
Heyes et al., 2012; Simmering & Perone, 2012) and might
be weak in children (Riggs, McTaggart, Simpson &
Freeman, 2006; Zhang, Shen, Tang, Zhao & Gao, 2013).
Importantly, visual processing and visual working memory
have been shown to be immature in children with language
impairments (Collisson et al., 2015), further underscoring
the importance of understanding the development of these
processes.
In sum, we documented that words influence visual
processing, likely by highlighting information about the
objects’ category. This fits with our proposal that one
pathway by which language influences human cognition is
by activating category information, which influences visual

processing, and that this pathway likely starts in early
childhood.

Acknowledgments
The authors thank Brianna Le, Lizzie Hart, and Adriana
Valtierra for their help with stimuli creation, recruitment,
and data collection; and the parents and children who
participated in these studies. This work was supported by a
Graduate Fellowship from the Portuguese Foundation for
Science and Technology (SFRH/BD/68553/2010) awarded
to CV and a grant from the National Institute of Child
Health and Development (HD28675) awarded to LBS.

References
Augustine, E., Smith, L. B., & Jones, S. S. (2011). Parts and
relations in young children's shape-based object
recognition. Journal of Cognition and Development, 12(4),
556-572.
Beale J.M., & Keil F.C. (1995) Categorical effects in the
perception of faces. Cognition 57: 217–39.
Brady, T. F., Konkle, T., & Alvarez, G. A. (2011). A review
of visual memory capacity: Beyond individual items and
toward structured representations. Journal of Vision, 11(5),
4.
Burnett Heyes, S., Zokaei, N., van der Staaij, I., Bays, P.
M., & Husain, M. (2012). Development of visual working
memory precision in childhood. Developmental Science,
15(4), 528-539.
Collisson, B. A., Grela, B., Spaulding, T., Rueckl, J. G., &
Magnuson, J. S. (2015). Individual differences in the shape
bias in preschool children with specific language
impairment and typical language development: theoretical
and clinical implications. Developmental Science, 18(3),
373-388.
Davidson, D. J., & Martin, A. E. (2013). Modeling accuracy
as a function of response time with the generalized linear
mixed effects model. Acta Psychologica, 144(1), 83-96.
Daoutis, C. A., Pilling, M., & Davies, I. R. (2006).
Categorical effects in visual search for colour. Visual
Cognition, 14(2), 217-240.
Dessalegn, B., & Landau, B. (2008). More than meets the
eye: The role of language in binding and maintaining
feature conjunctions. Psychological Science, 19(2), 189195.
Dessalegn, B., & Landau, B. (2013). Interaction between
language and vision: It’s momentary, abstract, and it
develops. Cognition, 127(3), 331-344.
Edmiston, P., & Lupyan, G. (2015). What makes words
special? Words as unmotivated cues. Cognition, 143, 93100.
Eimas, P. D., Siqueland, E. R., Jusczyk, P., & Vigorito, J.
(1971). Speech perception in infants. Science, 171(3968),
303-306.
Elman, J. L. (1979). Perceptual origins of the phoneme
boundary effect and selective adaptation to speech: A
signal detection theory analysis. The Journal of the
Acoustical Society of America, 65(1), 190-207.

1240

Fausey, C. M., & Boroditsky, L. (2011). Who dunnit?
Cross-linguistic differences in eye-witness memory.
Psychonomic bulletin & review, 18(1), 150-157.
Feist, M. I., & Gentner, D. (2007). Spatial language
influences memory for spatial scenes. Memory &
Cognition, 35(2), 283-296.
Goldstone, R. L. (1995). Effects of categorization on color
perception. Psychological Science, 298-304.
Goldstone, R. L., & Hendrickson, A. T. (2010). Categorical
perception. Wiley Interdisciplinary Reviews: Cognitive
Science, 1(1), 69-78.
Goldstone, R. L., Lippa, Y., & Shiffrin, R. M. (2001).
Altering object representations through category learning.
Cognition, 78(1), 27-43.
Hemmer, P., & Steyvers, M. (2009). Integrating episodic
memories and prior knowledge at multiple levels of
abstraction. Psychonomic Bulletin & Review, 16(1), 80-87.
Højsgaard, S., Halekoh, U. & Yan J. (2006) The R Package
geepack for Generalized Estimating Equations. Journal of
Statistical Software, 15, 2, 1-11
Huettig, F., & Altmann, G.T. (2007). Visual-shape
competition during language-mediated attention is based
on lexical input and not modulated by contextual
appropriateness. Visual Cognition,15(8), 985–1018.
Huettig, F., Rommers, J., & Meyer, A. S. (2011). Using the
visual world paradigm to study language processing: A
review and critical evaluation. Acta Psychologica, 137(2),
151-171.
Jonides, J., & Gleitman, H. (1972). A conceptual category
effect in visual search: O as letter or as digit. Perception &
Psychophysics, 12(6), 457-460.
Jusczyk, P. W., Rosner, B. S., Cutting, J. E., Foard, C. F., &
Smith, L. B. (1977). Categorical perception of nonspeech
sounds by 2-month-old infants. Perception &
Psychophysics, 21(1), 50-54.
Jüttner, M., Wakui, E., Petters, D., Kaur, S. & Davidoff, J.
(2013). Developmental trajectories of part-based and
configural
object
recognition
in
adolescence.
Developmental Psychology 49, 161-176.
Levinson, S. C., & Haviland, J. B. (1994). Introduction:
Spatial conceptualization in Mayan languages. Linguistics,
32(4-5), 613-622.
Livingston, K. R., Andrews, J. K., & Harnad, S. (1998).
Categorical perception effects induced by category
learning. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 24(3), 732.
Loftus, E. F., & Palmer, J. C. (1974). Reconstruction of
automobile destruction: An example of the interaction
between language and memory. Journal of Verbal
Learning and Verbal Behavior, 13(5), 585-589.
Lorsbach, T. C., & Reimer, J. F. (2005). Feature binding in
children and young adults. The Journal of Genetic
Psychology, 166(3), 313-328.
Lupyan, G. (2008). From chair to" chair": A
representational shift account of object labeling effects on
memory. Journal of Experimental Psychology: General,
137(2), 348.

Lupyan, G. & Spivey, M.J. (2008). Ascribing meaning to
unfamiliar items facilitates visual processing. Current
Biology, 18: R410-R412
Lupyan, G. & Spivey, M.J. (2010). Making the invisible
visible: Verbal but not visual cues enhance visual
detection. PLoS One 5(7).
Lupyan, G., & Thompson-Schill, S.L. (2012). The evocative
power of words: Activation of concepts by verbal and
nonverbal means. Journal of Experimental Psychology:
General. 141(1), 170-186.
MacKain, K. S., Best, C. T., & Strange, W. (1981).
Categorical perception of English/r/and/l/by Japanese
bilinguals. Applied Psycholinguistics, 2(04), 369-390.
Massaro, D. W. (1984). Children's perception of visual and
auditory speech. Child Development, 1777-1788.
Morgan, P. L., Farkas, G., Hillemeier, M. M., Hammer, C.
S., & Maczuga, S. (2015). 24-Month-Old children with
larger oral vocabularies display greater academic and
behavioral functioning at kindergarten entry. Child
Development, 86(5), 1351-1370.
Newell, F. N., & Bülthoff, H. H. (2002). Categorical
perception of familiar objects. Cognition, 85(2), 113-143.
Olsson, H., & Poom, L. (2005). Visual memory needs
categories. Proceedings of the National Academy of
Sciences of the United States of America, 102, 8776–8780.
Pereira, A. F., & Smith, L. B. (2009). Developmental
changes in visual object recognition between 18 and 24
months of age. Developmental science, 12(1), 67-80.
Simmering, V. R., & Perone, S. (2012). Working memory
capacity as a dynamic process. Frontiers in Psychology, 3.
Sloutsky, V. M., & Fisher, A. V. (2004). Induction and
categorization in young children: A similarity-based
model. Journal of Experimental Psychology: General,
133(2), 166.
Smith, L. B. (2003). Learning to recognize objects.
Psychological Science, 14(3), 244-250.
Riggs, K. J., McTaggart, J., Simpson, A., & Freeman, R. P.
(2006). Changes in the capacity of visual working memory
in 5-to 10-year-olds. Journal of Experimental Child
Psychology, 95(1), 18-26.
Stanovich, K. E. (1986). Matthew effects in reading: Some
consequences of individual differences in the acquisition
of literacy. Reading Research Quarterly, 360-407.
Tarr, M. J., & Bülthoff, H. H. (1998). Image-based object
recognition in man, monkey and machine. Cognition,
67(1), 1-20.
Treisman, A., & Schmidt, H. (1982). Illusory conjunctions
in the perception of objects. Cognitive Psychology, 14(1),
107-141.
Vales, C., & Smith, L. B. (2015). Words, shape, visual
search and visual working memory in 3-year-old children.
Developmental Science, 18(1), 65-79.
Zhang, Q., Shen, M., Tang, N., Zhao, G., & Gao, Z. (2013).
Object-based encoding in visual working memory: A life
span study. Journal of Vision, 13(10), 11.

1241

