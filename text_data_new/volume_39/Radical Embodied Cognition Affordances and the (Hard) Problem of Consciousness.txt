Radical Embodied Cognition, Affordances, and the (Hard) Problem
of Consciousness
Valerie Gray Hardcastle (VALERIE.HARDCASTLE@uc.edu)
Departments of Philosophy, Psychology, and Psychiatry & Behavioral Neuroscience
Cincinnati, OH 45221 USA
Abstract

Radical Embodied Cognitive Science

Tony Chemero advances the radical thesis that
cognition and consciousness is actually the same
thing. He draws this conclusion from his understanding
of cognition as an extended process. I question this
conclusion because this view expands cognition beyond
being the sort of natural kind to which one can tie
phenomenal experience. Moreover, because cognition has
been radically inflated, despite Chemero’s claim to the
contrary, embodied cognition does not solve any of the
hard problems associated with consciousness.

Most date the recent embodied movement in cognitive
science to the work of Rodney Brooks (1991a, 1991b)
and Francisco Valera, Evan Thompson, and Eleanor
Rosch’s book The Embodied Mind (1991), though of
course J.J. Gibson’s ecological theory is its earliest
contemporary incarnation (Gibson 1962,1966,1979).
This work was intended to be an antidote for
computational views of mind, in which perception,
memory, and thought all become manipulations of
brain-based mental representations.
Proponents of embodied cognition hold agents’
bodies, and often their local environments, are not
only physically relevant to cognition, but are also
causally constitutive. Moreover, cognition is not the
rational and abstract process that computationalists
assume, but instead is dedicated to helping our
bodies move and act upon our environment.
We evolved as a species to take advantage of our
environment, and we do so as we solve so-called
cognitive problems. In many cases, what at first
appears to be a difficult problem to solve using abstract
representations and computations divorced from the
physical world turns out to be much easier to resolve if
we are allowed to consider our bodies and our
environment as cognitive resources. It is easy for a
human to learn to move about on land because
Mother Nature designed our legs for walking on
Earthly terrain (Thelen and Smith 1994). In other
words, instead of using our brain to solve problems,
we manipulate our bodies and our environments to
dissolve them. Moreover, in doing this, we can also
alter our bodies and our environments such that the
problems we need to solve also change. Gathering
food presents a different sort of challenge in a
cultivated field, compared to an unspoiled savannah
rich with bison.
Hence, instead of thinking of the agent and its
environment as two separate entities that occasionally
touch each other, it is better to see them a single,
interacting, system. It follows from this perspective
that cognition is extended into the environment. It also
follows that any mathematical model of this larger
system should describe how it unfolds dynamically
over time, which would require non-linear differential
equations.

Keywords: radical embodied cognition; consciousness;
perception-in-action; the hard problem.

Novel stimuli capture our attention. This well-known
fact forms the basis for several contemporary theories
of theories of mind and brain, including Tony
Chemero’s notion of embodied cognition (Chemero
2009). Chemero holds that noticing unexpected
events is key to understanding the larger cognitive
system of which our brains are one part. He also
believes that expecting some event to occur in the
world is somehow tied to our conscious experiences.
In his book Radical Embodied Cognition (2009; see
also Silberstein and Chemero 2012, 2015) Chemero
(along with Michael Silberstein) advance the radical
thesis that cognition and consciousness is actually the
same thing. He draws this conclusion from his
understanding of cognition as a dynamical, non-linear,
relational, and extended process. I question this
conclusion. Even if, we are the brain-bodyenvironment synergies that Chemero and others claim
we are (e.g., Anderson et al. 2012, Silberstein and
Chemero 2012, Kello and van Orden 2009, Kelso
2009), we will not be able to conclude that
consciousness and cognition are two sides of the
same coin because this view expands cognition
beyond being the sort of natural kind to which one
can tie phenomenal experience. Moreover, contra
Chemero’s claim that “the problem of qualia does not
arise in radical embodied cognitive science” (2009,
Loc 2530/3178), embodied cognition does not solve
any of the
hard problems associated with
consciousness. Nonetheless, some of Chemero’s
views do help us understand some aspects of
conscious experience.

476

What makes Chemero’s views of embodied cognition
radical is that he claims that dynamical systems
theory, which we need to be able to model
cognition,
does
not
presuppose
mental
representations, or indeed any representations at all.
If brains, bodies, and environment form one unified
system, then there is no need for one part of the
system to represent another part of the system for
everything is always and already connected. Perception,
action, and thought itself are all non-representational
and non-computational. Let us accept this view as true
and see how he might explain consciousness using
this understanding of human cognition and action.

identical to a human’s (or a brain’s) physical
interactions without also imagining that thing’s
consciousness, it appears that nothing about any
physical interaction should give rise to phenomenal
experience. And yet, we are conscious, nonetheless.
How can this be? (Leiniz’s answer, like David
Chalmer’s (1995, 1996) more contemporary one, is to
posit that consciousness is a fundamental part of the
ontology of the universe.)
But if computational theories of mind are false, then
this particular problem of consciousness does not
arise. Cognition is a feature of our extended and
embodied system, as is consciousness. By “[refusing]
to
separate
meaningful
cognition
and
phenomenology” (2012, p. 41), Silberstein and
Chemero believe that they have eliminated the so-called
hard problem of consciousness essentially by
definitional fiat. They assert that, “neutral monism
properly conceived really does deflate the hard problem
once and for all” (2015, p. 182).
Can they do this? To answer this question, we
need a more complete picture of what they are
envisioning an extended phenomenological-cognitive
system to be.
Our nervous system has its own spontaneous and
internally generated dynamics, which in turn create
transient
neural
assemblies
comprising
our
sensorimotor capabilities. We are coupled to our
environment via these sensorimotor structures, which
result in changes to both our internal transient neural
assemblies via sensory feedback and in the external
environment via behavioral responses. Over time, we
become attuned to nuances in the extended brain-bodyenvironment
system
that
complements
our
sensorimotor sensitivities and external features; this is
our niche.
What we perceive in our environment via our
sensorimotor structures (and probably other related
neural assemblies) are nothing less than Gibsonian
affordances, relational features of the brain-bodyenvironment system used to guide our actions and
behavior. They are what the environment contains and
what we can do. Silberstein and Chemero claim that the
“set of affordances” we perceive in our world, “just is
the environment as [we] experience it” (2012, p. 43,
italics theirs). Hence, “cognition and conscious
experience can be understood as a single phenomenon”

Conscious Cognitive Systems
Silberstein and Chemero (2012) hold that conscious
experience is “an essential feature of extended brain–
body– environment systems” (p. 36) and that
phenomenology and cognition are “inseparable and
complementary aspects of coupled brain-bodyenvironment systems….Experience is cognition and
cognition is experiential” (pp.40-41). They each “codetermine” the other (p. 41). They get there by
positing that some version of neutral monism must be
true, if the thesis of radical embodied cognition is true
(Silberstein and Chemero 2015). They trace this
metaphysics back to William James, who held that
there was no actual difference between the so-called
objective world out there and the subjective
experience of the world in each of us. “What
represents and what is represented is here numerically
the same” (James 1904, p. 484). Both the subjective
and the objective are defined in opposition to one
another, and both are ways of understanding the
world, which is the “more basic neutral ‘stuff’ of
experience” (Silberstein and Chemero, 2015, p. 186).
Hence, one cannot have cognition, an objective
process, without also having at the same time,
consciousness, the subjective experience.
Computational theories of mind artificially create a
problem for consciousness, for they give the impression
that one can have mental computation without
concomitant conscious thought. We get the problem
of consciousness because we can imagine nonhuman, apparently unconscious, machines instantiating
a computational theory of mind. That is, we can
imagine cognition without consciousness, or so we
think.
This is the hard problem of consciousness, a
challenge that dates back to at least Gottfried Leibniz in
1714:1 because we can imagine a something that is

increased in size, while keeping the same proportions, so
that one might go into it as into a mill. That being so, (we
should, on examining its interior, find only parts which
work one upon another, and never anything by which to
explain a perception. Thus it is in a simple substance, and not
in a compound or in a machine, that perception must be
sought for. Further, nothing but this (namely, perceptions
and their changes) can be found in a simple substance. It
is also in this alone that all the internal activities of simple
substances can consist” (Leibniz 1714, section 17).

“Moreover, it must be confessed that perception and that
which depends upon it are inexplicable on mechanical
grounds, that is to say, by means of figures and motions. And
supposing there were a machine, so constructed as to think,
feel, and have perception, it might be conceived as

1

477

(p. 35). Consciousness “ is inseparable from cognition,
which is the ongoing activity of a nervous system,
body, and niche non-linearly coupled to one another”
(p. 43).
Just as our neural assemblies are not anatomically
hardwired – they are “softly” assembled – so too are
the borders of the brain-body-environment system. How
far and how much we extend into the environment
depend a great deal on what we are trying to do and
what barriers or assistance the environment provides to
us. The entire system itself then is also a soft assembly
whose interaction dynamics determine its structure.
Some call such interaction dominant, softly
assembled, systems “synergies.” A synergy is a set of
structural units that temporarily link together to form
a single cohesive functional system. It is maintained
or changed on the fly as its dynamics and processes
ebb and flow over time (Anderson et al. 2012, Kelso
2009).
We know that we have a synergy when we can
measure pink noise associated with it. Pink noise, or 1/f
noise, refers to a signal in which the power spectrum
density (energy per Hz) is inversely proportional to the
frequency. (It is called pink noise because visible
light with this power spectrum looks pink.) We can
contrast pink noise with white noise, which has equal
energy on every frequency. Pink noise is also a
hallmark of fractal timing and appears to be ubiquitous
in nature, occurring in everything from cosmic
background radiation to flooding patterns of the Nile
River (see also Strogatz 2004 for a popular way into
these phenomena). It is an indication of nested, selfsimilar structures that occur over time. Guy van
Orden and his colleagues (2003) argue that pink
noise signifies just the sort of interaction-dominant,
softly assembled, system we have been discussing as
a model for cognition. (See also Miyazaki et al.
2004.) And with this technical idea in hand, scientists
are now able to manipulate and measure our dynamic
embodiment experimentally.
For example, Chemero and his colleagues devised an
experiment that forces change in our extended
cognitive synergy (Dotov et al., 2010, 2017).
Undergraduates engaged in a simple video game,
using a computer monitor and a mouse. At irregular
intervals during each trial, the connection between the
mouse and the monitor was disrupted. Interestingly,
pink noise is present at the hand- mouse interface
until the disruption. Once the disruption is over and the
connection returns to normal, the pink noise returns.
These measures index changes in the boundary of
the extended cognitive synergy. During the normal
phase of the task, the mouse is part of the system.
During disruption, it is not.
Most important for our purposes, the measures of
pink noise correlate with our conscious experiences.
When we are engaged in the video game, we are

not aware of the hand-mouse interface per se, but
once the connection between mouse and monitor is
altered, then the mouse grabs our attention and we
become aware of it. The point is, we project ourselves
into our environment, and in so doing, we experience
the edges of our extended system. We have long
known that this is the case, but it is only now that
psychologists have been able to develop metrics for
measuring changes in our projections.
The pink noise of our cognitive synergy indexes our
phenomenal experience. I think that this is the best
argument for why the picture Chemero paints might in
fact be true. We notice and pay attention to,
experience, things that do not match our predictions or
expectations. And we experience these things in terms
of what we could do, or how we could act. Our
experiences are about or of the relationship we have
with the world, which is continuously changing and
evolving.
These mixes of brain, body, and environment are
what Gibson called objective-subjective hybrids. And
that fact, Chemero believes, solves the problem of
consciousness. For this is how subjectivity exists in an
objective world–it exists in the on-going relationship
between an agent and the context of its actions. (The
relationship itself is neither subjective nor objective.
This is the neutral substrate that allows us to define
subjectivity and objectivity as two different aspects of
the same “monism.”)

The Hard Problem is Hard
What is wrong with this story? Essentially, it is that
the sort of non-linear coupling that links us with our
environment is found at all sorts of levels of
organization. Without further analysis, we cannot
identify which level corresponds to cognition; hence,
tying consciousness to cognition either means
consciousness exists at multiple levels of organization,
which strikes most people as improbable, or more
work needs to be done to delineate consciousness
cognition from other synergies. If we need to do more
work, then the problem of consciousness remains to be
solved.
To take one example, we find synergies within the
brain itself. These are softly assembled, interactiondominant, nonlinear dynamical systems whose
behavior strongly resembles prototypical cognition,
perception, and action. It is questionable whether these
systems are also conscious.
Neuroscientists are now capable of recording
responses from thousands of neurons simultaneously.
It is becoming clear that neural correlates for things
like memory and decision-making are at the
population level (Abbott 2012). Modeling studies
show that while the action potentials of individual
neurons might appear disordered and uncoordinated,
population level activity is not.

478

We know that neurons and neural circuits have to
respond quickly and flexibly as contexts change.
This means that they need to be able to ignore
irrelevant information while reacting to whatever is
important to the larger task at hand. Neural responses
in the frontal eye fields in monkeys were recorded as
they performed a visual discrimination task using noisy
stimuli. It turns out that individual neurons
simultaneously respond to the motion and color of
stimuli, the context, as well as the target itself.
However, these signals are separable at the population
level through linear regression (Mante et al. 2012).
Importantly, stimuli analysis at the population level
is integrated with motor choices, just as proponents
of embodied cognition would have predicted. We see
similar dynamics in the olfactory system of the fly (Luo
et al. 2010).
One important facet of nonlinear dynamical
systems is that they are nested systems, and their
components exhibit the same sort of dynamics as the
system as a whole. Individual neurons and the ion
channels in neurons also appear to have the same
dynamical pink noise properties as the activity of
populations of neurons (White et al. 1998, Yu et al.
2005). While most are comfortable believing that
monkeys are conscious, it is less clear that we want to
assert that flies are, and it is even more problematic to
assert that parts of monkey brains or fly brains are
conscious.
Chemero perhaps could wriggle out of this problem
with his definition of cognition. That is, these might be
synergistic systems, but they are not cognitive synergies.
He defines cognition as “the ongoing, active
maintenance of a robust animal-environment system,
achieved by closely coordinated perception and
action” (2009, loc. 2696/3178). In other words, the
sorts of dynamically coupled systems I have been
discussing are necessary but not sufficient for cognition.
He is restricting consciousness to the brain-bodyenvironment system’s level, or perhaps even to the
animal brain-body-environment system. If you move
inside the head, while there might exist dynamical
systems modeled in identical ways to an animal
brain-body-world synergy, there would be no actual
cognition. And no cognition would mean no
consciousness either, according to Chemero’s view.
Of course, this move does not solve the hard
problem of consciousness, since it does not explain
what might be special about the animal brain-bodyenvironment synergy such that it has consciousness
but the olfactory system of the fly brain does not.
Indeed, this move echoes the challenge before the
computationalist: what is it that is special about human
(or primate or animal or whatever is conscious)
computations that make them conscious? Prima facie,
there is nothing about the computations themselves
that should give rise to conscious experience, and there

are certainly many computational systems that we
believe are not conscious. Similarly, we can ask: what
is it that is special about an animal brain-bodyenvironment interaction that is cognitive and
therefore consciousness? Prima facie, there is nothing
about being an animal synergy that should give rise to
conscious experience. In particular, there does not
seem to anything special about an animal brainbody-environment interaction that an animal brain
piece-body piece-environment interaction would not
also share. Put another way: there does not seem any
reason to believe that the neutral monads that
comprise our world exist at the level of animalenvironment relations as opposed to animal-partenvironment relations.
Of course, another alternative is that Chemero could
bite the bullet here and conclude that fly pieces are
indeed conscious, in their own sort of fly-ish way.
Being an interaction-dominant, softly assembled, pink
noise sort of synergy is both necessary and sufficient
for cognition and therefore for consciousness as well.
The right sort of dynamics is all you need for
cognition; the nested components of the nonlinear
systems have all the same properties as the mother
system, and this would include cogitating and
consciousness.
Perhaps, though, he would not want to do this,
since, as Silberstein and he point out, one advantage
of tying consciousness to cognition is to “[eliminate]
fruitless philosophical discussion of qualia and the
so-called hard problem of consciousness” (2012, p.
35). They want to get rid of the challenge of
envisioning odd machines as being conscious because
they are computing over representations by denying
that conscious systems compute at all. But here we are,
back discussing an odd machine and whether it has
experiences. This time, however, we are wondering
whether the system is cognitive after all.
The complaint similar to the one Chemero and
Silberstein lodge against traditional consciousness
studies can also be lodged against them. While we
can define cognition as a particular type of synergy,
and we can believe that cognition just is an extended,
softly assembled animal brain-body-environment
synergy, and we can deny that manipulating
representations has anything to do with humans
thinking, we still do not escape the fundamental
problem with explaining consciousness, that is,
explaining why anything at all is conscious.
In other words, there is no reason why a neutral
substrate should be conscious. It is, according to their
view. But just as we can imagine (or so the story
goes) things that are functionally identical to humans
but are not conscious, so too can we envision complex
brain-body-environment synergies comprised of a
neutral substrate that is not conscious. The hard
problem remains.

479

Or, perhaps a more accurate way to describe
Silberstein and Chemero’s move: consciousness just
is an inherent aspect of affordances. Like Chalmers,
they try to eliminate the hard problem by making
consciousness part of the fundamental structure of the
world. But just as with dualism, one needs an argument
or evidence for why subjectivity appears where it
allegedly does.

greater number of brain regions when we perceive
inanimate objects than when we do living things: in
both cases, we activate the areas associated with
visual perception, but in the case of seeing a tool in
our environment, we also activate kinesthetic and
motor movement brain regions. (Imaging studies bear
out Damasio’s conjecture, cf., Gerlach et al. 2002,
Kellenback et al. 2003.) Hence, it might be the case
that we do not have different brain areas that respond
differentially to living versus non-living objects, but
rather that we just have more regions involved with
one type of perception over another. With more
regions activated in response to inanimate objects,
and therefore more regions that would have to be
damaged in order to see the related agnosia, it would
not be surprising that we have a hard time finding
patients with deficits naming inanimate objects but not
living ones.
Here then is the hypothesis: we distinguish objects in
our environment based on how we (potentially)
interact with them. We perceive living things by their
visual features and concomitant affective responses,
but inanimate objects based on functional properties.
This, of course, is just another way to look at
affordances: we see and understand the objects around
us in terms how we relate to them, and they to us. But
now we can go further: not only are differences in
psychological projection between animate and
inanimate objects tied to perceptual differences, but
also to action-decisions and consciousness itself.
I am claiming that we do not project ourselves
through what we perceive to be other living things in
our environment. We can only project ourselves through
objects that we manipulate functionally (I note that
there might be good exceptions to this general rule; for
example, when we use a living thing as a tool in our
environment. A practiced person might project through
a trained seeing-eye dog to the environment beyond.)
And, we can only extend our conscious experience
into whatever psychological space of projection we
have available to us. One limit on our conscious
experience is not just the edge of the affordance, so to
speak, but it is also the type of affordance we perceive.
Functional objects become psychologically transparent
to us, such that we project our conscious experiences
through them. Animate objects do not.
I conclude: Chemero (and Silberstein) cannot escape
the hard problem of consciousness by positing neutral
monism. Nevertheless, there is something right about
his position. Consciousness is connected to or
indexed by or co-occurs with or identical to our
perception of affordances, which is intimately tied to
how we interact with the objects in our environment.
We are aware of what we intend to manipulate in our
environment in order to achieve our behavioral goals.
Hence, consciousness is not identical to all cognition;
it is not even identical to all brain-based cognition.

Coda: Consciousness, Projection, and Action
However, there is at least one important difference
between the brain-body-environment synergies and the
human coupling described above that might give us
some insight into conditions for conscious awareness:
we do not or cannot project ourselves psychologically
onto or through the other individuals. Unlike driving a
car, in which we can “feel” the tires on the road,
when coupled with another person, we do not “feel”
the other person’s feet hitting the ground. Whatever
sort of system or synergy coupled humans are, the
psychological reality of having an animate object in
the environment is quite different from having an
inanimate
object.
Inanimate
object-environment
synergies are transparent to us; human couplings are
not.
There has to be something fundamentally different
between the two. What is it? I argue that the difference
lies in how we perceive the respective affordances.
And insofar as how we perceive affordances is tied to
how we consciously experience the world, then it could
be that Chemero is onto something after all.
For example, there are some odd cases of associative
agnosia in which patients are unable to recognize or
name living things (like lions or opossums), but they
can recognize and name inanimate objects (like forks
and radios) without a problem (Satori and Job 1988).
If we take a traditional neuro-reductionist point of
view, then we should conclude that information
about living things is stored in a different place in the
brain than information about inanimate objects.
Damage to the “living thing” place in the brain
results in patients with deficits in recognizing living
things and damage to the “inanimate object” place
results in patients with deficits in recognizing
inanimate objects. But interestingly, and perhaps
counter-intuitively, there are very few cases in which
a patient cannot recognize inanimate objects, but can
recognize living things. We don’t get the neat double
dissociation that neuropsychologists love.
If there are two separate areas for living and
inanimate objects, then why would we find brain
damage possible in one area but not the other?
Antonio Damasio (1990) suggests that this pattern
could be due to a difference in how we perceive living
and inanimate objects. In particular, we manipulate
inanimate objects, but, for the most part, we do not
living ones. As a result, we would be activating a

480

Instead, it is deeply linked to one very important part
of our cognitive processes: perceiving affordances just
prior to action.

Kellenbach, M.L., Brett, M., and Patterson, K. (2003).
Actions speak louder than functions: The importance
of manipulability and action in tool representation.
Journal of Cognitive Neuroscience 15: 30-46.
Kello, C., & van Orden, G. (2009). The emergent
coordination of cognitive function. Journal of
Experimental Psychology: General, 136: 551-568.
Kelso, J.A.S. (2009). Synergies: Atoms of brain and
behavior. In D. Sternad (Ed.), Progress in Motor
Control. Heidelberg, Germany: Springer, pp. 83-91.
Leibniz, G.W. (1714/1991). Monadologie. Trans. by N.
Rescher. Pittsburgh, PA: University of Pittsburg Press.
Luo, S.X., Axel, R., & Abbott, L.F. (2010).
Generating sparse and selective third-order responses
in the olfactory system of the fly. Proceedings of the
National Academy of the Sciences (USA), 107: 1071310718.
Mante, V., Sussillo, D, Shenoy, K.V., & Newsome,
W.T. (2012). Selection and integration of relevant
sensory evidence without gating of sensory inputs.
Program No. 175.07. 2012. Neuroscience Meeting
Planner. Washington, DC: Society for Neuroscience.
Miyazaki, M., Nakajima, Y, Kadota, H., Chitose,
K., Ohtsuki, T., & Kudo, K. (2004). 1/f-type
fluctuation in human visuomotor transformation.
NeuroReport, 15:1133-1136.
Raafat, R., Chater, N., and Frith, C. 2009. Herding in
humans. Trends in Cognitive Sciences 13: 420-428.
Satori, G. and, Job, R. (1988). The oyster with four
legs: A neuropsychological study on the interaction
of visual and semantic information Cognitive
Neuropsychology 5: 105-132.
Silberstein, M., & Chemero, A. (2012). Complexity
and extended phenomenological-cognitive systems.
Topics in Cognitive Science 4: 35-50.
Silberstein, M., & Chemero, A. (2015). Extending
neutral monism to the hard problem. Journal of
Consciousness Studies.
Strogatz, S. (2004). Sync: How Order Emerges From
Chaos In the Universe, Nature, and Daily Life. New
York, NY: Hyperion.
Thelen, E., and Smith, L.B. (1994). A dynamic systems
approach to the development of cognition and
action. Cambridge, MA: The MIT Press.
Van Orden, G., Holden, J., & Turvey, M.T. (2003).
Self-organization of cognitive performance. Journal
of Experimental Psychology: General, 132: 331-351.
Varela, F., Thompson, E. & Rosch, E. (1991). The
embodied mind: Cognitive science and human
experience. Cambridge, MA: The MIT Press.
White, J.A., Klink, R., Alonso, A., & Kay, A.R.
(1998). Noise from voltage-gated ion channels may
influence neuronal dynamics in the entorhinal
cortex. Journal of Neurophysiology, 80: 262-269.
Yu, Y., Romero, R., & Lee, T.S., (2005). Preference
of sensory neural coding for 1/f signals. Physical
Review Letters, 94:108103.

Acknowledgments
Early versions of the paper were presented to the Society
for Philosophy and Psychology, the University of
Waterloo, and at the Conscious Persons workshop at
Calvin College. Many thanks to all the participants
for their helpful and thoughtful comments. Special
thanks are also due to Tony Chemero and Mike
Silberstein for engaging with me on this topic, and to
the referees for the Cognitive Science Society, whose
thoughtful comments made this essay better. This
research was partially supported by the Templeton
Foundation and the University of Cambridge.

References
Abbott, L. (2012). The collective wisdom of neurons.
Albert and Ellen Grass Lecture. Society for
Neuroscience 2012, New Orleans, LA.
Brooks, R. (1991b). Intelligence without reason.
Proceedings of 12th International Joint Conference
on Artificial Intelligence. 569–595.
Brooks, R. (1991b). Intelligence without representation.
Artificial Intelligence, 47: 139-159.
Chalmers, D.J. (1995). Facing up to the problem of
consciousness. Journal of Consciousness Studies 2:
200-219.
Chalmers, D.J. (1996). The Conscious Mind: In Search
of a Fundamental Theory. Oxford: Oxford University
Press.
Chemero, A. (2009). Radical embodied cognition.
Cambridge, MA: The MIT Press.
Damasio, A. (1990). Category-related recognition
defects as a cue to the neural substrates of
knowledge. Trends in Neuroscience 13: 95-98.
Dotov, D., Nie, L., & Chemero, A. (2010). A
demonstration of the transition from readiness-tohand to unreadiness-to-hand. PLoS ONE, 5: e9433.
Dotov, D., Nie, L., & Chemero, A. (2017).
Readiness-to-hand,
unreadiness-to-hand,
and
multifactality. Journal of Mind and Behavior.
Gerlach, C., Law, I., & Paulson, O.B. (2002). When
action turns into words. Activation of motor-based
knowledge during categorization of manipulable
objects. Journal of Cognitive Neuroscience 14: 12301239.
Gibson, J. (1962). Observations on active touch.
Psychological Review, 69: 477-490.
Gibson, J. (1966). The senses considered as perceptual
systems. Boston: Houghton-Mifflin.
Gibson, J. (1979). The ecological approach to visual
perception. Boston: Houghton-Mifflin.
James, W. (1904). Does “consciousness’ exist?
Journal of Philosophy, Psychology, and Scientific
Methods 1: 477- 491.

481

