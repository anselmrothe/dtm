A comparison between human micro-affordances and computational classification
Arthur-Henri Michalland (Arthur-Henri.Michalland@univ-montp3.fr, Arthur.Michalland@lirmm.fr)
Epsylon Laboratory EA 4556, University Paul Valéry, Site Saint Charles, route de Mende
34190 Montpellier, France
LIRMM: Laboratory of Informatics, Robotics, Microelectronics of Montpellier, University of Montpellier
CNRS, 860 rue de St Priest
34095 Montpellier cedex 5

Denis Brouillet (Denis.Brouillet@univ-montp3.fr)
Epsylon Laboratory EA 4556, University Paul Valéry, Site Saint Charles, route de Mende
34190 Montpellier, France

Philippe Fraisse (Philippe.Fraisse@lirmm.fr)
LIRMM: Laboratory of Informatics, Robotics, Microelectronics of Montpellier, University of Montpellier
CNRS, 860 rue de St Priest
34095 Montpellier cedex 5
Abstract
This study aimed to assess how specific components of an action could be selected by a simple computational system. We
performed an experiment to test associations between grasps
(precision or power grip) and several objects. We then ran
simulations using a naive bayes classifier to study to what extent it could reproduce participants’ choice. This classifier had
two learning matrices containing objects’ size associated with
a grip by means of our experiment. When receiving a new
object’ size it computed the probability for each grip to be
adapted. The highest probability was considered to represent
which grip was associated with the object by the classifier. Results show that the classifier can reproduce participants’ choice
depending on the size of its learning matrices, and can quickly
select the right type of grip for a majority of trials, showing
that micro-affordances (Ellis & Tucker, 2000) can be reproduced through naive bayesian classification.
Keywords: affordance; grip; bayesian method; classifier

Introduction
As Leonard de Vinci said : “movement is principle of life”.
The way people interact with the world through body movements is indeed a corner stone of psychology, and especially
of embodied psychology. As embodied psychology postulates that high-level cognitive processes are bodily rooted,
or at least that their result depends on bodily states (Wilson,
2002), movements of the living body is a crucial point to attend. Yet how adapted body movements occur is not well
determined and several propositions are made, one of them
being particularly attractive for embodied cognitivists: theory of affordances (Gibson, 1979).
Affordance is a concept coined by Gibson (1979) that relies
on direct perception. Although it has many interpretations,
we will rely on the definition of Chemero (2003) in which affordances represent the relations between an animal’s capacities and features of its environment. Abilities of an animal are
functional properties, that depends on this animal’s history.
This theory highlights the fact that voluntary actions are
products of our perception of the situation, our abilities, and
what we have learned. Moreover, this theory predicts that

action is part of objects’ memories and perception, as it is now
established (Brouillet et al., 2015), which is of interest for
psychology and for robotics as they permit to gain insight into
the perception-action loop (Montesano et al., 2007, 2008).
Yet, the link between perception and affordances needs further investigation, as clues, or features, need to be extracted
from, or constructed on the basis of the environment. Such
clues would facilitate the link between a rich perception and
an adapted movement, and permit on line adaptation.
Our purpose was to test how adapted voluntary movements
could be selected, by a very simple computational system, on
the basis of clues extracted from perception. To do this we
chose to test some specific components of an action: grasping movements (Koester, Schack, & Westerholz, 2016). A
lot of our interactions with the world depend on our ability to grasp things around us in a proper way, for example
using a power or a precision grip (i.e. with all fingers of
the hand or with the thumb and index, respectively, see Figure 1). These specific components of action (that doesn’t include walking, reaching etc...) are termed micro-affordances
by Ellis and Tucker (2000). These micro-affordances are supposed to emerge while looking at an object, and to facilitate
a specific grasp. We selected object size to be the feature of
the environment that could be associated to a specific grasp,
in order to create a model that simulates a perceptually based
motor activity.
The computational system we used to infer specific grasps
rely on bayesian probability (Jones & Love, 2011; Pearl,
1985). The bayesian approach appears to be promising when
studying how humans can interact with the world in presence
of uncertainty (Perfors et al., 2011). It can apply to motor
planning and control, estimation of context and motor learning (Wolpert & Ghahramani, 2000; Wolpert, Ghahramani, &
Flanagan, 2001), and can be easily used in its simplest ways
(Robert, 2000). This approach rely on conditional probability and allows to determine the probability of a certain event
(for example a particular grasp) knowing some information :

2729

past experiences (e.g. earlier grasp in presence of an object)
or sensory inputs (e.g. object size) (Naı̈m et al., 2007).
The particular model we chose is a naive bayes classifier.
This model has two learning matrices : one containing the
size of objects graspable with a power grip, and one containing the size of objects graspable with a precision grip, size
being represented by three parameters x, y, and z. Once it has
computed these matrices, it receives the size of a novel object to be classified as graspable with a power grip or with a
precision grip. In order to do so, it selects the most probable
grasp, knowing the object size, to be the grasp to produce in
presence of this particular object.
This approach of micro-affordances as naive bayesian classification can be of interest for psychologists and roboticians,
as it can reduce the size of ontology, or databases, needed for
an adapted system, and permits to infer micro-affordances in
a very simple way.
In a first part we present the experiment to test microaffordances with human beings and select objects that can
be associated with a precision or a power grip. In a second
part we explain how the model categorizes objects as being
graspable with a precision or a power grip by means of naive
bayesian classification, and show the results obtained with
this model. We then compare human’s and classifier’s performances and discuss the possible developments of such applications.

Selection and association of objects with a
precision or a power grip
Participants
Sixteen students were recruited for a pre-experiment in order to select the objects used in our experiment and simulation. Eighty students, different from the previous ones, were
then recruited in order to select the appropriate grasp for each
object (seven of them were not taken into account as they
changed their grasping for the same objects between trials and
differed drastically from the others). All participants freely
signed a letter of consent, were right-handed, had normal or
corrected to normal vision and over 18 years old, none had
problems of motricity.

Materials
Forty-four pictures of objects were used. Each picture was
modified to have the object being centered, vertically oriented, and a half of their real size when displayed on the computer screen.
These images were presented to sixteen students in a preexperiment, with a hand near the object either making a
power grip or a precision grip (see Figure 1). Participants
had to indicate their level of agreement with the grip being
displayed with the object. A high level of agreement with a
grip meant that it was a reasonable grip to pick up and use the
object.As a result, twenty objects were selected for the experiment, ten being graspable with a power grip and ten with a
precision grip.

Figure 1: A hand making a power grip (left picture), and a
precision grip (right picture).

Procedure
All of eighty participants were received one by one in an experimentation room, and sat in front of a computer Lenovo
17.3” with graphics card AMD radeon HD 8500M. They
were asked to grab, with their right hand, a device that constrained them to make either a power or a precision grip. They
were instructed to look at the computer screen and make the
more appropriate grip on the device when seeing an object
displayed on the screen. The twenty objects were then displayed randomly. When the twenty objects had been exposed,
a second random presentation was made, in order to ensure
the grip selected by participants for each object.

Results
Overall, the grips selected by means of the pre-experiment
were respected, as shown in Table 1 and Table 2, and participants showed stable grip for each object. All of which allowed us to classify each object as associated with a precision
or a power grip.
Table 1: Percentage of responses for objects associated with
a precision grip, a number was attributed to each object for
further comparison.
Objects
grain of wheat
tweezers
nut
radish
smart card
screw
paper clip
strawberry
french beans
key

N
1
2
3
4
5
6
7
8
9
10

% power grip
0.68
3.42
0.68
10.96
1.37
0.00
0.00
6.85
1.37
2.74

%precision grip
99.32
96.58
99.32
89.04
98.63
100.00
100.00
93.15
98.63
97.26

Simulation with a naive bayes classifier
The naive bayes classifier
The second step of this work was to put the naive bayes classifier to the test. To do so, we had to implement the size of
objects used in our experiment. We chose to represent size in

2730

ject, represented by a vector (xn , yn , zn ), was associated by the
model to probabilities P(gripi |xn , yn , zn ) for i = 1 the precision grip (grip1 = G1 ) and i = 2 the power grip (grip2 = G2 ).
The Bayes’ theorem permits to decompose these probabilities :
P(gripi , xn , yn , zn )
(1)
P(gripi |xn , yn , zn ) =
P(xn , yn , zn )

Table 2: Percentage of responses for objects associated with a
power grip, a number was attributed to each object for further
comparison.
Objects
glass
hair clipper
coconut
apple
corn
computer mouse
board wiper
universal pliers
pepper
deodorant

N
11
12
13
14
15
16
17
18
19
20

% power grip
97.26
91.10
100.00
99.32
95.89
89.73
92.47
95.21
95.21
91.78

%precision grip
2.74
8.90
0.00
0.68
4.11
10.27
7.53
4.79
4.79
8.22

The probability P(gripi , xn , yn , zn ) can be written as :
P(gripi , xn , yn , zn ) = P(xn , yn , zn , gripi )
= P(xn |yn , zn , gripi ) × P(yn , zn , gripi )
= P(xn |yn , zn , gripi ) × P(yn |zn , gripi ) × P(zn , gripi )
= P(xn |yn , zn , gripi )×P(yn |zn , gripi )×P(zn |gripi )×P(gripi )
(2)
Here, the naive assumption of conditional independence
assumes that given the category gripi , xn , yn and zn are independent, so that :

a three dimensional cartesian coordinate system, representing
height, width, and depth.

P(xn |yn , zn , gripi ) = P(xn |gripi )

(3)

P(yn |zn , gripi ) = P(yn |gripi )

(4)

and
Thus, using equations (1) (2) (3) and (4)
P(gripi |xn , yn , zn ) =
P(xn |gripi ) × P(yn |gripi ) × P(zn |gripi ) × P(gripi )
P(xn , yn , zn )

Figure 2: A computer mouse mesured on x, y and z.

The model then selected the adapted grip for the object
(xn , yn , zn ) using :

Table 3: Mean and Variance for objects associated with a precision grip or a power grip.
Objects
precision
power

x
1.265
(0.422)
6.76
(3.83)

Mean (Variance)
y
0.62
(0.291)
5.27
(8.58)

argmax[P(G1 |xn , yn , zn ); P(G2 |xn , yn , zn )]
z
4.87
(11.72)
13.92
(22.94)

We defined a rule to mesure our objects : z axis for the
longest axis of the object, y axis for the shortest axis of the
object, and x the last one, following the right hand rule (e.g.
mesure of a computer mouse in centimeter: x = 6, y = 1.65,
z = 11.50, see Figure 2).These rules were followed in order
to satisfy the concept of axis for grasping proposed in Michel
(2006), we simplified Michel’s studies to reduce the natural
axis of prehension of an object to its longest side. Mean and
variance of objects associated with a precision grip and objects associated with a power grip are presented in Table 3.

Procedure
The model received an unknown object to be classified as
graspable with a power grip or a precision grip. This ob-

(5)

(6)

In concrete terms the naive bayes classifier had two learning matrices of size ( j, 3), j being the number of objects in
the learning matrices, represented by their three coordinates
(x j , y j , z j ). One matrix included the objects classified as graspable with a precision grip (G1 ), the other included the objects classified as graspable with a power grip (G2 ).
The following calculations were applied similarly for G1
and G2 , we will only present the calculations for parameter
x in G1 for the sake of clarity. The classifier computed the
probability for an object to be graspable with a precision grip
(P(G1 ) = 2jj = 12 ).
And the mean and variance of each parameter x, y,
and z for a precision grip : µG1 (x), µG1 (y), µG1 (z) and
σ2G1 (x), σ2G1 (y), σ2G1 (z); and for a power grip, resulting in
µG2 (x), µG2 (y), µG2 (z) and σ2G2 (x), σ2G2 (y), σ2G2 (z).
When a novel object with parameters (xn , yn , zn ) was presented to the model, the classifier had to compute the probabilities P(G1 |xn , yn , zn ) and P(G2 |xn , yn , zn ), using (5).
As measurements were on continuous variables, the new
parameters were computed given the known parameters

2731

of the model using a gaussian probability density function, in order to calculate P(xn |G1 ), P(yn |G1 ), P(zn |G1 ) and
P(xn |G2 ), P(yn |G2 ), P(zn |G2 ) with:

P(xn |G1 ) = q

1

−

e

[xn −µG (x)]2
1
2σ2G (x)
1

2πσ2G1 (x)

Then the model selected the highest probability (the appropriate grip), using (6).
As gaussian probability density function could return 0 for
the probability of a parameter given a class gripi , we distinguished two cases. In the first case only one parameter of
the novel object had a probability equal to zero, in this case
we did not change anything (we show in discussion why this
case is a limit for this type of classification). In the second
case two parameters of the novel object, one for each class,
had a probability equal to zero (for example P(yn |G1 ) = 0
and P(zn |G2 ) = 0), we changed these probabilities to ε close
to zero , this changed P(G1 |xn , yn , zn ) and P(G2 |xn , yn , zn ) to

P(G1 |xn , yn , zn ) = lim

ε→0

P(xn |G1 ) × ε × P(zn |G1 ) × P(G1 )
P(xn , yn , zn )
(7)

and
P(G2 |xn , yn , zn ) = lim

ε→0

P(xn |G2 ) × P(yn |G2 ) × ε × P(G2 )
P(xn , yn , zn )

As P(xn , yx , zn ) = P(xn , yn , zn , G1 ) + P(xn , yn , zn , G2 )

Results

P(xn , yn , zn ) =
P(xn |G1 ) × ε × P(zn |G1 ) × P(G1 )+
P(xn |G2 ) × P(yn |G2 ) × ε × P(G2 )
= ε × [P(xn , zn , G1 ) + P(xn , yn , G2 )] (8)
So that, using (7) and (8):
P(G1 |xn , yn , zn ) =

P(xn |G1 ) × P(zn |G1 ) × P(G1 )
P(xn , zn , G1 ) + P(xn , yn , G2 )

Thus the probability of a grip given the three parameters
of the novel object became the probability of a grip given
the two parameters of the novel object for which probability
was not changed by ε, as the changes operated cancelled each
other out.

Simulation
Simulation was performed using Matlab R2015a with a computer running on Windows 7 with a CPU Intel Core i5-4258U
2.10GHz.
We aimed at assessing naive bayes classification by
analysing classifier’s performance with different learning
matrices (different learned objects and number of objects

learned). In addition we compared the results of the classifier to the results obtained with human participants.
Simulation ran using j = 1 to 7 learned objects for each
category (we always used the same number of learned objects
in the two categories : objects associated with a precision grip
and objects associated with a power grip).
Objects that were not used in learning matrices were categorized using the method described earlier.
As learning order did not have any impact on classification,
number
of trials was defined using the binomial coefficient
N
with
N = 10 the total number of objects in each catej
gory and j the number of objects learned in each category.
This binomial coefficient gives the number of combination
of learned objects without taking into account possibilities of
permutation (learning order). The classifier was tested for every possible combination of learning: for each combination of
precision grip’s learning, we tested all combinations of power
grip’s learning. This way the results presented in Table 4 and
Table 5 show the proportion of correct classification for every
object over all possible learnings of our material.
For each object and each j we verified the grip selected by
the classifier within each trial. For objects associated with
a precision grip by means of our experiment (see Table 1),
classification was recorded as right when the classifier calculates a higher probability for precision grip than for power
grip. The reverse was made for objects previously associated
with a power grip (see Table 2). If probabilities for a precision grip and for a power grip were equal, we considered that
classification was incorrect.

Overall it took 1397.71 seconds (23 minutes and 29 seconds)
for the program to select learning matrices and make 1837440
classification. The classification of one object took in average
7.61 × 10−1 ms.
When more than one parameter for one class was equal to
zero (33 cases), or when P(xn , yn , zn ) was considered equal
to zero due to very small probabilities (82 cases), classification was impossible. These particular numeric cases happened rarely (115 objects impossible to classify over 1837440
classified objects).
We computed the percentage of right classification for each
object and each j (number of learned objects before classification). The percentages of right classification are shown in
Table 4 (the percentage of right classification for objects considered as associated with a precision grip), and Table 5 (the
percentage of right classification for objects considered as associated with a power grip).
A few things are to be discussed here. First, we can see
that overall the classifier returned the right grip most of the
time, in all the conditions (92.86% of right classification).
Secondly we can see that classification was better for objects that were considered associated with a power grip than
for the others.
Thirdly, we see that classification performance increased
as number of learned objects increased. This is because pa-

2732

rectly.
The fact that object 4 was hardly well classified, instead
of being a real issue for naive bayesian classification, could
be an advantage when comparing the classifier’s performance
and human classification: in our experiment object 4 reveals
the higher percentage of selection for the competing grip (see
Table 1).

Table 4: Percentage of right classification for objects associated with a precision grip and for k objects learned.
Objects
1
2
3
4
5
6
7
8
9
10
Mean

2
85.22
76.62
88.39
43.34
82.93
84.07
87.49
63.03
52.78
86.63
75.05

Number of learned objects
3
4
5
6
95.95 99.60
100
100
86.97 95.57 99.21
100
96.83 99.90
100
100
47.52 46.28 45.85 42.15
93.91 98.81 99.73
100
95.37 99.43
100
100
98.33
100
100
100
80.10 91.42 96.49 98.76
56.54 63.03 67.64 73.39
94.98 99.26
100
100
84.65 89.33 90.89 91.43

7
100
100
100
30.36
100
100
100
100
80.37
100
91.07

Comparison of human and classifier’s performance
To compare human’s and classifier’s performance we used a
χ2 test of independence between variable object (object 1 to
object 20) and variable responding entity (human participants
or naive bayes classifier).
When three, four, five and six objects of each category
were put in the classifier’s learning matrices, we found that
the two variables were independent (χ2 (19) = 25.22, p =
0.15; χ2 (19) = 23.06, p = 0.23; χ2 (19) = 21.69, p =
0.30; χ2 (19) = 22.71, p = 0.25, respectively), this meaning
that classifier’s performance and human grip’s choice were
not significantly different.
When two objects of each category were put in the classifier’s learning matrices, we found that variables object
and responding entity were independent, but with a greater
difference between human’s and classifier’s performance
(χ2 (19) = 29.26, p = 0.06).
Finally, when seven objects of each category were put in
the classifier’s learning matrices, it appeared that the two variables were not independent anymore (χ2 (19) = 33.01, p <
0.05), human’s and classifier’s performance became significantly different.

Table 5: Percentage of right classification for objects associated with a power grip and for k objects learned.
Objects
11
12
13
14
15
16
17
18
19
20
Mean

2
96.22
86.66
96.82
95.54
94.21
92.29
95.09
86.63
96.97
94.04
93.45

Number of learned objects
3
4
5
6
99.93
100
100
100
96.26 99.52
100
100
99.79
100
100
100
99.56
100
100
100
98.77 99.82
100
100
98.75 99.96
100
100
99.73
100
100
100
94.82 98.82 99.84 100
99.76
100
100
100
99.30
100
100
100
98.67 99.81 99.98 100

7
100
100
100
100
100
100
100
100
100
100
100

Discussion

rameters µ and σ were more representative of a class (power
or precision grip) as number of learned objects increased.
What is counterintuitive is that classification of object
number 4 got worse and worse, it is because we put more
objects different from object 4 in the precision grip’s learning
matrice as the simulation went on. Object 4 had its three parameters close to boundaries of the precision grip space (represented by its mean and variance for each parameter x, y and
z). Thus, depending on the objects learned, increasing the
number of learned objects put object 4 out of the boundaries:
the more learned objects associated with a precision grip had
parameters close to the parameters of object 4, the more object 4 was classified as part of precision grip’s objects. Conversely the more learned objects associated with a precision
grip had parameters distant from object 4, the more it was
classified as part of power grip’s object. Compared to object
4, other precision grip’s objects had one of their parameter
close to the boundaries of precision grip’s space, but not all
of their parameters, which made them easier to classify cor-

The results we obtained reveal that naive bayesian classification can reproduce the grip’s choice made by human participants.
A good association of a novel object and its adapted grip
can be accomplished with a reduced database and few parameters. This may permit to determine quickly a subclass of
grips belonging to the precision or power grip classes when
looking at an object, in other words to detect the possible
nested micro-affordances associated with the object (for example a precision grip could comprise several nested microaffordances: a grip with the thumb and the index, a grip with
the thumb, the index and the middle finger, with more or less
strenght etc...). Quickness of the categorisation in precision
or power grip classes could then be an advantage for real-time
adaptation.
But some limitations are to be exposed. The calculation of
conditional probabilities through gaussian probability density
function implies that a parameter could have a zero probability given a certain grip class. This pulled the probability of
this grip to zero, while the probability of the competing grip
automatically became one, biasing the classification of the
object. A second limitation is the ad hoc hypothesis that parameters are independent, which could induce errors for other
parameters than the ones we used.

2733

When seven objects of each category were learned by the
classifier, the selection made by the classifier and human
choice became significantly different probably because classifier’s selection only account for a calculation made on the
basis of mean and variance of the three parameters representing the objects. This calculation is always the same and as
long as enough objects are learned the mean and variance of
each class’ parameter began to show little variability no matter the learning matrices. This shows that the algorithm used
with this classifier produces a rigid classification, and cannot, at some point, reproduce the diversity created both by
the complexity of our cerebral structures and the variations of
embodiment between different human beings.
Yet this classifier can reproduce, in the majority of cases,
human grip’s choice in a small amount of time, and with few
parameters needed to be taken into account. This shows that
micro-affordances could be reproduced in some way with a
simple computational system using naive bayesian classification, suggesting that some early stages of the processes linked
to human micro-affordance could be performed by some simple probabilistic mechanisms.
Future studies should take more parameters for an object
by cutting up the objects in three parts in order to determine the type of grip and the position of the grip on the object (Faria et al., 2014), and introduce action’s consequences
(Hommel, 2015; Shin, Proctor, & Capaldi, 2010) through
tactilo-kinesthetic parameters (Pfister et al., 2014), like pressure induced by the weight of the object, or muscle tension,
in order to permit an efficient grip with a simple classification
algorithm. We should also investigate the classifier’s performance when an increased number of objects are learned and
classified.

Acknowledgments
We would like to thank Johan Briglia, Jean-Pierre Rivet and
Firas Kaddachi for their contributions to this work. We also
thank Epsylon’s DynaCSE team and LIRMM’s IDH team for
welcoming us during our thesis, and Paul Valery University
for funding this thesis.

References
Brouillet, D., Vagnot, C., Milhau, A., Brunel, L., Briglia, J.,
Versace, R., & Rousset, S. (2015). Sensorymotor properties of past actions bias memory in a recognition task.
Psychological Research, 79, 678.
Chemero, A. (2003). An outline of a theory of affordances.
Ecological Psychology, 15, 181–195.
Ellis, R., & Tucker, M. (2000). Micro-affordance : The potentiation of components of action by seen objects. British
Journal of Psychology, 91, 451–471.
Faria, D. R., Trindade, P., Lobo, J., & Dias, J. (2014).
Knowledge-based reasoning from human grasp demonstrations for robot grasp synthesis. Robotics and Autonomous
Systems, 62, 794–817.
Gibson, J. J. (1979). The ecological approach to visual perception. Boston, MA: Houghton-Mifflin.

Hommel, B. (2015). The theory of event coding (TEC) as
embodied-cognition framework. Frontiers in Psychology,
6, 1318.
Jones, M., & Love, B. (2011). Bayesian fundamentalism or
enlightenment? on the explanatory status and theoretical
contributions of bayesian models of cognition. BEHAVIORAL AND BRAIN SCIENCES, 34, 169–231.
Koester, D., Schack, T., & Westerholz, J. (2016). Neurophysiology of grasping actions: Evidence from erps. Frontiers
in Psychology, 7, 1996.
Michel, C. (2006). Stratégie de saisie pour une main robotisée à caractère anthropomorphique. Doctoral dissertation, Robotics Department, University of Paris 6 Paris.
Montesano, L., Lopes, M., Bernardino, A., & Santos-Victor,
J. (2007). Affordances, development and imitation. In
Development and learning, 2007. icdl 2007. ieee 6th international conference on. Piscataway, NJ: IEEE.
Montesano, L., Lopes, M., Bernardino, A., & Santos-Victor,
J. (2008). Learning object affordances: From sensory–
motor coordination to imitation. In Ieee transactions on
robotics (pp. 15–26). Piscataway, NJ: IEEE.
Naı̈m, P., Wuillemin, P. H., Leray, P., Pourret, O., & Becker,
A. (2007). Réseaux bayésiens. Paris, France: Eyrolles.
Pearl, J. (1985). Bayesian networks: a model of self-activated
memory for evidential reasoning. In Proceedings of the annual conference of the cognitive science society 1985 (pp.
329–334). Irvine, UC: Cognitive Science Society.
Perfors, A., Tenenbaum, J. B., Griffiths, T. L., & Xu, F.
(2011). A tutorial introduction to bayesian models of cognitive development. Cognition, 120, 302–321.
Pfister, R., Janczyk, M., Gressmann, M., Fournier, L. R., &
Kunde, W. (2014). Good vibrations? vibrotactile selfstimulation reveals anticipation of bodyrelated action effects in
motor control. Exp Brain Res, 232, 847–854.
Robert, C. (2000). L’analyse statistique bayésienne. Paris,
France: Economica.
Shin, Y. K., Proctor, R. W., & Capaldi, E. J. (2010). A review
of contemporary ideomotor theory. Psychological Bulletin,
136, 943–974.
Wilson, M. (2002). Six views of embodied cognition. Psychonomic Bulletin Review, 9, 625–636.
Wolpert, D. M., & Ghahramani, Z. (2000). Computational principles of movement neuroscience. Nature Neuroscience, 3, 1212–1217.
Wolpert, D. M., Ghahramani, Z., & Flanagan, J. R. (2001).
Perspectives and problems in motor learning. Trends in
Cognitive Sciences, 5, 487–494.

2734

