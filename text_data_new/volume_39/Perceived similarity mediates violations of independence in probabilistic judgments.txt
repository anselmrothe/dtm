Perceived similarity mediates violations of independence in probabilistic
judgments
James M. Yearsley (james.m.yearsley@vanderbilt.edu)
Daier Yuan (daier.yuan@vanderbilt.edu)
Jennifer S. Trueblood (jennifer.s.trueblood@vanderbilt.edu)
Department of Psychology, Vanderbilt University, Nashville TN, USA
Abstract
We outline a simple way of representing sets of non-normative
judgements that makes them look as similar as possible to normative ones. This representation allows us to view certain
types of non-normative judgments, such as conjunction fallacies, as arising from a misestimation of the correlation between
events, that might arise when decision-makers have no prior
information about the frequency of co-occurrence. We suggest that decision-makers use the perceived similarity between
events to make inferences about correlation, and we describe
the results of an experiment showing that judged correlation
and violations of independence in probabilistic judgments are
strongly influenced by the perceived similarity between events.
Keywords: Conjunction fallacy, similarity, normative reasoning

Introduction
Being able to make unbiased and reasonably accurate likelihood judgments about simple events is a foundation for
more complicated tasks such as inference or causal reasoning. Human reasoners are often very competent at providing
such judgments, in the sense that their judgments align well
with normative prescription. However there are classic results, such as those associated with the famous Tversky and
Kahneman research program, which show that in some cases
human reasoners may provide likelihood judgments for simple combinations of events that show systematic biases. In
causal reasoning tasks for example, this can lead to violations
of the predictions of models based on classical probability
theory, with a resulting need to supplement classical models
with extra unobserved relationships (Rehder, 2014), or even
to reject classical probability theory entirely and attempt to
construct models based on other theories of probability, such
as quantum probability theory (Pothos & Busemeyer, 2013).
Several decades of experience have taught researchers
where to expect violations of normative rules when making
likelihood judgments, but there has been less success in determining why such violations occur. Tversky and Kahneman (1983) argued that conjunction fallacies occur because
of a representativeness heuristic, while explanations for violations of normative rules such as the Markov Condition in
causal reasoning often involve the presence of additional enabling or disabling causes (Rehder, 2014). Meanwhile models based on non-classical probability theory posit that violations of classical probability rules occur because of a somewhat mysterious property known as ‘incompatiblity’ (Busemeyer & Bruza, 2012). Perhaps one or more of these explanations is correct, perhaps none are, but regardless they all

suffer from the same problem that it is difficult to predict in
advance whether a given set of events will be ‘representative’
or ‘incompatible’ etc.
An additional problem faced when attempting to understand why some judgments are normative and some are not
is that different frameworks are used to model the different types of judgments. Partly this is due to the fact that
non-normative judgements are defined by what they are not,
viz. those that can be explained by an underlying classical
(Bayesian) belief state. One way of modeling non-normative
judgments is via heuristics (see e.g., Gigerenzer et al, 2015)
which may bear no relationship to classical probability computations. Another is to replace classical sample spaces with
quantum vector (Hilbert) spaces, as done in quantum models
of cognition (Busemeyer & Bruza, 2012), which again appear
to have little relation to classical probability theory.
There would appear, therefore, to be a disconnect between
the way cognitive states, and computations on them, are represented depending on whether one is dealing with normative or non-normative reasoning. This poses a challenge if we
wish to understand the reasons why we might sometimes give
normative judgments and sometimes not, or, for example, if
we wish to understand how corrective feedback may improve
performance.
What we want to do in this contribution is to introduce a
way of thinking about non-normative judgments that makes
them look as similar as possible to normative ones. This representation can be used in a variety of settings to study transitions between non-normative and normative behaviors. We
will show that for non-normative judgments the notion that
an underlying probability distribution ‘does not exist’ can be
formalized by considering quasi-distributions, which are similar to standard probability distributions except that some elements may be negative. This gives us a way to think about
smoothly transitioning from non-normative judgments, represented by quasi-distributions, to normative ones, where all
elements of the distribution are positive and it may be interpreted as a classical probability distribution.
By itself this achieves little beyond expressing the problem
of non-normative judgments in a different language, however
we will argue that this representation provides a new way to
understand the origin of non-normative judgments, and even a
way of visualizing how learning can cause a transition to normative behavior. We will see that non-normative judgments
can arise because of an misestimation of the correlation be-

1387

Joint quasi-probability distributions
If a set of judgments S is not normative, then a probability

tween events, and we will argue that this may occur when
events are perceived to be highly similar. We test this in an
experiment, looking at judgments about the joint occurrence
of events with different degrees of similarity.
The rest of this contribution is structured as follows, first
we provide a brief introduction to quasi-probability distributions, our aim being to show how they may be used to encode
non-normative judgments. Next, we use this framework to
develop a novel empirical prediction that a high degree of
perceived similarity between features of an object can give
rise to violations of independence and conjunction fallacies
in probabilistic judgments. Then, we describe an experiment
to test this prediction. We conclude with some possible avenues for further study.

distribution capturing these judgments does not exist. However there may still exist some function q(Ai , B j ,Ck ...) such
that all the elements in the set S can be obtained by summing
out the other variables in q(...). This function q(Ai , B j ,Ck ...)
will generally fail to be a probability distribution because it
will not be non-negative.

Probability distributions and
quasi-distributions
A common theme in experiments on probabilistic judgment is
that participants are asked to make a set of judgments about
the likelihood of some events, e.g. p(A), p(B), p(A ∩ C) etc,
and the normative status of these judgments is assessed by
proving that there either does or does not exist a probability distribution p(Ai , B j ,Ck ) such that all the measured judgments can be thought of as marginals of this joint distribution. For example, the conjunction fallacy, wherein participants judge p(A ∩ B) > p(A), is non-normative because it is
impossible for participants to have a single joint probability
distribution for A and B with this property.

Joint probability distributions
Establishing whether a set of probability or likelihood judgments is normative is therefore equivalent to the following:
Given
some
set
of
probabilities,
S =
{p(A), ...p(A, B), ..., p(A, B,C), ...} etc does there exist
a joint distribution p(Ai , B j ,Ck ...) of which all elements of
the set S may be considered as marginals?
If such a probability distribution exists, then the set of judgments S are normative, otherwise they are non-normative.
Some Examples
• This definition includes trivial cases, e.g. where ∑i p(Ai ) 6=
1. Such cases are obviously non-normative.
• A simple example is provided by the set S =
{p(Ai ), p(B j ), p(Ck ), ...} where participants are only asked
to make judgments about a single event. In this case
we can easily find a joint distribution that has the single
event probabilities as marginals, e.g. p(Ai , B j ,Ck , ...) =
p(Ai )p(B j )p(Ck )... will work (there are many choices).
A Less Trivial Example Suppose we have three binary
events A, B,C and we are given the joint probabilities, S =
{p(Ai , B j ), p(B j ,Ck ), p(Ai ,Ck )}. An important result is that it
is not always possible to find a joint distribution p(Ai , B j ,Ck )
with these marginals. The conditions under which this is possible are when the Bell inequalities are satisfied (Fine, 1982).

Example Suppose S = {p(A), p(B), p(A ∩ B)} for some binary valued features A, B and p(A ∩ B) > p(A). Clearly
there is no probability distribution which can have S as its
marginals. However a quasi-distribution with these properties may be given as:
q(A, B) = p(A ∩ B),
q(A, B̄) = p(A) − p(A ∩ B),
q(Ā, B) = p(B) − p(A ∩ B),
q(Ā, B̄) = 1 − p(A) − p(B) + p(A ∩ B).
Note that this has the desired marginals, e.g. q(Ā, B) +
q(Ā, B̄) = 1 − p(A), but that q(A, B̄) < 0.
The use of quasi-distributions in psychology to understand
inconsistent judgments has been advocated before, most notably by de Barros, (e.g. de Barros, 2013). In physics there
is a long history of trying to apply ‘extended’ probabilities to
understand aspects of quantum theory (see e.g. Muckenheim,
1986). Their interpretation can be challenging (Halliwell &
Yearsley, 2013) but here we shall avoid assigning any meaning to them and regard them simply as a computational tool.
So far all we have done is to express some classes of nonnormative judgments in terms an object which is superficially
similar to a joint probability distribution, but which fails to
be one in some (rather drastic) way. Why is this useful?
Well the usefulness of quasi-probability distributions lies in
part in the fact that they smoothly capture the idea of transitioning between non-normative behavior (where one or more
of the elements of the distribution is negative) to normative
behavior, where all elements are non-negative. Suppose for
example that we are performing an experiment where participants have to bet on the outcome of some gamble involving a
conjunction. If they commit a conjunction fallacy in their
reasoning, they may initially perform badly, but with corrective feedback they may revise their estimate of the probabilities of the outcomes. At some point their beliefs will
change from non-normative to normative discontinuously, but
in terms of quasi-distributions their their belief state may
change smoothly as they learn.
Quasi-distributions also allow us to define a notion of distance from normative behavior, for example one could define
the degree of non-normativity as,
∆=

∑

|q(Ai , B j ,Ck ...)| − 1

(1)

i, j,k...

which is zero if q(...) is a probability distribution and nonzero otherwise. For example, for the case above of a conjunction fallacy, ∆ = 2|p(A, B) − p(A)|, which is an appealing
measure of the non-normativity.

1388

One reasonable proposal would be to look at cases where
a set of judgements S only just fails to be normative by this
measure. One could then try to define a genuine probability
distribution p(...) and a new set of judgments S 0 which are
‘close’ to the real judgments S in the sense that p(...) is close
to q(...). If there is a sense in which this is possible then one
might regard the judgments S as almost normative, and perhaps attribute the discrepancy to some sort of response noise.
We will not pursue this further here. Instead we will make
use of another advantage of quasi-distributions, which is that
by expressing normative and non-normative behaviors in a
similar language, they suggest ways to understand how nonnormative behaviors may come about. We shall explore one
such idea in the next section.

A Simple Proposal
In a typical conjunction fallacy type experiment, participants
might be expected to have some information about the rate
of occurrence of the features A and B, and be asked to guess
the likelihood of the conjunction p(A ∩ B). It is important to
realize that even given p(A), p(B) there is no ‘correct’ answer
to this question. Rather there are a range of possible allowed
values, in other words, the marginal probabilities p(A), p(B)
under-specify the joint distribution. One extra piece of information is needed, one of the joint probabilities would do, as
would some linear combination of these. One possibility is to
consider the quantity,
SAB = p(A ∩ B) + p(Ā ∩ B̄)

(2)

which is closely related to the correlation. The difference between a normative probability distribution and a nonnormative quasi-distribution can be thought of, perhaps simplistically, as the difference between choosing a value for SAB
within or outside of the allowed range. This is important because decision makers armed only with p(A), p(B) have no
information about SAB , and there is therefore a significant
possibility that they may chose incorrectly. To put it another
way, if decision makers make an incorrect guess for the correlation between A and B, this can lead to a non-normative set
of judgments.
Now SAB is a number which varies between 1 if the events
always happen together, to 0 if the presence of one event implies the absence of the other and vice versa. One possibility
is that decision makers simply pick a value for SAB based on
a uniform prior. Another possibility is that decision makers
equate SAB with a more primitive quantity such as the similarity between A and B. (We note in passing that the idea of
similarity as essentially joint probability appears in accounts
of similarity judgment based on quantum cognitive models
(Pothos et al, 2015).)
This leads to an important prediction, which we will test
below: In the absence of any information about joint occurrence, human decision makers will use features of events such
as their similarity to construct a joint distribution. Manipulating these relationships in an experimental setting should lead

to greater or lesser degrees of violations of independence for
these events, and more generally to changes in the correlation
between events. We describe an experiment to test these ideas
in the next section.

An Experiment
Methods
58 undergraduate students from Vanderbilt University participated in the experiment online at a time of their choosing for
course credit. Participants answered questions about three
different novel categories, an animal, a natural object and a
human made object, adapted from previous work on causal
reasoning (Rehder, 2014) . Each object had three binary features (A, B, and C). For each feature participants were told
that ‘most’ members of the category had a high value for
that feature, while ‘a few’ members of the category had a low
value for the feature. Participants were not told about any relationships between the features. For example, in the Kehoe
Ant category, A = Blood iron level (high or low amount), B =
Immune system activation level (hyperactive or suppressed),
and C = Blood thickness (thick or thin).
After this, participants answered a number of questions
where they were told that a new member of the category had
been discovered, and were asked to indicate how likely they
thought it was that the new object had various features. There
were three question types: (1) how likely it was that the object had a particular feature, e.g. blood high in iron sulphate,
(2) how likely it was that the object had a combination of
features, e.g. blood high in iron sulphate and an immune system that is hyperactive, and (3) a conditional, e.g. a hyperactive immune system given that a previous test had established a high level of iron sulphate in the blood. Participants
were asked about all possible conjunctions of events, but only
about conditionals where one feature was conditioned on the
presence of a low value for another feature. The reason for
this was to reduce the overall number of questions in the experiment, particularly since our expectation was that features
would be positively correlated, which would be likely to lead
to floor or ceiling effects for the other possible conditionals.
The responses were either requested as whole numbers between 0 and 100, or as points on a 9 point Likert scale. The
response format for all questions concerning a given category
were the same, and participants were randomly assigned either the whole number or the Likert response options for each
category. After completing the likelihood judgment questions
for each category, participants were asked to rate the similarity between the feature types on a 7 point Likert scale. The
order in which the features appeared in the similarity question
(e.g. how similar is feature 1 to feature 2) was randomized
between participants for every judgment, however there were
no significant order effects in the similarity judgments.
After finishing the main part of the experiment, participants
completed an extended version of the Cognitive Reflection
Test (CRT, Frederick, 2005), but there was no significant effect of CRT and it will not be discussed further here.

1389

Results
We first wanted to examine whether we had conjunction fallacies and violations of independence in this data set. For each
pair of likelihood judgments, e.g. {A, A ∩ B} or {A, A|B} we
can perform a paired samples t-test to assess the presence of
these effects, however this procedure would generate a substantial volume of test statistics without giving much insight.
Instead we will plot the relevant likelihoods, and quote some
representative statistics. In this contribution, we only report Bayesian statistical tests that were performed using JASP
(JASP team, 2016). In particular we report Bayes factors for
the alternative versus the null hypothesis, so that values > 1
indicate evidence for the alternative hypothesis.
We begin by assessing the conjunctions. For each pair
{A, A ∩ B} we plotted the average values across participants
of the single event and the conjunction. It is useful to split
these pairs up into four different types, depending on whether
each of the events has high or low individual probability. The
results are shown in Fig 1, and we have separated out data
that comes from responses using whole numbers and from the
Likert scale. Points that lie above the diagonal correspond to
conjunction fallacies. The first thing to note is that there are
three obvious clusterings of data points. We see straight away
that pairs of the form {A, A ∩ B̄} behave as expected, there
are no conjunction fallacies. Equally the pairs {A, A ∩ B} do
not display robust conjunction fallacies (All Bayes factors for
t-tests < 1), although these data points are slightly odd in another way, which we will return to shortly. The pairs which
do display conjunction fallacies are {Ā, Ā∩B} and {Ā, Ā∩ B̄}.
The pairs of the form {Ā, Ā ∩ B} display robust conjunction
fallacies. For the whole number responses 14 out of 18 of the
Bayes factors for t-tests are > 3, and 10 out of 18 are > 10.
For the Likert responses 16 out of 18 of the Bayes factors for
t-tests are > 3, and 11 out of 18 are > 10. These are the pairs
for which conjunction fallacies are typically expected, with
one likely and one unlikely event. In contrast the presence of
conjunction fallacies in the pairs of the form {Ā, Ā ∩ B̄} are
less expected. For the whole number responses none of the
Bayes factors for t-tests are > 3, but for the Likert responses
7 out of 18 of the Bayes factors for t-tests are > 3, and 5 out
of 18 are > 10. We will return to why this may be so later.
Overall then, we have good evidence for conjunction fallacies in some of these judgments, for both response types.
Note also that there do not appear to be large systematic differences between the data obtained from different response
modes, which is reassuring.
Next we check for violations of independence. Note
that these violations are not necessarily non-normative, since
no information about the relationship between features was
given to participants. However systematic violations of independence would still be a surprising finding. We proceed as
for the conjunctions, plotting the pairs {A, A|B̄} and {Ā, Ā|B̄}
separately and also separating out whole number and Likert
responses. The results are shown in Fig 2. Independence
would be indicated by data points lying on the diagonal.

Figure 1: Plots of likelihood judgments for conjunctions against
single constituent events. Data points above the diagonal indicate
conjunction fallacies. a) Likert scale responses. b) Whole number
responses.

For the pairs of the form {A, A|B̄} all points appear to lie
below the diagonal, and this is confirmed by Bayesian t-tests.
For the whole number responses and for the Likert responses
all Bayes Factors are > 10.
For the pairs of the form {Ā, Ā|B̄} all points appear to lie
above the diagonal, and this is confirmed by Bayesian t-tests.
For the whole number responses 13 out of 18 Bayes Factors
are > 3, and 7 out of 18 are > 10. For the Likert responses
we also have 13 out of 18 Bayes Factors > 3, and 7 out of 18
> 10. Again overall there is good evidence for violations of
independence in this data.
More specifically, the conjunctions and the conditionals
point to similar behavior - namely participants appear to believe that there is strong correlation between the different features, such that “high” or “low” values of these features are
likely to occur together.
Now we turn to the question of whether the perceived similarity between features mediates the correlations and violations of independence.
We begin with the correlation, defined for each pair of features A, B as p(A ∩ B) + p(Ā ∩ B̄) − p(A ∩ B̄) − p(Ā ∩ B). We
ran a Bayesian ANOVA with the perceived similarity as the

1390

participants who gave higher similarity ratings (40-66). In addition, for the lowest similarity rating a higher than expected
proportion of participants giving this rating (5 out of 8 for the
Likert scale and 6 out of 9 for the whole numbers) had the
highest possible CRT score. This is significant because if two
events, each of which has an individual probability of 0.8, are
independent, then the expected correlation is 0.32, which is
in fact close to the observed value for a similarity rating of 1
in the whole numbers condition.
Next we analyze the violations of independence. We compute a violation ‘score’ which is just the sum of the absolute
value of the difference between the conditional and the single event, e.g. |p(A|B) − p(A)| for all the conditionals we
measured. Again we ran a Bayesian ANOVA, with perceived
similarity as the independent variable.
For the whole number responses, the results of the
Bayesian ANOVA show that a model including perceived
similarity is preferred over the null model (BF10 ∼ “∞”). For
the Likert responses the results of the Bayesian ANOVA show
that a model including perceived similarity is again preferred
over the null model (BF10 > 1010 ). Analysis of effects for
both ANOVAs are given in Table 2.
In Fig 3b we plot the violation of independence score as
a function of perceived similarity. Again we transform the
values for the Likert scale responses allowing us to plot them
on the same axes. The pattern is qualitatively similar to that
for the correlation; a general trend towards larger violations
of independence for higher values of the perceived similarity.
Figure 2: Plots of likelihood judgments for conditionals against the
conditioned events. Data points on the diagonal indicate independence. Data points off the diagonal indicate violations of independence. a) Likert scale responses. b) Whole number responses.

independent variable. Note that we collapse across features
and scenarios here, since we have similarity data for each individual feature pair.
For the whole number responses the results of the Bayesian
ANOVA show that a model including perceived similarity is
preferred over the null model (BF10 > 107 ). For the Likert responses the results of the Bayesian ANOVA also show that a
model including perceived similarity is preferred over the null
model (BF10 > 103 ). Analysis of effects for both ANOVAs
are given in Table 1.
We plot in Fig 3a below the correlation as a function of
the similarity. Since we saw in the analysis of the conjunctions and conditionals there were no obvious differences between the response types we have converted the Likert scale
responses to numbers in the range 0-100 and plotted them on
the same axis. This lets us establish that the same qualitative
pattern holds for both response types, namely there is some
apparent decrease in correlation for very small similarity ratings, but then a robust increase in correlation with increasing
perceived similarity. The reason for the decrease in correlation for small similarity ratings is unclear, although it is worth
noting that the number of participants who gave similarity
ratings from 1-3 is small (7-11) compared with the number of

Table 1: Analysis of effects for Bayesian ANOVA of Correlation
Whole Numbers
Effect
p(incl)
Similarity 0.500

p(incl|data)
1.000

BFInclusion
3.01 × 107

Likert Scale
Effect
p(incl)
Similarity 0.500

p(incl|data)
0.999

BFInclusion
1.58 × 103

Table 2: Analysis of effects for Bayesian ANOVA of Violations of
Independence
Whole Numbers
Effect
p(incl)
Similarity 0.500

p(incl|data)
1.000

BFInclusion
“∞”

Likert Scale
Effect
p(incl)
Similarity 0.500

p(incl|data)
1.000

BFInclusion
3.08 × 1010

Overall the data provide strong support for our proposal
that perceived similarity mediates perceptions of correlation
and violations of independence in probabilistic judgments. It
is also worth noting that there are strong positive correlations
between the correlation function and violations of independence, (Pearson’s rho = 0.481, BF10 > 1014 for whole number
responses, Kendall’s tau = 0.345, BF10 > 1013 for the Likert
responses.)

1391

ments, participants are given extra information about the features in the form of causal relationships between them. Judgments about correlations in this case could then reasonably
be interpreted as meaning participants believe the presence of
one feature caused another. This work suggests that care is
needed when interpreting these studies - participants may believe that features are correlated even in the absence of causal
relationships, which may lead to overestimation of perceived
causality. Future work should explore this possibility.
Finally, the results of this study suggest quasi-distributions
may be a valuable way of thinking about non-normative reasoning, and we are hopeful that this approach may be used
fruitfully in other areas. One important task is the development of a learning model which works directly with quasidistributions. This could help us understand how people learn
to avoid committing probabilistic fallacies (Nilsson, 2008).

Acknowledgments
JMY and JST were supported by NSF grant SES-1556415.

References

Figure 3: Plots of the correlation and degree of violation of independence against the perceived similarity. a) Correlation as a function of
perceived similarity for the whole number responses (blue line) and
the Likert scale responses (red line.) b) Violations of independence
as a function of perceived similarity for the whole number responses
(blue line) and the Likert scale responses (red line.)

Conclusions and Future Directions
We have shown that quasi-probability distributions can be
used to encode certain sets of probabilistic judgments which
are non-normative, in the sense that they cannot be regarded as marginals of a joint probability distribution. Quasidistributions generalize regular probability distributions in
that they can have negative elements. By themselves these
do not provide any great insight into non-normative behavior,
but the fact that one can define analogues of properties such
as correlations for quasi-distibutions lets us examine the ways
in which sets of judgments fail to be normative, and perhaps
suggest some possible reasons why. We proposed that in the
absence of information about joint occurrence, human decision makers might use properties such as the similarity between features to set the correlation, which we demonstrated
experimentally. Similarity does seem to mediate correlation
and violations of independence. We also showed that these
results are largely independent of the response format.
These findings are particularly significant for attempts to
assess the normative status of human causal inference using
stimuli of this nature (e.g. Rehder, 2014). In these experi-

de Barros, JA (2013). Decision making for inconsistent expert judgments using negative probabilities. In, Atmanspacher, H et al (Eds.) Proceedings of the Sixth
Quantum Interaction Symposium. LNCS, 8369, 257269.
Busemeyer, JR & Bruza, P (2011). Quantum models of cognition and decision. CUP: Cambridge, UK.
Fine, A. (1982). Joint distributions, quantum correlations,
and commuting observables. Journal of Mathematical
Physics, 23, 1306-1310.
Frederick, S (2005). Cognitive reflection and decision making. Journal of Economic Perspectives. 19, 25-42.
Gigerenzer, G, Hertwig, R & Pachur, T (eds.) (2015). Heuristics: The foundations of adaptive behavior. (OUP).
Halliwell, JJ & Yearsley, JM. (2013). Negative probabilities,
Fine’s theorem and linear positivity. Phys. Rev. A 87,
022114.
JASP Team. (2016). Jasp. https://jasp-stats.org
Muckenheim, G. (1986). A review of extended probabilities.
Phys. Rep. 113(6), 337-401.
Nilsson, H. (2008). Exploring the conjunction fallacy within
a category learning framework. Journal of Behavioral
Decision Making. 21, 471-490.
Pothos, E. M. & Busemeyer, J. R. (2013). Can quantum probability provide a new direction for cognitive modeling?
Behavioral & Brain Sciences, 36, 255-327.
Pothos, EM, Barque-Duran, A, Yearsley, JM, Trueblood, JS,
Busemeyer, J, & Hampton, JA. (2015). Progress and
current challenges with the quantum similarity model.
Frontiers in Psychology, 6, 205.
Rehder, B (2014). Independence and dependence in human
causal reasoning. Cognitive Psychology, 72, 54-107.
Tversky, A., & Kahneman, D. (1983). Extensional versus intuitive reasoning: The conjuctive fallacy in probability
judgment. Psychological Review, 90, 293-315.

1392

