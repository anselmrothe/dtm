Relational Concept Learning via Guided Interactive Discovery
John D. Patterson1 (jpatter4@binghamton.edu)
David Landy2 (dlandy@indiana.edu)
Kenneth J. Kurtz1 (kkurtz@binghamton.edu)

1

2

Department of Psychology, Binghamton University, 4400 Vestal Parkway East, Binghamton, NY 13905 USA
Department of Psychological and Brain Sciences, Indiana University, 1101 East 10th Street Bloomington, IN 47405 USA
Abstract

categories need only share a relational structure to belong,
members of a category can be quite featurally disparate
(e.g., your sibling and your dog’s sibling hopefully don’t
look alike). In this way, relational category members share
analogical similarity. It should be noted that relational
categories are not an idiosyncratic facet of category learning
- roughly half of the 100 highest frequency nouns are
relational (Asmuth & Gentner, in press). Thus, to
understand human category learning generally, it is critical
to understand relational category learning.
A question that bears both theoretical and applied import
is: how do we come to acquire relational category
knowledge? Previous research has explored the potential for
comparison to promote relational discovery and transfer.
This work follows from a large body of research showing
the benefits of comparison to analogical transfer (Gick &
Holyoak, 1983; Loewenstein, Thompson, & Gentner, 1999;
see also Alfieri, Nokes-Malach, & Schunn, 2013 for a metaanalysis and review). Studies of comparison with relational
categories have largely corroborated findings from the
analogical transfer literature; presenting same-category pairs
(Patterson & Kurtz, 2015) or a mixture of same- and
different-category pairs (Kurtz, Boukrina, & Gentner, 2013)
during training leads to enhanced learning and transfer over
sequential item presentations. The power of comparison can
be understood through a process of structural alignment
(Markman & Gentner, 1993). Comparing instances
facilitates the alignment of their parallel relational
predicates. This serves to highlight common relational
structure that is not salient when either instance is
considered in isolation. Additionally, comparison facilitates
abstraction, which promotes later analogical retrieval and
transfer.
As many of the core concepts taught in educational
settings are relational in nature (e.g., evolution by natural
selection, Newton’s laws), relational categories represent a
key bridge between cognitive and educational research
(Goldwater & Schalk, 2016). Thus, investigating how
relational categories are best learned can both palpably
advance educational techniques and further basic,
theoretical understandings. In the present work, we draw on
an innovative area of education research that serves as a
promising avenue for enhancing relational category
learning: discovery learning. Discovery learning generally
refers to unsupported learning where the learner actively
constructs their understanding of some target information
using only a set of materials or a task environment. Though
many flavors of discovery have been the subject of study, a

A key goal in both education and higher-order cognition
research is to understand how relational concepts are best
learned. In the current work, we present a novel approach for
learning complex relational categories – a low-support,
interactive discovery interface. The platform, which allows
learners to make modifications to exemplars and see the
corresponding effects on membership, holds the potential to
augment relational learning by facilitating self-directed,
alignably-different comparisons that explore what the learner
does not yet understand. We compared interactive learning to an
identification learning task. Participants were assessed on their
ability to generalize category knowledge to novel exemplars
from the same domain. Although identification learners were
provided with seven times as many positive examples of the
category during training, interactive learners demonstrated
enhanced generalization accuracy and knowledge of specific
membership constraints. Moreover, the data suggest that
identification learners tended to overgeneralize category
knowledge to non-members – a problem that interactive learners
exhibited to a significantly lesser degree. Overall, the results
show interactive training to be a powerful tool for
supplementing relational category learning, with particular
utility for refining category knowledge. We conclude with
implications of these findings and promising future directions.
Keywords: relational categories; structural alignment;
discovery learning; category learning; generalization

Introduction
A key aim of higher-order cognition research is to
understand the mechanisms that undergird the ability for
humans to acquire and use abstract, complex categories. The
literature in concepts and categories research has primarily
been devoted to the study of attribute categories –
categories whose members possess a set of independent
features by which they can be classified. Research on
attribute category learning has unequivocally advanced our
understanding of human concept acquisition and its many
facets.
However, much of the category knowledge we possess is
not reducible to knowledge of specific attributes – myriad
concepts such as positive feedback loop are abstract,
attribute-agnostic, and dependent on relationships rather
than features. Fittingly, an increasing amount of empirical
attention has been granted to the study of relational
categories (Gentner & Kurtz, 2005; Markman & Stilwell,
2001). Relational categories are rule-like categories whose
members share a common relational structure characterized
by extrinsic relationships between objects and/or attributes
(e.g., protection, sibling, reciprocity). Because relational

907

common theme in the literature is that completely unassisted
discovery approaches are not effective for learning (Mayer,
2004; for a meta-analysis see Alfieri, Brooks, Aldrich, &
Tenenbaum, 2011). Among other reasons, the large
cognitive load incurred by needing to generate and explore
hypotheses (Sweller, 1988) while metacognitively
maintaining an idea of what is known and what needs to be
known (Kirschner, Sweller, & Clark, 2006) can present
challenges for the approach. However, when some guidance
is introduced (such as direct instruction – e.g., Chen &
Klahr, 1999), discovery learning can be a highly effective
tool (Alfieri et al., 2011).
Discovery learning has the clear potential to augment the
learning of complex relational concepts in educational
settings – particularly when the target category is abstract or
when classroom instruction is subpar. With a basic
understanding of the target category, an interactive
environment that enables learners to freely create or modify
category exemplars and receive dynamic category
membership feedback ought to enhance category
knowledge, notably through three mechanisms. First, it
would allow learners to engage in self-directed exploration
that is specifically catered to what they do not understand or
need further clarification on. The opportunity to select
exemplars for study has been shown to confer benefits on
rule-based category learning (e.g., Markant & Gureckis,
2014). Second, the dynamic membership feedback provided
by the task interface would implicitly encourage
explanations about the causes underlying the effects of
learners’ modifications. Such self-explanation has been
demonstrated to be a powerful facilitator of concept
acquisition (e.g., Chi, de Leeuw, Chiu, & LaVancher, 1994).
Third, critically, a learning environment such as this should
strongly engage analogical processing faculties. In
modifying an exemplar and receiving membership feedback,
the learner effectively creates a temporally juxtaposed
comparison between the item’s new state (s) and s-1.
Modifications that do not break membership create
alignably-different, same-category comparisons. These
comparisons should promote highlighting of common
relational structure and facilitate abstraction. Conversely,
modifications that do break membership create alignablydifferent different-category comparisons, which critically
should serve to highlight membership-relevant relations.
In the present work, we explore the efficacy of a lowsupport, interactive discovery learning tool to promote the
learning of complex relational categories. To avoid effects
of domain knowledge, we created an artificial, multiconstraint category that served as the target of learning.
Advised by the discovery learning literature and pilot data,
we gave participants some support to reduce cognitive load.
This support was a clear, but quite abstract, definition of the
category that was given to all learners immediately prior to
the learning phase. In the interactive condition, participants
were given a computerized interface where they could
engage in self-directed exploration of three examples of the
category. We contrasted interactive training with an

identification learning control in which learners were
exposed to a larger number of exemplars in the context of a
member identification task. To evaluate the effectiveness of
the interactive learning mode, we compared the two learning
conditions on their ability to generalize category knowledge
to novel exemplars. We predicted interactive learning would
lead to enhanced generalization performance.

Method
Participants
Seventy undergraduates from Binghamton University
participated to partially fulfill a course requirement.

Materials
The training and generalization stimuli consisted of
arrangements of blocks that varied in their size (small,
medium, or large), color (white, gray, or dark brown),
border color (black or distinctive blue), and spatial location
(see Figure 1 for examples). The ‘matched containment’
concept instantiated by these blocks was quite complex.
Category members were characterized by the presence of
three or more blocks that obeyed all of the following
constraints: (1) the blocks were aligned vertically or
horizontally, (2) two of the involved blocks were special by
sharing a distinctive blue border color, (3) the special blocks
were exactly matched in their attributes, (4) the special
blocks contained/flanked at least one additional ‘normalbordered’ block in the lineup, and (5) all of the contained,
normal blocks matched the special blocks on at least one
attribute (i.e., color, size, or both).
Twenty-one category members and 21 non-members were
used as the stimuli for the identification condition. All
members contained the category-defining core – constituted
by either three (Length 3 [Len3]; two flanking, one flanked)
or four (Length 4 [Len4]; two flanking, two flanked) objects
– and one additional distracter block, such that all examples
had length + 1 blocks. The category core and distracter
block were varied in their attributes (i.e., orientation of core
[vertical, horizontal], spatial location, color, size) across
examples to ensure an attribute-based solution was not
available.
The members were comprised of six item types, each
which instantiated the special-normal match constraint in a
unique way. For both Len3 and Len4 stimuli, there were
items whose flanked object(s) matched based on (1) color,
(2) size, (3) or both color and size. For Len4 stimuli there
were also items whose flanked objects consisted of (4) one
color and one size match, (5) one both and one color match,
or (6) one both and one size match. The item breakdown can
be seen in Table 1. Since the Len4 stimuli included
matching types that were distinct from those present in the
Len3 stimuli, the Len4 examples were weighted on types 46 to ensure comprehensive coverage of the category for
identification learners. The non-member set used was
programmatically generated by randomly sampling and
arranging blocks, with the constraint that two of the blocks

908

had to possess the distinctive border. Number of blocks was
matched between the members and non-members. The
interactive condition was given considerably fewer
examples: one Len3 color match and two Len4 examples,
each which had one color match and one size match.
To evaluate participants’ ability to generalize their
knowledge, a distinct set of 30 members and 30 nonmembers was created. The members were sampled from
several match types. Critically, non-members consisted of
items that violated the constraints of membership in several
focal ways (see Table 2 for generalization item breakdown).
As knowledge of the specific constraint that was violated
was necessary to get each of these items correct, they served
as a stringent test of category knowledge.

Condition-specific instructions for the interactive group
informed learners they would receive (1) an ‘exploration
zone’ that would tell them if the objects inside were
currently in a Togging situation and (2) a set of ‘exploration
tools’ that could be used to modify the objects/attributes in
informative ways. They were then told they could gain an
understanding by paying attention to modifications that
break the Togging situation and by trying to create novel
Togging situations. To combat confirmation bias – as
piloting revealed this to be a considerable impediment to
learning – subjects were also told to try to prove their ideas
about Togging wrong by fully testing them. Lastly, subjects
were informed they would be tested later and that they
would have seven minutes with the learning task. Following
these general task instructions, interactive learners then read
a brief tutorial that described the ways they could modify
the examples with the exploration tools.
Table 2: Number of exemplars by length, type, and
membership in the generalization assessment.

Figure 1: Eight example stimuli from the training
(identification) and generalization phases.

Design and Procedure
Participants were randomly assigned to either identification
(n = 39) or interactive (n = 31) learning conditions in a
between-subjects design. Due to a spreadsheet error,
condition assignments were slightly imbalanced.
In the pre-training instructions, all subjects were first
informed they would be learning about something called a
‘Togging situation’ – the arbitrary category label – before
being provided with an abstract definition of the category:
“A Togging situation occurs when (1) there are two
matching special objects with other objects in the space
between them; and (2) all the objects in the space between
have at least one thing in common with the special objects.”
Subjects were then told they were to gain a full and clear
understanding of Togging situations by engaging in the
upcoming learning experience.

Instructions in the identification condition informed
learners they would receive a series of frames with objects
inside, some of which would have a Togging situation. They
were told they could gain an understanding by paying
attention to the frames and feedback they received and by
learning to identify which frames contained a Togging
situation. The identification learners also received an
analogous instruction to try to prove their ideas about
Togging wrong by fully considering the frames and
feedback on each trial. Finally, identification learners were
informed of the upcoming test.
To remind participants, and guide learning, both
conditions were again given the abstract category definition
immediately prior to the learning task.

Table 1: Number of category members by length and type
for identification training.

Training – Interactive Condition The training interface
can be seen in Figure 2. In the center of the interface was an
‘exploration zone’ that dynamically checked whether the
constraints of category membership were met by the objects
inside. The zone’s border color turned green if the
constraints were met, and red if not. A textual notification
above the zone regarding membership mirrored the color
feedback. The exploration zone started with a positive
example of the category, randomly selected from the three

909

positive examples that were provided to the interactive
group.
Participants could freely engage the training interface in
five distinct ways. First, clicking the ‘new’ button cycled
through the three positive examples. The button allowed
learners to reset the exploration zone to a positive example
if they became lost with their current discovery path and
also get experience with the three different instantiations of
the category. Second, double clicking a block would change
its color – cycling in order through the three colors with
each double click. Third, clicking and dragging the bottom
right corner of a block diagonally allowed participants to
stretch or shrink it to one of the three discrete sizes. Fourth,
clicking and dragging elsewhere on a block allowed
participants to change its spatial location. Lastly,
participants could add or remove objects from the
exploration zone. To the left of the zone was a space
containing additional normal blocks that varied in their size
and color. Participants could bring additional blocks into the
exploration zone or remove any of the blocks from the zone
to this space. This allowed participants to: (1) swap blocks
to change attributes, (2) simplify the example in the
exploration zone, and (3) create more elaborate examples of
the category that involved more objects.

examples of the category – seven times as many as were
provided to interactive learners. These 21 positive cases
were combined with the 21 negative cases in a random order
for each participant. Participants made one pass through the
set. On each trial, the participant was presented with an item
and two response buttons (“Togging situation”, “Not a
Togging situation”). The amount of time to study the
example and make a response was unconstrained.
Participants selected their response using the mouse and
were given feedback indicating if they were (in)correct and
whether the item was (not) an example of a Togging
situation. Feedback was presented for 2.5s before moving
on to the next trial.
Generalization Assessment Following the learning phase,
all participants were given a generalization assessment to
assay their ability to both identify category members and
correctly reject near-miss non-members. The 60
generalization items were presented in a randomized order
for each participant. The trial structure of the generalization
phase was identical to that of identification training, except
no feedback was given.

Results
Training
All except three learners in the identification condition (M =
.83, SE = .02) performed reliably above chance. Data from
these non-learners were retained in the subsequent analyses
for two reasons: (1) the general pattern of results did not
change when their data were excluded, and (2) there was not
a comparable basis for excluding interactive learners.
Identification training took 3-8 minutes (M = 3.89 minutes,
SE = .14). Though there was a wide range, time spent during
training did not predict generalization accuracy in a trialwise logistic regression (β = -0.005, SE = 0.01, Z = -.44, p =
.66).
Interactive learners made between 151 and 321
manipulations (M = 227.21, SE = 6.60). Number of
manipulations, however, did not predict generalization
accuracy (β = -0.0001, SE = 0.001, Z = -.12, p = .91),
suggesting that the quantity of manipulations was not
critical. However, higher rates of crossover – the proportion
of the manipulations that switched the state from member to
non-member (or vice versa) – were associated with higher
generalization accuracy (β = 3.05, SE = 0.86, Z = 3.54, p <
.001), suggesting that generating alignably-different
different-category comparisons is key for getting the most
out of the platform.

Figure 2: Visual of the interactive workspace.
Since there were many ways participants could interact
with the interface, they were provided with a ‘how to’ cheatsheet to the right of the exploration zone. During the task,
participants had seven minutes for self-directed
investigation of the category. A timer in the upper left
corner of the interface showed how much time remained. To
encourage participants to stay on task, a query was
presented below the text notification of membership. The
query corresponded to the current state of the objects in the
exploration zone. When category constraints were met, the
query asked participants if they could, “find a way to break
the Togging situation.” When the constraints were not met,
it asked if they could “find a way to make a Togging
situation again.” Besides this general query, no additional
direction was given during the task.

Generalization Accuracy
Trial-wise accuracy data were modeled with logistic
regressions. Using condition as the lone predictor, the main
analysis yielded the key finding that interactive learning (M
= .73, SE = .01) significantly augmented generalizable
category knowledge over identification learning (M = .67,
SE = .01); β = 0.29, SE = 0.07, Z = 4.27, p < .001.

Training – Identification Condition Learners in the
identification group were directly provided with 21

910

To further probe the effect of condition, we conducted a
follow-up analysis to see how each condition performed on
members and non-members. To this end, we used condition,
item membership (1, 0), and their interaction as predictors.
Interestingly, the regression revealed a highly reliable crossover interaction between condition and item membership
(see Figure 3; β = 1.35, SE = 0.18, Z = 7.70, p < .001). The
interaction was marked by a reliable enhancement for the
identification group on category members (identification: M
= .93, SE = .01; interactive: M = .87, SE = .01; β = -0.63, SE
= 0.15, Z = -4.20, p < .001), but a reliable enhancement for
the interactive group on non-members (identification: M =
.41, SE = .01; interactive: M = .59, SE = .02; β = 0.72, SE =
0.09, Z = 8.01, p < .001). It should be noted that average
accuracy on non-members was generally low. This is
directly attributable to their more challenging nature.
Contrasted with the member set, on which it was possible to
successfully identify all items using knowledge of any
single relational constraint, the non-member set consisted of
items that each focally violated a constraint of membership.
To perform successfully on these, participants required
knowledge of the specific constraint that was violated in
each instance. Thus, performance on the non-members
serves as a proxy for learners’ understanding of the
category’s composite constraints. While learners still had
much to learn about the category, low means should not be
interpreted to mean that performance was at chance or
random in nature. Rather, the high accuracy observed for
members suggests that learners took a limited understanding
of the constraints of membership and overgeneralized it to
non-members.
Given the curious reversal in the effect of condition
between levels of item membership, we were prompted to
explore the possibility that identification learners were more
likely to overgeneralize category knowledge, which
ostensibly would explain this pattern of results. We used
two signal detection theory measures to this end: d’ and β.
d’ is a measure of sensitivity to the signal when present that
reflects hit rate on signal trials while adjusting for false
alarm rate on noise trials. A higher d’ indicates a greater
sensitivity to the underlying signal (category members). β is
a likelihood ratio that reflects response bias. A β of 1
indicates learners were neither biased towards nor against
extending the category label, whereas β below or above 1
indicates a bias towards extending or not extending the
label, respectively. d’ and β were computed for each subject
and the values for each were then predicted by condition in
separate linear regressions. Despite showing increased
accuracy for members, identification learners were not more
sensitive, owing to a significantly increased false alarm rate
(identification: M = 0.58, SE = .04; interactive: M = 0.41,
SE = .04; β = -0.17, SE = 0.05, t(68) = -3.19, p < .01). In
fact, a numerical advantage in d’ favored interactive learners
but did not reach significance (identification: M = 1.46, SE
= .09; interactive: M = 1.71, SE = .21; β = 0.24, SE = 0.21,
t(68) = 1.16, p = .25). Additionally, identification learners
were found to be significantly more biased towards

endorsing items as members – showing lower β than their
interactive counterparts (identification: M = 0.34, SE = .06;
interactive: M = 0.61, SE = .09; β = 0.27, SE = 0.11, t(68) =
2.50, p < .05). Collectively, these measures indicate that the
identification group’s enhanced accuracy for members was
not the result of greater sensitivity. Instead, it appears to be
a byproduct of a liberal extension of a limited understanding
of the category, relative to interactive learners.

***
***

Figure 3: Generalization performance by condition and item
membership. Error bars represent +/- 1 SE.

Discussion
The primary goal of this study was to evaluate the potential
for a novel, interactive discovery platform to facilitate the
acquisition of a complex relational concept. Consistent with
our hypothesis, our findings resolutely show that interactive
training is an effective way to affect relational category
knowledge. Compared to identification training – a learning
mode organic to both category learning experiments as well
as common educational practices – interactive learners
exhibited an enhanced ability to generalize and enriched
knowledge of specific membership constraints.
The results of this study inform both basic and applied
interests. Our data suggest that our interactive platform can
aptly supplement learning when complex, abstract relational
categories are the target of learning. On an intriguing note,
this paradigm appears to possess a distinct utility for
combating overgeneralization by helping learners to explore
and refine the boundaries of membership. It should be noted
these advantages accrued despite the minimalistic support
that was given (compared to other guided discovery
approaches; e.g., Chen & Klahr, 1999), the short amount of
time allotted for learning, and the transfer appropriate
processing advantage granted to identification learners in
the shared task between training and test.
A limitation of this study is the use of randomly generated
non-members in the identification training condition. As a
function of the random generation, they tended to be slightly
more entropic than the positive examples. This exposes a
possible deflationary account of these findings – that
identification learners may have simply learned to
differentiate more and less entropic examples from each

911

other, which might explain poorer generalization
performance. However, this account is unlikely for two
main reasons. First, learners were provided a definition of
the relational concept not once, but twice, prior to training.
A basic understanding of the category should have guided
learners to seek information that extended that
understanding, not part with it altogether. Second, if learners
acquired and used an entropy strategy during training, the
effects of this should have been notable in the generalization
data. Unlike the training set, non-members in the
generalization phase were orderly. If learners adopted an
entropy strategy, they would likely use it before realizing,
later in the generalization phase, that there were not any
entropic cases – at which point they might shift to the
principle-relevant knowledge they acquired through the
definition and learning experience. If this occurred, we
should expect better performance later in the generalization
phase. To investigate this possibility, we compared
performance on the first 30 trials to the second 30 trials of
generalization for identification learners. The difference was
non-significant (p = .81), suggesting identification learners
engaged the task the way we intended. Nevertheless,
planned research using yoked controls will provide more
definitive evidence.
Further work will be necessary to specify the cognitive
processes behind the benefits of interaction in relational
category learning. Consistent with Markant & Gureckis
(2014), the effect of actively selecting modifications that
supplement one’s current understanding is likely to be
critical. However, our next main pursuit in developing this
platform is to more deeply explore the potential for analogy
and comparison to serve as the engine for interactive
relational category learning. Much of the power of this
learning paradigm likely follows from its facilitation of
informative, user-created comparisons with alignable
differences – a possibility echoed by the higher
generalization accuracy associated with higher rates of
category crossover. To the extent that this underlies its
utility, providing learners with co-presented exemplars that
are dynamically linked in their manipulations should
promote enhanced generalization and transfer, and possibly
serve to shorten acquisition time. Contrasting this
interactive approach with static comparisons and other
educational tools, such as the explicit elicitation of selfexplanations, will be integral to the evaluation of this tool’s
potency in upcoming research.

Alfieri, L., Nokes-Malach, T. J., & Schunn, C. D. (2013).
Learning through case comparisons: a meta-analytic
review. Educational Psychologist, 48(2), 87-113.
Asmuth, J., & Gentner, D. (2017). Relational categories are
more mutable than entity categories. The Quarterly
Journal of Experimental Psychology, 70(10), 2007-2025.
Chi, M. T. H., DeLeeuw, N., Chiu, M., & LaVancher, C.
(1994). Eliciting self-explanations improves
understanding. Cognitive Science, 18, 439–477.
Chen, Z., & Klahr, D. (1999). All other things being equal:
Acquisition and transfer of the control of variables
strategy. Child Development, 70, 1098-1120.
Gentner, D., & Kurtz, K. J. (2005). Relational categories. In
W. K. Ahn, R. L. Goldstone, B. C. Love, A. B. Markman,
& P. W. Wolff Categorization inside and outside the
laboratory: Essays in honor of Douglas L. Medin.
Washington, DC: American Psychological Association.
Gick, M. L., & Holyoak, K. J. (1983). Schema induction
and analogical transfer. Cognitive Psychology, 15(1), 138.
Goldwater, M. B., & Schalk, L. (2016). Relational
categories as a bridge between cognitive and educational
research. Psychological Bulletin, 142(7), 729-757.
Kirschner, P.A., Sweller, J., & Clark, R.E. (2006). Why
minimal guidance during instruction does not work: An
analysis of the failure of constructivist, discovery,
problem-based, experiential, and inquiry-based teaching.
Educational Psychologist, 41, 75-86.
Kurtz, K. J., Boukrina, O., & Gentner, D. (2013).
Comparison promotes learning and transfer of relational
categories. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 39(4), 1303–1310.
Loewenstein, J., Thompson, L., & Gentner, D. (1999).
Analogical encoding facilitates knowledge transfer in
negotiation. Psychonomic Bulletin & Review, 6(4), 586597.
Markant, D. B., & Gureckis, T. M. (2014). Is it better to
select or to receive? Learning via active and passive
hypothesis testing. Journal of Experimental Psychology:
General, 143(1), 94.
Markman, A. B., & Gentner, D. (1993). Structural
alignment during similarity comparisons. Cognitive
Psychology, 25(4), 431-467.
Markman, A. B., & Stilwell, C. H. (2001). Role-governed
categories. Journal of Experimental & Theoretical
Artificial Intelligence, 13, 329– 358.
Mayer, R. E. (2004). Should there be a three-strikes rule
against pure discovery learning?. American
Psychologist, 59(1), 14-19.
Patterson, J.D., & Kurtz, K.J. (2015). Learning mode and
comparison in relational category learning. Proceedings
of the 37th Annual Conference of the Cognitive Science
Society.
Sweller, J. (1988). Cognitive load during problem solving:
Effects on learning. Cognitive Science, 12, 257-285.

Acknowledgments
We greatly thank David Brokaw for his help with
programming and the Learning and Representation in
Cognition (LaRC) lab for their valuable input.

References
Alfieri, L., Brooks, P. J., Aldrich, N. J., & Tenenbaum, H.
R. (2011). Does discovery-based instruction enhance
learning?. Journal of Educational Psychology, 103(1), 118.

912

