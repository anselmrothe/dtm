UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Training Principle-Based Self-Explanations: Transfer to New Learning Contents

Permalink
https://escholarship.org/uc/item/4w5528f4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Renkl, Alexander
Solymosi, Judith
Erdmann, Michael
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Training Principle-Based Self-Explanations:
Transfer to New Learning Contents
Alexander Renkl (renkl@psychologie.uni-freiburg.de), Judith Solymosi (judith.solymosi@gmail.com)
University of Freiburg, Germany, Department of Psychology, Engelbergerstaße 41,
D-79085 Freiburg Germany

Michael Erdmann (michael.erdmann@web.de)
St. Ursula-Gymnasium Freiburg, Eisenbahnstraße 45
D-79098 Freiburg Germany

Vincent Aleven (aleven@cs.cmu.edu)
Human-Computer Interaction Institute, School of Computer Science, Carnegie Mellon University
5000 Forbes Ave, Pittsburgh, PA 15213 USA
Abstract
The present study tested the transfer effects of a short training
intervention on principled-based self-explanations. The
intervention used fables as well as mathematics examples and
problems as "exemplifying" domains for training such selfexplanations. The effects were tested in a new learning
environment about attribution theory and feedback messages.
In this experiment, 58 German high-school students were
randomly assigned to the self-explanation training condition
or a control condition (i.e., training of mnemonic strategies).
The learning outcomes from the learning environment about
attribution theory and feedback did not significantly differ
between groups. However, those students who also reported
to have applied the strategies from the training intervention
actually showed the best learning outcomes. Overall, the selfexplanation training intervention "convinced" just part of the
learners to engage in principle-based self-explanations in a
new environment. There seems to be two options to achieve
more reliable effects by future training interventions: The
learners have to be prompted more clearly that they should
employ the learned strategies in the transfer learning
environment or the short-term training intervention should be
extended to have a stronger effect on spontaneous strategy
application.
Keywords: Self-explanation, training intervention, transfer.

Introduction
If students acquire cognitive skills, these skills should
ideally be based on an understanding of the underlying
domain principles (e.g., Chi & VanLehn, 2010; Goldstone
& Day, 2012; Renkl, 2002). Such a conceptual
underpinning facilitates the transfer of the acquired skills to
new problems for which a modified solution procedure has
to be found. In addition, deep conceptual understanding is
considered to facilitate further procedural learning (e.g.,
Rittle-Johnson, Siegler, & Alibali, 2001). In many learning
situations, however, the learners acquire cognitive skills
without understanding the corresponding domain principles.
Thus, a major goal of instruction is to facilitate meaningful
learning that strives for a principle-based understanding.
One way to induce a principle orientation for meaningful
learning is to prompt learners for principle-based selfexplanations (Kalyuga, 2011). For example, Atkinson,

Renkl, and Merrill (2003) encouraged learners to determine
the principle (here: probability rule) behind each step of a
worked example. This prompting procedure fostered
transfer to isomorphic and to novel problems, for which
modified solution procedures had to be found. Principlebased prompting also worked in "verbal" domains without
mathematical solution procedures. For example, Schworm
and Renkl (2007) provided principle-based prompts to
learners when they studied video examples of sound
scientific argumentation. Such prompts help determine the
argumentative structures and, thereby, the argumentation
skill. Whereas the Atkinson et al. and the Schworm and
Renkl studies analyzed example-based learning, Aleven and
Koedinger (2002) showed that principle-based selfexplanation prompts also enhance learning by problemsolving (here: in the intelligent tutorial environment
Cognitive Tutor). Further, there are numerous studies
affirming the positive effects of prompting principle-based
self-explanations (e.g., Berthold & Renkl, 2009; Conati &
VanLehn, 2000; Renkl, 1997; Schworm & Renkl, 2006).
The successful prompting procedures have, however,
significant disadvantages. First, when prompts in the form
of external guidance are provided, there is no guarantee that
the learners do not fall back on rote learning when the
prompts are not present anymore (cf. Wecker & Fischer,
2011). Second, it is a substantial amount of work to enrich
learning materials or environments with prompts; it may not
be practical to do so for all materials a learner may need, or
even to know what learning materials a learner may need in
the future. It would be far preferable if the learners acquired
self-explanation skills that they can use for further selfregulated learning in new learning environments.
There are several tried-and-tested self-explanation
training interventions. However, they all have restrictions
with respect to fostering principle-based self-explanations
when learners study worked examples and solve problems
in order to acquire cognitive skills. McNamara and
colleagues focus on reading strategies in their selfexplanation training interventions SERT and iStart
(McNamara, 2004; Levinstein, Boonthum, Pillarisetti, Bell,
& McNamara, 2007). These strategies are not tailored to

1205

learning by examples and problem-solving. A restriction of
other training interventions for self-explaining examples and
problems that have been tested so far is that they employed
the same type of materials in the training phase as in a
subsequent learning phase (e.g., Bielaczyc, Pirolli, &
Brown, 1995). For example, Renkl, Stark, Gruber, and
Mandl (1998) trained participants using examples of
(compound) interest calculation in order to prepare them for
a later learning phase dealing with the same domain. The
self-explanation training of Wong, Lawson, and Keeves
(2002) focuses on geometry learning in all phases.
The expectation that the self-explanation strategies
addressed by these previous training will solely transfer to
similar contents seems to be realistic because transfer to
dissimilar contexts (e.g., different learning domain) is very
hard to achieve (e.g., Detterman 1993; Goldstone & Day,
2012; Perkins, 2009). Nevertheless, some researchers found
some training effects that transfer over contents. For
example, Chi and VanLehn (2010) had their learners work
in an intelligent tutoring environment called "Pyrenees"
(domain: probability) that demanded, among other things, a
focus on domain principles. The learners were prompted to
reason about the principles in order to determine sought
values and they had to apply the principles to the problems
at hand. It was found that this principle orientation
transferred when working in another intelligent tutorial
environment (i.e., "Andes"; domain: probability and
physics); this was in particular true for learners with less
prior knowledge. Note that there was not only a transfer
across learning environments (Pyrenees to Andes) but also
across learning domains (probability to physics).
Whereas Chi and VanLehn (2010) found transfer of a
principle orientation acquired during physics learning,
Busch, Renkl, and Schworm (2008) developed a training
intervention with the "sole" purpose to foster selfexplanations. This short intervention (less than 30 min.) was
conducted with the topic "fables." The learners were shown
that in order to determine that a short story is a fable one has
to self-explain whether some crucial principles were
implemented in the story (e.g., animals as actors, hidden
message). This intervention showed considerable transfer
effects to a rather distant topic: example-based acquisition
of scientific argumentation skills. Although this short-term
training was surprisingly successful, it had a significant
restriction. Although there was transfer from fables to
scientific argumentation, it was "just" transfer between
verbal domains. As the Busch et al. intervention did not
refer to mathematical solution procedures, which are typical
not only of mathematics but also of many science subdomains, we did not expect transfer to the latter domains.
Hence, it is sensible to modify the Busch et al. training
intervention by including mathematical contents.

The Present Study
We trained high-school students providing selfexplanations in two domains. As in the study by Busch et al.
(2008) we used fables as “verbal” exemplifying domain, and

mathematics as an algorithmic exemplifying domain.
Afterwards the students learned from an example-based
learning environment how to apply psychological attribution
theory in order to provide feedback that has favorable
motivational effects. This content domain was not taught or
mentioned in the training intervention. Hence, we test the
hypothesis that the self-explanation training using
mathematics problems and fables as materials has positive
effects on learning about the provision of productive
feedback on the basis of attribution theory.
As control group, we did not use a non-treatment group,
as these effects might be rather trivial. Instead, we compared
the self-explanation intervention with a training intervention
on mnemonic strategies. Although the latter strategies might
be useful for remembering facts, we hypothesized that the
self-explanation intervention is more favorable for highlevel learning goals (e.g., applying what has been learnt
about feedback to evaluating new feedback messages).
When testing the effects of a modified version of the short
training intervention by Busch et al. (2008), we tried to keep
the training time short, that is, about half an hour (as in the
original training intervention). Such a short training
intervention is applicable within the usual class periods in
schools. In the self-explanation intervention, we kept the
basic example of a fable in order to demonstrate the value of
principle-based self-explanations. In addition, we used
mathematics examples in order to show how to self-explain
while studying mathematics examples and while solving
mathematics problems. We saved some training time in
order to add mathematics contents by focusing on principlebased self-explanations and leaving out other types of selfexplanations (e.g., goal-operation elaborations) that were
part of the original training intervention. Nevertheless, we
had to shorten the treatment of self-explaining fables in
order to keep the intervention time within the limits of about
half an hour. A question that arose was whether the training
intervention has still transfer effects to other verbal areas,
even if the treatment of fables as verbal training examples
was substantially reduced. The unique contribution of this
study is the evaluation of a self-explanation training
intervention that is designed to have across-domain transfer
effects, that is, effects that are not bound to the
"exemplifying" domains used during training.

Method
Participants and Design
We randomly assigned 58 female high-school students
(age: M = 16.52, SD = 0.71) to two conditions: training
intervention on principle-based self-explanations (n = 31)
and training intervention on mnemonic strategies (n = 27).
The participants were members of elective courses in
psychology from a "mono-educational" (i.e., just female
students) Gymnasium (i.e., highest high-school track of the
German three-track system). The main dependent variable
was the learning outcomes in a learning environment that
followed the different training interventions. This transfer

1206

environment was about attribution theory and its application
to providing productive feedback. The contents that the
students learned in this experiment were not directly related
to their currently treated topics in their psychology courses.
However, they were (validly) informed that the topics fit the
overall learning goals of these courses.

Instruments and Materials
Short-term training environments. We compared the
transfer effects of two training environments: Training of
principle-based self-explanations versus training of
mnemonic strategies. They lasted about half an hour. Both
training interventions were parallel in a number of features.
They both introduced the fictitious character Sarah who had
learning difficulties (see Figure 1). In both cases, a friend
helps out by suggesting some strategies (i.e., principle-based
self-explanations or mnemonic strategies, respectively).
Both training modules presented the contents within a
dialogue between Sarah und her friend. During the program
the learners in both conditions got work sheets in order to
practice the respective strategies. Both modules ended with
a short summary of the training contents.

Figure 1: Screenshot from the training intervention
module on principle-based self-explanations (translated
form German)
The training intervention on principle-based selfexplanation was divided into two main modules, which
explained and practiced principle-based self-explanations
when (a) studying an example and (b) solving a problem.
The first example in the example-studying section was
Aesop's fable "The fox and the crow." We showed that a
fable is characterized by several principles or underlying
features (e.g., animals as actors, principle of polarization,
hidden message) and that the readers have to self-explain a
story in terms of above-mentioned underlying features in
order to identify the story as a fable (see Figure 1). Next the
learners practiced principle-based self-explanations,
supported by corresponding prompts, on a work sheet
presenting a worked example applying the Pythagorean

Theorem. Hence, a first instance of inter-domain transfer
was practiced. In the second part, we supported further
transfer by presenting and practicing principle-based selfexplanations when solving diverse mathematics problems.
The training intervention on mnemonic strategies
introduced and practiced three strategies: (a) Using mental
images; (b) "Eselsbrücken," which is a German term for (in
many cases funny) phrases that interconnect two items (e.g.,
word in a foreign language and translation). (c) "Mnemonic
sentences" similar to "My very educated mother just served
us nine pickles" for the planets and their distances to the sun
(note, however, that we used other mnemonic sentences
because this one does not work in German language).
Transfer environment. The transfer environment first
introduced the concept of attribution and explained why
attributions are important in learning contexts. Then it
introduced the basics of Kelley's (1971) attribution theory,
that is, the co-variation model. On this basis, it explained
how feedback should be given to students so that functional
attributions are fostered. Two small exercises were included
in which the participants had to analyze feedback
statements. Finally, a summary was provided. The learner
worked on average 7.10 min (SD = 2.02) in this module (no
significant difference between the conditions).
Posttest. The posttest assessing the transfer effects of the
self-explanation training consisted of 15 problems (average
time: 23 min). In addition, the posttest booklet asked three
questions that were to be answered on 5-point rating scales
at the very beginning (I found the first program useful; I
found the second program useful; in the second program I
applied the strategies that I have learned in the first
program). After these questions, we presented the problems
assessing the learning outcomes.
Three problems asked what should be emphasized in
feedback in different circumstances. Six items asked for the
attribution theory principles behind exemplary feedback
messages (e.g., "In a dance class: A lot of people struggle
with Tango" (the feedback message itself is printed in
italics). Solution: Such feedback suggests attributions to
task difficulty and it should "prevent" internal attributions
when having difficulties). Four items required writing a
short feedback statement for different circumstances.
Finally, two items ask for identifying what is problematic
with two suboptimal feedback statements. This scale had a
good internal consistency (Cronbach's α of .86).

Procedure
The students participated at experimental group sessions
in a university computer laboratory (about 20 students per
session). The students worked individually in front of a
computer. The different computers were randomly assigned
to one of the two experimental conditions. These sessions
lasted about 100 min. At first glance, this duration is longer
than to be expected from the average time of the single
phases such as training intervention, transfer environment,
and posttest. Note, however, that the faster students had to
wait for the slower ones before going on to the next phase.

1207

After some welcome words, we informed the students that
they will learn about some learning strategies in a first
computer-based learning environment and that they should
apply these strategies in a second computer-based learning
environment. Subsequently, students were asked to fill in a
short paper-pencil questionnaire on demographic data (one
page), previous school grade, and on learning goal
orientation (Dweck & Leggett, 1988). As the latter scale
neither predicted learning outcomes nor interacted with the
different treatments we did not consider the students'
learning goal orientation in the following.
After completing the questionnaire the students worked
on the training intervention modules. Subsequently the
students learned about feedback and attribution theory in a
second learning program. Finally, they took the posttest.

Results
A significance level of .05 was used for all analyses. We
used d as an effect-size measure with values between .20
and .50 classified as small, values between .50 and .80 as
medium, and values > .80 as large (Cohen, 1988).
We did not find any significant differences between the
groups with respect to the grade point average on the last
report card or the experience with learning programs (both
Fs < 1). Eight students said that they have never heard the
term attribution. Fifty students said that they have already
heard about this term but did not remember its meaning. No
student was able to explain what attribution means. Overall,
the student had hardly any prior knowledge.
The self-explanation condition scored descriptively higher
on the posttest as compared to the mnemonics condition, M
= .55, SD = .23 vs. M = .48, SD = .21 (Ms represent the
percentage scores as compared to the theoretically possible
maximum). However, this difference did not reach the level
of statistical significance, t(56) = 1.08, p = .286, d = 0.32.
This relatively weak and statistically not significant effect
could be due to the following factors: (a) The effect of the
self-explanation training intervention interacts with learning
prerequisites (aptitude-treatment interaction explanation);
(b) some of the learners superficially scanned or quickly
read the training module (scan and skim explanation); (c)
the training module was too difficult at least for some
learners (difficulty explanation); (d) the learned selfexplanation strategies were not applied by some learners in
the application environment on attribution and feedback
(production deficiency explanation).
(a) Aptitude-treatment interaction explanation. The most
important learning variable with respect to aptitudetreatment interaction is prior knowledge or achievement
level (Kalyuga, 2007). The grade point average, as indicator
of prior school achievement, was significantly related to the
posttest (r = .37, p = .005). However, there was no
interaction between condition and grade point average, with
respect to the posttest, F < 1. Further exploratory analysis
with other learning prerequisites (e.g., grades for
mathematics or German; experience with computer-based
learning program) did not indicate any aptitude-treatment

interaction. Hence, the aptitude-treatment interaction
explanation is likely not true.
(b) Scan and skim explanation. If the weak and
insignificant transfer effect was due to some learners’ just
scanning and skimming the training environment, there
should be a correlation between learning time and training
outcomes. However, the learning time in the training
modules was not significantly related to learning outcomes,
neither in the whole sample (r = .05, p = .699) nor in the
two sub-groups (self-explanation group: r = .11, p = .551;
mnemonic strategies group: r = -.15, p = .455). In this
context, it should also be noted that the self-explanation
group spend more time in the training module, M = 29.87,
SD = 6.70, than the mnemonic group, M = 24.07, SD = 6.89,
t(56) = 3.25, p < .002, d = 0.85. Overall, there is no
indication that some learners in the self-explanation
condition just quickly scanned the training module, which
impeded their learning outcomes. Hence, the scan and skim
explanation is likely not true.
(c) Difficulty explanation. If the self-explanation training
intervention was too difficult for some learners, there should
be a substantial number of errors in practice sheets that were
included in the learning environment, and the number of
errors in these practice sheets should predict lack of transfer.
To test this explanation, we coded the quality of the
students’ responses to the four interspersed work sheets in
the self-explanation training module from 1 (completely
wrong) to 5 (correct, clear principle application). We found
a mean of 4.35 (SD = 0.55), clearly indicating that the
training was not too difficult for the learners. In addition,
there was no significant correlation between the worksheet
score and the posttest (r = .18, p = .180). Overall, the
difficulty explanation is likely not true.
(d) Production deficiency explanation. We asked the
participants to rate on a five-point scale whether they
applied the strategies learned in the first module (selfexplanation or mnemonics, respectively) in the second
module on attribution, as suggested by the experimenter in
the beginning of the session. When adding this rating in the
prediction of learning outcomes (predictors: condition,
rating, and condition by rating), we found a significant
interaction effect between condition and reported strategy
application with respect to the posttest, F(1,54) = 9.72, p =
.003. To better understand this interaction, we determined
the regression scores and their statistical significance in both
conditions. In the self-explanation condition, the more the
students reported that they applied the learned strategies, the
better the posttest performance, b = 0.09, t(29) = 2.59, p =
.015. In the mnemonics condition, we did not find a
significant relation between self-reported strategy
application and posttest performance in the transfer
environment, ß = -0.07, t(25) = -1.89, p = .071. In accord
with a production deficiency explanation, these findings
indicate that only part of the students applied the learned
strategies in the module on attribution and feedback and,
thereby, profited with respect to learning outcomes.

1208

In order to get an idea of how many non-applying
students were "responsible" for the insignificant overall
training effect, we conducted some post-hoc analyses. When
we excluded the three students from the self-explanation
condition who stated that they did not at all apply the
strategies (i.e., choosing 1 on the 1 to 5 rating scale of
strategy application), there was still no significant effect of
condition on learning outcomes. However, when excluded
an additional nine students, namely, all students who stated
that they did not apply the strategies (i.e., choosing 2 on the
1 to 5 rating scale of strategy application), the condition
effect gets to be statistically significant (self-explanation
condition: N = 19; M = .63, SD = .22; mnemonics condition
(as already reported): N = 27; M = .48, SD = .21, t(44) =
2.23, p = .031, d =.70). Hence, only when we consider the
(roughly) two thirds of the students that were convinced to
apply the strategies, we get a significant effect of the selfexplanation training intervention.
The preceding post-hoc analysis might be criticized
because we excluded only participants from the selfexplanation condition and we, therefore, had rather different
group sizes. If we also exclude the ten participants from the
mnemonic condition (i.e., roughly the lower third) that
reported about low strategy application, we also got a
significant group difference: self-explanation condition (as
already reported): N = 19; M = .63, SD = .22; mnemonics
condition: N = 17; M = .42, SD = .23, t(34) = 2.70, p = .011,
d =.89). This finding again underlines that the selfexplanation treatment was successful in about two thirds of
the cases.

Discussion
We tested whether we could successfully implement a
short-term training intervention on principle-based selfexplanations that has positive effects on learning in a
subsequent learning environment. Unfortunately, we got
only a weak and statistically insignificant effect. According
to our post-hoc analyses, it is unlikely that this weak effect
was due to aptitude-treatment interactions with learning prerequisites, a scan-and-skim behavior of some learners, or the
difficulty of the training intervention. Instead, only part of
the students (about two thirds) was "convinced" by the
training intervention to apply the learned strategies in a
subsequent learning environment. Students who applied the
strategies profited from the training intervention.
Why did some learners not apply the self-explanation
strategies? There are at least three possible explanations: (a)
These learners did not find the strategies in the selfexplanation training useful; (b) it was not salient enough, at
least for some learners, that they were expected to apply the
strategies that they have learned in the first environment in
the second learning environment; (c) the training
intervention was too short to fully change the students'
habitual learning behavior.
The perceived usefulness argument can be evaluated by
further post-hoc analyses. After completing the learning
environment on attribution theory and before they took the

posttest, the learners rated how useful they found the
strategy training module. The learners from the selfexplanation condition rated this module as rather useful (M
= 4.03, SD = 0.98 (5-point scale from 1, not at all, to 5, fully
agree). The perceived utility predicted to some extent
whether the strategies applied (r = .36, p < 0.05). However,
the perceived utility did not interact with the treatment, in
contrast to the reported strategy application. Obviously, the
(low) perceived usefulness was not a major cause for not
applying the strategies and for reduced training effects.
How salient was it for the learners that they should apply
the learned strategies in the second learning environment?
In the beginning of the experimental sessions, the
experimenter informed the students that they should apply
the strategies to be learned in a first environment in the
second computer-based learning environment. However,
this prompt was not repeated (keep in mind that the question
of to what extend the strategies learned in the first program
were applied was posed after the transfer phase). Note also
that in the beginning of the session, the students got a
variety of information and were confronted with many new
"impressions," that is, they came to a new building (i.e.,
Department of Psychology), they were introduced to the
computer room and the experimenter, they were informed
about various aspects of the study, etc. Thus, for some
students, the instructions about strategy application might
not have been very salient and they might not have been
remembered when they began to work on the second
learning environment. It seems plausible that - given the
short duration of the training intervention so that no
profound effect on habitual behavior can be expected - the
students would need at least some form of "kick-off" prompt
at the start of the transfer learning environment to apply the
learned strategies to new contents.
As already argued, the short training duration makes it
implausible that the students' habitual strategy use was
changed. Against the background of the present
intervention's short duration and the corresponding transfer
literature (e.g., Detterman 1993; Goldstone & Day, 2012), it
can even be regarded as success that about two thirds of the
learners transferred the newly learned self-explanation
strategies across domains.
In this context, it should also be noted that we have
replaced the verbal self-explanation training materials of
Busch et al. (2008) to a large degree with mathematical
examples. Given that Busch et al. found significant transfer
effects across two verbal domains, it can be tentatively
assumed that the "verbal part" was too much reduced.
Hence, a sensible next step in improving the training
intervention would be to extend the verbal part roughly to
the length of the Busch et al. intervention. Thus, we extend
the verbal part of our training intervention in a next step on
our way to develop some type of "generic" self-explanation
training. We also intend to test transfer effects on
mathematical learning environments.
An alternative explanation for the positive training effect
when looking at the two thirds of student reporting strategy

1209

application is that the mnemonic intervention suppressed at
least some students' tendency to self-explain spontaneously.
Hence, further studies should also include a control
condition allowing for spontaneous self-explanations.
Overall, the present study and Busch et al. (2008) have
taken partly successful steps towards a self-explanation
strategy training that has the potential to achieve acrossdomain transfer effects. Nevertheless, there is some further
research to be done (e.g., extending the intervention; testing
transfer to mathematical contents). However, the available
findings justify some optimism that we can step by step
come to a successful training approach.

Acknowledgments
This work was supported by the Pittsburgh Science of
Learning Center, which is funded by the National Science
Foundation; award number SBE-0354420.

References
Aleven, V., & Koedinger, K. R. (2002). An effective metacognitive strategy: Learning by doing and explaining with
a computer-based Cognitive Tutor. Cognitive Science, 26,
147-179.
Atkinson, R. K., Renkl, A., & Merrill, M. M. (2003).
Transitioning from studying examples to solving
problems: Combining fading with prompting fosters
learning. Journal of Educational Psychology, 95, 774783.
Berthold, K., & Renkl, A. (2009). Instructional aids to
support a conceptual understanding of multiple
representations. Journal of Educational Psychology, 101,
70-87.
Bielaczyc, K., Pirolli, P., & Brown, A. L. (1995). Training
in self-explanation and self-regulation strategies:
Investigating the effects of knowledge acquisition
activities on problem solving. Cognition &Instruction, 13,
221-252.
Busch, C., Renkl, A., & Schworm, S. (2008). Towards a
generic self-explanation training intervention for
example-based learning. In P. A. Kirschner, F. Prins, V.
Jonker, & G. Kanselaar (Eds.), Proceedings of the 8th
International Conference of the Learning Sciences 2008
(CD version only). Utrecht, NL: ICLS.
Cohen, J. (1988). Statistical power analysis for the
behavioral sciences (2nd ed.). Hillsdale, NJ: Erlbaum.
Conati, C., & VanLehn, K. (2000). Toward computer-based
support of meta-cognitive skills: A computational
framework to coach self-explanation. International
Journal of Artificial Intelligence in Education, 11, 398415.
Chi, M. & VanLehn, K. (2010). Meta-cognitive strategy
instruction in intelligent tutoring systems: How, when,
and why. Journal of Educational Technology and Society,
13, 25-39.
Detterman, D. L., (1993). The case for the prosecution:
Transfer as epiphenomenon. In D. K. Detterman & R. J.
Sternberg (Eds.), Transfer on trial: Intelligence,

cognition, and instruction (pp. 1-24). Norwood, NJ:
Ablex.
Dweck, C. S., & Leggett, E. L. (1988). A social-cognitive
approach to motivation and personality. Psychological
Review, 95, 256–273.
Goldstone, R. L., & Day, S. B. (2012). Introduction to "New
Conceptualizations of Transfer of Learning.” Educational
Psychologist, 47, 149-152.
Kalyuga, S. (2007). Expertise reversal effect and its
implications for learner-tailored instruction. Educational
Psychology Review, 19, 509–539.
Kalyuga, S. (2011). Cognitive load theory: How many types
of load does it really need. Educational Psychology
Review, 23, 1-19.
Kelley, H. H. (1971). Attribution in social interaction. New
York: General Learning Press.
Levinstein, I. B., Boonthum, C., Pillarisetti, S. P., Bell, C.,
& McNamara, D. S. (2007). iSTART 2: Improvements for
Efficiency and Effectiveness. Behavior Research Methods
Instruments and Computers, 39, 224-232.
McNamara, D. S. (2004). SERT: Self-explanation reading
training. Discourse Processes, 38, 1-30.
Perkins, D. (2009). Making learning whole: How seven
principles of teaching can transform education. San
Francisco, CA : Jossey-Bass.
Renkl, A. (1997). Learning from worked-out examples: A
study on individual differences. Cognitive Science, 21, 129.
Renkl, A. (2002). Learning from worked-out examples:
Instructional explanations supplement self-explanations.
Learning & Instruction, 12, 529-556.
Renkl, A., Stark, R., Gruber, H., & Mandl, H. (1998).
Learning from worked-out examples: The effects of
example variability and elicited self-explanations.
Contemporary Educational Psychology, 23, 90-108.
Rittle-Johnson, B., Siegler, R. S., & Alibali, M. (2001).
Developing conceptual understanding and procedural skill
in mathematics: An iterative process. Journal of
Educational Psychology, 93, 346-362.
Schworm, S., & Renkl, A. (2006). Computer-supported
example-based learning: When instructional explanations
reduce self-explanations. Computers & Education, 46,
426-445.
Schworm, S., & Renkl, A. (2007). Learning argumentation
skills through the use of prompts for self-explaining
examples. Journal of Educational Psychology, 99, 285296.
Wecker C., & Fischer F. (2011). From guided to selfregulated performance of domain-general skills: The role
of peer monitoring during the fading of instructional
scripts. Learning & Instruction, 21, 746-756.
Wong, R. M. F., Lawson, M. J., & Keeves, J. (2002). The
effects of self-explanation training on students' problem
solving in high-school mathematics. Learning &
Instruction, 12, 233-262.

1210

