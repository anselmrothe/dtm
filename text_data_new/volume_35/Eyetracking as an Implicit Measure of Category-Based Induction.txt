UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Eyetracking as an Implicit Measure of Category-Based Induction

Permalink
https://escholarship.org/uc/item/5wh0c4fs

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Chen, Stephanie
Ross, Brian
Murphy, Gregory

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Eyetracking as an Implicit Measure of Category-Based Induction
Stephanie Y. Chen (syc341@nyu.edu)
Department of Psychology, 6 Washington Place
New York, NY 10003 USA

Brian H. Ross (bhross@illinois.edu)
Department of Psychology, 603 E. Daniel St.
Champaign, IL 61820 USA

Gregory L. Murphy (gregory.murphy@nyu.edu)
Department of Psychology, 6 Washington Place
New York, NY 10003 USA
Abstract

is consistent with Bayesian approaches to classification and
prediction in which people weight different possibilities by
their prior likelihoods. Anderson (1991) proposed such a
model of category-based induction1 in which the probability
that an object with observed features, F, has an unobserved
feature, j, is the weighted sum of the probabilities across all
categories, k (assuming they are mutually exclusive):

Category information is used to predict unknown properties
of category members. Previous research has found that when
categorization is uncertain, property predictions do not reflect
integration of information across categories as normative
principles and Bayesian models would suggest. Rather,
people often base their predictions on only the most likely
category and disregard information from less likely ones.
Research in category-based induction tends to elicit explicit,
verbal responses which may not readily allow for integration
of information across categories. This paper explores whether
changing response mode can promote more normative use of
category information in induction. Experiment 1 used an
implicit measure of prediction: eye movements. The results
suggest that when making predictions implicitly people
integrate information across categories. The results of
Experiment 2 suggest that the integration of information
found in Experiment 1 were not a result of explicit strategies.

P(j | F) = Σ P(k | F) x P(j | k).

(1)

k

Thus, if you were a Bayesian food thief you would take
the probability that the unknown food is Chinese food and
multiply that by the probability that Chinese food is spicy.
Next you would take the probability that the food is Indian
food and multiply that by the probability that Indian food is
spicy. The sum of the two products is the probability that
the food is spicy. This appears normatively correct, since it
takes into account your uncertainty and weighs the strength
of the prediction accordingly. If very certain that the food is
Chinese food you should make a moderate prediction about
the likelihood of it being spicy; if uncertain, you should
make a stronger prediction. Surprisingly, however, previous
research on induction with uncertain categories has provided
evidence using both real-life and artificial categories that
people usually base their induction on only a single category
(Hayes & Newell, 2009; Malt, Ross, & Murphy, 1995;
Murphy, Chen, & Ross, 2012; Murphy & Ross, 1994).
These findings are in contrast to those of perception and
motor control research that often find that people integrate
information across possibilities in a Bayesian manner
(Kersten, Mamassian, & Yuille, 2004; Tassinari, Hudson, &
Landy, 2006; Trommershäuser, Landy, & Maloney, 2006;
Trommershäuser, Maloney, & Landy, 2008). In perception,
Bayesian models are used to explain how the visual system
takes ambiguous inputs and returns percepts that are most

Keywords: category-based induction; reasoning; implicit
processes.

Introduction
The ability to use category-level information to infer
information about novel objects aids our reasoning, social
interactions, communication and predictions. By placing an
object into a category, we can make predictions about it
even though we have never encountered that particular
object before. Because you know about the category of
Chinese food in general, when you see some Chinese food
cartons in your refrigerator you know that there is some
chance that the food is spicy, but it’s likely not. For our
purposes, category-based induction refers to a process like
the one described above (the extension of category
information to a new item in that category). This process
becomes more complicated when you are unsure what
category an item belongs to. Imagine that your roommate
has left unmarked cartons of leftover food in the
refrigerator, and you can’t tell whether they hold bland
Chinese or spicy Indian food. Do you take an acid reducer
before eating? You must make a prediction about the food's
spiciness based on the characteristics you can observe.
To decide whether the food will be spicy, you should take
into account both the possibility that it is Chinese food and
the possibility that it is Indian food. This type of reasoning

1

In all our experiments, the categories are novel and equally
probable, so we omit the prior probability component of Bayesian
reasoning. We continue to use the term Bayesian because of the
common feature of Bayesian models of induction that predictions
are integrated across multiple categories, weighted by their
likelihood.

316

likely. People use knowledge about prior probabilities of
states of the world and the likelihood of each state given the
visual stimulus to arrive at the most probable interpretation
of the stimulus (Kersten et al., 2004). In motor control, one
action may be best suited to achieve a goal, given the state
of the world. But since perception is not perfect, the state of
the world is uncertain. Models of action propose that people
integrate information about the likelihood of the possible
states of the world to make near optimal actions (Haruno,
2001). These actions are sensitive to the payoff structure of
the task: Subjects make motor decisions that minimize
costs, given the uncertainty of different motor outcomes and
the costs and benefits associated with each action
(Trommershäuser,
Landy,
&
Maloney,
2006;
Trommershäuser, Maloney, & Landy, 2008).
Why might people be unable, or unwilling, to combine
information about two categories in category-based
induction tasks, but are able to integrate across possibilities
and weigh costs and benefits in seemingly more complex
perception-action tasks? We suggest that this discrepancy
can, in part, be explained by the distinction between implicit
and explicit processes (Sloman, 1996). Explicit processes
are conscious and rule-based, while implicit processes are
unconscious and associative. Explicit reasoning is subject to
a reasoning heuristic called the singularity principle, which
states that people generally only consider one possibility at a
time (Evans, 2007). More specifically, we suggest that
response mode is critical to whether information is
integrated across categories. In category-based induction
tasks, subjects often explicitly report what category they
think an item belongs to prior to making a prediction. In
contrast, perception and motor control experiments tend to
depend on implicit responses. Subjects in these experiments
are not asked to explicitly consider the potential possibilities
(states of the world) but are instead prompted to act on this
information (often, but not always, with a motor response).
Chen, Ross, & Murphy (in press) provided evidence that
implicit and explicit responding lead to different use of
category information during induction. In one experiment,
subjects learned artificial categories of moving geometric
figures defined by two features: shape and direction. At test,
subjects were presented with a shape and asked to predict its
direction either implicitly or explicitly. The implicit test was
a novel, game-like motor task that elicited a speeded
prediction, and the explicit test was a formally identical
verbal task that elicited a conscious, unspeeded prediction.
The categories consisted of eight moving geometric
figures (see Table 1). There were two critical shapes of
interest: squares and hearts. Each of these shapes belonged
to one of two categories, the target or secondary categories.
The target category is the category that the shape is most
likely to be in given its distribution in the categories. For
example, there was a 66% chance that a square belonged to
Category 1, the target category, and a 33% chance that it
belonged to Category 2, the secondary category (that is,
there were eight squares in Category 1 and four in Category
2). In the target category, half of the squares moved in the 1

o’clock direction and half moved in the 5 o’clock direction.
In the secondary category, the critical shapes moved in only
one direction. In Condition 1, the squares moved to 1
o’clock; in Condition 2, which served to counterbalance the
direction of the secondary category, they all moved to 5
o’clock. Therefore, if people only attend to the target
category in predicting the direction of a new square, they
should be indifferent between predicting movement toward
1 and 5 o’clock, and thus their average prediction should be
around 3 o’clock. If they attended to both the target and
alternative categories, they should have a preference,
because the alternative category (Category 2) would break
the tie (in different directions in the two conditions).
This design was replicated for another stimulus and other
directions: For hearts, the target category was Category 4,
and half of the hearts moved in the 11 o’clock direction and
half moved in the 7 o’clock direction. The secondary
category was Category 3, and its hearts moved either toward
11 or 7 o’clock, depending on condition (see Table 1). Thus,
if people integrated information across categories they
would shift their predictions depending on what condition
they are in, that is, depending on the less likely, secondary
category. All subjects went through an identical learning
phase in which they learned all four categories, based on the
objects’ shapes and direction of movement.
For the implicit test, subjects saw each shape presented
briefly in the center of the screen before it rapidly moved off
the screen in one of the learned directions. The subjects’
task was to catch the shape with their cursor before it
disappeared from the screen. Subjects were unable to catch
the shapes in the middle of the screen, so they had to place
their cursor towards the edge of the screen. Subjects
controlled cursor placement and movement with the mouse.
For the explicit test, subjects were presented with static
shapes and asked three questions about them: what category
the shape was most likely to belong to, the probability their
categorization was correct, and what direction the shape was
most likely to travel in.
Subjects performed both the implicit and explicit
induction tasks (order of tasks was counterbalanced). The
results revealed that the exact same category knowledge led
to significantly different inductions. Implicit inductions
were, on average, shifted towards the secondary category,
showing evidence of integration of information across
categories. Explicit inductions showed no evidence of
normative integration across categories. This pattern of
results suggests that response mode is critical in determining
how category information is used in induction. This is not to
say that all things that make categories implicit lead to
integration across categories. In Experiment 4 of Chen et al.
(in press), subjects learned categories implicitly and made
predictions explicitly. These predictions showed no
evidence of integration of information across categories.
While these results suggest that implicit response
promotes integration of information across categories, they
are in contrast to much research on category-based
induction under uncertainty which has consistently found

317

Table 1: Category Structure used in Experiments 1 and 2 (and Chen et al., in press)
Category 1
Category 2
Category 3
(target for squares)
(secondary for squares)
(secondary for hearts)
Exemplar
Shape
Direction
Shape
Direction*
Shape
Direction*
1
Square
1
Square
1/5
Heart
7/11
2
Square
1
Square
1/5
Heart
7/11
3
Square
1
Square
1/5
Heart
7/11
4
Square
1
Square
1/5
Heart
7/11
5
Square
5
Rectangle
1/5
Diamond
7/11
6
Square
5
Rectangle
1/5
Diamond
7/11
7
Square
5
Rectangle
1/5
Diamond
7/11
8
Square
5
Rectangle
1/5
Diamond
7/11
Note. The direction entries are clock directions (1 = 1 o’clock, etc.).
*The first number refers to the direction in condition 1, the second to condition 2.
that most people based their inferences on only a single
category. In Experiment 1, we seek to replicate this result
with a different implicit measure of induction: eye
movements. In Experiment 2, we provide evidence that
subjects are not consciously aware of the strategies used in
this implicit induction task.

Category 4
(target for hearts)
Shape
Direction
Heart
7
Heart
7
Heart
7
Heart
7
Heart
11
Heart
11
Heart
11
Heart
11

Method
Design Subjects were randomly assigned to one of two
between-subjects conditions. The conditions served to
counterbalance the direction of the secondary categories.
Participants Subjects were 32 undergraduates at New York
University who participated for course credit. Data from
eight subjects were dropped for not fixating prior to the
shape’s reappearance on at least five trials. One subject was
dropped for not reaching the performance criterion during
learning.
Materials Stimuli for each category were 8 black shapes
approximately 1.75 to 2.5 cm in length, as shown in Table
1. The same shapes were used during test except they had
stripes (see Figure 1). The category structure was the same
as that used in Chen et al. (in press). See Table 1 for details.
All stimuli were presented on the background of a light
gray circle 30 cm in diameter centered on a black computer
screen. Stimuli started in the center of the screen and then
moved off the screen disappearing once they moved beyond
the border of the circle. Eye movements were monitored
with the SR Research (Ontario, Canada) EyeLink 1000.
Procedure The experiment consisted of three phases: 1)
observation, 2) learning, and 3) test. A Macintosh computer
presented the instructions and controlled all three phases.
Eye movements were recorded during the test phase only.
Subjects were told that they would view four categories of
moving shapes and were to learn what combination of
shapes and directions belonged to each category for a
memory test. During observation, all shapes from each
category were presented singly. Each shape appeared in the
center of the screen for 1 s, then moved horizontally
(towards 3 o’clock for shapes in Categories 1 and 2, towards
9 o’clock for Categories 3 and 4) for .4 s, and then moved
towards its assigned clock direction for .95 s until it
disappeared off the edge of the gray circle (see Table 1 for
directions). Each shape’s category name appeared in the
center of the screen for the entire time it was on the screen.
All exemplars from Category 1 were presented, then all
exemplars from Category 2, and so on.
Subjects were next told that they would see the same
items as in the observation phase. They were to classify

Experiment 1
To examine whether subjects would integrate information
across categories when making predictions implicitly,
Experiment 1 used a cover task, in which predicting
movement was incidental. Subjects learned the four
categories of moving shapes used in Chen et al. (in press).
During test they performed a cover task (same/different
task) in which they saw the shapes appear in the center of
the screen. The shapes were the same as the ones subjects
had learned, except they now had diagonal stripes that were
either tilted right or left. After their initial presentation in the
center, the shapes moved towards the edge of the computer
screen but momentarily disappeared behind an annulus that
was on the test screen such that subjects were unable to tell
which direction the shape was going to move. Shapes
briefly reappeared from behind the annulus and then
disappeared off the edge of the screen. When the shapes
reappeared from behind the annulus, their stripes may have
reversed their tilt (e.g., from left to right). Subjects’ task was
to report whether the tilt of the stripes was the same or
different from when it appeared in the center of the screen.
Thus, subjects were never asked to predict direction or
category as they were only questioned about the stripes.
However, since the shapes only reappeared briefly, looking
close to where they reappeared improved performance (e.g,
for squares, it would be beneficial to look near 1 o’clock or
5 o’clock depending on where you thought it would go).
Position of eye gaze just prior to the shape’s reappearance is
the dependent measure as it is a proxy for subjects’
prediction of shape direction. If subjects integrate
information across categories, fixations should, on average,
be shifted towards the direction of the secondary category.

318

each shape into one of the four categories by pressing a
number key on the keyboard. At the beginning of each trial,
a white fixation cross appeared in the center of the screen
for 1 s. The shape then moved as they did in the observation
phase. There was no time limit on responding. After
answering, the correct answer appeared for 1.25 s. After an
error, subjects viewed a repeat display (without responding)
of the moving shape with the correct category displayed.
There were four learning blocks in which each of the 32
items was tested in random order. Because of the category
uncertainty of the critical items (e.g., a square could be in
Categories 1 or 2), subjects could get no more than 75%
correct, assuming they chose the most likely category for all
presented stimuli. In all experiments subjects had to reach at
least 50% correct during the final block of learning to be
included in analysis.
The final phase of the experiment consisted of a 64-trial
test in which subjects had to perform the same/different task
while their eye movements were tracked by the EyeLink
1000. Subjects saw the same items they had seen in the
previous phases except that the shapes would now move a
little bit faster and have diagonal stripes on them. These
shapes would appear in the center of the screen (for 1 s) and
continue to move along the same path as in previous phases.
However, there was now a black annulus on the screen such
that the shape would move horizontally (for .25 s) and then
disappear behind the annulus for .7 s. The shape would then
reappear from behind the annulus just before it disappeared
from the screen. (After the shape’s reappearance from
behind the annulus it was visible for .15 s before it
disappeared.) Recall that all stimuli were presented on a
gray circle 30 cm in diameter. The annulus (24 cm in
diameter) was centered on this image. Its center hole had a
diameter of 8 cm (see Figure 2).
The stripes on a test object were either tilted left or right
when the shape initially appeared (see Figure 1). The
subjects’ task was to report whether the direction of the
stripes was the same or different when it reappeared. The
direction of stripes remained the same for half of the trials
and changed for the other half. Subjects saw a 1.25 s
feedback message. There were five practice trials prior to
the test phase. As shapes only briefly reappeared from
behind the annulus, looking close to where shapes
reappeared was beneficial. Thus, fixation location just prior
to the shape’s reappearance was used as a proxy for
prediction of direction and as the dependent measure.
(Recall that horizontal movement for the critical shapes did
not indicate its category as the horizontal direction was the
same for Categories 1 and 2, and Categories 3 and 4.)

Figure 2: Illustration of the implicit induction task. The
shape appeared in the center of the screen for 1s. It then
moved horizontally for .25 s and disappeared behind the
annulus while traveling on its path (learned in phase 1).
Subjects reported whether the diagonal lines had changed
when it reappeared. Arrows indicate the shape’s path when
it was visible and did not appear in the experiment.
Data Analysis Responses for critical shape trials were
coded such that a position exactly in between the two
possible directions of the shape was 0 degrees, and a shift
from that point towards the direction reinforced by the
secondary category was coded as positive. For example, for
the squares in Condition 1 (which might move to 1 o’clock
or 5 o’clock), the 3 o’clock position was 0 degrees, the 1
o’clock position (the direction of the secondary category)
was 60 degrees, and the 5 o’clock position was -60 degrees.
In Condition 2, the latter values were reversed. We obtained
the mean fixation position for each subject by averaging the
mean fixation position for squares and hearts. Thus, use of a
single category (i.e., use of only the target category) is
evidenced by an average prediction of 0 deg. Normative use
of categories is evidenced by a positive average prediction,
as this represents a shift from 0 deg in the direction of the
secondary category.
Trials in which the fixation position was greater than 100
degrees or less than -100 degrees were not included in the
analysis because the subject was fixated on the opposite side
of the screen from where the shape traveled, indicating that
the subject either forgot where the shapes went, or did not
see the shape correctly prior to its movement. Additionally,
trials where fixation was within the hole of the annulus were
excluded from analysis. When subjects looked at the center
of the screen while doing the task, they were effectively not
making a prediction about direction.

Results & Discussion
Subjects were on average 66.4% correct (chance = 25%)
during their last training block, suggesting that they learned
the categories quite well. (Recall that maximum
performance was 75%, if subjects always classified

Figure 1: Example of stimuli used in the test phase of
Experiments 1 and 2.

319

ambiguous items into the most likely category.)
Performance on the same/difference task averaged 72%.
As explained above, integration of information across
categories is evidenced by a shift from 0 deg in the direction
of the secondary category, which we coded as positive. This
is indeed what we found. The mean fixation position for the
critical shapes, (M = 7.5 deg, SD = 8.9), was significantly
greater than 0 deg, t(23) = 4.1, p < .01, d = .84, indicating
that people’s predictions of direction were integrated across
the two categories. The mean fixation position was positive
for 21 of the 24 subjects. These results are consistent with
those of Chen et al. (in press) and suggest that implicit
induction promotes integration of information across
categories. A question for future research will be to examine
how categories are used during implicit induction. The
multiple category use found in Experiment 1 may be a result
of a feature-level strategy (e.g., using information about
only squares when making a prediction about where a
square will go) rather than a category-level strategy like that
described in Eq 1 (see Griffiths et al., 2011, for similar
ideas).
Perhaps subjects did not truly induce the objects’
direction but learned to change their eye movements via
practice in doing the task. To examine this possibility we
compared the mean fixation position for the first and second
blocks of testing. The difference between the mean fixation
positions for the first and second blocks was not significant
(Ms = 6.2 and 8.8 deg, SDs = 9.1 and 11.9), t(23) = 1.0, p
>.05, d = .25 suggesting that subjects’ normative use of
categories was not a result of learning during test. The
positive shift in eye movements was significant in block 1,
t(23) = 3.3, p < .01, d = 6.8, and in block 2, t(23) = 3.6, p <
.01, d = .76.

three trials. One more subject was dropped for not reaching
the performance criterion during learning.
Materials and Design Identical to Experiment 1.
Procedure The procedures of the observation and learning
phases were identical to those used in Experiment 1. As
with Experiment 1, eye movements were only recorded
during the test phase. The test phase consisted of a 16-trial
test in which subjects were asked to report where they
would look in order to best do the same/different task that
subjects in Experiment 1 performed. Subjects saw the same
five practice trials used in Experiment 1 and then were told
that they would not be doing the task but rather reporting
where they would look just prior to the shape’s
reappearance from behind the annulus to best do the task. In
order to keep the dependent measures of the two
experiments similar, we used eye position to indicate this
prediction. A white dot on the display indicated where the
subjects were looking. The task was to look at the location
on the screen that they thought would be best to do the
same/different task they had just observed. They then saw a
test screen (gray circle with the annulus) and were instructed
to look around the screen to get a sense of how the white dot
corresponded to their eye gaze.
The test phase consisted of four blocks in which each
shape was tested once in random order (except that shapes
were not queried twice in a row). Each test trial started with
the presentation of the shape in the center of the screen for 1
s. It then moved horizontally for .25 s until it disappeared
behind the annulus (the shape never reappeared). Subjects
then saw the white dot that marked their eye gaze on the
screen. To report their location, subjects moved their eyes
until they were satisfied with the location of the white dot
and then pressed the enter key. The white dot stayed on the
screen for 1.25 s so that the subjects could see their answer.

Experiment 2

Results & Discussion

Experiment 1 revealed that people use information from
multiple categories when making inductions implicitly.
However, it is possible that the placement of eye fixation
was not the result of implicit processes but instead the result
of a conscious strategy (i.e., after practice subjects could
have realized that they would perform better when they
looked closer to the direction reinforced by the secondary
category). Experiment 2 tested this explanation. Subjects
completed the full learning procedure of Experiment 1.
They then saw a few example trials of the same/different
task and then reported (using feedback from the eyetracker)
where they would look to best perform the task. This
question sampled subjects’ explicit beliefs about where they
would look. If the results match those of Experiment 1, this
would suggest that the fixations were the result of an
explicit strategy.

Subjects were on average 68.2% correct (chance = 25%)
during their last training block, near the 75% maximum,
suggesting that they learned the categories quite well.
As in the analysis of Experiment 1, subjects’ responses
for the critical shapes were coded such that the time
corresponding to the point exactly in between the two
possible directions of the shape was 0 degrees (3 o’clock for
squares and 9 o’clock for hearts, and a shift towards the
direction reinforced by the secondary category was
positive). To find the mean prediction (the amount of shift
from 0 deg towards the secondary category) for each
subject, we calculated the mean prediction for each shape
and took the average of the two. The mean prediction (M =
0.2 deg, SD = 2.9 deg) was not significantly different than
the average observed direction for the shapes in their target
category only (0 deg), t(15) = 0.2, p > .05, d = .07,
suggesting that subjects were not basing their responses on
multiple categories. Subjects chose locations around 0 deg
the majority of the time. In fact, 84% of all responses were
with within 10 deg of 0 deg. In contrast, in Experiment 1,
only 25% were in this range.

Method
Participants Subjects were 21 New York University
undergraduates who participated for course credit. Data
from four subjects were dropped for not fixating on at least

320

Acknowledgments

These predictions from this experiment show no
integration of information across categories. This suggests
that the integration of information across categories found in
Experiment 1 was not the result of a conscious decision or
strategy and provides further evidence that response mode is
critical to how category information is used in induction.

We thank Rebecca Bainbridge for her help with data
collection and analysis. The research was supported in part
by NSF grants BCS-1128769 and 1128029.

References

General Discussion

Anderson, J. R. (1991). The adaptive nature of human
categorization. Psychological Review, 98, 409-429.
Chen, S. Y., Ross, B. H., & Murphy, G. L. (in press).
Implicit and explicit processes in category-based
induction: Is induction best when we don’t think? Journal
of Experimental Psychology: General.
Devine, P. G. (1989). Stereotypes and prejudice: Their
automatic and controlled components. Journal of
Personality and Social Psychology, 56, 5-18.
Evans, J. S. B. (2007). Hypothetical thinking: Dual
processes in reasoning and judgment. New York:
Psychology Press.
Griffiths, O., Hayes, B. K., Newell, B. R., & Papadopoulos,
C. (2011). Where to look first for an explanation of
induction with uncertain categories. Psychonomic Bulletin
& Review, 18, 1212-1221.
Haruno, M., Wolpert, D., & Kawato, M. (2001). Mosaic
model for sensorimotor learning and control. Neural
Computation, 13, 2201-2220.
Hayes, B. K., & Newell, B. R. (2009). Induction with
uncertain categories: When do people consider the
category alternatives? Memory & Cognition, 37, 730-743.
Kersten, D., Mamassian, P., & Yuille, A. L. (2004). Object
perception as Bayesian inference. Annual Review of
Psychology, 55, 271-304.
Malt, B. C., Ross, B. H., & Murphy, G. L. (1995).
Predicting the features for members of natural categories
when categorization is uncertain. Journal of Experimental
Psychology: LMC, 21, 646-661.
Murphy, G. L., Chen, S. Y., & Ross, B. H. (2012).
Reasoning with uncertain categories. Thinking &
Reasoning, 18, 81-117.
Murphy, G. L., & Ross, B. H. (1994). Predictions from
uncertain categorizations. Cognitive Psychology, 24, 148193.
Sloman, S. A. (1996). The empirical case for two systems of
reasoning. Psychological Bulletin, 119, 3-22.
Tassinari, H., Hudson, T. E., & Landy, M. S. (2006).
Combining priors and noisy visual cues in a rapid
pointing task. Journal of Neuroscience, 26, 10154-10163.
Trommershäuser, J., Landy, M. S., & Maloney, L. T.
(2006). Humans rapidly estimate expected gain in
movement planning. Psychological Science, 17, 981-988.
Trommershäuser J., Maloney L. T., & Landy M. S. (2008).
Decision making, movement planning and statistical
decision theory. Trends in Cognitive Science 12, 291-297.

The results of Experiment 1 suggest that people integrate
information across categories when making inductions
implicitly. The results of Experiment 2 revealed that explicit
prediction of eye fixation position in the same/different task
showed no evidence of integration of information,
suggesting that subjects were unaware of the strategies used
to perform the task. Taken together, these results suggest
that response mode is critical in determining when people
integrate information across categories when making
inductions and that the single category focus found in
previous research on category-based induction may result
from conscious reasoning strategies. These results are
consistent with the findings of Chen et al. (in press), that
speeded catching of a stimulus also showed integration
across categories, but verbal predictions did not. These
results also help explain the discrepancy between studies of
induction in reasoning vs. perception and action.
Our findings suggest that implicit responses can, at least
sometimes, lead to greater use of available information than
our conscious, explicit responses do. This is particularly
important because many everyday predictions are about
items whose categorizations we may be unsure of. Doctors
may have to predict which treatment is most likely to work
even though they are not certain what the correct diagnosis
is. A person who is walking alone at night and sees an
unknown person approaching may have to decide whether
to avoid the person despite being unsure whether that person
belongs to the category of mugger or pedestrian. The results
of the present experiments help in understanding which
situations and contexts people are most likely to consider
alternative possibilities and make predictions based on
relevant information from them.
Additionally, many of these inferences can be made either
implicitly or explicitly (e.g., one might run upon seeing an
unknown person approaching, but given more time, one
may exclude less likely possibilities and act as if certain that
the unknown person is a pedestrian). In fact, in social
psychology, a similar distinction has been made between
automatic and controlled processes in prejudice. Automatic
processes are often associated with stereotype activation (a
type category-based induction) which, in low-prejudice
people, conflicts with explicit attitudes and is inhibited in
favor of explicit beliefs (Devine, 1989). Thus, the explicit
system’s bias to disregard or avoid information from
alternative categories (that made it less normative in our
task) could, in other cases, lead to more normative
responses. Our research shows that this distinction is crucial
for understanding when category-based predictions are more
likely to be accurate or inaccurate.

321

