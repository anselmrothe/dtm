UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
From Minor Mishap to Major Catastrophe: Lexical Choice in Miscommunication

Permalink
https://escholarship.org/uc/item/62w371w9

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Roche, Jennifer
Paxton, Alexandra
Ibarra, Alyssa
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

From Minor Mishap to Major Catastrophe: Lexical Choice in Miscommunication
Jennifer M. Roche (jroche@bcs.rochester.edu) a
Alexandra Paxton (paxton.alexandra@gmail.com)b
Alyssa Ibarra (aibarra@bcs.rochester.edu) a
Michael K. Tanenhaus (mtan@bcs.rochester.edu) a
a

b

Brain and Cognitive Sciences, University of Rochester
Rochester, NY 14627 USA

Cognitive and Information Sciences, University of California, Merced
Merced, CA 95343 USA

Abstract
Miscommunication is often regarded as noise or uninformative in
psycholinguistic research. However, Coupland et al. (1991)
suggest that miscommunication can provide rich information about
how interlocutors come to communicate successfully. Successful
communication necessarily needs the individuals involved to
coordinate and update their mutual knowledge, experiences,
beliefs, and assumptions. However, the process of updating this
information may be ridden with unsuccessful attempts that
eventually help interlocutors reach a common goal. This study
evaluates the relative contribution of linguistic factors to
communicative success, based on verbal grounding (e.g., mutual
agreement on a referent) and visual congruency (e.g., interlocutor’s
visual environments match or mismatch) during a collaborative
task. We show that varying levels of communicative success are
laden with rich linguistic information that may uncover interesting
aspects of successful and less successful communication.
Keywords:
Joint
action;
grounding;
successful
communication; miscommunication; psycholinguistics.

Introduction
Interactive language, in particular face-to-face interactive
conversation, is the most canonical form of language use
(Clark, 1992; Goodwin & Duranti, 1992). In interactive
conversation, interlocutors are typically both speakers and
listeners (addressees) and they often are conversing to
achieve joint goals. Nonetheless, most research on human
language processing focuses on the speaker and the listener
as individual cognitive agents in non-interactive tasks.
There are important exceptions. For example, a large
body of work has used the Edinburgh Map Task (Brown et
al., 1983) to address a range of psycholinguistic issues. In
this task two interlocutors collaborate, with the director
guiding the matcher to reproduce a route printed on the
director’s map. Aist and colleagues developed a “fruit cart”
domain as a vehicle for eliciting human language production
for (a) dialogue system research and development and (b)
psycholinguistic research (Aist, Campana Allen, Swift &
Tanenhaus, 2012). Senft (2002, 2007) developed a number
of domains to evaluate lexical choice in spatial terms during

a space game and tinker toy task for cross-cultural analysis.
Brown-Schmidt, Tanenhaus and colleagues have adopted a
complementary strategy, using targeted language games to
produce trial-like structure in unrestricted interactive
conversation to address specific psycholinguistic issues with
real-time response measures, such as visual world eyetracking (e.g., Brown-Schmidt, Gunlogson & Tanenhaus,
2008; Brown-Schmidt & Tanenhaus, 2008).
In this paper we provide a preliminary report on a project
using a new domain intended to examine how referential
domains are constructed, updated, accepted and rejected
during a goal-driven task, with naïve participants and
unrestricted speech. Here we examine how the language
used in grounding might be diagnostic of, and contribute to,
miscommunication.
The domain is similar to those discussed by Sentf (2002)
and is designed to allow a face-to-face interaction through a
barrier separating the two participants. This task involves a
collaborative dyadic interaction that required participants to
instruct each other in building a bloco™ animal figure
from abstract three-dimensional puzzle-like pieces (see
Figure 1 for an image of the animals; Methods for full task
description).
The bloco™ paradigm was created to serve a number of
purposes. First, we wanted a domain that would lend itself
to investigating both generation and interpretation of
referring expressions. Secondly, we wanted to observe how
referring expressions change when the goals change. For
example, during the build stage pieces that were initially
referred to using conceptual pacts, such as “the Christmas
tree” would eventually assume a different identity, “the
body” (see the green item on the left of Figure 2). This
domain offers a rich domain for investigating grounding.
The domain creates a corpus that contained frequent
communication
failures
(e.g.,
confusions
and
misunderstandings) that had to be resolved. These failures in
communication are often regarded as noise and therefore
uninformative in psycholinguistic research (Coupland,
Giles, & Weimann, 1991; Keysar, 2007). However, as

3303

Coupland et al. (1991) argue, communication failure could
provide valuable information about how interlocutors come
to communicate successfully, much like speech errors can
provide important insights into planning processes in
language production.
Successful
communication
necessarily
requires
interlocutors to coordinate and regularly update their mutual
knowledge, experiences, beliefs, and assumptions (e.g.,
Clark & Carlson, 1982; Clark & Marshal, 1981). However,
the process of updating this information may be riddled with
unsuccessful attempts that eventually help the interlocutors
reach a common goal.
Some researchers have provided insights into how
interlocutors might resolve communication problems (e.g.,
through ambiguity resolution or asking clarification
questions; see Clark & Brennan, 1991; Haywood, Pickering
& Branigan, 2004; Levelt, 1983; Pickering & Garrod, 2004;
Roche, Dale, Jaeger, & Kreuz, under revision). However,
the literature has minimally, at best, explored the rich
information these failures could provide. For example,
interlocutors’ language is often ambiguous because
ambiguity minimizes effort in production and because a
speaker can usually assume that her addressee can rapidly
use context to infer her intended meaning, perhaps because
it is easier on the production system (e.g., Bard et al., 2007;
Bock, 1986). This can result in utterances that initially
appear to be egocentric. However, once an interlocutor
realizes that her ambiguity might reduce the success of the
interaction, she almost immediately adapts her utterances to
eliminate the type of ambiguity that was confusing for her
listener (Roche, Dale, Jaeger & Kreuz, under revision).
Despite these efforts, the focus of the existing literature
has been primarily on the successful exchange of
information and largely ignores what happens when
interlocutors’ shared knowledge becomes de-coupled. Yet,
miscommunication occurs regularly and can directly impact
the quality and effectiveness of an interaction (McTear,
2008). Therefore, the current study provides a preliminary
analysis of how language reflects and perhaps influences
communicative successes and failures.

Methods

Figure 1: Images of the grasshopper (left) and lizard
(right) animal figures used in the task.
The grasshopper figure consisted of 25 pieces, and the
lizard figure consisted of 28 pieces. Each animal piece was
abstract and did not have a proscribed name (see Figure 2
for example pieces).

Figure 2: Sample of items from the animal figures.
Instruction Cards Each animal figure had a set of
instruction cards, each corresponding to one step of the
building process. The grasshopper and lizard figures
consisted of 13 and 15 instructions cards each, respectively
(see Figure 3 for sample instruction cards).

Figure 3: Sample of the animal figure instruction cards
(right: grasshopper; left: lizard).
Conditions We had a between-subjects condition, in which
dyads instructed each other in collaboratively building an
animal (lizard or grasshopper), but were separated by a
partition1.
Data Recording Three digital cameras recorded the
participant interaction from different angles (left, centerwide, right). All video files were time-aligned and
compressed into a single .mov file using Final Cut Pro.

Participants
Participants were 20 dyads of paid undergraduate students
(N = 40; females = 26; mean age = 19 years) from the
University of Rochester. Participants were native speakers
of American English. All reported normal to corrected
vision and no speech or hearing impairments.

Stimuli
The experiment included two types of bloco™ animal
figures (see Figure 1).

Procedures
Participants were seated across from each other, separated
by a partition. The participants were given identical sets of
bloco™ pieces on identical workspaces. Workspaces
featured a flat, white surface with a black box outline drawn
in each corner. Participants were told that they would be
working together to build identical objects. They were not,
however, told what the resulting object would become. The
1

The design of the experiment was more complex, including a
non-hidden phase that was not analyzed here. In the full design, the
animals were counterbalanced across the possible conditions. For
the purpose of the present analyses, only a subset of the data is
included here.

3304

experiment was divided into two phases: an Item Phase and
a Building Phase.
During the Item Phase, the participants moved the
individual bloco™ pieces into the four boxes on their
workspace. They were told that their workspaces had to
match before they could proceed to the next phase. They
were further instructed to take turns and decide together
how to separate their items.
Once the workspaces matched, they were allowed to
continue to the Build Phase. During the Build Phase, each
participant was given half of the instruction cards in a
predefined order. Participants alternated giving instructions.
They were told that they could ask each other questions and,
more generally, talk freely with one another. The majority
of pairs successfully built matching objects. The
unsuccessful pairs made only minor errors (e.g., wrong
orientation of the animal’s legs).

Measures
Transcription and coding of various behaviors were
annotated from a single workable file that contained a
compressed version of the video files from the three
different angles (left, center-wide, right) to aid in coding.

Coded Measures
The video files of each dyad’s interactions were transcribed.
After transcription, additional measures were coded and
included the following categories: confirmed and negated
utterances, visual congruency, and several standard LIWC
categories (Linguistic Inquiry and Word Count; Pennebaker,
Booth, & Francis, 2001).
Confirmed and Negated Utterances: We divided
utterances that presented new information into two
categories according to whether they were confirmed (e.g.,
yes, uh huh) or negated by the addressee. An utterance was
coded as Confirmed if the partner indicated acceptance of
the new information with an explicit confirmation (e.g.,
with a variant of yes) similar to the Common Ground Units
described by Nakatani and Traum (1999). At each turn, T1
presented a new piece of information. Once T2 accepted this
information it was coded as a Confirmed utterance. For
example:
T1: Uh, that piece, uh it’s in the, the center of box three, it
looks like a bell.
T2: Mhm.
An utterance was coded as Negated if presentation of
new information by T1 was negated or rejected by the T2.
For example:
T1: Ok, so what was the? Put it three rows down.
T2: No, no, no, no, no, three squares to the right.
Visual Congruence. We coded the participants’ workspaces
as either matching or mismatching (congruent) or

mismatching (incongruent) throughout the task (e.g., the
orientation of the object being described). Here we focus on
within-trial instances of congruent and incongruent targets.
Congruency and Confirmed/Negated utterances were used
to create a 2 x 2 contingency table of the different types of
communicative success (see next section).
Communicative Success was measured relative to the
congruent and incongruent physical environments in
conjunction with the verbal acknowledgement of the
information presented. Often, interlocutors believed their
objects were congruent when in fact they mismatched in
ways that interfered with the goal in that trial. A
contingency table illustrates the four types of outcomes
created by crossing confirmed and negated utterances with
object congruency: Confirmed Congruent (CC), Confirmed
Incongruent (CI), Negated Congruent (NC), and Negated
Incongruent (NI; see Table 1 for the outcome labels).
A CC outcome is an instance of Successful
Communication. The new information is confirmed (and
acted upon) and the objects are indeed visually congruent.
For example, one member of the pair says, “Yes, I got it,”
when in fact she did “get” it. A CI (Unrecognized
Miscommunication) outcome occurs when one of the
participants accepts the information presented, but the
objects in her visual workspace do not match those of her
partner (e.g., saying, “Yes, I got it,” when she did not
actually “get” it). The pair believes they have successfully
communicated, but in fact they have not. A NC outcome
(Unrecognized Success) occurs when a participant negates
her partner’s statement, but her visual workspace objects
matches her partner’s (e.g., saying, “No, I didn’t get it,”
when she actually did “get” it). The pair has actually
succeeded but believe they have not. Finally, in an NI
outcome, the pair has recognized the miscommunication.
Recognized Miscommunication occurs when at least one of
the participants fails to ground, and their visual workspace
objects do not match (e.g., saying, “No, I didn’t get it,”
when in fact she did not “get” it).
Table 1: Communicative Success Outcome Variables.
Acceptance Type
Confirmation
Negated

Congruent
Successful
Communication

Visual Environment
Incongruent
Unrecognized
Miscommunication

Unrecognized
Success

Recognized
Miscommunication

LIWC Categories were selected to determine the types
of linguistic categories that contribute to the varying
outcomes. Given the nature of the predetermined LIWC
categories, we do not venture to argue that this provides a
thorough linguistic analysis of miscommunication. The
main objective was to use these general categories as a firstpass attempt to see what linguistic patterns emerge as

3305

miscommunication unfolds. These included the words per
statement, assent, negation (i.e., different than “Negated”
described above), cognitive mechanisms, personal
pronouns, spatial, and perceptual linguistic forms. The
LIWC categories are structured to distinguish at most
general predicate classes (e.g., cognitive mechanisms) as
well as linguistic particles whose function conveys degrees
of interlocutor agreement (e.g., assent, negation).
Within the predetermined LIWC categories, we also
created novel subcategories for assent and negation that
included specific words (see Table 2 for the categories
evaluated and examples within a category). Assent and
negation were subdivided because it seemed at the time of
transcription that varying forms of these categories could
interact in interesting ways depending on the type of
success.

In order to further explore the relationship between
language and outcome, we examined the four different
outcomes [Successful Communication (SC), Unrecognized
Miscommunication (UM), Unrecognized Success (US) and
Recognized Miscommunication (RM)] as predicted by
words per statement, assent (strong yes and weak yes),
negation (strong and weak negation), and LIWC category
measures (personal pronouns, cognitive mechanisms,
perceptual, and spatial categories; Croissant, 2012). The
results from this model suggest that the measures
successfully predict the different outcomes (x2 = 1105.9, p <
.001; see Figure 5 for the proportion of occurrence within
each category). Additionally, the evaluation of the
significant odds ratios below represent the comparison of
each linguistic category relative to the SC trials and are
provided with regards to each of the types of communicative
success (see Table 3 for results).

Table 2: LIWC and linguistic category examples.

Personal Pronoun
Cognitive
Mechanism
Physical
Assent

Subcategories
Strong Negation
Weak Negation
First Person
Second Person
Insight
Certainty
Perceptual
Spatial
Strong Yes
Weak Yes

Example
No, nope
Don’t, didn’t
I, We
You
Think, know
Always, never
See, hear, feel
Top, bottom
Yes, okay
Mhm, uh huh

p(occurrence)	  

Category
Negation

0.7	  

p(occurrence)	  

0.3	  
0.2	  

SC	  

UM	  

US	  

RM	  

Figure 5. Mean and standard errors of the proportion of
occurrence within each of the types of communicative
outcomes.
Table 3: Significant predictors for the four outcomes, with
SC as the reference category: *p < .05; **p < .01, ***p < .001.

US

UR

0.8	  
0.6	  
Congruent	  

RM

Incongruent	  

0	  
Negate	  

0.4	  

0	  

We first established that, as expected, assenting and
negating words were associated with visual congruency. We
used a mixed logit model (Jaeger, 2008) to evaluate the
proportion of visual incongruency, as predicted by assenting
and negating words (LIWC categories), with trial set as a
covariate and dyad as a random effect. The results from this
analysis revealed that there were significantly fewer
assenting words (b = -.177, z = -4.973, p < .001), but more
negating words (b = .392, z = 5. 210, p < .001) when visual
incongruence occurred (see Figure 4 for means and standard
errors for assent and negation for the visual congruency
categories). Nonetheless, it is striking how often assenting
words are used when the objects are incongruent.

0.2	  

0.5	  

0.1	  

Results

0.4	  

0.6	  

Assent	  

Figure 4. Mean and standard errors for negation and assent
categories for the visual congruency measure.

3306

Linguistic Category
WPS
Weak Yes
Strong Negation
Weak Negation
We
Insight
Perceptual
WPS
Strong Yes
Strong Negation
I
You
Spatial
WPS
Strong Negation
Weak Negation
You
Insight
Certainty

Odds Ratio
1.053
1.589
129.907
17.439
1.474
4.468
1.229
0.983
0.727
6.463
1.767
1.207
1.071
1.051
207.009
21.919
1.333
3.699
1.931

t-value
4.083***
2.528*
13.621***
10.9857***
2.361*
7.059***
3.268**
-1.982*
-3.452***
5.159***
5.943***
2.681**
2.708**
3.441***
14.655***
11.279***
2.317*
5.447***
2.077*

Conclusions
Overall, our results suggest that interlocutors use
language in interesting ways when they are having problems
with communication. The results for words per statement
suggest that using more words can be both helpful and
harmful. For example, during US (Unrecognized Success)
and RM (Recognized Miscommunication), interlocutors use
more words. This might suggest that explaining things too
extensively may prevent the listener from encoding all of
the information presented due to the limits of processing
load. This overload may then result in loss of essential
information leading to a communication breakdown.
However, fewer words per statement were also associated
with UM (Unrecognized Miscommunication) relative to SC
(Successful Communication). This might suggest that not
providing enough detailed information may furnish the
listener with insufficient information to reject the speaker’s
statement when necessary.
Interlocutors’ use of personal pronouns (i.e., I, you, and
we) may be indicative of a unique role of perspective taking
in creating and repairing unsuccessful communication, as
seen in US, UM, and RM. Specifically, there were more
instances of saying I and you, during UM (and you for RM),
suggesting that the talkers may be attempting to reconcile
differing perspectives. Additionally, the increased
occurrence of we during US suggests that interlocutors
attempt to find a shared perspective when a “minor mishap”
occurs. These findings are interesting given a common
interpretation of speakers as primarily egocentric (e.g.,
Keysar, 2007). While there was no difference in the use of
personal pronouns during Successful Communication (SC),
it would seem as if dyads tended to respond somewhat
egocentrically during instances of less-than-successful
communication. However, miscommunicating may have
allowed them to (1) remedy a communication breakdown by
highlighting their individual and shared perspectives and (2)
access more information. Thus, it appears that a dyad may
reference their partner’s point of view to help re-couple their
perspectives.
Additionally, use of spatial terminology increased during
Unrecognized Miscommunication (UM). Anecdotally, we
noticed that participants’ interpretation of each other’s use
of spatial orientation was often problematic. For example,
one participant’s use of the word “top” was often not the
same as her partner’s, especially when the animal pieces
were not similarly oriented in space. This type of mistake
was not quickly realized, and it was not until a “major
catastrophe” happened (i.e., they could not continue with the
build until the problem was resolved) that they were able to
reconcile each other’s meanings of spatial terms. Although
intuitively simple, the uses of spatial terms appear to be
highly perspective-dependent and can result in
communication problems if interlocutors’ perspectives are
not aligned.
Participants appear to use assent and negation differently
during various outcomes. The use of strong and weak
confirmation words (such as yes and mhm) may carry

different meaning depending on the context. One
explanation of how interlocutors may use the varying forms
of confirming and negating words may be that these words
help the talker keep track of what they are doing and how
they understand it while simultaneously communicating
their state of mind to their partner (e.g., saying yes and no to
themselves while trying to interpret an instruction). This
may be especially important when the talker is confused
about how to describe something. In these cases, confirming
and negating words may cue the listener to help the talker
find the best way to describe something. Therefore, an
indirect expression of confirmation and negation may be a
cue to the mental state of the speaker.
Alternatively, a confirmation may sometimes be a social
nicety. Anecdotally, participants sometimes use a weak
form of yes while clearly ignoring their partner (e.g., doing
something completely different or unrelated to the current
instruction). In these cases, the confirmation may be a
socially acceptable filler word used to mask his or her
inattention.
Finally, insight words (e.g., think, know) are more
prevalent during both Unrecognized Success (US) and
Recognized Miscommunication (RM). The prevalence of
these words in the US outcomes is particularly interesting.
This may indicate some degree of uncertainty. Additionally,
interlocutors were more likely to use certainty words during
Recognized Miscommunication (RM).
Some of our results are clearly expected given both
common sense and previous observations (e.g. see Senft,
2002 for similar results for a tinker-toy task with Trobriand
Islanders). For example, interlocutors confirm to ground and
they negate to indicate confusion. Nonetheless, there are
clearly subtle differences in the language used when
participants are grounding successfully (SC) and incorrectly
(UM). RM results in an increase in spatial language that
reflects a negotiation about differences in perspective. This
indicates that interlocutors recognize the importance of
shared
perspective
to
resolve
confusion
when
communication is unsuccessful. Speakers may say less and
appear to disregard listeners’ perspective in an attempt to
balance egocentrism and audience needs; providing less
detail allows speakers to sample the space of the interaction
cheaply and easily, while listeners’ requests for additional
information continually refine speakers’ understanding of
listeners’ needs.
The main outcome of this preliminary analysis is that
different communicative outcomes are associated with
subtle differences in language use. This provides insight
into how language reflects and influences how
miscommunication is recognized and resolved. In order to
establish this, however, we will need to investigate whether
the language used in miscommunication predicts more
global measures of success in the task. For example, RM
might result in strategies that will improve performance
because it forces interlocutors to negotiate about and resolve
alignment of their perspectives. In contrast, failures to
recognize the correct state (US) might result either in

3307

interlocutors discounting each other’s confirmations or
alternatively becoming more sensitive to subtle cues that
their interlocutor is uncertain.
While this initial pass of the bloco™ corpus (currently
lacking measures of reliability for our coding procedure)
should be interpreted mindfully, our findings do provide
interesting preliminary insights into how lexical choice
influences communicative success. Additionally, the
categories investigated with LIWC may seem somewhat
arbitrary, but the category labels selected were standard and
validated LIWC labels (e.g., cognitive mechanisms). In the
current form, these categories are not meant to map onto any
specific linguistic forms or stages of language processing.
Nevertheless, we view the patterns that emerged through
these categories as a springboard for more thorough
analyses. For example, within the categories of negation and
assent, we can next look at specific forms of confirmation to
study how they emerge as a function of certainty. Further
analyses of the corpus should provide data that will help
evaluate these hypotheses.

Acknowledgments
Special thanks go to our undergraduate research assistants at
University of Rochester (University of Rochester, Chelsea
Marsh, Eric Bigelow, Derek Murphy, Melanie Graber, and
Anthony Germani) and at University of California, Merced
(UC, Merced, Chelsea Coe and J.P. Gonzales). Thanks also
go to Rick Dale (University of California, Merced) and
Rachel Wu (University of Rochester) for their valuable help,
comments and feedback. Preparation of this manuscript was
supported by grants from the National Institute of Health
(R01 HD027206) to Michael Tanenhaus.

References
Aist, G., Campana, E., Allen, J., Swift, M., & Tanenhaus,
M. (2012). Fruit carts: A domain and corpus for research
in dialogue systems and psycholinguistics. Computational
Linguistics, 38(3), 469-478.
Bard, E., Anderson, A., Chen, Y., Nicholson, H., Harvard,
C. & Dazel-Job, S. (2007). Let’s you do that: Sharing the
cognitive burdens of dialogue. Journal of Memory and
Language, 57(4), 616-641.
Bock, K. (1986). Meaning, sound, and syntax: Lexical
priming in sentence production. Journal of Experimental
Psychology: Learning, Memory and Cognition, 12, 575586.
Brown, G., Anderson, A., Yule, G., & Shillcock, R. (1983).
Teaching talk. Cambridge, U.K.: Cambridge University
Press.
Brown-Schmidt, S., Gunlogson, C. & Tanenhaus, M.
(2008). Addressees distinguish shared from private
information when interpreting questions during
interactive conversation. Cognition, 107, 1122-1134.
Brown-Schmidt, S. & Tanenhaus, M. (2008). Real time
investigation of referential domains in unscripted
conversation: A targeted language game approach.
Cognitive Science, 32, 643-684.

Clark, H.H. (1992) Arenas of language use. Chicago:
Chicago University Press.
Clark, H. H. & Carlson, T. (1982). Hearers of speech acts.
Language, 58, 332-373.
Clark, H. H. & Brennan, S. (1991). Grounding in
communication. In L. B. Resnick, J. Levine & S.D
Behread (Eds). Perspectives on Socially Shared
Cognition. (pp. 222-233). Washington, DC: American
Psychological Association.
Clark, H. H. & Marshal, C. (1981). Definite reference and
mutual knowledge. In A. Joshi, B. Webber & I. Sag
(Eds.), Elements of Discourse Understanding, (pp. 1063).
Coupland, N., Giles, H. & Wieman, J. M. (1991).
Miscommunication and problem talk. Newbury Park:
Sage.
Croissant, Y. (2007). Mlogit: Multinomial logit model. R
package version 0.2-3.
Garrod, S. & Pickering, M. (2004). Why is conversation so
easy? Trends in Cognitive Science, 8(1), 8-11.
Goodwin, C. & Duranti, A. (1992). Rethinking context:
Language as an interactive phenomenon. Cambridge,
U.K., Cambridge University Press.
Haywood, S., Pickering, G. & Branigan, H. (2004). Do
speakers avoid ambiguities in dialogue? Psychological
Science, 16(5), 362-366.
Jaeger, T. F. (2008). Categorical data analysis: Away from
ANOVAs (transformation or not) and towards logit mixed
models. Journal of Memory and Language, 59(4), 434446.
Keysar, B. (2007). Communication and miscommunication:
The role of egocentric processes. Intercultural
Pragmatics, 4, 71-84.
Levelt, W. (1983). Monitoring and self-repair in speech.
Cognition, 14(1), 41-104.
McTear, M. (2008). Handling miscommunication: Why
bother? Recent Trends in Discourse and Dialogue, 39,
101-122.
Nakatani, C. & Traum, D. (1999). Coding discourse
structure in dialogue. University of Maryland Institute for
Advanced Computer Studies Technical Report, 1, 1-42.
Pennebaker, J.W., Booth, R. J., & Francis, M. E. (2007).
Linguistic Inquiry and Word Count: LIWC [Computer
Software]. Austin, TX: LIWC.net.
Pickering, M. & Garrod, S. (2004). Toward a mechanistic
psychology of dialogue. Behavioral and Brain Sciences,
27, 169-226.
Roche, J., Dale, R., Jaeger, T. F. & Kreuz, R. J. (under
revision). Learning to avoid syntactic ambiguity: Don’t
rush the navigator.
Senft, G. (2002). Frames of spatial reference in Kilivila.
Studies in Language, 25(3), 521-555.
Senft, G. (2007). The Nijmegen space games: Studying the
interrelationship between language, culture and cognition.
In J. Wassman & K. Stockhaus (Eds.). Person, Space and
Memory in the Contemporary Pacific: Experiencing New
Worlds (pp. 224-244). New York: Berghan Books.

3308

