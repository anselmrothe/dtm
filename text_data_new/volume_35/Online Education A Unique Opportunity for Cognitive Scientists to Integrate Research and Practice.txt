UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Online Education: A Unique Opportunity for Cognitive Scientists to Integrate Research and
Practice

Permalink
https://escholarship.org/uc/item/06v3k982

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Williams, Joseph Jay
Renkl, Alexander
Koedinger, Ken
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Online Education: A Unique Opportunity for Cognitive Scientists to Integrate
Research and Practice
Joseph Jay Williams (joseph_williams@berkeley.edu)

Alexander Renkl (renkl@psychologie.uni-freiburg.de)

Department of Psychology, University of California at Berkeley

Psychological Institute, University of Freiberg

Ken Koedinger (koedinger@cmu.edu)

John Stamper (jstamper@cs.cmu.edu)

Human Computer Interaction Institute, Carnegie Mellon University

Human Computer Interaction Institute, Carnegie Mellon University

Abstract

provides an unprecedented opportunity to simultaneously
carry out basic and applied research. When experimental
manipulations correspond to comparisons of instructional
effectiveness, stimuli are educational materials, and
dependent measures are students’ learning outcomes,
experimental methodology from cognitive science can be
used to iteratively improve the pedagogical principles
incorporated into online educational resources. Rather than
years of laboratory research that “suggest” instructional
principles or are eventually followed by a laborious
classroom study, the steps from basic to translational
research are greatly simplified.
Moreover, the product of research programs that
investigate online learning is not only new scientific
knowledge, but specific products that concretely instantiate
theories and learning principles. These proven and
iteratively improved resources can be provided directly to
students for use as they exhibit such great fidelity to
research context. And using the Internet, they can be
disseminated to hundreds of thousands of students over an
extended period of time, all across the world – a clear
contribution of cognitive scientists to public education.

That there is a rapid expansion of online education is much
better understood than what its consequences will be. This
symposium considers that one key feature of “real-world”
education that takes place on the Internet is that it provides a
high level of experimental control and automatic data
collection & analysis, which can support cognitive science
research that was previously only possible in laboratory
settings and small-scale educational environments. The
presenters discuss the unprecedented opportunities online
learning provides for conducting research in ecologically
valid contexts: linking existing laboratory experiments to
relevant online contexts, personalizing adaptive instruction,
embedding in vivo research studies of education, and using
the vast amount of high quality data available. The product of
such work is not only theories and empirical discoveries that
better characterize learning, but also the opportunity to
directly translate these into practical benefits to students
through concrete improvements to educational resources.
Keywords: learning; education; technology; online
education; online learning; e-learning; intelligent tutors;
educational data mining;

Laboratory experiments and classrooms rarely overlap in
the physical world, much to the chagrin of educational
psychologists. But researchers increasingly use computers
and the Internet to run experiments, and the recent explosion
of online education now brings student learning into the
very same digital medium. Hundreds of thousands of
students take Massive Open Online Courses (MOOCs from
Coursera, Udacity, EdX) at the university level, use
websites
like
www.mathtutor.cmu.edu,
www.khanacademy.org or www.mathalicious.com that are
populated with K-12 videos & interactive exercises, not to
mention a host of supplementary online educational
resources that can be delivered over devices as ubiquitous as
smartphones.
These web-based resources offer the potential for
extensive novel research on learning (Anderson, 2008; Ally,
2004; Linn et al, 2004; Pea, 2003). One distinctive feature is
the possibility of embedding in vivo randomized
experimental comparisons (Koedinger et al, 2012) into these
(now) ecologically valid online educational environments.
Furthermore, unlike educational environments in bricksand-mortar education, in a digital medium there can be
precise control over materials and instructions, and
systematic collection of data from large samples (Stamper et
al, 2012). In addition to investigating learning processes in
authentic educational contexts, studying online learning

Mapping laboratory studies to online educational
settings
In the context of his research on the role of explanation in
learning, Joseph Jay Williams presents a perspective from
basic experimental psychology on finding fruitful
connections between lab experiments and experimental
manipulations embedded in authentic online educational
resources. He discusses the interplay and transitions
between typical lab experiments (research on explaining
membership in artificial categories, Williams & Lombrozo,
2010), to online studies using convenience samples from
Amazon Mechanical Turk (in which explaining promotes
learning of mathematics, Williams et al, 2012), and
experiments implemented using identical mathematics
exercises on Khan Academy’s educational platform, but
with real students who visit the site for genuine help with
authentic schoolwork.
This approach blends rigorous experimentation in
contexts with different levels of control, rapid iterative
improvement, and the development of an ecologically valid
educational resource. Such web resources serve a basic
research goal, as (for example) the structure and dynamics
of an interactive video or exercise reflects a concrete and
empirically supported instantiation of theoretical principles

113

and empirical discoveries that would otherwise be verbally
communicated – reminiscent of the benefits of
computational models. They also serve a clear practical
goal, as the products of research are empirically evaluated
and multiply revised resources that have been shown to
work in learning online. They can therefore be disseminated
using the massive scale of the internet, to improve education
for thousands of students over an extended period of time.

complementary strengths and disseminate these benefits on
a large scale.

Automated improvement of instructional
systems using educational data mining
John Stamper runs Datashop, the largest openly available
repository of detailed student learning data, with learning
and instructional events logged as often as every 10
seconds, scored, and tagged based on models of student
learning. He will discuss how educational data mining and
statistical models of students’ learning can be used to infer
improvements to instructional systems, automatically
develop intelligent tutoring systems, and shed light on many
of the problems that typically are solvable only through
extensive human investment.

Using Eye-Tracking and Rapid Assessment to
Detect and Address Knowledge Gaps During
Learning
Alexander Renkl has conducted extensive research in
computer environments, such as investigating how learning
from worked examples can be enhanced by the use of
scaffolding, fading and other instructional design features.
He reports a project that bears on the ability of online
environments to personalize instruction.
The project develops and researches an adaptive approach
to closing gaps in students’ knowledge that remain after
initially studying the learning materials. Rapid assessment
tasks are interspersed in the learning environment to identify
the knowledge deficits in individual students, which can
then be targeted by prompting learners to engage in
remedial activities. In the first experiment, university
students (N = 71) learned about mitosis in a multimedia
learning environment. When rapid assessment tasks
indicated gaps in students’ knowledge, the experimental
manipulation was to randomly assign them to one of three
different types of prompts, hypothesized to be optimal for
the particular deficit. However, we found that each type of
prompt was equally effective in closing the knowledge gaps
identified by rapid assessment.
In the second experiment we obtained further results as to
the effects of different prompts – finding that ostensibly
“enriched” prompts even led to sub-optimal effects.
Comparing our results to the final test of learning outcomes,
we identified our rapid assessment tasks as failing to detect
important knowledge gaps. Rather than risk disturbing
learning by increasing the number of rapid assessment tasks,
we now integrate eye-tracking data to improve our
assessment. We use this data to select rapid assessments to
verify the presence of a knowledge gap. Pilot data suggests
such a combined approach is more effective for learning.

References
Anderson, T. (2008). The theory and practice of online
learning. Au Press.
Ally, M. (2004). Foundations of educational theory for
online learning. Theory and practice of online learning, 331.
Koedinger, K. R., Aleven, V., Roll, I., & Baker, R. (2009).
In vivo experiments on whether supporting metacognition
in intelligent tutoring systems yields robust learning. In D.
J. Hacker, J. Dunlosky, & A. C. Graesser
(Eds.), Handbook of Metacognition in Education (pp.
897-964). The Educational Psychology Series. New
York : Routledge.
Linn, M. C., Davis, E. A., & Bell, P. (Eds.). (2004). Internet
environments for science education. Mahwah, NJ:
Lawrence Erlbaum Associates.
Means, B., Toyama, Y., Murphy, R., Bakia, M., & Jones, K.
(2010). Evaluation of evidence-based practices in online
learning: A meta-analysis and review of online learning
studies.
Pea, R. D. (Ed.). (2003). Planning for two transformations
in education and learning technology: Report of a
workshop. National Academy Press.
Renkl, A. (2011). Instruction based on examples. In RE
Mayer & PA Alexander (Eds.), Handbook of research on
learning and instruction (pp. 272-295). New York, NY:
Routledge.
Stamper, J., Lomas, D., Ching, D., Linch, K., Ritter, S.
(2012) Internet Scale Experimental Design and
Deployment for Educational Games using BrainPOP.
In Proceedings of the 8th Games + Learning + Society
Conference (GLS 2012). Madison, WI. pp. 275-281.
Williams, J.J. & Lombrozo, T. (2010). The role of
explanation in discovery and generalization: evidence
from category learning. Cognitive Science, 34, 776-806.
Williams, J. J., Walker, C. M., & Lombrozo, T. (2012).
Explaining increases belief revision in the face of (many)
anomalies. In N. Miyake, D. Peebles, & R. P. Cooper
(Eds.), Proceedings of the 34th Annual Conference of the
Cognitive Science Society (pp. 1149-1154). Austin, TX:
Cognitive Science Society.

In-vivo experiments with cognitive tutors
As director of the Pittsburgh Science of Learning Center and
one of the pioneers in the development of intelligent
tutoring systems, Ken Koedinger has helped set the
standards of rigorous research in realistic educational
contexts. He discusses how cognitive tutors can be used to
conduct in vivo experiments in classroom environments,
collecting sophisticated learning measures and giving
personalized feedback to learners. He considers how
cognitive tutors and in vivo experiments can be integrated
with online education platforms to take advantage of

114

