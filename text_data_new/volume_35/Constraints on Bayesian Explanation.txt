UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Constraints on Bayesian Explanation

Permalink
https://escholarship.org/uc/item/2sf1p3qd

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Kwisthout, Johan
Van Rooij, Iris
Colombo, Matteo
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Constraints on Bayesian Explanation
Johan Kwisthout (j.kwisthout@donders.ru.nl), Iris van Rooij (i.vanrooij@donders.ru.nl) [moderator]
Radboud University Nijmegen, Donders Institute for Brain, Cognition and Behaviour
Montessorilaan 3, 6525 HR Nijmegen, The Netherlands

Matteo Colombo (m.colombo@uvt.nl)
Tilburg Center for Logic and Philosophy of Science, Tilburg University
PO Box 90153, 5000 LE Tilburg, The Netherlands

Carlos Zednik (czednik@uos.de)
Institute of Cognitive Science, University of Osnabrück
49069 Osnabrück, Germany

William A. Phillips (w.a.phillips@stir.ac.uk)
University of Stirling, School of Natural Sciences
Stirling FK9 4LA Scotland, UK,
and Frankfurt Institute of Advanced Studies, Germany
Keywords: Bayesian inference, levels of explanation,
constraints, tractability, coherent infomax, computational
complexity, unification, philosophy of science

science, cognitive neuroscience, information theory,
machine learning, and theoretical computer science.

Introduction

A complexity-theoretic perspective on the
preconditions for Bayesian tractability

The hypothesis that human cognition may be well
characterized as a set of Bayesian computations has been the
topic of considerable debate over the last two decades.
Recently, critics have argued that this hypothesis is either
unlikely to be true or otherwise too unconstrained to be
particularly useful for explaining cognition (e.g., Bowers &
Davis, 2012), whereas proponents have defended their
position by stating that the Bayesian perspective has been
misunderstood, is not necessarily in conflict with other
perspectives on cognition, and can still be explanatorily
useful as a framework for cognitive science even if underconstrained in many ways (e.g., Griffiths, Chater, Norris, &
Pouget, 2012). Our position in this debate is that both sides
of this debate may be right as well as wrong: Proponents
may be right that the Bayesian perspective has something
uniquely useful to bring to cognitive science (and then the
critics are wrong in their denial of this); yet, the critics may
be right that cognitive theories are explanatorily useful only
if properly constrained (and then proponents are wrong in
their denial of this).
With this perspective in mind, we wish to move the
debate forward in a constructive way by bringing in new
perspectives and proposing novel constraints that can be
exploited for purposes of improving the explanatory values
and virtues of Bayesian explanations of cognition.
Specifically, with this symposium we aim to focus on how
constraints on Bayesian explanations can be exploited in
ways that are yet underrepresented and underexplored.
The symposium brings together researchers from various
disciplines, contributing a variety of perspectives on how
Bayesian explanations can be fruitfully constrained, drawing
on theories, analyses, and results from philosophy of

Johan Kwisthout (joint work with Iris van Rooij)
Many Bayesian computations have been proven to be
computationally intractable (NP-hard) for unconstrained
input domains, even if only an approximate solution is
sought. Informally, this means that computations postulated
by Bayesian models can take astronomical amounts of time
for their completion even for realistic sized inputs. This
property seems to be in strong contrast with the ease and
speed with which humans can typically make the inferences
that are modeled by Bayesian models. Some critics of the
Bayesian approach have taken this property of Bayesian
models as a reason to reject the entire approach (e.g.,
Gigerenzer, 2008). In contrast, I propose that it means that
tractability forms a useful constraint on Bayesian
explanations of cognition. In this talk, I will elucidate the
use of complexity-theoretic concepts and techniques for
making Bayesian models meet the tractability constraint,
building on known results from theoretical computer science
(e.g., Kwisthout, 2011). I will furthermore report on recent
complexity results that have lead to novel hypotheses about
the conditions under which Bayesian inferences can be
tractably approximated (Kwisthout & van Rooij, 2013).

Bayesian cognitive science, unification, and
explanation
Matteo Colombo (joint work with Stephan Hartmann)
A recurrent claim is that the greatest value of studying
cognitive phenomena such as perception, action,
categorization, and decision-making, within the Bayesian
framework consists in its unifying power. Several Bayesian

87

probabilities given only what is known. Second, Jaynes’s
desiderata can only be met in simple cases. Third, contextual
modulation operates via likelihoods, not priors (Kay &
Phillips, 2010). Fourth, inferences are the common currency
of feed-forward transmission, not prediction errors. Fifth,
modulatory interactions within hierarchical levels are at
least as crucial as those between levels.
I will also note that, in addition to the constraints imposed
by Jaynes’s desiderata, the use of prior event frequency is
constrained by the curse-of-dimensionality. It becomes
rapidly less useful as dimensionality of the event space
increases because the number of possible locations within it
then increases exponentially.
Finally, I will briefly outline the possibility that functional
specializations combined with various cellular and localcircuit mechanisms for context-sensitive gain-control have
evolved within mammalian cortex to restrict the problems to
be solved by neuronal inference to what is feasible within the
above constraints, as formulated using information theoretic
concepts in the theory of coherent infomax (Phillips, 2012).

cognitive scientists, however, implicitly assume that
unification is obviously linked to explanatory power. But
this link is not obvious (e.g., Morrison, 2000).
A crucial feature of adequate explanations in the
cognitive sciences is that they reveal aspects of the causal
structure of the mechanism that produces the phenomenon
to be explained. The kind of unification afforded by the
Bayesian framework to cognitive science does not
necessarily reveal the causal structure of a mechanism (cf.
Colombo & Seriès, 2012). Bayesian unification is the
product of the mathematics rather than of a causal
hypothesis concerning how different cognitive phenomena
are brought about by a single type of mechanism.
Nonetheless, Bayesian unification can place fruitful
constraints on causal mechanical explanation, which will be
elucidated in this talk.

Bayesian modeling and heuristic strategies
for model-development
Carlos Zednik (joint work with Frank Jäkel)

References

It is generally agreed that Bayesian models in cognitive
science operate at Marr’s computational level of analysis
(Marr, 1982). Unfortunately, it remains unclear exactly how
the computational, algorithmic, and implementation levels
are related.
This talk explicates inter-level relationships in terms of
heuristic strategies for model-development (Zednik, in
press). Specifically, Bayesian computational-level models
play the heuristic role of suggesting possible algorithms to
compute a particular function, and of suggesting particular
ways of delineating and interpreting the components of a
physical mechanism. In turn, algorithmic and mechanistic
models specify memory, time, and resource limitations that
constrain the cognitive tasks described by Bayesian models.
In contrast to the view that Bayesian computational-level
modeling is independent of low-level considerations, on this
view the development of Bayesian models is constrained by,
and at the same time itself constrains, the development of
models at lower levels of analysis.

Bowers, J.S., & Davis, C.J. (2012). Bayesian just-so stories
in psychology and neuroscience. Psychological Bulletin,
138(3), 389–414.
Colombo, M., & Seriès, P. (2012). Bayes in the brain. On
Bayesian modelling in neuroscience. The British Journal
for Philosophy of Science, 63, 697–723.
Griffiths T., Chater N., Norris D., & Pouget A. (2012). How
the Bayesians got their beliefs (and what those beliefs
actually are). Psychological Bulletin, 138(3), 415–422.
Gigerenzer, G. (2008). Why heuristics work. Perspectives in
Psychological Science 3(1), 20–29.
Jaynes, E.T. (1998/2003). Probability theory: The logic of
science. Oxford: Oxford University Press.
Kay, J., & Phillips, W.A. (2010). Coherent infomax as a
computational goal for neural systems. Bulletin of
Mathematical Biology, 73, 344–372.
Kwisthout, J. (2011). Most probable explanations in
Bayesian networks: Complexity and tractability.
International Journal of Approximate Reasoning, 52(9),
1452–1469.
Kwisthout, J., & van Rooij, I. (2013). Bridging the gap
between theory and practice of approximate Bayesian
inference. Cognitive Systems Research, 24, 2–8.
Marr, D. (1982). Vision. New York: Henry Holt & Co.
Morrison, M. (2000). Unifying scientific theories,
Cambridge: Cambridge University Press.
Phillips, W.A. (2012). Self-organized complexity and
Coherent Infomax from the viewpoint of Jaynes’s
probability theory. Information, 3(1), 1–15.
Zednik, C. (in press). Heuristics, descriptions, and the scope
of mechanistic explanation. In C. Malaterre & P-A.
Braillard (Eds.), How does biology explain? An enquiry
into the diversity of explanatory patterns in the life
sciences. Springer.

Neuronal inference from the perspective of
Jaynes’s probability theory and the coherent
infomax objective
William A. Phillips
In support of the ‘Bayesian’ perspective on cognition, I will
agree that the adaptively organized complexity of life, and
particularly mental life, depends on inductive inference. I will
put five major caveats on this support, however. First, this
perspective should be based not on Bayes theorem alone but
on the logic of probability theory as developed most
rigorously and extensively by the statistical physicist Edwin
T. Jaynes (1998/2003). Interpreting probabilities as
quantifying uncertainty he showed that optimal inference
rests on a few requirements, or ‘desiderata’, and he developed
maximum entropy methods for justifiably allocating prior

88

