UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Patterns in Noise: Environmental Statistics explain the Sequential Effect

Permalink
https://escholarship.org/uc/item/2j21r2zg

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Schurr, Friederike
Tam, Brian P.
Maloney, Laurence T.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Learning Patterns in Noise: Environmental Statistics Explain the Sequential Effect
Friederike Schüür (fs62@nyu.edu), Brian Tam (bpt218@nyu.edu), Laurence T. Maloney (ltm1@nyu.edu)
Department of Psychology, 6 Washington Place
New York, NY 10003 USA
Abstract
Effects of trial history, or sequential effects, are typically
observed in perceptual, motor, and decision making tasks and
explained by subjects’ irrational sensitivity to local patterns in
stimulus history. We propose that in 2 alternative forced
choice reaction time tasks (2AFC), sequential effects are a
consequence a rational agent engaging in probability learning
but with an inappropriate world model for 2AFC. We
manipulate subjects’ world model and show expected changes
in sequential effects. Sequential effects are at least in part
driven by subjects’ beliefs about their environment.
Keywords: sequential effects; two alternative forced choice
reaction time tasks; Bayesian modeling

Sequential Effects
Subjects display sensitivity to local patterns in stimulus
history in perceptual (Howarth & Bulmer, 1956; Maloney,
Martello, Sahm, & Spillmann, 2005), motor (Cho et al.,
2002; Remington, 1969; Soetens, Boer, & Hueting, 1985),
and decision making tasks (Ayton & Fischer, 2004;
Gilovich, Vallone, & Tversky, 1985). In two alternative
forced choice reaction time tasks (2AFC), for example,
subjects’ reaction times (RTs) depend not only on the
current stimulus but also on the sequence of preceding
stimuli (Cho et al., 2002; Remington, 1969), a phenomenon
known as sequential effects (SQE). In addition, participants
typically respond faster to an alternation of stimuli after a
run of alternations compared to a repetition of stimuli after a
run of repetitions (Soetens, et al., 1985). We refer to this
finding as alternation bias in SQE. While alternation bias
seems more common, repetition bias has been observed, too
(Cho et al., 2002). We here ask what processes give rise to
biased SQE.
SQE are in part determined by the time interval between
subsequent stimuli (inter-trial interval). If this interval is
short (< 500 ms), SQE are driven by automatic facilitation
(Bertelson, 1961; Soetens et al., 1985). Responses to
repeated stimuli benefit from residual activation left by
previous stimulus-response cycles and consequently, RTs to
repeated stimuli are faster while responses to alternating
stimuli are slower (Soetens et al., 1985). If the inter-trial
interval is long (> 500 ms), SQE are driven by subjective
expectancy. Subjects use the sequence of preceding stimuli
to predict the next, upcoming stimulus and consequently, a
run of alternations induces expectancy for more alternations
while a run of repetitions induces expectancy for more
repetitions (Soetens et al., 1985).
But in typical 2AFC tasks, the sequence of preceding
stimuli does not predict the next, upcoming stimulus – a

repetition of stimulus X does not increase the probability of
stimulus X compared to stimulus Y. In other words,
stimulus history has no predictive value and should not
affect subjects’ expectancy (or RTs if the inter-trial interval
exceeds 500ms). Why do we find persistent SQE (after >
4000 trials) (Soetens et al., 1985) in 2AFC tasks?
Previously, SQE in 2AFC tasks with long inter-trial
intervals were cast as instances of irrational sensitivity to
local patterns in stimulus history, presumed to give rise to
other suboptimal behavior, like the gambler’s and hot-hand
fallacy in decision making (Ayton & Fischer, 2004;
Gilovich et al., 1985). Instead, we propose that SQE effects
are driven by subjects’ attempts to learn the probability of
occurrence of the two stimuli in 2AFC with a world model
that, while ecologically plausible, does not match the true
generative model of the task.
In 2AFC tasks, which out of two stimuli is going to appear
on each trial is sampled from a Bernoulli distribution. With
probability p one stimulus will appear and its alternative
with probability 1− p . In common 2AFC, probability p is
constant throughout the experiment (or at least throughout
an experimental block). The true generative model is thus a
Bernoulli distribution with constant probability p .
Participants could learn probability p by using stimulus
history to update estimated probability p̂ using, for
example, Bayesian updating (Gerhard, Wolfe, & Maloney,
under review).
But participants may believe that instead, probability p
changes over time. In other words, instead of a stable world
with constant probability p – the true generative model of
2AFC – participants may believe in a dynamic world with
changing probability pt . We propose that such belief could
give rise to biased SQE: biased SQE are a consequence of
an agent engaged in probability learning with an incorrect
world model. As participants cannot possibly know the
correct world model of 2AFC prior to taking part in 2AFC,
a belief in a changing world is, while incorrect, not
irrational. Under this account, SQE are a consequence of
conditionally rational behavior: given one incorrect
assumption – an inappropriate world model – subsequent
behavior (SQE) is rational (see Green, Benson, Kersten, &
Schrater (2010) for a similar approach to explain probability
matching).
Two previous studies suggested that SQE may be due an
inappropriate world model and developed a computational
model to explain commonly observed SQE in 2AFC
(Wilder, Jones, & Mozer, 2009; Yu & Cohen, 2009). We
developed a modified 2AFC task to test for effects of an

3378

inappropriate world model on SQE accompanied by a
Bayesian model. Participants took part in a 2AFC task
before and after a training session (Figure1). Participants
were instructed to press a left or right button with their left
or right index finger in response to a stimulus, which
appeared either left or right to central fixation. On each trial,
stimuli were equally likely to appear left or right ( pLR = 0.5 )
and were equally likely to repeat or alternate ( pRA = 0.5 ).
Crucially, pLR and pRA did not change over time.

induced to produce SQE and belief in a biased world after
change (or biased “re-set prior”) was induced to produce
biased SQE (see Computational Model & Hypotheses).
We expected to find biased SQE before and after training,
given the numerous reports of biased SQE in 2AFC. We
aimed to change participants’ bias in SQE in line with the
bias they received during training – towards alternation bias
for alternation training and repetition bias for repetition
training. Such change would suggest that biased SQE are –
at least in part – driven by participants’ (inappropriate)
world model: manipulating their world model during
training changes biased SQE in the expected direction in a
post- compared to pre-measurement.

Computational Model and Hypotheses
If participants believe that probability pt changes over time,

Figure 1: Experimental design. a Participants completed a
2AFC task. The stimulus could appear left or right of
fixation and participants were instructed to press a button
with their left or right index finger. During pre- and postmeasurement, the probability of left / right and of repetition
/ alternation was 0.5. During training, repetition probability
was resampled on 18% of all trials. Each change was
signaled to the subjects. b The probability of repetition was
resampled from a Beta-distribution biased towards
repetition c (high values, green) or biased towards
alternation d (low values, orange).
During training, we put participants into an environment
with changing pRA . Participants continued responding to
stimuli presented to the left or right of central fixation with
a left or right index finger button press but 18% of all trials,
pRA was (re-)sampled from a Beta-distribution Β(a,b)
,which was biased either towards repetitions (a = 12, b = 6)
or alternation (a = 6, b = 12). Each change in pRA was
explicitly signaled to the subject. Belief in change was

they should estimate current probability p̂t based on the
outcome of all trials since the final change in probability
and discard the outcome of all trials prior to this change.
The decision which trials to include in estimating p̂t is easy
when participant know when change happened, or
alternatively, when they know the run length r since
change. But in most situations, change is not explicitly
signaled to participants and participants need to estimate
change c or alternatively run length r̂ (Wilson, Nassar, &
Gold, 2010).
The full Bayesian model of probability updating in changing
environments requires maintaining a distribution over all
possible r , which grows as participants complete more
trials. In addition, participants need to estimate the hazard
rate ht – the probability of change on trial t - and maintain
a distribution across all possible hazard rates (and functions)
for optimal Bayesian probability updating in a changing
world (Nassar, Wilson, Heasly, & Gold, 2010). Probability
updating can very quickly become computationally
expensive if not intractable.
Nassar and colleagues (2010) developed a reduced Bayesian
model to make probability-updating algorithms more
tractable. They designed their model for probability
updating in a changing environment with constant
probability of change (or constant hazard rate h ) and in
their model, trial outcomes were supposed to be generated
from a normal distribution. We adapted their reduced model
to fit our task with an increasing hazard rate hr̂ and a
Bernoulli distribution with pRA (see Appendix for details).
We used this model to compute probability estimates p̂RA of
an agent that beliefs in a changing world (incorporated in
the model) and completes a 2AFC task (incorporated in the
input to the model). Based on the agent’s p̂RA we
subsequently computed his expectation γ t (or posterior, see
Appendix) for the upcoming trial. We then grouped γ t
based on preceding trial history: whether it was preceded by

3379

three alternations AAA, three repetitions RRR, or any of the
six other possible combinations: AAR, ARA, …
In Figure 2 we plot 1− γ t grouped by preceding trial history
(x-axis). The curves depend on three parameters: the
probability of change pc and a0 and b0 of the Betadistribution Β(a0 ,bo ) , which incorporates the agents belief in
what the world is like after change prior to new, incoming
evidence. Simulations show that if a0 > b0 and pc > 0 SQE
are repetition biased and if a0 < b0 and pc > 0 SQE are
alternation biased. During training, we lead participants to
believe that pc > 0 and either a0 > b0 (repetition bias group)

asked to wear BOSE QuietComfort 15 Acoustic Noise
Cancelling headphones to reduce background noise and to
allow them to listen to incorporated auditory feedback. The
experiment was run on a Mac Mini (Mac OS X Version
10.7.5)
programmed
in
MatLab
7.5
(http://www.mathworks.com/)
and
Psychtoolbox
3
(Brainard, 1997; Pelli, 1997). Participants responded by
pressing the c-key with their left index finger or the m-key
with their right index finger on a standard QWERTY
keyboard.

Experimental design

or a0 < b0 (alternation bias group) and expected to observe a
corresponding change in bias from pre- to postmeasurement.

Figure 2: Effects of an agent’s belief in frequency of
change (solid, dashed, and dashed-dotted lines represent
increasing frequency) and bias in its environment after
change (green: repetition biased / orange: alternation biased)
determined by pc , a0 , and b0 .

Methods
Participants
25 participants took part in the experiment (12 female, mean
age: 22.3 years, age range: 19 - 24 years, 2 left handed) and
completed a single session of 60 minutes. They were
compensated for time and effort ($10) and received an
additional bonus of $4. Participants were told they would
get rewarded for fast responses but we rewarded all
participants for their fastest 25% of all trials so they all
received the same bonus, unbeknownst to them. Informed
consent was obtained prior to testing. An internal ethics
review board at New York University approved of
experimental procedures.

Participants completed a pre-training, training, and posttraining (Figure 1). During the pre- and post-training,
participants took part in a 2AFC task based on the arcade
game “Whack-a-Mole (elMo)!”. At trial onset, participants
saw a box with two holes – a gray square with two black
circles equidistant from a white, central fixation cross.
250ms after trial onset, the white fixation cross turned red
and then, after an additional 250ms, blue. Once the fixation
cross had turned blue, the stimulus – Sesame Street’s Elmo
– appeared to the left of right of fixation with probability
pLR = 0.5 and with repetition probability pRA = 0.5 after a
time interval chosen from a truncated exponential
distribution (mean = 500ms, max. 2000ms). We chose the
exponential to reduce temporal expectancy (Luce, 1991).
The initial color change of the fixation cross – or count
down – ensured that inter-trial intervals exceeded 500ms to
ensure that we measured subjective expectancy and not
automatic facilitation (Soetens et al., 1985).
During training, participants completed the same task with
one important modification. The probability of repetition
pRA was resampled on 18% of all trials from a Betadistribution with a = 12 and b = 6 in the repetition biased
group and a = 6 and b = 12 in the alternation biased group.
Each time pRA changed, this change was signaled explicitly
to the subjects. The word ‘CHANGE’ was displayed on the
gray box prior to each trial with a new re-sampled
probability. Participants were not told pRA after change.
We chose to manipulate the probability of repetition versus
alternation, instead of the probability of left versus right, for
two reasons. First, studies on SQE typically look at effects
of trial history coded in as repetition versus alternations
instead of left versus right (Cho et al., 2002; Remington,
1969; Soetens et al., 1985; Yu & Cohen, 2009). Second, by
manipulating pRA , we kept pLR = 0.5 and therefore, any
biases in SQE we find cannot be due to differences in left
versus right hand action preparation, for example.

Data analysis

Procedure and Apparatus
Participants were randomly allocated to receive either
repetition training (N = 12) or alternation training (N = 13).
They were seated at approximately 40 cm viewing distance
from a 19’’ Dell computer screen in a dimly lit room and

We measured RTs, defined as the time interval between
stimulus-onset and button press, as a measure of subjective
expectancy during pre- and post-training. Trials with
incorrect responses (left button press for a stimulus
presented to the right of fixation and vice versa) were

3380

removed from the data (5.8%). We refrained from analyzing
error trials, due to their small number. Reaction times were
normalized for each participant and the pre- and posttraining separately. We then classified each trial according
to its current stimulus and trial history. As we manipulated
the probability of alternation and repetition, trials were
classified according to whether a trial was a repetition R or
alternation A trial and whether a trial was preceded by three
alternations AAA, three repetitions RRR, or any of the six
other possible combinations: AAR, ARA, … We computed
the mean RTs for each trial group and analyzed mean RTs
using a 2 x 2 x 2 x 8 mixed design ANOVA with bias as a
between subject factor (repetition vs. alternation), and
measurement (pre- vs. post), final event (R vs. A) and trial
history (AAA, AAR, ARA, …, RRR) as within subject
factors.

Results
We found a significant 3-way interaction between group,
measurement, and final event (F(1,24) = 6.39, p = 0.012).
Prior to training, we found a bias towards alternations A
(mean = -0.132, SE = 0.022) compared to repetitions R
(mean = 0.124, SE = 0.024; final event: F(1,24) = 24.26, p <
0.001; Figure 3). After training, bias was different for each
group (final event * training group: F(1,24) = 8.89, p =
0.005). If repetition trained participants experienced an
alternation, then it took them longer to respond (mean =
0.076, SE = 0.063), compared to alternation trained
participants (mean = -0.092, SE = 0.045; t(24) = -2.23, p =
0.036). And conversely, repetition trained participants
marginally significantly responded faster when they
experienced a repetition (mean = -0.011, SE = 0.057)
compared to alternation trained participants (mean = 0.118,
SE = 0.043; t(24) = 1.86, p = 0.076). Experiencing a
dynamic environment with a bias either towards repetitions
or alternations determines the bias in SQE in a subsequent
stable environment.

Discussion
SQE are a pervasive phenomenon in 2AFC and are typically
explained by an irrational sensitivity to local patterns in trial
history, which is supposed to give rise to other suboptimal
behavior, too, such as the gambler’s and hot-hand fallacy in
decision making. We propose instead that SQE are
conditionally rational: they arise because subjects attempt to
learn the probability of occurrence of the two stimuli in
2AFC but with an inappropriate world model. Instead of
constant stimulus probability, they believe in change. We
trained participants in a changing world with a repetition or
alternation bias and observed a change in participants’
repetition or alternation bias in SQE consistent with the
repetition or alternation training they received. Our data
support the conclusion that biased SQE are at least in part
driven by an inappropriate world model: SQE are
conditionally rational.
Two previous studies proposed that participants’ belief in a
changing world gives rise to SQE. Yu and Cohen (2009)
developed a Bayesian model of probability updating. Like
our model, probability updating was based on stimulus
repetitions and alternations (2nd order) in trial history. Their
model produced SQE similar to the one’s described in the
literature, primarily Cho and colleagues (2002). Crucially,
the authors did not explicitly measure the effects of training
participants to believe in a particular world model on SQE
and their model could account for bias in SQE only through
ad hoc choice of a reset-prior (a prior belief in what the
world will most likely be like after change) skewed towards,
in their case, repetitions. Our results indicate that such
biases can be altered by relatively small amounts of training.
Wilder and colleagues (Wilder et al., 2009) also developed a
Bayesian model of probability updating to explain
previously observed SQE based on stimulus repetitions and
alternations (2nd order) and stimulus location (1st order).
Like Yu and Cohen (2009), Wilder and colleagues (2009)
explained bias in SQE through ad hoc choice of a biased
reset-prior. They state that bias in SQE changes from
experiment to experiment, is difficult to predict, and should
not be cast as part of a computational theory of SQE.
Instead, it reflects attentional and perceptual mechanism.
We assume they hereby mean that bias reflects automatic
facilitation and not subjective expectancy, to use Soetens’ et
al. terminology (Soetens et al., 1985). We observed a
predicted chance in bias after a manipulation of participants’
world model, which speaks against this interpretation. The
bias in SQE should be part of a computational theory of
SQE.
Cho and colleagues (2002) conducted a 2AFC experiment
and developed a computational model to explain the
repetition biased SQE they observed. Their model explains
SQE as the consequence of special pattern detectors.
According to the authors, subjects have two detectors: (a) a
relatively simple repetition detector, which increases our
expectation to observe a stimulus again when it has just
occurred and (b) a more complex alternation detector which
counts observed alternations and increases the expectation

Figure 3: Results. a Prior to training, we find alternation
biased SQE. b After training, we find a change in bias
from alternation to repetition in repetition trained
participants (green lines). Alternation trained participants
(orange lines) maintained their alternation bias. c bias in
SQE prior to training and d bias in SQE after training
3381
averaged across trial history t-1 to t-3.

to another alternation in proportion to the number of already
observed alternations. But other than being able to account
for their data, the model does not explain why we have
certain pattern detectors and not others (Cho et al. (2002)
list six possible detectors). Crucially, their model cannot
easily explain why the training participants received in our
experiment altered bias in SQE.
Green and colleagues took a similar approach to ours to
explain a different phenomenon, namely probability
matching in sequential binary decision tasks (2010). They
proposed that participants’ belief in an inappropriate world
model for sequential binary decision tasks causes
probability matching. In sequential, binary decision tasks,
participants have to choose one of two options. One option
has a higher probability of winning (70% versus 30%). The
optimal strategy for this task is to determine which option
has a higher probability of winning and then choose that
option exclusively. Instead, participants tend to choose the
option with 70% success probability 70% of the time and its
alternative 30% of the time. While this probability matching
behavior is suboptimal, Green and colleagues showed that
given a particular albeit inappropriate world model for the
task, probability matching is optimal. The authors asked
participants to complete sequential, binary decision tasks
and manipulated them to believe in different world models.
This manipulation changed probability matching behavior –
a strong support for their claim. Probability matching is
conditionally rational. We conclude similarly that biased
SQE are conditionally rational.
Simpler models, exponential down-weighting of trial history
(Anderson & Carpenter, 2006), for example, can explain
SQE but cannot explain the change in bias in SQE that we
observed. SQE indicate that subjects are sensitive to recent
but not distant trial history. The change in bias in SQE,
however, indicates that subjects are sensitive to what they
experienced many trials back (during training), too.
Exponential down weighting of evidence cannot explain this
dependence on temporally distant and at the same time
recent information. One could augment a model that
explains SQE by exponential down weighting of trial
history with a bias but, to compete with our explanation,
there would have to be a rational explanation for this bias.

In summary, we proposed that biased SQE are a
consequence of participants’ selection of an inappropriate
world model for 2AFC. We manipulated participants’
beliefs and observed predicted changes in bias of SQE. Our
predictions were based on a Bayesian model of probability
updating, which estimates probability of change and
estimated run length to derive trial-by-trial estimates of the
probability of observing a repetition versus alternation.

Our findings thus show that an inappropriate world model at
least in part gives rise to biased SQE. This shows that in
2AFC, participants try to learn the generative process of the
task – the process, which determines how outcomes, in this
case repetition versus alternation, are generated. Learning
such a generative model is what distinguishes model-based
from model-free learning, according to Daw and colleagues
(Daw, Niv, & Dayan, 2005; Doll, Simon, & Daw, 2013;
Otto, Gershman, Markman, & Daw, 2013) and Green and
colleagues (Green, Benson, Kersten, & Schrater, 2010). We
demonstrate that a seemingly simple behavioral
phenomenon (SQE) is at least in part driven by model-based
learning, which supports the recently proposed ubiquity of
model-based learning algorithms (Doll et al., 2013).

bias group and p̂RA,t = max Β(a0 ,b0 ) with a0 < b0 for the

Appendix
The predictive distribution is computed with respect to
expected run length r̂t (Nassar, Wilson, Heasly, & Gold,
2010). On each trial, the agent computes the probability that
a change c occurred using Bayes rule:
p(c | X t ) =

p( X t | c) p(c)t
p( X t | c) p(c)t + p( X t | p̂RA,t )(1− p(c)t )

(1)

In the repetition bias group p( X t | c) = max Β(a0 ,b0 ) with
a0 > b0 for a repetition and p( X t | c) = 1− max Β(a0 ,b0 ) with
a0 > b0 for an alternation. In the alternation bias group
p( X t | c) = max Β(a0 ,b0 ) with a0 < b0

for an alternation and

p( X t | c) = 1− max Β(a0 ,b0 ) with a0 < b0 for a repetition. p(c)t

depends on current, estimated run length
with increasing

r̂t and increases

r̂t :

p(c) = 1− (1− pc )r̂t

(2)

Change becomes more likely as participants complete more
trials without intervening change (a uniform distribution has
an increasing hazard function). p( X t | p̂rep,t ) is the predictive
distribution if a change point did not occur and depends on
r̂t and the number of alternations A and repetition R in r̂t .
The expected or mean value of the predictive distribution is
based on two possibilities: (a) a change point occurred, in
which case p̂RA,t = max Β(a0 ,b0 ) with a0 > b0 for the repetition
alternation bias group, or (b) no change point occurred, in
which case the recent outcome X t is used to update p̂RA,t . If
X t is a repetition, the number of repetitions Rt in estimated

run length r̂t is increased by one: Rt = Rt−1 + 1 . If X t is an
alternation then At = At−1 + 1 and in the repetition bias group
(note that Rt + At = r̂t ):
p̂RA,t = max B(a0 + Rt ,b0 + At )

3382

(3)

with a0 > b0 in the repetition bias group and a0 < b0 in the
alternation bias group. The posterior distribution is a
weighted average of these two possibilities:
γ t = p(c | X t ) p(c)t + (1− p(c)t ) p̂RA,t

(4)

Expected run length is updated on each trial based on the
probability that change occurred (in which case it is reset to
one) and based on the probability that there was no change
(in which case it is incremented by one):
r̂t+1 = ( r̂t + 1)(1− p(c)t ) + p(c)t

(5)

Acknowledgements
FS and LTM were funded by NIH # EY019889.

References
Anderson, A. J., & Carpenter, R. H. S. (2006). Changes in
expectation consequent on experience, modeled by a
simple, forgetful neural circuit. Journal of Vision, 6(8),
822-835. doi:10.1167/6.8.5
Ayton, P., & Fischer, I. (2004). The hot hand fallacy and the
gambler’s fallacy: Two faces of subjective randomness?
Memory
&
Cognition,
32(8),
1369–1378.
doi:10.3758/BF03206327
Bertelson, P. (1961). Sequential redundancy and speed in a
serial two-choice responding task. Quarterly Journal of
Experimental
Psychology,
13(2),
90–102.
doi:10.1080/17470216108416478
Brainard, D. H. (1997). The Psychophysics Toolbox. Spatial
Vision, 10(4), 433–436. doi:10.1163/156856897X00357
Cho, R. Y., Nystrom, L. E., Brown, E. T., Jones, A. D.,
Braver, T. S., Holmes, P. J., & Cohen, J. D. (2002).
Mechanisms underlying dependencies of performance on
stimulus history in a two-alternative forced-choice task.
Cognitive, Affective, & Behavioral Neuroscience, 2(4),
283–299. doi:10.3758/CABN.2.4.283
Daw, N. D., Niv, Y., & Dayan, P. (2005). Uncertainty-based
competition between prefrontal and dorsolateral striatal
systems for behavioral control. Nature neuroscience,
8(12), 1704–1711.
Doll, B. B., Simon, D. A., & Daw, N. D. (2013). The
ubiquity of model-based reinforcement learning. Current
Opinion in Neurobiology. doi:10.1016/j.conb.2012.08.003
Gerhard, H. E., Wolfe, U., & Maloney, L. T. (under review).
Anticipating motor performance: Effects of experience
and abruptly imposed movement constraints on estimating
success probability.
Gilovich, T., Vallone, R., & Tversky, A. (1985). The hot
hand in basketball: On the misperception of random
sequences. Cognitive Psychology, 17(3), 295–314.
doi:10.1016/0010-0285(85)90010-6
Green, C. S., Benson, C., Kersten, D., & Schrater, P. (2010).
Alterations in choice behavior by manipulations of world

model. Proceedings of the National Academy of Sciences.
doi:10.1073/pnas.1001709107
Howarth, C. I., & Bulmer, M. G. (1956). Non-random
sequences in visual threshold experiments. Quarterly
Journal of Experimental Psychology, 8(4), 163–171.
doi:10.1080/17470215608416816
Luce, R. D. (1991). Response Times: Their Role in Inferring
Elementary Mental Organization. Oxford University
Press, USA.
Maloney, L. T., Martello, M. F. D., Sahm, C., & Spillmann,
L. (2005). Past trials influence perception of ambiguous
motion quartets through pattern completion. Proceedings
of the National Academy of Sciences of the United States
of
America,
102(8),
3164–3169.
doi:10.1073/pnas.0407157102
Nassar, M. R., Wilson, R. C., Heasly, B., & Gold, J. I.
(2010). An Approximately Bayesian Delta-Rule Model
Explains the Dynamics of Belief Updating in a Changing
Environment. The Journal of Neuroscience, 30(37),
12366–12378. doi:10.1523/JNEUROSCI.0822-10.2010
Otto, A. R., Gershman, S. J., Markman, A. B., & Daw, N.
D. (2013). The Curse of Planning Dissecting Multiple
Reinforcement-Learning Systems by Taxing the Central
Executive.
Psychological
Science.
doi:10.1177/0956797612463080
Pelli, D. G. (1997). The VideoToolbox software for visual
psychophysics: transforming numbers into movies.
Spatial
Vision,
10(4),
437–442.
doi:10.1163/156856897X00366
Remington, R. J. (1969). Analysis of sequential effects on
choice reaction times. Journal of Experimental
Psychology, 82(2), 250–257. doi:10.1037/h0028122
Soetens, E., C, L., & E, J. (1985). Expectancy or automatic
facilitation? Separating sequential effects in two-choice
reaction time. Journal of Experimental Psychology:
Human Perception and Performance, 11(5), 598–616.
doi:10.1037/0096-1523.11.5.598
Wilder, M., Jones, M., & Mozer, M. (2009). Sequential
effects reflect parallel learning of multiple environmental
regularities. Advances in neural information processing
systems, 22, 2053–2061.
Wilson, R. C., Nassar, M. R., & Gold, J. I. (2010). Bayesian
Online Learning of the Hazard Rate in Change-Point
Problems. Neural Computation, 22(9), 2452–2476.
doi:10.1162/NECO_a_00007
Yu, A., & Cohen, J. (2008). Sequential effects: Superstition
of rational behavior? NIPS, 1873-1880.

3383

