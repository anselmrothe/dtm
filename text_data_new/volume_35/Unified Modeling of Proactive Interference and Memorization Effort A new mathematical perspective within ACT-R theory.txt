UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Unified Modeling of Proactive Interference and Memorization Effort: A new mathematical
perspective within ACT-R theory

Permalink
https://escholarship.org/uc/item/1p05s7db

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Das, Arindam
Stuerzlinger, Wolfgang

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Unified Modeling of Proactive Interference and Memorization Effort:
A new mathematical perspective within ACT-R theory
Arindam Das, Wolfgang Stuerzlinger
Computer Science and Engineering, York University, Toronto, Canada
{arindam, wolfgang} @cse.yorku.ca

Following this idea, we propose a simple mathematical
model of visuo-spatial learning that combines the effect of
“practice” in terms of practice time, the effect of “decay” in
terms of a small numeric constant, the effect of “proactive
interference” in terms of visual search cost, and the effect of
“memorization” effort in terms of a newly introduced model
parameter, an effort factor, explained later. All these effects
are expressed in a single equation of memory activation. To
achieve this goal, we adapt an existing memory activation
equation of ACT-R theory developed by Anderson et al.
(1998). We focus on the cognitive aspects of interaction
more than the perceptual-motor control complexities in our
model. Therefore, we leverage the empirically proven
axioms of ACT-R theory that the time cost of a visual
encoding is a constant and that a motor response can be
modeled as an average value, according to the task specific
behavior, such as a mouse movement.
Guided by Altmann et al. (2002), we implement our
mathematical model in a spreadsheet and validate it against
previous empirical data collected by others.

Abstract
We parsimoniously model the effect of proactive interference
and memorization effort in learning stable graphical layouts.
We model the visual search cost, i.e. the number of distractors
visually encoded while looking for a target item, as a
reasonable surrogate of onscreen proactive interference.
Further, we show that a novel quantity that we term “effort
factor” is an acceptable estimate for comparing the
memorization effort across different access cost of onscreen
information during the early stages of practice.
Keywords: ACT-R declarative memory,
Interference, Memorization Effort, User Interface

Proactive

Introduction
Onscreen information is an important part of daily life today
– On one hand, they are prevalent in handheld devices like
smart-phones and tablets; On the other hand, they can also
be found in critical displays in aircraft and other machinery.
The screens usually display a structured set of items for the
user to interact with. When interacting, it is rare that users
remember the position of every item in the set perfectly.
One explanation for this forgetting effect is proactive
interference caused by distractor items seen during the
visual search for the desired item. Proactive interference
causes loss of memory activation. In contrast, explicit
memorization of item locations helps to mitigate the effect
of such interference. People exert mental effort in order to
accomplish such memorization.
A study in flight simulation training (Waldron et al.,
2008) found that temporarily decreasing the availability of
onscreen information for pilots orients pilots more towards
memory-based interaction strategies. This in turn helps them
better remember critical information such as the aircrafts’
location. The study established that an increase in
information access cost increases the perceptual-motor
effort. This normally encourages users to choose the highest
performance option of using fewer perceptual-motor
operations but more memory operations, even if memory
retrieval is imperfect.
Rowe et al. (2008) empirically suggested that “practice”
and “memorization” positively influence visuo-spatial
learning while “proactive interference” impacts it
negatively. On the other hand, Altmann et al. (2002)
proposed a theory that not only holds proactive interference
but also “decay” (i.e. loss of memory activation with
passage of time) responsible for forgetting. Taking into
account the mutually constraining effects of “practice”,
“memorization”
effort,
“decay”
and
“proactive
interference”, an integrated, yet simple and easily applicable
performance model is possible that would reflect the effect
of these phenomena on visuo-spatial learning.

ACT-R Theory of Declarative Memory
The ACT-R theory by Anderson et al. (1998) describes a
modular system that aims to replicate the human mind. The
theory is a framework of mathematical equations that
models the neural computations in order to realize human
dynamic behavior.
The core of ACT-R declarative memory builds upon the
notion of memory activation. It posits that memory
encodings of items have different levels of activation to
reflect their past use: items that have been used recently or
items that are used very often receive a high activation. This
activation decays over time if the item is not used. When the
cognitive system needs to retrieve an item, memory returns
the one with the highest activation at that instant. The job of
memory retrieval is complicated by the noise in activation
levels, which can temporarily make an item more active
than the current one, or which can temporarily push all
items below a threshold, thereby making the cognitive
system transiently unable to recall information (Altmann et
al., 2008; p. 604). Furthermore, the activation of an item
controls its speed of retrieval. We focus on the following
three equations behind the ACT-R declarative memory
system that we leverage in our current work.

ACT-R Activation Equation
The equation describing the activation, A, of an item in the
memory is given by

A = B + Activation Equation

358

(1)

where B is the base-level activation of the item discussed
later in detail and  is the noise component. Noise is
assumed to cause transient fluctuations in activation levels.
Guided by Altmann et al. (2002), we implement the noise 
as a constant for our modeling purposes. In the complete
ACT-R memory model, environmental context and
relevance to the current goal also influences the activation
of an item (Gray et al., 2006, p. 481). However this
component introduces additional complexity not relevant to
our modeling effort in this work. Being guided by Gray et
al. (2006) we have therefore omitted the component here.

The Model
We next propose our extension to the base-level activation
equation in order to account for the effect of proactive
interference and memorization effort. We do so largely by
adapting existing cognitive constructs rather than
developing entirely new ones.

Proactive Interference Modeling
Our approach adapts ACT-R’s classic model of memory
strength to account for proactive interference. In other
words, we account for the effects of distractors that get
visually encoded or cumulated before the encoding or
accumulation of the target item, during a visual search. We
accomplish this by replacing the decay constant, d, of the
base-level activation equation, with a function consisting of
a constant term and a varying term. The constant term
models the loss of memory strength with passage of time as
before. The new varying term models the loss of memory
strength due to proactive interference. Our proposal for
modeling the combined effect of decay and interference on
memory activation is in line with the observations of
Altmann et al. (2002, 2008) which indict both decay and
proactive interference for forgetting.
The varying term we propose is governed by the visual
search cost – the number of distractors that get visually
encoded prior to encoding the target item when one tries to
find an item on a user interface. The encoded number of
distractors during a search contributes to a measure for the
proactive interference effect: The lower the number of
distractors visually encoded during a search for a target
item, the lower should be the “loss” of activation of the
target item. Hence, the next recall of that item will be
affected by its higher activation, leading to the lowering of
its retrieval time. This will show an improvement in “search
and selection” performance time during exploration of the
interface. Our hypothesis is grounded in the primary
research result of Underwood (1957) on proactive
interference, namely, the effect that the number of
previously learned items has on the recall of the target item:
The lower the number of previously learned items is, the
lower is the forgetting effect and therefore the lower is the
recall latency for the target item.
We propose a decay rate, dj, calculated for an item, after j
practices of the item are completed, as follows:

ACT-R Base-Level Activation Equation
The equation describing the base-level activation of an item
in memory is given by

 n

B  ln  t j d  Base-Level Activation Equation (2)
 j 1 
where n is the number of “practices” of the item completed
so far, tj is the age of the j-th practice of the item, and the
negative exponent d is the decay constant that controls how
quickly the activation decreases. As postulated by ACT-R
theory, the d term thus models the loss of memory strength
with the passage of time. The equation therefore represents
the strength of a memory item as the sum of a number of
individual memory strengthening, each corresponding to a
past practice event. It implies that each time an item is
practiced, the activation of the item receives an increment in
strength that decays away as a power function of time.

ACT-R Reaction Time Equation
The activation of an item discussed earlier controls its speed
of retrieval. The time required for the declarative memory to
respond to a request (recognition or recall) for an item is
given by the following equation:
RT = I + F e(f A) Reaction Time Equation

(3)

where I is an intercept time reflecting the time cost of
perceptual (visual) encoding and motor response. F is the
latency factor, and maps activation to time. f is the latency
exponent. The purpose of parameters F and f is only to scale
the time to retrieve an item from memory. They remain
fixed across all experimental conditions.
The time cost of a visual encoding is set at 185 ms which
is taken from the estimate used by ACT-R (Anderson &
Lebiere, 1998, pp. 150–151) for human attention to move to
an object at a location.
The time cost of a motor response is set according to the
task specific behavior. The task we model involves finding a
pre-cued item on a structured layout of graphical buttons
presented on a computer screen and then selecting it by
clicking on the appropriate button using a mouse (Ehret,
2000, 2002). Guided by Ehret (2000), Gray et al. (2006) and
Card et al. (1978), we estimate the average time cost of a
motor response to be 300 ms for our modeling purposes.

dj = h + 0.5Xj-1/N

Decay Rate Equation

(4)

where h represents the time-based decay constant, the
fraction 0.5 is a scaling factor (our choice of 0.5 is explained
in the next paragraph), N is the total number of items on the
layout and Xj-1 is the number of distractors visually encoded
at the time of jth practice. Naturally, j has to be larger or
equal to 1. X0 denotes the number of distractors encoded at
the first practice. When Xj-1 is 0, i.e. when the user is able to
complete the task by direct recall, without going through
any explicit visual search, the decay rate equation
degenerates to dj = h. This implies that, in the absence of
the impact of distractors, decay in activation occurs only

359

an effort factor, as they suggested the usage of a cost factor
similar to ours, albeit in different domains.

with the passage of time as modeled by the classic baselevel activation equation.
We introduce the varying term 0.5Xj-1/N to represent the
loss of memory activation due to proactive interference. It
transforms the number of distractors, Xj-1, to a “decay” value
suitable for ACT-R theory. We assume such values to be
ranging from 0 to 0.5: Since 0 implies no decay, it can be
considered as a lower bound. The value of 0.5 is used as the
default decay constant in the classic ACT-R theory (see
Anderson et al., 1998). Therefore 0.5 can be considered as a
valid upper bound for our work. The ratio Xj-1/N ranges
from 0 to 1. Consequently, the varying term 0.5Xj-1/N
results in a value in the desired interval, 0 to 0.5. The
0.5Xj-1/N = 0.5 refers to a situation where the maximum
possible number of distractors is encountered, i.e. when
Xj-1 = N, leading to the highest level of proactive
interference effect. This, in turn, reduces the term to the
maximum of 0.5. On the other hand, 0.5Xj-1/N = 0 implies
an absence of impact from distractors, and therefore no
proactive interference effect as a consequence. This occurs
when the user is able to complete the task by direct recall.
Our model of proactive interference is adapted from the
model of Das et al. (2010). Our work is a significant
improvement over their model of proactive interference
because firstly, our decay rate equation contains less number
of free parameters (decay constant h is the only free
parameter in our equation) and secondly, our equation is
constrained by the total number of items, N, of a layout
under scrutiny. Consequently, the chances for data
overfitting decrease significantly in our model.

Modified Base-Level Activation Equation
With the decay rate equation and the effort factor parameter
conceptualized, we modify the base-level activation
equation (Equation 2) to

 n d 
B  ln k  t j j 
 j 1

Modified Base-Level Activation Equation

(5)

Equation 5 is obtained by adding two new elements dj and
k to Equation 2. We explain the new elements below.
dj describes the new decay rate equation (Equation 4) that
sums up two terms: one representing the traditional timebased “decay” constant and the other representing the “loss
of activation due to proactive interference”.
The element k is the aforementioned effort factor
parameter. We explain k in the context of learning layouts
that vary in the information access costs (henceforth
referred to as “access cost”) associated with their items. The
access cost differs in terms of representativeness of item
labels. Our context of learning accounts for the fact that the
total practice time for learning is held constant across all
layouts (i.e. for every level of access cost).
If all model parameters, except k, in Equations 1, 3, 4 and
5 are left at fixed values across layouts that differ in access
costs, then we hypothesize two properties about k while
comparing layouts in terms of reaction time estimates (RT)
of Equation 3 as follows:
(i) First, we hypothesize that one value of k corresponds to
one particular layout, i.e. one particular access cost
condition.
(ii) Second, a lower value of k would correspond to higher
memorization effort whereas a higher value of k would
correspond to lower memorization effort. The Appendix
provides an argument for this.
Our modified base-level activation equation is therefore a
hypothesis that accounts for the combined effect of
“practice time”, “memorization” effort, “proactive
interference” and “decay” on visuo-spatial learning
performance. We validate our hypotheses later in this work.
Our model of memorization effort is adapted from the
work of Das et al. (2012). Their model did not account for
proactive interference which is the central constraint
compared to decay in learning in situations where learning
is affected by distractors (Altmann et al., 2002, 2008).
Moreover, they had varied the values of multiple model
parameters across different conditions of access cost leaving
their model vulnerable to overfitting.

Memorization Effort Modeling
Our modeling of memorization effort is guided by the soft
constraints hypothesis of Gray et al. (2006). The soft
constraints hypothesis is a rational analysis approach which
proposes that the mixture of perceptual-motor and cognitive
resources allocated for interactive behavior is adjusted based
on temporal cost-benefit tradeoffs, such that the least-effort
path of executing the visuo-spatial task at hand, gets
implicitly chosen. As perceptual-motor effort increases,
users will normally choose the least-effort option of fewer
perceptual-motor operations and more memory operations,
even if the memory retrieval is imperfect. We term the effort
exhausted in carrying out the memory operations as
“memorization effort”.
The soft constraints hypothesis concludes that the tradeoff
between selecting the perceptual-motor versus cognitive
behavior minimizes the total effort (and hence performance
cost) measured in the currency of time (Gray et al., 2006, p.
463). Motivated by the hypothesis, we introduce a
parameter in the base-level activation equation of ACT-R
(Equation 2) as a coefficient of practice time and include it
inside the logarithmic term (shown later in Modified BaseLevel Activation Equation). We call this novel parameter
effort factor. We hypothesize the effort factor to be the
“temporal” representation of the memorization effort
expended to accomplish a visuo-spatial learning task. The
works of Anderson (1983, p. 277) as well as Stewart et al.
(2007, p. 235), also motivate our choice for the adoption of

Validation
In order to validate our model, we use existing
experimentally derived data sets for human performance
over several practice sessions for location learning of items
in a stable layout. Our goal is to focus on the novice to
expert transition because of two reasons. On one hand, the
effect of proactive interference is most pronounced during

360

of every button was always visible across all conditions
(Ehret, 2000; Figure 2, p. 27). To discourage errors, when
participants clicked the wrong button the computer would
beep five times, a dialog box would appear, and the trial
would have to be repeated (Ehret, 2002; p. 212).
Ehret’s observations were point-of-gaze data collected via
an eye-tracker. In order to validate our model we extracted
three data sets from his observations. The data sets were
mean “visual search and select” time (reaction time) from an
experiment, limited to the first 10 sessions of practice, since
learning plateaued off after the tenth session. In his study,
Ehret (2002; 2000, p. 19) had reported two costs, the visual
search cost which is the number of buttons visually encoded
before the target button is found and the verification time,
which is the time required to decide whether the button
visually encoded is really the target or not. For a given
session, we arrived at the mean human reaction time per
button by multiplying the mean visual search cost with the
mean verification time corresponding to that session.
The three data sets differed in the level of meaningfulness
of labels associated with the buttons. The first set of data
was obtained while searching for a pre-cued color in buttons
labeled with the name of color written in English. The aim
was to have a meaningful association between a color and
the button representing the color. The second set of data was
obtained while searching for buttons labeled with arbitrary
icons. The aim was to reduce the meaningfulness of the
association between a color and the button representing it.
The third set consisted of the reaction times for searching
and selecting a pre-cued color among buttons with no labels
on them. The aim was to eliminate any meaningfulness of
the association between a color and the button representing
it. The data sets thus contain three sets of reaction times
corresponding to the three different levels of difficulty in
accessing information: textual label, arbitrary label and
invisible label. Each condition therefore represented a
certain level of access cost, the textual label condition being
the lowest cost condition among them. The total practice
time was held constant across all conditions. It is to be
noted that for the arbitrary and invisible label conditions, a
tooltip was provided for each button to aid the subject, if
memory failed. Accessing the tooltip for a button revealed a
small rectangle containing the color associated with it. The
cost of accessing this tip was a one-second delay between
moving the mouse cursor to the button and the appearance
of the tooltip.
Our choice of data aligns with our modeling objective.
We aim to model the combined effect of visual search cost
(the surrogate of proactive interference) as well as
memorization effort on reaction time, over a reasonable
number of practice sessions. Ehret’s data shows that for any
given access cost condition, the visual search cost decreases
over practice sessions implying that proactive interference
decreases with practice. However, Ehret’s data further
shows that during the search for a pre-cued color, as the
access cost increased from textual to arbitrary to invisible
label conditions of buttons, so did the time to visually verify
and decide (verification time) whether a button currently
under scrutiny is indeed the target or not, at any given
session. The verification time was observed to be the lowest

this transition phase. On the other hand, the effect of
memorization effort to overcome such interference is also
evident in this stage. We therefore concentrate on modeling
early sessions of skill development. Each data set we
validate against corresponds to a certain access cost in terms
of label representativeness of graphical buttons that were
laid out on a computer screen. The task we model involves
finding a pre-cued button and selecting it using a mouse.
We next explain the rationale behind all model parameter
values that were fixed across all experimental conditions.
The time-based “decay” constant h in the decay rate
equation was fixed at h = 0.058. We are motivated here by
Pavlik et al. (2005, p. 572), who used it as a decay intercept
albeit in a different modeling context. In the absence of any
inter-trial data in the empirical study that we validate
against, we assume that there have been insignificant pauses
between any two consecutive trials. Hence, a relatively
small value for the time-based “decay” constant is
appropriate, implying that the decay due to passage of time
had been minimal. Since the focus of our decay rate
equation is to model the effect of proactive interference, we
place greater emphasis on the role of distracting
information. In this regard, we are motivated by the
discourse of Altmann et al. (2002) who argues for the
influential role of proactive interference in forgetting
compared to the role of decay in the domain of distractoraffected learning. Our choice of a very small value of the
time-based “decay” constant is therefore appropriate.
The activation noise  in the activation equation was fixed
at  = 0.28, a value in line with other applications of this
equation in the domain of graphical user interface (e.g.,
Gray et al., 2006).
The latency factor F in the reaction time equation is left at
its default value of F = 1sec, as per classic ACT-R theory.
The latency exponent f in the reaction time equation is
fixed at f = 0.65. On carrying out sensitivity analysis, we
found that setting f at 0.65 instead of 1 substantially reduces
the root-mean-square error (RMSE) value between the
human data and its corresponding model data. It has very
negligible influence on the correlation between them.
As we discuss below, the effort factor k of the Modified
Base-Level Activation Equation is the only parameter that
we varied across conditions in order to account for the
relative differences in memorization effort spent in learning
layouts with different access costs (conditions).

Circle of Buttons Experiment
Knowing an object’s location can reduce a user’s task time,
errors, and frustration. As the number of screen objects
increases, so does the utility of location knowledge. Ehret
(2002) carried out an experiment that tests how well users
learn the location of buttons arranged in a circle on a
computer screen and how the mechanisms underlying
location learning interact with the level of meaningfulness
of button labels. He used a “search and select” task in
which, for a given trial, participants were presented a
particular color and were required to find and click the
button associated with that color. The correct button was
one among the twelve buttons that remained in constant
positions throughout the experiment. The contour and shape

361

10-2) is found to have noticeable impact on the reaction time
estimates. This is particularly true for the first few sessions
of practice.

for the textual label condition and highest for the invisible
label condition. In other words, the layouts with higher
access cost featured higher verification time to identify the
correct item, implying higher effort to learn those layouts
compared to the ones with lower access cost. As posited by
the soft constraint hypothesis and given the same amount of
practice time across all conditions, the higher perceptual
cost of arbitrary and invisible label conditions results in a
higher memorization effort for those label conditions
compared to the memorization effort required for the textual
label condition.
For our validation, we had to make a few assumptions, as
certain information was not mentioned explicitly in the
work of Ehret (2002). The assumptions are the same across
all conditions as follows: Each practice session took 37.5
seconds to complete – since 16 sessions took 10 minutes or
600 seconds as expressed in a related work by Ehret (2000,
p. 136). We also assume the inter-session periods to be
constant. Also, except for the target pre-cue, we assume that
environmental context cuing is minimal and irrelevant for
our purposes.
Validating the Proactive Interference Effect
We provide an example scenario on how the effect of
proactive interference on spatial learning can be modeled
using our new model. Ehret (2002) had an onscreen layout
of graphical buttons labeled with icons where each icon is
arbitrarily associated with a color. A subject’s task was to
visually search for a pre-cued color among the buttons and
click the appropriate button when found using a mouse. The
pre-cued color always appeared at the center of the circle. In
case the subject’s memory failed to recall the color
associated with a button, she could access the button’s
tooltip to know its color by moving the mouse cursor over
it. The tooltip appeared after a one-second delay once the
mouse cursor was moved to the button.
The mean numbers of distractors measured in Ehret’s
experiment in the arbitrary label condition are 5.27, 2.93,
2.58, 2.34, 2.31, 1.61, 1.49, 1.31, 1.36 and 1.14
corresponding to sessions 1 to 10. We input these numbers
in the decay rate equation of our model to obtain the mean
activation value per item for each session. We adjust the
value of k in our model to 0.068 for the experimental
condition (i.e. arbitrary labeling condition). The other model
parameters stay fixed at the values discussed earlier. We fit
our model to the empirical reaction time for a button. We
found the R2 of the fit to be .993 implying a qualitative
correspondence between human and model results.
The effect of proactive interference was also evident in
the textual label condition. After substituting the values of
mean numbers of distractors for this condition (measured in
Ehret’s experiment) in the decay rate equation, we again
found a close match between the human and model results
with R2 = 0.978. Our adjusted value of k was 0.500 in this
condition.
As apparent from the decay rate equation, a change in the
number of distractors changes the decay rate. While
modeling the proactive interference, we noticed that the
mean number of distractors per item, Xj-1 in the decay rate
equation influences the shape of the curve at each sessionpoint. A small change in the decay rate, dj, (at the level of

Figure 1. Reaction times per item (button) for textual,
arbitrary and invisible label conditions.

Validating the Comparison of Memorization Effort
Figure 1 shows the fit of our model to the human data in
terms of reaction times. We compared the effort factor k for
the invisible label condition against the textual label
condition. We found k = 0.056 for the difficult to access
invisible labels, compared to k = 0.500 for the easily
accessible textual labels. Furthermore, k was 0.068 for the
difficult to access arbitrary labels, compared to k being
0.500 for the easy to access textual labels. The comparison
of k in both instances thus points to lower values of k for
layouts with high access cost (high perceptual cost)
compared to the conditions where relevant information is
easily available in the environment. We therefore conclude
that the comparison of memorization effort via our new
effort factor k follows the soft constraint hypothesis to a
significant extent.
With R2 = 0.978, RMSE = 0.215 for the textual, R2 =
0.993, RMSE = 1.153 for the arbitrary and R2 = 0.941,
RMSE = 0.785 for the invisible conditions, the correlation
between the human and model data were good. The RMSE
as a percentage was 13% for textual and 15% for invisible
condition. However, the percentage RMSE for arbitrary
condition being 38% was higher than the 20% mark
suggested by John and Newell (1989). The RMSE for the
arbitrary condition therefore implied a high error.

Discussions
Our work in this paper introduces two mathematical terms,
one to account for the effect of “proactive interference” (PI)
and the other to account for the effect of “memorization
effort”. We add them to an existing memory activation
equation of ACT-R theory that hitherto accounted for the
effects of only “practice” and “decay”.
In this work, we have left all but one model parameter
fixed across all conditions, thereby omitting the scope of
overfitting significantly. The effort factor k is the only
model parameter that we varied in order to reflect the

362

differences in the memorization effort across different
accessibility conditions.
Earlier, Altmann et al. (2002) had used ACT-R theory to
mathematically model the effect of PI on recall probability.
On the other hand, we have mathematically modeled the
effect of PI on response latency.
Our modulation of decay rate to reflect PI is motivated by
the approach of previous researchers such as Pavlik et al.
(2005), Cochran et al. (2006) who had modulated the decay
rate to model phenomena, albeit different from PI.
Previously, Ehret (2000, 2002) had used ACT-R theory to
model memorization effort. Unlike ours, his approach
involved computer-based simulation. In this work, we
provide an alternative look at Ehret’s modeling endeavor.
We do so through a mathematical model.
Initially, to keep our modeling endeavor simple, we
started out by creating separate models of proactive
interference as well as memorization effort. While
developing the standalone model of proactive interference,
we tried to leave the effort factor constant across all
conditions. On the other hand, while developing the
standalone model of memorization effort, we tried to leave
the decay rate constant across all conditions. In both cases,
however, we were unable to identify fixed values for model
parameters. Rather, every “access cost” condition demanded
a separate set of values for multiple model parameters to fit
the data in a satisfactory manner. This motivated us to
model proactive interference and memorization effort in a
unified way.
Our mathematical model has its limitations. (i) At any
given trial for searching a target location on a layout, when
the number of distractors Xj-1 encountered is much less than
the total number of items N on the layout, we assume that
proactive interference owing to that trial has been
negligible. This situation may arise when N is very large.
Further investigation is warranted to identify a practical
upper limit on N. (ii) Our model is restricted to comparing
layouts that have the same number of items in them. (iii) We
do not consider the level of similarity between distractors
and target. (iv) Increased recall latency observed in high PI
conditions can be caused by interference of the target with
distractor activations at the time of retrieval. We have not
considered that. (v) ACT-R theory has a threshold parameter
that specifies a minimum activation below which an item is
invisible to the cognitive system. Similar to Altmann et al.
(2002), we assume no such threshold. As the threshold
parameter is not a variable in the equations we use, this
assumption does not impact our work directly.
Our model concentrated purely on the cognitive aspects of
interaction; thus it did not model the motor control
complexities involved in the spatial search and selection
processes on graphical user interfaces. In reality though,
these are all important factors that influence the overall user
experience.
The advantages of our proposal are its simplicity and
transparency. However, it is an ad hoc alternative focused at
solving a specific problem in a specific way. We do not
claim that we have arrived at a “generic” solution.

References
Altmann, E. M. et al. (2002). Integrating decay and interference: A
new look at an old interaction. 24th CogSci. pp. 65–70.
Altmann, E. M. & Gray, W. D. (2008). An integrated model of
cognitive control in task switching. Psychol. Rev. 115, 602-639.
Anderson, J. R. (1983). A Spreading Activation Theory of
Memory, J. Verbal Learning and Verbal Behavior, 22, 261-295.
Anderson, J. R. & Lebiere, C. (1998). The atomic components of
thought. Mahwah, NJ: Lawrence Erlbaum Associates, Inc.
Card, S. K., English, W. K., & Burr, B. J. (1978). Evaluation of
mouse, rate-controlled isometric joystick, step keys and text
keys for text selection on a CRT. Ergonomics, 21, 601–613.
Cochran, R. E. et al. (2006). Modeling emotion: Arousal's impact
on memory. 28th CogSci. pp. 1133-1138.
Das, A. et al. (2010). Proactive Interference in Location Learning:
A New Closed-Form Approximation. 10th ICCM. pp. 37-42.
Das, A. et al. (2012). Comparing cognitive effort in spatial learning
of text entry keyboards and ShapeWriters. AVI. pp. 649-652.
Ehret, B. D. (2000). Learning where to look: The acquisition of
location knowledge in display-based interaction. Doctoral
Dissertation. George Mason University.
Ehret, B. (2002). Learning Where to Look: Location Learning in
Graphical User Interfaces, CHI 2002, 211-218.
Gray, W. D. et al. (2006). The soft-constraints hypothesis: A
rational analysis approach to resource allocation for interactive
behavior. Psychological Review, 113, 461–482.
John, B. E., & Newell, A. (1989). Cumulating the science of HCI:
From S-R compatibility to transcription typing. CH1 1989, pp.
109-114.
Pavlik, P. I., Jr., & Anderson, J. R. ( 2005). Practice and forgetting
effects on vocabulary memory: An activation-based model of
the spacing effect. Cogn. Sci., 29, 559-586.
Rowe, G. et al. (2008). Age differences in visuospatial working
memory. Psychology and Aging, 23, 79-84.
Stewart, T. C. and West, R. L. (2007). Deconstructing and
reconstructing ACT-R: Exploring the architectural space.
Cognitive Systems Research, 8, 227–236.
Underwood, B. J. (1957). Interference and forgetting. Psychol.
Rev. 64, 49-60.
Waldron, S. M. et al. (2008). Designing information fusion for the
encoding of visual–spatial information. Ergonomics, 775-797.

Appendix
If the effort factor k is varied while leaving other model
parameters at fixed values across different accessibility
conditions, then a lower value of k would correspond to
higher memorization effort whereas a higher value of k
would correspond to lower memorization effort. The reason
is as follows. A lower k (in Equation 5) results in a higher
RT (in Equation 3). Higher values of RTs are typically
evident in the early stages of practice for layouts with higher
access costs (see the empirical data in Ehret, 2002).
However according to the soft constraint hypothesis,
learning a layout with higher access cost would require a
higher number of memory operations compared to
perceptual-motor operations. Consequently, we conclude
that a lower value of k refers to a higher number of memory
operations and therefore reflects higher memorization effort.
In contrast, a higher value of k refers to a lower number of
memory operations and therefore reflects lower
memorization effort.

363

