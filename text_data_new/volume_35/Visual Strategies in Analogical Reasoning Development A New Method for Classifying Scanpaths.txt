UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual Strategies in Analogical Reasoning Development: A New Method for Classifying
Scanpaths

Permalink
https://escholarship.org/uc/item/0fc9k0n4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Glady, Yannick
Thibaut, Jean-Pierre
French, Bob

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Visual Strategies in Analogical Reasoning Development:
A New Method for Classifying Scanpaths
Yannick Glady, Jean-Pierre Thibaut, Robert French
{yannick.glady, jean-pierre.thibaut, robert.french}@u-bourgogne.fr
LEAD-CNRS, UMR 5022, University of Burgundy, Pôle AAFE – Esplanade Erasme
21065 DIJON. FRANCE

Abstract

Background

Development of analogical reasoning is often explained by
general maturation of executive functions. A consequence of
the involvement of executive functions would be that children
and adults differ in the visual strategies they apply when
solving analogical problems. Since visual strategies can be
studied by means of eye-tracking, we compared the visual
scanpaths of children and adults in three different analogical
reasoning tasks. This comparison was done by means of a
novel technique that combined a recently developed algorithm
for computing a “distance” between any pair of scanpaths
(Jarodzka, Holmqvist, & Nyström, 2010), multidimensional
scaling (MDS), and a neural network classifier. This analysis
clearly showed a difference between adults' and children's
visual strategies in solving analogy problems. We focus both
on the demonstration that adults and children employ different
visual search strategies to solve analogy problems and on the
novel technique used to do this. This general technique
complements other approaches to eye-movement analysis that
rely on local properties of scanpaths, in particular, itemfixation times.
Keywords: Analogical reasoning; development; eye-tracking;
strategies.

Introduction
Analogical reasoning is a ubiquitous process in thinking and
reasoning (Gentner & Smith, 2012; Holyoak, 2012). It can
be defined as a comparison of two domains (the source and
the target domains) on the basis of their respective relational
structure (Gentner, 1983). Studies of analogy making have
explored two main explanations for its development,
increase of structured knowledge (Gentner & Rattermann,
1991; Goswami, 1992) and maturation of executive
functions (Halford, 1993; Richland, Morrison, & Holyoak,
2006; Thibaut, French, & Vezneva, 2010a, 2010b). One
important prediction of the executive-function view is that
children and adults use different strategies when solving
analogy problems. The present study addressed this question
by means of a combination of a recently developed
algorithm (Jarodzka et al., 2010) for comparing visual
scanpaths from an eye-tracker, multi-dimensional scaling
(MDS), and a neural net classifier. This technique allowed
us to give an affirmative answer to the central question of
this paper — namely, whether or not children’s analogy
strategies are quantifiably different than those of adults.

Humans rely heavily on vision for virtually every task they
do (e.g. categorization, spatial orientation, problem solving,
etc.) and it remains a privileged way of acquiring
information about the environment. In the case of problem
solving, what information is sought and how this search is
organized through time to come to a solution for the
problem (i.e. visual strategies) may help researchers
understand which solving strategies are used. Attention and
gaze-fixation are highly correlated, especially for complex
stimuli (Deubel & Schneider, 1996; He & Kowler, 1992)
and the fixation time for a given object is correlated with its
informativeness in a scene (Nodine, Carmody, & Kundel,
1978). This argues in favor of studying eye-movements as
indicators of the application of a specific strategy through
control of attention.
Eye-tracking data, especially if they involve scanpaths —
i.e., the complete visual trajectory of a participant’s eye
movements during the task — are often complex and hard to
analyze. For this reason scanpath information is often
reduced to static information about the participant’s gaze
times at specified locations. This simplification, while
certainly easier to analyze, generally fails to fully capture
the temporal aspects of the data involved in visual
strategies. Even when an attempt is made to take into
account temporal aspects of the data, it is often difficult to
compare two scanpaths because, in general, they differ in
length and complexity. Jarodzka et al. (2010) have
developed a method that is able to compare any two
scanpaths. As the Jarodzka et al. algorithm plays a key role
in the analysis that follows, we will describe our variant of
this algorithm in some detail below. We combined this
scanpath-comparison algorithm with multidimensional
scaling and a neural-network classifier to demonstrate that
children’s analogy-making strategies, as reflected in their
visual search patterns across three different problems, are
measurably different from those of adults.
We are not the first to use eye-tracking technology to
study analogy making, but this type of analysis is,
nonetheless, still in its infancy. Eye-tracking techniques
were first used by Bethell-Fox, Lohman, & Snow (1984) to
study strategies when reasoning by analogy. They found
strategic differences in adults with high or low fluid

2398

intelligence when solving geometric A:B::C:? problems.
More recently, Gordon & Moser (2007) investigated adults’
strategies in scene analogy problems. Thibaut, French,
Missault, Gérard, & Glady (2011) also used an eye-tracker
to examine infants’ gaze locations and item-to-item
transitions during an analogy task. However, all of these
studies focused on what information was searched for by
participants as they attempted to solve the analogy problem.
None of this research compared participants’ global
scanpaths. In other words, previous eye-tracking studies
have focused on local aspects of participants’ scanpaths as a
means of revealing part of the dynamics of visual search in
doing analogy problems. By contrast, in the present study
we will use participants’ global scanpaths in our attempt to
respond to the question of whether children have different
visual search strategies than adults when solving visual
analogy problems. Woods et al. (2013) showed that the
organization of search in visual-attention tasks becomes less
variable over the course of development. Because the tasks
we used rely on visual attention, we expected children to
have more variable scanpaths than adults.

Experiment
Methods
Participants
Subjects were 20 adults (14 females, 6 males; mean
age=20;5 years; SD=2.21; range: 17 to 27), students at the
University of Burgundy and naïve to analogical reasoning
tasks and 26 6-year-olds (16 females, 10 males; mean age=
79.5 months; SD=3.6; range: 73 to 84). For children
participating in this experiment, parents’ informed consent
was required from their parents.

Materials
Three tasks, each composed of three training trials and four
experimental trials, constituted the experiment (see Figure
1). The first task was a scene analogy problem task, the
second a standard A:B::C:? task and the third an A:B::C:?
task with the items composing the problems put within a
context. Each problem of each task was composed of 7
black and white line drawings.
In the scene analogy problems, the top scene was
composed of two elements depicting a binary semantic
relation (e.g. a cat chasing a mouse). One of these two
elements had an arrow pointing to it. The bottom scene was
composed of five drawings: the two elements depicting the
same relation as in the top picture (e.g. a boy chasing a girl),
a distractor item, and two elements that were consistent with
the scene but that had no salient relation with the elements
of the relation. These pictures (501x376 pxs) were based on
Richland et al., (2006) except for the distractor that was
chosen not to be perceptually, only semantically, related to
one member of the relation in the bottom picture.
In the standard A:B::C:? trials, the A, B, C drawings were
presented in the top row along with a black empty square
symbolizing the location of the solution. The four remaining
pictures (the Target, a Related-to-C Distractor, and two
Unrelated Distractors) were presented in a row at the bottom
of the screen. The size of each picture was 200x195 pxs.
The A:B::C:? task within context was constituted of two
scenes (501x376 pxs). The top picture was composed of two
black and white line drawings with a relation between them
(e.g. a wolf and meat, with the wolf looking at the meat)
with a contextual cue (e.g. a horizontal line for the horizon
or the lines of the joining walls and floor for a room). The
bottom picture was composed of the five remaining
drawings: the C term, the Target, the Related-to-C
Distractor and the two Unrelated Distractors. This task
differed from the first task in that it was the C term that was

Figure 1. Presentation of the three tasks used for this experiment: a) scene analogy task, b) standard A:B::C:? task, c) sceneoriented A:B::C:? task

2399

pointed at with an arrow, and not one of the elements
constituting the source relation. It differed from the second
task because of the different pictures constituting the
problems being grouped in two scenes, but equivalent to the
standard A:B::C:? task in other respects.
The materials of the last two tasks were based on
materials previously used by Thibaut et al. (2011). The four
trials of each task were two trials with weak association
strengths between A and B, C and T, and C and Dis, and
two with strong association strengths in order to equilibrate
this factor.
The tasks were displayed on a Tobii T120 eye-tracker
device with a 1024x768 screen resolution.
Procedure
Appropriate controls were carried out to ensure that the
participants knew what the items in each of the problems
were and that they understood the instructions. In the first
task, they were asked to point to the element in the bottom
scene that played the same role as the one which had an
arrow pointing to it in the top scene. The two others tasks
were administered as in Thibaut et al. (2011). Eye-tracking
data was gathered from moment of the initial presentation of
the problem to the moment a choice of one of the answers
was made. The participant’s scanpath for a particular
problem consisted of a record of his/her gaze-fixation points
taken every 8ms.

phase and a comparison phase. A scanpath is considered to
be made up of a series of “saccade vectors,” i.e., a
connected series of vectors whose endpoints correspond to
coordinates of successive gaze points (Figure 2a). First, the
scanpath is simplified by combining into a single vector two
consecutive saccade vectors if:
i) their combined length does not exceed 200 pixels in
amplitude (i.e., each is very small) and
ii) they are nearly in straight line (i.e., the angle between
them is between 2.62 and 3.67rad).
In other words if a saccade vector is very small or very
linear with respect to its predecessor in the scanpath, the two
vectors are combined (Figure 2b).
Once each of the two scanpaths has been simplified, they
can be compared. We begin by giving an intuitive
explanation of how this is done. Assume, for example, there
are two simplified scanpaths, S1 and S2 made up of 3 and
saccade vectors, respectively. In other words, S1 = {u1, u2 ,
u3} and S2 = {v1 , v2 , v3 , v4}. Note that these saccade

Data Analysis

Figure 2. Simplification of a scanpath
The goal of this analysis is to compare the sets of children’s
and adults’ scanpaths and to show that there are quantifiable
differences in the two. To do this we use a combination of (a
variant of) Jarodzka et al.’s (2010) scanpath-comparison
algorithm, multidimensional scaling and a neural-net
classifier. As the latter two techniques are well known, we
will not discuss them at length. However, the Jarodzka et al.
algorithm is relatively recent and requires explanation.
Jarodzka et al. (2010) scanpath-comparison algorithm
The algorithm is designed to determine the similarity of any
two scanpaths. It consists of two phases, a simplification

Figure 3. Saccade-vector difference table (a): Each of the
saccade vectors from each of the two scanpaths are
compared based on the chosen metric. (b) The comparison
of each pair of stretched scanpaths corresponds to a traverse
of the table from the upper-left to the lower-right corner of
the saccade-vector difference matrix (the only directions of
movement permitted are down, right and diagonally downand-right). We find the path that produces the lowest total
difference value and this value is the similarity measure
assigned to S1 and S2
vectors are ordered in time. For example, in S1, the saccade
vector u1 is followed by u2, which is followed by u3. To
compare S1 and S2, we need two scanpaths of the same
length. To achieve this, we will "stretch" each scanpath by
adding immediate repetitions of saccade vectors, so that

2400

they both have the same length. Our goal is to find the two
stretched scanpaths, SS1 and SS2 that are as similar as
possible with respect to the chosen metric (orientation,
length, etc.). This similarity will be the measure of the
distance between S1 and S2.
The easiest way to illustrate this stretching is by means of
a saccade-vector difference table for the two scanpaths, S1
and S2, defined above.
A saccade-vector difference matrix is first created (Figure
3a). Each of the saccade-vectors making up one of the
scanpaths S1 is compared to each of the saccade-vectors of
the other scanpath S2, according to a metric, generally,
vector magnitude or orientation (length in our study). Once
this table is constructed, we consider all paths through the
table that begin with the comparison of the first saccade
vectors in both scanpaths (i.e., cell (1, 1) of the table, (u1,
v1)) and end with a comparison of the final saccade vectors
in each scanpath (i.e., cell (3, 4) of the table, (u3, v4)) and
always move to the right, down, or diagonally down-andright. Three examples of paths through the matrix are
illustrated in the right-hand panel of Figure 3. Each path
through the table corresponds to the comparison of two
specific stretched scanpaths. For example, the uppermost
path shown corresponds to a comparison between SS1 = {u1,
u1, u1, u2, u2, u3} and SS2 = {v1, v2, v3, v3, v4, v4}. This path
corresponds to the sum of the values in the cells (1,1), (1,2),
(1,3), (2,3), (2,4), (3,4) of the saccade-vector difference
matrix. When all of these paths through the matrix are
considered, the path which has the smallest value (i.e. the
smallest cumulative sum of comparisons) is selected. This
path corresponds to the two stretched scanpaths that are the
most similar. This value, normalized by the number of
comparisons done, is the similarity measure assigned to the
comparison of scanpaths S1 and S2.
Note that the algorithm as described here differs from
Jarodzka et al. (2010) in that it does not rely on the more
complex Dijkstra (1959) tree-search algorithm. Instead, we
constructed a matrix, cell by cell, with the lowest
cumulative sum of comparisons possible for each cell while
taking into account the constraints put on the comparisons
of the two scanpaths (navigate rightward, downward, or
diagonally downward and to the right). In our example, the
final distance value between S1 and S2 is the cumulative sum
in C(3,4) normalized by the number of steps taken through
the matrix. This algorithm was computationally less
complex for identical results.
The Jarodzka et al. (2010)/MDS/MLP algorithm applied to
scanpaths of analogy problems
We only compared the scanpaths from strictly identical
problems, but not different trials from the same task. Thus,
when we were comparing an adult scanpath and a child's
scanpath, the disposition of the items in the problem they
were solving was identical.

In this way, for a given set of isomorphic problems (i.e.,
where all of the items were in identical places on the
screen), we computed the differences between all pairs of
scanpaths. In other words, if there were S1 to Sn scanpaths
from children and A1 to Am scanpaths from adults on the
same set of isomorphic problems, we computed the
similarity of all pairwise comparisons of scanpaths Si versus
Sj, Si versus Aj, and Ai versus Aj for all i and j.
Once we had calculated the mean differences between
scanpaths generated by each participant in each task, we
used Multidimensional Scaling to obtain the coordinates on
a 2D map that best preserved the distance between
scanpaths. As can be seen in Figure 4, for each of the three
tasks, the scanpaths clustered according to participant type
(Adult or Children). We verified this clustering using a 3layered perceptron (MLP) with a bias node on the input and
hidden layers (5 hidden units, learning rate = 0.05,
momentum = 0.9) with the coordinates of each scanpath on
the MDS map translated into bipolar values and
concatenated on input. We used a Leave-One-Out crossvalidation technique to test the robustness of the
classification. Leave-One-Out cross-validation is a standard
technique in machine learning whereby the classifier (in this
case a neural network) is trained on all items but one. Once
training is complete, the classifier is tested on the item that
had been left out to see whether or not it is classified
correctly.

Results
Using the method of analysis described above, we did a
pairwise comparison of all scanpaths generated by adults
and children on isomorphic analogy problems. We then
conducted a multi-dimensional scaling analysis of this data,
which produced the location-map clusters shown in Figure
4. These points are a 2D representation that best reflects the
distances between the scanpaths. The crosses correspond to
children's scanpaths; the circles correspond to adults'
scanpaths.
Classification of adults’ versus children’s scanpaths
The Jarodzka et al. (2010) method along with
Multidimensional Scaling led to a 2D location map that best
represented the relative distances between the set of
scanpaths, as calculated by the Jarodzka et al. algorithm
(Figure 4). A three-layered feedforward backpropagation
network (MLP) with a Leave-One-Out cross-validation
method, was used to test the robustness of a classification of
the points representing the two groups (i.e. children and
adults). For the scene analogy and A:B::C:? tasks (Figure 1a
and 1b), the network classified 74% of the participants
correctly based on their scanpath (70% of the 20 adults and
78% of the 23 children for both tasks). For the real-world
A:B::C:? task, the network classified 72% of the subjects
correctly (65% of the adults and 78% of the children). This

2401

was significantly above chance (50%) for each task
(binomial test: Z=14.89; p<.001 for the first and second;
Z=14.30; p<.001 for the third). Intuitively, this result can be

seen in Figure 3. The adult group tends to be more
homogenous than the children as the crosses (children’s
scanpaths) are more scattered than the circles (adults’
scanpaths), and this is reflected in the high degree of
accurate classification of the MLP.

General discussion

Figure 4. Location-map of an MDS analysis of the relative
differences among participants for the scene analogy task
(a), the standard A:B::C:? task (b), and the scene-oriented
A:B::C:? task (c).

The present study addressed the following question in a
novel manner: Do children and adults have different visual
strategies in analogical reasoning tasks? To answer this, we
used an eye-tracking methodology whose data were
analyzed by a combination of the Jarodzka et al. (2010)
scanpath-comparison algorithm, the transformation of this
data into a 2D location map using multidimensional scaling,
and, finally, a quantitative adult/child classification by
means of a feedforward backpropagation network. The
neural-net classification was done by training the network
on the scanpath data for all but one participant. Once the
network was trained, it was tested on the one scanpath that
was left out of the training set. This was done for each
participant’s scanpath data and the result was scored
according to whether the network classified the test
scanpath correctly or not. The results obtained with this
method agree with previous results from Thibaut et al. 2011
who also showed, by analyzing item gaze times and the
number of transitions between items that adults and children
differed in their search strategies in the standard A:B::C:?
analogy task. The present work, using an approach based on
individuals’ entire scanpaths, also extends this previous
work to scene analogy problems and scene-oriented
A:B::C:? problems. This scanpath analysis showed, among
other things, that children’s scanpaths were more variable
than those of adults in the three tasks. These differences
support the hypothesis of the key role of executive functions
in analogy making because the lower variability of adults’
scanpaths is indicative of them applying, through control of
attention, a previously adopted plan for solving analogy
problems (Woods et al., 2013)
The scanpath analysis presented in this paper provides a
means of studying various search strategies in analogy
making. The technique presented in this paper overcomes
thorny problem of comparison of scanpaths of different
lengths and allows to take into account the dynamic features
of search, which are largely missed in other, more static
eye-tracking approaches based on item fixation times. It
could also be used, for example, to confirm differences in
analogy-making strategies observed in adults in Bethell-Fox
et al. (1984) and to classify participants based on their
scanpath data (i.e., “elimination strategies” for participants
with low fluid intelligence and “constructive matching
strategies” for participants with high fluid intelligence). This
method is, of course, not limited to studies of analogymaking, and could be used with any other type of problems
whose crucial information for its solution could be
presented on a screen.

2402

Conclusion
The method of scanpath analysis presented in this paper
provides a new tool to analyze the dynamic aspects of
search strategies in a wide variety of experimental contexts.
As shown by the results, this method is sensitive to global
differences between scanpaths and is useful to discriminate
clusters of strategies. In this paper it has been used to show
that children’s and adults’ differ in their variability while
solving analogical reasoning problems, suggesting the
involvement of executive functions in such tasks. However,
to fully understand the causes of these differences, it is
inevitable to use local information. Thus, it should be used
in combination of other existing methods, in particular,
Area-of-Interest (AOI) methods that provide information on
what information is sought and how long it is watched
(informativeness of stimuli), since this information is not
captured by the Jarodzka et al. method. On the other hand,
AOI methods give limited information about the dynamic
progression of search, something which is captured when
full scanpath information is used. In short, the Jarodzka et
al. (2010), combined with an MDS analysis and a classifier
(backpropagation networks, Support Vector Machines, etc.),
provides a potentially far-reaching tool for analyzing
participants’ dynamic strategies in various problem-solving
contexts.

Acknowledgements
This research has been supported by French ANR Grant 10BLAN-1908-01 to the second author and a joint ANRESRC grant 10-065 GETPIMA to the last author.

References
Bethell-Fox, C. E., Lohman, D. F., & Snow, R. E. (1984).
Adaptive reasoning: Componential and eye movement
analysis of geometric analogy performance. Intelligence,
8(3), 205–238.
Deubel, H., & Schneider, W. (1996). Saccade target
selection and object recognition: Evidence for a common
attentional mechanism. Vision research, 36, 1827–1837.
Dijkstra, E. (1959). A note on two problems in connexion
with graphs. Numerische mathematik, 1, 269–271.
Gentner, D. (1983). Structure-mapping: A theoretical
framework for analogy. Cognitive Science, 7(2), 155–170.
Gentner, D., & Rattermann, M. J. (1991). Language and the
career of similarity. In S. A. Gelman & J. P. Byrnes
(Eds.), Perspectives on Language and Thought:
Interrelations in Development (pp. 225–277). New York,
NY: Cambridge University Press.

Gentner, D., & Smith, L. (2012). Analogical reasoning.
Encyclopedia of Human Behavior (2nd ed., Vol. 1, pp.
130–136). Elsevier Inc.
Gordon, P. C., & Moser, S. (2007). Insight into analogies:
Evidence from eye movements. Visual Cognition, 15(1),
20–35.
Goswami, U. (1992). Analogical Reasoning in Children.
Hillsdale, NJ: Lawrence Erlbaum Associates, Inc.
Halford, G. S. (1993). Children’s Understanding: The
Development of Mental Models. Hillsdale, NJ: Erlbaum.
He, P., & Kowler, E. (1992). The role of saccades in the
perception of texture patterns. Vision research, 32(11),
2151–2163.
Holyoak, K. J. (2012). Analogy and relational reasoning. In
K.J. Holyoak & R. G. Morrison (Eds.), The Oxford
Handbook of Thinking and Reasoning (pp. 234–259).
New York, NY: Oxford University Press.
Jarodzka, H., Holmqvist, K., & Nyström, M. (2010). A
vector-based, multidimensional scanpath similarity
measure. ETRA ’10: Proceedings of the 2010 Symposium
on Eye Tracking Research & Applications (pp. 211–218).
New York, NY.
Nodine, C. E., Carmody, D. P., & Kundel, H. L. (1978).
Searching for Nina. In J. Senders, D. F. Fisher, & R.
Monty (Eds.), Eye movements and the higher
psychological functions (pp. 241–258). Hillsdale, NJ:
Erlbaum.
Richland, L. E., Morrison, R. G., & Holyoak, K. J. (2006).
Children’s development of analogical reasoning: Insights
from scene analogy problems. Journal of Experimental
Child Psychology, 94(3), 249–273.
Thibaut, J.-P., French, R. M., Missault, A., Gérard, Y., &
Glady, Y. (2011). In the eyes of the beholder: What eyetracking reveals about analogy-making strategies in
children and adults. Proceedings of the Thirty-Third
Annual Meeting of the Cognitive Science Society (pp.
453–458).
Thibaut, J.-P., French, R. M., & Vezneva, M. (2010a).
Cognitive load and semantic analogies: Searching
semantic space. Psychonomic Bulletin & Review, 17(4),
569–74.
Thibaut, J.-P., French, R. M., & Vezneva, M. (2010b). The
development of analogy making in children: Cognitive
load and executive functions. Journal of Experimental
Child Psychology, 106(1), 1–19.
Woods, A. J., Göksun, T., Chatterjee, A., Zelonis, S.,
Mehta, A., & Smith, S. E. (2013). The development of
organized visual search. Acta psychologica, 143(2), 191–
199.

2403

