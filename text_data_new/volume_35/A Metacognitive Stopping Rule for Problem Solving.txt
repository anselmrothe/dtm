UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Metacognitive Stopping Rule for Problem Solving

Permalink
https://escholarship.org/uc/item/8pb5j26h

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Author
Ackerman, Rakefet

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Metacognitive Stopping Rule for Problem Solving
Rakefet Ackerman (Ackerman@ie.technion.ac.il)
Faculty of Industrial Engineering and Management, Technion – Israel Institute of Technology
Technion City, Haifa, 3200003 Israel

execute more deliberate and lengthy analytic reasoning.
However, Evans (2009) identified a third type of processes
(T3). These T3 processes are responsible for (a) identifying
the need for T2 intervention, and (b) examining whether a
given model is satisfactory (see also the reflective mind
suggested by Stanovich, 2009a). Thompson (2009)
proposed that metacognitive processes underlie identifying
the need for T2 intervention. Indeed, Thompson and her
colleagues (Thompson, Prowse Turner, & Pennycook, 2011;
Thompson et al., in press) asked participants to provide an
initial answer and their Feeling of Rightness (FOR) about it.
Subsequently, they were allowed to reconsider their answer.
As expected, lower FORs were associated with more
reconsideration time and with a higher likelihood of
providing an alternative for the initial answer. These
findings support the role of metacognitive monitoring as
bridging T1 and T2 processes. This relates to the first aspect
mentioned by Evans (2009). The present paper deals with
the second aspect he mentioned; namely, examining
whether a given model is satisfactory for deciding whether
to stop investing effort in a particular problem.

Abstract
Although people expect to improve by investing effort in
solving a problem, several studies have found negative timeconfidence correlations in various problem-solving tasks. The
present study employed the metacognitive approach to
illuminate why, despite lengthy thinking, people provide
solutions in which they have only low confidence. According
to the proposed Diminishing Criterion Model (DCM), as
people invest longer in a problem, their confidence in their
solution increases in a goal-driven manner, in accordance
with the common belief. Nevertheless, the process ends up
with a negative time-confidence correlation, because people
tend to find lower confidence levels as satisfactory as they
invest longer in solving a problem, reflecting a compromise in
their stopping criterion. The hypotheses derived from the
DCM were supported with two problem types. Even when the
participants were allowed to submit a “don’t know” response,
they still provided low confidence solutions after lengthy
thinking, suggesting that they found these low confidence
solutions to be satisfactory. The study offers reconciliation
between beliefs and empirical findings and explains why
people end up offering solutions with low confidence rather
than continuing attempts to improve or admitting failure (via
the “don’t know” option).

Metacognitive Stopping Rules

Keywords: Metacognition; problem solving; dual-process
theory; stopping rule; time allocation.

In the experimental examinations of metacognitive
regulation of memorizing, the fact that people invest more
time in studying the more difficult items has led to the
development of the discrepancy reduction model (Nelson &
Narens, 1990). According to this model, people set a target
level according to their motivation for the given scenario
and study each item until they consider their knowledge to
be satisfactory. This process seems to also be applied to a
problem-solving task: people set a criterion for their
confidence level, and continue to search for better solutions
until they judge their chance for success to be satisfactory
(Evans, 2006). Thus, for both memorizing words and
solving problems, the discrepancy reduction model suggests
that lengthy processing positively correlates with the chance
for success. In line with this model, Koriat et al. (2006)
associated goal-driven effort with a positive time-judgment
correlation.
Considering the final form of time-judgment correlation,
if people progress in their goal pursue until they reach the
judgment level they consider as satisfactory, we would
expect to find no correlation between time and judgment.
This is because people are expected to stop investing effort
when their judgment passes the preset goal regardless of the
time it takes to reach this perceived knowledge level.
However, studies of both memorizing and problem solving

Introduction
Solving a problem requires representations of the relevant
components, rules (or constraints), and goal, followed by a
sequence of inferences or calculations. However, beyond the
cognitive process per se, solving a problem also involves
regulation of the cognitive effort. Regulation of effort is at
the heart of metacognitive theories. According to this
approach, to achieve a cognitive goal, people constantly
judge, or monitor, the state of their performance relative to
the goal they pursue and decide whether to continue to
invest further effort or cease (Koriat, Ma'ayan, &
Nussinson, 2006; Nelson & Narens, 1990). The
metacognitive approach is commonly used for learning
research, mainly memorizing, but as yet is rarely employed
for problem solving. Although metacognitive considerations
have been mentioned in some discussions (e.g., Payne &
Duggan, 2011), establishing metacognitive monitoring as a
causal link in regulating problem solving has only started to
emerge, in particular with regard to dual-process theories.
According to the dual-process theories (Kahneman,
2003), System 1 or Type 1 processes (T1) are responsible
for suggesting a quick solution that comes to mind based on
default procedures. System 2 or Type 2 processes (T2)

121

was that the opportunity to respond with “don’t know”
would not eliminate this pattern of results.

repeatedly found that negative correlations dominated timejudgment relationships (e.g., Begg, Duft, Lalonde, Melnick,
& Sanvito, 1989; Koriat et al., 2006). In particular, in
problem solving, this negative time-confidence correlation
was found even when reaction times were not valid as
predictors of success (Ackerman & Zalmanov, 2012;
Topolinski & Reber, 2010). In these studies the participants
were more confident when they provided the solutions
quickly than when they provided the solutions after lengthy
thinking, regardless of the actual chance for success. These
findings are puzzling: Why do people stop investing effort
when they knowingly provide solutions with low
confidence? Is investment of time perceived as a waste of
time, with no progress in the assessed chance for success?
Previous explanations for the consistent negative timejudgment correlation were based on bottom-up fluency
(Koriat, Ackerman, Adiv, Lockl, & Schneider, in press;
Koriat et al., 2006), Ackerman and Zalmanov (2012)
included. In light of the goal-oriented nature of problemsolving tasks (Evans, 2006), the present study offers a topdown explanation for the findings. According to the
proposed Diminishing Criterion Model (DCM), as people
invest longer in a problem, their confidence in the currently
considered solution option increases in a goal-driven
manner, aiming to improve the chance for success, as is also
derived from the discrepancy reduction model. However,
the stopping criterion does not remain constant along the
solving process, but diminishes, reflecting an increased
compromise as more time is invested. That is, if an
immediate solution option comes to mind with high
confidence, higher than the initial stopping criterion, this
solution would be provided. If the confidence regarding the
initial solution is lower than the criterion, more
consideration time is invested, until reaching a satisfying
level of confidence. Importantly, a confidence level which
may not satisfy the solver regarding a quickly produced
solution may satisfy him or her after lengthy consideration.
But what if the confidence after lengthy thinking remains
very low and no way to find a better solution is found? In
this case, people may prefer to respond with “don’t know”,
stemming from their desire to provide solutions with
reasonable confidence. In this case, a “don’t know”
response may be more socially acceptable than a solution
accompanied by a very low confidence (Ackerman &
Goldsmith, 2008). The question is whether the “don’t
know” option would eliminate the negative time-confidence
slope and lead respondents to provide only high confidence
solutions. The prediction by the DCM is that it would not,
because if a great deal of time is already invested, people
compromise and refer to quite low confidence levels as
satisfactory.
Two hypotheses derived from the DCM were examined in
two experiments, one with regular problems and the other
with misleading problems often used in studies of the dualprocess approach. The first hypothesis was that judgments
are positively correlated with time while the final timeconfidence correlation is negative. The second hypothesis

Experiment 1
The task in Experiment 1 was the Compound Remote
Associate (CRA) test. In this test, participants are presented
with a word triplet and their task is to find a fourth word
that forms a compound word or two-word phrase with each
cue word separately. In an attempt to solve these problems,
immediate associations for each word are expected to come
up (Wiley, 1998). However, an association that fits only one
or two of the cue words does not satisfy the requirements.
For example, for the triplet PINE/CRAB/SAUCE, the word
PINE might initially elicit PINECONE rather than the
correct PINEAPPLE. Recognition that the initial solution
option does not fit should trigger a search for a better
solution (Thompson et al., 2011; Thompson et al., in press).
In Ackerman and Zalmanov (2012) these problems yielded
a strong negative time-confidence correlation.
In the present study there were two groups. The
intermediate ratings group was asked to provide ongoing
confidence ratings regarding the solution options they
considered at each point in time (see also Ackerman &
Goldsmith, 2011; Metcalfe & Weibe, 1987; Vernon &
Usher, 2003). The “don’t know” group provided
intermediate ratings as well, but also had the option to
respond with “don’t know”.

Method
Participants. Forty-four undergraduates participated in the
experiment for course credit or for payment (Mage = 24.8;
50% females). They were randomly assigned to working
with or without the “don’t know” option, with 22
participants in each group.
Materials. Thirty-four CRA problems were used. Two
problems were used for demonstration and two for selfpractice. Pretesting verified that all problems were solvable
by the target population.
Procedure. The experiment was conducted on two to eight
participants in parallel, in a small computers lab. The
instruction booklet detailed the procedure, explained what
constituted a valid solution, and illustrated the procedure
using two problems. Pressing the “Start” button brought up
a problem. Respondents had to type the solution and press
the “Continue” button. Response time was measured from
when participants pressed “Start” to when they pressed
“Continue”. This exposed the question, “How confident are
you that your answer is correct?”, and a horizontal scale
(0% - 100%). Pressing the “Next” button cleared the screen
for the next problem.
The participants were asked to report on intermediate
confidence ratings interspersed with solving each problem.
The ends of each scale were marked as “I still have no
idea”, and “I’m sure I found it”. The first scale, appeared

122

The progress of the problem-solving process exposed by
the intermediate confidence ratings is also plotted in Figure
1. Because there was no data on all points for all
participants, we used the initial confidence (by the first
intermediate scale) and final confidence to statistically
examine the progress in the ratings. The analysis was based
on participants who provided initial confidence under all
four quarters (N = 26, 59%). A mixed three-way ANOVA
Group (2) × Quarter (1-4) × Rating (initial vs. final
confidence) yielded no main effect of the group, F < 1. The
main effect of the quarter was significant, F(3, 72) = 90.92,
MSE = 352.64, p < .0001, reflecting that the ratings fell
from the first to the fourth quarters. The main effect of the
rating was also significant, F(1, 24) = 90.78, MSE = 404.03,
p < .0001, supporting the increase from the initial to the
final confidence ratings. Importantly, the triple interaction
was insignificant, F < 1, suggesting a similar pattern of
results with and without the “don’t know” option.

three seconds after the problem’s presentation. Later on, an
additional scale appeared every 15 seconds and the previous
scale became inactive, even if no rating was entered. This
way the repeated request to enter a rating was clearly
noticeable. The screen could present up to five intermediate
scales. The participants could enter the answer at any time,
rate their final confidence, and move on to the next problem.
The times for entering the intermediate confidence ratings
were documented. The only difference for the “don’t know”
group was that adjacent to the space for answer entry, there
was a “don’t know” button. Pressing this button deactivated
the confidence rating scale.
After demonstration with two problems, the two other
practice problems appeared first, and the rest were randomly
ordered for each participant. The session lasted 30 minutes.

Results and Discussion
The participants provided meaningful solution words (rather
than “XXX”, for example) for 97% of the problems.
Overall, the results were highly similar to those of the group
reported in Ackerman and Zalmanov (2012), which was
drawn from the same population and solved the problems
without intermediate ratings. In the “don’t know” group, 19
participants of 22 used the “don’t know” option. Percent
correct (with “don’t know”: M = 56.5%, SD = 20.3; without
a “don’t know” option: M = 48.0%, SD = 16.8) and
confidence ratings were somewhat higher with the “don’t
know” option than without it, but the differences were not
significant; both were ps > .13. The mean response time was
shorter with the “don’t know” option (with “don’t know”: M
= 29.0 sec., SD = 13.1; without a “don’t know” option: M =
41.6 sec., SD = 12.6), t(42) = 3.27, p < .01. This finding
may indicate that the “don’t know” option allowed
participants to avoid providing the results of their lengthy
solving processes. Indeed, the “don’t know” responses (M =
56.9, SD = 26.6) were provided after more time than the
provided solutions, t(18) = 5.90, p < .0001. This finding
suggests that the participants provided the “don’t know”
response after deliberation, rather than for moving quickly
to the next problem.
To examine the ongoing progress of the confidence
ratings, the data was split for each participant for his/her
own quarters of final response times, with seven or eight
problems in each quarter. The points on the black lines in
Figure 1 represent the mean final times and confidence for
each quarter, with (panel A) and without (panel B) the
“don’t know” option. A two-way Analysis of Variance
(ANOVA) examining the effects of the Group (2) and
Quarter (1-4) on final confidence ratings, revealed only the
main effect of the quarter, F(3, 126) = 136.49, MSE =
218.32, p < .0001. No difference was found among the
groups, F < 1, and the interaction was not significant, F(3,
126) = 1.64, MSE = 218.32, p = .18. Thus, confidence
ratings were higher for the quickly provided solutions than
for the lengthy solutions, and this pattern did not differ
among the groups.

Figure 1: Experiment 1 - The intermediate and final
confidence ratings on the timeline of solving the
problems, divided by final response time quarters
(1-4). Each panel presents the results of one group.
Overall, the results of Experiment 1 support the
hypotheses derived from the DCM. There was a positive
relationship between the time in which each rating was
provided and the progress of the confidence ratings and a
negative relationship between the total invested time and
final confidence ratings. Importantly, this was the case even
with the “don’t know” option, which suggests that the
participants found low confidence solutions provided after
lengthy thinking as satisfactory for that point in time. It is
also clear from Figure 1 that confidence levels that were not
considered satisfactory in initial stages of the problemsolving process (e.g., the mean of the FOR ratings in the
second quarter in panel A, which is 33), were provided if a
similar level of confidence was reached after lengthy
deliberation (e.g., the mean final confidence rating at the
fourth quarter in panel A, which is also 33).

Experiment 2
Misleading problems are commonly used in the literature
related to dual-process theories to differentiate between the
fast intuitive (T1) solutions and the results of more
deliberate processing (T2). For example: “A bat and a ball
cost $1.10 in total. The bat costs $1 more than the ball. How

123

much does the ball cost? ____cents” (Kahneman, 2003).
The immediate solution that comes to mind is 10 cents,
while the correct solution is 5 cents. From a metacognitive
point of view, these problems allow dissociation between
the confidence and accuracy in their relationship with
response time, since the very first solutions tend to be
accompanied by high confidence but a low chance for being
correct, in particular when presented in an open-ended
format (Ackerman & Zalmanov, 2012).
What should we expect with regard to final confidence in
solutions provided after lengthy thinking? In cases where
the respondent reaches the correct solution, he or she may
be aware of the successful processing and be highly
confident of the found solution. High confidence after
deliberate processing can also be expected to accompany
wrong solutions in cases such as over-generalized rules
without appropriate exceptions, or investing effort in finding
support for the initial and wrong solution (Stanovich,
2009a). Indeed, Ackerman and Zalmanov (2012) found
higher confidence ratings regarding lengthy solutions with
misleading problems than regarding CRA problems.
However, despite this finding, a negative correlation
between time and confidence was found even with the
misleading problems. This might indicate that even with
these problems, people see relatively low confidence levels
as satisfying after lengthy thinking, as suggested here. To
examine this possibility, Experiment 2 examined whether
the “don’t know” option allows the participants to avoid the
low confidence solutions, with the hypothesis that it will
not. Like in Experiment 1, all participants provided
intermediate confidence ratings. One group worked with
and one without the “don’t know” option.

Results and Discussion
The participants provided meaningful solution words (rather
than “XXX”, for example) for all the problems. In the
“don’t know” group, only six participants of 20 utilized the
“don’t know” option. As in Experiment 1, percent correct
(with “don’t know” option: M = 47.2%, SD = 16.4; without
the “don’t know” option: M = 43.9%, SD = 15.5) and
confidence ratings were equivalent in both groups, both ts <
1. In this case, no difference was found also for response
time, t < 1. Like in Experiment 1, the results were highly
similar to those found by Ackerman and Zalmanov (2012),
where there were no intermediate confidence ratings.
In this experiment, there were only 12 problems, so they
were divided into thirds rather than quarters, with four
problems in each third. As can be seen in Figure 2, the
overall pattern of results remained with (Panel A) and
without (Panel B) the “don’t know” option, although
confidence levels were higher than in Experiment 1.

Figure 2: Experiment 2 - The initial feeling of rightness
(FOR), and intermediate and final confidence ratings on
the timeline of solving the problems, divided by final
response latency thirds (1-3). Each panel presents the
results of one group.

Method
Participants. The 40 participants were drawn from the
same population (Mage = 25.2; 36% females). The
participants were randomly assigned to the “don’t know”
conditions, with 20 participants in each group.

A two-way ANOVA examining the effects of the Group
(2) and Third (1-3) on final confidence ratings, revealed
only a main effect of the third, F(2, 76) = 60.37, MSE =
67.82, p < .0001. No difference was found among the
groups, F < 1, and no interactive effect, F(2, 76) = 1.73,
MSE = 67.82, p = .18. Thus, confidence ratings were higher
for the quickly provided solutions than for the lengthy
solutions, but this pattern did not differ among the groups. A
mixed three-way ANOVA Group (2) × Third (1-3) × Rating
(FOR vs. Final confidence) was based on participants who
provided FORs under all thirds (N = 20, 50%). The main
effect of the group was not significant, F(1, 18) = 2.29, MSE
= 1399.72, p = .15. The main effect of the third was
significant, F(2, 36) = 29.25, MSE = 163.62, p < .0001,
reflecting that the ratings dropped from the quickly provided
to the slowly provided solutions. The main effect of the
rating was also significant, F(1, 18) = 95.80, MSE = 948.31,
p < .0001, supporting the increase from the initial FORs to
the final confidence ratings. The triple interaction was again
insignificant, F(2, 36) = 1.84, MSE = 180.92, p = .17
suggesting a similar pattern of results with and without the
“don’t know” option.

Materials. The problems used by Ackerman and Zalmanov
(2012) were used for this experiment. They included twelve
experimental problems and a practice problem for
demonstrating the procedure. The experimental problems
included the three problems used by Frederick (2005; the
bat and ball, water lilies cover half a lake, and machines that
produce widgets at a certain rate), the drinks version of
Wason’s selection task (Beaman, 2002), the A-is-lookingat-B problem (Stanovich, 2009b), and a conditional
probability problem (Leron & Hazzan, 2009). The other
problems were misleading problems adapted from
preparation booklets for the Graduate Management
Admission Test (GMAT).
Procedure. The procedure was highly similar to that used in
Experiment 1. The practice problem appeared first, and the
rest were randomly ordered for each participant.

124

brings to the fore additional factors that may have broader
ecological validity. The present study evolved from
considering problem-solving tasks, which are generally
understudied from the metacognitive point of view, and
which highlight puzzling aspects of time investment and its
relationship to metacognitive regulation. By proposing the
DCM, this paper aims to shed light on the processes that
lead people to end up with low confidence in their success,
even when they can potentially avoid it by continuing
improvement attempts or admitting failure.

The results of Experiment 2 support the two hypotheses
derived from the DCM as well. This experiment generalizes
the results of Experiment 1 with a different type of
problems, in which one may expect to find high confidence
ratings after lengthy thinking. Even with these problems, the
time-confidence relationship is neither positive nor flat. It is
consistently negative, even when participants could avoid
low confidence solutions by utilizing the “don’t know”
option.

General Discussion
Acknowledgments

The motivation for the present study stemmed from the
puzzling inconsistency between the goal-driven nature of
the problem-solving task — which leads to the expectancy
of positive or no correlation between time and confidence
— and the empirical findings of persistent negative
correlation between them, even when people are free to
regulate their solving time (Ackerman & Zalmanov, 2012;
Koriat et al., 2006). The proposed DCM suggests that the
cognitive process indeed progresses in a goal-driven
manner, with a positive correlation between time and
confidence. It also suggests that people stop investing effort
when their metacognitive monitoring passes their stopping
criterion. Until this point the process accords with the wellknown discrepancy reduction models (Nelson & Narens,
1990). The unique characteristic of the proposed DCM is
the suggestion that the negative correlation stems from the
willingness of people to compromise on the satisfactory
level of their chance for success. These predictions were
supported by the two experiments, with two task types: nonmisleading and misleading problems. It was found that
although the final time-confidence relationship is negative,
the process progresses with a positive correlation between
them. The “don’t know” procedure was used to ensure that
the negative correlation does not stem from the desire to
move on to the next problem, even if a satisfactory solution
was not yet found. The results suggest that people find the
relatively low confidence they experience after lengthy
thinking to be satisfactory, even though the same confidence
levels were not acceptable if reached earlier in the process.
The present study suggests a difference between the
stopping rules for T1 and for T2. Thompson and her
colleagues (Thompson et al., 2011; Thompson et al., in
press) suggested that FOR is the basis for the stopping rule
for T1 and for triggering T2. If FOR is high enough, people
provide the first answer that comes to mind. Otherwise they
activate T2. The present study extends this idea to the
decision to stop T2. While time allocation for T1 was
explained to be based on fluency in which the first solution
option comes to mind, in a bottom-up manner, the stopping
rule for T2 is explained here as stemming from a goaldriven, top-down, effort investment. Importantly, this does
not rule out fluency effects on final confidence ratings as
well, but suggests that the goal-driven decision dominates
the process.
To conclude, metacognitive studies traditionally focus on
memorizing word lists. Investigating more complex tasks

The study was supported by a grant from the Israel
Foundation Trustees (2011-2013).

References
Ackerman, R., & Goldsmith, M. (2008). Control over grain
size in memory reporting—With and without satisficing
knowledge. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 34(5), 1224-1245.
Ackerman, R., & Goldsmith, M. (2011). Metacognitive
regulation of text learning: On screen versus on paper.
Journal of Experimental Psychology: Applied, 17(1), 1832.
Ackerman, R., & Zalmanov, H. (2012). The persistence of
the fluency–confidence association in problem solving.
Psychonomic Bulletin & Review, 19(6), 1189-1192.
Beaman, C. P. (2002). Why are we good at detecting
cheaters? A reply to Fodor. Cognition, 83, 215-220.
Begg, I., Duft, S., Lalonde, P., Melnick, R., & Sanvito, J.
(1989). Memory predictions are based on ease of
processing. Journal of Memory and Language, 28(5),
610-632.
Evans, J. (2006). The heuristic-analytic theory of reasoning:
Extension and evaluation. Psychonomic Bulletin &
Review, 13(3), 378-395.
Evans, J. (2009). How many dual-process theories do we
need? One, two, or many. In J. Evans & K. Frankish
(Eds.), In two minds: Dual processes and beyond.
Oxford, UK: Oxford University Press.
Frederick, S. (2005). Cognitive reflection and decision
making. Journal of Economic Perspectives, 19(4), 2542.
Kahneman, D. (2003). Maps of bounded rationality:
Psychology for behavioral economics. American
Economic Review, 93(5), 1449-1475.
Koriat, A., Ackerman, R., Adiv, S., Lockl, K., & Schneider,
W. (in press). The effects of goal-driven and data-driven
regulation on metacognitive monitoring during learning:
A developmental perspective. Journal of Experimental
Psychology: General.
Koriat, A., Ma'ayan, H., & Nussinson, R. (2006). The
intricate relationships between monitoring and control in
metacognition: Lessons for the cause-and-effect relation
between subjective experience and behavior. Journal of
Experimental Psychology: General, 135(1), 36-68.

125

Leron, U., & Hazzan, O. (2009). Intuitive vs analytical
thinking: four perspectives. Educational Studies in
Mathematics, 71(3), 263-278.
Metcalfe, J., & Weibe, D. (1987). Metacognition in insight
and noninsight problem solving. Memory & Cognition,
15, 238-246.
Nelson, T. O., & Narens, L. (1990). Metamemory: A
theoretical framework and new findings. In G. Bower
(Ed.), The Psychology of learning and motivation:
Advances in research and theory (Vol. 26). San Diego,
CA: Academic Press.
Payne, S. J., & Duggan, G. B. (2011). Giving up problem
solving. Memory & Cognition, 39(5), 902-913.
Stanovich, K. E. (2009a). Distinguishing the reflective,
algorithmic, and autonomous minds: Is it time for a triprocess theory? In J. Evans & K. Frankish (Eds.), In two
minds: Dual processes and beyond. Oxford, UK: Oxford
University Press.
Stanovich, K. E. (2009b). Rational and Irrational Thought:
The Thinking that IQ Tests Miss. Scientific American
Mind, 20(6), 34-39.
Thompson, V. A. (2009). Dual process theories: A
metacognitive perspective. In J. Evans & K. Frankish
(Eds.), In two minds: Dual processes and beyond.
Oxford, UK: Oxford University Press.
Thompson, V. A., Prowse Turner, J., & Pennycook, G.
(2011). Intuition, reason, and metacognition. Cognitive
Psychology, 63(3), 107-140.
Thompson, V. A., Turner, J. A. P., Pennycook, G., Ball, L.
J., Brack, H., Ophir, Y., & Ackerman, R. (in press). The
role of answer fluency and perceptual fluency as
metacognitive cues for initiating analytic thinking.
Cognition.
Topolinski, S., & Reber, R. (2010). Immediate truthTemporal contiguity between a cognitive problem and
its solution determines experienced veracity of the
solution. Cognition, 114(1), 117-122.
Vernon, D., & Usher, M. (2003). Dynamics of
metacognitive
judgments:
Pre-and
postretrieval
mechanisms. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 29(3), 339-346.
Wiley, J. (1998). Expertise as mental set: The effects of
domain knowledge in creative problem solving. Memory
& Cognition, 26(4), 716-730.

126

