UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Mental Simulation for Grounding Object Cognition

Permalink
https://escholarship.org/uc/item/8vj3r73k

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Author
Schendan, Haline E.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Mental Simulation for Grounding Object Cognition
Haline E. Schendan (haline.schendan@plymouth.ac.uk)
Cognition Institute, School of Psychology, University of Plymouth, Drake Circus
Plymouth, Devon PL4 8AA UK
Abstract
Grounded (embodied) theories of cognition propose that
memory, including knowledge and meaning, is grounded in
sensorimotor and mental state processes. The main proposed
mechanism for how memory is grounded is mental
simulation. Simulation occurs when neural activity in modal
association cortex triggers time-locked, recurrent and
feedback activity across multiple lower-level modal
processing areas from which the memory was initially
constructed. Through this distributed multi-regional activity,
seeing an object or reading its name (e.g., “dog”) re-enacts
associated features that were stored during earlier learning
experiences (e.g. its shape, color, motion, actions with it),
thereby constructing cognition, memory, and meaning. This
paper reviews convergent evidence from cognitive
neuroscience of mental imagery, object cognition, and
memory that supports a multi-state interactive (MUSI)
account of automatic and strategic mental simulation
mechanisms that can ground memory, including the meaning,
of objects in modal processing of visual features.
Keywords: Embodiment, grounded cognition; category;
concept; meaning, memory; shape; object; vision; brain.

The MUSI account of the brain dynamics of visual object
cognition proposes that posterior object processing areas
activate at different times in at least 3 states performing
distinct functions (Schendan & Ganis, 2012; Schendan &
Kutas, 2007). In state 1, initial activation of object
processing cortex feeds forward from occipital to anterior
temporal cortex. In this state, from ~120 to 200 ms, an
object is perceptually categorized coarsely for the first time
(Ganis & Schendan, 2008; Ganis, Smith, & Schendan, 2012;
Schendan & Ganis, 2013; Schendan, Ganis, & Kutas, 1998).
An event-related potential (ERP) that localizes to
occipitotemporal cortex, the N170/VPP, shows the first
clear object-sensitivity (i.e., greater for intact objects than
scrambled versions depicting no figure), which is a hallmark
of this cortex using functional magnetic resonance imaging
(fMRI) (Schendan & Lucia, 2010; Schendan & Stern,
2007). However, cognitive factors (e.g., mental imagery,
category decision success, meaning, semantic context)
modulate this cortex sensitively in fMRI studies but do not
likewise affect the N170/VPP (e.g., Ganis & Kutas, 2003;
Schendan & Lucia, 2009; Schendan & Lucia, 2010;
Schendan & Maher, 2009). Thus object information
activated in state 1 supports categorical perception, but
cognition that enables complex behavior (e.g., deciding the
object is a member of the dog category) does not start until
later, in a second state.
State 2 operates from ~200 to 500 ms when
occipitotemporal cortex is activated again but in a sustained,
interactive manner dominated by feedback and recurrent

processing among these areas and with ventrolateral
prefrontal cortex (VLPFC). The frontal N3(00) complex is
the first ERP to reflect activity in occipitotemporal cortex
related to the success of visual object cognition. Like the
N170/VPP (state 1) and fMRI activation, the N3 is objectsensitive, category-specific, and shows adaptation effects
(Ganis & Schendan, 2008; Schendan & Ganis, 2012;
Schendan & Lucia, 2010). However, unlike state 1 but like
occipitotemporal and VLPFC activity in fMRI, the N3
varies dramatically with mental imagery and factors
affecting category decision success, such as stimulus
typicality and impoverishment, implicit memory,
knowledge, and meaning (Ganis & Kutas, 2003; Philiastides
& Sajda, 2007; Schendan & Ganis, 2012; Schendan &
Kutas, 2002, 2003, 2007; Schendan & Lucia, 2009, 2010;
Schendan & Maher, 2009; Schendan & Stern, 2008; Voss,
Schendan, & Paller, 2010). Later from 300 to 500 ms, the
centroparietal N400 reflects semantic memory activation
related to processing word-related information in anterior
temporal cortex and VLPFC (Kutas & Federmeier, 2011).
Intriguingly, N3 effects start and peak before those on the
N400, placing the N3 in a temporal position to reflect
processes supporting mental simulation of object
information that constructs the meaning analyses indexed by
the N400. State 2 reflects decision, implicit memory,
knowledge, and meaning processes distinct from earlier
state 1 and later state 3 processes.
State 3 operates from ~400 to 900 ms during complex
cognitive tasks and evaluates internally the accuracy of
earlier and ongoing decision processes and executes
verification processes, including effortful, strategic,
conscious mental simulations. These brain dynamics are
reflected in a centroparietal late positive complex (LPC) that
distinguishes between correct and wrong decisions but does
not vary with how well the stimulus matches memory,
which, by contrast, sensitively modulates the N3 (Schendan
& Kutas, 2002; Schendan & Maher, 2009). The LPC varies
with episodic recollection, as when recalling details of the
learning experience during recognition and mental imagery
tasks (Rugg & Curran, 2007; Schendan & Ganis, 2012), as
does a default mode network that connects strongly with the
mediotemporal system for episodic memory and is
associated with episodic simulation and strategic, conscious
mental imagery (Ganis & Schendan, 2011; Schacter, Addis,
& Buckner, 2008). Such late processes, however, may also
support complex semantic analysis (e.g., Sitnikova, Goff, &
Kuperberg, 2009). Thus the LPC reflects internal evaluation
and verification processes that also support strategic,
conscious, goal-driven mental simulation that can contribute

1684

to grounding cognition in more abstract and complex ways
than earlier automatic mental simulation.
The MUSI account can explain object cognition as well as
the brain mechanisms of mental simulation to ground
cognition in visual object processing, positing two
functionally-distinct states of mental simulation: Earlier
automatic simulation and later strategic simulation
(Schendan & Ganis, 2012). Crucially for grounded
cognition theory, the pattern of mental imagery findings on
the N3, N400, and LPC resembles that for repetition
priming of perceived pictures, implicating these ERPs as
markers of mental simulation. Following initial categorical
perception of objects in state 1, interactive, top-down and
reflexive feedback, and recurrent processes in state 2
support automatic mental simulation to ground knowledge
and meaning (Barsalou, 2009) in modal processing of visual
features in occipitotemporal cortex (N3) and word-related
semantic processes in anterior temporal cortex (N400). The
second type of mental simulation is strategic, goal-directed,
and conscious and recruited when the task demands internal
evaluation of cognition, as in mental imagery and episodic
memory tasks. This simulation reflects intentional top-down
processes directed by lateral prefrontal and posterior parietal
networks for attention, cognitive control, and working
memory (LPC). These neural markers of automatic and
strategic mental simulation should be the focus of needed
research into the brain mechanisms for how modal
information processing grounds cognition.

Acknowledgments
EU FP7 PCIG09-GA-2011-294144-COGNITSIMS.

References
Barsalou,
L.
W.
(2009).
Simulation,
situated
conceptualization, and prediction. Philos Trans R Soc
Lond B Biol Sci, 364(1521), 1281-1289.
Ganis, G., & Kutas, M. (2003). An electrophysiological
study of scene effects on object identification. Brain Res
Cogn Brain Res, 16(2), 123-144.
Ganis, G., & Schendan, H. E. (2008). Visual mental
imagery and perception produce opposite adaptation
effects on early brain potentials. Neuroimage, 42(4),
1714-1727.
Ganis, G., & Schendan, H. E. (2011). Mental imagery.
Wiley Interdisciplinary Reviews: Cognitive Science, 2(3),
239-252.
Ganis, G., Smith, D., & Schendan, H. E. (2012). The N170,
not the P1, indexes the earliest time for categorical
perception of faces, regardless of interstimulus variance.
Neuroimage, 62(3), 1563-1574.
Kutas, M., & Federmeier, K. D. (2011). Thirty years and
counting: finding meaning in the N400 component of the
event-related brain potential (ERP). Annu Rev Psychol,
62, 621-647.
Philiastides, M. G., & Sajda, P. (2007). EEG-informed
fMRI reveals spatiotemporal characteristics of perceptual
decision making. J Neurosci, 27(48), 13082-13091.

Rugg, M. D., & Curran, T. (2007). Event-related potentials
and recognition memory. Trends Cogn Sci, 11(6), 251-7.
Schacter, D. L., Addis, D. R., & Buckner, R. L. (2008).
Episodic simulation of future events: concepts, data, and
applications. Ann N Y Acad Sci, 1124, 39-60.
Schendan, H. E., & Ganis, G. (2012). Electrophysiological
potentials reveal cortical mechanisms for mental imagery,
mental simulation, and grounded (embodied) cognition.
Frontiers in Psychology, 3(Article 329), 1-22.
Schendan, H. E., & Ganis, G. (2013). Face-Specificity Is
Robust across Diverse Stimuli and Individual People,
Even When Interstimulus Variance Is Zero.
Psychophysiology.
Schendan, H. E., Ganis, G., & Kutas, M. (1998).
Neurophysiological evidence for visual perceptual
categorization of words and faces within 150 ms.
Psychophysiology, 35(3), 240-251.
Schendan, H. E., & Kutas, M. (2002). Neurophysiological
evidence for two processing times for visual object
identification. Neuropsychologia, 40(7), 931-945.
Schendan, H. E., & Kutas, M. (2003). Time course of
processes and representations supporting visual object
identification and memory. Journal of Cognitive
Neuroscience, 15(1), 111-135.
Schendan, H. E., & Kutas, M. (2007). Neurophysiological
Evidence for the Time Course of Activation of Global
Shape, Part, and Local Contour Representations during
Visual Object Categorization and Memory. J Cogn
Neurosci, 19(5), 734-749.
Schendan, H. E., & Lucia, L. C. (2009). Visual object
cognition precedes but also temporally overlaps mental
rotation. Brain Research, 1294, 91-105.
Schendan, H. E., & Lucia, L. C. (2010). Object-Sensitive
Activity Reflects Earlier Perceptual and Later Cognitive
Processing of Visual Objects between 95 and 500 ms.
Brain Research, 1329, 124-141.
Schendan, H. E., & Maher, S. M. (2009). Object knowledge
during entry-level categorization is activated and
modified by implicit memory after 200 ms. Neuroimage,
44(4), 1423-1438.
Schendan, H. E., & Stern, C. E. (2007). Mental rotation and
object categorization share a common network of
prefrontal and dorsal and ventral regions of posterior
cortex. Neuroimage, 35(3), 1264-1277.
Schendan, H. E., & Stern, C. E. (2008). Where Vision
Meets Memory: Prefrontal-Posterior Networks for Visual
Object Constancy during Categorization and Recognition.
Cerebral Cortex, 18(7), 1695-1711.
Sitnikova, T., Goff, D., & Kuperberg, G. R. (2009).
Neurocognitive abnormalities during comprehension of
real-world goal-directed behaviors in schizophrenia. J
Abnorm Psychol, 118(2), 256-277.
Voss, J. L., Schendan, H. E., & Paller, K. A. (2010).
Finding meaning in novel geometric shapes influences
electrophysiological correlates of repetition and
dissociates perceptual and conceptual priming.
Neuroimage, 49(3), 2879-2889.

1685

