UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Effects of Objects' "Embodiment" on the Acquisition of Problem-Solving Skills through
Practice or Video-based Modeling Example Study

Permalink
https://escholarship.org/uc/item/7k92t7t1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Van Gog, Tamara
Post, Lysanne
Ten Napel, Robyn
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Effects of Objects’ “Embodiment” on the Acquisition of Problem-Solving Skills
through Practice or Video-based Modeling Example Study
Tamara van Gog (vangog@fsw.eur.nl)
Institute of Psychology, Erasmus University Rotterdam
P.O. Box 1738, 3000DR Rotterdam, The Netherlands

Lysanne S. Post (l.s.post@fsw.eur.nl)
Institute of Psychology, Erasmus University Rotterdam
P.O. Box 1738, 3000DR Rotterdam, The Netherlands

Robyn J. ten Napel (robyn.napel@gmail.com)
Institute of Psychology, Erasmus University Rotterdam
P.O. Box 1738, 3000DR Rotterdam, The Netherlands

Lian Deijkers (cmdeijkers@gmail.com)
Institute of Psychology, Erasmus University Rotterdam
P.O. Box 1738, 3000DR Rotterdam, The Netherlands

Abstract
We investigated whether “embodiment” of objects used in a
problem-solving task (i.e., whether they have a bodily shape)
would have a detrimental effect on learning to solve that
problem through practice or through studying video-based
modeling examples. A 2x2 design with factors Training
(Practice/Example study) and Embodiment (Present/Absent)
was used (N = 80). Results showed a large main effect of
Training on effort investment in learning and on retention test
performance, with Example study leading to higher scores
with lower investment of effort during the learning phase
than Practice. Numerically, Embodiment seemed to have an
effect, with participants practicing/studying the task with
embodied objects (plastic animals) performing worse on
retention than participants practicing/ studying with nonembodied objects (discs), but this did not reach statistical
significance. A new study with more power and an additional
control condition is currently being conducted and results are
expected to be available well before the conference.
Keywords: problem solving; example study; embodiment.

Introduction
A substantial body of research in cognitive science has
investigated the effects of a problem’s appearance on the
acquisition of problem-solving skills. For instance, versions
of the Tower of Hanoi task that had the exact same problem
space but instead of discs, featured monsters passing globes,
or acrobats jumping on each other’s shoulders, were found
to be much more difficult (Kotovsky, Hayes, & Simon,
1985; see also findings by Goldstone & Son, 2005, on
effects of concrete vs. idealized object appearance on
pattern learning from a simulation). The present study
investigated whether the “embodiment” of objects featured
in a problem, that is, whether the objects have a bodily
shape, would have a detrimental effect on learning to solve
a problem either by means of practice or by means of
studying digital video-based modeling examples. To the

best of our knowledge, the effects of problem appearance
on acquiring problem-solving skills from examples has
never been investigated yet.

Practice vs. Example Study
For students who need to acquire problem-solving skills
but lack prior knowledge of a task, practicing with problem
solving is not the most efficient way to acquire those skills.
It is far more effective and efficient for novice learners to
study examples in which the solution procedure is workedout (worked examples) or demonstrated to the learner
(modeling examples; for reviews, see Atkinson, Derry,
Renkl, & Wortham, 2000; Renkl, 2011; Sweller, Van
Merriënboer, & Paas, 1998; Van Gog & Rummel, 2010).
Interestingly, the higher effectiveness and efficiency of
example study (possibly alternated with problem-solving)
compared to problem-solving practice has not only been
found when problems contain no guidance whatsoever, but
also when they are tutored problems, on which feedback
and hints are provided when errors are made (Salden,
Koedinger, Renkl, Aleven, & McLaren, 2010).
Cognitive load theory explains these beneficial effects of
example study compared to problem solving in terms of the
underlying cognitive processes and associated cognitive
load (Sweller et al., 1998). Problems usually contain only a
description of some “givens” and a goal statement, without
providing any information on how to move from the givens
to the goal state. As a consequence, novices have to figure
out the correct solution steps to use by themselves, and
often do so by resorting to weak problem-solving strategies
such as trial-and-error, or means-ends analysis, which
impose a high cognitive load but are not very effective for
learning: even though such weak strategies may allow
learners to succeed in solving the problem eventually (i.e.,
good performance), they have been shown to contribute

3621

very little to learning (i.e., good performance of that task at
a later moment; Sweller, 1988).
Worked examples prevent the use of such weak problemsolving strategies, by presenting the learner not only with
the givens and a goal statement, but also with the workedout solution steps that are to be taken to reach the goal state.
The learner can devote all of his or her available cognitive
capacity to studying the given solution and constructing a
cognitive schema for solving such problems, which can be
applied to solve this (or a isomorphic) problem in the
future. As such, compared to instruction consisting of
problem-solving practice, instruction that relies more
heavily on studying worked examples reduces ineffective
cognitive load on working memory, and leads to enhanced
learning outcomes and often to improved transfer
performance (Sweller et al., 1998).
In addition to being more effective for learning, a heavier
reliance on examples has also been shown to have
beneficial effects on required acquisition time (i.e., lower;
see e.g., Sweller & Cooper, 1985; Van Gog, Paas, & Van
Merriënboer, 2006; Zhu & Simon, 1987) and cognitive load
experienced by students during acquisition (i.e., lower; see
e.g., Paas & Van Merriënboer, 1994; Van Gog et al., 2006)
as well as during the test (i.e., lower; see e.g., Paas, 1992;
Paas & Van Merriënboer, 1994).
However, it should be kept in mind that the beneficial
effects of worked examples on learning, acquisition time,
and cognitive load, seem to apply primarily to novice
learners (for advanced learners, an ‘expertise reversal
effect’ occurs, and problem solving becomes more
effective; Kalyuga, Chandler, Tuovinen, & Sweller, 2001;
see also Kalyuga, Ayres, Chandler, & Sweller, 2003), and
apply only when the examples are well-designed. That is,
following early studies on the worked example effect
(Cooper & Sweller, 1987; Sweller & Cooper, 1985) it was
soon discovered that studying worked examples was not
always more effective for learning than problem solving.
Rather, the design of the examples played a crucial role in
their effectiveness (Tarmizi & Sweller, 1988). For instance,
examples that induced split-attention (Chandler & Sweller,
1991; Tarmizi & Sweller, 1988) or included redundant
information (Chandler & Sweller, 1991), did not have
beneficial effects on cognitive load and learning.
The present study also addresses the effects of problem
and example design on cognitive load and learning, though
in a very different manner, that is, by investigating the
effects of embodiment of the objects used in the task.

Problem-solving Task and Design Effects
The task used in this study is based on a computer-based
problem-solving task called Frog Leap (see Van Gog, 2011;
Van Gog, Jarodzka, Scheiter, Gerjets, & Paas, 2009). In this
computer-based task, the goal is to switch the sides of three
brown frogs on the right and three green frogs on the left by
clicking on them. There is an empty space in the middle.
The frogs face in the direction of their goal. If they are
clicked on they jump one place ahead or jump over one

other frog (they cannot jump over two others, and they
cannot go back). The problem can be solved in only one
way, in 15 moves.
Prior research has shown the superiority of studying
modeling examples (consisting of screen-recordings) over
problem solving with this computer-based task. Van Gog et
al. (2009) showed that none of the 11 participants in the
problem-solving condition managed to solve the problem
after practicing twice, and Van Gog (2011) reported pilot
data with 7 participants showing the same result even after
four practice attempts. In contrast, after studying two
examples, the numbers of participants to successfully solve
the problem was approximately 58% (Van Gog et al.,
2009), and the number of moves correctly completed was
approximately 10 (out of 15; Van Gog, 2011). Effects on
transfer were not really explored in these prior studies. A
second test task was included on which participants had to
start on the opposite side as in the example, which was
more difficult because the task had not been practiced or
studied starting from this side. Therefore, participants could
not simply copy the procedure they had learned, and
performance on this second test task was lower than on the
first (Van Gog, 2011). However, an even stronger transfer
test would be to add an additional component on each side,
in which case the solution procedure still relies on the same
mechanism, but consists of 24 steps and can only be
successfully performed when the mechanism is understood.
A closer look at the task suggests that the errors made
during problem solving (both during practice and on the
test) seem to result from a failure to carefully consider all
possible moves and their consequences. This would explain
why test performance strongly improved when participants
had the chance to study a video-based modeling example
twice, in which the procedure was demonstrated (Van Gog,
2011) or demonstrated and explained (Van Gog et al.,
2009).
Based on anecdotal evidence of some participants’
responses to the task in prior studies, we began to wonder
whether this failure to consider all possible moves could be
related to the fact that the objects had a bodily shape, that is,
were frogs that had a face and “were headed in a direction”.
That characteristic seemed to evoke anthropomorphic
thinking in some participants (i.e., assigning intentions or
goals to the frogs; for a discussion of anthropomorphic
thinking, see Epley, Waytz, & Cacioppo, 2007). Assigning
intentions to the objects that need to be moved, might
aggravate the tendency to rapidly execute steps that seem to
physically reduce the distance of a frog to its goal, without
considering the other possible moves (cf. Sweller &
Levine’s, 1982, maze learning experiment, in which people
who had their left hand on the finish and had to move their
right index finger through the maze to get to the finish,
continuously made incorrect moves to the left, where they
knew their goal was).
If this indeed plays a role, then using the same task but
with non-embodied objects should lead to better learning
outcomes. To investigate this question, we re-created the

3622

computer-based problem-solving task with real objects, that
were either “embodied” (i.e., animals) or “non-embodied”
(i.e., discs).

Hypotheses
Based on prior research on example-based learning in
general (for reviews, Atkinson et al., 2000; Renkl, 2011;
Sweller et al., 1998; Van Gog & Rummel, 2010), and on the
computer-based version of this task in particular (Van Gog,
2011; Van Gog et al., 2009), we first of all expected that
studying digital video-based modeling examples would also
be more effective (result in higher learning outcomes) as
well as more efficient (higher learning outcomes attained
with less investment of mental effort) than problem-solving
practice for this real object version of the task. The open
question of whether performance on a transfer task would
also be enhanced when an additional object is added on
each side, is explored.
Secondly, it was hypothesized that practicing the
problem-solving task with “embodied” objects (i.e. animals)
would lead to lower performance than doing so with “nonembodied” objects (i.e., discs). The open question of
whether this would only be the case for the problem-solving
practice conditions (cf. Kotovsky et al., 1985), or also for
the examples conditions, was explored. On the one hand,
when studying examples and subsequently taking a test with
embodied objects, this might not have negative effects on
test performance because participants had a chance to learn
the correct procedure from the examples. On the other hand,
however, participants might still be affected by the objects’
embodiment (e.g., fall prey to anthropomorphic thinking)
once they start performing the test task themselves.

based task, three green frogs are sitting on stones on one
side of the river, three brown frogs on the other side, with
one empty stone in the middle. The goal is to have them
switch sides, but frogs can only jump one place ahead if that
is free, or jump over one other frog to a free place. They
cannot go back or jump over two other frogs. The goal can
be reached in 15 steps. In this study, a version of the task
was created using real objects (see Figure 1), and the
objects consisted either of plastic yellow fishes and green
seals (Embodiment Present) or yellow and green discs
(Embodiment Absent).
In the practice conditions, participants were given two
practice opportunities in which they attempted to solve the
problem for 1 min.; if they got stuck, they were allowed to
start again. In the examples conditions, participants
observed a digital video-based modeling example (1 min.
duration) twice, in which a human model demonstrated the
correct solution procedure with either the animal objects or
the discs. The model did not provide any verbal
explanations and only the model’s hand moving the objects
was visible in the video. The digital video was presented on
a laptop with a screen resolution of 1280 x 720 pixels at a
size of 28.5 x 18 cm.

Method

Figure 1: Initial state of the problem in the Embodiment
Present (top) and Absent (bottom) conditions

Participants were 80 adults (M = 22.8, SD = 2.61; 43
women) recruited from the general population. A 2 x 2
design with factors Training (Practice vs. Example) and
Embodiment (Present vs. Absent) was used. Participants
were assigned to one of the four conditions matched for
gender, but otherwise randomly: (1) Embodiment Present –
Practice (n = 20), (2) Embodiment Absent – Practice (n =
20), (3) Embodiment Present – Example (n = 21), and (4)
Embodiment Absent – Example (n = 19).

Test tasks The retention test task was identical to the
learning task. The transfer test task consisted of the same
problem, but with four objects on either side. This task
could be solved in 24 steps.
Mental effort After each practice task, each example, and
each test task, participants rated how much effort they
invested in problem solving or example study on Paas’
(1992) 9-point rating scale ranging from (1) very, very low
effort, to (9) very, very high effort. This subjective rating
scale is widely used in educational research (for reviews,
see Paas, Tuovinen, Tabbers, & Van Gerven, 2003; Van
Gog & Paas, 2008).

Participants

Materials
Demographic questionnaire A demographic questionnaire
asked for age, gender, level of education, and it also
included a check on whether participants were familiar with
the learning task (by showing them a picture of the initial
state of the problem in the computer-based version
discussed above).
Learning task The learning task was based on the
computer-based problem-solving task mentioned above (see
Van Gog, 2011; Van Gog et al., 2009). In this computer-

Procedure
The study was conducted in individual sessions of
approximately 10 min. After filling out the demographic
questionnaire, the learning phase started. Participants were
first instructed about the rules of the task (i.e., an object can
only move one space ahead to a free space or over one other
object to a free space, moving back or moving over two
other objects is not allowed). Depending on their assigned

3623

condition, they subsequently received the instruction to
either practice for 1 min., during which they were allowed
to start again if they got stuck, or to study the example
presented in the video. After practicing or example study,
they rated how much effort they invested in problem
solving or example study. Then this sequence was repeated
a second time. Depending on their assigned condition,
participants practiced with either animals or discs or
observed a modeling example with either animals or discs.
Immediately after the learning phase, the test phase started,
during which all participants were required to solve the
problem themselves, first the retention task, which was the
exact same problem they had encountered in the learning
phase, with three objects on both sides, then the transfer
task with four objects on both sides. Depending on their
assigned condition, participants performed the test tasks
with either animals (when they had practiced/studied the
task with animals) or discs (when they had practiced/studied
the task with discs). Immediately after each task, they
indicated how much effort they invested in attempting to
solve the problem. In the test phase, participants’
performance was recorded on digital video (zooming in on
their hands and the task), to be able to score their
performance afterwards.

Data analysis
Using the video recordings, each participant’s
performance on the test tasks was determined by scoring the
number of steps correctly executed. For the first test task,
this resulted in a maximum score of 15, for the transfer task,
in a maximum score of 24. For two participants,
performance scores were lost due to a technical recording
error and two participants failed to fill out an effort rating.
Because initial explorative analyses showed that the
performance on the test tasks was not normally distributed,
a log transformation was conducted (Field, 2009).

Results
Data were analyzed using 2 x 2 ANOVAs with betweensubjects factors Training (Practice vs. Example) and
Embodiment (Present vs. Absent). For all analyses a
significance level of .05 was used and Cohen’s d is reported
as a measure of effect size, with 0.20, 0.50, and 0.80
constituting small, medium, and large effects, respectively.

Effort Invested in the Learning Phase
There was a significant main effect of Training on mental
effort invested in the learning phase F(1,74) = 102.09, MSE
= 3.08, p < .001, Cohen’s d = 2.31, with participants who
studied the video-based modeling examples reporting much
lower effort (M = 2.94, SD = 1.63) than participants who
practiced problem solving (M = 7.00, SD = 1.87). There
was no significant main effect of Embodiment, nor a
significant interaction effect.

Retention Test Task
There was a significant main effect of Training, F(1,74) =
15.09, MSE = .07, p < .001, Cohen’s d = 0.87, which
indicated that participants in the Example conditions
outperformed (M = 0.79, SD = 0.30; non-transformed: M =
6.74, SD = 5.44) participants in the practice conditions (M =
0.56, SD = 0.22; non-transformed: M = 3.13, SD = 2.49).
Although there was a trend towards an effect of
Embodiment, with participants in the Embodiment Absent
conditions performing better (M = 0.72, SD = 0.29; nontransformed: M = 5.51, SD = 4.78) than participants in the
Embodiment Present conditions (M = 0.63, SD = 0.28; nontransformed: M = 4.36, SD = 4.36) this did not reach
significance, F(1,74) = 2.35, MSE = .068, p = 0.129,
Cohen’s d = 0.30. There was no significant interaction.
A 2 x 2 ANOVA on invested mental effort on the
retention test task, showed a significant main effect of
Training, F(1,76) = 9.63, MSE = 5.12, p < .01, Cohen’s d =
0.70, indicating that participants who had studied examples
invested less mental effort in solving the retention test
problem (M = 5.22, SD = 2.60) than participants who had
practiced (M = 6.82, SD = 1.91). There was no significant
main effect of Embodiment F(1,76) < 1, nor an interaction
effect, F(1,76) = 2.58, MSE = 5.12, p = .113 and indicated
that in the Example conditions, the Embodiment Absent
condition tended to invest more effort than the Embodiment
Present condition on the retention test task, whereas in the
Practice conditions, this was the other way around.

Transfer Test Task
There were no significant main or interaction effects on
performance and invested mental effort on the transfer test
task (all F < 1).

Discussion
In line with our first hypothesis, we found a large (d =
0.87) beneficial effect of example study on test
performance. Moreover, the examples conditions reached
this higher test performance with less investment of effort
during the learning phase (indicating a more efficient
learning process), as well as less investment of effort during
the retention test (indicating more efficient learning
outcomes; Van Gog & Paas, 2008). This finding is in line
with prior studies in other domains that have shown higher
learning outcomes with less investment of mental effort
during acquisition (e.g., Paas & Van Merriënboer, 1994;
Van Gog et al., 2006) as well as during the test (e.g., Paas,
1992; Paas & Van Merriënboer, 1994). This effect was
limited to the retention test task, though. There were no
effects on transfer, which suggests that students in the
Example study conditions remembered the procedure (they
performed better on the retention test), but did not really
understand it sufficiently to be able to adapt it to a new
problem situation with an additional object on each side. It
would therefore be interesting to investigate whether
including verbal explanations by the model, emphasizing
the possible options at each step and indicating why the

3624

eventually chosen step is correct and the others are not,
would enhance understanding of the solution procedure and
thereby, transfer performance.
Regarding our second hypothesis about effects of
Embodiment on test performance, we saw a trend in the
expected direction, with participants in the Embodiment
Absent conditions performing better than participants in the
Embodiment present conditions: practicing or studying
examples with animal-like plastic objects led to less steps
correctly completed on the retention test than practicing or
studying examples with wooden discs. However, this
difference failed to reach statistical significance (p = .129; d
= 0.30), possibly due to the relatively low number of
participants. Therefore, we will replicate this study with a
larger number of participants.

Second Study
We are currently conducting a replication study with a
larger number of participants to achieve more statistical
power. This study will also include an additional condition
in which we will control for the effect of direction. That is,
because the animals were embodied, they were also headed
in a direction. The discs did not imply any direction. So
assuming we would find a significant effect of Embodiment
when we have more statistical power, this additional
condition will allow us to answer the question of whether
this is really due to anthropomorphism (assigning goals and
intentions to objects that have a bodily shape) or simply a
consequence of implied direction. If so, that would still be
an interesting finding in terms of understanding factors that
might affect problem solving and the acquisition of
problem-solving skills through example study. The results
of this second study are expected to be available well before
the conference.

References
Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D.
(2000). Learning from examples: Instructional principles
from the worked examples research. Review of
Educational Research, 70, 181-214.
Chandler, P. & Sweller, J. (1991). Cognitive load theory
and the format of instruction. Cognition and Instruction,
8, 293-332.
Cooper, G., & Sweller, J. (1987). The effects of schema
acquisition and rule automation on mathematical problemsolving transfer. Journal of Educational Psychology, 79,
347-362.
Epley, N., Waytz, A., & Cacioppo, J. T. (2007). On seeing
human: A three-factor theory of anthropomorphism.
Psychological Review, 114, 864-886.
Field, A. (2009). Discovering statistics using SPSS (3rd
edition). London: Sage Publications.
Goldstone, R. L., & Son, J. Y. (2005). The transfer of
scientific principles using concrete and idealized
simulations. The Journal of the Learning Sciences, 14, 69110.
Kalyuga, S., Ayres, P., Chandler, P., & Sweller, J. (2003).

The expertise reversal effect. Educational Psychologist,
38, 23-32.
Kalyuga, S., Chandler, P., Tuovinen, J., & Sweller, J.
(2001). When problem solving is superior to studying
worked examples. Journal of Educational Psychology, 93,
579-588.
Kotovsky, K., Hayes, J. R., & Simon, H. A. (1985). Why
are some problems hard? Evidence from Tower of Hanoi.
Cognitive Psychology, 17, 248-294.
Paas, F. (1992). Training strategies for attaining transfer of
problem-solving skill in statistics: A cognitive load
approach. Journal of Educational Psychology, 84, 429434.
Paas, F., Tuovinen, J. E., Tabbers, H., & Van Gerven, P. W.
M. (2003). Cognitive load measurement as a means to
advance cognitive load theory. Educational Psychologist,
38, 63-71.
Paas, F., & Van Merriënboer, J. J. G. (1994). Variability of
worked examples and transfer of geometrical problem
solving skills: A cognitive-load approach. Journal of
Educational Psychology, 86, 122-133.
Renkl, A. (2011). Instruction based on examples. In R. E.
Mayer & P. A. Alexander (Eds.), Handbook of research
on learning and instruction (pp. 272¬295). New York:
Routledge.
Salden, R. J. C. M., Koedinger, K. R., Renkl, A., Aleven,
V., & McLaren, B. M. (2010). Accounting for beneficial
effects of worked examples in tutored problem solving.
Educational Psychology Review, 22, 379–392.
Sweller, J. (1988). Cognitive load during problem solving:
Effects on learning. Cognitive Science, 12, 257-285.
Sweller, J., & Cooper, G. A. (1985). The use of worked
examples as a substitute for problem solving in learning
algebra. Cognition and Instruction, 2, 59-89.
Sweller, J., & Levine, M. (1982). Effects of goal specificity
on means-ends analysis and learning. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 8, 463-474.
Sweller, J., Van Merriënboer, J. J. G., & Paas, F. (1998).
Cognitive architecture and instructional design.
Educational Psychology Review, 10, 251-295.
Tarmizi, R., & Sweller, J. (1988). Guidance during
mathematical problem solving. Journal of Educational
Psychology, 80, 424-436.
Van Gog, T. (2011). Effects of identical example-problem
and problem-example pairs on learning. Computers &
Education, 57, 1775-1779.
Van Gog, T., Jarodzka, H., Scheiter, K., Gerjets, P., & Paas,
F. (2009). Attention guidance during example study via
the model’s eye movements. Computers in Human
Behavior, 25, 785-791.
Van Gog, T., & Paas, F. (2008). Instructional efficiency:
Revisiting the original construct in educational research.
Educational Psychologist, 43, 16-26.
Van Gog, T., Paas, F., & Van Merriënboer, J. J. G. (2006).
Effects of process-oriented worked examples on
troubleshooting transfer performance. Learning and

3625

Instruction, 16, 154-164.
Van Gog, T., & Rummel, N. (2010). Example¬based
learning: Integrating cognitive and social¬cognitive
research perspectives. Educational Psychology Review,
22, 155-174.
Zhu, X., & Simon, H. A. (1987). Learning mathematics
from examples and by doing. Cognition and Instruction,
4, 137-166.

3626

