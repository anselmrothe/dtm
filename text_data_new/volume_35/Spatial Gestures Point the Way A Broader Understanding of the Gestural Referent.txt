UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Spatial Gestures Point the Way: A Broader Understanding of the Gestural Referent

Permalink
https://escholarship.org/uc/item/49v9g5mx

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Atit, Kinnari
Resnick, Ilyse
Shipley, Thomas
et al.

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Spatial Gestures Point the Way: A Broader Understanding of the Gestural Referent
Kinnari Atit (kinnari.atit@temple.edu)
Ilyse Resnick (ilyse.resnick@temple.edu)
Thomas F. Shipley (tshipley@temple.edu)

Tilbe Goksun (tilbe@mail.upenn.edu)

Temple University, 1701 N. 13th St.
Philadelphia, PA 19122 USA

University of Pennsylvania, 3400 Spruce St.
Philadelphia, PA 19104 USA

Carol J. Ormand (cormand@carleton.edu)
Cathryn A. Manduca (cmanduca@carleton.edu)

Basil Tikoff (basil@geology.wisc.edu)
University of Wisconsin-Madison, 1215 W Dayton St.
Madison, WI 53706 USA

Carleton College, One North College St.
Northfield, MN 55057 USA

Abstract
We investigated the use of iconic and deictic gestures
during the communication of spatial information. Expert
structural geologists were asked to explain one portion of a
geologic map. Spatial gestures used in each expert’s response
were coded as deictic (indicating an object in the
conversational space), iconic (depicting an aspect of an object
or event), or both deictic and iconic (indicating an object in
the conversational space by depicting an aspect of that
object). Speech paired with each gesture was coded for
whether or not it referred to complex spatial properties (e.g.
shape and orientation of an object). Results indicated that
when communicating spatial information, people occasionally
use gestures that are both deictic and iconic, and that these
gestures tend to occur when complex spatial information is
not provided in speech. These results suggest that existing
classifications of gesture are not exclusive, especially for
spatial discourse.
Keywords: gesture; deictic; iconic; highlighting

Introduction
People communicate and focus the listener’s attention to
different levels of spatial information in speech and gesture.
Spatial information is expressed in gesture both for
communicating with others and for individual problem
solving (Alibali, 2005). Common spatial activities (e.g.
giving directions) (Lavergne & Kimura, 1987; Allen, 2003)
and the communication of complex spatial ideas (e.g.
geology) (Liben, Christensen, & Kastens, 2010) often
include gesture.
Communicating three-dimensional spatial relationships
using only language is difficult. As most spatial words are
qualitative and are not apt for asserting metric spatial
information (Tversky & Lee, 1998), gesture is critical in
conveying relations that cannot be easily expressed in
speech. Gesture allows one to communicate thoughts that do
not easily fit into the categorical system language offers
(Goldin-Meadow, 1999). The literature provides a
classification for spontaneous gestures made during regular
discourse (e.g. McNeill, 1992; Krauss, Chen, & Chawla,
1996; Ekman & Friesan, 1969). This study investigates

whether the existing classification is appropriate for gestures
that occur during spatial discourse involving complex
spatial reasoning.
Extant research indicates that gestures occur more
frequently when communicating spatial information, than
when communicating non-spatial information (e.g. Alibali,
Heath, & Myers, 2001; Rauscher Krauss, & Chen, 1996;
Lavergne & Kimura, 1987). For example, Alibali, Heath,
and Myers (2001) asked participants to narrate a Tweety and
Sylvester cartoon to a naïve addressee, and found that the
speakers were nearly twice as likely to produce gestures
with units that contained spatial prepositions than with units
that did not. Furthermore, gesture frequency varies
depending on speech topic. Lavergne and Kimura (1987)
asked participants to speak for six minutes each on neutral
topics (e.g. describe your typical school day routine), verbal
topics (e.g. describe your favorite books and authors), and
spatial topics (e.g. describe the route you would take to walk
from the university’s main library to the main entrance of
campus). Participants produced twice as many gestures
when speaking about spatial topics than when speaking
about verbal or neutral topics.
People convey information using gestures in many
different ways. For the purpose of this paper, gestures are
defined as movements of the hands and arms that are
produced when engaging in effortful cognitive activity (e.g.
speaking, problem solving) (Alibali, 2005). Much of the
literature has focused on two broad categories of
movements: beat and representational gestures. Beats are
hand movements that match the rhythm of the associated
speech. For example, when reciting his grocery list, the
speaker moves his finger up and down for every item on the
list, “apples, bananas, cheese, and bread.” Within the
category of representational gestures (gestures that convey
semantic content by virtue of shape, placement, or motion
trajectory of the hands - e.g. pointing to the right to mean
“right”) (Alibali, 2005), gestures can be categorized as
iconic or deictic (McNeill, 1992). These two broad types of
gesture are the focus of this paper.
Iconic gestures “bear a close formal relationship to the
semantic content of speech” (McNeill, 1992, p.12). For

1786

example, when describing a scene from a comic book in
which a character bends a tree back to the ground, the
speaker makes gripping and pulling gestures as he or she
describes the same actions (McNeill, 1992). Deictic gestures
indicate entities in the conversational space (the physical
space visible to both participants of the conversation).
Usually, deictic gestures are pointing gestures that indicate
objects and events in the concrete world (McNeill, 1992).
For example, when choosing a puppy at the pet store, the
child points to the puppy that he wants to buy.
Starting at 9 to 12 months of age, humans use pointing
gestures to indicate objects in the environment (Bates, 1976;
Bates, Benigni, Bretherton, Camaioni, & Volterra, 1979).
Though pointing is an easy and efficient way of indexing an
object in space, and although the distinction between iconic
and deictic gestures may be helpful in classifying nonspatial discourse, we propose that in tasks involving the
communication of complex spatial information, the current
classification may be limiting. The current classification is
implicitly mutually exclusive, perhaps for methodological
reasons, such that gestures would be classified as either
deictic or iconic, but not both. If this assumption is
incorrect, researchers could be in danger of missing
potentially informative gestures that are both deictic and
iconic.
The existing classification does not capture gestures that
simultaneously draw the listener’s attention to a specific
object and represent two or more dimensions of spatial
information. Gestures that are not pointing (or tracing) can
provide “deictic” information; for example, an “iconic”
gesture that resembled an object could be used to refer to the
object. Such gestures have been reported anecdotally, Roth
(2000) details a middle school science student explaining to
his class the mechanism behind a pulley system. In his
explanation, the student says, “Pull here,” and used a
gesture that made salient both the location and direction of
the pull (Roth, 2000). The gesture is both iconic and deictic.
As in this example, one could use the hand to draw the
listener’s attention to the form and location of something in
the environment. Since we know that listeners make use of
the information in a speaker’s gestures (e.g. Alibali,
Flevares, & Goldin-Meadow, 1997; Goldin-Meadow &
Sandhofer, 1999) and spatial concepts can be hard to convey
in speech alone, we may learn more about the function of
gestures by observing their use in discussion of complex
spatial settings.
Thus, the current study examines the use of deictic
gestures during a spatial task. The results presented here are
part of a larger study investigating the communication of
spatial information by structural geologists. Structural
geology is a spatially complex and cognitively demanding
field, where experts gesture extensively when they speak. A
reason to begin research in this domain is that these experts’
gestures are likely to focus on complex spatial information.
In the future, we plan to investigate if the patterns of
communication found here are also present in other, more
common, spatial situations. In the study, expert structural

geologists were asked to complete a series of tasks,
including explaining the geology of two regions using
geologic maps. Here we investigate experts’ use of pointing
gestures versus iconic gestures to indicate one or more
objects on a map.
One reason geologists gesture is they are often in a
situation where it is not possible to see the entire object of
interest. Since the information found on an outcrop is
complex and only one face of a structure is usually visible
(providing two-dimensional information), experts could use
iconic gestures to highlight critical features since the whole
three-dimensional structure is not observable (Frodeman,
1995). A geologic map shares some of the same
characteristics. The information found on a geologic map is
quite complex, and it is a two-dimensional representation of
three-dimensional structures. Based on our observations of
experts in the field, combined with the complexity and twodimensional quality of a geologic map, we hypothesize that
structural geology experts will use iconic gestures, in
addition to pointing gestures, to index specific geological
entities. We predict that they will use iconic gestures for the
following reasons: 1) pointing gestures may be ambiguous
as the referent is located within a complex image with
overlapping features; and 2) the object of interest is a threedimensional structure – something that is not shown, but
needs to be inferred from the map as only a slice through the
three dimensional form may be visible at the surface. To test
our hypothesis and characterize the gestures experts use, we
coded experts’ gestures for type (deictic, iconic, or both),
and kind of spatial information (point, line, plane, or form,
process/event) for responses to one question about one
geologic map.

Methods
Participants
Thirty-four attendees at a Structural Geology and
Tectonics Conference participated in the study. To focus on
experts’ gestures, we restricted analysis to data from those
participants with a PhD who were also professors at an
academic institution. Thus, data from ten participants were
excluded. Data from one additional expert was excluded
because he or she was bilingual in English and American
Sign Language. Therefore, data from 23 expert structural
geologists (14 men, 9 women, Mage=45.8 years, age range:
33-60 years) was used for this analysis.

Materials
Explanations were recorded with a Canon HD Video
Camcorder HV20 (3.1 Megapixels). The map used for this
portion of the study was a Geologic Map of the Black Hills
Area, South Dakota and Wyoming (DeWitt, Redden,
Buscher, & Wilson, 1989). It was presented on a flat 78 cm
high table.

1787

Design and Procedure
The study took place in a quiet room where only the
experimenter and the participant were present. After
arriving, the participant completed the consent process. He
or she was then asked to stand behind the empty table
placed in the center of the room. Throughout the course of
the study, the experimenter stood directly across from the
participant, approximately five feet away.
The experimenter explained that this was a study
investigating teaching and reasoning about geologic maps.
A Geologic Map of the Black Hills Area, South Dakota and
Wyoming (DeWitt, Redden, Buscher, & Wilson, 1989) was
then placed on top of the table so the participant could see it.
Participants were first asked whether they were familiar
with the map before beginning the task. They were then
asked to pretend that the experimenter was a geology
undergraduate student with some domain knowledge,
specifically having completed an introductory course and
one or two upper level geology classes. The task was to
explain what structures were under the ground along a
specific cross-section, and explain how he or she knew. This
task would be a familiar one to a structural geologist, and
the map was designed to provide this information. After
providing the prompt, the experimenter indicated the crosssection region on the map for the participant. Gesturing was
never mentioned. Responses were audio and videorecorded.

Coding
Each of the experts’ spontaneous gestures and
accompanying speech was coded by the first-author. Interrater reliability was established by having a second trained
coder who independently coded a subset (20%) of the
responses. Each gesture was coded for the following things:
Speech The speech accompanying each gesture was
transcribed. Due to the complexity of the information
communicated by the experts, participants’ speech was used
to clarify the information represented in the gesture.
Furthermore, speech accompanying each gesture was coded
for whether it included information about a structure (e.g.
dome, mountain) or provided orientation information (e.g.
layers are steeply dipping). Inter-rater agreement for speech
was κ=0.80 (n=182 gestures).

gesture that conveys 1D information indicates a point, a
gesture that conveys 2D information indicates a line,
gestures that convey 3D information indicate planes and
forms, and gestures conveying 4D information indicate
changes or processes. For more information on this
categorization of gestures, see Atit, Shipley, and Tikoff
(2013).
Each gesture was coded for one of the following six
spatial categories: 1) point: hand-shape used was typically
an index finger indicating a location in space, 2) line: hand
shape typically was an index finger indicating a line in
space, 3) plane: hand shape typically was a flat palm
indicating a plane in space (generally providing information
about orientation), 4) form: hand formed a threedimensional shape in space (e.g., forming the hand in the
shape of a dome or moving the hand to sculpt the shape of a
dome), 5) process/event: hand conveyed a process or an
event (e.g., hand showing the movement of magma
representing an intrusion), and 6) other: all other gestures.
Inter-rater agreement for spatial information in gesture was
κ=0.81 (n=182 gestures).
Function Type Each gesture was also categorized into one
of the following four types: 1) deictic: if it indicated an
entity on the map (e.g. pointing to a specific fault line on the
map, or tracing the fault line on the map), 2) iconic: if it
“bears a close relationship to the semantic content of
speech” (McNeill, 1992, p. 12), and depicted an aspect of an
object within the conversational space (e.g. a curved hand
used to represent a fold), 3) both: if it simultaneously drew
the listener’s attention to a specific object on the map while
depicting an aspect of it (e.g. using a curved hand to show
the shape and location of a fold on the map), or 4)
unrelated: if it could not be classified into any of the three
type categories. Inter-rater agreement for gesture type was
κ=0.82 (n=182 gestures).

Results
Spatial Gestures

Gesture Using the accompanying speech to clarify, each
gesture was coded for whether or not it represented a spatial
property (e.g. the spatial relations between two rocks). See
Atit, Shipley, and Tikoff (2013) for more information about
the spatial properties represented in gesture. Inter-rater
agreement for spatial property represented was κ=0.79
(n=182 gestures). Gestures that represented spatial
properties were further characterized as follows.
Spatial Information The categories for the spatial
information in a gesture were created based on the
dimensional information that the gesture conveyed. A

On average, each participant gestured 51.87 times over
the course of the task (SD=26.94). We found no difference
in the number of gestures produced by men (M=51.00,
SD=29.14) versus women (M=53.22, SD=24.75), n.s; and
no difference in the number of gestures produced by
participants who were familiar with the map (M=58.60,
SD=30.93) versus those that were not familiar with the map
(M=46.69, SD=23.37), n.s.
When looking at the information conveyed within
gestures, we found that participants gestured more about
spatial information (gestures conveying a spatial property)
(M=0.73, SD=0.14) than about non-spatial information
(M=0.27, SD=0.14), t(22) = 7.96, p<.001. All means and
standard deviations for the following analyses are provided
in Table 1.

1788

Table 1: Means and standard deviations of gestures

Deictic
NonDeictic

Point
M=0.11
SD=0.08
M=0.01
SD=0.02

Line
M=0.20
SD=0.15
M=0.01
SD=0.02

Plane/Form/Process/Other
M=0.06
SD=0.07
M=0.37
SD=0.22

Note. Table presenting means and standard deviations
across participants for the different kinds of gesture (point,
line, plane/form/process/other) and for different types of
gesture (deictic, non-deictic). The descriptives reported here
are the means and standard deviations of the proportions of
spatial gestures for each category. As there were no
differences between the plane, form, process, and other
categories, we collapsed across these categories. Gestures
that were deictic indexed an object on the map, and could be
composed of point, line, plane, form, process, and other
gestures. Gestures that were non-deictic did not index an
object on the map, but also could be composed of point,
line, plane, process, and other gestures.
First, we looked at what proportion of spatial gestures was
pointing gestures. On average, 12% of each participant’s
spatial gestures involved pointing (M=0.12, SD=0.09). An
overwhelming majority of those were identified as deictic
(M=0.11, SD=0.08), with only 1% of gestures being iconic
and pointing (M=0.01, SD=0.02), t(22)=5.98, p<.001.
Pointing gestures were mainly used to index an object in the
conversational space.
Second, we considered the other cases of deictic gestures.
The first notable observation is that while pointing maybe
the prototypical deictic gesture, in this context the most
frequent deictic gesture was tracing a line in the
conversational space. On average, 21% of each participant’s
spatial gestures were of this kind (M=0.21, SD=0.15). More
line gestures were classified as deictic (M=0.20, SD=0.15),
than non-deictic (M=0.01, SD=0.02), t(22)=5.83, p<.001,
and the frequency of deictic line gestures (M=0.20,
SD=0.15) was significantly greater than pointing gestures
(M=0.11, SD=0.08), t(22)=3.24, p<.01.
Finally, when we consider the spatial gestures that were
plane, form, or process/event gestures, we find that most of
these were iconic (M=0.37, SD=0.22). However, an
intriguing portion was both iconic and deictic (M=0.06,
SD=0.07). The proportion of gestures classified as “both”
iconic and deictic was significantly different from 0,
t(22)=4.25, p<.001. Thus, most of the gestures made by
experts could be classified as iconic or deictic, but there
were a significant number of gestures that were both deictic
and iconic. Experts in this task used complex iconic gestures
to index objects in the conversational space.

Gestures Classified as Both, Iconic and Deictic
To further explore the information represented in the
gestures that were both deictic and iconic, we categorized
them by the spatial information in the gestures. About half

of the 6% represented planes (M=0.03, SD=0.04) and half
represented forms (M=0.03, SD=0.05). Less than 1% of all
gestures represented a process or event, or other kind of
information. Experts may have used the planar and form
gestures because the task was to explain the structures at a
line of cross-section where orientation and shape
information is not readily visible on the map. Without
visible support for this spatial information in the diagram,
experts may have employed gestures to ensure the threedimensional referent was clear.
Lastly, we investigated the information conveyed in
speech when experts employed these iconic and deictic
gestures compared to when they pointed or traced to
indicate an object. To make this comparison, we computed
the following for each participant: 1) the proportion of
pointing deictic gestures paired with spatially complex
speech (speech containing structure or orientation
information) relative to the total number of pointing deictic
gestures; 2) the proportion of line deictic gestures paired
with spatially complex speech relative to the total number of
line deictic gestures; and 3) the proportion of plane and
form gestures classified as both iconic and deictic paired
with spatially complex speech relative to the total number of
plane and form gestures classified as both iconic and deictic.
We found that a greater proportion of pointing deictic
gestures were paired with spatially complex speech
(M=0.34, SD=0.36) than planar/form iconic and deictic
gestures, (M=0.04, SD=0.12), t(22)=3.57, p<.01. Similarly,
more line deictic gestures were paired with spatially
complex speech (M=0.27, SD=0.23) than planar/form iconic
and deictic gestures, t(22)=3.91, p<.01. Thus, experts used
gestures classified as both iconic and deictic especially in
instances where the complex spatial information was not
provided in speech.

Discussion
This study investigated the relevance of an existing
distinction made in the gesture literature, iconic versus
deictic gestures, within the realm of communicating spatial
information. Traditionally, deictic gestures are defined as
hand movements that indicate entities in the conversational
space and usually consist of pointing (McNeill, 1992).
Iconic gestures are hand movements that “bear a close
formal relationship to the semantic content of speech”
(McNeill, 1992, p.12), and generally do depict some aspect
of an object in the conversational space.
Data from this study indicates that when asked to explain
the structures present in a section of a geologic map, expert
structural geologists use gestures that can be classified as
deictic or iconic, along with gestures that fall in both
categories. When using gestures traditionally classified as
deictic, experts tended to trace more than point to draw the
listener’s attention to an object on the map. When using
gestures traditionally classified as iconic, we found that
experts used some iconic gestures to indicate an object on
the map. Furthermore, gestures that were both iconic and
deictic and represented information about planes and forms,

1789

tended to occur when there was no spatially complex
information (e.g. structure or orientation information)
conveyed in speech.
A number of studies have shown that gestures are useful
in separating relevant from irrelevant information (e.g.
Roth, 2000; Lozano & Tversky, 2006; Heiser, Tversky, &
Silverman, 2004). Gestures help organize the conversational
space into a salient foreground and an unrepresented, more
diffuse background. Researchers in the past have likely
focused on pointing because this hand shape is the most
common one used to indicate the foreground. In contrast,
here we replicate previous work (e.g. Lozano & Tversky,
2006; Heiser, Tversky, & Silverman, 2004) that has found
that when the referent is complex and includes multiple
kinds of information (e.g. maps), the speaker also uses
tracing gestures to highlight objects for the listener. For
example, Lozano and Tversky (2006) asked participants to
explain to a listener how to assemble a piece of furniture,
and found that participants used tracing gestures in addition
to pointing gestures to draw the listener’s attention to
individual pieces (Lozano & Tversky, 2006). Heiser et al.
(2004) asked pairs of students to use a campus map to
design and produce an optimal emergency rescue route.
They found that students also used tracing gestures along
with pointing gestures to focus their partner’s attention to
specific aspects of their sketch and to highlight certain
routes (Heiser, Tversky, & Silverman, 2004). We suspect
that speakers used tracing gestures because pointing alone
may be ambiguous when the referent has significant spatial
extent and when it does not have clear boundaries.
The results from our study reveal an interesting type of
gesture that is used to draw the listener’s attention to an
object. Experts in our study used complex gestures
traditionally classified as iconic to highlight objects on the
geologic map. A geologic map presents a horizontal crosssection through the three-dimensional topography of a
region. Therefore, many objects of interest to a geoscientist
will be three-dimensional structures that are not completely
visible at the surface. Indeed what is visible at the surface
may be a slice through a three-dimensional form. Since the
two-dimensional information presented on the map does not
directly resemble the actual three-dimensional form of these
objects, the expert may use gesture to provide the listener
with the missing information. For example, the elliptical
outcrop pattern of rock layers presented on the map in this
study does not resemble the three-dimensional form of the
dome in the Black Hills region. Furthermore, it can be
difficult to determine the orientation of the rock layers
within a domal structure on a geological map because the
inclination of the rock layers is typically represented using a
symbol. Thus, the expert uses gestures to depict the shape of
the dome and planar gestures to show the orientation of the
layers in space. Whether it is the two-dimensional
characteristic of the map, or the penetrative nature of
geological structures that elicits this special type of gesture
is a question for future research. For example, would an

architect use gestures that could be classified as both iconic
and deictic when explaining a blueprint of a building?
Finally, gestures classified as both iconic and deictic were
used in instances where the spatially complex information is
not provided in speech. For example, an expert represents
the orientation and location of a layer of rocks on the map
while referring to their relative ages in speech. Since
complex spatial information is difficult to convey using
language (Tversky & Lee, 1998) and gesture allows one to
communicate thoughts that are not easily conveyed in
speech (Goldin-Meadow, 1999), perhaps the speaker uses
this type of gestures when providing multiple levels of
information (e.g. location and orientation information) in
language alone becomes difficult. Or, perhaps the expert
could not produce the gesture and speech at the same time
due to the cognitive load required by the task. A more
global analysis of speech in the future can address this
question.
One potential limitation of the current study may be that
the experts were asked to pretend that the experimenter was
a geology undergraduate to whom they were explaining the
cross-section. It is possible the experts’ language and
gestures would have differed if they were providing
explanations to real geology undergraduates. This seems
unlikely as the experts were obviously engaged in their
answers to the questions. Nevertheless, studies collecting
and analyzing interactions between experts and novices in
the field are in progress.
Supported by the findings of this study, we argue that the
existing types of representational gestures (e.g. iconic and
deictic) should not be treated as exclusive categories –
overlap between the two types exists. People do use iconic
gestures (e.g. planar gestures) to indicate, or highlight,
objects in the world when the important spatial information
is three-dimensional. One open question is whether the
number of gestures that fall into “both” categories is related
to the spatial complexity of the information conveyed.
Perhaps the communication of more spatially complex
information elicits a greater use of this special type of
gestures.
Understanding how different types of gestures are
employed in simple communicative contexts to highlight
and convey complex spatial information may serve as the
foundation for developing pedagogical techniques for
conveying spatial information. A richer understanding of the
different types of gestures could inform geology professors,
and science professors in general, about how to most
effectively communicate information to their students.

Acknowledgements
This research was supported by a grant to the Spatial
Intelligence and Learning Center, funded by the National
Science Foundation (SBE-0541957 and SBE-1041707), and
by a Fostering Interdisciplinary Research on Education
grant, funded by the National Science Foundation (grant
number DRL-1138619).

1790

References
Alibali, M. W. (2005). Gesture in spatial cognition:
Expressing, communicating, and thinking about spatial
information. Spatial Cognition & Computation, 5(4), 307331.
Alibali, M., Flevares, L. M., & Goldin-Meadow, S. (1997).
Assessing knowledge conveyed in gesture: Do teachers
have the upper hand?. Journal Of Educational
Psychology, 89(1), 183-193.
Alibali, M. W., Heath, D. C., & Myers, H. J. (2001). Effects
of visibility between speaker and listener on gesture
production: Some gestures are meant to be seen. Journal
Of Memory And Language, 44(2), 169-188.
Allen, G. L. (2003). Gestures accompanying verbal route
directions: Do they point to a new avenue for examining
spatial
representations?
Spatial
Cognition
and
Computation, 3(4), 259-268.
Atit, K. A., Shipley, T. F., & Tikoff, B. (submitted). A
framework for classifying spatial gestures. In D.
Montello, K. Grossner, & D. Janelle (Eds.), Space in
Mind: Concepts and Ontologies for Spatial Education.
Chapter submitted for publication.
Bates, E. (1976). Language and context: The acquisition of
pragmatics Academic Press New York.
Bates, E., Benigni, L., Bretherton, I., Camaioni, L., &
Volterra, V. (1979). The emergence of symbols: Cognition
and communication in infancy Academic Press New
York.
DeWitt, E., Redden, J., Buscher, D., & Wilson, A. B.
(1989). Geologic map of the Black Hills Area, South
Dakota and Wyoming.
Ekman, P., & Friesen, W. V. (1969). The repertoire of
non-verbal behavior: Categories, origins, usage, and
coding. Semiotica, 1, 49–98.
Frodeman, R. (1995). Geological reasoning: Geology as an
interpretive and historical science, GSA Bulletin, 107, 960
968.
Goldin-Meadow, S. (1999). The role of gesture in
communication and thinking. Trends in Cognitive
Science, 3, 419-429.
Goldin-Meadow, S. & Sandhofer, C. M (1999). Gestures
convey substantive information about a child’s thoughts
to ordinary listeners. Developmental Science, 2(1), 67-74.
Heiser, J., Tversky, B., & Silverman, M. (2004). Sketches
for and from collaboration. Visual and Spatial Reasoning
in Design III, , 69-78.
Krauss, R. M., Chen, Y., & Chawla, P. (1996). Nonverbal
behavior and nonverbal communication: What do
conversational hand gestures tell us? Advances in
Experimental Social Psychology, 28, 389–450.
Lavergne, J., & Kimura, D. (1987). Hand movement
asymmetry during speech: No effect of speaking topic.
Neuropsychologia, 25(4), 689-693.
Liben, L. S., Christensen, A. E., & Kastens, K. A. (2010).
Gestures in geology: The roles of spatial skills, expertise,

and communicative context. Spatial Cognition VII, 95111.
Lozano, S. C., & Tversky, B. (2006). Communicative
gestures
facilitate
problem
solving
for
both
communicators and recipients. Journal of Memory and
Language, 55(1), 47-63. doi: 10.1016/j.jml.2005.09.002
McNeill, D. (1992). Hand and mind: What gestures reveal
about thought University of Chicago Press.
Rauscher, F. H., Krauss, R. M., & Chen, Y. (1996). Gesture,
speech, and lexical access: The role of lexical movements
in speech production. Psychological Science, 7(4), 226231.
Roth, W. M. (2000). From gesture to scientific language.
Journal of Pragmatics, 32(11), 1683-1714.
Tversky, B., & Lee, P. (1998). How space structures
language. In C. Freksa, C. Habel, & K. F. Wender (Eds.),
Spatial Cognition: An Interdisciplinary Approach to
Representing and Processing Knowledge (pp. 157-175).
Heidelberg, Germany: Springer-Verlag.

1791

