UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Syntax in music and language: The role of cognitive control

Permalink
https://escholarship.org/uc/item/2zt516z1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 35(35)

Authors
Slevc, L. Robert
Reitman, Jason
Okada, Brooke

Publication Date
2013-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Syntax in music and language: The role of cognitive control
L. Robert Slevc (slevc@umd.edu)
Department of Psychology, University of Maryland
College Park, MD 20742 USA

Jason G. Reitman (jreitman@wesleyan.edu)
Wesleyan University
Middletown, CT 06459 USA

Brooke M. Okada (bokada@umd.edu)
Department of Psychology, University of Maryland
College Park, MD 20742 USA
Abstract
The relationship between structural (or syntactic) processing
in music and in language is not yet clear. Evidence indicating
that these two processes are shared conflicts with other results
suggesting that they are largely distinct. These conflicting
findings suggest that musical and linguistic processing may
share some, but not all, underlying processes, raising the
question of what exactly those shared processes might be.
Two experiments tested the idea that one shared process is
cognitive control by pairing manipulations of musical
structure with the Stroop task, a standard test of cognitive
control. Manipulations of harmonic expectancy, but not of
timbral expectancy, interacted with Stroop interference
effects, suggesting that cognitive control is at least one
specific process underlying shared syntactic processing in
music and language.
Keywords: cognitive control; music and language; musical
syntax

Introduction
Interest in the relationship between music and language has
a long history, dating back at least to Darwin (1871). Over
the last several years, a more specific focus on the
relationship between structural (or syntactic) processing in
music and language has received increasing attention (for
recent reviews, see Patel, 2008; Slevc, 2012; Tillmann,
2012). This likely is due, at least in part, to an influential
proposal about the relationship between structural
processing in language and music: Patel’s (2003) shared
syntactic integration resource hypothesis (SSIRH; see also
Patel, 2008). The SSIRH proposes that music and language
involve separate representations (e.g., nouns and verbs in
language, tonal functions in music), but recruit a shared set
of cognitive resources that are required to integrate these
separate representations into evolving sequences.
There is a growing body of evidence supporting the
SSIRH. Much of this evidence comes from experiments
using interference paradigms, where participants are
simultaneously presented with both musical and linguistic
stimuli. In these paradigms, syntactic manipulations in both
domains are crossed to look for interactive effects that
indicate shared processing (vs. additive effects, which
would indicate independent processes). For example, an

electrophysiological response characteristic of a violation of
linguistic syntax (the left anterior negativity, or LAN) is
reduced when linguistic syntactic violations are paired with
a concurrent music-syntactic irregularity (Koelsch, Gunter,
Wittfoth, & Sammler, 2005). Similarly, sung complex
sentences are especially difficult to understand when critical
regions are sung out-of-key (Fedorenko, Patel, Casasanto,
Winawer, & Gibson, 2009).
Other behavioral evidence comes from on-line sentence
processing paradigms, where readers’ slowed processing of
temporary syntactic ambiguities is especially pronounced
when the disambiguating word is paired with a harmonically
unexpected chord (Slevc, Rosenberg, & Patel, 2009; also
see Hoch, Poulin-Charronnat, & Tillmann, 2011, for related
findings). More specifically, Slevc et al. (2009) relied on
garden path effects, where readers are slower to
comprehend the disambiguating word was in a sentence like
“The scientist proved the hypothesis was false” compared to
an unambiguous context like “The scientist proved that the
hypothesis was false.” This slowed processing presumably
reflects the need to revise an initial syntactic interpretation
where the hypothesis was interpreted as the direct object of
the verb proved rather than as the subject of an embedded
sentence complement. This garden path effect was more
pronounced when the disambiguating word (was) was
accompanied by a harmonically unexpected chord (but not
when accompanied by a chord of unexpected timbre).
Importantly, such an interaction did not emerge for
semantically unexpected words (e.g., pigs as a continuation
of “The mailman was afraid of…”) suggesting that the
interactive processes are specific to syntax. However, a
more recent finding casts doubt on this last conclusion: the
same harmonic manipulations did lead to interactive effects
when paired with sentences containing “semantic garden
paths” such as “The old man went to the bank to withdraw
his net which was empty” (Perruchet & Poulin-Charronnat,
2013). Thus it seems that these interactive effects (and the
shared integration resource of the SSIRH) may not be
specific to syntactic processing per se.
In addition, some recent neuroimaging studies have not
found substantial overlap between neural regions implicated
in the processing of language and music (Fedorenko, Behr,

3414

& Kanwisher, 2011; Rogalsky, Rong, Saberi, & Hickok,
2011). These studies compared a linguistic contrast
(activation to intact sentences versus non-words or versus
jabberwocky sentences) to a musical contrast (activation to
intact music versus scrambled music or versus silence), and
found little evidence for shared regions implicated in both
contrasts.
These conflicting findings raise the question: what kind of
shared process links musical structural processing to some
aspects of linguistic processing (including syntactic errors,
syntactic complexity, and both syntactic and semantic
garden paths), but not to other aspects such as the
processing of semantically surprising words and the
difference between intact and scrambled sentences? One
way to characterize this distinction is that the aspects of
language processing that are related to musical structure
require not only the processing of an unexpected element,
but also the resolution of conflict between this unexpected
information and a current representation of an incrementally
constructed (and/or predicted) structure. The unrelated
aspects of language, in contrast, may not place demands on
conflict resolution per se as there is no obvious way to
resolve a semantic anomaly or a scrambled sentence.
This sort of conflict detection and resolution process is
termed cognitive control, referring broadly to the cognitive
processes that allow for the regulation of mental activity
required to resolve competing representations (see, e.g.,
Miller & Cohen, 2001). Cognitive control processes have
been implicated in various aspects of language processing,
including parsing of garden path sentences and semantic
plausibility effects (see Novick, Trueswell, & ThompsonSchill, 2010, for a recent review), and it is possible that the
types of linguistic manipulations that interact with musical
structure are of this general type. By this account, studies
finding interactive effects between musical structure and
language (be it linguistic syntax or non-syntactic situations
that require resolution between conflicting representations
like semantic garden paths) might reveal simultaneous use
of cognitive control resources.
This account implies that musical syntactic processing–at
least as measured in the studies cited above–also relies on
cognitive control mechanisms. Indeed, this is likely to be
the case. Listening to music involves building up complex
cognitive representations of musical structure. This not only
involves processing and integrating musical elements as
they occur, but also incrementally generating and evaluating
predictions based on implicit knowledge of musical
structure (see Rohrmeier & Koelsch, 2012, for discussion).
One hazard of this predictive processing is that new
information can be inconsistent with one’s prediction, thus
harmonic processing requires the ability to both detect
conflict between predicted and observed precepts and the
ability to resolve this conflict by overriding and updating an
evolving representation of musical structure. Conflict
between musical precepts and predictions likely arises in
many situations, not the least of which are cases of musical
ambiguity (e.g., musical garden paths; Temperley, 2001).

One form of indirect evidence for a role of cognitive
control in musical syntax comes from neuroimaging
findings. Regions in the inferior frontal gyrus (including
Broca’s area) that are linked to cognitive control processes
(both generally and in language processing; e.g., Miller &
Cohen, 2001; Novick et al., 2010) have also been implicated
in neuroimaging studies of musical syntactic processing
(albeit more bilaterally or even right lateralized; e.g., Maess,
Koelsch, Gunter, & Friederici, 2001; Tillman, et al., 2006).
A second form of indirect evidence for a role of cognitive
control in musical syntactic processing comes from
evidence that musical training is associated with advantages
in cognitive control ability (Bialystok & DePape, 2009;
Pallesen et al., 2010) among other types of cognitive
advantages (e.g., Schellenberg, 2006). A musician
advantage in cognitive control could plausibly result from
the additional demands placed on cognitive control
mechanisms from extensive musical training and practice,
but only if those demands tax (and thus potentially
strengthen) cognitive control processes.

Current experiments
The aim of the experiments reported here was to provide a
direct test of whether cognitive control mechanisms are
involved in musical syntactic processing (as has been
argued to be the case for linguistic syntactic processing). If
cognitive control processes are, in fact, an important part of
musical syntactic processing, less expected chords should
impose relatively greater demands on cognitive control.
Assuming cognitive control is a limited-capacity resource,
this should lead to a temporary reduction in the ability to
exercise cognitive control in other tasks.
In order to measure demands on cognitive control, we
turned to a prototypical cognitive control task: the Stroop
task (Stroop, 1935; see McLeod, 1991, for a review). In the
standard Stroop task, participants must name the ink (or
font) color of printed stimuli. These stimuli can be of three
types: congruent, where the printed word is the same as the
to-be-named ink color (e.g., the word “GREEN” printed in
green font), incongruent, where the printed word is a
different color name than the two-be-named ink color (e.g.,
the word “BLUE” printed in green font), and neutral (e.g.,
the string “####” printed in green font). Cognitive control
demands are reflected in Stroop interference, where
responses are slower to incongruent than to neutral trials.
The Stroop task can also yield Stroop facilitation, reflected
in faster responses to congruent than neutral trials, however
these facilitative effects are not generally assumed to result
from demands on cognitive control.
Because Stroop interference is a prototypical measure of
cognitive control, it can be used as an index of cognitive
control demands at a given moment. The experiments
presented below do just this by investigating if, and how,
Stroop interference is affected by a concurrent musical
syntactic manipulation.

3415

Experiment 1
In Experiment 1, participants performed a standard Stroop
task while hearing musical chorales. The primary question
was whether the harmonic expectancy of a chord occurring
during a trial of the Stroop task would influence Stroop
interference effects.

Method
Participants Twenty-five undergraduate students from the
University of Maryland participated in exchange for course
credit. Participants were unselected with regard to musical
training.
Materials Stimuli for the Stroop task were the strings
“RED”, “GREEN”, “BLUE”, or “XXXX”. The word
stimuli appeared half of the time in a congruent color (e.g.,
the word “BLUE” in blue font) and half of the time in an
incongruent color (e.g., “BLUE” in green or red font); the
neutral (“XXXX”) stimuli appeared equally often in each of
the three font colors. Because the primary effect of interest
here is in Stroop interference (vs. facilitation), congruent
trials were treated as fillers and excluded from analysis.
Musical stimuli were twelve six-chord chorales based on
Western musical structure, half in major and half in minor
keys. Each chorale ended either on a tonic chord (the tonal
center of the chorale’s key) or ended on a chord belonging
to another key, and thus was either harmonically expected
or unexpected (see Figure 1 for an example). In addition,
each chorale occurred once more as a filler item; these
fillers ended on a variety of chords. While these fillers were
generally harmonically unexpected, they were not
constructed in a theoretically constrained way and so were
excluded from analyses. (Note, however, that treating these
fillers as harmonically unexpected trials does not
substantially alter the main pattern of results.)

Procedure Participants were tested individually on iMac
computers using PsychoPy software (Pierce, 2007). The
primary task was to respond to the color of the visual
stimuli (red, green, or blue) by pressing a corresponding
button (the left, down, or right arrow, respectively). These
color/button mappings were presented on the screen during
the entire task. Participants first performed a practice block
of twenty-one color-naming trials (without concurrent
musical stimuli) to learn the color/key mappings, then a
second practice block of ten trials where the target stimulus
appeared at the onset of the final chord of a six-chord
chorale (all practice chorales ended on the tonic). Finally,
participants performed the experimental block consisting of
72 chord sequences ending on the tonic, 36 chord sequences
ending on a harmonically unexpected chord, and 36 filler
sequences. Within each musical condition, one third of the
trials were neutral, one third were incongruent, and one third
were congruent (filler) trials.
A schematic of the four conditions for an individual
experimental trial is shown in Figure 1.
Design and analysis Response times were log-transformed
and analyzed using linear mixed-effects models in the
statistical software R (version 2.15.2; R Development Core
Team, 2012). Stroop trial type (text condition: incongruent
or neutral) and the harmonic role of the final chord
(harmonic condition: expected or unexpected) were entered
as fixed effects using orthogonal contrast coding. The fully
specified random effect structure was included for both
participants and items (see Barr, Levy, Scheepers, & Tily,
2013), but random effects are not reported as only fixed
effects were of theoretical interest. The current
implementation of lme4 does not compute p values for
models that include random slopes, therefore we follow
Gelman and Hill (2007) by assuming that any absolute t
value greater than 2 indicates a significant effect.

Results
A)

B)

i) BLUE
ii) XXXX
time

Figure 1: Example stimuli in Experiment 1. The top panel
shows an example musical chorale ending in a harmonically
expected tonic chord (A) or a harmonically unexpected
chord from a different key (B). The bottom panel represents
the incongruent (i) or neutral (ii) visual target for the
primary color response task.

A significant main effect of text condition (b = -0.24, SE =
0.029, t = -8.23) revealed (unsurprisingly) that responses
were slower for incongruent than neutral strings. There was
not a significant main effect of harmonic condition (b = 0.0048, SE = 0.022, t = -0.22), however a significant
interaction between harmonic condition and text condition
(b = -0.10, SE = 0.042, t = -2.39), revealed that the Stroop
interference effect was significantly larger when
accompanied by an unexpected final chord. The Stroop
interference effects in the harmonically expected and
unexpected conditions are plotted in Figure 2.

Discussion
Experiment 1 found larger Stroop interference effects when
Stroop trials occurred during structurally unexpected chords,
suggesting that the processing of harmonically unexpected
chords involves an underlying process that is shared with
Stroop interference. This bolsters theoretical reasons to
expect cognitive control processes to play a role in musical

3416

syntactic processing and adds to previous indirect evidence
for such a relationship, such as (bilateral) inferior frontal
activation associated with musical syntax (e.g., Tillmann et
al., 2006) and cognitive control advantages associated with
musical training (e.g., Bialystok & DePape, 2009).

does not require conflict resolution. If, on the other hand,
the interaction observed in Experiment 1 reflects the role of
conflict resolution processes, then such interactions should
not arise unless the unexpected stimuli induces some degree
of resolvable conflict with an incremental and predictive
cognitive representation of musical structure.
To examine these possibilities, Experiment 2 employed
the same design as Experiment 1, but instead of
manipulating musical syntactic expectancy, manipulated
musical timbre (cf. Slevc et al., 2009). In contrast to the
harmonic manipulation in Experiment 1, where an
unexpected chord could reflect some kind of resolvable
modulation or other harmonic “twist,” there is no obvious
way to resolve an unexpected timbre. Thus, a chord of
unexpected timbre (that plays an expected harmonic role)
should not lead to conflict resolution processes, and should
not interact with the Stroop interference effect.
A chord of unexpected timbre should, however, be at least
as surprising and attention demanding as an out-of-key
chord, so if the interaction observed in Experiment 1 results
from surprise or distraction, the same pattern of results
should emerge in Experiment 2.

Method
Participants Thirty undergraduate students from the
University of Maryland participated in exchange for course
credit or for a small ($5) payment. As in Experiment 1,
participants were unselected with regard to musical training.
Figure 2: Stroop interference (incongruent minus neutral)
by the harmonic condition of the final chord (the tonic chord
or an unexpected chord from another key) in Experiment 1.
Data are plotted as untransformed means of participant
means and dots indicate individuals’ scores.1
A counter explanation for these results might be that the
harmonically unexpected chord drew attention away from
the primary task of responding to font colors, thus leading to
an exaggerated effect of incongruent trials due not to shared
mechanisms, but simply to surprise or distraction. It is not
obvious that simple distraction would enhance the Stroop
effect as this distraction would presumably affect neutral as
well as incongruent trials. However it is nevertheless
possible that some aspect of the musical manipulation
besides its harmonic unexpectedness is responsible for the
observed interaction. Experiment 2 aimed to address this
possibility by using a noticeable, but not music-syntactically
relevant, manipulation of timbre, or sound quality.

Experiment 2
If the interaction between Stroop interference and harmonic
expectancy found in Experiment 1 results from surprise or
distraction, then similar results should emerge when another
type of unexpected auditory event occurs, even if that event
1
For ease of interpretation, Figures 2 and 3 display means of
participants’ mean untransformed RTs; note, however, that
analyses were conducted over non-averaged, log-transformed RTs.

Materials and Procedure The visual stimuli in Experiment
2 were identical to those in Experiment 1. The musical
chorales were also identical except for the final chords in
the unexpected conditions, which were always the tonic
chord (thus always harmonically expected) but varied in
terms of their timbre. Specifically, the final chord was either
of the expected piano timbre, i.e., the same timbre as the rest
of the chorale, or was played in a distinct timbre (the sitar
timbre, as implemented in MuseScore version 1.2). An
additional set of trials ended with a timbre only slightly
different from the rest of the chorale (MuseScore’s ukulele
timbre, which sounds remarkably similar to a piano); as in
Experiment 1, these intermediate trials were treated as fillers
and not included in the analysis.
Design and Analysis Response times were analyzed just as
in Experiment 1. Experiment 2 crossed the fixed-effects
factors of text condition with timbral condition (expected or
unexpected timbre) with the maximal random effects
structure supported by the data.2

Results
As in Experiment 1, participants were reliably slower to
respond to the color during incongruent trials than
2
The by-item random slopes for timbral condition and the
timbral condition by text condition interaction had to be removed
for the statistical model to converge.

3417

congruent trials (i.e., a significant effect of text condition; b
= -0.17, SE = 0.023, t = -7.14). There was no significant
effect of the timbre of the final chord (b = 0.20, SE = 0.14, t
= 1.42) and, unlike in Experiment 1, no interaction between
these factors (b = -0.16, SE = 0.029, t = -0.55). The Stroop
interference effects in the timbrally expected and
unexpected conditions are plotted in Figure 3.

Figure 3: Stroop interference (incongruent minus neutral)
by the timbral expectancy of the final chord (same vs.
different timbre) in Experiment 2. Data are plotted as
untransformed means of participant means and dots indicate
individuals’ scores.

Discussion
Experiment 2 showed a standard effect of Stroop
interference, but this effect did not interact with the timbre
of a concurrent (tonic) chord. If anything, the average
magnitude of the Stroop interference effect was numerically
smaller in the unexpected timbre condition. This suggests
that the interactive effects found in Experiment 1 did not
result simply from the attention capturing nature of the
unexpected stimuli, but were rather a function of the need to
resolve conflict between the final chord and its expected
harmonic role.

General Discussion
The experiments reported here tested the idea that the
processing of musical structure relies on general cognitive
processes of cognitive control, which are also thought to
underlie aspects of language processing. Experiment 1
crossed a standard cognitive control task–the Stroop task–
with a manipulation of harmonic expectancy, and found
interactive effects: Stroop interference was exacerbated
when accompanied by a structurally unexpected chord.

Experiment 2 showed that this interaction between harmonic
expectancy and Stroop interference was not simply due to
distraction or divided attention as such an effect did not
emerge when Stroop trials were paired with chords of an
unexpected timbre.
The interactive effects in Experiment 1 are perhaps
especially notable as there was no musical task requiring
participants to pay attention to the musical chorales, and
participants were an unselected group of undergraduate
students, not a group of musicians. These observations
suggest that these effects do not depend on any particularly
effortful type of musical processing, but instead reflect the
broad knowledge of musical syntax that arises simply
through a lifetime of exposure to a specific musical tradition
(cf. Bigand & Poulin-Charronnat, 2006).
These findings support the theory that cognitive control
does, in fact, underlie at least some of the shared processing
resources implicated in linguistic and musical syntax. A
further implication is that the processing of both music and
language should overlap to some extent with a variety of
other domains that also rely on these general mechanisms of
cognitive control (not just simple cognitive tasks like the
Stroop task). There is already evidence for some such
relationships; for example, interactive effects have been
demonstrated during simultaneous processing of music and
arithmetic (Hoch & Tillmann, 2012). In addition, “action
syntax” or “scripts” (i.e., meaningful structured
representations of action sequences) may be related to both
linguistic syntax (e.g., Farag et al., 2010) and to musical
syntactic processing (Harding et al., 2011).
These relationships between different types of structural
processing – be those structures musical, linguistic,
mathematical, or action schemas – are not likely to reflect a
syntax-specific shared underlying process. Instead, these
processes likely draw on the same cognitive mechanisms to
deal with similar demands, and these data suggest that one
such mechanism is cognitive control. Of course, it is
unlikely that the relationship between structural processing
in language and music reflects only cognitive control
mechanisms. Musical and linguistic structure are rich and
complex systems that surely draw on a variety of cognitive
mechanisms. Nevertheless, these data take a step towards a
more specific account of exactly what sort of shared
integration resources might underlie linguistic and musical
syntax by implicating the well-studied cognitive construct
of cognitive control.

Acknowledgments
The authors wish to thank Ilana Green for help with
experimental stimuli and data collection, and Jared Novick,
Aniruddh Patel, Sharon Thompson-Schill, and Matt Weber
for discussions that (perhaps unbeknownst to them) helped
to motivate these experiments.

References
Barr D. J., Levy R., Scheepers C. & Tily, H.
(2013). Random-effects structure for confirmatory

3418

hypothesis testing: Keep it maximal. Journal of Memory
and Language, 68(3), 255-278.
Bialystok, E. & DePape, A-M. (2009). Musical expertise,
bilingualism, and executive functioning. Journal of
Experimental Psychology: Human Perception and
Performance, 35(2), 565-574.
Bigand, E. & Poulin-Charronnat, B. (2006). Are we
“experienced listeners”? A review of the musical
capacities that do not depend on formal musical training.
Cognition, 100, 100-130.
Darwin, C. (1871). The Descent of Man, and Selection in
Relation to Sex. London: John Murray.
Farag C., Troiani V., Bonner M., Powers C., Avants B., Gee
J., Grossman M. (2010). Hierarchical organization of
scripts: converging evidence from FMRI and
frontotemporal degeneration. Cerebral Cortex, 20(10),
2453-2463.
Fedorenko, E., Behr, M. K., & Kanwisher, N. (2011).
Functional specificity for high-level linguistic processing
in the human brain. Proceedings of the National Academy
of Sciences, 108(39), 16428-16433.
Fedorenko, E., Patel, A. D., Casasanto, D., Winawer, J., &
Gibson, E. (2009). Structural integration in language and
music: evidence for a shared system. Memory and
Cognition, 37, 1-9.
Gelman, A. & Hill, J. (2007). Data Analysis Using
Regression and Multilevel/Hierarchical Models. New
York, NY: Cambridge University Press.
Harding, E., Sammler, D., D’Ausilio, A., Friederici, A.,
Fadiga, L., & Koelsch, S. (2011). Explicit action
perception shares resources with music syntax: A
controlled behavioral study. Poster presented at The
Neurosciences and Music IV: Learning and Memory,
Edinburgh, United Kingdom.
Hoch, L., Poulin-Charronnat, B., & Tillmann, B. (2011) The
influence of task-irrelevant music on language processing:
Syntactic and semantic structures. Frontiers in
Psychology, 2, 112. doi: 10.3389/ fpsyg.2011.00112
Hoch, L. & Tillmann, B. (2012). Shared structural and
temporal integration resources for music and arithmetic
processing. Acta Psychologica, 140, 230-235.
Koelsch, S., Gunter, T. C., Wittfoth, M., & Sammler, D.
(2005). Interaction between syntax processing in language
and in music: An ERP study. Journal of Cognitive
Neuroscience, 17(10), 1565-1577.
Maess, B., Koelsch, S., Gunter, T. C., & Friederici, A. D.
(2001). Musical syntax is processed in Broca’s area: an
MEG study. Nature Neuroscience, 4(5), 540-545.
MacLeod, C. M. (1991). Half a century of research on the
Stroop effect: An integrative review. Psychological
Bulletin, 109(2), 163-203.
Miller, E. K., & Cohen, J. D. (2001). An integrative theory
of prefrontal cortex function. Annual Reviews of
Neuroscience, 24, 167-202.
MuseScore (Version 1.2) [Computer software]. URL:
http://musescore.org/

Novick, J. M., Trueswell, J. C. & Thompson-Schill, S. L.
(2010). Broca’s area and language processing: Evidence
for the cognitive control connection. Language and
Linguistics Compass, 4, 906-924.
Pallesen K. J., Brattico E., Bailey C. J., Korvenoja A.,
Koivisto J., Gjedde, A., & Carlson, S. (2010) Cognitive
Control in Auditory Working Memory Is Enhanced in
Musicians. PLoS ONE 5(6): e11120.
Patel, A. D. (2003). Language, music, syntax and the brain.
Nature Neuroscience, 6(7), 674-681.
Patel, A. D. (2008). Music, Language, and the Brain.
Oxford University Press.
Peirce, J. W. (2007) PsychoPy - Psychophysics software in
Python. Journal of Neuroscience Methods, 162(1-2), 813.
Perruchet, P. & Poulin-Charronnat, B. (2013). Challenging
prior evidence for a shared syntactic processor for
language and music. Psychonomic Bulletin & Review, 20,
310-317.
R Development Core Team. (2012). R: A language and
environment for statistical computing (Version 2.15.2): R
Foundation for Statistical Computing, Vienna, Austria.
ISBN 3-900051-07-0, URL: http://www.R-project.org.
Rohrmeier, M. A. & Koelsch, S. (2012). Predictive
information processing in music cognition. A critical
review. International Journal of Psychophysiology, 83,
164-175.
Rogalsky, C., Rong, F., Saberi, K., & Hickok, G. (2011).
Functional anatomy of language and music perception:
temporal and structural factors investigated using
functional magnetic resonance imaging. Journal of
Neuroscience, 31(10), 3843-3852.
Schellenberg, E. G. (2006). Long-term positive associations
between music lessons and IQ. Journal of Educational
Psychology, 98(2), 457-468.
Slevc, L. R. (2012). Language and music: sound, structure,
and meaning. Wiley Interdisciplinary Reviews: Cognitive
Science, 3(4), 483–492.
Slevc, L. R., Rosenberg, J. C., & Patel, A. D. (2009).
Making psycholinguistics musical: Self-paced reading
time evidence for shared processing of linguistic and
musical syntax. Psychonomic Bulletin & Review, 16(2),
374–381.
Stroop, J. R. (1935). Studies of interference in serial verbal
reactions. Journal of Experimental Psychology, 18, 643662.
Temperley, D. (2001). The Cognition of Basic Musical
Structures. Cambridge, MA: MIT Press.
Tillmann, B., Koelsch, S., Escoffier, N., Bigand, E., Lalitte,
P., Friederici, A. D., & von Cramon, D. Y. (2006).
Cognitive priming in sung and instrumental music:
Activation of inferior frontal cortex. NeuroImage, 31,
1771-1782.
Tillmann, B. (2012). Music and Language Perception:
Expectations, Structural Integration, and Cognitive
Sequencing. Topics in Cognitive Science, 4(4), 568-584.

3419

