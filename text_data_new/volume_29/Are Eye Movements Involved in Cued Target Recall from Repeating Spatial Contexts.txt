UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Are Eye Movements Involved in Cued Target Recall from Repeating Spatial Contexts?

Permalink
https://escholarship.org/uc/item/14j1z4hq

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)

Authors
Myers, Christopher W.
Gray, Wayne D.

Publication Date
2007-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Are Eye Movements Involved in Cued Target Recall from Repeating Spatial Contexts?
Christopher W. Myers & Wayne D. Gray
[myersc] & [grayw] @rpi.edu
Cognitive Science Department, Rensselaer Polytechnic Institute
110 8th Street
Troy, NY 12180 USA
Abstract

manual motor movements, and memory retrievals during
interactive behavior.
Soft constraints theory provides an approach to
understanding how endogenous and exogenous influences
are mediated, and can be interpreted as predicting efficiency
gains in patterns of visual search across repeated experience
with the same visual stimulus/goal combination. Indeed,
recent research indicates that the cost of a single dwellsaccade pair is eliminated from behavior when it does not
reliably lead to the task goal, as predicted by soft constraint
theory (Myers & Gray, submitted).

Across two experiments we set out to determine if visual
scans adapt to repeatedly searched stimuli. We adopt a
paradigm reported to produce cueing effects from repeatedly
searching the same stimulus (Chun & Jiang, 1998). We
discover that eye movements may be useful to the cueing
process, and that the cueing phenomenon is finicky.
Keywords: visual scanning, scanpath, contextual cueing,
rational analysis, soft constraints

Introduction
Every day, humans actively access information from their
visual environment. A visual stimulus, such as a kitchen
counter, may be examined hundreds of times with short
delays (minutes or hours) or long delays (days or weeks)
between each viewing. Examinations can be broken into
instances where the eyes are relatively stable (dwells) and
when they move at high velocities (saccades). Task goals,
such as making a sandwich (Hayhoe, Shrivastava, Mruczek,
& Pelz, 2003), have been demonstrated to affect the
distributions of dwell locations and dwell durations.
Consequently, ocular behavior can result from endogenous
processes influencing the eyes where and when to acquire
task-relevant information.
Research has also demonstrated that ocular behavior is
affected by environmental nuances. Such effects result from
exogenous processes – the environment influences the eyes
to particular locations. Exogenous processing is facilitated
by the salience of stimulus features that compose the visual
environment, where salient stimuli attract attention,
constraining the order of information visited through
stimulus-driven eye movements (Franconeri, Simons, &
Junge, 2004; Theeuwes, 2004).
Several lines of research across several disciplines have
addressed the interaction between human cognition and the
task environment (for a summary see Gray, Neth, &
Schoelles, in press). For example, Anderson’s rational
analysis (1990) suggests a cost-benefit tradeoff during
human-environment interactions. Rational analysis is an
analytical approach to understanding the mediation between
cognitive and environmental influences, and asserts that
much of human cognition is adapted to the statistical
structure of the task environment. Gray’s soft constraints
theory (Gray, Sims, Fu, & Schoelles, 2006) applies the
rational analysis framework to the 1/3 s level of behavior, or
the embodiment level (Ballard, Hayhoe, Pook, & Rao,
1997), and predicts the scheduling of eye movements,

Consistent Sequences of Eye Movements
Previous research has demonstrated that dwell-saccade
sequences can become relatively consistent across repeated
scans of the same stimulus, forming stable visual scans.
Stable scans are hypothesized to take the form of
proceduralized sequences of saccades stored in memory
rather than successions of individually programmed eye
movements (Noton & Stark, 1971). Consequently, stable
scans are hypothesized to result directly from endogenous
processes (Grosbras et al., 2001; Josephson & Holmes,
2002).
Understanding visual scanning requires an active vision
approach to understanding ocular behavior as opposed to the
passive vision approach. The active vision approach
advocates understanding vision via understanding the fovea
and movements of the eye while the passive vision approach
fundamentally discounts saccades and dwells from
explanations and theories of ocular behavior (Findlay &
Gilchrist, 2003). Because the passive approach to vision has
dominated much of the reported research in visual
cognition, little is known about scanning behavior or its
contribution to visual and perceptual phenomena. However,
the research that has been reported on visual scanning
demonstrates that stable scans occur on repeated visual
stimuli and are mostly idiosyncratic (Zangemeister,
Sherman, & Stark, 1995) but can be similar between
participants (Josephson & Holmes, 2002), are important to
recalling imagined items (Laeng & Teodorescu, 2002), and
have been correlated to neural structures that differ to the
neural structures involved in executing a novel sequence of
saccades (Grosbras et al., 2001).
A critical limitation to understanding visual scanning is
that a majority of the reported research has been conducted
using a free-view paradigm – participants are allowed to
freely view a stimulus with instructions amounting to

515

“remember this image.” The current research extends the
understanding of visual scanning from a free-view paradigm
to goal-oriented tasks. Furthermore, previously reported
research demonstrates that visual scans obtained with a freeview paradigm are stable across multiple views of the same
stimulus, and are thus just like any other sequential motor
skill, making them subject to memory mechanisms and
proceduralization. Theories of behavioral refinement (e.g.,
soft constraints theory) state that behavior is adjusted to
reduce cost in units of time during goal-oriented tasks.
Consequently, it is likely that visual scans repeatedly used
during a goal-oriented task are adapted to the environment
through some refinement mechanism. Such an adaptation
could occur by reducing the number of eye movements
necessary to obtain the goal over repeated exposures to the
same stimulus. Finally, it is possible that the two hypotheses
just presented are the mechanism behind the contextual
cueing phenomenon, elaborated in the following section.

Gray, submitted). Refinement would occur through a
mechanism that influences the scheduling of behaviors to
reduce the cost associated with a task while maintaining
accuracy, hypothesized by soft constraints theory.

The Contextual Cueing Phenomenon
Previous research has demonstrated that visual context
implicitly guides spatial attention during visual search tasks
(Chun & Jiang, 1998; Song & Jiang, 2005). Chun, Jiang,
and colleagues operationally define context as the relative
visuospatial arrangement of items composing a stimulus.
Research on how visual context affects visual search has
demonstrated that multiple searches through repeating
contexts improves search times beyond regular motor speedup of practiced skills (see Figure 1). Chun, Jiang, and
colleagues contend that memory for visual context is
instance based and implicitly learned across repeated
exposures to the same context. Consequently, search
improvements result from an implicit context-target pairing,
leading to the context cueing the target location. A target
location is cued when the current context reaches a
similarity threshold with another, previously encoded,
context stored in memory. When the similarity threshold is
reached, the instance is retrieved from memory and its
paired target location directs attention to that location in the
current context. Indeed, the hypothesized mechanism,
rooted in the passive vision approach, eliminates the need
for eye movements to acquire contextual cueing effects.
Although contextual cueing has been documented and its
underlying processes alluded to across several studies (Chun
& Jiang, 1998; Jiang & Wagner, 2004; Peterson & Kramer,
2001), there remains room for an active vision account of
contextual cueing effects. Contextual cueing is a functional
adaptation to the task environment, and likely results from
mechanisms that function to minimize cost, in units of time,
at the task level (Gray et al. 2006; Myers & Gray,
submitted). Repeated visual scans are hypothesized to
trigger contextual cueing phenomena–eye movements as the
similarity metric assumed to occur in memory.
Proceduralized visual scans may not be enough to obtain
response times similar to those associated with contextual
cueing. In this case, refining visual scans by eliminating
some dwell-saccade pairs would be necessary (Myers &

Figure 1. Prototypical contextual cueing effect.

Summary
Although the contextual cueing phenomenon has been
documented in several studies, an explicit mechanistic
account rooted in the active vision approach remains absent
from explanations of contextual cueing effects. We report
the results from investigating an active vision approach to
understanding contextual cueing. This approach is based on
the notions that eye movements are functional and that
contextual cueing is a functional adaptation to the statistical
structure of the task environment.

Experiments
Two experiments were conducted to determine if eye
movements are associated with contextual cueing and if
scans adapt to repeatedly searched stimuli. Experiment 1
slightly modifies the procedures from Chun & Jiang’s
(1998) fifth experiment, which they used to demonstrate the
presence of contextual cueing without eye movements, but
fails to replicate their results. In experiment 1 we add to
their controls in an added between-participant condition.
Experiment 2 explores the refinement of visual scans in the
typical contextual cueing paradigm.

Experiment 1 – The Necessity of Eye Movements
Experiment 1 is a test of Chun and Jiang’s (1998)
assertion that “contextual cueing can be obtained without
eye movements” (p. 56).
Method Used By Chun & Jiang (1998)
In experiment 5 from Chun & Jiang (1998), participants
were instructed to find a rotated target (T) among rotated
distractors (L) and respond to the target’s direction (right or
left). Participants performed a total of 32 blocks of 24 trials
per block (768 trials). Blocks were divided into three

516

phases: training, testing-practice, and testing. Participants
completed 20 blocks in the training phase, 2 blocks in the
testing-practice phase, and 10 blocks in the testing phase.
Within a block, all stimulus configurations were unique,
however, across blocks, 12 configurations repeated. Thus,
during the training phase participants viewed 12 repeating
stimulus configurations 20 times each, and 240 random
stimulus configurations once each.
Because repeating configurations were the same spatial
arrangement across blocks and because the target was
always located in the same location within a repeating
configuration, participants could learn target locations. To
ensure that any search benefit of repeating configurations
was not attributable to learning target location probabilities,
12 target locations were also used for the random
configurations. Thus, when a random configuration trial
occurred within a block, a target location was randomly
sampled without replacement from a set of target locations
used for creating random configurations. After target
location selection, the distractor locations (11 total) were
randomly assigned around the picked target location.
Consequently any benefit in repeating configurations cannot
be attributable to a small set of possible target locations in
repeating configurations (12).
Three displays composed a single trial during the training
phase: a dwell control display, a stimulus display, and a
feedback display. Participants were instructed to dwell a
small dot on the dwell control display for 500 ms. Next, the
stimulus was displayed until a response was issued. After
the response, a blank screen was displayed and accuracy
feedback was provided. The feedback display remained for
1 sec and was then replaced by a dwell control display
signaling a new trial. Chun and Jiang (1998) report that
participants demonstrated a contextual cueing effect by the
end of the training phase.
During the testing-practice and testing phases, four
displays composed a single trial. Each trial began with a
dwell control display for 600 ms followed by the stimulus.
After 200 ms the stimulus was replaced with a blank screen
that remained present until the participant responded with
the rotation of the target. Following a response, accuracy
feedback was presented with tones signaling either correct
or incorrect responses. After 1 second, the dwell control
display reappeared signaling a new trial. In the testingpractice phase, participants completed 2 blocks of trials
where all trials were random configurations. In the testing
phase, participants completed 240 trials.
The key comparison of the testing phase was the accuracy
levels between repeated and random configurations. Chun &
Jiang report that participants demonstrated a significant 5%
increase in accuracy for repeated configurations (78.5%)
when compared to random configurations (73.5%).
Method Used in Experiment 1
The current experiment uses a modified version of Chun
and Jiang’s (1998) method (free-view) and adds a second
between-participants condition (fixed-view) that further

controls for eye movements throughout a trial and presents
masks during feedback.
There were two slight differences between our training
phase and Chun & Jiang’s. First, the item on the dwell
control display was a set of crosshairs rather than a single
dot. Second, the crosshairs were gaze contingent: changing
from green to red when participants’ gaze moved from the
crosshairs, and changing back to green when participants’
gaze returned. Gaze contingency was used to provide realtime feedback of participants’ gaze locations to help ensure
all participants’ began all trials from the same location. All
participants completed the same training phase and were
then randomly transferred into either the free-view testing
phase or the fixed-view testing phase. Both testing phases
began with a testing-practice phase composed of 2 blocks of
random configuration trials, as in Chun & Jiang (1998).
The free-view testing phase condition was a slightly
modified version of Chun & Jiang’s. The two differences
were that the dwell control item on the dwell control display
was a set of crosshairs rather than a single dot, and the
crosshairs were gaze contingent, as in the training phase.
The fixed-view testing phase condition differed
considerably from Chun & Jiang’s testing phase in two
important ways. First, gaze-contingent crosshairs were
present on all displays in our fixed-view condition. This
helped to further ensure eye movements did not occur at
anytime throughout a trial. Second, a visual mask was also
presented at the same time the feedback display was
presented.
If eye movements are unnecessary for contextual cueing
to occur, both the free-view and fixed view conditions
should replicate Chun & Jiang’s (1998, experiment 5)
results.
Participants. A total of forty-two undergraduate students
consented to participate. All participants had normal, or
corrected–to–normal vision.
Apparatus. The data collection apparatus consisted of an
Apple G4 computer running MacOS 10.4, a 17-inch flat
panel display with the resolution set to 1280 x 1024, a
chinrest to promote head stability, and an Eyegaze
binocular, video-based remote eye-tracking system
developed by LC Technologies that measured point of gaze
at a 120Hz rate. Items composing a stimulus subtended 2°
of visual angle at a viewing distance of ≈ 56 cm. The
Eyegaze system tracking error was 0.63 cm, or less.
Results
Trial data were averaged at the epoch level (1 epoch = 5
blocks = 120 trials) for increased statistical power. Prior to
analyses, 2 participants were removed as outliers on
response times from the training and testing phases.
Training Phase. Following from Chun and Jiang’s
analyses, a 2x(2x2) transfer-type (free-view, fixed-view) x
[epoch (1,4) x configuration-type (repeating, random)]
mixed ANOVA was performed on response times from
correct trials. There was a significant configuration-type x
epoch interaction on response times, with repeating
configuration response times decreasing at a faster rate than

517

random configurations from epoch 1 to epoch 4, signifying
a contextual cueing effect, F(1, 38) = 4.6, p = 0.038.
Importantly, there was not a significant main effect of
transfer-type, F(1, 38) = 1.0, p > 0.32, NS, nor was there a
significant 3-way interaction of transfer-type, configurationtype and epoch, indicating that the transfer conditions did
not interact with contextual cueing, F(1, 38) = 0.04, p >0.83,
NS. There were no significant effects associated with
accuracy, which was a correct response average of 98.2%.
Testing Phase. As in the training phase, trials were
accumulated into epochs, where an epoch was 120 trials.
The dependent variable of interest during this phase is the
proportion of correct responses; consequently, correct and
incorrect trials were included. A 2x(2x2) transfer-type (freeview, fixed-view) x [epoch (5, 6) x configuration-type
(repeating, random)] mixed ANOVA was performed on the
proportion of correct trials. The transfer-type x epoch x
configuration-type interaction from the omnibus ANOVA
was not significant, F(1, 38) = 0.994, p > 0.32, NS.
However, there was a significant epoch x configuration-type
interaction, F(1,38) = 4.327, p = 0.044, where responses to
repeating configurations became more accurate from epoch
5 (M = 0.72) to epoch 6 (M = 0.73), whereas random
configurations became less accurate from epoch 5 (M =
0.75) to epoch 6 (M = 0.72) (see Figure 2). Most
importantly, whereas Chun and Jiang found a significant
main effect of configuration-type, we did not, Mrepeating =
0.74, Mrandom = 0.73; F(1,38) = 0.89, p > 0.35, NS.

(repeating, random) mixed ANOVA was performed on the
proportion of correct trials for the free-view and fixed-view
conditions, separately. There was not a significant
configuration-type by epoch interaction, F(1, 20) = 0.65, p >
0.4, NS, However, in the fixed-view condition there was a
marginally significant effect of configuration-type, F(1,18)
= 3.91, p = 0.064, where random stimulus configurations
(Mrandom = 0.73) lead to a higher proportion of correct trials
when compared to repeating stimulus configurations
(Mrepeating = 0.70) (see Figure 2) – just the opposite of what
was found in Chun & Jiang, experiment 5 (1998). Finally, a
transfer-type (fixed-view, free-view) x epoch (5, 6) mixed
ANOVA was performed on the proportion of correct trials
from repeating configurations during the testing phase to
determine if there were any differences in accuracy based on
our increased eye movement controls (fixed-view) when
compared to relatively relaxed controls (free-view). There
was a marginally significant effect of, F(1,40) = 3.327, p =
0.076. Furthermore, note that the random configuration
accuracy results from the testing phases of both conditions
are nearly identical to Chun & Jiang’s results of 0.735.
Experiment 1 Conclusions
There are three key points to make. First, contextual
cueing was established by the end of the training phase, just
as Chun & Jiang (1998). Second, we did not replicate Chun
and Jiang’s testing phase accuracy results in the condition
most closely similar to their experiment 5 experiment
methods (free-view): repeating configurations were no more
likely to result in a correct response than random
configurations.
Third, the condition with extra eye
movement controls (fixed-view) resulted in lower response
accuracy for repeating configurations than random
configurations – following what would be predicted if eye
movements play a role in cueing target locations.
We hypothesize that our free-view condition did not
replicate Chun & Jiang’s results on account of the gaze
contingent crosshairs acting as a subtle, yet reliable, dwell
control beyond that used by Chun and Jiang (a black dot).
Experiments are currently underway test this hypothesis, but
will not be reported in the current manuscript.
These results support previous work suggesting that eye
movements are more than epiphenomenal, such as playing a
functional role during the recall of visual information
(Laeng & Teodorescu, 2002). This was demonstrated in
experiment 1 as a decrease in response accuracy with
increased eye movement controls as evidenced when
comparing free-view and fixed-view accuracy results in the
testing phase of experiment 1. Indeed, these results suggest
that eye movements play a functional role in implicitly
cueing target locations within repeating configurations.

Figure 2. Test Trial Results. Configuration-type
(repeating, random) by epoch (5, 6) interaction on
proportion of correct trials during the free-view and fixedview testing phase.

Experiment 2 – The Refinement of Visual Scans

Of particular interest was whether transferring to a fixedview condition inhibited response accuracy below that from
the free-view condition. Although the transfer-type x epoch
x configuration-type interaction was not significant in the
omnibus ANOVA, an epoch (5, 6) x configuration-type

The soft constraints hypothesis predicts that behavior adapts
to environmental regularities within a task, resulting in a
reduction of task completion time (Gray et al. 2006). The
contextual cueing phenomenon is a case in point – when the
environment provides stable cues for acquiring the target

518

Results

location, the cognitive system exploits this stability, leading
to quicker response times for repeating configurations, as in
Figure 1. Myers and Gray (submitted) have demonstrated
that unnecessary saccades are avoided to reduce search time,
demonstrating search behavior can be refined to reduce
costs, in units of time, associated with extraneous saccades
and their resultant dwells.
Based on experiment 1 results which suggest that eye
movements are useful during contextual cueing, experiment
2 was designed to (a) determine if visual scans are reused
across multiple instances of repeated stimuli, (b) to
determine if the reused visual scans are refined to decrease
response times through the elimination of saccades and
dwells, and (c) to determine if there is visual scan similarity
between participants on the same stimuli.
Method
Paradigm. The design was a 3 (configuration-group) x
[2(configuration-type) x 6(epoch)] mixed design. The task
environment contained three key differences from
experiment 1. First, items composing each stimulus were
reduced in size from 2° of visual angle in experiment 1 to
0.25° in experiment 2. This served to reduce the number of
dwells between stimulus items that were near one another.
Second, there was no speeded-response testing phase as in
experiment 1; instead, all participants performed 720 trials
following the same structure as the training phase of
experiment 1. Third, participants were given the same set of
24 target locations for repeating and random configurations.
However, repeating configurations differed between 3
groups of 5 participants1. This allowed us to determine if
different people scanned the same repeating configuration in
a similar manner. Target locations were determined
randomly with the constraint that locations must be at least
4° of visual angle from all target locations and the dwell
control crosshairs. Importantly, a two-sample t-test on target
location distance from dwell control crosshairs did not
reveal a difference between repeating and random
configuration target locations [t(22) = -1.13, p > 0.25].
Participants. A total of 15 undergraduate students
consented to participate. All participants had normal, or
corrected–to–normal vision.
Apparatus. The data collection apparatus was the same
used in experiment 1, except items composing a stimulus
now subtended 0.25° of visual angle at a viewing distance
of ≈ 56 cm to facilitate visual scan analyses.
Procedure. Participants completed 360 trials, took a 5minute break, and finished the experiment by completing
the remaining 360 trials. The study lasted approximately 1.5
hours. Participants were run individually and compensated
for their time.

Trial data were averaged into epochs for increased statistical
power, where 1 epoch = 5 blocks = 120 trials, just as
experiment 1.
Response Time Analyses. One participant was removed
from analyses as a response time outlier, leaving 14
participants for analysis. An epoch (1-6) by configurationtype (repeating, random) repeated-measures ANOVA was
performed on correct trials to determine if participants were
contextually cued. To our dismay, there was not an epoch
by configuration-type interaction, F(5, 55) = 0.877, p > 0.5,
NS, indicating participants were not contextually cued.
There was a main effect of epoch, F(5, 55) = 32.15, p <
0.001, where response times decreased from epoch 1
(Mepoch-1 = 1988.23 ms) to epoch 6 (Mepoch-6 = 1605.5 ms).
The main effect of configuration-type was not significant (p
> 0.5, NS).
Eye Data Analyses. ProtoMatch software (Myers &
Schoelles, 2005) was used to determine dwells and their
durations, assign items to dwells, and objectively compare
the similarity between visual scans. Two additional
participants were removed from the analyses due to poor
eye data throughout the experiment. Only correct trials were
analyzed. Whereas, there were no effects on dwell duration,
the number of dwells to find a target significantly decreased
across epochs from a mean of 6 in epoch 1 to a mean of 4.6
in epoch 6, F(5, 55) = 13.608, p < 0.001. This effect did not
interact with configuration type, F(5, 55) = 1.67, p > 0.14,
NS. The mean number of times an item was examined more
than once during a trial also reduced across epochs from a
mean of 0.37 in epoch 1 to a mean of 0.13 in epoch 6, F(5,
55) = 14.94, p < 0.001, and did not interact with
configuration type, F(5, 55) = 1.26, p > 0.29, NS.
Strategy Analyses. The objective of experiment 2 was to
determine if visual scans are reused across multiple
instances of repeated stimuli, to determine if the reused
visual scans are refined to decrease response times through
the elimination of saccades and dwells, and to determine if
there is visual scan homogeneity between participants.
Unfortunately, rather than analyzing the similarities
between visual scans, we attempted to determine why
contextual cueing did not replicate. One possibility is that
participants overrode contextual cueing with a different
search strategy employable on any stimulus configuration.
One candidate strategy is to begin at the stimulus display’s
center, and then search outward examining items until the
target is found. If participants searched in this manner, there
should be a significant positive correlation between target
locations’ distance from the crosshairs on the fixation
control display and response times. Indeed, there was a
positive correlation (r2 = 0.61) that was significantly
different from zero, t(13) = 6.853, p < 0.001.

1
We did not intend to conduct statistical tests between
configuration-groups, as a sample size of 5 is not powerful enough
to detect reliable differences. Rather, we wanted to ensure
ourselves that there was not something special about a single set of
repeating configurations if repeating configurations were scanned
in a similar manner between participants.

Experiment 2 Conclusions
We began by inspecting configuration-types across response
time and dwell analyses, but found no evidence of
contextual cueing. We next checked to see if a simple

519

References

strategy was used, namely starting in the center of the
stimulus display and scanning outward. The center-out
scanning strategy appears to be how most participants
searched for the target, but does not explain why contextual
cueing did not occur. A possibility for the absence of
contextual cueing in experiment 2 may result from a change
in the size of items composing a stimulus, which were
reduced from 2° of visual angle in experiment 1 to 0.25° in
experiment 2. Neither the contextual mechanism
hypothesized in the current paper, nor the mechanism
proposed by Chun and Jiang (1998) predict an effect of item
size and merits testing.

Anderson, J. R. (1990). The Adaptive Character of Thought.
Hillsdale, NJ: Erlbaum.
Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P. N.
(1997). Deictic codes for the embodiment of cognition.
Behavioral and Brain Sciences, 20(4), 723-742.
Chun, M. M., & Jiang, Y. (1998). Contextual Cueing: Implict
Learning and Memory of Visual Context Guides Spatial
Attention. Cognitive Psychology, 36, 28-71.
Findlay, J. M., & Gilchrist, I. D. (2003). Active Vision: The
Psychology of Looking and Seeing (Vol. 37). Oxford: Oxford
University Press.
Franconeri, S. L., Simons, D. J., & Junge, J. A. (2004). Searching
for stimulus-driven shifts of attention. Psychonomic Bulletin &
Review, 11(5), 876-881.
Gray, W. D., Neth, H., & Schoelles, M. (in press). The functional
task environment. In A. F. Kramer, A. Kirlik & D. Wiegman
(Eds.), Applied attention. Nahwah, NJ: Lawerence Erlbaum
Associates.
Gray, W. D., Sims, C. R., Fu, W.-t., & Schoelles, M. (2006). The
soft constraints hypothesis: A rational analysis approach to
resource allocation for interactive behavior. Psychological
Review, 113(3), 461-482.
Grosbras, M. H., Leonards, U., Lobel, E., Poline, J. B., LeBihan,
D., & Berthoz, A. (2001). Human cortical networks for new and
familiar sequences of saccades. Cerebral Cortex, 11(10), 936945.
Hayhoe, M. M., Shrivastava, A., Mruczek, R., & Pelz, J. B. (2003).
Visual memory and motor planning in a natural task. Journal of
Vision, 3(1), 49-63.
Jiang, Y., & Wagner, L. C. (2004). What is learned in spatial
contextual cueing – configuration or individual location?
Perception & Psychophysics, 66(3), 454-463.
Josephson, S., & Holmes, M. (2002). Attention to repeated images
on the world-wide-web: Another look at scanpath theory.
Behavior Research Methods, Instruments, & Computers, 24(4),
539-549.
Laeng, B., & Teodorescu, D. S. (2002). Eye scanpaths during
visual imagery reenact those of perception of the same visual
scene. Cognitive Science, 26(2), 207-231.
Lleras, A., & Von Muhlenen, A. (2004). Spatial context and topdown strategies in visual search. Spatial Vision, 17(4-5), 465482.
Myers, C. W., & Gray, W. D. (submitted). Regulating visual
search: Optimizing initial saccades to the cost-structure of the
visual task environment.
Myers, C. W., & Schoelles, M. (2005). ProtoMatch: A tool for
analyzing high-density, sequential eye gaze and cursor
protocols. Behavior Research Methods, 37(2), 256-270.
Noton, D., & Stark, L. W. (1971). Scanpaths in Eye Movements
during Pattern Perception. Science, 171(3968), 308-311.
Peterson, M. S., & Kramer, A. F. (2001). Contextual cueing
reduces interference from task-irrelevant onset distractors.
Visual Cognition, 8(6), 843-859.
Song, J.-H., & Jiang, Y. (2005). Connecting the past with the
present: How do humans match an incoming visual display with
visual memory? Journal of Vision, 5, 322-330.
Theeuwes, J. (2004). Top-down search strategies cannot override
attentional capture. Psychonomic Bulletin & Review, 11(1), 6570.
Zangemeister, W. H., Sherman, K., & Stark, L. (1995). Evidence
For A Global Scanpath Strategy In Viewing Abstract Compared
With Realistic Images. Neuropsychologia, 33(8), 1009-1025.

Discussion
Visual scanning is a ubiquitous activity – we all do it each
time we look for our lost file on our computer desktop.
Research on visual scanning has demonstrated that scans
can be stored in memory and used at later times, such as
when recalling information about imagined stimuli (Laeng
& Teodorescu, 2002). After searching and finding your
missing file on your computer’s desktop once, it is likely
you’ll search in much the same way the second time you
lose the file.
The evolution of visual scans across multiple searches
through the same stimulus was what we set out to test, and
the contextual cueing paradigm lent itself directly to testing
visual scan adaptations. Moreover, visual scan adaptations
provide a likely explanation for the contextual cueing
phenomenon. Indeed, in experiment 1 we found that
limiting eye movements during a testing phase hampers
accuracy for repeating configurations while not affecting
random configurations. Experiment 2 was setup to visual
scans were stabilized and refined across repeated exposures
to repeating stimuli. However, we were unable to obtain
contextual cueing effects when items composing a stimulus
were small (≈ 0.25° of visual angle) suggesting that the
phenomenon is much more volatile than originally reported.
Across two experiments we demonstrate both the
presence and absence of a phenomena that has been
replicated in many publications (see Lleras & Von
Muhlenen, 2004, for an exception). The only major change
to our stimulus was the size of each item (L and T) within
each stimulus from 2° of visual angle in experiment 1 to
0.25° in experiment 2. It is currently unclear to us why this
would have the effect of diminishing contextual cueing.
Consequently, the size of items composing stimuli has
become a lead for further empirical investigations on when
and where people are likely to be contextually cued.

Acknowledgments
The research reported here was supported by a grant from
the Air Force Office of Scientific Research (AFOSR
#FA9550-06-1-0074) to Wayne Gray.

520

