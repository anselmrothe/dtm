Although this paper analyzes shaping with respect to
its benefits on search problems, the reader should recognize that shaping is often intimately related to reinforcement learning. The objective in reinforcement learning
is to find a policy (i.e., a mapping from states to actions) that maximizes the reward obtained. In general,
searching the policy space for an optimal policy (or even
a good policy) is computationally intractable. However,
it is possible that an agent can learn to perform a task
faster if a teacher is available that adaptively modifies
the reward function in the manner suggested by behavioral shaping. For example, consider a sequential decision problem in which an agent attempts to reach the
reward state by choosing one of two actions at each moment in time. The agent chooses sequences of actions of
length dlog2 ne, and then is told whether the resulting
state is the reward state. This situation can be characterized by a binary tree in which nodes correspond to
states and edges correspond to actions. The tree has n
leaf nodes, one of which corresponds to the reward state,
and the tree’s depth is dlog2 ne. Consequently, a policy
is a sequence of dlog2 ne actions. The optimal policy is
the sequence leading to the leaf corresponding to the reward state. This scenario is analogous to the scenario
described above; instead of searching for a reward element in an array, the agent now searches for a sequence
of actions leading to a reward leaf of a tree. Using the actual target reward function, the agent accumulates O(n)
regret in the worst case where regret is defined as the total number of action sequences that the agent tries before
discovering the optimal sequence leading to the reward
state. What if a teacher is available that modifies the
reward function in the manner suggested by behavioral
shaping? Assuming that the teacher marks 1/2 of the
leaves with reward at iteration 1 and successively halves
the reward area at each iteration (as described above),
then the agent can learn the optimal policy with only
O(log2 n) regret. Again, this is an exponential improvement in performance relative to the case where there is
no teacher available to guide the agent’s search.

Target concept T
0

1

Figure 1: The target concept T is a subset of the concept
S = [0, 1]. The search agent needs to search S for a point
in T .
reward functions are binary, whereas those of Ng et al.
allow real-valued rewards.
In the next section, we describe a formal model of
behavioral shaping. This model can be used to prove
the benefits of shaping in several cases involving convex
reward regions lying in multi-dimensional spaces. For
pedagogical reasons, the following section focuses on a
simple one-dimensional case where we prove that shaping can be helpful in finding intervals on a straight line.
We show a lower bound on regret when shaping is used,
and a learning algorithm which hits that bound. Lastly,
we show that the convexity of reward regions is an important requirement of our framework.

Formal Model
Let (X, B) be a measurable space with a measure µ (see
Doob, 1994, for an introduction to mathematical measure theory). Let C ⊆ B. The set C is called a concept
class and its members are called concepts. Examples
of concept classes that we study include intervals in R,
axis-parallel rectangles in Rd , balls in Rd , and convex
bodies in Rd . We will assume that there is a representation scheme for the concept class C (Kearns & Vazirani,
1994).
Definition 1 (Search problem). Let C be a concept class.
A search problem is a pair of concepts (S, T ) such that
T ⊆ S, and S, T ∈ C.
A search agent is given a representation of S and has to
find a point in T using the membership oracle of T . This
scenario is illustrated in Figure 1 where the target concept T is a subset of the concept S = [0, 1]. The number
of oracle queries until a point is found in T is defined as
the regret. Throughout this paper, without loss of generality, we assume that µ(S) = 1, and µ(T ) = 1/R, where
R ≥ 1. Note that for any concept class there is a natural randomized algorithm to solve the search problem:
query independent uniform random points from S until
you find a point in T . The expected regret of the algorithm is R. For sufficiently complicated concept classes
(e.g., finite unions of intervals), the use of randomness
might be inevitable because a deterministic algorithm
with bounded regret need not exist.
In a shaped search problem the agent’s search task will
be aided by a shaping sequence which is a sequence of
nested sets between S and T . The sets in the shaping
sequence will be gradually shrinking concepts from the
underlying concept class C. The rate of shrinking will

Our work is related to the “reward shaping” framework of Ng, Harada, & Russell (1999). These authors
sought to speed-up reinforcement learning by transforming the original reward function to a new reward function
that provides additional training information to guide an
agent’s search. They gave mathematical conditions under which a transformation is policy invariant meaning
that an optimal policy for the original reward function is
also an optimal policy for the new reward function. Our
approach is different from theirs in at least two ways.
First, we use a temporal sequence of reward functions
as compared to their fixed reward transform. Consequently, we believe that our approach is more consistent
with the practice of behavioral shaping as reported in
the psychological literature (Skinner, 1938). Second, our
876

tion of T (through the membership oracles O1 , . . . , Ok−1 ),
an agent with access to a shaping sequence can potentially achieve a smaller regret than would otherwise be
the case. For certain classes of search problems, for
example, it might be possible to approximately determine Si using oracle Oi . If Si is approximately located,
then Si+1 could be approximately located (via queries
to Oi+1 ) by searching only inside the approximation of
Si rather than inside S. As Si has a smaller measure
than S, this search may require a relatively small number of queries. This process can be used iteratively from
i = 1 to i = k − 1 to find a point inside Sk = T . In the
next section we show that it is indeed possible to reduce
an agent’s regret using this method when S and T are
intervals on a straight line.
The regret accumulated by the agent during the search
also depends on the value of γ. Very small (close to 0)
γ values are detrimental because the agent will need to
search a relatively large region for a point lying in a
much smaller region [e.g., µ(S1 ) will be a small fraction
of µ(S)], meaning that the agent will need to search for
a “needle in a haystack”. Large values of γ (close to 1)
may seem detrimental (because the teacher will take a
long time to converge to T ), but are actually not as we
discuss below.
Note that our approach is related to a technique from
the mathematical optimization literature known as quasiconvex optimization (Boyd & Vandenberghe, 2004). A
weaker version of the shaped search problem in which the
concepts are convex and all the oracles are available to
the agent simultaneously can be viewed as an instance of
a quasi-convex optimization problem. However, in our
approach, the oracles are not available simultaneously
but, rather, are available as a temporal sequence. This
is because behavioral shaping almost always proceeds in
a temporal fashion (typically, rewards are initially provided to coarse approximations to the target behavior,
and then only finer approximations are rewarded at later
stages of training).

Concept S
0

1
Concept S1

0

1
Concept S2

0

1
Concept S3 = T

0

1

Figure 2: This figure illustrates the use of a sequence of
nested concepts. Intuitively, the agent initially searches
concept S for a point that lies in concept S1 . Next,
the agent searches in the neighborhood of the discovered
point in S1 for a point that lies in S2 , and then searches
in the neighborhood of the discovered point in S2 for a
point that lies in S3 which is the target concept T .
be a parameter denoted γ. This scenario is illustrated
in Figure 2 which shows a sequence of nested concepts.
Intuitively, the agent initially searches concept S for a
point that lies in concept S1 . Next, the agent searches in
the neighborhood of the discovered point in S1 for a point
that lies in S2 , and then searches in the neighborhood
of the discovered point in S2 for a point that lies in S3
which is the target concept T .
Definition 2 (Shaped search problem). Let C be a concept class. A shaped search problem is defined by the
tuple (S, T, γ, S1 , . . . , Sk ) such that S, T, S1 , . . . , Sk ∈ C,
1
R ≤ γ < 1, T = Sk ⊆ Sk−1 ⊆ . . . S1 ⊆ S, µ(S1 ) =
γµ(S), µ(Si+1 ) = γµ(Si ) for all i = 1, . . . , k − 2. k
is such that µ(Sk−1 ) ≥ 1/R ≥ γµ(Sk−1 ); i.e., k =
dlog γ1 Re. The sequence (S1 , . . . , Sk−1 ) is called a γ shaping sequence.
An agent in a shaped search problem setting is given
a representation of S and has access to the membership
oracles O1 , . . . , Ok of S1 , . . . , Sk , respectively. However,
if the agent makes a query to Oi , it can no longer make
a query to any Oj such that j < i. In other words, the
oracles Oi are presented to the agent in k iterations, with
the agent making (zero or more) queries only to oracle
Oi at iteration i. The agent has to find a point in T
by making queries to the oracles. In this context, the
regret is defined as the total number of queries made to
all oracles until a point in T is found.
Note that an agent solving the shaped search problem
cannot have a regret larger than what its regret would
be on the original search problem; the agent can always
choose to ignore the shaping sequence and only use the
last membership oracle Ok for Sk = T . Because a shaping sequence provides extra information about the loca-

Finding a Point in an Interval
To keep our discussion relatively simple, this section focuses on the case where concepts are intervals on the real
line. Before analyzing the effectiveness of using a shaping sequence in this circumstance, we consider learning
in the absence of such a sequence.
Consider a search problem (S, T ) such that S = [0, 1] ⊂
R is a closed interval of length 1, and T ⊂ S is an interval of size 1/R. The search agent has access to O, which
is the membership oracle of T . Consider the following
simple deterministic algorithm to find a point inside T .
The algorithm starts with the leftmost point in S, and
query points 0, 1/R, 2/R, 3/R, . . . , 1 (as a matter of terminology, we say that the algorithm “makes jumps of
size 1/R in S”). As T is a contiguous, closed interval of
877

size 1/R, the algorithm is guaranteed to hit one point
inside T . As T has size 1/R, there will be at most O(R)
queries. Therefore the regret will be at most O(R).
The previous algorithm assumed that R is known.
Next, we show that even without this information, it
is possible to solve the problem with O(R) regret. To
do this, the agent first sets µ̂(T ), its estimate of the
length of T , to 1 and makes queries at points 0 and 1.
If it hits a point in T , it stops; otherwise it halves the
value of µ̂(T ) to 1/2, and queries points 0, 1/2, and 1.
The algorithm keeps halving µ̂(T ), and keeps making
jumps of size µ̂(T ) in S, until it hits a point inside T .
In general, if the agent estimates µ̂(T ) = 21k , it queries
less than 2k+1 points. Importantly, there is a nonnegative integer k0 such that 2k01+1 ≤ 1/R ≤ 2k10 . When
the agent guesses µ̂(T ) = 2k01+1 , it is guaranteed to hit
a point in T . The total number of queries to O will
be 2 + · · · + 2k0 +2 = 2k0 +3 − 2 which is less than 8R.
Therefore, there is an algorithm to solve the search problem with regret O(R) even if the agent does not know
the value of R and, thus, does not know the size of T .
Throughout the rest of the paper, we assume that the
agent knows the value of R and knows that the size of T
is 1/R.
We now show that no deterministic algorithm can find
a point in T with less than bR − 1c regret. Suppose a
deterministic algorithm has a regret r < bR − 1c. Without loss of generality, assume that all the r queries to
the oracle are distinct. These r distinct points will induce r + 1 intervals in S. The average size of the interval
1
will be r+1
. Therefore, at least one interval will be of
1
size at least r+1
. As r < bR − 1c, at least one interval
will be of size at least 1/R which means that there is at
least one way in which T can be placed such that the
agent will not be able to query any point inside T if it
makes less than bR − 1c queries. Using a similar argument, it can be shown that any randomized algorithm
will accumulate Ω(R) regret. This gives us the following
proposition:
Proposition 1. If the concept class C is the set of closed
intervals then there is an algorithm that can solve the
search problem (S, T ) with O(R) regret where |S| = 1
and |T | = 1/R. Further, any (randomized) algorithm
that solves the search problem will have Ω(R) regret.
We now turn our attention to the case where a shaping
sequence is available. In summary, we show that when
any γ shaping sequence S1 , . . . , Sk−1 is available such
that the Si are closed intervals, it is possible to find a
point in T with a regret which is logarithmic in R. Suppose a shaping sequence S1 , . . . , Sk−1 of nested intervals
is available. We present two algorithms which make use
of this sequence to find a point in T . Algorithm 1 solves
the problem with O( γ1 log γ1 R) regret for R1 ≤ γ < 1.
Although this regret is logarithmic in R for a fixed γ,
it goes beyond the O(R) regret when γ approaches 1.

Algorithm 2 fixes this problem and achieves a regret of
O(log2 R) for γ > 1/2.
We start with Algorithm 1. At the first iteration, the
algorithm’s goal is to find a point inside S1 . The algorithm does not know where S1 lies, but it knows that
S1 is of size γ, so it makes jumps of size γ in S and is
guaranteed to hit a point inside S1 . At the first iteration, the algorithm makes at most d γ1 e queries to oracle
O1 . At the ith iteration (where i > 1), the algorithm’s
goal is to find a point in Si . The algorithm has a point
p which lies in Si−1 (from the previous iteration). The
interval Si of size γ i can contain points lying on either
side of p but, because Si ⊂ Si−1 , its left (right) edge can
lie at most γ i−1 to the left (right) of p. The algorithm
makes d γ1 e jumps of size γ i to the left and right of p,
and hits a point in Si . Therefore, at each iteration, at
most 2d γ1 e queries are made. As there are dlog γ1 Re iter-

ations, the total regret is 2d γ1 edlog γ1 Re = O( γ1 log γ1 R).
For a fixed value of γ, this is an exponential improvement
over the case when a shaping sequence is not available.
However, when γ is close to 1, this regret exceeds O(R)
(as discussed below, Algorithm 2 solves the problem for
large γ by skipping oracles). This gives us the following
theorem:
Theorem 1. If the concept class C is the set of closed
intervals then there is an algorithm that can solve the
shaped search problem (S, T, γ, S1 , . . . , Sk ) for any γ shaping sequence S1 , . . . , Sk with O( γ1 log γ1 R) regret where
|S| = 1 and |T | = 1/R.
Algorithm 1 An algorithm to solve the shaped search
problem (S, T, γ, S1 , . . . , Sk ) such that T, S, S1 , . . . , Sk ⊂
R using the sequence of oracles O1 , . . . , Ok .
Require: 1/R ≤ γ < 1, S = [0, 1], membership oracles
O1 , . . . , Ok of the sets S1 , . . . , Sk .
1. p ⇐ 0
2. for i = 1 to k do
3.
if i=1 then
4.
query O1 with points 0, γ, 2γ . . .
5.
p ← first point at which O1 outputs 1.
6.
else
7.
Query oracle Oi with points p − γ i−1 , . . . , p −
2γ i , p − γ i , p, p + γ i , p + 2γ i , . . . , p + γ i−1
p ← first point at which Oi outputs 1.
8.
end if
9.
10. end for
11. return p
An interesting aspect of our analysis is that it reveals
a number of issues regarding the shrinking rate parameter γ. First, the above algorithm assumes that γ is
known. Importantly, it can be shown that even if γ is
unknown, it is still possible to solve the shaped search
878

problem with O( γ1 log γ1 R) regret. The method to do so
is very similar to the one described above which solved
the search problem (S, T ) when R was unknown (and,
thus, will not be described here).
Second, there exists an optimal value for γ that minimizes γ1 log γ1 R. This value is γ = 1/e. This result is

lem (S, T, 1/2, Ss , S2s , . . . , Sk ) using Algorithm 1, which
solves the search problem with O(log2 R) regret.
When R1 ≤ γ < 12 , the bound on regret depends on γ.
Note that Algorithm 2 calls Algorithm 1 when γ < 12 ,
meaning that the total regret is O( γ1 log γ1 R). We show
that this is also a lower bound when γ < 12 . In Algorithm 1, suppose that at each iteration i, the location of
the interval Si is fully revealed if the algorithm makes
more than b γ1 − 1c queries. We show that even with this
extra information, the total regret to find a point in the
interval T is still O( γ1 log γ1 R).

1
γ

obtained by differentiating log γ1 R with respect to γ,
setting the derivative to zero, and solving for γ.
Lastly, there is a trade-off involving the value of γ. If
γ = R1 , then k = 1 and the shaping sequence is nonexistent (i.e., S1 = T ) meaning that the regret becomes
O(R). If γ is close to one, then k is large and the shaping
sequence is very long. In this case, the regret increases
rapidly to infinity as γ approaches 1. Consequently,
Algorithm 1 is not optimal because, when γ is large,
the agent could simply ignore the shaping sequence and
make queries only to the final oracle Ok which will lead
to O(R) regret. Fortunately, it is possible to do better
than this. When γ is large, the agent can choose to make
queries only to oracles Os , O2s , . . . , Ok where s is the first
integer such that γ s < 1/2 (for simplicity, we assume
that k is a multiple of s). In other words, the strategy of
a new algorithm, denoted Algorithm 2, is to use sets of
the shaping sequence that are successively shrinking by
a factor of about 1/2, and ignore other elements of the
shaping sequence. In this way, γ is effectively reduced
to 1/2 for the agent, and the regret reduces to O(log2 R).
We next prove a lower bound on regret, and show that
Algorithm 2 achieves this lower bound. That is, we show
that no algorithm can do better than Algorithm 2 (up
to a constant factor).
Theorem 2. If the concept class C is the set of closed
intervals then there is a deterministic algorithm that can
solve the shaped search problem (S, T, γ, S1 , . . . , Sk ) with
O( γ1 log γ1 R) regret for γ < 1/2 and with O(log2 R) regret for γ ≥ 1/2 for any shaping sequence S1 , . . . , Sk
where |S| = 1 and |T | = 1/R. Further, there is no algorithm, deterministic or otherwise, that can solve the
shaped search problem (with Si being closed intervals)
with smaller regret (up to a constant factor).

At iteration i, the interval Si of size γ i must lie within
the interval Si−1 of size γ i−1 . For each i, we are supposing that the algorithm knows Si−1 exactly, as it was
revealed at the end of the previous iteration. Without
loss of generality, we assume the agent queries only inside
Si−1 at iteration i. If the algorithm queries t points, it
induces t + 1 intervals on Si−1 . The average interval size
i−1
of these intervals will be γt+1 . This means that there
will be at least one interval which will be i−1
at least the
average size. If t < b γ1 − 1c < γ1 − 1, then γt+1 > γ i . In
other words, there is at least one interval which will be
of size at least γ i . As Si might lie anywhere in Si−1 , the
alleged algorithm is not guaranteed to be able to find Si
if Si lies in this interval of size at least γ i . Consequently,
any correct search algorithm will have to make at least
b γ1 − 1c = O( γ1 ) queries at each iteration and, thus, the
total regret is bounded from below by Ω( γ1 log γ1 R). A
similar argument holds for randomized algorithms.

Algorithm 2 An optimal algorithm to solve the
shaped search problem (S, T, γ, S1 , . . . , Sk ) such that
T, S, S1 , . . . , Sk ⊂ R using the sequence of oracles
O 1 , . . . , Ok .

Proof. First we show an information-theoretic lower bound
on regret which is independent of γ. For a given R, we
can place R intervals of size 1/R next to each other inside
an interval of size 1. To encode the identity of a particular interval, we need log2 R bits. As the oracles are
providing one bit of information at each query, any algorithm that successfully solves the problem must make
Ω(log2 R) total queries to the oracles.
We now show that Algorithm 2 hits this bound when
γ > 12 , meaning that the bound is tight for γ > 12 .
When γ > 12 , the algorithm sets s = d log1 1 e (with2 γ

out loss of generality, assume that γ s = 1/2) and calls
Algorithm 1 with the oracles Os , O2s , . . . , Ok . Therefore the algorithm is solving the shaped search prob879

Require: 1/R ≤ γ < 1, S = [0, 1], membership oracles
O1 , . . . , Ok of the sets S1 , . . . , Sk .
1. if γ ≤ 21 , call Algorithm 1 and return p, otherwise
continue.
2. s = d log1 1 e
2 γ

3. call Algorithm 1 with γ = 1/2 and membership ora-

cles Os , O2s , . . . , Ok and return p.

Convexity is Important
In Theorem 2 we showed that if the concept class is the
set of closed intervals, it is possible to solve the shaped
search problem with smaller regret than required to solve
the original search problem. In this section, we show
that if the members of the concept class are a union of
two closed intervals, then there are shaped search problems such that, for a fixed γ, it is not possible to find a

point in T with less than O(R) regret for certain shaping
sequences.
Consider the following example with γ = 1/2. Suppose each set Si in the shaping sequence consists of two
segments. The first segment is the target interval T , and
it remains fixed throughout all sets in the shaping sequence. The second segment shrinks at a rate such that
successive sets in the sequence maintain a size ratio of
1/2. In the last iteration, this second segment vanishes.
More formally, let S = [0, 1] and γ = 1/2. The
shaping sequence S1 , . . . , Sk−1 is the sequence of sets
Si = T ∪ Qi , i = 1, . . . , k − 1, where Qi = [0, 1/2i − 1/R],
T = [l, l + 1/R], and 1/2 ≤ l ≤ 1 − 1/R. In this case,
even if the teacher fully reveals the location of the segment Qi to the agent at each iteration, the agent still
needs to locate the set T , which can lie anywhere in a
region of size 1/2. Hence, to find a point in T , O(R)
queries are needed.
We have just shown that there are shaping sequences
which do not exponentially reduce an agent’s regret if the
concept class is the set of unions of two closed intervals.
Although this example assumes a fixed value of γ, similar
results can be shown for arbitrary values of γ when the
concept class consists of more complicated non-convex
concepts. For example, if the concept class is the set of
unions of three closed intervals, an exponential reduction
in regret is not possible for any value of γ.
We conjecture that convexity is an important requirement for shaped search. That is, we conjecture that
when an agent seeks to discover a concept through a
shaped search procedure, it will only be able to achieve
a small regret when the concept is convex. In fact, all
our additional results regarding shaped search in multidimensions are for concept classes consisting of convex
bodies (Chhabra, Jacobs, & Stefankovic, 2007).

cept class is the set of unions of two intervals, there are
shaping sequences which do not reduce regret.
The results presented here form the foundation for additional results reported in a longer article (Chhabra,
Jacobs, and Stefankovic, 2007). In this article, we study
the cases where concepts are rectangles, ellipsoids, or
general convex bodies in high dimensions. In multidimensions, new methods are required to create efficient
search algorithms.

Acknowledgments
This work was supported by AFOSR research grant FA955006-1-0492.

References
Anthony, M. & Biggs, N. (1992). Computational Learning Theory. Cambridge, UK: Cambridge University
Press.
Boyd, S. & Vandenberghe, L. (2004). Convex Optimization. Cambridge, UK: Cambridge University Press.
Chhabra, M., Jacobs, R. A., & Stefankovic, D. (2007).
Behavioral shaping for geometric concepts. Journal of
Machine Learning Research, in press.
Doob, J. L. (1994). Measure Theory. New York: SpringerVerlag.
Dorigo, M. & Colombetti, M. (1994). Robot shaping:
Developing autonomous agents through learning. Artificial Intelligence Archive, 71, 321-370.
Kearns, M. J. & Vazirani U. V. (1994). An Introduction
to Computational Learning Theory . Cambridge, MA:
MIT Press.
Ng, A., Harada, D., & Russell, S.(1999). Policy invariance under reward transformations: Theory and application to reward shaping. In I. Bratko (Ed.), Proceedings of the 16th International Conference on Machine
Learning. San Francisco: Morgan Kaufmann.

Summary
Shaping is a commonly used procedure for teaching complicated tasks to people, animals, and robots. Both
behavioral experiments and computer simulations have
demonstrated that learners trained via shaping achieve
significant improvements in learning speeds.
In this paper, we mathematically formalized a model
of shaping, and studied it in the context of search problems. To keep our discussion simple, we focused on the
one–dimensional case where concepts are intervals on
the real line. When a shaping sequence is available, the
search problem can be solved with exponentially less regret than would otherwise be possible. We also showed
that there do not exist algorithms which can solve the
search problem using a smaller number of queries. Our
analysis revealed a number of interesting issues regarding
the shrinking rate parameter γ. Lastly, we conjectured
that it is important that concepts are convex for shaping
sequences to be useful. We showed that when the con-

Randlov J. (2000). Shaping in reinforcement learning
by changing the physics of the problem. In P. Langley
(Ed.), Proceedings of the 17th International Conference on Machine Learning. San Francisco, CA: Morgan Kaufmann.
Skinner, B. F. (1938). The Behavior of Organisms. New
York: Appleton-Century-Crofts.
Sutton, R. S. & Barto, A. G. (1998). Reinforcement
Learning: An Introduction. Cambridge, MA: MIT
Press.

880

