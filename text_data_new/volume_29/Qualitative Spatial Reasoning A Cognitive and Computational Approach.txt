UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Qualitative Spatial Reasoning: A Cognitive and Computational Approach

Permalink
https://escholarship.org/uc/item/76n0t0kv

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 29(29)

Authors
Ragni, Maro
Steffenhagen, Felix

Publication Date
2007-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Qualitative Spatial Reasoning:
A Cognitive and Computational Approach.
Marco Ragni (ragni@informatik.uni-freiburg.de)
University of Freiburg, Department of Computer Science
D-79110 Freiburg, Germany

Felix Steffenhagen (steffenh@informatik.uni-freiburg.de)
University of Freiburg, Department of Computer Science
D-79110 Freiburg, Germany
Mental Models. For such relational reasoning problems,
there exist several empirically validated effects in reasoning: the number of models (indeterminacy effect), the form
of premises (figural effect), the wording of conclusion and
the preference effect. These effects are explained by mental model theory (MMT) (Johnson-Laird & Byrne, 1991;
Johnson-Laird, 2001). According to the MMT, linguistic
processes are relevant to transfer the information from the
premises into a spatial array and back again, but the reasoning process itself fully relies on model manipulation only. A
mental model is an internal representation of objects and relations in spatial working memory, which matches the state of
affairs given in the premises. The semantic theory of mental
models is based on the mathematical definition of deduction,
i.e. a propositional statement ϕ is a consequence of a set of
premises P , written P |= ϕ, if in each model A of P , the conclusion ϕ is true.

Abstract
In recent years a lot of psychological research efforts have
been made in analyzing human spatial reasoning. Psychologists have implicitly used few spatial cognitive models, i.e.
models of how humans conceptualize spatial information and
reason about it. But only little effort has been put into the
task of identifying from an algorithmic point of view the control mechanism and complexity involved in spatial relational
reasoning. In this paper we extend the SRM model (Ragni,
Knauff, & Nebel, 2005; Ragni & Steffenhagen, 2007) by new
specifications and formalization of Baddeleys Working memory model. By the resulting model CR OS we are able to explain a number of new psychological effects of spatial representation and reasoning by the number of mental operations
involved in solving these tasks. The discussion includes consequences of the formalization for the role of the central executive in spatial relational reasoning.
Keywords: Spatial Reasoning; Computational Modelling

Introduction
The ability to deal with spatial and temporal information is
one of the most fundamental skills of any intelligent system
and important in our everyday lives. When route descriptions are given, spatial information is usually contained in the
description. While in engineering or physics it is most common to represent spatial information quantitatively, e.g. using coordinate systems, human communication mainly uses
a qualitative description, which specifies qualitative relationships between spatial entities. But how is this information
processed? Where is the focus of cognitive attention in processing qualitative information? In the following we focus on
relational reasoning problems, e.g.
(1)

The red car is to the left of the yellow car.
The yellow car is to the left of the orange car.
The yellow car is to the left of the green car.
The green car is to the left of the blue car.
Is the blue car (necessarily) to the right of the orange car?
The statements are called premises, the cars are the terms, and
the question refers to a putative conclusion. A premise of the
form “The red car is to the left of the yellow car” consists
of (two) objects, and a (usually binary) relation like “to the
left of”. More precisely, the first object (red car) is the ”to
be localized object”(LO), which is placed according to the
relation (left of) of the second object (yellow car1 ), which is
the “reference object” (RO) (Miller & Johnson-Laird, 1976).
1 In

the following he objects are abbreviated by R,Y, O, G and B

Without having an algorithmic formalization of a cognitive
model, the task of testing and improving this model seems
to be rather difficult, whereas the transfer of such cognitive
models to AI systems seems to be even harder. Only a precise computational model, which defines parameters and operations, makes testable predictions. Furthermore, by using
empirical data, formally specifying the role of the subsystems
of a cognitive model, i.e. its store systems, it is possible to
identify the necessary abilities of a computational model.
In this paper we formalize and analyze a combination of
the preferred mental model theory and Baddeleys working
memory model. Then we show how this model (i) is able
to solve relational reasoning tasks, (ii) explains empirical results in the literature by the number of mental operations, (iii)
report an experiment, which tests a new prediction made by
the CR OS , and (iv) finally give an idea how the CR OS can
help in specifying the role of the central executive (CE).

State of the Art
Psychological Background. For joining spatial reasoning
and representation, it is necessary to specify and work out the
main assumptions of mental model theory (MMT) and Baddeleys Working Memory Model (BWMM).
The mental model theory assumes that the human reasoning process consists of three distinct phases: The model generation phase, in which a first model is constructed out of

1415

tial reasoning uses mental models (Byrne & Johnson-Laird,
1989). The mental models can be located in the WMM in
the visuo-spatial sketchpad, where the construction and manipulation of the mental models can be located as well. The
model in the VSSP is manipulated by a special device which
is called focus. The PL uses some dynamic memory allocation like the first-in-first-out principle (Vandierendonck et al.,
2004; Baguley & Payne, 1999).

Figure 1: Baddeleys (1999) Working Memory Model

the premises, an inspection phase, in which the model is inspected to check if a putative conclusion is consistent with
the current model. In the validation phase, finally, alternative
models are generated from the premises that refute this putative conclusion. In our example presented above, the exact
relation between “Y” and “G” is not specified and leads to
multiple-model cases like R Y O G B or R Y G O B. This
is caused by the indeterminacy effect and is mainly responsible for human difficulty in reasoning (Johnson-Laird, 2001).
The classical MMT is not able to explain a phenomenon encountered in multiple-model cases, namely that humans generally tend to construct a preferred mental model (PMM). This
model is easier to construct, less complex, and easier to maintain in working memory compared to all other possible models (Knauff, Rauh, Schlieder, & Strube, 1998). The principle
of economicity is the determining factor in explaining human
preferences (Manktelow, 1999). This principle also explains
that a model is constructed incrementally from its premises.
Such a model construction process saves working memory
capacities because each bit of information is immediately
processed and integrated into the model (Johnson-Laird &
Byrne, 1991). In the model variation phase, this PMM is varied to find alternative interpretations of the premises (Rauh et
al., 2005). From a formal point of view, however, this theory
has not yet been formalized and is therefore not fully specified in terms of necessary operations to process such simple
problems described above. In other words, the use, construction, and inspection of mental models have been handled in a
rather implicit and vague way (Johnson-Laird, 2001; Baguley
& Payne, 1999; Vandierendonck, Dierckx, & Vooght, 2004).
BWMM assumes a central executive, which is responsible for monitoring and coordinating the operations of two
subsystems, the phonological loop (PL) and the visuo-spatial
sketchpad (VSSP) (Fig. 1). The first subsystem, the phonological loop, stores information in a language-based form.
The second subsystem, the visuo-spatial sketchpad, which
is independent from the PL in terms of limits, stores visual
and spatial information. Both subsystems are controlled by
a Central Executive which is able to store and manipulate
information in both subsystems. For combining the PMMT
and BWMM, the following questions have to be answered:
In which subsystem and how does the reasoning takes place?
Which limits do the subsystems and the control process have?
These questions are answered by results, which can be found
in the literature: The deduction process in relational spa-

Figure 2: The CR OS -Model

1416

Computational Models. A first computational model for
mental models was presented 1991 (Johnson-Laird & Byrne,
1991). This model is mainly able to insert objects into an array and to generate a mental model. This model simulates and
explains experimental results of three-term problems. The
most general model in reasoning with relations is the UNICORE model (Bara, Bucciarelli, & Lombardo, 2001). This
model is able to explain several effects on relational reasoning (e.g. figural effect), but so far it does not model the variation phase or include any representation of human memory.
A first approach to specifying a computational model for the
preferred mental model theory has been the SRM presented
by (Ragni et al., 2005). This model consists of an input device
for the premises, a two-dimensional spatial array in which the
mental model is constructed, inspected, and varied, and a focus, which performs these operations. The application of a
standard cost measure was able to explain empirical results.
But this model still contains some limitations. Complex relations, defined by the number of dimension and sources of
variations that are related (Halford1, 1998), are not definable.
There is no working memory representation and the model
variation phase is not specified.

The CR OS Model
Each computational model is based on assumptions and abstractions depending on its aim. The CR OS -Model (Cognitive Relational Operating System) which formalizes the

meaning of the input has to be interpreted. In linguistics, as
well as in psychology, the existence of a semantic interpreter
(SI) is assumed, which in our model maps syntactically analyzed texts to the formal representation. The semantic interpretation is not part of this paper. We simply assume a parser
that provides the correct interpretations to the system. If indeterminacy occurs, information about other possible models
must be stored. Since a mental model is only a representation, information of other models must be held in another
subsystem. This information is psychologically modeled by
annotating objects (Vandierendonck et al., 2004). Since we
do not now how humans encode such information, we use
the full premise as annotation. The appropriate memory system in the WMM for this kind of propositional information is
the PL. This is consistent with neuropsychological evidence
(Knauff, Mulack, Kassubek, Salih, & Greenlee, 2002). The
PL is managed by a dynamic memory allocation system like
FiFo or least-recently-used strategy (LRU), which allows the
modeling of activated objects.
Since both systems, the SA and the PL, are only memory systems and the focus manipulates only the SA, a control process, which manages the CR OS , is needed, managing
the subsystems and controls the focus operations on the SA.
The control process has a limited instruction set (Fig. 1). Several instructions directly control read/insert/move operations
of the focus, statements to branch or loop the control flow,
and simple test instructions. With this set of instructions, algorithms for all three reasoning phases can be defined and
different insertion strategies can be tested and compared. The
premises are read and interpreted iterativeley by the SI, and
the control process inserts the new encountered information
immediately into the model by moving the focus in the SA
and adding indeterminacy information to the PL. The focus
has the ability to create new layers for premises that cannot
be constructed into one layer .
In the following we present the algorithms for the construction, inspection and variation on the basis of problem (1) with
abbreviated initial letters for the car objects.

Table 1: The instruction set of the CR OS .
Control process operations
read the next premise from SI and save values
to the variables LO, RO, and REL
SubSystem(sys)
change sub system the central process is
working on; sys can be the PL or the SA
Control Flow
if val then
test whether val is true and
{instr. block}
process first instruction block
[else {instr. block }] else 2nd block is processed
while val do
process instr. block as long as
{instr. block}
val <> 0
Operations on Phonological Loop
writep(prem)
write premise into loop
annotate(o,a)
annotate object o with a
annotations(o)
return annotations of objects o
annotated(o)
return true if o is annotated
Focus Operations
fmove(d)
move the focus to direction d
fread()
read cell where focus is on, return false
if cell is empty
fwrite(o)
write object o to cell where focus is on
newLayer()
create new empty layer
Complex Sub-Programs
shift(o, d)
shift object o to direction of d
exchange(o,rel,concl) exchange object o to direction
of rel generating a new model
fmoveto(o)
move focus to object o
inverse(rel)
compute inverse relation to rel
layer(o)
returns the layer of object o,
merge(l1 , l2 )
merge layer l1 and l2
readnext()

WMM and PMMT consists of: A conceptualization of the
WMM (with subsystems), a manipulation device for the mental models, a (relational) language describing object positions, and a semantic interpreter, interpreting the language.
The central place where models are located is the VSSP. The
VSSP is a spatial array (SA) of two-dimensional grids, called
layer, in which the models are generated and manipulated by
a device called focus. The focus can perform a small number of operations like moving, reading, and inserting. For
example for ’A left B’ and ’C right D’, there are two possible
submodels, each placed in its own layer, so that submodel AB
would be in the first and CD in the second layer. Formally,
the CR OS is a 6-tuple (I, SI, A, F, PL,C) with:
I: the input device
SI: the semantic interpreter; interprets the input of I.
A: a spatial array containing the layers. We set: ω(A) the
objects held by array A; λ(O): the layer of object O.
F: the focus working on the spatial array, able to perform
move (L,R,B,F,No-Move), group, and shift operations.
PL: the PL, a memory for storing verbal information.
C: a control process, which uses the instructions of Fig 1.
Problems related to the ambiguity of spatial relations are
not accounted. The model interprets the string “A is left of
B” as: both objects are in the same line and A is to the left
of B. The relations “right”, “front”, and “behind” are equivalently defined. When processing natural language strings, the

Model construction The algorithm for the model construction has to distinguish five types of premises (O1 , r, O2 )
to place the objects of the premises: (1) ω(A) = 0/ (first
premise), (2) O1 ∈ ω(A) and O2 6∈ ω(A) or vice versa, (3)
O1 , O2 6∈ ω(A), (4) λ(O1 ) 6= λ(O2 ) (connecting two layers),
(5) λ(O1 ) = λ(O2 ) (additional knowledge).
The construction process begins with the first premise and
an empty layer. First the RO is placed, then the focus moves
in the direction of the relation and places the LO to the next
free cell. In our example Y is inserted first, the focus moves
to the left and inserts R. The algorithm (Fig. 3) checks the
type of each new premise and inserts the object(s) according
to the specific case. For premises of type 2 only one object
will be inserted into the model according to the already contained object. If the new object cannot be placed as a direct
neighbor, the model structure is indeterminate, so the control process annotates the object by inserting the relational

1417

information as a proposition into the PL, and the focus places
the present object according to the fff-principle (first free fit).
For premises of type 3, where neither of both objects are contained in the model, a new layer is generated, and both objects
will be placed as seen in the beginning of the model construction. If both objects are contained in different layers (type 4),
both layers have to be merged according to the relation of
the premise. Premises of type 5 specify additional knowledge for two objects contained in the same layer. They are
processed by a model variation step, trying to check if the inverse premise holds in all variations of the actual model. If a
counter-example exists, it is a model containing the additional
knowledge. The second and third premise are of type 2 because Y is already in the model, so O and G are inserted to the
right of Y according to the fff-principle. Because G cannot be
placed adjacent to Y it is annotated with ’right Y’. The next
processed premise is also of type 2 and object B, that is not
in the model, is inserted directly to the right of G. Because G
is annotated, B has to be annotated too. Now the construction
phase is complete and the resulting model is shown in the first
line of Fig. 6.
def c o n s t r u c t M o d e l ( ) :
readnext ( )
f w r i t e (RO)
fmove ( i n v e r s e (REL) )
f w r i t e (LO)
while r e a d n e x t ( ) do
{ i f type2 then
{ fmove f o c u s t o c o n t a i n e d o b j
fmove f o c u s
while not p l a c e d do
{ i f f r e a d ( ) then
annotate missing obj
else
fw r i te missing object
p l a c e d = true } }
i f type3 then
{ l = newLayer ( )
f w r i t e (LO ) ; fmove ( i n v e r s e (REL) )
f w r i t e (RO) }
i f type4 then
merge ( l a y e r (LO) , l a y e r (RO) )
i f type5 then
{ newModel=v a l C o n c l (LO, i n v e r s e (REL) ,RO)
i f newModel then
wr iteMo del ( ) }}

f o c u s i n s p e c t (LO, r e l , RO) :
fmoveto (RO)
while f r e a d != LO do
{
fmove ( r e l )
i f f r e a d ()==LO then
return true }
return f a l s e

Figure 4: Pseudo code for the inspection algorithm.
PMM (in which the putative conclusion holds). The algorithm checks if one of the objects in the conclusion is annotated. Annotations on objects specify the positional relation
to reference objects, which we refer to as anchor. If the annotations on one of the objects include the relation and the other
object of the putative conclusion then the putative conclusion
holds. The same argument holds if none of the conclusions’
objects is annotated because then the positions of the objects
are determined. If there is an annotation only one of the objects , as in the example conclusion ’B is to the right of O’ (see
Fig. 6), the only object of the conclusion which is to be moved
is B and not O. This goes along with the use of annotations,
i.e. in the construction process an annotation is created only
for indeterminate object positions. If the object which is to be
moved has an anchor, it may be necessary to move the anchor
first. To provide an example: B cannot be moved because G,
the anchor of B, is a direct neighbor of B. Thus, the algorithm
first exchanges the anchor to the left of O, which is possible
since G is the anchor of Y . Now the counter-example can be
generated by exchanging B beyond O because the anchor of
B can be placed to the left of O, so false is returned. If both
objects are annotated, then first the LO of the putative conclusion is exchanged. LO is moved into the direction of RO
until its anchor is reached. If this results in the generation of
an inconsistent model, the algorithm stops, and returns false.
It is possible that the anchor object is between LO and RO, so
LO is exchanged until it reaches the anchor. Then the anchor
object is exchanged recursively towards the RO. If no further
exchanges to RO are possible, the exchange process starts to
exchange the RO into the direction of LO.

Psychological Results

Figure 3: The construction algorithm.
Model inspection After model the construction, the inspection phase searches for new information (cp. Fig. 4) that
was not specified by the premises. The focus moves to the
first given object (RO) and from there it inspects the model
according to the relation in order to find the second object
(LO). The search process terminates after O(n) steps, since
the model is bounded by the number of objects.
Model variation The model variation comes into play if
a conclusion must be verified or if additional knowledge of
two already contained objects must be processed during the
model construction process. The focus starts in the variation process with the PMM and varies the model with local
transformations to generate a counter-example to the putative
conclusion. The variation process starts from the generated

There are several psychological experiments investigating
spatial relational reasoning. The findings vary from the classical question determinacy/indeterminacy (Byrne & JohnsonLaird, 1989), the wording of conclusion to questions which
investigate the role of relational complexity. What do all these
different effects have in common? The measure of effects can
be explained by one general concept: The number of “mental
operations” necessary to perform the tasks is sufficient to explain the results. We analyze the role of the Central Executive
w.r.t relational complexity and the model variation phase.
Relational Complexity and Operations. The influence of
relational complexity in the model generation phase is studied
by (Goodwin & Johnson-Laird, 2005). Participants had to
infer the relative starting positions of 4 runners on 5 lanes in
a race, given by:

1418

v a l i d a t e C o n c l u s i o n ( Model , c o n c l ) :
{ i f l a y e r (LO) != l a y e r (RO)
return f a l s e
i f not check ( c o n c l )
return f a l s e
i f c o n c l u s i o n i n a n n o t a t i o n s ( Model )
o r i n v e r s e ( c o n c l ) i n a n n o t a t i o n s ( Model )
return true
i f LO not i n o b j e c t s ( a n n o t a t i o n s )
o r RO not i n o b j e c t s ( a n n o t a t i o n s )
return true
i f not excha ng e (RO, r e l a t i o n , c o n c l )
return f a l s e
else
i f not excha ng e (LO, r e v ( r e l a t i o n ) , c o n c l )
return f a l s e
return true }

problem (1) with relations left of or above. They consisted
of fruits (kiwi, mango, pear, apple, peach). The participants
read the four premises self-paced in a sequential order. Each
premise was displayed in the center of the screen and disappeared before the next premise was shown. For each problem
one of six models (written out fruit names) was presented,
three valid and three invalid one. The participants were asked
to decide whether the offered model was a consistent model
of the previous premises. The models were designed in different ways: (1) to (3) are consistent models, which are con(1)
(2)
(3)

Figure 5: Model variation algorithm. The exchange method
exchanges an object according to the given premise and conclusion to find a counter-example. The object is exchanged
until the ’anchor’ object is reached, ¿from there it recursively
proceeds with the anchor and so on.
right Y right G
R

Y

O

G

right G

right Y
R

Y

G

B

O

B

right Y right G
R

Y

G

B

O

RYOGB
RYGOB
RYGBO

(4)
(5)
(6)

ROYGB
RGOYB
BYOGR

Figure 7: Models presented in experiment.
structed corresponding to (1) the fff-principle (PMM), (2)
a mixture of the fff- and the ff-principles, and (3) the ffprinciple. The models (4) to (6) are inconsistent models with
an exchange in (4) the second an third term (near exchange),
(5) in the second and fourth term (middle exchange) and (6)
in the first and last term (far exchange). 21 participants from
the University of Freiburg took part in the experiment.

The first line shows the constructed PMM. The bold
marked objects are varied to
check a conclusion. The second
line shows a mix-model, the
third a ff-model (first fit), which
occur through the variation
process.

Figure 6: The variation process.
(2)

A is left of C and B is left of A
B is left of C and D is left of B
A is further away from C than B is from A
Who is closer to the empty lane, B or A?

which results in the model: D B A C
The third premise yields the allocation to the lanes. They
tested two kinds of the third premise: (i) A is further away
from C than B is from D. (ii) B is further away from C than D
is from A. The third premise yields the allocation to the lanes.
The answer in both cases is that A is closer to the empty lane
than B. The difficulty has been explained as the number of individuals to be simultaneously integrated (hence (i) is easier
than (ii)). The authors introduced the principle of integration
to explain this effect. But is this really necessary? The result
can be explained in terms of the number of necessary operations. We show the computations of the CR OS (for (ii)): First
the distance between D and A (with the focus) is measured
and stored (dist.:2). Then the focus searches for object B and
then counts the steps to get from B to C. After that the focus
moves object C one position to the right. The focus needs 5
operations more for (ii) than for (i).
Testing the CR OS . How does the variation phase work?
The CR OS predicts a continuous transformation which starts
from the PMM. This prediction is now tested empirically.
Material, Procedure, and Participants. We designed
20 indeterminate 5-term series problems with 4 premises of

Figure 8: Experimental results of 5-term series problems.
Results and Discussion. We analyzed the accuracy and reaction times for the offered models. We summarize only the
main findings, for a full report see (Ragni, Fangmeier, Webber, & Knauff, 2006b). The participants which had to validate
models congruent with the fff-principle produced the highest
number of correct answers (92%) and the reaction times were
the smallest (M = 3797 ms, SD = 1640 ms). There was a decrease in both accuracy and reaction times from those models
constructed with the fff-principle to the mixed models to ffmodels (cp. Fig. 8). ¿From the construction point of view the
fff- or the ff-principle makes much more sense with regard to
simplicity and use of a single strategy compared to the mixprinciple. For the invalid models there was an increase in the
error rates from far to near exchange and the reaction times
were also longer for far and middle. As in (Ragni, Fangmeier,
Webber, & Knauff, 2006a) the results indicate that participants more likely construct a PMM (fff-principle), because
accuracy and reaction times were significantly better if they
were asked to validate a PMM. The results indicate that participants construct first the PMM out of the premises (following the fff-principle), and since it is easier to construct, than

1419

the mix-model and than the ff-model, the accuracy and reaction times were better in the mixed case than in the ff-case.
The results of the CR OS are confirmed: less operations are
necessary to transform the PMM into the mix-model than to
transform the PMM into the ff-model (cp. Fig. 6).

General Discussion
The preferred mental model theory as well as Baddeleys
WMM can explain several of empirical results in spatial reasoning. But both theories have not yet been brought together
or been formalized. Since human reasoning is based on mental operations as well as on mental structure, only a cognitive as well as formal model, comprising both aspects, is able
to explain intra- and inter-individual differences. This is the
starting point for our investigation and formalization of both
theories. By benchmarking the resulting cognitive model on
experimental results from the literature we could show that
the CR OS 2 is able to cover a wide span of effects, from preference effects to relational complexity effects (Ragni & Steffenhagen, 2007). More important, several CR OS -predictions
like the insertion principle (fff-principle) and the continuous
transformation process have been empirically validated in human experiments (Ragni & Steffenhagen, 2007). Our symbolic approach has not yet covered the property that objects
can have different activation levels. It seems reasonable to
import the activation function from ACT-R. Can we determine, starting from the formalization of the data structure and
for a given (solvable) problem, computational properties of
the Central Executive? Take for instance problem (2) (Ragni
et al., 2006a). How is the query A as near to D as C is near to
E to be processed and where is this information stored? Partcipants explained that they used a divide-and-conquer strategy to solve this problem. That first the distance between A
and D is determined and than the distance between C and E
and then both distances have to be compared. Numeric information is generally not assumed to be stored in the VSSP,
and since the PL is a mere rehearsal process , where information can be stored but not manipulated, the memory system
in which this information is stored and manipulated remains
unclear. It seems reasonable that in the Central Executive
two operating cells in which incremental operations (+1) and
comparisons (<, =, >) take place can be assumed. This existence is implicitly assumed in (Lemair, P. and Abdi, H. and
Fayol, M., 1996). Such implications of an algorithmic formalization of BWMM are to be investigated next.

Acknowledgements
This work was partially supported by the Deutsche
Forschungsgemeinschaft (DFG) as part of the Transregional
Collaborative Research Center SFB/TR 8 Spatial Cognition.
We thank Markus Knauff and Bernhard Nebel for various
helps. We also owe thanks to the anonymous reviewers for
their helpful comments.

References
Baguley, T. S., & Payne, S. J. (1999). Memory for spatial
descriptions: A test of the episodic construction trace hypothesis. Memory and Cognition, 27.
Bara, B., Bucciarelli, M., & Lombardo, V. (2001). Model theory of deduction: a unified computational approach. Cognitive Science, 25, 839-901.
Byrne, R. M., & Johnson-Laird, P. N. (1989). Spatial reasoning. Journal of Memory & Language, 28(5).
Goodwin, G. P., & Johnson-Laird, P. N. (2005). Reasoning
about relations. Psychol Rev, 112(2).
Halford, G. S., Wilson, W. H., & Phillips, S. (1998). Processing capacity defined by relational complexity: implications
for comparative, developmental, and cognitive psychology.
Behavioural Brain Sci, 21.
Johnson-Laird, P. N. (2001). Mental models and deduction.
Trends in Cognitive Sciences, 5(10).
Johnson-Laird, P. N., & Byrne, R. M. J. (1991). Deduction.
Hove (UK): Erlbaum.
Knauff, M., Mulack, T., Kassubek, J., Salih, H. R., & Greenlee, M. W. (2002). Spatial imagery in deductive reasoning:
a functional MRI study. Cognitive Brain Research, 13(2),
203-12.
Knauff, M., Rauh, R., Schlieder, C., & Strube, G. (1998).
Continuity effect and figural bias in spatial relational inference. In Proc. of the 20th cogsci conf. Erlbaum.
Lemair, P. and Abdi, H. and Fayol, M. (1996). The Role of
Working Memory in Simple Cognitive Arithmetic. European Journal of Cognitive Psychology, 8(1), 73-103.
Manktelow, K. (1999). Reasoning and Thinking. Hove: Psychology Press.
Miller, G. A., & Johnson-Laird, P. N. (1976). Language and
perception. Cambridge: Cambridge University press.
Ragni, M., Fangmeier, T., Webber, L., & Knauff, M. (2006a).
Complexity in spatial reasoning. In Proceedings of the 28th
annual cognitive science conference. Erlbaum.
Ragni, M., Fangmeier, T., Webber, L., & Knauff, M. (2006b).
Preferred mental models: How and why they are so important. In Spatial cognition V. Berlin: Springer.
Ragni, M., Knauff, M., & Nebel, B. (2005). A Computational Model for Spatial Reasoning with Mental Models.
In B. Bara, L. Barsalou, & M. Bucciarelli (Eds.), Proc. of
the 27th CogSci. Erlbaum.
Ragni, M., & Steffenhagen, F. (2007). A cognitive computational model for spatial reasoning. In Aaai spring symposium 2007. AAAI Press; Menlo Park, CA.
Rauh, R., Hagen, C., Knauff, M., T., K., Schlieder, C., &
Strube, G. (2005). Preferred and Alternative Mental Models in Spatial Reasoning. Spatial Cog. and Comp., 5.
Vandierendonck, A., Dierckx, V., & Vooght, G. D. (2004).
Mental model construction in linear reasoning: Evidence
for the construction of initial annotated models. The
Quarterly Journal of Experimental Psychology, 57A, 13691391.

2 Further information and an implementation can be found at
http://gkiweb.informatik.uni-freiburg.de/∼srm

1420

