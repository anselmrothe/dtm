UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Integrating Perceptual Organization and Attention: A New Model For Object-Based Attention

Permalink
https://escholarship.org/uc/item/2s13r557

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Author
Jarmasz, Jerzy P

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Integrating Perceptual Organization and Attention:
A New Model For Object-Based Attention
Jerzy P. Jarmasz (jjarmasz@ccs.carleton.ca)
Cognitive Science Program and Centre for Applied Cognitive Research,
Carleton University, Ottawa, Canada, K1R 7W9
Abstract
Recent research shows that, under certain conditions, visual
attention is object-based. That is, attention preferentially
selects objects in the visual field. These objects are processed,
culminating in object recognition. On this formulation, the
objects selected by attention are perceptual groups determined
by the principles of perceptual organization of Gestalt
psychology. These groups are formed independently of
attentional processes and conceptual knowledge. This view is
not consistent with available data about the visual system,
which shows that perceptual organization is sensitive to
conceptual information, depends on attentional processes, and
infers representations that best explain the visual stimulus.
Here, I propose a new account of visual attention that aims to
correct these limitations of the Gestalt-based formulation. The
nature of the object representations underlying perceptual and
attentional mechanisms is discussed. It is proposed that
attention and perception interact in an iterative process
wherein constraints imposed both by the visual stimulus and
an observer’s cognitive set determine the “objects” to which
attention is allocated. Thus, visual attention is object based
precisely because it is intricately involved in perceptual
organization, and not because it selects the output of
perceptual organization, as is generally claimed. Experimental
results that support the claim that attention influences
perceptual organization are reviewed. Finally, the
implications for human factors research and the metaphysics
of everyday objects are discussed.

Introduction
Vision is generally assumed to have the functions of
identifying, locating, and directing action towards objects
(Solso, 1996). It is also assumed that the visual system
requires attentional mechanisms to limit the amount of
sensory information it processes (Fernadez-Duque &
Johnson, 1999). Thus, awareness of objects in the
environment is supposed to result from a series of
processing stages that select sensory information and then
construct representations of objects by extracting
regularities from the visual stimulus and matching them to
patterns in memory (Palmer, 1999).
It was first assumed that visual attention selects certain
regions of the visual field, much the way a spotlight
illuminates part of a stage and leaves the rest in the dark.
Accordingly, this model is known as the spotlight model of
visual attention (Fernandez-Duque & Johnson, 1999). On
this model, attention is first directed to a region of the visual
field, and only the information within that region is
processed for object identification. This assumption was

questioned when researchers observed that people respond
to visual features that belong to a single object more quickly
and accurately than when the features belong to two objects
(Duncan, 1984; Treisman, Kahneman & Burkell, 1983).
Subsequent research confirmed that it is usually easier to
process information within a single object than across
objects (Lavie & Driver, 1996). These findings have lead to
the object-based model of visual attention (Duncan, 1984;
Lavie & Driver, 1996). It is now generally recognized that
the spotlight and the object-based models capture
complementary aspects of visual attention (Driver & Baylis,
1998).
It is undeniable that information can be processed more
readily within one object than across many (Lavie & Driver,
1996; Driver & Baylis, 1998). However, the object-based
explanation for this difference in processing efficiency is
problematic. Cognitive psychologists generally distinguish
between spatio-temporally bounded physical objects and the
mental representations of these objects. Physical objects
correspond to what philosophers call concrete particulars
(Loux, 1998), and will subsequently be referred to as cobjects. Similarly, the mental representation of visual
objects will be henceforth referred to as p-objects (for
“phenomenological” objects). The generally accepted story
about object perception is that the visual system constructs
p-objects, which represent c-objects via various perceptual
and cognitive processes. Researchers who accept the objectbased model contend that attention selects “objects” for
further processing. Which objects are these – p-objects or cobjects? P-objects are supposed to be the end product of
visual processing (Solso, 1996), so attention must
presumably be engaged prior to the construction of pobjects. However, the alternate claim that attention directly
processes c-objects themselves instead of sensory input is
nonsense. Most researchers assume the visual system first
constructs low-level representations of c-objects, based on
the physical properties of the stimulus. These
representations are then elaborated into p-objects by higherorder visual and conceptual processes (Hoffman, 1998;
Palmer, 1999). These low-level representations will be
referred to as a-objects (for “attentional objects”). The
object-based model can be restated thus: Visual attention
selects a-objects, which are passed on to higher visual
processes for elaboration into p-objects, which are
representations of c-objects.
Philosophers are actively studying the nature of c-objects
(see Loux, 1998) and perceptual psychologists are

researching p-objects (e.g. see Biederman, 1995, and
Kosslyn, 1995). But the notion of a-object implicit in
object-based attention is still poorly defined. Most
researchers take a-objects to be perceptual groupings based
on the Gestalt principles of perceptual organization (Driver
& Baylis, 1998), according to which observers perceive the
details of a scene only as parts of global patterns. Perceptual
organization was thought to conform to the general principle
of figural goodness, or Prägnanz (Koffka, 1935). Figural
goodness was exemplified in a number of specific principles
(e.g., figure-ground, grouping by similarity, good
continuation, closure, and common fate; Palmer, 1999).
However, this view of a-objects is inadequate.
Cognitive scientists tend to assume that cognitive
processing occurs in discrete stages, as first proposed by
Sternberg (1969), until evidence forces them to think
otherwise. Accordingly, researchers studying object-based
attention have typically assumed that perceptual grouping,
in the form of Gestalt grouping, occurs at a processing stage
that is independent of, but feeds into, attentional processes,
and that the product of attentional selection are independent
of, but feed into, object recognition processes (Feldman,
1999). This view is problematic on two counts: first, the
evidence that perceptual organization occurs prior to, and
independently of, visual attention is not definitive. Second,
the Gestalt account of perceptual organization itself has
many shortcomings. Let us examine these two issues in
turn.

Attention and Perceptual Organization
Mack, Tang, Tuma, Kahn and Rock (1992) and Rock,
Linnett, Grant and Mack (1992) have presented results that
suggest that perceptual organization does not occur without
attention. They had participants perform a task that engaged
their attention (typically, judging the relative length of the
branches of a cross) while varying the background on which
the main stimulus was displayed. Most trials had either a
blank or a random background, but each participant also
saw three (non-consecutive) trials where the background
contained a ‘critical stimulus’, either a single shape or
formed some Gestalt grouping. On the first critical trial,
most participants reported not seeing the Gestalt grouping or
not perceiving the shape or size of the lone object. On the
second critical stimulus trial, participants were generally
more successful in detecting the Gestalt group or the object.
On third critical stimulus trial, participants were asked to
report on the background stimulus only, generally with
nearly perfect results.
Mack et al. (1992) and Rock et al. (1992) assumed that on
the first critical stimulus trial, participants were not
expecting to see anything of import in the background, and
thus focused all of their attention on their primary task,
whereas on the second and third critical stimulus trials, they
implicitly allocated some or all of their attention to the
background pattern. Accordingly, they interpreted their
results to mean that perceptual organization cannot occur
without attention. Ben-Av, Sagi and Braun (1992) reported

a similar study where participants had difficulty identifying
background Gestalt groupings as their primary visual task
became more demanding.
The results just discussed are not conclusive, however, as
they cannot rule out that participants were merely unable to
remember or encode the ‘unattended’ stimuli rather than
failing to perceive them at all. Evidence along these lines is
provided by Moore and Egeth (1997)1. In a series of
experiments, they had subjects judge the relative length of
two parallel horizontal lines while varying the background.
On half the trials the background consisted of random black
and white dots, while on the other half, the background
together with the two lines (now identical in length) formed
the well-known Ponzo and Müller-Lyer illusions through
the Gestalt principle of grouping by similarity. Participants
reliably responded in a manner consistent with the illusions
(i.e. reporting that the appropriate line was longer), even
though the vast majority of them were not aware of seeing
the background pattern. What is crucial here is that
processing the background pattern is necessary for the
illusion to influence participants’ responses. The conclusion
is that participants perceived the right background grouping
even though they had no awareness of having done so.
Do the results of Moore and Egeth (1997) establish that
perceptual organization does not require attention? Not
necessarily. Moore and Egeth (1997) had each participant
view the displays with the illusions 16 times while they
performed the line-comparison task, whereas Mack et al.
and Rock et al. tested their participants’ awareness of the
background patterns after only the first time each participant
saw the pattern. It is possible that Moore and Egeth’s
participants learned implicitly and unconsciously that the
background was informative and divided their attention
between the primary and the secondary stimuli.
Furthermore, they report that once the participants were
aware of the Ponzo illusion, their performance of the linejudgment task dropped to chance levels, suggesting that the
illusion was no longer effective (this pattern did not obtain
with the Müller-Lyer illusion). Thus, for the Ponzo illusion
at least, attention does play a role in perceptual organization.

Beyond Gestalt Grouping Principles
Taken together, the results from Mack et al. (1992), Moore
and Egeth (1997) and Rock et al. (1992) suggest that
attention can influence perceptual organization. Gestalt
theory offers no way of accounting for this, as on this view
perceptual grouping is largely determined by stimulus
properties. Palmer (1999) and Pomeranz and Kubovy (1986)
have pointed out further problems for the Gestalt view.
First, the Gestalt principles don’t distinguish between
objects and groups of objects. Also, Gestalt principles
ignore the role of top-down, general-purpose knowledge in
perceptual organization. For instance, the Gestalt principles
cannot explain why people who don’t know that Figure 1 is
1

I would like to thank the anonymous reviewer who brought this
to my attention.

a picture of a Dalmatian usually fail to see any meaningful
pattern in the image, whereas people who are aware that the
image represents a dog not only find the dog easily but also
organize the stimulus so that otherwise indistinguishable
black dots become a dog, a sidewalk, and the shade beneath
a tree.

Figure 1: Spot the Dalmatian!
In order to address these problems, an account of
perceptual organization must do two things: it must show
how perception and attention interact to form a-objects, and
it must show how general-purpose conceptual knowledge
can participate in the formation of a-objects without
requiring full object recognition. Both of these objectives
could be facilitated by construing perceptual organization as
Inference to the Best Explanation (IBE), whereby where the
visual system infers three-dimensional structures which best
explain the retinal image (Hoffman, 1998; Leyton, 1992;
Feldman, 1999) 2. IBE is an appealing account of human
explanatory practice in general, but it suffers from the defect
that explanatory ‘goodness’ has not yet been properly
defined (Lipton, 1991). Nevertheless, vision researchers
provide some candidates for goodness criteria in perceptual
inference. Albert and Hoffman (1995), Feldman (1999), and
Pomerantz and Kubovy (1986) have suggested that visual
inference is overarchingly guided by the principle of
genericity. That is, the visual system assumes, in the
absence of other data, that the retinal image is a generic
view of three-dimensional objects, rather than a very
specific and “accidental” view of some other set of threedimensional objects. A generic view is a two-dimensional
projection of a three-dimensional structure that does not
entail special or accidental circumstances in the projection.
For instance, a straight line in the retinal image is a generic
view of a straight edge in the environment, but would be a
non-generic view of a curved edge that just happens to be
seen head-on. The genericity principle can account for a
large number of phenomena of perceptual organization.
Furthermore, Pomerantz and Kubovy (1986) show that the
Gestalt principles can and should be reinterpreted as
instances of the genericity principle.
The notion of genericity can be extended to explain the
role of conceptual knowledge in perceptual organization.
Assuming an observer expects to see a Dalmatian in Figure
2

This does not necessarily imply deliberate, conscious inference.

1, the splotches obviously form a generic view of the dog.
Whereas, if the splotches corresponded to a horse, it would
have to be either a typical horse seen under very specific
shading conditions, or a strangely Dalmatian-like horse seen
under normal viewing conditions. “Explaining” the image as
that of a horse would require invoking a number of special
circumstances, which interpreting the image as that of a
Dalmatian does not. The visual system might thus limit the
conceptual information involved in constructing a-objects to
knowledge of generic views and expectations about which
objects are present in a scene.
A-objects can now be re-defined: An a-object is a
representation of the three-dimensional structure that best
explains the two-dimensional retinal stimulus according to
the genericity principle, which takes into account both
physical stimulus properties and general-purpose conceptual
knowledge.
Although the Dalmatian example demonstrates the role of
semantic information in perceptual organization, it remains
to be shown that a-objects as defined above actually play a
role in object-based attention. The following section
presents some recent experimental evidence bearing on this
issue from our laboratory.

Recent Evidence for the Involvement of
Attention in Perceptual Organization
A first line of evidence for the role of attention in perceptual
organization comes from recent studies on object-based
attention using moving stimuli (Jarmasz, 2001; Jarmasz,
Herdman & Johannsdottir, in preparation). In these
experiments, participants were shown a display consisting
of two groups of identical dots. One set of dots was static,
while the dots in the second group moved in unison in an
elliptical trajectory that overlapped the location of the static
dots. During each trial, two of the dots in the display
changed color from light gray to one of two colors (either
red and green, or blue and yellow). The target dots were
located both in the static group, both in the moving group,
or one in each group. Participants were required to
determine whether the target dots were the same color. On
some trials participants had to focus their attention on only
one group of dots, while in other trials they had to spread
their attention to the display as a whole, and avoid focusing
on a specific group. When participants attended to the whole
display, they responded significantly faster to target dots
displayed within a single group than to targets appearing
across both groups. The results were consistent with those
found in the object-based attention literature using static
displays (e.g. see Lavie & Driver, 1996; Treisman et al.,
1983). However, when participants focused on only one of
the groups, their responses were faster when both targets
appeared in the attended group, and slowest when targets
appeared either in the unattended group only or across
groups. A comparison of response latencies across
attentional focus conditions suggests that focused attention
inhibits information processing of unattended stimuli rather
than enhancing processing of attended stimuli relative to

situations where attention is deployed across the whole
display. In all attentional focus conditions, both groups of
dots overlapped in the display, so foveal limitation on visual
acuity likely do not account for these results. Rather, they
suggest that deliberate attentional allocation strategies
influence the degree to which multiple perceptual groups are
perceived as being separate from the others, or conversely
as being part of a larger whole. This is consistent with the
proposal above that a-objects depend on attentional factors
as well as bottom-up stimuli properties.
A second line of evidence implicating attention in
perceptual organization comes from a study using static
visual objects (Jarmasz, 2002). In this study, participants
were shown a display based on one used by Lavie and
Driver (1996) consisting of two intersecting dashed lines.
On each trial, two of dashes were replaced by two target
elements, either a shorter dash or a gap (absence of a dash).
The target elements could appear either near to each other
on separate lines (‘near’ condition), far from each other on
separate lines (‘far’ condition) or far from each other but on
the same line (‘object’ condition). On half the trials, both
dashed lines were the same color (either pink or yellow),
whereas in the other trials each line was a different color. In
all cases, participants responded most quickly to targets in
the object condition, even though they were approximately
seven times further apart in the object condition than in the
near condition, thus replicating the effect found by Lavie
and Driver (1996). When the dashed lines were of different
colors, participants were equally slow in responding to
targets in the near and far conditions relative to the object
condition. However, when both lines shared a common
color, participants responded more quickly to targets in the
far condition than in the near condition (responses to targets
in the object condition were still fastest overall). This
suggests that in the same color condition, participants parsed
the display either as two separate lines or as one large
figure, depending on the location of the targets. These
results further suggest that observers can implicitly acquire
top-down attention allocation strategies that affect the
perceptual organization of a stimulus from bottom-up cues
(color & target location).
The two studies described above show that attention can
be deployed, either implicitly or explicitly, so as to
influence perceptual organization. The results of these two
studies are inconsistent with the spotlight model of visual
attention, in which spatial separation, but not shape, affects
how quickly two stimuli are compared. However, the
“standard” object-based attention model cannot account for
these results either, as on this model perceptual grouping is
assumed to be preattentive, and thus impervious to changes
in attentional allocation strategies. An adequate account of
visual attention and object perception will have to explain
both how perceptual organization can affect attention (i.e.
object-based attention) and how attention can affect
perceptual organization. The next section presents such a
model.

Towards a New Theory of Object-Based
Attention
Current accounts of object-based attention do not reflect the
reciprocal influences between attention and perceptual
organization. Consequently, I propose a new account, the
Inferential Attentional Allocation Model (IAAM; Jarmasz,
2001). Briefly, on this model attention and perceptual
organization interact to incrementally build up
representations of c-objects. Potential a-objects are
constructed from regions of uniform color, luminance, and
texture, and edge-bound surfaces in the visual stimulus
(Palmer, 1999). These potential a-objects represent rival
hypotheses as to the 3-D structures in the environment, and
lack detail. A-objects are refined through cycles of
grouping and selection (Grossberg, Mingolla & Ross, 1994).
At each cycle, attention selects a-objects that best satisfy
both genericity and cognitive set (i.e., an observer’s
perceptual expectations and general-purpose knowledge).
This progressively liberates resources for generating more
detailed a-objects that better “explain” the retinal image. If
this process is interrupted before it culminates in stable aobjects, an observer may fail to perceive a c-object (Di
Lollo, Enns, and Rensink, 2000, have found evidence for
such a phenomenon). Figure 2 depicts these iterative
processes.
The IAAM is a heuristic (i.e., exploratory) model. Even
so, it allows for the following predictions: (1) stimulusdependent, bottom-up information constrains possible aobjects in the scene, and as well as how much attentional
resources the stabilization of particular a-objects will
require; and (2) conceptual, top-down knowledge acts to
determine which a-objects will eventually become stable
and become p-objects. Thus, bottom-up properties of a
stimulus should determine how “easy” it is to perceive
certain objects, i.e., how much attention perceiving those
objects will require and how efficient the processing will be.
Top-down factors will sometimes push the visual system to
organize a stimulus into more attentionally demanding
configurations which will result in less efficient processing
(reflected either in slower processing or more interference
from other stimuli). The experiments reported above are
largely consistent with these hypotheses. Common motion
(a bottom-up factor) makes the segregation of a stimulus
into distinct objects possible, but the intention to pick out
one of these objects (top-down) enhances the processing of
that object at the expense of processing information from
other objects (Jarmasz, 2001; Jarmasz, Herdman &
Johannsdottir, in preparation). Similarly, collinearity and
common color (bottom-up) facilitate the segregation of two
dashed lines into two objects, but implicit task demands
(top-down) seem to determine whether the two lines are
actually parsed as one large figure or two lines (Jarmasz,
2002)
Further work is needed to elaborate and test the IAAM.
Namely, the notions of ‘ease’ of perceptual grouping and of
efficiency of visual processing need to be operationally
defined. Nevertheless, one can imagine how the IAAM

Visual stimulus
Successive
iterations

IBE

GENERALPURPOSE
KNOWLEDGE

GENERICITY

Progressive
grouping and
selection
A-objects

P-objects

Figure 1: Grouping and selection processes in the IAAM
might apply to “real world” stimuli. For instance, if
someone intends to move a box with a lid from a table to the
top shelf of a bookcase, they will form a single a-object
corresponding to the box and its lid. If, however, that person
wants to open the box, they will form two a-objects, one for
the lid and one for the box. On this view, a-objects are
interest-relative; that is, a-objects depend on an observer’s
goals and general-purpose conceptual knowledge, in
addition to bottom-up stimuli. This is in contrast to the
standard view, where a-objects are defined purely by
stimulus properties.

Conclusion: Some Implications of the IAAM
The object-based model of attention is currently based on
the assumption that visual attention selects perceptual
groups that are formed preattentively according to the
Gestalt grouping principles. This conceptualization of visual
attention does not reflect the reciprocal influences between
perceptual organization and attention, and further ignores
the role of top-down information in perceptual organization.
Moreover, this formulation is limited in its ability to guide
human factors research, where broad principles are often
lacking and problems often require ad-hoc solutions. A
growing body of experimental evidence supports the notion
that while attention is influenced by perceptual organization,
it in turn influences whether and how perceptual
organization occurs as well. Consequently, a new model of
object-based attention, the Inferential Attentional Allocation
Model, is proposed which attempts to capture the interaction
between attention and perceptual organization. On this
model, visual attention is object based not because attention
selects objects, but rather because attention itself is
indispensable to perceptual organization.
The IAAM is a heuristic model. In addition to providing a
framework for developing a comprehensive account of
visual attention, the IAAM also has potentially significant
implications both for human factors research and for the
metaphysics of concrete particulars. Regarding research on
human factors, the IAAM shows that strategies for
deploying attention interact both with visual stimuli and

with task demands. Thus, the design of graphical user
interfaces such as desktop computer applications and headup displays in aircraft and automobiles should take into
account how a user’s cognitive and attentional sets might
interact with the display.
The IAAM shows that what counts as an object for the
visual system depends intimately on an observer’s goals and
expectations. This reminds us that in a larger sense,
everyday objects are embedded in a complex web of human
activities and conventions. Standard metaphysical theories
generally attempt to define concrete particulars without any
reference to the agents that use and perceive them (e.g., see
Loux, 1998). However, assuming that at least the broad
lines of the IAAM are a valid account of object-based
attention, what counts as an object for us as agents also
depends on our expectations, intentions and general
background knowledge. The criteria of “objecthood” might
ultimately depend as much on epistemic issues as on
metaphysical ones, as suggested by Smith (1996). Attention
is object-based not only because attention and perceptual
organization are mutually dependent, but also because
objects would not be objects if we did not perceive them as
such, but merely relatively coherent portions of the
spatiotemporal flux we call the universe.

Acknowledgments
I am grateful to C. Herdman, A. Brook, A. Vellino, J.
LeFevre, R. West, S. Scott and A. Pyke for their helpful
feedback. L. Jerzykiewicz and two anonymous reviewers
provided valuable comments on a previous version of this
paper that was presented at the Graduate Student
Conference on Philosophy of Mind, Philosophy of
Language, and Cognitive Science at Carleton University,
Ottawa, Canada on September 29, 2001. L. Stelmach of the
Communications Research Centre in Ottawa, Canada was
most helpful with technical support in the early stages of
this research. Thanks go to K. Johannsdottir and J. Shaw for
their help with conducting various experiments. This
research is funded by the Centre for Research in Earth and
Space Technology, the Natural Sciences and Engineering

Research Council of Canada, CMC Electronics, the HFE
Group, the Aviation and Cognitive Engineering Laboratory
at Carleton University, and Neptec.

References
Albert, M. K., & Hoffman, D. D. (1995). “Genericitiy in
spatial vision.” In R. D. Luce, M. D’Zmura, D. D.
Hoffman, G. J. Iverson, & A. K. Romney (Eds.),
Geometric representations of perceptual phenomena.
Mahwah, NJ: Erlbaum.
Ben-Av, M. B., Sagi, D., & Braun, J. (1992). “Visual
attention and perceptual grouping.” Perception &
Psychophysics 52: 277-294.
Biederman, I. 1995. “Visual object recognition.” In S. M.
Kosslyn and D. N. Osherson (Eds.), An Invitation to
Cognitive Science (Second Edition), Volume 2.
Cambridge, MA: MIT Press.
Di Lollo, V., Enns, J. T., & Rensink, R. A. (2000).
“Competition for consciousness among visual events: The
psychophysics of reentrant visual processes.” Journal of
Experimental Psychology: General 12: 481-507.
Driver, J., & Baylis, G. C. (1989). “Movement and visual
attention: The spotlight metaphor brakes down.” Journal
of Experimental Psychology: Human Perception and
Performance 15: 448-456.
Driver, J., & Baylis, G.C. (1998). “Attention and visual
object segmentation.” In R. Parasuraman (Ed.), The
Attentive Brain. Cambridge, MA: MIT Press.
Duncan, J., (1984). “Selective attention and the organization
of visual information.” Journal of Experimental
Psychology: General 113: 501-517.
Feldman, J. (1999). “The role of objects in perceptual
grouping.” Acta Psychologica 102: 137-163.
Fernandez-Duque, D., & Johnson, M. L. (1999). “Attention
metaphors: How metaphors guide the cognitive
psychology of attention.” Cognitive Science 23: 83-116.
Grossberg, S., Mingolla, E., & Ross, W. D. (1994). “A
neural theory of attentive visual search: interactions of
boundary, surface, spatial and object representations.”
Psychological Review 101: 470-489.
Hoffman, D. D. (1998). Visual Intelligence. New York: W.
W. Norton & Company.
Jarmasz, J. (2001). Towards the Integration of Perceptual
Organization
and
Visual
Attention:
The
Inferential Attentional Allocation Model. Carleton
University Cognitive Science Technical Report
2001-08. URL http://www.carleton.ca/iis/TechReports.
Jarmasz, J (2002). Brief report on the effects of color and
target location in the Lavie and Driver object-based
attention paradigm. Cognitive Science Technical Report
2002-01. URL http://www.carleton.ca/iis/TechReports.
Jarmasz, J. Herdman, C. M., Johannsdottir, K. R. (in
preparation). Object-based attention and cognitive
tunneling with heads-up displays in aircraft.
Koffka, K. 1935. Principles of Gestalt Psychology. New
York: Harcourt, Brace & World.

Kosslyn, S. M. (1995). “Mental Imagery.” In S. M. Kosslyn
and D. N. Osherson (Eds.), An Invitation to Cognitive
Science (Second Edition), Volume 2. Cambridge, MA:
MIT Press.
Lavie, N. & Driver, J. (1996). “On the spatial extent of
attention in object-based visual selection.” Perception &
Psychophysics 58: 1238-1251.
Leyton, M. (1992). Symmetry, Causality, Mind. Cambridge,
MA: MIT Press.
Lipton, P. (1991). Inference to the Best Explanation.
London: Routledge.
Loux, M. J. (1998). Metaphysics: A Contemporary
Introduction. London: Routledge.
Mack, A., Tang, B., Tuma, R., Kahn, S., & Rock, I. (1992).
“Perceptual organization and attention.” Cognitive
Psychology 24: 475-501.
McLeod, P., Driver, J., Dienes, Z., & Crisp, J. (1991).
“Filtering by movement in visual search.” Journal of
Experimental Psychology: Human Perception and
Performance 17: 55-64.
Moore, C. M., & Egeth, H. (1997). “Perception Without
Attention: Evidence of Grouping Under Conditions of
Inattention.” Journal of Experimental Psychology:
Human Perception and Performance 23: 339-352.
Palmer, S. E. (1999). Vision Science: Photons to
Phenomenology. Cambridge, MA: MIT Press.
Pomerantz, J. R., & Kubovy, M. (1986). “Theoretical
approaches to perceptual organization.” In , K. R. Boff, L.
Kaufman, and J. P. Thomas (Eds.), Handbook of
Perception and Human Performance, Volume II. New
York, NY: John Wiley & Sons, Inc.
Rock, I., Linnett, C. M., Grant, P., & Mack, A. (1992).
“Perception without attention: Results of a new method.”
Cognitive Psychology 24: 502-534.
Smith, B. C. (1996). On the Origin of Objects. Cambridge,
MA: MIT Press.
Sternberg, S. (1969). Memory-scanning : Mental processes
revealed by reaction-time experiments. In American
Scientist, 57, 421-457.
Solso, R. L. (1996). Cognition and the Visual Arts.
Cambridge, MA: MIT Press.
Treisman, A., Kahneman, D., & Burkell, J. (1983).
“Perceptual objects and the cost of filtering.” Perception
& Psychophysics 33: 527-532.

