UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Do people update spatial relations described in texts?

Permalink
https://escholarship.org/uc/item/1zj1f6xm

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Author
Avraamides, Marios N

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Do People Update Spatial Relations Described in Texts?
Marios N. Avraamides (Marios@Psu.Edu)
Department of Psychology,
The Pennsylvania State University
604 Moore Building
University Park, PA 16801 USA
Abstract
Previous studies (e.g., Rieser, 1989) have established
that physical rotations result in effortless updating of
spatial information contained in visually perceived
scenes. The present experiment provided evidence that
this is not the case for scenes that are encoded through
texts. Performance was better under the perspective that
the scenes were learned than under novel perspectives,
regardless of whether rotations were physical or
imagined. In addition, the experiment suggested that the
orientation of the ecological frame affects spatial
performance even when people operate in a purely
represented framework.

Introduction
Various studies (e.g., Chance, Gaunet, Beall, &
Loomis, 1998; Klatzky, Loomis, Beall, Chance, &
College, 1998; Rieser, Guth, and Hill, 1986; Simons &
Wang, 1998; Wang & Simons, 1998) have established a
link between active locomotion and the successful
spatial updating of previously viewed scenes.
Researchers have proposed that spatial updating is
carried out by an internal mechanism that constantly
computes the relative locations of objects as people
move in the environment (Wang & Spelke, 2000).
Indeed, when people change their position within an
environment they seem to experience little difficulty
with keeping track of how the locations of objects
change, even when the objects are no longer in view
(Attneave & Farrar, 1977; Fukusima, Loomis, & Da
Silva, 1997; Loomis, Klatzky, Colledge, Cicinelli, and
Pellegrino, 1993). In fact, responding to locations of
objects after locomoting to a new position is no more
difficult than doing so from the original standpoint
(Rieser, 1989; Rieser et al., 1986). However, difficulties
arise when judgments are made from perspectives that
are imagined (Presson & Montello, 1994). For example,
Rieser has shown that pointing to objects from a novel
standpoint is slower and less accurate when the
observer mentally rotates to the new standpoint than
when she is physically rotated to it.
In short, the evidence suggests that moving
organisms update their representations of their
surroundings in an efficient and effortless manner.
However, non-moving organisms need to engage in
additional mental processing in order to reason about
their surroundings from imagined standpoints.

The majority of the previous studies have examined
spatial updating with paradigms that involved visually
presented stimuli. Visual perception is not, however,
the only way we form mental representations of the
world. Very often, we learn about space by reading or
listening to verbal descriptions. A number of studies
(e.g., Denis & Cocude, 1989) have shown that at least
in terms of geometrical properties, mental
representations constructed from language are
equivalent to those created through perception. In
general, mental representations of space seem to
preserve many of the characteristics of real
environments (Zwaan & Radvanksy, 1998).
An interesting issue that arises is whether mental
representations derived from text are updated when
changes in the spatial relations come about. A study by
De Vega and Rodrigo (2001) attempted to provide an
answer to this question by contrasting how easily
people locate objects after physical and imagined
rotations. In that study, participants first read sentences
that described spatial layouts in which objects were
located at each of the four canonical horizontal
directions from a protagonist. The protagonist was then
described to rotate to novel perspectives. The subjects
were probed with the names of the objects and were
asked to determine their locations from the perspective
of the protagonist. One group of participants performed
the task by physically rotating along with the
protagonist, while a different group performed the task
with no physical rotation. De Vega and Rodrigo
contrasted the judgment latencies of the two groups to
assess whether spatial updating took place. In one
experiment that required that subjects use spatial labels
(i.e., front, left etc) to provide their answers,
performance was equally fast for the two rotation
modes. In another experiment in which subjects pointed
to objects, performance was faster when rotation was
physical instead of imagined. De Vega and Rodrigo
concluded that physical rotations led to effortless
updating only in the pointing experiment. Furthermore,
they suggested that the actual body position of the
participant is not important for performing the task
when responses are made by using spatial labels. That
is because subjects performed the task in a represented
framework from which their actual self was disengaged.
Certain limitations of the study by De Vega and
Rodrigo (2001) create concerns regarding the

interpretation of the results. First, the absence of a
difference between physical and imagined rotation
latencies in the labeling task does not necessarily mean
that participants failed to effortlessly update their
representations. It could very well be the case that they
were successful at updating their representations under
both modes of rotation. This is quite possible given the
simplicity of the scene and its relatively low working
memory demands (only four objects needed to be
tracked). Second, although no differences were
observed in the latency measures, subjects were
significantly more accurate in their judgments with
physical rotations than with imagined rotations.
The present study uses a different measure to
examine whether spatial updating takes place under
either imagined or physical rotations. Performance
under the original perspective (i.e. the perspective from
which the scene is encoded) and novel perspectives is
contrasted in the two modes of rotation. If subjects fail
to update their original representation when they rotate
– either physically or imaginary – to a novel
orientation, then performance should be better when the
task is performed from the original than from the novel
perspectives. If any of the two modes of rotation results
in successful updating, this should be indicated by
equal performance between the original and novel
perspectives.
A second goal of the study is to examine more
closely the role – if any – of the participants’ ecological
frame in tasks that require judgments using deictic
terms. A hypothesis of the present study is that the
orientation of ecological frame affects how easily
people discriminate the two poles of an axis and map
spatial terms to the appropriate regions of space. If this
is true then the orientation of the participants’ bodies
will affect the ease of using deictic terms in the task.
This should be particularly true for judgments within
the left/right axis because our bodies provide the only
source of asymmetry for this axis. Manual dexterity is
probably the least subtle cue that people can use to
discriminate left from right (Corballis & Beale, 1976).
Therefore, the prediction is that left Vs right judgments
will be less difficult when the ecological reference
frame of the participant is aligned with the reference
frame imposed on the protagonist.

Experimental Task
The present study uses a paradigm that has been used
widely in the past to study the accessibility of directions
in spatial memory. The task, developed by Franklin and
Tversky (1990), involves the presentation of a narrative
which describes a naturalistic scene in the second
person. Objects are described occupying positions at
canonical directions from the protagonist (i.e., above, in
the front, on the left etc). Participants are given
unlimited time to study the narrative. Then, the

protagonist is described to rotate to a new orientation.
The narrative continues on a sentence by sentence
fashion with participants pressing a key to request a
new sentence. Occasionally, instead of a new sentence,
the name of an object appears. Participants are asked to
report where the object is with respect to the current
perspective of the protagonist. The task continues until
all objects are probed from various perspectives.
Studies that used this paradigm (e.g., Bryant &
Tverksy, 1992) were primarily focused on the
accessibility pattern for the various self-object
directions. Therefore, latencies from the various
protagonist perspectives were collapsed to provide a
single average value for each direction. The major
result from these studies is that objects on the
above/below axis are located faster than objects on the
front/back axis, which are in turn located faster than
objects on the left/right axis. Furthermore, objects in the
front are retrieved faster than objects at the back of the
protagonist. An account for this accessibility pattern has
been provided by the Spatial Frameworks model
(Franklin & Tversky, 1990) which posits that the scene
is represented on the basis of the three orthogonal body
axes.
The current study uses the Spatial Frameworks
paradigm to examine latency differences – if anybetween the original and the novel perspectives of the
protagonist. As in De Vega and Rodrigo (2001), a mode
of rotation manipulation is introduced. A group of
participants perform the task by physically rotating to
novel perspectives while a different group of
participants perform the task by only imagining
rotations to novel perspectives. In contrast to the
narratives of De Vega and Rodrigo, the present study
involves narratives that are somewhat more complex. In
addition to the four objects in the horizontal plane,
another two objects are described to occupy the poles of
the above/below axis. Because all protagonist
reorientations occur in the horizontal plane, the
positions of these two objects do not need to be updated
at all throughout the task,. Nevertheless, they add an
extra load on working memory, thus making the task
more cognitively demanding.
In order to examine the role of the ecological frame,
another variable is introduced. Half of the narratives
require that subjects respond with a direction judgment
(e.g., left, front etc) while in the other half they simply
need to respond with an axis judgment. In the latter
case, if for example the object is located on the left of
the protagonist, the participant only need to respond
with “left/right”. This manipulation has been previously
used with this paradigm in a study by Bryant and
Wright (1999). The rationale for including the judgment
type manipulation in the present study is that if the
ecological reference frame helps to make easier
direction judgments, then simply removing the need for
such judgments will produce the same effect.
Furthermore, if real rotations and axis judgments affect

performance in the same way, then having one of them
should be sufficient; that is, no better performance will
be observed when both of them apply instead of just
one.

Method
Participants Forty students (20 females) from
psychology classes at the Pennsylvania State University
participated in the experiment in exchange for course
credit. Ten male and 10 female participants were
randomly assigned to the physical and the imagined
rotation conditions.
Materials Four narratives, taken from those used by
Franklin and Tversky (1990) and two taken from
Bryant & Wright (1999) were used in the present study.
The first portion of the narratives described in the
second person a naturalistic scene -- a barn, a
construction site, a hotel lobby, a space museum, a
lagoon, and a navy ship –in which objects were located
at the six canonical axes of the reader-protagonist.
Narratives were modified to include 6 instead of 5
objects and in contrast with Franklin and Tversky, the
initial portions were also presented on computers. The
six critical objects in each narrative appeared in blue
upper-case characters, in contrast to the rest of the
narrative which appeared in lower-case black
characters. The order in which objects were introduced
in the initial portions of the narratives was determined
with the use of a 6 x 6Latin Square so that each object
direction appeared at a different serial position in each
narrative. For each participant, half of the narratives
were randomly assigned to the direction judgment
condition and the other half to the axis judgment
condition. Narratives were presented to participants in a
random order with the constraint that no more than 2
narratives of the same judgment type were presented in
sequence.
Design The experiment was a 2 (mode of rotation:
imagined, real) x 2 (type of judgment: direction, axis) x
2 (perspective: original, novel) x 6 (self-object
directions: above, below, front, back, left, right) mixed
factorial design. The type of rotation was manipulated
between subjects while both the type of judgment and
self-object directions varied within subjects. Each selfobject direction was tested four times in each narrative,
once under each of the four possible perspectives. Selfobject directions were tested in a random order within
each perspective. Also, the original perspective was
never the first perspective that subjects were tested on.
Procedure The procedure was similar to the one used
by Franklin and Tversky (1990). Two main differences
from De Vega and Rodrigo (2001) were that a voice
key was not used to collect responses and that the
narratives included objects located on the above/below
axis. The narratives were presented on a laptop

computer that participants held onto their laps while
sitting in a swivel chair. Participants were given
unlimited time to study the first portion of the
narratives. The narrative then continued in a sentence
by sentence fashion with subjects pressing the space bar
to request a new sentence. The second sentence after
the first portion described the protagonist rotating to a
new orientation in the horizontal plane. Depending on
the condition they were assigned to, participants were
instructed to either turn their selves by swiveling the
chair to produce the reorientations that were described
in the text, or to imagine their selves rotating without
changing their actual orientation at any point
throughout the experiment. After two filler sentences
were presented, the name of one of the objects in the
scene appeared. Subjects were instructed to press the
space bar as soon as they were ready to report the
relative position of the object. The time between the
appearance of the object probe and the space bar press
was the critical latency measure and will hereinafter be
referred to as response latency. For direction
judgments, when subjects pressed the space bar, a list
with the terms “above”, “below”, “front”, “back”,
“left”, and “right”, presented in a random order each
time, appeared. Participants were instructed to press the
key that corresponded to the integer (1 to 6) that
appeared next to the direction they chose. For axis
judgments,
the
list
contained
the
choices
“above/below”, “front/back”, and “left/right”, and
participants entered their answer using the 1 to 3 keys.
The time between the appearance of the list and the key
press for selecting the direction will be referred to as
answer latency. Each narrative continued in the same
fashion until all six objects were probed in each
protagonist perspective. Each narrative involved 24
probes, 6 for each protagonist perspective. For each
participant, three of the narratives were randomly
assigned to the direction judgment type, and the rest to
the axis judgment type. Below each object probe the
words “direction” or “axis” were presented to remind
participants of the type of response they needed to
make.

Results
Participants responded correctly to 96.3% of the probes.
Data from 2 subjects -- one from each rotation
condition -- were discarded because accuracy did not
exceed 60%.
Latency Incorrect responses were discarded from the
latency analyses. Outliers in latency data were defined
as reaction times deviating more than 3 standard
deviations from each participant’s type of judgment
mean. Outliers in response RT resulted in an additional
6% of data and were also discarded from the analyses.
Latency data for each self-object direction were
collapsed to form three dimension means (i.e., a

MSE=55533, p<.001. The pattern of latencies for the
three body axes corresponded with the pattern predicted
by the Spatial Frameworks model.
4500
RT (ms)

3800
Above/Below
Front/Back
Left/Right

3100
2400
1700
1000
original

novel

imagined

original

novel

physical

Rotation-Perspective

Figure 1: Latency for body axes as a function of the
mode of rotation and the perspective of the protagonist.
Additionally, the analysis revealed a mode of rotation
x judgment type x dimension interaction, F(2,70)=3.49,
MSE=60334,
p<.05.
4500
RT (ms)

separate mean of each body axis). Moreover, latencies
for the three novel perspectives did not differ from each
other so they were collapsed to form a single novel
perspective mean.
Answer Latency Analyzing answer RT provides a
check on whether subjects successfully followed
instructions on how to respond. Frequently, spillover
effects of response RT on answer RT are observed.
When this happens, however, answer RT patterns tend
to mimic the ones observed in the response RT data and
are either omitted from analyses (e.g., Bryant, Tversky,
& Franklin, 1992) or combined with response RT
(Franklin, Tversky, & Coon, 1992). No spill-over
effects were observed in the present study. The only
significant effect was a main effect for the type of
judgment, F(1,36)=90.28, MSE=105394, p<.001. The
average answer RT for direction judgments was greater
than the corresponding RT for axis judgments (1944 ms
and 1655 ms respectively). This is expected because the
response choices were 3 for axis judgments and 6 for
direction judgments.
Response Latency Several Analyses of Variance
(ANOVA’s) were performed. Interactions that are not
discussed were not significant at a=.05.
As predicted, a significant mode of rotation x
perspective x dimension interaction was obtained,
F(2,72)=4.23, MSE=75530, p<.05 (figure 1).
Separate ANOVAS were performed for each mode of
rotation.
When rotation was imagined, a significant
perspective x dimension interaction was obtained,
F(2,36)=8.05, MSE=114939, p<.01. Significant main
effects for both perspective and dimension were
obtained, F(1,18)=22.93, MSE=264189, p<.001 and
F(2,36)=19.57, MSE=212008, p<.001 respectively.
Performance was faster with the original than the novel
perspective for above/below and left/right. For
front/back the difference was not statistically
significant, F(1,18)=2.73, MSE=193450, p=.12.
Nevertheless, even in this dimension the average for the
original perspective was smaller than that for novel
perspective (2127 ms and 2363 ms respectively).
Overall, the patterns of accessibility of the three axes
conformed to the predictions of the Spatial Frameworks
model for both the original and novel perspectives.
Judgments on the left/right dimension were particularly
slow when performed under a novel perspective (3025
ms) than under the original perspective (2208 ms),
F(1,18)=32.83, MSE=193290, p<.001.
When rotation was physical, latency for the original
perspective was shorter than the average latency for the
novel perspective (1821 ms and 2149 ms respectively),
F(1,18)=57.26, MSE=53699, p<.001. The perspective x
dimension
interaction
was
not
significant,
F(2,36)=1.99, MSE=36120, p=.15. However, there was
a main effect of dimension, F(2,36)=21.61,

3800

Above/Below

3100

Front/Back
Left/Right

2400
1700
1000
axis

direction

imagined

axis

direction

physical

Rotation-Judgment

Figure 2: Latency for body axes as a function of the
mode of rotation and the judgment type.
Further analyses were performed separately for each
judgment type. When judgment was direction, a
significant rotation x dimension interaction was
obtained, F(2,72)=6.61, MSE=134329, p<.01. Overall
with direction judgments, subjects were faster when the
rotation was physical than imagined (2507 ms and 1979
ms respectively), F(1,36)=5.48, MSE=1448481, p<.05.
An effect for dimension was also present,
F(2,72)=31.49, MSE=134329, p<.001. Latency patterns
conformed to the Spatial Frameworks model for both
rotation modes. However, times were longer for all
dimensions when rotation was imagined. The
interaction was caused by a very long latency average
for the left/right dimension under imagined rotations.
When the judgment was axis, latencies for the various
axes were similar for both types of rotation. The
rotation x dimension interaction did not approach
significance, F(2,7)=1.23, MSE=84641, p=.30.
Similarly, no main effect for rotation mode was
obtained,
F(1,35)=.07,
MSE=1353673,
p=.80.
However, a significant main effect for dimension was

obtained, F(2,70)=30.96, MSE=84641, p<.001. The
Spatial Frameworks pattern was observed in the
dimension latencies. As seen in figure 2, the average
latency for the left/right dimension (2452 ms) was
shorter than the respective average of imagined rotation
with a direction decision (3045 ms) but longer than that
of real rotation with a direction decision (2170 ms).
An interesting result was the pattern observed for the
rotation x judgment interaction, F(1,35)=11.66,
MSE=216901, p<.01. When rotation was imagined,
axis judgments (2212 ms) were faster than directional
judgments (2463 ms), F(1,17)=8, MSE=212424, p<.05.
However, when rotation was physical, the pattern of
judgment times were actually opposite than the one
obtained with imagined rotations. Axis judgments took
longer than direction judgments (2155ms and 1979ms
respectively). This difference was marginally
significant, F(1,18)=4, MSE=221130, p=.06. A further
analysis revealed that a significant type of judgment x
perspective interaction for imagined rotations,
F(1,17)=5, MSE=24966, p<.05. For novel perspective,
direction judgments were performed significantly faster
than axis judgments, F(1,17)=13.6, MSE=56705, p<.01.
However, for the original perspective the two judgment
types were not statistically different, F(1,17)=0.95,
MSE=150568, p=.34.
Accuracy In contrast to the latency analysis, the
ANOVA on accuracy revealed a significant main effect
for the mode of rotation, F(1,36)=4.41, MSE=.017,
p<.05. Accuracy was higher when rotations were
physical instead of imagined (98% and 94%
respectively). An advantage for physical rotation is also
reported by De Vega and Rodrigo (2001). A significant
mode of rotation x type of judgment interaction,
F(1,36)=5.32, MSE=.017, p<.05, revealed that the
effect of rotation was confined to direction judgments.
As in the latency analysis, a significant mode of
rotation x perspective x dimension interaction was
obtained, F(2,72)=3.84, MSE=.0008, p<.05. The mode
of rotation x judgment x dimension interaction that was
obtained in the latency analysis, was marginally
significant, F(2,72)=3.07, MSE=.002, p=.05. For both
interactions, the pattern of results resembled the
patterns obtained in the latency analysis to a great
extent. The only deviation from the latency data was
that sometimes the judgments for front/back were no
less accurate than judgments for above/below.

Discussion
The present experiment produced results that deviated
from those reported by De Vega and Rodrigo (2001).
When participants made direction judgments – the
condition tested by De Vega and Rodrigo – they were
both faster and more accurate with physical than
imagined rotations. De Vega and Rodrigo reported that

their subjects were more accurate but not faster with
physical rotations. Perhaps, the use of only four objects
in their narratives made it easy for participants to keep
track of how their relative locations of objects changed
with the protagonist reorientations.
Although the performance advantage for physical
rotation would qualify as evidence for successful
updating under De Vega and Rodrigo’s (2001)
methodology, other results from the present study
suggest otherwise. Results suggest that the fastest
performance under physical rotations was due to the
relative ease with which direction judgments, especially
left Vs right, were made when rotation was physical.
The same result was obtained for imagined rotation
when axis judgments were introduced. Indeed, when
participants were not required to make a direction
judgment, their performance was similar to that of
participants with physical rotations. This suggests that
the orientation of the ecological reference frame is
important for making difficult discriminations between
the poles of body-centric axes. The differences between
the three dimensions were smaller when the ecological
frame was aligned with the frame of the protagonist.
This was true both when participants performed the task
from the original perspective, under which their
ecological frame is aligned with the protagonist frame,
in either mode of rotation.
Despite the performance advantage with physical
rotations, the present results provide clear evidence that
participants did not update the self-object direction with
either imagined nor physical rotations. In both cases,
performance was both faster and more accurate when
the task was performed from the original than a novel
perspective. This result is not obtained in studies that
use visually presented scenes (e.g., Rieser et al., 1986),
and suggests one aspect that mental representations
derived from texts might differ from those derived from
perception. A possible account for this dissociation is
provided by De Vega and Rodrigo (2001). While
visually perceived scenes are anchored in a
sensorimotor framework based on the ecological
reference frame of the observer, mental representations
of described scenes are grounded into a mental
framework from which the self is detached. While
physical movements can provide proprioceptive
feedback that helps updating the mental representation
in the sensorimotor framework, this feedback is not
very helpful for representations that are anchored in a
mental framework. However, as shown in the present
study, although the ecological self might be disengaged
from the mental framework, it is still important for
making spatial decisions in it.
Finally, the accessibility patterns for the three
dimensions conformed to the predictions of the Spatial
Frameworks model (Franklin & Tversky, 1990).
Objects on the above/below axis were located faster

than objects on the front/back axis, which were in turn
located faster than objects on the left/right axis. The
differences among the dimensions were greater when
rotations were imagined and judgments were for
direction. While this result might be due to the higher
difficulty of performing the task under these
circumstances, it could alternatively mean that a part of
the Spatial Frameworks effect is due to the need for
discriminating the poles of the axes. Results from
Bryant and Wright (1999) suggest that the difficulty of
making discriminating decisions within the axes does
not fully account for the Spatial Frameworks results.
In summary, the present study provided more
substantial evidence to confirm the conclusions of De
Vega and Rodrigo (2001), while at the same time
provided a better understanding of how the ecological
self interacts with spatial reasoning about imagined
spaces derived from texts. While physical rotations led
to no spatial updating of the original mental
representation, they produced better performance by
reducing the difficulty with making discrimination
between the poles of body-centric axes. This result can
have important practical implications for situations
where spatial reasoning occurs from imagined
perspectives (e.g., teleoperating robots for rescue
mission and space exploration).

Acknowledgments
I am grateful to Barbara Tversky for providing narrative
material and Jessica Glick for modifying that material
for use in the present study. For valuable discussions, I
thank Rich Carlson, Frank Ritter, Judy Kroll, and Lael
Schooler. I also thank Allison DeGrano, Tom Jolly, and
Jessica Glick for their enthusiastic help with data
collection.

References
Attneave, F., & Farrar, P. (1977). The visual world
behind the head. American Journal of Psychology,
90, 549-563.
Bryant, D. J., Tversky, B., & Franklin, N. (1992).
Internal and external spatial frameworks for
representing described scenes. Journal of Memory
and Language, 31, 74-98.
Bryant, D. J., & Wright, G. W. (1999). How body
asymmetries determine accessibility in Spatial
Frameworks. The quarterly journal of experimental
psychology, 52A, 487-508.
Chance, S. S, Gaunet, F., Beall, A. C, & Loomis, J. M.
(1998). Locomotion mode affects the updating of
objects during travel: The contribution of vestibular
and proprioceptive inputs to path integration.
Presence, 7, 168-178.
Corballis, M. C., & Beale, I. L. (1976). The psychology

of left and right. Hillsdale, NJ: Lawrence Erlbaum.
De Vega, M., & Rodrigo, M. J. (2001). Updating spatial
layouts mediated by pointing and labelling under
physical and imaginary rotation. European Journal of
Cognitive Psychology, 13, 369-393.
Denis, M., & Cocude, M. (1989). Scanning visual
images generated from verbal descriptions. European
journal of cognitive psychology, 1, 293-307.
Franklin, N., & Tversky, B. (1990). Searching
Imagined Environments. Journal of Experimental
Psychology: General, 119, 63-76.
Franklin, N., Tversky, B., & Coon, V. (1992).
Switching points of view in spatial mental models.
Memory & Cogntion, 20, 507-518.
Fukusima, S. S, Loomis, J. M, & Da Silva, J. A. (1997).
Visual perception of egocentric distance as assessed
by triangulation. Journal of Experimental
Psychology: Human Perception and Performance,
23, 86-100.
Klatzky, R. L, Loomis, J. M, Beall, A. C, Chance, S. S,
& Golledge, R. G. (1998). Spatial updating of selfposition and orientation during real, imagined, and
virtual locomotion. Psychological Science, 9, 293298.
Loomis, J. M, Klatzky, R. L, Golledge, R. G, Cicinelli,
J. G, Pellegrino, J. W, & Fry, P. A. (1993). Nonvisual
navigation by blind and sighted: Assessment of path
integration ability. Journal of Experimental
Psychology: General, 122, 73-91.
Presson, C. C, & Montello, D. R. (1994). Updating after
rotational and translational body movements:
Coordinate structure of perspective space.
Perception, 23, 1447-1455.
Rieser, J. J, Guth, D. A, & Everett, W., & Hill, E. W.
(1986). Sensitivity to perspective structure while
walking without vision. Perception, 15, 173-188.
Rieser, J. J. (1989). Access to knowledge of spatial
structure at novel points of observation. Journal of
Experimental Psychology: Learning, Memory, &
Cognition, 15, 1157-1165.
Simons, D. J, & Wang, R. F. (1998). Perceiving real
world viewpoint changes. Psychological Science, 9,
315-320.
Wang, R. F., & Simons, D. J. (1998). Active and
passive scene recognition across views. Cognition,
70, 191-210.
Wang, R. F., & Spelke, E. S. (2000). Updating
egocentric representations in human navigation.
Cognition, 77, 215-250.
Zwaan, R. A, & Radvansky, G. A. (1998). Situation
models in Language comprehension and memory.
Psychological Bulletin, 123, 162-185.

