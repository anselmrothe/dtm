UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reminiscence and Arousal: A Connectionist Model

Permalink
https://escholarship.org/uc/item/4v45r3gd

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 24(24)

Author
Chown, Eric

Publication Date
2002-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Reminiscence and Arousal: A Connectionist Model
Eric Chown (echown@bowdoin.edu)
Department of Computer Science, 8650 College Station
Brunswick, ME 04011 USA

Abstract
In recall tasks, increased levels of arousal soon after
presentation time leads to short-term performance that is
contradictory to standard memory models. Despite the
fact that long-term recall is excellent in such situations,
short-term recall is poor, worse than in the long-term
case. This article presents a model, based upon Hebb’s
cell assembly construct, to account for this puzzling data.
The system, called MultiTrace, has previously been used
to model a lexical priming task and was adapted with
only minor changes for this task.

Introduction
The relationship between arousal and short-term
memory has presented a problem for standard memory
models for nearly 40 years. In a pair of studies in the
early 1960s Kleinsmith and Kaplan (1963; 1964) found
that while there is a positive correlation between
increases in arousal and long-term memory, in the
short-term case the reverse is true. Further, in cases of
where arousal markedly increases, short-term recall is
substantially worse than long-term recall, an effect
called “reminiscence.” Because these results challenge
standard memory models in which short-term memory
is necessarily stronger than long-term memory, they
have often been criticized, but just as often have been
replicated (Eysenck, 1977; Weingartner & Parker,
1984; Revelle & Loftus, 1990). To date, no widely
accepted explanation has ever been provided to account
for the data (see, for example, Revelle & Loftus, 1990).
However, more modern views of memory, updated with
an increased understanding of the underlying neural
mechanisms involved, can now provide a plausible
explanation of the data. This article presents an
existing model that can account for the data in a way
that is surprisingly close to the original account of
Kleinsmith and Kaplan.
The model used in this article, called MultiTrace
(Sonntag, 1991; Chown, 1994; Forbell & Chown,
2000), is a variant on the cell assembly construct
proposed by Hebb (1949) and later extended by Kaplan,
et. al. in their TRACE system (1991). What makes the
cell assembly model so attractive for this task is that,
unlike many other neural network models, cell
assemblies have complex temporal dynamics directly
affected by the physiological properties of neurons.
MultiTrace is an extension of the single cell assembly

TRACE model to allowing sequence learning through
the inclusion of multiple cell assemblies.
This article will begin with a discussion of the
Kleinsmith and Kaplan data and some of the theoretical
problems it raises. Next the MultiTrace model is
presented, highlighting parts of the model directly
relevant to this task. Finally, the original experiments
are modeled in MultiTrace and the results are compared
to the originals.

Reminiscence
The learning paradigm used by Kleinsmith and Kaplan
was a simple paired-associate task. In the first
experiment, subjects were shown a word for four
seconds and then the same word and a number for
another four seconds. The recall task was to remember
the number when the word was given as a cue.
Changes in galvanic skin response (GSR) deflection
were used as the measure of arousal response. These
changes were sorted into “high” and “low” categories
for each subject. In the long-term case (one week),
Kleinsmith and Kaplan got the results that they
expected – recall was better for words in the “high”
category. The surprising result was that in the shortterm cases (2 minutes and 20 minutes) this was not the
case, and further, recall in the “high” categories was
worse than in the long-term case. When the arousal
deflection was “low”, the recall curves generated were
what would normally be predicted – short-term recall
was very good but decayed over time (Figure 1). In the
“high” case, however, Kleinsmith and Kaplan found
that the recall curve was essentially an inverted U
(Figure 1). To address criticism of the original study,
Kleinsmith and Kaplan replicated their work the
following year, but used nonsense syllables instead of
words, and got qualitatively similar results.

Recall

High Arousal
Low arousal

Log Time
Figure 1: The Kleinsmith and Kaplan data.

The major question raised by the Kleinsmith and
Kaplan data is why recall is so poor in the short-term
case in the high deflection condition. Among other
things, the results would seem to discount the notion
that long-term memory is just a decayed version of
short-term memory, or that memories transition from
short-term into long-term storage.
Kleinsmith and Kaplan proposed that the neural
circuits involved in the task rapidly reverberated under
conditions of increased arousal and were relatively
unavailable because of that reverberation. They went
on to theorize that this same reverberation was
responsible for the better long-term recall due to greater
perseverative consolidation. This explanation was
discounted due largely to the lack of an accepted
mechanism that could account for the unavailability of
the circuits in the short-term. Kleinsmith and Kaplan
proposed neural fatigue as the mechanism, but this is a
property of neurons that only started to become
accepted more than 20 years later (Ito, 1992; Artola &
Singer, 1993) and was criticized at the time for being
implausible.
Most of the alternative explanations proposed in the
interim involved some combination of consolidation
and interference in conjunction with separate short and
long-term memory mechanisms. None of them were
satisfactory (Revelle & Loftus, 1990), and work in the
area appears to have died out due to the lack of
attractive theories. The model presented here is closely
related to Kleinsmith and Kaplan’s original proposal.
The neural circuits in this case are cell assemblies. In
this paradigm learning comes as the result of correlated
neural activity (this is usually called Hebbian learning).
One effect of an increase in arousal is to generate
intense and focused activity in the brain (Oades, 1985).
In a Hebbian paradigm one byproduct of intense
activity is that the areas of focused activity experience
more correlated activity and therefore more learning.
As this activity stretches out over a few seconds it
essentially serves as the memory consolidation period.
On the other hand, this intense activity also tends to
fatigue the neurons that have been repeatedly firing.
The net result is that these fatigued cell assemblies
temporarily require an unusual amount of stimulation in
order to become reactivated.

The MultiTrace Model
Hebb developed the cell assembly construct to address
questions concerning the temporal nature of neural
processing. Hebb needed a way to explain how neurons
could hold information over time (e.g. the
psychological concept of “set”) even though they
essentially pass through information. He solved this
problem by proposing that cell assemblies consist of a
large collection of neurons that are highly
interconnected. These connections form a kind of loop

that enables the cell assembly to effectively hold
information through the reverberation of the loop once
it becomes active. In this way cell assemblies are
neural analogs of “symbols.” Hebb’s theory was
rejected after early models showed that the recurrent
connections tended to lead to out of control activity
(Rochester, et. al., 1956). This was because Hebb had
cautiously omitted inhibition from his model because
no direct physiological evidence existed for it at the
time. More recently, however, cell assembly theory has
undergone something of a revival as experimental
evidence for their existence has been found (Amit,
1995) and several models have been proposed that
extend Hebb’s original conception (Kaplan, et al, 1991;
Hetherington & Shapiro, 1993; Amit, 1995; Horn, et
al., 2000).

TRACE
MultiTrace is based upon one such model, the
TRACE (Tracing Recurrent Activity in Cognitive
Elements) model of Kaplan et. al. (1991). TRACE is
based on the idea that there must be counterbalancing
forces to offset the tendency of cell assemblies to
continually reverberate. The most important of these
forces are inhibition, which provides a mechanism for
selection and for competition with other cell
assemblies, and fatigue which ensures that cell
assemblies do not stay active indefinitely.
TRACE is modeled as a set of difference equations
that capture the biological properties of the population
of neurons that comprise the cell assembly. The
equations are similar to population models used by
biologists.
Rather than trying to work out the
interactions of neurons individually, the Kaplan group
decided to work at a slightly higher level in order to
understand their collective behavior. TRACE units,
therefore, are more complex than typical neural
network units, but are still at a higher level than
neurons.
The crux of any cell assembly model is that activity
in a cell assembly is the basis of cognitive processing.
Perception, for example, would correspond to a cell
assembly reaching some internal threshold of activity
(defined as the percentage of active neurons at any
given time step). TRACE added several theoretical
constructs to Hebb’s theory that are relevant to this
article; they are inhibition, fatigue, and short-term
connection strength.
Inhibition serves numerous roles in cognition,
including selection and providing a mechanism for
perceptual competition. These will be discussed in
more detail in the discussion of the MultiTrace
extension to TRACE.
Fatigue provides a kind of shut-off mechanism to cell
assemblies, ensuring that the cognitive system does not
literally get stuck on a single thought. It has also been

speculated that fatigue may play a central role in
learning in much the same way that muscle fatigue is
crucial to getting stronger. Neurons, like muscles are
physical systems that require fuel (e.g. transmitter
substances) to work efficiently. With extreme usage
that fuel supply can run out and essentially damage the
system. With muscles it is the repair of the damage that
makes the muscle stronger. It may be that neural
fatigue is a kind of signal to rewire synapses in order
for the system to run more efficiently in the future.
The important function of short-term connection
strength with regard to this article, is that it provides a
mechanism for short-term memory.
Short-term
connection strength (STCS) is based on post-tettanic
potentiation, the property of neurons that once they fire
they are temporarily more likely to fire again. In other
words, once a cell assembly has been active, for a short
time it will be easily reactivated (or recalled). STCS’s
counterpart in TRACE is long-term connection strength
(LTCS) which comprises the long-term structure of the
brain and is what changes with learning.
The TRACE equations are shown in Table 1. As
difference equations, they are updated on each time step
(set at 10 milliseconds in TRACE).
Table 1: The TRACE equations
Update Equations

Delta Equations

A(t+1) = A(t) + ∆Α
F(t+1) = F(t) + ∆F
S(t+1) = S(t) + ∆S
L(t+1) = L(t) + ∆L

∆A = P − M
P = ( A + A I)A V
M = (A L + AA C )V

I = I exc − I inh (see text)

BLAST
BLACK

A: activity
F: neural fatigue
S: STCS
L: LTCS
I: network input
AR: Arousal
Equation Note: X denotes
quantity (1 – X)

BLUES

/k/ /t/

MultiTrace
MultiTrace extends TRACE by putting TRACE units
into a larger architecture consisting of multiple cell
assemblies. In addition to the properties of the
individual units that come from the TRACE model,
units also have properties associated with the
architecture of the brain. There are two properties that
are important with regard to this article and they have

/b/

/l/
/u/

/a/
/s/

PHONEME

θl : unit loss
θc : inhibitory
competition
v : normal factor
φg : fatigue growth
φd : fatigue decline
σg : STCS growth
σd : STCS decline

Excitatory
Inhibitory

LEXICAL

∆F = φgA F - φd F
∆S = σgA S - σdS
V = 1 v ( S + L ) F AR

previously been used with MultiTrace to model a
lexical priming task (Forbell & Chown, 2000). The
first property is what Kinsbourne (1982) called “the
functional distance principle.” This is the property that
similar concepts tend to interfere with each other more
than dissimilar ones. In neural terms, similar concepts
are processed near each other in the brain and will tend
to inhibit each other. This provides a means for
perceptual competition among other things. The second
property is that cortex consists of a large number of
layers. It is possible to think of these layers vertically,
with the perceptual layer on the bottom and more
abstract layers higher in the hierarchy. In the original
TRACE paper it was proposed that each layer consists
of cell assemblies with different temporal properties (in
the context of the model this is achieved by varying the
parameter settings).
Figure 2 is drawn from (Forbell & Chown, 2000) and
demonstrates both of these properties. The lexical layer
is more abstract than the phoneme layer and is therefore
at a higher level in the cognitive hierarchy. In this case
the lexical layer is one level up since words consist of
sequences of phonemes. Each layer has slightly
different properties (for example, perceptual layers will
need to recover from fatigue very quickly so the
perceptual system can always be ready for the next
input) and similar items within a layer tend to compete
with each other through lateral inhibition. In the figure,
for example, “BLAST” will inhibit “BLACK” more
than it will inhibit “BLUES” since it is more similar to
“BlACK.”

/z/

Figure 2: The two-tiered connectionist architecture.
Similar words are processed near each other and will
tend to inhibit each other based upon distance.

The main extensions to the original TRACE model
added in MultiTrace is to use a more complex input
function that combines several sources of inhibition as
well as excitation. The input equations found here are
the same as in (Forbell & Chown, 2000) and more
details on the derivations can be found there.
For clarity a unit’s input can be divided into
inhibitory and excitatory components. Because of the
functional distance principle, neighboring units will
tend to inhibit each other. The amount of inhibition is a
function of the distance between units and the activity
and fatigue of the inhibiting unit:

I jkinh =

A j (1 − Fj )
D jk

j: source unit
k: target unit
D: distance
There is an additional inhibitory factor in the model
termed “regional inhibition” which is designed to limit
the total activity in any given cognitive layer.
Therefore the total inhibition for a unit, k, is the sum of
the inhibition from other units, plus its regional
inhibition:

Ikinh =

n
1 n inh
(∑ I jk ) + R(∑ Ai )
L j =1
i=1

n: number of units in a layer
R: regional inhibition factor
L: lateral inhibition factor
Excitatory input is computed in a conventional
connectionist manner. The only difference is that units
have both long-term and short-term connections
between them:

I jkexc = (LTCSjk + STCSjk )Aj
n

Ikexc = ∑ I jkexc
i=1

j: source unit, k: target unit
n: number of incoming connections for unit k
Once the excitatory input is computed it is run
through a standard sigmoid function to force it to values
between 0 and 1.
Learning in MultiTrace is based upon the Hebbian
learning rule that connections between units are
increased when they fire nearly simultaneously. This is
modulated by the fatigue (raised to the power P) of the
unit as well as a learning rate, Λ.
∆LTCSkj = Λ * Ak * Aj * FkP

Simulation and Results
The experiments simulated in this article are from
(Kleinsmith & Kaplan, 1964). The only changes to
MultiTrace from (Forbell & Chown, 2000) were in
parameter settings related to operating at a different
level of cognition than the perceptual experiments in
that work. The parameters internal to units are largely
based upon those in the original TRACE paper (Kaplan,
et. al., 1991) since it was meant to model higher
cognition.
With regard to the experiments, the
important parameters are the ones affecting fatigue,
short-term connection strength and arousal. The values
are shown in Table 2. With regard to arousal, the value
shown is taken to be a baseline that varies
experimentally as described below.
Table 2: Unit Parameters
Parameter
Φg
Φd
σg
σd
Ar

Description
Fatigue Growth
Fatigue Decline
STCS Growth
STCS Decline
Arousal

Value
0.007
0.0001
0.1
0.001
0.95

In terms of the architecture selected, a two-tiered
system was used similar to the one shown in Figure 2.
The reasoning is that nonsense syllables were selected
specifically to be unlike normal words. This means
there should be no perceptual competition between the
nonsense syllables and the associated digits. Further,
connections between the layers should be relatively
uniform and weak. One difference between the layers
is that nonsense syllables represent “unlearned” or
weakly connected cell assemblies. Digits, on the other
hand, are frequently used, and thus the cell assemblies
that represent them should be tightly connected. In the
original TRACE paper it was proposed that unlearned
cell assemblies have an internal long-term connection
strength (LTCS) of 0.2, while well-learned ones have
an LTCS of 0.5. In the experiments that follow, this is
the only difference between the two layers.
The basic format of a given run of a simulation is
simple: a unit was randomly selected from the first
layer and was stimulated. Meanwhile, a starting arousal
level was also generated. Then two seconds later a
random arousal deflection was generated. This was
categorized as either “high” or “low” by comparing it
against the median arousal level. Two seconds after
that the original unit was again stimulated along with a
randomly selected unit from the second layer. In the
short-term case the network was then allowed to run for
two minutes of simulated time. Then arousal was again
set randomly (it was found that there was no correlation
between arousal at presentation and arousal at recall

(Kaplan & Kaplan, 1970)) and the first unit was restimulated. If the second unit became active due to
stimulation from the first, it was categorized as
successful recall. The procedure was the same in the
long-term case except that factors such as fatigue and
STCS were simply reset to normal levels to simulate
the passage of time. In addition, the network learned
(in the form of changes in inter-unit LTCS) in the longterm, but not the short-term case. This is because
consolidation data shows that the physical process of
long-term memory generally takes at least 20 minutes
Miller & Marlin, 1984).
The 20-minute recall case was dropped for a variety
of reasons. One reason is that the simulation essentially
runs in real time. This means it is not possible to run a
significant number of trials as compared to the 1000
trials in the other cases. A second reason is that the 20minute case mixes short-term and long-term memory
processes. There is no a priori way of knowing how
much the recall rates at those times are due to either
factor. The tested cases are purely short-term memory
on the one hand, and purely long-term memory on the
other, and therefore can generate more meaningful
results. There is no obvious way to set the learning rate
in the 20-minute case and trying to determine one
experimentally would be extremely difficult due to the
time-scale involved.
The architectural parameters relating specifically to
MultiTrace are given in Table 3.
Table 3: MultiTrace Parameter Settings
Parameter
R
L
Λ
P

Description
Regional Inhibition
Lateral Inhibition
Learning Rate
Fatigue Power

Value
0.1
3
0.03
3

To test the robustness of the model, in each
simulation run a new “subject” was generated by
randomly perturbing all of the relevant model
parameters. For example, if the parameter’s ideal value
was set at 0.1 a new one was generated for each run by
using a Gaussian distribution with a mean of 0.1 and a
standard deviation of 0.01. In all, 1000 runs were done
for both the long and the short-term cases. The results
are shown in Table 4.
Table 4: Recall Rates
Arousal
Low
High

2-minute
0.55
0.11

1-week
0.25
0.50

The results are similar to those obtained by
Kleinsmith and Kaplan, though exact comparisons
cannot be drawn since they published curves, but not
the actual numbers. Further, pursuit of an exact match
is probably a fruitless enterprise as the results were later
reinterpreted with different scoring methodologies
(Kaplan & Kaplan, 1970). The conclusion of that study
was that the trends in the results were consistent across
experiments and scoring, but with a fair degree of
variation. The important trends being that initial recall
is high in the low arousal case and then declines, and
that the reverse is true in the high arousal case.
It is important to emphasize that the parameters for
this work were drawn from previous sources. The
TRACE parameters in Table 2 were taken directly,
without modification, from an extension to TRACE
where arousal was added (Chown, 1994). These
parameters are different than those used in (Forbell &
Chown, 2000) due to the fact that different levels of
cognition were being modeled. In the previous case the
individual units represented phonemes; in the current
case the cell assemblies represent entire syllables.
Since syllables are comprised of sequences of
phonemes the time course of activity must be longer.
In terms of the MultiTrace architectural parameters in
Table 3, the only parameter that varied from (Forbell &
Chown, 2000) was the learning rate. It is reasonable to
believe that the learning rate for lexical material is
different than the learning rate at higher levels of
cognition, such as at the word level.

Discussion
This work serves two purposes. First, an existing
biologically grounded model was used to address a
theoretical problem in the memory and arousal
literature. The results support Kleinsmith and Kaplan’s
theory that their data can be explained in terms of
reverberating neural circuits.
Second, their data
provides further constraints in exploring the temporal
dynamics of neural processing in cognition and the
development of cell assembly-based models.
TRACE and MultiTrace were developed as modern
versions of Hebb’s cell assembly construct. The
individual parts of each model were theoretically
motivated as part of a general cognitive theory. The
fact that MultiTrace was able to model the Kleinsmith
and Kaplan results with only minor parameter changes
lends credence to Kleinsmith and Kaplan’s original
supposition about the underlying cause of their results.
In turn, their data, which has defied other explanations
for four decades, shows that the physiology of the
brain, including architectural factors such as wiring, are
critical in fully understanding human learning.
Hebbian learning has become increasingly popular in
connectionist models in recent years and the paradigm
explored in this paper provides evidence of how it

might be useful in a general theory of learning. The
postulate that learning comes as the result of correlated
neural activity implies that variation in learning can
largely be explained in terms of factors that impact that
activity. Arousal is a primary example of such a factor.
Cell assembly models such as MultiTrace have the
potential to explore this idea by modeling the dynamics
of neural activity at a fairly high level while still
incorporating physiological constraints.
These
constraints are often architectural, depending on factors
that are not easily modeled in many other types of
neural networks where, for example, the temporal
dynamics of the individual units are essentially
irrelevant.
Dynamic models are gaining in popularity, and
control issues, such as those involved in the TRACE
and MultiTrace models, will be central in their
continuing development. Time dependent data, such as
the Kleinsmith and Kaplan data is crucial to the
development of these models as it provides a source of
constraints on how the models must operate. This work
is part of an ongoing process of collecting such
constraints and using them to develop and calibrate the
model. The diversity of the tasks involved – e.g.
modeling priming and interference effects in phoneme
processing versus modeling paired-associate learning –
is crucial in showing the generality and power of the
model.

Acknowledgments
This material is based upon work supported by the
National Science Foundation under Grant No. 0092605.
Any opinions, findings and conclusions or
recommendations expressed in this material are those of
the author and do not necessarily reflect the views of
the National Science Foundation (NSF).

References
Amit, D.J. (1995). The Hebbian paradigm reintegrated:
Local reverberations as internal representations.
Behavioral and Brain Sciences, 18(4): 617-657.
Artola, A., & Singer, W. (1993). Long-term depression
of excitatory synaptic transmission and its
relationship to long-term potentiation. Trends in
Neurosciences, Vol. 16, No. 11, pp. 480-487.
Chown, E. (1994). Consolidation and learning: A
connectionist model of human credit assignment.
Doctoral dissertation. The University of Michigan.
Eysenck, M.J. (1977). Human Memory: Theory,
Research and Individual Differences. Pergamon
Press.
Forbell, E. & Chown, E. (2000). Lexical contact during
speech perception:
A connectionist model. In
Proceedings of the Twenty Second Annual Meeting of
the Cognitive Science Society.

Hebb, D.O. (1949). The Organization of Behavior.
John Wiley.
Hetherington, P.A., & Shapiro, M.L. (1993).
Simulating Hebb cell assemblies: the necessity for
partitioned dendritic trees and a post-not-pre LTD
rule. Network, 4, 135-153.
Horn, D., Levy, N., Meilijson, I., & Ruppin, E. (2000).
Distributed synchrony of spiking neurons in a
Hebbian cell assembly. In S.A. Solla, T.K. Leen, and
K.R. Muller (eds.), Advances in Neural Information
Processing Systems, 12, 129-135. MIT Press.
Ito, M. (1992). Posttetanic depression. In L.R. Squire
(ed.) Encyclopedia of Learning and Memory. New
York: Macmillan Pub. Co.
Kaplan, S. & Kaplan, R. (1970). The interaction of
arousal and retention interval: Ipsative vs normative
scoring. Psychonomic Science, 19, 115-117.
Kaplan, S., Sonntag, M. & Chown, E. (1991). Tracing
recurrent activity in cognitive elements (TRACE): A
model of temporal dynamics in a cell assembly.
Connection Science, 3, 179-206.
Kinsbourne, M. (1982). Hemispheric specialization
and the growth of human understanding. American
Psychologist, 37(4), 411-420.
Kleinsmith, L.J., & Kaplan, S. (1963). Paired-associate
learning as a function of arousal and interpolated
interval. Journal of Experimental Psychology, 65,
190-193.
Kleinsmith, L.J. & Kaplan, S. (1964). Interaction of
arousal and recall interval in nonsense syllable
paired-associate learning. Journal of Experimental
Psychology, 67, 124-126.
Miller, R.R., & Marlin, N.A. (1984). The physiology
and semantics of consolidation. In H. Weingartner,
& E.S. Parker (Eds.), Memory Consolidation:
Psychobiology of Cognition , Hillsdale, NJ: Lawrence
Erlbaum.
Oades, R.D. (1985). The role of noradrenaline in
tuning and dopamine in switching between signals in
the CNS, Neuroscience & Behavioral Reviews, Vol.
9
Revelle, W. & Loftus, D.A. (1990).
Individual
differences and arousal: Implications for the study of
mood and memory. Cognition and Emotion, 4, 209237.
Rochester, N., Holland, J.H., Haibt, L.H., & Duda,
W.L. (1956). Tests on a cell assembly theory of the
action of the brain, using a large digital computer.
IRE Transactions on Information Theory, IT2:80—93.
Sonntag, M.. (1991).
Learning sequences in an
associative network: A step towards cognitive
structure. Doctoral Dissertation. The University of
Michigan.
Weingartner, H., & Parker, E.S. (Eds.) (1984). Memory
Consolidation:
Psychobiology
of
Cognition.
Hillsdale, NJ: Lawrence Erlbaum.

