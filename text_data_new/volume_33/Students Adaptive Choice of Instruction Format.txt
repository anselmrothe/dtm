UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Student’s Adaptive Choice of Instruction Format

Permalink
https://escholarship.org/uc/item/266282xd

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Jang, Jooyoung
Schunn, Christian

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Student’s Adaptive Choice of Instruction Format
Jooyoung Jang (joj15@pitt.edu)
Department of Psychology, 823 LRDC, 3939 O’Hara Street
Pittsburgh, PA 15260 USA

Christian D. Schunn (schunn@pitt.edu)
Department of Psychology, 821 LRDC, 3939 O’Hara Street
Pittsburgh, PA 15260 USA
Abstract
A spatially distributed instruction format (i.e., when
information sources are presented side-by-side) has been
found to be generally beneficial for learning statistics (Jang,
Schunn, & Nokes, 2011). In a follow-up classroom study, we
examined whether students generally selected the better
format (i.e., faster problem solving with better understanding
of materials; distributed format in this study) when given the
choice and whether individual differences affect students’
instruction format preferences. Students were found to prefer
the instruction format that matches to their ability (an
adaptive choice): Students with high mental rotation and
verbal learning ability preferred the spatially stacked format
of instruction to a distributed format.
Keywords: Cognitive load theory; split-attention effect;
instruction design; individual differences.

Introduction
Spatial arrangement of information has been found to be
important for learning, as it affects the amount of extraneous
load that students may experience. According to cognitive
load theory (Sweller, van Merriënboer, & Paas, 1998; van
Merriënboer & Sweller, 2005), three types of cognitive load
consume a single limited working memory capacity. Two of
them are beneficial for learning: Intrinsic load is required
for learning itself (e.g., information processing,
understanding, schema construction); thus it reflects the
inherent difficulty of a given task. Germane load is caused
when learners actively engage in learning (e.g., filling in
blanks of worked examples). In contrast, extraneous load is
harmful for learning because it imposes an unnecessary load
that is not related to learning (e.g., split-attention effect:
learners’ attention is split across separately presented
information pieces that are, in fact, meaningful when
integrated). Extraneous load can be quite detrimental to
learning, especially for integrative tasks (i.e., when
dispersed learning components are so closely related to each
other as to be meaningful only when taken together:
inherently high intrinsic load). For example, the normal
benefit of worked examples (i.e., studying a fully solved
problem rather than actively solving one) can be wasted due
to a small increase of extraneous load. It has been repeatedly
found that learners no longer benefit from worked examples
when the text and diagrams are presented in a separated
format (Tarmizi & Sweller, 1988; Ward & Sweller, 1990).

Thus, it is recommended to design instructions in an
integrated format.
Integrated formats are, however, impractical for complex
tasks that require integration across many sources of
information (Wickens & Carswell, 1995). As the volume of
information to integrate increases, separated but spatially
distributed format of display (i.e., when information sources
are presented side-by-side) can be a practically and
theoretically robust alternative (Jang & Schunn, under
review; Jang, et al., 2011; Wiley, 2001). We have found
that spatially distributed displays shorten problem-solving
time and facilitate learning, when compared to spatially
stacked displays (i.e., when information sources are sitting
on top of one another with only the top source fully visible).
In a series of experiments involving learning of statistics,
students were provided with instructions either in a spatially
distributed or a spatially stacked format (Jang, et al., 2011).
Students who worked with the distributed format of
instruction finished a t-test analysis significantly faster
without any loss of accuracy, and scored higher on a posttest than those who had the same instruction in a stacked
format. Moreover, students in the stacked format condition
reported higher level of cognitive load than those in the
distributed condition.
Although the finding is consistent with cognitive load
theory in that it shows the continuum of split-attention
effect (i.e., as the degrees of separation increase, the amount
of extraneous load grows along integrated displays <
distributed displays < stacked displays), a more important
theoretical question remains unsolved: What causes the
extra cognitive load in the stacked display? A recent eyetracking study suggested that problem solvers may shift to
an information memorization strategy in stacked conditions,
and this memorization time could account for the stacked
display time disadvantage (Jang, Trickett, Schunn, &
Trafton, under review). Participants in the stacked display
condition fixated significantly longer on information pieces
on each page throughout an integrative problem-solving
task than those who solved the same problem using the
distributed display, presumably as a micro-strategy to
bypass the relatively higher information access cost in the
stacked display. That is, the stacked display presumably
produces a high information access cost situation because
information is a page-turn away, compared to the cost of an
eye/head turn away in the distributed display. Consequently,
problem solvers chose to memorize information rather than

2070

repeatedly turn pages to look for information (Gray & Fu,
2004). When the cost of accessing external information
increases, people tend to memorize information to make it
readily accessible in the head (i.e., memorization strategy;
stacked display). In contrast, when information access cost
is low, people do not bother to memorize information and
instead rely on external/ in the world information (i.e.,
perceptual-motor strategy; distributed display).
In terms of performance accuracy, the memory strategy
selection can be construed as an adaptive choice balancing
accuracy and effort. Information in the world is accurate but
that in the head may not be. For example, participants made
more errors in a given task when they adopted the
memorization strategy, but with a reduction in task time
(Gray & Fu, 2004).
Even though people on average may seem to adopt one
strategy for a given situation, individuals with different
cognitive ability may react differently to the demands of the
same situation. Then, what if we give them a chance to
choose a format of instruction for themselves? In the
strategy choice literature, problem solvers are thought to
select strategies that reduce effort and increase the
probability of solving the given problem (Gray & Fu, 2004;
Kerkman & Siegler, 1993; Lovett & Anderson, 1996).
When there are individual differences in strategy preference,
this can be explained in one of three different ways: 1) some
people value the problem solving goal more, and thus are
willing to use more effortful and successful strategies to
achieve the goal; 2) some people have less experience with
some of the strategies and have not yet figured out which
strategies are the best balance of likely success and minimal
effort; and 3) through different overall skill levels with each
strategy, different people will have different strategies that
best balance likely success and minimal effort. So when we
see problem solvers making apparently non-adaptive
choices, we ask: do they simply not care, do they not know,
or is their choice actually adaptive for them?
In the current study, we gave students free choice between
two formats of instruction and examined how individual
differences interact with instruction format choice. We
measured mental rotation ability given the visual-spatial
element to the statistical thinking learning topic being
examined as well as the experimental manipulation itself
(distributed vs. stacked format). Also, individual learning
style (self-report questionnaire) was measured as an index
of perceived strength of cognitive abilities in the two
general cognitive ability dimensions (verbal and visual),
allowing for some teasing apart of the effects of actual
ability versus self-perceived ability/style.
The better choice in this setting (based our prior work
with exactly these materials in exactly this class context) is
to choose distributed instructions as they will produce less
cognitive load on memory regardless of students’ cognitive
ability. But an adaptive choice can also be made depending
on each individual’s cognitive ability, which leads to some
interesting ambiguities regarding what to predict. Which
individuals will select the distributed vs. stacked formats?

Those with lower spatial skill may be in more need of the
cognitive supports of the distributed format, while those
with higher spatial skill are more able to memorize content
from prior pages. Alternatively, those with lower spatial
skill may have less practice with spatially distributed
information. Further, those who are visualizers may prefer
more spatially rich environments as afforded by the
distributed format.

Method
Participants
Participants consisted of 50 undergraduates (39 women)
enrolled across three lab sections of an introductory
cognitive psychology course at the University of Pittsburgh.
All students had previously completed prerequisite courses
in psychology research methods and introductory statistics.

Design
The experiment consisted of four phases—background
instruction, practice, testing, and individual differences.
Students were allowed to freely choose one of two formats:
distributed format instructions or stacked format instructions
during the practice phase. All four phases were implemented
as normally scheduled lab activities. The background phase
covered two consecutive labs one week apart (1.5 hours
each, 3 hours in total), the practice and testing phase
occurred in the third lab, and the individual differences were
measured five weeks later. During this period, students
learned about and practiced how to analyze independent
two-sample data using common data organization and
statistic tools (i.e., Excel and SPSS).

Materials
The Background Phase During the background phase,
detailed handouts were provided for four main steps in a
basic data analysis procedure relevant to basic cognitive
psychology lab studies: (1) organize the data (e.g., how to
count the number of males and females using Excel, and
how to calculate the derived dependent variable), (2) create
a pivot table (e.g., how to calculate means, standard
deviations, and Ns using the pivot table function in Excel),
(3) create a graph (e.g., how to calculate standard errors and
create a graph with standard error bars in Excel), and (4) run
a t-test (e.g., how to run an independent samples t-test in
SPSS and interpret outputs). Step-by-step text instructions
and corresponding screen shots that matched exactly to the
practice data were provided in the form of stapled letter-size
documents. Two practice datasets were given to students;
one for the in-class learning activity and the other for
homework. The data sets shared a common structure (i.e.,
no difference in terms of running analyses) but their cover
stories and numbers were different for practice purposes.

2071

The Practice Phase During the practice phase, students
were asked to freely choose the instruction format (i.e.,
distributed or stacked format) according to their preferences.
Given that students had practiced the same analysis twice
before, this time the instructions were less detailed than
those provided in the background phase. However, core
information (e.g., complex equations and high-level
instructions) was kept intact. For the distributed format
condition, instructional text and accompanying screenshots
were presented on an 11x17 paper, with four sources of
information laid side-by-side on a single-side of the paper
(i.e., four separate panels of information: see Figure 1). For
the stacked format condition, the distributed format was cut
into four pieces (one for each of the four steps: see Figure 2)
and stapled. Exactly these two formats with exactly this
content were used in the previous study that found a large
overall performance and learning advantage of distributed
instructional format (Jang, et al., 2011).
To measure task time, accuracy, and cognitive load during
the practice phase, a four-page task worksheet was
provided, which asked students to record start and end times
of each step, to report a few requested results, and to rate the
degree of perceived cognitive load on a 9-point scale.

Figure 1. Distributed format of instruction.

consisting of one open-ended question asking for reasons
for the choice. To measure overall learning outcomes, a 26item closed-book test (21 multiple choice and 5 short
answer questions; Cronbach’s alpha = .57) was used, which
covered various types of questions targeting factual,
conceptual, and integrative knowledge. The test items were
developed to closely match the broad instructional goals of
this unit. The modest overall alpha reflects the diversity of
concepts that were being tested. Previously, distributed vs.
stacked instruction conditions produced a difference in
learning outcomes on this test.
Individual Differences To examine the relationships
between individual differences and instruction format
preference, two tests measuring individual differences were
implemented: a mental rotation test (Peters et al., 1995; 24
items, Cronbach's Alpha=.87) and a verbal and visual
learning style questionnaire (Mendelson & Thorson, 2004;
20 items, Cronbach's Alpha=.67).

Procedure
Students worked individually at computer workstations in
the lab for the background instruction and practice phases.
For the background phase, students learned how to analyze
data from a one-factor study. They learned four main steps
of data analysis (i.e., organize data, create a pivot table,
draw a graph, and run a t-test), two per lab. The first three
steps were done in Excel and the last step was done in
SPSS. Detailed handouts for each step were provided and
lab instructors walked through each step with students
during the lab. Homework was assigned to allow students to
begin to practice each step on their own. Students could ask
questions or request help from instructors at any time during
the background phase.
For the practice phase, students selected the format of
instruction that they preferred to use: either the distributed
or stacked version. Students were asked to analyze new data
from a one-factor study, but within a maximum time of 40
minutes and on their own. They were allowed to use only
the less detailed handout in the format that they chose to use
that day. While completing this data analysis task, they
filled out a task worksheet. Students who finished the task
early turned in handouts and task worksheets, and then they
were allowed to quietly engage in any other activity while
the other students completed the task. After the 40 minutes
of data analysis activity, all students filled out the format
preference survey for 5 minutes and took the overall
learning test for 25 minutes (the testing phase).
Five weeks later, students were given a booklet measuring
their mental rotation ability and cognitive learning style—7
and 5 minutes were given to each test, respectively.

Figure 2. Stacked format of instruction.

Results

The Testing Phase During the testing phase, to examine
why students chose one format over the other, a brief survey
was implemented at the beginning of the test booklet,

Out of 50 students, 16 chose distributed and 34 chose
stacked format of instruction, a surprising overall ratio given
that the distributed format had previously produced more
efficient problem solving and greater learning outcomes.

2072

Table 1. Correlations between the measures of performance and individual differences
with format choice (distributed=1, stacked=0).
Dependent
Measures
Format choice

Format
choice

.06

Task
accuracy
-.08

Cognitive
load
.09

N=48

N=49

N=49

-.37*

.65**

-.27

-.14

-.16

-.06

N=48

N=48

N=47

N=41

N=41

N=41

Task time

-

Task time

-

Task accuracy

-

-.29*

Mental
rotation
-.39**

N=49

N=43

Test score

Verbalizer

Visualizer

-.34*

-.10

N=43

N=43

-.29*

.34*

.16

-.07

.12

N=49

N=48

N=42

N=42

N=42

-.14

-.39*

-.33*

-.31

N=48

N=42

N=42

N=42

Cognitive load

-

Test score

-

Mental rotation

.36*

.35*

.17

N=43

N=43

N=43

-

Verbalizer

.09

.23

N=43

N=43

-

.09
N=43

Note. *p < .05. **p < .01.

Performance

The size of N varied across the analyses as some students
missed a lab during the four weeks of experimentation.

Reason for choice (Self-report)
Open responses from the format preference survey
(distributed N=16 vs. stacked N=34), which was collected at
the beginning of the test phase, were categorized as follows
(multiple categories possible per student given the
sometimes extended written responses). Students who
preferred the distributed format reported the benefit of
having everything in a single view: Easy to see everything
(63%), No need to turn a page (56%), Easy to follow steps
(25%), Easy regression to previously visited instruction
(13%).
By contrast, students who preferred the stacked format
reported the benefits of easy manipulation (size issue) and
less distraction from overflowing information: Small-size
instruction considering limited space of lab desks (59%),
Less distracting so as to do a step at a time (50%), Easy to
keep track (9%), Easy regression (3%).
Table 2. Means and SDs for performance and individual
differences measures as a function of instruction format.

Task time (min)
Task accuracy (%)
Cognitive load (9)
Test score (%)
Mental rotation (24)
Verbalizer (%)
Visualizer (%)

Distributed
M
SD
25.3
4.6
91.8
13.5
3.1
0.8
66.0
8.4
6.4
4.5
61.3
6.8
73.7
13.1

Stacked
M
SD
26.4
6.5
92.6
8.5
3.3
1.2
72.7
12.7
10.5
4.5
68.1
9.5
76.1
9.9

From an adaptive strategy selection framework, we expect
that performance differences across representational formats
will disappear when individuals are given free choice
between formats because each individual will select the
more adaptive choice for him or herself.
A MANOVA (listwise deletion: distributed, N=13 vs.
stacked, N=34) was conducted examining the effect of
selected format on the dependent measures obtained from
the practice and testing phase: task time, task accuracy, task
cognitive load, and test score. Consistent with our
expectation, no overall significant effect was found between
the two self-selected formats, Wilks’ Λ=0.91, F(4,42)=1.02,
p=.41. Univariate tests showed no difference as well1: task
time, F(1,45)=.30, p=.59; task accuracy, F (1,45)=.07,
p=.80; task cognitive load, F (1,45)=.19, p=.66. Test score
was marginally significant, F (1,45)=3.04, p=.09. Means
and SDs are presented in Table 2.

Individual differences: better vs. adaptive choice
A MANOVA (listwise deletion: distributed N=13 vs.
stacked N=30) was conducted, examining the effect of
format choice on individual differences measures: mental
rotation test score and visual/verbal learning style scores.
Significant differences were found between the two formats,
Wilks’ Λ=.75, F(3,39)=4.24, p=.01. Univariate tests
indicated significant differences for mental rotation score
and verbal-learning style score, but not visual-learning style
score2: mental rotation test, F(1,41)=7.53, p=.01, Cohen’s
1
Levene’s tests: task time F(1,45)=1.32, p=.26; task accuracy
F(1,45)=.99, p=.32; task cognitive load F(1,45)=2.52, p=.12; test
score F(1,45)=2.35, p=.13.
2
Levene’s tests: mental rotation test F(1,41)=.41, p=.53;
learning style verbal F(1,41)=1.26, p=.27; learning style visual
F(1,41)=.69, p=.41.

2073

d=0.91; verbal-learning style, F(1,41)=5.32, p=.03, Cohen’s
d=0.83; visual-learning style, F(1,41)=.44, p=.51. Means
and SDs are presented in Table 2.
In summary, students who selected the stacked format of
instruction had significantly higher mental rotation scores
and verbalizer ratings than students who selected the
distributed format. Note the surprising combination of
higher spatial ability with higher verbalizer style, rather than
with visualizer style.
To further unpack the relationships between the measures,
a correlation matrix was computed with format choice
coded as 1 for distributed and 0 for stacked format. As
shown in Table 1, several statistically significant correlation
patterns were found. First, there was no sign of timeaccuracy trade off; in fact, a negative relationship was
observed between task time and task accuracy.
Second, plausible correlations were found between
cognitive load, task accuracy, and test score. Students who
experienced a higher cognitive load took longer to finish the
task and scored lower on task accuracy. Not surprisingly,
task accuracy and test score were positively correlated,
which suggests that test items were well matched to the
skills and knowledge required in the task.
Third, a significant negative correlation was found
between format choice (distributed=1, stacked=0) and test
score. Students who chose the stacked format tended to
score higher in the test; however, the difference was not
large enough to be statistically significant with the list-wise
deletion used in the MANOVA (see results in the
Performance section). Even though the format these
students selected (stacked format) was not the overall better
choice (distributed format), they had higher levels of
learning, presumably the result of their higher individual
cognitive abilities rather than their instruction format
choice.
Finally, individual difference measures showed several
interesting relationships with cognitive load and test score.
Students who had higher mental rotation and high rated
verbal learning ability (who chose the stacked format more
often) reported lower perceived cognitive load and they
scored better on the test. The overall results suggest that
students made adaptive instruction format choices that
matched to their abilities and learning styles.

Discussion
At the overall level, leaving individual differences aside,
students were found to choose the stacked format of
instruction more often, which is the opposite of what is
known to be beneficial. This odd preference may be the
result of students’ general resistance to an unfamiliar format
of instruction (Davis, 1993). In problem-solving settings,
several studies have found that people preferred stacked
displays over distributed displays even when distributed
displays were readily available⎯e.g., two monitors were set
up on desks (Jang & Schunn, under review)⎯or when
participants were specifically instructed to use two-

windowed browser design rather than a single browser
design (Wiley, 2001).
Once individual differences were included in the
framework, the current study showed that the seemingly odd
preference for stacked display could in fact be plausible. It
demonstrated that individual differences among students in
terms of cognitive abilities and learning styles might
significantly differentiate the extent to which a student
could benefit from instructional manipulations. What might
benefit some students may not necessarily do the same for
other students. Depending on students’ abilities, a generally
recommended format of instruction may provide redundant
information that could distract learners’ attention, as it was
found in studies comparing novice and intermediate learners
in the domain of electricity (Kalyuga, Chandler, & Sweller,
1998).
More importantly, this study showed that students could
adaptively select the instruction format they needed. As
further examination of individual differences measures
suggests, students were able to make sufficiently effective
choices in instructional formats they would use for their
learning. Specifically, we found that students with higher
spatial ability and advanced verbal skill chose the stacked
format of instruction more often than students who were
less skilled in those dimensions. Presumably, the better
choice for the students in our study was distributed because
they were all novices in the domain of statistics, as was
shown in a prior study that took place in the same setting
(Jang, et al., 2011) . Even though their choice was not the
generally better choice, it is interesting to see that students
could choose instructional formats adaptively so that the
instruction did not hinder their learning and performance,
rather than selecting the opposite or on a random basis.
Also, it is interesting to observe that students’ adaptive
format choices were made in a compensating manner, rather
than in an additive way. Although one could expect that
high spatial ability students may prefer spatially rich
distributed format as these choices play to their strengths,
the results showed the opposite. High spatial ability students
might have not bothered to use the distributed format as
their cognitive ability likely could overcome the extraneous
load coming from the stacked format. Further, it could be
that the spatially rich format may distract and hinder
learning of high spatial ability students as such students may
be sensitive to spatial features.
It is also notable that verbalizers selected the stacked
format more often than visualizers. According to the way
the cognitive learning style test is structured, a student can
be high in both; verbal and visual abilities are treated as
separated dimensions that can coexist, and our data
supported independence on these scales. The relationship of
various variables with style may suggest an effect that is not
specific to our manipulation. In general, verbal skill is
essential to any learning because instructions and tests are
mainly provided in text. The positive correlation between
verbalizer score and test score, and the negative correlation
between verbalizer rating and cognitive load could reflect

2074

the general learning component. Also, as the low nonsignificant correlation between visualizer rating and mental
rotation score shows, visual and spatial abilities are two
different constructs; while visual is more related to diagrams
or pictures (e.g., a preference/ability to use diagrams to
explain things), mental rotation is more related to spatial
features (e.g., an ability to grasp relative spatial relationship
between objects) per se. Furthermore, the instructions in this
study were mainly offered in text, and diagrams were only
to show an example of end state for each analysis step.
Thus, it seems plausible that the visualizer score did not
show a contribution as strong as mental rotation score did.
As a specific caveat of this study, the small desk space in
the lab might have encouraged students to choose the
stacked format as it was indicated in the format preference
survey; the majority of the students who selected the
stacked format mentioned the space issue. More carefully
prepared experimental materials and environment may be
needed to take advantage of distributed materials without
these space-use problems, because statistics learning often
involves manipulating many resources (e.g., instructional
handouts, multiple windows showing data and statistical
packages, and practice worksheets) in a small space.
For future studies, other individual factors could be tested
as well. Particularly, visual and verbal working memory
capacity may need to be included, as use of a memorization
strategy was found to be dominant in stacked displays. It
suggests that even a small increase of information access
cost in the stacked display⎯due to spatial separation⎯was
large enough to induce extraneous load on working
memory. Supposedly, individual difference in working
memory capacity could produce differential effect on
learning from distributed vs. stacked formats of instruction
via adaptive strategy choices. Likewise, further attention to
the presentation of learning materials can prove to be a
fruitful enterprise, both for building our theoretical
understanding of working/spatial memory, and for helping
to improve educational practice.

Acknowledgments
Work on this project was funded by NSF grant SBE0830210 and SBE-0823628. We would also like to thank
Chelsea Eddington, Eli Silk, and Alba Tuninetti for their
help in implementing the study.

References
Davis, F. (1993). User acceptance of information
technology: system characteristics, user perceptions and
behavioral impacts. International Journal of ManMachine Studies, 38(3), 475-487.
Gray, W. D., & Fu, W. T. (2004). Soft constraints in
interactive behavior: the case of ignoring perfect
knowledge in-the-world for imperfect knowledge in-thehead. Cognitive Science: A Multidisciplinary Journal,
28(3), 359 - 382.

Jang, J., & Schunn, C. D. (under review). The performance
benefits of spatially separated vs. stacked information on
information integration tasks.
Jang, J., Schunn, C. D., & Nokes, T. J. (2011). Spatially
distributed instructions improve learning outcomes and
efficiency. Journal of Educational Psychology, 103(1),
60-72. doi: 10.1037/a0021994
Jang, J., Trickett, S., Schunn, C., & Trafton, G. (under
review). Unpacking the temporal advantage of
distributing complex visual displays.
Kalyuga, S., Chandler, P., & Sweller, J. (1998). Levels of
expertise and instructional design (theory on learning).
Human
Factors,
40(1),
1-17.
doi:
10.1518/001872098779480587
Kerkman, D. D., & Siegler, R. S. (1993). Individual
differences and adaptive flexibility in lower-income
children's strategy choices. Learning and Individual
Differences, 5(2), 113-136. doi: 10.1016/10416080(93)90008-g
Lovett, M., & Anderson, J. (1996). History of success and
current context in problem solving. Cognitive Psychology,
31(2), 168-217.
Mendelson, A. L., & Thorson, E. (2004). How verbalizers
and visualizers process the newspaper environment.
Journal of Communication, 54(3), 474-491. doi:
10.1111/j.1460-2466.2004.tb02640.x
Peters, M., Laeng, B., Latham, K., Jackson, M., Zaiyouna,
R., & Richardson, C. (1995). A redrawn Vandenberg and
Kuse mental rotations test - different versions and factors
that affect performance. Brain and Cognition, 28(1), 3958. doi: 10.1006/brcg.1995.1032
Sweller, J., van Merriënboer, J. J. G., & Paas, F. G. W. C.
(1998). Cognitive architecture and instructional design.
Educational Psychology Review, 10(3), 251-296. doi:
10.1023/A:1022193728205
Tarmizi, R., & Sweller, J. (1988). Guidance during
mathematical problem solving. Journal of Educational
Psychology, 80(4), 424-436. doi: 10.1037/00220663.80.4.424
van Merriënboer, J. J. G., & Sweller, J. (2005). Cognitive
load theory and complex learning: Recent developments
and future directions. Educational Psychology Review,
17(2), 147-177. doi: 10.1007/s10648-005-3951-0
Ward, M., & Sweller, J. (1990). Structuring effective
worked examples. Ethics & Behavior, 7(1), 1-39. doi:
10.1207/s1532690xci0701_1
Wickens, C. D., & Carswell, C. M. (1995). The proximity
compatibility principle: its psychological foundation and
relevance to display design. Human Factors, v37(n3),
p473(422). doi: 10.1518/001872095779049408
Wiley, J. (2001). Supporting understanding through task
and browser design. Paper presented at the Proceedings
of the Twenty-third annual Conference of the Cognitive
Science Society.

2075

