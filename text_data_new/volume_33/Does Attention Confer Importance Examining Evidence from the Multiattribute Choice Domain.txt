UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Does Attention Confer Importance? Examining Evidence from the Multiattribute Choice
Domain

Permalink
https://escholarship.org/uc/item/8j02p1f2

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Tiwathia, Anirudh
Goldstein, William

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Does Attention Confer Importance? Examining Evidence from the Multiattribute
Choice Domain
Anirudh Tiwathia (atiwathia@uchicago.edu)
Division of the Social Sciences and the Harris School of Public Policy Studies, University of Chicago
245 E. 40th St. Apt 25F, New York, NY 10016 USA

William M. Goldstein (gold@uchicago.edu)
Departments of Psychology and Comparative Human Development, University of Chicago
5848 South University Avenue, Chicago, IL 60637 USA

Abstract
There is a prevalent claim in the judgment and decision
making (JDM) literature that attention to a piece of
information confers weight or importance upon that
information. The prevalence of that claim is not
commensurate with the empirical evidence – the quantity of
evidence is sparse, and, is constrained by significant
limitations in the methodological approach of previous
studies. The current work presents a novel method for
covertly manipulating attention to different components of a
decision scenario. Using this approach, the current work
provides empirical evidence from three multiattribute
scenarios in support of a consistent, positive causal
relationship between the attention allocated to a piece of
information and the influence accorded to it. In addition, the
current work demonstrates the viability of crowdsourcing
psychological research, including research that involves
significant perceptual components.
Keywords: attention; weight; importance; multiattribute
choice; working memory; crowdsourcing; Amazon’s
Mechanical Turk.

Introduction
When deciding between two or more options, one must
determine how much importance to place on the different
attributes that define each option. For example, when
choosing between two cars with different price and mileage,
one must know how much relative importance to give to
each of the two attributes. This everyday notion of
importance has been incorporated into models of choice
through the notion of decision weight. In the broadest sense,
decision weight represents the amount of influence that the
attribute value has in the evaluation of a particular option.
There is a prevalent trend in the literature that postulates
an intimate relationship between decision weight and
attention (e.g. Busemeyer & Johnson, 2008; Weber &
Kirsner, 1997). Frequently, attention is claimed to bestow
importance upon the variable under consideration. For
example, while discussing de-biasing effects, Kahneman &
Frederick (2002) claim that “the weight of neglected
variables can be increased by drawing attention to them.”
Similarly, Carmon & Ariely (2000) draw upon the same
premise to propose an attention-based explanation for
differences in willingness-to-pay and willingness-to-accept.
While attention to a piece of information is likely to be a
necessary condition for that information to influence

decision-making, there is inadequate empirical evidence to
support the claim that attention is a sufficient condition for
determining the influence attached to a piece of information.
Some authors have argued that the effect of attention may
depend on characteristics of the attended attribute, such as
evaluability (Bertini & Wathieu, 2008), relevance to
decision at hand (Bastardi & Shafir, 1998), or even the
motivational predispositions of decision maker (Sherman et
al., 2005).
Crucially, however, these studies suffer from substantial
methodological limitations. Most manipulate attention
through indirect techniques such as asking the decision
maker to adopt different roles (e.g. as cited in Kahneman &
Frederick, 2002), timing of information (Bastardi & Shafir,
1998), price splitting (Bertini & Wathieu, 2008), or fontsize (Weber & Kirsner, 1997). As such, these studies face
difficulties separating the effects of attention from other
effects (e.g. larger font may yield demand effects, since
large font is customarily associated with more importance).
The current empirical evidence does not support
conclusions regarding the causal relationship between
attentional allocation and weight. Given that attention is
deeply embedded in cognitive theories of decision-making
and psychologically-plausible conceptions of weight, the
relationship between attention and weight needs to be
carefully examined (Weber & Johnson, 2009).

Experimental Overview
The current study aims to examine whether attentional
allocation causally modifies the weight associated with an
attribute. To do so, we introduce a novel method for
covertly manipulating the attention of the decision-maker.
Using this method, we can systematically measure the effect
of attentional allocation on choice, and thus, we can infer
the effect of attentional allocation on attribute weight.

Covert Manipulation of Attention
To covertly manipulate the decision-maker’s attention, the
current design used a spatial working memory task.
Working memory (WM) and selective attention show
behavioral, functional, and neural overlap (Soto et al.,
2008). The contents of WM guide the allocation of attention
(Downing, 2000) under a broad set of scenarios, including
conditions where it is disruptive to the primary task; when

2395

there is a long interval between the WM prompt and the
search display; when the WM stimulus is encoded verbally;
and when the WM stimulus shares only a semantic
relationship to the probe display items (Soto et al., 2008).
Based upon such results, WM is conceptualized by some
researchers as attention-based rehearsal (for a review, see
Awh, Vogel, & Oh, 2006). Spatial WM, in particular, may
be maintained by means of covert shifts of spatial attention
to the memorized locations (Awh & Jonides, 2001;
Theeuwes, Belopolsky, & Olivers, 2009). In addition,
memorized locations can behave like attended locations and
show enhanced visual processing (Awh et al., 1998).
These findings suggest that a spatial working memory
task can be used to direct participant attention to a specified
location. Thus, it provides a method to systematically direct
attention to specific components of a decision problem.
Based on this premise, the present work employed a dualtask paradigm: (a) a spatial WM task, and (b) a
multiattribute-decision
problem.
First,
participants
memorized a location on screen. Then, they solved a multiattribute choice problem. Since the participants solve the
decision problem while keeping the location in WM, the
memorized location should receive additional attention
while they are engaged in the decision problem. If so, we
can systematically direct the participant’s attention to
specific components of a decision problem by selecting a tobe-memorized location that overlaps with the target
information.
1. Spatial WM load (Timing: 1 sec)

Stimuli and Procedures
The current work has a 3 (Question: Q1 – Q3) x 2
(Attention: Attribute 1 / 2) between-subjects design.
Stimuli Order Each participant was presented stimuli in the
following order: (1) Spatial WM load; (2) Decision
problem; (3) Spatial WM test; (4) Surprise recall test; (5)
Debriefing questions. See Figure 1.
All stimuli were presented in an 800 x 500 pixel frame.
The location to be memorized was indicated by a red
rectangle (35 x 92 px) that appears on a white background
for 1 second. After the red square, there was a 250ms onset
delay before the decision problem was presented on screen.
The decision problem was on screen for a minimum of 8
seconds before the participant could submit an answer and
progress to the next page. However, participants on average
spent about 50 seconds per question, thereby demonstrating
a healthy degree of engagement with the problem scenarios.
After submitting their answer, participants were asked to
click on screen to mark the memorized location. Clicking on
screen caused a red rectangle – identical to the original – to
be centered at the site of the click as a visual aid.
Participants could continue to modify their answer until
satisfied. They spent an average of 15 seconds doing so,
suggesting a healthy engagement with the memory task.
Attentional Manipulation The decision questions (Q1 –
Q3) were presented such that the attribute values for both
options appeared in columns. Participants were randomly
assigned to one of two attentional manipulation conditions:
either the memorized location overlapped with the value
column of Attribute 1 or it overlapped with the value
column of Attribute 2. See Figure 2.

2. Decision Problem (Timing: User Controlled)

3. Spatial WM Test (Timing: User Controlled)

Figure 2. The two transparent rectangles show the position
of the box in the Attribute 1 and 2 conditions.1
Dependent Variables For each participant and condition,
the primary variables of interest are the stated choice itself
and the performance on the spatial memory task.
Figure 1. The participants had to sustain the memorized
location in WM while making their choice.

1

The red box is never on screen at the same time as the
question. It appears in both locations here only to facilitate
visualization of the attentional manipulation.

2396

Performance on the memory task was measured as the total
number of pixels between the centers of the original
location and the remembered location.

Data Collection and Analysis
Data for the current studies were collected using a
crowdsourcing platform called Amazon’s Mechanical Turk
(AMT). AMT is an online service through which workers
and requesters can engage in micro-contracts, where the
worker completes a micro-task for the requester in
exchange for some predetermined wage.
AMT as an Experimental Platform AMT provides a
largely untapped and easy-to-reach subject pool. According
to a recent demographic survey, workers were primarily
from America (47%) and India (34%) (see, Paolacci,
Chandler, & Ipeirotis, 2010 for details). Paolacci et al.
found no significant differences in the pattern of choices for
classic judgment and decision making (JDM) problems (e.g.
Asian Disease Problem, or Linda Problem) between subjects
drawn from (a) AMT, (b) internet forums, and (c) a US
university. Horton, Rand, & Zeckhauser (2010) also
replicated classic findings using AMT, such as the framing
effect; pro-social preferences in prisoner’s dilemma games,
and priming effects on choice behavior. Both Paolacci et al.
(2010) and Horton et al. (2010) concluded that online labor
markets are more representative than traditional university
subject pools and have potential as experimental platforms.
It is beyond the scope of this paper to fully evaluate the
merits and drawbacks of utilizing AMT as an avenue for
research (see, Paolacci et al., 2010 and, especially, Horton et
al., 2010). The data presented in the above-mentioned
papers, as well as the growing interest in such tools, do,
however, bolster the methodology used here.

Data Validity
Due to the limited accountability afforded by AMT and the
low English proficiency of many participants, a significant
portion of the data was below acceptable standards, thereby
requiring a systematic data screening process. Based on
pilot data from 300+ participants, a series of precautions and
data verification measures were developed to allow a
measure of task engagement and to systematically mitigate
data validity concerns.
For the current study, a total of 227 participants were
recruited using AMT. Participants came from 32 countries,
with the majority from the US (45%) and India (38%). The
following section describes each of the catch mechanism,
and lists the number of participants excluded based on each
criterion. 2

Methodological Precautions
Unlike the AMT studies discussed earlier (Paolacci et al.,
2010; Horton et al., 2010), the current design involved
2
So as to avoid double counting, participants who violated two
or more exclusion criteria are only listed once.

perceptual components, which pose a particular challenge to
online experimentation. One difficulty comes from the
significant variation in user’s screen sizes and resolutions.
To minimize any unintended effects resulting from this
variability, the study was presented in an iframe3.
Additionally, the study was launched in a new window that
automatically covered the entire monitor at the onset. The
window and monitor size was measured at the beginning
and the end of the study. Participants were disqualified if
they changed the window size. The back-button on the
participant’s browser was disabled and tracking variables
were used to prevent participants from cheating on the recall
questions by re-visiting the previous screen or restarting the
study. Further, the mouse cursor was hidden during the
memory test so participants could not use it to mark the
memorized location.

Catch Mechanisms and Exclusion Criteria
In addition to the precautions described above, the current
design included several “catch mechanisms” to identify the
participants who were either “cheating” or not actively
engaged with the task. A total of 78 participants were
excluded; the distribution across criteria is detailed below.
Spatial Memory Task In the current design, successful
attentional manipulation depended upon the participants’
engagement with the spatial WM task. With this in mind,
the data set was restricted to those participants whose total
error was less than two standard deviations above mean (i.e.
error < Avg. + 2 SD). A total of 16 participants were
excluded based upon this criterion.
Question Time The time spent on each portion of the study
was recorded. On average, participants spent 50 seconds
reviewing the problem. Participants who spent less than 15
seconds were excluded; a total of 4 fell under this criterion.
Numerical Recall Participants were given a surprise recall
test asking them to list the four numbers that comprised the
two options of the decision problem. Participants were
excluded if they could not recall at least three of the four
numbers presented on screen. The participant response was
coded as acceptable if it was ± 5 from the actual value. The
use of a range was based on the idea that participants may
encode and recall the gist, rather than the specific value. A
total of 24 participants were excluded under this criterion.
Problem and Reason Recall As part of the surprise recall
test, participants were asked to restate the problem scenario
and give a reason for their choice. This was intended as a
basic comprehension test. Responses were entered as free
text. To avoid any inadvertent biases, both fields were
analyzed by a coder who was blind to the participant’s
3
By using an iframe, the presentation space does not vary with
the size of browser window or the screen resolution of the
computer. Thus, participants with larger monitors would have a
larger white background framing the presentation space.

2397

attentional manipulation condition. Participants were
excluded only if they showed little or no evidence of
problem comprehension or engagement. Eighteen
participants were excluded under this criterion.
Demand Effects Participants were asked three funneled
questions to determine if they were aware of the
experimental manipulation. The most general one asked if
participants saw “a connection between the two tasks” The
narrower question asked if they thought the memory task
had changed their choice. Finally, the most pointed question
asked if the specific location of the rectangle had any effect
on their answer to the problem. Almost all participants
remained entirely unaware of the true intentions of the
experimental manipulation. However, three did correctly
identify the purpose of the attentional manipulation; their
data were excluded to avoid concerns about demand effects.

the performance values (91; 76), and vice versa; χ2 (1, N =
57) = 3, p = 0.042 (one-tailed). See Table 1.
Table 1: Effect of Attentional Focus on Choice of Car
[N = 57]
Attention to
Performance Ratings

Safety
Car
11
(48%)

Performance
Car
12
(52%)

Attention to Safety
Ratings

24
(71%)

10
(29%)

Question 2: Production Engineer
The following scenario was replicated from Tversky,
Sattath, & Slovic (1988).
You are an executive of a company. You have to
select between two candidates for the position of a
Production Engineer. The candidates were scored
on their technical knowledge and human relations
on a scale from 40 (very weak) to 100 (superb).
Both attributes are important, but technical
knowledge is slightly more important than human
relations. On the basis of the following scores,
which candidate would you choose?

Self-Report As a final methodology check, participants
were asked if they had used any tricks or strategies to
complete the task. They were clearly informed that they
would not be penalized for revealing them. Thirteen
participants admitted to using their fingers to mark the
memorized location on screen; data for those 13 participants
were excluded from further analysis.

Results
Question 1: Choosing Among Cars
Participants were asked to choose between two cars rated on
their safety and performance. The attribute values for each
option were mirrored such that the safety rating for Car A
was equal to the performance rating for Car B (shifted by 3
to occlude the mirroring), and vice versa. Car A was
superior on performance and Car B was superior on Safety.
For notational convenience, we will hereon refer to them as
the Performance and Safety cars respectively.

Candidate A
Candidate B

Table 2: Selection of Engineer Candidate

Car A
Car B

[N = 34]
Attention to Human
Relations Scores
Attention to Technical
Knowledge Scores

Performance
91
76

Effect of Attentional Manipulation The attribute values
displayed at the memorized location had an increased
influence on final choice. Participants who had the
memorized location overlap with the column of safety
values (73; 88) were more likely to select the safety car than
participants who had the memorized location overlap with

Human
Relations
76
91

Candidate A was superior on Technical Knowledge, while
Candidate B was superior on Human Relations; for
notational convenience, we refer to them as the Technical
Candidate and Sociable Candidate respectively.

You wish to buy a new car. You have narrowed the
choice to the two cars listed below. Both cars cost
the same. Each car is rated on safety and
performance using an industry-wide rating scale
ranging 0 (worst) – 100 (best). Based on the
ratings, which car would you buy?
Safety
73
88

Technical
Knowledge
86
78

Technical
Candidate
8
(44%)

Sociable
Candidate
10
(56%)

11
(69%)

5
(31%)

Effect of Attentional Manipulation The direction of
effects was consistent with Q1, however, the result only
approached statistical significance, with χ2 (1, N = 34) =
2.03, p = 0.08 (one-tailed). The non-significant outcome
may be in part due to the small participant pool. 4

4
The data for the final 27 participants was lost due to errors
with the database servers.

2398

Question 3: Manager of Engineers
Based upon the recall and reason responses from Question
2, it was clear that many participants were treating the claim
“technical knowledge is slightly more important than human
relations” as justification for limiting the decision scope to
technical knowledge alone. This trend was noticed in
Question 1 as well, where many participants interpreted
performance narrowly as referring to speed, and thereby
based their decision disproportionately on car safety alone.
Question 3 attempted to curb this tendency by ensuring
that both attributes were of equal importance, and a tradeoff was required across attributes. The scenario from Q2
was modified into a choice between two managerial
candidates, thereby increasing the natural importance of
human relations candidate scores. In addition, the
participants were told that “both attributes are very
important.” Finally, the difference between the two
candidates’ scores was made more extreme to increase the
perceived difference between them.

in Q2 & Q3). Similarly, we defined Option A as the choice
that is superior on the Attribute 1 (i.e. safety car in Q1;
technical candidate in Q2 & Q3), and Option B as the
choice that is superior on Attribute 2 (i.e. performance car
in Q1; sociable candidate in Q2 & Q3). Using this scheme
to collapse the data across Q1 – Q3, we found a highly
significant effect of attention on choice in favor of the
attended attribute, χ2 (1, N = 149) = 9, p = 0.001 (onetailed). See figure 3.

You are an executive of a company. You have to
select between two candidates for the position of
Manager of your Engineering Division. The
candidates were scored on their technical
knowledge and human relations on a scale from 40
(very weak) to 100 (superb). Both attributes are
very important. On the basis of the following
scores, which candidate would you choose?

Candidate A
Candidate B

T. Knowledge
57
88

H. Relations
91
60

Effect of Attentional Manipulation There was a
statistically significant effect of attentional manipulation on
choice, χ2 (1, N = 58) = 3.87, p = 0.02. As shown in Table 3,
the effect of the attentional manipulation was similar to the
effect of increased importance on the attended attribute.

Figure 3: Main Effect of Attention on Choice Behavior

Discussion

Table 3: Selection of Manager of Engineering Division
[N = 58]
Attention to Human
Relations
Attention to Technical
Knowledge

Technical
Candidate
10
(42%)

Sociable
Candidate
14
(58%)

23
(67%)

11
(32%)

Attentional Effects across Questions
Given the consistency of results across Q1 – Q3, we
examined the main effect of attention on choice behavior.
To do so, we defined Attribute 1 as the primary attribute in
each question, (i.e. safety in Q1 and technical knowledge in
Q2, 3). We defined Attribute 2 as the secondary attribute in
each question, (i.e. performance in Q1 and human relations

For all decision scenarios presented here, we found a direct
and positive relationship between the location of the
memorized rectangle and the amount of influence accorded
to the information presented at that location on screen. In
Question 1, participants were asked to choose between two
cars rated on their safety and performance. When the
memorized location overlapped with the performance
ratings, 52% selected the car that was superior on
performance, whereas only 29% made the same choice
when the memorized location overlapped with the safety
ratings. Similarly, in Question 2 and Question 3, when
choosing between two job candidates rated on technical
knowledge and human relations, the majority of participants
(69% in Q2 and 67% in Q3) preferred the technical
candidate when the memorized location overlapped with the
technical knowledge scores, but not when it overlapped with
human relations scores (only 31% in Q2 and 32% in Q3). It

2399

is notable that the effects of attentional manipulation were
remarkably consistent across the three decision scenarios.
These findings clearly demonstrate that the memory task
was – presumably through attentional allocation – causing
the participants to give that information greater influence in
the decision process. For all three questions, the attentional
manipulation increased the selection of the option that was
superior in attended attribute. This pattern of results is most
parsimoniously interpreted as a change in the weight
associated with the different attributes.
While previous claims have been made in this regard (e.g.
Carmon & Ariely, 2000; Weber & Kirsner, 1997), no
previous study had directly manipulated attention with the
express purpose of empirically verifying this relationship.
Some previous work had manipulated attention by indirect
techniques such as task (e.g. pricing vs. choosing, Tversky
et al., 1988), adopted role (e.g. statistician vs. clinical
psychologist, as cited in Kahneman & Frederick, 2002),
pursuit of information (e.g., Bastardi & Shafir, 1998) et
cetera. However, these studies face difficulties separating
the effects of attention from other effects.
The experimental manipulation presented here minimized
such externalities. It induced significant and systematic
changes in choice preference without altering any aspects of
the decision problem, the task instructions, or the techniques
used to elicit the preference values. Moreover, the vast
majority of participants remained unaware of the influence
on their decision making process.

Conclusion
The current work presents a novel methodology to reliably
and covertly manipulate the attention of an observer and
direct that attention to specific components of a decision
scenario. This methodology was deployed in the present
work to empirically examine the relationship between
attention and decision weight in a multi-attribute context.
It should be noted that although, in the scenarios chosen
here, additional attention bestowed greater importance upon
the attended attribute, there may be situations where the
relationship does not hold (e.g. as claimed by Bastardi &
Shafir, 1998; Bertini & Wathieu, 2008; Sherman et al.,
2005). If so, the current design provides a systematic
method to examine such exceptions to the oft-assumed
direct, positive link between attention and importance.
Finally, the current work also reaffirms the unique
potential of crowdsourcing psychological research,
including studies that have various perceptual components.
Although the data validity concerns and exclusion rates may
be higher than expected at a physical lab, the current work
confirms that a carefully designed system of precautions and
catch mechanisms can be used to overcome these limitations
and take advantage of this new and underutilized resource.

Acknowledgements
We would like to sincerely thank Emir Kamenica, Joshua
Stevenson and Andres Millan for their assistance with the
design, implementation, and manuscript, respectively.

References
Awh, E. & Jonides, J. (2001). Overlapping mechanisms of
attention and spatial working memory. Trends in
Cognitive Science, 5(3), 119 – 126.
Awh, E., Jonides, J., & Reuter-Lorenz, P.A. (1998).
Rehearsal in Spatial Working Memory. Journal of
Experimental Psychology: Human Perception and
Performance. 24(3), 780-790.
Awh, E., Vogel, E. K., & Oh, S. H. (2006). Interactions
between attention and working memory. Neuroscience,
139, 201-208.
Bastardi, A., & Shafir, E. (1998). On the pursuit and misuse
of useless information. Journal of Personality and Social
Psychology, 75, 1, 19-32.
Bertini, M., & Wathieu, L. (2008). Research Note-Attention Arousal Through Price Partitioning. Marketing
Science, 27(2), 236-246.
Busemeyer, J. R. and J. G. Johnson (2008). Micro-process
Models of Decision Making. R. Sun (Ed.) Cambridge
Handbook of Computational Cognitive Modeling.
Cambridge University Press, p. 302 – 322.
Carmon, Z. & Ariely, D. (2000), Focusing on the Forgone:
How Value Can Appear So Different to Buyers and
Sellers, Journal of Consumer Research, 27 (3), 360-370.
Downing, P. E. (2000). Interactions between visual working
memory and selective attention. Psyc. Sci., 11, 467–473.
Horton, J. J., Rand, D. G. and Zeckhauser, R. J. (2010). The
Online Laboratory: Conducting Experiments in a Real
Labor Market (April 16, 2010). Available at SSRN:
http://ssrn.com/abstract=1591202
Kahneman, D. & Frederick, S. (2002). Representativeness
revisited: Attribute substitution in intuitive judgment. pp.
49-81 in T. Gilovich, D. Griffin, and D. Kahneman [eds].
Heuristics & Biases: The Psychology of Intuitive
Judgment. New York. Cambridge University Press.
Paolacci, G., Chandler, J., and Ipeirotis, P. G. (2010).
Running Experiments on Amazon Mechanical Turk.
Judgment and Decision Making, 5(5), 411-419. Available
at SSRN: http://ssrn.com/abstract=1626226
Sherman, J. W., Stroessner, S. J., Conrey, F. R., & Azam,
O. (2005). Prejudice and stereotype maintenance
processes: Attention, attribution, and individuation.
Journal of Personality and Social Psych., 89, 607-622.
Soto, D., Hodsoll J., Rotshtein, P., & Humphreys G. W.
(2008). Automatic guidance of attention from working
memory. Trends in Cognitive Science, 12, 342-348.
Theeuwes J., Belopolsky A., Olivers C.N. (2009)
Interactions between working memory, attention and eye
movements. Acta Psycholgica.
Tversky, A., Sattath, S., & Slovic, P. (1988). Contingent
weighting in judgment and choice. Psychological review,
95(3), 371 – 384.
Weber E. U. & Johnson, E. J. (2009). Mindful judgment and
decision making. Annual Review of Psyc., 60, 53 – 85.
Weber, E. U., & Kirsner, B. (1997). Reasons for RankDependent Utility Evaluation. Journal of Risk and
Uncertainty, 14(1), 41-61.

2400

