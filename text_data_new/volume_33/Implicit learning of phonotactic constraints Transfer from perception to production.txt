UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Implicit learning of phonotactic constraints: Transfer from perception to production

Permalink
https://escholarship.org/uc/item/7mn0p359

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Kittredge, Audrey K.
Dell, Gary S.

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Implicit learning of phonotactic constraints: Transfer from perception to
production
Audrey K. Kittredge (akittre2@illinois.edu)
Beckman Institute, University of Illinois
405 N. Matthews Ave., Urbana, IL 61801, USA

Gary S. Dell (gdell@cyrus.psych.uiuc.edu)
Beckman Institute, University of Illinois
405 N. Matthews Ave., Urbana, IL 61801, USA
Abstract
This study asked whether new linguistic patterns acquired
through recent perception experience can transfer to speech
production. Participants heard and spoke sequences of
syllables featuring novel phonotactic constraints (e.g. /f/ is
always a syllable onset, /s/ is always a syllable coda).
Participants’ speech errors reflected weaker learning of the
constraints present in the spoken sequences (e.g. /f/ must be
onset) when they heard sequences with the inverse constraints
(e.g. /f/ must be coda), suggesting that the constraints
experienced in perception interfered with learning in
production. The results did not depend on the presence of a
shared orthographic code in perception and production trials,
suggesting that direct transfer between heard speech and
produced speech is possible, perhaps through prediction via
inner speech. Further work is needed to determine the exact
mechanism supporting inter-modality transfer of phonological
generalizations.
Keywords: phonotactic learning; transfer of learning;
implicit learning; prediction; orthography.

Introduction
Humans have a remarkable ability to implicitly learn
sequential patterns in a variety of knowledge domains (e.g.
Alsin & Newport, 2008). This ability is especially important
in language, where it has been hypothesized that linguistic
structures are acquired, at least in part, through domaingeneral learning principles (e.g. Dell, Juliano, & Govindjee,
1993; Elman, 1990). Although much work on implicit
pattern detection in language has focused on word
identification, investigating learning of more rule-like
systems, such as phonotactics, is key to understanding
language acquisition. Phonotactics are the constraints on
possible sound sequences in a language; for example, the
sound combination /sr/ can appear as an onset (beginning of
a syllable) in Russian (“sravnivat”, to compare), but not in
English. These constraints affect both our language
perception (we expect to hear sequences of sounds that
follow the phonotactics of our language) and production
(our speech conforms to our language’s phonotactics).
Native speakers of a language acquire some phonotactic
knowledge in the first year of life. Moreover, infants can
rapidly learn new artificial phonotactic constraints in
laboratory settings simply by listening to syllables that

follow the constraints (Chambers, Onishi, & Fisher, 2003).
This ability is not unique to children; adults, too, learn new
phonotactic constraints. They can even acquire constraints
in opposition to native-language phonotactics (e.g. English
speakers learning than /ng/ can be an onset, Whalen & Dell,
2006), as when learning a foreign language.
Several studies with adult participants have demonstrated
phonotactic learning within the auditory speech-processing
system. Participants are exposed to syllables that exhibit
new phonotactic constraints, such as /p/ always occurring as
an onset, and never in syllable-final (coda) position. After
listening to these syllables, participants are more likely to
accept novel syllables as familiar if they obey, rather than
disobey, the constraint (Bernard & Fisher, 2010), and are
slower to shadow those that violate the constraint (Onishi,
Chambers, & Fisher, 2002). Adults can acquire new
phonotactic constraints in language production, as well as in
perception. After just 9 trials of producing sequences of
syllables that follow a novel constraint, participants’ speech
errors obey the novel constraint (Taylor & Houghton, 2005).
For example, the slips of participants producing syllables, in
which /f/ is always an onset and /s/ is always a coda, will
mirror that distribution: /f/’s will erroneously move to onset
positions, and /s/’s to coda positions (see also, Dell, Reed,
Adams, & Meyer, 2000; Warker & Dell, 2006). These
production studies thus stand as an experimental analogue to
the well known tendency for everyday speech errors to
follow the phonotactics of the language one is speaking (e.g.
Fromkin, 1971). For example, because English disallows
onset /ng/, slips never create such syllables, even though
they commonly create nonwords with /ng/ codas.
Phonotactic constraints are first encountered and acquired
through listening to language. Eventually, they are also
reflected in spoken language. How do they get there? The
above studies demonstrate that phonotactic learning can
occur within the perception and production systems.
Consistent with this, neuropsychological data strongly
suggest that separate phonological representations are
employed in speech perception and production (e.g. Martin,
2003). Are speakers obliged to learn the same constraints
separately through listening and speaking, or is it possible
for learning to transfer from perception to production? More
broadly, how efficient is phonotactic learning? What is its
scope and generalizability?

2679

In our experimental paradigm, participants alternate
between listening to and rapidly speaking sequences of
syllables that follow English phonotactics (e.g. “hes meg fen
keng”). Some consonants’ positions are “restricted”
(English /h/ can only be an onset, and /ng/ can only be a
coda), while others are “unrestricted” (e.g. /k/, /g/, /m/ and
/n/ can appear freely as onsets and codas). Crucially, two
consonants (/f/ and /s/), which are unrestricted in English,
are restricted in the experiment. For some participants, /f/
will always be an onset and /s/ will always be a coda, and
others will experience the reverse. When quickly producing
such sequences, participants tend to make speech errors (e.g.
“hes meg feng keng” instead of “hes meg fen keng”). Errors
involving /h/ and /ng/ will almost always be legal (obey the
language-wide constraints, e.g. /ng/ can only slip to coda
position). This is the well known phonotactic regularity
effect on speech errors. The key findings will concern the
experimentally restricted consonants. If errors involving /f/
and /s/ tend to be legal according to the experiment-specific
constraints, we can conclude that the constraints have been
acquired by the language production system.
We investigate transfer from perception to production by
manipulating the relationship between constraints
experienced in perception and production. In an Oppositeconstraint condition, the constraint in sequences that are
only heard (e.g. /s/-onset, /f/-coda) is the inverse of the
constraint present in sequences to be spoken (/f/-onset, /s/coda). If there is robust transfer between perception and
production, we should see no evidence of the /f/-onset, /s/coda constraint in participants’ speech errors, because the
constraints will cancel out one another. There is no longer
any restriction of /f/ to onset in production if, half the time,
it is heard as a coda, and if this perceptual experience is
integrated with production experience. If there is no
transfer, we should see strong evidence of the production
constraint in speech errors. Participants in a Same-constraint
condition (e.g. /f/-onset, /s/-coda in both perception and
production sequences) should produce errors that obey the
constraint, regardless of whether or not there is transfer.
Using this paradigm, Warker, Xu, Dell, and Fisher (2009)
found little evidence for transfer. Nothing was found in their
first two experiments and a third found weak transfer
(learning of the constraint present in spoken syllables
differed to a small extent between the Same- and Oppositeconstraint conditions). Assuming this latter result is
replicable, the various ways in which the third experiment
differed from the others leaves open several possible
mechanisms of transfer. Transfer could easily have been
mediated by orthography. On perception trials, participants
listened to sequences spoken by another participant while
checking them for errors against a written version, and the
production task used written presentation of the sequences
as well. Thus, the perceptual and production experiences
actually shared a visual representational format.
There is another, more intriguing explanation for the
partial transfer observed by Warker et al. (2009). A recent
computational model of sentence production learns to

“speak” simply from “listening,” rather than from direct
production experience (Chang, Dell, & Bock, 2006). The
model predicts upcoming words in the sentences that it
comprehends, and its learning consists of adjusting its
ability to predict (e.g. Elman, 1990). Prediction (the
generation of expected words and structures) is a process
akin to language production, but without articulatory
realization. Consequently, learning from comprehension
transfers seamlessly to production. The idea that active
prediction occurs during comprehension and that prediction
is carried out by the production system has become an
important component of modern psycholinguistic theory
(e.g. Federmeier, 2007; Pickering & Garrod, 2007).
While participants in Warker et al. (2009) were listening,
perhaps they were predicting upcoming syllables based on
the written text used to check sequences for errors. If the act
of prediction activates the production system, this would
allow the constraint present in heard sequences to interfere
with constraints learned during the speaking trials.
Heightened attention to the syllables, required by the error
monitoring task, may have facilitated transfer as well.
To investigate the robustness and origin of partial transfer
of phonotactic constraints, we explicitly investigated the
two hypothesized mechanisms for transfer: prediction and
orthography. On each perception trial, participants heard a
sequence (e.g. “hes meng fen kes”) twice. Their task was to
report whether the second presentation of the sequence
deviated from the first (e.g. “hes neng fen kes” has an error
on the second syllable). Our task forced the participants to
form an expectation or prediction of which syllables were
about to be heard. For half of the subjects, the first auditory
presentation was accompanied by a written version
presented on a computer screen (Orthography condition).
We predict that if transfer is mediated by orthography, only
participants in the Opposite-constraint, Orthography
condition should show transfer. If transfer is mediated by
prediction, all participants in the Opposite-constraint
condition should show transfer, regardless of whether they
received orthographic input.

Methods
Participants
Thirty-two University of Illinois students participated for
psychology course credit. Participants were native English
speakers with normal or corrected-to-normal vision and
hearing, and no known linguistic or psychiatric disorders.

Stimuli
A total 384 sequences of four syllables were generated by
randomly scrambling 8 consonants (/h/, /ng/, /f/, /s/, /m/, /n/,
/k/, /g/) and inserting the vowel /ε/ into the resulting syllabic
structures (e.g. heng fes men keg). All sequences obeyed
English phonotactics (/h/ was always an onset and /ng/
always a coda). Half of the sequences only featured /f/-

2680

onsets and /s/-codas (the “fes constraint”), while the other
half only featured /s/-onsets and /f/-codas (the “sef
constraint”). The 384 sequences were arranged into 4 lists,
two lists featuring the fes constraint, and two featuring the
sef constraint. Participants in the Opposite-constraint
condition were assigned to lists with different constraints in
perception and production (either perception-sef and
production-fes or the reverse), while participants in the
Same-constraint condition were assigned to perception and
production lists with the same constraint (both fes or sef).
Deviant versions of 49 sequences in each perception list
were created that contained “errors” for the participants to
detect during error monitoring. These errors were similar to
those made by participants in Warker et al. (2009), except
that no errors occurred on restricted consonants /f/ and /s/.
The deviant sequences were distributed randomly
throughout the experiment. All perception trial stimuli were
produced by a female native English speaker from Illinois.

Procedure
Participants viewed stimuli on a Dell computer screen and
received auditory input through a set of external speakers.
Participants’ voices were recorded by a lapel microphone
which fed into a Marantz digital recorder.
Participants alternated between perception and production
trials, completing 96 of each type. On a perception trial
(cued by a picture of an ear), the numbers 1 2 3 4 appeared
in a row on the screen. Subjects heard a sequence of
syllables, in which the first syllable was “1”, the second “2”,
etc.. Subjects in the Orthography condition saw a written
version of each syllable appear on the screen as it was
spoken. Next, a gray bar with exclamation marks was shown
for 750 ms to cue readiness for the monitoring task. On the
next screen, all subjects saw the numbers and listened to a
second version of the sequence, which contained errors on
0, 1 or 2 consonants. Subjects were instructed to type in the
numbers corresponding to any syllables that contained
errors, and to type 0 if there were no errors.
On a production trial (cued by a picture of lips), a
sequence of syllables appeared in smaller font at the bottom
of the screen. Participants were instructed to press a space
bar to start a metronome (2.53 beats per second), wait for 4
beats, and say the sequence twice, timing each syllable to a
beat. Producing all syllables was emphasized over accuracy.
Participants practiced perception and production trials
before the experiment. The entire procedure, including 2
breaks, took approximately half an hour.

Coding performance in error monitoring task
If a participant correctly detected the presence of any
error(s), this was counted as a “correct” response. False
alarms (reporting an error when there were none), misses
(reporting no errors when there was at least one), and
omission responses were coded as “incorrect”.

Coding speech errors made on production trials
Speech errors were coded offline. Errors in which one
consonant was replaced by another from the sequence were
classified as legal or illegal by the original location of the
error consonant in the target sequence. For example, given
the target “hes meg fen keng” and the errorful sequence
“hes mek feng g-…keng”, the /ng/ in “feng” would be
classified as a legal error (/ng/ kept its position as a coda),
while the /k/ in “mek” would be classified as an illegal error
(/k/ moved from onset position to coda position). Cutoff
errors such as “g-…keng” were included in the analysis;
omissions, intrusions of consonants not present in the
sequence, and unintelligible responses were excluded.

Statistical analysis
A hierarchical logistic regression model was fit to the
speech-error data, and focused on the extent to which each
error was legal (maintained its status as onset or coda) or
illegal (moved to a different position). As the hypotheses of
interest dealt only with differences between experimentally
restricted consonant (/f/, /s/) and unrestricted consonant (/k/,
/g/, /m/, /n/) errors, language-wide restricted consonant (/h/,
/ng/) errors were excluded from the regression analysis.
The log odds of an error being legal was predicted from
constraint (a contrast-coded variable, Same-constraint
condition vs. Opposite-constraint condition), orthography
(contrast-coded variable, Orthography condition vs. No
orthography condition), restrictedness (a dummy-coded
variable where 1=restricted consonant error and
0=unrestricted consonant error), and their interactions. A
random error term was also included to model betweensubject variability.
Two additional hierarchical logistic regression analyses
were run, one on the data from participants in the Sameconstraint condition only, and one on data from the
Opposite-constraint condition only. In each case, the log
odds of an error being legal was predicted from
restrictedness and a subject random error term.

Results
A total of 2203 consonant errors were made by the 32
participants, for an overall error rate of 4.4% per consonant.
Of these, 1577 met inclusion criteria for statistical analysis.
Participants in the Same-constraint condition showed
good evidence of learning: on average, only 1.0% of all
experimentally-restricted consonant errors were illegal (see
Figure 1), a rate nearly identical to that found for languagewide restricted consonant (/h/ and /ng/) errors (1.1%). Even
though these participants had never before encountered the
experimental constraints, their slips followed them as
strongly as they followed the constraints learned from a
lifetime of speaking English. By contrast, on average
31.9% of all unrestricted consonant errors were illegal (see
Figure 2), significantly more than for slips of the

2681

experimentally restricted consonants (coefficient = 3.404,
standard error = 0.725, p < .001). More unrestricted
consonant errors are legal than would be expected by chance
(illegality is below 50%) because even unrestricted
consonants tend to stick to their syllable positions in a
sequence (MacKay, 1970).
Errors from participants in the Opposite-constraint
condition showed a different profile (Figure 1). Most
importantly, there was evidence of transfer between
perception and production: restricted consonants were
illegal 13.5% of the time on average in the Oppositeconstraint condition, more than ten times the illegality rate
in the Same-constraint condition. By contrast, the illegality
rate of unrestricted consonants in the Opposite-constraint
condition (36.3% on average) was comparable to that in the
Same-constraint condition, an expected result given that
unrestricted consonants did not differ in their distribution
across conditions (Figure 2). The interaction between
constraint and restrictedness was significant (coefficient =
1.049, standard error = 0.384, p = .006).
We can be sure that participants learned the constraints
present in heard sequences, because these interfered with
(Opposite-constraint condition) and/or enhanced (Sameconstraint condition) the constraints learned in production,
as revealed by their speech errors. This interpretation is
bolstered by good error monitoring accuracy of participants
in the Opposite- (71.5%) and Same- (73.5%) constraint
conditions. This suggests that participants did indeed engage
in the task designed to make them predict during perception
trials: they remembered the first presentation and used it to
monitor the second presentation of the sequence.
The transfer between perception and production, however,
was only partial, like that found by Warker et al. (2009).
Participants in the Opposite-constraint condition still
showed evidence of the production constraint in their speech
errors: experimentally restricted consonant errors had a
higher legality rate than unrestricted consonant errors
(coefficient = 1.266, standard error = 0.235, p < .001).
The orthographic manipulation, unlike Same- vs.
Opposite-constraint, did not influence speech errors (see
Figures 1 and 2). Most importantly, the presence of
orthography did not modulate the transfer effect: the
interaction of orthography with constraint was not
significant for restricted consonants (coefficient = 0.073,
standard error = 0.384, p = .850). This was true even though
seeing orthography during the perception task slightly
increased error detection accuracy (76.1% in the
Orthography condition, compared to 69.0% in the No
orthography condition). There was also no significant main
effect of orthography on error legality for unrestricted
consonants (coefficient = -0.407, standard error = 0.087, p =
.589) or restricted consonants (coefficient = -0.107, standard
error = 0.384, p = .781). Although these null effects must be
interpreted with caution, they suggest that orthography is
not the mechanism leading to the transfer of phonotactic
constraints between perception and production.

Figure 1: percentages of restricted consonant errors that
are illegal across conditions, with standard error of the mean

Figure 2: percentages of unrestricted consonant errors that
are illegal across conditions, with standard error of the mean

General Discussion
Previous work has shown that transfer of newly acquired
phonotactic constraints between the perception and
production systems is difficult to achieve, but may be
possible under some circumstances (Warker et al., 2009).
Moreover, little is known about possible mechanisms for
transfer. We explored two such mechanisms: the presence of
orthographic mediating representations, and the prediction
(via the production system) of upcoming sound sequences
during perception. On alternating trials, participants either
listened to, or produced, sequences of syllables (“mek nes
feng heg”) containing either identical or opposing artificial
phonotactic constraints. Weakened sensitivity to the
production constraint in the speech errors of participants
who received opposite constraints indicates transfer between
perception and production. Participants receiving identical
constraints in perception and production should show good
learning of the production constraint in their slips. An
additional manipulation of the presence or absence of
orthographic input during perception allowed us to evaluate
its effect on transfer.

2682

Speech errors collected from participants clearly showed
partial transfer of constraints between perception and
production. The transfer effect is, thus, robust and, given
the third experiment of Warker et al. (2009), replicable.
Under the right conditions, learning of phonotactic
constraints in one modality leads to their expression in
another modality.
Our results go beyond previous findings by showing that
the difference between the Same- and Opposite-constraint
conditions is truly due to transfer between the speech
modalities. The presence of orthography during both
perception and production trials in Warker et al. (2009)
meant that learning and interference could have taken place
at a common, orthographic level. We found a partial transfer
effect independent of orthographic input during perception,
suggesting that learning from heard speech transfers to
produced speech.
The null effect of orthography condition also weakens
other hypotheses in which orthography mediates transfer.
Thus, enhanced processing of the syllables that could arise
from multimodal presentation does not seem to be necessary
for transfer. Similarly, activation of production phonology
from orthography is not a likely mechanism.
If orthography is not the key to transfer, then what is? In
order for constraints in perception to transfer to production,
production phonology must have been activated during the
perception task. Our results leave open several possible
mechanisms of this activation. We designed our perception
task to induce prediction of upcoming sequences:
participants were expecting the second sequence to be
identical or nearly identical to the first, and so they may
have mentally anticipated the syllables before the second
presentation (it is unlikely that they mouthed them, as all
participants were explicitly instructed not to do so). The task
used in Warker et al. (2009)’s successful transfer study may
also have encouraged prediction. The exact nature of the
prediction participants engaged in is unclear, although it is
possible that they were using inner speech (the “little voice
in your head”). Inner speech is much like overt speech,
except that lower (e.g. articulatory) levels of representation
are not activated (Oppenheim & Dell, 2008). In our
experiment, the individual sounds of an upcoming sequence
could be activated in production phonology by inner speech.
In this way, constraints present in the heard sequences
would also effectively be “produced”, and could interfere
with the constraint present in the spoken sequences, since
they are mapped onto the same level(s) of representation.
The transfer may be partial because production phonology is
only weakly activated by inner speech (as compared to overt
speech production; Oppenheim & Dell, 2008), and thus the
constraint present in perception sequences may not be
represented as robustly.
Inner speech is not so different from the sort of prediction
thought to take place in everyday language processing
(Federmeier, 2007). Although prediction at the phonological
level may not be ubiquitious in normal language
comprehension, it does occur if contextual constraints are

sufficiently strong (e.g. DeLong, Urbach, & Kutas, 2005). If
future work determines that prediction during input
processing leads to transfer, this would support the viability
of language comprehension theories that incorporate
prediction (Federmeier, 2007), and language acquisition
theories in which comprehension practice trains production
(Chang et al., 2006).
There are, however, other mechanisms that could explain
the transfer effect besides prediction via inner speech.
Participants had to remember the first presentation of a
sequence for the monitoring task, and so they may have
subvocally rehearsed the first presentation to check it
against the second presentation. Rehearsal could even have
been simultaneous with perception, rather than anticipatory.
In this case, production phonology would be activated via
deliberate rehearsal, rather than more implicit prediction.
Indirect activation of production phonology could also
have contributed to the transfer effect. The perception trials
in our study and in the successful transfer study of Warker
et al. (2009) required participants to monitor for errors, a
task involving active processing of the sequences. Perhaps
all that is needed for transfer is any kind of task that requires
attention. We note, however, that no transfer was found in
the experiment from Warker et al. (2009) in which the
perception task consisted of monitoring the perceived
syllables for a specific target syllable (always “heng”). So,
not just any attention-demanding task creates transfer. It is
possible, though, that monitoring for error specifically
increased attention to individual phonemes of the perceived
sequence, and that the resulting high activation of perceptual
phonology led to partial activation of production phonology.
Although our results cannot rule out these mechanisms,
follow-up studies addressing this issue are under way.
Our results can also speak to the degree of overlap
between phonological representations in perception and
production. If we know the degree of overlap, we can know
whether to expect transfer. For example, if you learn how to
hear the difference between /r/ and /l/, will you then know
how to produce the difference? If the representations are
completely shared between modalities, one would expect so.
Taking together our findings and those of Warker et al.
(2009), the fact that only two out of four experiments found
transfer, and that that transfer was incomplete, suggests that
representations mediating phonotactic learning are
modality-specific. If representations were shared across
modalities, participants would be able to learn modalityindependent phonotactic constraints from either perception
or production experience. However, it seems that only under
certain conditions can knowledge learned in one modality
transfer to another. For example, transfer of phonotactic
constraints may happen as a result of direct activation of
production phonology during perception (prediction), which
could take place in a system with completely separate
perception and production phonologies.
The partial transfer observed in the domain of
phonotactics stands in contrast to the full transfer observed
in the domain of syntax. Hearing a prime syntactic structure

2683

makes the listener as likely to produce that structure
compared to when the prime structure is spoken (Bock,
Dell, Chang, & Onishi, 2007). This result is taken to suggest
that syntactic-level representations are fully shared between
production and comprehension. Perhaps transfer at lower
levels of linguistic structure is not likely to be more than
partial because, as one approaches the periphery (audition
vs. articulation), input- and output-oriented representations
must necessarily diverge.
Addressing the issue of transfer is not only important for
investigating the structural overlap between comprehension
and production, but it also has implications for second
language acquisition. Although our experiment focuses on
learning of English phonotactic constraints, other work has
found implicit learning of non-English phonotactics by
native-English adults in laboratory settings (e.g. Whalen &
Dell, 2006). Is transfer from perception to production
possible for these sorts of constraints, as well? Learning a
second language in adulthood is notoriously difficult, and so
knowing which aspects must be acquired through direct
production experience, and which can be subtly trained
through comprehension, would be of great theoretical and
educational interest.

Acknowledgments
This research was supported by the NIH (HD-44458 and
DC-00191) and a National Science Foundation graduate
research fellowship. Thanks to Pamela Glosson for help in
recording, to three anonymous reviewers for their
suggestions, and to the members of the University of Illinois
Phonotactic Learning Group and Language Production Lab
(especially Nazbanou Nozari) for insightful discussion.

References
Aslin, R. N., & Newport, E. L. (2008). What statistical
learning can and can’t tell us about language acquisition.
In J. Colombo, P. McCardle, and L. Freund (eds.), Infant
Pathways to Language: Methods, Models, and Research
Directions. Mahwah, NJ: Lawrence Erlbaum Associates.
Bernard, A., & Fisher. C., (2010). An onset is an onset:
abstraction of newly-learned phonotactic constraints.
Paper presented at the Annual Meeting of the
Psychonomic Society, St. Louis, MO, United States.
Bock, K., Dell, G. S., Chang, F., & Onishi, K. H. (2007).
Persistent
structural
priming
from
language
comprehension to language production. Cognition, 104,
437-458.
Chambers, K. E., Onishi, K. H., & Fisher, C. (2003). Infants
learn phonotactic regularities from brief auditory
experience. Cognition, 87, B69-B77.
Chang, F., Dell, G. S., & Bock, K. (2006). Becoming
syntactic. Psychological Review, 113, 234-272.
Dell, G. S., Juliano, C., & Govindjee, A. (1993). Structure
and content in language production: A theory of frame

constraints in phonological speech errors. Cognitive
Science, 17, 149-195.
Dell, G. S., Reed, K. D., Adams, D. R., & Meyer, A.S.
(2000). Speech errors, phonotactic constraints, and
implicit learning: A study of the role of experience in
language
production.
Journal
of
Experimental
Psychology: Learning, Memory, and Cognition, 26, 13551367.
DeLong, K. A., Urbach, T. P., & Kutas, M. (2005).
Probabilistic word pre-activation during language
comprehension inferred from electrical brain activity.
Nature Neuroscience, 8, 1117-1121.
Elman, J. L. (1990). Finding structure in time. Cognitive
Science, 14, 179-211.
Federmeier, K. D. (2007). Thinking ahead: The role and
roots of prediction in language comprehension.
Psychophysiology, 44, 491-505.
Fromkin, V. A. (1971). The non-anomalous nature of
anomalous utterances. Language, 47, 27-52.
MacKay, D. G. (1970). Spoonerisms: the structure of errors
in the serial order of speech. Neuropsychologia, 8, 323350.
Martin, R. C. (2003). Language processing: Functional
organization and neuroanatomical basis. Annual Review
of Psychology, 54, 55-89.
Onishi, K. H., Chambers, K. E., & Fisher, C. (2002).
Learning phonotactic constraints from brief auditory
experience. Cognition, 83, B13-B23.
Oppenheim, G. M., & Dell, G. S. (2008). Inner speech slips
exhibit lexical bias, but not the phonemic similarity
effect. Cognition, 106, 528-537.
Oppenheim, G. M., & Dell, G. S. (2010). Motor movement
matters: the flexible abstractness of inner speech. Memory
& Cognition, 38 (8), 1147-1160.
Pickering, M. J., & Garrod, S. (2007) Do people use
language production to make predictions during
comprehension? Trends in Cognitive Sciences, 11, 105110.
Taylor, C. F., & Houghton, G. (2005). Learning artificial
phonotactic constraints: Time course, durability, and
relationship to natural constraints. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 31, 1398-1416.
Warker, J. A., & Dell, G. S. (2006). Speech errors reflect
newly learned phonotactic constraints.
Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 32, 387-398.
Warker, J. A., Xu, Y., Dell, G. S., & Fisher, C. (2009).
Speech errors reflect the phonotactic constraints in
recently spoken syllables, but not in recently heard
syllables. Cognition, 112, 81-96.
Whalen, C.A., & Dell, G.S. (2006). Speaking outside the
box: Learning of non-native phonotactic constraints is
revealed in speech errors. Proceedings of the 28th Annual
Conference of the Cognitive Science Society (pp. 23712374). Vancouver, BC: Lawrence Erlbaum Associates.

2684

