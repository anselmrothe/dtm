UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visualizing Feedback: Using Graphical Cues to Promote Self-Regulated Learning

Permalink
https://escholarship.org/uc/item/7cg520kj

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Ferrera, Lisa
Butcher, Kirsten

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Visualizing Feedback: Using Graphical Cues to Promote Self-Regulated Learning
Lisa Ferrara (lisa.ferrara@utah.edu)
Department of Educational Psychology, 1705 Campus Center Dr, MBH 327
Salt Lake City, UT 84112 USA

Kirsten R. Butcher (kirsten.butcher@utah.edu)
Department of Educational Psychology, 1705 Campus Center Dr, MBH 327
Salt Lake City, UT 84112 USA
Abstract

Self-Regulated Learning in Online Environments

We examined whether the addition of graphical cues on a
concept map could promote self-regulated learning with
online materials. College-aged students were provided with
concept map visualizations to guide revisions of a scientific
essay. These visualizations varied in their use of two
graphical cues: color-coded nodes that indicated error types
and size-scaled nodes that indicated the importance of domain
ideas. Metacognitive strategies were assessed using students’
self-reported visualization use and essay changes. Learning
was assessed via true/false items, short answer questions, and
self-generated concept maps. Results indicated that colorcoding promoted better revision strategies, and both graphical
cues supported deeper understanding of domain content
compared to a typical concept map display. Implications are
discussed for visual display designs that provide meaningful
feedback during online learning.
Keywords: visualization; graphical display; self-regulated
learning; multimedia; online learning

Introduction
Prior research has demonstrated that students experience
many challenges in regulating their own learning in online
environments (e.g., Azevedo, Guthrie, & Seibert, 2004).
Because these online environments are inherently nonlinear
and user-controlled, effective learning requires students to
plan, monitor, and reflect in meaningful ways as they work
with Web materials (e.g., Williams, 1996). Significant
challenges remain in finding instructional strategies and
materials that will support learners in the cognitive and
metacognitive processes necessary to promote effective selfregulated, online learning. In this research we explored the
potential benefits of using graphical cues (e.g., color-coding
and size-scaled nodes) in concept maps to help guide
students in effective self-regulated learning with online
resources. Concept maps may serve as an effective
advanced organizer for online learning, because they depict
a coherent conceptual structure that may be difficult to
extract from unorganized, online content. Prior research has
shown that, for a given set of learning materials, concept
map visualizations enhance the saliency of text
macrostructures (O'Donnell, Dansereau, & Hall, 2002).
Although concept maps have repeatedly been shown to
enhance recall of main ideas from text, there has been little
evidence that these visualizations can support knowledge
transfer or effective metacognitive processing during
learning.

Online learning involves comprehension across many
media-rich resources presented in a non-linear environment.
Learning online (i.e., from the Web) is a complex task that
involves both information search and retrieval (e.g.,
Marchionini, 1995, 2006) and comprehension of a variety of
materials that lack overall coherence (e.g., Lynch, 2008).
Searching for information online is a self-regulatory
challenge because (among other demands) it requires
planning a search strategy based upon individual learning
goals. Assuming that students are able to complete the
difficult task of finding and selecting relevant Web-based
materials, they then face the challenge of successfully
regulating their learning processes in order to develop
meaningful domain understanding from the online resources
themselves (e.g., Azevedo, Guthrie, & Seibert, 2004; Winne
& Perry, 2000). Part of this self-regulated learning challenge
is that learners must manage multiple, competing cognitive
demands as they work with online materials. In the next
section, we discuss the cognitive processes associated with
self-regulated learning.
Processes of Self-Regulated Learning In online learning
environments, students must make learning decisions (e.g.,
what are the most important ideas/concepts), plan how to
learn targeted information, and constantly monitor their
developing understanding (Williams, 1996). To effectively
self-regulate, learners must monitor their knowledge
development as they engage in planning effective learning
strategies – overall, they must be strategic in these efforts,
knowing when and how to adapt these strategies to match
cognitive, motivational, and task conditions (e.g., Winne,
2001).
Research has revealed that learners typically demonstrate
great difficulty in self-regulating their learning when using
online environments to learn about complex topics, such as
science; in the face of these challenges learners sometimes
experience little overall knowledge gain even after online
study (e.g., Azevedo & Cromley, 2004). Less effective
learners in these online environments frequently lack
effective planning, goal setting, monitoring of
understanding, effective strategy use, and reflection on their
overall learning progress.
In this research, we were particularly interested in
effective planning during self-regulated, online learning.
Planning is an important part of online learning because it

1880

influences the ways that students seek information (i.e.,
search for resources online), in addition to the ways that
they comprehend it (i.e., learning from the online
resources).

processing or deeper understanding (as opposed to simple
recall) during learning.

Supporting Self-Regulated Learning Various methods
have been investigated to support self-regulated learning in
online environments; these methods include training in the
processes of self-regulated learning (Azevedo & Cromley,
2004) and providing scaffolding hints and prompts during
hypermedia learning (Azevedo, Cromley, & Seibert, 2004).
Although both methods have shown promise, they also are
relatively resource-intensive and may be difficult to scale
into larger practice. For example, in Azevedo et al. (2004),
adaptive scaffolding provided by human tutors facilitated
the greatest gains in learning and the most effective selfregulated learning processes.
In this research, we explore the possibility of utilizing
visual displays and graphical cues to support effective selfregulated learning while searching for and learning with
online materials.

Learning with Visual Displays
Visual Displays and Learning Research on visual displays
has demonstrated that the structure of a visual representation
can change the knowledge representations formed by
learners. For example, representing two steps in a process as
occurring simultaneously in a visual graphic leads to closer
association between the steps (as measured by reaction
time) than when the steps are described as occurring
simultaneously but appear linear in text order (Glenberg &
Langson, 1988). Adjunct visual displays (i.e., cause-andeffect diagrams accompanying text) facilitated better
comprehension and causal understanding than when learners
were provided with text alone or cause-effect statements in a
list form (McCrudden, Schraw, & Lehman, 2009).
Research in online reading and comprehension of
hypertext indicates that graphical displays can impact the
quality of students’ comprehension, likely by providing a
conceptual structure to hypertext materials. Salmerón et al.
(2009) found that graphical overviews studied prior to
reading complex hypertext content led to greater
comprehension, even when participants had little or no prior
knowledge. Students learn more when they follow online
links in an order that is driven by conceptual coherence
rather than student interest (Salmerón, Kintsch, & Cañas,
2006), but students with low prior knowledge most often
choose links based upon screen position or interest
(Salmerón, Kintsch, and Kintsch (2010).
The graphical overviews used by Salmerón et al. (2009)
to structure hypertext learning are similar to concept maps,
which have long been shown to support novice learners in
facilitating recall of main text ideas (i.e., text
macrostructure) when provided prior to learning (see
O’Donnell, Dansereau, and Hall, 2002, for a review).
However, there has been little evidence that these concept
map visualizations can support effective metacognitive

Graphical Cues in Visual Displays
Research has demonstrated that highlighting a specific
feature within a diagram or other visual instruction can
successfully direct the learner’s attention to critical
information and enhance learning and comprehension (e.g.,
de Koning, Tabbers, Rikers, & Paas, 2009; Mautone and
Mayer, 2007). Thus, graphical cues can impact how learners
process multimedia materials. From a self-regulated
learning perspective, graphical cues could help learners plan
their online learning activities and could scaffold their
monitoring of their existing understanding by drawing
attention to the weak concepts in the student work product,
much like a human tutor would do.

Experiment
In this research we explored the impact of personalized
feedback (through the use of graphical cues) in combination
with a domain knowledge visualization to promote effective
planning during self-regulated learning with online
resources. These graphical cues were: 1) color-coding of
feedback to indicate error types, and 2) size-scaling of nodes
to indicate conceptual importance to the overall domain.
We hypothesized that color-coding would facilitate
effective planning, by helping learners to implement more
effective learning strategies as they revised specific types of
problems in their existing understanding (e.g., looking up
new information when their knowledge was incomplete).
We hypothesized that size-scaling would help students
engage in more effective planning, by helping them
prioritize and focus on key domain content during online
learning. Assessments focused on changes in self-reported
planning (specifically prioritization of learning), selfreported revisions to a scientific essay, and domain learning.

Method
Participants Forty-four undergraduate students at the
University of Utah participated in this study in partial
fulfillment of a class research requirement.
Design This study utilized a 2 (color-coding vs. no colorcoding) X 2 (size-scaling vs. no size-scaling), betweensubjects experimental design. Participants were randomly
assigned to one of the four experimental conditions upon
arrival.
Materials
Draft Essay The learning task in this study asked
participants to make revisions to an existing essay on plate
tectonics. Providing this draft essay to all conditions
allowed us to create a visualization that provided the same
conceptual overview to all students, across which graphical
cues could be varied systematically, and compare revisions
to the same five targeted erroneous sentences across all
conditions rather than judging individual essay quality.

1881

Although the learning task is formatted like a writing
intervention, we are not focused on the students’ writing,
per se. We are interested in how the graphical cues influence
actions taken during the research and revision process.
The “draft” essay contained three types of errors that have
been identified as common knowledge issues for novice,
undergraduate science learners using an automatic feedback
system for online learning (Butcher & Sumner, 2011; de la
Chica et al., 2008): incorrect statements, missing concepts,
and fragmented/incomplete knowledge. The draft essay
contained five targeted errors (one incorrect statement, two
missing concepts, and two fragmented/incomplete
statements).
The draft essay was introduced to participants during the
learning task by asking them to imagine that they had been
assigned a group project – to write an essay on plate
tectonics – for an introductory Earth Sciences class. The
draft essay was introduced as the first draft, written by a
fictitious member of their group. Each participant was told
that his/her goal was to revise the essay so that it would be
ready to submit for final grading.

Feedback Visualization In each condition a concept map
visualization provided a domain overview (see Figures 1
and 2) in addition to feedback on the draft essay. The
visualization was provided on a computer screen alongside a
dynamic view of the draft essay the participant was tasked
with revising. The concept map presented relevant concepts
from the draft essay in nodes; arrows between the nodes
indicated a relationship between connected concepts. Sizescaled nodes and color-coded nodes varied by condition.
All concept nodes in the visualization were interactive:
nodes that were highlighted in some manner (by varied
colors corresponding to different error types in the colorcoding condition or by consistent, yellow highlighting in the
no-color-coding condition) indicated errors that had been
“detected” in the draft essay for that concept.

Figure 2: The concept map provided to participants in the
combined condition with suggested resources for the sea
floor spreading node are shown below the concept map.

Figure 1: The concept map provided to the control group
(no color-coded nodes, no size-scaling of nodes) with
suggested resources for the sea floor spreading node are
shown below the concept map.

When a student clicked a highlighted node, two things
occurred. First, the sentence(s) in the draft essay
corresponding to the click node were highlighted. The
purpose of this highlighting was to support coordination
across the visual and textual information provided to
participants. Second, clicking a highlighted node in the
visualization displayed a list of selected resources pertaining
to the node drawn from the Digital Library for Earth System
Education (http://dlese.org). Resources were selected based
upon a prior study in which the draft essay had been

1882

analyzed (Butcher & Sumner, 2011). All conditions were
provided with the same suggested resources; students were
free to use (or not to use) the resources in any manner that
they wished. Presenting resources held the self-regulatory
process of searching for applicable online resources constant
across conditions and, therefore, information search and
retrieval processes were not included in this study design or
analysis.

Table 1: Self-Reported Revision Categories & Examples.
Reported Revision
Shallow
Deleted content
Grammar/stylistic
changes

Graphical Cues The control condition visualization
displayed equal sized nodes and no color-coding beyond the
consistent, yellow highlights that indicated an error in the
essay (see Figure 1). Color-coded errors (see Figure 2)
varied the color of the error node depending upon the error
type. Pink nodes indicated incorrect information, blue nodes
indicated fragmented knowledge, and yellow nodes
indicated missing concepts. Size-scaling (see Figure 2) was
used to indicate the importance of the node to the overall
domain. The variance in circle diameter indicated the size
difference. Large nodes were the most important domain
ideas among the concepts detected as errors from the draft
essay, medium nodes were moderately relevant to the
domain, and small highlighted nodes were not completely
necessary in understanding plate tectonic theory. Criticality
to the domain was determined by relationship to the theory
of plate tectonics.
Revision Questionnaire The revision questionnaire was a
self-report measure that participants completed following
the draft revision task. This questionnaire sought to
determine how learners planned/prioritized their learning
and what strategies they used to revise the draft essay.
Questions were split into two sections: section one asked
how the participant utilized the concept map and what, if
any, features guided revision; section two asked participants
to explain – for each of the five essay errors – why the
sentence had been targeted as problematic and how the
participant had revised the error (if s/he had done so).
Students’ self-reported error revisions were coded to
assess the effectiveness of strategy use; revisions were
analyzed according to the Construction-Integration model
(Kintsch, 1994). According to the CI model, knowledge that
is integrated or transformed leads to the development of a
situation model. The situation model is a flexible, longlasting representation of knowledge that is associated with
deep understanding and knowledge transfer. In contrast,
knowledge that is learned in a rote manner (e.g., by
memorizing) leads to a textbase representation. The textbase
representation does not support application or transfer of
knowledge. In the current study, students’ self-reported
revisions were analyzed for whether they integrated or
transformed knowledge (see Table 1 for examples); these
revisions were coded as deep. Revisions that failed to
transform or integrate information were coded as shallow;
these revisions include revisions to grammar and style, as
well as removal of errors (see Table 1).

Deep
Describe
relationships
Integrate domain
content

Example
“I deleted it, it was incomplete
and irrelevant.”
“The only thing I changed in the
sentence was that I added rock
after the word molten.”
“I talked about how sea floor
spreading has little to do with
creating volcanoes and more to
do with recycling the sea floor.”
“I added information about what
causes sea-floor spreading and
mentioned convection currents
in the magma.”

Learning Assessments Learning was assessed via true/false
items, short answer questions, and a self-generated concept
map. All assessments were completed before and after the
essay revision and online learning task.
True/False Items. Factual knowledge was assessed using
a true/false test that targeted general, factual knowledge
about plate tectonics. For example, plate boundaries can be
convergent, divergent, or transform. This test included 40
items; participants were given one point per correct
response for a maximum total score of 40 points.
Short Answer Questions. Short answer questions were
designed to test knowledge transfer/application. Each
question asked participants to apply their understanding of
plate tectonics to a problem that had not been learned or
encountered in the online materials. For example, John says
that most volcanoes are located at transform plate
boundaries – where friction between plate boundaries
creates great heat that melts rock into molten lava. Is John
right about the typical location and cause of volcanoes?
Short answer questions were scored using a rubric that
specified a point for each relevant idea unit. The maximum
score on the short answer test was 20 points.
Concept Map Generation. Concept maps were compared
within subjects by analyzing change in concept map
structure to classify participants as either indicating nonlearning (1 point), surface learning (2 points), or meaningful
learning (3 points), using the map structures described by
Hay (2007; Hay, et al., 2008). Non-learning was indicated
by an unchanged knowledge structure; surface learning was
indicated by some new or rejected concepts but no new
links between prior and new knowledge; and meaningful
learning was indicated by significant revision to the
knowledge structure. Concept maps were used to assess
students’ depth of domain understanding.
Procedure First, participants were assessed on their prior
knowledge of plate tectonic theory using the learning
assessments. Following the pretests, participants were

1883

briefed on the essay task. Once the participants read the
provided draft essay, they used their randomly assigned
condition to explore online materials and revise the essay.
Participants were given 35 minutes to revise the draft essay.
Immediately following the revision task, participants had 20
minutes to complete the revision questionnaire. Finally,
participants again completed the learning assessments (the
true/false items, short answer questions, and concept map
generation). Total study duration was two hours.

Table 3: M and (SD) for Concept Map Generation.
Condition
Control
Color-coded
Size-scaled
Both color-coded and size-scaled

Self-Reported Revisions Participants using the color-coded
concept map reported making more revisions to target
sentences compared to participants who saw the size-scaled
nodes (F(1,40)= 8.84, p<.01; η2= .18). Another main effect for
the color-coded concept map was found in self-reported
revision quality; participants in the color-coded condition
reported making significantly more deep revisions to the
essay’s five identified errors (F(1,40)= 52.4, p< .01; η2= .29).
There was no observed interaction of the independent
variables. Overall, 89% of participants reported prioritizing
their essay revisions by error type, as indicated by the colorcoding graphical cue (e.g., fixing incorrect sentences first,
then missing concepts, and fragmented concepts last). Table
4 reports statistics for both the total errors modified out of
five targeted error sentences in the draft essay and the
percent of self-reported revisions classified as deep.

Analysis Results were analyzed using a repeated measures
multivariate analysis of variance for pre and post true/false
and short answers. A multivariate analysis of variance was
calculated for the revision questionnaire (since this
assessment was given only after learning) and concept map
structural change. A Chi square was performed for selfreported use of graphical cues. Alpha level was set at p =
.05 for all analyses.

Results
Learning Assessments Results showed a main effect of test
time for true/false items (F(1,40)= 6.58, p< .01) and short
answer questions (F(1,40)= 5.81, p< .02). Means and standard
deviations for true/false and short answer are shown in
Table 2. All students gained significant factual knowledge
between pre- and posttest on the true/false statements and
short answer questions. This is not surprising, given that the
learning task supported specific error revision and provided
sufficient online resources with information for revising
those areas. There were no significant differences between
graphical cue conditions on these assessments (Fs< 1).

Table 4: M and (SD) for Self-Reported Revisions.
Condition
Control
Color-coded
Size-scaled
Both (color-coded
and size-scaled)

Table 2: M and (SD) for Learning Assessments.
Condition
Control
Colorcoded
Size-scaled
Both colorcoded and
size-scaled

True/False Items %
Pretest
Posttest
.60(.03) .62(.02)
.67(.02) .69(.02)

Short Answer Total
Pretest
Posttest
3.8(.85) 4.8(.94)
5.3(.78) 6.7(.86)

.59(.03)
.59(.03)

3.8(.81)
3.8(.81)

.67(.02)
.63(.02)

M (SD)
1.90 (.32)
2.25 (.45)
2.36 (.51)
2.18 (.41)

# Modified
2.10 (1.19)
3.17 (1.03)
1.73 (1.10)
2.73 (1.27)

% Deep Revisions
.06 (.09)
.35 (.21)
.11 (.13)
.25 (.22)

Use of Graphical Cues A Chi square was calculated for the
number of participants who reported using the graphical
cues. As seen in Table 5, more students reported prioritizing
their revisions based upon graphical cues when they viewed
the color-coded nodes compared to those who did not see
color-coded nodes (x2= 11.78, p< .01).

5.5(.90)
3.8(.90)

Table 5: N for Graphical Cues Usage.

However, results did show condition differences when
examining the measure of domain understanding. Scores
from students’ self-generated concept maps showed a
significant interaction between independent variables
(F(1,40)= 4.23, p<.04; η2= .10). Table 3 displays concept map
scores by condition. Since concept maps reflect key domain
ideas and their relationships, this result indicates that
graphical cues can impact deeper domain understanding
during online learning, possibly by providing a conceptual
organization to scaffold online activities. The size-scaled
condition showed the strongest concept map scores,
suggesting that providing domain centrality cues may help
guide overall domain exploration.

Color-Coded
Yes
No

Used Graphical Cues
15
3

Discussion and Conclusion
Overall, results suggest that students can make use of
graphical cues integrated within a domain knowledge
visualization to support key online self-regulated learning
processes such as planning by prioritization. Findings show
that color-coding of errors in a concept map helped students
prioritize their revisions, supported more frequent revision,
and improved the quality of students’ revision strategies.
Students’ inattention to size-scaled nodes may indicate
that they are unable to utilize indicators of domain centrality

1884

within the experimental learning task. Although size-scaled
nodes failed to impact students’ perceived processes and
strategies, they ultimately did have an effect on students’
final conceptual understanding of the domain (as
represented in the post-learning, self-generated concept
maps). Thus, while size-scaling may not impact the strategic
processes of which students are aware (and can report),
these cues may support deeper conceptual coherence of
encountered information in an online environment.
Notably, color-coding not only improved the frequency
with which students reported revising errors, but also the
depth of their reported revision strategies. It should also be
noted that this result occurred even though the control
condition saw a concept map in which errors were
highlighted (but not color-coded by error type). In this case,
the visual cue provides an effective method for strategically
processing error types as a planning tool during selfregulated learning.
More work is needed to understand the range of graphical
cues that can support self-regulated learning in online
environments. This study provides a promising first step in
demonstrating that well-designed cues in visual displays can
have a positive and significant effect on self-regulated
learning. Research is underway to investigate the impact of
the feedback content (error type and concept importance)
versus the saliency of the graphical cues (color-coding and
size-scaling).

Acknowledgments
This material is based upon work supported, in part, by the
National Science Foundation under Grant DRL-0835454.
Any
opinions,
findings,
and
conclusions
or
recommendations are those of the author(s) and do not
necessarily reflect the views of the National Science
Foundation. Many thanks to Kimberly Meyers and Natalie
Harris for help in conducting study sessions and to Nicki
Turnidge-Halvorson for rubric development.

References
Azevedo, R. & Cromley, J. G. (2004). Does training on selfregulated learning facilitate students’ learning with
hypermedia? Journal of Educational Psychology, 96(3),
523-535.
Azevedo, R., Guthrie, J. T., & Seibert, D. (2004). The role
of self-regulated learning in fostering students' conceptual
understanding of complex systems with hypermedia.
Journal of Educational Computing Research, 30(1&2),
87-111
Butcher, K. R., & Sumner, T. (2011). Self-directed learning
and the sensemaking paradox. Human Computer
Interaction, 26(1), 123-159.
de Koning, B., Tabbers, H., Rikers, R., & Paas, F. (2007).
Attention cueing as a means to enhance learning from an
animation. Applied Cognitive Psychology , 21 (6), 731746.
de la Chica, S., Ahmad, F., Sumner, T., Martin, J. H., &
Butcher, K. R. (2008). Computational foundations for

personalizing
instruction
with
digital libraries.
International Journal of Digital Libraries, Special Issue
on Educational Digital Libraries, 3-18.
Glenberg, A. M. & Langston, W. E. (1992). Comprehension
of illustrated text: Pictures help to build mental models.
Journal of Memory and Language, 31 (2). 129-151.
Hay, D. (2007). Using concept maps to measure deep,
surface and non-learning outcomes. Studies in Higher
Education , 32 (1), 39-57.
Hay, D., Kehoe, C., Miquel, M., Hatzipanagos, S., Kinchin,
I., Keevil, S., et al. (2008). Measuring the quality of elearning. British Journal of Educational Technology , 39
(6), 1037-1056.
Kintsch, W. (1994). Text comprehension, memory, and
learning. American Psychologist , 49 (4), 294-303.
Lynch, C. (2008). Digital libraries, learning communities,
and open education. In T. Iiyoshi & M. S. V. Kumar
(Eds.), Opening up education. Cambridge, MA: MIT
Press.
Marchionini, G. (2006). Exploratory search: From finding to
understanding. Communications of the ACM, 49(4), 4146.
Mautone, P., & Mayer, R. (2007). Cognitive aids for
guiding graph comprehension. Journal of Educational
Psychology , 99 (3), 640.
McCrudden, M. T., Schraw, G., & Lehman, S. (2009). The
use of adjunct displays to facilitate comprehension of
causal relationships in expository text. Instructional
Science, 37(1), 65-86.
O'Donnell, A., Dansereau, D., & Hall, R. (2002).
Knowledge maps as scaffolds for cognitive processing.
Educational Psychology Review , 14 (1), 71-86.
Salmerón, L., Baccino, T., Cañas, J., Madrid, R., & Fajardo,
I. (2009). Do graphical overviews facilitate or hinder
comprehension in hypertext? Computers & Education , 53
(4), 1308-1319.
Salmerón, L., Kintsch, W., & Cañas, J. J. (2006). Coherence
or interest as basis for improving hypertext
comprehension. Information Design Journal, 14(1), 4555.
Salmerón, L., Kintsch, W., & Kintsch, E. (2010). Selfregulation and link selection strategies in hypertext.
Discourse Processes, 47(3), 175-211.
Williams. M. (1996). Learner control and instructional
technologies. In D. Jonassen (Ed.), Handbook of research
on educational communications and technology. NY:
Scholastic.
Winne, P. H. (2001). Self-regulated learning viewed from
models of information processing. In B. Zimmerman &
D. Schunk (Eds.), Self-regulated learning and academic
achievement: Theoretical perspectives. Mawah, NJ:
Erlbaum.
Winne, P. H., & Perry, N. E. (2000). Measuring selfregulated learning. In M. Moekaerts, P. Pintrich & M.
Zeidner (Eds.), Handbook of self-regulation. Orlando, FL:
Academic Press.

1885

