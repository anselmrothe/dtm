UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Bilinguals activate words from both languages when listening to spoken sentences:
Evidence from an ERP-study

Permalink
https://escholarship.org/uc/item/4hh4r9cg

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Altvater-Mackensen, Nicole
Mani, Nivedita

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Bilinguals activate words from both languages when listening to spoken sentences:
Evidence from an ERP-study
Nicole Altvater-Mackensen (naltvat@gwdg.de)
Free-Floater Research Group “Language Acquisition“, Georg-August-Universität, Gosslerstrasse 14
37073 Göttingen, Germany

Nivedita Mani (nmani@gwdg.de)
Free-Floater Research Group “Language Acquisition“, Georg-August-Universität, Gosslerstrasse 14
37073 Göttingen, Germany

Abstract
The current study examines whether bilingual word
recognition in spoken sentences is influenced by cross-lingual
phonological similarity. ERPs were measured while GermanEnglish bilinguals listened to German sentences. Target
words in the sentences were either German-English
homophones (e.g., eagle – Igel ‘hedgehog’), German words
that were phonologically closely related to English words
(e.g., kitten – Kittel ‘smock’), or German words that had no
phonological relation to English words (e.g., Ziegel ‘brick’).
ERPs to target words showed an N400-like facilitation effect
for words with cross-lingual phonological overlap
(homophones and German-English related words) compared
to words with no cross-lingual overlap. However, these
results were restricted to bilinguals who learned both
languages before age 6, but not for those bilinguals who
learned English after age 6. This suggests that early bilinguals
activate words from both languages when processing spoken
sentences in their dominant language-context.
Keywords: Lexical access; Word recognition; Bilingualism;
N400.

Introduction
A crucial question in bilingual research is whether lexical
access in bilinguals is language-selective, i.e. whether
recognition of words in one language of a bilingual involves
activation of words from the bilingual’s other language. In
the last years, a growing body of studies suggests that this
is, indeed, the case. These studies provide evidence for
models of bilingual word recognition which assume that
lexical access is not always constrained by language context
(e.g., the BIA+model; Dijkstra, Grainger & Van Heuven,
1999; Dijkstra & Van Heuven, 2002). Yet most of these
studies investigated word recognition of isolated, visually
presented words (for some recent studies see Wu & Thierry,
2010; Martin, Dering, Thomas & Thierry, 2009; Kerkhofs,
Dijkstra, Chwilla & De Bruijn, 2006; De Bruijn, Dijkstra,
Chwilla & Schriefers, 2001). Thus, the question arises in
how far the results can be generalized to spoken word
recognition and to word recognition in sentence context –
the modality and context in which most communication
occurs. Indeed, for monolinguals, there is evidence that
lexical access in auditory and visual word recognition
involves autonomous systems (e.g., Taft, 1986; Kouider &
Dupoux, 2001) and that word recognition in single-word

context dramatically differs from word recognition in
sentence context (e.g. Van Petten, 1995).
Spivey and Marian (1999) report one of the few studies
investigating spoken word recognition in bilinguals. They
investigated whether Russian-English bilinguals’ word
recognition in Russian is influenced by knowledge of
English words. The participants saw familiar objects on the
screen and were instructed to perform an action on one of
the items. Crucially, the labels for the target image and
distracter image overlapped phonologically across
languages. For example, participants saw a stamp (marku in
Russian) and a marker (flomaster in Russian) and received
the Russian instruction Ploji marku nije krestika (‘Put the
stamp below the cross’). Tracking the eye-movements of
their participants, Spivey and Marian showed that RussianEnglish bilinguals considered the marker as a target before
finally picking up the stamp. This suggests that participants
briefly activated the English object-labels even though the
experiment only involved Russian and it was therefore
neither necessary nor required to activate English words.
This result provides evidence that lexical access in
bilinguals is not language selective in auditory word
recognition. However, in this study, the L2 competitor (e.g.,
marker) was visually adjacent to the target. This is not the
case in our everyday communication and might influence
participants’ responding in a manner not typical to standard
lexical access. In addition, the sentences in Spivey and
Marian’s study were highly restricted (e.g., ‘Put the stamp
below the cross’), whilst listeners are typically faced with
the task of recognizing words in more variable sentence
contexts.
A study investigating visual word recognition in sentence
context was conducted by Duyck, van Assche, Drieghe and
Hartsuiker (2007). They presented Dutch-English bilinguals
with orthographically presented English sentences that
contained a cross-language cognate like cat (Dutch kat). A
first experiment presented the cognate as the final word in
the sentence and measured subjects’ response times to judge
the lexicality of the sentence-final word. A follow-up
experiment presented the cognate in sentence-medial
position and monitored subjects’ eye-movements while
reading the sentences. The results indicate that subjects
show lower lexical decision times for Dutch-English

1382

cognates and that subjects read Dutch-English cognates
embedded in sentences faster compared to words with no
cross-lingual overlap. This suggests that bilinguals activate
words from both languages when reading sentences that are
presented in their L2. Interestingly, this also seems to hold
for L1 reading. Van Assche, Duyck, Hartsuiker and
Diependale (2009) monitored the eye-movements of DutchEnglish bilinguals while reading Dutch sentences that
contained English-Dutch cognate words like oven. They
replicate the effect obtained by Duyk et al. (2007): Reading
times of cognate words were faster than those of control
words. This is especially interesting because it suggests that
not only do bilinguals activate native words when reading in
L2, but they also activate L2 words when reading in L1.
However, both studies only compared recognition of
cognate words and words with no cross-lingual overlap.
Thus, the effect might be bound to only those words that
exist in both languages of the bilingual.
Global language context might also influence word
recognition in bilinguals. Elston-Güttler, Gunter and Kotz
(2005) presented advanced German learners of English with
a movie narrated in either English or German. They then
measured ERPs to orthographically presented English
sentences that ended in a German-English homograph.
Additionally, they measured subjects’ response times to
judge the lexicality of a word semantically related to the
homograph. In the first block (36 trials) of the testing phase,
ERPs and behavioural data differed for homographs, but
only for those subjects who saw the German movie before.
Neither behavioural nor ERP data showed a priming effect
in the rest of the testing phase. It thus seems that the local
English sentence context prevented the activation of the
German interpretation of the homograph and that the global
language context provided by the movie had small and
short-lived effects on lexical activation.
Taken together, results are mixed concerning bilingual
word recognition in sentence context. While Duyck and
colleagues show an effect of cross-lingual relation on word
recognition, Elston-Güttler and colleagues only find very
limited evidence of cross-language activation. Yet, it seems
vital for our understanding of bilingual word recognition to
see how bilinguals cope with cross-lingual relations in
sentences, and especially in spoken sentences. The current
study broadens the scope of the preceding studies in several
ways. First, we explore whether bilinguals activate words
from both languages when listening to spoken sentences
instead of reading in one of their languages. Second, we
used both cross-lingual homophones and words that were
phonologically closely related across languages, to see how
far the effects of earlier studies are restricted to cognate
words. Third, we tested early and late bilinguals to see how
age of acquisition affects lexical processing in bilinguals.
And fourth, the task presented to subjects during the
experiment was non-linguistic. This ensured that we did not
draw subjects’ attention to the target word or explicitly
engage processes related to lexical access. More precisely,
we presented German-English bilinguals with spoken

German sentences while we measured their ERPs. At the
end of each sentence, subjects were presented with either a
triangle or a rectangle and asked to decide the shape of the
visually presented form. Subjects were told that the main
purpose of the task was the visual form and that the
sentences were intended to distract them. Crucially, the
target word in the sentences was an English-German
homophone (homophone condition), or a German word that
forms a minimal pair with an English word (related
condition), or a German word that has no cross-lingual
relation to English words (unrelated condition). If bilinguals
indeed activate words from both languages when
recognizing words in fluent speech, we expect differences in
lexical activation for the words with cross-lingual relation
compared to the unrelated condition. Second, if the effects
that have been found in earlier studies are not restricted to
cognate words and homographs, we expect to find an effect
of cross-lingual activation for homophones and related
words as well. Third, if age of acquisition does not influence
lexical activation in bilinguals, we expect no differences
between our two groups of participants (highly proficient
bilinguals who learned both English and German before age
6, or L2 learners who learned English after age 6).

Material and Methods
Participants
A total number of 18 German-English bilinguals
participated in the study (7 female). Participants’ mean age
was 33.5 years, ranging from 18 to 65 years. All participants
lived in Germany when the study was conducted. 10 out of
18 participants learned both English and German before age
6 (early bilinguals), the remaining 8 participants learned
English after age 6 (late bilinguals). Participants rated their
fluency in reading, writing, listening, speaking and grammar
on a scale from 1 (very low) to 10 (very high) (questionnaire
adapted from Rüschemeyer, Nojack & Limbach 2008).
Mean fluency was rated 9.3 for German (range 7.6 to 10)
with 9.3 for early bilinguals (range 7.6 to 10) and 9.2 for
late bilinguals (range 7.6 to 10). Mean fluency for English
was rated 8.9 (range 6 to 10) with 8.6 for early bilinguals
(range 6 to 10) and 9.3 for late bilinguals (range 7.6 to 10).
Participants also rated how often they use English and
German in everyday life (with family, friends and
colleagues, when reading books, listening to the radio and
watching TV). Mean usage of German was 60.4%, with
60.8 for early bilinguals and 60 for late bilinguals; mean
usage of English 40%, with 39.2% for early bilinguals and
39.6% for late bilinguals. T-tests comparing language
fluency and language use between participants that learned
English before and after age 6 did not show any significant
differences. All participants had normal or corrected-tonormal vision and self-reported normal hearing. They
signed informed consent to take part in the study and
received 15 Euros for their participation.

1383

Stimuli
The audio stimuli consisted of 180 German sentences
spoken by a female native speaker of German in a neutral
tone of voice. Stimuli were recorded in a quiet room, using a
sampling rate of 44100 Hz. Stimuli were volume matched.
All sentences were main clauses with no subordinate clauses
so that the sentences began with the subject, followed by the
verb, a direct object and in some cases an indirect object.
The 180 sentences were split into 6 blocks, each containing
30 sentences. Across blocks the sentences were repeated and
held constant as far as possible, although sometimes slight
adjustments had to be made in order to prevent grammatical
or semantic anomalies. The target word was always the
subject of the clause, i.e. occurred preverbal, so that
participants could not build expectations about the referent
(see e.g. Altmann & Kamide, 1999, for the influence of verb
information on referent selection). Sentences were not
semantically restricted so that upcoming words could not be
anticipated based on sentence context. At the same time
sentences were not semantically incongruous or
inappropriate (see e.g., Schwartz & Kroll, 2006, for the
influence of sentence context on bilingual word
recognition). In half of the sentences target words were
German words. In the other 90 sentences, target words were
German pseudowords. Words could be either cross-lingual
homophones, like Igel ‘hedgehog’ and eagle, German words
that are phonologically closely related to English words, like
Kittel ‘smock’ and kitten, or German words that have no
relation to English. Frequency of the words and
neighborhood size was matched across conditions (average
number of neighbors: homophones =4.8, related words =4.5,
unrelated words =4.5; average frequency class in
Wortschatz (Quasthoff, Richter & Biemann, 2006):
homophones =12, related words =12, unrelated words =13).
Target words were also matched in length with respect to
number of phonemes and duration across conditions
(average number of phonemes: homophones =3.4, related
words =3.4, unrelated words =3.5; average duration:
homophones =593 ms, related words =529 ms, unrelated
words =576 ms). Each type of word (homophone, related,
unrelated) appeared in 30 sentences each.
Visual stimuli were created in an image editing program
and then exported as pictures. The stimuli were either a
filled red triangular shape or a filled red rectangular shape.
Each shape measured 300 x 300 pixels, and was displayed
against a black background

Procedure
Participants were seated in a dimly lit, quiet experimental
room, facing a 92 cm wide and 50 cm high TV screen at a
distance of 100 cm. All conversation during preparation for
the experiment, as well as the instruction sheet, was in
German. Participants were told that we were interested in
how visual perception is affected by background noise.
They were instructed that they will hear sentences while two
kinds of objects, triangles and rectangles, appear on the
screen. Their task was to ignore the sentences and to

indicate as fast as possible which object they had seen by
pressing the corresponding button on an X-Box controller.
Participants were presented with 180 trials in random order.
Each trial started with a white fixation cross on a black
background presented in the middle of the screen. Auditory
presentation of the sentence stimuli was timed so that the
target word started 1000 ms into the trial. At the end of the
sentence, an object (a triangle or rectangle) appeared on the
screen. The trial ended automatically when the subject had
given a response. The visually presented form was a triangle
in one-third of the trials, and a rectangle in the remaining
two-thirds of the experiment. The ratio of triangles to
rectangles attempted to ensure that subjects would stay
focused on the decision task.

ERP recording
Electrophysiological data was recorded using the Biosemi
Active Two Amplifier system at a sampling rate of 2048 Hz
from 32 Ag/AgCl electrodes placed according to the 10-20
convention. Electrode offsets were kept < 25 µV.
Electroencephalogramm was re-referenced offline to the
averaged mastoid reference. EEG data was then filtered offline using a 0.01 Hz high-pass forward filter and a 25 Hz
low-pass, zero-phase shift filter. Blink and movement
artifacts were automatically rejected using an 80 Hz
amplitude cut-off on the mastoid and three eye channels
(left, right and lower eye). Epochs were defined from -200
to 1000 ms after the onset of the target word. Baseline
correction was performed in reference to pre-stimulus
activity (-200 to 0 ms).

Data analysis
Data was averaged across all trials, split by participant,
electrode and condition. We then calculated mean
amplitudes for 50 ms segments, ranging from 200 ms before
the target word onset to 1000 ms after the target word onset,
split by participant, condition and electrode. This allowed us
to detect periods of significant differences across conditions.
Statistical analysis was performed on mean measures of
frontal, central, parietal and occipital sites in both
hemispheres [right frontal (FC2, FC6), left frontal (FC1,
FC5), right central (C4, CP2, CP6), left central (C3, CP1,
CP5), right parietal (P4, P8, PO4), left parietal (P3, P7,
PO3), right occipital (O2) and left occipital (O1)] in an
N400 latency window (500 to 1000 ms). Note that the
latency window is slightly shifted because N400 effects tend
to appear later in bilinguals compared to monolinguals,
especially when they process their L2 (for a review see
Moreno, Rodriguez-Fornells & Laine, 2008). Within-subject
factors for repeated ANOVAS included condition
(homophone/ related/ unrelated), hemisphere (left/ right)
and site (frontal/ central/ parietal/ occipital), while age of
acquisition (before/after age 6) served as a between subject
factor. The Geisser-Greenhouse correction was always
applied.

1384

Results and Discussion
Figure 1 plots the brain activity in the homophone, related
and unrelated condition for early bilinguals. The pattern
illustrated in Figure 1 indicates that ERPs to homophone
and related condition were less negative compared to the
unrelated condition between 500 to 1000 ms. Figure 2 plots
this difference by comparing the averaged mean amplitudes
per condition for early bilinguals. Figure 3 plots that the
averaged mean amplitudes for late bilinguals are not
different between conditions.

Figure 3: Mean amplitudes in the 500 to 1000 ms window for
right and left hemisphere of late German-English bilinguals. Plots
show the average for German words that cross-lingual
homophones (homophones), German words that are
phonologically related to English words (related), and German
words with no phonological relation to English words (unrelated).

Figure 1: ERPs elicited by critical targets at selected electrode
sites in early German-English bilinguals. Waveforms in panel A
show the average for cross-lingual homophones (dashed line) and
unrelated words (solid line). Waveforms in panel B show the
average for words that are phonologically related to English words
(dotted line) and unrelated words (solid line).

Figure 2: Mean amplitude in the 500 to 1000 ms window for right
and left hemisphere of early German-English bilinguals. Plots
show the average for German words that are cross-lingual
homophones (homophones), German words that are
phonologically related to English words (related), and German
words with no phonological relation to English words (unrelated).

Statistical analysis confirmed this pattern of results. A
repeated measures ANOVA showed a main effect of
hemisphere (F(1) =5.436, p=.033) and interactions of
condition*age of acquisition (F(1.95) =4.717, p=.017) and
condition*site (F(3.35) =14.363, p=.073). No other main
effects or interactions approached significance. For further
analysis, we split the data by age of acquisition and
separately analyzed subjects who acquired both languages
before age 6 (early bilinguals), and subjects who learned the
second language after age 6 (late bilinguals). For the early
bilinguals, planned comparisons showed a significant
difference between the homophone and unrelated condition
on left occipital (OL), right occipital (OR), left parietal
(PL), and left central (CL) electrode sites (tOL(9) =2.387,
p=.041; tOR(9) =2.554, p=.031; tPL(9) =2.009, p=.075; tCL(9)
=3.116, p=.012). Similarly, there was a significant
difference between related and unrelated condition on left
occipital (OL), right occipital (OR), left central (CL) and
right parietal (PR) electrode sites (tOL(9) =2.603, p=.029;
tOR(9) =3.261, p=.010; tCL(9) =2.941, p=.016; tPR(9) =2.388,
p=.041). There were no significant differences between
homophone and related condition. For the late bilinguals,
planned comparisons showed a significant difference
between homophone and related condition on left frontal
(FL), right frontal (FR) and right central (CR) electrode sites
(tFL(9) =-4.584, p=.003; tFR(9) =-2.258, p=.059; tCR(9) =2.194, p=.064). There were no significant differences
between related and unrelated condition, and a nearsignificant difference between homophone and related
condition on left frontal electrode sites (t(9) =-2.186,
p=.065).
In sum, the data show different effects depending on age
of acquisition of the subjects. Early German-English
bilinguals, who learned both languages before age 6, show a
more positive N400-like effect for homophones and related

1385

words compared to unrelated words. This indicates a
facilitation effect for the recognition of German words that
are phonologically related to English words or cross-lingual
homophones. Interestingly, we found no further difference
between homophones and related words indicating that
homophones do not lead to different activation compared to
words that are minimal pairs across languages. In sharp
contrast, German-English bilinguals of similar proficiency,
who learned English after age 6, do not show differences in
the N400 effect for words that have a cross-lingual relation
and control words. This suggests that late bilinguals do not
automatically activate words from both their languages
when recognizing words in fluent speech but that the effect
is bound to those bilinguals who learned both languages
very early in life.The finding that early bilinguals show a
facilitation effect whilst recognizing words that have a
cross-lingual relation fits nicely with earlier results on word
recognition in bilinguals. It suggests that bilinguals activate
words from both their languages when processing spoken
sentences and not only when recognizing isolated words
(e.g. Wu & Thierry, 2010; De Bruijn et al., 2001) or words
in written sentences (e.g. Duyck et al., 2007, Van Assche et
al., 2009). This finding is not trivial, since bilinguals might
use different strategies in spoken and written language
comprehension. Indeed, most day-to-day communication
involves language in the spoken modality and in sentence
context.
We also find a clear effect of age of acquisition on
subjects’ ERPs. While early bilinguals who learned both
languages before age 6 show a facilitation effect for the
recognition of cross-lingual related words, bilinguals who
learned English after age 6 did not show such an effect. This
difference is unexpected given that both groups of bilinguals
were similarly high proficient speakers of English and
German, and used English equally often in their daily life
(as indicated by participants’ self-rating in the administered
questionnaire). For such highly proficient bilinguals, earlier
results clearly indicate a cross-language priming effect (e.g.,
Kotz, 2001; Martin et al., 2009). Yet, most studies
investigating lexical access in bilinguals used designs in
which it is more likely that both languages would be
triggered by explicitly presenting subjects with stimuli from
both languages (see e.g., Martin et al., 2009; De Bruijn et
al., 2001). Furthermore, as pointed out before, auditory and
visual word recognition involve different systems and word
recognition of isolated words is different from word
recognition in sentence context. Thus, late bilinguals might
not continuously activate words from both languages when
they listen to sentences that are clearly uttered by a L1
native speaker in an obviously L1 language context where it
is unlikely that an L2 word will be uttered. Nevertheless,
Van Assche et al. (2009) find faster reading times for
cognate words not only for L2 but also for L1 sentences. We
suggest that the different findings originate from differences
in the stimuli used. The most important difference between
our study and theirs is that Van Assche and colleagues used
cognate words while we used homophones and German-

English minimal pairs. Cognates might be much more likely
to elicit activation of the L2 compared to cross-language
minimal pairs or homophones, given the overlap at both
semantic and phonological levels in cognates. We further
speculate that the difference between the bilingual groups
arises because the two languages of the early bilinguals are
more integrated or interconnected than the languages of the
late bilinguals. However, this speculation requires further
empirical substantiation.
What implications do our data have for models of
bilingual word recognition? The finding that early bilinguals
show a facilitation effects in recognizing words that have a
cross-lingual relation, i.e. German-English homophones and
minimal pairs, provides evidence for language non-selective
lexical access, as predicted by models like the BIA+ model
(Dijkstra, et al., 1999; Dijkstra & Van Heuven, 2002). The
model assumes an integrated lexicon for both languages of a
bilingual. Lexical access is, therefore, initially not language
selective; rather, word candidates from both languages are
accessed in parallel. The word identification system is
assumed to be not affected by local or global language
context, i.e. sentence context or surrounding language
context. This assumption is in accordance with our finding
that early bilinguals show a facilitation effect for crosslingual related words despite the fact that neither the
sentences in which the words are embedded nor the global
language context provide any hint of a cross-language
relation of the embedded words. However, the finding that
late bilinguals do not show similar facilitation effects for
words with cross-lingual relation in sentence context seems
to contradict this prediction. Yet, although lexical access is
initially not language selective, the model predicts that
differences in activation of L1 and L2 words might occur
because of differences in usage frequency and/or task
related strategies. Despite the fact that we matched
proficiency and language use of the bilinguals tested, the
late bilinguals might use the English words corresponding to
our German target words less frequently than the early
bilinguals. According to the model, this would result in
different resting-level activation of the L2 words and might,
therefore, lead to differences in activation of the L2 words
in the two bilingual groups. But it might also be that late
bilinguals do not automatically activate words from both
languages when recognizing words in fluent speech. The
fact that they learned their second language later in life
might lead to less integration and/or interconnection
between lexical representations from both languages as
assumed by models like the Revised Hierarchical Model of
bilingual language processing (Kroll & Stewart, 1994). The
model assumes two separate lexicons for the two languages
of a bilingual. The lexical word form representations are
assumed to be stored separately, while both languages share
a common conceptual level. Although there exist
connections both from L1 to L2 and from L2 to L1, the
strength of the connections is mediated by proficiency. In
principle, the assumption of two separate lexicons allows
for language selective lexical access. Thus, the model would

1386

not necessarily predict co-activation of words from both
languages in an obvious L1 context for late bilinguals.
Taken together, our results suggest that early and late
bilinguals show differences in cross-language activation
during word recognition. Our findings indicate that early
bilinguals activate words from both languages when
listening to fluent speech in one of their languages
suggesting strong interconnections of the two languages.
This complements earlier findings in two important ways:
First, it shows that the earlier results of languageunconstrained lexical access for word recognition in
orthographically presented sentences also applies to spoken
word recognition in sentence context. Second, it shows that
the earlier results obtained with cognates extends also to
homophones with no meaning overlap and to crosslanguage minimal pairs. Crucially, such cross-language
activation persists despite our task not drawing special
attention to the target items and not requiring subjects to
perform a language-based task. Concerning late bilinguals,
our data suggest that global and/or local language context
can eliminate the effect of cross-language relations. This
might be due to differences in frequency of L1 and L2
words, task demands, or less strong interconnections of L1
and L2 words in late bilinguals.

Acknowledgments
We thank Katie von Holzen for her help in recruiting
participants and collecting the data. This work was funded
by the German Initiative of Excellence.

References
Altmann, G. & Kamide, Y. (1999): Incremental
interpretation at verbs: restricting the domain of
subsequent reference. Cognition, 73, 247-264.
De Bruijn, R.A., Dijkstra, T., Chwilla, D.J. & Schriefers,
H.J. (2001). Language context affects on interlingual
homograph recognition: evidence from event-related
potentials and response times in semantic priming.
Bilingual Language Cognition, 4, 155-168.
Dijkstra, T., Grainger, J. & Van Heuven, W.J.B. (1999).
Recognition of cognates and and interlingual
homographs: the neglected role of phonology. Journal of
Memory and Language, 41, 496-518.
Dijkstra, T. & Van Heuven, W.J.B. (2002). The architecture
of the bilingual word recognition system: from
identification to decision. Bilingualism: Language and
Cognition, 5, 175-197.
Duyck, W., Van Assche, E., Drieghe, D. & Hartsuiker, R.J.
(2007). Visual word recognition by bilinguals in a
sentence context: Evidence for non-selective access.
Journal of Experimental Psychology: Learning, Memory
and Cognition, 33, 663-679.
Elston-Güttler, K.E., Gunter, T.C. & Kotz, S.A. (2005).
Zooming into L2: Global language context and
adjustment affect processing of interlingual homographs
in sentences. Cognitive Brain Research, 25, 57-70.

Kerkhofs, R., Dijkstra, T., Chwilla, D.J., & de Bruijn, E.R.
(2006). Testing a model for bilingual semantic priming
with interlingual homographs: RT and N400 effects.
Brain Research, 1068, 170-183.
Kotz, S. (2001). Neurolinguistic evidence for bilingual
language representation: a comparison of reaction times
and event-related brain potentials. Bilingualism:
Language and Cognition, 4, 143-154.
Kouider, S. & Dupoux, E. (2001). A functional
disconnection between spoken and visual word
recognition: evidence from unconscious priming.
Cognition, 82, B35-B49.
Kroll, J.F. & Stewart, E. (1994). Category interference in
translation and picture naming: evidence for asymmetric
connections between bilinguals memory representations.
Journal of Memory and Language, 33, 149-174.
Martin, C.D., Dering, B., Thomas, E.M. & Thierry, G.
(2009). Brain potentials reveal semantic priming in both
the ‘active’ and the ‘non-attended’ language in early
bilinguals. NeuroImage, 47, 326-333.
Moreno, E.M., Rodiguez-Fornells, A. & Laine, M. (2008).
Event-related potentials (ERPs) in the study of bilingual
language processing. Journal of Neurolinguistics, 21,
477-508.
Quasthoff, U., Richter, M. & Biemann, C. (2006): Corpus
Portal for Search in Monolingual Corpora. Proceedings of
the 5th international conference on language resources
and evaluation, 1799-1802.
Rüschemeyer, S., Nojack, A. & Limbach, M. (2008). A
mouse with a roof? Effects of phonological neighbors on
processing of words in sentences in a non-native
language. Brain and Language, 104, 132-144.
Schwartz, A.I. & Kroll, J.F. (2006). Bilingual lexical
activation in sentence context. Journal of Memory and
Language, 55, 197-212.
Spivey, M.J. & Marian, V. (1999). Cross talk between
native and second languages: Partial activation of an
irrelevant lexicon. Psychological science, 10, 281-284.
Taft, M. (1986). Lexical access codes in visual and auditory
word recognition. Language and Cognitive Processes, 1,
297-308.
Van Assche, E., Duyck, W., Hartsuiker, R.J. & Diependale,
K. (2009). Does bilingualism change native-language
reading? Cognate effects in a sentence context.
Psychological Science, 20, 923-927.
Van Petten, C. (1995). Words and sentences: event-related
brain potential measures. Psychopysiology, 32, 511-525.
Wu, Y. & Thierry, G. (2010). Chinese-English bilinguals
reading English hearing Chinese. The Journal of
Neuroscience, 30, 7646-7651.

1387

