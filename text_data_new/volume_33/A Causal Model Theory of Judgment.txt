UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Causal Model Theory of Judgment

Permalink
https://escholarship.org/uc/item/32j5q1c8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 33(33)

Authors
Sussman, Abigail B.
Oppenheimer, Daniel M.

Publication Date
2011-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Causal Model Theory of Judgment
Abigail B. Sussman and Daniel Oppenheimer
{asussman, doppenhe}@princeton.edu
Department of Psychology
Princeton University
Princeton, NJ 08540 USA
Abstract

Heuristic and Linear Models of Judgment

How do people combine cues to form judgments? Recent
debate has focused on whether and when individuals use
heuristics versus linear models. We propose instead that
people may rely on an understanding of the causal
relationships between cues to determine how much weight to
place on each one. Predictions of the causal model approach
match those of linear models under certain circumstances and
heuristic models under others, while making unique
predictions in additional cases. In two experiments, we show
that, as the causal relationships among cues changes,
participant judgments consistently conform to predictions of
the causal model approach while matching either heuristic or
linear judgments in only a limited subset of cases.
Keywords: judgment, causal reasoning, heuristics, linear
models

Introduction
When making judgments about the world, we typically
have access to various pieces of information, or cues, that
might facilitate those judgments. Doctors might consider
the weight of the patient and the severity of symptoms to
determine how much medication to prescribe. Jurors might
consider the number of people injured by a product and the
average age of the victim when determining damages. One
question that has been central in the study of judgment is
how these cues are used and combined. The manner in
which people combine cues impacts judgments, attitudes,
and choices, and has important ramifications for welfare.
Within the field of judgment and decision making, two
primary approaches have defined the debate over how
people combine available information to form judgments:
linear models and heuristic models. Each approach has
demonstrated a high correlation between individuals’
predictions and actual outcomes under certain
circumstances, but both approaches also have systematic
gaps in their ability to make predictions under various (and
predictable) environmental situations. Since linear models
excel at explaining judgment in some environments, and
heuristic accounts are more effective in others, many
researchers have argued that people switch between the
strategies depending on the judgment task. Although
strategy switching accounts have become dominant in the
field, we propose that a model based upon causal reasoning
may be able to subsume both linear and heuristic models to
account for judgments across various environments, in a
single, unified framework.

One influential approach to judgment assumes that
individuals are able to process complex information about
correlations between events with a high degree of accuracy
(e.g. Brunswik, 1943, 1952).
According to these
Brunswikian accounts, people incorporate many (or all) of
the available pieces of information into their judgments and
predictions by combining and weighting each cue to form an
algebraic, linear model (Anderson, 1981; Brehmer, 1994;
Hammond, 1996). Variations on this approach allow for
simplified methods of combining cues such as inconsistency
in weighting correlations (Hoffman, 1960), or equal cue
weighting (Dawes & Corrigan, 1974; Einhorn & Hogarth,
1975). In many situations, linear models approximate
human judgments (e.g. Hammond, 1955; Hoffman, 1960),
leading researchers to propose them as a basis for
understanding human cognitive processing. Indeed, in
certain environments process tracing has shown information
search patterns that are consistent with the predictions of
linear models (e.g. Payne, Bettman, & Johnson, 1988).
Despite the positive evidence for linear models, there are
reasons to doubt their descriptive validity. Questions
remain about whether people have the cognitive capacity to
perform the calculations necessary to compute linear models
when making judgments. Even in simplified forms they
regularly outperform the average decision maker (Dawes,
1979; Wainer, 1976). In some cases, reasoners’ judgments
have significantly deviated from linearity (e.g. Brehmer &
Brehmer, 1988; Slovic, 1969; Wiggins & Hoffman, 1968).
Thus, while linear models have provided insight into
cognitive processes, there are a number of things that they
struggle to explain.
In contrast, heuristic models assume that people engage in
mental shortcuts (Gigerenzer, Todd, & the ABC Research
Group, 1999; Kahneman, Slovic, & Tversky, 1982; Simon,
1957). While there is variation in the nature of heuristics
that have been proposed, many of the most prominent
accounts posit that people focus on a single cue at a time
rather than incorporating all available information—
typically the cue that is most relevant to the decision or most
accessible to the decision maker (e.g. Gigerenzer &
Goldstein, 1996; Shah & Oppenheimer, 2009; Tversky &
Kahneman, 1974). By using only a single piece of
information at a time, they are able to greatly reduce the
amount of cognitive effort required (Shah & Oppenheimer,
2009).
While there is a great deal of evidence for the use of
heuristics, there is also evidence to suggest that simple

1703

heuristic models are incomplete descriptors of human
cognition. A number of studies have shown patterns of
results inconsistent with the use of single cues (e.g.
Oppenheimer, 2005). Furthermore, the previously discussed
evidence supporting linear models of judgment are
challenging to account for if one assumes a single cue
receives all or most of the weight. In other words, like
linear models, heuristics can explain judgment in some
cases, but leave gaps in accounting for others.
Since linear models excel at explaining judgment in some
environments, and heuristic accounts are more effective in
other environments, many researchers have argued for a
strategy switching account. This suggests that people have
a number of cognitive strategies in their repertoire and
switch between them depending on the task environment.
In other words, people rely on each type of model under
certain circumstances (Gigerenzer, Todd, & the ABC
Research Group, 1999; Hogarth & Karelaia, 2005, 2007;
Newell & Shanks, 2003; Payne, Bettman, Johnson, 1988,
1993). However, while strategy switching accounts have
become dominant in the field, an alternative approach would
be a single strategy that mimics linear combinations under
some conditions, and mimics heuristics under others—while
predicting unique patterns in still others.

Using Causal Models to
Reconcile Alternate Approaches
Causal models are applicable across a wide array
judgments and, together with research on causal learning,
can specify which cues are relevant for forming an accurate
judgment and when (for reviews see Glymour, 2001;
Gopnik & Shultz, 2007; Sloman, 2005). People are known
to engage in spontaneous causal reasoning (Weiner, 1985).
Moreover, researchers have shown that causal models play a
role in how people make decisions (Hagmayer & Sloman,
2009; Sloman & Hagmayer, 2006). Specifically, Hagmayer
and Sloman argue that people generate causal models of a
situation and use these to determine which actions they
should take (the action that causes the intended effect rather
than one that is merely correlated with it). Further, causal
narratives have been shown to influence jury decision
making (Pennington & Hastie, 1993), and causal
assumptions have been shown to affect risk assessment
(Morgan, Fischhoff, Bostrom, & Atman, 2002).
While there is ample evidence that people use causal
information, there has been little work to investigate
whether causal models might be able to explain when
people’s judgments emulate heuristics vs. linear models.
However, it is possible that apparent switches in strategy
arise because of differences in the causal relationships of
cues. This could account for the findings supporting both
linear models and heuristics without resorting to the notion
of strategy switching (and also make valid novel
predictions). The studies described provide evidence that
individuals determine cue weights based on the underlying
causal relationships among cues being considered, and that

causal models can account for patterns of data that have
previously been attributed to strategy switching.

Causal Model Predictions
The present approach posits that when exposed to a set of
cues, people spontaneously attempt to understand the causal
relationships between those cues and the criterion of interest
(c.f. Oppenheimer, 2004). Importantly, different causal
relationships will lead different cues to become more or less
important. Consider the following causal structures, where
an arrow from A  B represents that A causes B (i.e.
increasing the value of A will directly lead to an increase in
the value of B), and where C represents the target of
judgment.
1. A  B  C
2. C  B  A
3. A  B  C
In these three cases, the predictions of a causal model
emulate those of attribute substitution or a fast-and-frugal
single cue stopping rule. While A may be correlated with C,
it is not directly causally related.
For the causal
relationships presented in 1-3, B “screens off” A, so that
once a person knows the value of B, there is no additional
predictive information conveyed about C through A (Pearl,
2000; Sloman, 2005). In causal structure 1, if A causes B
and B causes C, then A and C are independent, conditional
on the value of B; P(C|A, B) = P(C|B). The same rationale
can be used in the reverse direction in causal structure 2. A
similar logic also applies in feature set 3, where knowledge
of B should make knowledge of A irrelevant. As such, a
causal model theory predicts that for causal structures such
as those presented in 1–3, people who have access to B will
use it to the exclusion of A when making judgments about
C, just like non-compensatory heuristics.
Contrast those causal structures with the following:
4. A  C  B
5. A  C  B
6. A  C  B
A causal model for these relationships emulates the
predictions of a linear model. Both A and B are directly and
independently causally related to C. As such, both A and B
would be useful predictors of C in some combination. Just
as linear models would typically weight cues based on the
magnitude of the correlation between cues, causal models
would weight cues based on the strength and the structure of
the perceived causal relationship (Griffiths & Tenenbaum,
2005). Stronger causal relationships lead to higher
correlations. As such, a causal model theory predicts that
for causal structures such as those presented in 4-6, people
will use a weighted combination of A and B, just like linear
models.
Importantly, while a causal model theory can, in a single
unifying framework, subsume both heuristic and linear
modeling approaches to judgment, it can also make unique
predictions for certain causal structures. Consider:

1704

7. C  B  A
In feature set 7, reliance on the causal model would lead to a
unique pattern of cue use. As in 1-3, , there is no direct
causal relationship between A and C. However unlike in 13, the utility of the cue B in judging C is conditional on the
value of A. That is, in scenario 7, a high value of B could
be explained by either a high value of C or A (or both).
Thus, while A does not directly impact judgments of C, it
changes the amount of weight placed on cue B. In the
causal reasoning literature, this is known as explaining away
or discounting (for a review, see Khemlani & Oppenheimer,
2010). And in fact, this pattern of results has been found in
several studies of judgment (e.g. Oppenheimer, 2004; 2005;
Oppenheimer & Monin, 2009).
Importantly, this pattern of results could not arise from
either heuristic models or linear models. Heuristic models
would predict that reasoners would rely on a single cue (B)
for their judgment because it is the most highly correlated
with C. Linear models would factor in both A and B, but
since A is uncorrelated with C, the weight would likely be
near zero and the predictions would align with those of
heuristic models. In other words, causal model theory can
account for the successful predictions of both heuristic
models and linear models, as well as other findings in the
literature that previous models have been unable to explain.
The ensuing experiments compare the accuracy of
predictions of causal models to those made by using
representative linear or heuristic models.

When pressure in the Blanden Pipe increases, it causes
water flow through the Morton Spout to increase. And,
when water flow through the Morton Spout increases, it
causes the Nurbert Clamp to tighten.
In the Common Cause condition, the relationship described
was:
When the Nurbert Clamp tightens, it causes water flow
through the Morton Spout to increase. And, when the
Nurbert Clamp tightens, it also causes the pressure on the
Blanden Pipe to increase.
And, in the Common Effect condition, the relationship
described was instead:
When the Nurbert Clamp tightens, it causes water flow
through the Morton Spout to increase. And when
pressure in the Blanden Pipe increases, it also causes
water flow through the Morton Spout to increase.
In each trial, participants were given values for two of the
parts (amount of pressure in the Blanden Pipe and level of
water flow through the Morton Spout) and their task was to
estimate the value for the third part (tightness of the Nurbert
Clamp). They responded by marking their judgment on a
10 point scale that ranged from “very loose” to “very tight”.
Participants completed 10 trials during which the cue values
of the Blanden Pipe and Morton Spout were systematically
varied. However, these values were held consistent across
conditions – the only thing that varied between conditions
was the causal relationship between the cues.

Experiment 1
The primary predictions of the causal model approach are
that qualitatively different cue weighting patterns will arise
depending on the causal relationships between the cues. In
particular, cue weighting will mimic the predictions of
heuristic approaches for certain causal structures (e.g. the
Causal Chain: A  B  C), will mimic the predictions of
linear models for other causal structures (e.g. the Common
Cause: A  C  B), and will show patterns that differ from
both heuristic and linear models for still other causal
structures (e.g. the Common Effect: C  B  A). This
prediction was directly tested here.

Method
Participants. 32 participants were recruited through an
online platform hosted through Amazon.com, in exchange
for monetary compensation. The population was 66%
female, with a mean age of 35.
Design and Procedure. Participants were randomly
assigned to one of three conditions (Chain, Common Cause,
or Common Effect as specified above) in a between-subjects
design. Participants were then introduced to a novel (blank
predicate) domain involving a set of mechanical parts and
how they relate to each other; the causal relationship
between the parts varied by condition. For example, in the
Chain condition, participants saw:

Results and Discussion
For one of the 10 trials, the values of both cues were the
same; this question was included as a manipulation check.
Regardless of how they chose to combine the cues, anyone
who read this question carefully and understood the task
should have responded to the missing value with the same
value that had been provided for the other two devices. Prior
to analyzing the data, responses from 7 participants were
discarded for failing the manipulation check. Results are
similar if data from these participants is included.
Data from each of the remaining participants were
examined to determine how participants were integrating
known information into their final judgment. β weights
were calculated for each participant using a linear regression
to determine the weight given to the values of cue A
(Blanden Pipe) and cue B (Morton Spout) in participant
estimations of cue C (Nurbert Clamp). This method of
estimation of participants’ weighting policy is common in
both the Brunswikian tradition of linear modeling (Cooksey,
1996) and in heuristic approaches to attribute substitution.
While heuristic models would predict that participants
should weight one cue substantially more heavily than the
other, and linear models would predict that weights should
be split more evenly between the cues, they both predict that
weights should look equivalent across conditions. Because
the judgment environment was held constant across
conditions (e.g. no cognitive load or time pressure, identical

1705

cue values, etc.) there is no a priori reason to expect strategy
switching. The causal model, however, predicts qualitative
differences in the weights placed on cues depending on the
causal structure that the participants were presented with.
In Table 1 below, weights predicted by the causal model
hypothesis are shown beside actual weights generated by
participant data. Each of the hypothesized beta weights
were generated by using a regression approach where we
entered the expected responses for each of the 10 trials
shown to participants, based on the anticipated weight given
to each cue. Specifically, predicted weights for the Chain
condition (βA = 0; βB = 1) were determined as a result of
screening off; B receives the full weight of the judgment
while A remains unused. Predicted weights for the Common
Cause condition (βA = .63; βB = .55) are a result of the both
A and B having an independent causal impact on the value
of C (the predictions are not βA = .5; βB = .5 because we
created these weights using the cue values actually shown to
participants, which were somewhat arbitrarily chosen and
therefore not perfectly balanced around the midpoint of the
scale). In the case of the Common Effect condition,
predictions may vary depending on the amount of causal
discounting that takes place, as described in the theoretical
background above. However, the most straightforward
prediction (βA = -0.64; βB = 1.07), is based on the
assumption that A takes on the average value of B and C,
and is included in Table 1.
Table 1: Actual and predicted cue weights in estimating missing
cue values in Experiment 1.

Condition
Chain
Common Cause
Common Effect

Causal Model
Prediction
βA
βB
0.00
1.00
0.63
0.55
-0.64
1.07

Participant Responses
βA
0.02
0.50
0.03

cognitive load influences discounting (Oppenheimer &
Monin, 2009). Importantly, the overall data pattern seems
to support the key prediction of qualitative differences in
weighting by condition.
To determine if the differences between conditions were
statistically reliable, a one-way ANOVA was run. Results
revealed a main effect of condition on the difference
between weights participants placed on A and B in their
judgments (F(2, 22) = 9.27, p = .001, η2 = .46). Consistent
with the causal model hypothesis, post-hoc tests indicated
that the mean difference in weights for the Chain condition
(M = .87) was marginally greater than for the Common
Cause condition (M =.05, p = .070) and significantly greater
than for the Common Effect condition (M = -.96, p < .001).
The difference in weights for the Common Cause condition
was also marginally greater than for the Common Effect
condition (p = .056). Not only was the difference in weights
lowest in the case of the Common Effect condition, but the
sign was actually reversed, indicating a distinct pattern of
evaluation.

Experiments 2a-d
In addition to the study described above, we have
conducted four variations that extend results to all seven
proposed causal models, as well as a control condition
where no model is specified. Because these variations are
similar to one another, for the purposes of brevity and space
constraints, we will describe them briefly below and
combine results in subsequent analysis.

Methods

βB
0.73
0.45
0.84

While heuristic and linear models would predict similar
weights across conditions, the pattern of data suggests that
this is not what is occurring. Instead, the pattern matches
the qualitative predictions of a causal model.
Although it appears at first glance that predictions are off
in the case of the Common Effect condition, this may be due
to individual differences in discounting. The averaged
values shown in the table above hide individual level
judgments: no individual placed the majority of her
judgment on cue B alone. Instead, approximately half of
responses for the Common Effect condition suggested
negative beta weights for cue A while the other half of
responses implied positive beta weights for cue A. These
averaged to zero, making it appear as if no weight was given
to cue A when looking across the whole sample. While a
bimodal distribution could be explained by individual
differences in discounting, this is admittedly a post-hoc
explanation. Research supports the possibility that there are
individual differences in discounting; differences in working
memory capacity impact susceptibility to a cognitive load
manipulation (Cokely, Kelley, Gilchrist, 2006) and

Participants. All participants (numbers specified below)
were recruited online, through an online platform hosted by
Amazon.com, and completed the experiment for monetary
compensation. The population was 61% female, with a
mean age of 35.
Experiment 2a: 110 participants were randomly assigned to
one of eight conditions in a between subjects design. The
conditions corresponded to each of the seven causal models
specified above as well as an additional condition where no
model was specified (used as a control). Apart from the
additional conditions, the central procedure was the same as
described in the Experiment 1 above. However, after the 10
trials were complete, participants were presented with a new
page with the names of each of the three parts and asked to
draw arrows connecting them. This procedure was included
to determine whether the participants understood the
underlying causal model intended by each experimental
condition, and to allow for additional analysis based on
participants’ causal models, regardless of their condition.
Experiment 2b: One concern stemming from Experiment 2a
was that participants may not understand the basic causal
relationships being described. This could be a result of lack
of attention rather than a true underlying cognitive process.
To address this, the remaining experiments used a Star Trek

1706

theme to engage participants. Specifically, 95 participants
were told that their crew was on a mission to rescue human
hostages from the Romulans on a faraway planet. Their
ship had been facing a string of mechanical problems and
the participants needed to incorporate known information
about mechanical parts to identifying key issues to fix the
ship and make it there in time! Pages with encouragement
from Star Trek characters were interspersed throughout the
experiment to keep participants engaged in the task. Apart
from the theme, study 2b was identical to 2a.
Experiment 2c: This study varied by changing from named
mechanical parts to colored gears spinning to ensure that
(84) participants were not overlaying any prior knowledge
of the relationships between mechanical parts into the causal
descriptions presented to them. Additionally, it changed the
method of testing participants’ causal models to multiple
choice questions asking what each gear directly causes to
avoid any difficulty with the causal drawing task.
Otherwise, this study was identical to 2b.
Experiment 2d: This study incorporated the changes in
Experiment 2c, and also allowed (81) participants to
intervene on the system to visualize the relationship
between gears (including stochastic elements), thus aiding
their learning of the causal relationships. After reading
through the introduction participants were show a diagram
with a separate vertical bar representing the speed of each of
the three gears. They were able to change and set the speed
of one gear at a time and watch as the speed of the other
gears changed. The remainder of the experiment was
identical to Experiment 2c. Responses to the (multiple
choice) questions regarding causal relationships at the end
of the experiment revealed that this learning phase did help
participants grasp the intended models.

Results and Discussion
195 participants reported causal models (collected at the
end of the experiment) that did not match the model
intended by the condition they were randomly assigned to.
Two analyses were done, one including these participants
and one excluding them. The results, as well as underlying
demographic characteristics, were qualitatively the same.
Due to page constraints, only the latter analysis (subjects
who passed the manipulation check) will be reported here.
Table 2: Actual and predicted cue weights in estimating missing
cue values in Experiment 2a-d.
Condition (Predicted
Model Match)
1-3 (Heuristic Model)
4-6 (Linear Model)
7 (Causal Model Only)
8 (No Model)

Causal Model
Prediction
βA
βB
0.00
1.00
0.63
0.55
-0.64
1.07
―
―

Participant
Responses
βA
βB
0.12
0.69
0.56
0.54
-0.33
0.82
0.24
0.23

To conserve space and to simplify analysis for reporting,
we will pool data across experimental variations as well as
group conditions based on the predictions made about their

weights. Thus, conditions 1-3, which all share predictions
of the heuristic model, and conditions 4-6, which all share
predictions of the linear model, will be grouped together. In
the analysis that follows, all predictions are generated based
on the reasoning described in the data analysis for
Experiment 1. As shown in Table 2, differences across
groups were consistent with the causal model hypothesis.
Specifically, a one-way ANOVA revealed that the main
effect of condition on the difference between weights
participants placed on A and B in their judgments was
significant (F(3, 162) = 20.38, p < .001, η2 = .28).
Consistent with the causal model hypothesis, post-hoc tests
indicated that the mean difference in weights for the
combined conditions 1-3 (M = .57) was significantly greater
than for that of conditions 4-6 (M =-.02, p = < .001) and
condition 8 (M = .01, p =.002). At the same time, the
differences between weights given to cues A and B in
conditions 1-3 were significantly lower than in condition 7
(M = 1.15, p < .001), as predicted.

General Discussion
In this paper, we have proposed a causal model theory of
judgment; namely, that people rely on their understanding of
the causal relationships among events to determine how to
weight various cues when forming judgments. Across two
studies with several variations, we have shown that
predictions of the causal model approach consistently meet
or exceed the accuracy of predictions of human judgment
made by either linear or heuristic models. Furthermore, the
causal model theory can specify when predictions of linear
versus heuristic models will be more accurate, and make
unique predictions in other situations.
These results suggest that, while linear and heuristic
models may be able to make predictions about cue weights
that match those of human judgments under certain
circumstances, these models may not be accurate
descriptions of the underlying cognitive process. Although
a strategy-switching approach may map onto actual
judgments more closely than either heuristic or linear
models do independently, this possibility adds unnecessary
complexity. Furthermore, without the ability to make a
priori specifications about which strategies would be used
under which circumstances, a strategy-switching approach
becomes unfalsifiable. In contrast, the causal model theory
makes clear predictions that parsimoniously explain
observed changes in the weights placed on various cues.
Absent specific prompts used in this paper to differentiate
causal relationships, situational factors may also change
perceived causal models, even when the underlying
relationship among events remains unchanged. This would
allow for judgments based on causal relationships to follow
patterns previously found by strategy switching in other
contexts. For example, putting people under time pressure
or cognitive load may lead them to develop simplified
causal models (e.g. Oppenheimer & Monin, 2009). This
underlying change would lead to judgments that mimic
those described by a shift from a linear model to a heuristic

1707

strategy. While we acknowledge that causal models may be
used to inform strategy switching rather than supplant it, it
will be worthwhile to investigate both the strong (causal
models supplant strategy switching) and weak (causal
models inform strategy use) versions of the hypothesis.
The experiments reported here support the hypothesis that
the presumed combination of heuristics and linear models is
actually describing specific instantiations of reliance on
causal models in judgment. While this paper has begun to
build a case for the causal model hypothesis, future studies
should aim to provide converging evidence as well as to
improve understanding of when and how a particular causal
model would be used.

Acknowledgements
We are grateful to Steven Sloman and members of the
Opplab for useful comments and suggestions.

References
Anderson, N. H. (1981). Foundations of information integration
theory. New York: Academic Press.
Brehmer, A., & Brehmer, B. (1988). What has been learned about
human judgment from thirty years of policy capturing? In B.
Brehmer & C.R.B. Joyce (Eds.), Human judgment: The SJT
view. Amsterdam: North-Holland, Elsevier.
Brehmer, B. (1994). The psychology of linear judgment models.
Acta Psychologica , 87, 137–154.
Brunswik, E. (1943). Organismic achievement and environmental
probability. The Psychological Review, 50, 255-272.
Brunswik, E. (1952). Conceptual framework of psychology.
Chicago, IL: University of Chicago Press.
Cokely, E.T., Kelley, C.M., & Gilchrist, A.L. (2006). Sources of
individual differences in working memory: Contributions of
strategy to capacity. Psychonomic Bulletin and Review, 13, 991997.
Cooksey, R.W. (1996). Judgment analysis: Theory, methods, and
applications. San Diego, CA: Academic Press, Inc.
Dawes, R.M., & Corrigan, B. (1974). Linear models in decision
making. Psychological Bulletin, 81, 95-106.
Dawes, R. M. (1979). The robust beauty of improper linear models
in decision making. American Psychologist, 34, 571-582.
Einhorn, H.J. & Hogarth, R.M. (1975). Unit weighting schemes
for decision making. Organizational Behavior and Human
Performance, 13, 171-192.
Gigerenzer, G., & Goldstein, D.G. (1996). Reasoning the fast and
frugal way: Models of bounded rationality. Psychological
Review, 103, 650–669.
Gigerenzer, G., Todd, P.M., & the ABC Research Group (Eds.)
(1999). Simple heuristics that make us smart. New York: Oxford
University Press.
Glymour, C. (2001). The mind’s arrows: Bayes nets and graphical
causal models in psychology. Cambridge, MA: MIT Press.
Gopnik, A. & Shulz, L. (Eds.) (2007). Causal learning:
Psychology, philosophy, and Computation. New York: Oxford
University Press.
Griffiths, T.L. & Tenenbaum, J.B. (2005). Structure and strength
in causal induction. Cognitive Psychology, 51, 334-384.
Hagmayer, Y., & Sloman, S. A. (2009). Decision makers conceive
of themselves as interveners, not observers. Journal of
Experimental Psychology: General, 138, 22-38.
Hammond, K.R. (1955). Probabilistic functionalism and the
clinical method. Psychological Review, 62, 255–262.

Hammond, K.R. (1996). Human judgment and social policy:
Irreducible uncertainty, inevitable error, unavoidable injustice.
New York: Oxford University Press.
Hogarth, R.M., & Karelaia, N. (2005). Ignoring information in
binary choice with continuous variables: When is less “more”?
Journal of Mathematical Psychology, 49, 115-124.
Hogarth, R. M., & Karelaia, N. (2007). Heuristic and linear models
of judgment: Matching rules and environments. Psychological
Review, 114, 733–758.
Hoffman, P.J. (1960). The paramorphic representation of clinical
judgment. Psychological Bulletin, 57, 116–131.
Kahneman, D., Slovic,P. & Tversky, A. (Eds.) (1982). Judgment
Under Uncertainty: Heuristics and Biases. New York:
Cambridge University Press.
Khemlani, S., & Oppenheimer, D.M. (2010). A levels of analysis
framework of causal discounting.
Morgan, M. G., Fischoff, B., Bostrom, A., & Atman, C. J. (2001).
Risk communication. A mental model approach. New York:
Cambridge University Press.
Newell, B. R., & Shanks, D. R. (2003). Take the best or look at the
rest?
Factors influencing “one-reason” decision making.
Journal of Experimental Psychology: Learning, Memory, and
Cognition, 29, 53–65.
Oppenheimer, D. M. (2004). Spontaneous discounting of
availability in frequency judgment tasks. Psychological Science,
15(2), 100-105.
Oppenheimer, D. M. (2005). Consequences of erudite vernacular
utilized irrespective of necessity: Problems with using long
words needlessly. Applied Cognitive Psychology, 20(2), 139156.
Oppenheimer, D. M., & Monin, B. (2009). The retrospective
gambler’s fallacy: Unlikely events, constructing the past, and
multiple universes. Judgment and Decision Making, 4, 326–334.
Payne, J.W., Bettman, J.R., & Johnson, E.J. (1988). Adaptive
strategy selection in decision making. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 14, 534-552.
Payne, J.W., Bettman, J.R., & Johnson, E.J. (1993). The adaptive
decision maker. New York: Cambridge University Press.
Pearl, J. (2000). Causality. New York: Cambridge University
Press.
Pennington, N., & Hastie, R. (1993). Reasoning in explanationbased decision making. Cognition, 49, 123–163.
Shah, A.K. & Oppenheimer, D.M. (2009). The path of least
resistance: Using easy-to-access information.
Current
Directions in Psychological Science, 18, 232-236.
Simon, H. (1957). Models of man. New York: Wiley.
Sloman, S.A. (2005). Causal models: How people think about the
world and its alternatives. New York: Oxford University Press.
Sloman, S.A. & Hagmayer, Y. (2006). The causal psycho-logic of
choice. Trends in Cognitive Sciences, 10, 407-412.
Slovic, P. (1969). Analyzing the expert judge: A descriptive study
of a stockbroker’s decision processes. Journal of Applied
Psychology, 53, 255-263.
Tversky, A., & Kahneman, D. (1974). Judgment under uncertainty:
Heuristics and biases. Science, 185, 1124–1131.
Wainer, H. (1976). Estimating coefficients in linear models: It
don’t make no nevermind. Psychological Bulletin, 83, 213-217.
Weiner, B. (1985). Spontaneous causal thinking. Psychological
Bulletin, 97, 74-84.
Wiggins, N. & Hoffman, P.J. (1968). Three models of clinical
judgment. Journal of Abnormal Psychology, 73, 70-77.

1708

