UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Neural Synchrony Through Controlled Tracking

Permalink
https://escholarship.org/uc/item/6vc9p8p0

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)

Authors
Pozega, Dennis
Thagard, Paul

Publication Date
2001-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Neural Synchrony Through Controlled Tracking
Dennis Pozega (dpozega@engmail.uwaterloo.ca)
Department of Systems Design Engineering, University of Waterloo, Waterloo, ON N2L 3G1 Canada

Paul Thagard (pthagard@uwaterloo.ca)
Department of Philosophy, University of Waterloo, Waterloo, ON N2L 3G1 Canada

Abstract
We present a model for generating a kind of neural
synchrony in which the individual spike trains of one
neuron or group of neurons closely match the spike
trains of another. This kind of neural synchrony has
been observed in animals performing auditory, visual
and attentional information processing tasks. Our model
is realized in a system of functionally identical,
refractory spiking neurons. Larger systems with more
sophisticated information processing capabilities can be
constructed from aggregated instances of the basic
network.

Introduction
Recently researchers ranging from neurobiologists (e.g.
Ritz & Sejnowski, 1997) to computer scientists (e.g.
Shastri, 1999) to psychologists (e.g. Hummel &
Holyoak, 1997; Sougné, 2000) have studied the thesis
that the synchrony of neural activity is one means by
which bits of information are aggregated into the larger
wholes necessary for complex information processing.
In brief, neural synchrony is thought to implement the
‘dynamic binding’ of certain representations in the
brain. It has also been suggested that neural synchrony
is part of the process by which consciousness emerges
from distributed brain activity.
But which neural dynamics are actually being
synchronized? The answers provided by a decade of
intensive research have generally all been variations on
three basic themes. The first approach to synchrony
intends the term to refer to coherence between
‘oscillations’ observed in the brain. In these cases it is
the aggregated neural activity generated by the whole of
a particular neural population that is deemed to be
oscillating, not individual cortical neurons. Ritz and
Sejnowski (1997) provide an excellent review of the
conditions under which this mode of synchrony occurs,
as well as its reputed significance in information
processing tasks. Two representative examples include
the observation of oscillatory synchrony in the brains of
cats completing a sensorimotor task (Roelfsema, Engel,
König & Singer, 1997), and its generation in an
artificial neural network modeling the brain’s solution
of a figure-ground segregation problem (Sporns,
Tononi & Edelman, 1991). Engel et al. have even
speculated that oscillatory synchrony may be

instrumental
in
bringing
representations
to
consciousness, based on results showing that this mode
of synchrony correlates with perceptual awareness in
cats (1999).
Synchrony is understood elsewhere as
correlated quasiperiodic activity occurring at a constant
phase offset with respect to a persistent background
oscillation. Different groups of neurons periodically
become active during different phases of the
background oscillation; neurons that become coactive
during the same subperiods are said to exhibit phase
synchrony. Phase synchrony allows the expression of
phase-coded representations: representations in which
information is coded in the relative timing of
quasiperiodic neural activity. Gerstner, Kempter, van
Hemmen and Wagner (1999) use empirical evidence
for phase-coding’s involvement in the sound source
localization task in barn owls to build a successful
mathematical simulation of the process.
As well,
Jensen and Lisman argue that data from psychological
experiments and rat EEGs support accounts of short
term memory capacity (1998) and position
reconstruction in rats (2000), respectively, framed in
phase-coding terms.
Phase synchrony is also exploited in a number
of influential models of cognitive processes. Shastri, in
his SHRUTI model of inference and reasoning, uses
phase synchrony to bind neurons corresponding to rolefiller words; e.g., John, with other neurons
corresponding to specific roles in propositions; e.g., X
in “X sees Y” (Shastri & Ajjanagadde, 1993; Shastri,
1999). Similarly, phase-coded bindings of roles to rolefillers underlie Hummel and Holyoak’s IMM and LISA
models of analogy formation (Hummel, Burns &
Holyoak, 1994; Hummel & Holyoak, 1997).
Finally, there is a third synchrony
phenomenon that we have termed ‘spike train
synchrony.’ This synchrony is present when strong
correlations exist between the individual firing times of
different neurons or groups of neurons. There is no
need that these firing times be quasiperiodic, as in
phase synchrony. Nor is it generally possible to explain
the aggregate synchronized activity as oscillatory; in
fact, the mean overall activity of the neurons involved
can remain close to constant except over very short
time intervals.

DeCharms and Merzenich (1996) observed the
spike train synchrony of neurons in the brains of
anesthetized marmoset monkeys responding to a pure
tone stimulus. For the duration of each tone, the firing
patterns of selected neural regions became correlated,
even though their mean firing rates remained
unchanged. In addition, this correlation disappeared
when the tone ended and was absent before it began.
Tightly correlated spike trains have also been reported
for neighbouring cells in two early vision regions: the
retinal ganglia (Meister, 1996) and the lateral geniculate
nucleus (Alonso, Usrey & Reid, 1996). More recently,
Steinmetz et al. (2000) have found that certain
somatosensory neurons in monkeys increase the
correlation of their spike trains when performing visual
and tactile tasks requiring increased attention.
All three modes of synchrony outlined here
have been empirically observed under conditions which
suggest a role for them in specific information
processing tasks. Furthermore, previous research, as
cited above, has resulted in working models
demonstrating how the first two types, oscillatory and
phase synchrony, may be generated. The design of
computational simulations targeting the generation of
synchrony at the level of individual spike trains,
however, has received little attention.
Simulation-based research of this type should
help to elucidate the structural and functional aspects of
the brain necessary for spike train synchrony as it has
been observed. Moreover, even in the absence of an
artificial system mirroring the exact architecture of the
brain, spike train synchrony models should provide
insights and help researchers test hypotheses
concerning information processing tasks whose
realizations in the brain presumably require this form of
synchrony. Advances generated by analogous models
depending on other synchronies—Shastri’s model of
logical reasoning, for example—corroborate this claim.
In this paper we present an artificial neural
network designed to exhibit spike train synchrony. The
neurons in the network are all functionally identical,
refractory neurons, and the connections between them
are all of the same, standard type.
The controlled tracking network displays a
simple behaviour: the clone neuron copies or ‘tracks’
the spike train of the primary neuron. The copying
process is selective, meaning that it stops and starts in
response to signaling from two actuator neurons. In
this way, the clone neuron can be made to fall in and
out of synchrony with the primary neuron.
The design of the network was completed in
two stages. In the first, a basic network was built in
which the clone neuron was made to copy the activity
of the primary neuron at all times. Pausing or halting
the copying is not allowed in this network. These
operations were implemented in the second stage of
network design, in which the control component of the
system was integrated. Finally, in the last section, we

highlight the contributions of the model to
understanding the generation of biological spike train
synchrony and its role in information processing. This
includes a discussion of the merits of our model’s
representational capabilities over those used in other
influential modeling approaches.

Mathematical Fundamentals
This section describes the dynamics of the neurons we
use to build our spike-tracking networks. In brief, our
neurons function like the Spike Response Model
neurons developed in Gerstner (1999), with only slight
modifications. We review the defining equations of our
neurons here, drawing heavily from Gerstner’s
formulations.
The total membrane potential ui of each
spiking neuron i is given by:
u i (t ) =
(t − t i ) +
wi , j i , j (t − t j ) . (1)

∑

∑∑

j∈Γi t j ∈F j

ti ∈Fi

The last term of this equation quantifies the
contributions to the membrane potential of neuron i due
to excitations and inhibitions from the set i of neurons
with efferent connections to i. Each such neuron j will
contribute to i’s membrane potential due to postsynaptic potentials seen coming from j across the
synapse connecting to i. The function i,j(s) equals the
excitatory post-synaptic potential seen at post-synaptic
neuron i at a time of s seconds after the firing of a presynaptic neuron j. The set Fi represents the set of all
individual spike times ti of the neuron i; likewise, Fj and
tj for neuron j. Finally, the constant wi,j represents the
strength of the connection from neuron i to neuron j. In
summary, the last term of Eq. (1) sums the
contributions to membrane potential due to incoming
post-synaptic
potentials,
after
scaling
these
contributions by the appropriate connection weights.
The function i,j(s), introduced above is
defined by:
  s − ∆i, j 
 s − ∆ i , j 
 − exp −
 H ( s − ∆ ) , (2)
( s ) = exp −
i, j







m







s




i, j

where m and s are time constants determining the
shape of the post-synaptic pulse, i,j is the propagation
time of the electric potential signal between the
beginning and end of a connection from i to j (also
called the axonal delay or ‘length’) , and H is the
Heaviside unit step function:

0
H(t) = 
1

for t < 0

(3)

otherwise

The left term on the right hand side of equation (1)
accounts for the response of neuron i to its own
previous spikes. This term quantifies the refractoriness
of neurons; i.e., the decreased capacity of a neuron to
spike soon after it has just spiked. Refractoriness is
modeled as a short-term, decaying, inhibitory signal:

(s) = −

0

 s
exp− H(s)− K [ H (s)] H(
 r

abs

− s) (4)

The variable s is the time since a previous spike, while
the parameters
and r scale the amplitude and the
decay rate, respectively. H(s) remains the Heaviside
unit step function as discussed above. Finally, the
constant K represents an arbitrarily large number and
the parameter abs designates the duration of absolute
refractoriness. This represents the length of time after a
spike during which a second spike is physically
impossible.
A neuron spikes each time that its membrane
potential ui exceeds a threshold value provided that ui
is increasing from a subthreshold value on the last
discrete time step. Each spike results in a new spike
time ti being added to the set Fi of all spike times for
neuron i.

Tracking Network
In this section, we describe a network where one
neuron’s spike train, the clone neuron, closely
duplicates the spike train of another neuron, the primary
neuron, at all times. We call this network the tracking
network. Fig. 1 illustrates the architecture of our
tracking network, in which auxiliary neurons serve to
enable a clone neuron to synchronize its firing with the
primary neuron. The complication of the network,
primarily due to the many feedback connections, is
necessary in a tracking system composed of refractory
neurons.
Refractoriness causes a transient
desensitization of a neuron to incoming inputs shortly
after that neuron’s firing. Consequently, a pulse in an
input signal will not elicit the same response from a
refractory neuron that has just fired as it will from one
that has not yet fired. This means that simply
connecting the primary neuron to the clone neuron will
not produce reliable tracking because the clone neuron
will be biased to respond differently to different postsynaptic pulses sent from the primary neuron. The
clone neuron will be slower to spike in response to an
incoming superthreshold pulse coming a short time
after the last one, in comparison to one coming a long
time after the last one.
Primary
neuron
Auxiliary
neurons
Clone
neuron
Figure 1. Spike tracking system.

To restore the efficacy of the external input to
a refractory neuron, which in our system corresponds to
the primary neuron’s outgoing post-synaptic pulses, we
construct an auxiliary signal that provides a second
input to the clone neuron. This signal is implemented
using the output pulses of auxiliary neurons connected
efferently to the clone neuron. These auxiliary neurons
are coerced to fire in such a way that the potential
pulses they output individually to the clone neuron add
up to a negative approximation of the refractory term
of Eq. (1).
Mathematically, each connection from an
auxiliary neuron to the clone neuron results in an
additional term in the expansion of the double
summation of Eq. (1). Therefore, for the set A of
auxiliary neurons to successfully mitigate refraction,
the mathematical constraint to be satisfied is specified
by Eq. (5) in the appendix. The variables wc,a and c,a
represent the auxiliary to clone neuron connection
strengths and time delays, respectively, while ta
represents the firing times of the auxiliary neurons.
These three sets of variables remain to be specified, in
addition to the total number of auxiliary neurons to be
used. To determine acceptable values for these
unknowns we first perform the following simplifying
analysis.
The analysis solves the approximation
problem for only a limiting case, but we go on to show
that straightforward modifications lead to a more
general solution.
For now we assume a single, isolated
refractory incident corresponding to a single, isolated
firing of the clone neuron at time tc = 0. Second, we
require that pulses from the auxiliary neurons arrive
instantaneously at the membrane of the clone neuron;
i.e., we set the connection time delays
c,a to 0.
Finally, we tentatively prohibit each auxiliary neuron
from firing more than once. These conditions allowed
us to reformulate the constraint of Eq. (5) using Eq. (6)
in the appendix. In graphical terms, this simplified
constraint commits us to build up an approximation to
the refractory function by summing time-shifted and
scaled postsynaptic pulses . The pulses are vertically
scaled according to the connection strengths wc,a. Their
time shifting is specified by the times of firing ta of the
auxiliary neurons.
For convenience we chose to limit the
maximum relative error of our particular approximation
to less than 5%. Better approximations are possible,
but as error decreases, the number of required auxiliary
neurons increases, making the network larger. For our
error tolerance of 5% we were able to construct a
feasible solution set of values ta and wc,a using 23
auxiliary neurons.
The set of solution values ta indicate the time
each auxiliary neuron must spike, relative to the clone
neuron, in order to mitigate refractoriness. To force the
neurons to spike at these times, we apply the same
external input signal that the clone neuron experiences

to each of the auxiliary neurons, with a time delay of
length ta, the firing offset time for that neuron. In
physical terms this means connecting the primary
neuron to each auxiliary neuron. The strengths wa,p of
these primary to auxiliary connections should be
identical to the strength wc,p of the single primary to
clone neuron connection. The lengths a,p of the
primary to auxiliary connections, however, must equal
the primary to clone neuron connection length plus the
firing time offset ta calculated for the particular
auxiliary neuron a in question.
Returning to the assumptions we made earlier,
the system thus connected is only strictly guaranteed to
mitigate the clone neuron’s refractoriness due to its
very first spike. This is because the clone neuron was
assumed to fire only once in isolation. To compensate
for the refractoriness following all spikes, the auxiliary
neurons need to spike—and with a precise time lag of
ta—not just the first time that the clone neuron spikes,
but every time it spikes.
Though all the auxiliary neurons share the
same external input as the clone neuron, they will fail to
spike as required (i.e., every time the clone neuron
spikes) because the clone neuron now has an additional
input signal compensating for its internal refractoriness.
It is no longer desensitized due to the refractoriness
following from its first spike, but the auxiliary neurons
still are.
We remedy this problem by feeding an
additional input into each of the auxiliary neurons.
Each of these additional input signals should be
identical to the refractoriness compensation signal for
the clone neuron, except that, as before, the signals
should arrive with a time lag or delay of ta specific to
the auxiliary neuron a in question.
In terms of implementation, this translates into
an additional bundle of connections to each auxiliary
neuron. Each bundle consists of a set of connections
leading from each auxiliary neuron to one of those
auxiliary neurons. Therefore, if there are N auxiliary
neurons, N feedback bundles are required, each
containing N unique connections. This makes for N2
auxiliary neuron feedback connections in total.
We should emphasize that we have been
ignoring the absolute refractory component of the
refractoriness signal corresponding to the second term
in Eq. (2). Physiologically the absolute refractoriness
of neurons could never be compensated for in
biological networks in any event, because it arises from
a fundamental electrochemical constraint on the
availability of certain molecules (Paul, 1975).
Furthermore, because all our neurons are identical, a
clone neuron would never be expected to track a spike
which would land itself in the absolute refractory period
following a previous spike: the primary neuron would
not be capable of producing such a spike train.
We tested the capacity of the clone neuron to
copy the spike train of the primary neuron, as connected

in the tracking network described above. The network
was simulated using the SpikeSim program we
designed in Java. As input to the tracking system, spike
trains were evoked from the primary neuron that
corresponded to an exponential distribution of spikes
with a mean of 30 time steps between spikes.
The results indicate that missing spikes and
bursts of spikes at inappropriate times (‘ringing’) seem
to be the only symptoms of inaccurate tracking. In
biological systems such aberrations could be explained
by molecular and thermal noise.
A very strong cross correlation over a set of
ten trials was observed between the spike trains of the
primary and clone neuron. We found that the spike
train of the clone neuron slightly lags the spike train of
the primary neuron. A non-zero time lag is inevitable
because it takes time for the post-synaptic pulses to
peak. Nevertheless, it should not be of too much
concern because the signals can be time-shifted so they
coincide as seen from a third neuron’s perspective.
Setting appropriate connection lengths for the primary
to third neuron connection and the clone to third neuron
connection will implement the necessary shifting.

Discussion
We have presented a new computational model for
synchrony generation, a model that implements
controlled spike train tracking of one neuron by
another. In this closing discussion, we investigate a
possible variation of the model promising greater
physiological plausibility. We then move on to
compare the merits of this model to others in the field;
namely, Shastri’s and Hummel’s. Finally, we argue
that our basic model and its variations will likely prove
helpful in the effort to develop larger scale simulations
of cognitive processes.
To build the controlled spike tracking system,
we constructed connections between the auxiliary
neurons and the clone neuron of length (or time delay)
zero. The connections between the primary neuron and
the clone neuron, however, are variable in length and
all non zero, in order to implement time lag delays. As
a result of this configuration all the auxiliary neurons
and clone neurons end up generating identical but timeshifted spike trains: these neurons fire in a wave-like or
‘follow-the-leader’ type manner.
Theoretic considerations suggest that an
operationally identical network can be implemented in
a way that is more physiologically realistic. Instead of
implementing the time delays through lengthening the
connections from the primary to auxiliary neurons, we
can set these constant and stagger the lengths of two
sets of connections: those in the feedback bundles, and
those between the auxiliary neurons and the clone
neuron. This removes the need for problematic zerolength connections across which electrical pulses would
presumably need to instantaneously travel, while
preserving the critical time-delay dynamics of the

refractoriness compensation signal. In this revised
setup, the auxiliary neurons and the clone neuron would
all fire identical spike trains, just as before, but with no
time lag asynchrony.
We also reason that if auxiliary neurons exist
in the brain to mitigate for refraction, they likely play
roles in other brain circuits as well. If this is so, their
mutually synchronous firing would help to maintain
signal or information synchrony in all of these circuits.
Such synchrony would not evolve from the original
controlled tracking network, but would characterize the
auxiliary neurons in the modified variation, as
described above. In short, there are several reasons for
believing that the proposed network variation should be
superior to the original controlled tracking network.
The artificial neural networks whose results
were presented above were simulated with the
assumption of no noise. In later trials we investigated
the effect of introducing noisy dynamics to the Spike
Response Neuron model defining the neurons in our
network. More specifically, the firing thresholds were
made noisy by adding to the membrane threshold
function a Gaussian random variable with mean of zero
and standard deviation proportional to the degree of
desired noisiness. This method of introducing noise is
one of the standard ones discussed in Gerstner (1999).
When simulated, noisy neurons resulted in
severely poor tracking performance, even when the
noisiness was kept low. The largest errors in tracking
were bursts of extraneous spikes occurring after a single
premature firing. This initial firing was in turn due to a
transient lowering of the membrane threshold of a
single neuron when that neuron’s membrane potential
was close to the average threshold.
We expect that poor tracking under noise
conditions can be mostly eliminated by a redesign of
the feedback connections between auxiliary neurons,
one which would not modify their basic role in the
network. Our ideas are still only in an early stage of
development, however. For now we have to concede
that our system’s spike tracking performance is poor
under noisy conditions.
Future research could investigate the
implications of the unique information encoding and
processing properties our system possesses by nature of
its design. For instance, the system allows for more
versatile synchronic neural coding than that available in
networks used in Shastri’s SHRUTI model of logical
reasoning or Hummel’s LISA or IMM models of
analogy formation. In these systems individual neurons
are active for a maximum of one portion or ‘phase’ of
each background oscillatory cycle, during which they
may fire either alone or more generally in synchrony
with a group of other neurons that are also active only
during that phase. During other periods of the
background oscillatory cycle all these neurons are
inactive.

The neurons in the controlled spike-tracking
system presented here can be made to synchronize in
this way, but they are capable of more sophisticated
synchronic dynamics as well, as the simulation results
demonstrated. Through the control interface, variable
length periods of transient synchrony were elicited from
our system on demand. Furthermore, as will be
demonstrated below, the clone neuron can be made to
regularly switch between synchrony with different
groups of neurons. In contrast, the other three models
require a neuron to synchronize with only one group of
neurons and only then during short, periodic time
windows of constant width.
Another significant difference lies in the firing
patterns during periods of synchrony. In the SHRUTI,
LISA and IMM-based networks, the firing of a neuron
within its interval of synchrony is only described in
terms of its overall firing rate or ‘level of activity.’ But
in controlled spike tracking systems, significant
subcoding can take place within time intervals of
synchronized activity. By subcoding we mean that
additional information can be stored in the relative
timing of spikes within each period or instance of
neural synchrony.
For the other models noted,
supporting subcoding within periods of synchrony
would
effectively
require
system
redesign.
Consequently, we claim that our tracking system allows
for more detailed elaboration of representations during
synchronous neural firing.
Finally, we suggest that sophisticated neural
networks for simulating higher level cognitive
processes could be designed using the controlled
tracking system as a reusable component, a repeated
building block. Such networks would broaden our
understanding of the processes they model, just as
SHRUTI and LISA have provided insights into the
reasoning and analogy-forming processes they were
built to simulate.
Imagine a network with six inputs. Three of
these are generated by three primary neurons, each of
which we assume signals a separate and unique stream
of representations coded within its spike train. The
other three inputs are provided by three switch neurons,
each corresponding to one of the three primary neurons.
The network takes advantage of these inputs, and four
spike tracking subsystems embedded within it, to
implement a relatively complex behaviour: on receiving
a single spike from one of the three switch neurons, the
network begins to track the spike train of the
corresponding primary neuron. When a different
switch neuron spikes, the network switches inputs and
starts tracking a different primary neuron. In effect,
this network implements the ability to reorganize
arbitrary parts of neural signals, corresponding to
different temporally coded representations, in
sophisticated ways. Such reorganization or ‘splicing’
mechanisms could prove quite useful for a number of
information processing tasks.
Compressions of

sequences of elaborate representations into more
succinct streams could be one such task.
This network demonstrates the potential
increase in information processing sophistication that
emerges from constructing larger networks within
which simple spike tracking subsystems work in
coordination. We hope that the application of this kind
of design approach will contribute to the future
development of neural network models that carry out
information processing tasks similar in complexity to
those that the brain performs. Moreover, by shedding
light on the internal mechanics of the processes
involved, such models might not only demonstrate or
mimic what the brain does but also help to further
clarify just how it does it.

Acknowledgments
We thank Brandon Wagar and Sid Fingerote for helpful
discussions. This work was funded by NSERC.

References
Alonso, J.-M., Usrey, W. M., & Reid, R.C. (1996).
Precisely correlated firing in cells of the lateral
geniculate nucleus. Nature, 383, 815-819.
deCharms, R. C. & Merzenich, M. M. (1996). Primary
cortical representation of sounds by the coordination
of action-potential timing. Nature, 381, 610-613.
Engel, A.K., Fries, P., König, P., Brecht, M., & Singer,
W. (1999). Temporal binding, binocular rivalry, and
consciousness. Consciousness and Cognition, 8,
128-151.
Gerstner, W. (1999). Spiking neurons. In W. Maass &
C. M. Bishop (Eds.), Pulsed neural networks (pp. 353). Cambridge, Mass.: MIT Press.
Gerstner, W., Kempter, R., van Hemmen, J. L., &
Wagner, H. (1999). Hebbian learning of pulse
timing in the barn owl auditory system. In W. Maass
& C. M. Bishop (Eds.), Pulsed neural networks (pp.
353-377). Cambridge, Mass.: MIT Press.
Hummel, J. E., Burns, B., & Holyoak, K. J. (1994).
Analogical mapping by dynamic binding: preliminary
investigations. In K. J. Holyoak & J. A. Barnden
(Eds.), Advances in connectionist and neural
computation theory: volume 2 (pp. 416-445).
Norwood, New Jersey: Ablex.
Hummel, J. E. & Holyoak, K. J. (1997). Distributed
representations of structure: a theory of analogical
access and mapping. Psychological Review, 104(3),
427-466.
Jensen, O. & Lisman, J. E. (2000).
Position
reconstruction from an ensemble of hippocampal
place cells: contribution of theta phase coding.
Journal of Neurophysiology, 83, 2602-2609.
Jensen, O. & Lisman, J. E. (1998). An oscillatory
short-term memory buffer model can account for data

on the Sternberg task. The Journal of Neuroscience,
18(24), 10688-10699.
Meister, M. (1996). Multineuronal codes in retinal
signaling. Proceedings of the National Academy of
Science USA, 93, 609-614.
Paul, D. H. (1975). The physiology of nerve cells (pp.
57-8). Oxford: Blackwell Scientific.
Ritz, R. & Sejnowski, T. J. (1997). Synchronous
oscillatory activity in sensory systems: new vistas on
mechanisms. Current Opinion in Neurobiology, 7,
536-546.
Roelfsema, P. R., Engel, A. K., König, P., & Singer, W.
(1997). Visuomotor integration is associated with
zero time-lag synchronization among cortical areas.
Nature, 385, 157-161.
Shastri, L. (1999). Advances in SHUTRI – a neurally
motivated
model
of
relational
knowledge
representation and rapid inference using temporal
synchrony. Applied Intelligence, 63, 69-142.
Shastri, L. & Ajjanagadde, V. (1993). From simple
associations to systematic reasoning: a connectionist
representation of rules, variables and dynamic
bindings using temporal synchrony. Behavioral and
Brain Sciences, 16, 417-494.
Sougné, J.P. (2000). Simulating conditional reasoning
containing negations: A computer model and human
data. In L.R. Gleitman, & A.K. Joshi. (Eds.)
Proceedings of the Twenty-Second Annual
Conference of the Cognitive Science Society (pp.
918-923). Mahwah,NJ: Erlbaum.
Sporns, O., Tononi, G., & Edelman, G.M. (1991).
Modeling perceptual grouping and figure-ground
segregation by means of active reentrant connections.
Proceedings of the National Academy of Science
USA, 88, 129-133.
Steinmetz, P. N., Roy, A., Fitzgerald, P. J., Hsiao, S. S.,
Johnson, K. O., & Neibur, E. (2000). Attention
modulates synchronized neuronal firing in primate
somatosensory cortex. Nature, 404, 187-189.

Appendix
Equation (5):

∑

(t− t c) ≈ −

tc ∈ Fc

= −

∑ ∑w

(t − ta )

c, a c, a

a ∈Γ A t a ∈ Fa

∑ ∑

a ∈Γ A ta ∈ Fa





 t −t −∆


t −ta −∆ c, a 
 −exp  − a c, a   H( t −t −∆ )
a c, a 


 
m
s








wc, a  exp−


Equation (6):



c ,a 



(t ) ≈ − ∑ w
a∈ΓA



  t − ta 
 t − t a 
 − exp −
 H (t − t a ) 
exp −

m 
s 

 


