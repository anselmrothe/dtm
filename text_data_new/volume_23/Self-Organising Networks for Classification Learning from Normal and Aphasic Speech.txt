UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Self-Organising Networks for Classification Learning from Normal and Aphasic Speech

Permalink
https://escholarship.org/uc/item/52t5s42f

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)

Authors
Garfield, Sheila
Elshaw, Mark
Wermter, Stefan

Publication Date
2001-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Self-Organising Networks for Classification Learning from Normal and
Aphasic Speech
Sheila Garfield, Mark Elshaw and Stefan Wermter
University of Sunderland
Informatics Centre, SCET
St. Peter’s Way
Sunderland SR6 0DD, United Kingdom
Email: Stefan.Wermter@sunderland.ac.uk
Phone: +44 191 515 3279
Fax: +44 191 515 3553
Abstract
An understanding of language processing in humans is
critical if realistic computerised systems are to be produced to perform various language operations. The examination of aphasia in individuals has provided a large
amount of information on the organisation of language
processing, with particular reference to the regions in the
brain where processing occurs and the ability to regain
language functionality despite damage to the brain. Given
the importance played by aphasic studies an approach that
can distinguish between aphasic forms was devised by
using a Kohonen self-organising network to classify sentences from the CAP (Comparative Aphasia Project) Corpus. We demonstrate that the different distributions of
words in aphasics types may lead to grammatical systems
which inhabit different areas in self-organising maps.

Introduction
The examination of neural language processing is of importance as it offers the opportunity for producing realistic computerised language systems and a comprehension
of the underlying biological mechanisms and constraints
involved. One technique that has proved useful for identifying the organisational arrangement of language processing is the examination of aphasia. Aphasia is the inability to perform one or more cognitive language functions due to damage to the brain. The typical causes
of aphasia are brain tumours, strokes, head injuries and
infections. Although this is a rough simplification, the
two most common types of aphasia are Broca’s and Wernicke’s aphasia.
Broca’s Aphasia: Subjects with damage to the Broca’s
area of the cerebral cortex have problems creating spoken responses. These responses are often grammatically
incorrect, effortful, laboured, come in bursts and have
a restricted vocabulary. Furthermore, verbs are often
missed out or replaced by the nominal form in spontaneous speech. However, many individuals with this condition can perform language processing functions such
as language comprehension, dealing with non-reversible
sentences, object and verb recognition and the identification of semantic and verb errors. Table 1 provides examples of typical spontaneous speech from Broca’s aphasics
[Wermter, Panchev and Houlsby (1999), Marshall, Pring
and Chait (1998) and Brendt and Caramazza (1999)].
Wernicke’s Aphasia: Although individuals with Wernicke’s aphasia have problems understanding language

and producing sentences that are meaningful, they can
produce fluent phrases that have a reasonable syntactic, grammatical and symbolic structure [Chen and Bates
(1998) and Wermter, Panchev and Houlsby (1999)]. Table 2 provides examples of spontaneous speech from
Wernicke’s aphasics.
An approach previously used to distinguish aphasic
forms is recurrent neural networks [Wermter, Panchev
and Houlsby (1999)]. Such networks can represent long
term memory and context using recurrent connections
and extracting the appropriate context from inputs. In
the simple recurrent network outlined by Elman (1990)
the context layer stores the activations of the hidden layer
units for one time step and passes them back to the hidden layer units on the next step. Typically there is a oneto-one relationship between the number of units in the
context layer and in the hidden layer [Spitzer (1999)].
This offers the opportunity to recycle information from
multiple time steps and to identify temporal relationships. As the hidden layer receives inputs from both the
input and the context layer, patterns should have an impact across time and context be learned.
However, there are certain drawbacks with recurrent
neural networks which led us to consider an alternative
approach. Recurrent neural networks are a supervised
learning approach that do not perform in a manner that
is close to neural networks in the human brain. Therefore in this paper we used unsupervised self-organising
networks that can identify categories, features and regularities using unsupervised learning in a manner closer
to the cerebral cortex. In this paper we analyse spoken language from Broca’s aphasics, Wernicke’s aphasics and normal patients. We demonstrate that the different distributions of words in aphasics types may lead
to grammatical systems which inhabit different areas in
self-organising maps.

Location of Aphasia and Language
Function
The examination of aphasics provides some indication of
how language processing is organised and the form that
language recovery takes. A language processing model
that has been established from studying the location of
damage in the cerebral cortex of aphasics is that the human brain performs diverse language processing opera-

Table 1: Typical spontaneous speech from Broca’s aphasics.
Normal phrase
A boy is giving the ball to the man
A monkey is eating a banana
Chrysanthemum
Cat cries

Broca’s aphasic response
A boy is ... the ball
Monkey ... banana
Chrysa...mum...mum
Cat tears

Table 2: Typical spontaneous speech from Wernicke’s aphasics.
Typical Wernicke’s aphasic responses
They are running a swimming water and snow
The boy is running he is talking to the it is a cat
It is a cat and he is talking the flower

tions. According to Taylor (1999) and Dodel, Hermann
and Geisel (1999) the cortex is made up of various somewhat overlapping regions which are responsible for cognitive language sub-operations. In order to produce the
final language functions there is a need to coordinate and
combine the outcomes of the appropriate regions. According to Reilly (2001) the brain performs as a group of
collaborating specialists, none of which can deal with a
difficulty alone, but only do so when each cooperates. In
the brain it is possible to deal with a complex difficulty
by splitting the task into smaller elements and coordinating these elements. The uniqueness of the human brain
does not come from the number of neurons but the structural complexity. It has been identified that the module
approach can offer re-usability by having a region of the
brain doing the same processing activity as part of many
different cognitive functions [Reilly (2001)].
In terms of the actual functions that are associated with
diverse regions of the cerebral cortex a few examples
will now be outlined. When Binder, Frost, Hammeke,
Cox, Rao and Prieto (1997) required individuals to state
whether an animal was native of America and used by
humans, different principal regions of the cerebral cortex were established as responsible for the language processing involved: (i) an area incorporating the superior
temporal sulcus, middle temporal gyrus and parts of the
inferior temporal gyrus; (ii) sections of the inferior and
superior frontal gyri, the middle frontal gyrus and the
anterior cingulate; (iii) angular gyrus; and (iv) a region
containing the posterior cingulate and gyrus zones.
Silent word generation starting with a certain letter
takes place in Broca’s and Wernicke’s areas and sections
of the left frontal, temporal and parietal lobes [Papke,
Hellmann, Renger, Morgenroth, Knetcht, Schuierer and
Petersen (1999)] and the resolution of whether two
words belong to the same semantic group involves increased activity in the superior frontal gyrus and frontal
gyrus [Shaywitz, Shaywitz, Pugh, Constable, Skudlarski,
Fulbright, Bronen, Fletcher, Shankweiler, Katz, Gore
(1995)]. Finally, the process of generating verbs out loud

was found by Xiong, Rao, Gae, Woldroff, Fox (1998)
and Raichle, Fiez, Videen, Macleod, Pardo, Fox, Petersen (1994) to be associated with areas of the left posterior temporal cortex, right anterior cingulate, inferior
frontal gyrus, Broca’s area, left superior temporal gyrus,
cingulate gyrus, inferior temporal gyrus and the occipital
gyri.
The examination of aphasia has assisted in creating
models of the form that the recovery of language processing takes in the brain. Examinations of the brain following death have identified injuries to parts of the cerebral
cortex in normally functioning individuals which should
have produced aphasia. This led to the view from Karbe,
Thiel, Weber-Luxenburger, Herholz and Heiss (1998),
Basso, Gardelli, Grassi and Mariotti (1989) and Capp,
Perani, Grassi, Bressi, Alberoni, Franceschi, Bettinardi,
Todde, and Frazio (1997) that language functions are recovered through regeneration of the damaged tissue or
the redistribution of functionality to other regions of the
brain that are operationally linked but not required in
healthy individuals.
There is mixed research evidence for the time it normally takes for repair of injured tissue. However, researchers have found than redistribution of functionality
to new regions of the brain can take longer and repair
of the left superior temporal gyrus occurs over numerous months following the injury [Mimura, Kato, Kato,
Santo, Kojima, Naeser and Kashima (1998) and Weiller,
Isensee, Rijntjes, Huber, Müller, Bier, Dutschka, Woods,
Noth and Diener (1995)]. As early as in the 19th Century Gower determined that individuals who lost speech
due to damage to the left hemisphere were able to recover it through interaction with the right hemisphere.
The region of the right hemisphere analogous to Broca’s
area and the right perisylvian have taken over the functions associated with the Broca’s and Wernicke’s areas
respectively when they are injured. According to Reggia, Shkuro and Shevtsova (2000) the reorganisation of
the brain regions responsible for language explains the
remarkable capacity to recover from injury and robust,

fault-tolerant processing. So in summary several brain
regions may be involved with aphasia, even though at
a highest level often a distinction of Broca’s and Wernicke’s aphasia has been made in the past.

Classification of Aphasia using
Self-Organising Networks
As aphasia studies provide a significant amount of relevant information regarding the organisation of brain processing, there is a motivation to develop an approach to
classify interviewed subjects to distinguish the aphasia
form they have.

Fitting of model sectors is performed by a sequential
regression procedure, where t = 1, 2, ... is the step index:
For every sample x(t), the winner index c is established
by the condition
i, x(t) − mc (t)

x(t) − mi (t)

Once this has occurred, every model vector mi or a
subgroup of them that belong to units centred around unit
c = c(x) are altered as
mi (t

1) = mi (t)

hc(x),i (x(t) − mi (t))

The ‘neighbourhood function’ hc(x),i defines those
units that are to be updated.

Method Overview
The language transcripts used for the training and test
data sets for a self-organising network were obtained
from the CAP Corpus [Bates, Fredrici and Wulfeck
(1987a and 1987b)]. The CAP Corpus is made up of
transcripts of English-speaking subjects that are divided
into three groups: Broca’s aphasia, Wernicke’s aphasia
and a control group of healthy people. The language
transcripts were produced using a variation of the “givennew” picture description task of MacWhinney and Bates.
In this task subjects were shown nine sets of three pictures and were asked to describe them (see Table 3).
The transcripts contained the subject’s response and the
morphemic coding. We used the coding from a previous study by Wermter, Panchev and Houlsby (1999).
This maps the morphemic coding of the corpus patterns
using the following syntactic descriptors: DET (Determiner), N (Noun), N-PL (Plural), PRO (Pronoun), PREP
(Preposition), ADJ (Adjective), CONJ (Conjunction), V
(Verb), V-PROG (Progressive), AUX (Auxiliary Verb),
ADV (Adverb), ADJ-N (Numeric).

Unsupervised Learning
The self-organising network that was used consists of an
input and an output layer, with every input neuron linked
to all the neurons in the output layer [Spitzer (1999),
Hecht-Nielsen (1990), Kohonen (1997) and Anderson
(1999)]. A self-organising network can be used by itself or as a layer of another neural network. Input data
is presented one sample at a time and the nodes compete
against each other. The Kohonen layer creates a topographical representation of the critical characteristics of
the input by creating a pattern of active and inactive units
(see Figure 1). The activation of the units are calculated
by multiplying the input from each input unit by its related synaptic weight and summing all the inputs for a
specific unit.
Learning in self-organising networks is performed by
updating the links between the input layer and the output
layer via a form of Hebbian learning. Self-organising
networks attempt to depict the input data with a set of
models, with similar words and concepts producing models that activate the units in the output layer that are close
together.

Figure 1: A representation of the activity maps of a selforganising network - The darker the neuron the greater
the activation.
The self-organising network architecture considered
to classify aphasic types contained 100 units (10 x 10)
in the output layer. Using a different training/test set
pair a self-organising network was trained and tested using the following approach. A network was trained over
1000 epochs using 80 phrases for each of the three aphasic types (Wernicke’s aphasics, Broca’s aphasics and a
healthy control group) that were produced from the CAP
Corpus. So in total there were 240 phrases. The location
of each of these training phrases on the self-organising
maps was identified based on the units that had the highest activation. The trained network was then tested by
identifying where on the map 80 unseen phrases per
aphasic type are positioned and the degree of symmetry between the training and test samples. The objective
was to test if the phrases for Broca’s and non-Broca’s
aphasics are located in different regions of the map and
whether the network is able to generalise by placing the
test phrases for the two groups in the same regions as the
training ones. If the same unit has the highest activation
level for phrases from both groups the unit is allocated to
the aphasic type that has the most phrases associated with
it. The grouping of Wernicke’s aphasics with the healthy
control group is motivated by the observation that Wernicke’s aphasics often use correct syntax like the healthy
control group while Broca’s aphasics do not.
To remove any bias in classification and clustering the
test/training phrases are based on the first six words of

Table 3: Picture series.
Syntactic Description
DET N AUX V-PROG
DET N AUX V-PROG
DET N AUX V-PROG DET N
DET N AUX V-PROG DET N
DET N AUX V-PROG DET N
DET N V PREP DET N
DET N V PREP DET N
DET N AUX V-PROG DET N PREP DET N
DET N AUX V-PROG DET N PREP DET N

Sentences
A bear/mouse/bunny is crying.
A boy is running/swimming/skiing.
A monkey/squirrel/bunny is eating a banana.
A boy is kissing/hugging/kicking a dog.
A girl is eating an apple/cookie/ice-cream.
A dog is in/on/under a car.
A cat is on a table/bed/chair.
A lady is giving a present/truck/mouse to a girl.
A cat is giving a flower to a boy/bunny/dog.

Table 4: Three word phrases for the aphasic types and their numeric representation.
Aphasic Type
Broca’s Aphasic
Broca’s Aphasic
Wernicke’s Aphasic
Wernicke’s Aphasic
Healthy Control
Healthy Control

Phrases
Banana three eat
Boy is sport
Little small here
Squirrel with banana
The banana eating
A young boy

the sentences. A sliding window of three words that
moves along one word at a time is used to create the
final training/test three word phrases. Hence, if a transcript includes a sentence “The monkey is sitting down
eating a small yellow banana.” the first six words obtained are “the monkey is sitting down eating” and two of
the training/test phrases are “the monkey is” and “monkey is sitting”. Since every word of these phrases is represented by a four digit binary number, the input layer
for the network architecture has twelve units. The binary representations for the word are Determiner (0110),
Noun (1100), Plural (0011), Pronoun (0111), Preposition (1001), Adjective (0101), Conjunction (1011), Verb
(0010), Progressive (1000), Auxiliary Verb (0100), Adverb (0001) and Numeric (1010). Table 4 shows typical
reponses of the aphasic types and the numeric representations that were input for the self-organising networks.

Syntactic Description
NOUN ADJ-N VERB
NOUN AUX NOUN
ADJ ADJ PREP
NOUN PREP NOUN
DET NOUN V-PROG
DET ADJ NOUN

Numeric Represention
1100 1010 0010
1100 0100 1100
0101 0101 1001
1100 1001 1100
0110 1100 1000
0110 0101 1100

training and test samples. Therefore, unsupervised selforganising networks are a suitable alternative to supervised approaches for classifying aphasic types.

B ro c a ’s A p h a s ia
W e rn ic k e ’s A p h a s ia /H e a lth y C o n tro l G ro u p

Results
Figures 2 and 3 show that it is possible to identify clear
regions of the self-organising networks that are associated with the Broca’s aphasic test phrases for both the
test and training data. For Broca’s aphasics there are two
clear regions of the map, which is an indication that two
forms of the condition might exist. For the two maps the
Wernicke’s aphasic/healthy control group are distributed
around the rest of the map. When considering the test
and training sample locations it is clear that the areas
of the map associated with the test Broca’s aphasics are
very similar to the training ones. In many cases the cells
with the highest activiation are exactly the same for the

Figure 2: The regions on the self-organising map for a
network based on 12 input and 100 output layer units
associated with the second training set phrases for the
aphasic types.
It is often the case when neural networks are trained
to learn grammatical structures that two classes of examples are used; grammatically correct and incorrect
phrases. The self-organising network architecture used
in this paper is more general than these networks as it can
identify three grammatical phrase structures, where the

B ro c a ’s A p h a s ia
W e rn ic k e ’s A p h a s ia /H e a lth y C o n tro l G ro u p

Figure 3: The regions on the self-organising map for a
network based on 12 input and 100 output layer units
associated with the second test set phrases for the aphasic
types.
test phrases contain both typical and non-typical grammatical structures. Since phrases for the healthy control
group/Wernicke’s aphasics and Broca’s aphasics are located at different regions on the self-organising maps it
may be possible to develop a model of how the brain represents and processes grammatical structures of different
individual types [Zurif, Swinny, Parther, Solomon, and
Bushell (1993), Hartsuiker and Kolk (1998) and Marshall, Pring and Chiat (1998)].
The results in our experiments indicate that unsupervised networks are a suitable alternative to supervised
approaches for classifying aphasic types. In terms of
cognitive science the results show that while the spoken
output of Broca’s aphasics has a very distinct grammatical structure, healthy individuals and Wernicke’s aphasics are much closer. This supports the view that language production may be based on a modular but interactive approach associated with particular regions of the
brain and that correct grammatical construction is dependent on Broca’s area.
By identifying two clear zones of the output maps associated with Broca’s aphasics these could be associated
with different degrees of injury and performance. If this
is the case the different individuals in the two groups
could provide the basis of a computational model of different levels of Broca’s injury and hence of recovery. A
final issue for consideration is why those classified as
Broca’s aphasic by the self-organising network failed to
recover functionality by either tissue recovery or functional redistribution. A case examination of these individuals might provide information on the factors that are
significant in functional recovery such as age, extent of
injury and the type and level of medical intervention following injury.
The approach in this paper for classifying different
aphasic types using a self-organising network was based
on the difference between the grammatical constructs

produced. This is an important step in our research with
our overall aim being to incorporate other spoken language characteristics such as semantics and vocabulary
level into the classification process by using a set of selforganising nets. The impact of that would be to produce
a benchmark approach to classify many more aphasic
types using a self-organisation approach and so provide
cognitive scientists with a powerful diagnostic tool.
An additional advantage to cognitive scientists from
the extented classifier is the removal of the subjective
manner by which researchers include and exclude aphasics from pooled studies. For example, when considering if Broca’s aphasics can deal with reversable sentences Brendt and Caramazza (1999) state that the percentage that cannot deal with these sentences is much
less than those identified by Grodzinsky, Pin̈ango, Zurif and Drai (1999) from the examination of the same
pooled studies. Brendt and Caramazza (1999) add that
the difference comes from Grodzinsky, Pin̈ango, Zurif
and Drai (1999) willingness to exclude Broca’s aphasics.
It is argued that they are not true Broca’s aphasics. Finally, this system should offer an indication of the underlying organisational properties of language in the brain
and so assist with the development of computational hybrid neural processing models [Wermter and Sun (2000)
and Wermter and Meurer (1997)].

Conclusion
Studying individuals that have aphasia has provided a
great deal of information connected with the nature of
language processing and how the brain is able to recover language functionality following injury. By using self-organising network architectures it is possible
to distinguish between a control group of healthy individuals/Wernicke’s aphasics and Broca’s aphasics using
sentences from the CAP Corpus. One possible reason
for the self-organising network’s ability to separate the
inputs into these two groups is their capacity to learn the
grammatical structure produced by these aphasic types,
which typically for Broca’s aphasics are grammatically
incorrect and for Wernicke’s aphasics/healthy individuals are grammatically correct.

Acknowledgments
This research has been funded in part by EPSRC
GR/M56555/01 awarded to Prof. Wermter.

References
Anderson, B. Kohonen neural networks and language.
Brain and Language, 70:86–94, 1999.
Basso, A., Gardelli, M., Grassi, M. & Mariotti, M. The
role of the right hemisphere in recovery from aphasia:
Two case studies. Cortex, 25:555–566, 1989.
Bates, E., Friederici, A. & Wulfeck, B. Grammatical
morphology in aphasia: Evidence from three languages. Cortex 23:545–574, 1987a.

Bates, E., Friederici, A. & Wulfeck, B. Sentence comprehension in aphasia: A cross-linguistic study. Brain
and Language, 32:19–67, 1987b.
Binder, J., & Frost, J., Hammeke, T., Cox, R., Rao, S.
& Prieto, T. Human brain language areas identified by
functional magnetic resonance images. The Journal of
Neuroscience, 17(1):280–288, 1997.
Brendt, R. & Caramazza, A. How regular is sentence
comprehension in broca’s aphasia? it depends on
how you select the patients. Brain and Language,
64(2):231–256, 1999.
Capp, S., Perani, D., Grassi, F., Bressi, S., Alberoni, M.,
Franceschi, M., Bettinardi, V., Todde, S. & Frazio,
F. A PET Follow-up Study of Recovery after Stroke
in Acute Aphasics. Brain and Language, 56:55–67,
1997.
Chen, S. & Bates, E. The dissociation between nouns
and verbs in Broca’s and Wernicke’s aphasia: Findings
from Chinese. Aphasiology, 12(1):5–36, 1998.
Dodel, S., Hermann, J. & Geisel, T. Stimulusindependent data analysis of fMRI data. In Wermter,
S., Austin, J. & Willshaw, D., editors, EmerNet: International Workshop on Emergent Neural Computational Architectures Based on Neuroscience, pages 7–
10. EmerNet, 1999.
Elman J. Finding structures in time. Cognitive Science,
14:179–211, 1990.
Grodzinsky, Y., Pin̈ango, M., Zurif, E. and Drai, D.
The Critical Role of Group Studies in Neuropsychology: Comprehension Regularities in Broca’s Aphasia,
Brain and Language, 67:134–147, 1999.
Hartsuiker, R. & Kolk, H. Syntactic Facilitation in
agrammatic sentences production. Brain and Language, 62:221–254, 1998.
Hecht-Nielsen, R. Neurocomputing. Addison-Wesley,
Reading MA, 1990.
Karbe, H., Thiel, A., Weber-Luxenburger, G., Herholz,
K. & Heiss, W. Brain plasticity in poststroke aphasia: What is the contribution of the right hemisphere?
Brain and Language, 64:215–230, 1998.
Kohonen, T. Self-Organizing Maps. Springer Verlag,
Heidelberg, 1997.
Marshall, J., Pring, T. & Chait, S. Verb Retrieval and
Sentence Production in Aphasia. Brain and Language,
63(2):159–183, 1998.
Mimura, M., Kato, M., Kato, M., Santo, Y., Kojima, T.
and Naeser, M. and Kashima, T. Prospective and Retrospective Studies of Recovery in Aphasia: Changes
in Cerebral Blood Flow and Language Functions.
Brain, 121: 2083–2094, 1998.
Papke, K., Hellmann, T., Renger, B., Morgenroth, C.,
Knecht, S., Schuierer, G. & Reimer, P. Clinical applications of functional MRI at 1.0 t: motor and language
studies in healthy subjects and patients. European Radiology, 9(2):211–220, 1999.

Raichle, M., Fiez, J., Videen, T., MacLeod, A., Pardo, J.,
Fox, P. & Petersen, S. Practice-related changes in human brain functional-anatomy during nonmotor learning. Cerebral Cortex, 4(1):34–54, 1994.
Reggia, J., Shkuro, Y. & Shevtsova, N. Emergent Specialization in Cerebral Regional Modules. In Wermter,
S., Austin, J. & Willshaw, D., editors, Proceedings of
the Third International Workshop on Computational
Architectures Intergrating Neural Networks and Neuroscience, pages 11–14. EmerNet, 2000.
Reilly, R. Collaborative cell assemblies: Building blocks
of cortical computation. In Wermter, S., Austin, J. &
Willshaw, D., editors, In Emergent Neural Computational Architectures based on Neuroscience, SpringerVerlag, Heidelberg, Germany, 2001.
Shaywitz, B., Shaywitz, S., Pugh, K., Constable, R.,
Skudlarski, P., Fulbright, R., Bronen, R., Fletcher, J.,
Shankweiler, D., Katz, L. & Gore, J. Sex differences in
the functional organisation of the brain for language.
Nature, 373(6515):607–609, 1995.
Spitzer, M. The Mind Within the Net: Models of Learning, Thinking and Acting. MIT Press, Cambridge,
MA, 1999.
Taylor, J. Images of the mind: brain images and neural
networks. In Wermter, S., Austin, J. & Willshaw, D.,
editors, Proceedings of the International Workshop on
Emergent Neural Computational Architectures based
Neuroscience, pages 1–6. EmerNet, 1999.
Weiller, C., Isensee, C., Rijnties, M., Huber, W., Müller
S., Bier, D., Dutschka, K., Woods, P., Noth, J. &
Diener, C. Recovery from Wernicke’s aphasia: A
positron emissions tomographic study. American Neurological Association, 37(6):723–732, 1995.
Wermter, S., Panchev, C. & Houlsby, J. Language disorders in the brain: Distinguishing aphasia forms with
recurrent networks. In AAAI99 Conference Workshop
on Neuroscience and Neural Computation, pages 93–
98, 1999.
Wermter S. & Meurer M. Building Lexical Representations Dynamically Using Artificial Neural Networks.
Proceedings of the International Conference of the
Cognitive Science Society, pages 802–807, Stanford,
1997.
Wermter, S. and Sun, R. Hybrid Neural Systems
Springer-Verlag, Heidelberg, 2000.
Xiong, J., Rao, S., Gao, J., Woldorff, M. & Fox, P. Evaluation of hemispheric dominance for language using
functional MRI: A comparison with positron emission tomography. Human Brain Mapping, 6:367–389,
1998.
Zurif, E., Swinney, D., Prather, P., Solomon, J. &
Bushell, C. An on-line analysis of syntatic processing
in Broca’s and Wernicke’s aphasia. Brain and Language, 45:448-464, 1993.

