UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Context-Dependent Nature of Action Knowledge

Permalink
https://escholarship.org/uc/item/5gx3q5tj

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Shipp, Nicholas
Vallee-Tourangeau, Frederic
Anthony, Susan

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Context-Dependent Nature of Action Knowledge
Nicholas J. Shipp (n.j.shipp@herts.ac.uk)
Department of Psychology, University of Hertfordshire
Hatfield, AL10 9AB, UNITED KINGDOM

Frédéric Vallée-Tourangeau (f.vallee-tourangeau@kingston.ac.uk)
Department of Psychology, Kingston University,
Kingston upon Thames, KT1 2EE, UNITED KINGDOM

Susan H. Anthony (s.h.1.anthony@herts.ac.uk)
Department of Psychology, University of Hertfordshire
Hatfield, AL10 9AB, UNITED KINGDOM
Abstract
Recent theories of semantic memory have proposed that
concepts are grounded in sensorimotor activity and
mediated by the context from which the knowledge is
drawn (Barsalou, 1999, 2003, 2008). Conceptual
knowledge draws upon information from all modalities and
therefore includes knowledge of associated object actions
linked with both function and general movement (Bub,
Masson, & Cree, 2008). The following experiment
examined the conditions under which action information
exerts an influence on experimental tasks particularly when
taxonomic information is present. The experiment used a
forced-choice triad task giving participants the choice of
selecting between items that shared either a taxonomic or
an action based relation with the target. The results showed
that when the objects were presented as images on a white
background (context-lean condition), participants were
more likely to select the taxonomically related item. In
contrast, when the same triads were presented as images
being used in a functional scene (context-rich condition)
they were more likely to select the action-related item. The
results show that action knowledge is not automatic but is
context-dependent. In line with views on embodied
semantics, action-related information is drawn upon when
objects are viewed and this influences task performance
despite being unnecessary for the task.
Keywords: Action; Triads; Categorisation; Context.

Introduction
The traditional view of conceptual knowledge suggested
that concepts are formed from amodal abstractions of the
context in which they were previously encountered
(Barsalou, 1999, 2003; Yeh & Barsalou, 2006). However
an increasing number of researchers have shown that
concepts are embodied within sensorimotor activity
(Barsalou, 1999, 2008; Wu & Barsalou, 2009; Yeh &
Barsalou, 2006). Embodied semantics takes the view that
concepts are much more than decontextualised feature
lists and that they reside within the same sensory-motor
circuits in which they were first established (Aziz-Zedah
& Damasio, 2008; Fernandino & Iacoboni, 2010).
According to Barsalou (1999, 2003, 2008) the conceptual
system does not record the images seen of an entity, but
registers the concomitant neural experience. When
encountering or re-instantiating the concept at a later date
the conceptual system partially reactivates those neuronal
patterns, thereby producing a simulation of the

experience. Areas of the motor cortex that are active upon
the initial object encounter will be reactivated and as such
common actions associated with objects should readily
come to mind when thinking of an object. Empirical work
over the last decade has supported this view showing that
semantic knowledge is embedded within physical actions
which influences performance across a variety of
cognitive tasks (Anelli, Nicoletti, & Borghi, 2010; Borghi,
2004; Borghi, Flumini, Natraj, & Wheaten, 2012; Bub &
Masson, 2006; Bub, Masson, & Bukach, 2003; Chao &
Martin, 2000; Creem & Proffitt, 2001; Iachini, Borghi, &
Senese, 2008; Tipper, Paul, & Hayes, 2006; Tucker &
Ellis, 1998, 2004; Vanio, Symes, Ellis, Tucker, &
Ottoboni, 2008).
What has been particularly evident from the research is
that action can play a role even in tasks where knowledge
of associated action is neither required nor asked for.
Borghi (2004) used a property generation task to show
that when participants are asked to simply think about an
object such as a car the first parts of the car that they name
are those related to direct human interaction (e.g., the
gearstick, steering wheel). The same parts were named
first when participants were given a direct context to think
about such as building the object. This would be in line
with the view that thinking about the car activated the
motor cortex and as such direct interaction became an
influential feature in this task. Helbig, Graf and Keifer
(2006) showed how actions are drawn upon in object
recognition using a priming task. In their experiment
participants were asked to name both a prime and a target
object and showed that participants were more accurate in
naming the target object when the prime was congruent in
its action manipulation. Here the prime had a clear effect
of activating the motor system and its relevant action
knowledge that remained active for the target and hence
identification was quicker. Helbig, Steinwender, Graf and
Keifer (2010) used video primes of an agent performing
an action on an object that was blacked out. Following the
prime participants then saw an image of an object
followed by a word, they were asked to identify if the
word matched the object. Participants were again more
accurate in their responses when the action seen in the
prime matched the action of the following object. Further
priming studies have shown similar action-based effects
(Bub & Masson, 2012; Vanio et al., 2008).

2925

Research has also shown that when participants are
asked to make an action-based response they are typically
faster and more accurate when action-based knowledge is
taken into account. Jax and Buxbaum (2010) presented
participants with objects that they termed as being either
conflict or non-conflict. Non-conflict objects, they
suggest, are objects that require the same action to both
use and transport them (e.g., drinking glass). In contrast
when the action of use is different from the action of
transport (e.g., as for a calculator) the object is referred to
as a conflict object. When participants were asked to place
their hand on the objects as though they would use them
they were faster for the non-conflict items over the
conflict items. In addition they also found that generally
participants were faster at making hand placements to
pass the objects to another person rather than to use them.
Osiurak, Roche, Ramone and Chainay (2013) showed the
reverse effect when participants were physically asked to
either pick up the objects in order to hit a ping pong ball
or pass it to the experimenter. Here participants were
faster at making use actions over transport. The authors
attribute this to additional information being activated
such as weight and solidity, which would not be activated
if participants are simply asked to place their hand on the
objects.
Yee, Chrysikou, Hoffman and Thompson-Schill (2013)
found that performing concurrent actions along with a
semantic decision task slowed down task performance.
Their participants undertook a semantic decision task
judging if spoken words were abstract or concrete while
concurrently performing a three-step manual ‘patty-cake’
task. This involved participants placing two fingers, four
fingers or the whole hand on its side onto a table top in a
repeating manner while engaging in the semantic decision
task. Yee et al. found a significant interference effect of
performing such manual actions with slower decisions
made when compared to participants who performed no
concurrent task. The patty-cake task was found to have an
increased interference effect on those objects that
participants had greater levels of previous handling
experience. No interference was found when participants
performed a mental rotation task.

The Influence of Context
Research has shown that the context in which information
is presented influences what type of conceptual
knowledge becomes activated. Barsalou (1982) showed
that while certain types of information are contextually
independent and activated irrespective of the context other
types of information can be contextually dependent and
activated under certain circumstances. Barsalou showed
that, in a property verification task, participants were
quicker to verify that a basketball can float when given a
context requiring someone to use one as a floatation
device compared to verifying whether a basketball can
bounce. Therefore such information would be
contextually dependent as it does not always come
straight to mind for this task but varies according to
context. In contrast participants showed no difference in
verifying sentences regarding how skunks have an
unpleasant smell across different conditions. This would
be regarded as contextually independent being drawn

upon across different contexts. In supporting such
findings Borghi et al. (2012) showed that activation of
object affordances was contextually dependent.
Participants were shown object pairs that were related
either functionally (paper + scissors), spatially (stapler +
scissors) or had no relation (bottle + scissors). In addition
to this the pairs were also shown with either a hand with a
functional grasp on one of the objects, a manipulative
grasp, a hand present but not holding either item or with
no hand present. The participants were quicker and more
accurate at making decisions on the objects being related
or unrelated when object pairs shared a functional context.
Participants were also faster when pairs were presented
with a functional hand grasp rather than a manipulative
grasp, however overall responses were faster when the
images were presented with no hand. Items that share the
same function also share a related goal. As such it is
possible that participants drew upon the related goal of the
items that in turn decreased the reaction time between
them. Since manipulative pairs share only a spatial
context and no related goal they were slower than the
functional pairs.

The Present Experiment
The first aim of the current experiment was to explore the
role that action plays in category formation when it is
presented in conjunction with category membership. It
should be noted that for the purposes of this experiment
action is defined as the direct interface between objects
and the human body. For example the action of a rifle
would be the grasp made by the hand around the handle,
rather than action in terms of the act that can be carried
out using a rifle. Many items that are action related also
share category membership. For example an orange and a
banana both require a peeling action and also belong to
the same category of fruit. In addition, many items can
share an action without sharing category membership such
as a rifle and a water pistol which both require a grasp of
the handle in the same fashion but are not both weapons.
Therefore a task was designed in which category
membership could be directly pitted against the action of
interfacing with an object when using it in its functional
capacity. Using this method it could be tested if
participants would always choose category membership or
if action knowledge would be drawn upon in line with
recent views on embodied semantics. The experiment
used a forced-choice triad task. This basic task has been
used to demonstrate the influence of situational (thematic)
information (Lin & Murphy, 2001; Murphy, 2001) when
previously only taxonomic (shared property) information
would have been predicted to guide choices. In Lin and
Murphy’s (2001) studies, the choice items were selected
to share either a taxonomic or a thematic relation to the
target. For example the target bee was presented with
wasp (taxonomic similarity) or honey (thematic
similarity). In a similar manner to Lin and Murphy,
participants in the present experiment were presented with
a target and two choice options, only one of which shared
an action with the target. Based on the previous research
showing the strong role of action knowledge in a range of
tasks based on category knowledge, we predicted that
participants would be more likely to select the action-

2926

Figure 1: Examples of stimuli employed in the experiment. From left to right: Same Category Object triad, Different
Category Object triad, and Perceptual Category Object triad in the context-lean condition (top panels) and in the contextrich condition (bottom panels).
related item over the taxonomic choice only when it too
shared a taxonomic relation to the target. When the
action-related item bore no taxonomic relation to target,
we predicted that participants would be more likely to
select the taxonomic choice.
The second aim of the experiment was to investigate the
nature of action information and whether its activation is
contingent on the context of categorisation. The triads
shown were manipulated between subjects based on
context. Participants either saw the objects on a white
background (context-lean condition) or shown within an
action based scenario with the objects being used by an
agent (context-rich condition). It was predicted that in line
with Borghi et al. (2012) the action choice within the
triads would be selected more often when the images are
shown within a functional context.

Method
Participants
Fifty undergraduate students (36 females) from the
University of Hertfordshire participated in return for
course credit with a mean age of 25.3 years (SD = 7.9,
Range = 18-49).

Materials
The triads were based on the standard design of a target
item followed by two items from which a choice could be
made. Since the aim of the research was to compare the
effect of action knowledge both alongside and set against
taxonomic information, two sets of triads were initially
designed, namely same-category object (SCO) triads and
different-category object (DCO) triads (see Fig. 1). In the
SCO triads participants saw a target (e.g., orange) and
two choice items (e.g., banana and strawberry) which all
belonged to the same category (fruit) as confirmed by
pilot work. Of these choice items both share category

membership with the target and in addition banana also
shares a motor action with orange. In the DCO triads, one
choice item shared category membership with the target
but not an action (rifle and sword). The remaining choice
item shared a motor action with the target but not category
membership (rifle and water pistol).
In order to test the effect of context two sets of images
were collected. The first set showed the objects against a
white background (context-lean condition). The second
set projected the objects being used in a functional context
(context-rich condition, see Fig. 1). Twenty participants
not used in the experiment took part in pilot work to
ensure that the SCO and DCO triads were matched in
terms of category membership and the action used to
functionally interact with them. Fifteen of each triad set
were initially designed and piloted. Using a Chronbach’s
alpha level of .7 as a threshold criterion, the final sets of
SCO and DCO items were composed of 10 triads of each
type.
A third set of triads (PCO) was designed based on the
results of experimental pilot work. It seemed possible that
participants might select the choice item sharing an action
not because they shared an action, but because they shared
perceptual properties. For example pencils and
paintbrushes share perceptual properties, in part as a
function of the ergonomic constraints that guide their
design. Using the triads described above it is not possible
to ascertain whether such items are selected because of
action or because they look the same. In the PCO triads
neither of the choice items shared category membership
with the target item. One of the choice items shared an
action with the target but few perceptual features (nut and
car key). The remaining choice item shared perceptual
features with the target but not an action (nut and money).
The PCO triads were again presented in the same contextlean/context-rich manner as the SCO and DCO triads (see
Fig. 1). Twenty participants not used in the experiment
took part in pilot work to ensure that the PCO triads were

2927

Procedure
The experiment employed a 3x2 mixed design where triad
type was a repeated measure factor and context was a
between subjects factor. The main dependent measure was
the percentage of action choices calculated for each set of
triad type in both context conditions. Stimuli and task
instructions were presented on a 15” Macintosh laptop.
Participants were instructed to “Please indicate which of
the two items goes best with the item at the top of the
screen”, as they were in Lin and Murphy (2001). A
fixation cue was presented on the screen for 1000ms after
which the cue disappeared and the target word appeared
along with the appropriate picture depending on which
condition the participant was assigned to. After 1500ms
the two choice options appeared beneath the target
alongside the appropriate images. The triad remained on
the screen while participants made their choice.
Participants were instructed to press the ‘a’ key to choose
the item on the left-hand side of the screen and the ‘l’ key
for the item on the right-hand side of the screen. The
choice items were counterbalanced across the triads so
that in half the triads the action choice appeared on the left
hand side while in the remaining half the action choice
appeared on the right. After they had made their choice
the triad disappeared and the fixation cue appeared again
for the next triad.

Results
The mean percentage of action choices for each of the
three triad types in both the context-lean and context-rich
conditions are illustrated in Figure 2. As can be seen, the
SCO triads produced the highest percentage of actionrelated responses in both the context-lean (61%, SD =
15%) and the context-rich condition (70%, SD = 15%).
The action choice was selected least often with the DCO
triads, though the mean was greater in the context-rich
condition (53%, SD = 21%) than in the context-lean
condition (32%, SD = 13%). In the PCO triads
participants chose the action item less often than the
perceptual item in the context-lean condition (48%, SD =
20%) but more often in the context-rich condition (69%,
SD = 14%). For all three triad types participants selected
the action choice more frequently when contextualised. A
3x2 mixed analysis of variance revealed that the main
effect of context was significant, F (1, 48) = 39.22, p <
.001, ƞ2 = .45. Participants were more likely to select the
action item in the context-rich condition when pictures of
the objects were shown in a functional context. The main
effect of triad type was also significant, F (2, 96) = 22.77,
p < .001, ƞ2 = .32. Post hoc analyses using the Bonferroni
adjustment showed that participants selected more action
choices overall on the SCO triads than in both the DCO
triads (p < .001) and the PCO triads (p = .031).

Participants also selected more action choices in the PCO
triads than in the DCO triads (p = .001). The interaction
between triad type and context was not significant, F (2,
96) = 2.33, p = .10, ƞ2 = .05.
	  
	  
Context Lean
Context Rich
80%

Percentage of Action Choice

matched in terms of perceptually relevant features and the
action used to functionally interact with them. Fifteen
PCO triads were initially designed and piloted. Using a
Chronbach’s alpha level of .7 as a threshold, a final set of
10 PCO triads were selected. Thus the experimental
material was composed of 30 triads consisting of 10 SCO,
DCO and PCO triads.

	  
	  

	  

70%
60%
50%
40%

	  

30%

	  
	  

20%
10%
0%
SCO

DCO

PCO

Triad Type

	  
Figure	  2.	  Mean percentage of action choices with Same
Category Object (SCO), Different Category Object
(DCO), and Perceptual Category Object (PCO) triads in
the context-lean condition (light grey bars) and in the
context-rich condition (dark grey bars). Error bars are
standard errors of the mean.	  

Discussion
The experiment reported here sought to investigate the
role of action in shaping categorical decisions. The first
aim was to measure how action knowledge was used in
the forced-choice triad task when pitted both against and
alongside taxonomic information. The results from the
different-category object (DCO) triads showed that when
action knowledge was pitted against taxonomic
information participants primarily grouped items together
based on taxonomic information. For example participants
were more likely to put rifle with sword rather than water
pistol. The finding that shared action alone could not
overcome taxonomic constraints is perhaps not surprising
given the central role that functional knowledge plays in
category membership. Participants were most likely to
select the action choice when it was combined with
taxonomic information, as with the same-category objects
(SCO), showing that knowledge of action is perhaps
insufficient on its own to act as a basis for category
membership. Therefore while shared action may not be
considered a sufficient basis in which to form categories
as gauged by this task, it does appear to have an additive
effect increasing the shared relations between two items.
The perceptual-category object (PCO) triads were
designed specifically to determine whether participants
were selecting the items based on shared action or shared
perceptual properties. If participants were drawing upon
action knowledge then in such pairs where the choice
comes down to a shared action or perceptual choice they
should pick the action. In contrast if perceptual
information is driving choices then participants should
pick the item that looks more similar. The results showed
that action knowledge was more likely to be used on the
PCO triads over perceptual similarity when shared
category membership was removed. Therefore, we can

2928

infer that participants were drawing upon knowledge of
how they interacted with the objects rather than how they
looked. As revealed with the SCO triads, participants
were most likely to group items together when they shared
both category membership and a functional action. The
use of the perceptual-category object triads showed that
this was not due to shared perceptual features between
items that share an action. However, when participants
were asked to choose between either a shared action or
category membership in the DCO condition, participants
were most likely to choose the latter until such items were
shown in a functional context.
The second aim of the experiment was to see if action
knowledge is drawn upon in all situations or whether its
use in such tasks is context-dependent. The results showed
that when participants saw the items in the context-rich
condition they were more likely to select the action related
item. It is possible that when participants viewed the
images in the context-lean condition, action-related
knowledge was simply not sufficiently salient to greatly
influence choices over and above the other commonalities
between items. In contrast, the context-rich condition
clearly showcased the objects being used in their standard
capacity and as such the shared actions presented
themselves more clearly as ‘features’ that could influence
the choice. The relevance of action knowledge in driving
categorisation intuitions is thus contingent on the context
of presentation. This suggests that viewing items without
a context is not necessarily enough to instantiate action
knowledge and this is in line with previous research
(Borghi, Bonfiglioi, Lugli, Ricciardelli, Rubichi, &
Nicoletti, 2007; Borghi et al., 2012). In the same way that
object properties have been shown to be contextdependent (Barsalou, 1982), the actions associated with
objects also seem to become most salient and influential
in this passive task in the presence of context.
In order to fully extend this research a new set of triads
would need to be designed in which the items share an
action along with taxonomic information, but do not share
perceptual properties. While this would be the ideal
condition there might be insurmountable constraints on
designing the material required to run this experiment: In
aiming to optimise the functionality of the human-artefact
interface, objects that share an action will invariably share
perceptual properties. For example pencils and
paintbrushes look similar as they are designed to be used
with a pinch grip and rest within the thenar space of the
thumb and index fingers. Items sharing category
membership further confines this problem as items
become more similar to each other based on the
ergonomics of design. Therefore it might prove
impossible to find items that require the same method of
interaction/operating but that did not share the perceptual
properties linked with that action.
In conclusion the data reported here indicate that actionrelated information is influential when participants are
engaging in categorisation tasks that do not require any
action to be made. This effect is made even more evident
when the presentation of the objects is embedded in an
action-relevant context. It has further been shown that
while perceptual information plays a strong role in
categorisation there are circumstances when action

knowledge is chosen over perceptual information. The
results of the experiment have established conditions
under which action knowledge informs categorisation
intuitions in a passive cognitive task.

Acknowledgments
We are grateful to Lia Kvavilashvili for her advice
throughout the preparation of this work and comments on
earlier drafts.

References
Anelli, F., Nicoletti, R., & Borghi, A. M. (2010).
Categorization and action: What about object
consistence? Acta Psychologica, 133, 203-211
Aziz-Zadeh, L., & Damasio, A. (2008). Embodied
semantics for actions: Findings from functional brain
imaging. Journal of Physiology – Paris, 102, 35-39.
Barsalou, L. W. (1982). Context-independent and contextdependent information in concepts. Memory &
Cognition, 10, 82-93.
Barsalou, L. W. (1999). Perceptual symbol systems.
Behavioral and Brain Sciences, 22, 577-660.
Barsalou, L. W. (2003). Situated simulation in the human
conceptual system. Language and Cognitive Processes,
18, 513-562.
Barsalou, L. W. (2008). Grounded cognition. Annual
Review of Psychology , 59, 617-645.
Borghi, A. M. (2004). Object concepts and action:
Extracting affordances from objects parts. Acta
Psychologica, 115, 69-96.
Borghi, A. M., Bonfiglioli, C., Lugli, L., Ricciardelli, P.,
Rubichi, S., & Nicoletti, R. (2007). Are visual stimuli
sufficient to evoke motor information? Studies with
hand primes. Neuroscience Letters, 411, 17-21.
Borghi, A. M., Flumini, A., Natraj, N., & Wheaton, L. A.
(2012). One hand, two objects: Emergence of
affordance in contexts. Brain and Cognition, 80, 64-73.
Bub, D. N., & Masson, M. E. J. (2006). Gestural
knowledge evoked by objects as part of conceptual
representations. Aphasiology, 20, 1112-1124.
Bub, D. N., & Masson, M. E. J. (2012). On the dynamics
of action representations evoked by names of
manipulable objects. Journal of Experimental
Psychology: General, 141, 502-517.
Bub, D. N., Masson, M. E. J., & Bukach, C. M. (2003).
Gesturing and naming: The use of functional
knowledge in object identification. Psychological
Science, 14, 467-472.
Bub, D. N., Masson, M. E. J., & Cree, G. S. (2008).
Evocation of functional and volumetric gestural
knowledge by objects and words. Cognition, 106, 2758.
Chao, L. L., & Martin, A. (2000). Representation of
manipulable man-made objects in the dorsal stream.
Neuroimage, 12, 478-484.
Creem, S. H., & Proffitt, D. R. (2001). Grasping objects
by their handles: A necessary interaction between
cognition and action. Journal of Experimental
Psychology-Human Perception and Performance, 27,
218-228.
Fernandino, L., & Iacoboni, M. (2010). Are cortical

2929

motor maps based on body parts or coordinated actions?
Implications for embodied semantics. Brain &
Language, 112, 44-53.
Helbig, H. B., Graf, M., & Keifer, M. (2006). The role of
action representations in visual object recognition.
Experimental Brain Research, 174, 221-228.
Helbig, H. B., Steinwender, J., Graf, M., & Keifer, M.
(2010). Action observation can prime visual object
recognition. Experimental Brain Research, 200, 251258.
Iachini, T., Borghi, A. M., & Senese, V. P. (2008).
Categorization and sensorimotor interaction with
objects. Brain and Cognition, 67, 31-43.
Jax, S. A., & Buxbaum, L. J. (2010). Response
interference between functional and structural actions
linked to the same familiar object. Cognition, 115, 350355.
Lin, E. L., & Murphy, G. L. (2001). Thematic relations in
adults' concepts. Journal of Experimental PsychologyGeneral, 130, 3-28.
Murphy, G. L. (2001). Causes of taxonomic sorting by
adults: A test of the thematic-to-taxonomic shift.
Psychonomic Bulletin & Review, 8, 834-839.
Osiurak, F., Roche, K., Ramone, J., & Chainay, H.
(2013). Handing a tool to someone can take more time
than using it. Cognition, 128, 76-81.
Tipper, S. P., Paul, M. A., & Hayes, A. E. (2006). Visionfor-action: The effects of object property discrimination
and action state on affordance compatibility effects.
Psychonomic Bulletin & Review, 13, 493-498.
Tucker, M., & Ellis, R. (1998). On the relations between
seen objects and components of potential actions.
Journal of Experimental Psychology: Human
Perception and Performance, 24, 830-846.
Tucker, M., & Ellis, R. (2004). Action priming by briefly
presented objects. Acta Psychologica, 116, 185-203.
Vainio, L., Symes, E., Ellis, R., Tucker, M., & Ottoboni,
G. (2008). On the relations between action planning,
object identification, and motor representations of
observed actions and objects. Cognition, 108, 444-465.
Wu, L. & Barsalou, L. W. (2009). Perceptual simulation
in conceptual combination: Evidence from property
generation. Acta Psychologia, 132, 173-189.
Yee, E., Chrysikou, E. G., Hoffman, E., & ThompsonSchill, S. L. (2013). Manual experience shapes object
representations. Psychological Science, 24, 909-919.
Yeh, W., & Barsalou, L. W. (2006). The situated nature of
concepts. American Journal of Psychology, 119, 349384.

2930

