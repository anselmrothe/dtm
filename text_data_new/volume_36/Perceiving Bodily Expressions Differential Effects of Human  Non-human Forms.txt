UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Perceiving Bodily Expressions: Differential Effects of Human &amp; Non-human Forms

Permalink
https://escholarship.org/uc/item/3kg9p3xt

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Pierce, Devin
Kadiyala, Mani
Ives, Christian

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Perceiving Bodily Expressions:
Differential Effects of Human & Non-human Forms

!

Devin Pierce (Devin.Pierce@tamuc.edu)
Mani Kadiyala (mkadiyala@leomail.tamuc.edu)
Christian Ives (cives@leomail.tamuc.edu)

Department of Psychology, Counseling, and Special Education, Texas A&M University-Commerce
Commerce, TX 75428 USA

!

Abstract
Theories in embodied cognitive science emphasize the
importance of self-other mapping during emotion perception.
This implies the body form through which an emotion is
expressed may impact how the emotion is perceived.
Research in human computer interaction has demonstrated
that people can reliably label emotions of virtual characters;
however, it has hardly examined how people perceive the
emotions of virtual characters at a visceral level. Here, we
asked participants to identify under time pressure for action,
whether an observed bodily movement is angry or happy. Our
research provides evidence that emotions conveyed by nonhuman virtual characters and humans are indeed perceived
differentially, at the visceral level. This work carries
implications for theories of embodied cognition and the
design of virtual environments.
Keywords: body; mapping; emotion; virtual character

Introduction
Often times, it is imperative to quickly identify emotional
body movements undertaken by other humans, so that
adaptive action plans can be executed swiftly by the
perceiver. For example, observing someone stomp their feet
and wave their arms frenziedly may lead perceivers to both
identify the behavior as threatening and retreat from the
aggressor. Inherent in identifying threatening behaviors is
that there is time pressure for action, given that if such
behaviors are not identified injury may result if appropriate
actions are not executed quickly. Non-verbal emotional
expressions conveyed by humans are thus fundamental to
social interactions (Ekman 1992); serve as a valuable signal
for guiding one’s behavior (Darwin 1872/1965); and are an
integral part of the phylogentic development of the human
species (de Gelder 2006). Technological advancements have
now made it possible to create non-human virtual characters
that precisely replicate human body movements conveying
emotions (e.g., McDonnell et al, 2009).
How might emotion perception be impacted when
observing expressive body movements displayed by
different body forms, such as a non-human virtual body as
opposed to a human body? Reeves and Nass (1996), in their
media equation theory, maintain that human brains have not
evolved to deal with modern technology and that perceivers
will consequently treat media representation of people as
real. However, they draw this conclusion based on studies
using stimuli that did not differ from humans in terms of
body form (e.g., pictures of humans). It is thus unclear as to
whether media representations that have body forms
different from the human body could trigger differences in

emotion perception. Studies in embodied cognition point to
the possibility that such dissimilarities may indeed surface.
Embodied approaches to body perception stress the
mappings that occur between the bodies of perceivers and
those being perceived (e.g., Wilson 2001). Reed (2002)
maintains that specialized long-term body representations
referred to as body schemas are central to self-other
mapping. These schemas contain information common to
the human body, such as its physical appearance and
biomechanics, thereby allowing them to be used for
representing the form and dynamics of one’s own body as
well as the bodies of other humans (Reed et al. 2005). This
suggests that observing actions carried out by different body
forms could impact self-other mapping and how movements
are perceived. Perani et al (2001) recorded brain activity as
participants watched movements performed by a human
body or a virtual body modeled after it. Results showed that
the human body selectively activated the right inferior
parietal cortex and the superior temporal sulcus. Whereas
the former brain region may involve relating with others as
members of the human species (Decety & Chaminade
2003), the later involves perceiving movements as
biological (Allison et al. 2000). This suggests that even
though the virtual hand exhibited biological motion,
perceivers did not relate with the virtual body as a
conspecific and it was perceived as non-biological.
There is reason to believe that self-other mapping may
also be important for emotion perception. Theories of
embodied simulation maintain that the perceived actions and
emotions of others are mapped by the same neural circuits
that are involved when observers act or feel the same
(Gallese 2010). Evidence for these shared neural circuits in
humans has been demonstrated in the domain of actions
(Grezes & Decety 2001), as well as emotions (Wicker et al.
2003). Embodied simulation allows the actions and
emotions of others to be directly understood because they
are grounded in the perceivers’ own motor and emotional
circuits (Gallese 2009). Because affective states are internal
and thus invisible, some have raised the possibility that
mapping others’ emotions may rely in part on mapping their
behavior (Bastiaansen et al. 2009). The idea is that people
have a history of performing actions (e.g., waving arms
frenziedly) while experiencing emotions (e.g., anger) that
lead to associations between specific states of motor and
emotion circuits. Accordingly, when an observed action is
mapped onto one’s own motor circuits involved with
executing the same action, neural activity will cascade to its
associated emotional circuits and provide insight concerning
the observed person’s emotional state. Neuroimaging

2127

research has shown that when observing the same biological
movements performed by a human body or animated body,
the animated body triggers less activity in cortices
associated with mental state attribution and emotional
processing (Mar et al. 2007).
McDonnell et al. (2009) recently conducted a behavioral
study to examine whether identical biological motions
indicative of the six basic emotions (e.g., happy, angry)
would be perceived differently depending on whether they
were exhibited by human or virtual bodies. Participants first
viewed and described the appearance of a static body image,
followed by watching it perform an emotional movement as
many times as desired. The data revealed no significant
difference in recognizing emotions expressed by the human
and virtual bodies. McDonnell et al. argued that when
virtual characters are rendered with biological motion it is
not the body form but the motion that governs emotion
perception. However, as reviewed above, work in
neuroscience suggests that cortical areas associated with
perceiving motions as biological, as well as, attributing
emotional states, are less involved when observing virtual
characters.
There is one issue concerning the methodology of
McDonnell et al. that could have contributed to their results.
In particular, participants were allowed a great deal of time
to analyze the body forms and movements before
responding, which could have helped them identify
emotions better via overcoming perceptual differences
between the real body and virtual bodies. This possibility is
consistent with research showing that self-other mappings
and body perception can be greatly facilitated by simply
increasing processing time (Reed & McGoldrick 2007). In
light of this issue, we asked participants to identify emotions
under time-pressure, to examine whether different body
forms could impact emotion perception.
To examine whether identification of emotional body
movements under time-pressure is impacted by different
body forms carrying out the behaviors, an examination of
false alarms for threatening and non-threatening movements
performed by human bodies and non-human virtual bodies
could yield insights. To begin with, consider angry human
body movements, which perceivers can observe and
determine if a direct physical attack is potentially being
carried out (Pichon et al. 2009). As discussed in the previous
section, perceivers engage in self-other mapping to gain
insight into the emotional states of other humans. The
observation of a human body performing angry movements
may thus promote self-other mappings that contribute to
perceiving the emotion as emanating from a body that
experiences genuine emotional states and that is capable of
inflicting physical harm. In contrast, the observation of a
non-human virtual body performing angry movements may
promote self-other mappings that contribute to perceiving
the emotion as emanating from a body that does not
experience real emotional states and that is incapable of
inflicting physical harm.
It is reasonable to think that a body-specific threat bias
might emerge for perceiving human emotional body
movements as threatening, in order to reduce one's chance
of being harmed as a result of failing to detect a potential

threat. Arguments in evolutionary psychology maintain that
humans are biased towards attending to threat (Ohman et al.
2001). Additionally, research in mammals has indicated that
false alarms for threat are very common, representing a
significant proportion of all alarms (Beauchamp & Ruxton
2007). Therefore, when observing a human body, there may
be an increased rate of false alarms misidentifying nonthreatening movements as angry and relatively few false
alarms misidentifying angry movements as non-threatening;
however, when observing a non-human virtual body, there
may be comparable false alarm rates to angry and nonthreatening behaviors.
If it is found that perceivers exhibit a threat bias when
observing emotional body movements performed by a
human body but not a non-human virtual body, an auxiliary
question arises as to whether there might also be a bias
towards activating motor contingences geared towards
evading threat conveyed by the angry movements of a
human body but not a non-human virtual body. According to
evolutionary perspectives, humans have developed adaptive
action plans that are triggered by environmental stimuli and
occur without conscious awareness. Bradley and Lang
(2000) argue that avoidance-related behaviors are made in
response to displeasing stimuli and approach-related
behaviors are made in response to pleasing stimuli.
Measuring arm movements is an established method for
investigating how affective stimuli can trigger motor
contingencies in perceivers (Solarz, 1960). Most often,
participants will observe a negative or positive stimulus for
which they are to evaluate its valence by making a response
that involves either extending the arm (e.g., pushing lever
away from self) or flexing the arm (e.g., pulling lever
towards self). An interaction between stimulus valence and
arm movement is taken as evidence for avoidance and
approach-related behaviors. For example, it has been shown
that people respond faster to negative stimuli when flexing
the arm than extending it, but that they respond faster to
positive stimuli when extending the arm rather than flexing
it (Lavender & Hammel, 2007).
The current work’s auxiliary question asks whether an
interaction between arm movement and perceived emotion
will emerge when observing a human body but not a nonhuman virtual body, for which the respective interaction will
be driven by a greater divergence between how fast
participants push and pull, when responding to an angry
human (threatening) as opposed to a happy human (nonthreatening) human. Work in neuroscience has demonstrated
that viewing angry human body movements activate brain
regions related to defensive movements (Pichon et al. 2007),
but that viewing happy human body movements evoke
significantly less activity in regions associated with adaptive
movements (de Gelder et al. 2004). This indicates the
possibility that whereas an avoidance motor contingency
will be triggered by an angry human body movement, there
will be no approach motor contingency triggered by a happy
human body movement.
We examined whether having a human body might
impact perceiving emotional body movements expressed
through different body forms. To accomplish this, we had
participants categorize emotional body movements under

2128

time-pressure for action, as being angry or happy, for which
the respective movements were performed by either a real
human body (Experiment 1) or non-human virtual bodies
(Experiments 2a & 2b)1. As a preview, Experiment 1
demonstrated that when observing the movements
performed by a human body, participants exhibited biases
for identifying behaviors as threatening and executing
avoidance motor contingences. It was expected that if
perceiving emotional body movements conveyed by
different body forms does not impact emotion perception,
then participants in Experiments 2a and 2b who observe the
same movements performed by non-human virtual bodies
should reveal the same biases. In contrast, if different body
forms do impact the perception of emotional body
movements, the biases found in Experiment 1 would not be
expected in the subsequent experiments.

Experiment 1
We first examined whether a threat bias would emerge
during the perception of emotional human body movements.
Participants were shown one of two short video clips
corresponding to a human whose bodily movements either
conveyed happiness or anger. Under the instruction to do so
as quickly as possible, some participants were required to
push a lever if they considered the emotion happy and to
pull the same lever if they considered the emotion angry,
whereas other participants received the opposite directions.
Each participant thus made one response to one video. This
method of identifying emotions under time-pressure for
action allowed us to measure false alarm rates, given that an
incorrect response to one behavior (e.g., happy)
corresponded to categorizing it the other behavior (e.g.,
angry). To the extent that the human body triggered a threat
bias, there should be more false alarms misidentifying the
happy behavior as angry than false alarms misidentifying
the angry behavior as happy. In addition, there should be a
greater tendency to activate avoidance motor contingencies
in response to the angry behavior than approach motor
contingences in response to the happy behavior.

Method
Participants Ninety-five undergraduates.

!

Materials Two videos approximately 3s in length were used
that contained a male human actor behaving either happy or
angry, respectively. They were taken from previous research
that used these exact behaviors to create virtual characters
exhibiting the same body movements, and which also
demonstrated that people reliably identified the movements
as corresponding to the two emotions (McDonnell et al.
2009). The virtual characters that were created from the
human body motions and that were used in Experiments 2a
and 2b will be discussed in more detail below.

The filming took place during a motion capture session so
that the video and virtual stimuli would be identical in all
respects except for changes in body type. Forty-one sensors
were placed on the actor who wore a black jumpsuit. The
motion capture environment consisted of a floor area that
was 4.5m long x 2m wide and a backdrop was 3m high x
2m wide. A Vicon optical system consisting of 10 cameras
was used for the motion capture and a digital camcorder was
used for the filming. The videos were then edited so that the
actor’s face and hands were blurred, in order to prevent
participants from relying on facial or hand gestures to
identify emotions. Stimuli can be viewed at the following
website: http://gv2.cs.tcd.ie/mcdonner/APGV08.htm. Aside
from our critical stimuli, an optical illusion picture that can
be perceived as either a young or old woman was used for a
practice trial (see Hill 1915).
Design and Procedure Participants sat at a desk equipped
with a joystick and 16-inch monitor. They were told that
they would be categorizing some items presented on the
computer by pushing or pulling the joystick, with their right
hand, as quickly as possible. Participants first completed a
practice trial, for which they were told that they would be
viewing a picture of a woman and that they should push the
joystick if they thought she was old, and to pull the joystick
if they thought she was young.
Participants received one critical trial, for which emotion
(happy, angry) and arm movement (push, pull) was
manipulated using a 2 X 2 factorial design, with each factor
varying between-subjects. Participants were told that they
would be moving the joystick to categorize a short video of
a behavior that is either happy or angry. They received one
of two versions of instructions that manipulated arm
movement direction. One version stated, “If you believe the
emotion in the video is angry, push the joystick all the way
forward; however, if you believe the emotion in the video is
happy, pull the joystick all the way backward.” The other
version stated, “If you believe the emotion in the video is
happy, push the joystick all the way forward; however, if
you believe the emotion in the video is angry, pull the
joystick all the way backward.” E-prime 2.0 (Schneider et
al. 2007) was used to record accuracy and the amount of
time that elapsed between the presentation of the video and
when the joystick reached its maximal point from the
baseline position.
Screening & Analyses Reaction times corresponding to
correct and incorrect responses were screened separately,
using a 2.5 standard deviation criterion from each
condition’s respective mean. One incorrect response did not
meet this criterion and was thus excluded from analyses,
which accounted for losing 1% of the data. Two factorial
analyses of variance (ANOVA) were carried out, each based
on the following design: 2 (emotion: happy, angry) X 2 (arm
movement: push, pull). Whereas one ANOVA was carried

1

A pilot study was conducted with an independent group of participants (n = 25) to ensure that the bodily movements could be perceived
as exhibiting the respective emotions, when they were viewed only once and there was no time-pressure. Participants watched an
expression in its entirety and verbally identified at their own pace, the basic emotion they felt was displayed. Each participant did this for
each body form and emotion. Results revealed high accuracy, as no errors were made.

2129

out on false alarm rates, the other ANOVA was carried out
on reaction times corresponding to correct responses.

Results & Discussion
As illustrated in Fig. 1, the ANOVA on false alarm rates
revealed a main effect for emotion, F (1, 90) = 15.74, p < .
001, indicating that more false alarms were made
misidentifying the happy behavior as angry (M = 47.5; SE =
6.4), than misidentifying the angry behavior as happy (M =
9.1; SE = 5.1). The analysis on false alarm rates revealed no
main effect for arm movement, F (1, 90) = .37, n.s., nor
interaction between arm movement and emotion, F(1, 90)
= .01, n.s.

!

Figure 1: Mean false alarm rates in misidentifying
movements as angry when they were happy (solid bars) and
misidentifying movements as happy when they were angry
(clear bars). Error bars represent standard errors of means.

The ANOVA on reaction times for correct responses
revealed no main effects for emotion, F (1, 58) = 1.30, n.s.,
or movement direction, F (1, 58) = 1.03, n.s., but did reveal
an interaction, F (1, 58) = 4.03, p < .05 (see Table 1). This
interaction is not likely due to a speed-accuracy trade-off
given that the ANOVA conducted on false alarm rates
revealed no interaction. Participants were faster at pulling
than pushing the lever in response to the angry behavior, t
(28) = 2.35, p < .05; however, although they were also faster
at pushing than pulling the lever in response to the happy
behavior, this was not significant, t (30) = .66, n.s.

!

Table 1: Means and standard errors for reaction times (in
milliseconds) corresponding to correct responses.

!
The results extend previous research in emotion and body
perception when observing humans. First, the high rate of
false alarms in categorizing happy movements as angry,
accompanied by the low false alarm rate in categorizing the
angry movement as happy, suggest that people exhibit a bias
towards identifying emotional body movements performed
by humans as threatening. Second, that the angry movement
triggered a motor contingency but the happy movement did
not, suggests that the identification bias had a downstream
influence on behavior via biasing adaptive action plans in
the direction of avoidance. These findings are consistent

with the idea that perceivers often act on caution when
observing other humans whose bodily movements are
emotional, as doing so can help perceivers avoid potential
harm. Our data is also compatible with the neuroscience
evidence reviewed, which demonstrated that angry but not
happy body movements trigger adaptive motor programs.
These results are not likely due to the specific stimuli
used in the current experiment. The results of our pilot
study, where there was no time-pressure, indicated that
people were very accurate at identifying the emotions.
Furthermore, for those observing the happy movement, it
took longer for making correct responses (M = 2563; SE =
220) than incorrect responses (M = 1764; SE = 101), F (1,
59) = 10.18. This is precisely what would be expected if
people were indeed false alarming happy movements as
angry, as it suggests that participants had to overcome the
threat bias to correctly identify the happy human.

Experiments 2a and 2b
Here, we investigated whether perceiving the same body
movements embodied by non-human virtual characters
would reproduce the findings of Experiment 1, for which
the movements made by a real human body triggered biases
in perceiving the movements as a potential threat and
executing avoidance motor contingencies. Experiments 2a
and 2b used the same method as Experiment 1, but with
non-human virtual characters. For Experiment 2a, we chose
to present participants with a wooden mannequin, because
we wanted to begin with a virtual character that had no
obvious positive or negative associations. In contrast, for
Experiment 2b, we presented participants with a virtual
zombie, reasoning the character might be even more likely
to elicit biases towards threat due to the negative
connotations associated with zombies.

Method
Participants Whereas 96 undergraduates participated in
Experiment 2a, a separate group of 73 undergraduates
participated in Experiment 2b.

!

Materials Four virtual replicas of the human actor from
Experiment 1 were used, which consisted of a wooden
mannequin behaving happy or angry (Experiment 2a), as
well as, a zombie behaving happy or angry (Experiment 2b).
Measurements taken from the motion capture session
described in Experiment 1 was for rendering the characters
in 3D Studio Max. They can be found at the following
website: http://gv2.cs.tcd.ie/mcdonner/APGV08.htm. As in
Experiment 1, face and hands were blurred, in order to
prevent participants from relying on facial or hand gestures
to identify emotions.

!

Design and Procedure This was the same as Experiment 1,
but those in Experiment 2a observed the wooden mannequin
and those in Experiment 2b observed the zombie.

!

Screening & Analyses This was the same as described in
Experiment 1. All responses in Experiment 2a and 2b fell
within the criterion and were thus analyzed.

2130

Results & Discussion
Experiment 2a (Wooden Mannequin) As illustrated in
Figure 1, the ANOVA conducted on false alarms revealed no
main effect for emotion, F (1, 92) = .02, n.s., indicating that
participants made a comparable number of false alarms
misidentifying the happy behavior as angry (M = 26.5; SE =
6.4) and misidentifying the angry behavior as happy (M =
27.7; SE = 6.6). There was no main effect for movement
direction, F (1, 92) = .15, n.s., nor interaction between
emotion and arm movement, F (1, 92) = .33, n.s.
The ANOVA conducted on reaction times for correct
responses revealed no main effect for movement direction,
F (1, 66) = .00, n.s., no main effect for emotion, F (1, 66) =
1.58, n.s., and no interaction, F (1, 66) = .04, n.s. (see Table
1 for data).

!

Experiment 2b (Zombie) As illustrated in Figure 1, the
ANOVA conducted on false alarms revealed no main effect
for emotion, F(1, 69) = .10, n.s., indicating that participants
made a comparable number of false alarms misidentifying
the happy behavior as angry (M = 25.7; SE = 7.5) and
misidentifying the angry behavior as happy (M = 28.9; SE =
7.5). There was no main effect for movement direction, F
(1, 69) = .29, n.s., nor interaction between emotion and arm
movement, F (1, 69) = .89, n.s.
The ANOVA conducted on reaction times for correct
responses revealed no main effect for movement direction,
F(1, 49) = .06, n.s., no main effect for emotion, F(1, 49) = .
43, n.s., and no interaction, F(1, 49) = .44, n.s. (see Table 1
for data).
There were two critical findings that differed from
Experiment 1. First, perceivers exhibited no threat bias
when identifying the emotional body movements of a
wooden mannequin (Experiment 2a) or a zombie
(Experiment 2b). Second, the emotional body movements
did not trigger motor contingencies.

False Alarms in Experiment 1 vs. 2a and 2b
To the extent that participants were more biased in
perceiving movements as a potential threat when observing
the human (Experiment 1) than the Wooden Mannequin
(Experiment 2a) or the Zombie (Experiment 2b), those
perceiving the human should make the most false alarms
misidentifying happy movements as angry and make the
fewest false alarms misidentifying angry movements as
happy. Two ANOVAs compared false alarms made in
response to the happy human, to false alarms made in
response to the happy wooden mannequin and the happy
zombie; that is, misidentifying the happy movements as
angry. Two additional ANOVAs also compared false alarms
in response to the angry human, to false alarms made in
response to the angry wooden mannequin and the angry
zombie; that is, misidentifying angry movements as happy.

Results and Discussion
The ANOVAs conduced on false alarm rates revealed that
identifying emotional body movements was affected by the
type of body in which the expression was embodied.
Compared to false alarms misidentifying the happy human

as angry, there were significantly fewer false alarms
misidentifying the happy wooden mannequin as angry, F(1,
108) = 5.23, p < .05, or the happy zombie as angry, F(1, 94)
= 4.55, p < .05. Furthermore, compared to false alarms
misidentifying the angry human as happy, participants made
significantly more false alarms misidentifying the angry
wooden mannequin as happy, F(1, 78) = 4.30, p < .05 and
the angry zombie as happy, F(1, 69) = 4.56, p < .05.
Together, these results provide additional evidence that
emotional body movements expressed by humans and nonhuman virtual characters are not treated the same at the
visceral level. In particular, they suggest that when
observing non-human virtual characters, the need for
perceivers to be on alert was significantly less and thus did
not trigger a bias in identifying movements as angry.

General Discussion
Our findings indicate that the identification of emotional
body movements is not entirely a disembodied process. As
reviewed, mapping observed bodily movements onto one’s
own motor system can play a pivotal role in attributing
emotional states to others. It is thus possible that because
our participants had human bodies, mappings may have
differed in such a way that led them to perceive the human
movements as genuinely experiencing anger and having a
body that is capable of physical threat. However, that we
demonstrated an effect of body form on emotion perception
stands in contrast to the study conducted by McDonnell et
al. (2009), which used some of the same body forms and
movements that were used in the current work. One critical
difference between our work and their work is that our
participants had to make judgments under time-pressure
rather than after extensive viewing. This suggests that
embodied processes in body and emotion perception
particularly impact judgment calls that are made under timepressure and that more processing time can improve these
processes.
The current work carries implications for theories
concerned with how humans perceive real life versus
mediated life. For example, it adds to the media equation’s
hypothesis that perceivers will not treat emotional body
movements performed by human bodies and non-human
virtual bodies differently. Our pilot data revealed no
difference in identifying emotions conveyed by the two
types of beings, when there was no time-pressure for action,
which is consistent with the media equation. However, our
data also revealed that dissimilarities could be found in
identifying the exact same emotions, when there was timepressure for action.
One may wonder to what extent our work is limited,
given that each experiment used only two stimuli, as well
as, a between-subjects design where participants were given
a single trial. A drawback to this approach is that the
absence of multiple stimuli could have potentially led to a
significant effect that was not controlled for. For example,
the happy human might have one subtle difference other
than being human that was unconsciously processed,
thereby contributing to the emotion being misidentified as
angry. This is a common problem among researchers using
virtual characters and it is often dealt with by using multiple

2131

methods to examine how results converge. Recent work
using a different time-sensitive paradigm corroborates our
findings by demonstrating angry body movements are more
recognizable in a real human than a virtual human, but that
happy body movements are more recognizable in a virtual
human than a real human (McHugh, MacDonnell, Chan, &
Newell, 2008). Nonetheless, even if a single feature of our
stimuli did tip the scale in emotion perception, this would
reveal important information concerning how people
perceive emotions under time pressure. In particular, it
would suggest that such scenarios can result in emotion
judgments being tainted by nonessential features. This idea
is consistent with past research revealing that the same
facial configuration can convey diverse emotions depending
upon the context (Aviezer, et al. 2008). Future research
should examine whether our findings generalize to other
portrayals of the emotions examined in our study, as well as,
across different human actors and virtual characters.
Another short-coming of our method is that it could have
rendered the reaction time analyses unreliable, due to the
fact that reaction time data often varies greatly and requires
collecting numerous responses to achieve stability. Aside
from being hindered by difficulties in obtaining a sizeable
stimulus set, there was a concern that practice effects might
emerge from using multiple trials, which could have
reduced the chance of findings a potential false alarm effect.
We conducted Levene’s Test of Equality of Variances on
reaction times for correct responses, using the same design
(Emotion x Arm Movement ) used in each experiment,
which revealed no significant differences in between-subject
variability in reaction times. Further evidence for the
interpretations of our reaction time data can be found by
noting how pulling responses to an angry human were
quicker than pulling responses to an angry virtual character.

References
Allison T., Puce A., & McCarthy G. (2000). Social
perception from visual cues: Role of the STS region.
Trends in Cognitive Sciences, 4, 267-278.
Bastiaansen J. A., Thioux M., & Keysers, C. (2009).
Evidence for mirror systems in emotions. Philosophical
Transactions of the Royal Society Biological Science, 364,
2391-2404.
Beauchamp, G., & Ruxton, G. (2007). False alarms and the
evolution of antipredator vigilance. Animal Behavior, 74,
1199-1206.
Bradley, M., & Lang, P. (2000). Measuring emotion:
Behavior, feeling, and physiology. In Lane, R. D., Nadel
L (Eds.), Cognitive Neuroscience of Emotion. NY: Oxford
University Press.
Darwin, C., (1872/1965). The expression of emotions in man
and animals, London: John Marry.
de Gelder, B., (2006). Towards the neurobiology of
emotional body language. Nature Reviews Neuroscience,
7, 242-249.
Decety, J., & Chaminade, T. (2003). When the self
represents the other: A new cognitive neuroscience view
on psychological identification. Consciousness and
Cognition, 12, 577-596.

Ekman, P., (1992). Are there basic emotions? Psychological
Review, 99, 550-553.
Gallese, V., (2009). Mirror neurons, embodied simulation,
and the neural basis of social identification.
Psychoanalytic Dialogues, 19, 519-536.
Gallese, V. (2010). Embodied Simulation and its Role in
Intersubjectivity. In Fuchs, T., Sattel, H. C.,
&
Henningsen, P. (Eds.), The Embodied Self. Dimensions,
Coherence and Disorders. Germany: Schattauer.
Grèzes, J., & Decety, J., (2001). Functional anatomy of
execution, mental simulation, observation and verb
generation of actions: A meta-analysis. Human Brain
Mapping, 12, 1-19.
Mar, R. A., Kelley, W. M., Heatherton T. F., & Macrae, C.
N. (2007). Detecting agency from the biological motion
of veridical versus animated agents. Social Cognitive and
Affective Neuroscience, 2, 199-205.
McDonnell, R., Jorg, S., McHugh, J., Newell, F., &
O’Sullivan, C. (2009). Investigating the role of body
shape on the perception of emotion. ACM Transactions on
Applied Perception, 6, 14:1-14:11.
Ohman, A., Lundqvist, D., & Esteves, F. (2001). The face in
the crowd revisited: A threat advantage with schematic
stimuli. Journal of Personality and Social Psychology, 80,
381-396.
Perani, D., Fazio, F., Borghese, N., et al. (2001). Different
brain correlates for watching real and virtual hand actions.
NeuroImage, 14, 749-758.
Pichon, S., de Gelder, B., & Grezes, J. (2009). Two different
faces of threat: Comparing the neural systems for
recognizing fear and anger in dynamic body expressions.
NeuroImage, 47, 1873-1883.
Reed, C. L. (2002). What is the body schema? In Printz, W.,
& Meltzoff, A. (Eds.), The imitative mind: Development,
evolution, and brain bases. MA: Cambridge University
Press.
Reed, C. L., & McGoldrick, J. E. (2007). Action during
body perception: Processing time affects self-other
correspondences. Society for Neuroscience, 2, 134-149.
Reeves, B., & Nass, C. (1996). The media equation: How
people treat computers, television, and new media like
real people and places. NY: Cambridge University Press.
Rotteveel, M., & Phaf, R. H. (2004). Automatic affective
evaluation does not automatically predispose for arm
flexion and extension. Emotion, 4, 156-172.
Solarz, A. (1960). Latency of instrumental responses as a
function of compatibility. Journal of Experimental
Psychology, 59, 239-245.
Wicker, B., Keysers, C., Plailly, J., Royet, J. P., Gallese, V.,
& Rizzolatti, G. (2003). Both of us disgusted in my
insula: The common neural basis of seeing and feeling
disgust. Neuron, 40, 655-664.
Wilson, M. (2001). Perceiving imitatable stimuli:
Consequences of isomorphism between input and output.
Psychological Bulletin, 127, 543-553.

2132

