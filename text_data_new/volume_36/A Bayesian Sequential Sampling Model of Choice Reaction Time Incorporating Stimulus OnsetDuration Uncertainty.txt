UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Bayesian Sequential Sampling Model of Choice Reaction Time Incorporating Stimulus
Onset/Duration Uncertainty

Permalink
https://escholarship.org/uc/item/9tp3f6qh

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Meyer, Jordan
Zhang, Jun

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Bayesian Sequential Sampling Model of Choice Reaction Time Incorporating
Stimulus Onset/Duration Uncertainty
Jordan Meyer (jlmeyer@umich.edu) and Jun Zhang (junz@umich.edu)
University of Michigan, Department of Psychology
Ann Arbor, MI 48109 USA
where the log likelihood ratio X(et ) = log(la (et )/lb (et )) is
a random number determined by the stochastic evidence et .
Thus, the variable log(Pr[a|et ]/ Pr[b|et ]) can be seen as a random walk process with “drift rate” equal the expectation of
X(et ), namely, EPr {log (Pr[a|et ]/ Pr[b|et ])} which, assuming
a to be the true stimulus, equals


Pr[a|et ]
∑ Pr[a|et ] log Pr[b|et ] = KL(Pr[a|et ] k Pr[b|et )) (2)
e

Abstract
We propose a Bayesian sequential sampling model of choice
reaction time (RT) which incorporates uncertainties about
stimulus identity, onset, and duration. The model is the nowstandard random-walk/drift-diffusion model, with a thresholdbased response mechanism. The “substance” of the drift, however, is the posterior probability (belief) that a participant updates on a moment-to-moment basis during a trial — the update is done by combining the likelihood function on the evidence (modeling trial-dependent perception) with prior probability about stimulus identity, onset time, and duration (modeling trial-independent task knowledge). Response threshold,
which equals the probability of correct response in choosing
each alternative conditioned on prior knowledge and accumulated evidence, modulates speed-accuracy tradeoff. While sequential Bayesian updating without temporal uncertainty (regarding stimulus onset/offset) is trivial, we overcome the hurdle of incorporating the temporal prior into the dynamics of
belief updating to derive an analytic expression for Bayesian
belief. The advantage of the Bayesian formulation is to allow
full control of where and how many free parameters appear: in
likelihood functions, priors, or response threshold. Comparison of computer simulation of our model with human performance data (Smith, 1995) will be reported.
Keywords: Choice Reaction Times; Bayesian Modeling; Sequential Sampling; Stimulus Onset/Duration Uncertainty

where KL(· k ·) denotes Kullback-Leibler divergence.
Stone (1960) adapted the SPRT model to study choice reaction times. Further development (Thomas, 1975; Swensson
& Green, 1977) derived the surprising prediction that RT distributions for correct and error trials should be identical. This
has long been known to be empirically violated (e.g., Laming,
1968; Link, 1975). Ashby (1983) proposed an amelioration
in the form of a constant bias term log(k) added to the drift
rate X(et ) in (1). Later, the SPRT model was generalized to
the case of an arbitrary number of hypotheses (Baum & Veeravalli, 1994; Draglia, Tartakovsky, & Veeravalli, 1999).

Stimulus Uncertainty and Prior Knowledge

Introduction
The study of the underlying mechanisms that mediate trialby-trial variation in reaction time (RT) in simple choice tasks
has been prolifically pursued in the field of mathematical psychology for over a century (cf. Luce, 1986, for a classic review). Here, we propose as a novel model for choice-RT
experiments an exact Bayesian belief update procedure that
dynamically combines sequential accumulation of evidence
with prior knowledge about stimulus identity as well as temporal uncertainty in stimulus presentation.
The general leitmotif of most RT models is the assumption
that information regarding the nature and onset of a stimulus
is accumulated stochastically in discrete time steps from the
beginning of a trial until some stopping point is reached, at
which point a response is issued and an RT measured. Wald
(1947) offered a seminal analysis of the statistical properties
of such sequential sampling processes. In his SPRT (“Sequential Probability Ratio Test”) model, a stimulus is presented at time zero (starting point), an evidence et is stochastically generated by the environment at time t, and the stimulus may be either a or b, with associated likelihood functions
la (e) and lb (e). Their probabilities prior to (Pr[·]) and after
receiving et (Pr[·|et ]) are related by:




Pr[a]
Pr[a|et ]
= log
+ X(et ) ,
(1)
log
Pr[b|et ]
Pr[b]

Other variants of sequential sampling models were proposed (e.g., Ratcliff and Smith, 2004; Busemeyer and
Townsend, 1993; Usher and McClelland, 2001; Bogacz,
Brown, Moehlis, Holmes, and Cohen, 2006). However, one
curiosity is that most models assume the initiation of evidence
accumulation is concurrent with the onset of stimulus presentation. But for such a process to be triggered, the system
would already have known that a target has been presented.
This seems to imply the unsavory conclusion that choice tasks
consist of a stimulus detection stage in serial connection with
a stimulus identification stage. Alternatively, one can allow
for “premature” sampling, in which pure noise information
is sampled before stimulus onset (e.g., Rouder, 1996). However, there has not yet been a principled way of incorporating
prior knowledge about stimulus onset (and duration) uncertainty into RT models.
By uncertainty, we refer both to uncertainty regarding target identity, and uncertainty regarding its temporal presentation (onset time, offset time or duration). If a participant is
trained extensively on a given task, it is usual for them to acquire a significant amount of task knowledge regarding the
statistical structure of the stimulus. This knowledge can be
embodied in a joint prior distribution over stimulus identity
and stimulus onset-duration across trials. In the sequential
sampling framework, a participant on a given trial receives

2639

a sequence of evidence that is (stochastically) related to the
true stimulus state, and the participant uses this evidence to
adjust their decision tendency over time. The participant
will in general be simultaneously using their prior knowledge
of the stimulus presentation to inform this adjustment. The
dynamic interaction between information accumulation and
prior knowledge about temporal aspect of the stimulus uncertainty during the decision process has not been well researched in the RT literature, and is the key theoretical motivation for the present work.
Previously, one Bayesian sequential sampling model was
proposed that explicitly took account of temporal uncertainty
in modeling detection RT. Stein and Rapoport (1978) modeled performance on a simple detection task (without a choice
component) by combining prior probability of stimulus onset
time with a Bayesian sequential sampling procedure. Unfortunately, the model did not extend to a choice paradigm (let
alone with > 2 alternatives), nor was the stimulus onset distribution general enough (from their restricted case of Poisson
distribution). Stimulus onset uncertainty in a choice task has
been treated only with the above-mentioned ad hoc method
of premature sampling. On the other hand, the study of the
effect of the stimulus identity prior (i.e., stimulus presentation
rate) dates back to the seminal studies of Hick (1952), Hyman
(1953), and Crossman (1953), the latter two of whom proposed on information-theoretic grounds that the reaction time
to the i-th stimulus with presentation probability pi should
obey
RT = c − d log(pi )
(3)
(with c, d constants) so that the mean RT is linearly related
to the stimulus entropy H = − ∑i pi log(pi ). The prediction
made by (3) has found some empirical support, for example
in the study of an oculomotor task by Carpenter and Williams
(1995).
Most interestingly, the question of how stimulus and onset/offset uncertainty interact and influence each other during
the decision process is not well known empirically nor well
understood theoretically. The main goal of the present work
is to provide a Bayesian modeling framework for decision
processes that systematically combines both types of prior
knowledge with moment-to-moment stochastic evidence accumulation.

A Bayesian Sequential Sampling Model
Bayesian theory has proven to provide a powerful framework
for decision making (DM) in uncertain environments . In general, a Bayesian DM agent may be interested in a particular
phenomenon about which the agent maintains a complete set
H of mutually exclusive hypotheses hi ∈ H . By making observations of its environment, the agent accumulates evidence
regarding the relative truth or falsehood of each hypothesis in
H . Before such information accumulation process begins,
the agent has a pre-established judgment regarding the probability of the truth of each hi , denoted Pr[i]. This is the prior
distribution. Usually there is some information intrinsic to

the phenomenon in question that allows for the establishment
of nontrivial (i.e. non-uniform) priors. During the observation stage, the agent receives a particular evidence e ∈ E . The
probability of e having been observed given that hi is true is
denoted Pr[e|i] and referred to as the likelihood of the evidence; this is how the agent accounts for the evidence in light
of its hypothesis hi . At each time t, the agent uses the new
evidence et to refine its estimation of the probability of its
hypotheses from its previous estimate. At t = 1, the first datum e1 is collected, and the posterior probability is calculated
according to Bayes’ theorem:
Pr[i|e1 ] =

Pr[e1 |i] Pr[i]
.
∑ Pr[e1 | j] Pr[ j]

(4)

j

Now, if at time t = 2 datum e2 is generated independently
of e1 , Bayes’ theorem may be applied again to yield the new
posterior probability
Pr[i|e1 e2 ] =

Pr[e2 |i] Pr[i|e1 ]
,
∑ Pr[e2 | j] Pr[ j|e1 ]

(5)

j

where the independence of e1 and e2 is assumed. The update
of the form (5) may be applied iteratively at the reception of
each new datum et , obviating the need for storage of data in
memory.
Applied to the choice RT setting, evidence accumulation
starts at the beginning t = 0 of each trial. As the Bayesian decision maker updates posterior beliefs over the set of hypotheses, he/she must evaluate the utility/cost of obtaining more
evidence before terminating a trial by making a choice. Generally, a participant is instructed to perform a speeded choice
task as accurately and quickly as possible, and rewarded accordingly. The determination of an optimal stopping rule for
such a sequential sampling process that maximizes the expected reward is the familiar speed-accuracy tradeoff problem. In most sequential sampling sampling models, the
threshold parameter and correct-choice rate are (generally
monotonically) related but depend on other parameters. In
contrast, a Bayesian sequential sampling model, in which
posterior probability is the substance of drift-with-diffusion,
has the advantage of equating the threshold parameter with
the conditional probability of that choice being correct. This
provides a special link between subjective threshold evaluation and external observed performance not present in other
models, as shown below.
It must be realized that a special challenge arises in applying the vanilla Bayesian (5) updating to the data sampling
process. It has been implicitly assumed that the environment
remains stationary; that is, the denotation of environment status embodied in the hypotheses and likelihood functions must
not change over the whole course of evidence accumulation.
However, in a choice task in which the stimulus onset and
offset vary probabilistically across trials, in each trial the environment undergoes a stochastic transition from a target-off
state to a target-on state, then possibly another transition from

2640

target-on back to target-off. Because of this temporal uncertainty regarding the environmental state, the hypotheses of
behavioral interest, i.e., whether the target (ii) has not yet appeared, (ii) is currently on, or (iii) was on in the past but has
been turned off, cannot be directly ported into the Bayesian
formulation. To work around this, we develop a formulation
of an exact Bayesian model in terms of mini-hypotheses, from
which we then can straightforwardly derive a behavior-level
equivalent.

potheses regarding target identity and temporality. In contrast, the behavior-level hypotheses maintained by the decision units are different; they are formulated as unions of
mini-hypotheses as shown below.
fk (τ1 , τ2 ) – the prior probability that hk,τ1 ,τ2 is true. This
distribution is presumably acquired through task instruction or learned through previous task training. Of course,
∑k ∑τ1 >0 ∑τ2 >τ1 fk (τ1 , τ2 ) = 1.
et – the particular datum drawn from E through stochastic
generation by the sensor(s) during run-time (t, t + 1). The
form or structure of such evidence et can be determined as
appropriate for modeling purposes. For example, it may
be uni- or multi-dimensional, with discrete or continuous
values.

Basic Elements of the Bayesian Model
We consider the following general paradigm for a choice reaction time experiment, with arbitrary stimulus onset-offset.
In each trial, a warning signal is given at time t = 0, beginning the trial. The k-th target (out of N possible ones) appears at some time t = τ1 > 0, and remains on until some
time t = τ2 > τ1 . The index k for the set of targets is general
and refers to whatever stimulus attribute is relevant for the
given task (e.g., spatial location, frequency, orientation, etc.).
For simplicity, we will use the example of target location in a
visual paradigm throughout, referring interchangeably to the
k-th target and the target at the k-th location. Reaction time
is defined as time lapse from τ1 to the time step in which the
participant makes a choice response (a judgment that “k-th
target has already appeared”). The target location k, onset
time τ1 , and offset time τ2 vary probabilistically from trial to
trial according to the design of the experiment. Importantly,
it is assumed the participant has been extensively trained on
the task, so that the prior probabilities for stimulus location,
onset, and offset are effectively known.
The model consists of two basic elements: decision (accumulator) units and sensor (perceptual) units. The sensors
reports evidence generated stochastically at each time step
based on the true state of the environment. Each sensor is endowed with a particular tuning on the relevant dimension of
the stimulus space, and its activation level depends (assumed
to be deterministically) on the evidence stochastically generated by the environment. In this way, the sensors implement
the likelihood functions in the Bayesian framework. The decision units read-in the likelihood evaluation from the sensors
and combine it with prior knowledge about the stimulus uncertainty in the task (presumably store in memory representation) to update the posterior probabilities of each behaviorlevel hypothesis. This cycle is continued until the posterior
probability for one of the 2N + 1 behavior-relevant hypotheses (to include onset-offset of N targets plus target absent)
reaches a pre-determined threshold, at which time the corresponding response is made.
The following notation is used to denote various aspects of
the Bayesian model framework:
hk,τ1 ,τ2 – the hypothesis that “the k-th target appears at time
τ1 and disappears at time τ2 .” These are the so-called minihypotheses mentioned earlier. The set of all such minihypotheses H = {hk,τ1 ,τ2 : 0 < τ1 < τ2 , 1 ≤ k ≤ N} forms
a complete, mutually exclusive partition of the space of hy-

E(t) – the entire sequence of evidences generated up to time
t in a given trial. That is, E(t) = {e0 e1 · · · et−1 }.
l0 (et ) – the probability of evidence et being generated when
no target has appeared. This is the sensory activation to the
background noise.
lk (et ) – the probability of evidence et being generated given
that the k-th target is currently on. This is the sensory activation in the presence of the k-th target.
lk (et ) – the probability of evidence et being generated given
that no target is currently on, but the k-th target was previously on. In the current implementation, this is taken to
be equivalent to l0 (et ), but can in principle take alternative
functional forms.
In a given trial, at each time step t, the probabilities of
all mini-hypotheses hk,τ1 ,τ2 are evaluated according to the
Bayesian recursive update formula (4) and (5), using the previous probabilities computed at time step t − 1 and the likelihood of the evidence et−1 generated between t − 1 and t.
The process continues until a response threshold is reached.
Note that the mini-hypotheses are about target at a particular
location with particular onset and offset times. Hence they
are stationary during any trial – they are either true or false
throughout the trial. As such, vanilla Bayes updating is adequate. However, the decision maker is not asked to act upon
each mini-hypothesis; rather he/she is instructed to respond
whenever a stimulus at a particular location has appeared.
This leads to the behavioral model below.

Formulation of Behavioral Model
For modeling behavior, only the following hypotheses are
task-relevant (where run-time t can be interpreted as “now”)
H0 (t) – No target has yet appeared as of time t.
Hk (t) – The k-th target is currently on at time t.
Hk (t) – No target is currently on at time t, but the k-th target
was previously on. That is, the k-target has been off as of
time t.

2641

H1

H1

H2

H2

HN

HN

are made up may switch membership dynamically from one
to another as t evolves, as demonstrated in Figure 1. Therefore, at each t, the update of the behavior-level probabilities
must take into account both (a) the standard Bayesian update of all mini-hypotheses conditioned on new evidence et
(equivalently, on E(t + 1)) and (b) the transfer of probability
due to certain mini-hypotheses switching membership. We
will denote by Pi∗ (t) the partially updated probability of Hi (t)
conditioned on new evidence et ; that is, Pi∗ (t) has updated
with respect to (a), but not (b). Applying the standard Bayes’
formula, we get:

h1,30,200

H0

Pi (t)li (et )

Pi∗ (t) =

Figure 1: Markovian transition diagram in which mini-hypotheses
(depicted as black dots) switch their memberships over the timecourse of a trial into various behavior-level hypotheses (depicted as
2N + 1 nodes). Consider, for example, the mini-hypothesis marked
h1,30,200 , stating that stimulus is presented at time τ1 = 30 at location
1 and then turned off at time τ2 = 200. Starting from its membership in H0 , which maintains that “target has not been turned on as
of now”, this mini-hypothesis h1,30,200 will transition its membership, at run-time t = 30 during a trial, from H0 to H1 , which states
that “target has been turned on at location 1 as of now” (i.e., as
of t = 30), and, at run-time t = 200, from H1 to H1 , which states
that “target has been turned off at location 1 as of now” (i.e., as of
t = 200). Note that these membership transitions occur on each trial
regardless what and when a stimulus is presented on any particular
trial. The various sizes of dots in H0 schematically represent the
associated posterior probabilities, which change during the progression of a trial according to sequential Bayesian updating. Change of
posterior probabilities on a given trial depends on stimulus presentation of that trial.

These are the hypotheses maintained by the decision units
during run-time t of a given trial. Our key observation is that
these behavior-level hypotheses can be represented as sets of
mini-hypotheses whose memberships vary as a function of
time t (see Figure 1):

S

H0 (t) = {S hk,τ1 ,τ2 , t < τ1 < τ2 , 1 ≤ k ≤ N}
(6)
Hk (t) = { hk,τ1 ,τ2 , τ1 ≤ t < τ2 }

S

Hk (t) = { hk,τ1 ,τ2 , τ1 < τ2 ≤ t}
Performing direct Bayesian updating on the set H of minihypotheses, the posterior probabilities associated with these
behavior-level hypotheses can be formulated as sums of the
mini-hypotheses that constitute them:

P0 (t) = Pr[H0 (t)|E(t)] = ∑ Pr[hk,τ1 ,τ2 |E(t)]




t<τ1 <τ2


1≤k≤N


Pk (t) = Pr[Hk (t)|E(t)] = ∑ Pr[hk,τ1 ,τ2 |E(t)]
(7)

τ1 ≤t<τ2






Pk (t) = Pr[Hk (t)|E(t)] = ∑ Pr[hk,τ1 ,τ2 |E(t)]

N

N

(8)

P0 (t)l0 (et ) + ∑ Pk (t)lk (et ) + ∑ Pk (t)lk (et )
k=1

k=1

To complete the update, we must take into account the
probability transfer due to all mini-hypotheses that switched
membership after time t. It is straightforward to check, simply by definition, which mini-hypotheses are to switch at a
given time step (again refer to Figure 1). The complete update of the behavior-level hypotheses can thus be written:

P0 (t + 1) = P0∗ (t) − ∑ Pr[hk,t+1,τ2 |E(t + 1)]



τ2 >t+1



1≤k≤N



∗


Pk (t + 1) = Pk (t) + ∑ Pr[hk,t+1,τ2 |E(t + 1)]
τ2 >t+1
(9)


−
Pr[h
|E(t
+
1)]

k,τ
,t+1
∑
1



τ1 <t+1



∗


Pk (t + 1) = Pk (t) + ∑ Pr[hk,τ1 ,t+1 |E(t + 1)]
τ1 <t+1

It is now possible to eliminate the reference to the minihypotheses in the update equations of (9) by introducing an
equivalent formulation in terms of “hazard” functions (cf.
Luce, 1986). Let gk (t +1) denote the prior probability that the
k-th target will appear at time t + 1, given that no target has
yet appeared. Similarly, let gk (t + 1) denote the prior probability that the k-th target will disappear at time t + 1, given
that the k-th target is currently on. It is fairly straightforward
to see then that (9) can be reformulated as follows:

N
∗
∗

P0 (t + 1) = P0 (t) − ∑k=1 gk (t + 1)P0 (t)
∗
∗
Pk (t + 1) = Pk (t) + gk (t + 1)P0 (t) − gk (t + 1)Pk∗ (t)


Pk (t + 1) = Pk∗ (t) + gk (t + 1)Pk∗ (t)
(10)
Equating (9) and (10), solving for gk (t + 1) and gk (t + 1),
and simplifying, we arrive at the following solutions for the
hazard functions:

τ1 <τ2 ≤t

Update of Posterior Beliefs As mentioned above, it is not
possible to simply apply the vanilla Bayesian update procedure for the posterior probabilities of any of the 2N + 1
behavior-level hypotheses Pi (t), since their environmental denotation is non-stationary; the mini-hypotheses of which they

2642

∑

τ2 >t+1

gk (t + 1) =

fk (t + 1, τ2 )
(11)

N

∑

∑ fk (τ1 , τ2 )

∑

k=1 τ1 ≥t+1 τ2 >τ1

∑

gk (t + 1) =

τ1 <t+1

∑

fk (τ1 ,t + 1)
∑

τ1 <t+1 τ2 ≥t+1

fk (τ1 , τ2 )

(12)

where the final simplification yielding (12) is the result of an
enforcement of a restriction on the priors:
fk (1,t + 1)
= ··· =
∑ fk (1, τ2 )

τ2 ≥t+1

fk (t,t + 1)
∑ fk (t, τ2 )

τ2 ≥t+1

This enforcement is not necessary generally, and may be dispatched with as needed. Experimentally, it corresponds to the
assumption of independence of onset time and duration for
each target. Lifting the restriction significantly increases the
complexity of the analytic form of (12).
Putting everything together, using (8) to eliminate Pi∗ (t)
from (10), the iteration has the “canonical” form:



N


P
(t)l
(e
)
1
−
g
(t
+
1)
∑
0
0 t
k



k=1

P0 (t + 1) =

N
N



P0 (t)l0 (et ) + ∑ Pk (t)lk (et ) + ∑ Pk (t)lk (et )



k=1
k=1




gk (t + 1)P0 (t)l0 (et ) + Pk (t)lk (et ) 1 − gk (t + 1)
P (t + 1) =
N
N
 k


P
(t)l
(e
)
+
P
(t)l
(e
)
+
Pk (t)lk (et )
∑
∑

0
0
t
t
k
k


k=1
k=1




Pk (t)lk (et ) + gk (t + 1)Pk (t)lk (et )


Pk (t + 1) =

N
N



P0 (t)l0 (et ) + ∑ Pk (t)lk (et ) + ∑ Pk (t)lk (et )
k=1

k=1

(13)
These equations derived here are generalizations of the standard Bayes’ formulation to explicitly include the prior knowledge embodied in gk (t) and gk (t). It is seen that the effects
of evidence and prior knowledge on posterior probability is
interactive; it is not possible to simply redefine the likelihood
function to reduce (13) to the usual Bayes’ formula. Note the
prior probability does not simply enter as a bias term, contra
Ashby (1983).

Analysis and Discussion of the Model
Interpretation of Threshold for Stopping Rule At the beginning of each trial (t = 0), the initial values of the behaviorlevel hypotheses are set so that P0 (t = 0) = 1, while the remaining Pi (t = 0) = 0. The model then begins the cycle of
evidence accumulation and probability update as described
above. If we consider the vector P = (P0 , P1 + P1 , . . . , PN +
PN ), we can view this process as a trajectory Pt within an
(N+1)-dimensional probability simplex, with starting point
(1, 0, . . . , 0). In the present model, whenever one of the targetpositive terms of Pt of the form Pk + Pk exceeds a predetermined threshold θk , the corresponding response is made. Differences among the elements of the threshold vector θ reflect
response biases determined by the Bayesian decision-maker.
Such could naturally arise, for instance, in the case of asymmetric payoffs among responses.
It is worth noting that, in determining the stopping time
(and thus the response), the posterior probabilities corresponding to the pairs of behavior-level hypotheses of the form
{Hk , Hk } are pooled, instead of competing. This corresponds
to the task demand of responding to the target location once

the target is on and choosing the k-th alternative whether or
not the target is subsequently turned off. With a small enough
τ2 , this models a transient stimulus that is briefly turned on
and then off; with large enough τ2 , this models a steady
stimulus that is turned on and stays on. Our model incorporates both the transient channels (through Hk ’s) and sustained channels (through Hk ’s), while controlling the mixture
of transient and sustained components through manipulating
stimulus duration τ2 − τ1 ; this has been empirically and theoretically investigated in behavioral contexts (cf. Smith, 1995)
and in neural context (Cleland, Dubin, & Levick, 1971).
As mentioned earlier, the threshold θk has a special interpretation. Because the sum Pk (t) + Pk (t) is exactly the posterior probability conditioned over all evidence in a trial that the
target has already appeared at location k (but may have been
turned off) by time t, this means that when θk is reached,
it is precisely this same probability. Thus, if we count over
many trials in which the k-th response was made, it can be
shown that θk emerges as the percentage of correct trials (conditioned on the k-th response). Let ak denote the probability
with which the experimenter chooses to present the k-th target
each trial, sk denote the proportion of correct trials among all
trials in which target k is presented, and rk denote the proportion of trials in which the participant responds with the k-th
alternative. Then it follows that:
ak sk = rk θk .

(14)

Summing over k in (14), we get:
%correct = ∑ ak sk = ∑ rk θk .
k

(15)

k

Evidence Representation The model framework is intentionally general and non-committal regarding the mode of evidence representation and the sensor unit response. Ideally,
any specific representational commitment should be made in
light of the nature of the particular task, agent, and stimuli
one wishes to model. However, for illustration purposes, we
offer an example of minimal implementation. Consider the
restricted case N = 2, a two-alternative forced choice task.
The evidence generation can be accomplished by a single
sensor unit, which may be either firing (F) or resting (R) at
any time t. Thus, the evidence space is E = {F, R}, while
the environment may be in any one of three states: no target
present, target 1 present, target 2 present. Suppose the sensor
is slightly tuned to respond to target 1, slightly inhibited in
response by target 2, and equally likely to be firing or resting
when there is no target. Thus, its likelihood functions may
take the following form:
(
Pr[F|0] = 0.5
l0 (e) = l1 (e) = l2 (e) :
Pr[R|0] = 0.5
(
Pr[F|1] = 0.5 + ε
l1 (e) :
(16)
Pr[R|1] = 0.5 − ε
(
Pr[F|2] = 0.5 − ε
l2 (e) :
Pr[R|2] = 0.5 + ε

2643

0.012

density

0.008

0.004

0.000
0

100

rt

200

300

Figure 2: Characteristic shape of RT distributions for correct responses when stimulus presentation probabilities are equal on a uniform temporal prior. Note the heavy tail in the RT density function.

where ε is a small constant representing the sensor’s tuning.
It is easy to extend such a representation to multiple sensors,
complex activation functions, interactions between units, etc.
Simulation Results We simulated a variant of the twochoice model presented above, and were able to reproduce
many empirical data patterns of choice RT experiments, such
as the prediction of (3) that median RT is dependent via a loglinear transformation upon prior stimulus probability (Carpenter & Williams, 1995), the speed-accuracy tradeoff, and
the dependency of both correct and error RT distributions
on stimulus probability (Link, 1975; Green, Smith, and von
Gierke, 1983; see Figure 2). We also were able to numerically simulate and confirm the special Bayesian significance
of the threshold θk parameter, as described above.

Acknowledgments
Supported by ARO grant W911NF-12-1-0163 and AFOSR
grant FA9550-13-1-0025 (PI: Jun Zhang).

References
Ashby, F. G. (1983). A biased random walk model for two
choice reaction times. Journal of Mathematical Psychology, 27(3), 277–297.
Baum, C. W. & Veeravalli, V. V. (1994). A sequential procedure for multihypothesis testing. IEEE Transactions on
Information Theory, 40(6), 1994–2007.
Bogacz, R., Brown, E., Moehlis, J., Holmes, P., & Cohen,
J. D. (2006). The physics of optimal decision making: a formal analysis of models of performance in two-alternative
forced-choice tasks. Psychological review, 113(4), 700–
765.
Busemeyer, J. R. & Townsend, J. T. (1993). Decision field
theory: a dynamic-cognitive approach to decision making

in an uncertain environment. Psychological review, 100(3),
432–459.
Carpenter, R. H. S. & Williams, M. L. L. (1995). Neural computation of log likelihood in control of saccadic eye movements. Nature, 377(6544), 59–62.
Cleland, B. G., Dubin, M. W., & Levick, W. R. (1971). Sustained and transient neurones in the cat’s retina and lateral geniculate nucleus. The Journal of Physiology, 217(2),
473–496.
Crossman, E. R. F. W. (1953). Entropy and choice time: the
effect of frequency unbalance on choice-responses. Quarterly Journal of Experimental Psychology, 5, 41–52.
Draglia, V. P., Tartakovsky, A. G., & Veeravalli, V. V. (1999).
Multihypothesis sequential probability ratio tests. i. asymptotic optimality. IEEE Transactions on Information Theory,
45(7), 2448–2461.
Green, D. M., Smith, A. F., & von Gierke, S. M. (1983).
Choice reaction time with a random foreperiod. Perception
& Psychophysics, 34(3), 195–208.
Hick, W. E. (1952). On the rate of gain of information. Quarterly Journal of Experimental Psychology, 4(1), 11–26.
Hyman, R. (1953). Stimulus information as a determinant of
reaction time. Journal of experimental psychology, 45(3),
188–196.
Laming, D. R. J. (1968). Information theory of choicereaction times. New York: Wiley.
Link, S. W. (1975). The relative judgment theory of two
choice response time. Journal of Mathematical Psychology, 12(1), 114–135.
Luce, R. D. (1986). Response times: their role in inferring
elementary mental organization. New York: Oxford University Press.
Ratcliff, R. & Smith, P. L. (2004). A comparison of sequential
sampling models for two-choice reaction time. Psychological review, 111(2), 333–367.
Rouder, J. N. (1996). Premature sampling in random walks.
Journal of Mathematical Psychology, 40(4), 287–296.
Smith, P. L. (1995). Psychophysically principled models of
visual simple reaction time. Psychological Review, 102(3),
567–593.
Stein, W. E. & Rapoport, A. (1978). A discrete time model for
detection of randomly presented stimuli. Journal of Mathematical Psychology, 17(2), 110–137.
Stone, M. (1960). Models for choice-reaction time. Psychometrika, 25(3), 251–260.
Swensson, R. G. & Green, D. M. (1977). On the relations between random walk models for two-choice response times.
Journal of Mathematical Psychology, 15(3), 282–291.
Thomas, E. A. C. (1975). A note on the sequential probability
ratio test. Psychometrika, 40(1), 107–111.
Usher, M. & McClelland, J. L. (2001). The time course of perceptual choice: the leaky, competing accumulator model.
Psychological review, 108(3), 550–592.
Wald, A. (1947). Sequential analysis. New York: Wiley.

2644

