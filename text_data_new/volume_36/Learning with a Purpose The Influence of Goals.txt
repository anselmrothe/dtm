UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning with a Purpose: The Influence of Goals

Permalink
https://escholarship.org/uc/item/0r61w1xm

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Wellen, Sarah
Danks, David

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Learning with a Purpose: The Influence of Goals
Sarah Wellen (swellen@andrew.cmu.edu)
Department of Philosophy, Baker Hall 135
Pittsburgh, PA 15213 USA

David Danks (ddanks@cmu.edu)
Department of Philosophy, Baker Hall 135
Pittsburgh, PA 15213 USA
Abstract
Most learning models assume, either implicitly or explicitly,
that the goal of learning is to acquire a complete and veridical
representation of the world, but this view assumes away the
possibility that pragmatic goals can play a central role in
learning. We propose instead that people are relatively frugal
learners, acquiring goal-relevant information while ignoring
goal-irrelevant features of the environment. Experiment 1
provides evidence that learning is goal-dependent, and that
people are relatively (but not absolutely) frugal when given a
specific, practical goal. Experiment 2 investigates possible
mechanisms underlying this effect, and finds evidence that
people exhibit goal-driven attention allocation, but not goaldriven reasoning. We conclude by examining how frugality
can be integrated into Bayesian models of learning.
Keywords: Goals, Learning, Task-effects, Rationality,
Frugality, Bayesian inference

Introduction
Intuitively, what we need to know depends on what we want
to do: the information we require from the environment will
partially depend on our goals, desires, and intentions. For
example, consider reading a recipe. If I am deciding whether
to make this dish for a friend with a dairy allergy, then I
need to know simply whether the dish contains any milk at
all. If I am instead preparing a shopping list so that I can
later make the dish for myself, then I need to know how
much milk is required, not just whether any at all is
involved. In this paper, we examine the extent to which
learning is responsive to pragmatic goals (e.g. our desire to
succeed at an expected future task).
Many cognitive models of learning assume that
individuals are trying to acquire (approximately) complete
representations of their environments, so pragmatic goals
play essentially no role. For example, most models of causal
learning assume that agents are trying to learn the “true”
causal structure; most models of language learning assume
that people are trying to infer the underlying structure of the
language; and most models of category learning assume
people are trying to acquire conceptual representations that
most closely track the world’s statistical regularities. Under
these models, pragmatic goals play essentially no role in
learning; instead, the learner always tries to acquire a
(relatively) complete and veridical representation of the
world. This representation can later be used for a range of
practical purposes precisely because it is complete and
veridical.

Despite this, previous research suggests that pragmatic
goals do impact learning. For example, people acquire
different categories from identical data when learning
occurs through a categorization task (selecting a category
label based on a set of feature values) vs. a feature inference
task (inferring a feature value given the values of other
features) (e.g., Markman & Ross, 2003; Zhu & Danks,
2007). Also, people learn more in dynamic control tasks
when given a general learning goal (learn about the system)
rather than a specific task (maintain the system at a specific
state) (Burns & Vollmeyer, 2002; Osman & Heyes, 2005).
Tasks have even been found to influence low-level
processes; for instance, negative priming in selective
attention is directed to only task-relevant dimensions of
distractor objects (Frings & Wentura, 2006; Maruff et al.,
1999; Tipper, Weaver, & Houghton, 1994).
While task effects are common, there has been little study
of the extent to which learning is modulated by longer-term
pragmatic goals (vs. the task performed during learning).
Much of everyday learning is driven by the desire to
succeed at an expected future task, and it is possible that
learning is highly responsive to beliefs about how
information will be used in the future. If this is the case, our
models of learning cannot ignore the important role that
pragmatic goals play in many real-world learning situations.
Our central theoretical proposal is that people’s pragmatic
goals direct their learning towards pragmatically relevant
information and, perhaps more importantly, away from
pragmatically irrelevant information. That is, people are
relatively frugal learners who encode only the information
they need: they acquire goal-relevant representations and
ignore goal-irrelevant dimensions of the environment. We
first report experimental results suggesting that people are
relatively frugal when given a concrete, pragmatic goal
(Experiment 1). We then present preliminary evidence about
possible mechanisms underlying this frugality (Experiment
2). We finish by arguing that frugality can be a ‘rational’
strategy that can be reconciled with commonly used models
of rational learning, including Bayesian inference.

Experiment 1
Experiment 1 directly tests whether people display frugal
learning when provided with a concrete, practical goal. The
learning
paradigm
involved
four
buttons
that
probabilistically produced numbers between 1 and 100,
where two of the buttons had relatively high means and two
1

1766

had relatively low means. At the outset, learners were
assigned a task to perform after learning: they had to choose
the button with either the highest (MAX condition) or
lowest average (MIN condition), or else simply report the
mean for each button (Expected Outcome, or EO condition).
If people are frugal learners, then they should learn just
the information necessary for their task and so learn more
about task-relevant contrasts than task-irrelevant ones. For
instance, the critical decision in MAX is which button has
the highest mean. Participants can easily rule out the two
low-mean buttons (since their numbers are much lower than
the other two), and so focus on deciding between the two
high-mean buttons. They should thus be more likely to learn
the rank order of the two high-mean buttons than that of the
two low-mean buttons. Conversely, MIN participants should
be more likely to learn the rank order of the low-mean
buttons than the high-mean ones. For EO participants, each
contrast is equally relevant, so they should learn the rank
orders (and hopefully the values) of all four buttons equally
well. The EO condition thus acts as a control condition to
determine the extent to which participants were able to learn
about the values and rank order in this experiment.

Figure 1: Example learning trial
The button means were 80, 70, 30, and 20, and all had
standard deviation of 9.8.1 The button means varied between
button order conditions to ensure that response differences
were not due to differences in the position or color of the
best/worst buttons. In the B-High (vs. C-High) condition,
the A/B/C/D means were: 30/80/20/70 (vs. 70/20/80/30).

Participants
149 Amazon Mechanical Turk participants (mean age=35.5;
43% female,) were randomly assigned to one goal condition
(MIN/MAX/EO), and one of two button order conditions
(B-High/C-High). Participants received 50 cents for
participation and 50 cents for performance. 29 participants
were excluded based on independent criteria (see Results
section), leaving 120 participants (mean age=36.9; 43%
female) in the final analysis.

Method
Instructions All participants were told that they would be
presented with a set of buttons, and that each button
produced a number between 1 and 100 when pressed. They
were told that the exact number produced by each button
would vary, but that different buttons tended to produce
higher or lower numbers. Participants were then assigned a
task and told that they would be given a bonus based on
their success at that task. In the MAX and MIN conditions,
participants would later press a single button and receive a
bonus dependent on the resulting number: either more if it
was higher (MAX), or more if it was lower (MIN). In the
EO condition, participants would later estimate the average
number produced by each button and receive a bonus based
on the accuracy of their estimates.
Learning Phase The learning phase for all participants
involved passively viewing ten trials in which all buttons
were pressed simultaneously and then the results were
displayed (Figure 1). The buttons were labeled and colored,
and the numbers were displayed in a similarly colored
square. Learning was self-paced, though participants had to
view each trial for a minimum of three seconds.

Testing Phase In the testing phase, all participants (i) chose
between all four buttons in accordance with their goal; (ii)
chose separately between the high and low pairs of buttons,
again in accordance with their goal; and then (iii) estimated
each button’s average. In the EO condition, participants
were randomly assigned to choose the largest or smallest
button for the forced choices in (i) and (ii). Numerical
estimates for (iii) were recorded using a sliding scale
between 1 and 100 with the exact number provided. After
all questions had been answered, participants received
feedback about the accuracy of their performance on
question corresponding to their initial goal, along with the
appropriate bonus.

Results
Exclusion Criteria With Mechanical Turk populations, it is
particularly important to check if participants understood
the instructions and paid attention during the task. We used
two exclusion criteria:
(i) Choice of a clearly suboptimal button (e.g., choice of
µ=20 button in the MAX condition). Every observed
number for the low-mean buttons is less than every
observed number for the high-mean pair, so this
behavior implies the participant did not understand the
instructions or did not pay attention during learning.
(ii) Mean estimate for a ‘goal-relevant button’ (i.e., those
that should be focal given the goal) falling outside of
the ‘acceptable range’ (i.e., more than 5 points outside
of the actual observed range of either button in the
relevant pair2). Mean estimates significantly larger or
smaller than any actually observed value indicate either
comprehension or attentional failure. We used only the
goal-relevant button estimates since lack of attention to
1

Equal standard deviations imply that the optimal choice in
MAX (MIN) is always the button with highest (lowest) mean.
2
[52,100] for high buttons; [2,50] for low buttons.

2

1767

goal-irrelevant buttons could be a deliberate (frugal)
learning strategy.
Twenty-nine participants were excluded (seven from MAX,
nine from MIN, and thirteen from EO).

their means (1=lowest, 4=highest). A two-way multivariate
ANOVA with the number estimates as the dependent
variables and the goal and button order as independent
variables3 revealed a significant multivariate effect of goal
condition (Pillai’s Trace=.44, F(8, 224)=7.90, p<.05); no
significant effect of order (Pillai’s Trace=.07, F(4,
111)=2.17, p=.08), and a significant goal-order interaction
(Pillai’s Trace=.07, F(8, 224)=2.47 p<.05).4 Post-hoc
comparisons were conducted using the Tukey HSD test at
the α=.05 significance level. For the two higher buttons,
MIN participant estimates were significantly lower (and less
accurate) than from MAX and EO participants. There were
no significant differences between estimates for the second
lowest button. For the lowest button, estimates in the MAX
condition were significantly higher (and less accurate) than
those in MIN, but there were no differences between either
of those conditions and the EO condition.

Button Choices Participants made forced choices in
accordance with their goal between (i) all four buttons; (ii-a)
the two highest buttons; and (ii-b) the two lowest buttons.
EO participants were randomly assigned to choose the
largest or smallest each time. For analysis, choices were
recoded as correct or incorrect. No significant differences in
correctness were found between EO participants who chose
largest vs. smallest (Fisher’s Exact Tests: all four buttons
p=1.0; high pair p=.66; low pair p=.72), so they were pooled
for further analyses. There was a significant effect of button
order on the accuracy of choices between all four buttons
(p<.05), but no effect on choices between the high (p=.82)
or low (p=.22) pairs. Only these latter comparisons provide
the critical test for frugal learning, so we pool participants
from the two order conditions in those analyses below.

Table 2: Mean estimates of average number for each of
the four buttons (bold indicates goal-relevance)

Table 1: Percentage of participants choosing the correct
button (goal-relevant choices in bold; * = significantly
different from chance). Chi-Square tests compare correct
choice frequencies for the high vs. low choice sets.

MAX
MIN
EO

% Correct Choices
All
High
Low
77.5* 87.5* 67.5*
97.5* 45.0_ 97.5*
90.0* 85.0* 75.0*

MAX
MIN
EO

Chi-Square
X2
p
26.9
<.05*
4.59
<.05*
1.25
.26

1 (µ=20)
27.7
19.6
23.2

2 (µ=30)
31.9
28.2
31.9

3 (µ=70)
68.9
60.6
70.0

4 (µ=80)
76.7
62.1
76.8

Table 3: Mean differences between estimates (bold
indicates goal-relevance)
MAX
MIN
EO

Table 1 shows the percentages of correct choices for each
choice set and goal condition. Participants in all conditions
did significantly better than chance at choosing from all
buttons (MAX: X2(1, N=40)=12.1, p<.05; MIN: X2(1,
N=40)=36.1, p<.05; EO: X2(1, N=40)=25.6, p<.05). They
also were better than chance for choices involving goalrelevant pairs (high for MAX: X2(1, N=40)=22.5, p<.05; low
for MIN: X2(1, N=40)=36.1, p<.05; both for EO: high: X2(1,
N=40)=19.6, p<.05; low: X2(1, N=40)=10.0, p<.05).
Performance on goal-irrelevant pairs varied; choices for the
low pair in MAX were significantly better than chance
(X2(1, N=40)=8.1, p<.05), but choices for the high pair in
MIN were not (X2(1, N=40)=0.4, p=.53). It appears that at
least some MAX participants learned goal-irrelevant
information, while MIN participants did not. Crucially,
participants in both conditions extracted more information
about goal-relevant than goal-irrelevant buttons: they were
significantly more accurate at choice for the goal-relevant
pair than the goal-irrelevant pair (MAX: X2(1, N=80)=4.59,
p<.05; MIN: X2(1, N=80)=26.9, p<.05). In contrast, no
significant difference between choice performance was
found in the EO condition (X2(1, N=80)=1.25, p=.264).

Low pair (2 – 1)
4.2
8.6
8.7

High pair (4 – 3)
7.8
1.4
6.9

It is somewhat informative that estimates were generally
more accurate for goal-relevant buttons than goal-irrelevant
ones, but we are more interested in whether people learned
about differences between the buttons in each pair, goalrelevant and goal-irrelevant. (We assume that both
differences are goal-relevant in the EO condition.) Table 3
gives mean differences between estimates for the high-mean
buttons (4-3) and for the low-mean buttons (2-1). A twoway multivariate ANOVA with the differences as dependent
variables yielded a significant main effect of goal condition
(Pillai’s Trace=.14, F(4, 228)=4.21, p<.05), but no order
(Pillai’s Trace=.01, F(2, 113)=.28, p=.76) or interaction
effects (Pillai’s Trace=.02, F(4, 228)=.55, p=.699).
3

Estimates Mean number estimates are displayed in Table 2;
the button labels were recoded to reflect the rank order of

A MANOVA of only the EO condition revealed no significant
differences in mean estimates of participants instructed to choose
high vs. low buttons (Pillai’s Trace = .182, F(4, 33)= 1.83 p=.146),
so these participants are pooled for all further analyses.
4
Estimates were significantly lower for goal-irrelevant buttons
in B-HIGH vs. C-HIGH, regardless of whether the goal-irrelevant
buttons were high or low. It is quite unclear what might underlie
such a difference. More importantly, this interaction does not
affect the estimated difference between these two buttons, and thus
should not influence the substance of our findings.

3

1768

Post-hoc comparisons (Tukey HSD with α=.05) showed
that MIN participants reported a significantly smaller
difference between the high-mean buttons than MAX and
EO participants (between whom there was no significant
difference). In contrast, MAX participants reported a
significantly smaller contrast between the low-mean buttons
than MIN and EO participants (between whom there was no
significant difference). Thus the goal-relevance of the
buttons had a significant effect on the difference that
participants perceived (or failed to perceive) between them.
Paired t-tests revealed a significant difference between
estimates for the two low-mean buttons in the MAX
condition (t(39)=2.80, p<.05), but no significant difference
between the estimates for the two high-mean buttons in the
MIN condition (t(39)=0.77, p=.45) reinforcing the
conclusion that MAX participants learned some goalirrelevant information whereas MIN participants did not.

This asymmetry suggests that there may be conditions that
encourage frugality. For example, the MIN condition might
be more cognitively demanding than the MAX condition, as
people might be more used to tracking large numbers than
small ones (since higher numbers are usually better).
This experiment demonstrated that people are relatively
frugal learners, but also left open the question of the
mechanisms underlying this process. A particularly
intriguing question is whether it occurs because of how
learners allocate attention, because of how they reason and
make inferences, or both. Experiment 2 attempts to
distinguish between these distinct possibilities.

Experiment 2

Discussion
Both participants’ choices and estimates of the button
means revealed a significant influence of goal on learning.
Participants in the MAX condition learned more about the
higher buttons than the lower ones, although they still
appeared to learn some information about the difference
between the two lower buttons. Participants in the MIN
condition learned more about the lower buttons than the
higher buttons, and this asymmetry was so strong that they
were at chance when choosing between the higher buttons
and their estimates of the two button means were not
significantly different. Moreover, participants in the EO
condition learned the contrasts between both the high and
low buttons, so relatively ‘complete’ learning was possible
given the evidence. The evidence thus seems to be that
people are at least somewhat frugal: they learn more goalrelevant than goal-irrelevant information.
This finding cannot be due simply to task familiarity, in
which participants perform better because of repeated
practice or advance knowledge of the task. Participants in
the EO condition did not know that they would have to
make forced choices, and yet performed well. Similarly,
participants in the MIN and MAX conditions did not know
they would have to estimate the average outcomes, yet they
performed quite well at reporting goal-relevant button
features. It appears that people focus on information
relevant for achieving their goal, and can then use that
information in a variety of ways. In contrast, they do not
collect (as much) information about goal-irrelevant features.
Substantial further questions remain about the extent of
frugality in learning, the conditions (if any) that enhance or
mitigate frugality, and the mechanisms that drive this effect.
The results of this experiment are mixed on the extent of
frugality. MAX participants appeared to be moderately
frugal, as they learned some goal-irrelevant information but
certainly less than was possible (as evidenced by the
performance of the EO participants). In contrast, MIN
participants appeared to be more radically frugal, learning
little more than the information necessary for their goal.

This experiment aimed to test whether goal effects are
mediated purely by attention allocation, or also because of
differences in reasoning about the goal-relevant objects. We
used the same learning paradigm as Experiment 1, though
with only MAX and MIN goal conditions. In addition, there
were two task conditions that required different information
for successful completion of the task. In the ONE condition,
participants had to choose a single button in testing (as in
Experiment 1), so should try to identify the single highest or
lowest button. In the MANY condition, participants could
choose multiple buttons, and so they should identify all
buttons with average higher/lower than 50. That is, ONE
required people to learn rank order but not average value,
while MANY required the people to learn (very rough)
averages, but not ranks.
Both ONE and MANY require attention on the same
buttons (high-mean in MAX, low-mean in MIN), and so
attention allocation should be the same. Thus, if goaldirected learning is due solely to attention modulation, then
learning should be the same in the two conditions. However,
if goal-directed learning involves goal-directed reasoning or
encoding during learning, then MANY participants should
learn less about the difference between the average values
for the goal-relevant buttons, as that difference is irrelevant
to that goal.

Participants
96 Mechanical Turk participants (mean age=36.0; 46%
female) were randomly assigned to a goal (MIN/MAX) and
task condition (ONE/MANY). Participants were paid 50
cents for participation and 50 cents based on performance.
16 participants were excluded (see Results below), leaving
80 participants (mean age=36.8; 47% female) for analysis.

Method
Instructions were identical to Experiment 1, except that
participants were told that they would be paid based on the
amount that the final button outcome was higher/lower than
50. In the MANY condition, participants were also told they
would be able to press as many buttons as they wished.
The learning phase was identical to Experiment 1, except
that all participants were assigned to the B-High button
order. The critical test in this experiment is between the
4

1769

ONE and MANY participants within each goal condition
(MAX/MIN), so controlling for button order between goal
conditions was unnecessary. The only difference in the
testing phase was that participants in the MANY condition
were able to select more than one button in the four-button
forced choice.

Table 6: Mean differences between estimates (bold indicates
goal-relevance)
MAX-ONE
MAX-MANY
MIN-ONE
MIN-MANY

Results & Discussion
Exclusion Criteria The same exclusion criteria were used.
16 participants were excluded from analysis (one from
MAX-ONE, one from MAX-MANY, nine from MIN-ONE,
and five from MIN-MANY). The asymmetry in exclusion
numbers suggests that the MIN conditions yielded less
comprehension or less diligence. However, the critical
comparisons are within, rather than across, goal conditions,
and so this asymmetry should not impact the results.
Button Choices Table 4 compares the percentage of correct
button choices for each goal and button pair in the ONE and
MANY conditions. Chi Square tests (right hand column)
revealed no significant differences between these
conditions, even when the choice was goal-relevant in the
ONE condition but not the MANY condition (e.g. high pair
for MAX, low pair for MIN).
Table 4: Percentage of participants choosing the correct
button (* if sig. different than chance, bold if goal-relevant).

MAX
MIN

high pair
low pair
high pair
low pair

% Correct Choices
ONE
MANY
90.0*
85.0*
75.0*
60.0
60.0
70.0
80.0*
70.0

Chi-Square
X2
p
0.23
.63
1.03
.31
0.44
.51
0.06
.81

Estimates The mean number estimates are shown in Table
5. A two-way multivariate ANOVA with number estimates
as the dependent variables and the goal and test task as the
independent variables revealed a significant multivariate
effect of goal (Pillai’s Trace=.26, F(4, 73)=6.47, p<.05), but
no significant effect of task (Pillai’s Trace=.06, F(4,
73)=1.12, p=.36) and no interaction (Pillai’s Trace=.02, F(4,
73)=0.45, p=.36), suggesting that task type did not have an
effect on the participant’s judgments.
Table 5: Mean estimates of average number for each of
the four buttons (bold indicates goal-relevance)
MAX-ONE
MAX-MANY
MIN-ONE
MIN-MANY

1 (µ=20)
23.4
25.0
19.1
22.7

2 (µ=30)
29.5
28.4
27.6
30.0

3 (µ=70)
68.1
69.8
64.2
68.0

4 (µ=80)
76.4
75.9
66.7
62.6

Low pair (2 – 1)
6.1
3.4
8.5
7.3

High pair (4 – 3)
8.3
6.1
2.5
-5.4

As in Experiment 1, the critical comparison is whether
participants learned the difference between buttons within
the high and low pairs (see Table 6). A two-way
multivariate ANOVA with the two comparison variables (43 and 2-1) revealed a significant effect of goal (Pillai’s
Trace=.17, F(2, 83)=8.36, p<.05), but no task (Pillai’s
Trace=.05, F(2, 83)=2.15, p=.12) or interaction (Pillai’s
Trace=.02, F(2, 83)=0.81, p=.45) effects, which reinforces
the conclusion that participants learned differently between
the two goals, but not between the two test phase tasks.
Discussion The results of Experiment 2 suggest that goaldependence of learning arises principally because of
attention allocation. We did not find evidence of differential
information processing or encoding after attention has been
allocated. Instead, it appears that people encode and process
the button information similarly whenever the button is
goal-relevant. That is, Experiment 2 is suggestive that a key
mechanism in the goal-dependence of learning is attention
allocation, with people focusing on the goal-relevant
information. Of course, drawing any conclusions from a null
result is difficult, and more experiments are clearly
necessary before any general conclusions can be reached.
Nevertheless, these results suggest that attention plays a key
(and perhaps essential) role in the influences of goals.

General Discussion and Conclusion
These experiments clearly demonstrate that people’s longerterm goals (i.e., not just learning tasks) influence their
learning. Experiment 1 showed that people are relatively
frugal about what they learn: they represent goal-relevant
information significantly more accurately than goalirrelevant information. However, this frugality is not
absolute, as the results of Experiment 2 (and some results in
Experiment 1) suggest that people sometimes acquire richer
representations than are strictly necessary for task success.
Experiment 2 suggests that attention allocation plays a key
role in goal-dependent learning, but that goal-relevant
reasoning does not (at least, in this context). Other factors
remain to be investigated: perhaps frugality occurs only
under high cognitive load, or perhaps involves differential
processing in more complex domains. We are far from
understanding the conditions and mechanisms responsible
for frugal learning. However, the experiments presented
here suggest that this is an area ripe for future research.
To the extent that people are frugal in their learning, this
poses a significant challenge to the widespread practice of
focusing on cognitive models that assume people have
5

1770

purely epistemic goals (e.g., most rational models of
learning and reasoning). However, it is not clear whether
this is an inherent weakness of these modeling paradigms,
or a byproduct of the lack of attention paid to pragmatic
goals in current learning research. Most models of ‘rational’
learning are silent on the normative question of how goals
should influence learning, and instead focus on how people
should make inferences in order to arrive at true (or at least
justified) conclusions. Bayesian inference provides a clear
(and influential) example, but our discussion here applies
equally well to any axiomatic theory of rationality (e.g.
deductive inference).
Bayesian models (Oaksford & Chater, 2007; Griffiths,
Kemp, & Tenenbaum, 2008) assume that learners (i) have
degrees of belief that are compatible with a probability
distribution over a set of mutually exclusive and exhaustive
hypotheses; and (ii) update this belief distribution by
conditioning on new evidence. Crucially, the Bayesian
updating procedure (Bayes’s Rule) is goal-invariant; its
behavior depends only on the prior probabilities of the
hypotheses and the probabilities of the evidence conditional
on each possible hypothesis. The Bayesian model assumes
that learners are only trying to determine the most probable
hypothesis (or hypotheses) from among the previously
specified possibilities. Thus, non-epistemic goals can
influence learning only through the initial specification of a
hypothesis space, or in the assignment of prior probabilities.
Standard practice in Bayesian models of psychological
phenomena is to use a hypothesis space covering all
possible distinctions (e.g., all possible causal structures, all
possible category schemes, etc.), but this choice is decidedly
non-frugal and perhaps even sub-optimal. In the (very) long
run, selecting a hypothesis space with maximally many
distinctions will ensure that you learn as much as you can
from the evidence. In the short run, however, such a space
may be detrimental because it can increase the variance of
the learning method and make overfitting more likely (for
an extended discussion see Wellen & Danks, under review).
An alternative is to use a hypothesis space that contains
only goal-relevant distinctions. For instance, suppose you
are a participant in Experiment 1 and your goal is to choose
the button that produces the highest number. In this case, the
hypothesis space need only distinguish between ‘worlds’
with different highest mean buttons. It need not encode the
precise means or even the rank order of the suboptimal
buttons; these are all irrelevant to the test phase choice. A
frugal Bayesian learner could thus select a hypothesis space
H with variation on only the relevant dimension, such as: H
= {a is best, b is best, c is best, d is best}. In the Bayesian
framework, however, the choice of hypothesis space occurs
before the model can be applied. Hence, although frugality
can be captured indirectly, it requires conceptual resources
from outside the model.
There are thus ways to (try to) incorporate non-epistemic
goals in those models, but that theoretical work remains to
be done. More generally, we conjecture that many standard
models of learning can incorporate goal effects only through

the way that they represent the learning problem (e.g., the
assumed hypothesis space). If that is correct, then any
attempts to model goal effects in learning will be forced to
include aspects of the situation that have previously been
simply stipulated by the theoretician (see also Wellen &
Danks, under review). Moreover, there is likely to be a
complex interaction between prior beliefs, goals, and
evidence, which will further complicate matters. Of course,
we are far from understanding how these (and other) factors
interact to influence learning, but this paper provides some
initial empirical constraints.

Acknowledgments
This research was partially supported by a James S.
McDonnell Foundation Scholar Award to DD.

References
Burns, B. D., & Vollmeyer, R. (2002). Goal specificity
effects on hypothesis testing in problem solving.
Quarterly Journal of Experimental Psychology, 55, 241261
Frings, C. & Wentura, D. (2006). Negative priming is
stronger for task-relevant dimensions: Evidence of
flexibility in the selective ignoring of distractor
information. Quarterly Journal of Experimental
Psychology, 59(4), 683-693.
Griffiths, T. L., Kemp, C., & Tenenbaum, J. B. (2008).
Bayesian models of cognition. Cambridge handbook of
computational cognitive modeling, 59-100.
Markman, A. B., & Ross, B. H. (2003). Category use and
category learning. Psychological bulletin, 129(4), 592.
Maruff, P., Danckert, J., Camplin, G., & Currie, J. (1999)
Behavioural goals constrain the selection of visual
information. Psychological Science, 10(6), 522-525.
Oaksford, M., & Chater, N. (2007). Bayesian rationality:
The probabilistic approach to human reasoning. Oxford
University Press, USA.
Osman, M., & Hayes, C. (2005). Practice doesn’t always
make perfect: Goal induced decrements in the accuracy of
action- and observation-based problem solving. In B. G.
Bara, L. Barsalou, & M. Bucciarelli (Eds.), Proceedings
of the 27th Annual Conference of the Cognitive Science
Society (pp. 1690-1695). Stresa, Italy: Cognitive Science
Society.
Tipper, S. P., Weaver, B., Houghton, G. (1994) Behavioural
goals determine inhibitory mechanisms of selective
attention. The Quarterly Journal of Experimental
Psychology Section A: Human Experimental Psychology,
47(4), 809-840.
Wellen, S., & Danks, D. (under review) Adaptively rational
learning. Manuscript submitted for publication.
Zhu, H., & Danks, D. (2007). Task influences on category
learning. In D. S. McNamara & J. G. Trafton (Eds.),
Proceedings of the 29th annual meeting of the cognitive
science society (pp. 1677-1682). Austin, TX: Cognitive
Science Society.
6

1771

