UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Spatial Reasoning: the Effect of Training for Adults and Children

Permalink
https://escholarship.org/uc/item/5507v4gm

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Schaeken, Walter
Breugelmans, Veerle
Janssens, Leen

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Spatial Reasoning:
the Effect of Training for Adults and Children
Walter Schaeken (walter.schaeken@ppw.kuleuven.be)
Department of Psychology, University of Leuven, Tiensestraat 102
B-3000 Leuven, Belgium

Veerle Breugelmans (veerlebreugelmans@msn.com)
Department of Psychology, University of Leuven, Tiensestraat 102
B-3000 Leuven, Belgium

Leen Janssens (leen.janssens@pww.kuleuven.be)
Department of Psychology, University of Leuven, Tiensestraat 102
B-3000 Leuven, Belgium

putative conclusion (the conclusion validation stage). If one
finds such a model, one returns to the second stage. If one
doesn’t find such a model, the putative conclusion is
accepted as a valid conclusion.
Consider the following problem:

Abstract
The mental models theory of relational reasoning postulates
that individuals reason by constructing the possible models of
the situation described by the premises. The present article
reports two experiments about spatial relational reasoning and
focuses on the possibility of training In Experiment 1, we
compared two different training methods, one in line with the
mental models theory and one in line with the rule-based
account Both accuracy and training data supported the mental
models theory. In Experiment 2, we compared different
training methods for children. Again, results were in line with
the mental models theory.

Problem 1:

Keywords: mental models theory; spatial reasoning; training

Introduction
Many daily deductions depend on relations between things.
Suppose you want to pile up some boxes on a shelf. Your
partner gives you the following information:
Box A is heavier than Box B.
Box C is lighter than Box B.
On the basis of this information, you can infer that Box A is
heavier than Box C. For some problems, people can easily
make such relational inferences, but for some other
problems they regularly make mistakes. This paper reports
two experiments, one with adults and one with children. The
focus is on a specific form of relational reasoning, that is
spatial reasoning, and on how we can improve spatial
reasoning by training.
There has been considerable controversy over how people
deal with spatial deductions. Byrne and Johnson-Laird
(1989) contrasted experimentally a rule-based theory and
the mental models theory. According to the account based
on the mental models theory (Johnson-Laird, 1983), one
first constructs a model of the meaning of the premises (the
model construction stage). Next, one formulates a putative
conclusion on the basis of this model (the conclusion
construction stage). Finally, one searches for a falsifying
model, that is, a model that is consistent with the
information in the premises, but inconsistent with the

A is to the left of B
B is to the left of C
D is in front of A
E is in front of C
What is the relation between D and E?
According to the mental models theory (Byrne & JohnsonLaird, 1989), first one should construct the following model:
A
B
C
D
E
On the basis of this model, one can infer that “D is to the
left of E” (or “E is to the right of D”). Next, one tries to
falsify this initial conclusion by attempting to build another
model compatible with the premises. Because there is not
such a model, Problem 1 is called a one-model problem.
The initial conclusion can be considered as the final
conclusion.
Consider now Problems 2 and 3 with the same question as
for Problem 1:
Problem 2:
Problem 3:
A is to the left of B
A is to the left of B
C is to the left of B
C is to the left of B
D is in front of C
D is in front of C
E is in front of B
E is in front of A
For Problem 2, a first model can be built,
C
A
B
D
E
which supports the conclusion “D is to the left of E”. In
contrast with Problem 1, another model is compatible with
the premises:
A
C
B
D
E

2423

However, both models support the same conclusion “D is to
the left of E”. Problem 2 is a multiple-model-problem. For
Problem 3, there are also two models, but now these two
models lead to contradictory conclusions:
C
A
B
D
E
A
C
B
E
D
Consequently, there is no determinate answer and Problem
3 is called a problem-with-no-valid-answer. According to
the mental models theory, Problem 2 should be more
difficult than Problem 1 because it is harder to deal with two
models than with one model. Moreover, Problem 3 should
be more difficult than Problem 2 because it necessarily calls
for the construction of two models in order to reach the
correct answer.
A rule-based approach as framed in Hagert (1984) should
make the opposite prediction with respect to one-model and
multiple-model-problems. In order to solve Problem 1, one
must infer the relation between the pair of items to which
the two items in the question (D and E) are directly related.
To make this inference, one must use a meaning postulate
that captures the transitivity of the relations in the premises:
If x is to the left of y, and y is to the left of z, then x is to the
left of z. Multiple-model-problems, such as Problem 2, do
not require the use of such a meaning postulate. The first
premise is irrelevant, and the second explicitly shows the
relation between the pair of items to which D and E are
related. Therefore, according to the rule-based theory of
Hagert (1984), Problem 2 should be easier than Problem 1.
No evidence was found for the latter prediction. Instead, the
predictions of the mental models theory have been
supported in a number of other studies using different types
of relational premises, that is, spatial (Carreiras &
Santamaria, 1997; Roberts, 2000, Vandierendonck & De
Vooght, 1996), temporal (Schaeken, Johnson-Laird &
d’Ydewalle, 1996a; 1996b; Schaeken, Girotto & JohnsonLaird, 1998; Schaeken & Johnson-Laird, 2000;
Vandierendonck & De Vooght, 1996) and abstract relational
premises (Carreiras & Santamaria, 1997). Van der Henst
(1999, 2002; Van der Henst & Schaeken, 2005; see also
Schaeken, Van der Henst, & Schroyens, 2007) presented
somewhat mixed results.
It is one thing to investigate the original performance of
reasoners. It is, however, another thing to investigate
whether their original accuracy can be increased. In a
review, Klauer and Meiser (2007) convincingly showed that
deductive reasoning can be trained. They reported training
gains in propositional and syllogistic reasoning. Successful
training was often focused on improving the semantic
understanding, whereas syntactic approaches showed in
general less evidence for training gains. In a semantic
training, one tries to support or improve the construction
and explication of the representation of the possible
situations. In a syntactic training, one trains one or more

syntactic inference rules, which would drive the underlying
reasoning processes.
Johnson-Laird (2006) developed a practical training
method for the mental models theory that takes only a few
minutes to learn. This model method consists of one
command: Try to construct all the possibilities consistent
with the given information. Participants learned how to
operationalize this command by drawing a diagram
designed to keep track of the different possibilities.
The experiments in Johnson-Laird (2006) with
conditionals, biconditionals and disjunctions show that the
model method, even though it takes only a few minutes to
teach, has robust effects on both the accuracy and speed of
reasoning. The crucial aspect seems to be that it helps
individuals to bear in mind the alternative possibilities
compatible with the premises. To our knowledge, however,
no training methods for spatial reasoning have been tested.
In this article, we aim to compare different methods and to
include a developmental dimension.

Experiment 1
We developed two different trainings, one in line with the
mental models theory and one in line with the rule-based
account. Klauer and Meiser (2007) argued that training
conditions for the mental models theory might practice the
construction of appropriate models of the premises and the
training conditions might aim at optimizing the required
operations that must be performed on the constructed mental
models. The method of Johnson-Laird (2006) is perfectly in
line with this. Therefore, we developed a variant of this
successful training method, which we focused on spatial
reasoning problems. For the formal rules theory, training
conditions might support the interpretative process and they
might enhance the accessibility and application of required
inference rules (Klauer & Meiser, 2007). With a formal
training, we opted to enhance the accessibility of the
meaning postulate that captures the transitivity of the
relations in the premises.

Method
Participants A total of 48 adults participated in the
experiment. They were all psychology students at the
University of Leuven and participated as part of a course
requirement. They had not received any training in logic.
Design The crucial and between-subjects manipulation
consisted in the variation of the training. One group
received a spatial mental models training, one group a
formal training and one group received no training.
Material and Procedure The participants were tested in
three different groups, one for each training condition and
one for the control group. The participants carried out three
sorts of problems. The three sorts of problem were as
follows: one-model-problems, multiple-model-problems,
and problems-with-no-valid-answers.

2424

The participants carried out four versions of each of the
three different sorts of problems, making a total of 12 trials.
The four versions were constructed in the following way:
The first two premises contained either the spatial relation
'to the left of' or else the spatial relation 'to the right of'; for
half the problems, the first object in the question was to the
left of the second object and for half the problems, this was
the opposite. All the problems had a different content
(although all problems were about fruits on a table), and
they were presented in a different random order to each
participant. The instructions were presented on the first page
of the booklet. They explained that the participants' task was
to answer a question based on the information in the
preceding assertions, and that the answers should be those
that must be true given the truth of the previous assertions.
If the participants thought that there was no definite answer
to the question, they had to write that as their conclusion.
Each problem was on a separate page of the booklet and the
experiment was conducted in Dutch.
There were two sorts of training. In the spatial model
training, an instructor solved two problems in front of the
participants. The first problem was a one-model-problem
with a valid conclusion based on two premises:
The Apple is to the right of the Banana.
The Pear is to the right of the Apple.
What is the spatial relation between the Banana
and the Pear?
The instructor read the first premise and drew the spatial
relation on the blackboard, using the first letters of the
pieces of fruit. Next, she read the second premise and added
the piece of fruit. This resulted in the following drawing:
B
A
P
After this, the instructor read the question and concluded:
“therefore, the banana is to the left of the Pear”. Finally, she
asked if everyone agreed and she waited until everyone said
“yes”.
Next, she started with the second training problem, a
problem-with-no-valid-answer:
The Kiwi is to the right of the Cherry.
The Orange is to the right of the Cherry.
What is the spatial relation between the Kiwi and
the Orange?
She read the first premise and drew the spatial relation.
Then, she read the second premise, placed the Orange to the
right of the Kiwi and explicitly said: “Oh, is this the only
place I can place the Orange? Oh no, there is a second
possibility, I can place the Orange also in between the Kiwi
and the Cherry.” After that, she drew these two possibilities:
C
K
O
and
C
O
K
The instructor read the question, showed that the
participants had to look to the two possibilities and pointed
out that the correct answer is “you cannot know what the
relation is between the Kiwi and the Orange”. Next she
asked if everyone agreed and she waited until everyone said
“yes”.

In the formal training, participants were confronted with
the two same training problems. When they read the first
problem, the instructor said “we know spatial relations are
transitive, that is, if A is to the left of B, and B is to the left
of C, then A is to the left of C. Let’s look if we can use this
transitivity rule for the current problem.” The instructor
showed that it could be applied, formulated the correct
answer and asked if everyone agreed. Next, she presented
the second problem, showed that the transitivity rule could
not be applied and produced the correct answer that “you
cannot know what the relation is between the Kiwi and the
Orange”. Again she asked if everyone agreed.
In the no-training group participants were just handed the
booklets without being given any further information, apart
from the regular instructions.

Results and Discussion
Table 1 presents the percentages of correct responses to the
different sorts of problems. We performed a repeated
measures ANOVA which resulted in a significant main
effect of the within variable Problem Type (F(2, 90) =
12.296, p < .0005). Fisher LSD Post-Hoc Tests show that
one-model-problems are significantly easier than multiplemodel-problems (90.3% versus 63.2%, p < .00001) and
problems-with-no-valid-answers (90.3% versus 68.8%, p <
.0005). The two sorts of multiple-model-problems did not
differ significantly from each other.
Table 1: The percentages of correct responses in Experiment
1 for the three sorts of problems and the three conditions.

Control
Spatial Training
Formal Training

1M
90
94
88

MM
58
83
48

NVC
54
77
75

There was a significant main effect of the between variable
Training (F(2,45) = 5.6276, p < .01). Fisher LSD Post-Hoc
Tests show that in the condition with spatial model training
participants solved more problems correct than in the
control condition (84.7% versus 67%, p < .005) and in the
condition with the formal training (84.7% versus 70.1%, p <
.05). The control condition and the formal training condition
did not differ from each other.
The interaction between Training and Problem Type was
marginally significant (F(4, 90) = 2.4147, p = .05458).
Fisher LSD Post-Hoc Tests show that there was no
difference between the three conditions for the one-modelproblems. For the multiple-model-problems, however,
participants in the spatial model training condition were
significantly more accurate than participants in the control
condition and the formal training condition (83.3% vs
58.3%; p < .0005; 83.3% vs 48.2, p < .0005). The difference
between the control condition and the formal training
condition was not significant. For the problems-with-novalid-answer, participants in both training conditions were
significantly more accurate than those in the control

2425

condition: 77.1% vs 54.2% for the spatial model training (p
< .05) and 75% vs 54.2% for the formal training (p < .05).
Hence, regarding the difference between the three sorts of
problems, we confirmed the mental models theory
prediction that one-model-problems are the easiest. We did
not observe a difference between multiple-model-problems
and problems-with-no-valid-answer. However, this lack of a
difference is also observed in some other studies and is not
really problematic for the mental models theory. Multiplemodel-problems are especially easier than problems-withno-valid-answer if reasoners construct only one of the
models. In that situation, they can still formulate the correct
response for a multiple-model-problem, but they will draw
an erroneous conclusion for a problem-with-no-validanswer. Of course, when reasoners construct both models
for the two sorts of problems, the difference is not expected
to be big.
Regarding the training, the spatial models training led to
the best performance. This observation extends the
beneficial effect of the model training (Johnson-Laird,
2004) to spatial reasoning. The spatial model training led to
an overall improvement and in more detail, after the model
training participants were more accurate on both the
multiple-model-problems and the problems-with-no-validanswer compared to the control condition. The latter
problems were solved better in the formal training
condition. However, for the multiple-model-problems the
trend was in the opposite direction: after formal training
participants were less accurate. It seems that they correctly
observed that they could not use the transitivity meaning
postulate for these multiple-model-problems, but next
inferred incorrectly from this that there was no valid
conclusion. One could argue that the formal training was a
bit ambiguous: by stressing the importance of the
transitivity meaning postulate, it disfavoured the multiplemodel-problems. However, if that’s the case, one could say
the same for the spatial model training: Indeed constructing
two models is only vital for the problems-with-no-validanswer.

Experiment 2
Experiment 1 established that a mental model training
improved spatial reasoning for adults. Would such a training
have a similar effect with children, who have less working
memory capacities? That is the aim of Experiment 2.
Moreover, we wanted to test the boundaries of successful
training in more detail. Therefore we developed three
versions of the mental model training: (1) the one used in
Experiment 1, (2) a very short version and (3) one that did
not have spatial problems as the training problems. The
short version is one where the children were only told that
they would perform better when they would draw all
possibilities for the problems. In the more distant training,
the children were still trained in thinking of all possibilities
but the specific problems presented were disjunctions
instead of spatial problems. Finally, we dropped the formal
training. This type of training only had a weak effect in

Experiment 1, that is, only an effect on the problems-withno-valid-answer. Moreover, we believed that a term as
“transitivity” would be too difficult for children to
understand and because of the lack of clear effects in
Experiment 1. We acknowledge that we cannot rule out that
this might partly explain the lack of other formal training
effects in Experiment 1, although none of the participants
mentioned this.

Method
Participants A total of 179 children from an elementary
school participated in Experiment 2. Eighty-three children
were nine years old (M: 9.1, SD: 0.3) and 86 were 11 years
old (M: 10.9, SD: .27).
Design, Material and Procedure The participants were
tested in four different groups, one for each training
condition and one for the control group. They solved the
same problems as the adults in Experiment 1. However, the
question was a little bit different (“which object was the
most to the left/right?”) and the children did not have to
produce their answer themselves but could select the correct
answer between four options: the correct fruit, the wrong
one, you cannot decide, and I don’t know.
The spatial training was almost the same as in
Experiment 1, except that the instructor read the question
and showed the children where they had to look for the
answer (i.e., to the left or to the right of the drawing).
In the short-tip training, the children simply read on the
first page of the booklet the following: “before you start, we
give you a tip. It’s a simple one, but we know the tip works
if you use it well: try to draw all possible solutions for the
problems. This will help you to find the correct answer.”
In the more distant training, the children received the
training developed by Johnson-Laird (2004). The first
problem was:
Mister Adams is teaching or mister Peters is
teaching or both are teaching.
If Mister Peters is not teaching, then Mister Jones
is teaching.
Mister Jones is not teaching.
As in Johnson-Laird (2004) all possibilities were drawn
sequentially on the blackboard. This is the result after
Premise 1 and 2:
1
2
3
Mister A
Mister P
Mister A & P
Mister J
Next, the instructor focused on Premise 3 and explained that
this premise rules out the first possibility. She therefore
crossed possibility 1 and said that one could conclude that
“Mister Peters definitely is teaching and that Mister Adams
might be teaching”.

2426

Results
Table 2: The percentages of correct responses in Experiment
2 for the three sorts of problems, the four conditions and the
two age groups.

Control

9y
60

1M
11y
85

9y
62

MM
11y
82

9y
12

NVC
11y
56

Spatial
training

61

80

69

80

36

70

Short
tip

63

74

64

75

34

28

More
distant

43

81

52

66

29

54

Table 2 presents the percentages of correct responses to the
different sorts of problems.We performed We performed a
repeated measures ANOVA which resulted in a significant
main effect of the between variable age (F(1, 172) = 37.270,
p < .000001): the 11-year-olds were significantly more
accurate than the 9-year-olds (69% versus 49%). There was
also a significant main effect of the within variable Problem
type (F(2, 344) = 57.902, p < .000001). Fisher LSD PostHoc Tests show that problems-with-no-valid-answer are
significantly more difficult than multiple-model-problems
(41% versus 69%, p < .000001) and one-model-problems
(41% versus 69%, p < .000001).
There was no significant main effect of the between
variable Training, but there was a significant interaction
between Training and Problem Type (F(6, 344) = 2.9194, p
< .01). Fisher LSD Post-Hoc Tests show that there is no
difference between the different training conditions for the
one-model and the multiple-model-problems. However,
there is a significant difference for the problems-with-novalid-answer: The children performed significantly better
when they received spatial training in comparison with no
training (54% versus 36%; p = .05) and in comparison with
a short tip (54% versus 36%; p < .01).
Finally, there was a three-way interaction between Age,
Problem Type and Training (F(6, 344) = 2.2727, < .05).
Fisher LSD Post-Hoc Tests show that for the nine-year old
children, there is only a significant difference for the
problems-with-no-valid-answer: the condition with spatial
training is significantly better than the condition with no
training (36% vs 12%; p < .05). For the eleven-year old
children, we observed a bad performance for the problemswith-no-valid-answer in the short tip condition: this
condition is significantly worse than the condition with no
training (28% versus 56%, p < .05), spatial training (28%
versus 70%, p < .0005) and with more distant-training (28%
versus 54%, p < .05). When one looks at the condition with
no training, the nine-year-olds perform worse than the

eleven-year-olds on the one-model-problems and the
problems-with-no-valid-answer (respectively 60% versus
85%, p = .026263 and 12% versus 56%, p < .0005). For the
multiple-model-problems, the results are in the same
direction, but only marginally significant (62% versus 82%,
p = .079343).
Hence, regarding the difference between the three sorts of
problems, we confirmed the mental models theory
prediction that problems-with-no-valid-answer are the most
difficult ones. We did not observe a difference between onemodel-problems and multiple-model-problems. These
findings seem to indicate that children just construct one
model: That’s enough for solving the one-model and
multiple-model-problems correctly, but not for the
problems-with-no-valid-answer. This is in line with other
developmental findings (see e.g; Markovits & Barrouillet,
2002).
Regarding age, it was also observed that eleven-year-olds
performed better, especially on the one-model-problems and
the problems with no-valid-conclusion. One explanation
might be more working memory capacity (see ). However,
increased fluency, processing fluency or some other
executive function might cause this effect. Further research
should elucidate this effect.
Regarding the training, as for the adults, the spatial
models training led to the best performance, especially on
the problems-with-no-valid-answer. The other trainings
were less effective. For the eleven-year old children, we
observed an unexpected bad performance for the problemswith-no-valid-answer in the short tip condition. Further
research has to clarify why this was a worse training
condition for the eleven-year-olds in comparison with the
nine-year-olds.

General Discussion
The aim of the present paper was twofold: First we wanted
to shed light on the debate between the mental models
theory and the rule-based approach on the way people
reason with spatial deductions. Secondly, it was tested
whether the accuracy on spatial reasoning problems can be
enhanced by training. More specifically, the efficiency of
the “model method” was compared to other training
methods.
The results are supportive for the mental models theory,
whereas no real support for the rule-based approach is
observed: One-model-problems are easier than multiplemodel-problems and older children perform better than
younger children. Moreover, the experiments show the
beneficial effect of model training over other types of
training on spatial reasoning for adults. In Experiment 2 it
was shown that the spatial mental model training is also
beneficial for children.
Nevertheless, we admit that more research is definitely
necessary. As we mentioned already, a term as “transitivity”
might have been too difficult to understand, even for the
university students in the first experiment. Moreover, some
rule-based theorists do not claim that mental rules are

2427

accessible consciously. Rips (1994), for instance, argues
that mental rules operate automatically once certain
conditions are met. Therefore, we definitely cannot rule out
that other formal trainings would produce better results.

Acknowledgments
This research was carried out with the financial support of
the National Council for Scientific Research – Flanders,
Belgium (FWO grant G.0634.09)

References
Byrne, R.M.J. & Johnson-Laird, P.N. (1989). Spatial
reasoning. Journal of Memory and Language, 28, 564575.
Carreiras, C. & Santamaria, C. (1997). Reasoning about
relations : spatial and nonspatial problems. Thinking and
Reasoning, 3, 309-327.
Hagert, G. (1984). Modelling mental models: Experiments
in cognitive modelling spatial reasoning. In T. O'Shea
(Ed.), Advances in artificial intelligence. Amsterdam:
North-Holland.
Johnson-Laird, P.N. (1983). Mental Models. Cambridge:
Cambridge University Press.
Johnson-Laird, P. N. (2006). How We Reason. Oxford:
Oxford University Press.
Klauer, K.C., & Meiser, T. (2007). Training effects in
deductive reasoning: A theory-based review. In W.
Schaeken, A. Vandierendonck, W. Schroyens, & G.
d’Ydewalle (Eds.), The mental models theory of
reasoning: Refinements and extensions. Mahwah,
(NJ):Erlbaum.
Markovits, H., & Barrouillet, P. (2002). The development of
conditional reasoning: a mental model account.
Developmental Review, 22, 5-36.
Roberts, M.J. (2000). Strategies in relational reasoning
Thinking and Reasoning, 6, 1-26.
Schaeken, W., Girotto, V. & Johnson-Laird, P.N. (1998).
The effect of irrelevant premise on temporal and spatial
reasoning. Kognitionswissenchaft, 7, 27-32.
Schaeken, W., & Johnson-Laird, P.N. (2000). Strategies in
temporal reasoning. Thinking and Reasoning, 6, 193-219.
Schaeken, W., Johnson-Laird, P.N. & d’Ydewalle, G.
(1996a). Mental models and temporal reasoning.
Cognition, 60, 205-234.
Schaeken, W., Johnson-Laird, P.N. & d’Ydewalle, G.
(1996b). Tense, aspect and temporal reasoning. Thinking
and Reasoning, 2, 309-327.
Schaeken, W., Van der Henst, J.B., & Schroyens, W.
(2007). The mental models theory of relational reasoning:
Premises’ relevance, conclusions’ phrasing, and cognitive
economy. In W. Schaeken, A. Vandierendonck, W.
Schroyens, & G. d’Ydewalle (Eds.), The mental models
theory of reasoning: Refinements and extensions.
Mahwah, (NJ): Erlbaum.

Van der Henst, J.B. (1999). The mental model theory of
spatial reasoning re-examined: The role of relevance in
premise order. British Journal of Psychology, 90, 73-84.
Van der Henst, J.-B. (2002) Mental Model Theory versus
the Inference Rule Approach in relational reasoning.
Thinking and Reasoning, 8, 193-203.
Van der Henst, J.B., & Schaeken, W. (2005). The wording
of conclusions in relational reasoning. Cognition, 97 (1),
1-22.
Vandierendonck A, & De Voogt G. (1996). Evidence for
mental-model-based reasoning: comparison of reasoning
with time and space concepts. Thinking and Reasoning 2,
249- 272.

2428

