UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Assessing Parsimony in Models of Aspect

Permalink
https://escholarship.org/uc/item/35w460pt

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Munch, Damien
Dessalles, Jean-Louis

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Assessing Parsimony in Models of Aspect
Damien Munch (munch@telecom paristech.fr)
Jean-Louis Dessalles (dessalles@telecom-paristech.fr)
Telecom ParisTech, 46 rue Barrault,
F-75013 Paris, France

Abstract
Though human beings are experts in the determination of
aspectual relations, current models of Aspect lack principled
parsimony. We show that even on a limited segment of
language, determining aspectual interpretations seems to
require much ad hoc information. Our suggestion is to give
parsimony first priority. The model we present in this paper is
limited in scope, but its complexity is bounded in principle.
Keywords: Temporal Aspect; Cognitive minimalism; Natural
Language Processing.

Aspect and Parsimony
Human beings have strong intuitions about Aspect. For
instance, though the two following sentences are
syntactically well-formed, only the first one is semantically
acceptable.
(1)

She wants to eat up the cake in one minute.

(2)

# She wants to eat up the cake for one minute.

Principled vs. Actual Parsimony

These intuitions suggest that native speakers of a given
language have a genuine competence concerning Aspect.
Aspect combines different features, such as termination or
repetition. It is tempting to consider this “aspectual
competence” as consisting in a mere pattern-matching
process. For instance, some incompatible features such as
boundedness and unboundedness would be assigned to “to
eat up the cake” and to “for one minute” respectively,
making their combination illegal in (2). Unfortunately, no
pure pattern-matching model of Aspect has been discovered
yet. All models include computational components
consisting in exceptions, type change (coercion) or contextdependent procedural rules. For instance, the sequence of
instructions shown in Figure 1 has been proposed by
Gosselin (1996) to describe the behavior of the French
equivalent of ‘in’ + duration (as in example (1)).
(a)
(b)
(c)
(d)
(e)

that expand Reichenbach’s (1947) reference point system;
these intervals may coincide, overlap or be in various
inclusion relations. The whole system produces many
potential combinations, but only a few of them are useful to
represent aspectual meanings.
The problem with computational models is that they may
uncontrollably depart from parsimony. For instance,
Gosselin’s model sets no limit to the size of the instruction
set that may be assigned to a given word combination.
The present paper has three related objectives. First, our
aim is to highlight the necessity of limiting the complexity
of models of Aspect, while making the distinction between
actual and principled parsimony. Second, we will propose a
small benchmark on which the parsimony of models of
Aspects may be compared. Third, we will evaluate our own
model in regard to this benchmark and discuss the results.

construct an interval [ct1, ct2]
make it non-punctual (ct1 < ct2)
make it coincide with the process interval
make the process interval ‘intrinsic’
include it into the ‘reference’ interval

Any model of Aspect must face the difficulty of describing
a variety of sentence types that sometimes differ in minute
details. Several authors tried to discover notions that prove
useful to explain aspectual variation. The best known
conceptual framework in this respect is probably Vendler’s
(1967) categorization of the lexical Aspect of verbs (state,
activity, accomplishment, achievement). Certain notions
such as dynamicity or perfectivity have been explored by
various authors (e.g. Comrie, 1976; Gosselin, 1996; Smith,
1997). Elucidating the way human beings process Aspect
would be easy if the only problem was to check the
compatibility of fixed features attached to lexical entries or
to predicates, such as ‘activity’, ‘dynamicity’ or ‘telicity’.
Unfortunately, mere feature unification proves insufficient
to predict the aspectual acceptability of sentences. For
instance, ‘drink a glass of wine’ is expected to clash with
‘for three years’, because the former is perfective and the
latter is durative. The sentence:
(3)

Figure 1: Instructions representing en + duration
(after Gosselin,1996).
Another sequence of instructions is needed for
‘in’ + period (as in “in 2010”). Gosselin proposes a variety
of “programs” like this one to account for aspectual words.
Each step of these programs has several alternatives. For
instance, Gosselin’s model introduces four interval types

She drank a glass of wine for three years

is however acceptable with an iterative interpretation (‘She
drank a glass of wine everyday for three years’). The
sentence is ‘saved’ dynamically, thanks to a phenomenon
called ‘coercion’ (de Swart, 1998) or ‘conflict resolution’
(Gosselin, 1996): iteration transforms a perfective situation
(‘drink a glass of wine’) into an imperfective repeated
situation that matches ‘for three years’.
Though the introduction of procedural components like
coercion seems inevitable, it introduces a risk. If the
language in which procedures are expressed is too rich, the
model is no longer constraining. When it reaches the
1

2121

expressivity of a Turing machine, the model can express any
computation. It becomes purely descriptive and loses any
explanatory power. An explanatory model must be able to
restrict the range of possibilities.
A possible answer is that though the procedural power of
models of Aspect is often not limited in principle, it may be
parsimonious in fact. Procedural rules may be kept simple,
even if they are expressed in a rich meta-language. For
instance, although no upper bound is set in principle to the
variety and the size of its procedures, Gosselin’s model
could be claimed to be actually parsimonious (but this
actual parsimony has yet to be established).
The form of parsimony we are referring to corresponds to
a minimum description length (MDL) principle. It measures
the static length of procedures, not the number of procedural
steps executed at processing time. For instance, despite the
fact that a recursive procedure may require time and
memory resources to be executed up to a certain depth, it
may constitute a parsimonious model if it can be expressed
in a compact way. The question is to know whether we can
achieve reasonably parsimonious models of Aspect. Several
requirements must be met.

 E: manger (to eat) with the following meanings:
o Efrom: to eat from something (to eat cake)
o Eup:
to eat something up (to eat the cake)
o Elunch: to have lunch
o Ebite: to take a bite
 S: ronfler (to snore)
Complements for manger may be:
 F: du gâteau (cake, from the cake)
 T: le gâteau (the cake)
 (void) no complement.
Only two prepositions are considered:
 I: en ( in)
 D: pendant (for, during)
Periods can be:
 M: une minute (one minute)
 S: le spectacle (the show)
 2 : 2010
Table 1: Set of sentences.

 Principled parsimony
o Fixed number of possible features
o Upper bound for procedure length
 Actual parsimony
o Compact procedures (i.e. of small static length)
o No or few exceptions
Though parsimony is of course a primary concern when
dealing with Aspect, authors are sometimes more sensitive
to exceptions than to the potential computational power of
their models. As a consequence, few attempts have been
made to demonstrate the principled parsimony of models.
The purpose of the present paper is to show that a (partial)
model of Aspect can be parsimonious in principle.

A Benchmark for Models of Aspect
Processing Aspect is a baffling task. We can observe a
variety of interpretations with only a limited set of examples
(Table 1). We consider examples in French because
aspectual relations are less constrained by the chosen
lexicon than in English. This example set represents already
a challenge for most models of Aspect. Of course, any
model can be adapted to cover the examples, but with the
risk of adding ad hoc knowledge. The examples correspond
to a simple pattern (most of them translate straightforwardly
in English):
<Elle> <pp> <verb> <compl.> <preposition > <durative period>

where elle means ‘she’ and <pp> means ‘present perfect’.
For instance:
(4) Elle a mangé du gâteau pendant une minute
(she has been eating cake for one minute)

This sentence is coded as Efrom–F–D–M in Table 1. We
consider only two verbs:

verb
Efrom
Efrom
Efrom
Efrom
Efrom
Eup
Eup
Eup
Eup
Eup
Elunch
Elunch/bite
Elunch/bite
Elunch/bite
Elunch/bite
Elunch
Ebite
Elunch/bite
Ebite
Ebite
Snore
Snore
Snore
Snore
Snore

Sentence
co. prep.
F
I
F
I
F
D
F
D
F
D
T
I
T
I
T
I
T
D
T
D
I
I
I
I
I
D
D
D
D
D
I
I
D
D
D

period
M
2
M
S
S
M
M
2
M
S
M
M
M
2
2
M
M
S
S
S
M
2
M
S
S

Interpretation
Corresp.
rep. pred.
after
vp
slice
vp
cover
vpp
slice
vp
cover
vpp
cover
vpp
after
vp
slice
vp
#
#
#
slice
vp
cover
vpp
after
vp
after (?)
vp
vpr
slice
vp
slice (?)
vp
vpr
#
#
#
cover
vp
vpp
slice
vp
cover
vp
vpp
slice (?)
vp
vpr
after
vp
slice
vp
cover
vp
cover
vpp
slice
vp

Table 1 lists all syntactically admissible combinations of
these words. The verb manger (to eat) can take various
aspectual forms. With no complement, it may be perfective
(= to have lunch) or imperfective (to snack, to nibble). The
complement (‘the cake’ vs. ‘cake’) controls perfectivity. The
preposition pendant corresponds to ‘for’ when used with
actual duration (“one minute”); it corresponds to ‘during’
2

2122

when used with a definite situation (“during the show”). The
temporal meaning of en corresponds to ‘in’, but is slightly
more restricted: “I’ll leave in three minutes” translates into
“je pars dans trois minutes”.
Table 1 shows all admissible aspectual interpretations for
each sentence (last three columns). The first interpretation
(column ‘correspondence’) has three possible values.
 cover: the situation holds for the whole period. For
instance, “to be eating cake for one minute” (manger du
gâteau pendant une minute).
 slice: the situation holds during a portion of the period.
For instance, “to eat (up) the cake during the show”
(manger le gâteau pendant le spectacle).
 after: the situation holds just after the period is over. For
instance: “to eat cake in one minute” (manger du gâteau
en une minute).
The latter interpretation (sometimes called inchoative) is
not straightforward in French with these examples, but it is
nevertheless possible (e.g. in a context with a child who
does not want to eat). It is more obvious with other verbs, as
in “she confessed in one minute” (elle a avoué en une
minute), which has a clear inchoative interpretation.
The column called ‘repetition’ indicates that the situation
corresponding to the verb phrase (vp) is repeated.
The last column, called ‘predication’, indicates when a
phrase must be predicated. Predication here means that the
phrase carries the attitude. Attitudes are at the interface with
relevance; they may be epistemic (unexpectedness, constraint
violation) or epithymic (wanted or unwanted) (Dessalles,
2008). For our purpose here, we only need to consider that
predication correlates with attitudes, and therefore with
negation: the situation is contrasted with its opposite. For
instance, the last line of Table 1 refers to a situation in which
“she snored (at some point) during the show” (elle a ronflé
pendant le spectacle). For this interpretation to be valid,
“snore” must carry the attitude (e.g. snoring was unexpected
or unwanted, by opposition with not-snoring, which is the
norm). By contrast, the durative interpretation of the same
sentence: “she snored during the (whole) show” this time
requires that the attitude be carried by the whole verb phrase
(vpp), i.e. vp with prepositional complement (“snore during
the show”). Now, the opposition is not ‘snore’ vs. ‘not-snore’,
but “snore during the whole show” vs. any incompatible
alternative (e.g. be interested at some points by the show,
snore for a shorter/longer time). Note that the vp-predication
(e.g. snoring is forbidden or scandalous) prevents from
considering the durative interpretation.
Predication is a crucial component of aspectual relations.
As Table 1 illustrates, predication controls inchoative (after)
and slice interpretations. The first example of the Table 1:
“she ate cake in (= after) one minute” is only valid if “eating
cake” can take the attitude (e.g. it was unexpected, wanted
or forbidden). The same holds for the second example (“she
ate cake in 2010”).
Note that Table 1 allows for repeat-slice or repeat-after
combinations. For instance, “she ate during the show” (elle

a mangé pendant le spectacle) can be understood as “she
(repeatedly) snacked at some point during the show, a fact
that must have some relevance (e.g. being unexpected, or
shocking, or (un)wanted). This complication (repetition +
predication) leads to borderline admissibility, indicated by
question marks in Table 1.
Table 1 represents a challenge for any model of Aspect. It
is not clear whether any classical model of Aspect can
provide all admissible interpretations of these examples
(and no more) without ad hoc addition. The challenge is not
only to predict the two dozens of cases listed in the table. It
is also to account for them with a simple computation.
Any data set can be explained by merely listing the data.
We can compute the complexity of this “null-model”. For
each word combination, one has to decide among four
possible correspondences: ‘cover’, ‘slice’, ‘after’ and
incorrect (#); one has also to determine whether the
situation is repeated or not, and which phrase is predicated.
Each word combination therefore generates 16 possible
interpretations, among which the model must determine
those that are correct. This requires 16 bits, as each
combination may be correct or not. For the simple sentence
pattern we are using, the null-model requires
16VPA bits to predict all interpretations, where V is the
number of verbs, P the number of prepositions and A the
number of periods. If we take the four nuances in the
meaning of manger into account, this makes 400 bits to
account for Table 1 (after syntactic filtering). This number
would grow uncontrollably if we increase the size of the
vocabulary. The challenge is to find a simple model that can
predict interpretations with much less information. If a
model explains only part of the data, each exception must be
included in the complexity of the model.

A Minimalist Model of Aspect
Models of Aspect offer only partial explanations of
aspectual relations, since Aspect depends on actual
languages and, within a language, on a variety of specific
words or morphemes, including tense, prepositions, adverbs,
verbs or adjectives. In English, the present perfect, the
preposition ‘in’, the adverb ‘still’, the verb ‘to stop’ or the
adjective ‘ancient’ impose aspectual constraints. The grail
of research on Aspect would be to find a languageindependent model that would predict aspectual meaning
based on minimal lexical specification for a limited set of
words.
Purely linguistic knowledge is however insufficient to
predict aspectual correctness, as illustrated by the following
example.
(5)

# She bought this book three minutes after her trip to China.

Assuming a trip to China would last typically for a week,
this sentence is semantically odd. It is however acceptable if
we replace ‘minutes’ by ‘days’ or ‘week’. Conversely,
example (3) is no longer correct with ‘seconds’ instead of
‘years’. Knowledge about situations in the ‘world’ is
therefore necessary to process Aspect. We must have some
3

2123

language-independent means to know that drinking a glass
of wine takes seconds or minutes, but not years, or that
eating a crumb takes much less time than eating a big cake.
Any model of Aspect must be able to interface with this
kind of perceptual device to know whether durations are
compatible.

whether the situation is considered from the outside (f) or
from the inside (g). This notion of viewpoint matches
similar binary attributes used by other authors (Smith, 1991;
Filip, 1999; Ghadakpour, 2003). The French preposition en
(‘in’) is associated with an f, whereas pendant (‘for’ or
‘during’) is associated with a g.

Figure 2: Architecture of the model

On the other hand, much of aspectual processing seems to
be independent from perception. The unacceptability of (2)
is not due to the inability to form an image. Special words
like ‘in’ or ‘during’ play a crucial role. Models may explain
aspectual data by postulating complex behavior directed by
those words. For instance, the procedure shown in Figure 1
has been imagined to control the behavior of en + duration
(Gosselin, 1996). Note that the procedure does not suffice to
produce inchoative interpretations, and that en + 2010
would require yet additional instructions. Can we think of
simpler models of Aspect?

Architecture of the model
The model presented in this section is an attempt to answer
this question (Munch, 2013). Though it is still far from
processing the whole gamut of aspectual relations, it is
sufficient to correctly predict the most important ones,
including those used in Table 1. Figure 2 shows the
architecture of the model. The procedural components are
fixed. They synchronize with syntactic processing, as each
syntactic combination triggers an attempt to combine
meanings (semantic merge). The semantic merge gives rise to
new structures which are then executed. Lastly, two optional
operations are performed: repetition and predication.

Aspectual Information Structures
Contrary to most other models, the model of Figure 2
operates on fixed-size structures, called Aspectual
Information Structures (AIS) (Munch, 2013).
Figure 3 lists the content of an AIS. The three first items
are binary attributes. The viewpoint attribute may take two
exclusive values, f (figure) or g (ground). It indicates








Viewpoint (f or g)
Determination (d or u)
Multiplicity (s or m)
Operation
Image
Duration

Figure 3: Aspectual Information Structure
Determination is another binary switch. It opposes
situations that have a unique temporal location, such as ‘the
show’, from periods with no definite locations, such as ‘one
minute’.
Multiplicity is a binary flag that holds repetition in
memory. It is well-known that aspectual processing is blind
to the frequency of repetition. In example (3), the
periodicity could be every day or once a year (at each
birthday, say). A binary flag is therefore sufficient for
keeping track of repetition.
The operation slot refers to a procedure. Contrary to other
models (see Figure 1), only a limited set of fixed procedures
is allowed. The examples of Table 1 are processed with only
one procedure: simultaneity.
The image slot is meant to be a reference to a perceptual
structure. It is necessary to trigger image synthesis
(Kosslyn, 1994). We do not use it in the current version of
the model.
The duration slot holds a numerical value that represents
a typical duration value (it could have been included in
image). Duration is used during merge to check that the two
merged structures have compatible durations (i.e. that they
differ by no more than one order of magnitude). This is
necessary to avoid the kind of duration incompatibility
4

2124
Figure 2: Architecture of the Model

illustrated by example (5).
Table 2 lists relevant AIS elements for a few words.
Typical durations are given by their logarithmic values in
seconds (60  101.8).

 Cover.
 Slice, if the complement is determined.
 After (inchoativity), if the complement is a not-determined
figure.

Table 2: A few AIS.

The determination flag of the complement is forgotten.
The duration of the output for slice and after is set to a non
numerical value, nil.
Figure 2 shows two additional procedural components.
The first one is repetition. Only verb phrases that
correspond to figures (f) can be repeated.
The last procedural component is predication. Only
phrases can be predicated. Its effect is to set viewpoint to f,
determination to d, multiplicity to s (singular) and duration
to nil. Only one predication is allowed per sentence.

en (in)
pendant (for)
eat (lunch)
minute
the
show
2010
“during the show”

viewp.
f
g
–
–
–
–
–
g

det.
–
–
–
u
d
–
d
–

duration
–
–
3.5
1.8
–
3.8
7.5
3.8

operation
simult
simult

Implementation

Unification
Unification is triggered when two words or phrases (head
and complement) are merged by syntax. All attributes in the
two AIS are matched by compatibility. The last line of
Table 2 shows how unification can lead to new AIS when
semantic merge has been performed (note that determination
is not set, as explained below).
Unification alone explains the contrast between
examples (1) and (2). “To eat up the cake” is an f. It
matches with the f of “in one minute”, but it clashes with
the g of “for one minute”. Viewpoint incompatibility also
explains why a durative interpretation of “She ate during the
show” cannot be based on the meaning “to have lunch”
(Elunch), where the lunch would last for the whole show,
but requires the repetitive version of Ebite (see Table 1).
Determination is essential to control for the possibility of
slicing and of inchoativity. Only determined periods such as
“2010” or “the show” can be sliced. Conversely, inchoativity
requires an undetermined period, such as “one minute”.
Duration compatibility explains why “she ate during the
show” (line Ebite–D–S in Table 1) accepts a repetitive
interpretation with the meaning Ebite, but not with the
meaning Elunch (there is not enough time to have multiple
meals during the show).

Procedural components
As Figure 2 suggests, the procedural component of our
model is not limited to unification. There is an execution
phase in which certain operations can be performed. The
parsimony of the model relies on the fact that there can be
only a few operations. To account for the examples of
Table 1, we only need one operation: simult (simultaneity).
A few other operations are needed to account for other
aspectual relations, such as after-now, which is used to
process the temporal meaning of dans in French.
Simult is executed when words like en or pendant are
merged with their complement (see Table 2). It requires a
durative complement (i.e. with a numerical duration). It has
three possible outputs (Figure 2).

The model is currently implemented in Prolog1. Syntactic
processing is achieved using a small DCG grammar. All
procedural combinations are explored through backtracking.
For instance, repetition and predication have no effect at first
call, and act on the current AIS only at backtracking time.
One originality (and strong point) of the model is that all
operations beyond merge are unary (monadic). Most models
use binary (dyadic) operations, like the operation shown in
Figure 1. One operand is the duration given as complement,
and the other one is the process (which should not yet be
available from the syntax). By contrast, our operations are
strictly unary. For instance, when “during the show” is
processed, simult is executed and does not wait for the vp.
“During the show” gives two alternative AIS:
 viewp = g / det = – / duration = 3.8 / image = cover
 viewp = – / det = d / duration = nil / image = slice
Similarly, and contrary to classical models, inchoativity is
achieved by transforming the period, not the situation given
by the verb. “In one minute” produces the following AIS:
 viewp = f / det = – / duration = 1.8 / image = cover
 viewp = f / det = d / duration = nil / image = after
Outputs of the procedural component, such as ‘cover’,
‘slice’ or ‘after’, should be further processed by a perceptual
module (not implemented).

Discussion
The preceding model has been designed to be as
parsimonious as possible. As it stands, it predicts all the
examples of Table 1. Moreover, it does not produce any
incorrect output that it would not signal as such.
Parsimony relies on several characteristics.
 Fixed-size structures. Contrary to most models, AIS have
a bounded size. They are not recursive (an AIS does not
contain another AIS), unlike for instance HPSG structures.

1

Available at www.dessalles.fr/Data/MD_Cogsci2014.zip

5
2125

 Amnesia. Many models are procedurally monotonic,
which means that the structures they process can only
grow in size and complexity during processing, becoming
unrealistic for large inputs (Ghadakpour, 2003). The
semantic merge operator is ‘amnesic’, which means that
the input AIS are lost. It makes one single fixed-size AIS
from two AIS. Our model is therefore procedurally nonmonotonic.
 Procedural components such as simult or repetition are
given in advance. They belong to the model and are not
attached to the lexicon (unlike what is shown in Figure 1).
This last point is crucial. The symbolic information
contained in the AIS is bounded by 6 bits (one bit for each
of the three binary flags: viewpoint, determination,
multiplicity, plus three bits if we allow for eight operations).
This means that the model requires a fixed amount of
information corresponding to its procedures (Figure 2), plus
6 bits times the size of the aspectual vocabulary (‘in’,
‘during’, ‘minute’, ‘since’…). This is of course much less
than the null-model, which requires 16 bits, not per word,
but per word combination!
This upper bound makes our model parsimonious in
principle and not only in fact. To our knowledge, it is the
first computational model of Aspect that has this property.
Thanks to this property, not only the descriptive power of
the model, but also its explanatory power, can be
considered. Models with procedures directly attached to the
lexicon (as shown in Figure 1) can hardly be falsified, as it
is always possible to fit the data by adding new instructions.
Our model refuses this easy option.
Admittedly, part of the information needed to process
Aspect is not included in the above assessment of the model’s
parsimony. Information about typical durations, the polysemy
of a verb like ‘to eat’ (to have lunch, to take a bite) or the fact
that there is only one lunch per day, is not counted. In line
with (Moens & Steedman, 1988), we consider that this
information belongs to other cognitive modules.
An original aspect of the model is the introduction of the
predicative component. To our view, it is inevitable if we
want to account for many of the examples of Table 1.
Consider the following examples.
(6)
(7)

I want to drink alcohol next year.
I want to drink alcohol for ten minutes next year.

(6) makes sense for instance if I am a Muslim and if
drinking alcohol is unexpected for me. “Drink alcohol”
becomes a binary fact (to drink or not to drink). This binary
aspect is incompatible with duration. This is why (7) may
seem odd. For (7) to be acceptable, the Muslim context is of
no help. One has to imagine that drinking alcohol for that
duration is unexpected. This means that predication must
concern the whole verb phrase (vpp) and not the vp (‘drink
alcohol’) alone. As the model predicts, the latter is
excluded, because nil duration would not match the
durativity of “ten minutes”.

Conclusion
We tried to show that explaining aspectual relations with a
restricted set of principles is a hard task, even for a limited
segment of language. We introduced a set of sentences that
can be used as a benchmark for models of Aspect. We
suggested that though many models can be claimed to have
bounded actual complexity, their complexity is not bounded
in principle. We introduced our own model and showed that
its complexity has the property of being bounded in
principle.
Our approach to aspectual processing has several original
features, such as the use of unary operations and the formal
use of predication.
We did not demonstrate that our approach can scale up to
deal with the whole gamut of aspectual phenomena. For
this, a lot more investigation work is still required. At this
point, our purpose was rather to show that a very limited
corpus of examples is already sufficient to assess the
parsimony of models. This study can be understood as an
invitation to evaluate the performance (in terms of
principled and actual parsimony) of alternative models
against a given set of sentences, as the one listed in Table 1.

Acknowledments
This study is supported by a grant from the Chaire
Modélisation des Imaginaires, Innovation et Création.

References
Comrie, B. (1976). Aspect. Cambridge Univ. Press.
de Swart, H. (1998). Aspect shift and coercion. Natural
Language & Linguistic Theory, 16 (2), 347-385.
Dessalles, J-L. (2008). La pertinence et ses origines
cognitives - Nouvelles théories. Paris: Hermes-Science.
Filip, H. (1999). Aspect, eventuality types and noun phrase
semantics. New York: Routledge.
Ghadakpour, L. (2003). Le système conceptuel, à l’interface
entre le langage, le raisonnement et l’espace qualitatif:
vers un modèle de représentations éphémères. Paris:
Thèse de doctorat, Ecole Polytechnique.
Gosselin, L. (1996). La sémantique de la temporalité en
français - Modèle calculatoire et cognitif. Duculot.
Kosslyn, S. M. (1994). Image and brain. Cambridge (MA):
MIT Press, ed. 1999.
Moens, M. & Steedman, M. (1998). Temporal ontology and
temporal reference. Comp. Linguisitics, 14 (2), 15-28.
Munch, D. (2013). Un modèle dynamique et parcimonieux
du traitement automatisé de l’aspect dans les langues
naturelles. Paris: PhD dissertation, Telecom ParisTech
2013-ENST-0058.
Reichenbach, H. (1947). Elements of symbolic logic. New
York: Macmillan Co.
Smith, C. S. (1997). The Parameter of Aspect. Dordrecht:
Kluwer.
Vendler, Z. (1967). Linguistics in Philosophy. Ithaca, NY:
Cornell University Press.

6
2126

