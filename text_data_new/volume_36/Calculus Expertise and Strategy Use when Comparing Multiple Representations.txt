UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Calculus Expertise and Strategy Use when Comparing Multiple Representations

Permalink
https://escholarship.org/uc/item/6rq8t841

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 36(36)

Authors
Booth, Julie
Chang, Briana
Cromley, Jennifer
et al.

Publication Date
2014-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Calculus Expertise and Strategy Use when Comparing Multiple Representations
Julie L. Booth (julie.booth@temple.edu)
College of Education, 1301 W. Cecil B. Moore Avenue
Philadelphia, PA 19122 USA

Briana L. Chang (briana.chang@temple.edu)
College of Education, 1301 W. Cecil B. Moore Avenue
Philadelphia, PA 19122 USA

Jennifer G. Cromley (jcromley@temple.edu)
College of Education, 1301 W. Cecil B. Moore Avenue
Philadelphia, PA 19122 USA

Thomas F. Shipley (thomas.shipley@temple.edu)
Department of Psychology, 1701 North 13th Street
Philadelphia, PA 19122 USA

Theodore Wills (twills@temple.edu)
College of Education, 1301 W. Cecil B. Moore Avenue
Philadelphia, PA 19122 USA

Abstract
Expertise affords individuals a variety of advantages for
learning and for problem solving, including competing
advantages such as using automatic strategies vs. using
sophisticated strategies. In the present study, high school
students with varying levels of calculus expertise completed
measures of conceptual understanding and skill with external
representations before a task in which they were asked to
coordinate between multiple representations (CMR) and
determine whether they represented the same mathematical
function. Strategy use during the CMR task was coded based
on think-aloud data. Results indicate that students with more
expertise tended to use automatic strategies when completing
the task, and, surprisingly, used fewer sophisticated strategies
than more novice peers.
Keywords: expertise; mathematics; coordinating multiple
representations

Introduction
Numerous studies have documented the advantages that
experts in a domain have for performance and learning in
that domain. These advantages include, but are not limited
to, improved memory abilities (Chi, 1978), knowledge of
strategies (Gaultney, 1995), and reasoning skills (Johnson,
Scott, & Mervis, 2004). Further, such benefits have been
shown to arise in widely varied domains of expertise,
including physics (Chi, Feltovich, & Glaser, 1981),
dinosaurs (Johnson, Scott, & Mervis, 2004), chess (Chi,
1978), computer programming (Barfield, 1986), and
gymnastics (Tenenbaum, Tehan, Stewart, & Christensen,
1999).
Regardless of domain, several of these advantages have
direct implications for experts’ problem solving skills.

Perhaps the most obvious implications follow from
improved strategy knowledge. By definition, experts have a
greater conceptual understanding within their domain, and
they are able to use this knowledge to generate better
strategies for problem-solving in that domain (Chi et al.,
1981). Their strategies tend to be driven by theory and
consistent with their conceptual understanding of the
problem situation (Dhillon, 1998). In contrast, novices tend
to think about problems in a more basic manner, with
strategies that focus on surface structures rather than on
deep ones (Lovett & Anderson, 1996). Overlapping waves
theory maintains that all individuals know and use a variety
of strategies for solving problems, and that those strategies
compete for use in every given situation; as individuals
become more experienced and gain expertise, they are likely
to use more sophisticated strategies than peers with less
expertise (Siegler, 1996). Experts’ greater success in
problem solving can be, at least partially, attributed to their
use of more sophisticated strategies (Chi, Glaser, & Rees,
1982).
Another key advantage for experts that is relevant to
problem solving is experts’ automaticity—that they have
automatized certain knowledge and thus do not have to
spend limited working memory resources to process
problem components or carry out the procedures (Bereiter &
Scardamalia, 1993). Such procedures are thus carried out
without the individual consciously monitoring them (Aarts
& Dijksterhuis, 2003), allowing experts to perform better on
difficult problem-solving tasks (Brown & Bennett, 2002).
Automaticity can also happen in interpretation of the
problem situation (Bargh, 1999), which is arguably related
to another advantage of expertise: rapid and effective

1935

encoding of relevant information (Ericsson & Kintsch,
2000). Both automaticity and encoding are core mechanisms
in information processing theories, indicating ways in which
more experienced individuals are able to bypass capacity
limitations in order to focus on critical problem features
(e.g., LaBerge & Samuels, 1974; Heatherington & Parke,
2003). These mechanisms may also help account for the
fact that experts often have difficulty articulating the
strategies they utilize when solving problems (Chao &
Salvendy, 1994).
In the present study, we investigate how mathematics
expertise relates to students’ approaches to the problem of
coordinating
multiple
representations
(CMR)
in
mathematics. The National Council for Teachers of
Mathematics recommends use of external representations
throughout mathematics instruction, even in elementary
school, and stresses the importance of being able to
coordinate between multiple representations (NCTM, 2010).
This skill is especially emphasized in reform approaches to
teaching higher-level mathematics courses, such as calculus
(e.g. Hughes-Hallett et al., 2011). Here, we examine
specifically how conceptual knowledge in calculus
(expertise) relates to students’ use of automatic vs.
sophisticated vs. basic strategies for completing a CMR
task. We also test the degree to which conceptual
knowledge is predictive of strategy use above and beyond
other factors which could increase performance (grade level
and skill with external representations). Based on the
literature described above, we expect that students with
greater conceptual knowledge will use sophisticated
strategies (Siegler, 1996) or automatic strategies (Bereiter &
Scardamalia, 1993), but not basic ones. However, it is
unknown whether they are more likely to use automatic or
sophisticated strategies when coordinating multiple
representations.

Method
Participants
Participants included 40 pre-calculus and calculus students
from two public, suburban high schools in the Northeast.
Their mean age was 16.6; 45% were male; 77% were White,
18% Asian, 3% Black, and 5% other races. As a proxy for
socioeconomic status, median parental education was a
Bachelor’s degree.

Procedure
Parental consent and student assent were acquired, after
which students were tested individually in a session lasting
approximately 70 minutes. Students received gift cards as
compensation in the amount of $10 for their involvement in
the study. Participants completed a series of paper and
pencil measures, including a standardized measure of basic
graph/table skills and one researcher-constructed calculus
conceptual knowledge measure. Students also completed an
eye-tracking measure for coordination of multiple

representations (CMR) while verbalizing their thoughts.
These measures are described below.

Measures
Calculus conceptual measure (CCM). To assess students’
calculus conceptual knowledge, we used 32 researcherconstructed items that measured students’ understanding of
concepts that have been identified as crucial for success in
calculus, including functions and limits (Lauten, Graham, &
Ferrini-Mundy,1994),
derivatives
(Asiala,
Cottrill,
Dubinsky, & Schwingendorf, 1997), and the chain rule
(Clark et al., 1997).
For example, one item asks
participants to identify which pieces of information they
would use to complete a mathematical task (e.g., finding the
zeros of a function); students respond by circling any
number of the following options; f, f’, and f”. Students were
given 7 minutes to complete the measure. Scores ranged
from 0% to 72% (M=47%) and were highly correlated with
a measure of students’ proficiency in calculus (Cromley et
al., revision under review). Internal consistency was
computed using Cronbach’s alpha; α= .99.
Graph/table skills. We created a measure comprised of 6
released NAEP Grade 12 graph items and 5 released NAEP,
NAAL, and ALL table items. These are from the “Easy”
groups of multiple-choice items, which tap basic graph and
table comprehension, such as finding a single data
point/cell, rather than coordinating multiple representations
skills which are typical of many “Hard” and some
“Medium” questions. One item asks participants to find the
highest temperature in a city from a graph of temperatures
across a range of days. Given these are well-validated
questions used by NAEP for years before public release, we
expected them to show excellent reliability and validity with
high school students and undergraduates. Participants were
given 6 minutes to complete the measure. Cronbach’s alpha
for the sample is .66.
Think-aloud CMR Measure.
Student participants
completed CMR tasks on an eye-tracking apparatus (eyetracking data reported elsewhere; Wills, Shipley, Chang,
Cromley, & Booth, in press) while following a think-aloud
protocol (Ericsson & Simon, 1998). Participants were
shown 12 pairs of representations and were asked to
determine whether or not they expressed the same function.
We used linear, quadratic, and cubic functions, with an
equal number of matches and mismatches and equal
numbers of the three possible pairings of each
representation type (i.e., equation-graph, equation-table,
graph-table). Position of the first representation on the left
or right was controlled for across participants. A sample
item is shown in Figure 1. Cronbach’s alpha for responses
to the match/mismatch questions for the sample is .87.

Coding of Think-aloud Data
Student verbalizations during the CMR task were
transcribed and analyzed to develop a coding scheme for

1936

Table 1: Think-aloud codes for automatic, sophisticated, and basic strategy use during the CMR task.
Strategy Code
Description
Example
Automatic
AHA
Feeling of knowing or “Aha!” moment
oh, alright, f(x) equals y
IDK
Reflecting on not knowing how to work
I'm not really sure how to determine if they are the same
through a stimulus
because I haven't seen a graph like that before
Sophisticated
EVALDIR

Evaluating the direction (positive or
negative)

I see that this parabola is facing downwards so I would
say that that’s negative and it’s not negative in the
function

EVALCOEFF

Evaluating the magnitude of a coefficent

EVALCON
EVALOR

Evaluating the magnitude of the constant
Evaluating the order

The slope is 2 in the equation, rise 2 over 1, looks good
in the graph
It looks like this graph is shifted to the right
To me that doesn’t look like an x squared function, that
looks to be like x cubed.

Basic
MOP
MX

MY

Mapping an ordered pair between
representations
Mapping the x intercept between
representations (with or without verbally
identifying it as such)

Let’s see, x is 2 on the table, put it on the graph, equals
negative 20, that fits with the table
x equals 3 and y equals 0, that matches the graph

Mapping the y intercept between
representations (with or without verbally
identifying it as such)

So when x is zero, f of x is around negative one

student strategy use. The second author coded 1,370
utterances across all participants (M = 34 utterances per
participant). A second coder was trained on data other than
those used for calculating inter-rater statistics and re-coded
35% of the corpus (Cohen’s kappa = .91). See Table 1 for a
description of the think-aloud codes used in the present
analyses. Two of the codes (AHA and IDK) represent
automatic strategies, in which overt procedures are not
undertaken to solve the problem. Four of the codes
(EVALDIR, EVALCOEFF, EVALCON, and EVALOR
represent sophisticated strategies which invoke deep
problem features (the direction, coefficient, constant, or
order of the function) in the solution process. The remaining
three codes (MOP, MX, MY) reflect more basic problem
solving strategies, in which only surface features in the
problem (namely, the discrete ordered pairs in the functions)
are utilized.

EVALCOEFF, and EVALCON strategies. Thus, all further
analyses will be conducted only on these strategies.
To determine whether CCM is a useful and independent
predictor of the use of each of these strategies, and to further
investigate the nature of its impact, we conducted a series of
regression analyses, one for each of the strategies with

Results
First, to determine which types of strategies should be
further explored with relation to conceptual understanding,
we computed the mean number of times per item that verbal
data indicated the use of each strategy. We then computed
correlations between the CCM scores and the mean use of
each strategy. As shown in Table 2, significant correlations
were found between CCM scores and the AHA, IDK,

1937

Figure 1: A sample item from the eye tracking CMR task.
This example pairs an equation with a graph; other items
included equation-table or graph-table pairs.

Table 2: Correlations between conceptual understanding and automatic, sophisticated, and basic strategy use.
Automatic
AHA
IDK
CCM
.36**
-.38**
Note: ***p<.01, **p<.05

EVALDIR
.18

Sophisticated
EVALCOEFF
EVALCON
-.47***
-.35**

EVALOR
.24

MOP
-.02

Basic
MX
.05

MY
.14

Table 3: Regression results for conceptual understanding (CCM), grade level, and graph/table skills (NAEP) on use of each
strategy

Analysis
AHA
IDK
EVALCOEFF
EVALCON

β
.36
-.43
-.49
-.31

CCM
Significance
p < .05
p<.01
p<.01
p<.10

which CCM scores were correlated. In each model, we also
included two alternate predictors: grade level and NAEP
scores. Grade level was included because students in higher
grade levels tend to have higher conceptual knowledge
(r(38) = .33, p < .05), and being in an advanced grade may
also lead to more sophisticated strategy use, as more
sophisticated strategies are likely to be taught in higher
grades. NAEP graph/table scores were included in order to
isolate the impact of domain-specific expertise (e.g.,
conceptual knowledge in calculus) rather than more general
competence with external representations (e.g., graphs and
tables) which may also come with increased experience in
mathematics classes.
As shown in Table 3, conceptual knowledge in calculus
was a significant positive predictor of the AHA strategy and
the MOPY strategy, whereas it was a negative predictor of
the IDK strategy and the EVALCOEFF strategy, and a
marginal negative predictor of the EVALCON strategy.
Students with higher conceptual knowledge of calculus were
thus more likely to have an “Aha” moment or to match
ordered pairs for the y-intercept, and less likely to evaluate
the magnitude of the coefficient or the constant, or to say
they did not know. Grade and NAEP graph/table scores
proved to be marginal predictors of the IDK strategy (e.g.,
students with higher NAEP scores were less likely to say
they don’t know, but students in higher grades are more
likely to say they don’t know), but in all cases, there was an
impact of conceptual understanding above and beyond that
of the other factors.

β
.04
.26
.00
-.15

Grade
Significance
ns
p<.10
ns
ns

β
-.12
-.25
.11
.11

NAEP
Significance
ns
p<.10
ns
ns

likely to just have an “Aha!” moment in which they feel that
they know whether the functions are the same.
Conceptually strong students, however, do not just use
any automatic strategy. They are less likely than more
novice peers to utilize a relatively unproductive automatic
strategy—giving up and saying they do not know whether
the functions are the same.
While it may not be surprising that experts in this study
preferred productive automatic to overt sophisticated
strategies, it is perhaps perplexing that the relation between
expertise and use of overt sophisticated strategies was, in
fact, negative. Experts used sophisticated strategies less
often than more novice peers. This seems contrary to the
wealth of literature on experts’ better repertoire of
strategies. However, it is important to note that these results
do not speak to whether or not more advanced students
know more sophisticated strategies, just whether or not they
seem to use them overtly during the comparison tasks. The
underlying procedures that they are using to automatically
process and solve the problem may or may not be
sophisticated; it is impossible to tell that from the think
aloud data. Further analysis of eye-tracking data collected
during the CMR task will be necessary for distinguishing
which problem feature(s) the conceptually strong students
noticed before and while they experienced the feeling that
they knew the answer. Analysis of the eye-tracking data
may also allow us to determine whether experts’ decisions
were made based on automatic processing of problem
features (encoding differences) or automatic application of
problem-solving procedures.

Discussion
Results from this study suggest that students with greater
conceptual understanding do not, in fact, use more
sophisticated overt strategies than peers with less conceptual
knowledge.
Instead, our results indicate that more
conceptually strong students tend to complete the task
without using overt strategies at all. These students are most

Acknowledgments
The research reported here was supported by the Institute of
Education Sciences, U.S. Department of Education, through
Grant R305A120471 to Temple University. The opinions
expressed are those of the authors and do not represent
views of the Institute or the U.S. Department of Education.

1938

References
Asiala, M., Cottrill, J., Dubinsky, E., & Schwingendorf, K.
E. (1997). The development of students’ graphical
understanding of the derivative. Journal of Mathematical
Behavior, 16, 399–431.
Barfield, W. (1986). Expert-novice differences for software:
Implications for problem solving and knowledge
acquisition. Behaviour and Information Technology, 5,
15-29.
Bargh, J. A. (1999a). The unbearable automaticity of being.
American Psychologist, 54(7), 462–479.
Bereiter, C., & Scardamalia, M. (1993). Surpassing
ourselves: An inquiry into the nature and implications of
expertise. Chicago, IL: Open Court.
Brown, S. W., & Bennett, E. D. (2002). The role of practice
and automaticity in temporal and nontemporal dual-task
performance. Psychological Research, 66, 80–89.
Chao, C., & Salvendy, G. (1994). Percentage of procedural
knowledge acquired as a function of the number of
experts from whom knowledge is acquired for diagnosis,
debugging, and interpretation tasks. International Journal
of Human-Computer Interaction, 6(3), 221–233.
Chi, M.T.H. (1978). Knowledge structures and memory
development. In R.S. Siegler (Ed.), Children’s thinking:
What develops? (pp. 73-96). Hillsdale, NJ: Erlbaum.
Chi, M. T. H., Feltovich, P. J., & Glaser, R. (1981).
Categorization and representation of physics problems by
experts and novices. Cognitive Science, 5, 121–152.
Chi, M. T. H., Glaser, R., & Rees, E. (1982). Expertise in
problem solving. In R. J. Sternberg (Ed.), Advances in the
psychology of human intelligence, vol. 1.
Hillsdale, NJ: Erlbaum.
Clark, J. M., Cordero, F., Cottrill, J., Czarnocha, B.,
DeVries, D. J., St. John, D., Tolias, T., & Vidakovi´c, D.
(1997). Constructing a schema: The case of the chain rule.
Journal of Mathematical Behavior, 16, 345–364.
Cromley, J.G., Booth, J.L., Wills, T.W., Chang, B.L.,
Shipley, T.F., Zahner, W., Tran, N., & Madeja, M.
(revision under review). Spatial ability, conceptual
knowledge, and calculus proficiency. Learning and
Instruction.
Dhillon, A. S. (1998). Individual differences within
problem-solving strategies used in physics. Science
Education, 82, 379–405.
Ericsson, K. A., & Kintsch, W. (2000). Shortcomings of
generic retrieval structures with slots of the type that

Gobet (1993) proposed and modeled. British Journal of
Psychology, 91, 571–590.
Ericsson, K., & Simon, H. (1980). Verbal reports as data.
Psychological Review 87 (3): 215–251.
Gaultney, J.F. (1995). The effect of prior knowledge and
metacognition on the acquisition of a reading
comprehension strategy. Journal of Experimental Child
Psychology, 59, 142-163.
Hetherington, E.M., & Parke, R.D. (2003). Child
Psychology: A Contemporary Viewpoint (Updated Fifth
Edition). Boston: McGraw-Hill.
Hughes-Hallett, D., Gleason, A. M., Lock, P. F., & et al.
(2010). Applied calculus (4th ed.). Hoboken, NJ: Wiley.
Johnson, K.E., Scott, P., & Mervis, C.B. (2004). What are
theories for? Concept use throughout the continuum of
dinosaur expertise. Journal of Experimental Child
Psychology, 87, 171-200.
Laberge, D., & Samuels, S. J. (1974). Towards a theory of
automatic information processing in reading. Cognitive
Psychology, 6, 293-323.
Larkin, J. H., McDermott, J., Simon, D. P., & Simon, H. A.
(1980). Expert and novice performance in solving physics
problems. Science, 208, 1335–1342.
Lauten, A. D., Graham, K., & Ferrini-Mundy, J. (1994).
Student understanding of basic calculus concepts:
Interaction with the graphics calculator. Journal of
Mathematical Behavior, 13, 225–237.
Lovett, M. C., & Anderson, J. R. (1996). History of success
and current context in problem solving: Combined
influences on operator selection. Cognitive Psychology,
31, 168–217.
National Council of Teachers of Mathematics. (2010).
Principles and standards for school mathematics. Reston,
VA: Author.
Siegler, R. S. (1996). Emerging minds: The process of
change in children’s thinking. New York: Oxford
University Press.
Tenenbaum, G., Tehan, G., Stewart, G., & Christensen, S.
(1999). Recalling a floor routine: The effects of skill and
age on memory for order. Applied Cognitive Psychology,
13, 101-123.
Wills, T., Shipley, T. F., Chang, B. L., Cromley, J. G., &
Booth, J. L. (in press). What gaze data reveal about
coordinating
multiple
mathematical
representations. Proceedings of the 36th Annual Meeting
of the Cognitive Science Society.

1939

