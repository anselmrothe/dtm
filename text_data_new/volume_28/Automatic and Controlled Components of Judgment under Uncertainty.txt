UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic and Controlled Components of Judgment under Uncertainty

Permalink
https://escholarship.org/uc/item/4cd035s1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Ferreira, Mario B.
Garcia-Marques, Leonel
Garrido, Margarida
et al.

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Automatic and Controlled Components of Judgment under Uncertainty
Mário B. Ferreira (mabf@fpce.ul.pt), Leonel Garcia-Marques (garcia_marques@sapo.pt)
Faculty of psychology and Education, Alameda da Universidade,
1649-013 Lisboa, Portugal

Steven J. Sherman (sherman@indiana.edu)
Department of Psychology, Indiana University
Bloomington, IN 47405

Margarida Garrido (margarida.garrido@iscte.pt)
Department of Social Psychology, ISCTE , Av. das Forças Armadas
1649-026 Lisboa, Portugal

Abstract
The categorization of inductive reasoning into largely
automatic processes (heuristic reasoning) and controlled
analytical processes (rule-based reasoning) put forward by
dual-process approaches of judgment under uncertainty (e.g.,
Stanovich & West, 2000) has been primarily a matter of
assumption with a scarcity of direct empirical findings
supporting it. We used the process dissociation procedure
(Jacoby, 1991) to provide convergent evidence validating a
dual-process perspective to judgment under uncertainty based
on the independent contributions of heuristic and rule-based
reasoning. Process dissociations based on experimental
manipulation of variables were derived from relevant
theoretical properties typically used to contrast the two forms
of reasoning. These included processing goals (Experiment 1)
and priming (Experiment 2). Results consistently supported
the present perspective. We conclude that judgment under
uncertainty is not either an automatic or controlled process,
but that it reflects both processes, with each making
independent contributions.
Keywords: Heuristics; dual process models; automatic
processes; controlled processes; judgment under uncertainty.

Introduction
From our perspective, the greatest contribution of more than
30 years of research concerning the use of heuristics and
biases is not so much the realization that intuitive judgments
are often governed by heuristics that do not follow
probability rules, but the revelation of a gap, within our own
heads, between “natural assessments” such as availability or
representativeness and the deliberate application of a
justifiable set of inductive rules.
In recent years, dual-process approaches of judgment
under uncertainty (e.g.,Kahneman & Frederick, 2002;
Stanovich & West, 2000) have categorized the cognitive
processes underlying inductive reasoning into two basic
forms of reasoning: largely automatic associative processes,
here referred to as heuristic reasoning (H) and controlled
analytical processes, rule-based reasoning (RB).
But, what are these two forms of reasoning; How do they
work; and When do they become active?

The what question: H refers to inferences based on
simplifying principles such as similarity and contiguity,
whereas RB refers to symbolically represented inferential
rules structured by logic.
The how question: H operates intuitively in the sense that
once triggered it gives rise to an autonomous process
without further control until an end response pops out into
consciousness. RB’s operation involves the deliberate
application of rules that are put to work strategically
according to the person’s goals.
The when question: H’s activation depends only on
appropriate triggering cues (e.g., similarity matching
involved in the representativeness heuristic), whereas RB’s
activation depends on recognizing the applicability of an
abstract rule (based on the verification of formal
conditions), as well as on the availability of cognitive
resources and motivation.
Research on judgment under uncertainty has traditionally
employed errors and biases in answers to inferential
problems to characterize the underlying heuristic principles
and their consequences (e.g., Tversky & Kahneman, 1974).
In such research, RB is typically gauged in terms of correct
responses (defined by applicable probability or statistical
rules) or calibrated responses (defined by ecological
considerations or objective criteria) to inferential problems,
while H is usually estimated by incorrect or badly calibrated
responses to the same kind of inferential tasks.
This approach contrasts with our own both conceptually
and methodologically. At the conceptual level, the above
approach implies a zero-sum or hydraulic relation between
the RB and the H process. As correct responses increase,
incorrect responses necessarily decrease. Our dual-process
approach conceives of the two processing modes as
contributing independently to the judgment. At the
methodological level, the above approach assumes that
inferential problems or tasks are pure measures of
underlying processes. However, such a process-pure
assumption may be troublesome to maintain because tasks
differ in a number of ways beyond the extent to which they
tap H and RB. Rather, most, if not all, judgments under
uncertainty will be influenced by simultaneously occurring
heuristic and rule-based processes. Therefore, it is important
to employ uncontaminated measures of processes through
procedures that do not require or assume a one-to-one

1293

relation between tasks and processes. We employ one such
solution by applying the process dissociation framework
(Jacoby, 1991) to judgments under uncertainty.

Process Dissociation Procedure (PDP) and
Judgments Under Uncertainty
The PDP was originally designed to separate automatic and
conscious contributions to memory task performance
(Jacoby, 1991). However, its logic may be applied to
different experimental contexts as a general methodological
tool for separating contributions of automatic and controlled
processes. The procedure makes use of an inclusion
condition where automatic and controlled processes act in
concert, and an exclusion condition where the two processes
act in opposition. Assuming that both processes contribute
to performance and operate independently, estimates of each
can be obtained by comparing performance across the two
conditions.
Suppose you are asked to respond to the lawyer-engineer
problem (Kahneman & Tverky, 1972). In this problem Dan
is described by the psychologists who interviewed him as
conservative, careful, and ambitious with no interest in
political issues and spending most of his free time on his
many hobbies, which include carpentry, sailing, and
mathematical puzzles. Dan’s description was drawn
randomly from a set of descriptions that included 30
engineers and 70 lawyers. Which of the following is more
likely? a) Dan is an engineer; b) Dan is a lawyer.
In this problem, Dan’s description is closer to that of an
engineer, but not highly diagnostically so. Thus, a judgment
by representativeness (Kahneman & Tverky, 1972), based
on the similarity between the description and the prototypes
of engineer and lawyer, is in opposition to a response based
on the application of a sampling rule (taking into
consideration the prior probabilities of being an engineer or
a lawyer). As such, choosing the response option “Dan is an
engineer” is assumed to happen only if conscious
application of a relevant inferential rule (C) fails and as a
result of the automatic influences of heuristic processing:
A(1 – C). The lawyer-engineer problem, as well as other
inferential problems possessing the same basic structure,
may be considered good instantiations of an exclusion
condition. However, one can also develop an inclusion
condition for the same problem by simply inverting the
base-rates. That is, you now consider a group of
interviewees composed of 70 engineers and 30 lawyers.
Therefore, the response option “Dan is an engineer” may be
chosen as a consequence of using base-rates or simply
because it was automatically computed as more similar to
Dan’s description. The proportion of responses “Dan is an
engineer” is given by, C + A(1 - C).
In sum, we begin with a dual-process approach to
judgment under uncertainty that postulates the existence of
two different processing modes, RB (involving explicit and
controlled rule application) and H (based on automatic
processing). We assume that RB and H processes operate in
parallel and that they contribute to judgment independently
of each other.

The Present Experiments
We report two experiments exploring how different
independent variables influence RB and H. Each
manipulation is historically relevant to the distinction
between automatic and controlled processes. Our main goal
is to determine whether derived estimates of RB and H will
show expected trends based on our assumptions.
Literature involving judgments under uncertainty has
traditionally assumed that performance based on H is
unaffected by participants’ intentions or goals (Sherman &
Corty, 1984). Although some research has suggested that
goals such as incentives to be accurate do not reduce
heuristically driven biases (Camerer, 1987; Tversky &
Kahneman, 1974), there is no direct evidence supporting
this notion. Experiment 1 sought such evidence by
manipulating participants’ goals through instructions to
answer the inferential problems in an intuitive or in a
rational way. RB is believed to be under participants’
control, whereas H is assumed to be largely automatic.
Accordingly, varying participants’ goals should affect RB
but leave H unchanged.
Processing a particular stimulus in a particular way
facilitates the subsequent repetition of the same processing
with new stimuli (Smith, 1994). This facilitation is generally
independent of any explicit memory of the previously
presented stimuli. Accordingly, priming the use of heuristics
is expected to dissociate the two reasoning modes by
increasing H but leaving RB invariant. Experiment 2 primed
participants with inferential problems designed to facilitate
H highly similar to the target stimuli. On the other hand,
RB was expected to be invariant because it corresponds to a
reasoning mode governed by explicit application of rules,
quite insensitive to the automatic processing principles
underlying H.

Experiment 1
Participants The participants were 40 students (29 females
and 11 males) at the University of Lisbon who participated
in partial fulfilment of course requirements.
Procedure and Material For the experiments here
reported, participants were given a brief oral introduction to
the experiment on arrival at the laboratory. Written
instructions followed by a list of problems were presented,
and responses were collected on the computers. Each
problem was followed by two response options. Participants
had to choose one option before they could go on to the
following problem.
In order to guarantee that participants never saw the
inclusion and exclusion version of the same problem two
lists of problems (list 1 and list 2) were created and
manipulated between-participants such that inclusion
problems in list 1 became exclusion problems in list 2 and
vice versa. In each of these lists, problems were sorted
differently to control for order effects. Order of presentation
of the problems was random.
Two experimental conditions, corresponding to two
instruction sets, were used in Experiment 1. In one
condition, referred to as the intuitive condition, the
experiment was introduced as a study of human intuition.

1294

The study’s goal was to evaluate personal intuition and
sensibility when one has to make choices based on
incomplete information. Participants were encouraged to
base their answers to the problems on their intuition and
personal sensitivity.
In the other condition, referred to as the rational
condition, the experiment was introduced as a study on
human rationality. The study’s goal was to evaluate
scientific reasoning ability when one has to make choices
based on incomplete information. Participants were
encouraged to behave like scientists, and to base their
answers on rational and reflective thinking. Half of the
participants were randomly assigned to each condition.
Problems used in Experiment 1 included base-rate
problems, conjunction problems, and ratio-bias effect
problems. Base-rate problems are equivalent to the classical
lawyer-engineer problem (Kahneman & Tversky, 1972) but
somewhat “easier”. Base-rates used were more extreme and
were expressed in absolute numbers (e.g., 85 lawyers and 15
engineers out of 100 persons). Individuating information
was less diagnostic of a given category (e.g., engineer) than
in the original problems. These changes allowed for a larger
base-line of statistical answers when compared to the
original problems.
Problems involving the conjunction rule appeared in a
format not used in previous research. Participants were
presented with two alternative solutions. The single case
solution was associated with a certain probability of success,
whereas the compound case solution involved two different
stages with independent probabilities of success. Each one
of these independent probabilities was higher than the
probability of the single solution but the conjunction of the
two was lower. For instance, one single agent can
accomplish a certain activity within a specified time period
with a probability of 60% (single case). Alternatively, two
independent agents can divide that activity in two parts and
finish them within a specified time period with probabilities
of 70% and 80%, respectively (compound case). Note that
the mean probability of success of the two agents is 75%,
but the probability of both agents finishing their parts in
time is only 56% (lower than the 60% probability of success
of the single agent). If our participants consider only how
large each independent probability is and neglect the
consequences of set intersection (conjunction) for the
compound case, this leads to a statistically incorrect answer.
The ratio-bias effect refers to the preference for equally
small or even smaller probabilities for success when they
are based on a larger sample size (Miller, Turnbull, &
McFarland, 1989). For instance, Kirkpatrick and Epstein
(1992) reported that 9 out of 100 is frequently preferred to 1
out of 10 probability of success, showing that this bias even
extends to cases where the ratio of the larger sample
actually represents a lower probability of success than the
ratio of the smaller sample. In the ratio-bias effect problems
used here, participants had to choose between two
probabilities of success presented in the form of large and
small samples. For the large samples, the absolute number
of favorable cases is obviously larger than in the smaller
samples. In the exclusion cases the smaller samples
correspond to a higher probability of success.

In all these problems statistical response alternatives
reflect “extensional” reasoning and non-statistical response
alternatives (to exclusion problems) reflect “non
extensional” reasoning. Extensional reasoning involves
taking into consideration set inclusion and/or intersection
(e.g., the consideration of base-rates, proportionality,
conjunction, etc.). Non-extensional reasoning corresponds
to the neglect of these problem features. (cf. Tversky &
Kahneman, 1983).
All problems in Experiment 1 and 2 had an inclusion and
an exclusion version. The exclusion versions (described
above) correspond to the format traditionally used in
research in judgments under uncertainty. The statistical and
non-statistical answers correspond to alternative response
options. The inclusion versions were the equivalent of
exclusion versions except that the statistical information was
inverted, so that both RB and H produced the same response
option, the dominant response. In base-rate problems, baserates and individuating information point to the same
answer. In conjunction problems, the response option based
on the conjunction of two items is not only less probable but
also less representative than the single response option. In
the ratio-bias effect problems, the larger sample is also a
higher probability than the smaller one.
Data analysis of Experiment 1 considered participants’
responses to 10 problems (5 base-rates problems, 2
conjunction problems, and 3 ratio-bias effect problems).
Dependent Measures To arrive at the H and RB estimates
used as dependent measures, the proportions of nonstatistical answers to exclusion problems and statistical
answers to inclusion problems were obtained for each
participant across problems and then used to compute
individual RB and H estimates from PDP equations (Jacoby,
1991) presented below.
RB=P(dominant answers inclusion)–P(non-statistical answers exclusion )
H=P(non-statistical answers exclusion ) / (1 – RB)

Estimation of the experimental parameters H and RB is
dependent on a minimum level of errors in exclusion tasks.
Perfectly statistical performance (i.e., no non-statistical
answers to exclusion problems) mathematically constrains
individual estimates of H to be zero (H = 0/(1 – RB) = 0).
As a precaution, participants with zero non-statistical
answers to exclusion problems were discarded for purposes
of analyses (see Jacoby, Toth, & Yonelinas, 1993).
Dependent measures for Experiment 2 were obtained in the
same manner.
Design The Design is a 2 X 2 X 2 X 2 factorial with
instructions type (intuitive and rational conditions), problem
versions (list 1 and list 2), and problem order (list A and list
B) between-subjects, and type of problem (inclusion and
exclusion problems) within subjects.
Results Several separate one-way ANOVAs showed neither
version effects nor order effects on the RB and H estimates.
The increase in the proportion of dominant answers
(inclusion problems) and the decrease in non-statistical

1295

answers (exclusion problems) from the intuitive to the
rational condition indicate that the instructions to consider
the problems as a scientist have enhanced participants’
performance (see table 1). An analysis of variance was
performed with instruction type as a between-subjects factor
and the RB and H estimates as repeated measures. The
analysis revealed a reasoning mode main effect, indicating
that H is greater than RB, F(1,36) = 127,89; p = 0.00
(MSE=0.04), and an instruction type X reasoning mode
interaction, F(1,36) = 3.75, p = .06 (MSE = 0.04), reflecting
the differential impact of instruction type on H and RB.
Changing from “rational” instructions to “intuitive”
instructions produced a strong reduction of RB, t(36) = 2.02,
p = .02; SD = 0.12 (one-tailed planned comparisons), while
leaving H constant, t(37) < 1; SD = 0.05 (two tailed planned
comparisons)1.
Discussion As predicted, RB was greater for rational
instructions when compared to intuitive instructions, while
H was largely unchanged across instructions sets. The
invariance of H across instructions is in line with previous
research on heuristics as natural assessments, showing
heuristic-based reasoning to be insensitive to incentives to
respond more thoroughly such as the use of pay-off matrices
(e.g., Tversky & Kahneman, 1974).
To further test the independent contributions of H and RB
to judgment it is crucial to show that, in contrast to
Experiment 1’s results, variables already known to affect
automatic processes change H but left RB invariant. Priming
effects have been investigated in judgment under
uncertainty by varying the order in which more rule-based
or heuristic perspectives are presented (e.g., Ginossar &
Trope, 1987). In a related vein, Experiment 2 explored
heuristic priming effects by manipulating the presentation of
neutral versus heuristic priming problems.

alternative response options, one of which was favored on the basis
of a large sample (indicating statistical reasoning) and the other of
which was favored by evidence from a much smaller sample (the
choice of which would indicate non-statistical processing based on
representativeness). In the inclusion versions of these problems,
both H and RB processes favored the same option. The material

also included heuristic priming problems, and neutral
problems (used in the priming and control condition,
respectively).
Besides sharing the same statistical principle as the target
problems, heuristic priming problems were very similar to
target problems in terms of their superficial structure
(subject matter and story outline) within each problem’s
type. There are, however, two main differences between
priming problems and target problems. First, priming
problems do not have inclusion versions; they all are
exclusion problems. Second, the target description
information of priming problems is so diagnostic that, even
in the face of opposing statistical information, the nonstatistical response option is more appropriate than the
statistical response option. As an example, consider a
population that consists of 80 men and 20 women (high
base-rate of men). One person is randomly chosen. This
person likes modern art, is fashion aware, and breast fed the
children. Is the person a woman or a man?
Table 1: Observed mean proportions of dominant answers
(D) for inclusion problems and non-statistical answers (NS)
for exclusion problems, and estimates of H and RB across
priming and control conditions.
Problem version
Inclusion (D) Exclusion (NS)
Exp. 1
Intuitive
condition
(n=19)
Rational
condition
(n=19)
Exp. 2
Control
condition
(n=37)
Priming
condition
(n=40)

Experiment 2
Participants The participants were 95 students (26 male
students and 69 female students) at Indiana University who
participated in partial fulfilment of course requirements.
Procedure and Material target problems were equivalent
to the problems used in Experiment 1 except that conjunction
problems were replaced by a new type of problem based on the law
of large numbers (LLN). In the exclusion version of LLN
problems, participants were asked to choose between two
1

In the experiments here reported, it is hypothesized that
the manipulations affect one of the reasoning modes in a given
direction, leaving the other invariant. To test for these hypotheses,
we used planned comparisons that are one-tailed tests for the
changes of the reasoning mode estimates in the predicted direction,
and two-tailed tests for the invariance of the other reasoning mode.
In other words, the hypotheses receive empirical support if Ho is
rejected in the first case and if Ho is accepted in the second case.
To decrease the probability of committing a Type II error when
accepting Ho, the value of α (probability of making a Type I error)
is set to .1. Thus, when predicting change (one tailed tests), Ho will
be rejected for α < .05; when predicting invariance (two-tailed
tests), Ho will be rejected for α < .1.

Estimates
H RB

.69

.59

.70

.10

.80

.47

.76

.33

.74

.42

.70

.32

.83

.53

.83

.30

Despite the high base-rate of men, the description is even
more diagnostic, and H-based judgments yield the better
answer.
Neutral problems do not involve inductive reasoning, nor
do they share similar superficial structures with priming and
target problems. They are small texts followed by a question
about mundane aspects of life. For instance, one neutral
problem tells the story of Chad, who went to New York,
loved it, but realized he would not like to live in such a big
city. The following question was “Where would you prefer
to live? a) In a big city like New York; b) In a small city like
Bloomington.”

1296

Participants were randomly assigned to a priming
condition or a neutral problem control condition. Problems
were organized in four blocks, one for each type of target
problem (base-rate problems, conjunction problems, ratiobias effect problems, and problems based on the law of large
numbers). In the priming condition, each block was
composed of six priming problems followed by two target
problems (one exclusion problem and one inclusion
problem) that shared the same superficial features of the
priming problems. The control condition was equivalent to
the priming condition, except that priming problems were
replaced by neutral problems. Data analysis considered
participants’ responses to 6 target problems (2 base-rate
problems, 2 law of large numbers problems, and 2 ratio-bias
effect problems).
Design The design is a 2 X 2 X 2 X 2 factorial with priming
manipulation (heuristic priming and control condition),
problem versions (list 1 and list 2), and problem order (list
A and list B) between-participants, and type of problem
(inclusion and exclusion problems) within participants.
Results Several separate one-way ANOVAs showed neither
version nor order effects on the RB and H estimates.
In the heuristic priming condition, the proportion of both
dominant answers for inclusion problems and non-statistical
answers for exclusion problems increased (see table 1). An
analysis of variance was performed, with heuristic priming
as a between-subjects factor and RB and H estimates as
repeated measures. The analysis revealed a reasoning mode
main effect, indicating that H is greater than RB, F(1,75) =
163,69 (MSE=0.05); p = 0.00, and a heuristic priming X
reasoning mode interaction, F(1,75) = 3.87; p = .05 (MSE =
0.05). Planned comparisons indicated that priming H
produced an increase in H, t(75) = 2.278, p = .01; SD = 0.24
(one-tailed) while leaving RB largely unchanged, t(75) < 1;
SD = 0.18 (two-tailed planned).
Discussion As predicted, heuristic priming problems with
highly similar superficial structures to the target problems
facilitated subsequent H processes without affecting RB.
Heuristic priming seems to be an effective way to
increase H. The individuating information of the target
problems used in the present experiments was less
diagnostic than in the original problems used by others (e.g.,
Tversky & Kahneman, 1974). It is likely that, at least for
some participants, this individuating information was not
diagnostic enough to trigger the automatic associative
process that characterizes H. Thus, Experiment 2’s priming
manipulation increased H’s activation level enough so as to
augment heuristic-based responses to subsequent target
problems that had weak individuating information. The
same priming manipulation did not affect RB because this
reasoning mode is a deliberate activity governed by
cognitive representations of inductive rules and is not based
on the automatic processing principles underlying H.

General Discussion
Judgment under uncertainty has recently been approached
from the perspective of dual-process models (e.g.,

Kahneman & Frederick, 2002; Stanovich & West, 2000).
These models converge in postulating that inductive
judgment may be based on heuristic (H) and/or on analytical
(RB) processing modes.
According to these models, H, as a largely automatic, fast,
and effortless process, consists of the spontaneous activation
of simplifying principles such as similarity and temporal
structure (e.g., the representativeness heuristic). In contrast,
RB is a controlled process involving the intentional and
effortful activation of a sequence of symbolically
represented information (inductive rules).
The above characterization of H and RB has been mostly
a matter of assumption, with surprisingly little direct
empirical support. The work reported here intended to
change this state of affairs. Specifically, we used the PDP to
assess both H and RB and to demonstrate theoretically
derived process-dissociations. The experiments showed that
variables traditionally associated with controlled processes
such as processing goals (experiment 1) affected RB but not
H processes. Conversely, a variable already known to affect
automatic processes such as procedural priming
(Experiment 2) affected H but left RB unchanged. The
process dissociations obtained across the two experiments
support the proposal that automatic versus controlled
processes in judgments are not an either/or proposition but
rather that both operate in an independent and parallel way.
In addition, the results demonstrate that simply assessing
statistical or non-statistical responses can not reveal the
level of rational or heuristic processing.
Past research found greater attention to base-rates when
participants were instructed to think like scientists (Zukier
& Pepitone, 1984) and greater use of base-rates to the extent
that it was instrumental to reach previously defined goals
(Ginossar and Trope (1987). Experiment 1’s results suggest
that these effects are independent of H and are exclusively
due to an increase in RB.
A number of dual-process models have argued that
heuristic and rule-based processes represent distinct
alternatives and that the processes do not co-occur (e.g.,
Kahneman & Tversky, 1973). Other models (e.g., Fiske &
Neuberg, 1990) have argued that RB and H represent two
ends of a continuum, and that movement toward one end of
the continuum necessarily coincides with diminished
activity on the other end. In contrast, the PDP approach
assumes that all judgments reflect the joint and independent
contributions of RB and H. Increases in one process do not
imply decreases in the other. Other dual-process models do
emphasize the simultaneous influences of heuristic and
systematic processes both in judgment under uncertainty
(e.g., Kahneman & Frederick, 2002) and in reasoning (e.g.,
Evans & Over, 1996; Johnson-Laird et al., 1999). However,
only the PDP approach also offers a means for
independently assessing the joint contributions of these
processes to performance on a single task.
The use of the PDP experimentally constrains the
automatic nature of H, defining it by the relation between
performance in inclusion problems and that in exclusion
problems. As a consequence, to be automatic, H must have
an obligatory nature in that it remains the same regardless of

1297

whether its influence facilitates or hampers performance.
Other uses of the term “heuristic reasoning” that does not
accommodate this conception of automaticity refer to
reasoning forms that could not be separated from
(controlled) RB using the PDP and as such are beyond the
scope of the present definition of H. Other dual-process
approaches to reasoning adopt a conception of automaticity
that is similar to our own (Kahneman & Frederick, 2002;
Stanovich & West, 2000). On the other hand, since RB does
not capture all forms of rule-governed cognitive activity but only
the deliberate use of certain statistical principles, other controlled
processes not anticipated by us may have also contributed to the
dominant answers to inclusion problems and non-statistical
answers to exclusion problems. Nevertheless, a nonrandom
distribution of such types of bias would certainly affect the PDP
estimates, rendering findings of invariance highly unlikely.

In the PDP model applied here (Jacoby, 1991), the RB
process constrains the influence of the H process. That is,
the equations are such that the influence of H will be
observed only in cases in which RB does not provide a
response. However, it is clear that automatic and controlled
processes do not always interact in this C-first fashion.
Instead, in some cases, it will be the automatic process that
dominates and constrains the application of control. For
example, on incompatible trials in the Stroop Task (i.e., the
word Blue written in red ink), the automatic habit to read
the word captures attention and interferes with the more
controlled process of naming the color of the ink (see
Lindsay & Jacoby, 1994 for an A-first application of the
PDP). Since the C-first model has consistently provided a
better account of results than the A-first model, it is the Cfirst analyses that are reported here. It is important to note
that, although the choice of which model to apply was an
empirical one, that choice did constrained subsequent
interpretation of our data.
In applying the PDP to inductive judgment, the present
work aims to contribute a clearer definition of the automatic
and intentional processes involved in inductive judgment. In
essence, the resulting dual-process approach explores the
operating principles and representational nature of human
inferences in light of advances in the social cognitive
literature toward a better and more articulated
comprehension of judgments under uncertainty. This work
is far from being completed.

Acknowledgments
Preparation of this paper was supported in part by the Grant
POCTI/PSI/47252/2002 from the FCT (Portugal).

References
Camerer, C. F. (1987). Do bias in probability judgment
matter in markets? Experimental evidence. American
Economic Review, 77, 981-997.
Evans, J. St. B. T. & Over, D.E. (1996). Rationality and
Reasoning. Hove, UK; Psychology Press.
Fiske, S. T., & Neuberg, S. E. (1990). A continuum of
impression
formation,
from category-based
to
individuating processes: Influences of information and
motivation on attention and interpretation. In M. P. Zanna

(Ed.), Advances in experimental social psychology (Vol.
23, pp. 1_74). San Diego, CA: Academic Press.
Ginossar, Z., & Trope, Y. (1987). Problem solving in
judgment under uncertainty. Journal of Personality and
Social Psychology, 52, 464-474.
Jacoby, L. L. (1991). A process dissociation framework:
Separating automatic from intentional uses of memory.
Memory and Language, 30, 513-541.
Jacoby, L. L., Toth, J. P., & Yonelinas, A. P. (1993).
Separating conscious and unconscious influences of
memory: Measuring recollection. Journal of Experimental
Psychology: General, 122, 139-154
Johnson-Laird, P.N., Legrenzi, P., Girotto, V., SoninoLegrenzi, M. &Caverni, J-P. (1999). Naive probability: A
mental model theory of extensional reasoning.
Psychological Review, 106 (1), 62-88
Kahneman, D., & Frederick, S. (2002). Representativeness
revisited: Attribute substitution in intuitive judgment. In
T. Gilovich, D. Griffin, & D. Kahneman (Eds.),
Heuristics and biases: The psychology of intuitive
judgment. Cambridge: Cambridge University Press.
Kahneman, D., & Tversky, A. (1972). Subjective
probability: A judgment of representativeness. Cognitive
Psychology, 3, 430-454.
Kahneman, D., & Tversky, A. (1973). On the psychology of
prediction. Psychological Review, 80, 237-251.
Kirkpatrick, L. A., & Epstein, S. (1992). Cognitiveexperiential self-theory and subjective probability:
Further evidence for two conceptual systems. Journal of
Personality and Social Psychology, 63, 534-544.
Lindsay, D. S., & Jacoby, L. L. (1994). Stroop processdissociations: The relationship between facilitation and
interference. Journal of Experimental Psychology:
Human Perception and Performance, 20, 219-234.
Miller, D. T., Turnbull, W., & McFarland, C. (1989). When
a coincidence is suspicious: The role of mental
simulation. Journal of Personality and Social Psychology,
57, 581-589.
Sherman, S. J., & Corty, E. (1984). Cognitive heuristics. In
R. S. Wyer & T. K. Srull (Eds.), Handbook of social
cognition (Vol. 1). Hillsdale, NJ: LEA.
Smith, E. R. (1994). Procedural knowledge and processing
strategies in social cognition. In R. S. Wyer & T. K. Srull
(Eds.), Handbook of social cognition (Vol. 1). Hillsdale,
NJ: Lawrence Erlbaum Associates.
Stanovich, K. E., & West, R. F. (2000). Individual
differences in reasoning: Implications for the rationality
debate. Behavioral and Brain Sciences, 23, 645-665.
Tversky, A., & Kahneman, D. (1974). Judgment under
uncertainty: Heuristics and biases. Science , 185, 11241131.
Tversky, A., & Kahneman, D. (1983). Extensional versus
intuitive reasoning: The conjunction fallacy in probability
judgment. Psychological Review, 90, 293-315.
Zukier, H., & Pepitone, A. (1984). Social roles and
strategies in prediction: Some determinants of the use of
base-rate information. Journal of Personality and Social
Psychology, 47, 349-360.

1298

