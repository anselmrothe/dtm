UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Linear Separability and Manifestations of Abstract Category Structures

Permalink
https://escholarship.org/uc/item/9vv762fz

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Author
Kenpei, Shiina

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Linear Separability and Manifestations of Abstract Category Structures
Shiina Kenpei (shiina@waseda.jp)
Department of Educational Psychology, Waseda University, Tokyo, 169-8050 JAPAN
Abstract
Experimental evidence thus far has been overwhelmingly
against the idea that linear separability is intrinsically
important in category learning. This paper tries to shed new
light on this old problem and shows conditions under which
linear separability promotes learning.

After the seminal study of Medin & Schwanenflugel (1981)
on the role of linear separability (LS) in categorization, it
has been repeatedly reported that LS has virtually no
positive effect on category learning especially when withinand between- category similarities are controlled. In this
paper, after formally defining LS and linear discriminant
function with research review, we introduce several
properties of LS that have been unnoticed in the past studies.
Then 2 experiments are reported that showed LS learning
advantages followed by discussion.

category, however, tends to underestimate the effect of
structures in the environment (Malt, 1995) because people
do not generally use theories or themes.
It is fair to say that experimental evidence thus far is
overwhelmingly against the idea that LS is essential in
category learning; Medin and Schwanenflugel (1981),
Kemler-Nelson (1984), Nakamura (1985), Wattenmaker et
al. (1986), and Wattenmaker (1995) reported that LS had
virtually no positive effect per se on category learning when
within- and between- category similarities are controlled.
Smith, Murray, and Minda (1997), who encourage prototype
model, also failed to provide evidence. But they raised
several key questions about how experimental stimuli are
generated. In particular, their demonstration of poor
differentiation of NLS categories in the universe of category
structures is quite insightful. More recently Blair and Home
(2001) have found an LS advantage, but their experimental
setting is different from that of the present study.

Definition and Research History
Suppose there are two Categories A and B comprised of m
instances each and instance i is represented by a pdimensional row vector: x i = ( xi1 , xi 2 ,...., xip ).
A binary
dimension is often called a feature in this paper. Linear
discriminant function (LDF) f is a linear function:
f ( xi ) = ω 1 x i1+ ω 2 x i 2 + ... + ω p x ip + c , such that
if f ( x i ) ≥ 0 then i ∈ Category A else i ∈ Category B, where
ω= (ω1, ω2, ...., ωp) is a weight vector and c is a constant. If
an LDF exists Categories A and B are linear separable.
The LDF approach has been a topic of intense debate
(Ashby & Maddox, 2005.) There are many studies which
directly compared learning rates of LS and NLS (not linear
separable) categories. Shepard and Chang (1963) compared
the difficulty of supervised classification learning for 6
category structures, and found that LS categories were
easier to learn. They suggested that "the easy classifications
tend to differ from the difficult ones in that their points can
be roughly partitioned into the two subclasses simply by
drawing a straight line through the two-dimensional space"
(p.102). Ashby and his colleagues (Ashby & Gott 1988;
Ashby & Maddox 1990, 1992) found a consistent advantage
for LS categories over NLS ones. Wattenmaker et al. (1986)
and Wattenmaker (1995) also found some positive effects of
LS. Specifically, strong interactions between category
structures and activated domain theories were found and
they were attributed to the coding of stimulus properties
induced by theories or themes. They concluded that when
theories are available, the compatibility between theory and
category structure will determine the ease of learning, which
gave an impetus to the theory-based category learning
models (Murphy & Medin, 1985). The idea of theory-based

Some Hidden Properties of Linear Separability
In the research of categorization, there are several conceptual and procedural problems that might have disturbed
the detection of LS effects.
Reconstruction of Feature Space Consider the binary,
abstract category structure shown in Table 1a. Category
structures of this type are used in numerous studies, and an
experimenter will assign somewhat arbitrary concrete values
(on a nominal, ordinal, interval, or ratio scale) to the 0’s and
1’s to generate stimulus manifestations (Table 1b). A key
assumption in such studies is that participants will and can
reconstruct the experimenter-defined abstract structure from
the experienced category instances, whereas in ignorance of
the experimenter’s feature value assignment people should
assign new abstract binary values to the manifested values
in the reconstruction process and thus the reconstructed
abstract structure may look like Table 1c. Moreover, in
order to control possible interactions between category
structure and feature manifestation, the concrete feature
values are ordinarily assigned randomly between subjects.
As such, a participant might reconstruct a category structure
that is a double transform of the original abstract structure.
Interpretation of Features Since we cannot numerically
add a circle and whiteness, the construction of an LDF
requires inter-dimensional additivity (including subtractivety) of the abstract values. If the binary features in Table 1c
are interpreted as nominal or logical variables, their addition
is unnatural and logical operations should be used instead. If
the values are interpreted as numerical, however, arithmetic
operations can be used and LDFs can be computed. Furthermore, since we are reluctant to compare, say, body weight
with annual income, dimensional homogeneity will promote
LDF construction together with additivity.

2152

Table 1 An Abstract Category Structure (Medin and Schwanenflugel(1981) Experiment 1, LS structure)
and a flow of typical categorization experiment
(a) Experimenter Defined Structure
Dim 1 Dim 2 Dim 3 Dim 4
Category
1
0
1
1
A
1
0
1
0
1
1
0
1
0
1
1
0
Category
1
0
0
1
B
0
0
1
0
0
1
0
0
0
0
0
1
Random Assignment of Concrete Values
Dim 1 Dim 2 Dim 3 Dim 4
1=white 1=square 1=big
1=right
0=black 0=circle 0=small 0=left

(b) An Experimental Manifestation
A1

A2

(c) Reconstructed Structure
Dim 1 Dim 2 Dim 3 Dim 4
1
1
0
1
1
1
0
0
1
0
1
1
0
0
0
0
Category
1
1
1
1
B
0
1
0
0
0
0
1
0
0
1
1
1

A4

A3

Category
A

B1

B2

B3

B4

Reconstruction of Abstract structure

Ease of Weight Computation In Table 1a we can easily
find an LDF with weights ω1=ω2=ω3=1, ω4=0 :
If dim1+ dim2 + dim3 ≥ 2 then Category A else B, (1)
while in Table 1c it is not easy to find an LDF:
If dim1 - dim2 - dim3 ≥ 0 then Category A else B. (2)
It seems unlikely that the computational cost is the same for
all LDFs: f(x)=3.7dim1-.9dim2+.2dim3+.4 should be harder
to compute than g(x) =dim1+dim2+dim3+0. In an extreme
situation where one dimension, say Dim2, is sufficient to
construct an LDF with null weights to irrelevant dimensions,
we have: If dim2 >c then Category A else B, which is often
called a rule and Dim2 is ordinarily called a defining
dimension. If an LDF happens to be: If dim1 - dim2 >0 then
Category A else B, this LDF is identical to a relational
property “larger than”: dim1> dim2. This example shows
that LS can capture relational properties, contrary to the
assertion of previous studies (e.g., Medin & Schwanenflugel
(1981)). “Larger than” relational property reduces to a pair
of defining features in binary cases. In sum, any category
structure that is partitioned by either a rule or a type of
simple relational property should be LS (but not vice versa),
and this fact supports the idea that LS should play some role
in categorization.
Within- and Between- Category Variation LS and NLS
categories are different in coherence and separation
measured by within- and between- category distances or
similarities (e.g., Smith et al, 1997; Blair & Homa, 2001).
Define Total- , Within-, and Between- category squared
distances as
⎛ Total ⎞
TSD ⎜ Squared ⎟ = ∑ ∑ dij2 = ∑ ∑ ∑ ( xik − x jk ) 2
⎝ Distances ⎠ i∈A∪ B j∈A∪ B
i∈A∪ B j∈A∪ B k
⎛ Within ⎞
⎛ Between ⎞
WSD ⎜ Squared ⎟ = ∑ ∑ dij2 + ∑ ∑ dij2 , BSD ⎜ Squared ⎟ = ∑ ∑ dij2
Distances
⎝
⎠ i∈A j∈A
⎝Distances ⎠ i∈A j∈B
i∈B j∈B
then it is easy to find a relation: TSD=WSD+2BSD.
(3)
WSD measures category coherence, and BSD category
separation. Equation (3) shows that with TSD fixed, WSD
and BSD are negatively correlated, as are category
coherence and separation. An alternative way of defining
category coherence and separation is through the totalwithin-, and between- category variances as in ANOVA:
Define TV, WV, and BV as follows:

TV =
WV =
BV =

∑ ∑ (x

i∈ A ∪ B k

ik

− xk ) 2

∑ ∑ (x

ik

− x Ak ) 2 +

∑ ∑ (x

Ak

− xk ) 2 +

i∈ A k

i∈ A k

∑
∑ (x
i∈ B k

∑ ∑ (x

i∈ B k

ik

− x Bk ) 2

Bk

− xk ) 2

where
xk = ∑ xik / 2m , x Ak = ∑ xik / m , xBk = ∑ xik / m .
i∈A∪ B

i∈B

i∈A

TV is psychologically interpretable as the diversity of the
overall configuration of instances, WV as the withincategory variation, and BV as a measure of separation or
contrast between two categories. We have an interesting
relation similar to (3), namely,
TV=WV+BV
(4)
which again shows a negative correlation between
coherence and separation. With additional work relations:
TSD = 4mTV , WSD = 2mWV , BSD = mWV + 2mBV
can be derived and we find that :
TSD=WSD+2BSD=4mTV=4mBV+4mWV.
As an index of category separation, Correlation Ratio:
(5)
η 2 = BV / TV = (2 BSD − WSD ) / TSD
is used in the sequel, which has the merit of permitting both
binary and continuous dimensions. This index ranges over
[0, 1], with larger values indicating a better separation of
categories. For binary dimensions Structural Ratio (additive
version) is often used and we have the relation between the
two indexes:

∑ s + i∑
∑s
∑ within
similarity i∑
∈A j∈A
∈B j∈B
ij

SR =

∑ between
similarity

=

2∑

ij

∑

i∈A j∈B

sij

=

2mp − 2TV (1 − η 2 )
2mp − TV (1 + η 2 )

Although it is not impossible to set up LS and NLS
structures with equated η2 , in many cases LS categories
have smaller WV and thus larger BV, while NLS categories
have larger WV and smaller BV. It seems, therefore, that
NLS categories are less easily discriminated and will have
slower learning rates. A similar argument holds for the
relationship among TSD, WSD, and BSD as well.
Given the properties pointed out in this section, the
question of whether LS per se is advantageous to learning

2153

Experiment 1a

1.0

0.9

PROBABILITY CORRECT

under some conditions still deserves investigation. The
present study tries to reexamine the effects of LS by
arranging conditions in which several of the following
requirements are satisfied. R1) Reconstruction of the feature
space is a transparent process for subjects and the
reconstructed abstract structures are not too diverse. R2)
Interpretation of reconstructed features is unambiguous. In
particular, the features are interpreted as continuous and
additive (homogeneous) with constant dimensional polarity.
R3) LDF weights are simple, and promote relational
properties (e.g., “larger than”) or rules. The three
requirements are all designed to promote the LS advantages.
Finally, R4) within- and between- category variations are
controlled in terms of η2 , respecting the tradition in this
field.

0.8

0.7

LS(η2=.143)
NLS(η2=.143)
LS-NOISY(η2=.136)
NLS-NOISY(η2=.135)

0.6

0.5
1-40

41-80

81-120

121-160

161-200

BLOCKS

Figure 1 Learning Curves of Experiment 1a

Procedure To each condition 28 subjects were randomly
assigned. Twenty-five randomized runs were used to make a
total of 200 stimulus presentations. The experiment was run
individually and was subject-paced. After a subject sat in
front of a CRT screen, the instruction was appeared on the
screen. Then a stimulus was presented one at a time and
his/her task was to classify the stimulus into either Category
A or Category B by pushing two response keys. An
immediate feedback was given and then the next stimulus
was presented. Proceeding in this way, a total of 200
presentations were made. The labeling of categories and
response keys were randomly assigned across subjects.
Results and Discussion The learning curves for the four
conditions are shown in Figure 1. There was an interaction
between category structure and noise. In no-noise conditions
the categories were easier to master than in noisy conditions
but the LS categories were easier to learn only in the noisy
condition. Logistic regression analysis revealed that the LS
effect was significant (χ2(1) =20.38, p<.01), the effect of
noise was significant (χ2(1) =727.49, p<.01), and the
interaction between them were significant (χ2(1) =10.90,
P<.01). Post hoc test by Tukey method revealed that there
was no significant difference between the LS no-noise and
NLS no-noise conditions across blocks.
The values of η2 for the four conditions were virtually the
same and thus the LS gain in the noisy condition is not
attributable to the category variability: The
results showed evidence that there are
Table 2 An Abstract Category Structure
situations in which LS without favorable
Medin and Schwanenflugel(1981) Experiment 1, NLS structure
properties (large η2, relational properties, and
(b) Noisy Experimental Manifestation
(a) Experimenter Defined Structure
Dim 1 Dim 2 Dim 3 Dim 4
rules) can promote category learning. One
Category
1
0
0
0
common property of previous studies such as
A
0
1
1
1
Medin and Schwanenflugel (1981) that found
1
1
1
0
no positive LS effect is that the dimensions
1
0
1
1
Category
0
1
1
0
were binary. Consistent with these studies,
B
1
0
0
1
the binary valued dimensions in the no-noise
0
0
0
0
condition did not produce an LS advantage,
0
0
0
1
whereas in the noisy conditions where the
1 -> long bar (145 dots)
random perturbation suggested to the subjects
0 -> short bar (100 dots)
that the dimensions were continuous, the LS
The base is 20 dots
structure was easier to master.

Using the LS structure in Table 1a and NLS one in Table 2a,
a set of bar charts was generated as shown in Table 2b (only
the NLS set of bar charts are shown.) Relating bar lengths
to dimension values satisfies R1, R2, and R3, and the
category structure complies with R4.
In the original study of Medin and Schwanenflugel
(1981), binary qualitative features were used and the LS and
NLS structures were equalized in terms of η2=.143. In the
present experiment 0 referred to a short bar and 1 referred to
a long bar and no random assignment of concrete values
were performed, that is, the subjects experienced the same
set of manifested stimuli. Evidently, if subjects construct an
LDF similar to (1) the categories can be learned perfectly.
The goal of Experiment 1a is to contrast the effect of manifestation of dimensions with the original experiment in
which LS category was no easier to learn. Since the possibility remains that subjects interpret the bar length as a discrete feature, noisy conditions were arranged where bar
length was fluctuated with small random numbers ranging
from -9 to 9 to discourage the subjects from interpreting the
dimensions as binary. Noisy conditions will also discourage
memorization strategies. There were 4 conditions
combining Factors A and B (Factor A: LS vs. NLS, Factor
B: no-noise vs. noisy). The subjects were 112 students of
Waseda University.

2154

Table 3 NLS Abstract Category Structures
in Experiment 1b
LS structure is shown in Table 1c
NLS
Dim 1 Dim 2 Dim 3 Dim 4
1
0
1
1
0
1
0
0
0
0
1
0
0
1
1
1
Category
0
0
0
0
B
1
1
1
1
1
0
0
1
1
1
0
1
Category
A

1.0

0.9

PROBABILITY CORRECT

Why, then, do binary dimensions impair learning of LS
categories? As mentioned previously, the concept of LS in
general (and LDFs in particular) is meaningful in a
continuous space, because summation and multiplication are
valid only when the values are on an interval or on a ratio
scale. It follows that, for a summation strategy to be feasible,
the feature values should be interpreted as continuous even
if they can only take discrete values. In ordinary situations,
however, binary features are interpreted as nominal values,
preventing multiplication and summation and rendering the
concept of LS irrelevant.
Experiment 1b
It seems that previous studies assume that there are no
differences in the ease of setting up LDFs. In prototype
models, in particular, subjects should always set up LDFs.
Although Experiment 1a produced some evidence that LS
promotes learning, the LDFs to be derived have only
positive, unit weights (see equation (1)) and thus are easy to
compute. In Experiment 1b a variation of the original
abstract structure was used to introduce negative weights,
making the LDF computation more difficult. Even if
subjects are able to use LDFs in some situations, they might
fail to utilize negative weights and the LS effect may vanish.
Category Structure The two conditions compared were LS
(Table 1c) and NLS (Table 3) structures with noise. The LS
structure was arranged by reversing the abstract values of
dim2 and dim3 in Table 1a. The LDF thus takes the form of
equation (2). The NLS structure was arranged by first
reversing the values of dim2 and dim3 in Table 2a and
changing the order of dimensions to dim3, dim4, dim1,
dim2. Note further that 7 out of 8 stimuli in both structures
are common, which may control memorization effects.
Subjects and Procedure The subjects were 32 students of
Waseda University and they were randomly assigned to the
two equal-sized conditions. None of these subjects
participated in Experiment 1a. The general procedure was
identical to that of Experiment 1a.
Results and Discussion Learning curves are depicted in
Figure 2. Evidently, no difference was found between the
LS and NLS conditions (χ2(1)=.3572, P>.5). The results
indicate that an LDF with negative weights did not promote
category learning, and suggest that the ease of LDF
computation would affect LS category learning.

0.8

0.7

0.6

LS-NOISY(η2=.139)
NLS+NOISY(η2=.134)

0.5
1-40

41-80

81-120

121-160

161-200

BLOCKS

Figure 2 Learning Curves of Experiment 1b

Figure 3 Stimulus Arrangement in Experiment 2

Experiment 2
In Experiment 2, using bar charts with three bars as stimuli,
we highlight the effects of one dimensional rules and
“longer than” relational properties (RP) that are sufficient
conditions for LS. Specifically, we contrast the LS+RULE
and LS+RP category structures to two NLS structures, one
with the matched-η2 and the other with a small η2.
Category Structure The numerical values of the experimental stimuli with three bars x, y, and z are summarized in
Table 4. The position of each stimulus in the stimulus space
is represented in Figures 3a and 3b, where each axis corresponds to one of the bar lengths and the center (centroid) of
each cube corresponds to the coordinates in Table 4. Two
factors were considered. Factor A, concerned with structural
differences, includes four conditions: LS with a relational
property (LS+RP), LS with a defining dimension (LS +
RULE), NLS with a small η2 (NLS-small-η2 ), and NLS
with a large η2 that matches the η2 of LS + RP and LS +
RULE conditions (NLS-matched-η2). Factor B comprised
the no-noise and noisy conditions as in Experiment 1. The
no-noise condition is explained first.
No-noise Conditions In this condition, bar charts corresponding to the centroids of the cubes in Figures 3a and 3b
are presented to subjects. Category structures are defined by
how each cube is associated with a category label (Table 4.)
In the LS+RP condition (LS with a relational property ),
cubes A, B, C, and D in Figure 3a were combined to make

2155

PROBABILITY CORRECT

PROBABILITY CORRECT

1.0
Category 1, and E, F, G, and H to make Category 0: The
category structure has a “longer than” relational property :
if z > y then Category 1 else 0. In the LS+RULE
0.9
condition cubes A, B, G, and H in Figure 3a were combined
to make Category 1 and C, D, E, and F Category 0, where
0.8
Dimension x is the defining dimension (Table 4.) In the
2
NLS-small-η condition, A, B, E and F were combined to
0.7
make Category 1 and the others were combined to make
2
Category 0. Finally, in the NLS-matched-η condition, A, B,
LS+RP (η2=.400)
G and H of Figure 3b were combined to make Category 1
0.6
LS+RULE(η2=.398)
and the others were combined to make Category 0. The
NLS-small-η2(η2=0)
NLS-matched-η2(η2=.399)
LS+RP, LS+RULE, and NLS-matched-η2 conditions have
0.5
2
2
1-40
41-80
81-120
121-160
161-200
the same η value, while the NLS-small-η condition have a
2
BLOCKS
much smaller value of η but have the same set of instances
as those of the LS+RP and LS+RULE conditions.
Figure 4 Results of Experiment 2 no-noise conditions
1.0
Noisy Conditions While in no-noise conditions only the
LS+RP (η2=.365)
centroids of the cubes were used, in noisy conditions
LS+RULE(η2=.365)
random samples from inside the cubes were presented to the
0.9
NLS-small-η2(η2=0)
subjects as perturbation of controids. The side length of the
NLS-matched-η2(η2=.360)
cube was 60 dots. This procedure is equivalent to adding a
0.8
uniform noise term whose boundary is the cube surface to
the cube centroid.
0.7
Procedure The subjects were 128 undergraduate and
graduate students of Waseda University. No subject
participated in Experiment 1. The subjects were randomly
0.6
assigned to one of the eight equal-sized experimental
conditions. The general procedure was identical to that of
0.5
Experiment 1 and 25 randomized runs were used to make a
1-40
41-80
81-120
121-160
161-200
total of 200 stimulus presentations.
BLOCKS
Results The learning curves for 8 conditions are shown in
Figure 5 Results of Experiment 2 noisy conditions
Figures 4 and 5. Overall they show that the LS categories
than” relational property and those with a defining
were easier to learn than NLS ones even when η2 values
dimension are easier to learn even when η2 values are
were equated.
equated. Furthermore the results were consistent with the
The Analysis of No-noise Condition Logistic regression
idea that η2 affects performance: the two LS categories were
analysis revealed that the variable of category type (LS+RP,
easier to learn than the NLS-small-η2 category (LS+RP and
LS+RULE, NLS-small-η2, and NLS-matched-η2) produced
NLS-small-η2, q(4, ∞)=29.20, P<.01 ; LS+RULE and NLSdifferent learning rates (χ2 (3)=452.42, P<.001). Multiple
small-η2, q(4,∞)=15.59, P<.01). Interestingly, the difference
comparison between the four category types revealed that
between the LS+RP and LS+RULE conditions was also
all the differences were significant. Because the differences
significant (q(4,∞)=16.95, P<.01) indicating that the “longer
2
between the NLS-matched-η and LS+RULE conditions
than” property was more advantageous to category learning
2
(q(4, ∞)=5.25, p<.01) and between the NLS-matched-η and
than the defining dimension in the present experiment. The
LS+RP conditions (q(4, ∞)=21.08, p<.01) were significant,
difference between the LS+RULE and NLS-matched-η2
we obtained evidence that LS categories with a “longer
was, however, not too compelling. In
TABLE 4 Numerical Values of Cube Controids
particular, there was no difference between
and Category Structures
them in the third, fourth and fifth blocks
Category Structure of Figure 3a
Category Structure of Figure 3b
(q(20, ∞)=1.63, P>.05 ; q(20, ∞)=1.38,
Category Structure
Dimensional Values of
Dimensional Values of Category Structure
P>.05 ; q(20, ∞)=0, P>.05, respectively)
Cube Cube Centroid
Cube Cube Centroid
The Analysis of Noisy Conditions The
x
y
z LS+RP LS+RULE NLS-small-η2
x
y
z NLS-matched-η2
120
65
76
1
1
1
95 120 103 1
A
A
learning curves and statistical results were
101
54 112
1
1
1
105
80
97 1
B
B
very similar overall to those of the no-noise
86
69 133
1
0
0
86
69 133 0
C
C
conditions. Logistic regression analysis
75 110 139
1
0
0
75 110 139 0
D
D
revealed that the effect of category
80 135 124
0
0
1
80 135 124 0
E
E
99 146
88
0
0
1
99 146
88 0
F
F
structure on learning rates was significant
114 131
67
0
1
0
120
65
76 1
G
G
(χ2 (3)=317.38, P<.001) and multiple
125
90
61
0
1
0
140
75
39 1
H
H
comparison revealed that the differences
Notes Relational property : if z>y then category 1 else 0 exists in LS+RP
between the four conditions were all

x is a defining deminsion in LS+RULE

2156

reliable : Again the differences between the NLS-matchedη2 and LS+RULE conditions (q(4,∞)=5.15, P<.01) and
between the NLS-matched-η2 and LS+RP conditions
(q(4,∞)=13.10, P<.01) were both significant. The LS
categories with a “longer than” property and with a defining
dimension were easier to learn than the NLS-small-η2
category (LS+RP and NLS-small-η2, q(4, ∞)=29.05, P<.01 ;
LS+RULE and NLS-small-η2, q(4, ∞)=16.60, P<.01 ).
Finally, the difference between the LS+RP and LS+RULE
conditions was again significant ( q(4, ∞)=8.09, P<.01).
Joint analysis of noisy and no-noise conditions. Logistic
regression analysis showed that the effect of category type
(χ2(3)=627.66, p<.001) and the effect of noise
( χ2(1)=158.39, p<.001) were both significant.
Summary and Discussion Essentially, the results showed
that the differences between LS+RP and LS+RULE,
LS+RULE and NLS-matched-η2, and NLS-matched-η2 and
NLS-small-η2 were all reliable and clearly the LS+RP
condition was the easiest to learn. Therefore we can state the
following: (1) We obtained evidence that “longer than”
relational properties and defining dimensions, which can be
derived from LS but never from NLS, both promote
category learning. This will be so even when contrast NLS
category structures have almost the same η2. (2) At the
same time, the results suggested that relational properties
could be more effective than defining dimensions. (3) The
difference between the LS+RULE and NLS-matched-η2
conditions without noise would not be too compelling.
These results clearly indicate that some types of LS
category are easier to learn when the four requirements
described at the end of introduction are satisfied. A next
question is whether this is also the case in the absence of
such beneficial properties. The results of Experiment 1b and
numerous existent studies strongly suggest that the LS
advantage will vanish.
In this experiment the “longer than” relational property
was more effective than the defining dimension, which may
show that people are more sensitive to emerging relational
properties than they are to parent dimensions at least under
some conditions. The apparent fact that bar charts are used
to compare values supports the idea that the bar chart
stimuli would have promoted dimensional comparisons and
helped subjects to find relational properties. Another
interpretation is, because the separation of values on
Dimension x in the LS+RULE condition was small (there
was only 2 dot difference); the defining dimension did not
have perfect validity especially in the noisy condition in
which random noise on the original dimensional values
made the difference quite imperceptible.

General Discussion
This paper does not claim that LS should be beneficial in
all situations and thus contributes little to the revival of prototype theory. This paper does deny the assertion, however,
that LS has nothing to do with categorization. It is highly
plausible that high structural coherence, relational properties,

and rules will promote LS category learning. One reason
why previous studies failed to demonstrate positive effects
of LS is that they used qualitative and/or heterogeneous dimensions; under such situations, LS categories would not be
able to enjoy the benefits of relational properties and rules.
The generality of the present results should be examined
further, paying close attention to the scale type of
dimensions, because the use of homogeneous dimensions
would have promoted the evaluation of relative lengths of
the bars. As in the numerous previous studies, if we had
used heterogeneous and qualitative dimensions instead, the
results would have been greatly different. Because there is
no logical reason that stimulus dimensions should be
homogeneous, it is safe to say for the present that LS is
advantageous to category learning only when dimensions
are homogeneous and/or directly comparable inducing
relational properties and rules. Conversely, because there is
no necessity that stimulus should be comprised of binary
features and in view of the plain fact that many dimensions
of natural categories are continuous, further studies
contrasting binary and continuous dimensions will be
needed.
References
Ashby, F.G., & Gott, R.E. (1988). Decision rules in the perception
and categorization of multidimensional stimuli. Journal of Experimental Psychology: Learning, Memory, and Cognition, 14, 33–53.
Ashby, F.G., & Maddox, W.T. (1992). Complex decision rules in
categorization: contrasting novice and experienced performance.
Journal of Experimental Psychology: Human Perception and
Performance, 18, 50–71.
Ashby, F.G., & Maddox, W.T. (2005). Human Category Learning. Annual Review of Psychology, 56, 149-78.
Blair, M., & Homa, D. (2001). Expanding the search for a linear
separability constraint on category learning. Memory & Cognition,
29 (8), 1153-1164.
Kemler-Nelson, D.G. (1984). The effect of intention on what
concepts are acquired. Journal of Verbal Learning and Verbal
Behavior, 23,734-759.
Malt, B.C. (1995). Category coherence in cross-cultural perspective. Cognitive Psychology, 29, 85-148.
Medin, D.L., & Schwanenflugel ,P.J. (1981). Linear separability in
classification learning. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 8, 37-50.
Murphy, G.L., & Medin, D. (1985). The role of theories in conceptual coherence. Psychological Review, 92, 289-316.
Nakamura, G.V. (1985). Knowledge-based classification of illdefined categories. Memory & Cognition, 13, 377-382.
Shepard, R.N., & Chang, J.J. (1963). Stimulus generalization in the
learning of classifications. Journal of Experimental Psychology,
65, 94-102.
Smith, J. D., Murray, M. J., & Minda, J. P. (1997). Straight talk
about linear separability. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 23, 659-680.
Wattenmaker, W.D., Dewey, G.I., Murphy, T.D., & Medin, D.L.
(1986). Linear separability and concept learning : Context, relational properties, and concept naturalness. Cognitive Psychology,
18, 158-194.
Wattenmaker, W.D. (1995). Knowledge structures and linear
separability: integrating information in object and social
categories. Cognitive Psychology, 28, 274-328.

2157

