UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Strategies for Evaluating Opinions: A Cross-Cultural Study

Permalink
https://escholarship.org/uc/item/9r14d6qp

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Adachi, Kuniko
Kawasaki, Yayoi
Mercier, Hugo
et al.

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Strategies for Evaluating Opinions: A Cross-Cultural Study
Hugo Mercier (hmercier@isc.cnrs.fr)
Institut Jean Nicod, 1bis, Avenue Lowendal
Paris, 75007 France

Jean-Baptiste Van der Henst (vanderhenst@isc.cnrs.fr)
Institut des Sciences Cognitives, 67, boulevard Pinel
Bron, 69675 France

Hiroshi Yama (yama@mail.kobe-c.ac.jp)
School of Human Sciences, Kobe College, 4-1 Okadayama
Nishinomiya, 662-8505 Japan

Yayoi Kawasaki (yayoi@iris.dti.ne.jp)
School of Human Sciences, Kobe College, 4-1 Okadayama
Nishinomiya, 662-8505 Japan

Kuniko Adachi (k-adachi@osa.att.ne.jp)
School of Human Sciences, Kobe College, 4-1 Okadayama
Nishinomiya, 662-8505 Japan

psychologists, under the headings of persuasion and attitude
change. Here we will restrain the investigations to simple
instantiations of these categories, using numerical estimates
and giving only limited cues that might allow differentiating
the value of the different opinions. Numerical estimates
allow a precise evaluation of the way the various opinions
involved are taken into account in establishing a final
estimate.

Abstract
This paper aims at checking the cross-cultural validity of
well-know findings concerning the way people integrate
communicated information. In a first experiment, a Japanese
and a French population weighted the advices they were given
in similar ways. In a second experiment, both populations
showed some evidence of bias towards their own answer
relative to an advice. In both experiments, participants were
more prone to choose one of the possible answers than to
average over them. By replicating what had been previously
found only in Western populations, these findings contradict
some cross-cultural predictions.

Mechanisms used in evaluating opinions

Introduction
Should you take your umbrella when leaving for work this
morning? The weather forecast is good, but these clouds
look quite menacing. Should you sell your shares in
TransGear Inc.? Some experts say they will rise, but others
predict a sudden drop. In everyday life we often have to
rely, at least in part, on the opinions of other people.
However, more often than not, these opinions are not in full
agreement with each other. They may even openly clash, or
they can contradict something you already thought. To deal
with all these cases, we must be able to assess the value of
the different pieces of information at our disposal, perhaps
to reject some of them, before making our decisions.
This paper will focus on the cases in which only two
opinions are involved. They can either both come from
some other people and pertain to a matter that we have no
knowledge of; or an opinion can be given by someone else
and be compared to our own. Broadly construed, this kind
of phenomena has been extensively studied by social

Several mechanisms designed to deal with these situations
have been proposed. The first is the weighting heuristic
(Yaniv, 1997). It is used when the quantitative estimates
given are accompanied by a range of certainty. For example,
one might predict that the chances that it rains tomorrow are
of 50%, and give a range of 40 to 60%. Since it has been
observed that confidence is correlated with accuracy (see
Yaniv, Yates, & Smith, 1991), it is possible to use the size
of the interval as a clue to the accuracy of the estimate. This
is what the weighting heuristic does: it weights the different
estimates by the relative size of the related interval: the
wider the interval of an estimate, the smaller its weight.
Other mechanisms are involved when one’s own opinion is
involved in the process. In this case, the more robust finding
is the self-other effect: it is a general bias to discount the
other person’s opinion and to stick with one’s initial
estimate (Harvey & Fischer, 1997; Lim & O'Connor, 1995;
Yaniv, 2004; Yaniv & Kleinberger, 2000); see also (Mercier
& Van der Henst, 2005). For a personal estimate of 0, and a
communicated estimate of 100, the average final estimate
will be around 30. This bias seems to depend on the distance
separating one’s original opinion from the one that is

1817

communicated: as the distance increases, the discounting of
the other’s opinion also increases; this has been dubbed the
distance effect (Yaniv, 2004).
In a reanalysis of the literature on the topic, Soll and
Larrick, (submitted) claim that the classic way to look at
these effects is misleading. Averaging the results of all the
subjects gives the idea that most people provide a final
estimate at around one third of the distance between their
original estimate and the one that was given by someone
else. However, the individual data indicates that only a few
people actually apply this strategy: most people either
choose frankly to go for one of the estimates – the choosing
strategy – or just average between the two – averaging
strategy. In their paper, Soll and Larrick discuss the two
strategies and argue that the use of the averaging strategy is
generally the most normative/rational one. They conclude
that people use the choosing strategy too often.

Cross-cultural considerations
The weighting heuristic, the self-other effect and the
preference for the choosing strategy seem to be quite robust
results. However a major concern could be raised regarding
these studies: all of them were conducted with Western type
populations. Would we observe the same effects in
populations with a widely different cultural setting? Over
the past few years experimental cross-cultural psychology
has made very surprising discoveries showing differences in
the way even very basic cognitive mechanisms, such as
perception, are put to work by various populations (Lehman,
Chiu, & Schaller, 2004; Nisbett & Miyamoto, 2005; Nisbett,
Peng, Choi, & Norenzayan, 2001). The most studied
contrast, between Easterners and Westerners, is fully
relevant here: the cross-psychological literature can give us
plenty of reasons to expect discrepancies between these two
populations on the topic at hand.
The points where the greatest differences could be
predicted are the preference for choosing instead of
averaging and the self-other effect. In the former case, a
wealth of literature in anthropology, sociology, history and
now in experimental psychology stresses the importance for
Easterners of finding a “middle way” (Lloyd, 1990;
Nakamura, 1964/1985). To give a taste of the experimental
evidence, in the study 3 of Peng and Nisbett (1999)
participants were presented with a scenario in which two
persons were in conflict. Chinese participants were inclined
to find a “middle way” by taking into account both opinions
in their judgment when American participants tended to side
decidedly with one of the characters (see also Briley,
Morris, & Simonson, 2000). In the present context, it might
be predicted that Easterners would be more prone to use the
averaging strategy than Westerners. This tendency to look
for a “middle way” could also bear on the self-other effect,
in which case a decrease in its strength could be predicted
among Easterners. A lessening (or even a reversal) of this
effect could also be expected on the grounds that Easterners
tend to be more collectivistic than Westerners, and so

should take the other’s opinion more into account1 (e.g.
(Triandis & Suh, 2002) but see (Oyserman, Coon, &
Kemmelmeier, 2002). Peng and Nisbett (1999) also argued
that Easterners are not so put out by contradiction as
Westerners are. It is thus possible that Easterners do not see
the opinion of the other as clearly contradicting their own,
even if they are far apart. That would lead to an attenuation
of the distance effect.
If it is possible to predict some cross-cultural variation,
one might also find it justified to stick with the standard
stance of cognitive psychology and favor a more
universalist view. The weighting heuristic is a highly
valuable tool that yields good results in a broad range of
situations, thus it has good reasons to be widely shared
(Yaniv, 1997). The self-other effect may have a sound
evolutionary rationale, and the product of an adaptation
present everywhere (Mercier & Van der Henst, 2005). We
don’t have the space here to evaluate the strength and the
precise predictions of the classic and the cross-cultural
views: the point is that it would be premature to count on
the universality of all the mechanisms previously found only
among Western populations before some cross-cultural
studies have been performed. The present study is to be
thought of as a first step in this direction. Since we don’t
make fine cross-cultural predictions, it is possible to take
two populations that may not be the ‘purest’ instances of the
Western and Eastern cultural types: Japanese and French.
The first experiment that we carried out aimed to measure
the effect of the weighting heuristic alone. This experiment
is a necessary prerequisite before studying the self-other
effect since if any difference is to be found in the way
Japanese and French people apply the weighting heuristic, it
might then be used to explain away any difference observed
in the strength of the self-other effect. Moreover and as
already stated, the purported preference for the ‘middle
way’ among Easterners might lead one to expect a different
distribution of the answers, with more Japanese people
using the averaging strategy and less the choosing strategy.

Experiment 1
Method
The aim of this first experiment is to check that the two
populations under study use the weighting heuristic in a
similar way. To do so, we used an experimental paradigm
close to that of Yaniv (1997). Participants were given
booklets with instructions and questions. The instruction
went as follows2,3:
In this experiment, you will have to imagine that you are
traveling in a foreign country. You have very limited
knowledge of this country, and you would like to know more
1

Insofar as this other is construed as belonging to the in-group.
All the excerpts from the material are translated from French.
3
A note on the translations from French to Japanese: all the
materials were first written in French, then translated into
Japanese, and then back-translated into French. All discrepancies
were resolved and the texts were checked again.
2

1818

about its history. To do so, you ask French [Japanese]
people who have lived in this country for quite a long time
to answer your questions. Below you will find the answers
of these different persons to your questions. These answers
are two dates between which the person who answered
thinks the event happened. Here is an example:
The question you have asked: In what year did event X
happen?
The answers you obtained:
Person 1: 1896-1904
Person 2: 1920-1960
Depending on the questions, the number of answers can
be different. Your task will be to try to estimate the date in
which you think the event happened by taking into account
the different answers that were given. You will have to
provide a precise answer and two dates between which you
think the event happened.
Fifteen sets comprising a question and its answers were
included in each booklet. Each question was related to a
different event (event A to O). Twelve of these questions
were used to study different mechanisms, and we won’t use
them here4. The three relevant questions had two person
answering them and the answers were designed so that one
of them would be precise (interval width: 8 years) and the
other imprecise (interval width: 40 years). The midpoints of
the two intervals were 40 years apart, and they were
scattered in the last two centuries among the three questions.
So for example, one of the informants could answer ‘18961904’ (precise answer), and the other ‘1920-1960’
(imprecise answer). For them not to be confounded with the
actual answer of the participant, the answers given to the
participants will be called ‘advice’ thereafter.
The experiment was run in classrooms with
undergraduates in business and economic science (Japan,
N=122; France, N=123)5.

Results and discussion
In order to know whether participants are effectively using a
weighting heuristic we have to compute the answers
predicted by that heuristic, and see if it gives a better
account of the subjects’ results that the default strategy of
simply averaging between the given advices6. As defined by
Yaniv (1997) the weighting heuristic assigns weight
inversely related to interval width so that the result is drawn
towards the more precise answers (the result is the center of
mass of the weighted answers). Once we have the results
predicted by the weighting heuristic and by simple
averaging, we calculate the normalized error to evaluate the
fit between the prediction and the participant’s answer. The
4

Thus they can be considered here as fillers preventing subjects
from establishing a simple answering strategy.
5
In both experiments the only results kept were those of
participants that were of Japanese (French) nationality and who
had Japanese (French) as their mother tongue.
6
The results predicted by averaging and by weighting are
computed using the midpoints of each of the two intervals given to
the participant.

normalized error is |a – p|/w where a is the answer of the
participant, p is the answer predicted by the strategy whose
fit we wish to measure, and w is the width of the
participant’s answer; By taking the width into account, this
measure allows us to pool the data from all the questions
together (see Yaniv, 1997). In both populations, the fit of
the weighting heuristic was superior to that of averaging:
0.64 for weighting and 0.81 for averaging in Japan, 0.77 for
weighting and 1.11 for averaging in France (small numbers
indicate a better fit). Both differences are statistically
significant using paired t tests (Japan: t(121)=3.66, p<0.005;
France: t(122)=3.04, p<0.005). The overall strength of the
weighting heuristic can be assessed by computing the
deviation from the answer predicted by averaging towards
the more precise advice. As an example, using the two
advices given above, averaging yields 1920, and we can see
how much the participants’ answers deviate from that
towards 1900 (the midpoint of the precise advice). The
average of this deviation is 3.6 years for the Japanese
population and 4.0 years for the French population the (the
difference is non significant: t(243)=0.42, p=0.67).
Having established that both populations use some kind of
weighting heuristic, we can try to see if they differ in some
ways. We have seen that there is no qualitative difference in
the strength of the effects of the weighting heuristic.
However, it is still possible that this result is obtained
despite a difference in the underlying distribution of the
answers. To check for this, we divided the range of the
answers (between the midpoints of the two advices, thus
encompassing the vast majority of the answers) into 5
intervals of equal length, and the frequency of the answers
falling into each of these intervals was calculated. The first
and the fifth categories represent the choosing strategy,
since they imply taking nearly only one of the answers into
account, and the middle category represents the averaging
strategy. The results (cf. Table 1) show nearly identical
distributions among the two populations. Looking at the
table it could be argued that instead of a weighting strategy,
participants in both populations tend to use a choosing
strategy. However, the conflict is not necessary: the answer
that fall into the ‘choosing’ category may also be conceived
of as reflecting the use of a weighting strategy in which the
weight awarded to the more precise answer is very high.
Both populations thus seem to use the weighting heuristic,
and to do it in very similar ways. That being established we
can go on to study the self-other effect in the second
experiment.
Table 1: Distribution of the answers in experiment 1
Part
Japan
France

1819

1
36.2%
37.9%

2
23.9%
23.0%

3
12.2%
17.0%

4
16.9%
16.7%

5
10.8%
5.4%

Experiment 2
Method
The aim of this second experiment is to evaluate the way
people take another person’s opinion into account. Its
principle is similar to that of Yaniv’s first experiment
(2004): participants have to estimate the date of an historical
event and are given the answer of a supposedly equally
qualified person and can then give a new estimate. It was
thus necessary to choose a set of events that both
populations would have heard of but, because a difference
between the participant’s first answer and the advice7 is
necessary here, most of the participants should not be able
to give the exact date. Once a pilot study established that
our set of event respected these basic criteria, it was used in
the gathering phase. The aim of this phase was to gather the
data that would be used during the experiment proper to
give advice to the participants.
The gathering phase was run in classrooms. After
participants were asked if they agreed to take part in the
experiment, they were distributed booklets with the
instructions and the set of 15 dates they had to estimate.
There were two tasks: for each event, participants had to
give a precise answer and an interval in which they were
sure at 95% that the event took place. Here is an example of
a question with the format of answer:
In what year was the UN (United Nations) created?
Precise answer: __________
Dates between which you are sure at 95% that the answer
falls: ________ -_________
.The participants of this gathering phase were
undergraduates in human sciences, mainly majoring in
psychology (Japan, N=43; France, N=37).
The results of the gathering phase yielded an ecologically
sound set of answers. In order to incorporate these results in
the material of the experiment, the extreme answers were
rejected: when the precise answer to a question was more
than two standard deviations away from the correct answer,
it was not further used. Booklets containing answers drawn
from this pool were then created: for each question, an
answer was randomly picked from the set of answer to this
question in the gathering phase and added to the booklet.
Twenty such booklets were created, warranting a broad
distribution of answers to each question.
The testing phase was run in classrooms as well. Its first
part was identical to the gathering phase: after agreeing to
take part in the experiment, participants were given the
same booklet as in the gathering phase and had to fill it
(they were not aware that there would be a second part).
When all the participants had finished, they were given a
second booklet which contained the same questions, each
having the space for three answers: The first answer of the

participant (A1), the advice (answer of the other person:
AO), and the second answer of the participant (A2). Here is
an example:
In what year was the UN (United Nations) created?
Your first answer:
Precise answer: __________
Dates between which you are sure at 95% that the answer
falls: ________ -_________
The answer of another student:
Precise answer: ___1945___
Dates between which you are sure at 95% that the answer
falls: __1944__ -___1945__
Your new answer:
Precise answer: __________
Dates between which you are sure at 95% that the answer
falls: ________ -_________
Participants were told that this booklet contained the
answers previously given to the same questions by a student
with a background similar to theirs, they were requested to
copy their answer from the first booklet to the second and
then to give a second answer. Both booklets were collected.
Participants were undergraduates in social sciences, again
mainly doing a major in psychology (Japan, N=51; France,
N=64).

Results and discussion
The first thing that needs to be checked is the similarity
between the gathering phase and the experimental groups..
The accuracy, measured as the deviation of the precise
answer from the correct answer, is then nearly identical in
both groups; Other parameters (like interval width) were
found to be nearly identical between the group of the
gathering phase and the test group too, thus guaranteeing the
ecological validity of the answers from the gathering phase.
Since both groups’ answers had the same average interval
width, there should be no overall effect of the weighting
heuristic by itself. Moreover since the first experiment has
shown that both populations use the weighting heuristic
very similarly, any difference observed in this experiment
will have to be accounted for by other effects.
To evaluate the self-other effect, we have to measure the
weight that participants assign to the advice relative to their
first answer: weight of the advice = |A2 – A1|/|AO – A1|. If
the result is 0, it means that the participant stuck with her
first answer, if it is 1 that she adopted the advice entirely
and if it is 0.5 that she averaged over both answers. Any
result under 0.5 indicates a self-other bias – the lower the
figure, the stronger the bias. The average weight assigned to
the advice was 0.43 in the Japanese population, and 0.28 in
the French population8. Both differ significantly from 0.5
(Japan: t(51)=5.18, p<0.005; France: t(63)=117.60,
p<0.005), and they differ significantly from one another
(t(114)=9.89, p<0.005). This means that participants in both
populations tended to discount advice, but that the French

7

Here we dub ‘advice’ the answer given by the other person. Note
however that it was not presented as such, but more neutrally as
someone else’s answer, since ‘advice’ might have had positive
connotations that might have differed in the two populations.

8

This value of 0.28 is in the range of values already found in
similar tasks with other Western type populations (e.g. Harvey &
Fischer, 1997; Yaniv, 2004)

1820

did so much more than the Japanese. However, taking the
advice into account led to an amelioration of the accuracy
(measured as the difference between the precise answer of
the participant and the correct answer) in both populations
with the Japanese participants gaining an average 32% in
accuracy, and the French participants 24%.
This difference in self-other bias is rendered hard to
interpret by the fact that the average accuracy of the
Japanese participants was much lower than that of the
French (Japan: 37.0 years from the correct answer; France:
17.7 years). On the one hand, inside each population the
overall quality (accuracy and interval width) of the
participants’ first answer and of the advice was very similar.
Thus in neither of the two populations had participants an
objective reason to discount the advice more. On the other
hand, if Japanese participants were not too confident in their
knowledge regarding the specific historical questions they
answered (as seem to be indicated by the large interval
width they tended to give – Japan, 63.7 years; France: 28.1
years), it is also possible that the difference is purely
domain specific, and would not have been found if the
performances had been equal between the two populations.
There is no easy way to disentangle these possibilities, so
even if we can be sure that both populations displayed a
self-other bias, the weakening of this effect among the
Japanese participants would have to be replicated with other
materials.
In order to find a potential distance effect, the range of
answers was divided into three categories depending on how
far the advice was from the first answer (|A1-AO|). The
category ‘near’ represented the 25% with the minimum
distance, the category ‘far’ the 25% with the maximum
distance, and the category ‘medium’ the 50% in between.
The distance effect would predict a stronger self-other effect
(discounting of the other’s opinion) as the distance
increases. However we found opposite results for both
populations, with the self-other bias diminishing as the
distance increases (see Table 2). It should be noted that in
Yaniv, 2004, experiment 2, the distance effect was observed
only among the group with the higher accuracy; but even
taking that into account and dividing both populations into a
high accuracy and a low accuracy group, we find the same
effect – namely the opposite of the distance effect. The
distance effect may be much more fragile than the other
effects studied here. It has not been the topic of as much
empirical work as the self-other effect for example, and it is
therefore possible that it is more sensitive to some variation
in the materials or the procedure used. Perhaps our
participants did not deem it necessary to revise their first
answer if the advice was close, when a more distant advice
might have motivated them to think their answer anew and
perhaps doubt their initial answer. The difference in the
experimental setup between our experiments and former
experiments found in the literature (large groups and a paper
and pencil task in our case, small groups and a computer
based task for Yaniv, 1997, for example) might support this
explanation: our participants may have been less motivated,

and, when confronted with an answer that was close to their
own, think that their own was good enough and not go to
the trouble of calculating a new answer. Here again, some
further experiments testing the cases in which the distance
effect – or its opposite – holds will be necessary to clarify
this issue.
Table 2: Strength of the self-other effect as a function of
the distance of the advice
Category
Japan
France

Near
0.33
0.18

Medium
0.42
0.28

Far
0.55
0.36

The last important aspect of the results is the use of the
choosing and the averaging strategies. Regarding the choice
among these two strategies, the weaker self-other bias
shown by the Japanese population could have two main
explanations: instead of deciding to stick with their initial
answer, Japanese participants might either have averaged
more, or they may have chosen to go for the advice entirely.
To find out which explanation is correct, we did as in the
first experiment and divided the range (from their initial
answer to the advice) of the participants’ second answers
into 5 intervals of equal length, and the frequency of the
answers falling into each of these intervals was calculated.
The first part comprises the 20% of second answers that are
closer to the participant’s first answer and the fifth part the
20% of second answers that are closer to the advice. These
two parts represent the choosing strategy. The third part
includes the second answers that are between 40 % and
60%, thus representing the averaging strategy. The results
(Table 3) firstly show that both populations differed in the
distribution of their answers (χ2(4)=76.3, p<0.005), and they
also clearly indicates that the second explanation holds:
Japanese participants were not averaging more and choosing
less, they were only choosing their own opinion less often
and that of the other more often.
Again, this finding is rendered hard to interpret by the fact
that the French participants performed much better in the
task. We’ve seen that this might explain the difference in
the self-other bias, and it is also possible that it explains the
accrued tendency, among the Japanese choosers, to choose
the other’s answer instead of their own. One the other hand,
these findings fit nicely with classical cross-cultural
explanations: the Japanese population displayed a reduced
self-other bias, and tended to choose the other’s opinion
more often, as might be predicted by, for example, the
collectivist – individualist cultures distinction. At this we
need some more experiments to disentangle this issue.
Table 3: Distribution of the answers in experiment 2
Part
Japan
France

1821

1
38.9%
52.3%

2
9.3%
15.2%

3
14.3%
12.7%

4
13.0%
9.1%

5
24.5%
10.6%

General discussion and conclusion
The experiments presented in this paper aimed at checking
the cross-cultural validity of some findings related to the
way people integrate communicated information. The
outcome of the first experiment was clear cut: French and
Japanese participants were very similar in their use of the
weighting heuristic. For the second experiment, the
interpretation of the results is more ambiguous. Regarding
the self-other effect, the only clear conclusion is that both
populations displayed it. The weakening of its strength for
the Japanese participants remains to be replicated. No
distance effect was observed – in fact, the opposite effect
was found. It is not possible with our data to give an
explanation of this reversal, but it should be noted that it
was not culture specific: both populations showed the same
trend. Lastly, if we found some differences in the way the
Japanese and the French participants used the choosing
strategy – with the French using it to stick with their first
answer more often – the overall pattern is the same: in both
populations, the participants tended to choose more often
than they averaged.
On the whole our results could thus be taken as evidence
in favor of the universality of: the use of the weighing
heuristic, the self-other effect and the preference for
choosing over averaging. Obviously this kind of experiment
would have to be replicated in many more cultures before
any claim of universality could be really founded. Some
explanations might also be offered for this discrepancy
between our results and some previous results in crosscultural psychology: maybe the new Japanese generation
fails to reflect some of the patterns to be found among their
elders for example, or perhaps different results would obtain
in China. However Japan was a good case study since many
works bearing on cross-cultural differences could have
predicted very different outcomes. For example, we found
no evidence of a preference for the ‘middle-way’ which
might have showed up as an increase of the use of the
averaging strategy among the Japanese participants. So we
are optimistic as to what would be the results of some
further replications in other cultures.

Acknowledgments
Guy Politzer gave us numerous advices on different aspects
of this paper, Tomoko Horishita granted us access to some
of the participants, Françoise Sabban and Akira Mukai
helped us with the translations: we are grateful to all of
them. This research has been supported by a CHORUS
grant from the French Ministry of Research and the
Japanese Society for the Promotion of Science.

responsibility. Organizational Behavior and
Human Decision Processes, 70, 117-133.
Lehman, D. R., Chiu, C.-Y., & Schaller, M. (2004).
Psychology and culture. Annual Review of
Psychology, 55, 689-714.
Lim, J. S., & O'Connor, M. (1995). Judgmental adjustment
of initial forecasts: Its effectiveness and biases.
Journal of Behavioral Decision Making, 8, 149168.
Lloyd, G. E. R. (1990). Demystifying Mentalities.
Cambridge: Cambridge University Press.
Mercier, H., & Van der Henst, J.-B. (2005). The source of
beliefs in conflicting and non conflicting situations.
Paper presented at the XXVII Annual Conference
of the Cognitive Science Society.
Nakamura, H. (1964/1985). Ways of thinking of Eastern
peoples: India, China, Tibet, Japan. London: Paul
Kegan International.
Nisbett, R. E., & Miyamoto, Y. (2005). The influence of
culture: Holistic versus analytic perception. Trends
in Cognitive Science, 9, 467-473.
Nisbett, R. E., Peng, K., Choi, I., & Norenzayan, A. (2001).
Culture and systems of thought: Holistic versus
analytic cognition. Psychological Review, 108(2),
291-310.
Oyserman, D., Coon, H. M., & Kemmelmeier, M. (2002).
Rethinking individualism and collectivism:
Evaluation of theoretical assumptions and metaanalyses. Psychological Bulletin, 128(1), 3-72.
Peng, K., & Nisbett, R. E. (1999). Culture, dialectics and
reasoning
about
contradiction.
American
Psychologist, 54(9), 741-754.
Soll, J. B., & Larrick, R. P. (submitted). Strategies for
revising judgments.
Triandis, H. C., & Suh, E. M. (2002). Cultural influences on
personality. Annual Review of Psychology, 53, 133160.
Yaniv, I. (1997). Weighting and trimming: Heuristics for
aggregating
judgments
under
uncertainty.
Organizational Behavior and Human Decision
Processes, 69(3), 237-249.
Yaniv, I. (2004). Receiving other people's advice: Influence
and benefit. Organizational Behavior and Human
Decision Processes, 93, 1-13.
Yaniv, I., & Kleinberger, E. (2000). Advice taking in
decision making: Egocentric discounting and
reputation formation. Organizational Behavior and
Human Decision Processes, 83, 260-281.
Yaniv, I., Yates, J. F., & Smith, J. E. K. (1991). Measures of
discrimination skill in probabilistic judgment.
Psychological Bulletin, 110, 611-617.

Briley, D. A., Morris, M. W., & Simonson, I. (2000).
Reasons as carriers of culture: Dynamic versus
dispositional models of cultural influence on
decision making. Journal of Consumer Research,
27, 157-178.
Harvey, N., & Fischer, I. (1997). Taking advice: Accepting
help,
improving
judgment
and
sharing
1822

