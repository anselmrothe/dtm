UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Supporting Information Comparisons in Example-Based Hypertext Environments

Permalink
https://escholarship.org/uc/item/94s393wg

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Gerjets, Peter
Scheiter, Katharina
Schuh, Julia

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Supporting Information Comparisons in Example-Based Hypertext Environments
Peter Gerjets (p.gerjets@iwm-kmrc.de)
Hypermedia Research Unit, Knowledge Media Research Center
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany

Katharina Scheiter (k.scheiter@iwm-kmrc.de)
Department of Applied Cognitive Psychology and Media Psychology, University of Tuebingen
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany

Julia Schuh (j.schuh@iwm-kmrc.de)
Virtual Ph.D. Program: Knowledge Acquisition and Knowledge Exchange with New Media
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany
Abstract
Global comparisons of learning from hypertext and traditional
text have yet failed to show major advantages concerning the
effectiveness of hypertext learning. In the current paper it is
proposed that an effective hypertext design needs to be based
on thorough cognitive task analyses with regard to structures,
processes, and resources that are required to benefit from a
specific learning approach. This claim is illustrated by two
experiments, in which we investigated two methods for supporting effective cognitive processes in example-based hypermedia environments, namely, elaboration prompts and an
interactive comparison tool. Both methods improved performance for near-transfer problems. Ways of extending this
task-analytical approach to facilitating far transfer are discussed.

Promises and Drawbacks of Hypertext:
The Need for Cognitive Task Analyses
Hypertext-based learning environments consist of networklike information structures where fragments of information
are stored in nodes that are interconnected by hyperlinks
(Conklin, 1987). They are characterized by a high degree of
learner control, where users can select information and
choose the pacing and sequence of its presentation according to their goals, preferences, and needs.
Several instructional benefits have been postulated for
learning from hypertexts from different theoretical perspectives, whereby these perspectives mainly emphasize that
hypertext allows for active, constructive, flexible, adaptive,
and self-regulated learning. However, they are also characterized by some serious usability problems. Conklin (1987)
postulated that disorientation (e.g., not knowing how to get
to another point in the network) and cognitive overload limit
the effectiveness of hypertext for learning. The term cognitive overload refers to the assumption that metacognitive or
executive skills necessary for hypertext navigation may require cognitive resources that will no longer be available for
the pursuit of the currently performed learning task (Niederhauser, Reynolds, Salmen & Skolmoski, 2000). Furthermore, “many learners may not be proficient computer users
and must, therefore, use cognitive resources to operate the
computer” (Niederhauser et al., 2000, p. 251). According to
1364

the cognitive load theory (Sweller, van Merriënboer & Paas,
1998), these processes may impede learning as they require
cognitive resources that may exceed the limits of workingmemory capacity. Cognitive load due to the requirements of
selecting and integrating information and due to the interaction with the computer (so-called extraneous cognitive load)
may thus reduce the possible benefits of hypertext-assisted
learning (Gerjets, Scheiter, & Tack, 2000). Cognitive resources required by extraneous cognitive load can no longer
be devoted to mindful cognitive processes that are associated with a useful type of cognitive load, namely germane
cognitive load. Rouet and Levonen (1996, p. 20) conclude
that “hypertext efficiency involves a trade-off between the
power of the linking and the searching tools it provides and
the cognitive demands or costs these tools impose on the
reader.” This may explain why global comparisons of
learning from hypertext and traditional text have yet failed
to show major advantages concerning the effectiveness of
hypertext learning (e.g., Dillon & Gabbard, 1998). From a
cognitive load perspective, an important objective of instructional design with regard to hypertext-assisted learning
is thus to minimize extraneous cognitive load and to stimulate learners to invest cognitive resources in activities that
result in germane cognitive load.
To achieve this objective, much more detailed analyses of
the relevant cognitive processes and resources involved in a
specific learning situation are needed in order to predict
under which conditions hypertext environments will be
beneficial or harmful for learning (cf. Gerjets & Hesse,
2004). Much of the early research on hypertext learning can
thus be criticized for comparing learning from text and hypertext in a very general way, without specifying the learning approach chosen and the cognitive structures, processes,
and resources necessary to benefit from this learning approach. Without these specifications, findings with regard to
the relative superiority of hypertext or text are of rather limited value as it is not clear whether these findings might
generalize over different learning approaches. In our own
research we thus try to combine hypertext experiments with
cognitive task analyses in order to compare instructional
conditions that differ in the cognitive processes that they
support or require and in the cognitive resources needed.

The learning approach in the presented studies focuses on
the acquisition of problem schemas from worked-out examples. For this learning approach, research literature is available that addresses the cognitive processes involved as well
as the cognitive resources needed for successful learning.
Furthermore, pivotal cognitive processes in schema acquisition from worked-out examples are comparison processes
and elaboration processes. As will be outlined in the following, these processes seem to be particularly apt for hypertext-assisted learning.

Example-Based Hypertexts and Schema
Acquisition: A Task-Analytic Approach
It has often been argued that probably the most important
prerequisite for successful problem solving consists in the
availability of abstract problem schemas, that is, representations of problem categories together with category-specific
solution procedures. Schemas highlight structural problem
features that determine a problem’s category membership
and detach these structural features from merely incidental
and irrelevant surface features of the domain context or
cover story. Because of their abstract nature, schemas allow
to efficiently solve problems that belong to one of the represented problem categories. Once a problem has been identified as belonging to a known problem category, the relevant
schema is retrieved from memory and information that is
specific to the problem is filled into the slots of the schema.
Finally the category-specific solution procedure attached to
the schema is executed in order to solve the problem.
With regard to the acquisition of problem schemas,
studying worked-out examples (i.e., example problems together with a step-by-step solution) seems to be superior to
actively solving training problems – at least in initial skill
acquisition (cf. Atkinson, Derry, Renkl & Wortham, 2000).
It has, however, also been shown that the mere availability
of examples is not sufficient to guarantee the acquisition of
appropriate schemas. Rather, students have to deploy profitable strategies of processing worked-out examples, that is,
elaborations and comparisons of examples.
A commonly found problem in skill acquisition from
worked-out examples is that learners “tend to form solution
procedures that consist of a long series of steps – which are
frequently tied to incidental features of the problems” (Catrambone, 1998, p. 355). To overcome these shallow representations of solution procedures, learners have to elaborate
examples by drawing inferences concerning the structure of
example solutions, the rationale behind solution procedures,
and the goals that are accomplished by individual solution
steps (e.g., by relating example-specific information to more
abstract information; e.g., Renkl, 1997). Without example
elaborations, transfer difficulties might result when learners
attempt to solve novel problems that do not fall into known
problem categories and that require an adaptation of procedures illustrated by examples.
Moreover, learners need to compare different examples in
order to notice structural features that differ among problem
categories and that are shared by all problems within a cate-

1365

gory. Comparing examples within and among categories
with regard to their differences and similarities might allow
learners to identify the relevant features of worked-out examples and to avoid confusion due to examples' surface
features (Quilici & Mayer, 1996). Without these comparison
processes learners might tend to categorize test problems
according to their surface features and in turn tend to apply
inappropriate solution procedures to them. Two different
types of example comparisons can be distinguished, namely,
within- and across-category comparisons, which will be
described in the following section.
Bernardo (1994, p. 379) proposes “that problem-type
schemata are acquired through some inductive or generalization process involving comparisons among similar or
analogous problems of one type.” Therefore, it has often
been advocated to provide learners with multiple examples
for each problem category (e.g., Quilici & Mayer, 1996) so
that they can compare examples within problem categories
with regard to their differences and similarities. From these
comparisons, learners can infer that shared properties of
examples from the same category may potentially be the
structural features that determine a problem’s category
membership. Additionally, comparisons within a problem
category may enable learners to identify surface features
that vary between the category’s examples and that are
therefore obviously irrelevant with regard to the applicability of the solution principle attached to this problem category. Thus, by comparing multiple instances within a category with regard to their commonalities and differences, all
example features can be hypothetically classified as either
being structural or surface features. Despite the fact that
many researchers advocate the provision of multiple examples, there is not much empirical evidence to support this
claim. In particular, there is a lack in studies that directly
compare single- and multiple-example conditions. An exception to that is a study conducted by Quilici and Mayer
(1996). However, contrary to their initial expectations they
found no performance differences between single-example
and multiple-example conditions. In line with these findings, we could demonstrate in our own studies that there are
promising example-processing strategies that rely on single
examples per problem category and that are as effective for
schema acquisition as comparing multiple examples within
categories, namely comparing examples across problem
categories (Scheiter & Gerjets, 2005). However, in order to
have learners profit substantially from across-category comparisons, the surface features of examples have to be kept
constant across categories in order to allow learners to recognize that these surface features are not suitable to determine a problem’s membership to a specific category. From
these across-category comparisons, learners can infer that
only properties that differ between the examples may potentially be the structural features that determine a problem’s membership to a specific category.
We hypothesize that the linking capabilities of hypertext
environments and the resulting distributed information representation may support example comparisons and example

elaborations by providing navigational affordances for
them (thereby increasing germane cognitive load). In contrast to linear structures, each information unit can be explicitly related to a large number of other units by means of
hyperlinks, which should encourage example comparisons
as well as elaborations and thus aid schema construction.
However, the same hypertext features might also impose
extraneous cognitive load on the learner. For instance, a
distributed information representation might cause splitattention effects where learners must integrate different
sources of information simultaneously (Sweller et al., 1998).
This has to be taken into account when designing examplebased hypertext environments.

Results of Previous Experiments with
Example-Based Hypertext Environments
To test the instructional potential of example-based hypertext environments for supporting schema acquisition, Gerjets et al. (2000) studied whether learners were able to use
the linking capabilities to engage in example comparisons
and elaborations. The hypertext used taught learners how to
solve probability problems. All learners could retrieve abstract explanations on six problem categories. As a first independent variable the availability of worked-out examples
that illustrated the abstract information was manipulated.
Learners had the opportunity to either study no, one or three
worked-out example(s) with different surface features for
each problem category. All examples in the one-example
condition were couched in the same cover story. As a second independent variable learners with low and high domain-specific prior knowledge were distinguished.
The results showed that whereas prior knowledge had a
significant impact on later problem-solving performance,
participants did not differ in performance as a function of
whether they could retrieve zero, one, or three examples.
However, more detailed analyses of example-processing
strategies revealed that mindfully processing these examples
was strongly predictive for performance. In particular,
learners who processed the examples carefully in the oneexample condition and learners who retrieved more than one
example per category in the three-examples condition
showed better performance than participants who displayed
a less intensive example-processing behavior. Moreover, the
profitability of different example-processing strategies was
moderated by prior knowledge. Low prior knowledge learners benefited only from carefully studying single examples
per category, whereas for high prior knowledge learners
comparing multiple examples for each problem category
was also effective. Moreover, other prior studies (Scheiter &
Gerjets, 2005) showed that learning from multiple examples
may even be harmful if learners do not process these examples appropriately. Single examples are probably less vulnerable to effects of inappropriate, that is, not sufficiently
intense processing of examples, because there is less information to process from the very beginning.
Based on these experimental findings and on the taskanalytic considerations elaborated in the previous section we
developed and evaluated two instructional devices that were
1366

intended to stimulate learners’ processing of single examples per problem category. Experiment 1 investigates the
effects of processing prompts that provided learners with
instructional guidance on how they should relate examplespecific information to the more abstract information (i.e.,
example elaborations). Experiment 2 investigates the effects
of an interactive comparison tool that was designed to
stimulate learners to engage in across-category comparisons.

Experiment 1: Processing Prompts
In order to stimulate learners’ processing of single examples
per problem category we combined the hyperlinks for retrieving worked-out examples with processing prompts that
were intended to scaffold learners’ interaction with the examples. Processing prompts have been used successfully in
other studies to elicit specific self-explanation activities in
learners (cf. Conati & VanLehn, 2000). We assumed that
these prompts would be particularly helpful for learners
with a low level of prior knowledge, who benefited most
from single examples in the study by Gerjets et al. (2000).
Method
Participants Eighty university students participated in this
study (average age 24.3 years, 48 female, 32 male).
Materials and Procedure For experimentation the hypertext-based learning and problem-solving environment
H YPER C OMB on combinatorics was used (for details cf.
Gerjets, Scheiter, & Schuh, 2006). Subsequent to a short
introduction to the domain of combinatorics, participants
could use an example-based learning environment that allowed learners to select and sequence instructional materials
by means of a navigation bar that was permanently visible.
This navigation bar contained links to each of six problem
categories. Whenever a participant clicked a hyperlink, first
the abstract information was displayed. The abstract information page additionally contained one hyperlink that enabled the retrieval of an urn example for the illustration of
the problem category in question. Whenever a participant
had clicked on an example-hyperlink, the example together
with a step-by-step solution was displayed on a single page.
After having processed this example, participants could either go back to the abstract information page or they could
switch to another problem category by clicking one of the
six hyperlinks in the navigation bar. Thus, the linking
structure used in HYPERCOMB provided affordances to
compare examples across categories as well as to compare
examples with abstract information. In order to allow learners to draw substantial inferences with regard to structural
problem features from these comparisons, we used the same
cover story across problem categories (i.e., selecting marbles from an urn). Participants could decide by themselves
when to quit the learning phase and when to start working
on the test problems.
Design and Dependent Variables As a first independent
variable the availability of processing prompts as a between-

subject factor was varied. Learners with processing prompts
received the following annotation of the hyperlink on the
abstract information page: “You can access a simple urn
example in order to better understand this solution procedure. This example is very helpful in clarifying the principle
of <NAME OF PROBLEM CATEGORY>. The example
can help you to understand how to apply the formula. Read
the example thoroughly and especially pay attention on how
to determine the value of the variables n and k”. Moreover,
an example page could only be left after learners had confirmed that they had understood the information by clicking
a respective link. Domain specific prior knowledge (low vs.
high) according to a median split within the two prompting
conditions served as the second independent variable
(multiple-choice pretest at the beginning of the experiment).
As dependent variables, the problem-solving performance
for three isomorphic test problems (in percentage correct) as
well as the mean time spent per example retrieved were obtained. The mean time spent per example retrieved was registered in order to investigate whether the prompts prolonged the processing of individual worked-out examples.
Results
The data (Table 1) were analyzed by a 2-factorial analysis
of variance (prior knowledge x processing prompts).
Moreover, as the learners’ gender had turned out to be significantly correlated with problem-solving performance in
prior experiments, we used this variable as a covariate. The
analysis of problem-solving performance revealed better
learning outcomes for learners with high prior knowledge
(F(1,75) = 8.09; MSE = 304.61; p < .01; η 2 = .09). Additionally, the provision of processing prompts led to a marginally significant improvement in problem-solving performance (F(1,75) = 3.62; MSE = 304.61; p = .06; η2 = .04).
There was no interaction (F(1,75) = 2.07; MSE = 304.61; p
> .10; η2 = .02). Subsequent specific contrasts revealed that
processing prompts were especially beneficial for learners
with low prior knowledge (t(38) = 2.13; p < .05, one-tailed),
while they had no reliable impact on the problem-solving
performance of learners with high prior knowledge (t(38) =
0.22; p > .40, one-tailed). To test whether the impact of
processing prompts on problem-solving performance was
moderated by a more intensive example processing, we
analyzed the time spent per example retrieved. Processing
prompts resulted in the expected increase in study time
(F(1,75) = 6.20; MSE = 400.99; p < .05; η2 = .06); there was

neither a main effect of prior knowledge, nor an interaction
(both Fs < 1).
To conclude, annotating hyperlinks with specific processing prompts is a suitable instructional device to intensify
the elaboration of worked-out examples and to stimulate
learners to relate example-specific information to more abstract information on different problem categories. This improved problem-solving performance particularly for low
prior knowledge learners.

Experiment 2: Interactive Comparison Tool
Experiment 2 was designed to test the effectiveness of a
hypertext-based comparison tool for engaging learners in
comparing worked-out examples across problem categories.
Method
Participants Thirty one high-school pupils participated in
this study (average age 14.0 years, 14 female, 17 male).
Materials and Procedure Prerequisite knowledge was
measured by a pretest on important concepts necessary to
solve algebra word problems (e.g., rules for operating with
fractions). Subsequently, the pupils used a hypertext environment, which conveyed knowledge on how to solve algebra word problems. They were asked to study three computer-based textbook chapters on biology, chemistry, and
politics. Embedded in each of the three chapters were three
algebraic worked-out examples that illustrated how to solve
specific problems in these domains (e.g., damage rates of
different types of trees, mixing liquids, rules about the election process of the German parliament). Depending on the
experimental condition either only the examples were presented or they were followed by an interactive comparison
tool for across-category comparisons. Within each chapter,
the three examples differed with regard to the problem category they belonged to and thus required a different algebraic
solution formula. The three formulas were identical across
the three school subjects. In the subsequent test phase pupils
had to solve algebraic word problems on paper. The overall
time for learning and problem solving was restricted to 120
minutes.
Design and Dependent Measures A 2x4-factorial design
was used with the between-subject factor “comparison tool”
and the within-subject factor “transfer distance”. Learners

Table 1: Results as a function of the provision of processing prompts and the level of prior knowledge (Exp. 1).

Prior knowledge (% correct)
Problem-solving performance (% correct)
Time spent per example retrieved (in sec)

Without
processing prompts
Low PK
High PK
(n = 20)
(n = 20)
35.75
70.30
50.83
67.22
39.00
42.44

1367

With
processing prompts
Low PK
High PK
(n = 20)
(n = 20)
36.35
68.10
63.89
68.33
50.60
53.34

2.68; p < .01, one-tailed) and isomorphic problems (t(29)
= 1.81; p < .05, one-tailed), but did not affect solving
similar problems (t(29) = 1.27; p > .10, one-tailed) or unrelated problems (t(29) = 0.72; p > .20, one-tailed). Thus,
the experiment demonstrates that an interactive comparison tool helps learners to abstract from irrelevant surface
features by having them compare examples that share the
same cover stories across problem categories. This facilitates later problem-solving performance particularly for
solving near transfer problems.

without comparison tool were presented only with the
text-based worked-out examples. Learners with comparison tool additionally had available an interactive comparison tool after they had studied the nine worked-out examples. This comparison tool was based on hyperlinks and
pop-up windows that allowed learners to quickly compare
the three structural different worked-out examples from
the biology domain with regard to their similarities and
differences. Whenever learners clicked on one of the three
comparison links, two pop-up windows displayed the examples to be compared directly aligned to each other. We
used multiple pop-up windows to create an integrated
presentation thereby avoiding split attention.
As a second independent variable four levels of transfer
distance were constructed for the 21 test problems that
learners had to solve subsequent to the learning phase, to
assess the differential effectiveness of the comparison
tool. Equivalent problems shared surface as well as
structural features with the worked-out examples. Isomorphic problems shared only structural features with the
worked-out examples, but were embedded in different
cover stories. Equivalent and isomorphic problems both
required near transfer only, because the solution formula
presented during learning could be used without modification to solve these problems. Similar problems shared
only surface features with the worked-out examples but
differed with regard to their structural features. Thus,
similar test problems can be described as novel problems
that require far transfer in that known algebraic solution
formulas have to be modified to be applicable to these
problems. Unrelated problems neither shared surface nor
structural features with the examples and were thus novel
problems, too. Learners’ performance for solving the 21
problems (in % correct) was registered as a dependent
measure. We analyzed the percentage of equivalent, isomorphic, similar, and unrelated test problems solved.

Summary and Discussion
In this paper we have argued that the development of
powerful and effective hypertext environments for learning should be based on a strong theoretical foundation in
detailed cognitive task analyses with regard to the structures, processes, and resources involved in specific learning approaches that are to be supported by hypertext technology. Only then “hypertext can enhance learning. It
does so by presenting environments that offer greater opportunities for students to engage in the type of cognitive
activities recognized by theorists as encouraging learning”
(Shapiro & Niederhauser, 2004, p. 618).
In the experiments reported in this paper we focused on
the learning approach of using worked-out examples for
the acquisition of problem schemas. For this learning approach, there are a couple of research findings that address the cognitive processes involved as well as the cognitive resources needed for successful learning. Based on
these findings, pivotal cognitive processes in schema acquisition from worked-out examples are elaboration processes and comparison processes that seem to be particularly apt for hypertext-assisted learning. In Experiment 1
we demonstrated that annotating hyperlinks for retrieving
worked-out examples with processing prompts intensified
the elaboration of worked-out examples by stimulating
learners to relate example-specific information to more
abstract information on different problem categories. This
stimulation of cognitive processing improved problemsolving performance particularly for learners with low
prior knowledge. In Experiment 2 we provided evidence
for the effectiveness of an interactive comparison tool that
encouraged learners to compare worked-out examples
with common surface features across problem categories.
The comparison tool facilitated later problem-solving
performance particularly on near transfer problems.
From a theoretical perspective, both instructional devices implemented in Experiment 1 and 2 mainly aimed at
helping learners to abstract from irrelevant surface features of examples and to construct appropriate problem
schemas. This schematic knowledge is, however, tied to
the boundaries of problem categories. Accordingly, both
instructional devices mainly improved performance for
near-transfer problems, which originate from the same
categories as the examples previously studied.
Improving far-transfer performance would require additional instructional support that allows learners to go
below the schema level and to understand the rationale of
individual solution steps. One promising avenue to support learners in this type of reasoning is to embed dy-

Results
Analyzing learners’ problem-solving performance (Table
2) by an ANOVA (comparison tool x transfer distance)
yielded a main effect in favor of the comparison tool
(F(1,29) = 467.87; MSE = 1010.38; p = .05; η2 = .13).
Table 2:Performance ( % correct) as a function of the
comparison tool and transfer distance (Exp. 2).

Prerequisite knowledge
Equivalent problems
Isomorphic problems
Similar problems
Unrelated problems

Comparison tool
No (n = 16)
Yes (n = 15)
89.06
87.78
75.78
93.17
64.06
79.33
46.50
55.20
37.50
42.67

Additionally, performance depended on transfer distance
(F(3,87) = 59.46; MSE = 208.96; p < .001; η2 = .64).
There was no interaction (F(3,87) = 1.20; MSE = 208.94;
p > .30; η2 = .11). Specific contrasts for the four levels of
transfer distance revealed that the comparison tool improved performance for equivalent problems (t(29) =
1368

namic visualizations within an example-based hypermedia
environment. For instance, we used task-analytic methods
to design dynamic visualizations that depict the initial
problem state as well as changes to this problem state
resulting from applying a solution step. We studied these
visualizations in the domain of combinatorics (Scheiter,
Gerjets & Catrambone, 2006) as well as in the domain of
algebra (Schuh, Gerjets & Scheiter, 2005) and could
demonstrate that they have the potential to particularly
foster learners’ far-transfer performance. However, there
is evidence that not every visualization is similar effective. The best learning outcomes with regard to fartransfer performance resulted from dynamic visualizations
that initially depicted the examples’ concrete objects and
than visually showed the transition from a concrete problem statement to an abstract mathematical representation
of the problem and its solution. Thus, the effectiveness of
the visualizations seems to reside in the fact that they help
learners to translate a concrete example into an abstracted
representation, based on which mathematical operations
can be carried out more easily. Accordingly, the main
methodological claim on designing hypertext structure
advocated in this paper apparently also applies to the issue
of augmenting hypermedia environments with dynamic
visualizations. Namely, it is not enough to merely postulate some general advantages of some particular instances
of educational technology in quite broad terms. Instead,
detailed cognitive task analyses with regard to structures,
processes, and resources are required to guide the development of powerful and effective learning environments
(cf. Gerjets & Hesse, 2004).

activities and of students’ conceptions of educational
technology. International Journal of Educational Research, 41, 445-465.
Gerjets, P. H., Scheiter, K., & Schuh, J. (2006). Information comparisons in example-based hypertext environments. Manuscript submitted for publication.
Gerjets, P., Scheiter, K., & Tack, W. H. (2000). Resourceadaptive selection of strategies in learning from
worked-out examples. In L. R. Gleitman & A. K. Joshi
(Eds.), Proceedings of the 22nd Annual Conference of
the Cognitive Science Society (pp. 166-171). Mahwah,
NJ: Erlbaum.
Niederhauser, D. S., Reynolds, R. E., Salmen, D. J., &
Skolmoski, P. (2000). The influence of cognitive load
on learning from hypertext. Journal of Educational
Computing Research, 23, 237-255.
Quilici, J. L., & Mayer, R. E. (1996). Role of examples in
how students learn to categorize statistics word problems. Journal of Educational Psychology, 88, 144-161.
Renkl, A. (1997). Learning from worked-out examples: A
study on individual differences. Cognitive Science, 21,
1-29.
Rouet, J.-F., & Levonen, J. J. (1996). Studying and
learning with hypertext: Empirical studies and their implications. In J.-F. Rouet, J. Levonen, A. Dillon, & R.
Spiro (Eds.), Hypertext and cognition. Mahwah, NJ.
Erlbaum.
Scheiter, K., & Gerjets, P. (2005). When less is sometimes more: Optimal learning conditions are required
for schema acquisition from multiple examples. In B.
G. Bara, L. Barsalou, & M. Bucciarelli (Eds.), Proceedings of the 27th Annual Conference of the Cognitive Science Society (pp. 1943-1948). Mahwah, NJ: Erlbaum.
Scheiter, K., Gerjets, P., & Catrambone, R. (2006). Making the abstract concrete: Visualizing mathematical solution procedures. Computers in Human Behavior, 22,
9-26.
Schuh, J., Gerjets, P., & Scheiter, K. (2005). Fostering the
acquisition of transferable problem-solving knowledge
with an interactive comparison tool and dynamic visualizations of solution procedures. In B. G. Bara, L. Barsalou, & M. Bucciarelli (Eds.), Proceedings of the 27th
Annual Conference of the Cognitive Science Society
(pp. 1973-1978). Mahwah, NJ: Erlbaum.
Shapiro, A., & Niederhauser, D. (2004). Learning from
hypertext: Research issues and findings. In D. H. Jonassen (Ed.), Handbook of Research on Educational Communications and Technology. Mahwah; NJ: Erlbaum.
Spiro, R. J., & Jehng, J.-C. (1990). Cognitive flexibility
and hypertext: Theory and technology for the nonlinear
and multidimensional traversal of complex subject
matter. In D. Nix & R. J. Spiro (Eds.), Cognition, education, and multimedia. Hillsdale, NJ: Erlbaum.
Sweller, J., van Merriënboer, J. J. G., & Paas, F. W. C.
(1998). Cognitive architecture and instructional design.
Educational Psychology Review, 10, 251-296.

References
Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D.
W. (2000). Learning from examples: Instructional principles from the worked examples research. Review of
Educational Research, 70, 181-214.
Bernardo, A. B. I. (1994). Problem-specific information
and the development of problem-type schemata. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 20, 379-395.
Catrambone, R. (1998). The subgoal learning model: Creating better examples to improve transfer to novel
problems. Journal of Experimental Psychology: General, 127, 355-376.
Conati, C., & VanLehn, K. (2000). Toward computerbased support of meta-cognitive skills: A computational
framework to coach self-explanation. International
Journal of Artificial Intelligence in Education, 11, 389415.
Conklin, J. (1987). Hypertext: An introduction and survey. Computer, 20, 17-41.
Dillon, A., & Gabbard, R. (1998). Hypermedia as an educational technology: A review of the quantitative research literature on learner comprehension, control, and
style. Review of Educational Research, 68, 322-349.
Gerjets, P. H., & Hesse, F. W. (2004). When are powerful
learning environments effective? The role of learner

1369

