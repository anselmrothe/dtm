UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Deaf Readers' Lack of Implicit-Prosody Effects

Permalink
https://escholarship.org/uc/item/5bc4h9s6

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Kobayashi, Mari
Miyamoto, Edson T.
Sato, Kaori

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Deaf Readers’ Lack of Implicit-Prosody Effects
Mari Kobayashi
Edson T. Miyamoto
(etm@lingua.tsukuba.ac.jp)
Kaori Sato
University of Tsukuba
College of Japanese Language and Culture
Tsukuba, Ibaraki 305-8572 Japan
written words or the way that working memory handles
longer phrases could be the crucial factor.
Ideally, one would like to compare how silent reading
is conducted with and without implicit prosody, but this
is not easily achieved (but see Miyamoto, Nakamura &
Takahashi, 2004, Experiment 2; Slowiaczek & Clifton,
1980, on the possibility of eliminating inner speech during reading through simultaneous articulation of nonsense syllables).
We report the results of a fragment completion study
with deaf readers of Japanese, which indicate that they
are not sensitive to the manipulations used by Hirose
(2003). Therefore, the results support the proposal that
the effects are related to prosodic contours rather than
working memory or perception, under the assumption
that deaf readers are less likely to be affected by implicit
prosodic contours during silent reading.

Abstract
According to the implicit prosody hypothesis, prosodic
contours usually associated with spoken utterances are
implicitly imposed on sentences read in silence, thereby
affecting the interpretation of ambiguous constructions
(Fodor 2002). Some of the strongest evidence supporting this hypothesis manipulated the prosodic length of
segments (Hirose 2003). However, such manipulations
also increase the number of characters in the critical
words, thus the results may not reflect the influence of
prosodic factors but rather how perceptual mechanisms
and working memory handle written words with larger
number of characters. If so, such results should be replicable even with readers who have low ability in handling
phonological information. We report experimental results suggesting that deaf readers are not sensitive to
such length manipulations. This is compatible with the
assumption that prosodic contours, and not some other
type of length measure, are at stake, therefore providing
further support for the implicit prosody hypothesis.

Key words: sentence comprehension, deaf, implicit
prosody, Japanese, clause boundary, ambiguity

Introduction
According to the implicit prosody hypothesis (IPH),
prosodic contours usually associated with spoken utterances are implicitly imposed on sentences read in silence,
thereby affecting the interpretation of ambiguous constructions (Fodor, 2002). The effects of such implicit
prosodic contours have been explored recently both in
formal syntax as well as in the language processing literature. A number of empirical results have been reported
on implicit prosody effects, but many of them have not
addressed alternative explanations. The most common
type of manipulation increases the length of constituents
in order to show that longer phrases are more likely to
modify the farther of two potential attachment sites (see
Fodor, 2002, for a summary of the relevant studies).
One of the strongest sets of results providing support
for the IPH has used ambiguous relative clause constructions in Japanese (Hirose, 2003; see also Hirose & Kakei,
1998). However, as in other similar studies, the manipulation used leads to unavoidable side-effects such as
longer words and phrases measured in number of characters, and not just longer in terms of prosodic length
as was intended. This is a problem because it allows for
the possibility that it is not implicit prosody that is driving the effect. Instead, perceptual processes for longer
1629

Ambiguous relative clauses in Japanese
Japanese is a head-final language with subject-objectverb order. There are no overt markers to indicate the
beginning of embedded clauses, therefore words in the
embedded clause are commonly taken to be part of the
matrix clause (but see Venditti, in press, for prosodic
cues in speech). For example, readers usually interpret the fragment in (1) as a single clause (‘Morishita
truly trusted the medicine’, where Morishita is a proper
name).1
(1) Morishita-ga shinyaku-o kokorokara shinyooshita
PN-nom
medicine-acc truly
trusted
However, when a noun such as yuujintachi-ni ‘friendsdat’ is read after ‘trusted’, it is clear that this verb is
part of a relative clause modifying the noun (relative
clauses in Japanese precede the noun they modify) and
readers have to decide where the beginning of the relative
clause is likely to be. The two most common alternatives
are the late opening interpretation, in which the relative
clause starts after the direct object, and the early opening interpretation, in which the relative clause starts at
the direct object ‘medicine-acc’ as schematically represented in (2a, b) (Mazuka & Itoh, 1995; see Hirose, 2003,
1
The nominative case marker (nom) is usually used for
subjects, the accusative marker (acc) for direct objects and
the dative marker (dat) for indirect objects.

on the early versus late opening labels; also Inoue, 1990;
Miyamoto, 2002, for related experimental results).
(2) a. Late opening
Morishita-ga shinyaku-o [RC kokorokara . . .
PN-nom
medicine-acc
truly
b. Early opening
Morishita-ga [RC shinyaku-o kokorokara . . .
PN-nom
medicine-acc truly
If the late opening interpretation is chosen, the direct
object (the accusative marked ‘shinyaku’) is to the left
of the embedded clause boundary, therefore it belongs
to the matrix clause together with the matrix subject
(‘Morishita’). In this case, the matrix verb at the end of
the sentence must be a predicate that can take the direct
object as an argument. The dative marked ‘friends’ is
also attached to the matrix verb, therefore ditransitive
predicates such as susumeru ‘recommend’ would be a
natural continuation (as in ‘Morishitai recommended the
medicine to the friends that (hei ) really trusts’).
If an early opening interpretation is chosen, the direct
object is part of the relative clause, therefore only the
dative-marked NP ‘friends’ has to attach to the matrix
predicate, therefore a verb such as au ‘meet’ is a grammatical continuation (as in ‘Morishita met the friends
that really trust the medicine’).

Prosodic contours in speech
During oral communication, prosodic contours (such as
pauses and word-end lengthening) produced by speakers
can help listeners choose between early and late opening
interpretations (Sakamoto, Muraoka & Matsuura, 2005;
also Venditti, in press, for a summary of prosodic contours in the processing of sentences in Japanese).
Furthermore, Experiment 3 in Hirose (2003) provides
evidence that the length of the matrix subject in fragments such as (1) affects the prosodic contours produced
by speakers. When an accented noun such as ‘Morishita’ is used, the subject spans one minor phrase and
it becomes part of a major phrase together with an accented noun such as the direct object ‘medicine’ in (3a).
In contrast, with two accented nouns (e.g., the conjoined proper names Morishita-to Hosokawa ‘Morishita
and Hosokawa’), the subject alone constitutes a major
phrase as shown in (3b).
The inclusion of the extra accented noun does not
change the nature of the syntactic ambiguity. That is,
the left edge of the relative clause remains ambiguous
and both alternatives in (2) are still possible when ‘Morishita’ is replaced by ‘Morishita and Hosokawa’.
Nevertheless, the prosodic markings often accompanying major phrase boundaries can bias listeners interpretations as they are preferentially aligned with the beginning of the embedded clause. Thus, the major phrase
boundary immediately after the conjoined names in (3b)
favors the adoption of the early-opening interpretation
in (2b); whereas the major phrase boundary after the
direct object in (3a) is preferentially aligned with the
beginning of the relative clause boundary as in the late
opening interpretation in (2a).
1630

Implicit prosody and relative clauses
In Experiment 1 in Hirose (2003), native Japanese speakers read fragments as in (3a, b) in silence, and were
asked to complete them into full sentences. The fragments containing conjoined names were more likely to
be completed with early opening interpretations than
single-name fragments (Hirose, 2003, who also reports
similar results when the conjoined names were replaced
with a family name followed by a first name, therefore
without increasing the number of discourse entities).
These results suggest that a change in the prosodic
length of the matrix subject affects the way how readers
interpret relative clauses even when the fragments are
not overtly articulated.
This type of completion questionnaire task is commonly used in the sentence processing literature to investigate the types of interpretations that are likely to
be pursued after a given fragment (see Hirose, 2003, Experiments 4 and 5, for reading time data confirming the
questionnaire findings).
One could argue that plausibility factors (how likely is
it that ‘Morishita really trusts his friends’ compared to
‘Morishita’s friends really trust the medicine’ ?) or preferences in gap position within the relative clause (gaps
in subject position are preferred over gaps in object position in Japanese; e.g., Miyamoto & Nakamura, 2003)
could affect the preference for early opening versus late
opening. However, such differences are orthogonal to
the subject-length manipulation and are equally likely
to affect the interpretations of fragments with a single
name as well as fragments with conjoined names, therefore they do not constitute a problem in this case.
In sum, although the syntactic ambiguity in (2a, b)
remains the same, the prosodic length of the matrix subject affects the favored interpretation even when read in
silence, thus providing support for the IPH.
However, it is conceivable that the number of characters, rather than the prosodic length of the matrix
subjects, influenced the way the relative clauses were
interpreted and a number of alternative explanations
would be possible. For example, at least since the 1970s
(e.g., Frazier & Fodor, 1978) there have been proposals that the perceptual span during reading may affect
how phrases are associated together. Another possibility
is the way working memory may handle longer strings
of letters as they are concatenated into more complex
chunks, which in turn may define phrasal boundaries.
If non-phonological aspects of the input strings are
responsible for the effects reported by Hirose (2003), it
should be possible to replicate them even with participants who are less likely to be generate implicit prosodic
contours.

Experiment
Under the assumption that deaf readers are less likely to
produce prosodic contours during silent reading, a completion questionnaire experiment was conducted with
deaf Japanese readers.

(3) a. Single-name matrix subject (‘Morishita’)
Morisita-ga sinyaku-o
kokorokara sinyoosita yuujintati-ni
PN-nom
medicine-acc
truly
trusted
friends-dat
[ MinP
MinP
]M ajP
b. Conjoined-names matrix subject (‘Hosokawa and Morishita’)
Hosokawa-to Morisita-ga
sinyaku-o
kokorokara sinyoosita yuujintati-ni
PN-and
PN-nom
medicine-acc truly
trusted friends-dat
[ MinP
MinP
]M ajP
c.

   

Method
Participants Forty-one deaf students at the Tsukuba
University of Technology were paid to take part in the
experiment. One of the requirements for entrance in this
university is that the candidate is unable to hear sounds
below 60 dB or unable to carry out conversations even
with the use of hearing aids (there is a different set of
requirements for blind candidates). In the case of the
participants, hearing levels for the right ear were between 65 and 140 dB (M = 104), and between 77 and
140 dB for the left ear (M = 105.7). Thirty participants were deaf since birth, four since the age of 1 year,
another four since the age of 2 years, and two others
since the ages of 3 and 4 years. At the time of the experiment, their ages ranged from 18 to 27 years (M =
20.1). Because of the diverse educational backgrounds,
age in which Japanese Sign Language (JSL) acquisition
started varied considerably (one participant since birth,
two at 3 years, seven between 6 and 10 years, six between 12 and 14, seven at 15 years, seventeen between
16 and 23 years, and one never learned JSL). Twentytwo participants reported to use one of the dialects of the
Kanto (Tokyo and surroundings) or the Kansai (Kyoto
or Osaka) areas.
As control group, 56 hearing students at Kobe Shoin
Women’s University, volunteered to take part in the experiment. Their age range was between 18 and 23 years
(M = 19.7) and 45 of them reported to be users of one of
the dialects of the Kansai area (Kobe, Kyoto or Osaka).
Materials Eight pairs of fragments (from Hirose,
2003) like the ones shown in (3a, b) were used. The
fragments included up to the head of the relative clause
(‘friends’), which was always followed by the dative
marker ni. Each pair of sentences was exactly the same
except that in the single-name condition, the fragment
included a matrix subject with a single name (or a profession) as in (3a), while in the conjoined-names condition,
the matrix subject contained two conjoined names (or
two professions) as in (3b).
Assuming that deaf readers are less likely to produce
prosodic contours when reading in silence, they should
not be affected by the length manipulations in (3a, b)
if those are prosodic in nature. However, if the manipulations affect a non-phonological process during sentence comprehension, then deaf readers should show biases similar to those reported by Hirose (2003), namely
matrix subjects that contain two conjoined names should
lead to more completions with the early opening inter1631

pretation than matrix subjects that contain only one single name.
Procedure The eight pairs of test sentences were distributed into two lists according to a Latin Square design, and filler items were added to each list. Each of
the two resulting lists were ordered pseudo-randomly so
that at least one filler intervened between two test items.
Each participant saw one list and was instructed to complete each fragment into a sentence using a pen. Fragments were presented in Japanese fonts followed by a
straight line as in (3c) (which corresponds to (3a)).
For the control group, 44 fillers were included in each
list. However, because the procedure took longer than
expected (around 30 minutes), the number of fillers was
decreased to 28 for the deaf participants in order to
avoid long sessions. With 36 items (8 test items and
28 fillers), the deaf participants completed the questionnaire in around 30 minutes. Although the number of
fillers was smaller, their variety was kept the same for the
two groups, with some fragments requiring one predicate
while others requiring two predicates to yield complete
sentences.
Each questionnaire was preceded by a consent form, a
profile (requesting information such as age and major at
the university attended) and instructions.
For the deaf participants, the profile also requested
self-assessments of their Japanese (e.g., grammar, pronunciation) and JSL. The completion questionnaire was
followed by a kanji (Chinese origin characters used in
written Japanese) test. Because the critical manipulations in (3a, b) require the proper names and professions
in the matrix subject to be read correctly, the kanji test
included those words intermixed with 16 unrelated kanji
words, and participants were requested to write their
readings in kana (syllabic characters). Although some of
the answers were not the most standard for the names
used (proper names can have virtually any reading), they
fell within the uses in current Japanese, and most important for our purposes, the readings were compatible with
the prosodic manipulations described earlier.
Analysis Completions obtained for the eight test
items were classified according to their grammaticality.
Ungrammatical completions were not analyzed further.
Following Hirose (2003), grammatical completions
were analyzed as being of the early opening or the late
opening type depending on the matrix clause produced
by participants. For example, completions with a matrix verb that cannot take an accusative NP as argument

were analyzed as early opening because in this case the
direct object ‘medicine-acc’ in (3a, b) cannot be part
of the matrix clause. In contrast, completions with a
matrix verb that requires an accusative NP as an argument were analyzed as being of the late opening type
if that argument position was not saturated by another
accusative NP appearing in the completion.
Analyses of variances (ANOVA) on participant means
(F1 ) and on item means (F2 ) were conducted with the
percentages of grammatical completions and with the
percentages of early opening completions. Participant
group (control or deaf participants) was entered in the
analyses as a between-participants factor, and matrixsubject type (single-name or conjoined names) as a
within-participants factor.
Arcsine corrected analyses were also conducted and
revealed trends similar to the ones obtained for the analyses on the raw percentages reported.

Results
In terms of percentage of grammatical completions, there
was no interaction between group (control × deaf) and
type of matrix subject (single name × conjoined names;
both F s < 0.5). The main effect of matrix-subject type
was not reliable either (F s < 0.2). There was, however,
a main effect of group as the control group produced
more grammatical completions (single name: 96%; conjoined names: 97.3%) than the deaf participants (single
name: 88.4%; conjoined names: 89%; F1 (1,95)= 13.2,
P < 0.001; F2 (1,7) = 7.61, P < 0.05). This is compatible with earlier reports that the deaf tend to have
an imperfect command of Japanese (Matsui, Watanabe,
Sato & Hosoya, 2006, and references therein).
For the grammatical completions, the percentage of
early openings did not differ between the two groups
(deaf: 74.7%; control: 72.5%; F s < 1). This overall preference for early opening (where 50% would be
chance) is compatible with earlier literature (Mazuka &
Itoh, 1995; also Miyamoto, 2002, for experimental results) and indicates that the deaf participants are not
interpreting the construction in a way completely different from the hearing participants. Detailed results are
reported in the following sections and in Table 1.
Types of completions for the control group In
the control group (column A in Table 1), the conjoinednames condition led to more early-opening completions
than the single-name condition according to the participant analysis (F1 (1,55) = 7.57, P < 0.01; F2 (1,7) =
4.12, P = 0.082). Restricting the analysis to the 45
participants in the control group who claimed to use dialects of the Kansai area, the conjoined-names condition
led to more early opening completions (76.8%) than the
single-name condition (66.7%) in the participant analysis (F1 (1,44) = 5.34, P < 0.05; F2 (1,7) = 4.25, P =
0.078). These results replicate previous findings (Hirose,
2003) according to which the conjoined-names condition
tend to lead to more early opening interpretations. The
weak results in the analysis by items is probably due
to the small number of items used (in Hirose, 2003, 12
items or more were used in each experiment).
1632

The results with the speakers of Kansai dialects suggest that the effect is not restricted to speakers of Kanto
dialects (as the ones in Hirose, 2003). This is unsurprising given that the Kanto accent is adopted as standard
Japanese, is widely used in spoken media and is likely
to be enforced when students read aloud in school (see
Sakamoto, Muraoka & Matsuura, 2005, who report that
speakers of the Hakata dialect are sensitive to Kanto
prosodic cues when they hear sentences similar to (3a)).
Types of completions for the deaf participants
For the deaf participants (column B in Table 1), the
conjoined-names condition led to numerically fewer early
opening interpretations (71.7%) than the single-name
condition (77.6%) but the difference was not statistically
reliable (F1 (1,40) = 1.1, P = 0.301; F2 (1,7) = 1.09,
P = 0.332). In the analysis including group (control
× deaf; i.e., A × B in Table 1) and matrix-subject type
(conjoined names × single name), an interaction is observed in the participant analysis (F1 (1,95) = 6.2, P <
0.05; F2 (1,7) = 3.84, P = 0.091). A similar interaction
was detected when the deaf participants were restricted
to the 22 users of Kansai or Kanto dialects (F1 (1,76) =
11.02, P < 0.005; F2 (1,7) = 9.41, P < 0.05). The
latter analysis was conducted because the influence that
the various dialects may have is uncertain, and right now
it is only clear that the prosodic manipulation works for
speakers of Kanto (Hirose, 2003) and Kansai (the control
group) dialects.
We also conducted analyses with a more strict cutoff
with the 29 deaf participants who claimed to have hearing levels equal or above 100 dB for each ear (right ear
M = 110.72 dB, left ear M = 108.83 dB). In this case as
well (column G in Table 1), the conjoined-names condition led to fewer early opening completions (70.4%) than
the single-name condition (81.3%) but the difference was
only marginal in the participant analysis (F1 (1,28) =
3.47, P = 0.073) and not reliable in the item analysis
(F2 (1,7) = 1.87, P = 0.214). However, this group of
participants and the control group (G × A) interacted
with the type of matrix-subject in the fragments according to both types of analyses (F1 (1,83) = 10.05, P <
0.005; F2 (1,7) = 6.74, P < 0.05).
The results indicate that deaf readers (and the ones
with hearing levels equal or above 100 dB in particular) behave differently from hearing readers with respect
to the the matrix-subject manipulation. This difference
can be readily understood if one assumes that the deaf
participants are less likely to be sensitive to prosodic manipulations. If some non-phonological feature had been
responsible for the effect, the same result should have
been observed with the deaf participants. That this is
not the case provides further evidence for the IPH.
There is, however, the possibility that deaf readers imperfect knowledge of the grammar of Japanese (Matsui,
Watanabe, Sato & Hosoya, 2006, and references therein)
may have had some influence on the results. The syntactic constructions investigated are complex, involve relative clauses and, more crucially, require reanalysis in
order to correct an initial misparse of the sentence as a
simple clause. However, this is unlikely given that the

Table 1: Percentage of early-opening completions for the control group (column A) and
for the deaf participants (B to G). Deaf participants were classified as high skill or low
skill according their self-assessments of their pronunciation skills (C and D) and grammar
knowledge (E and F) of Japanese.
Control
All
Group
Number of participants
(I) Conjoined-names
(II) Single-name
Difference: (I) - (II)

A
56
77.7
67.4
10.3

B
41
71.7
77.6
-5.9

number of ungrammatical completions produced by deaf
participants, although reliably larger than for the control group, was small (an average of less than one incorrect completion per participant). Analyses based on the
deaf participants’ self-assessments of their knowledge of
Japanese grammar are reported in the following section
and tend to confirm this claim.
Self-assessment scores In the profile form, deaf
participants were asked to assess their knowledge
of Japanese grammar and their skill in pronouncing
Japanese aloud on a scale from 0 (poor) to 7 (perfect).
This type of self-rating is commonly used in the assessment of participants’ linguistic knowledge and is considered to be one of the best measures available in the
bilingual literature (e.g., Fishman & Cooper, 1969).
Participants who rated themselves from 5 to 7 were
classified as high skill for each individual category (grammar or pronunciation), and participants who rated themselves from 0 to 4 were classified as low skill. In terms
of grammar, there were 23 high-skilled participants and
18 low-skilled. For pronunciation, there were 18 highskilled and 23 low-skilled. There were 13 participants
who rated themselves as low skilled in both grammar and
pronunciation, another 13 were high skilled in both categories, 10 were high skilled in grammar but low skilled
in pronunciation, whereas the reverse pattern included
the remaining five participants.
The percentages of early-opening completions for each
subgroup in each category are shown on columns C to
F in Table 1. For the grammar-based breakdown, the
difference between the conjoined-names and single-name
completions (last row on the table) are similar for the
low-skill (-6.0, column E) and high-skill (-5.8, column
F) participants, and this is reflected in the lack of interaction between the two skill groups (E × F) and matrixsubject type (conjoined names × single name; F s < 0.3).
When each skill group is compared to the control group
(column A), a tendency for interaction between group
and matrix-subject type is observed in each case (A ×
E: F1 (1,72) = 3.35, P = 0.072; F2 (1,7) = 4.3, P =
0.077; A × F: F1 (1,77) = 5.41, P < 0.05; F2 (1,7) =
1.8, P = 0.22). In other words, knowledge of Japanese
grammar does not seem to have affected the completions
produced by the deaf participants.
1633

Deaf participants
Pronunciation
Grammar
Low
High
Low High
C
D
E
F
23
18
18
23
69.6
74.5
68.1 74.6
84.1
69.4
74.1 80.4
-14.5
5.1
-6.0
-5.8

>100dB
G
29
70.4
81.3
-10.9

In contrast, when we consider pronunciation, the highskilled participants (column D) show more early opening
interpretations with conjoined-names than with singlename subjects (a 5.1% difference) similar to the control
participants, whereas the low-skilled participants show
the reverse tendency (-15.5%), although the interaction
is only marginal in the participant analysis (F1 (1,39) =
3.15, P = 0.084) and not reliable in the item analysis
(F2 (1,7) = 1.31, P = 0.29). When compared to the control group, the differences become more evident. There
is no interaction between the control and the high-skilled
participants (A × D) and matrix-subject type (F s < 1),
whereas the equivalent interaction is reliable with the
low-skilled participants (A × C: F1 (1,77) = 11.76, P <
0.005; F2 (1,7) = 9.63, P < 0.05).
In sum, while the classification according to grammar
knowledge does not have any detectable effect, different levels of pronunciation skills reveal differences in the
types of completions produced. Hence, these results reinforce the possibility that the manipulations conducted
are having an effect at the phonological level. Clearly,
the results in this section should be interpreted with caution given that several of the statistical results are suggestive at best and they are based on self-assessment
scores. But the trends are encouraging and are compatible with our claims.
The difference between the conjoined-names condition
and the single-name condition for the deaf participants
was consistently negative (last line of Table 1 for columns
B to G, except for column D) indicating a larger number
of early-opening interpretations for the single-name condition, although none of the pairwise comparisons was
statistically reliable. At the moment we do not have
an explanation for such a possible bias and future work
should investigate it further. It is unlikely that interference from JSL caused the effect as analyses considering
age of JSL acquisition as well as self-assessed JSL ability
did not detect any differences across groups.

General discussion
The present results suggest that deaf readers, especially
the ones that are most likely to have problems handling
phonological information (i.e., the participants that can
only hear sounds above 100 dB, on column G of Ta-

ble 1; or the ones with low self-assessed pronunciation
skills, on column C), are less likely to be affected by
the length of the matrix subject when compared to the
control group. This result underscores the phonological
nature of the effect, and thus provides new support for
the implicit prosody hypothesis by raising the likelihood
that implicit prosodic contours are affecting the way ambiguous sentences are read by hearing participants.
However, a version of the alternative explanation
based on working memory factors may still be sustainable. It is possible that the way the phonological
loop (Baddeley, 1992) handles longer-sounding phrases or
how it converts written input into phonological representations may influence phrasal-boundary analysis (which
in turn could affect prosodic contours rather than the
other way around as assumed in the IPH). It is not
clear at this point how to differentiate between a purely
prosody-base explanation from the possible effects of the
phonological loop. But the present results contribute in
determining more firmly that the phenomenon considered is phonological in nature, thus at least restricting
the kinds of explanations that can be entertained.
It is not our intention to claim that deaf readers generate no phonological representation when they read. At
least for those who are highly skilled in pronouncing
Japanese, there does seem to be a tendency for prosody
to affect sentence comprehension (column D of Table 1)
in a way similar to the control group. Even for the other
deaf participants who show the opposite tendency, it is
possible that prosodic structures are being created but
that these readers are unable to use this type of information in order to disambiguate the input.
A final caveat is in order in relation to grammatical
knowledge. We have claimed based on self-assessments of
grammatical knowledge that the deaf readers’ less than
perfect command of Japanese language is not an issue
here. This should not be taken to mean that grammatical knowledge is not important in the processing of the
relative clause constructions investigated. On the contrary, grammatical knowledge is crucial in understanding the experimental sentences as they involve complex
structures that lead to longer reading times even for
hearing participants with full command of the language
(Inoue, 1990; Miyamoto, 2002; and references therein).
It just seems that for the particular deaf participants in
our study, their overall grammatical knowledge is high
enough not to interfere with our results (this is probably
because students at this university are likely to be relatively successful academically as this is the only tertiary
school for the deaf in Japan).

Acknowledgments
The authors would like to thank Yuki Hirose for providing the items used in her experiments, Yoko Iguchi
for help running the experiment with the control participants, Marie Watanabe for helpful discussions, and
professor Miyoko Hosoya for help recruiting the participants at the Tsukuba University of Technology.
1634

References
Baddeley, A. (1992). Working memory. Science, 255,
556-559.
Fishman, J. A., & Cooper, R. L. (1969). Alternative
measures of bilingualism. Journal of Verbal Learning
and Verbal Behavior, 8, 276-282.
Fodor, J. D. (2002) Prosodic disambiguation in silent
deading. Proceedings of NELS 32 — North East
Linguistics Society (pp. 113–132). Amherst, Mass.:
GLSA Publications.
Frazier, L., & Fodor, J. D. (1978). The sausage machine:
a new two-stage parsing model. Cognition, 6, 291–325.
Hirose, Y. (2003) Recycling prosodic boundaries. Journal of Psycholinguistic Research, 32, 167–195.
Hirose, Y., & Kakei, K. (1998). Aimaina setsukyokaini okeru senzaitekina inritsu-no yakuwari. Onsei-to
bunpou II. Tokyo: Kuroshio-syuppan.
Inoue, M. (1990). Kouzou-teki aimai bun-no rikai-ni
okeru gaaden pasu-ka. Proceedings of the 32nd Nippon
Kyouiku Shinri Gakkai (p. 378).
Matsui, H., Watanabe, M., Sato, K., & Hosoya,
M. (2006).
Choukakusyougaisya-wo taisyoto shita nihongo-test-no kaihatsu-ni mukete –
nihongonoryokushiken-no ouyoukanousei-ni tsuite–.
Nihongo Kyouiku, 128, 110-115.
Mazuka, R., & Itoh, K. (1995). Can Japanese speakers be led down the garden path? In R. Mazuka and
N. Nagai (Eds.), Japanese Sentence Processing. Hillsdale, NJ: Lawrence Erlbaum Associates.
Miyamoto, E. T. (2002). Case markers as clause boundary inducers in Japanese. Journal of Psycholinguistic
Research, 31, 307-347.
Miyamoto, E. T., & Nakamura, M. (2003). Subject/object asymmetries in the processing of relative
clauses in Japanese. In G. Garding & M. Tsujimura
(Eds.), Proceedings of the 22nd West Coast Conference
on Formal Linguistics (pp. 342-355). Somerville, MA:
Cascadilla Press.
Miyamoto, E. T., Nakamura, M., & Takahashi, S. (2004).
Processing relative clauses in Japanese with two attachment sites. Proceedings of NELS 34 — North East
Linguistics Society (pp. 441-452). Amherst, Mass.:
GLSA Publications.
Sakamoto, T., Muraoka, S., & Matsuura, T. (2005).
Pitch and pause in detecting clause boundary in
Japanese. Talk presented at the International Workshop on the Interface between Prosody and Information Structure. Kobe University, December 17, 2005.
Slowiaczek, M. L., & Clifton, C., Jr. (1980). Subvocalization and reading for meaning. Journal of Verbal
Learning and Verbal Behavior, 19, 573-582.
Venditti, J. J. (In press). Prosody in sentence processing.
In M. Nakayama, R. Mazuka and Y. Shirai (Eds.),
Handbook of Japanese Psycholinguistics. Cambridge,
UK: Cambridge University Press.

