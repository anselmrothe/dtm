UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Issues in Reasoning about Iffy Propositions: Reasoning Times in the Syntactic-Semantic
Counter-Example Prompted Probabilistic Thinking and Reasoning Engine

Permalink
https://escholarship.org/uc/item/99k7p1p8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Schroyens, Walter
Sevenants, Aline

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Issues in Reasoning about Iffy Propositions:
Reasoning times in the Syntactic-Semantic Counter-Example Prompted Probabilistic
Thinking and Reasoning Engine (SSCEPPTRE)
Walter Schroyens (Walter.Schroyens@hec.ca)
HEC Montreal, Université de Montréal, 3000 Ch. de la Côte St.-Catherine, H3T 2A7 Montreal, QC, Canada

Aline Sevenants (Aline.Sevenants@psy.kuleuven.be)
University of Leuven, Laboratory of Experimental Psychology, Tiensestraat 102, B-1000 Leuven, Belgium
provides the conceptual background against which RTs
emerge.

Abstract
The
Syntactic-Semantic
Counter-Example
Prompted
Probabilistic Thinking and Reasoning Engine (SSCEPPTRE;
Schroyens et al., 2001; Schroyens & Schaeken, 2003) predicts
both conditional inference rates and reasoning times.
Acceptance times of MP (‘A therefore C”), AC (“C therefore
A”), MT (“not-C therefore not-A) and DA (not-A therefore notC) would follow the order: RT(MP/1) < RT(AC/1) < RT(DA/1)
< RT(MT/1). For each of these arguments rejection times
would be longer than acceptance times. These predictions are
corroborated by an extensive study (N= 350) in which
reasoning times were recorded. Participants also solved a truthtable task in which they had to evaluate the different
contingencies (‘A and C’, ‘A and not-C’, ‘not-A and C’, ‘not-A
and not-C’). Truth-table evaluation times confirm
SSCEPPTRE’s expectation that evaluating “not-A and C” takes
more time than evaluating “A and not-C”.

The Model Theory of Conditionals
This section summarizes the main principles of the model
theory of conditionals. The model theory postulates that
individuals understand sentences by representing possibilities.
In accordance with the Gricean principles of conversation
(Grice, 1975, also see Levinson, 2000), people will assume
that the information they are confronted with is true: They
will initially consider only possibilities that are compatible
with the conditional. This is the so-called truth-principle
(Johnson-Laird, 1999, p. 116). Moreover, since people are
bounded in their rationality (Simon, 1957), they cannot and
hence will not even consider all true possibilities from the
outset. This is the implicit-model principle. Content and
context will aid the construction of alternative possibilities
that are not represented ab initio. This is the idea behind the
so-called principles of semantic and pragmatic modulation.
Let us elaborate.

Introduction
If you are sceptical about the import(ance) of conditional
reasoning, then consider that you would not even be able to
understand the very sentence you are reading now. Our ability
to reflect on potential implications of what is, could have
been, or will be predicates some of the prime examples of the
human marvel. The elusive nature of conditionals has
accordingly received much interest from psychology, AI,
linguistics, neuro-science, and philosophical-logic.
In the reasoning literature few papers have considered
reaction or reasoning times (RTs). We suspect that the
complexity of the analyses might have kept theorists from
taking up the challenge. We take up this challenge and
present a computational model of conditional reasoning that
yields fine-grained predictions about reasoning times. Insights
about human reasoning do not come as such. ‘Facts’ only
become interesting and interpretable within the context of a
theoretical narrative. We therefore ask the reader to bear with
us when we first present the general model theory of
conditionals. Once we have the general theory, we can
specify its principles to a particular topic of interest. Our
specification of conditional by model is referred to as the
Syntactic-Semantic-Counter-Example Prompted Probabilistic
Thinking and Reasoning Engine (SSCEPPTRE). The general
model theory of conditionals, and the specific computational
processing model of conditional reasoning (SSCEPPTRE),

Initial representations
Sentential Information will be
processed to yield semantically rich representations. These
representations can be described at a biological, subsymbolic, or symbolic level of detail. There is no immaculate
perception; one has to start with something. At the surface, a
sentence like <if A then C> describes some sort of relation
between <A> and <C>. (We leave it up to the reader to use
his/her imagination to specify an antecedent and consequent
event, <A> and <C>). As the bare minimum, this relation
captures the idea that <C> occurs within the context of <A>.
That is:
A (C)
This initial model reflects the bare minimum1. Some
reasoners might note that <A> is exhaustively represented.
An exhaustively represented token signifies that there are no
1

Our notation deviates from the one used by Johnson-Laird and
Byrne (2002). They did not present a notation that reflects the idea
that <C> occurs within the context of <A>. We place <C> in round
brackets to reflect this. As Johnson-Laird and Byrne (2002)
expressed it: “The antecedent refers to a possibility, and the
consequent is interpreted in that context” (p. 649, italics added) or
“the antecedent of a basic conditional describes a possibility, at
least in part, and the consequent can occur in this possibility” (p.
650, italics added).

762

Interpretational processes are not distinct from reasoning
processes. Both are representational processes. That is, ‘the’
interpretation of a conditional does not exist. Interpretations
are ephemeral and reflect ongoing processes of constructing
and modulating mental model like representations. For
instance, as will be illustrated below, to have the conditional
interpretation it is required that reasoners engage in a search
for alternatives to the initial model.
Pragmatic and semantic modulation aids the process of
constructing alternatives models. In the absence of specific
pragmatic and semantic cues, people need to resort to
syntactic procedures or more systematic strategies in
constructing alternative models. SSCEPPTRE assumes that
people will engage in a goal-directed search for alternatives:
the alternative models are constructed by denying the
possibility one looks and alternative for.

other situations in which <A> occurs than those wherein <C>
is also the case. By implication, all other possibilities depict
<not-A> events, i.e., state of affairs in which <A> is not the
case. It also implies that <not-C> events that occur within the
context <A> are inconsistent with the conditional: <A(notC)> cases falsify the conditional. Exhaustiveness is
conventionally denoted by square brackets around the
exhausted event token.
[A] (C)
Johnson-Laird and Byrne (2002) state “modulation can add
information about temporal and other relations between
antecedent and consequent” (p. 646). They present these
processes of semantic or pragmatic modulation as two
fundamental processing principles. One part of these twin
principles of content and context refers to the process of
enriching models. For instance, “If the cardinality of the set
matters, then models can be tagged with numerals, just as
they can be tagged to represent numerical probabilities”
(Johnson-Laird & Byrne, 2002, p. 655).

Conditional Reasoning with SSCEPPTRE
Conditional inference problems are set by a categorical
premise that affirms or denies either the antecedent <A> or
consequent <C> of the conditional statement, <if A then C>.
The top panel of Figure 1 presents the four basic inference
problems. The two affirmation problems are referred to as
Modus Ponens (MP, i.e., an affirmation of the antecedent
problem) and Affirmation of the Consequent (AC) problems.
The two denial problems are known as Denial of the
Antecedent (DA), and Modus Tollens problems (MT, i.e.,
denial of the consequent). Performance on these problems is
mostly discussed in terms of the standard affirmation and
denial inference rates.
MP If A then C; A, therefore C
AC If A then C; C, therefore A
DA If A then C; Not-A, therefore Not-C
MT If A then C; Not-C, therefore Not-Ca
The content of the antecedent and the consequent can be
formed by virtually any well-formed lexical term, for
instance: “ If the letter is a ‘A’, then the number is a ‘2’”.
Studies of human reasoning competence commonly use
knowledge-lean utterances. The rational is that such abstract
materials are less likely to cue prior beliefs.
Figure 1 presents the parameterized processing tree of
constructing and manipulating mental models within
SSCEPPTRE. In a simplified form, the likelihood by which
people would endorse the standard determinate inferences is
captured by the following equations:
P(MP) = 1-LCETF
P(AC) = 1-LCEFT
P(MT) = LCEFF.(1 - LCETF)
P(DA) = LCEFF.(1 - LCEFT).
The MP and AC functions express that affirmation inferences
(MP/AC) are endorsed by all people (p = 1.0) except those
who accept a counter-example to it (with a probability of
LECTF or LCEFT)2. Initially people only consider the True-

Looking for alternative possibilities
Content and context
not only adds information to the initial model. A second
import of semantic and pragmatic modulation concerns
constructing alternative models: content and context “can
prevent the construction of otherwise feasible models and aid
the process of constructing fully explicit models”. Indeed, we
have as yet not considered the implicit model to which the
implicit-model principle thanks it name. The model theory
assumes that most people realize that more possibilities are
consistent with <if A then C>, without explicitly representing
which these possibilities are. The convention is to denote this
implicit model by an ellipsis.
A (C)
[A] (C)
…
…
The model theory holds that at a basic level of processing,
some people forget about the empty model. If so, then people
will not consider alternative possibilities. They are satisficing.
The likelihood of looking for alternative possibilities is
context and context dependent. A conditional of the form <if
A then C> could for instance be interpreted as a tautological
utterance <if A then possibly C>. It allows for all four
contingencies: <A(C)| A(not-C)| not-A_C| not-A_not-C>.
Another interpretation of <if A then C> refers to the
conditional interpretation, in which three possibilities are
considered: <A(C) | not-A_C | not-A_not-C>. People who
represented <A> exhaustively in relation to <C> can use the
exhaustiveness tag to explicate the alternative models. The
<A(not-C)> contingency is excluded since it incorporates the
exhausted token <A>, which can thus not be used to construct
alternative models. The only possible alternatives are events
in which A is not the case: <not-A_C> or <not-A_not-C>.
Depending on content and context these contingencies will be
more or less plausible. They are accordingly more or less
likely considered as alternatives to the initial <[A](C)>
model. When people have a so-called bi-conditional
interpretation, for instance, they will not consider <not-A_C>
a true possibility.

2

The <LCEFT> and <LCETF> parameters are a composite of (a) the
likelihood by which people Look for a counterexample, (b) the
ease of Constructing it and (c) the likelihood of Evaluating and
accepting the hypothetical possibility. The latter component is
763

conclusion (p =
1). They are only
able to generate
the
denial
inference
provided
they
construct
and
accept
an
alternative
to
<null>.
This
alternative
represents
the
contingency
wherein both the
antecedent and
consequent are
false and yields
the
denial
inference. That
is, the likelihood
Figure 1: Simplified parametric processing tree of solving conditional inference problems by
by which people
constructing and manipulating mental models.
generate
the
denial inference would equal the likelihood (i.e. LCEFF) of
antecedent-True-consequent contingency: TT<A(C)> vis-alooking for, constructing and accepting FF<not-A_not-C>.
vis <if A then C>. The two model sets are compatible and
Again, having generated a conclusion does necessarily imply
yield the affirmation inferences. We assume that everybody
that the inference will be endorsed. Some people will attempt
can generate the affirmation inference (p=1). Hence, the
to validate their conclusions. Of those people who generate
likelihood of endorsing vs. generating the inference equals
the denial inference, some could look for a counterexample.
unity minus the likelihood of rejecting them subsequently on
DA (“not-A therefore C”) is countered by FT<not-A_C>.
the basis of a counterexample.
The falsity of the antecedent is given by the categorical
If the falsity of the conclusion is considered possible, it
premise and the truth of the consequent is determined as the
follows that it is possibly false and hence not necessarily true.
only alternative to the falsity of the consequent. When people
The relevant counterexamples are captured by the
look for a counterexample to MT, they would consider
contingency reflecting the falsity of the conclusion in
TF<A_not-C>. Upon accepting the counterexample, they
combination with the given truth of the categorical premise.
reject the putative inference countered by it. That is, as shown
This means that MP is validated by considering the Truein Figure 1 the denial inferences (MT/DA) would be endorsed
antecedent-False-consequent, TF<A_not-C> contingency,
by those who generated it (with a probability of LCEFF)
whereas AC is validated by considering the False-antecedentTrue-consequent, FT<not-A_C> contingency. Figure 1
except those who generated it but considered and accepted a
shows that accepting the counterexamples results in rejecting
counterexample to it (with a probability of <LCEFT>).
the standard inferences. A failure to accept the
SSCEPPTRE’s reasoning behaviour
counterexamples (with a probability of [1- LCETF] or [1LCEFT]) results in endorsing them.
Conditional inference rates SSCEPPTRE predicts the
The initial model does not support the denial arguments. It
relative difficulty of the conditional arguments. First, the
does not include a representation of the falsity of the
affirmation inferences are more likely than the denial
consequent/antecedent (as asserted categorically by [notinferences. In the later case, there is an additional weight.
C]/[not-A] in MT/DA; see Figure 1). It is consequently
This weight (a multiplication factor, i.e. LCEFF < 1)
eliminated and people are left with only the empty model, [
corresponds to the additional processing difficulty of
...], which does yield any conclusion: “nothing follows”
generating the denial inferences. The initial models do not
(null). As before, supposedly all people infer this initialmodel
yield these denial inferences. Second, the logically valid
arguments, MP and MT, are more likely than the logically
invalid arguments, AC and DA. TF cases are impossible
probabilistic in nature: The higher the frequency of
given the truth of the conditional, and people almost indeed
counterexamples, the more likely people are to reject their initial
almost unanimously judge them as such (Barrouillet & Lecas,
model inferences (see, e.g., Schroyens et al., 2001). All processing
1998; Evans, 1983). FT is however possible and a sizable
step (i.e., parameters) have a particular likelihood of being
proportion of people state such. That is, everything else being
successfully executed. When people fail to executed a step, the
path is closed. Hence, the likelihood of reaching the end of this
equal, people are more likely to reject the logically invalid
part of the processing chain is formed as the product of the
arguments. Third, the logical validity effect is caused by the
likelihood of successfully executing each of the processing steps.

764

difference in the likelihood of accepting TF versus FT. In the
case of the denial problems this difference is conditional upon
first having generated and evaluated the denial inferences.
Generating and accepting these denial inferences is less likely
than generating the affirmation inferences (LCEFF < 1).
Hence the logical validity effect will be smaller on the denial
versus affirmation problems. See Schroyens and Schaeken
(2003, Schroyens et al., 2001) for meta-analyses and a
comparative model fitting exercise.

look for a counterexample. The extra time it takes to look for,
construct and evaluate the counterexamples will have a larger
import on MT/1, as compared to DA/1. Since almost nobody
will accept the TF counterexample to MT, almost all these
extra validation times are included in the overall reasoning
times of MT/1. In DA/1, fewer such validation times will
increase the overall reasoning times. Indeed, more than for
MT (because FT > TF), some of these longer validation times
will become part of the reasoning times of the rejected DA
arguments, DA/0.
Second, not everything else is equal. It takes more time to
evaluate the less certain FT vs. TF. That is, the higher
proportion of validation times, as compared to the proportion
of faster un-validated (but also accepted) MT reasoning times,
is counterbalanced by shorter latencies in evaluating TF vs.
FT. That is, RTs would again tend toward a null-effect. Third,
this annulling effect of counterexample evaluation times is
itself countered however by directionality. MTs
counterexample is incongruent with the conditional. We
therefore expect that the base prediction is reinstated:
RT(MT/1) > RT(DA/1). Endorsing MT will generally take
longer than endorsing DA.
In summary, first, the affirmation arguments will be
endorsed faster than the denial arguments. The initial model
does not represent FF, needed to endorse the denial
arguments and people are consequently less certain and will
take more time to accept the denial arguments. Second, there
will be an interaction between problem type and logical
validity. On denial the invalid argument (DA) will be
endorses faster, whereas on affirmation problems the valid
argument (MP) is the one that will be endorse faster.
Rejected Versus Accepted Arguments. SSCEPPTRE
predicts that the RT/0s for all four basic arguments will be
longer than their RT/1s. Figure 1 clearly shows this for
rejected versus accepted affirmation arguments. When people
reject the affirmation arguments, we know ex hypothesis that
they have completed the entire time-consuming validation
process of looking for, constructing and evaluating (i.e.,
accepting) the counterexample. The predictions are a
mathematical consequence of the computational model. With
each extra processing step (successfully executed, or not, with
a particular likelihood) there is an additional processing time.
Within the scope of the present paper we cannot present the
proof. We therefore need to suffice with the heuristic device
of Figure 1.
The processing chain associated with the denial inferences
is somewhat more complicated in detail. The general idea
however is relatively simple. The non-acceptance times are a
composite of fast “nothing follows” conclusions, <null>,
which are based on the initial representations, and slow
“nothing follows” inferences, <NULL>, based on the
accepted counterexamples. Figure 1 shows that the slow
<NULL> reflects the conclusion that both the denial
inference (e.g., <A>) and its counterexample (i.e., <not-A>)
are judged possible. The RT/1s are somewhere in between the
fast <null> and slow <NULL> inferences. Hence, we cannot
make an unequivocal prediction without specifying the

Reasoning times In the following we first consider the
accepted arguments. We then specify the novel predictions as
regards the difference between reasoning times of accepted
(RT/1) versus rejected (RT/0) arguments.
Accepted Affirmation Arguments We know that people are
less likely to accept TF vs. FT (Barrouillet & Lecas, 1998;
Evans, 1983). For MP, the validating search TF cases is
almost literally a waste of time. Indeed, virtually nobody
accepts TF. The validation times, i.e, reasoning times
associated with the search for counterexamples, will therefore
be added to the accepted MP latencies, RT(MP/1). In AC, a
proportion (1-LCEFT) of these validation times adds to the
rejected AC latencies. That is, ceteris paribus, we could
expect MP/1’s to take longer than AC/1’s. But, not everything
else is equal. First, we assume that there is a difference
between evaluating TF and FT. People are relatively certain
TF is impossible, whereas they are relatively uncertain that
FT is possible. The increased doubt about FT would be
reflected in longer evaluation times. It follows that the longer
evaluation times counterbalance the lower proportion of
validation-times in the AC/1 arguments. Second,
SSCEPPTRE assumes that the representations are relational
in nature (cf. Footnote 1). The consequent event occurs within
the context of the antecedent event. This factor introduces a
directional relation between <A> and <C>. This affects one
of SSCEPPTRE’s procedures. Counterexamples are formed
as the categorical premise in combination with the denial of
the to-be tested conclusion. That is, in case of “A therefore C”
(i.e., MP) the counterexample is formed as “A and not-C”.
This concurs with the directionality in <A(C)>. In case of “C
therefore A” (i.e., AC) the goal-directed search for
counterexamples yields “C and not-A”. This is incongruent
with the <A> to <C> directionality. That is, in AC the
evaluation times of the incongruent FT<C_not-A> would be
even higher, as compared to the evaluation times of the
congruent TF<A_not-C> counterexample.
In summary, we expect that the reasoning times of accepted
MPs are equal or longer than RTs for accepted ACs:
RT(MP/1) ≥ RT(AC/1). The higher proportion in MP of
validation times is counterweighted by the longer latencies
for
evaluating
AC’s
directionally
incongruent
counterexamples.
Accepted Denial Arguments The above derivation also
applies to MT vs. DA. The implications of some of our
assumptions differ however for denial arguments. First, we
could expect that, ceteris paribus, RT(MT/1) >RT(DA/1).
Once people have generated the denial argument, some will

765

‘follows’ or ‘does not follow’. RTs were recorded from
presentation onset until the response was given.
In the truth-table tasks, people evaluated the four randomly
presented truth-contingences: e.g., “an A in combination with
a 2”, “not an A in combination with not a 2”, etc. In the
possibility-based truth-table task, participants responded to
the question “is this situation possible or impossible
according to the rule” by clicking on <possible> or
<impossible>. In the truth-based truth-table task, participants
responded to the question “does the situation make the rule
true or untrue, or is she irrelevant regarding the truth of rule”
and clicked on <true>, <irrelevant> or <untrue> to provide
their answer. (In Dutch, ‘untrue’ and not ‘false’ is more
common). In the meta-theoretical condition, participants
indicated whether they agreed or disagreed with the following
paragraph:
A situation that is IMPOSSIBLE according to a rule
makes this rule UNTRUE. (e.g. ‘The letter is an A and the
number is a 4”. If this rule is true, then the letter-number
combination ‘B-5’ is impossible. ‘B-5’ shows that the rule
‘A AND 4’ is untrue about the set of letter-number
combination from which ‘B-5’ was taken).
A situation that is NOT IMPOSSIBLE according to a rule
does NOT make this rule UNTRUE. Something that is
NOT IMPOSSIBLE is POSSIBLE and something that is
NOT UNTRUE is TRUE. This means that a situation that
is POSSIBLE according to a rule makes this rule NOT
UNTRUE and therefore TRUE.
We do not have place here to discuss the reasons for
including this meta-theoretical question. The same goes for
the possibility vs. truth-based truth-table task. 3

relative proportion of the fast <null> and slow <NULL>
inference reasoning times. However, Schroyens et al. (2001)
already proffered that looking for counterexamples to <null>
is more likely than looking for alternatives to a determinate
conclusion. ‘Nothing’ does not satisfy the task demand to
decide what follows from the premises. People will tend to
look for a determinate inference, unless researchers
emphasise that “nothing’ is an acceptable conclusion. Indeed,
most tasks employ an evaluation format. It follows that the
initial null inference is bypassed by the given denial
inferences (see Schroyens, 2005, for further support of this
analysis).
Given the low proportion of people who satisfice with
<null>, overall RT/0s will tend to be longer for both MT and
DA. Moreover, this effect will be stronger for DA than for
MT. That is, the difference between RT(MT/0) and RT(DA/0)
will tend to smaller than the RT(MT/1) vs. RT(DA/1)
difference. The reason is fairly simple. The denial RT/0s are a
composite of fast <null> and slow <NULL> inferences. As
argued above, the proportion of fast <null> inferences would
be relatively small compared to the proportion of slow
<NULL> inferences. In MT/0 (vs. DA/0) this proportion of
slow <NULL> inferences would be smaller. Indeed, we know
that people are less likely to accept TF as compared to FT.
The RTs of the proportion of people who reject TF will
generally not make part of the overall RT/0s. People who
reject TF will tend to accept MT.

Experiment
Method

Results and Discussion

Design All Participants evaluated the four standard
Response frequencies. The inference rates (see Table 1) are
conditional arguments. Three sub-groups were formed by also
in line with Schroyens et al.’s (2001) meta-analytic
presenting the participants with a truth-table task. (The
conclusions, and SSCEPPTRE’s predictions. First,
presentation order of the inference and truth-table task was
affirmation problems are easier than denial problems (.811 vs.
counterbalanced). Participants completed a truth-based or
.697: T = 1667.5, Z = 5.68, p < .0001). Second, logically valid
possibility based truth-table task. One of the three subgroups
arguments
are
endorsed
more
solved the truth-based truth-table task after Table 1: Conditional inference
frequently than logically invalid once
responding to a meta-theoretical question about rates (P) and RTs for accepted
(.851 vs. .657: T = 1610, N = 153, Z =
truth.
7.80, p < .0001). Third, the logical(/1) and rejected (/0) arguments.
validity effect is larger for affirmation
Participants All participants (N = 350) were
than denial arguments (.35 vs. .04: T =
Argument
first year psychology students at the University
1564, N = 138, Z = 6.678, p < .0001).
MP AC MT DA
of Leuven who participated in partial fulfilment
Table 2 shows that all three truthof a course requirement. They were randomly P
.986 .637 .717 .677
table tasks confirm the standard order
allocated to three groups (100, 100 and 150 RT/1 9.32 11.56 14.42 12.00
in the acceptance rates (‘true’ or
participants).
‘possible’) of the four truthRT/0 n < 5 14.53 18.52 17.05
contingencies: 1 ≈ P(TT) > P(FF) >
Materials and Procedure The conditional inferences task
P(FT) > P(TF) ≈ 0. The overall linear contrast is highly are
followed an evaluation format. Participants evaluated the
reliable (Page L = 9708.5, ZL = 33.18, p < .0001). These
randomly presented affirmation and denial arguments. All
problems concerned letter-number combinations and were
3
The following citation might be enlightening though: “Each entry
presented as follows (translated from Dutch).
in a truth table represents the truth or falsity of an assertion given a
Given:
If the letter is an A, then the number is a 2.
particular possibility. In contrast, each mental model in a set
Given:
The number is not a 2.
represents a possibility. A corollary is that possibilities are
Conclusion: Hence the letter is not an A.
psychologically basic, not truth values. Discourse about the truth
Does this conclusion follow necessarily?
or falsity of propositions is at a higher level than mere descriptions
Participants responded by clicking the mouse cursor on
of possibilities” (Johnson-Laird & Byrne, 2002, p.653).
766

needed to make additional assumptions about reasoning times
results confirm SSCEPPTRE’s assumption about relative
associated with component processes. For instance, we
likelihood by which people will accept the different truth
assumed that relatively uncertainty is reflected in the
contingencies. The high proportion of ‘false’ evaluations of
evaluation times of the possibilities that people would
FT points towards so-called bi-conditional interpretations.
consider in the process of constructing and manipulating
As noted above, an in depth discussion of true versus
mental models. This yielded
possible situations falls beyond the
the novel prediction and
scope of the present manuscript. The
Table 2: Frequencies and reaction times (RT in
observation that evaluating the
expert reader will recognize the
sec.) associated with evaluating the four truth“not-A and C” combination
theoretical import of the higher
contingencies as possible or true.
(TF) takes longer than
acceptance rates of FF cases in the
Truth Contingency
evaluating the “A and not-C”
possibility-based task (e.g., .87 vs.
TT
FF
FT
TF
combination (FT) vis-à-vis a
.38). He/she will also appreciate (cf.
Possibility based task (N=100)
conditional of the form “if A
Footnote 3) the import of their
Possible
.91
.87
.52
.19
then C”.
decreased irrelevancy evaluations in
Impossible
.09
.13
.48
.81
We took up the challenge of
case participants first thought about
Overall RT 13.30
15.80
16.33
13.67 putting SSCEPPTRE to the
the relation between the ‘true’ and
Truth based task (N = 100)
test of explaining not only
the ‘possible’ (.54 vs. .41; χ² = 3.29;
True
.84
.38
.08
.06
inference rates but also
p < .05, one-tailed).
False
.05
.08
.63
.85
problem solving latencies. We
Irrelevant
.11
.54
.29
.09
hope that our results and
Response Latencies Table 1 shows
Overall RT 13.20
18.63
15.15
12.79 analyses provide a similar
that the rejection times are longer
Meta-Truth based task (N =150)
challenge
to
alternative
than their acceptance times for AC,
True
.93
.41
.13
.04
contemporary theories of
MT and DA: respectively, t = 3.49, p
False
.02
.18
.65
.89
human reasoning.
< .0006; t = 3.46, p <.0006, t = 4.67,
Irrelevant
.05
.41
.21
.07
p <.0006.
Acceptance Times. To test the
Overall RT 12.14
17.32
16.62
13.92
Acknowledgments
predicted main effect of problem
Note. TT is the True-antecedent-True-Consequent We gratefully acknowledge
type, and the ordinal interaction
contingency; TF is the True-antecedent-False- the support of the Flanders
between logical validity and problem
consequent contingency, etc.
(Belgium) Fund for Scientific
type on the RT/1s, we need to reduce
Research (G.0320.05) and the Canadian Natural Sciences and
the data set is to 45.7% of its original size, i.e. to the RTs of
Engineering Research Council (NSERC 297517).
the 160 participants who endorsed all four arguments. With
RT/1’s of 9.65, 11.61, 12.91 and 12.25 we indeed find that
References
affirmation arguments are endorsed faster than denial
arguments (10.63 vs. 12.08; F = 9.53, p < .005). The expected
Barrouillet, P., & Lecas, J.-F. (1998). How can mental models
difference between RT(MP/1) and RT(AC/1) (F = 6.59, p <
theory account for content effects in conditional reasoning?
.05) is in the opposite direction from the expected difference
A developmental perspective. Cognition, 67(3), 209-253.
between RT(MT/1) and RT(DA/1), F = 6.45, p < .05. The
Evans, J. St. B. T. (1983). Linguistic determinants of bias in
interaction is reliable (F = 11.91, p < .001).
conditional reasoning. Quarterly Journal of Experimental
The two pair-wise comparisons between MP/1 vs. AC/1 and
Psychology, 35A, 635-644.
MT/1 vs. DA/1 can be done independently, which means that
Johnson-Laird, P. N., & Byrne, R. M. J. (2002). Conditionals:
fewer cases are excluded. The additional data points do not
A theory of meaning, pragmatics, and inference.
make a difference. We have, respectively, 9.33 vs. 11.59, n =
Psychological Review, 109(4), 646-678.
222, t = 3.804, p < .001 and 13.56 vs. 11.89, n = 186, t =
Schroyens, W., & Schaeken, W. (2003). A critique of
2.609, p < .01. It will be recalled that these predictions hinge
Oaksford, Chater and Larkin's (2000) conditional
on the assumption that evaluation times of FT are slower than
probability model of conditional reasoning. Journal of
those of TF cases. Table 2 shows that all three truth-table
Experimental Psychology: Learning, Memory and
tasks corroborate the assumption (p's <.001 for all
Cognition, 29, 140-149.
comparisons).
Schroyens, W., & Schaeken, W. (2004). Guilt by association:
On iffy propositions and the proper treatment of mentalmodels theory. Current Psychology Letters, 12(1),
General Conclusion
http://cpl.revues.org/document411.html.
The theoretical import(ance) of our findings as regards
Schroyens, W., Schaeken, W., & d'Ydewalle, G. (2001). The
reasoning times can be summarized in one sentence: They
processing of negations in conditional reasoning: A metacorroborate the detailed processing assumptions of
analytic study in mental model and/or mental logic theory.
SSCEPPTRE. We asked readers to bear with us in presenting
Thinking and Reasoning, 7(2), 121-172.
the detailed picture of reasoning by model in SSCEPPTRE.
We hope the effort has paid off in virtue of seeing a picture
that approaches the indeed rather complex reality of thinking
and reasoning about ‘if’.
To derive our predictions about conditional reasoning we
767

