Allocation of attention during auditory word learning
Keith S. Apfelbaum (apfelbaum.3@osu.edu)
Department of Psychology, 1835 Neil Ave.
Columbus, OH 43210 USA

Vladimir Sloutsky (sloutsky.1@osu.edu)
Department of Psychology, 1835 Neil Ave.
Columbus, OH 43210 USA
Abstract
The deployment of selective attention has been studied in
depth as a mechanism of visual categorization for decades.
However, little work has investigated how attentional
mechanisms operate for non-visual domains, and many
models of categorization tacitly presume domain-general
attention use. In three experiments, we investigated whether
learners deploy attention to novel auditory features when
learning novel words in a similar fashion to the prevailing
visual categorization findings. These studies yielded evidence
of non-isomorphism, as selective attention in the auditory
domain shows high context specificity, in contrast to the wide
generalization of attention in the visual domain.
Keywords: selective attention; auditory
categorization; category learning; word learning

attention;

Introduction
Selective attention plays a crucial role in efficient
categorization. Selective attention allows an organism to
focus on features that reliably differentiate items from
different categories, and ignore irrelevant features. By using
only relevant features, organisms can efficiently classify
items (i.e., decide what category the items belong to)
without interference from irrelevant information. Classic
findings in category learning show that adult learners
readily and flexibly apply selective attention to learn
category structures (Shepard, Hovland, & Jenkins, 1961).
Attending selectively to features that are more predictive of
category membership drastically improves learning
compared to relying on all features equally. Such effects are
thought to occur regardless of the type of feature; as long as
features are not integral, learners readily show selective
attention to the features (Best, Yim, & Sloutsky, 2013;
Kruschke, 2003).
Selective attention’s benefit for category learning is
intuitive: in any category learning task where some features
are relevant and others are irrelevant, a learner is best served
by ignoring the irrelevant ones. However, despite this
general benefit of selective attention, attention could be
deployed in any number of ways: it could operate by
changing attention to entire dimensions, or by shifting
attention to regions within a dimension; it could be a finite
resource, such that increased attention to one dimension
necessitates decreased attention to another, or dimensions
could be independent; it could readily generalize across
contexts, or be tightly linked to contexts; and so on.
Critically, these differences could emerge across sensory

domains – for example, visual category learning may differ
from auditory lexical categories. The goal of research
presented here is to test the isomorphism of mechanisms of
categorization across modalities by examining how selective
attention operates in auditory lexical categorization.
The bulk of research on selective attention has relied on
visual stimuli. Although these studies are extremely
informative, they leave a critical question of how
categorization proceeds in non-visual domains. For
example, little work has investigated selective attention in
auditory learning of phonological or lexical categories.
Understanding selective attention in this domain is critical
to elucidating the nature of categorization. Isomorphism of
selective attention would rapidly broaden our understanding
of the processes of auditory categorization. Studying
attention in the visual domain is simpler in many respects,
such as the ability to explicitly measure attention through
eye-tracking (Rehder & Hoffman, 2005). Similarly use of
auditory tasks, such as measuring auditory processing in
young children during sleep, could help answer visual
categorization questions. However, a lack of isomorphism
would suggest a need for in depth investigations of auditory
attention, akin to those in the visual domain, to understand
points of demarcation between domains, and to describe the
mechanisms of auditory category learning.
Coarse grains of analysis suggest parallels between
attention in the two domains. Language learners perform a
type of dimensional attention to emphasize relevant
dimensions and down-weight irrelevant ones (Apfelbaum &
McMurray, 2015; Francis & Nusbaum, 2002; Toscano &
McMurray, 2010), akin to dimensional weighting in visual
categorization tasks (e.g., Nosofsky, 1986). Additionally,
language development may pass from early, holistic
representations of multiple stimulus features to more
selective, phonetic-based representations (Werker & Curtin,
2005), parallel to the shift from distributed to selective
attention in visual category learning (Sloutsky, 2010).
However, several domain differences may result in
differential use of attention. Visual attention can rely on
physical reorientation of the eyes to filter out irrelevant
visual features; the auditory system lacks such physical
means of selection. Additionally, auditory lexical categories
rely on highly overlearned phonetic features; the same small
set of features is used to differentiate all words throughout
the lifespan of a monolingual speaker; visual categories
include a wider variety of features, and sometimes even
necessitate creation of novel features on the fly (Schyns,

2195

Goldstone, & Thibaut, 1998). Finally, the temporal nature of
auditory stimuli may encourage flexible attention
deployment; static visual stimuli allow resampling
information after initial filtering, whereas ignored auditory
information may be unavailable if it later proves relevant.
The nature of selective attention use for auditory lexical
categories thus remains an open empirical question.
Although some work has demonstrated that selective
attention occurs within this domain (Francis & Nusbaum,
2002; Holt & Lotto, 2010; Idemaru & Holt, 2011), no
studies have examined if this attention is accomplished in
the same manner as in visual categorization. The present
experiments offer initial insight into the validity of an
amodal theory of selective attention that subserves both
visual and auditory-lexical category learning.

Experiment 1
Selective attention during category learning is signaled by
increased attention to one dimension accompanied by
decreased attention to other dimensions. Measuring the
deployment of selective attention relies on tracking either
how learners attend to features during processing directly,
such as with eye-tracking (Rehder & Hoffman, 2005), or
inferring attention from performance measures, such as
learning curves or discrimination thresholds (Kruschke,
2003). A challenge for gauging isomorphism across
domains is using a task that allows comparable dependent
variables; although eye-tracking allows direct measure of
visual selective attention, no comparable direct measure of
attention in the auditory domain is possible.
Additionally, the features themselves are not directly
comparable. Auditory features operate differently (e.g. their
temporal nature) and may be processed fundamentally
differently. Attempting to equate features across domains is
speculative at best. Instead, we emphasize qualitative
comparisons: patterns of selective attention are consistent
across different visual features, so differences that arise in
our selection of auditory features would signal a diversion
from the constant visual effects.
We thus used an inferential approach to gauging auditory
selective attention, allowing ready comparison with patterns
seen previously in the visual domain. Visual studies
typically show rapid optimization to relevant category
features, and concomitant decreased attention to irrelevant
dimensions (Best, Yim, & Sloutsky, 2013). This pattern
exhibits highlighting or down-weighting entire dimensions;
when attention is allocated to a dimension in one context or
one task, this pattern generalizes across contexts and values
of the dimensions (Best et al., 2013; Kruschke, 2003).
We adapted the learned inattention paradigm to study
selective attention allocation in the auditory lexical domain.
We measured how discrimination thresholds for novel
phonological contrasts changed based on their relevance for
an auditory category learning task. Specifically, we sought
evidence that learners improve discrimination of contrasts
that are relevant to category learning, and simultaneously
decline in discrimination of category irrelevant contrasts.

Methods
Participants Data from 56 participants were included in
analysis. The participants received partial course credit for a
psychology course at Ohio State University. All reported
being native speakers of English, and all had normal hearing
and normal or corrected-to-normal vision. An additional 14
participants failed to complete the study due to computer
error, exceeding time limitations to complete the task, or
failure to learn the categories within 140 trials.
Stimuli Two 11-step continua were generated based on a
single recording of the non-word dubo. The first continuum
derived from adjusting the duration of the first vowel in
dubo; the second consisted of different pitch patterns on the
second vowel. These features were selected because they are
not primary cues to phonetic distinctions in English;
learners are more likely to show changes in attention to
these features than primary phonetic features with which
they have a lifetime of experience.
The continua were generated by excising the vowels from
the recording, and then manipulating them to create equalspaced steps before re-splicing the vowels back into the
original recordings. The vowel-duration continuum on the
first vowel consisted of durations ranging from 66 ms to 152
ms in approximately 8.5 ms steps. For the pitch continuum
on the second vowel, all steps had a vowel-initial pitch of
184 ms. At the lowest step, this pitch slowly fell to 130 Hz;
at the highest step it rose to 233 Hz. Pilot testing showed
that these step sizes resulted in approximately equal
discrimination. We fully crossed the two continua, creating
121 unique stimuli (11 vowel-one durations X 11 vowel-two
pitches). The stimuli were visually and auditorily inspected
to ensure that they sounded natural and were free of artifacts
from the acoustic manipulations.
Procedure The procedure used a pre-test, training, post-test
design. Pre- and post-test were identical; these segments
measured participants’ discrimination thresholds separately
for each contrast to determine whether discrimination was
affected by categorization training. Specifically, we
measured whether discrimination improved for a contrast
that was relevant for categorization and simultaneously
decreased for a contrast that was irrelevant. For pre-and
post-test trials, participants were required to identify
whether two stimuli were acoustically identical or different.
On different trials, stimuli were chosen using an adaptive
staircase procedure to estimate discrimination thresholds.
Same and different trials were randomly interleaved. Trials
for each staircase continued until the participant (1) reversed
accuracy on different trials four times; (2) successfully
discriminated the smallest possible distinction (i.e. a onestep difference); or (3) failed to discriminate the largest
possible distinction.
Discrimination thresholds of the two vowel contrasts were
tested independently; when testing discrimination of the
duration contrast, the pitch contrast was held constant, so
discrimination could only emerge on the basis of a single
contrast. For each contrast, discrimination was measured

2196

Results and discussion
We first analyzed performance during categorization trials.
Participants quite quickly reached the accuracy criterion,
with a mean trials-to-criterion of 47.2 (SD=19.0). Thirtynine of the 56 participants reached criterion by the 40th trial.
Participants for whom duration was relevant reached
criterion slightly more quickly than those for whom pitch
was relevant (M=42.2 and 52.1, respectively; t(54)=-1.99,
p=.052), suggesting that the pitch contrast may have been
slightly more difficult than the duration contrast.
The critical analysis of discrimination thresholds showed
a classic pattern of learned inattention (Figure 1);
discrimination of the relevant contrast became more
sensitive after training (as indicated by decreased
discrimination thresholds), and the irrelevant contrast
showed poorer discrimination after training. We analyzed
these data using mixed effects models (ANOVA yielded
similar results). The DV was step-size of the discrimination
threshold for the contrast as estimated from the staircase
procedure. We contrast-coded feature type (irrelevant: -.5;
relevant: +.5) and test-type (pre-test: -.5; post-test: +.5) for
use as fixed factors. Participant was included as a random
intercept, as was the slope of relevance for participants.
Including which feature was relevant as a random intercept

6
Pre
5.5

Step-size

from the lowest step and from the highest step; the
discrimination threshold for that contrast was the average
estimated threshold from each of these steps. There were
thus four separate estimated thresholds (two each for the
duration and the pitch contrast). The staircases for the four
threshold estimations were randomly interleaved.
Training consisted of teaching participants two categories
defined by one of the novel features. One of the two
contrasts was selected as relevant to category identity, and
the other was irrelevant. Assignment of which contrast was
relevant was counterbalanced across participants: 28
participants had vowel-one duration relevant and the other
28 had vowel-two pitch relevant. Participants were informed
that they were going to learn two words from a language
that uses different sounds than English. Each trial, they saw
two visually distinct cartoon alien creatures and heard a
stimulus; they clicked on the alien they believed the word
identified, and then received feedback.
The relevant dimension determined which alien was
correct; one alien was associated with the lowest step on this
dimension, and the other with the highest step. No other
steps of the relevant contrast were presented. The step for
the irrelevant dimension was randomly selected on each
trial, so this dimension was unpredictive of category
membership. Participants continued receiving trials until
they reached 80% accuracy across a 40-trial window. If they
failed to reach this criterion in 140 trials, they were removed
from the experiment and their data were excluded.
After categorization training, participants completed the
post-test. This test was conducted exactly as in the pre-test,
allowing comparison of pre-training thresholds with those
after one dimension was made relevant for categorization.

Post

5
4.5
4
3.5
3
Relevant

Irrelevant

Figure 1. Mean step size of reversals as a function of
relevance and test-type. Error bars represent the standard
error of the mean.
did not improve model fit by χ2 test (p=.31), so this was not
included in the analyses; including this random effect
produced extremely similar results.
Results confirmed the pattern seen in Figure 1.
Specifically, there was no main effect of feature type (B=.363, SE=.299, t(55)=-1.22, p=.23) nor of test type
(B=.0011, SE=.082, t(168)=.014, p=.99). However, there
was a significant interaction of feature type and test type
(B=-.56, SE=.16, t(168)=-3.43, p<.001). Simple effects
testing showed a significant decrease in discrimination
threshold for the relevant feature (B=-.28, SE=.11, t(839)=2.59, p=.0098), and a significant increase in discrimination
threshold for the irrelevant feature (B=.28, SE=.12,
t(839)=2.30, p=.022).
The results present evidence for selective attention in
learning auditory lexical categories defined by novel
features. After training, participants’ ability to recognize
small acoustic changes in a feature that had been relevant
for categorization improved, whereas their ability to
recognize changes in a second feature that was irrelevant
declined. This pattern of results mirrors patterns from visual
category learning (Best et al., 2013; Dopson, Esber, &
Pearce, 2010; Hoffman & Rehder, 2010; Kruschke & Blair,
2000; Mackintosh & Little, 1969).
Although these results are suggestive of isomorphism of
selective attention across domains, evidence of
generalization is necessary before concluding that
isomorphism exists. Findings in the visual domain
demonstrate attention to entire dimensions; when a
dimension is attended, processing benefits persist in later
tasks, even for new values of the dimension and new
contexts. Experiment 1 used identical stimuli during training
and test – we tested the same values of the same features in
the same contexts. To further investigate selective attention
in the auditory lexical domain, we considered two types of
generalization. Experiment 2 examined generalization of
selective attention to a novel voice (a change in irrelevant
context). Experiment 3 examined generalization to a novel
word (a change in relevant context).

2197

Experiment 2

6

Experiment 2 followed the design of Experiment 1, but
incorporated a change in irrelevant context. Specifically,
training was done in one voice, whereas testing was
conducted in a different voice. The same words and features
were used in the two segments, so learning could readily
generalize if learners deploy attention to abstract
dimensions. However, if selective attention operates in a
context-specific manner, generalization may be unattested.

5.5

Pre
Post

Step-size

5
4.5
4
3.5
3

Methods
Participants Data from 81 participants were included in the
analysis of Experiment 2. Thirty-seven received male-voice
stimuli during pre- and post-test, and female-voice stimuli
during training; the remaining 44 received the reverse. Six
additional participants were excluded from analysis for
exceeding time limitations to complete the task, or failure to
learn the categories within 140 trials.
Stimuli The female-voice stimuli were identical to those in
Experiment 1. For the male-voice stimuli, we acoustically
manipulated the female-voice stimuli to approximate a male
voice. We used the Change Gender option in Praat, which
scales the formant values in a stimulus. We found that a
ratio of 1/1.1 altered the percept of talker gender without
impacting clarity of the stimuli. We thus created a malevoice version of every stimulus from Experiment 1.
Although this method is less natural than recording two
different talkers, it allows close control of the manipulated
features. The Change Gender function does not impact
duration or overall pitch, so the stimuli in the two voices
maintained identical values of the features despite the
percept of different voices. The distribution of cues was thus
identical between the two stimulus sets; learners can thus
generalize even on the basis of specific feature values, but
must do so in a novel context.
Procedure The procedure was identical to Experiment 1,
except that the voice used in pre- and post-test was the
opposite gender as that used in training.

Results and discussion
Analysis of the training portion of the study again showed
very rapid learning (M=45.8; 64 of 81 participants reached
criterion by trial 40). No difference in speed of learning was
seen between the voices used in training.
The discrimination thresholds showed sensitivity to
category relevance, as the threshold decreased for the
relevant feature (Figure 2). However, no concomitant
increase in threshold was seen for the irrelevant feature; this
feature also showed a (very small) decrease. We analyzed
these data using a mixed effects model with similar
structure to the one used in Experiment 1. In addition to the
random effects used for that model, we added training voice
as a random intercept, and a random slope of relevance for
training voice. Including training voice instead as a fixed

Relevant

Irrelevant

Figure 2. Mean step size of reversals as a function of
relevance and test-type. Error bars represent the standard
error of the mean.
factor yielded extremely similar results, with no main
effects or interactions of training voice.
This analysis revealed a main effect for test type (B=-.35,
SE=.069, t(2460.3)=-5.05, p<.0001), with lower thresholds
at post-test than at pre-test. There was no effect of relevance
(B=-.50, SE=.28, t(6.0)=-1.82, p=.12). However, there was a
significant two-way interaction of test type and relevance
(B=-.45, SE=.14, t(2460.3)=-3.24, p=.0012). Simple effects
analyses used to investigate this interaction showed a
significant effect of test type for the relevant contrast (B=.57, SE=.094, t(1230.0)=-6.10, p<.0001); thresholds were
lower at post-test than they were at pre-test. However, the
model for the irrelevant feature showed no effect of test type
(B=-.13, SE=.10, t(1230.3)=-1.23, p=.22); performance for
the irrelevant feature was similar at pre-test and post-test.
These results differ from classic findings of learned
inattention. Although the relevant feature showed evidence
of improved processing, this was not accompanied by the
expected drop in performance for the unattended feature.
This finding is quite surprising; nearly all models of
attention argue for a limited quantity of attention, such that
attention to one dimension necessitates decreased attention
to others. Our results violated this coupling, suggesting that
attention in the auditory lexical domain may not engage the
same coupling across dimensions.
Experiment 2 thus provided only partial evidence of
isomorphism across domains. Learners generalized
highlighting of a relevant dimension across talker voices,
but did not simultaneously generalize learned inattention to
the irrelevant dimension. This pattern suggests that attention
in the auditory lexical domain may operate in a more
context-specific manner than in the visual domain.

Experiment 3
Experiment 3 examined generalization more thoroughly, by
investigating generalization across a relevant context.
Specifically, training and testing used the same features, but
embedded in different words. During training, vowel
duration and pitch contour were manipulated in one word
(e.g. dubo), whereas testing employed these same features in
a second word (e.g. bugo). This more directly measures

2198

whether learners are deploying attention to abstract
dimensions; for example, if they are learning about vowel
duration in general, patterns of attention should generalize
across lexical contexts. However, if attention is deployed in
a context-sensitive manner, then attention to one word
learned in training may not generalize to other words at test.

Methods
Participants Data from 60 participants were included in the
final analysis. Thirty participants were included in each
training-word condition (dubo train/bugo test or vice versa).
Data from five additional participants were not included in
the final sample for exceeding time limitations to complete
the task, or failure to learn the categories within 140 trials.
Stimuli The stimuli included the original stimuli from
Experiment 1 using dubo, as well as new stimuli constructed
using the same features and methods of generating these
features, based on the word bugo. The new base word was
recorded by the same talker in the same session. This
second word includes the same vowels in similar
phonological contexts (surrounded by voiced obstruents).
As such, although generalization must occur across words,
the contexts are quite similar, and the values of the features
were quite similar. If generalization is unattested across
these similar words and feature values, it is unlikely to arise
across the much broader diversity of words in the language.

General Discussion

Procedure The procedure was identical to Experiment 1,
except that different words were used in pre-/post-test and
training.

Results and discussion
Analysis of the training data again showed that participants
rapidly reached the accuracy criterion (M=48.4 trials; 42 of
60 participants reached criterion by the 40th trial).
Analysis of the critical pre- and post-test discrimination
thresholds showed marked improvement in discrimination
for both relevant and irrelevant contrasts (Figure 3).
Statistical analyses were conducted using mixed effects
6

Pre
Post

Step-size

5.5
5
4.5
4
3.5
3
Relevant

Irrelevant

Figure 3. Mean step size of reversals as a function of
relevance and test-type. Error bars represent the standard
error of the mean.

models with similar structures to those in the prior
experiments, but adding a random intercept of word used
during training and a random slope of training word for
which feature was relevant. Including word as a fixed factor
instead yielded similar results, with no significant effects or
interactions of word.
The model revealed a main effect of test type (B=-.53,
SE=.085, t(1798.0)=-6.24, p<.0001), as discrimination
thresholds declined from pre- to post-test. However, there
was no effect of relevance (B=-.17, SE=.47, t(1.2)=-.37,
p=.76), nor was the interaction significant (B=-.14, SE=.17,
t(1798.0)=-.85, p=.40). The relevance of the features during
training had no effect on discrimination performance,
suggesting that category learning did not result in
generalization of selective attention. Instead, performance
improved similarly for relevant and irrelevant features.
These results demonstrate no generalization of selective
across lexical contexts. Instead, sensitivity improves for
both relevant and irrelevant features (perhaps because of
learning about the task). Whereas visual category learning
tasks show generalization of selective attention across
contexts (e.g., Best et al., 2013; Kruschke, 2003), the
auditory lexical domain seems to display much stronger
context specificity.

We examined the degree to which auditory lexical category
learning exhibits isomorphic use of selective attention to
visual category learning. Although we found evidence that
selective attention aids learning of auditory lexical
categories, its deployment proved more context sensitive
than for visual categories. Learners in Experiment 1
highlighted relevant features and decreased attention to
irrelevant features; however, this pattern only weakly
generalized to a novel voice, and showed no apparent
generalization to a novel word. Visual category learning
shows ready generalization; in fact, visual category learning
studies often use training in one context, and then measure
continued selective attention in a new context (Best et al.,
2013; Kruschke, 2003). This suggests a clear demarcation
between the two domains.
Phonological information seems to generalize eventually;
when learning novel words, learners bring prior learning
about feature relevance to bear. If generalization were never
attested, learners would have to learn for each word that
features like voice are irrelevant. Yet our results show that
at least initially, learners treat novel features with high
context specificity. This specificity is similar to
developmental evidence that infants may treat words as
functionally independent, without generalizing features
(Apfelbaum & McMurray, 2011; Werker & Curtin, 2005).
However, these similar patterns of specificity among adults
are surprising. In the visual domain, even for novel features
learners exhibit patterns of learned inattention (Best et al.,
2013). Generalized selective attention across contexts seems
the default in vision. For auditory lexical categories, it
appears to be non-default. This finding may lend credence

2199

to theories of voice-specific priming, in which words are
obligatorily processed with indexical information as part of
the representation (Papesh, Goldinger, & Hout, 2016).
Similar results suggest that talker information and phoneme
information are asymmetrically related because of talker
normalization processes (Mullennix & Pisoni, 1990); talker
information may be difficult to ignore to focus on abstract
features because these features are often altered by talker
characteristics. However, these talker-specificity effects are
less straightforward as an explanation of the lack of
generalization across lexical contexts.
This context specificity may arise because of the closedset nature of features used to differentiate lexical items.
Languages use a relatively small set of phonemes to
differentiate an enormous set of words. Listeners receive
copious exposure to this small set, allowing learning of the
relevant features to become quite entrenched. Processing
features differently (as in the present study) may prove quite
difficult. Indeed, inflexibility of processing speech features
may be why learning the phonology of a second language is
markedly difficult for adults (Jusczyk, 1993).
Yet even if such an explanation holds for why learners
show poor generalization across contexts in these
experiments, it nonetheless represents a departure from
processing in the visual domain. Auditory lexical category
learning may rely on a core set of inflexible features,
whereas visual category learning is flexible in the face of
novel features. Selective attention in the auditory lexical
domain would thus operate within a constrained context for
novel features, and only generalize for known features,
instead of generalizing readily. As such, selective attention
across these domains shows a lack of isomorphism; the way
attention operates depends on the domain.

References
Apfelbaum, K. S., & McMurray, B. (2011). Using
variability to guide dimensional weighting:
Associative mechanisms in early word learning.
Cognitive
Science,
35(6),
1105–38.
doi:10.1111/j.1551-6709.2011.01181.x
Apfelbaum, K. S., & McMurray, B. (2015). Relative cue
encoding in the context of sophisticated models of
categorization:
Separating
information
from
categorization. Psychonomic Bulletin & Review,
22(4), 916–943. doi:10.3758/s13423-014-0783-2
Best, C. A., Yim, H., & Sloutsky, V. M. (2013). The cost of
selective
attention
in
category
learning:
developmental differences between adults and infants.
Journal of Experimental Child Psychology, 116(2),
105–19. doi:10.1016/j.jecp.2013.05.002
Deng, W., & Sloutsky, V. M. (2015). The Development of
Categorization: Effects of Classification and Inference
Training on Category Representation. Developmental
Psychology, 51(3), 392–405.
Dopson, J. C., Esber, G. R., & Pearce, J. M. (2010).
Differences in the associability of relevant and
irrelevant stimuli. Journal of Experimental

Psychology: Animal Behavior Processes, 36(2), 258–
267. doi:10.1037/a0016588
Francis, A. L., & Nusbaum, H. C. (2002). Selective
attention and the acquisition of new phonetic
categories. Journal of Experimental Psychology:
Human Perception and Performance, 28(2), 349–366.
Hoffman, A. B., & Rehder, B. (2010). The costs of
supervised classification: The effect of learning task
on conceptual flexibility. Journal of Experimental
Psychology:
General,
139(2),
319–340.
doi:10.1037/a0019042
Holt, L. L., & Lotto, A. J. (2010). Speech perception as
categorization.
Attention,
Perception,
&
Psychophysics, 72(5), 1218–1227. doi:10.3758/APP
Idemaru, K., & Holt, L. L. (2011). Word recognition reflects
dimension-based statistical learning. Journal of
Experimental Psychology: Human Perception and
Performance, 37(6), 1939–56. doi:10.1037/a0025641
Jusczyk, P. W. (1993). From general to language-specific
capacities: The WRAPSA model of how speech
perception develops. Journal of Phonetics, 21, 3–28.
Kruschke, J. K. (2003). Attention in learning. Current
Directions in Psychological Science, 12(5), 171–175.
doi:10.1111/1467-8721.01254
Kruschke, J. K., & Blair, N. J. (2000). Blocking and
backward blocking involve learned inattention.
Psychonomic Bulletin & Review, 7(4), 636–645.
doi:10.3758/BF03213001
Mackintosh, N. J., & Little, L. (1969). Intradimensional and
extradimensional shift learning by pigeons.
Psychonomic Science, 14(1), 5–6.
Nosofsky, R. M. (1986). Attention, similarity, and the
identification-categorization relationship. Journal of
Experimental Psychology: General, 115(1), 39–61.
Rehder, B., & Hoffman, A. B. (2005). Eyetracking and
selective attention in category learning. Cognitive
Psychology,
51,
1–41.
doi:10.1016/j.cogpsych.2004.11.001
Schyns, P. G., Goldstone, R. L., & Thibaut, J. P. (1998).
The development of features in object concepts. The
Behavioral and Brain Sciences, 21(1), 1–54.
Shepard, R. N., Hovland, C. I., & Jenkins, H. M. (1961).
Learning and memorization of classifications.
Psychological Monographs: General and Applied,
75(13), 1–42. doi:10.1037/h0093825
Sloutsky, V. M. (2010). From Perceptual Categories to
Concepts: What Develops? Cognitive Science, 34(7),
1244–1286. doi:10.1111/j.1551-6709.2010.01129.x
Toscano, J. C., & McMurray, B. (2010). Cue integration
with categories: Weighting acoustic cues in speech
using unsupervised learning and distributional
statistics. Cognitive Science, 34(3), 434–464.
doi:10.1111/j.1551-6709.2009.01077.x
Werker, J. F., & Curtin, S. (2005). PRIMIR: A
developmental framework of infant speech
processing. Language Learning and Development,
1(2), 197–234.

2200

