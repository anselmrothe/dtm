A test of two models of probability judgment: quantum versus noisy probability
Fintan J. Costello (fintan.costello@ucd.ie)
School of Computer Science,
University College Dublin, Dublin 4, Ireland
Paul Watts (watts@thphys.nuim.ie)
Department of Mathematical Physics,
National University of Ireland Maynooth, Maynooth, Ireland
Abstract

predictions about the occurence and direction of these biases.
In this paper we test these contrasting predictions.

We test contrasting predictions of two recent models of probability judgment: the quantum probability model (Busemeyer
et al., 2011) and the probability theory plus noise model
(Costello and Watts, 2014). Both models assume that people estimate probability using formal processes that follow or
subsume standard probability theory. The quantum probability model predicts people’s estimates should agree with one
set of probability theory identities, while the probability theory plus noise model predicts a specific pattern of violation of
those identities. Experimental results show just the form of violation predicted by the probability theory plus noise model.
These results suggest that people’s probability judgments do
not follow quantum probability: instead, they follow the rules
of standard probability theory, with the systematic biases seen
in those judgments due to the effects of random noise.

The probability theory plus noise model
In standard probability theory the probability of some event
A is estimated by drawing a random sample of events, counting the number of those events that are instances of A, and
dividing by the sample size. The expected value of these estimates is P(A), the probability of A; individual estimates will
vary with an approximately normal distribution around this
expected value. The probability theory plus noise model assumes that people estimate the probability of some event A in
exactly the same way: by randomly sampling items from their
memory, counting the number that are instances of A, and dividing by the sample size. If this counting process was errorfree then people’s estimates would have an expected value of
P(A) just as in probability theory. Human memory is subject to various forms of random error, however. To reflect
this the model assumes a minimal form of random error such
that items have some probability d < 0.5 of being counted incorrectly (we assume that this error term is constant within a
given participant, but varies across participants: some participants are more prone to random error than others).
Because of this random error, there is a chance d that an
item which is not truly an instance of A will be incorrectly
counted as A, and the same chance d that an instance of A
will be incorrectly counted as not A. Given this error, a randomly sampled item can be counted as A in two mutually
exclusive ways: either the item truly is an instance of A and is
counted correctly (this occurs with probability P(A)(1 − d),
since P(A) items are truly instances of A, and items have a
(1 − d) chance of being read correctly), or else the item truly
is not an instance of A and is counted incorrectly as A (this
occurs with probability (1 − P(A))d, since (1 − P(A)) items
are truly not instances of A, and items have a d chance of being read incorrectly). The expected value for a noisy estimate
for the probability of A is thus

Introduction
Researchers over the last 50 years have identified a large
number of systematic biases in people’s judgments of probability. These biases are typically taken as evidence that
people do not follow the normative rules of probability theory when estimating probabilities, but instead use a series of
heuristics (mental shortcuts or ‘rules of thumb’) that sometimes yield reasonable judgments but sometimes lead to severe and systematic errors, causing the observed biases (Kahneman and Tversky, 1973). This ‘heuristics and biases’
view has had a major impact in psychology (Kahneman and
Tversky, 1982, Gigerenzer and Gaissmaier, 2011), economics
(Camerer et al., 2003), law (Sunstein, 2000), medicine (Eva
and Norman, 2005) and other fields, and has influenced
government policy in a number of countries (Oliver, 2013,
Vallgårda, 2012).
The existence of these systematic biases in people’s probabilistic reasoning is incontrovertible. The conclusion that
these biases necessarily demonstrate heuristic reasoning processes is, however, less sure. Recent research has shown that
many of these biases can be explained if we assume that people estimate probability using formal processes that follow
or subsume standard probability theory. Two such formal
models are the quantum probability model proposed by Busemeyer and colleagues (Busemeyer et al., 2011, Busemeyer
and Bruza, 2012), and our own probability theory plus noise
model (Costello and Watts, 2014, 2016a,b). Both models can
account for a number of well-known biases seen in people’s
probabilistic reasoning. Both models predict systematic bias
away from standard probability theory for a range of probalistic expressions: importantly, the models make contrasting

hPE (A)i = P(A)(1 − d) + (1 − P(A))d = (1 − 2d)P(A) + d
(1)
and we expect individual estimates PE (A) to vary independently around this expected value.
According to the model, the pattern of bias due to random
noise seen in Equation 1 is predicted for all types of events,
but will be more pronounced for complex events (such as

408

of quantum theory, measuring an observable A, which returns
one of two distinct outcomes: A (the event has occurred) and
¬A (the event has not occurred).1 Two observables A and B
are compatible, in quantum theory, if the outcome of a joint
observation (such as P(A ∧ B)) does not depend on the order
in which A and B were measured. Two observables are incompatible if the outcome of such a joint observation does
depend on the ordering of measurement of A and B. In other
words, if two observables are compatible then the equality
P(A ∧ B) = P(B ∧ A) must hold, while if the observables are
incompatible, equality need not hold. This distinction is fundamental both in standard quantum theory and in the quantum
probability model (see Busemeyer et al., 2011, p. 199). We
use this difference between P(A ∧ B) and P(B ∧ A) as a measure of compatibility in our experiment, with the idea that
the greater the difference between P(A ∧ B) and P(B ∧ A), the
more confident we are that the observables in question are
incompatible.
If two observables are compatible, then quantum probability expressions for all possible outcomes of those observables
(that is, for P(A), P(¬A), P(B), P(¬B), P(A ∧ B), P(A ∧ ¬B),
P(A ∨ B), and so on) are exactly equivalent to the standard
probability theory expressions for those outcomes. In other
words, if two observables are compatible then all the probability theory identities given in Table 1 should have the value
of 0, as required in standard probability theory.
If two observables are incompatible, in quantum theory
those observables cannot both be measured simultaneously:
instead they must be measured separately, one after the other.
If two incompatible observables are measured in the order A
then B, then quantum probability expressions for outcomes
of the second observable can deviate from the requirements
of probability theory, giving, for example

conjunctions or disjunctions), which, because of their complexity, give more opportunity for error compared to simple events. For simplicity and clarity we ignore this effect
here and assume the same rate of error for all events, so the
expected value for conjunctive events A ∧ B and disjunctive
event A ∨ B are
hPE (A ∧ B)i = (1 − 2d)P(A ∧ B) + d

(2)

hPE (A ∨ B)i = (1 − 2d)P(A ∨ B) + d

(3)

We’ve previously shown how this model explains various
biases frequently seen in people’s probabilistic reasoning,
such as underconfidence (people’s tendency to overestimate
the probability of low-probability events and understimate
the probability of high probability events), subadditivity (people’s tendency to give probabilities for the constituent events
of a disjunction which, when added, are reliably higher than
their probability for the disjunction as a whole) and the conjunction fallacy. The patterns of occurrence of these biases
in experimental results match the model’s predictions well
(Costello and Watts, 2014, 2016a,b).
This model also predicts a range of other deviations from
probability theory for people’s probability estimates. Table
1 gives a series of probability theory identities: expressions
which, in probability theory, are required to have a value of
0 for all events A and B. We can use our expected-value expression to obtain values for these identities as predicted by
our model. For identity 5, for example, our model predicts an
average value of
hPE (A)i + hPE (¬A ∧ B)i − hPE (A ∨ B)i
= (1 − 2d)P(A) + d + (1 − 2d)P(¬A ∧ B) + d
− (1 − 2d)P(A ∨ B) − d

P(B) = P(¬A ∧ B) + P(A ∧ B) + δB

=d

(4)

where P(B) is the probability obtained when B is measured
with no prior measurement of A, P(¬A ∧ B) and P(A ∧ B)
are the probabilities obtained when A and B are measured sequentially, and where δB is a ‘quantum interference’ term for
observable B. This quantum interference term arises because,
contrary to the ‘macroscopic realism’ view of the world and
thus to the assumptions of standard probability theory, in
quantum theory if A is not measured, it is not necessarily in
either state A or state ¬A: it may be in some ‘superposition’
of states. This means that the two probabilities P(¬A ∧ B)
and P(A ∧ B) do not necessarily cover all possible cases arising when estimating P(B) with no prior measurement of A,
and so P(B) = P(¬A ∧ B) + P(A ∧ B) does not necessarily
hold. Note that quantum interference is not an error term
here: for a given observable B (and a given participant, in

(with values varying randomly around that average). Since d
(the rate of random error) is always positive in this model, the
model predicts a positive value for this identity for all events
A and B: in other words, it predicts that, if we substitute people’s probability estimates for A, ¬A ∧ B, A ∨ B and so on, into
this identity, the values obtained will, on average, be positive
for all events. Similar predictions hold for the other identities
in table 1. As we see below, the quantum probability model
makes a different prediction.

The quantum probability model
The quantum probability model assumes that people’s probabilistic reasoning follows the mathematical principles of
quantum probability. The primary theoretical distinction between quantum and standard probability lies in the idea of
‘compatible’ or ‘incompatible’ observables. An observable
defines the set of all possible distinct outcomes for a given
measurement. For example, if we are checking to see whether
some event A has occurred or not, we are, in the terminology

1 In quantum theory, each of these outcomes A and ¬A would be
referred to as an eigenvalue of the observable, because the observable defines the set of orthonormal vectors of unit length (eigenvectors) in a multidimensional state space. We don’t need to use this
detailed view of quantum theory in our discussion here, and so we
avoid this more complex terminology.

409

Table 1: Predicted values of the noise model and the quantum model for a series of probability theory identities. Standard
probability theory requires these identities to have a value of 0. The probability theory plus noise model predicts that the
average value of each these identities will be positive for all events, deviating from 0 by more than d (the chance of random
error). The quantum probability model makes different predictions for three mutually-exclusive situations: when observables A
and B are compatible; when observables are incompatible and measured in the order A then B, or when they are incompatible
and measured in the order B then A.

label

identity

noise model

quantum model
compatible

incompatible incompatible
A then B

B then A

1

P(A) + P(¬A ∧ B) − P(A ∨ B)

d

0

0

δA

2

P(B) + P(A ∧ ¬B) − P(A ∨ B)

d

0

δB

0

3

P(A ∧ B) + P(A ∧ ¬B) − P(A)

d

0

0

−δA

4

P(A ∧ B) + P(¬A ∧ B) − P(B)

d

0

−δB

0

5

P(A ∧ B) + P(¬A ∧ B) + P(A ∧ ¬B) − P(A ∨ B)

2d

0

0

0

Busemeyer et al.’s model) this quantum interference term δB
has a fixed value that specifies the relationship between P(B)
and P(¬A ∧ B) + P(A ∧ B) for that observable. The quantum
interference term δB can take on different values for different observables B (and different participants): in some cases
positive, in some negative, and in some cases 0.
If two incompatible observables are measured in the order A then B then P(A) has no such interference term, and
so remain exactly equivalent to the corresponding standard
probability theory expression, giving, for example

will increase and a decrease in teenage smoking will occur,” it is natural to assume that the causal event “increase in cigarette tax” is processed first.
This approximately matches the approach taken in standard
quantum theory, where the observable that occurs first is, naturally enough, the first measured observable. In this case
the quantum probability model would allow deviations from
probability for the second observable (the caused event ‘a decrease in teenage smoking’) but not for the first observable
(the causing event ‘an increase in cigarette tax’). If A and
B have no causal link, Busemeyer et al. (2011) take a different approach and assume that the most probable of the two
events is measured first: that is, if P(A) > P(B) then the conjunctive probability P(A ∧ B) is measured, but if P(B) > P(A)
then the conjunctive probability P(B ∧ A) is measured. This
represents a significant deviation from quantum theory because it connects ordering not to observables but to outcomes
of observations. This also introduces other problems to the
model. One problem concerns the ordering of the ‘decision’
measurements of P(A) and P(B). To decide whether the conjunction is measured as P(A ∧ B) or P(B ∧ A), we must first
measure P(A) and P(B) to see which is more probable. If
A and B are incompatible, we will get different results if we
measure P(A) first and then P(B), or P(B) first and then P(A).
We cannot decide which ordering to use by assuming the most
probable event is measured first: before measurement, we
don’t know which event is most probable. It is not clear how
this issue is resolved in the quantum probability model; given
this, we don’t address this ‘ordering by probability’ approach
here.

P(A) = P(A ∧ ¬B) + P(A ∧ B)
This is because measurement of A causes the observable to
collapse out of superposition and take on either state A or
state ¬A: the two probabilities P(A ∧ ¬B) and P(A ∧ B) arising from subsequent measurement of B do cover all possible
cases arising after the outcome A, and so their sum equals
P(A). If incompatible observables are measured in the opposite order B then A, there is a parallel interference δA for observable A, and no interference term for observable B. Note
that deviations from probability theory in the quantum model
arise from single event probabilities (P(A) or P(B)) because
only these single-event probabilities have associated quantum
interference terms: there are no such interference terms associated with combined probabilities such as P(A ∧ B).
How does the quantum probability model impose an ordering on incompatible events? The model assumes that incompatible observables A and B are ordered in terms of causal
links between those observables. If observables A and B are
causally linked such that the occurrence of event A in some
way influences the subsequent occurrence or non-occurrence
of B, Busemeyer et al. (2011) assume that observable A is
measured first and B is measured second. To quote Busemeyer et al. (2011, page 199)

Predictions: probability theory identities
All of the identities in Table 1 have a value of 0 in standard probability theory. In the quantum model, probability
judgments necessarily agree with standard probability theory
when the observables A and B are compatible; and so in this

when asked to judge the likelihood that “cigarette tax

410

B , this two identity will always a value of 0 irrespective of
whether A and B are compatible or incompatible.
We can summarise the quantum model’s predictions for the
identities in Table 1 as follows. For a given pair of events A
and B, there are three possible situations: First, A and B are
compatible, in which case the quantum model predicts a value
of 0 for all identities. Second, A and B are incompatible and
measured in the order A then B, in which case the quantum
model predicts a value of 0 for all identities but 2 and 4: these
two identities are predicted to have opposite signs (one positive, one negative). Third, A and B are incompatible and
measured in the order B then A, in which case the quantum
model predicts a value of 0 for all identities but 1 and 3: these
two identities are predicted to have opposite signs (one positive, one negative). The probability theory plus noise model,
by contrast, predicts that every one of these identities will deviate from 0, and all will have positive values.

model, all of these identities should have a value of 0 for compatible observables and will only deviate from 0 for incompatible observables.
If observables are incompatible, then the values of these
identities depend on the ordering of observables A and B and
on whether the identity contains P(A) or P(B). If an identity contains a probability expression for the first measured
observable, there is no interference term and the identity has
a value of 0, as in standard probability theory. If an identity
contains the second observable, however, there is an interference term for that observable, and the identity’s value will
be related to the value of that term. Consider, for example,
identity 2 in Table 1. This identity contains P(B). If observables are incompatible and B is measured first, then there is
no interference term for B and identity 2 has a value of 0. If
observables are incompatible and A is measured first, however, there is an interference term for B and identity 2 has the
value

Experiment: incompatibility and probability
theory identities

P(B) + P(A ∧ ¬B) − P(A ∨ B)
= [P(¬A ∧ B) + P(A ∧ B) + δB ] + P(A ∧ ¬B) − P(A ∨ B)

In this experiment we assess the role of incompatibility in the
values of the probability theory identities in Table 1. Recall
that the probability theory plus noise model predicts that values for these identities should be reliably positive for all pairs
of events A and B. The quantum probability model, by contrast, predicts that for any pair of events, either all identities
are 0, all are 0 but identities 2 and 4 (and these have opposite signs), or all are 0 but identities 1 and 3 (and these have
opposite signs).
We tested these predictions using data from an experiment on conjunction and disjunction fallacies (Experiment 2
in Costello and Watts, 2014). This experiment gathered 68
participants’ estimates for P(A), P(B), P(A ∧ B), P(A ∨ B),
P(A ∧ ¬B) and P(¬A ∧ B) for 9 different pairs A, B of weather
events (see Table 2). These pairs were selected so that they
contained events of high, medium and low probabilities. Conjunctive and disjunctive weather events were formed by placing ‘and’/‘or’ between the elements of each pair as required,
generating weather events such as ‘windy and cold’, ‘windy
or cold’, and so on. One group of participants (N = 34) were
asked questions in terms of probability, of the form

= δB + P(¬A ∧ B) + P(A ∧ B) + P(A ∧ ¬B) − P(A ∨ B)
= δB
(from Equation 4): this identity is predicted to have a value
equal to the interference term δB .
Next consider identity 4 in Table 1. This identity again
contains P(B). If observables are incompatible and B is measured first, then there is no interference term for B and identity 4 has a value of 0. If observables are incompatible and A
is measured first, however, there is an interference term for B
and identity 4 has the value
P(A ∧ B) + P(¬A ∧ B) − P(B)
= P(A ∧ B) + P(¬A ∧ B) − [P(A ∧ B) + P(¬A ∧ B) + δB ]
= −δB
(from Equation 4): this identity is predicted to have a value
equal to the negative of the interference term, or in other
words, equal to that of identity 2 but with the opposite sign.
Parallel predictions hold for identities 1 and 3. These identities are expected to have values of 0 if A is measured first,
while if B is measured first these identities have values equal
to the interference term δA but with opposite signs. Note that,
since identities 2 and 4 can only have values δB and −δB when
A is measured first, while identities 1 and 3 can only have
values δA and −δA when B is measured first, these two cases
are mutually exclusive. This means that, if identities 2 and 4
have values significantly different from 0 for a given pair of
events A and B, then the quantum probability model requires
that identities 1 and 3 have a value equal to 0 (no interference
term) for those events, and vice versa.
Finally, consider identity 5. This identity does not contain an expression P(A) or P(B), and so does not contain a
quantum interference term. The quantum probability model
thus predicts that, for any fixed ordering of observables A and

• What is the probability that the weather will be W on a
randomly-selected day in Ireland?
for some weather event W . The second group (N = 34) were
asked questions in terms of frequency, of the form
• Imagine a set of 100 different days, selected at random. On
how many of those 100 days do you think the weather in
Ireland would be W ?
where the weather events were as before. These two question forms were used because of a range of previous work
showing that frequency questions can reduce fallacies in people’s probability judgments; the aim was to check whether

411

Table 2: This table shows the degree of incompatibility of constituent events A and B in the Experiment, measured as the
absolute difference between estimates for a conjunction in the ordering A ∧ B and estimates in the ordering B ∧ A. Events are
are listed in order of increasing incompatibility. This table also shows the average values for identities from Table 1, computed
from individual participant’s estimates for each event pair. The quantum model predicts that these identities should have a value
of 0 when events A and B are compatible; when events are incompatible the quantum model predicts that most identities will
have a value of zero, but some pairs of identities will have opposite signs (one positive, one negative) . The probability theory
plus noise model predicts that all of these will have positive values, in all pairs of events.

A

windy
icy
rainy
sunny
cold
sunny
cold
cloudy
cloudy

B

cold
windy
windy
icy
sunny
rainy
cloudy
rainy
icy

|PE (A ∧ B) − PE (B ∧ A)|

0.005
0.007
0.03
0.03
0.06
0.09
0.09
0.09
0.11∗

Identity
1

2

3

4

5

0.56 (0.31)
0.17 (0.28)
0.34 (0.32)
0.11 (0.27)
0.24 (0.28)
0.17 (0.28)
0.34 (0.27)
0.13 (0.26)
0.22 (0.3)

0.25 (0.24)
0.21 (0.24)
0.27 (0.31)
0.16 (0.27)
0.14 (0.3)
0.13 (0.25)
0.29 (0.27)
0.35 (0.29)
0.21 (0.29)

0.26 (0.27)
0.2 (0.21)
0.33 (0.27)
0.27 (0.29)
0.21 (0.32)
0.23 (0.24)
0.23 (0.3)
0.43 (0.28)
0.22 (0.27)

0.29 (0.29)
0.16 (0.27)
0.39 (0.35)
0.22 (0.27)
0.31 (0.29)
0.27 (0.3)
0.28 (0.28)
0.2 (0.26)
0.24 (0.27)

0.55 (0.4)
0.38 (0.38)
0.67 (0.47)
0.39 (0.4)
0.47 (0.44)
0.4 (0.38)
0.58 (0.41)
0.57 (0.35)
0.46 (0.46)

∗ Marginally

significant difference between orderings in an unpaired t-test (p = 0.06). All other differences in ordering were
unsignificant; all other differences gave evidence in favour of the null hypothesis (no difference between orderings) in a JZS
Bayes Factor test for two-sample designs. All values for the identities were positive and significantly different from 0 in a
one-sample t-test (p < .0001).

this question form could eliminate fallacy responses for everyday repeated events.
Half of participants in each group saw all conjunctions and
disjunctions in the ordering A ∧ B, A ∨ B, A ∧ ¬B and ¬A ∧ B,
the other half saw them in the reverse ordering B ∧ A B ∨ A,
B∧¬A and ¬B∧A. This randomisation of the order of presentation of events in conjunctions and disjunctions was carried
out purely to get a unbiased sample of probability estimates
for these conjunctions and disjunctions, unaffected by any
systematic influence of word order. Here, however, we use
this ordering to estimate the degree of incompatibility of the
twelve pairs of events used in the experiment, by considering
the degree of difference between estimates given for P(A ∧ B)
and estimates for P(B ∧ A) for each pair of events. The larger
the difference between these standard and reverse-order estimates, the more incompatible the given pair of events.
Participants were given questions containing all single
events and all conjunctive and disjunctive events, with questions presented in random order on a web browser. Responses
were on an integer scale from 0 to 100 and were divided
by 100 prior to analysis, and so probability estimates where
given in units of 0.01.

questions and the other because they gave responses of 0 to all
but 2 questions), leaving 66 participants in total. There was
little difference in responses between the ‘frequency format’
and ‘probability format’ forms of question, so for simplicity
we collapse the groups together in our analysis.
Each participant gave probability estimates for 42 distinct items ( 4 estimates P(A ∧ B), P(A ∨ B), P(A ∧ ¬B) and
P(¬A ∧ B) for each of the 9 A, B pairs, and 6 estimates for the
various constituents P(A) and P(B)). As a consistency check
we split the participants in into two random groups and calculated the average probability estimate in each group for each
one of the 42 presented items. If participants were responding
consistently we would expect there to be a reliable correlation
between these average estimates across the two groups. The
correlation was very high (r = 0.97, p < 0.0001), indicating consistent responses and showing that participants were
not simply responding randomly in the probability estimation
task.
For each participant we calculated the values of various
identities from Table 1 for each of the nine pairs A, B. We also
measured the degree of incompatibility between these event
pairs in terms of the absolute difference between the average
estimate for a conjunction presented in the order A ∧ B and a
conjunction in the order B ∧ A: the higher this difference, the
more incompatible the events are.
Table 2 shows the average values obtained for the relevant

Results
Two participants from the ‘probability format’ group were excluded (one because they gave responses of 100 to all but 4

412

identities for each of the 9 event pairs in the experiment, and
also shows the degree of measured incompatibility of those
event pairs, in increasing order. The degree of incompatibility was low for almost all pairs. There was no statistically
significant difference between conjunctive estimates for the
ordering A ∧ B and ordering B ∧ A for any pair: only one pair
approached significance. A JZS Bayes Factor test for twosample designs gave evidence in favour of the null hypothesis (no difference between orderings) for all but one pair.
There was no relationship between incompatibility and values
of the probability theory identities: identity values were reliably positive even when the difference between P(A ∧ B) and
ordering P(B ∧ A) was less than 0.01 (that is, less than 1 point
on the 100 point rating scale used in the experiment). This
is contrary to the predictions of the quantum model, which
would predict values of 0 for compatible pairs.
Values for all identities were reliably positive, as predicted
by the probability theory plus noise model. For each identitity and each event pair, we carried out a single sample t-test
comparing individual values for that identity against 0. Since
there are 9 event pairs, and 6 identities, this gives 45 separate t-tests. All these t-tests were significant at at least the
p < 0.001 level, supporting the probability theory plus noise
model and going against the quantum model, which would
expect either all or most of these values to be 0, and would
expect some to be negative.
Finally, recall that the probability theory plus noise model
predicts an average value of d for identities 1 to 4, and a value
of 2d for identity 5. The results in Table 2 support this prediction: the average value for identity 5 was 2.02 times the
average value for identities 1 to 4.

expressions in which this model predicts bias should be cancelled, people’s probability estimates agree closely with the
requirements of probability theory just as predicted by the
model (Costello and Watts, 2014). Here we’ve shown further experimental evidence that supports this model and goes
against a competing formal model based on quantum probability. Taken together, our results give evidence against the
popular idea that people estimate probabilities using heuristics that do not follow the normative requirements of probability theory (Ariely, 2009, Gigerenzer and Gaissmaier, 2011,
Kahneman, 2011, Shafir and Leboeuf, 2002).

References
Ariely, D. (2009). Predictably irrational: the hidden forces
that shape our decisions. HarperCollins.
Busemeyer, J. R. and Bruza, P. D. (2012). Quantum models
of cognition and decision. Cambridge University Press.
Busemeyer, J. R., Pothos, E. M., Franco, R., and Trueblood,
J. S. (2011). A quantum theoretical explanation for probability judgment errors. Psychological Review, 118(2):193.
Camerer, C., Loewenstein, G., and Rabin, M. (2003). Advances in Behavioral Economics. Princeton University
Press.
Costello, F. and Watts, P. (2014). Surprisingly rational: Probability theory plus noise explains biases in judgment. Psychological Review, 121(3):463–480.
Costello, F. and Watts, P. (2016a). Explaining high conjunction fallacy rates: the probability theory plus noise account.
Journal of Behavioral Decision Making. In press, available
at http://dx.doi.org/10.1002/bdm.1936.
Costello, F. and Watts, P. (2016b). Probability theory plus
noise: replies to Crupi and Tentori (2015) and to Nilsson, Juslin and Winman (2015). Psychological Review,
123(1):112–123.
Eva, K. W. and Norman, G. R. (2005). Heuristics and biases:
biased perspective on clinical reasoning. Medical Education, 39(9):870–872.
Gigerenzer, G. and Gaissmaier, W. (2011). Heuristic decision
making. Annual Review of Psychology, 62:451–482.
Kahneman, D. (2011). Thinking, fast and slow. Macmillan.
Kahneman, D. and Tversky, A. (1973). On the psychology of
prediction. Psychological Review, 80(4):237.
Kahneman, D. and Tversky, A. (1982). Judgment under uncertainty: Heuristics and biases. Cambridge University
Press.
Oliver, A. (2013). From nudging to budging: using behavioural economics to inform public sector policy. Journal of Social Policy, 42(04):685–700.
Shafir, E. and Leboeuf, R. A. (2002). Rationality. Annual
Review of Psychology, 53(1):491–517.
Sunstein, C. (2000). Behavioral Law and Economics. Cambridge University Press.
Vallgårda, S. (2012). Nudge: A new and better way to improve health? Health Policy, 104(2):200–203.

Conclusions
The results seen in this experiment appear to clearly contradict the quantum probability model’s predictions about compatibility and values of probability theory identities. That
model predicts that probability theory identities should have
a value of 0 when events are compatible. That prediction did
not hold. Even assuming the events are incompatible, the
quantum model predicts a value of 0 for all identities but 2
and 4 (and these two identities are predicted to have opposite
signs) or for all identities but 1 and 3 (and these two identities are predicted to have opposite signs). These predictions
also did not hold: instead, values for all identities were reliably positive, for all events. The results support the probability theory plus noise account, which predicts reliably positive
values for all the probability theory identities in Table 1.
The fundamental idea in the probability theory plus noise
account is that people’s process for estimating probabilities
follows the requirements of probability theory, and that the
systematic biases away from probability theory seen in people’s judgments are simply the consequence of random error in that process. In other work we’ve shown that this
model can explain biases such as conservatism, subadditivity, and binary complementarity. We’ve also shown that, for

413

