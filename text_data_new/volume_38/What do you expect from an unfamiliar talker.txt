What do you expect from an unfamiliar talker?
Dave F. Kleinschmidt1 , and T. Florian Jaeger1,2,3
1 Department

{dkleinschmidt, fjeager} @ mail.bcs.rochester.edu
of Brain and Cognitive Sciences, 2 Department of Computer Science, and 3 Department of Linguistics,
University of Rochester, Rochester, NY, 14627 USA
Abstract

Speech perception is made much harder by variability between
talkers. As a result, listeners need to adapt to each different
talker’s particular acoustic cue distributions. Thinking of this
adaptation as a form of statistical inference, we explore the role
that listeners’ prior expectations play in adapting to an unfamiliar talker. Specifically, we test the hypothesis that listeners
will have a harder time adapting to talkers whose cue distributions fall outside the range of normal variation across talkers.
We also show that it is possible to infer listeners’ shared prior
expectations based on patterns of adaptation to different cue
distributions. This provides a potentially powerful tool for directly probing listeners’ prior expectations about talkers that
does not rely on speech produced by many different talkers,
which is costly to collect and annotate, and only indirectly related to listeners’ subjective expectations.
Keywords: Cognitive Science, Linguistics, Psychology, Language understanding, Learning, Speech recognition, Bayesian
modeling, Experimental research with adult humans

Introduction
A longstanding problem in speech perception is how listeners manage to cope with substantial differences in how individual talkers produce speech. Recent evidence suggests that
one strategy listeners employ is to rapidly adapt to unfamiliar talkers (Bertelson, Vroomen, & de Gelder, 2003; Clarke &
Garrett, 2004; Kraljic & Samuel, 2007, among others). Such
adaptation can be understood as a form of statistical inference. This insight is captured by a recent proposal, the ideal
adapter framework (Kleinschmidt & Jaeger, 2015). Each
talker’s particular accent (way of talking) can be formalized
as the distribution of acoustic cues that they produce for each
phonetic category (or other underlying linguistic unit). Listeners are taken to adapt to an unfamiliar talker via distributional learning, inferring the underlying talker-specific cue
distributions from the talker’s productions.
Critically, this statistical inference process draws on implicit beliefs about how talkers tend to differ from each other.
As a consequence, adaptation to an unfamiliar talker should
depend on a listener’s prior experience with other talkers,
rather than only on the speech produced by the unfamiliar
talker themselves. Specifically, a listener’s experience with
other talkers provides the starting point for the distributional
learning required for adaptation, or, in Bayesian terms, a
prior belief about the probability of different possible accents
(cue distributions). More informative prior beliefs can substantially reduce the amount of direct evidence needed to converge on accurate beliefs about the current talker’s cue distributions.
Code and data to generate this paper is available from
github.com/kleinschmidt/cogsci 2016

The goals of the present work are two-fold. First, we
test a critical prediction of the ideal adapter framework. To
the extent that a listener’s prior beliefs are informative, they
must take some probability away from unlikely accents. Confronted by a talker whose accent falls well outside the range
of what they expect based on their previous experience, the
ideal adapter framework predicts that a listener will require
more evidence to adapt, leading to slowed or incomplete
adaptation. There is some evidence that this is the case. For
instance, Idemaru and Holt (2011) found that listeners have
difficulty adapting to a talker who produces anti-correlated
distributions of two cues that are typically positively or uncorrelated. Sumner (2011) found that listeners had trouble
adapting to a talker who produced a distribution of cues for
the /b/ and /p/ sounds that had substantially lower means than
a typical talker.
However, no studies have systematically probed whether
and how a listener’s prior expectations constrain phonetic
adaptation, or even what kind of prior beliefs listeners have.
To that end, we expose listeners to a range of different accents, which differ (only) in the cue distributions for /b/ and
/p/. By parametrically manipulating these distributions, we
create a range of accents that are more or less similar to what a
typical talker of English produces. We then assess the degree
to which listeners adapt their beliefs about the novel talker’s
cue distributions, depending on the a priori typicality of these
distributions.
To anticipate the results, we find that typicality of the novel
talker’s cue distribution predicts the degree to which listeners adapt to the talker. This suggests that listeners not only
have beliefs about the cue distributions for a particular single talker (as suggested by previous work; Clayards, Tanenhaus, Aslin, & Jacobs, 2008; Feldman, Griffiths, & Morgan,
2009; Kleinschmidt & Jaeger, 2015; Kronrod, Coppess, &
Feldman, 2012), but also have implicit beliefs about the ways
in which talkers tend to differ from each other, and hence
what to expect from an unfamiliar talker. This leads to the
second question we address here: what is the content of listeners’ prior beliefs about inter-talker variability? To this end,
we use a Bayesian belief-updating model to work backwards
from listeners’ adaptation behavior across talkers and infer
listeners’ shared prior beliefs. This approach provides a more
direct assessment of listeners’ subjective prior beliefs than
production data from many different talkers, which moreover
requires costly and time-consuming annotation. If successful,
this would provide a powerful method for investigating listeners’ prior beliefs that could be applied to other cues, categories, and even social variables (like gender, native language

2351

/b/ mean VOT
-10
0
10
20
30

Mean shift
29%
—
80%
53%
49%

95% CI
13–44%
—
57–104%
45–62%
40–57%

Table 1: Percentage of boundary shift from typical talker to
each exposure talker (see Figure 3), averaged over subjects
with 95% bootstrapped confidence intervals. 0% shift corresponds to no adaptation at all, while 100% corresponds to
perfect adaptation, ignoring any prior beliefs. Typical and exposure talker boundaries were too close together to reliably
determine boundary shift percentage in the 0ms condition.

Figure 2: Example trial display (beach/peach). Listeners first
click on the green button to play the word, then click on one
picture to indicate what they heard.

background, etc.).
/b/-/p/ classification function (fitted by a logistic GLM) to the
classification function derived from the typical talker’s cue
distributions (corresponding to no adaptation) and the exposure distribution (corresponding to maximal—but not necessarily optimal—adaptation).

Experiment
We tested the role that listeners prior expectations play in
adapting to an unfamiliar talker by exposing them to one of
five synthetic “accents” (Figure 1). These accents differed
only in the distribution of voice onset time (VOT), the primary cue to word-initial stop consonant voicing in English
(e.g., “beach” vs. “peach”). Adaptation was assessed based
on listeners’ classification function, or how they labeled each
VOT as /b/ or /p/.

Results and Discussion

Methods
Subjects We recruited 169 subjects via Amazon’s Mechanical Turk, who were paid $2.00 for participation, which took
about 20 minutes. We excluded subjects who participated
more than once (n = 4) or whose accuracy at 0 ms and 70 ms
VOT—as extrapolated via a logistic GLM—was less than
80% correct (n = 28; n = 1 for both reasons). Excluded
subjects were roughly equally distributed across conditions
(maximum of 5 in 0ms /b/ VOT condition, and minimum of
1 in 20ms /b/ VOT condition). After these exclusions, data
from 138 subjects remained for analysis for analysis.
Procedure Our distributional learning procedure is described in Kleinschmidt, Raizada, and Jaeger (2015), and is
based on Clayards et al. (2008). On each trial, two response
option images appeared, which corresponded to one of three
/b/-/p/ minimal pairs (beach/peach, bees/peas, or beak/peak).
Subjects then clicked on a central button which played the
corresponding minimal pair word, and then clicked on the
picture to indicate whether they heard the /b/ or /p/ member
of the minimal pair (Figure 2). Subjects performed 222 of
these trials.
Each trial’s word was synthesized with a voice onset time
(VOT) that was randomly drawn from a bimodal distribution,
with low and high VOT clusters implicitly corresponding to
/b/ and /p/, respectively. This distribution defined the accent
that the subject heard, and each subject was pseudorandomly
assigned to one of five accent conditions (Figure 1). Each
of these accents implies a different /b/-/p/ category boundary,
and listeners’ adaptation was evaluated by comparing their

Figure 3 shows the classification functions for each individual
listener. In each accent, these classification functions tend to
fall in between the boundaries predicted by the typical talker
distributions and the boundaries implied by the exposure distributions. We can quantify this by the percentage of the predicted shift in category boundary from the classification function for the typical talker to the boundary implied by the input
distribution (Table 1). A 0% shift corresponds to no adaptation at all, while a shift of 100% corresponds to complete
adaptation to the exposure distributions, with no (remaining)
influence of any prior beliefs.
In all conditions, the average shift percentage was between
0% and 100% (except the 0ms shift condition, which is so
close to the typical talker that estimating the percentage is
numerically unstable). More interestingly, the more extreme
conditions show less complete adaptation than the less extreme conditions. Together, these results suggest that listeners’ adaptation was constrained by their prior expectations
(given the finite amount of evidence they received about the
unfamiliar talker). This provides qualitative evidence that listeners combine their prior expectations with observed cue distributions in order to rapidly adapt to unfamiliar talkers, as
predicted by the ideal adapter framework (Kleinschmidt &
Jaeger, 2015).

Inferring prior beliefs about talker variability
Our second goal in this paper is to test whether it is possible
to infer listeners’ prior beliefs about talker variability, based
on their patterns of adaptation to different accents. To that
end, we use a variant of a Bayesian belief-updating model
that has previously provided a good account of how listeners
incrementally update their beliefs in order to rapidly adapt
to an unfamiliar talker (Kleinschmidt & Jaeger, 2015). This

2352

Frequency

−10

0

10

20

/b/ mean
VOT

30

Typical Talker
Exposure
Talker

60
40

−10
0
10

20

20

0
0

50

100

0

50

100

0

50

100

0

50

100

0

50

100

30

VOT (ms)

Probability /p/ response

Figure 1: Each subject heard one of these five synthetic accents, which differ only in the distribution of VOTs of the word-initial
stops. Black dashed lines show VOT distributions from a hypothetical typical talker (as estimated by Kronrod et al., 2012).
Note that the 0 and 10ms shifted accents are reasonably close to this typical talker, while the −10, 20, and 30ms shifted accents
deviate substantially.
−10
1.00 Expo−
sure
0.75
0.50

0

10

20

/b/ mean
VOT

30

−10

Actual
listeners

0
10

0.25

Typical
talker

0.00
0

50

20
0

50

0

50

0

50

0

50

30

VOT (ms)

Figure 3: Listeners’ responses, smoothed with logistic functions (thin lines), compared with the classification functions expected based on a typical talker (no learning; dashed black lines) and complete adaptation to the exposure distributions (thick
dashed colored lines). Listeners’ actual category boundaries lie between the typical talker and exposure talker boundaries (see
Table 1).
previous modeling work has treated the content of listeners
prior beliefs—the category means and variances they think
are most likely—as known and fixed, setting them based on
pre-adaptation classification data, and then fitting the confidence in those prior beliefs as a free parameter. Here, we wish
to fit both the content of (prior expected mean and variance of
each category) and the confidence in prior beliefs, based on
adaptation data presented above.

Methods
We denote the listener’s beliefs about the current talker’s generative model as the parameters of a two-component mixture
of gaussians
θ = {µb , σ2b , µp , σ2p }
(1)

p(φ|x, y) ∝

where µ is a category’s mean VOT and σ2 is its variance. As
in Kleinschmidt and Jaeger (2015), we use an independent,
conjugate Normal-χ−2 prior for each category, with parameters (Gelman, Carlin, Stern, & Rubin, 2003)
φ =
θ|φ ∼

{µ0,b , σ2b , µ0,p , σ2p , κ0 , ν0 }
σ2
Normal(µc |µ0,c , c )χ−2 (σ2c |σ20,c , ν0 )
κ0
c∈{b,p}

∏

where µ0 and σ20 are a category’s prior expected mean VOT
and variance, respectively, and κ0 and ν0 are the listener’s
confidence in these prior expectations, measured as pseudocounts. Note that, as in previous modeling work in this framework, these prior confidence parameters are shared between
the two categories. Preliminary simulations showed that it
wasn’t possible to uniquely identify the model using separate
prior confidence parameters for the two categories.
To estimate the listeners’ prior beliefs, we infer values for
these parameters given the observed adaptation behavior (category responses y and input VOTs x) using Bayesian inference, marginalizing over θ:
p(y|φ, x)p(φ)

(4)

Z

∝

(2)
(3)

dθp(y|θ, x)p(θ|x, φ)p(φ)

(5)

We two simplifying assumptions. First, we assume that
the order of the trials does not matter. Second, we assume
that listeners pick up on the cluster structure of the input they
receive, accurately detecting the mean and variance of each
cluster, but for categorizing they use their posterior beliefs

2353

Expected
243
-11
56
772
19
16

95% HPD Int.
163–495
-28–3
44–72
493–1180
16–23
14–20

Units
observations
ms VOT
ms VOT
observations
ms VOT
ms VOT

0.04

Likelihood

Parameter
κ0
µ0,b
µ0,p
ν0
σ0,b
σ0,p

0.03

Source
Inferred
prior
Kronrod et
al. (2012)

0.02
0.01
0.00
0

Table 2: Expected values and 95% highest posterior density
intervals for the prior parameters, given the adaptation data.

50

VOT (ms)

which combine their prior beliefs with these observed statistics. Backing off these assumptions is possible, but computationally more demanding, and we leave it for future work
to determine how they might affect our results. Finally, we
also add a lapse rate parameter (maximum a posteriori value
of 5%), that allows for some proportion of responses to be
attributed to random guessing (e.g., because of attentional
blinks, see Clayards et al., 2008 for a discussion).
The posterior distributions of each of these parameters (the
shared prior beliefs plus lapsing rate) were estimated using
MCMC with the Stan software package (Stan Development
Team, 2015). Weakly informative hyperpriors were used that
were centered at 0 with standard deviations of 100 for the
prior expected means and variances (making them roughly
constant over reasonable values) and 888 (four times the total number of trials that listeners heard) for the prior confidence pseudocounts (which is essentially uniform on the
whole range from completely ignoring prior beliefs to not
adapting at all). The prior for the lapsing rate was uniform
on [0, 1]. We ran four chains for 1000 samples each, discarding the first 500 as burn-in for a total of 2000 samples overall. This sampler converged well and achieved good mixing
(maximum R̂ = 1.01; Gelman & Rubin, 1992).

Results
The first way we evaluate this model is to ask how well it fits
listeners’ behavior. Figure 4 shows listeners’ average classification functions, compared with the posterior predictive
classification functions from the belief-updating model. The
first thing to notice is that the model fits the data well (loglikelihood ratio vs. an intercept-only binomial null model of
12385, and Spearman’s ρ = 0.9, p < 10−10 in both cases) capturing the different classification functions that result from
exposure to each input distribution. This in and of itself is
an interesting result: it shows that there does exist some set
of prior beliefs such that the range of adaptation behavior we
observed can be explained by a model where the listeners assigned to the different accent conditions all start from a common set of prior beliefs.
The second way to evaluate this model is based on the prior
beliefs it infers listeners to have. Table 2 shows the posterior
expectation and 95% highest posterior density intervals for
each of the prior belief parameters given the adaptation data
above. The behavioral data was consistent with high confi-

Figure 5: Expected cue distributions based on the prior beliefs
inferred here from behavioral adaptation data (solid lines).
Plotted with VOT distributions measured by Kronrod et al.
(2012) based on a combination of classification and discrimination behavior (dashed lines).

dence in prior beliefs with the prior confidence about category
variances (E(ν0 ) = 772.39) higher than confidence in the category means (E(κ0 ) = 243.26). Both of these (measured in
pseudo-observations) are larger than the number of trials that
listeners heard in the experiment (222), which means that as
far as the belief-updating model is concerned, listeners updated beliefs reflected their prior beliefs as much as (in the
case of the means) or more than (for the variances) the distributions they actually observed. This is consistent with the
qualitative finding that listeners’ category boundaries are intermediate between the boundaries corresponding to a typical
talker and the experimental exposure talker.
Figure 5 shows the cue distributions corresponding to the
posterior expected values of the prior expected mean and variance parameters given the behavioral data, compared with
the distributions corresponding to one typical talker (as determined by a combination of classification and discrimination data, Kronrod et al., 2012, see also Lisker & Abramson, 1964). The inferred prior beliefs are in reasonably good
agreement with this typical talker, with one exception: the
mean for /b/ is slightly lower (E(µ0,b ) = −10.69 ms), and the
standard deviation of /b/ is slightly higher (E(σ0,b ) = 19.4
ms).

Discussion
These modeling results show that the pattern of adaptation
behavior observed above is consistent with a belief-updating
model of phonetic adaptation that combines prior expectations with input statistics in order to infer the current talker’s
cue distributions. Specifically, it shows that there exists a single set of prior beliefs that captures the range of adaptation to
different input distributions that stretches from nearly complete adaptation to partial adaptation at best.
These prior beliefs are reasonably consistent with other attempts to determine what listeners think the underlying cue
distributions are (Kronrod et al., 2012), as well as the distributions produced by actual talkers (Lisker & Abramson,
1964). In fact, the prior expected VOT distribution for /p/

2354

Probability /p/ response

−10
1.00

0

● ●

10
●

●

0.75

20

● ●

30
● ● ●
● ●

● ● ● ●

● ● ●
●
●

●

●

−10

●

0

●

10

●

20

●

30

●
●
●

0.50

●
●

●

0.25
0.00

/b/ mean
VOT

●
● ● ●

●
● ● ●

0

●

●

50

0

● ●

50

●

●
●

0

50

0

●

●

●

50

0

50

VOT (ms)

Figure 4: The classification functions (shaded ribbons, 95% posterior predictive intervals) predicted by the belief updating
model fit listeners’ responses well (dots with lines showing bootstrapped 95% confidence intervals).
that our model inferred is almost identical to that observed by
both Kronrod et al. (2012) and Lisker and Abramson (1964).
The distribution for /b/ deviates from prior work, however.
One possible reason for this is that a substantial minority of
English speakers produce pre-voiced /b/ (Lisker & Abramson, 1964), which is characterized by a lower (negative) VOT
and a higher variance (often higher even than /p/). That is,
across talkers, the /b/ VOT distribution parameters (mean and
variance) have a bimodal distribution. We assumed a single,
unimodal prior distribution, and the prior beliefs we inferred
to be most likely are consistent with a compromise between
the two types of /b/ distributions that talkers actually produce.
This possibility suggests two directions for future work.
First, large-scale corpus studies of VOT distributions are
needed to determine to what extent the distribution of /b/
mean VOTs is really bimodal across talkers. However, the
only study of this type we are aware of considers only nonnegative VOTs (Chodroff, Godfrey, Khudanpur, & Wilson,
2015) and thus excludes talkers who pre-voice their /b/. Second, more modeling work is needed to test whether a multimodal prior is justified given the adaptation data, and if so,
whether it would change the inference about listeners’ prior
expectations for /b/.
The other major result of this modeling is that listeners
have high confidence in their prior expectations about the
VOT distributions of /b/ and /p/, acting as if they had already
observed around 200–800 samples from each category (for
the category means and variances, respectively) from the unfamiliar talker they encountered in our experiment.
At first blush, this conflicts with previous work on another
phonetic contrast, /b/-/d/, which found confidence values that
were one or two orders of magnitude smaller than those inferred here (Kleinschmidt & Jaeger, 2015). Interestingly, the
/b/-/d/ contrast is cued by spectral cues (formant frequency
transitions) which generally vary substantially across talkers
(e.g., Peterson, 1952). The acoustic cues to the /b/-/p/ contrast used in the current study do not show as much variability across talkers (e.g., Allen, Miller, & DeSteno, 2003;
Chodroff et al., 2015). When there is little variability across
talkers, past experience with other talkers’ VOT distributions

is highly informative about the distributions that an unfamiliar talker will produce, requiring less adaptation. Likewise,
when there is more variability across talkers, listeners need
to rely more on the current talker’s cue distributions and less
on their prior experience. Thus, the apparent discrepancy between the confidence that listeners place in their prior beliefs
in the current study and in Kleinschmidt and Jaeger (2015) is
actually in line with an ideal adapter which combines prior
beliefs with current experience weighted according to confidence. This idea finds further empirical support in Kraljic and
Samuel (2007), who found that after the same amount of exposure, listeners recalibrate a /d/-/t/ contrast (analogous to the
/b/-/p/ contrast used here) much less than an /s/-/S/ contrast
(where the latter exhibits larger variability across talkers; e.g.,
Newman, Clouse, & Burnham, 2001).

Conclusion
A central prediction of the ideal adapter framework
(Kleinschmidt & Jaeger, 2015) is that listeners adapt to unfamiliar talkers by combining their prior beliefs with observed
evidence about that particular talker’s cue distributions. In
this paper, we have shown first that for a range of different accents (cue distributions), listeners’ behavior in a distributional learning experiment reflects a compromise between
what would be expected for the cue distributions produced by
a typical talker and the exposure talker. Second, the range of
adaptation behavior observed across the various accents that
listeners heard can be captured by a belief-updating model
with a single set of prior expectations that are updated based
on experience with the exposure talker.
These results emphasize the importance of listeners’ prior
expectations for robust speech perception in the face of talker
variability. Even if all the listener knows about the talker
is that they are speaking English, they can still benefit from
prior experience with other speakers of English to provide an
informative head start for adaptation. The modeling framework we use has the additional advantage of allowing us to
infer what cue distributions listeners believe an unfamiliar
talker will produce. This provides a potentially powerful—
and heretofore missing—tool for probing listeners’ prior ex-

2355

pectations, based only on comprehension data. These beliefs
reflect what listeners have learned about the variability they
can expect across talkers, and probing how this internal model
is related to the actual variability across talkers (measured via
speech production data) is an important next step in advancing our understanding of robust speech perception.
More generally, prior knowledge is increasingly understood to play in important role in a number of perceptual and
memory domains (e.g., Brady & Tenenbaum, 2013; Froyen,
Feldman, & Singh, 2015; Orhan & Jacobs, 2011). Distributional learning provides an approach to probing prior expectations about the statistics of the sensory world, which, as in
speech perception, are critical to effectively coping with nonstationarity in sensory statistics.

Acknowledgements
This work was partially funded by an NSF Graduate Research
Fellowship to DFK and NICHD R01 HD075797 as well as
an Alfred P. Sloan Fellowship to TFJ. The views expressed
here are those of the authors and not necessarily those of the
funding agencies.

References
Allen, J. S., Miller, J. L., & DeSteno, D. (2003). Individual talker differences in voice-onset-time. The Journal of the Acoustical Society of America, 113(1), 544. doi:
10.1121/1.1528172
Bertelson, P., Vroomen, J., & de Gelder, B. (2003). Visual
recalibration of auditory speech identification: a McGurk
aftereffect. Psychological Science, 14(6), 592–597. doi:
10.1046/j.0956-7976.2003.psci 1470.x
Brady, T. F., & Tenenbaum, J. B. (2013). A probabilistic model of visual working memory: Incorporating
higher order regularities into working memory capacity
estimates. Psychological review, 120(1), 85–109. doi:
10.1037/a0030779
Chodroff, E., Godfrey, J., Khudanpur, S., & Wilson, C.
(2015). Structured Variability in Acoustic Realization : A
Corpus Study of Voice Onset Time in American English
Stops. In The Scottish Consortium for ICPhS (Ed.), Proceedings of the 18th international congress of phonetic sciences. Glasgow, UK: the University of Glasgow.
Clarke, C. M., & Garrett, M. F. (2004). Rapid adaptation to foreign-accented English. The Journal of the
Acoustical Society of America, 116(6), 3647.
doi:
10.1121/1.1815131
Clayards, M. A., Tanenhaus, M. K., Aslin, R. N., & Jacobs,
R. a. (2008). Perception of speech reflects optimal use of
probabilistic speech cues. Cognition, 108(3), 804–9. doi:
10.1016/j.cognition.2008.04.004
Feldman, N. H., Griffiths, T. L., & Morgan, J. L. (2009).
Learning phonetic categories by learning a lexicon. Proceedings of the 31st Annual Conference of the Cognitive
Science Society, 2208–2213.

Froyen, V., Feldman, J., & Singh, M. (2015). Bayesian Hierarchical Grouping : Perceptual Grouping as Mixture Estimation. Psychological Review, 122(4), 575–597.
Gelman, A., Carlin, J. B., Stern, H. S., & Rubin, D. B. (2003).
Bayesian Data Analysis (Second ed.). Taylor & Francis.
Gelman, A., & Rubin, D. B. (1992). Inference from Iterative
Simulation Using Multiple Sequences. Statistical Science,
7(4), 457–472. doi: 10.1214/ss/1177011136
Idemaru, K., & Holt, L. L. (2011). Word recognition reflects
dimension-based statistical learning. Journal of Experimental Psychology: Human Perception and Performance,
37(6), 1939–56. doi: 10.1037/a0025641
Kleinschmidt, D. F., & Jaeger, T. F. (2015). Robust speech
perception: Recognize the familiar, generalize to the similar, and adapt to the novel. Psychological Review, 122(2),
148–203. doi: 10.1037/a0038695
Kleinschmidt, D. F., Raizada, R., & Jaeger, T. F. (2015). Supervised and unsupervised learning in phonetic adaptation.
In R. Dale et al. (Eds.), Proceedings of the 37th annual
conference of the cognitive science society. Austin, TX:
Cognitive Science Society.
Kraljic, T., & Samuel, A. G. (2007). Perceptual adjustments
to multiple speakers. Journal of Memory and Language,
56(1), 1–15. doi: 10.1016/j.jml.2006.07.010
Kronrod, Y., Coppess, E., & Feldman, N. H. (2012). A Unified Model of Categorical Effects in Consonant and Vowel
Perception. In N. Miyake, D. Peebles, & R. P. Cooper
(Eds.), Proceedings of the 34th annual conference of the
cognitive science society (pp. 629–634). Austin, TX: Cognitive Science Society.
Lisker, L., & Abramson, A. (1964). A cross-language sudy
of voicing in initial stops: Acoustical measurements. Word,
20(3), 384–422.
Newman, R. S., Clouse, S. a., & Burnham, J. L. (2001).
The perceptual consequences of within-talker variability in
fricative production. The Journal of the Acoustical Society
of America, 109(3), 1181–1196. doi: 10.1121/1.1348009
Orhan, A. E., & Jacobs, R. A. (2011). A Nonparametric
Bayesian Model of Visual Short-Term Memory. In L. Carlson, C. Hoelscher, & T. F. Shipley (Eds.), Proceedings of
the 33rd annual conference of the cognitive science society
(pp. 2451–2456). Austin, TX: Cognitive Science Society.
Peterson, G. E. (1952). Control Methods Used in a Study
of the Vowels. The Journal of the Acoustical Society of
America, 24(2), 175. doi: 10.1121/1.1906875
Stan Development Team. (2015). Stan: A C++ Library for
Probability and Sampling, Version 2.9.0.
Sumner, M. (2011). The role of variation in the perception of accented speech. Cognition, 119(1), 131–6. doi:
10.1016/j.cognition.2010.10.018

2356

