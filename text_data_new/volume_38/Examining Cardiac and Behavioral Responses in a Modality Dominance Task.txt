Examining Cardiac and Behavioral Responses in a Modality Dominance Task
Christopher W. Robinson (robinson.777@osu.edu)
Krysten R. Chadwick (chadwick.63@osu.edu)
Jessica L. Parker (parker.1026@osu.edu)
Department of Psychology, The Ohio State University at Newark
1179 University Dr, Newark, OH 43056, USA
Scott Sinnett (ssinnett@hawaii.edu)
Department of Psychology, University of Hawaii at Manoa
2530 Dole Street, Honolulu, HI 96822, USA
Abstract
The current study examined cardiac and behavioral responses
to changing auditory and visual information while using
modified oddball tasks. When instructed to press the same
button for auditory and visual oddballs, auditory dominance
was found with cross-modal presentation slowing down
visual response times and decreasing visual accuracy. When
instructed to make separate responses to auditory and visual
oddballs, visual dominance was found with cross-modal
presentation slowing down response times and decreasing
auditory accuracy. However, examination of cardiac
responses that were time-locked to stimulus onset show crossmodal facilitation effects, with discrimination of oddballs and
standards occurring earlier in the course of processing in the
cross-modal condition than in the unimodal conditions. These
findings shed light on potential mechanisms underlying
modality dominance effects and have implications on tasks
that require simultaneous processing of auditory and visual
information.
Keywords: Cross-modal processing; Sensory Dominance;
Attention.

Introduction
While most of our experiences are multisensory in nature,
historically, most research has focused on processing within
a single sensory modality. Over the last 40 years there has
been a growing body of research examining how sensory
systems process and integrate incoming information (see for
example Driver & Spence, 2004; Posner, Nissen, & Klein,
1976; Spence, 2009; Wickens, 1984), with some
multisensory environments facilitating learning (e.g.,
Alsius, Navarra, Campbell, & Soto-Faraco, 2005; Massaro,
1998) and others attenuating learning (Sloutsky &
Napolitano, 2003; see also Robinson & Sloutsky, 2010a for
a review). For example, intersensory redundancy, when the
same information can be conveyed in different sensory
systems, can often facilitate learning and speed up responses
(Bahrick & Lickliter, 2000; Giard & Peronnet, 1999).
However, in many situations, information presented to one
sensory modality is irrelevant or may even conflict with
information presented to a different sensory system. In these
latter situations, modality dominance effects can be
observed, with one modality attenuating encoding and/or
responding to information in the other modality (see Spence,
Parise, & Chen, 2012 for a review).
One commonly used paradigm to study modality
dominance is the Colavita visual dominance task (Colavita,

1974; Colavita, Tomko, & Weisberg, 1976; Colavita &
Weisberg, 1979; Egeth & Sager, 1977). In this task,
participants are presented with auditory or visual
information and instructed to quickly respond by pressing
one button when they hear an auditory stimulus and a
different button when they see a visual stimulus. On a small
percentage of trials, the auditory and visual stimuli are
presented at the same time. Participants often miss these
cross-modal trials by only pressing the visual button, as
opposed to pressing both buttons, or a third button
associated with a cross-modal stimulus (see Sinnett, Spence,
& Soto-Faraco, 2007). Research using variations of this task
consistently points to visual dominance, with most of the
sensory and attentional manipulations weakening but not
reversing the effect (but see Ngo, Cadieux, Sinnett, SotoFaraco & Spence, 2011). While visual dominance effects
are robust and well-studied, underlying mechanisms are
poorly understood (see Spence et al., 2012 for a review).
The current study expands on this literature in several
important ways. Robinson, Chandra, and Sinnett (2016)
recently demonstrated that it is possible to reverse modality
dominance in an oddball paradigm by having participants
make the same response to auditory and visual oddballs.
More specifically, participants were repeatedly presented
with the same sound, picture, or sound-picture pairing, and
were required to inhibit responses to this stimulus
(standard). They were also instructed to press a button on a
keyboard as quickly as possible if the picture, sound, or both
the picture and sound changed (visual, auditory, or crossmodal oddballs, respectively). While pairing the pictures
and sounds together slowed down response times to visual
oddballs, it often had no negative effect on auditory
processing (i.e., response times to auditory oddballs did not
differ when presented with or without the visual standard).
The first goal of the current study was to test the
generalizability of this finding by using a slightly different
procedure with more salient and familiar visual stimuli. It is
possible that auditory dominance was found because the
visual stimuli used in Robinson et al. were monochromatic,
unfamiliar images.
The second goal was to examine if auditory and visual
dominance effects can be modulated by top-down
attentional control, or if instead proceed with attention
having no effect. While attentional manipulations often fail
to reverse auditory and visual dominance (Napolitano &

2201

Sloutsky, 2004; Ngo, Sinnett, Soto-Faraco, & Spence, 2010;
Sinnett et al., 2007), it is possible that individual differences
in attentional control modulate or reverse the effect. For
example, one proposed mechanism underlying visual
dominance is that participants strategically bias their
attention in favor of visual input to compensate for the low
alerting properties of visual input (Posner et al., 1976).
Thus, it is possible that participants who are better at
selectively attending to visual input are more likely to show
visual dominance effects and/or less likely to be distracted
by conflicting auditory information. At the same time, it has
also been argued that auditory dominance may stem from
auditory stimuli automatically grabbing attention and
attenuating or delaying visual processing (Robinson &
Sloutsky, 2010a). If auditory dominance effects stem from
auditory stimuli automatically engaging attention, then
individuals with high or low attentional control may show
the same pattern of results. To examine effects of attentional
control on modality dominance, we collected individual
differences in resting Heart Rate Variability (HRV) prior to
the experiment. The underlying idea is that the prefrontal
cortex plays a significant role in executive functions such as
selective attention and emotional regulation. HRV may
serve as a proxy for individual variability in executive
functions because parasympathetic activity adds short term
variability to the heart beat via the vagus nerve and
participants with higher HRV often perform better on a
variety of executive function tasks (Hansen, Johnson, &
Thayer, 2003; Thayer & Lane, 2000). They may also show a
different pattern of results on modality dominance tasks.
The final goal of the current research was to examine
real-time psychophysiological responses to changing
auditory and visual information to possibly gain insight into
the time course of cross-modal interference effects. It is well
documented that infants’ heart rates slow down when
actively processing visual information (see Richards &
Casey, 1992 for a review), and using a modified oddball
task, heart rate also appears to slow down to novel, less
frequent sounds than to more frequent sounds (Robinson &
Sloutsky, 2010b). By time-locking heart rate with the onset
of standard and oddball items, the current study examined
the feasibility of using changes in adults’ cardiac responses
as a measure of auditory, visual, and cross-modal
processing. It was hypothesized that cardiac responses
would differ for standards and oddballs; thus, potentially
providing an additional measure of discrimination. We also
examined if comparing cardiac responses to auditory and
visual oddballs when presented cross-modally with the
respective unimodal baselines would provide converging
evidence of modality dominance effects.

Experiment 1
Experiment 1 employed a cross-modal oddball task and
participants made the same response to auditory and visual
oddballs. It was hypothesized that cross-modal presentation
would have a greater cost on visual processing.

Method

Participants Thirty-eight adults (23 Females, M = 19.1
years) participated in Experiment 1. Participants were
undergraduate students at The Ohio State University
Newark who received course credit in exchange for
participation.
Apparatus A Dell Latitude E6430 laptop computer with
DirectRT software was used for stimulus presentation and to
record response times and accuracies. Visual stimuli were
presented on a Dell P2212hB monitor and auditory stimuli
were presented via Kensington 33137 headphones at
approximately 65 dB. A Dell Latitude E6430 laptop
computer with Mindware software was used to record
electrocardiograms. Two Ag-AgCl electrodes were placed
on the participants’ right collarbone and left lower rib, and a
reference electrode was placed on the participants’ right
lower rib. Electrocardiograms were collected using a
BioNex acquisition unit with a BioNex Impedance
Cardiograph and GSC amplifier. DirectRT on the stimulus
presentation laptop sent event markers to Bionex; thus,
time-locking electrocardiograms with stimulus presentation.
Materials The stimulus pool consisted of five visual and
five auditory stimuli. Visual stimuli (see Figure 1) were
approximately 400 x 400 pixels and pulsated centrally on a
computer monitor for 750 ms, with a random 600-900 ms
Inter-Stimulus Interval (ISI). The auditory stimuli consisted
of bear, frog, elephant, cat, and dog sounds, which were
taken from Marcell et al. (2000) and were shortened to 750
ms using Audacity software. As in basic oddball paradigms,
one stimulus was frequently presented (approximately 90%,
standard) and other stimuli were less frequent
(approximately 10%, oddballs). The standard was a dog
bark, an image of a dog, or the dog and bark were paired
together. The auditory and visual oddballs were an elephant,
frog, cat, and bear.

Figure 1. Visual stimuli used in Experiments 1 and 2

Procedure The study consisted of four phases. In the first
phase, participants sat still for five minutes while the
computer recorded resting HRV. Participants then
completed three different oddball tasks on the computer,
while their heart rate was monitored. The current study
deviated from traditional oddball paradigms in that a trial
was defined as a series of stimuli with either a standard or
oddball at the end of the series (e.g., 5 standards →
oddball), as opposed to each stimulus being a trial. This
manipulation gave the heart at least 6 s to respond to an
oddball before encountering another oddball (assuming two
short oddball sequences were presented back to back).
In the auditory oddball condition, there were 16 standard
trials and 16 oddball trials. On auditory oddball trials, a dog
bark was presented either four or five times, followed by

2202

one of the other animal sounds (oddball). On auditory
standard trials, participants heard four or five dog barks,
followed by another dog bark (standard). Half of the trials
consisted of four standards followed by a standard or
oddball, and the remaining trials consisted of five standards
followed by a standard or oddball. DirectRT sent an event
marker to Bionex at the onset of the last standard or oddball
in each trial. The unimodal visual condition was similar to
the auditory condition, with the exception that standard and
oddballs were pictures, not sounds. Thus, for each
condition, we measured how quickly participants pressed a
button when they encountered an oddball and how quickly
the heart differentiated standards and oddballs.
In the cross-modal condition, the trials consisted of four
or five standard image-sound pairs (dog-dog bark) followed
by another image-sound pair that was either a standard or an
oddball. Each participant had a total of 96 trials (48 standard
and 48 oddball). Sixteen of the oddball trials had only a
visual change (visual oddball), while an additional 16 trials
only had an auditory change (auditory oddball). Lastly,
there were also 16 double oddball trials, where both
auditory and visual stimuli changed. As in the unimodal
conditions, each stimulus was presented for 750
milliseconds, with a 600-900 ms ISI.

than all trial types, ts > 2.26, ps < .05, suggesting that the
slowdown occurs because of the conflicting information
(e.g., auditory standard elicits no response; whereas, visual
oddball elicits button press), as opposed to cross-modal
presentation increasing task demands more generally.
HRV Analyses To examine the relationship between HRV
and modality dominance, we calculated a measure of resting
HRV for each participant during the five minute baseline
phase. Mindware software was used to isolate the baseline
phase and to detect and remove artifacts. Root Mean Square
of the Successive Differences (RMSSD) was calculated for
each participant, with higher values indicating more
variability in resting heart rate. A median split was used to
classify each participant as having low or high HRV.
Response times broken up by HRV are reported in Figure 2.
A 2 (HRV: Low vs. High) x 2 (Modality: Auditory vs.
Visual) x 2 (Presentation Mode: Unimodal vs. Cross-modal)
mixed-factors ANOVA revealed no significant effects or
interactions with HRV, F’s < 1.60, ps > .214, suggesting
that both groups showed the same overall pattern.

Results and Discussion
Behavioral Analyses Overall, participants correctly
reported when the auditory component changed and when
both modalities changed (hit rate > .99 across both unimodal
and cross-modal conditions). However, cross-modal
presentation interfered with visual oddball detection, with
visual hit rate in the unimodal visual condition (M = .99)
exceeding the cross-modal condition (M = .95), t (37) =
2.05, p = .048, suggesting that cross-modal presentation
attenuated responding to visual but not auditory oddballs.
Additional analyses focused on response times in the
cross-modal condition when only the auditory or visual
component changed, and these response times were
compared to the respective unimodal baselines. A 2
(Modality: Auditory vs. Visual) x 2 (Presentation Mode:
Unimodal vs. Cross-modal) repeated measures ANOVA
revealed an effect of Presentation Mode, F (1,37) = 33.63, p
< .001, and a Modality x Presentation Mode interaction, F
(1,37) = 10.91, p = .002. While auditory discrimination
times in the unimodal condition (M = 459 ms, SE = 9.92)
were faster than in the cross-modal condition (M = 474 ms,
SE = 9.72), t (37) = 2.10, p = .042, the interaction suggests
that the cost of cross-modal presentation was more
pronounced in the visual condition, with visual
discrimination in the unimodal condition (M = 443 ms, SE =
6.95) being faster than the cross-modal condition (M = 488
ms, SE = 8.84), t (37) = 7.17, p < .001. Thus, accuracy and
RT data show that cross-modal presentation attenuated
visual processing more than auditory processing, a finding
consistent with auditory dominance. However, there was no
slow down when both modalities changed (M = 424 ms, SE
= 11.34). In fact, response times on these trials were faster

Figure 2. Mean response times across trial types, conditions, and
HRV in Experiment 1. Error Bars denote Standard Errors and “*”
denotes cross-modal RTs differ from unimodal RTs, ps < .001.

HR Analyses Weighted Inter-Beat Intervals (IBIs) were
exported every second, and difference waveforms were
calculated by subtracting pre-stimulus IBI (Weighted IBI
from -1 s to stimulus onset) from each 1 s IBI bin post
stimulus. Note that IBIs reflect the time between heartbeats;
thus, increases in IBI reflect slowed heart rate, and
difference IBIs greater than 0 reflect heart rate slowed
compared to pre-stimulus levels. Paired t tests comparing
standard and oddball IBIs were conducted each second to
determine how quickly the heart differentiated oddballs
from standards.
As can be seen in Figures 3A and 3B, cardiac responses
to oddballs and standards differed at 4 s after stimulus onset
in the auditory condition and 5 s after stimulus onset in the
visual condition. Note that these effects were primarily
driven by heart rate acceleration to oddballs; whereas,
infants show slower heart rate to less frequent oddballs
(Robinson & Sloutsky, 2010b). One explanation for this
difference may stem from using passive looking time tasks
with infants and speeded response time tasks with adults.

2203

However, it is also worth noting that the discrimination of
auditory and visual oddballs occurred earlier in the crossmodal condition (2 s after stimulus onset) compared to the
unimodal conditions. Thus, behavioral data point to crossmodal interference with cross-modal presentation slowing
down visual response times, but changes in time-locked
cardiac responses show facilitation, with discrimination
occurring earlier in the course of processing when
information is presented to both sensory modalities.

(Colavita, 1974). It was hypothesized that requiring separate
responses to auditory, visual, and cross-modal oddballs
would result in visual dominance, with participants making
more visual based errors when both modalities change (c.f.,
Robinson et al., 2016; Sinnett et al., 2007).

Method
Participants, Materials, and Procedure Twenty-seven
new participants (15 Females, M = 23.97 years) from The
Ohio State University Newark participated in Experiment 2.
The stimuli and procedure was identical to Experiment 1
except that participants were instructed to press 1 on the
number pad if the auditory component changed, 2 if the
visual component changed, and 3 if both modalities changed
(button
assignment
was
counterbalanced
across
participants). Participants in the unimodal condition were
only instructed to press one of the buttons.

Results and Discussion

Figure 3. Cardiac responses across time. Error Bars denote SEs,
and “+” and “*” denote auditory and visual oddballs differed from
standard, ps < .05 and .007, respectively. Bonferonni corrections
require a p value of .007 to reach significance.

Experiment 2
The primary goal of Experiment 2 was to further examine
modality dominance effects, while using a task that is more
similar in structure to the traditional visual dominance tasks

Behavioral Analyses Accuracies in the current experiment
were in the opposite direction compared to Experiment 1.
While hit rates exceeded .99 when detecting visual oddballs,
cross-modal presentation attenuated auditory hit rates, with
auditory oddball detection in the unimodal auditory
condition (M = .99) exceeding auditory hit rates in the
cross-modal condition (M = .78), t (26) = 6.57, p < .001.
To examine Colavita visual dominance effects, we
examined errors made on double oddballs. The overall error
rate to double oddballs was 15%. Of the 66 errors made,
there were 11 misses where participants failed to make any
response. On the remaining trials, participants pressed only
the visual button 41 times and only the auditory button 14
times, resulting in a visual modality bias, χ2 (1, N = 27) =
12.30, p < .001.
Additional analyses focused on response times. A 2
(Modality: Auditory vs. Visual) x 2 (Presentation Mode:
Unimodal vs. Cross-modal) repeated measures ANOVA
only revealed an effect of Presentation Mode, F (1,26) =
449.17, p < .001, which suggests that cross-modal
presentation equally affected response times in both
modalities.
To make direct comparisons across Experiments, we
submitted accuracies and RTs to two 2 (Experiment: 1 vs. 2)
x 2 (Modality: Auditory vs. Visual) x 2 (Presentation Mode:
Unimodal vs. Cross-modal) mixed-factors ANOVAs. We
focus only on the effects and interactions with Experiment.
All main effects and interactions were significant for
accuracy, Fs (1,63) > 11.52, ps < .001, but only a main
effect of Experiment and an Experiment x Modality
interaction were found for RT, Fs (1,63) > 178.96, ps <
.001.
HRV Analyses As in Experiment 1, we collected resting
heart rate, calculated RMSSD for each participant, and used
a median split to classify each individual as low or high
HRV. A 2 (HRV: Low vs. High) x 2 (Modality: Auditory
vs. Visual) x 2 (Presentation Mode: Unimodal vs. Cross-

2204

modal) mixed-factors ANOVA revealed no significant
effects or interactions with HRV, F’s < 2.31, p’s > .141,
suggesting that both groups showed the same overall pattern
(Figure 4).
We also examined if HRV could predict the type of
errors made on double oddballs. The low HRV group made
18 visual-based errors and 4 auditory-based errors. The high
HRV group made 23 visual-based errors and 10 auditorybased errors. A Fisher's exact test revealed no differences
between the proportion of visual-based errors, p = .36.

response keys. Opposite to Experiment 1, participants made
more errors to auditory oddballs when paired with the visual

Figure 4. Mean response times across trial types, conditions, and
HRV in Experiment 2. Error Bars denote Standard Errors and “*”
denotes cross-modal RTs differ from unimodal RTs, ps < .001.

HR Analyses Time-locked cardiac responses to standards
and oddballs are reported in Figure 5 and significant paired t
tests are reported on the x axis. While discrimination was
not as robust as in Experiment 1, the same pattern emerged
with discrimination of auditory and visual oddballs being
more robust and occurring earlier in the course of
processing in the cross-modal condition than in the
unimodal condition.

General Discussion
The Colavita visual dominance effect (Colavita, 1974) has
been robustly replicated in the literature for the past several
decades (see for example, Ngo et al., 2010; Sinnett et al.,
2007; Spence et al., 2012 for a review). Indeed, while Ngo
et al. (2011) did manage to reverse the effect (only under
extreme conditions), it was not until recently (Robinson et
al., 2016) that visual dominance has been consistently
reversed. The first goal of this experiment was to extend
these findings by using a slightly different procedure with
more salient visual stimuli. In doing so, auditory dominance
was again demonstrated when looking at both response
latency and accuracy (Experiment 1). That is, responses to
visual oddballs were slowed down when presented
concomitantly with auditory standards, when compared to
visual oddballs presented in silence. Additionally, more
errors were made to visual oddballs when paired with an
auditory standard than when presented in silence. This
demonstration of auditory dominance dovetails with other
research using a similar oddball/change detection paradigms
(Robinson et al., 2016; Sloutsky & Napolitano, 2003).
In Experiment 2, auditory dominance reverted to visual
dominance when participants were required to use multiple

Figure 5. Cardiac responses across time. Error Bars denote SEs,
and “+” and “*” denote auditory and visual oddballs differed from
standard, ps < .05 and .007, respectively.

standard when compared with auditory oddballs presented
without images. Visual dominance was further reflected in
the percentage of visually-based errors (responding with the
visual response button only) to double oddballs.
The second goal of the current study was to explore
whether auditory or visual dominance effects can be
modulated by top-down attentional control. To address this,
we used HRV as a proxy for top-down attentional control,
as previous research (Hansen, Johnson, & Thayer, 2003;
Thayer & Lane, 2000) has demonstrated that high HRV is
correlated with increased performance on tests of executive
functioning. Interestingly, when performing a median split

2205

on our participants (see Figures 2 and 4), HRV did not seem
to modulate dominance type. These findings are consistent
with previous research showing that attentional
manipulations do not reverse modality dominance
(Napolitano & Sloutsky, 2004; Ngo et al., 2010; Sinnett et
al., 2007), and suggest that factors other than endogenous
attention may modulate dominance effects.
The third goal of this project was to examine real-time
psychophysiological responses to changing auditory and
visual information to possibly gain insight into the time
course of cross-modal interference effects. While both
studies report slower behavioral responses in the crossmodal conditions, cardiac responses to auditory and visual
oddballs were actually faster than the cross-modal
condition. Interestingly, these early cardiac responses in the
cross-modal condition were decelerations, not accelerations.
While future research is needed, it is possible that both
auditory and visual dominance reflect competition while
participants are making a decision and/or initiating a
response, and that early cardiac decelerations reflect more
robust or possibly even faster encoding in the cross-modal
conditions.

References
Alsius, A., Navarra, J., Campbell, R., & Soto-Faraco, S.
(2005). Audiovisual integration of speech falters under
high attention demands. Current Biology, 15(9), 839–843.
Bahrick, L. E., & Lickliter, R. (2000). Intersensory
redundancy guides attentional selectivity and perceptual
learning in infancy. Developmental psychology, 36(2),
190.
Colavita, F. B. (1974). Human sensory dominance.
Perception & Psychophysics, 16, 409-412.
Colavita, F.B., Tomko, R., & Weisberg, D. (1976). Visual
prepotency and eye orientation. Bulletin of the
Psychonomic Society, 8, 25-26.
Colavita, F.B., & Weisberg, D. (1979). A further
investigation of visual dominance. Attention, Perception
& Psychophysics, 25, 345–347.
Driver, J., & Spence, C. (2004). Crossmodal spatial
attention: Evidence from human performance. In C.
Spence & J. Driver (Eds.), Crossmodal space and
crossmodal attention. Oxford, UK: Oxford University
Press.
Egeth, H.E., & Sager, L.C. (1977). On the locus of visual
dominance. Attention, Perception & Psychophysics, 22,
77-86.
Giard, M.H., & Peronnet, F. (1999). Auditory-visual
integration during multimodal object recognition in
humans: A behavioral and electrophysiological study.
Journal of Cognitive Neuroscience, 11(5), 473-490.
Hansen, G., Johnsen, M.W., J.J., & Thayer, J.F. (2003).
Cardiac vagal tone is correlated with selective attention to
neutral distractors under load. Psychophysiology, 50,
398–406.
Marcell, M. M., Borella, D., Greene, M., Kerr, E., &
Rogers, S. (2000). Confrontation Naming of

Environmental Sounds. Journal of Clinical and
Experimental Neuropsychology, 22:6, 830 - 864.
Massaro, D.W. (1998). Perceiving talking faces: From
speech perception to a behavioral principle. Cambridge,
MA: MIT Press.
Napolitano, A., &Sloutsky, V.M. (2004). Is a Picture Worth
a Thousand Words? The Flexible Nature of Modality
Dominance in Young Children. Child Development,
75(6), 1850-1870.
Ngo, M. K., Cadieux, M. L., Sinnett, S., Soto-Faraco, S., &
Spence, C. (2011). Reversing the Colavita visual
dominance effect. Experimental Brain Research, 214(4),
607-618.
Ngo, M. K., Sinnett, S., Soto-Faraco, S., & Spence, C.
(2010). Repetition blindness and the Colavita effect.
Neuroscience Letters, 480, 186–190.
Posner, M.I., Nissen, M.J. & Klein, R.M. (1976). Visual
dominance: An information-processing account of its
origins and significance. Psychological Review, 83, 157171.
Richards, J. E., & Casey, B. J. (1992). Development of
sustained visual attention in the human infant. In B. A.
Campbell, H. Hayne, & R. Richarson (Eds.), Attention
and information processing in infants and adults, pp. 3060. Hillsdale, NJ: Erlbaum.
Robinson, C.W., Chandra, M., & Sinnett, S. (2016).
Existence of competing modality dominances. Attention,
Perception, & Psychophysics, 78, 1104-1114.
Robinson, C. W., & Sloutsky, V. M. (2010a). Development
of cross-modal processing. Wiley Interdisciplinary
Reviews: Cognitive Science, 1, 135-141.
Robinson, C. W., & Sloutsky, V. M. (2010b). Attention and
cross-modal processing: Evidence from heart rate
analyses. In S. Ohlsson & R. Catrambone (Eds.),
Proceedings of the 32nd Annual Conference of the
Cognitive Science Society (pp 2639-2643). Austin, TX:
Cognitive Science Society.
Sinnett, S., Spence, C., & Soto-Faraco, S. (2007). Visual
dominance and attention: Revisiting the Colavita effect.
Perception & Psychophysics, 69, 673–686.
Sloutsky, V.M., & Napolitano, A. (2003). Is a picture worth
a thousand words? Preference for auditory modality in
young children. Child Development, 74(3), 822-833.
Spence, C. (2009). Explaining the Colavita visual
dominance effect. Progress in Brain Research, 176, 245–
258.
Spence, C., Parise, C., & Chen, Y. C. (2012). The Colavita
visual dominance effect. In M.M. Murray, & M.T.
Wallace (Eds.), The Neural Bases of Multisensory
Processes (pp. 529-556). Boca Raton, FL: CRC Press.
Thayer, J. F., & Lane, R. D. (2000). A model of
neurovisceral integration in emotion regulation and
dysregulation. Journal of Affective Disorder, 61, 201–
216.
Wickens, C. D. (1984). Processing resources in attention. In
R. Parasuraman & D. R. Davies (Eds.), Varieties of
attention (pp. 63–101). Orlando, FL: Academic Press.

2206

