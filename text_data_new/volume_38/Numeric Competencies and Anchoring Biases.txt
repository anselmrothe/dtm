Numeric Competencies and Anchoring Biases
Sangsuk Yoon (ssyoon@temple.edu), Nathan Fong (nmfong@temple.edu)
Department of Marketing, 1801 Liacouras Walk
Philadelphia, PA 19122 USA
Abstract

For example, Bergman et al. (2010) showed that participants
with higher cognitive reflection task (CRT) score were less
influenced by an anchor than participants with lower CRT
score, while Oechssler, Roider, and Schmitz (2009) and
Stanovich and West (2008) did not.
Surprisingly, even though most anchoring tasks involve
numeric estimation or judgments, the literature on
individual differences and anchoring has not shown any
significant effects of numeracy on anchoring bias.
Numeracy an important cognitive ability, and is a separable
construct from other cognitive abilities (Peters &
Bjalkebring, 2015). Moreover, previous studies showed that
numeric competencies are associated with diverse decision
tasks (Burns, Peters, & Slovic, 2012; Dieckmann, Slovic, &
Peters, 2009; Liberali, Reyna, Furlan, Stein, & Pardo, 2012;
Miron-Shatz, Hanoch, Doniger, Omer, & Ozanne, 2014;
Peters, 2012), but only a handful of studies have
investigated the role of numeracy on anchoring bias, all
finding null effects. For example, Stanovich and West
(2008) showed a null effect of numeracy (partially captured
from SAT score) on anchoring, and Welsh et al. (2014)
investigated the effect of numeracy skill on anchoring
susceptibility using the Numerical Ability Test (Bennett,
Seashore, & Wesman, 1947). Both studies, however, did not
find any significant association between numeracy and
anchoring biases.
In this study, we aimed to investigate the role of numeric
competencies on anchoring bias by improving two
limitations from the previous studies on the role of
numeracy in anchoring. First, the previous studies focused
on only one facet of numeracy, objective numeracy - the
ability to understand and utilize mathematical concepts.
However, Peters and Bjalkebring (2015) recently showed
that numeracy is not a single construct. They introduced
three aspects of numeracy (objective, subjective, and
approximate numeracy), and that they are distinct from
other. Subjective numeracy is a person’s self-perception of
their own ability to use and understand numbers, which
might be formed by their actual ability to utilize numbers
and emotional responses about numbers. Approximate
numeracy is the ability to accurately classify numeric
magnitude, which is known to be associated with informal
math skills in early developmental stages. Peters and
Bjalkebring (2015) also showed that each numeric
competency is associated with different cognitive tasks. For
example, objective numeracy is associated with decision
bias in an attractiveness rating task (Bets task; showing
lower preference for a non-loss gamble ($9 in 7/36; nothing
in 29/36) over a loss gamble ($9 in 7/36; lose 5 cents in
29/36), even though the non-loss gamble has higher

Two experiments were conducted to examine the role of three
facets of numeracy (objective (ONS), subjective (SNS), and
symbolic number mapping (SMap)) in three anchoring tasks
(experimenter-given, self-generate, and valuation). We found
that the three numeric competencies were associated with
different anchoring tasks. SMap was associated with none of
the three anchor tasks, while ONS consistently predicted
stronger susceptibility to self-generated anchoring. The role
of ONS and SNS in experimenter-given and valuation tasks
were inconsistent. In Experiment 1, where the direction of
adjustment from an anchor is specified, ONS and SNS were
positively associated with anchor susceptibility in a valuation
task, while they were not in an experimenter-given anchor
task. On the other hand, in Experiment 2 where the direction
of adjustment from an anchor is uncertain, ONS and SNS
were positively associated with anchor susceptibility in an
experimenter-given anchor task, while they were not in a
valuation task.
Keywords: anchoring effect; numeric competencies;
individual differences; decision biases; symbolic number
mapping; anchor susceptibility

Introduction
Anchoring refers to a tendency for people’s numeric
judgments to incorporate an initially considered standard,
regardless of its relevance to the given numeric judgment
tasks (Tversky & Kahneman, 1974). Anchoring has been
examined in diverse domains, including factual knowledge,
negotiations, time estimation, physical length estimation,
math calculation, medical decisions, and legal sentencing
(for a recent review, see Furnham & Boo, 2011). A recent
project on replicability of diverse findings in psychological
science tested anchoring effects at 36 different labs around
the world, and found that anchoring is a robust
phenomenon, with an effect size stronger than in the
original study (Klein et al., 2014). Moreover, anchoring has
been known to be hard to debias (Wilson, Houston, Etling,
& Brekke, 1996).
Despite its robustness, the role of individual difference
factors in anchoring effect is inconsistent and inconclusive
(Bergman, Ellingsen, Johannesson, & Svensson, 2010;
Bodenhausen, Gabriel, & Lineberger, 2000; Brandt, Evans,
& Crawford, 2014; Furnham, Boo, & McClelland, 2012;
Welsh, Delfabbro, Burns, & Begg, 2014). For example,
McElroy and Dowd (2007) investigated the role of
personality traits on anchoring, and found that openness-toexperience to be positively associated with the anchoring
effect. Furnham et al. (2012), however, did not find the
same result from their study. Studies on the role of cognitive
abilities in anchoring have also shown inconsistent results.

728

expected value), while subjective and approximation
numeracy were not. In another task, where participants were
asked to state monetary amounts that made them indifferent
to risky gambles with high gains, they showed that objective
and approximation numeracy were associated with closer
valuation of the indifferent point for the sure thing to the
expected value of the risky gamble, while subjective
numeracy was not. Based on the finding that different
numeric competencies are associated with different decision
tasks, in this study, we used three different facets of
numeracy to investigate the role of numeracy in anchoring
biases.
Second, we investigated the role of numeracy on three
different types of anchoring tasks: experimenter-given
anchors, self-generated anchors, and valuation tasks. The
previous literature on the relationship between numeracy
and anchoring has focused on only experimenter-given
anchors for factual questions. In the experimenter-given
anchor task, participants are asked to answer a series of
factual questions (e.g., the length of Mississippi river),
preceded by a comparison (anchoring) question whether the
answer for the given question is lower/higher than an anchor
(Jacowitz & Kahneman, 1995). Self-generated anchor tasks
(e.g., the freezing point of vodka) also uses factual
questions, but a comparison question is not provided (Epley
& Gilovich, 2001). They can use self-generated anchors by
retrieving relevant quantities (e.g., the freezing point of
water), and previous studies show that the mechanisms are
different between experimenter-given and self-generated
anchor tasks (Epley & Gilovich, 2001, 2005). Valuation
tasks can also be regarded as a type of experimenter-given
anchor task, but an individual’s preferences plays into an
important role. Indeed, valuation studies showed weaker
and inconsistent results compared to other anchoring tasks.
For example, Ariely, Loewenstein, and Prelec (2003) and
Bergman et al. (2010) showed that a positive linear
relationship between numeric anchor and willingness-topay, while Fudenberg, Levine, and Maniadis (2012) and
Maniadis, Tufano, and List (2014) failed to replicate the
effects. Based on the fact that different mechanisms are
associated with different anchoring tasks, we tested the role
of the three facets of numeracy in these three different types
of anchoring tasks in two experiments.

For the subjective numeracy scale (SNS), we used an
eight-item scale developed by Fagerlin et al. (2007). An
example of a SNS item is: “how good are you working with
fractions?” We obtained a single score by adding up the
ratings. The Cronbach’s alpha of Experiment 1 was .85, and
that of Experiment 2 was .86.
For measuring approximate mapping competence, we
used a symbolic number mapping task, and followed the
same procedure introduced in Peters and Bjalkebring
(2015). Participants were asked to make marks
corresponding to six numbers (4, 6, 18, 71, 230, and 780) on
a 165-mm horizontal line with endpoints labeled 0 and
1,000, where each question was presented on a separate
sheet. For the scoring, we followed the same two-step
procedure used in prior studies (Peters & Bjalkebring, 2015;
Schley & Peters, 2014). First, we obtained absolute
deviation from the target length for each question, and
summed across all the absolute deviations. Next, we logtransformed the summed absolute deviation to reduce
positive skew issues, and multiplied by -1 so that a higher
score indicates higher symbolic mapping ability.
The three numeric competency scales were positively
correlated with each other, consistent with the literature
(Table 1), but the correlation was not extremely high. This
indicates that they are related but separable constructs
(Peters & Bjalkebring, 2015).
Table 1: The Correlations Between Numeracy Scales
(***p < .001)

Variable

Experiment 1
1
2

Experiment 2
1
2

1. ONS

-

-

2. SNS

0.41***

-

0.46***

-

3. SMap

0.50***

0.34***

0.32***

0.35***

Anchoring Tasks
For the experimenter-given anchor task, we used the same
eight stimuli used in Study 2 of Brandt et al. (2014) for
Experiment 1, while we used six items used in Jacowitz and
Kahneman (1995) for Experiment 2. For the self-generated
anchor task, we used the six questions used in Epley and
Gilovich (2006). For the valuation task, we used the six
market goods used in previous studies on valuation
anchoring (Ariely et al., 2003; Yoon, Fong, & Dimoka,
2013). An example of each task is presented in Table 2. In
the valuation task, participants were asked to state the
maximum amount they would be willing to pay (WTP). We
calculated individual-level anchor susceptibility with two
procedures: first, we calculated the distance from the given
anchor (anchor distance) and rank-transformed the anchor
distance to correct right skewedness (Brandt et al., 2014;
Klein et al., 2014). After rank-transformation, we rescaled
the score to be within a range from 0 to 1. This rescaled

General Method
Numeracy Measures
For measuring numeric competencies, we used the same
measures and protocol used in Peters and Bjalkebring
(2015). For the objective numeracy scale (ONS), we used an
eight-item scale developed by Weller et al. (2013). An
example of an ONS item is: “If the chance of getting a
disease is 10%, how many people would be expected to get
the disease out of 1,000?” We used the number of correct
answers as a single score for ONS. The Cronbach’s alpha of
Experiment 1 was .74, and that of Experiment 2 was .66.

729

anchor distance was a dependent variable in both
experiments. In Experiment 1, we explicitly presented the
direction of adjustment (e.g., the length of Mississippi River
is longer/shorter than 70 miles), as used in previous studies
on anchor susceptibility (Brandt et al., 2014). In Experiment
2, we used classic anchors in which the direction of
adjustment is uncertain (e.g., do you think the length of
Mississippi River is longer or shorter than 70 miles?), since
it has been shown that anchoring effect is stronger when the
direction of adjustment is uncertain than when it is certain
(Simmons, LeBoeuf, & Nelson, 2010).

Experimenter-Given Anchor Task: We found a significant
anchoring effect: the answer for high anchor questions was
significantly higher than that for low anchor questions (b =
0.16, p < .001). Similar to previous studies (Welsh et al.,
2014), ONS was not associated with anchor distance.
Indeed, the other numeracy scales (SNS and SMap) were
not significantly associated with anchor distance in
experimenter-given anchor task (Table 3, column 1).
Self-Generated Anchor Task: The result shows that ONS is
negatively associated with anchor distance, while SNS and
SMap were not. This implies that participants with higher
score in ONS are more susceptible to self-generated
anchoring (Table 3, column 2).

Table 2: An Example of Experimenter-Given, SelfGenerated, and Valuation Anchor Task

Valuation Task: For the valuation task, similar to previous
valuation tasks, we found a weaker anchoring effect
compared to the experimenter-given anchor task (b = 0.06, p
= .090). The results of hierarchical linear regression analysis
for the effect of numeracy on anchoring effect showed that
ONS and SNS were significantly associated with anchor
distance (positively), while SMap was not (Table 3, column
3). This implies that high ONS and SNS predict lower
anchor susceptibility in valuation task.

Experimenter-Given Anchor Task
What is your best estimate for the length of the Mississippi
River? (low: 70 miles; high: 2,000 miles)
Self-Generated Anchor Task
What is the freezing point of vodka?
(self-generated anchor: 32F, the freezing point of water)
Valuation Task
What is the most you would be willing to pay for this
cordless mouse?

Table 3: Multilevel Regression Results in Experiment 1
(each numeracy scale was run separately)
(* p < .05, ** p < .01, standard errors are in parentheses)

Experiment 1
Methods
Participants: A total of 216 participants (Mage = 35.75, SD =
10.80, Female = 42%) were recruited from Amazon MTurk,
receiving 50 cents in exchange for participating in a 15minute study. Participants were recruited with the criteria
that location is U.S. only, approval rate is greater or equal to
97%, and the number of times approved is greater or equal
to 1,000 times.

ONS

(1)
Experimenter-Given
0.119

(2)
Self-Generated
-0.185**

(3)
Valuation
0.152**

(0.064)

(0.055)

(0.055)

SNS
SMap

Procedure: Participants were randomly assigned to one of
the three conditions: experimenter-given anchor (N = 75),
self-generated anchor (N = 70), or valuation tasks (N = 71).
For experimenter-given anchor and valuation tasks, half of
the questions were given with high anchors, and the other
half was given with low anchors (a within-subject design).
The order was counterbalanced across participants. After
completing anchoring task, participants responded to the
three numeracy tests in a randomized order. At the end of
the study, participants were asked to provide demographic
information (e.g., age and gender). To test the anchoring
effect, we regressed numeric estimates (or WTP) on
anchoring condition (categorical variable, coded 0 for low
anchor and 1 for high anchor) and question fixed effects. To
examine the role of numeracy in anchoring, we used
hierarchical linear regression analysis with random
coefficients for each participant, using Stata 14 software.

N

0.131

-0.145

0.211**

(0.077)

(0.078)

(0.072)

0.170

-0.132

0.038

(0.116)

(0.072)

(0.079)

575

420

374

Discussion
In Experiment 1, we explored the relationships between
three facets of numeric competencies and three types of
anchoring tasks. For the experimenter-given anchor task, we
found a null effect of the three numeracy scales on
anchoring biases. This result is in line with the previous
literature on the role of ONS on anchoring effect (Stanovich
& West, 2008; Welsh et al., 2014). We additionally found
that SNS and SMap are not significant predictors of
anchoring biases. For the self-generated anchor task, ONS
significantly predicted anchor distance, but the direction
was toward self-generated anchor, which indicates higher
anchor susceptibility. This might be due to the fact that high
ONS participants may have considered self-generated

Results

730

anchors more and may have been influenced by selfgenerate anchors, similar to the result of higher decision
bias in the Bets task in Peters and Bjalkebring (2015). Peters
and Bjalkebring (2015) explained that the stronger bias for
high ONS participants in the bets task might be driven by
increased processing of available meaningful numerical
information (comparing $9 gain and losing 5 cents) for the
high ONS participants. We conjecture that more active use
of self-generated anchors by high ONS participants might
contribute to their higher susceptibility to self-generated
anchors. For the valuation task, both ONS and SNS were
positively associated with anchor distance, which indicates
less anchor susceptibility, while SMap was not a significant
predictor of anchor distance.
In Experiment 1, we explicitly specified the direction of
adjustment for the comparison question (anchor) in
experimenter-given and valuation tasks. Simmons et al.
(2010) showed that participants were less susceptible to
anchors when the direction of comparison question is
explicitly specified. Brandt et al. (2014) also showed a
stronger or similar anchoring effect when the direction of
adjustment is uncertain than when it was certain. Moreover,
the directed anchor in valuation task was informative to the
given task (e.g., the market price of the item higher than
$10) by informing participants about market price or by
having participants consider market price of the market
goods used in this study. In Experiment 2, we examined the
role of numeracy in anchoring biases using classic uncertain
direction comparison questions as anchors and employing a
between-subject design for high/low anchors to rule out the
possibility that the results were contributed from the
characteristics of within-subject design.

Self-Generated Anchor Task: Consistent with Experiment
1, only ONS was negatively associated with anchor
distance, while the other two numeracy measures were not
associated with anchor distance (Table 4, column 2). This
result replicates the finding that higher ONS predicts higher
susceptibility to self-generated anchor.
Valuation Task: In Experiment 2, we found a significant
positive effect of anchoring on WTP (b = 0.32, p < .001). In
Experiment 1 where anchor was market price, we found a
marginally significant anchoring effect, while in Experiment
2 where anchoring was their willingness-to-buy for a
random price, we found a significant anchoring effect. This
might imply that providing price information or leading
participants to think about the market price of an item seem
to reduce anchoring effects in valuation tasks. For the effect
of numeracy on anchoring, none of the numeracy measures
were associated with anchor distance (Table 4, column 3).
Table 4: Multilevel Regression Results in Experiment 2
(each numeracy measure was run separately)
(* p < .05, standard errors in parentheses)

ONS

(1)
Experimenter-Given
0.161*

(2)
Self-Generated
-0.196*

(3)
Valuation
-0.020

(0.058)

(0.091)

(0.083)

0.187*

-0.095

0.149

(0.072)

(0.095)

(0.083)

0.071

-0.010

0.158

(0.074)

(0.089)

(0.116)

848

384

788

SNS
SMap

Experiment 2

N

Participants and procedure: A total of 353 (Mage = 35.73,
SD = 11.77, Female: 46%) participants were recruited from
Amazon MTurk with the same recruitment criteria as in
Experiment 1. Overall procedures were similar to
Experiment 1, except that high/low anchor was a betweensubject factor and the direction of adjustment for the anchor
question was not explicitly specified. Therefore, participants
were randomly assigned one of the five conditions:
experimenter-given low anchor (N = 69), experimentergiven high anchor (N = 75), self-generated anchor (N = 64),
valuation low anchor (N = 72), and valuation high anchor (N
= 73).

Discussion
In Experiment 2, we examined the role of three facets of
numeracy on anchoring biases, with an uncertain anchor
where the direction of adjustment was not clear. While
participants generally adjusted their estimates in the
direction specified in the description in Experiment 1,
participants could adjust both higher or lower than a given
anchor in Experiment 2. Previous literature has shown that
anchoring effect is stronger when a comparison question is
uncertain than when the comparison anchor specifies a
certain direction to be adjusted (Brandt et al., 2014;
Simmons et al., 2010). Therefore, in Experiment 2, we tried
to replicate findings in Experiment 1 with a study design
wherein experimenter-given anchor shows stronger effect.
Compared to Experiment 1, we found slightly different
patterns regarding the role of numeracy on anchoring biases.
Consistent with Experiment 1, we found that only ONS
significantly predicted higher susceptibility to selfgenerated anchor. In contrast, we found the opposite pattern
in experimenter-given anchor and valuation tasks. ONS and
SNS significantly predicted lower anchor susceptibility in

Results
Experimenter-Given Anchor Task: We found a significant
anchoring effect (b = 0.58, p < .001): the answer for the
high anchor group was significantly greater than that for the
low anchor group. We found that both ONS and SNS are
positively associated with anchor distance, while SMap was
not (Table 4, column 1). This indicates that high ONS and
SNS participants may be less susceptible to experimentergiven anchor.

731

experimenter-given anchor task, which is inconsistent with
previous studies (Stanovich & West, 2008; Welsh et al.,
2014) and Experiment 1. For the valuation task, unlike
Experiment 1, we did not find significant effects of ONS
and SNS on anchor distance. The results seem to imply that
different types of anchor comparison might interact with
ONS and SNS in experimenter-given anchor and valuation
tasks.

anchor depending on numeracy. Second, we did not find
any association between SMap and the three anchoring
tasks. The main distinctive feature of approximate numeracy
is non-symbolic number-related capability, but the SMap
task we used in this study is involved in symbolic number
processing (mapping symbolic numbers to non-symbolic
magnitudes). Even though SMap is highly correlated with
other types of approximate numeracy tasks (e.g., dotdiscrimination, dot-line, dot-ratio tasks), a recent study
showed that they are separable (Chesney, Bjalkebring, &
Peters, 2015). Future research is needed to test the
relationship between approximate numeracy and anchoring
biases using other approximate numeracy tasks where only
non-symbolic mapping is involved. Indeed, a previous
study showed that higher SMap was associated with a less
concave shape in value function (Schley & Peters, 2014) but
we did not find a significant effect in the valuation task. One
limitation of the valuation task in this study is that the task
was not incentive compatible. Non-incentive compatible
methods might reduce participants’ commitment to the
valuation task. Future research may be required to more
precisely investigate whether SMap moderates the
relationship between anchoring and WTP using incentive
compatible methods as other anchoring valuation studies
used (Ariely et al., 2003; Fudenberg et al., 2012; Yoon et
al., 2013). Indeed, further research is needed to test whether
SMap is associated with other anchoring tasks using
informal math questions (e.g., physical length estimation
(LeBoeuf & Shafir, 2006), or time estimation (Thomas &
Handley, 2008)).

General Discussion
In this study, we examined the distinctive role of three
facets of numeracy (objective, subjective, and symbolic
number mapping) in anchoring biases by conducting two
experiments. In Experiment 1, we examined three different
anchoring tasks with a certain anchor where the direction of
adjustment was explicitly stated, and found that ONS was
associated with higher anchor susceptibility in the selfgenerated anchor task, and was associated with lower
anchor susceptibility in the valuation task. SNS was
associated with lower anchor susceptibility in the valuation
task, but was not associated with the other two anchoring
tasks. Finally, SMap was associated with none of the
anchoring tasks used in this study.
In Experiment 2, we tried to replicate the findings of
Experiment 1 with an uncertain anchor where the direction
of adjustment was not stated. Since previous literature has
shown that the anchoring effect is weaker when the
direction of adjustment is clear (Brandt et al., 2014;
Simmons et al., 2010), to rule out the possibility that the
findings were contributed by the characteristics of the
specified direction of adjustment, we employed the classic
anchoring paradigm where the direction of adjustment is
uncertain. We found the same result for the self-generated
anchor task: only ONS significantly predicted higher
susceptibility to self-generated anchoring, replicating the
findings of Experiment 1. Therefore, we conclude that ONS
is associated with higher anchor susceptibility in selfgenerated anchor tasks. For the other two tasks, however,
we found the opposite patterns. Contrary to Experiment 1,
ONS and SNS significantly predicted lower anchor
susceptibility in the experimenter-given anchor task, while
they did not predict anchor susceptibility in the valuation
task. The conflicting results seem to imply that there could
be a possible interaction between informativeness of an
anchor (e.g., direction of adjustment, market price) and the
two numeracy scales (ONS and SNS). Future research may
be required to clarify the relationship between
informativeness of an anchor and numeracy competencies in
experimenter-given and valuation tasks.
In this study, the results of two experiments showed that
the three different facets of numeracy were associated with
different anchoring tasks, but there are still several
limitations. First, even though we showed that ONS
predicted higher anchor susceptibility to self-generated
anchors, it is not clear that participants actually used the
self-generated anchor in the task. Future research may be
needed to test how actively participants use self-generated

References
Ariely, D., Loewenstein, G., & Prelec, D. (2003). "Coherent
arbitrariness": Stable demand curves without stable
preferences. Quarterly Journal of Economics, 118(1), 73105. doi:Doi 10.1162/00335530360535153
Bennett, G. K., Seashore, H. G., & Wesman, A. G. (1947).
Differential Aptitude Tests.
Bergman, O., Ellingsen, T., Johannesson, M., & Svensson,
C. (2010). Anchoring and cognitive ability. Economics
Letters, 107(1), 66-68.
Bodenhausen, G. V., Gabriel, S., & Lineberger, M. (2000).
Sadness and susceptibility to judgmental bias: The case of
anchoring. Psychological Science, 11(4), 320-323.
Brandt, M. J., Evans, A. M., & Crawford, J. T. (2014). The
unthinking or confident extremist? Political extremists are
more likely than moderates to reject experimentergenerated
anchors.
Psychological
Science,
0956797614559730.
Burns, W. J., Peters, E., & Slovic, P. (2012). Risk
perception and the economic crisis: a longitudinal study
of the trajectory of perceived risk. Risk Analysis, 32(4),
659-677.
Chesney, D., Bjalkebring, P., & Peters, E. (2015). How to
estimate how well people estimate: Evaluating measures
of individual differences in the approximate number

732

system. Attention, Perception, & Psychophysics, 77(8),
2781-2802.
Dieckmann, N. F., Slovic, P., & Peters, E. M. (2009). The
use of narrative evidence and explicit likelihood by
decisionmakers varying in numeracy. Risk Analysis,
29(10), 1473-1488.
Epley, N., & Gilovich, T. (2001). Putting adjustment back
in the anchoring and adjustment heuristic: Differential
processing of self-generated and experimenter-provided
anchors. Psychological Science, 12(5), 391-396.
Epley, N., & Gilovich, T. (2005). When effortful thinking
influences judgmental anchoring: differential effects of
forewarning and incentives on self-generated and
externally provided anchors. Journal of Behavioral
Decision Making, 18(3), 199-212.
Epley, N., & Gilovich, T. (2006). The anchoring-andadjustment heuristic Why the adjustments are insufficient.
Psychological Science, 17(4), 311-318.
Fagerlin, A., Zikmund-Fisher, B. J., Ubel, P. A., Jankovic,
A., Derry, H. A., & Smith, D. M. (2007). Measuring
numeracy without a math test: development of the
Subjective Numeracy Scale. Medical Decision Making,
27(5), 672-680.
Fudenberg, D., Levine, D. K., & Maniadis, Z. (2012). On
the robustness of anchoring effects in WTP and WTA
experiments.
American
Economic
Journal:
Microeconomics, 4(2), 131-145.
Furnham, A., Boo, H. C., & McClelland, A. (2012).
Individual differences and the susceptibility to the
influence of anchoring cues. Journal of Individual
Differences, 33(2), 89.
Jacowitz, K. E., & Kahneman, D. (1995). Measures of
anchoring in estimation tasks. Personality and Social
Psychology Bulletin, 21, 1161-1166.
Klein, R., Ratliff, K., Vianello, M., Adams Jr, R., Bahník,
Š., Bernstein, M., & Nosek, B. (2014). Investigating
variation in replicability: The “many labs” replication
project. Retrieved from Open Science Framework.
LeBoeuf, R. A., & Shafir, E. (2006). The long and short of
it: Physical anchoring effects. Journal of Behavioral
Decision Making, 19(4), 393-406.
Liberali, J. M., Reyna, V. F., Furlan, S., Stein, L. M., &
Pardo, S. T. (2012). Individual differences in numeracy
and cognitive reflection, with implications for biases and
fallacies in probability judgment. Journal of Behavioral
Decision Making, 25(4), 361-381.
Maniadis, Z., Tufano, F., & List, J. A. (2014). One Swallow
Doesn't Make a Summer: New Evidence on Anchoring
Effects. The American Economic Review, 104(1), 277290.
McElroy, T., & Dowd, K. (2007). Susceptibility to
anchoring
effects:
How
openness-to-experience
influences responses to anchoring cues. Judgment and
Decision Making, 2(1), 48-53.
Miron-Shatz, T., Hanoch, Y., Doniger, G. M., Omer, Z. B.,
& Ozanne, E. M. (2014). Subjective but not objective
numeracy influences willingness to pay for BRCA1/2

genetic testing. Judgment and Decision Making, 9(2),
152-158.
Oechssler, J., Roider, A., & Schmitz, P. W. (2009).
Cognitive abilities and behavioral biases. Journal of
Economic Behavior & Organization, 72(1), 147-152.
Peters, E. (2012). Beyond comprehension the role of
numeracy in judgments and decisions. Current Directions
in Psychological Science, 21(1), 31-35.
Peters, E., & Bjalkebring, P. (2015). Multiple numeric
competencies: When a number is not just a number.
Journal of personality and social psychology, 108(5),
802.
Schley, D. R., & Peters, E. (2014). Assessing “economic
value” Symbolic-number mappings predict risky and
riskless
valuations.
Psychological
Science,
0956797613515485.
Simmons, J. P., LeBoeuf, R. A., & Nelson, L. D. (2010).
The effect of accuracy motivation on anchoring and
adjustment: do people adjust from provided anchors?
Journal of personality and social psychology, 99(6), 917.
Stanovich, K. E., & West, R. F. (2008). On the relative
independence of thinking biases and cognitive ability.
Journal of personality and social psychology, 94(4), 672.
Thomas, K. E., & Handley, S. J. (2008). Anchoring in time
estimation. Acta Psychol (Amst), 127(1), 24-29.
Tversky, A., & Kahneman, D. (1974). Judgment under
uncertainty: Heuristics and biases. science, 185(4157),
1124-1131.
Weller, J. A., Dieckmann, N. F., Tusler, M., Mertz, C.,
Burns, W. J., & Peters, E. (2013). Development and
testing of an abbreviated numeracy scale: A Rasch
analysis approach. Journal of Behavioral Decision
Making, 26(2), 198-212.
Welsh, M. B., Delfabbro, P. H., Burns, N. R., & Begg, S. H.
(2014). Individual differences in anchoring: Traits and
experience. Learning and Individual Differences, 29, 131140.
Wilson, T. D., Houston, C. E., Etling, K. M., & Brekke, N.
(1996). A new look at anchoring effects: basic anchoring
and its antecedents. Journal of Experimental Psychology:
General, 125(4), 387.
Yoon, S., Fong, N. M., & Dimoka, A. (2013). The
Robustness of Anchoring Effects on Market Good
Valuations. Available at SSRN 2352692.

733

