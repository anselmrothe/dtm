Analogical Generalization and Retrieval for Denominal Verb Interpretation
Clifton J. McFate (c-mcfate@northwestern.edu)
Qualitative Reasoning Group, EECS Department, 2133 Sheridan Road
Evanston, IL 60208 USA

Kenneth D. Forbus (forbus@northwestern.edu)
Qualitative Reasoning Group, EECS Department, 2133 Sheridan Road
Evanston, IL 60208 USA

Abstract
The creativity of natural language poses a significant
theoretical problem. One example of this is denominal verbs
(those derived from nouns) such as spoon in “She spooned me
some sugar”. Traditional generative approaches typically
posit a unique entry in the lexicon for this usage, though this
approach has difficulty scaling. Construction Grammar has
evolved as a competing theory which instead allows the
syntactic form of the sentence itself to contribute semantic
meaning. However, how people learn syntactic constructions
remains an open question. One suggestion has been that they
are learned through analogical generalization. We evaluate
this hypothesis using a computational model of analogical
generalization to simulate Kaschak and Glenberg’s (2000)
study regarding interpretation of denominal verbs.
Keywords: Analogy; Construction Grammar; Linguistics;
Analogical Generalization

Introduction
Linguistic creativity poses a theoretical problem for models
of language learning and representation. One example of
this is the use of denominal verbs (Clark & Clark, 1979) e.g.
1) a. She spooned me some sugar.
b. The neighbor hosed the patio clean.
English speakers can easily interpret 1a as a transfer event
involving sugar (with the spoon as instrument). Similarly 1b
describes using the hose to wash a patio. How do we reach
these interpretations? In many conventional theories the
semantics of the sentence would be driven by the main verb.
However, as Clark and Clark’s (1979) analysis shows, the
semantics of denominal verbs are highly context sensitive,
and it certainly seems odd that spoon would independently
have a transfer meaning in our lexicon. Construction
grammar approaches present an alternative solution to this
problem—that the interpretations are grounded in the
argument structure itself (Goldberg, 2003).
Construction grammar proposes that the building blocks
of language are constructions, pairings of form and meaning
which are hierarchical and vary in both complexity and
degree of fixedness. A morpheme is a kind of construction,
as is the double-object (NP-V-NP-NP) pattern in 1a or the
partially filled idiom “Jog X’s memory” (Goldberg 2003).
An expression is a combination of non-contradictory
constructions. In 1a, each of the NPs ‘she’, ‘me’, and ‘some
sugar’ is an NP construction. They combine with the
double-object construction (exemplified in 1) that specifies
each NP’s location and role. A construction can also specify

general semantic meaning. For example, the double-object
construction is associated with transfer events (Goldberg,
2003). With construction grammar, we don’t need spoon to
have a new lexical entry. Instead, the double-object
construction imposes its meaning on the denominal verb.
Kaschak and Glenberg (2000) investigated how people
interpret novel denominal verbs and found that, consistent
with a constructionist approach, participants were sensitive
to argument structure differences when interpreting textual
entailment and selecting a meaning for the novel verbs.
Specifically, participants were more likely to attribute a
transfer interpretation to a double-object construction (like
that in 1a). However, a significant unanswered question is
how humans acquire and represent such constructions.
One proposal is that children use analogy processes to
generalize abstract constructions from item-based examples
(Tomasello, 2003). Under this account, language learners
would map the structural form and communicative function
of an utterance to other examples, thus gradually abstracting
away individual features. The generalization associates a
semantic function with the linguistic form and could be used
to interpret novel verbs appearing in the same context.
Our goal is to provide computational evidence for the idea
that analogical generalization and retrieval could result in
constructions accounting for Kaschak and Glenberg’s
denominal interpretations. We evaluate this using SAGE
(Mclure et al, 2015), a computational model of analogical
generalization based on Gentner’s (1983) structure-mapping
theory. Using a computational model further allows us to
investigate precisely what kinds of representations are
needed for successful generalization.
We train SAGE over a small corpus of annotated
sentences and use MAC/FAC, a model of analogical
retrieval, to retrieve and apply the learned constructions to
Kaschack & Glenberg’s stimuli. For our semantic
representation we use Fillmore et al’s (2001) FrameNet, a
frame-semantic resource for English. The result is a
semantic role assignment that we can evaluate as consistent
with either a transfer or transitive interpretation.

Background
Construction Grammar
Recently, several different constructionist approaches
have emerged (e.g. Boas and Saag, 2012; Steels, 2011).

1277

However, as Goldberg (2003) summarizes they generally
have a few core principles in common.
One principle is that construction grammar allows
argument structure to contribute semantic meaning. Also
unlike generative approaches (e.g. Chomsky, 1981),
differing syntactic expressions are not derived from
underlying deep structures; rather each surface form is its
own instantiation of a set of constructions.
Constructionist approaches have been especially useful in
explaining more idiomatic constructions such as the
comparative-correlative (‘The X-er, The Y-er) as in “The
bigger they are, the harder they fall” (Cullicover &
Jackendoff, 1999). Here, the structure of the sentence
provides extra semantic meaning beyond that provided by
the head verb. It is enriched but not derived from the verb.
Perhaps most importantly, constructionist approaches
view constructions as learnable using general cognitive
mechanisms on the basis of input from the environment
(Goldberg, 2003). There is no universal grammar (e.g.
Chomsky, 1981; Lidz et al, 2003) Thus, a constructionist
account naturally predicts piece-meal acquisition of
language such that a child’s early utterances are those that
occur in its linguistic environment. There is considerable
evidence for this pattern. For example, Rowland and Pine
(2000) found that subject-auxiliary inversion errors in a
child’s speech were mostly specific to individual wh-word
auxiliary pairs, and that the pairs the child produced
correctly were those that occurred more frequently in the
input. Similarly, Theakston et al (2001) found that
children’s usage of a verb in a transitive or intransitive
construction was predictable based on how frequently the
verb appeared in that construction in the mother’s speech.
More evidence of item-specific learning comes from
Akhtar and Tomasello (1997) who found that older children
(3;8) were able to use a transitive construction to interpret
agent and patient roles for a novel verb while younger
children (2;9) generally could not. However, both groups
demonstrated understanding of transitive commands with
known verbs. The older children had generalized a
productive transitive construction while the younger
children’s understanding was verb specific.
However, if children’s early language centers around
item-based constructions, then an important question is how
they develop more abstract syntactic knowledge.

Analogical Generalization
Analogy has been proposed as a mechanism for language
learning and more specifically for generalizing from itembased constructions (Gentner & Namy 2006; Tomasello,
2003). There is abundant evidence that comparison
facilitates language learning and relational extraction.
Christie & Gentner (2010) found that comparison
significantly improved relational abstraction in children
when extending novel spatial labels to new situations.
Further, Namy & Gentner (2002) found that common labels
can invite comparison, facilitating the formation of

categories based on relational rather than perceptual
similarities.
Gentner’s (1983) structure-mapping theory proposes that
the process of comparison consists of aligning structured
relational representations. The process is guided by
constraints which prohibit many-to-one matches between
entities and require matching parent relationships to have
matching children. Further, structure-mapping proposes a
bias towards systematicity, i.e. that people will prefer
mappings that preserve higher-order (e.g. causal) structure.
This preference has been demonstrated in humans with both
match selection and prediction tasks (Clement & Gentner,
1991). Structure-mapping forms the theoretical basis for our
model of analogical generalization. Forbus et al’s (2016)
structure-mapping engine (SME) is a computational
implementation of structure-mapping.
Our computational model of analogical generalization,
SAGE (Mclure et al, 2015), is built on top of SME. SAGE
operates over sets of predicate calculus representations
called cases. Given a new (probe) case and a library of
known cases, SAGE compares the case to ones in the library
using a two-stage retrieval model, MAC/FAC (Forbus et al,
1995). The first stage compares flat feature-vector
representations of the probe and case-library cases. While
fast, this stage doesn’t take into account structural
similarity. The second stage operates over cases selected in
the first phase and compares them using SME.
If the structural similarity score provided by SME is
above a defined threshold 1, the new example will be
combined with the retrieved case to create a generalization
with a probability distribution governing features of the
matched entities. Future examples can be added to the
generalization or combine with other singletons to form a
new generalization. If dissimilar to all, they join the case
library as an ungeneralized example. Figure 1 shows the
generalization process using representations from our
experiment.
SAGE has been used in tasks such as learning concepts
from maps (Mclure et al, 2015). Additionally, SAGE
models a phenomenon from the analogy literature called
progressive alignment, whereby highly-alignable cases pave
the way for understanding less similar pairs, (Kotovsky and
Gentner 1996; Kandaswamy et al, 2014).
There is evidence that progressive alignment contributes
to language development. For example, Goldwater et al
(2011) proposed a structure-mapping account of children’s
construction learning, as assessed by their syntactic priming
(that is, by whether and to what extent they can re-use the
syntactic form of a just-heard utterance when framing a new
utterance). Goldwater et al. (2011) found that both 4- and 5yr-old children showed syntactic priming, but (in keeping
with our earlier discussion) 4-yr-olds were more concrete—
the target had to be highly similar to the prime in order for
them to show priming. Goldwater and Echols (2014) further
1

An assimilation threshold of 1.0 means perfect identity would
be required to merge, whereas a threshold of 0.0 means any two
descriptions will be merged.

1278

found that 4-yr-olds primed with high-similar sentences
could go on to show priming from less similar sentences—
evidence for progressive alignment in learning constructions
(See also Childers & Tomasello, 2001).

1. Lyn crutched Tom her apple so he wouldn’t starve.
(double-object form)
2. Lyn crutched her apple so Tom wouldn’t starve.
(transitive form)
Figure 2: Example from Kaschak and Glenberg (2000)
In a second task, participants were shown each sentence
independently and asked which of a pair of meanings e.g.
“to act on using a crutch” or “to transfer using a crutch” best
fit the denominal verb. If they were influenced by the
argument structure, then they should select the transfer
meaning for the double-object construction.
Participants in the meaning-choice task showed a weaker
though still significant preference for the transfer definition
when presented with the double-object construction (61%
following double-object vs 42% following a transitive).
Our simulation models the semantic classification of
transfer vs transitive action. We trained SAGE on example
sentences annotated with semantic frames and roles. For
each double-object example from Kaschak and Glenberg
(2000), the simulation should assign semantic roles
consistent with a transfer frame. For each transitive
example, it should label it with a transitive frame. Kaschak
& Glenberg further claim that the full semantic meaning of
the sentence is based on the affordances of the noun the
denominal came from, a claim we do not examine.

Figure 1: SAGE Generalization
Double-object sentences 1 and 2 are compared using SME. Since
their similarity score is above threshold, their shared structure
(semantic roles and phrase structure) is abstracted into a
generalization with a probability distribution governing their
variable features. Sentence 3, an imperative, is compared using
MAC/FAC, but lacks a Donor FE and its Theme FE is in object
position. It becomes an ungeneralized example.

Representations and Materials

Experiment
The first goal of the experiment is to evaluate whether
analogical generalization can result in argument-structure
constructions. The second is to evaluate whether these
constructions can be used to interpret denominal verbs
through analogical retrieval.

Simulation Target
Our target for simulation is the first experiment from
Kaschak and Glenberg (2000). In Experiment 1, participants
were presented with pairs of sentences (e.g. Figure 2)
headed by either a conventional verb or a novel denominal
verb. One was a double-object construction while the other
was a transitive construction. Each also had an additional
Purpose argument. This ensured both examples had the
same number of entities, so readers must rely on structure.
Participants were evaluated on one of two tasks. In Task
1, participants were presented with one of two inferences.
One was consistent with a transfer interpretation and the
other a transitive action e.g. “Tom got the apple” vs “Lyn
acted on the apple”. They were then asked which example
most strongly implied the inference. If they were influenced
by the argument structure, then they should choose the
double-object sentence for the transfer inference. In the
inference task, participants overwhelmingly chose the
double-object construction for transfer inferences (92% for
conventional verbs and 80% for novel denominals).

We use Fillmore et al’s (2001) FrameNet as our semantic
representation. FrameNet defines frames that relate an
evoking lexical item and its dependent structures to roles in
a semantic description. For example, the word Give evokes
the Giving frame which includes required an optional roles
(frame elements) such as a Donor and Recipient. The
realization of frame elements in a construction is called a
valence pattern. Consider example (2) below:
2) I saw John give the teacher the apple.
With give as the target, the NP “John” would be annotated
as the Donor of a giving frame. The NP, “the teacher”,
would be the Recipient, and “the apple” would be the
Theme. This annotation format only identifies the arguments
to the target, ignoring other aspects of the sentence.
The training set was created by manually annotating 21
sentences from a 6th grade reading comprehension
workbook (Spectrum, 2007). Each training case consisted of
a sentence and predicate calculus representations of its
target verb, the arguments to that verb, their positions, their
roles, and the words in each argument. For sentence 2, the
first NP would be represented as follows:
(isa NP1 NP)
(FE-Donor “give” NP1)
(wordMemberOf NP1 “John”)
(loc1 sentence1 NP1)

The test set was created by automatically chunking the
stimuli from Kaschak and Glenberg (2005) into its valence
pattern phrases using regular expressions. Each phrase was

1279

labeled with its phrase type as above, but no information
about the evoked frame or the frame element was given. All
20 double-object examples from their experiment were
used. We discarded one transitive example because its
additional argument was not the same form as the rest of the
examples. Thus, our total test set consisted of 39 examples.

Procedure
In the training phase, SAGE was given each of the training
stimuli as an individual case for generalization (see Figure
1). The generalization threshold was set to .8. The training
set consisted of nine sentences that evoked Giving. Seven
examples were inheritors of the Transitive_action
frame (e.g. Cause_motion) and four were distractor
Motion frames. The training examples covered a wide
range of constructions including examples with several
prepositional attachments. Of the nine Transfer
sentences, only two illustrated the double-object in
isolation. Six examples included an additional argument.
A hallmark of SAGE is its sensitivity to the order of the
training stimuli, demonstrating progressive alignment. We
first evaluated the model with a hand-made progressive
alignment training order (PA-ordered) that clustered similar
constructions and then with randomly generated orders.
In the evaluation phase, each example from our test set
was used as a probe for analogical retrieval using
MAC/FAC over the learned case-library. The top-scoring
response is compared to the probe using SME. Structures in
the base that are missing in the target are hypothesized as
candidate inferences. These candidate inferences are the
model’s interpretation of the incoming sentence. This is
shown in Figure 3.

Figure 3: Retrieval and Interpretation of stimuli

Results
The results were evaluated based on the candidate
inferences generated by the retrieval process. For the 20
double-object examples, a response was counted correct if it
both correctly identified the frame-type of the verb (e.g.
crutched = Giving) and if it correctly labeled the 3 NPs as
Donor, Recipient, and Theme. This corresponds to a
double-object response in Kaschak and Glenberg (2000). An

interpretation was judged incorrect if it over-assigned the
three FEs which could happen if the double-object and
prepositional ditransitives formed a single generalization.
For the transitive stimuli, we counted the interpretation
correct if it chose an inheritor of transitive_action or a
generalization containing only those inheritors. Generic
non-transitive motion, for example, was incorrect. We did
not evaluate the specific frame elements because a generic
transitive action such as “Lyn acted on the apple” could be
consistent with many different types of transitive action and
the FEs vary across FN frames.
We compared to two baselines. The first was a random
baseline. For each example, we assume a random baseline
system that could label it Transfer, Transitive, or other
(corresponding to the Motion distractors). Thus it would
have a 1/3 chance of classifying the frame-type correctly.
For transfer classifications, it would further have to assign
each FE correctly (1/6 at random). Thus for the 19
transitives a random system would have a 1/3 chance of
being correct. For the 20 transfer examples, random
guessing would have a 1/18 chance of being correct. This
gives a random baseline an overall mean of 7.4 (19%). The
second was a baseline of guessing Transitive for each
example. Under our evaluation measure, this would result in
19 correct answers (49%). We call these the random and
choose-transitive baseline.
PA-Ordered Training Set:
On 19 out of 20 examples, the model correctly interpreted
the verb as evoking a Giving frame and correctly assigned
all frame elements (Donor, Recipient, Theme).
On the transitive examples, the model correctly
interpreted the event as non-transfer in 18 out of 19
examples. This gives us a total of 37 out of 39 (95%).
With a single manually determined training order, the
model is deterministic—there is no variance. Our model
significantly out-performs the expected performance of the
random baseline (P < .05). It is larger than the static choosetransitive baseline and thus out-performs that as well.
Random Training Orders:
We also evaluated our model using randomized training
orders. Across 25 trials using random orders, the mean total
correct dropped to 26.88 (68.9%). The double-object stimuli
were most affected, dropping to a mean accuracy of 9.96.
The max total accuracy across all 25 trials was 37 (95%)
correct with 19 correct double-object classifications. The
minimum accuracy was 19 (49%) correct classifications,
with only 4 correct double-object classifications.
A one-sample t-test demonstrated that the random order
mean was a significant improvement over the random
baseline t(24) = 16.05 P < .05. Its performance was also a
significant improvement compared to the choose-transitive
baseline t(24) = 6.49 P < .05.
Generalizations:
We manually inspected the generalizations produced by the
model trained on hand-ordered stimuli. SAGE produced
four generalizations. One was the simple double-object
construction. Another contained two of the double-object

1280

constructions with an additional modifier. The next
contained two simple cause_motion transitive sentences
and the final generalization contained two examples of
transitive actions with an additional argument.
Without phrase labels:
We also evaluated performance without phrase type labels.
Instead, the probe included the arguments to the verbs as
unlabeled ‘chunks’. The model was trained with the handordering. In this condition the model correctly identified the
Giving frame but consistently inferred a double-PP pattern,
thus misaligning FEs. Without labels, it essentially only
operates over the number of chunks and their size which
isn’t enough to distinguish between examples.

Discussion
After training, the model successfully applied the transfer
and transitive semantics to the novel denominal verbs. The
results of this model therefore support the claim that
analogical generalization could be a mechanism for
generalization and application of linguistic constructions.
As predicted, receiving the examples in progressive
alignment order led to the best results. This is consistent
with the progressive alignment phenomenon seen in human
learning. Indeed, the linguistic environment itself may
facilitate this kind of learning, as Cameron-Faulkner et al
(2003) found that 51% of child-directed speech began with
one of 52 constructions, and 45% began with one of
seventeen words. Future work demonstrating progressive
alignment in language learning would support our model.
We may predict that sequential comparison of canonical
verbs would improve performance on the novel denominals.
Kaschak & Glenberg (2005) do not evaluate this.
The model makes several representational assumptions.
First, we assume that humans are able to chunk sentences
into arguments for a target verb. We don’t claim that these
representations are part of a particular larger parse structure
nor do we endorse a specific account of how humans form
these arguments. Going from raw input to preliminary
structures will be a significant focus of future work.
Our results also suggest the importance of both chunking
a sentence into arguments and classifying sentence chunks.
Without phrase-labels, performance dramatically decreased.
One option is to include classification as a part of the
chunking process. A two-phase model could use analogy to
infer chunks from low-level features such as word order or
dependency parse information.

Related Work
Semantic role labeling has been an active area of research
in computational linguistics, though open-domain semantic
parsing remains elusive. An example is Das et al’s (2014)
statistical SEMAFOR parser. Ovchinnikova’s (2012)
statistical abduction system additionally uses a knowledgebase extracted from WordNet and FrameNet. However,
none of these systems focus on constructions. As far as we
know, our model is the first use of a cognitive simulation to
evaluate the analogical account of construction learning.

Connor et al’s (2008) Baby SRL system classified
transitive agent and patient arguments using a linear
classifier trained over a corpus of child directed speech.
They investigated the theory that children use the number of
nouns as a heuristic for classification, and replicated child
performance including over-generalization errors. Adding a
feature for verb position greatly improved performance.
Baby SRL targets a simpler construction and uses a wordlevel representation, but they propose that the approach
could be extended to use phrases. A fundamental difference
between our approaches is that SAGE produces
classifications for each phrase jointly (candidate inference),
while theirs labels independently. This should affect error
patterns, with independent labeling more likely to assign the
same roles to multiple arguments. Furthermore, a linear
classifier would not generally model progressive alignment.
Solan et al (2004) propose an incremental unsupervised
algorithm which represents sentences as paths through a
word-graph and identifies classes of equivalent words and
patterns. Their model trained over a corpus of child directed
speech and demonstrated intermediate performance on a 9thgrade ESL proficiency test. They did not include semantic
roles as is necessary for our task. A benefit of their approach
is that constructions are learned hierarchically, where we
currently learn a generalization for each valence pattern.
One direction for future work could use hierarchical models
of analogical generalization (Liang & Forbus, 2014).
Bergen, Chang, & Narayan (2000) propose Embodied
Construction Grammar (ECG) in which constructions link
linguistic form to conceptual schemas used to specify
parameters for simulation. The simulation generates
inference and prompts response. Their conceptual schemas
are similar to our frames in specifying a predicate-argument
mapping, though constructions in ECG also contribute
additional simulation parameters such as perspective. While
we don’t incorporate simulation into our model of
semantics, analogical generalization could support learning
of ECG’s conceptual-schemas.
Finally, Steels’ (2011) Fluid Construction Grammar is a
construction grammar formalism that was designed for work
on human-robot interaction, though not necessarily as a
cognitive model.

Conclusion & Future Work
Humans must adapt to an ever-shifting linguistic landscape.
Constructionist accounts of language facilitate this by
pairing semantic meaning and syntactic surface forms.
Furthermore, constructionist theories view language as
learnable using general cognitive abilities. We examine
whether analogy could be a mechanism used in both the
generalization of constructions and their application. We
simulated experiment 1 of Kaschak and Glenberg’s (2000)
denominal verb study using a computational model of
analogical generalization and retrieval, SAGE, which
allowed for inspections of and concrete hypotheses about
the representations used in construction building. Our model
produced correct transitive and ditransitive semantics,

1281

supporting the role of analogy in language learning.
Much remains to be done. We explored only a handful of
English constructions. Future work will focus on modeling
other linguistic studies as well as applying these techniques
to larger-scale problems. Finally, our system currently treats
phrase-level chunking as a black box. Future work will
involve building these representations from the ground up.

References
Akhtar, N., & Tomasello, M. (1997). Young children's
productivity with word order and verb morphology.
Developmental psychology, 33(6), 952.
Bergen, B., Chang, N., & Narayan, S. (2004). Simulated
action in an embodied construction grammar. In Proc.
26th Conference of the Cognitive Science Society.
Boas, H. & Saag, I, (Eds.) 2012. Sign Based Construction
Grammar. Stanford, CA: CSLI Publications.
Cameron-Faulkner, T., Lieven, E., & Tomasello, M. (2003).
A construction based analysis of child directed speech.
Cognitive Science, 27(6), 843-873.
Connor, M., Gertner, Y., Fisher, C., & Roth, D. (2008).
Baby SRL: Modeling early language acquisition. In Proc.
12th Conference on Computational Natural Language
Learning.
Culicover, P.W. & Jackendoff, R. (1999) The view from the
periphery: the English comparative correlative. Linguist.
Inq. 30, 543–571
Childers, J., & Tomasello, M. (2001). The role of pronouns
in young children’s acquisition of the English transitive
construction. Developmental Psychology, 37, 730–748.
Chomsky, Noam. 1981. Lectures on Government and
Binding. Dordrecht:Foris.
Christie, S. & Gentner, D. (2010). Where hypotheses come
from: Learning new relations by structural alignment.
Journal of Cognition and Development, 11 (3). 356-373.
Clark, E. V., & Clark, H. H. (1979). When nouns surface as
verbs. Language, 767-811.
Clement, C. A., & Gentner, D. (1991). Systematicity as a
selection constraint in analogical mapping. Cognitive
Science, 15, 89-132.
Das, D., Chen, D., Martins, A. F., Schneider, N., & Smith,
N. A. (2014). Frame-semantic parsing. Computational
Linguistics, 40(1), 9-56.
Forbus, K., Ferguson, R., Lovett, A., & Gentner, D. (2016).
Extending SME to handle large-scale cognitive modeling.
Cognitive Science.
Fillmore, C. J., Wooters, C., & Baker, C. F. (2001).
Building a Large Lexical Databank Which Provides Deep
Semantics. Proceedings of PACLIC-2001.
Forbus, K., Gentner, D. and Law, K. (April-June, 1995).
MAC/FAC: A model of Similarity-based Retrieval.
Cognitive Science, 19(2), 141-205.
Gentner, D. (1983). Structure-mapping: A theoretical
framework for analogy. Cognitive science, 7(2), 155-170.
Gentner, D. & Namy, L. L. (2006). Analogical processes in
language learning. Current Directions in Psychological
Science, 15(6), 297-301.

Goldberg, A. E. (2003). Constructions: a new theoretical
approach to language. Trends in cognitive sciences, 7(5),
219-224.
Goldwater, M.B., & Echols, C. H. (2014) Structural priming
as analogical mapping. Presented at the 13th ICSCL,
Amsterdam.
Goldwater, M., Tomlinson, M., Love, B., Echols, C. (2011).
Structural priming as structure-mapping: Young children
use analogies from previous utterances to guide sentence
production. Cognitive Science, 35(1), 156-170.
Kaschak, M. P., & Glenberg, A. M. (2000). Constructing
meaning: The role of affordances and grammatical
constructions in sentence comprehension. Journal of
memory and language, 43(3), 508-529.
Kotovsky, L., & Gentner, D. (1996). Comparison and
categorization in the development of relational similarity.
Child Development, 67, 2797-2822.
Liang, C. and Forbus, K. (2014). Constructing Hierarchical
Concepts via Analogical Generalization. In Proc. 36th
Conference of the Cognitive Science Society.
Lidz, J., Gleitman, H., & Gleitman, L. (2003).
Understanding how input matters: Verb learning and the
footprint of universal grammar. Cognition, 87(3), 151178.
McLure, M.D., Friedman S.E. and Forbus, K.D. (2015).
Extending Analogical Generalization with Near-Misses.
In Proc. 29th AAAI Conference on Artificial Intelligence.
Namy, L. L,. & Gentner, D. (2002). Making a silk purse out
of two sow's ears: Young children's use of comparison in
category learning. Journal of Experimental Psychology:
General, 131, 5-15.
Ovchinnikova, E. 2012. Integration of World Knowledge
for Natural Language Understanding. Atlantis Press,
Springer.
Rowland, C. F., & Pine, J. M. (2000). Subject–auxiliary
inversion errors and wh-question acquisition: ‘What
children do know?’. J. Child Language, 27(01), 157-181.
Solan, Z., Horn, D., Ruppin, E., & Edelman, S. (2003).
Unsupervised context sensitive language acquisition from
a large corpus. In Advances in Neural Information
Processing Systems,
Spectrum. (2007) Spectrum Reading Grade 6. School
Specialty Publishing. Columbus, OH.
Steels, L. (Ed.). (2011). Design patterns in fluid
construction grammar (Vol. 11). John Benjamins
Publishing.
Taylor, J. L. M., Friedman, S. E., Forbus, K. D., Goldwater,
M. and Gentner, D. (2011). Modeling structural priming
in sentence production via analogical processes. In Proc.
33rd Annual Conference of the Cognitive Science Society.
Theakston, A., Lieven, E., Pine, J., and Rowland, C. 2001.
The role of performance limitations in the acquisition of
verb argument structure. J.Child Language 28, 127–152.
Tomasello, M. (2003). Constructing a language: A usagebased theory of language acquisition. Harvard University
Press.

1282

