Varieties of experience: A new look at folk philosophy of mind
Kara Weisman
(kweisman@stanford.edu)

Carol S. Dweck
(dweck@stanford.edu)

Ellen M. Markman
(markman@stanford.edu)

Department of Psychology
Stanford University

Department of Psychology
Stanford University

Department of Psychology
Stanford University

Abstract
Philosophers, psychologists, and neuroscientists have often
divided the mind into fundamental component parts. Does this
intuition carry over into folk philosophy of mind? In a series
of large-scale studies, we explore intuitive distinctions among
different kinds of mental phenomena and consider how these
distinctions might organize the conceptual space of the
diverse “intelligent” and “social” entities in the modern
world. Across studies, independent exploratory factor
analyses reveal a common latent structure underlying mental
capacity attributions, centered on three types of phenomenal
experiences: physiological experiences of biological needs
(e.g., hunger, pain); social-emotional experiences of self- and
other-relevant emotions (e.g., guilt, pride); and perceptualcognitive abilities to detect and use information about the
environment (e.g., hearing, memory). We argue for an
expanded model of folk philosophy of mind that goes beyond
agency and experience (H. M. Gray, Gray, & Wegner, 2007)
to make basic and important distinctions among different
varieties of experience.
Keywords: mind perception; folk theories; sentience.

Introduction
The ontology of the mind or soul has been a topic of great
interest to humankind, from ancient philosophers to modern
neuroscientists. In Plato’s Republic, Socrates argued for a
tripartite division of the soul into reason, spirit, and appetite,
while Aristotle, in De Anima, posited four faculties of the
soul: nutrition, perception, mind, and desires. Half a world
away, the Buddha described sentient beings as aggregations
of five components: material form, feelings, perceptions,
impulses, and consciousness. Over two millennia later, the
tradition continues, from Freud’s model of the human
psyche as composed of id, ego, and superego, to ongoing
attempts to derive data-driven “cognitive ontologies” from
neural activity (Hastings, et al., 2014). Does the intuition
that the mind is composed of distinct parts carry over into
folk philosophy of mind? Here, we set aside questions about
the true organization of the mind to explore how lay people
conceptualize mental capacities and mental life.
Many converging traditions in psychology and philosophy
suggest that folk philosophy of mind might include a broad
distinction between internal experiences and behavioral
outputs (e.g., Gelman & Spelke, 1981; Knobe & Prinz,
2008). In an influential investigation of folk philosophy of
mind, Gray, Gray, and Wegner (2007) conducted a large
survey in which participants compared the relative mental
capacities of various characters (e.g., a frog vs. a robot; a
man vs. God). Participants’ judgments of capacities for
hunger, fear, pain, pleasure, rage, desire, personality,

consciousness, pride, embarrassment, and joy covaried,
forming a dimension that Gray et al. termed experience.
Judgments of self-control, morality, memory, emotion
recognition, planning, communication, and thought also
hung together; they termed this second dimension agency.
Gray et al. proposed that these two dimensions—experience
and agency—organize people’s understanding of different
kinds of minds, playing a particularly important role in the
identification of moral patients (capable of experience and
therefore vulnerable to harm) and moral agents (capable of
intentional behavior and therefore responsible for their
actions).
However, we suspect that there is more to the lay
ontology of mind than broad categories of experience and
agency—particularly in light of Gray et al.’s (2007)
untraditional analytical approach. In preparing their data for
dimension reduction, the authors collapsed across many
paired comparisons to estimate (non-independent) scores for
13 target characters on 18 mental capacities, and then
performed a principal components analysis on this 13x18
dataset. In contrast, guidelines for dimension reduction
generally recommend a much higher ratio of observations to
variables (see Fabrigar, Wegener, MacCallum, & Strahan,
1999). Given the constraints of their approach, Gray et al.’s
analysis would not be expected to yield much more than one
dimension of mind perception; indeed, we note that the
experience dimension actually accounted for nearly all of
the variance in their data (88%, compared to 8% for
agency). These findings thus leave open the possibility that
there may be more than two dimensions of mind perception.
In particular, lay people may make distinctions between
different kinds of “experience,” with potentially important
consequences for social and moral reasoning.
In line with this, in our previous work we have proposed a
three-part model of the lay concept of sentience, including
two distinct forms of experience: affect, the ability to
experience positively or negatively valenced states; and
perception, the ability to detect information about the
environment. (The third component in our model is
autonomy, similar to Gray et al.’s (2007) “agency.”) Our
studies have demonstrated that when adults or young
children learn that an unknown entity has one of these kinds
of experience they do not strongly infer that it has the other;
instead, affect and perception appear to be conceptually
distinct (Weisman, Markman, & Dweck, 2015).
If, indeed, people consider affect and perception to be
distinct capacities that do not mutually imply each other,
they might also distinguish between entities that have one
vs. both of these experiential capacities. For example,
perceptual abilities might allow some autonomous being to

2741

have a sensory impression of its environment, but
suffering—a hallmark of higher-order mental and moral
life—requires the ability to evaluate which sensations are
pleasant or unpleasant. As Gray and others have argued
(e.g., K. Gray, Young, & Waytz, 2012), attributions of
intentional action and suffering are fundamental to moral
reasoning. If these mental phenomena are thought to require
combinations of distinct capacities for affect and perception,
then differentiating between these varieties of experience
might be as important in sociomoral reasoning as the
broader distinction between experience and agency.
With these considerations in mind, the current studies
examine US adults’ attributions of a variety of mental
phenomena, including various affective, perceptual, agentic,
physiological, cognitive, social, and other capacities.
Building on Gray et al.’s (2007) data-driven approach, we
probe ontological distinctions among mental capacities in
three large-scale studies. Converging dimension reduction
analyses lead us to propose an expanded model of folk
philosophy of mind, focused on intuitive distinctions among
different varieties of experience.

Study 1
We begin by exploring people’s attributions of mental
capacities to two “edge cases” in social reasoning: a beetle
and a robot. We selected targets whose existence is beyond
question, but whose mental capacities were predicted to be
controversial. This ensured that not all participants would
endorse all mental capacity attributions (as they might if the
target were a human), providing the variance necessary for
the planned dimension reduction analyses. In addition, this
provided a glimpse into how lay people currently think
about robots, as social technologies begin to play
increasingly larger roles in our everyday lives.

Methods
Participants. 405 adults participated via Mechanical Turk.
All participants had gained approval for ≥95% of previous
work (≥50 assignments); had verified US MTurk accounts;
and indicated that they were ≥18 years old. Participants
were paid $0.30 for about 3-4 minutes of their time. Repeat
participation was prevented. An additional 48 respondents
were excluded for not completing the survey (n=14), failing
an attention check (19), or not providing a year of birth (15).
Materials and procedure. Participants were randomly
assigned to evaluate either a beetle, accompanied by a
photograph of a black beetle on a leaf (n=200); or a robot,
accompanied by a photograph of a humanoid robot (Sony’s
Qrio; n=205). The picture and label (“a beetle” or “a robot”)
were present throughout the survey.
Participants read the following instructions: “On the
following page, you will see a list of mental capacities. For
each mental capacity, please indicate the extent to which
you believe a [beetle/robot] has this capacity. Please note:
We care only about your opinion or best guess—please
do not do any external research about these questions.”

Participants then rated 40 mental capacities presented in a
random order, responding to the following question: “On a
scale of 0 (Not at all capable) to 6 (Highly capable), how
capable is a [beetle/robot] of...?” An attention check
(“Please select 4 for this question”) was embedded
randomly among the ratings, and respondents who failed
excluded from analyses (see Participants).
The 40 mental capacities were generated from an a priori
analysis of candidate ontological categories of mind:
physiological experiences of biological needs (e.g., getting
hungry); emotional experiences (feeling happy); perceptual
experiences (detecting sounds); cognitive abilities
(remembering things); capacities related to autonomy or
agency (having intentions); social abilities (experiencing
guilt); and several additional items that could have fallen
into either none or more than one of these categories (being
conscious). Each category included at least five items of
varying valence, complexity, and phrasing. All 18 mental
capacities from Gray et al.’s (2007) study, or close variants
thereof, were included. See Table 1 for the full set of items.
Exploratory factor analysis (EFA).1 For all EFAs reported
in this paper, we used Pearson correlations to find minimum
residual solutions. We examined maximal (39-factor)
unrotated solutions to determine how many factors to
extract. We report factor loadings from varimax-rotated
solutions that included only factors that had eigenvalues
>1.0 and that individually accounted for >5% of the total
variance in the maximal model.

Results and Discussion
Collapsing across conditions, the first three factors of an
unrotated EFA accounted for 68% of the variance in the
data, with eigenvalues of 15.37 (explaining 46% of total
variance), 4.36 (13%), and 3.09 (9%); all other factors
individually explained ≤5% of total variance.
After rotation, the first factor captures a continuum from
embodied physiological experiences of biological needs to
non-bodily computational abilities, with factor loadings
>0.60 for the following items, in descending order: getting
hungry, experiencing pain, feeling tired, experiencing fear,
experiencing pleasure, being conscious, having free will,
feeling safe, having desires, feeling calm, and feeling
nauseated. One item had a strong negative loading: doing
computations (-0.74); there were no other loadings <-0.29.
The second factor corresponds to social-emotional
experiences, with factor loadings >0.60 for the following
items: feeling embarrassed, experiencing pride, feeling love,
experiencing guilt, feeling depressed, feeling disrespected,
holding beliefs, understanding how others are feeling,
experiencing joy, having a personality, feeling happy, and
telling right from wrong. No items had loadings <-0.08.
The third factor includes a mix of perceptual experiences
and cognitive abilities, with factor loadings >0.60 for the
1

Factor analyses using polychoric correlations and/or oblimin
rotation; principal components analyses; correspondence analyses;
and item response analyses all yielded similar structures.

2742

Table 1: Factor loadings from exploratory factor analyses for all studies (S1-S3)
A priori
category

Item
How capable is a [target] of…?

Factor 1:
Physiological
S1
S2
S3

getting hungry*
experiencing pain*
feeling tired
experiencing fear*
doing computations
experiencing pleasure*
being conscious*
having free will
feeling safe
having desires*
feeling calm
feeling nauseated
getting angry*
having intentions
being self-aware
detecting odors

0.93 0.93 0.84
0.93 0.90 0.86
0.83 0.82 0.85
0.82 0.78 0.83
-0.74 -0.80 -0.41
0.74 0.70 0.79
0.70 0.69 0.65
0.70 0.69 0.59
0.70 0.69 0.73
0.69 0.73 0.68
0.65 0.59 0.75
0.65 0.64 0.70
0.58 0.54 0.67
0.54 0.54 0.48
0.52 0.49 0.38
0.45 0.54 0.58

COG
AGE

feeling embarrassed*
experiencing pride*
feeling love
experiencing guilt
feeling disrespected
feeling depressed
holding beliefs
understanding how others are feeling†
experiencing joy*
having a personality*
feeling happy
telling right from wrong†
having thoughts†
exercising self-restraint†

0.19 0.18
0.28 0.24
0.37 0.42
0.26 0.19
0.37 0.35
0.25 0.21
0.11 0.10
0.06 0.09
0.51 0.50
0.23 0.21
0.55 0.52
-0.04 -0.10
0.50 0.50
0.24 0.19

0.28
0.43
0.65
0.31
0.51
0.29
0.19
0.32
0.71
0.63
0.74
0.17
0.60
0.24

COG
SOC
PER
SOC
AGE
PER
PER
PER
AGE
COG

remembering things†
recognizing someone
sensing temperatures
communicating with others†
working toward a goal†
perceiving depth
detecting sounds
seeing things
making choices
reasoning about things

-0.20
-0.29
0.21
-0.02
0.09
0.11
0.06
0.36
0.25
-0.06

-0.15
-0.27
0.40
-0.11
0.16
0.20
0.20
0.37
0.27
-0.13

Percentage of total variance explained:

46%

47%

PHY
PHY
PHY
EMO
COG

AGE
PHY
EMO
PHY
EMO
AGE
PER
SOC
SOC
SOC
SOC
EMO
COG
SOC
EMO
EMO

Factor 2:
Social-emotional
S1
S2
S3

Factor 3:
Perceptual-cognitive
S1
S2
S3

0.01
0.10
0.23
0.28
0.19
0.43
0.36
0.37
0.36
0.40
0.41
0.50
0.57
0.35
0.48
-0.01

0.10
0.16
0.31
0.37
0.08
0.51
0.41
0.40
0.35
0.44
0.49
0.50
0.62
0.33
0.48
0.04

0.11
0.14
0.21
0.20
0.51
0.36
0.36
0.42
0.33
0.44
0.35
0.40
0.47
0.48
0.59
0.22

-0.08 -0.05
0.01 0.01
0.10 0.04
0.06 0.10
0.44 0.27
0.11 0.11
0.12 0.20
0.09 0.18
0.13 0.16
0.11 0.18
0.17 0.25
0.09 0.06
0.08 0.11
0.27 0.34
0.22 0.26
0.43 0.41

0.34
0.33
0.35
0.37
0.40
0.35
0.38
0.39
0.36
0.34
0.32
0.26
0.31
0.44
0.35
0.58

0.85
0.85
0.81
0.80
0.78
0.78
0.76
0.70
0.70
0.66
0.65
0.60
0.55
0.55

0.75
0.77
0.70
0.76
0.75
0.75
0.64
0.62
0.70
0.62
0.68
0.51
0.55
0.56

0.82
0.74
0.58
0.82
0.63
0.78
0.82
0.72
0.53
0.54
0.50
0.80
0.50
0.70

-0.01
0.05
0.06
0.02
0.03
0.04
0.12
0.29
0.10
0.31
0.10
0.32
0.22
0.31

0.02
0.08
0.15
0.07
0.06
0.07
0.15
0.35
0.14
0.37
0.17
0.37
0.33
0.27

0.09
0.20
0.18
0.13
0.23
0.18
0.14
0.30
0.25
0.33
0.23
0.25
0.33
0.38

0.25
0.43
0.41
0.34
0.23
0.28
0.45
0.56
0.37
0.16

0.17 0.19
0.29 0.29
-0.06 -0.06
0.20 0.16
0.17 0.21
0.11 0.11
-0.05 -0.03
-0.07 -0.04
0.18 0.21
0.47 0.41

0.41
0.39
0.06
0.31
0.41
0.32
0.08
0.13
0.37
0.66

0.72
0.71
0.66
0.65
0.62
0.62
0.61
0.61
0.60
0.57

0.65
0.66
0.58
0.60
0.56
0.58
0.64
0.55
0.59
0.59

0.71
0.59
0.72
0.71
0.57
0.68
0.75
0.67
0.67
0.48

63%

13%

10%

9%

8%

7%

11%

Note: Factor loadings >0.60 or <-0.60 are in bold. The full set of items, used for all studies reported here, is listed in the
second column. Each item is listed with its a priori category membership (first column): physiological (PHY); emotional
(EMO); perceptual (PER); cognitive (COG); agentic (AGE); social (SOC); and other/multiple (unmarked). Items marked
with an asterisk (*) or a dagger (†) constituted Gray et al.’s ( 2007) “experience” and “agency” dimensions, respectively.

2743

following items: remembering things, recognizing someone,
sensing temperatures, communicating with others, working
toward a goal, perceiving depth, detecting sounds, seeing
things, and making choices. No items had loadings <-0.09.
See Table 1 for the full set of factor loadings.
These results suggest that three latent constructs guided
participants’ assessment of the target characters included in
this study: physiological experiences, characterized by
embodied sensations related to biological needs; socialemotional experiences, characterized by positive or negative
valence and relevance to the self and/or social partners; and
perceptual-cognitive abilities, characterized by the detection
and use of information about the environment. Interestingly,
this analysis did not reveal any factor corresponding to
agency or autonomy, as Gray, et al. (2007) and Weisman, et
al. (2015) would predict. Instead, distinctions among
varieties of experience dominated the correlation structure
of participants’ judgments when they were asked to evaluate
the mental capacities of a beetle or a robot in isolation.2

among physiological, social-emotional, and perceptualcognitive experiences. This framework for mind perception
appears to be quite robust, at least in participants’ reasoning
about “edge cases” like beetles and robots.

Study 3
In Studies 1 and 2, participants evaluated entities that we
considered to be controversial in terms of their mental
capacities. Were the distinctions uncovered in these studies
specific to reasoning about edge cases, or would they apply
more to reasoning about a wider range of entities? More
broadly, how does the lay ontology of mind uncovered in
Studies 1 and 2 organize the range of potentially “mental”
entities people encounter in the world? In Study 3, we
presented a variety of entities ranging from an inert object (a
stapler) to a canonical social partner (a human adult).

Methods
Participants. 431 adults participated via MTurk and were
paid $0.30. An additional 40 respondents were excluded for
not completing the survey (n=15), failing the attention
check (24), or not providing a year of birth (1).

Study 2
In Study 1, each participant evaluated a single entity in
isolation. Study 2 was a within-subjects replication of Study
1, providing an opportunity to evaluate the reliability of this
framework and to examine whether this way of thinking
about minds is altered when people are presented with a
salient contrast between an animate and an inanimate entity.

Materials and procedure were identical to Study 1, except
that participants were randomly assigned to evaluate one of
the following entities (labeled as follows and accompanied
by a photograph): an adult, a child, an infant, a person in a
persistent vegetative state, a fetus, a chimpanzee, an
elephant, a dolphin, a bear, a dog, a goat, a mouse, a frog,
a blue jay, a fish, a beetle, a microbe, a robot, a computer, a
car, or a stapler. The number of participants per condition
ranged from 17 (stapler) to 24 (dog).

Methods
Participants. 400 adults participated via MTurk and were
paid $0.50. An additional 24 respondents were excluded for
not completing the survey (n=13), failing the attention
check (7), or not providing a year of birth (4).

Results and Discussion

Materials and procedure were identical to Study 1, except
that all participants rated both entities. Half of participants
saw the beetle on the left side of the screen and half saw the
beetle on the right. Although ratings for the two entities
were made simultaneously, they were independent (e.g., a
participant’s rating of a beetle’s capacity for joy did not
constrain her rating of a robot’s capacity for joy).

Results and Discussion
The first three factors of an unrotated EFA accounted for
67% of the variance in the data, with eigenvalues of 15.55
(explaining 47% of total variance), 3.77 (11%), and 2.63
(8%); all other factors individually explained ≤5% of total
variance. After rotation, all three factors were very similar
to those revealed in Study 1, corresponding to physiological
experiences, social-emotional experiences, and perceptualcognitive abilities; see Table 1.
A within-subjects design, which encouraged participants
to compare an animate being with a “social” technology,
revealed a very similar three-factor structure, distinguishing
2

A direct replication of Study 1 yielded very similar results,
although the third factor accounted for only 5% of total variance.

Once again, three factors emerged from the correlation
structure of participants’ mental capacity attributions,
distinguishing
social-emotional,
physiological,
and
perceptual-cognitive abilities. Notably, this framework was
revealed even when canonical minds, such as humans and
familiar mammals, were evaluated. In fact, the three
(unrotated) factors accounted for the vast majority of the
variance in Study 3 (80%), with eigenvalues of 22.77 (63%
of total variance), 3.72 (10%), and 2.42 (7%); all other
factors explained ≤2% of total variance. Rotated factor
loadings were very similar to Studies 1-2; see Table 1.
Target characters varied widely in their judged mental
capacities (see Figure 1): While a human adult was seen to
be highly capable of all mental capacities and a stapler was
seen to be incapable of any, judgments of other targets
revealed a diverse range of attribution patterns between
these extremes. Non-human mammals were judged to be
highly capable of most physiological experiences and many
perceptual-cognitive abilities and to have middling socialemotional capacities. Non-mammalian animals were judged
to have weaker capacities across the board, particularly in
the social-emotional domain. See the General Discussion for
comments on the particularly interesting case of the robot.

2744

Physiological
Social-Emotional
PerceptualCognitive

Figure 1: Mean ratings by mental capacity for a subset of target characters (Study 3)
Note. Target characters were rated on a scale from 0 (“Not at all capable”) to 6 (“Highly capable”). Error bars are bootstrap
95% confidence intervals. Mental capacities are grouped according to their dominant factor loading in Study 3; see Table 1.

General Discussion
In three large-scale studies, we set out to explore what, if
any, distinctions people make between categories of mental
phenomena—to examine, in other words, a folk ontology of
mind. Our results revealed reliable intuitive distinctions
between physiological experiences of biological needs (e.g.,
hunger, pain); social-emotional experiences of self- and
other-relevant emotions (e.g., guilt, pride); and perceptualcognitive abilities to detect and use information about the
environment (e.g., hearing, memory).
This three-factor structure seems to be quite robust. First,
we note that participants each rated a wide variety of mental
capacities, from multiple a priori domains, that varied in
valence and complexity. Given this experimental design,
additional or alternative latent factors—e.g., complex
cognitive abilities, negatively valenced experiences,
experiences of the self, etc.—could have emerged, but they
did not. Furthermore, we observed very similar factor
structures across independent analyses, both when
participants judged a single “mental edge-case” in isolation
(Study 1) and when participants were encouraged to

compare two edge-cases that contrasted in animacy (Study
2). Finally, when a wider range of entities was included—
from humans and other mammals down to microorganisms,
technologies, and an inert object—this three-factor
framework accounted for fully 80% of the variance in
participants’ judgments (Study 3). Given these observations,
we conclude that distinctions among varieties of experience
loom large in people’s intuitive ontology of mind.
Interestingly, the agency/autonomy construct predicted by
both Gray et al. (2007) and Weisman et al. (2015) did not
emerge as a separate factor in any of the current studies.
Instead, items that we predicted to be related to agency or
autonomy were evenly distributed across the physiological
(having free will, having intentions), social-emotional
(exercising
self-restraint),
and
perceptual-cognitive
(working toward a goal, making choices) factors. This
prompts us to speculate that people might also make
intuitive distinctions between different aspects of agency
(e.g., the experience of having intentions vs. abilities to act
or not act on these intentions); a modified version of the
current paradigm including a wider range of “agentic”

2745

abilities and actions could help substantiate this suggestion.
This null finding by no means rules out the possibility that
lay people consider agency to be an important, distinct
component of the mind. Our studies do, however, suggest
that distinctions among varieties of experience are at least as
prominent in people’s intuitive philosophy of mind as the
broad distinction between experience and agency.
We view these results as consistent with—but an
important expansion upon—Gray et al.’s (2007) dimensions
of mind perception. Rather than making a general
distinction between agency and experience, participants in
our studies focused on the extent to which mental capacities
and phenomenal states are embodied, socially valenced, or
perceptual in nature. These latter two kinds of experience—
social-emotional experiences and perceptual-cognitive
abilities—are closely aligned with Weisman et al.’s (2015)
model of the lay concept of sentience, which distinguishes
between affect and perception. In some sense, the current
results might be seen as a combination of Weisman et al.’s
theory with the classic animate–inanimate distinction, which
from early in development encompasses physiological
experiences of hunger and pain (Carey, 1985). Indeed, the
size of the physiological factor, which accounted for 4663% of the total variance across our studies, indicates that
reasoning about biological animacy might have played an
especially large role in people’s judgments in this task.
Differentiating among capacities for physiological, socialemotional, and perceptual-cognitive experience could have
important ramifications in social reasoning, particularly in
the identification of moral patients, beings that should be
protected from harm and suffering. Building on Gray et al.’s
(2012) argument that “mind perception is the essence of
morality,” we speculate that different varieties of experience
might play different roles in social and moral reasoning. For
example, our ongoing work examines whether attributions
of social-emotional experiences might be more strongly
predictive of judgments of moral patiency than attributions
of perceptual-cognitive abilities, at least among US adults.
Explorations of folk philosophy of mind have acquired
new urgency in recent years, as people have begun
interacting more frequently with increasingly sophisticated
“intelligent” and “social” technologies. Interactions with
robots and other social technologies are likely to be guided
by intuitive understandings of the mind; in turn, these
encounters might reshape lay intuitions about how minds
work, and what qualifies an entity to be considered an object
of sociomoral concern. The current studies provide a
snapshot into how US adults are currently thinking about
the “minds” of robots: The robot was judged to have
virtually no capacity for physiological experiences
(confirming that participants considered it inanimate), but it
received notably higher ratings for many perceptualcognitive abilities, and even for some capacities in the
social-emotional domain (contra K. Gray & Wegner, 2012).
In fact, in several cases, judgments of a robot’s capacities
for social-emotional and perceptual-cognitive abilities
exceeded judgments of the capacities of other “edge cases”

(e.g., a beetle; see Figure 1). In the agency–experience
framework, this result would have been obscured by the
stark discrepancy between these entities’ relative capacities
for physiological experiences. However, the attribution of
even low-level perceptual-cognitive and social-emotional
abilities to technological devices could have profound
implications for how people reason about artificial
intelligences as they become more enmeshed in our
everyday lives—particularly if these capacities are
conceptually linked to morally relevant abilities in their
respective ontological categories.
There is a growing body of evidence that lay people share
the ancient philosophical intuition that “the mind” is
composed of distinct parts. In particular, the current studies
shed light on an intuitive ontological distinction between
physiological sensations, social-emotional feelings, and
perceptual-cognitive abilities—three varieties of experience
that may play different roles in guiding people’s sense of
who or what “counts” as an object of moral concern.

Acknowledgments
This material is based upon work supported by the National
Science Foundation Graduate Research Fellowship Program
under Grant No. DGE-114747, and by a William R. & Sara
Hart Kimball Stanford Graduate Fellowship.

References
Carey, S. (1985). Conceptual Change in Childhood.
Cambridge, MA: MIT Press.
Fabrigar, L. R., Wegener, D. T., MacCallum, R. C., &
Strahan, E. J. (1999). Evaluating the use of exploratory
factor analysis in psychological research. Psychological
Methods, 4(3), 272–299.
Gelman, R., & Spelke, E. S. (1981). The development of
thoughts about animate and inanimate objects:
Implications for research on social cognition. In J. H.
Flavell & L. Ross (Eds.), Social cognitive development:
Frontiers and possible futures (pp. 43–66). Cambridge,
England: Cambridge University Press.
Gray, H. M., Gray, K., & Wegner, D. M. (2007).
Dimensions of mind perception. Science, 315(5812), 619.
Gray, K., & Wegner, D. M. (2012). Feeling robots and
human zombies: mind perception and the uncanny valley.
Cognition, 125(1), 125–30.
Gray, K., Young, L., & Waytz, A. (2012). Mind perception
is the essence of morality. Psychological Inquiry, 23(2),
101–124.
Knobe, J., & Prinz, J. J. (2008). Intuitions about
consciousness: Experimental studies. Phenomenology and
the Cognitive Sciences, 7(1), 67–83.
Weisman, K., Markman, E. M., & Dweck, C. S. (2015).
Reasoning about sentience and animacy: Children’s and
adults’ inferences about the properties of unseen entities.
In D. C. Noelle, R. Dale, A. S. Warlaumont, J. Yoshimi,
T. Matlock, C. D. Jennings, & P. P. Maglio (Eds.),
Proceedings of the 37th Annual Meeting of the Cognitive
Science Society (pp. 2625–2630). Pasadena, CA.

2746

