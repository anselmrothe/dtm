Surprising blindness to conversational incoherence
in both instant messaging and face-to-face speech
Gareth Roberts1,2 (gareth.roberts@ling.upenn.edu)
Benjamin Langstein2,3 (langstein@haskins.yale.edu)
Bruno Galantucci2,3 (bruno.galantucci@yu.edu)
1 Department

of Linguistics, University of Pennsylvania
255 South 36th Street, Philadelphia, PA 19104 USA

2 Department of Psychology, Yeshiva University
2495 Amsterdam Avenue, New York, NY 10033 USA
3 Haskins

Laboratories, 300 George Street
New Haven, CT 06511 USA

Abstract

that is so, then we should expect language users to be sensitive to cases of communicative failure, and for blatant cases
of incoherence to be readily identified and rapidly corrected.

Language is widely assumed to be a well designed tool for reliably communicating propositional information between people. This suggests that its users should be sensitive to failures
of communication, such as utterances that are blatantly incoherent with respect to an ongoing conversation. We present
experimental work suggesting that, in fact, people are surprisingly tolerant of conversational incoherence. In two previous
studies, participants engaged in instant-messaging conversations that were either repeatedly crossed with other conversations or had lines inserted into them that deliberately contradicted available information. In both cases, a substantial proportion of participants failed to notice. In a new study, confederates inserted unexpected, nonsensical lines into face-to-face
conversations. The majority of participants failed to notice.
We argue these findings suggest that we should be wary of
modeling spontaneous communication in terms of faithful information transmission, or language as a well designed tool for
that purpose.
Keywords: communication; miscommunication; language
evolution; change blindness

Introduction
A widely held view is that language is primarily a tool for reliably communicating propositional information between individuals, and that it is good at its job. This assumption,
which is closely connected to what has been termed the code
model of human communication (Blackburn, 1999), is not
only widespread outside academia, but it also pervades much
scholarly discourse. It is central, for instance, to models of
communication that follow the work of Shannon and Weaver
(1949); it has long been a guiding assumption of prominent
adaptive accounts of language evolution (Pinker & Bloom,
1990); and research has been conducted demonstrating the
communicative function of apparently maladaptive features
of language (e.g., Piantadosi, Tily, & Gibson, 2012). This is
not unreasonable, and it could scarcely be denied that a great
deal of linguistic interaction involves communicating propositions. But that is not the same as saying that this is the
primary purpose of linguistic interaction, or that language is
a system finely tuned by evolution to fulfil that purpose. If

In fact, however, there are reasons to be wary of assuming that communication is all that reliable. Humans
are poorer than might be expected at faithful information
transmission in a variety of non-linguistic perceptual tasks
(Rensink, O’Regan, & Clark, 1997; Simons & Levin, 1998;
Simons & Chabris, 1999). With respect to language, there
is evidence that comprehenders form representations that are
merely “good enough” for the task they need to perform
(Ferreira, Bailey, & Ferraro, 2002), while work on the “Moses
illusion” has shown that comprehenders fail to detect inconsistencies in input where inconsistent material is semantically
related to expected material (Park & Reder, n.d.). There is
reason to suspect that even more jarring inconsistencies might
be missed surprisingly often. One reason for this is that it
is unclear whether reliable communication is in fact the primary function of a great deal of linguistic interaction. It has
long been pointed that human conversations very often serve
what have been termed phatic goals (Malinowski, 1923) –
that is, they are aimed at creating and supporting social relationships. This observation has several consequences for the
reliability of communication. First, it suggests that failures
of communication, such as errors of fact or utterances that
are incoherent with respect to surrounding discourse, may
not be noticed by interlocutors, as speakers may focus on social coherence at the expense of communicational coherence.
Second, even if failures of communication are noticed, they
may not be queried or remedied – interrupting, correcting,
or questioning one’s interlocutor detracts from maintaining a
pleasant social interaction. Third, whether or not observed instances of miscommunication are resolved, they are likely to
be quickly forgotten, because they may not be especially important to the social goals of the interlocutors. In fact, the situation may be worse than has been suggested so far. It might
be countered, for example, that even if phatic interactions are

1211

very common, speakers still generally want to convey information, and the language has various features to help them
to do this. However, some of these very features may in fact
make it easier for speakers to overlook cases of communication failure. For example, the ambiguity that Piantadosi et al.
(2012) convincingly argue supports efficient communication
also allows cases of apparent incoherence in one’s interlocutor to be dismissed. In Gricean models of communication,
moreover, a meaning is reconstructed via an inferential process that assumes relevance on the part of the speaker (Grice,
1975; Wilson & Sperber, 2004). While this process is beneficial to successful communication, it is also a means by which
incoherent contributions to discourse can be explained away.
The above suggests that humans may be much less sensitive to incoherence in conversation than is typically assumed,
but most work on miscommunication to date has relied on
qualitative analysis of naturally occurring discourse (e.g.,
Tzanne, 2000), with very little work devoted to investigating it in controlled environments (see Mills, 2012, for a rare
exception). To remedy this, we conducted a series of studies
investigating people’s sensitivity to conversational incoherence. Two of these studies, which have already been published (Galantucci & Roberts, 2014; Roberts, Langstein, &
Galantucci, 2016), involved spontaneous instant-messaging
conversations. These two studies will be described below in
the Section Previous studies. We also report a new third study,
which involved face-to-face conversation with a confederate
who inserted a nonsensical line. In all three cases participants were asked whether they had noticed the incoherence
(Galantucci, Roberts, & Langstein, submitted). Since the
three studies are best understood in comparison with one another, we will present the previously published work in some
detail.

Previous work: Insensitivity to incoherence in
instant-messaging
In each of the two instant-messaging studies, 40 native nativeEnglish-speaking students, with no deficits in color vision or
communicative ability, participated for $20 each. In the first
study (henceforth Study A), participants’ conversations were
crossed with conversations by other naive participants. Study
B was similar, but involved the automatic insertion of lines
that were guaranteed to not fit well with information already
provided to participants.

Study A: Crossed instant-messaging conversations
(Galantucci & Roberts, 2014)
Procedure Participants took part in pairs. Care was taken
that the members of a pair did not already know each other
and met only at the start of the study. On arriving at the
lab, members of a pair were seated in separate rooms and
received the same scripted instructions. Each member of a
pair sat in front of a computer displaying a cartoon of five
famous people and an instant-messaging window (Figure 1).
As in widely used instant-messaging programs, the messag-

ing window consisted of two parts. At the bottom was a space
where a participant could type messages and relay them to
their partner. The rest of the window consisted of a space in
which messages would appear. Messages the participant had
sent appeared in black and were preceded by “You:”; received
messages appeared in red and were preceded by “Partner:”.
Both members of the pair saw the same exact cartoon except
that it was colored differently for each of them. (This was
explained to both participants.)
The task given to participants was manipulated. Ten pairs
of participants were put in the Narrowly focused condition
and were asked to identify the color differences by using the
instant-messaging software to chat for 15 minutes. The other
ten pairs were put in the Broadly focused condition and were
asked to discuss which of the five famous people they would
most and least like to spend a day with.
Although the above account focuses on one pair only, each
trial in fact involved two pairs, Pair A and Pair B (both pairs
were always in the same condition). The two pairs performed
the same task simultaneously, but with different cartoons.
Pair A’s cartoon contained five different famous people from
Pair B’s cartoon, set against a very different background (Figure 1). The software ensured that the task began at the same
time for both pairs, but no participant was aware of the existence of the other pair. Over the course of each conversation there were four 30-second crossings during which each
member of Pair A was re-partnered with a random member
of Pair B. Participants were not warned before the study that
these crossings would occur (indeed, no participant was even
aware of the existence of the other pair), and there were no
markers to indicate that they were occurring. All messages
received, whoever had sent them, continued to appear in red
preceded by “Partner:” (Figure 1). Crossings occurred at random points but began at least three minutes into the conversation.
After 15 minutes had elapsed the chat window closed and
a new window presented the following questions one by one:
1. How did you find the conversation today?
2. Did the conversation go smoothly?
3. Did you ever feel like you were having trouble communicating with your partner?
4. Did you notice anything unusual in the conversation?
5. Participants in this study are put in one of two groups. 50%
of participants are put in the No-Crossing Group. If we put
you in the No-Crossing Group then all the messages you
received came from your partner. The other 50% of participants are put in the Crossing Group. If we put you in the
Crossing Group then some of the messages you received
came from a different participant who intended them for
someone else and did not know that they would come to
you. Which group do you think you were in? Note: If you
are correct, you will win $3!

1212

Participants who answered “no” to Question 2 or “yes” to
Question 3 or 4 were asked to explain their answers before
the next question appeared.
Pair A
Participant A1

Participant A2

SERVER MESSAGE: 5 MINS LEFT
You: let’s try someone else
Partner: how about the guy with the toga
You: green shawl, purple shirt no pants
Partner: green shawl and like di↵erent shade
of green shirt under that
You: what about the lady behind him the
blonde one
Partner: ok, i also have a butterfly next to it
Partner: yeah i know i swear we just got here
You: i know
You: there is something next to the guy but i
can’t tell if it is a butterfly or a kite
Partner: shes got a rainbow colored bathing
suit by that covers her breast and the body
portion of the swimsuit is red

SERVER MESSAGE: 5 MINS LEFT
Partner: let’s try someone else
You: how about the guy with the toga
Partner: green shawl, purple shirt no pants
You: green shawl and like di↵erent shade of
green shirt under that
Partner: what about the lady behind him the
blonde one
You: she looks like a singer
Partner: there is something next to the guy
but i can’t tell if it is a butterfly or a kite
You: shes got a rainbow colored bathing
suit by that covers her breast and the body
portion of the swimsuit is red

Crossing
SERVER MESSAGE: 5 MINS LEFT
Partner: i guess we should talk about the
landscape in the mean time
You: lol okay , i have a orange and purple
flower next to mother teresa
You: did you just get that server message ?
Partner: my flower next to mother teresa is
rainbowish
Partner: yes i did wow time flies
You: ok , i also have a butterfly next to it
You: yeah i know i swear we just got here
Partner: i know
Partner: who looks like a singer?
You: do you see this castle like thing in the
back behind mlk
You: cleopatra , lookslike she has a makeshift
mic in her hand

SERVER MESSAGE: 5 MINS LEFT
You: i guess we should talk about the
landscape in the mean time
Partner: lol okay , i have a orange and purple
flower next to mother teresa
Partner: did you just get that server message
?
You: my flower next to mother teresa is
rainbowish
You: yes i did wow time flies
Partner: she looks like a singer
You: who looks like a singer?
Partner: do you see this castle like thing in
the back behind mlk
Partner: cleopatra , lookslike she has a
makeshift mic in her hand

Participant B1

Participant B2
Pair B

Figure 1: Example conversations from Study 1 (Narrowly focused condition) with crossed messages highlighted.

Results
Questions 2–4 were used to exclude participants whose answers to those questions were inconsistent with their answer
to Question 5. In the Narrowly focused condition there was
one Inconsistent detector (i.e., a participant who guessed
“Crossing Group” in answer to Question 5, but otherwise
claimed to have noticed nothing out of the ordinary) and
no Inconsistent Non-detectors (i.e., participants who claimed
to have noticed something odd, but answered “No-Crossing
Group on Question 5); in the Broadly focused condition there
were four Inconsistent detectors and one Inconsistent Nondetector. These patterns suggests the existence of a bias toward suspecting unusual circumstances. To test this, we replicated the study with 20 new participants and no crossings
(i.e., each participant chatted with the same partner for the
entire session). Consistent with the presence of such a bias,
six participants (30%) incorrectly answered that they were in
the Crossing Group (four in the Narrowly focused condition
and two in the Broadly focused condition).
Crossing detection rates In the Narrowly focused condition, 11 out of 19 participants answered that they were in
the Crossing Group, leading to a detection rate of 57.9%.
This rate is not significantly different from chance: 95% CI
[33.5%, 79.7%] (Figure 3; all CIs presented in this paper were
computed using the Clopper–Pearson exact method).
In the Broadly focused condition 10 out of 15 participants
answered that they were in the Crossing Group, leading to
a detection rate of 66.7%. Again this rate is not significantly
different from chance (95% CI [38.4%, 88.2%]; Figure 3) and
is rather far from the expectations of the sample reported in
the introduction.

Crossing detection rates for blatantly crossed conversations A possible explanation for the low detection rates is
that crossing the conversations did not in fact lead to blatant
violations of coherence. To check whether this was the case
we analyzed the transcripts of the conversations in two ways.
First, we read the transcripts, looking for out-of-the blue
references to famous people or salient items not present in
the cartoon and which had not been mentioned earlier in the
conversation. Such references should have provided blatant
indications that the conversation had been crossed with a different one.
The second analysis relied on four naive judges, who were
given ten transcripts each for each condition: five from the
No-Crossing Group (i.e., from the control study reported
above) and five from the Crossing Group. Transcripts were
distributed in such a way that (a) every judge received one
transcript from each set, and (b) each transcript was given
to one judge. We explained the basics of the study to the
judges and asked them to decide which condition each transcript came from. Judges were paid $10 an hour or given
course credit (in either case the reward was doubled if discrimination was perfect). There was no time-limit for completing the task.
This led us to exclude seven participants who were likely
not exposed to blatant indications of crossings. For the Narrowly focused condition, this produced a crossing detection
rate of 67%. For the Broadly focused condition this produced
a crossing detection rate of 72.7%. In neither case is the rate
significantly different from chance (95% CI [38.4%, 88.2%]
and [39%, 94%] respectively).
Although the detection rates in the Broadly focused condition were higher than in the Narrowly focused condition, the
results are consistent: People are surprisingly insensitive to
conversational incoherence.

Study B: Inserted lines in instant-messaging
conversations (Roberts et al., 2016)
Study 1 provided intriguing evidence that people are less sensitive to conversational incoherence that might have been expected. However, there are reasons to be wary of the findings.
The procedure used led to incoherencies that were inherently
uneven, meaning there was no way to ensure that conversations would include noticeable interruptions. This problem
was somewhat diminished by including three crossings in every conversation, and (as described above) the resulting conversations were carefully checked in two ways to ensure that
participants had in fact been exposed to clear incoherence.
Nevertheless, an obvious step was to replicate the study with
more controlled interruptions. Study 2 (reported in Roberts
et al., 2016) did precisely this by automatically inserting lines
that were guaranteed not to be consistent with ongoing conversations. Furthermore, it compared two different kinds of
interruption: Inserted lines that conflicted with shared taskrelevant information and lines that conflicted with the interlocutor’s apparent gender.

1213

Procedure The same procedure was employed for Study 2
as for the Broadly focused condition of Study 1, except in two
respects. First, instead of the cartoon used in Study 1, an image composed of six photos of famous historical people (Figure 2) was used to stimulate conversation. Second, there was
no crossing of conversations. Instead, two of the messages
sent during the conversation (one from each participant) were
replaced by fake messages (always at least 270 seconds after
the beginning of the conversation and within 120 seconds of
the end). All inserted messages all had the same phrasing:

lines from partners which were not themselves inserted, but
which referred to inserted lines (e.g., “I don’t see Oprah anywhere.”). If such a line occurred, the Transcript distance between it and the participant’s guess was also measured, and
the lower value was used for analysis.

of these six [FAMOUS PERSON]s kind of an icon for
[WOMEN/MEN] like me.
There were two between-subjects conditions (with 10 pairs
each). In the Gender-swap condition the famous person
named was chosen from among Hillary, Einstein, Marilyn,
and MLK, all of whom were depicted in the photograph (Figure 2), but the phrase “women like me” or “men like me”
was chosen to conflict with the apparent sender’s real gender. For example, a line that supposedly came from a female
participant might read “of these six Einsteins kind of an icon
for men like me”. In the Character-swap condition the reverse was true: The gender was as expected, but the famous
person referred to was not in the picture, but would be chosen
from among the names Oprah, Madonna, Gandhi, or Mandela
(e.g., a line supposedly from a female participant might read
“of these six Oprahs kind of an icon for women like me”).
Across both conditions a sentence ending “for women like
me” would always refer to a female celebrity and a sentence
ending “for men like me” would always refer to a male one.
The same two famous people were never used for both inserted lines in the same conversation.1
After 15 minutes had elapsed, as in Study 1, a questionnaire was presented. This differed only with respect to Question 5, which referred to “the Normal-Conversation Group”
and the “Inserted-Message Group” instead of “No-Crossing
Group” and “Crossing Group”. Having finished answering
Question 5, every participant was told that there had in fact
been an inserted message and was shown a transcript of the
conversation they had just been engaged in, which included
all the messages the participant had actually sent or received.
(The inserted message that the participant had received was
included; the inserted message that the participant’s partner
had received was not.) Every message in the transcript was
numbered and the participant was asked to scroll through
and select the message they thought had been inserted. The
distance in number of lines between the participant’s guess
and the actual inserted message was measured (henceforth
Transcript distance). The transcripts were also checked for
1 It should be noted that, on top of the incoherence generated by
the informational conflict, the message might introduce other forms
of incoherence, such as the absence of an answer to a direct question
or an abrupt change of topic. Furthermore, the inserted line might
generate messages from the receiver (e.g., “Why bring up Oprah?”)
which would not make sense to the other participant, who had no
knowledge of the inserted message.

Figure 2: Image used to stimulate conversation in Study
2. All photographs were taken from Wikimedia Commons
(https://commons.wikimedia.org/) and are either public domain or available under a creative commons license.

Results
In the interest of being conservative, Inconsistent detectors
were excluded only if they also failed to identify the line in
the transcript. In the Gender-swap condition there were seven
Inconsistent detectors and no Inconsistent Non-detectors.
In the Character-swap condition there was one Inconsistent
Non-detector and four Inconsistent detectors. These participants were excluded from further analysis.
Detection rates In the Gender-swap condition 66.66% of
participants (95% CI = [48.17% 82.04%]) correctly guessed
that they were in the Inserted-Message Group. In the
Character-swap condition 57.14% of remaining participants
(95% CI = [39.35% 73.68%]) correctly guessed that they
were in the Inserted-Message Group. In neither case was the
detection rate significantly better than chance (Figure 3).
Identification of inserted message The transcript distance
for one participant in the Character-swap condition (who
guessed that she was in the Normal-Conversation Group)
could not be computed because, due to a misunderstanding,
she did not perform the line identification task. For each
of the remaining participants, if the Transcript distance was
greater than three lines this was taken as an indication that
the participant had failed to identify the inserted message.
In the Gender-swap condition there were 14 such participants (35%), seven of whom responded that they were in
the Normal-Conversation group (63.64%) and seven of whom
thought they were in the Inserted-message Group (24.14%),

1214

suggesting that their answer to Question 5 might have been
simply a guess. The difference in line identification between
these two groups is significant (χ2 = 5.47, p < .05).
In the Character-swap condition 11 participants (28.21%)
failed to identify the inserted message, seven of whom responded that they were in the Normal-conversation Group
(46.67%) and four of whom responded that they were in the
Inserted-Message Group (16.67%). The difference in line
identification between the two groups is significant (χ2 =
4.39, p < .05).

Study B found similar results to Study A, with rather more
controlled interruptions. However, both studies involved instant messaging rather than face-to-face conversations. While
it is important to stress that instant messaging is a very natural
communication medium for a great number of people, especially college students like our participants, it remains possible that our results had something to do with the nature of the
interaction. We therefore conducted Study 3, in which participants chatted face-to-face with confederates (Galantucci et
al., submitted).

Methods
Participants 30 native English-speaking students (16 female, 14 male; mean age 24.73, SD = 6.43), with no deficits
in communicative ability, participated for $20 each.
Procedure Each participant engaged in face-to-face conversation with a confederate. In order to elicit a spontaneous and lively conversation, they were asked to discuss five
thought-provoking questions such as “Would you rather be
color blind, or not be able to understand puns?” or “Would
you rather live the rest of your life on a tree or in a cave?”.
The five questions were written on a whiteboard in front of
the individuals, who were told that they had about 15 minutes
to order them from funniest to least funny and from hardest
to answer to easiest to answer.
At some point during the conversation the confederate
would utter the nonsensical sentence “Colorless green ideas
sleep furiously”. The confederate was instructed to utter
the sentence clearly and audibly, at least eight minutes into
the conversation, and at a point where the participant was
silent. One minute after the sentence was uttered, the conversation was interrupted by an experimenter and the participant and the confederate were escorted to two separate rooms
for a follow-up questionnaire. When the 30 participants were
asked at the end of the study whether they ever suspected that
the person they conversed with was a confederate, only five
of them answered positively, and none of them mentioned the
nonsensical sentence as the reason for the suspicion.
The questionnaire was as in Studies 1 and 2 apart from
Question 5, which referred to “the Control Group” and the
“Nonsensical Sentence Group” (but was otherwise identical
to Question 5 in Studies 1 and 2). Right after answering Ques-

Results
Responses to Question 5 In answer to Question 5, 10 participants (33.33%) said they thought they were in the Nonsensical Sentence Group. This detection rate is not significantly
different from chance (95% CI [17.3% 52.8%]).
There were no Inconsistent detectors in Study 3. Furthermore, the mean confidence rating for the 20 participants who
said they thought they were in the Control Group was 8.8
(95% CI [7.81 9.79]), while the mean confidence rating for
the 10 participants who said they thought they were in the
Nonsensical Sentence Group was 7.7 (95% CI [6.34 9.06];
Figure 3).
Recognition of the nonsensical sentence Of the 10 participants who said they thought they were in the Nonsensical
Sentence Group, only one correctly recognized the sentence
“Colorless green ideas sleep furiously” in a list that included
20 other nonsensical sentences. In other words, 90% of the
participants who detected the nonsensical sentence forgot it
within a few minutes from hearing it. This finding is consistent with the well established fact that recalling linguistic
materials that lack a coherent overall meaning is a substantial
challenge (Marks & Miller, 1964).
Instant messaging

100%

Incoherence detec1on
(with 95% CI)

NEW STUDY: Inserted lines in face-to-face
conversation

tion 5, all participants were asked to estimate how confident
they were in their answer, using a scale from 1 to 10 (where
1 corresponded to “Not certain at all” and 10 to “Completely
certain”). Then, the participants who thought they were in the
Nonsensical Sentence Group were asked to identify the nonsensical sentence uttered by the confederate in a list which
included 20 other nonsensical sentences.

75%
50%

Face to face
Color
diﬀerences
(n = 19)

Free chat
(n = 15)

Characterswap
(n = 35)

Genderswap
(n = 33)

Overall IM
(n = 102)
Nonsensical
(n = 30)

25%

Chance
level

0%

Swap-induced
(random) incoherence

Systema1c incoherence (free chat)

Figure 3: Detection rates across all three studies

Discussion
In each of the three studies described here participants were
surprisingly blind to cases of blatant incoherence in spontaneous conversation (Figure 3). Even in the condition with the
highest detection rate (the Gender-swap condition of Study
2), more than 25% of participants failed to notice the incoherence. (This rises to a third once Inconsistent detectors are
excluded.) The results from Study 3 are particularly striking: In face-to-face conversation a full two thirds of participants failed to notice the introduction of a meaningless line

1215

that could have no relevance to the rest of the conversation,
and only one of the participants who did notice the line could
identify it a few minutes later. These results sit awkwardly
with the view that language is the product of biological evolutionary purposes fine-tuning it for reliable communication. If
that were the case, one would expect language users to be reliable communicators, sensitive to instances of communicative
failure. Our findings are more consistent with accounts that
see language as having evolved to serve social goals alongside
communicative ones (Dunbar, 1996), or accounts of language
evolution that downplay the role of adaptive biological evolution generally, emphasizing the role of cultural evolution instead (Dediu et al., 2013; Tamariz & Kirby, 2016; Tomasello,
2010).
In either case, it is likely that the social, phatic, dimension
of conversation is an important part of the explanation for our
findings. This would help to explain why incoherence detection was particularly poor in Study 3, in which participants
conversed face-to-face and were thus under a greater social
pressure than in the other two studies, where they could not
see each other. It might also help to explain why the highest detection rate was observed in the Gender-swap condition
of Study 2, where the inserted line had a social significance
lacking in Study 3 or the Character-swap condition of Study
2 (or, indeed, the majority of crossings in Study 1). However,
the difference between conditions in Study 2 was not significant, and other differences make it difficult to compare this
condition with the other studies directly.
Identifying precisely what mechanisms lie behind our findings, and how their relative importance varies from context
to context, is an important next step in this investigation. In
the meantime, however, we have presented compelling evidence that human linguistic communication is not as reliable
as tends to be assumed, as well as a paradigm for investigating this phenomenon in a controlled setting.

Acknowledgments
We thank the students in the Experimental Semiotics Lab at
Yeshiva University for their help with data collection.

References
Blackburn, P. L. (1999). The code model of communication: A powerful metaphor in linguistic metatheory. Unpublished doctoral dissertation. (Retrieved from ProQuest
Dissertations & Theses Full Text database – 304574107)
Dediu, D., Cysouw, M., Levinson, S. C., Baronchelli, A.,
Christiansen, M. H., Croft, W., . . . Lieven, E. (2013).
Cultural evolution of language. In P. J. Richerson &
M. H. Christiansen (Eds.), Cultural evolution: Society, technology, and religion. strüngmann forum reports
(Vol. 12, pp. 303–332). Cambridge, MA: MIT Press.
Dunbar, R. I. M. (1996). Grooming, Gossip and the Evolution
of Language. London: Faber and Faber.
Ferreira, F., Bailey, K. G., & Ferraro, V. (2002). Goodenough representations in language comprehension. Current Directions in Psychological Science, 11(1), 11–15.

Galantucci, B., & Roberts, G. (2014). Do we notice when
communication goes awry? an investigation of people’s
sensitivity to coherence in spontaneous conversation. PLoS
ONE, 9(7), e103182.
Galantucci, B., Roberts, G., & Langstein, B. (submitted).
Content deafness: When coherent talk just doesn;t matter.
Grice, H. P. (1975). Logic and conversation. In P. Cole &
J. L. Morgan (Eds.), Syntax and semantics, vol. 3: Speech
acts (pp. 41–58). New York: Academic Press.
Malinowski, B. (1923). The problem of meaning in primitive
languages. In C. K. Ogden & I. A. Richards (Eds.), The
meaning of meaning (pp. 146–152). London: Routledge.
Marks, L. E., & Miller, G. A. (1964). The role of semantic and syntactic constraints in the memorization of english
sentences. Journal of Verbal Learning and Verbal Behavior, 3(1), 1–5.
Mills, G. J. (2012). The evolution of miscommunication.
In T. C. Scott-Phillips, M. Tamariz, E. A. Cartmill, &
J. R. Hurford (Eds.), The 9th international conference on
the evolution of language (evolang ix). Singapore: World
Scientific.
Park, H., & Reder, L. M. (n.d.). Moses illusion: Implication for human cognition. In R. F. Pohl (Ed.), Cognitive
illusions (pp. 275–291). Hove: Psychology Press.
Piantadosi, S. T., Tily, H., & Gibson, E. (2012). The communicative function of ambiguity in language. Cognition,
122, 280–291.
Pinker, S., & Bloom, P. (1990). Natural language and natural
selection. Behavioral and Brain Sciences, 13, 707–84.
Rensink, R. A., O’Regan, J. K., & Clark, J. J. (1997). To see
or not to see: The need for attention to perceive changes in
scenes. Psychological Science, 8, 368–373.
Roberts, G., Langstein, B., & Galantucci, B. (2016).
(in)sensitivity to incoherence in human communication.
Language and Communication, 47, 15–22.
Shannon, C. E., & Weaver, W. (1949). The mathematical
theory of communication. Urbana, IL: University of Illinois
Press.
Simons, D. J., & Chabris, C. F. (1999). Gorillas in our midst:
Sustained inattentional blindness for dynamic events. Perception, 28.
Simons, D. J., & Levin, D. T. (1998). Failure to detect
changes to people during a real-world interaction. Psychonomic Bulletin and Review, 5(4), 644–649.
Tamariz, M., & Kirby, S. (2016). The cultural evolution of
language. Current Opinion in Psychology, 8, 37–43.
Tomasello, M. (2010). Origins of human communication.
Cambridge, MA: MIT Press.
Tzanne, A. (2000). Talking at cross-purposes: The dynamics
of miscommunication. John Benjamins.
Wilson, D., & Sperber, D. (2004). Relevance theory. In
L. R. Horn & G. Ward (Eds.), Handbook of pragmatics (pp.
607–632). Oxford: Blackwell.

1216

