Collective search on rugged landscapes:
A cross-environmental analysis
Daniel Barkoczi (barkoczi@mpib-berlin.mpg.de) Pantelis P. Analytis (analytis@mpib-berlin.mpg.de)
Charley M. Wu (cwu@mpib-berlin.mpg.de)
Center for Adaptive Behavior and Cognition (ABC), Max Planck Institute for Human Development
Abstract

solution in a given neighborhood may be far from the best
global solution (see Figure 1 for an illustration).

In groups and organizations, agents use both individual and social learning to solve problems. The balance between these two
activities can lead collectives to very different levels of performance. We model collective search as a combination of simple
learning strategies to conduct the first large-scale comparative
study, across fifteen challenging environments and two different network structures. In line with previous findings in the
social learning literature, collectives using a hybrid of individual and social learning perform much better than specialists
using only one or the other. Importantly, we find that collective performance varies considerably across different task environments, and that different types of network structures can
be superior, depending on the environment. These results suggest that recent contradictions in the social learning literature
may be due to methodological differences between two separate research traditions, studying disjoint sets of environments
that lead to divergent findings.

Behavioral scientists have conducted a handful of experimental studies on collective learning using one or two dimensional functions (Mason, Jones, & Goldstone, 2008;
Mesoudi, 2008; Mason & Watts, 2012), or simple combinatorial problems (Wisdom, Song, & Goldstone, 2013). In contrast, management and organization scientists have studied
search using simulations and experiments based on the NK
model inspired by evolutionary biology (Kauffman & Levin,
1987; Levinthal, 1997; Gavetti & Levinthal, 2000; Rivkin,
2000; Billinger, Stieglitz, & Schumacher, 2013), where the
environment is completely determined by two parameters, the
N number of components making up a solution, and the K
level of interdependence between components. This type of
formalism has the advantage that the difficulty of the problem
can be directly set by the parameter K, but also the drawback
that the problem is specifically tailored to a single type of
complexity (i.e., interdependence).

Keywords: Social learning; communication networks; collective behavior; search; rugged landscapes.

Introduction
There are two paths to the acquisition of knowledge. Organisms can search for new solutions through trial-and-error,
testing various courses of action in isolation from others, or
alternatively, they can copy existing solutions by imitating
other individuals (March, 1991; Rendell et al., 2010). Imitation is a cognitively simple strategy that can lead to exceptionally good outcomes (Boyd & Richerson, 1985; Rendell et
al., 2010; Laland, 2004; Miller & Dollard, 1941), however,
it cannot produce new information by itself. Thus, collective
learning in groups can be seen as the outcome of both individual learning and the spread of social information through
imitation (Tarde, 1903). A different balance of theses two
strategies can lead to very different levels of individual and
group performance (Rogers, 1988).
In this paper we examine how collectives using individual
and/or social learning perform across a wide range of environments embedded in different network structures, governing
the communication of social information. Models of social
exploration-exploitation dynamics regularly use the analogy
of search on a fitness landscape where nearby (similar) solutions can have quite different payoffs, forming a "rugged"
multi-peaked landscape (Levinthal, 1997; Lazer & Friedman,
2007; Mason & Watts, 2012). Real-world examples of rugged
landscapes may include combinatorial problems, technological innovation, or the fitness of an organism as a function of
its genome. A key feature of these environments is that they
can be dominated by multiple local maxima, where the best

Both communities have investigated the influence of communication networks on collective performance, but have
found contradictory results (Derex & Boyd, 2016; Fang, Lee,
& Schilling, 2010; Lazer & Friedman, 2007; Mason & Watts,
2012; Mason et al., 2008; Wisdom et al., 2013). Lazer
and Friedman (2007) found that less connected (inefficient)
networks lead to better collective performance in the NK
landscape, while Mason and Watts (2012) reached the opposite conclusion, finding support for the superiority of wellconnected (efficient) networks in a 2-dimensional landscape.
In these studies, the choice of fitness landscape was held
constant, with results often derived from a single type of
environment. Here we explore a promising explanation for
these contradictory results, namely that these studies investigated learning on disjoint sets of environments, differently
suited to specific types of collective search behavior. There
are also other possible explanations for these contradictory
results, such as the use of different social learning strategies
(Barkoczi & Galesic, 2016) or the nature of the task that the
collective has to perform (Shore, Bernstein, & Lazer, 2015).
In this study, we present simulations of collective search
across a wide range of multi-peak environments, which include both two dimensional (Mason & Watts, 2012) and NK
environments (Lazer & Friedman, 2007). Our approach uses
a cross-environmental analysis to resolve inconsistencies regarding the influence of network structure on collective performance.

918

imization problems. To be consistent with research on collective behavior in the behavioral and social sciences we inverted
the payoffs and turned them into maximization problems.
Mason & Watts and NK Environments. We replicated
the environment used in Mason and Watts (2012) and NK
environments from Lazer and Friedman (2007). To retain
consistency with the function-based environments described
above, we enlarged the Mason and Watts (2012) environment
to have 1001 · 1001 possible locations using bicubic interpolation. For the NK environments, we use N = 20, resulting in
a similar number of possible solutions (220 ).
#
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15

Figure 1: The Eggholder function is a typical example of a bivariate
function that generates a rugged payoff landscape. The exact formula can be found at the virtual library of simulation experiments
http://www.sfu.ca/~ssurjano/optimization.html.

Methods
Landscapes
In total we studied 15 different multi-peaked landscapes (Table 1). Environments 1-12 are bivariate functions obtained
from the virtual library of simulation experiments (Surjanovic
& Bingham, n.d.), which are regularly used in operations research and the field of global optimization to study how different optimization algorithms perform (e.g., Hu, Fu, & Marcus, 2007). These environments have been designed and investigated specifically because they pose challenges to adaptive optimization algorithms, covering a wide range of possible environmental structures with regards to the variability of
high quality solutions, the ruggedness of the landscape, and
the average pay-off. We also study the environment used in
Mason and Watts (2012) and two different NK landscapes
(K=5 and K=10) of the type used in Lazer and Friedman
(2007).
For each environment we normalized the payoff scales to
obtain relative payoffs between 0 and 1, with the global maximum was set to 1 and the global minimum set to 0. Following Lazer and Friedman (2007) we re-scaled these normalized
payoffs by raising each value to the power of 8. This monotonic transformation creates larger differences in the upper
range of payoffs but leaves other features of the landscape
unchanged.
Function-based Landscapes. Environments 1-12 are generated from bivariate functions, which translate any two values x and y (evaluated on a specific range of real numbers)
into a corresponding payoff between 0 and 1. For our purposes, we first transformed the continuous environments into
discrete units by dividing each axis into 1001 equally-spaced
regions. Since all the environments were two dimensional,
this resulted in a total of 1001 · 1001 possible locations that
an agent could explore. This harmonized the different x-axis
and y-axis scales of the individual environments, resulting in
the same number of possible solutions across environments.
Most of these environments were initially designed as min-

Environments
Ackley
Cross-in-Tray
Drop-wave
Eggholder
Griewank
Holder table
Langermann
Rastrigin
Schaffer n.2
Schaffer n.4
Schwefel
Shubert
Mason & Watts (2012)
N = 20, K = 5
N = 20, K = 10
Average

µ
0.001
0.14
0.003
0.03
0.17
0.006
0.02
0.05
0.007
0.001
0.03
0.005
0.001
0.04
0.04
0.036

σ
0.01
0.17
0.03
0.07
0.24
0.06
0.07
0.1
0.03
0.02
0.07
0.03
0.01
0.04
0.04
0.07

modality
4489
64
4391
353
50861
56
2461
121
88457
87737
64
761
1090
1143
7131
16612

Table 1: The 15 landscapes that we examined. We report the mean
(µ) and variability (σ) of pay-offs, and the modality (i.e., number
of peaks) of the landscape. Environments 1-12 are function-based
and the environmental statistics remain constant. Statistics for Mason and Watts (2012) were averaged over 10,000 replications of the
environment generation function, while the NK environments were
averaged over the 100 pre-generated landscapes used in simulations.

Learning processes and behavioral strategies
We considered a population of 100 agents simultaneously
learning about the environment using different strategies. In
separate conditions, we tested strategies that relied solely on
individual learning, solely on social learning, or on a combination of both (McElreath et al., 2008). We first describe the
rules associated with each strategy.
1. Individual learning: We studied two types of individual
learning, where agents evaluated new solutions without the
benefit of social information.
• Local search. In our simulations, local search (i.e.,
hill climbing) was performed by examining neighboring solutions for the largest increase in payoff. In
cognitive science, local search has been studied in
resource-allocation problems (Busemeyer & Myung,

919

●

●

●
●

1987; Rieskamp, Busemeyer, & Laine, 2003), and also
corresponds to the gradient descent algorithm used in
many learning systems. On the 2D landscapes (Environments 1-13), the local search strategy evaluated the
8 adjacent solutions accessible by modifying either the
value of x, y, or both simultaneously by one discrete
unit. If any of the explored solutions were better than
the current one, it adopted the best among these solutions, otherwise, it kept the current solution. In NK landscapes, local search was implemented by modifying a
single randomly chosen digit of the N-dimensional solution (Levinthal, 1997; Lazer & Friedman, 2007; Rivkin,
2000) 1 .
• Random search. Random search was performed by randomly evaluating a new location in the fitness landscape
and moving to that position if it had a higher payoff (i.e.,
long-jump). Random search relates to the idea of blind
variation in psychology (Campbell, 1960), but also corresponds to the random search assumption made by optimal stopping models in economics and statistics (e.g.
DeGroot, 2005; Analytis, Stojic, & Moussaïd, 2015).

●

●

●

●
●

●

●
●

●

●
●
●

●
●

●

●

●

●

●

●

●

●
●

●
●

●

●

●

Figure 2: Examples of a fully connected (left) and locally connected
lattice (right) networks.

only available indirectly, over several degrees of separation.
In contrast, information flowed more freely in the fully connected network, with the possibility for each agent to imitate
each other agent in the population. These two network structures were also studied by Lazer and Friedman (2007).

Simulation procedure
We assigned random starting solutions to a population of 100
agents. At each time step, agents used the strategies described
above to learn about the environment. Imitation actions were
performed simultaneously at the beginning of each time step
to avoid sequential effects (Analytis et al., 2015; Bikhchandani, Hirshleifer, & Welch, 1992).
We repeated this process for 100 time steps and 100 replications, and recorded the average payoff achieved in the population. In total we tested 7 different strategy and network
combinations; the three pure learning strategies (local search,
random search, and imitate-the-best2 ) and four versions of
the hybrid strategy (two rs values and two different network
structures)3 .

2. Social learning: Social learners sampled the solutions
from a number of other individuals (n=k) within the
connected population (see Network structures), and
adopted the solution with the highest observed payoff if
it was better than the agent’s existing solution (Lazer &
Friedman, 2007). In this paper we report results for n=3.
We refer to this this strategy as imitate-the-best.
3. Hybrid social/individual learning: Hybrid agents used a
combination of social and individual learning (Enquist,
Eriksson, & Ghirlanda, 2007; McElreath et al., 2008). At
each time step, agents followed a sequential strategy selection process (Gigerenzer, 2008), in which they first attempted to find a better solution through social learning
(described above), but switched to individual learning, using either local search or random search, if unsuccessful.
In this paper we report two variants of this strategy, one
with no option to perform random search (rs = 0) and one
where 20% of individual learning actions resulted in random search (rs = .2), with the remaining 80% of actions
performing local search.

Results
Overall, we found that performance varied across environments, with some environments being more challenging that
others (Figure 3). While the rank order remained relatively
stable across environments, there were several notable
differences. First, random search was always superior to
local search in the 2D environments (Environments 1-13),
while the opposite was the case in the NK environments
(Environments 14-15). Second, imitate-the-best typically
outperformed individual search strategies–by driving the
population to local peaks faster than individual search–
with one exception being the NK environments, where local
search performed better. These two results demonstrate
that local search is a highly effective strategy in the NK
environment, which could be because the peaks of NK landscapes have larger basins of attraction, allowing local search
to explore a larger space compared to the 2D landscapes
(Kauffman & Levin, 1987).

Network structures
To account for different channels of communication, we examined how hybrid agents performed when they were embedded in a fully connected network, allowing communication with all other agents, or a locally connected lattice in
which each agent was connected with four other agents from
the population (Figure 2). In both networks the agents sampled n=3 individuals at random from their connections. In
the locally connected lattice, access to the full population was

2 Note that imitate-the-best is used as a benchmark, therefore, we
only study its performance in a fully connected network.
3 See: https://github.com/dnlbrkc/collective_search for the simulation code.

1 The differences in the implementation of local search in 2D and
high dimensional NK landscapes are due to irreconcilable differences in the number of adjacent solutions as a function of the dimensionality of the problem space. We follow standard implementations
from the respective literatures.

920

Figure 3: Learning curves for the different models across 15 environments, reporting the change in average payoff (over each population of
100 agents and over 100 replications) for 100 time steps. We studied 7 different models using combinations of simple heuristic rules. Hybrid
models utilize both social and individual search strategies, where the random search parameter (rs) governs the balance of random search vs.
local search, while the network parameter (net) specifies either a fully connected or a locally connected lattice network. Hybrid strategies
consistently performed best with some random search (rs = .2); however, the superiority of different network structures depended on the
structure of the environment.

921

Network structure and performance We replicated the
results found in both Mason and Watts (2012) and Lazer
and Friedman (2007), and show that the contradictory conclusions can be explained by the choice of environment they
studied. Depending on the environment, network structure
can lead to three different types of results. First, hybrid agents
with a local lattice network can converge on a higher payoff than those with a fully connected network (particularly
when rs = 0; e.g., Ackley, Schaffer n.4, and NK environments). This replicates the results of Lazer and Friedman
(2007), who showed that local connections force the population to explore the landscape more extensively, delaying convergence on local optima. Second, fully connected networks
can initially outperform the local lattice network, and reach
comparable performance over time (e.g., Eggholder and Mason & Watts environments). This result is consistent with Mason and Watts (2012) and shows that in some environments,
slower communication does not lead to higher performance in
the long-run. Third, there can very small differences between
networks (e.g., Cross-in-Tray and Griewank), which happens
when the problem is relatively easy and hybrid agents quickly
reach high-value optima.

Hybrid (rs=.2,net=local)
1.0

Griewank

Cross−in−Tray
●
Schwefel
● ●
● Rastrigin
Holder table

●

Langermann
●

Shubert

0.8

●

●

Eggholder
N=20,K=5
●

Schaffer n.2●

0.6

Mason & Watts (2012) Drop−wave
●

●

Schaffer n.4

Average Payoff

●

●

Ackley
●

N=20,K=10

Hybrid (rs=.2,net=full)
1.0

Cross−in−Tray
●
Schwefel
●
●
Holder table
●
Rastrigin

Griewank
●

Langermann
Shubert
●

●

●

0.8

Eggholder
Mason & Watts
(2012)
●
●

0.6

N=20,K=5

Schaffer n.2 ●
●

Schaffer n.4 ●

Drop−wave
●

Ackley
N=20,K=10
●

4

6

8

10

log10(Modality)

Figure 4: The number of local maxima (modality) explains some of
the variability in performance across environments, but not all. Here
we show average payoff as a function of the (log10 ) modality of the
environments, for the locally connected (top) and fully connected
(bottom) hybrid models (where rs = .2). Average payoff was derived
by averaging over all individuals and time steps.

The role of random exploration Allowing for a mixture
of both local exploration (hill-climbing) as well as the ability
to occasionally undertake random exploration (long-jumps)
greatly benefited hybrid collectives, making it the overall
best performing strategy (rs=.2) by a large margin. Random search generated new information that gradually diffused to other agents by means of imitation. In fact, heuristics for global optimization problems such as genetic algorithms (Goldberg & Holland, 1988) or simulated annealing
(Kirkpatrick, Gelatt, Vecchi, et al., 1983) have explicit strategies to escape from the local optima. The ability to search
randomly (via long-jumps) in our simulation played exactly
the same role.

challenging search environments. As Herbert Simon illustrated with his scissors analogy, "[h]uman rational behavior
(and the rational behavior of all physical symbol systems) is
shaped by a [pair of] scissors whose two blades are the structure of task environments and the computational capabilities
of the actor" ((1990), p. 7). In a similar vein, to understand
collective performance, it is essential to study cognition in
tandem with the task environment in which it operates.
A large number of studies have addressed collective problem solving; however, they have focused on only one type
of task environment. This makes it (i) hard to compare results across studies, (ii) uncertain whether they generalize beyond a specific environment, and (iii) unknown whether certain strategies lead to superior collective performance when
paired with specific environments. To the best of our knowledge, this is the first study in the social and behavioral sciences that analyses collective problem-solving across many
different types of environments4 .

Explaining differences across environments. What are
the environmental features that influence the performance of
different strategies and networks? An obvious candidate is
the the number of peaks (i.e., modality) in an environment.
Figure 4 shows that modality can explain some of the variability in performance across environments, but not all. Higher
modality is correlated with lower payoffs for both the locally
connected (top; r=-.53, p=.04) and fully connected (bottom;
r=-.55, p=.03) hybrid strategies (where rs = .2). Still, a large
proportion of the variance remains unexplained. One striking
difference is that while the Mason & Watts (2012) and N=20,
K=5 environments have similar modality, the rank order of
average payoffs are inverted between the two network structures. In the future we aim to identify relevant features of task
environments (see Mersmann et al., 2011), that would allow
us to make predictions about which cognitive strategies and
network structures are best suited to a particular environment.

Network and environmental structure
An open question in the study of collective learning is the
influence of network structure on collective performance in
groups and organizations. Derex and Boyd (2016), Lazer
and Friedman (2007), Fang et al. (2010) and Mason et al.
(2008) found that less efficient networks may led to higher
4 To this end, we borrowed several environments that have been
used as test-beds for search algorithms in Operations Research.
Conversely, researchers from the OR community have often turned
to collective cognitive systems for inspiration. Algorithms imitating
the behavior of ant colonies (Bonabeau, Dorigo, & Theraulaz, 2000)
and swarms (Kennedy, 2010) have proved to be particularly powerful in solving combinatorial and global optimization algorithms.

General discussion
In this paper we investigated how groups of individuals relying on different cognitive strategies performed across 15

922

levels of collective performance. In contrast, a recent study
by Mason and Watts (2012) came to the opposite conclusion,
that more efficient networks are better. A crucial difference
between these studies is the type of environment that they
investigated, because as we have found, the performance of
a type of network structure depends on the underlying task
environment. We found that in a number of environments
(e.g., Ackley, Schaffer n.4, and NK environments), inefficient networks eventually converged on better payoffs than
efficient networks, while in others (including the Mason &
Watts environment), efficient networks had an initial advantage, but reached similar performance as inefficient networks
over time.

Gavetti, G., & Levinthal, D. (2000). Looking forward and looking backward: Cognitive and experiential search. Administrative
Science Quarterly, 45(1), 113–137.
Gigerenzer, G. (2008). Why heuristics work. Perspectives on psychological science, 3(1), 20–29.
Goldberg, D. E., & Holland, J. H. (1988). Genetic algorithms and
machine learning. Machine learning, 3(2), 95–99.
Hu, J., Fu, M. C., & Marcus, S. I. (2007). A model reference adaptive search method for global optimization. Operations Research,
55(3), 549–568.
Kauffman, S., & Levin, S. (1987). Towards a general theory of adaptive walks on rugged landscapes. Journal of theoretical Biology,
128(1), 11–45.
Kennedy, J. (2010). Particle swarm optimization. In Encyclopedia
of machine learning (pp. 760–766). Springer.
Kirkpatrick, S., Gelatt, C. D., Vecchi, M. P., et al. (1983). Optimization by simulated annealing. Science, 220(4598), 671–680.
Laland, K. N. (2004). Social learning strategies. Animal Learning
& Behavior, 32(1), 4–14.
Lazer, D., & Friedman, A. (2007). The network structure of exploration and exploitation. Administrative Science Quarterly, 52(4),
667–694.
Levinthal, D. A. (1997). Adaptation on rugged landscapes. Management Science, 43(7), 934–950.
March, J. G. (1991). Exploration and exploitation in organizational
learning. Organization Science, 2(1), 71–87.
Mason, W., Jones, A., & Goldstone, R. L. (2008). Propagation of
innovations in networked groups. Journal of Experimental Psychology: General, 137(3), 422.
Mason, W., & Watts, D. J. (2012). Collaborative learning in networks. Proceedings of the National Academy of Sciences, 109(3),
764–769.
McElreath, R., Bell, A. V., Efferson, C., Lubell, M., Richerson, P. J.,
& Waring, T. (2008). Beyond existence and aiming outside the
laboratory: estimating frequency-dependent and pay-off-biased
social learning strategies. Philosophical Transactions of the Royal
Society B: Biological Sciences, 363(1509), 3515–3528.
Mersmann, O., Bischl, B., Trautmann, H., Preuss, M., Weihs, C., &
Rudolph, G. (2011). Exploratory landscape analysis. In Proceedings of the 13th annual conference on genetic and evolutionary
computation (pp. 829–836).
Mesoudi, A. (2008). An experimental simulation of the copysuccessful-individuals cultural learning strategy: adaptive landscapes, producer–scrounger dynamics, and informational access
costs. Evolution and Human Behavior, 29(5), 350–363.
Miller, N. E., & Dollard, J. (1941). Social learning and imitation.
Yale University Press.
Rahwan, I., Krasnoshtan, D., Shariff, A., & Bonnefon, J.-F. (2014).
Analytical reasoning task reveals limits of social learning in networks. Journal of The Royal Society Interface, 11(93), 20131211.
Rendell, L., Boyd, R., Cownden, D., Enquist, M., Eriksson, K.,
Feldman, M. W., . . . Laland, K. N. (2010). Why copy others?
insights from the social learning strategies tournament. Science,
328(5975), 208–213.
Rieskamp, J., Busemeyer, J. R., & Laine, T. (2003). How do people learn to allocate resources? comparing two learning theories. Journal of Experimental Psychology: Learning, Memory,
and Cognition, 29(6), 1066.
Rivkin, J. W. (2000). Imitation of complex strategies. Management
Science, 46(6), 824–844.
Rogers, A. R. (1988). Does biology constrain culture. American
Anthropologist, 819–831.
Shore, J., Bernstein, E., & Lazer, D. (2015). Facts and figuring: An
experimental investigation of network structure and performance
in information and solution spaces. Organization Science.
Simon, H. A. (1990). Invariants of human behavior. Annual review
of psychology, 41(1), 1–20.
Surjanovic, S., & Bingham, D. (n.d.). Virtual library of simulation
experiments: Test functions and datasets. Retrieved January 26,
2016, from http://www.sfu.ca/~ssurjano.
Tarde, G. D. (1903). The laws of imitation. H. Holt.
Wisdom, T. N., Song, X., & Goldstone, R. L. (2013). Social learning
strategies in networked groups. Cognitive Science, 37(8), 1383–
1425.

Extensions and limitations
In this study we chose to adhere closely to the designs of
Mason and Watts (2012) and Lazer and Friedman (2007) to
resolve contradictory results in the literature on the role of
network structure in collective performance. We covered a
broad range of environmental structures, but we only looked
at two popular types of networks. In the future, we intend
to extend our analysis to additional networks (see Mason
& Watts, 2012), different behavioral rules (see Barkoczi &
Galesic, 2016) and types of tasks (see Rahwan, Krasnoshtan,
Shariff, & Bonnefon, 2014). However, the key challenge will
be to identify features of tasks or environments that favor the
usage of certain networks over others.

Acknowledgments
We thank Stojan Davidovic and Mirta Galesic for their useful
comments on an earlier version of this manuscript.

References
Analytis, P. P., Stojic, H., & Moussaïd, M. (2015). The collective
dynamics of sequential search in markets for cultural products.
Santa Fe Institute Working Paper.
Barkoczi, D., & Galesic, M. (2016). Social learning strategies modify the effect of network structure on group performance. Working
paper.
Bikhchandani, S., Hirshleifer, D., & Welch, I. (1992). A theory of
fads, fashion, custom, and cultural change as informational cascades. Journal of Political Economy, 100(5), 992-1026.
Billinger, S., Stieglitz, N., & Schumacher, T. R. (2013). Search on
rugged landscapes: An experimental study. Organization Science,
25(1), 93–108.
Bonabeau, E., Dorigo, M., & Theraulaz, G. (2000). Inspiration
for optimization from social insect behaviour. Nature, 406(6791),
39–42.
Boyd, R., & Richerson, P. J. (1985). Culture and the evolutionary
process. University of Chicago Press.
Busemeyer, J. R., & Myung, I. J. (1987). Resource allocation decision making in an uncertain environment. Acta Psychologica,
66(1), 1–19.
Campbell, D. T. (1960). Blind variation and selective retentions in
creative thought as in other knowledge processes. Psychological
review, 67(6), 380.
DeGroot, M. H. (2005). Optimal statistical decisions (Vol. 82). John
Wiley & Sons.
Derex, M., & Boyd, R. (2016). Partial connectivity increases cultural accumulation within groups. Proceedings of the National
Academy of Sciences, 201518798.
Enquist, M., Eriksson, K., & Ghirlanda, S. (2007). Critical social
learning: a solution to rogers’ paradox of nonadaptive culture.
American Anthropologist, 109(4), 727–734.
Fang, C., Lee, J., & Schilling, M. A. (2010). Balancing exploration
and exploitation through structural design: The isolation of subgroups and organizational learning. Organization Science, 21(3),
625–642.

923

