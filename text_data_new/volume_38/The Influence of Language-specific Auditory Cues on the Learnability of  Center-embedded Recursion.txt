The Influence of Language-specific Auditory Cues on the Learnability of
Center-embedded Recursion
Jun Lai (J.Lai@tilburguniversity.edu)
Tilburg centre for Cognition and Communication and Tilburg Center for Logic and Philosophy of Science,
Tilburg University, P.O. Box 90153, 5000 LE, Tilburg, the Netherlands

Chiara de Jong (c.dejong_3@tilburguniversity.edu)
Tilburg centre for Cognition and Communication, Tilburg University, the Netherlands

Dingguo Gao (edsgao@mail.sysu.edu.cn)
Department of Psychology, Sun Yat-sen University, China

Ren Huang (huangren@mail2.sysu.edu.cn)
Department of Psychology, Sun Yat-sen University, China

Emiel Krahmer (E.J.Krahmer@tilburguniversity.edu)
Tilburg Center for Cognition and Communication, Tilburg University, the Netherlands

Jan Sprenger (J.Sprenger@tilburguniversity.edu)
Tilburg Center for Logic and Philosophy of Science, Tilburg University, the Netherlands
Abstract
The learnability of center-embedded recursive structures has
attracted much attention (Corballis, 2007; Friederici, 2004;
Rey, Perruchet, & Fagot, 2012). However, most of the
previous studies adopted the artificial grammar learning
paradigm (Reber, 1967) and did not apply natural language
stimuli. Rather, they applied synthetic meaningless training
materials, which hardly represent the richness and complexity
of natural language. Accordingly, in the current study, we
attempt to tighten the link between artificial language learning
and natural language acquisition in the auditory modality, by
enriching our learning environment with phonological cues
that occur in natural, spoken information; in particular,
Chinese tones. In a grammaticality judgment task, we
examined the syntactical processing by participants from
different language backgrounds. Through the cross-language
comparison between Chinese and Dutch native speakers, we
aim to test the influence of language-specific phonological
cues on processing complex linguistic structures. The results
showed that tones had a more beneficial learning effect for
Chinese than for Dutch participants. In other words, when
participants learned a new language, they were likely to bring
their own language routines implicitly from the familiar
native language into processing the unfamiliar one.
Keywords: Phonological cues; Language-specific; Artificial
language; Syntactical processing; Auditory modality

Introduction
The ability to use and understand hierarchical structures has
been proposed to be a unique characteristic of human
primates (Hauser, Chomsky, & Fitch, 2002; Fitch & Hauser,
2004). One of these complex structures is center-embedded
recursion, which has attracted attention from various
research domains (Corballis, 2007; Friederici, 2004; Rey,
Perruchet, & Fagot, 2012). However, when centerembedded structures occur in natural language, such as the

English sentence “The dog that the cat chased ran away”, it
appears to be difficult to understand and to process for
human language users.
Although a large number of studies have investigated the
processing of center-embedded recursion using artificial
grammar learning paradigm, whether this type of structures
can be learned still remains controversial (Conway &
Christiansen, 2005; Conway, Ellefson & Christiansen, 2003;
Li, Jiang; Guo; Yang & Dienes, 2013; Vicari & Adenzato,
2005). Moreover, most previous studies focused on the
learning of center-embedded recursion in the visual
modality (de Vries, Monaghan, Knecht, & Zwitserlood,
2008; Rey, et al., 2012), whereas learning the structures in
the auditory modality, which deserves more research
attention, was virtually neglected (Conway et al., 2003;
Mueller, Bahlmann, & Friederici, 2010). This is quite
surprising since the auditory modality is arguably more
important than the visual modality for first language
acquisition during infancy. Hence, experiments that aim at a
proper understanding of how complex linguistic structures
are acquired have to include it.
A recent study (Lai, Krahmer, & Sprenger, 2015) has
demonstrated that learning such structures is indeed possible
in the auditory modality within a 30-miniute exposure.
Listeners were able to learn an artificial language, consisting
of sequences with center-embedding (for example, nonword sequences following the structure of A1B1, A1A2B2B1,
A1A2A3B3B2B1). Moreover, the results suggested that
facilitative cues from previous experiments in the visual
modality (Lai & Poletiek, 2011, 2013; Lai, Krahmer, &
Sprenger, 2014), which were observed in the learning of
visual center-embedded recursion, were also helpful in the
auditory modality (Lai, et al., 2015). These cues pertained to
1) the order of the stimuli in the learning environment

1901

(incrementally increasing the complexity of the training
input); 2) the total amount of stimuli presented (few
specimen rather than many); 3) the frequencies with which
the training stimuli were repeated (differential rather than
uniform). All three factors turned out to improve the
performance of the participants in judgments of
grammaticality significantly, and performance was best
when all three cues were combined.
More precisely, in Lai et al. (2014, 2015), there were
three groups: a) a Starting-small (SS) group, which was
trained with staged input. Participants saw 144 learning
exemplars, ranging from the easiest to the most difficult; b)
the Starting-less (SL) group, which saw less unique
exemplars (36), but all exemplar were repeated for an equal
number of time; c) the Starting-high (SH) group, which also
received less unique exemplars (36), but exemplars were
repeated for an unequal number of times. Results showed
that all groups performed significantly above chance level.
In addition, it was found that humans were able to extract
center-embedded recursion in an auditory learning
environment, when the training input was arranged
incrementally with increasing complexity. The starting
small facilitation effect thus also holds true for the auditory
modality. Moreover, the SH group performed significantly
better than both the SS and SL group. The small diversity in
exemplars of the SH group did not hinder learning CE
recursion, but helped participants to focus on regularities.
Additionally, the repetition of that limited amount of
exemplars enables learners to become acquainted with the
grammatical structures and to solidify their memory of the
recursive structures.
The adoption of artificial grammar learning paradigm has
been criticized for having low ecological validity and can
hardly mimic the complete natural language acquisition
procedure (Forkstam, Jansson, Ingvar, & Petersson, 2009).
The simplified artificial language does not have the richness
and complexity of the real natural language in various
dimensions, such as the large amount of vocabulary,
semantics, and phonology, etc. (Arciuli & Torkildsen, 2012).
Therefore, it remains under speculation to which degree
results from artificial language learning can be generalized
to the actual language acquisition process. Accordingly, the
purpose of the current study is to create a stronger link
between artificial language learning and natural language
learning. It is crucial that the statistical learning study that
we conduct can not only simulate the richness of natural
language environment, but also maintain its particular
advantage, namely, the strict control over prior language
knowledge and the learning material (Arciuli & Torkildsen,
2012). Therefore, we retain the artificial grammar paradigm,
but we supplement it by adding a property of natural
languages, namely, phonological cues. More precisely,
using the auditory modality, Chinese tones were added to
the artificial learning input. Firstly, we examine whether the
phonological property from natural language would
influence the processing of auditory center-embedded
recursion. Secondly, we investigate whether listeners from

different language background would process the complex
structures differently. Thirdly, we studied whether the
facilitative cues from our previous study (Lai et al., 2015)
also worked in the presence of phonological cues. Previous
studies showed that learners relied on native speech routines
in their own language while learning to segment a new
language (Vroomen, Tuomainen, & de Gelder, 1998,
Saffran, Werker, & Werner, 2006). For example, Vroomen
et al. (1998) found that word stress and vowel harmony had
a differential impact on Finnish, Dutch, and French listeners.
Similarly, in word segmentation studies, it has been shown
that adult learners profited from a “metrical segmentation
strategy”, which treated language-specific factors as signals
in recognizing word boundaries (Saffran, et al., 2006; Tyler,
2006). For example, English listeners tended to consider
strong syllables as the onsets of upcoming words, since
English is a stress-timed language and routinely most of
English words start with strong syllables (Cutler, & Norris,
1988).
These previous studies indicated that phonological cues
from natural language indeed affected participants
differently according to their natural language. The above
phenomena were observed in word segmentation tasks. We
examine whether they also exist in syntactical processing
tasks. We focus on tones in Chinese. We hypothesize that
tones, which are present in Chinese but absent in most
European languages, such as Dutch, would have a different
influence on Chinese and Dutch listeners, when they are
processing center-embedded structures in the auditory
modality. In a grammaticality judgement task, we exposed
Dutch and Chinese participants to two sets of artificial input,
one with and the other without Chinese tones. Chinese are
expected to make use the existence of tones, while Dutch
are not. We also test whether the optimal learning strategies
in our previous experiment (Lai et al., 2015) succeed when
the input resembles natural language more closely.

Methods
Participants
Fifty Dutch speakers (25 female, mean age 21.68 year, SD
2.12) from Tilburg University and fifty Chinese speakers
(38 female, mean age 20.38 year, SD 3.17) from Sun Yatsen University participated in this study for course credit.
None of the Dutch participants learned Chinese before the
experiment, and vice versa. No participants had prior
knowledge about the experiment. All the participants had
normal hearing abilities.

Materials and design
Non-word sequences were generated by a center-embedded
recursive rule, possessing the pattern A1B1, A1A2B2B1 or
A1A2A3B3B2B1 (c.f. Lai, et al., 2015). There were two sets
of stimuli: one was the non-tonal set, which was recorded by
a native Dutch speaker; whereas the other one is the tonal
set, which was recorded by a native Chinese speaker. Both
speakers were instructed to read sequences in a natural way

1902

as if pronouncing natural speech in their own language. The
speed of reading and intonation were held constant. For
example, each sequence was pronounced syllable by
syllable (approximately 400 ms per syllable). We also
checked the validation of our experimental material by
conducting an intelligibility test prior the main experiment.
The test showed that all Dutch utterances were intelligible
for Dutch native speakers, and Chinese utterances were also
clear to Chinese native speakers. Listeners in the
intelligibility test would not participate in the main
experiment.
For the stimuli set, the sequences consisted of two, four,
or six consonant-vowel syllables. The syllables were
constructed using six consonants (/b/, /p/, /d/, /t/, /n/, and
/m/) and two vowels (/i/, /e/, /o/, and /a/). We created a set
of A-syllables (i.e. bi, be, di, de, ni, ne), and a set of Bsyllables (i.e. po, pa, to, ta, mo, ma). The A-B mapping was
not random. Not every A can go with every B-syllable.
Instead, the pairs of consonants (b-d, d-t, n-m) determined
the relatedness of AB pairs. None of the sequences existed
in Dutch or Chinese lexicons.
For the Chinese stimuli set, the same set of (lexical)
syllables was used, while adding Chinese tones to the
syllables. A tonal syllable is characterized by two factors,
namely pitch height (fundamental frequency) and contour
(with a level, low-rising, high-falling, or dipping shapes)
(Wang & Saffran, 2014). Mandarin Chinese employs tones
to differentiate lexical meanings. These special variations in
Chinese tones appear as “truly foreign acoustic cues to the
ears of non-tonal speakers” (Wang & Saffran, 2014). In the
current design, two distinctive tones, i.e. Tone 2 (low-rising)
and Tone 4 (high-falling), were selected to differentiate
Category A syllables from Category B syllables. Syllables
with tones were strictly selected to avoid producing words
with semantic meanings.
Sequences were read out with a natural intonation. The

pattern was held consistent across all stimuli. Both Dutch
and Chinese utterances were presented at the same volume
and in the same manner to participants in all conditions. We
measured the pitch contour of the recorded sequences by
examining their acoustical parameter, namely, the
fundamental frequency (F0), as depicted in Figure 1.
As displayed in Figure 1, for four-syllable sequences,
Dutch- and Chinese utterances possessed distinctive features.
On the one hand, the pitch of Dutch utterances was
comparatively flat. The pitch of the third syllable was
slightly lower than the others, marking the start of the
second half of the sequences. (For the 6-syllable ones, the
lower pitch started at the fourth syllable). The pattern was
held consistent. On the other hand, for each Chinese
utterance, the first half had a low-rising trend, and the
second half had a high-falling pattern.

Procedure
Participants were randomly assigned into one of the four
groups: Dutch listener --Tonal stimuli, Dutch listener --Nontonal stimuli, Chinese listener --Tonal stimuli, and Chinese
listener --Non-tonal stimuli. The experiment consisted of
two phases, learning and testing. Participants were informed
that they were participating in a simple language learning
task. They were not provided with any information about
the underlying center-embedded recursive grammar. In the
learning phase, participants were instructed to listen to the
artificial sequences attentively. Each trial starts with a beep
(400 ms), followed by a learning sequence in a syllable-bysyllable method and then the inter-stimulus interval (1000
ms).
Regarding to the complexity of the exemplars, there was
an equal number of all three levels, i.e. zero-, one-, and twolevel of embedding (LoE) (for example, bepa, beditopa,
bedinimatopa). In the learning phase, in total there were 144
sequences, consisting of 36 unique exemplars with a

Figure 1. Comparison of fundamental frequency (F0) contours between Dutch and Chinese sequences. For example,
the F0 of a 4-syllable sequence (dibipata), on the left is the Dutch utterance and on the right is the Chinese one with tones.

1903

Mean Accuracy

Dutch

Chinese

Non-tonal

Tonal

Figure 2. Mean accuracy of Dutch and Chinese participants
on tonal and non-tonal test sequences. The dotted line
represents chance level (M= .50).

Non-tonal

Ungrammatical

Grammatical

0.90
0.85
0.80
0.75
0.70
0.65
0.60
0.55
0.50
0.45
0.40
Ungrammatical

A one-sample t-test showed that all groups performed
significantly above chance level accuracy: Dutch
participants listening to Non-tonal set, M= .60, SD= .08, t
(24) = 6.25, p < .001; Dutch participants listening to Tonal
set, M= .58, SD= .10, t (24) = 4.00, p < .001; Chinese
participants listening to Non-tonal set, M = .61, SD= .10, t
(24) = 5.50, p < .001; Chinese participants listening to Tonal
set, M= .69, SD= .14, t (24) = 6.79, p < .001.
An ANOVA showed that there was a main effect of
native language, F (1, 96) = 8.22, p = .005, ƞp2 = .08.
Generally, Chinese speakers (M = .65, SE = .02) scored
significantly higher than Dutch speakers (M = .59, SE= .02).
There was no main effect of tonality of input, F (1, 96) =
1.20, p = .276, ƞp2 = .12, but crucially the interaction
between native language and tonality was significant, F (1,
96) = 5.35, p = .023, ƞp2 = .053 (as shown in Figure 2).
When Chinese speakers listened to stimuli with tones,
they scored higher than they did when listening to stimuli
without tones, t (48) = 2.14, p = .037, r2 = .09. By contrast,
Dutch speakers performed similarly, irrespective of whether
they were exposed to stimuli with or without tones, t (48) =
1.01, p = .320, r2 = .02. Therefore, the presence of tones
advanced the learning performance of Chinese participants,
but not of Dutch participants.
Furthermore, as depicted in Figure 3, we observed a main
effect of grammaticality, F (1, 192) = 26.60, p = .000, ƞp2
= .122, and a main effect of group, F (3, 192) = 3.44, p
= .018, ƞp2 = .051 (Table 1), but no significant interaction, F
(3, 192) = .250, p = .861, ƞp2 = .04. Generally, scores on
grammatical items (M = .67, SE= .01) were significantly

0.90
0.85
0.80
0.75
0.70
0.65
0.60
0.55
0.50
0.45
0.40

Grammatical

Results

higher than on ungrammatical items (M = .57, SE= .01), p
< .001.

Mean Accuracy

repetition. Therefore, there were 12 unique sequences for
each LoE. Exemplars were repeated according to their
occurrence probability, which was determined by the centerembedded recursive grammar. High probable exemplars
were repeated more frequently than low probable ones.
Specifically, 0-LoE sequences were repeated more times
than 1-LoE ones, which in turn occurred more times than 2LoE ones. In the testing phase, there were 72 unique
sequences, half grammatical and half not. Ungrammatical
items were produced by mismatching the related syllables
with unrelated ones. The test sequences, which also had
three levels of complexity, occurred in a random manner,
instead of being arranged from the simplest to the most
difficult. Participants were required to make judgments
whether the test sequences were governed by the same rule
as the one in the learning phase. If they agreed that the test
sequences were generated by the same rule that generated
the learning sequences, then they pressed “YES”; if not,
then “NO”.
Prior to the formal start of test phase, a practice session
with four trials familiarized the participants with the
forthcoming procedure. Practical trials would not occur
again in formal tests. After the experiment, participants
were debriefed.

Tonal

Target Language
Dutch

Chinese

Figure 3. Mean accuracy of Dutch and Chinese participants
on the grammaticality of both tonal and non-tonal test
sequences. The dotted line represents chance level (M= .50).

1904

Discussion
In a complex linguistic structure learning experiment,
we added Chinese tones onto the non-word artificial input
and investigated whether listeners’ learning performance
would be influenced by their native language background.
Firstly, we replicated the significant learning effect obtained
by the starting-high strategy in previous research (Lai et al.,
2014; 2015). All groups achieved better than chance
accuracy in discriminating grammatical sequences from
non-grammatical ones. The successful learning overall is
potentially explained by the efficient interaction of three
factors: a) the incremental ordering (the most fundamental
associations being presented first, then dependencies with
one embedding, and in the end the most complex ones with
two embedding) helped learners deconstruct the complexity,
by arranging the learning input in a more efficient and easier
way; b) the small set of exemplars helped participants focus
on the underlying regularities. As a result, participants
avoided being easily confused by the diversity and
variations of the large amount of unique exemplars; c) the
repetition of exemplars helped them consolidate memories.
Therefore, the current results contribute to the debate about
the conditions under which complex statistical patterns can
be learned best (Conway et al., 2003; Perruchet & Rey,
2005). For instance, unlike the current study with a
relatively small set of stimuli, Gomez (2002) and Gomez
and Maye (2005) suggested that higher variability in
exemplars can actually help participants learn regularities.
They found that a token “X” can facilitate learning of “aXb”
structures. Being sensitive to the degrees of stimulus
complexity, statistical learning deserves further research on
the composition of learning input.
Crucially, our results revealed that the nature of
participants’ native language, instead of the target language,
had an important influence on syntactical processing of
center-embedded recursive structures. Chinese participants
performed better, when listening to stimuli with tones than
without. Chinese participants might possess comparatively
higher sensitivity towards the tonal variations. This
indicates that when the target artificial language contained
language-specific cues, participants made use of these
phonological cues that they were familiar with from their
native language. In contrast, these lexical tones had no
noticeable impact on Dutch participants when listening and
processing recursive structures, presumably because tones
are not present in Dutch. Regarding this aspect of second
language acquisition, our results confirm that learners might
benefit in learning the new language, when the target
language shares properties from their native language.
Recent cross-linguistic research has also probed into the
interplay between prior linguistic experience and subsequent
(second) language learning (Onnis & Thiessen, 2013). For
instance, in a tonal word vs. non-word discrimination task,
Mandarin bilinguals and monolinguals largely outperformed
English monolinguals (Wang & Saffran, 2014). On the one
hand, this might be due to the prior knowledge matching
with the target language or not; on the other hand, it might

be that the underlying cognitive mechanism for tonal
language users leads to better performances in more
domain-general cognitive tasks, compared to non-tonal
language users, as Bidelman, Hutka, and Moreno (2013)
suggested. Our results, which showed that Chinese scored
general higher than Dutch participants in this task, were
consistent with this potential account. Since our stimuli
were recorded by different speakers (Chinese for the tonal
set and Dutch for the non-tonal set), it is also conceivable
that other factors, besides the presence of tones, might
influence learning performance. Further research on
language-specific statistical biases is needed.
Furthermore, the previous literature mainly focused on
the contribution of phonological cues in speech processing,
e.g. phrase discrimination from sound stream (Bion, Höhle,
& Schmitz, 2007). Our results manifested that phonological
cues can facilitate syntactical processing in a higher level,
namely, phrase structure grammar (Chomsky, 1957), which
produces hierarchical center-embedding.
In addition, being consistent with previous research (Lai,
et al., 2014; 2015), we found that generally participants
were more accurate in recognizing grammatical sequences
than ungrammatical ones. However, our current data
showed that with the help of tones, Chinese participants
improved in detecting ungrammatical sequences.

Conclusion
The present study displayed the crucial influence of
language-specific cues on learning center-embedded
structures via the auditory modality. The phonological tone
cue had a different impact on speakers with a tonal and nontonal background. As predicted, when the target language
shares the phonological characteristics of participants’
native language, learning was enhanced. This finding sheds
further light on second language acquisition. Further more
studies are needed to incorporate more language-specific
cues in order to conduct the comparison between artificial
language learning and second language acquisition.

References
Arciuli, J., & Torkildsen, J. V. (2012). Advancing our
understanding of the link between statistical learning and
language acquisition: the need for longitudinal data.
Frontiers in Psychology, 3:324.
Bach, E., Brown, C., & Marslen-Wilson, W. (1986).
Crossed and nested dependencies in German and Dutch:
A psycholinguistic study. Language and Cognitive
Processes, 1(4), 249-262.
Bidelman, G.M., Hutka, S., & Moreno, S. (2013). Tone
language speakers and musicians share enhanced
perceptual and cognitive abilities for musical pitch:
evidence for bidirectionality between domains of
language and music. PLos ONE 8:e60676.
Bion, R.A.H., Höhle, B., & Schmitz, M. (2007). The role of
prosody on the perception of word-order differences by
14-month-old German infants. In J. Trouvain & W. J.
Barry (Eds.), Proceedings of the 16th International

1905

Congress of Phonetic Sciences (pp. 1537–1540).
Saarbrucken, Germany: International Congress of
Phonetic Sciences.
Chomsky, N. (1957). Syntactic Structures. The Hague/Paris:
Mouton.
Corballis, M.C. (2007). Recursion, language, and starlings.
Cognitive Science, 31, 697-704.
Conway, C. M., & Christiansen, M. H. (2005). Modalityconstrained statistical learning of tactile, visual, and
auditory sequences. Journal of Experimental PsychologyLearning Memory and Cognition, 31(1), 24-39.
Conway, C. M., Ellefson, M. R., & Christiansen, M. H.
(2003). When less is less and when less is more: Starting
small with staged input. In Proceedings of the 25th
annual conference of the cognitive science society (pp.
270-275). Mahwah, NJ: Lawrence Erlbaum.
Cutler, A., & Norris, D. (1988). The role of the strong
syllables in segmentation for lexical access. Journal of
Experimental Psychology: Human Perception &
Performance, 14, 113-121.
De Vries, M. H., Monaghan, P., Knecht, S., & Zwitserlood,
P. (2008). Syntactic structure and artificial grammar
learning: The learnability of embedded hierarchical
structures. Cognition, 107(2), 763-774.
Fitch, W. T., & Hauser, M. D. (2004). Computational
constraints on syntactic processing in a nonhuman
primate. Science, 303(5656), 377-380.
Forkstam, C, Jansson, A, Ingvar, M., & Petersson, K.M.
(2009). Modality transfer of acquired structural
regularities. Proceedings of the Annual Conference of the
Cognitive Science Society (pp. 1686-1691). Austin, TX:
Cognitive Science Society.
Friederici, A.D. (2004). Processing local transitions versus
long-distance syntactic hierarchies. Trends in Cognitive
Sciences, 8, 245-247.
Gomez, R.L. (2002). Variability and detection of invariant
structure. Psychological Science, 13, 431-436.
Gomez, R.L., & Maye, J. (2005). The developmental
trajectory of nonadjacent dependency learning. Infancy, 7,
183-206.
Hauser, M. D., Chomsky, N., & Fitch, W. T. (2002). The
faculty of language: What is it, who has it, and how did it
evolve? Science, 298(5598), 1569-1579.
Lai, J., Krahmer, E. J., & Sprenger, J. M. (2014). Studying
Frequency Effects in Learning Center-embedded
Recursion. In P. Bello, M. Guarini, M. McShane, & B.
Scassellati (Eds.), Proceedings of the 35th Annual
Conference of the Cognitive Science Society (pp. 797802). Austin, TX: Cognitive Science Society.
Lai, J., Krahmer, E. J., & Sprenger, J. M. (2015). The
learnability of Auditory Center-embedded
Recursion.
Proceedings of the 36th Annual Conference of the
Cognitive Science Society (pp.1237-1242). Austin, TX:
Cognitive Science Society.
Lai, J., & Poletiek, F. H. (2011). The impact of adjacentdependencies and staged-input on the learnability of

center-embedded hierarchical structures. Cognition,
118(2), 265-273.
Lai, J., & Poletiek, F. H. (2013). How “small” is “starting
small” for learning hierarchical centre-embedded
structures? Journal of Cognitive Psychology, 25(4), 423435.
Li, F. F., Jiang, S., Guo, X. Y., Yang, Z. L., & Dienes, Z.
(2013). The nature of the memory buffer in implicit
learning:
Learning
Chinese
tonal
symmetries.
Consciousness and Cognition, 22(3), 920-930.
Mueller, J. L., Bahlmann, J., & Friederici, A. D. (2010).
Learnability of Embedded Syntactic Structures Depends
on Prosodic Cues. Cognitive Science, 34(2), 338-349.
Onnis, L., & Thiessen, E.D. (2013). Language experience
changes subsequent learning. Cognition, 126(2), 268-284.
Perruchet, P., & Rey, A.,(2005). Does the mastery of centerembedded linguistic structures distinguish humans form
non-human primates? Psychonomic Bulletin and Review,
12(2), 307-313.
Reber, A.S. (1967). Implicit learning of artificial grammars.
Journal of Verbal Learning and Verbal Behavior, 77,
317-327.
Rey, A., Perruchet, P., & Fagot, J. (2012). Centre-embedded
structures are a by-product of associative learning and
working memory constraints: Evidence from baboons
(Papio papio). Cognition, 123(1), 180-184.
Saffran, J.R., Werker, J.F., & Werner, L.A. (2006). The
infant’s auditory world: Hearing, speech, and the
beginning of language. In R. Siegler & D. Kuhn (Eds.,),
Handbook of child development (6th ed., pp 58-108). New
York: Wiley.
Tyler, M.D. (2006). French listeners can use stress to
segment words in an artificial language. Proceedings of
the 11th Australasian International Conference on Speech
Sci. & Tech., edited by Warren P., & Watson, C.I.
(Australasian Speech Sci. & Techno. Assoc. Inc.,
Auckland, New Zealand), 222-227.
Vicari, G., & Adenzato, M. (2014). Is recursion languagespecific? Evidence of recursive mechanisms in the
structure of intentional action. Consciousness and
Cognition, 26, 169-188.
Vroomen, J., Tuomainen, J., & de Gelder, B. (1998). The
rules of word stress and vowel harmony in speech
segmentation. Journal of Memory and Language, 38(2),
133-149.
Wang, T.L., & Saffran, J.R. (2014). Statistical learning of a
tonal language: the influence of bilingualism and previous
linguistic experience. Frontiers in Psychology, 5.
Zimmerer, V. C., Cowell, P. E., & Varley, R. A. (2011).
Individual behavior in learning of an artificial grammar.
Memory & cognition, 39(3), 491-501.

1906

