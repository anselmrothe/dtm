Social Affordance Tracking over Time A Sensorimotor Account of False-Belief Tasks
Judith Bütepage (butepage@kth.se)
Hedvig Kjellström (hedvig@csc.kth.se)
Danica Kragic (dani@kth.se)
Computer Vision and Active Perception Laboratory,
CSC, KTH, Stockholm, Sweden
Abstract
False-belief task have mainly been associated with the explanatory notion of the theory of mind and the theory-theory.
However, it has often been pointed out that this kind of highlevel reasoning is computational and time expensive. During the last decades, the idea of embodied intelligence, i.e.
complex behavior caused by sensorimotor contingencies, has
emerged in both the fields of neuroscience, psychology and
artificial intelligence. Viewed from this perspective, the failing in a false-belief test can be the result of the impairment to
recognize and track others’ sensorimotor contingencies and affordances. Thus, social cognition is explained in terms of lowlevel signals instead of high-level reasoning. In this work, we
present a generative model for optimal action selection which
simultaneously can be employed to make predictions of others’
actions. As we base the decision making on a hidden state representation of sensorimotor signals, this model is in line with
the ideas of embodied intelligence. We demonstrate how the
tracking of others’ hidden states can give rise to correct falsebelief inferences, while a lack thereof leads to failing. With
this work, we want to emphasize the importance of sensorimotor contingencies in social cognition, which might be a key to
artificial, socially intelligent systems.
Keywords: social cognition, sensorimotor signals, affordances, false-beliefs, theory of mind.

could be involved in false-belief inferences. As social SMCs
and affordances belong to low-level cognitive mechanisms,
the tracking of these signals comes at a lower cost than mentalizing. While executive functions are of relevance for falsebelief tasks, see e.g. (Devine & Hughes, 2014), we want to
emphasize the importance of the understanding and incorporation of others’ SMCs into action prediction.
In this work, we investigate whether low-level social SMC
signals can give rise to false-belief inferences, a phenomenon
commonly believed to be caused by high-level cognitive reasoning. To this end, we develop a computational model that
demonstrates how the tracking of social affordances allows
for false-belief inferences. In order to include the temporal
evolution of social interaction and make use of the predictive
nature of cognition as proposed by the ST, we make use of
a Bayesian generative model which, based on hidden variables and prior knowledge, selects the optimal action towards
a given goal. While the presented model is generally applicable and not confined to false-belief tasks, we demonstrate
its generative power with help of the well-known Sally-Anne
test.

Introduction
Social cognition benefits highly from our ability to infer and
predict others’ percepts and future actions. Such inferences
have been postulated to occur on two levels; low-level sensorimotor contingencies (SMCs) and high-level goal and mental
state inferences. While the former phenomenon has been explained with help of the simulation theory (ST) and embodied cognition, the later inferences are commonly addressed
with help of the theory-theory (TT) and accounts of the theory of mind (ToM) (Dindo, Donnarumma, Chersi, & Pezzulo,
2015). While the simulation theory is supported by biological concepts such as mirror neurons, the ToM is rooted in
psychological approaches to social cognition.
One cornerstone of the theory of mind are “false-belief
tests”, which, according to the TT approach, necessitate the
ability to track and infer others’ mental states, beliefs and intentions. Since both young children and autistic children fail
false-belief tasks to a great extent, these tests are usually presented as a measure of advanced social intelligence. A recent proposal, however, views false-belief tasks in the light
of SMCs, with an emphasis on social affordances and working memory (Brincker, 2014). Instead of tracking and inferring others’ mental states, which is computationally expensive, the memory of past affordances, individual and shared,

False-Belief Tasks and the Theory of Mind
The Sally-Anne story goes as follows. Sally and Anne are
playing with a marble and two boxes, box A and B. Sally
puts the marble into box A and leaves the room. In her absence, Anne takes the marble from box A and puts it into box
B. Upon Sally’s return, the question is: Where will Sally look
for the marble? In a clinical or research setting, this story is
often either demonstrated with help of a pair of dolls or illustrated with a comic stripe. Participants, asked where Sally
will look for the marble, can give two answers. When passing the false-belief test, they successfully infer that Sally can
by no means know that Anne moved the marble. Thus, they
infer that Sally carries the false-belief that the marble is still
in box A, as this is the location where she put it. Failing the
false-belief test on the other hand implies that this inference is
not accomplished. Instead, the actual current location of the
marble, box B, is pointed out to be the goal of Sally’s next
action.
In an early study, Baron-Cohen et al. (Baron-Cohen,
Leslie, & Frith, 1985) showed that healthy children and children with Down syndrome are able to pass the Sally-Anne
test in 85-86 % in all cases, while autistic children pass only
in around 20 % of all trials. These and other findings have

1014

led to the belief that autistic children lack the ability to infer
others’ mental states and to develop, if at all, this trait later
than their peers. Furthermore, even healthy children pass explicit false-belief tests only from an age of two-five, which is
interpreted as a developmental account of a theory of mind
(Apperly, 2012).
In the view of the TT and ToM, mind reading is the ability
of humans to understand others’ beliefs, desires, intentions
and mental states by logically reasoning about their behavior with help of mental theories of the human mind. In the
Sally-Anne story, Sally’s desire to obtain the marble is hindered by her false-belief about the location of the object. The
interpretation of ToM with respect to the role of mental states
and beliefs differs within the research community (Apperly,
2012). This difficulty is only enhanced due to the fact that
different false-belief tasks test varying aspects of ToM and
subjects show diverging performances in different tests.
Hence, we claim here that TT can not fully account for
the experimental evidence of false-belief tasks. Instead, the
understanding of others’ SMC signals as well as executive
cognitive processes and low-level action constraints, such as
spatial and temporal conditions and goal-directedness, have
to be considered (Butterfill & Apperly, 2013).

Computational Approaches to False-Belief
Tasks
In order to gain more understanding of the underlying dynamics of ToM, computational models can help to identify the essential variables that give rise to correct predictions. We will here focus on three models concerned with
explicit (Goodman et al., 2006) and implicit (Berthiaume,
Onishi, & Shultz, 2008) false-belief tasks and a HumanRobot Interaction (HRI) setting (Ferreira, Milliez, Lefevre,
& Alami, 2015). While ToM has also been addressed with
help of inverse reasoning, e.g. inversion of Partially Observable Markov Decision Processes (POMDP) (Baker, Saxe, &
Tenenbaum, 2011), these approaches have not been applied
to a false-belief setting.
A probabilistic account of ToM has been developed by
Goodman et al. (2006). With the help of Bayesian networks,
two models, the copy theorist (CT) and the perspective theorist (PT), are compared. Both of these models incorporate
variables representing the world state, beliefs and desires of
an actor, while only the perspective theorist has access to
a variable indicating visual access. Manually defined, discrete probability distributions over mutual influences of these
variables allow for the derivation of a posterior distribution
over beliefs and desires given the observed events and actions. Additionally, the surprise about an observation can be
determined. As the CT is less complex, it is not able to represent a false-belief, resulting in a high level of surprise when
Sally is looking into the original box. The PT on the other
hand, predicts the false-belief correctly. Due to hand-picked
probability distributions and the additional information of visual access, the PT succeeds in the false-belief task. However,

the superimposed structure, simplicity of the model and lack
of temporal dynamics prohibit reliable conclusions about the
applicability of this model.
In contrast to the probabilistic viewpoint Berthiaume et al.
(2008) approached the implicit ToM, the idea that humans automatically and implicitly track others’ mental states, with a
neural network. To train networks with different numbers of
hidden unit layers, they presented the models with the state
and action data of an implicit Sally-Anne version. The training data was corrupted by adding incorrect samples. While
networks with no hidden units were not able to capture falsebeliefs, deeper networks could more reliably predict the behavior of the agents. Due to the nature of neural networks, the
performance increased with an increasing amount of training
samples. Furthermore, the results hint that the networks represented the statistics of the generated training data, with error rates matching the added noise. Although implicit knowledge should be more intuitive than explicit, conscious reasoning, it is dubious that this ability does only depend on correlations of observations. Instead, the internal motivation to
predict the actions of other agents and to engage in interaction
seems to be an important factor.
The examples introduced above function on the basis of
belief-desire inference on the one hand and correlations on
the other hand. As stated in the introduction, we propose
taking a sensorimotor approach towards false-belief inferences. One recent example of this idea has been introduced
by Ferreira et al. (2015) in a HRI setting. Applying two independent POMDP for the robot and human action space respectively, which use estimates of visual and reachable space
to determine hidden state information, this system is able
to interact with a human in a false-belief setting. By comparing manually designed and learned behavior, the authors
conclude that learning results in faster and more reliable predictions. Furthermore, a system that incorporates knowledge
about the humans belief space reacts faster towards misunderstandings. Nevertheless, the differences in performance
between belief incorporation and its absence are not significant. The advantages in conversation speed might be balanced by the additional computational load during the learning period. Additionally, the focus lies on successful communication while predictive power and a deeper analysis of the
system are not presented.

A Sensorimotor Approach to Social Inference
The application oriented approach towards false-belief inference based on visibility and reachability by Ferreira et al.
(2015), points towards the explanatory power of sensorimotor signals in a social context. Even Goodman et al. (2006)
and Berthiaume et al. (2008) conclude that visual access is an
important factor. Without this variable, both belief and desire
are not sufficient to account for false-belief inferences.
Thus, we propose that the theoretical considerations concerning ToM in such simple false-belief tasks as the SallyAnne test need to be revised. Instead of high-level reasoning

1015

The Model

Figure 1: A simplified version of active inference: The agent
is connected to the world through sensorimotor channels. Actions are chosen to minimize the distance between approximated hidden state and goal state distributions. The hidden
states are thought to represent hidden causes of events in the
world.

about mental states we suggest that tracking of SMCs and
affordances over time is the primary factor for successful inference.
Inspired by the ideas of predictive coding (Kilner, Friston,
& Frith, 2007) and active inference (Friston, Mattout, & Kilner, 2011) in the context of social cognition, we propose a
generative model of optimal action selection which can also
be employed for optimal action prediction of a co-actor. According to active inference, the human mind is prone to minimize uncertainty about the world state and sees actions as
an inferential process to fit internal state distributions to goal
distributions. The coupling between an agent and the world
is accomplished through sensorimotor channels as shown in
Figure 1. Since both actions and hidden causes can give rise
to changes in the world, the hidden state distributions are approximating these hidden causes.
Assuming that interaction partners are equipped with a
similar probabilistic inference machine, others’ actions can
be predicted with help of prior knowledge about their social
SMC signals and hidden and goal states. Since the consideration of other agents reduces uncertainty about future world
states significantly, these automatic mechanisms might account for many aspects of social cognition. Implicit tracking
of others’ sensory input and affordances is vital for both lowlevel and high-level interaction. We propose that failing in
false-belief task is less caused by the lack of ToM than by the
inability to identify and memorize others’ social SMC histories. In this case, estimates of the hidden state distributions
of the co-actor are impaired and have to be approximated by
ones own internal distributions at the current time. As the
hidden state distributions differ in the context of false-belief
tasks, such an assumption leads to incorrect inferences. In
the following, we will introduce a generative model that can
imitate both of these behaviors.

Our generative model is based on a joint distribution over observations and hidden states. Actions based on the current
hidden state estimates will have an effect on the actual environment. Optimal action selection is performed in two steps.
Firstly, the current observations are incorporated into the distribution over hidden states. Secondly, the optimal action,
which minimizes the distance between a given goal distribution and the updated hidden state distribution, is sought. The
found optimal action is then executed. In a Bayesian fashion, prior beliefs can be incorporated into the hidden state
distribution and affect action selection in a top-down manner.
In a further step, this model can be used to predict the actions of an interaction partner by using the same mechanisms
but different distributions over hidden states. Thus, instead
of inferring beliefs and desires, action prediction is based on
approximations of hidden states that represent SMC signals.
Mathematical Notation To clarify the mathematical notation, let v ∈ Rn be a column vector of dimension n and vT
denote the transpose. Equivalently, let M ∈ Rn,m represent
a matrix with n rows and m columns. The dimensions of a
vector are indexed by vi for i ∈ [1, ..n], while a matrix entry is
indexed by mi, j for i ∈ [1, ..n] and j ∈ [1, ..m]. Furthermore,
let the index t ∈ [1, ..T ] indicate the time step ranging from 1
to T , such that vt is a vector at time t. The time index for a
single vector in a set of N vectors {vt }N is represented by vt,k
for k ∈ [1, ..N].
Our generative model consists of a discrete vector representing the actual world state w ∈ RNw . Due to the noise inherent in perceptual channels, let an observation o ∈ RNo be
a representation of the world state with added noise such that
for each dimension i we have
oti = wti + εi ,

εi ∼ N (0, σi ),

(1)

where N (µ, σ) denotes the normal distribution with mean µ
and variance σ and σi is the variance belonging to the ith
dimension. Let the hidden states be represented by a set of Ns
normal distributions, denoted by {st }Ns , and each kth hidden
state consist of N f features such that
st,k ∼ N (µk , Σk ),

(2)

with mean µk ∈ RN f and covariance matrix Σk ∈ RN f ,N f . Finally, an agent is equipped with a set of Na actions ak for
k ∈ [1, ..Na ] that produce changes in the environment.
Integration of new observations In this discrete setting,
the joint probability distribution over hidden states and observations P(ot , {st }Ns ) at time t is defined as a mixture of
Gaussians
P(ot , {st }Ns ) = P(ot |{st }Ns )P({st }Ns )

(3)

Ns

=

∑ P(ot |st,k )P(st,k ).
k=1

1016

(4)

Assume that the conditional distribution of the observation
given the hidden states is multinomial distributed. Let the
parameters of this distribution be a linear combination of the
observations with a weight vector ui ∈ RNo that depends on
the respective hidden state such that
P(ot |st,k ) =

uTk ot
.
Ns
∑l=1 uTl ot

(5)

If the weight vectors have been determined, through learning or manual design, the update of the joint distribution
P(ot+1 , {st+1 }) is accomplished by inserting the new observation ot+1 into Eq. 3.
Optimal action selection Action selection is based on the
minimization of the distance between a given goal distribu∗ ) ∼ N (o∗ , σ
tion Pgoal (ot+1
t+1 goal I) and the joint probability
distribution P(ot+1 , {st }Ns ). Let this distance be defined as
the L2 vector norm of the distance between the mean vectors
of both distributions. Since this model is operating in a defined action space, let us assume, that an action ak produces a
discrete, deterministic hidden state ŝt+1 = Q(st+1 |{st }Ns , ak ),
where Q denotes a transition function. Then, Eq. 4 at time
t + 1 turns into

Figure 2: The Sally-Anne story enacted by our generative
model. For the purpose of visualization, the noise has been removed. Dark squares indicate a value of 1 and white squares
a value of 0. In the upper row, the dynamics of the story in
the world state are depicted, while the lower row shows the
hidden states of both agents in the view of Anne. Since Sally
is gone for several time steps, her hidden states are unknown
to Anne.

Ns

P(ôt+1 , ŝt+1 ) =

∑ P(ôt+1 |ŝt+1 )N (ŝt+1 : µk , Σk ),

(6)

k=1

where N (ŝt+1 : µk , Σk ) denotes the kth Gaussian evaluated at
ŝt+1 . Define p ∈ RNs to be a vector consisting of the evaluations of the Ns Gaussian distributions. Then, the approximated observation is given by
ôt+1 = U−T p,

(7)

where the matrix U consists of the stacked weight vectors u.
The optimal action is therefore selected by determining which
resulting approximate observation minimizes the L2 vector
norm
a∗ = argmin

∗
||(ôt+1 |ak ) − ot+1
||22 .

(8)

ak , k∈[1,..Na ]

When the optimal action is performed, it results in a change
of the environment as follows
ot+1 = P(ot+1 |st+1 )Q(st+1 |{st }Ns , a∗ ).

(9)

Action prediction Up to this point, the discussion was focused on the optimal action selection for a single agent. In a
joint setting, the same mechanism can be used to predict the
action of a co-actor. If the observing agent memorizes not
only its own past hidden state distributions, but also those of
its partner, the observer can use its internal models to make
inferences based on this information. As we assume the hidden states to represent SMC signals and affordances, many
of the hidden states are either identical or complementary,
such that the tracking of the additional states is computationally cheap. Thus, we assume that any agent keeps a memory over its own hidden states up to the current time T , i.e.

{s1:T }own , and an approximation of its partners hidden states,
i.e. {ŝ1:T }other . This approximation is based on the information made available by the observations and prior assumptions. Since the perceptual channels of the observed agent
are inaccessible, the input can only be estimated. But as both
agents share the same environment, these estimations can be
made under low uncertainty.

Experiment
The main goal of this work is to demonstrate that low-level
sensorimotor signals can account for inferences in a falsebelief task which are usually explained by high-level reasoning based on ToM. As the generative model presented above
allows predictions of others’ actions based on approximations
of hidden states which represent these low-level signals, we
can apply it to the Sally-Anne test. Following the idea of past
affordance tracking, suggested by Brincker (2014), we aim to
show that both passing and failing this false-belief task can
be accounted for by prior assumptions about others’ past affordances. In this scenario, we need to incorporate the two
agents Sally and Anne, the objects box A, box B and marble
and finally the room itself.
World Representation In order to test our generative
model in a false-belief setting, we need to specify the variables world state and hidden state and the transition function
describing effects of applied actions. While the former two
variables are defined to be binary, with feature 0 = false and
1 = true, the later represents changes in the hidden states and
world state.
Let the world state be defined as a vector with Nw = 6,

1017

information with her own representation at time t

representing the features marble in box A, marble in box B,
marble held by Sally, marble held by Anne, Sally present and
Anne present.
Furthermore, let each hidden state consist of N f = 9 features, box A is clearable, box A is fillable, box B is clearable,
box B is fillable, marble is takeable, marble is puttable, room
is leavable, agent X is holding and agent X is present.
Finally, let the Na = 4 actions be defined as agent X
takes marble from box Y, agent X puts marble into box Y,
agent X leaves room and agent X enters room, where X
∈ {Sally, Anne} and Y ∈ {A, B}.
We defined the parameters of the Gaussian distribution in
the mixture model and the mapping parameters of the multinomial distribution and the transition function manually. In
a more application oriented setting, these parameters could
also be learned either with help of learning by demonstration
or self-learning.

{ŝt }Sally = {st }Anne

or she recalls Sally’s representation at time τ < t when Sally
was last present in the room, i.e.
τ = max(t 0 ∈ [1, ...t] : {ŝt90 }Sally == 1|t 0 < t),
t0

{ŝt }Sally = {ŝτ }Sally .

Sally-Anne test As our generative model is generally applicable, we were able to let the model itself enact the SallyAnne story instead of predefining the variables manually. By
defining the goal observations at each time point t according
to the Sally-Anne story, the model determined the optimal
action and updated the distributions in accordance with the
mechanisms described above. This procedure was iteratively
performed up to the point, where Sally returns to the scene.
Fig. 2 illustrates the Sally-Anne story in this format.

What will Sally do next?
Upon Sally’s return, we ask the question “What will Sally
do next?”. In order to answer this question, we made use
of Anne’s inferential model since this agent has knowledge
about the current situation and Sally’s past hidden states.
Given that Sally has been absent, her hidden state representation at time t, i.e. {ŝt }Sally is unknown to Anne. However,
with the aim to predict her next action given that she wants to
hold the marble, the hidden states need to be approximated.
Anne has two alternatives. Either she replaces the missing

Figure 3: Predictions of the box that Sally would select based
on Anne’s generative model. To the left, the mapping approach demonstrates that the inference of a false-belief fails,
while the tracking approach to the right correctly predicts the
box into which Sally had put the marble before leaving.

(10)

(11)

While this approach is similar to the copy theorist (Eq.
10) and the perspective theorist (Eq. 11) as introduced by
Goodman et al. (2006), notice that our approach is not based
on the notion of beliefs and desires. Furthermore, we introduce temporal dynamics which make a fluent interaction possible, while Goodman et al. (2006) work in a static environment with predefined variables and distributions. Since our
idea is not following the TT approach but the ideas of ST, our
agents can not be viewed as theorists. Therefore, we denote
the approach of Eq. 10 as mapping and the past affordance
incorporation in Eq. 11 as tracking.

Results
For the sake of reliability, we performed N = 1000 trials of
the Sally-Anne test. Due to the induced noise in the mapping
from world state to observation and the variance of the Gaussian distributions representing the hidden states, the model
did occasionally fail to complete the Sally-Anne story up to
the point where Sally returns, i.e. it selected incorrect actions.
These trials were omitted and replaced by a newly generated,
successful trial. The average of the predicted location where
Sally will look for the marble is depicted in Fig. 3 for both
the mapping and the tracking approach. While the mapping
approach incorrectly predicted that Sally would look at the
actual location in 89 % of all trials, the tracking approach
correctly inferred Sally’s behavior in 91 % of all trials. These
results match closely those found in e.g. healthy (tracking)
and autistic (mapping) children as reported in Baron-Cohen
et al. (1985).

Discussion
In this work, we presented a generative model based on social
SMCs which can be employed for both optimal action selection and prediction. Instead of mental state, belief and desire
inferences, we hypothesize that SMCs can account for complex social behavior such as the recognition of a false-belief.
In this context, the tracking of others’ past affordances gives
rise to successful inferences, while a failure of these basic
sensorimotor functions results in incorrect predictions.
Why would the inference and tracking of others’ SMCs be
of advantage compared to belief and desire inferences? First
of all, the two approaches have not to be seen as contradictory
but as complementary. While the social SMC approach might
be involved to a great extent in social behavior, high-level reasoning is also a non-negligible part of interaction. Instead, we
argue for a shift from pure ToM reasoning towards the integration of essential, sensorimotor functions. As shown in this

1018

work, social SMC signals can account for complex interaction scenarios, while a lack or impairment of these functions
leads to the impoverished social capabilities found in infants
and autistic children. A focus on the entanglement between
low- and high-level cognition in a social context might reveal
important information for medical and therapeutic research.
One could argue that the memory of the world state alone
would result in the same predictions. Instead of inferring an
affordance space, the mere knowledge where the marble had
been when Sally was present could suffice. It is important
to keep in mind, that the world and agent are two separate
entities, coupled through sensorimotor channels. Thus, the
agent has no direct access to the location of the marble but
only to the hidden state representation of hidden causes in
the environment. Without the inference of the co-actor’s representation, successful prediction is impaired since the representations of observer and observed are entwined but not
identical.
How can such representations of others be acquired? Similar to other computational approaches towards false-belief
tests, such as Berthiaume et al. (2008) and Goodman et al.
(2006), we defined many parameters manually. However,
with a sufficient amount of training data, the model could be
learned in an adaptive fashion and be generally applicable in
dynamic interaction scenarios. As two agents share a considerable amount of the hidden state space, shared latent variable
models are one method that could be applied to this method.
While Ferreira et al. (2015) implemented a dynamic, socially
interactive system, they did not account for this redundancy in
the data. A putative future extension of the presented model
is therefore an actively learning system which detects shared
and individual latent manifolds in the action space that effectively encode action possibilities. Such an approach is both
data efficient and reduces the complexity of high-dimensional
interaction spaces. Models based on social SMCs can then be
employed in interactive agents that are able to master complex scenarios as e.g. a false-belief setting.

Conclusions
The Theory of Mind has a long tradition to account for complex, social behavior. Mental state inferences and the reasoning about beliefs and desires are viewed as a mile stone in
mental development. Advances of the idea of embodied intelligence however have started to give a complementary explanation of social phenomena. In this work, we demonstrated
how the tracking of others’ SMCs and affordances can be involved in certain false-belief inferences. This low-level approach to high-level cognition can clear the way for artificial
agents in which social intelligence emerges naturally through
the coupling between action and perception. Furthermore, a
deeper insight in the underlying dynamics of social interaction results in valuable information for medical and psychological research and applications. In conclusion, sensorimotor signals are vital for social interaction. Their incorporation into theoretical frameworks of social intelligence is an

important step towards an embodied understanding of social
communication.

Acknowledgments
References
Apperly, I. A. (2012). What is theory of mind? concepts, cognitive processes and individual differences. The Quarterly
Journal of Experimental Psychology, 65(5), 825–839.
Baker, C. L., Saxe, R. R., & Tenenbaum, J. B. (2011).
Bayesian theory of mind: Modeling joint belief-desire attribution. In Proceedings of the 32nd Annual Conference
of the Cognitive Science Society (pp. 2469–2474).
Baron-Cohen, S., Leslie, A. M., & Frith, U. (1985). Does the
autistic child have a “theory of mind?”. Cognition, 21(1),
37–46.
Berthiaume, V. G., Onishi, K. H., & Shultz, T. R. (2008).
A computational developmental model of the implicit false
belief task. In Proceedings of the 30th Annual Conference
of the Cognitive Science Society. (pp. 825–30).
Brincker, M. (2014). Navigating beyond “here and now”
affordances - on sensorimotor maturation and “false belief”
performance. Frontiers in Psychology, 5.
Butterfill, S. A., & Apperly, I. A. (2013). How to construct
a minimal theory of mind. Mind & Language, 28(5), 606–
637.
Devine, R. T., & Hughes, C. (2014). Relations between false
belief understanding and executive function in early childhood: A meta-analysis. Child Development, 85(5), 1777–
1794.
Dindo, H., Donnarumma, F., Chersi, F., & Pezzulo, G.
(2015). The intentional stance as structure learning: a computational perspective on mindreading. Biological Cybernetics, 109(4-5), 453–467.
Ferreira, E., Milliez, G., Lefevre, F., & Alami, R. (2015).
Users belief awareness in reinforcement learning-based situated human-robot dialogue management. In 7th International Workshop on Spoken Dialogue Systems.
Friston, K., Mattout, J., & Kilner, J. (2011). Action understanding and active inference. Biological Cybernetics,
104(1-2), 137–160.
Goodman, N. D., Baker, C. L., Bonawitz, E. B., Mansinghka,
V. K., Gopnik, A., Wellman, H., Tenenbaum, J. B. (2006).
Intuitive theories of mind: A rational approach to false belief. In Proceedings of the 28th Annual Conference of the
Cognitive Science Society (pp. 1382–1387).
Kilner, J. M., Friston, K. J., & Frith, C. D. (2007). Predictive
coding: an account of the mirror neuron system. Cognitive
Processing, 8(3), 159–166.

1019

