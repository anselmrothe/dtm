Expressive faces are remembered with less pictorial fidelity than neutral faces
Martina Lorenzino (martina.lorenzino@unifi.it)
Department of Neurosciences, Psychology, Drug Research, and Child Health (NEUROFARBA), University of Florence
via di San Salvi 12, Complesso di San Salvi, Padiglione 26, 50135 Firenze (FI), Italy

Giorgio Gronchi (giorgio.gronchi@unifi.it)
Department of Neurosciences, Psychology, Drug Research, and Child Health (NEUROFARBA), University of Florence
via di San Salvi 12, Complesso di San Salvi, Padiglione 26, 50135 Firenze (FI), Italy

Corrado Caudek (corrado.caudek@unifi.it)
Department of Neurosciences, Psychology, Drug Research, and Child Health (NEUROFARBA), University of Florence
via di San Salvi 12, Complesso di San Salvi, Padiglione 26, 50135 Firenze (FI), Italy
Abstract

the other hand, what characterizes face-identity recognition
is exactly the ability to isolate the identity-defining properties
of a face, while disregarding its transient features (e.g., pose,
lighting, transient muscles variations, and so on). Thus, in
general, one might expect that a better ability to recognize a
face comes to the cost of a worst pictorial fidelity with which
that face is represented in memory.
The aim of the present study is to measure the pictorial
fidelity of the Visual Working Memory (VWM) representations of expressive and neutral faces. In this regard, we can
make a specific prediction which is motivated by the following considerations. All the rest being the same, we should
expect that is more important to remember the identity of a
stranger if, in a casual encounter, she/he displays an angry expression (or a happy expression, for that matter) rather than a
neutral face (Jackson et al., 2009; Jackson et al., 2014). This
seems obvious, considering the implications of this situation
for future social interactions with that person. On the top of
this, we should also consider the fact that, as remarked above,
the creation of a facial-identity category requires the selection of the identity-defining features and the omission of the
category-irrelevant features. Specifically, the transient pictorial features of a face (the image properties that vary as a function of illumination, pose, and so on) are certainly irrelevant
for a facial-identity category. Therefore, we hypothesize that
(1) these transient pictorial properties are represented with a
lower pictorial fidelity in memory when a facial-identity category is created, and (2) this process is stronger for expressive
compared to neutral faces, because it is more important to
recognize facial identity in the former case than in the latter.
A face can be represented in memory with different degrees
of pictorial fidelity. For example, we can remember the gist of
a face and disregard its pictorial details (Leal, Tighe, & Yassa,
2014), or we keep in memory a very detailed photographic
representation of a face. By adapting the procedure of Wilken
and Ma (2004), in the present study we asked participants to
select from a morphing continuum the image of a learned face
(e.g., Bays & Husain, 2008; Lorenc et al., 2014; Zhang &
Luck, 2008). We expect to find (1) a lower pictorial fidelity
of VWM for expressive compared to neutral faces, and (2) a
decrease in VWM fidelity with the increase of the set size of

A repeated finding in the literature of face recognition is that
expressive faces are remembered better than neutral faces.
However, a better facial-identity recognition may come at a
cost of a reduced precision with which the pictorial facial features, irrelevant for identity recognition, are represented in
memory. By means of a continuous-report task, we tested
this hypothesis by measuring the memory precision of expressive and neutral faces. Commensurable face-identity and
facial-expressions variations were generated with the method
of Fechnerian scaling. The results confirm our hypothesis, but
only under conditions of high memory load. We interpret the
present findings as due to the effects of the categorical processes required for facial-identity recognition.
Keywords: emotion; faces; continuous-report procedure; visual working memory

Introduction
It has been often shown that expressive faces are easier to
remember than neutral faces (Jackson et al., 2008; Langeslag et al., 2009). Some studies have found an advantage for
the memory of positive expressive faces compared to negative
faces (D’Argembeau & Van der Linden, 2007; D’Argembeau
et al., 2003; Shimamura, Ross, & Bennett, 2006). However,
the greatest evidence for a memory advantage for expressive
versus neutral faces comes from studies comparing memory
for facial expressions with a negative valence and with neutral faces (Jackson et al., 2008; Jackson, Linden, & Raymond,
2014; Jackson et al., 2009; Sessa et al., 2011). This memory
advantage has been attributed to a more accurate encoding
and memory maintenance for expressive faces, compared to
neutral faces (Jackson et al., 2014; Ridout et al., 2003; Sergerie, Lepage, & Armony, 2005; Sessa et al., 2011).
It is important to point out that the majority of studies in
this area of research has employed an old-new face recognition task, in which participants are asked to decide whether
a test face had been previously presented in an array of expressive faces, or not. In this respect, it should be noted that
a better performance in a old-new recognition task does not
necessarily imply a better pictorial resolution for the memory
representation of expressive faces compared to neutral faces.
In fact, the memory representation of a face endowed of a
high pictorial fidelity contains all those transient facial features which are irrelevant for face-identity categorization. On

171

tinuum between a neutral face A to an “happy” face (50hA)1
with the same identity (Figure 1b, top row); (3) a continuum
between a neutral face A to an “angry” face (50aA)2 with the
same identity (Figure 1c, top row).

to-be-remembered faces.

Experiment
The degree of pictorial fidelity with which a face is represented in memory can be measured with the continuous report task (Wilken & Ma, 2004). Although this task has been
mostly employed with simple features (such as orientation
or color, for example), it can also be used with faces. In
the present study, participants were required to select a probe
within a morphing continuum in order to match it to a learned
face. This task was performed with face images belonging
to two different kinds of morphing continua. A first continuum provided facial-identity variations with a neutral facial
expression. A second continuum provided emotional expressions variations while keeping constant facial identity.
In general, it’s not possible to directly compare distances
along different morphing continua, because there is not a
linear relation between the physical distance on such continua and the similarity space among the stimuli in the mental memory representations (Caudek, 2013; Danilova & Mollon, 2014). To deal with this problem, we generated the two
morphing continua with the technique of Fechnerian scaling,
which creates (for each participant) perceptually commensurable spaces for identity and expression variations. In this
manner, the memory fidelity for the two classes of stimuli can
be directly compared because, in both cases, the unit of measurement for each continuum corresponds to each subject’s
threshold of perceptual discrimination (Domini & Caudek,
2009; Dzhafarov & Colonius, 1999).

Figure 1: (a). Creation of the Identity Neutral continuum. A
100-steps morphing was created between image A and image B. The image that produced an 82% rate of correct discrimination between A and B was employed as the new extreme (AB) for the creation of a new morphing continuum.
This procedure has been repeated in order to obtain four
thresholds of perceptual discrimination (AB, ABC, ABCD,
ABCDE). (b-c). Creation of Emotional Expression continuum. A 100-steps morphing was created between image A
and image 50hA and between image A and 50aA. The images
that produced an 82% rate of correct discrimination between
A and 50hA and between A and 50aA were employed as the
new extremes (hA and aA, respectively) for the creation of a
new morphing continuum. This procedure has been repeated
in order to obtain four thresholds of perceptual discrimination
(hA, hA+, aA and aA+).

Method
Participants Eight subjects (n=8; 7 females; age range 2630 years) with normal or corrected-to normal vision participated voluntarily to the Experiment. They were naı̈ve to the
purpose of the study and none of them had previously been
exposed to the stimuli employed. The experiment was undertaken with the understanding and written consent of each
participant. The experiment conformed with the institutional
and national guidelines for experiments with human subjects
and with the Declaration of Helsinki.
Stimuli Seven Caucasian faces (all males) were selected
from the Karolinska Directed Emotional Faces database
(Lundqvist, Flykt, & Öhman, 1998): Five images showed five
different facial identities with a neutral expression (A, B, C,
D, E, Figure 1a) and two images represented one of the previous facial identities with an happy and an angry emotional
expression (100hA, 100aA, Figure 1b-c). All images were
converted to grayscale, an oval aperture was superimposed on
each face, and the ovals were placed on a transparent background. Each face image measured 280 × 329 pixels and all
stimuli were matched for luminance and contrast values. We
generated three different morphing continua: (1) a continuum
between two face identities (indicated with A and B), both
having a neutral expression (Figure 1a, top row); (2) a con-

Procedure Phase 1. With the method of Fechnerian scaling, we generated the morphing continua that were then used
in Phase 2. A 2AFC discrimination task was used for determining face discrimination thresholds between pairs of images belonging to each morphing continuum. For the fa1 The 50hA image corresponded to the image numbered 50 of a
morphing continuum between A and 100hA.
2 The 50aA image corresponded to the image numbered 50 of a
morphing continuum between A and 100aA.

172

cial identity variations, for example, we created a morphing continuum between two facial identities. We kept fixed
one image (origin of the scale) and then, with psychometric
methods, we selected a second face image which produced,
for each participant, an 82% success rate in a perceptualdiscrimination task. We then morphed this second image
with a third face identity and repeated the procedure (Figure
1a). In this manner, we selected, for each participant, four
face images (three pairs of images, each one characterized by
one threshold of perceptual discrimination). We then linearly
morphed each of the successive pairs of images, so as to generate the Fechnerian continuum for face-identity variations
(Figure 2a). A similar procedure was used for generating the
Fechnerian continuum for face-expressions variations (Figure
1b-c; 2b).
To determine each perceptual discrimination threshold, in
each trial we presented the reference face (i.e., the frame
number 10 within the morphing continuum) and one of seven
test faces corresponding to greater distances along the morphing continuum from the reference face. A 1.000 ms fixation
cross indicates the start of each trial, followed by a 1.000 ms
blank screen. A comparison face (frame 100 of the morphing continuum) was centrally presented for 1.000 ms. After
a 1.000 ms blank screen, the reference and test faces were
centrally presented side-by-side. Participants were asked to
decide which of the two simultaneously presented faces was
more similar to the comparison face presented before each
trial. Stimuli were shown on the screen until the participant’s
response (Figure 3a).
A psychometric function was computed for each participant. The psychometric function was defined by the equation
P(x) = γ + (1 − γ − λ)p(x), where γ is the lower asymptote,
λ is 1 - the upper asymptote, and p(x) is the base psychometric function, varying between 0 and 1 (Wichmann & Hill,
2001)3 . From this fitted psychometric curve we then derived
the stimulus image corresponding to an 82% rate of correct
discrimination.
Phase 2. Each trial started with a fixation point for 1.000
ms, then one or four faces were presented on the screen for
4.000 ms. After a 1.000 ms blank screen, participants were
asked to select, from the Fechnerian continua generated in
phase 1, the image that more closely matched the test stimulus. Participants could move along the Fechnerian continuum
with a keypress, with only one image being shown on the
screen at any time.
For set-size four, each trial started with a fixation point for
1.000 ms, then four faces were shown on the screen for 4.000
ms. After a 1.000 ms blank screen, four grey ovals were
shown on the screen for 3.000 ms, in the same positions as
the previously presented faces, with a red dot indicating the
to-be-remembered face (Figure 3b).
Each session included 160 trials with 8 blocks of 20 trials
each and lasted for about 1 hour. Each participant completed

Figure 2: Each Fechnerian morphing continuum was created,
for each participant, by morphing between the four images
corresponding to the face discrimination thresholds measured
in Phase 1 and consisted of 80 images. We generated two
different types of Fechnerian continua: One Fechnerian morphing continuum of facial identity variations with a neutral
expression (Identity Neutral [IN] continuum) and one Fechnerian morphing continuum of variations of emotional expression (Emotional Expression [EE] continuum). (a) IN
continuum. The continuum was created by generating 20steps morphing between faces corresponding to the discrimination thresholds obtained in the first phase (A/AB, AB/ABC,
ABC/ABCD, ABCD/ABCDE). (b) EE continuum. The continuum was created by generating 20-steps morphing between
faces corresponding to the discrimination thresholds obtained
in the first phase (hA+/hA, hA/A, A/aA, aA/aA+).

a total of 320 trials (160 × 2 set-sizes). The two set-sizes
were tested in separate sessions, with the order of presentation of the two sessions being counterbalanced among participants.

Results
Figure 4 shows the average distance between the test face and
participants’ response, for each Fechnerian morphing continuum and for each set-size. The average response error was
smaller than the average perceptual discrimination thresholds
measured in Phase 1. The difference in memory fidelity between the IN and EE continua was not statistically significant,
χ21 = 0.44, p = .5075. The effect of Set-size was statistically
significant, χ21 = 3.85, p = .049. More importantly, the Continuum × Set-size interaction was statistically significant, χ21
= 10.49, p = .0012. We also divided the EE continuum into
two segments (“happy faces,” from frame 1 to frame 40, and
“angry faces,” from frame 41 to frame 80). However, the effect of face valence (positive, negative) was not statistically
significant, χ21 = 1.60, p = .2057. The Face Valence × Setsize interaction was not statistically significant, χ21 = 0.19, p
= .6599.

3 Psychometric functions were fitted by using R (R Core Team,
2013) and psyphy (Knoblauch, 2007)

173

new recognition task, occurs at the expenses of the pictorial precision with which the expressive faces are represented
in memory. The recognition of face identity is the consequence of an act of categorization. Each act of categorization
weakens the representation of the category-irrelevant features
(Caudek, 2013). We assumed that remembering face identity
is more important for expressive than for neutral faces. As
a consequence, we hypothesized that expressive faces should
be represented in memory with a lower pictorial fidelity than
neutral faces. Our results confirm this hypothesis, but only
for set-size of four (not for set-size of one). We interpret this
result as indicating that the negative impact of the categorization processes on the pictorial fidelity of the memory representation is stronger under a high memory load. With a low
memory load, in fact, we found no difference in the precision
of VWM for neutral and expressive faces, thus replicating the
results of Bankó, Gál, & Vidnyánszky (2009).
Although it could be expected that face identity recognition
is more important in the case of angry compared to happy
faces (Jackson et al., 2009; Jackson et al., 2014), we did
not find a difference between these two conditions. However, it should be noted that in the present study the level of
emotional intensity was very low. Therefore, we could expect different effects on memory fidelity for angry compared
to happy faces when emotional intensity is higher. Finally,
in line with the previous literature, we found a decrease of
VWM precision with an increase of set size (Alvarez & Cavanagh, 2004; Bays & Husain, 2008; Brady, Konkle, & Alvarez, 2011; Caudek, 2013).
A few limitations deserve mention. In particular, the
present experimental design does not allow to determine if
results are due to differences in memory for emotional versus
neutral faces, or differences in memory for expression versus
identity. To address this limit, in future experiments we plan
to compare memory for emotional versus neutral faces by using the same type of response continuum, by producing stimulus variations, for example, by a change in the illuminant
direction or in the orientation of the face, or by considering
the subtle transformations of the morphological properties of
the face during speech and language production. A second
limit of the present study concerns the low statistical power
due to small sample size. Finally, another issue to consider in
future research has to do with the impact that face familiarity
may have on VWM fidelity. We expect that familiar faces, by
encouraging an act of individuation more strongly than unfamiliar faces, will show a lower VWM fidelity for transient
facial features than unfamiliar faces. At the upper extreme
of the familiarity spectrum, the self-face is the most important face (Kircher et al., 2001). Therefore, we speculate that
VWM fidelity for irrelevant information should be lower for
the self-face than for other personally-familiar faces.

Figure 3: Experimental procedure. (a) In the simultaneous discrimination task (Phase 1) participants were forced to
choose the face more similar to a comparison face previously
shown. (b) In the continuous report task (Phase 2) a set (n =
1 or n = 4) of randomly chosen faces from a Fechnerian morphing continuum were shown (the figure reports the 4 items
set-size condition). After 1 second interval, a cue indicated
which image had to be remembered. In order to produce the
response, participants manipulated a scalar probe that could
vary along the morphing continuum.

Figure 4: Average of the absolute value of the difference between the value of the Fechnerian morphed face reported by
each participant and the value of the studied Fechnerian morphed face, for the IN and EE continua, as a function of the
set-size.

Conclusions
Discussion

The VWM advantage for expressive compared to neutral
faces that had been found with the old-new recognition task

We asked whether the memory advantage for emotional compared to neutral faces, which has been found with the old-

174

comes with a cost: Expressive faces are represented in VWM
with a lower pictorial fidelity than neutral faces. We interpret
this result as due to the effects of the categorical processes
required for facial identity recognition.

Langeslag, S. J., Morgan, H. M., Jackson, M. C., Linden,
D. E., & Van Strien, J. W. (2009). Electrophysiological correlates of improved short-term memory for emotional faces.
Neuropsychologia, 47, 887-896.
Leal, S. L., Tighe, S. K., & Yassa, M. A. (2014). Asymmetric effects of emotion on mnemonic interference. Neurobiology of Learning and Memory, 111, 41-48.
Lorenc, E. S., Pratte, M. S., Angeloni, C. F., & Tong, F.
(2014). Expertise for upright faces improves the precision
but not the capacity of visual working memory. Attention,
Perception, & Psychophysics, 76, 1975-1984.
Lundqvist, D., Flykt, A., & Öhman, A. (1998). The
Karolinska directed emotional faces (KDEF). CD ROM from
Department of Clinical Neuroscience, Psychology section,
Karolinska Institutet, 91-630.
Ridout, N., Astell, A. J., Reid, I. C., Glen, T., & O’Carroll,
R. E. (2003). Memory bias for emotional facial expressions
in major depression. Cognition and Emotion, 17, 101-122.
Sergerie, K., Lepage, M., & Armony, J. L. (2005). A face
to remember: Emotional expression modulates prefrontal activity during memory formation. NeuroImage, 24, 580-585.
Sessa, P., Luria, R., Gotler, A., Jolicur, P., & Dell’Acqua,
R. (2011). Interhemispheric ERP asymmetries over inferior parietal cortex reveal differential visual working memory
maintenance for fearful versus neutral facial identities. Psychophysiology, 48, 187-197.
Shimamura, A. P., Ross, J., & Bennett, H. (2006). Memory
for facial expressions: The power of a smile. Psychonomic
Bulletin & Review, 13, 217-222.
Wichmann, F. A., & Hill, N. J. (2001). The psychometric
function: I. Fitting, sampling, and goodness of fit. Perception
& Psychophysics, 63, 1293-1313.
Wilken, P., & Ma, W. J. (2004). A detection theory account
of change detection. Journal of Vision, 4, 1120-1135.
Zhang, W., & Luck, S. J. (2008). Discrete fixed-resolution
representations in visual working memory. Nature, 453, 233235.

References
Alvarez, G. A., & Cavanagh, P. (2004). The capacity of
visual short-term memory is set both by visual information
load and by number of objects. Psychological Science, 15,
106-111.
Bankó, M., Gál, V., & Vidnyánszky, Z. (2009). Flawless
visual short-term memory for facial emotional expressions.
Journal of Vision, 9, 1-13.
Bays, P. M., & Husain, M. (2008). Dynamic shifts of limited working memory resources in human vision. Science,
321, 851-854.
Brady, T. F., Konkle, T., & Alvarez, G. A. (2011). A review
of visual memory capacity: Beyond individual items and toward structured representations. Journal of Vision, 11, 1-34.
Caudek, C. (2013). The fidelity of visual memory for faces
and non-face objects. Acta psychologica, 143, 40-51.
D’Argembeau, A., & Van der Linden, M. (2007). Facial
expressions of emotion influence memory for facial identity
in an automatic way. Emotion, 3, 507-515.
D’Argembeau, A., Van der Linden, M., Comblain, C., &
Etienne, A.-M. (2003). The effects of happy and angry expressions on identity and expression memory for unfamiliar
faces. Cognition and Emotion, 17, 609-622.
Danilova, M. V., & Mollon, J. D. (2014). Symmetries and
asymmetries in chromatic discrimination. JOSA A, 31, A247A253.
Domini, F., & Caudek, C. (2009). The intrinsic constraint
model and Fechnerian sensory scaling. Journal of Vision, 9,
1-15.
Dzhafarov, E. N., & Colonius, H. (1999). Fechnerian metrics in unidimensional and multidimensional stimulus spaces.
Psychonomic Bulletin & Review, 6, 239-268.
Jackson, M. C., Linden, D. E., & Raymond, J. E. (2014).
Angry expressions strengthen the encoding and maintenance
of face identity representations in visual working memory.
Cognition and Emotion, 28, 278-297.
Jackson, M. C., Wolf, C., Johnston, S. J., Raymond, J. E.,
& Linden, D. E. (2008). Neural correlates of enhanced visual
short-term memory for angry faces: an FMRI study. PLoS
One, 3, e3536.
Jackson, M. C., Wu, C. Y., Linden, D. E., & Raymond, J. E.
(2009). Enhanced visual short-term memory for angry faces.
Journal of Experimental Psychology: Human Perception and
Performance, 35, 363-374.
Kircher, T., Senior, C., Phillips, M. L., Rabe-Hesketh, S.,
Benson, P., Bullmore, E. T., ... David, A. S. (2001). Recognizing one’s own face. Cognition, 78, 1-15.
Knoblauch, K. (2007). psyphy: Functions for analyzing
psychophysical data in R. R package version 0.0-5, URL
http://CRAN. R-project. org/package= psyphy.

175

