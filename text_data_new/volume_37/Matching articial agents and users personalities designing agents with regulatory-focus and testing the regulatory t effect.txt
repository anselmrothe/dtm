Matching artificial agents’ and users’ personalities: designing agents with
regulatory-focus and testing the regulatory fit effect
Caroline Faur (faur@limsi.fr)
LIMSI-CNRS, rue John Von Neuman, bt 508
91403 Orsay Cedex, France

Jean-Claude Martin (martin@limsi.fr)
Celine Clavel (clavel@limsi.fr)
Abstract

Thus, endowing artificial companions with personality could
also help to increase the companion’s believabiity, hence easing the interaction and thereby, producing an adequate environment for a relationship to take place. At the same time,
personality complementarity and similarity have been shown
as important factors for the acceptance of an interface by a
user (Nass & Lee, 2001). So, if something can be build between one user and its artificial companion, both personalities
(user’s and companion’s) will impact this relationship.
In this article, we propose to take a socio-cognitive approach of personality and use the regulatory focus theory
(Higgins, 1997) as a framework to endow artificial agents
with personality. Regulatory focus theory comes with the
concept of regulatory fit (Higgins, 2005): when people perceived a ”fit”, i.e. congruent regulatory focus, between them
and an object (in every sense), they feel ”right” about their interaction and the experience of ”correctness and importance”
is passed on the object, increasing its superficial worth (Avnet
& Higgins, 2003). We will adress three questions: 1/ how can
we implement regulatory focus for artificial agents, 2/ is the
intended personality perceived as such, and 3/ can we reproduce a regulatory fit effect between such an agent and users?
Therefore, we will present our data-driven approach of personality modelisation, along with an user study adressing the
last two issues.

Artificial agents are becoming more than human-computer interfaces: they are becoming artificial companions, interacting on a long-term basis and building a relationship with the
user. This evolution brought new challenges, such as designing agents with personalities to the benefits of users. We endow artificial agents with regulatory focus, taking a sociocognitive approach of personality, by using machine-learning
techniques. We test whether this personality can be perceived
by users and if there is a regulatory fit effect on the users credibility judgement of the agent (i.e. is the agent perceived as
more credible if its regulatory focus is the same as that of
the user?). Our results show agents regulatory focus can be
adequatly perceived by users playing a board game against
an agent expressing its regulatory focus via machine-learned
strategies. A regulatory fit effect was found on the likeability judgment for prevention focus users but not for promotion
focus users.
Keywords: Artificial agents; Personality; Regulatory fit; User
study; Affective computing

Introduction
In the last decade, software agents were brought to a new
level, due to technological evolutions : artificial agents ceased
to be only human-computer interfaces to become artificial
companions (Benyon & Mival, 2010). An articial companion
can be defined as ”a personalised, multi-modal, helpful, collaborative, conversational, learning, social, emotional, cognitive and persistent computer agent that knows its owner, interacts with the user over a long period of time and builds a
(long-term) relationship to the user” (Sviatlana, Busemann,
& Schommer, 2012). If we are going to be in ”relationship”
with our artificial companions, we better be compatible ! But
compatibility is not just a concept created by dating websites.
There is a wide range of studies about the impact of personality on any kind of relationships: from couples (Robins,
Caspi, & Moffitt, 2000) to teachers (Karwowski, 2011) or
work teams (Nahrgang, Morgeson, & Ilies, 2009). Thus, it
seems logical to think that endowing an artificial companion
with personality could have benefits.
Personality can be define as a coherent patterning of affect,
behavior, cognition, and desires (goals) over time and space
(Revelle & Scherer, 2009). From an affective computing perspective, believability is assessed by the consistency and the
coherence of an artificial entity at various levels (psychological and physical; intrapersonal as well as social) (Isbister &
Doyle, 2002; Niewiadomski, Demeure, & Pelachaud, 2010).

Theorical Background
Personality and affective computing
In 2000, Nass and Moon (Nass & Moon, 2000) suggest the
Computers As Social Actors (CASA) paradigm. The CASA
paradigm states that people tend to adopt social attitudes with
machines that can elicit social heuristics. So, personality can
be attributed by users to a computer and have an influence
over users’ behaviors. In this view, designing specific personalities that are perceived such as they were designed seems
especially important. If computer scientists make sometimes
their own model of personality (Gmytrasiewicz & Lisetti,
2002), most of the works in affective computing lean on psychological models. As the Five Factors Model (FFM) (Costa
& McCrae, 1992) is a dominant and well-known model in
personality psychology, this model is naturally becoming the
most used reference in affective computing. The five dimensions proposed, also known as the Big Five, are : Openness

662

to experience, Conscientiousness, Extraversion, Agreeableness and Neuroticism. The concept of trait can easily be
approached in a numerical way, an ideal way for computer
scientists. The five traits are used, all or in subsets, as variables altering behaviors of artificial agents (for a state-ofthe-art, see (Vinciarelli & Mohammadi, 2014)). Regarding
users’ preferences in terms of artificial personalities, compatibility of personalities have been studied inside the same
FFM framework. For now, researchers focuses especially on
the Extraversion trait (because extraversion is the most ”conveyable” trait through verbal and non-verbal behaviors). If
we overlook this limitation, literature shows that similarity
attraction is found (e.g. an introverted person prefers a introverted entity) (Nakajima et al., 2003) as well as complementary attraction (e.g. an introverted person prefers an extraverted entity) (Tapus, Tapus, & Matari, 2008). This effect
may be moderated by the social role of the artificial entity and
the stereotype expectations associated with this role (Joosse,
Lohse, Perez, & Evers, 2013; Tay, Jung, & Park, 2014). That
is one of the limits of the traits approach. Traits theories are
especially useful for the description of the personality. But,
by looking at the global structure of personality, they hide
intraindividual differences.
On the contrary, socio-cognitive models are explicative per
se. The socio-cognitive approach to personality underlines
the importance of a situation in exhibiting personality behaviors (Bandura, 1999). This approach attempts to understand
cognitive and social processes that lead to personality. For
that purpose, it focuses on the interaction between the person
and the social context and highlights the intra-individual differences (Mischel, Shoda, & Smith, 2004). That’s why we
take a more socio-cognitive approach of personality (Faur,
Clavel, Pesty, & Martin, 2013). Further to our previous
work, we propose to use the regulatory-focus theory (Higgins,
1997) as a framework for endowing artificial agents with personality.

Regulatory-fit states that matching user’s regulatory-focus
and means used to approach one goal creates a feeling
of rightness about the pursued goal and increases task engagement (Higgins, 2005). For example, a user in a state
of promotion-focus will be more receptive to promotionoriented messages (and respectively for prevention-focus)
(Lee & Aaker, 2004). Benefits of regulatory fit are explored in several domains like in working environments
(Park, Hinsz, & Nickell, 2015) or communications (Ludolph
& Schulz, 2015) but not in affective computing. Yet, if an
artificial companion can create a state of regulatory-fit with
its user, we can hope that the feeling of rightness and correctness will be transferred to the agent, increasing its likeability/credibility (i.e. its capacity of being perceived as believable and convincing (Burgoon et al., 2000)) along with
the user’s engagement towards the agent and the task they are
doing together.
To our knowledge, there is currently no study exploring
users’ preferences for artificial personalities based on the regulatory fit or the regulatory focus theory.

Methodology
Convey personality via game strategies
In this paper, we used a board game strategy as the first and
only modality for expressing the artificial agents personality. Several links have been made between personality and
games, in psychology (Bartle, 1996) and in computer sciences (Johansson & Verhagen, 2014). Games are quite relevant for designing and evaluating affective agents (Gratch,
Marsella, Wang, & Stankovic, 2009; Courgeon, Clavel, &
Martin, 2014). We selected as an application a board game,
named Cant Stop (designed by Sid Sackson). This game belongs to the type stop-or-again. It is a game asking to choose
between either stopping a turn, i.e. saving the current gains
but loosing in speed or playing again, i.e. taking the risk of
loosing the current gains to win more. We selected this very
game because it enables to study strategies in terms of promotion and prevention since at each turn the player has to 1/
select a movement that can be more or less risky and 2/ make
a choice between a vigilant strategy (stopping) or an eager
strategy (playing again).

Using the regulatory focus theory
The regulatory-focus theory (Higgins, 1997) distinguishes
between two self-regulation strategies: promotion-focus,
which look into the presence or absence of positive outcomes,
gains versus nongains and prevention-focus, which look into
the presence or absence of negative outcomes, losses versus
non-losses. Promotion-focus people would be more prone to
using their ideal-selves as guides for their behaviors (i.e., they
are looking for being what they want to be) than preventionfocus people, who would prefer using ought-selves (i.e., they
are looking for being what they think they have to be). Promotion and prevention are two independent dimensions. One
person has both a promotion-focus and a prevention-focus
score. Regulatory focus can be situational, i.e. induced by the
context, but theory states that people have a chronic focus, i.e.
an ”habitual” focus used by default. The orientation of this
chronic focus is equivalent to the highest of both promotionfocus score and prevention-focus score. The regulatory focus
theory also proposes the concept of regulatory-fit.

Data-driven implementation
We propose to use a data-driven implementation. By using machine learning and classification methods, we propose
to test whether people can perceive the intended regulatoryfocus of an artificial agent exhibiting a strategy learned from
human data. The results about the perception of regulatoryfocus could validate the concept as useful to convey personality and also guide future implementations if the classification models used are interpretable. The description of the
data-driven implementation is beyond the scope of this paper. To put it in a nutshell, fifteen participants (13 men, 2
women ; age M = 29,7 years, SD = 10,2) played against
each other Cant Stop games. Prior to the study, each par-

663

• H2: The credibility of the agent is increased by the presence of personality. The RF-agents are perceived as more
likeable and more intelligent than the Rand-agent and the
Avg-agent.

ticipant had answered the Regulatory Focus Questionnaire
Proverbs Form (RFQ-PF), a French questionnaire measuring
the strengh of the two self-regulatory strategies. Participants
played via computers, where all the games where logged, in
order to be analyzed later. Then, we proceed to classification with features calculated according to our own analyse
of the game with the sofware Weka (version 3.7). We computed three models : one for the choice of a move during the
game and two for the ”stop-or-again” decision (with and without taking into account personality scores as a feature; the
latter should smooth interindividual differences to produce a
”depersonalized” strategy). We choose to use the Alternative Decision Tree classifier (ADTree) (Holmes, Pfahringer,
Kirkby, Frank, & Hall, 2002) because of differents advantages : the robustness, the interpretability of the tree and the
ease of implementation. We performed a 10-fold stratified
cross-validation on the models produced and benchmarked
the results against different classifiers which finally presented
equivalent or lesser performances (e.g. results for our ”stopor-again” decision model with personality: Incorrectly categorized items = 19.7%; Kappa statistic = 0.33; Receiver operating characteristic (ROC) area = 0.80). We directly implemented the decision trees as decision-making strategies for
the agents.

• H3: According to the regulatory-fit theory, human player
oriented as promotion find RF-Pro agent more credible
than other agents (respectively for RF-Pre).

Design
Prior to the study, each subject had answered the Regulatory Focus Questionnaire Proverbs Form (RFQ-PF), a French
questionnaire measuring the chronic regulatory-focus with 18
questions to answer on a 7-point Likert scale. During the
study, the following procedure was applied. First, the participant is explained the rules of Cant Stop by viewing a explicative video. During the tutorial video, the possibility is given
to the participant to pause the video and to replay if necessary. Second, the participant plays a tutorial game against the
computer in order to familiarize with the game itself and its
interface. The participant is informed that the computer will
make random choices during the tutorial game. The experimenter answers questions if some of the rules remain unclear.
Third, the participant is informed that he or she will play 4
games against different artificial agents. The participant is
also informed that he or she will have to evaluate the agents
personality after each game. There is no visual display of
the artificial agent, the only modality for evaluate the agents
personality is the way the agent plays the game. The different conditions are counterbalanced to compensate a potential
effect of order. After each game against an agent, the participant answers the RFQ-PF in an other-ratings form (i.e. to caracterize the agents strategies during the game), along with 10
questions from the Godspeed Questionnaire (Bartneck, Kuli,
Croft, & Zoghbi, 2009) (5 about likeability and 5 about the
perceived intelligence of the agent ; 5-point Likert scale) as a
credibility measure.

Experimental design
In order to test the users’ perception of agents’ personality
and the regulatory fit effect, we wanted a (scientifically speaking) control agent: an agent playing without personality. In
psychology, there is no such thing as a person with no personality. So what could it be in affective computing? Two
types of strategies are generally used as control in the domain: random strategy (but does the absence of planned consistency convey an absence of personality?) or ”traditional
AI” strategy (but does the absence of implemented personality is equivalent to the absence of personality?). Finally, we
considered to have 4 types of agent : 1/ the random agent
(Rand), which chooses randomly its moves and has a 50%
probability to stop its turn ; 2/ the ”average” agent (Avg),
which follows the ”depersonalized” strategy ; 3/ the promotion agent (RF-Pro), which has a promotion score of 7 and
a prevention score of 1 ; 4/ the prevention agent (RF-Pre),
which has a promotion score of 1 and a prevention score of
7. The so-called RF-agents follow the same decision tree,
where some branchs are conditionned by the value of personality scores. Concerning users, we did not select them by
testing their chronic regulatory-focus before the study. At the
end, we had 14 participants with a chronic promotion focus
and 6 with a chronic prevention focus.

Participants
Twenty participants took part in this evaluation study. There
were 11 men and 9 women (age M = 30.6 years, SD = 8.1).
Of the participants, 17 were native french speakers and 3 were
bilingual.

Results1
First, we look at the mean and standard deviation for each
measure. We also computed the coefficient of quartile variation (CQV ; (Q3 − Q1)/(Q1 + Q3)), which offers a comparable statistic of dispersion (Bonett, 2006) and the Finn coefficient2 , as an index of the interraters agreement (Finn, 1970).
Complete results are presented in Table 1. To summarize,
important results are:

User study
Hypothesis
We make 3 hypothesis concerning the results of this study:

1 Data were analysed using R, version 3.1.2, http://www.Rproject.org
2 R package irr, version 0.84

• H1: The differences in agents personalities are perceived
by the human player

664

• Dispersion of data: The CQV of the Rand agent for personality scores is, on average, 1.5 times higher than other
agents CQV.
• Interraters agreement: Finn coefficient of the Rand agent
are the lowest for the promotion score and the prevention
score.
• Personality scores:
– Promotion score: the RF-Pro agent and the Avg-agent
are rated high (resp. M=5.26 ; SD=1.28 and M=5.30 ;
SD=1.44) unlike the RF-Pre agent and the Rand-agent
(resp. M=3.09 ; SD=1.22 and M=3.53 ; SD=1.47).
– Prevention score: the RF-Pre agent and the Rand-agent
are rated high (resp. M=5.58 ; SD=0.73 and M=4.51
; SD=1,71) unlike the RF-Pro agent and the Avg-agent
(resp. M=2.91 ; SD=1.33 and M=3.18 ; SD=1.40).

Figure 1: Interaction between the participant’s personality
and the agent’s personality regarding the likeability of the
agent.
score (χ2 (3) = 23.28; p < 0.001) and the perceived intelligence (χ2 (3) = 15.18; p = 0.002). We do not found significative differences for the likeability (χ2 (3) = 2.24; n.s.). Posthoc tests show the following results:

• Credibility scores:

• Promotion scores: the RF-Pro agent is significatively rated
higher than the RF-Pre agent (p ≤ 0.001) and the Randagent (p ≤ 0.01). There is no significative difference between the RF-Pro agent and the Avg-agent.

– Likeability: scores are around 3 (on a 5-point scale) for
all the agents.
– Perceived intelligence: scores have an higher range :
from 2.63 (Rand-agent) to 3.85 (RF-Pre agent).

• Prevention scores: the RF-Pre agent is significatively rated
higher than the RF-Pro agent (p ≤ 0.001) and the Avgagent (p ≤ 0.01). There is no significative difference between the RF-Pre agent and the Rand-agent.

For the analysis of differences between conditions, we
applied non-parametric statistics, as the assumption of normality could not be granted in these conditions. We used
the Friedman test as principal analysis and pairwise comparisons using Wilcoxon signed rank test as post-hoc test. For
the post-hoc tests, p-values were adjusted using the Holm
correction. Friedman tests reported significant differences
for promotion-score (χ2 (3) = 23.44; p < 0.001), prevention-

• Perceived intelligence: the RF-Pre agent is rated significatively higher than the Rand-agent, the Avg-agent and the
RF-Pro agent (resp. p ≤ 0.01; p ≤ 0.05; p ≤ 0.05). There is
no significative difference between the three other agents.
For the analysis of interactions, we choose to compare only
participants with the strongest chronic focus (i.e. highest
differences between promotion-focus and prevention-focus
scores) as they are the more proned to show a regulatoryfit effect. We selected a subset of data with the six more
promotion-inclinated and the six more prevention-inclinated
participants. We performed an adjusted rank transfom test
(Leys & Schumann, 2010), which is a robust way of testing interactions on non-parametric data. We found a significative interaction between the regulatory-focus inclination
of the participant and the type of agent for the likeability
(F(3, 30) = 4.532; p < 0.01; partial η2 =0.31). As shown
in Figure 1, prevention-oriented participants have found the
Rand and the RF-Pre agents (which have been both perceived
as prevention-focus) more likeable thant the Avg and the RFPro agents (which have been both perceived as promotionfocus). Promotion-oriented participants have found the Rand
agent less likeable than any other agent. No other significative interaction was found.

Table 1: Descriptive statistics of the different scores collected
during the study ; Pro Sc. = promotion score ; Pre Sc. =
prevention score ; Lik. = likeability ; Perc. Int. = perceived
intelligence ; CQV = Coefficient of Quartile Variation
Rand

Avg

RF-Pro

RF-Pre

Mean
SD
CQV
Finn coeff.

3.53
1.47
32%
0.46

5.3
1.44
15%
0.48

5.26
1.28
14%
0.59

3.09
1.22
20%
0.63

Mean
SD
CQV
Finn coeff.

4.51
1.71
30%
0.27

3.18
1.4
37%
0.51

2.91
1.33
25%
0.56

5.58
0.73
8%
0.87

Lik.

Mean
SD
CQV

3.3
0.78
19%

3.22
0.67
13%

3.02
0.95
18%

3.51
0.75
14%

Perc. Int.

Mean
SD
CQV

2.63
0.6
18%

2.94
1.16
33%

3.11
0.98
27%

3.85
0.68
11%

Pro Sc.

Pre Sc.

Discussion & perspectives
We first asked if users can perceive the differences between
agents’ personalities (H1). This first hypothesis is almost val-

665

idated. On the one hand, results show that our RF-Pro and
RF-Pre agents has been respectively perceived as promotionoriented and prevention-oriented, as we expected. We could
say that our data-driven strategies successfully convey the
agent’s regulatory-focus. On the other hand, our Rand and
Avg agents have been respectively perceived as preventionoriented and promotion-oriented. This result points out
the difficulty of controlling personality perception of virtual
agents. We raised our concerns (cf. Methodology - Experimental design) and, as brought up by (Liu, Tolins, Tree,
Walker, & Neff, 2013), by assessing personality with questionnaires, participants may be driven to rate something they
had not perceived. Besides, such attribution could also be
explain by what Shermer (Shermer, 2012) called patternicity and agenticity : respectively ”the tendency to find meaningful patterns in meaningless noise” and ”the tendency to
infuse [these] patterns with meaning, intention and agency”.
Otherwise, we have taken an user-centered and data-driven
approach with interpretable outputs. Because these outputs
can convey regulatory-focus, they could also inform us on a
psychological side, on the links between human regulatoryfocus and risk-taking in a stop-or-again game. On the computing side, such data and performances could fed symbolical
and theory-driven models, which suppose more assumptions
about cognitive processes. This complementary approach
could gives us more insights in the possible internal mechanisms to endow virtual agents with regulatory-focus.

this regulatory-focus can be accuretly perceived by users. We
also provided data which point to the possibility of using the
concept of regulatory fit with artificial agents. As perspectives, we list directions for future works in order to try to
provide data for answering the questions raised by our results
and better understand the regulatory fit effect with artificial
agents : making more longitudinal studies because only repeated interactions could allow users to form a real model of
the agent’s personality; using multi-modality to enhance the
interaction, such as verbal and non-verbal behaviors during
the game by providing a physical representation of a virtual
agent; complementing self-report measures by users’ behaviors measures, such as engagement for example.

Acknowledgments
This work is conducted as a part of the French funded ANR
MOCA project - ANR-2012-CORD-019-02. Authors would
like to gratefully thanks Philippe Caillou for his precious
guidance on the machine learning path.

References
Avnet, T., & Higgins, T. E. (2003). Locomotion, assessment,
and regulatory fit: Value transfer from how to what. Journal of Experimental Social Psychology, 39(5), 525–530.
Bandura, A. (1999). Social cognitive theory of personality. In
L. Pervin & O. John (Eds.), Handbook of personality (2nd
ed. ed., pp. 154–196). New York: Guilford Publications.
Bartle, R. (1996). Hearts, clubs, diamonds, spades: Players
who suit MUDs. Journal of MUD research, 1(1).
Bartneck, C., Kuli, D., Croft, E., & Zoghbi, S. (2009). Measurement instruments for the anthropomorphism, animacy,
likeability, perceived intelligence, and perceived safety of
robots. International Journal of Social Robotics, 1(1), 71–
81.
Benyon, D., & Mival, O. (2010). From human-computer interactions to human-companion relationships. In Proceedings of the first international conference on intelligent interactive technologies and multimedia.
Bonett, D. G. (2006, July). Confidence interval for a coefficient of quartile variation. Computational Statistics & Data
Analysis, 50(11), 2953–2957.
Burgoon, J. K., Bonito, J. A., Bengtsson, B., Cederberg, C.,
Lundeberg, M., & Allspach, L. (2000). Interactivity in
humancomputer interaction: A study of credibility, understanding, and influence. Computers in Human Behavior,
16(6), 553–574.
Costa, P. T., & McCrae, R. R. (1992). Four ways five factors
are basic. Personality and Individual Differences, 13(6),
653–665.
Courgeon, M., Clavel, C., & Martin, J.-C. (2014). Modeling facial signs of appraisal during interaction: impact on
users’ perception and behavior. In Proceedings of the 2014
international conference on autonomous agents and multiagent systems (pp. 765–772). International Foundation for
Autonomous Agents and Multiagent Systems.

Concerning the credibility of the different agents (H2), the
hypothesis is partially validated. We found a difference in favor of the RF-Pre agent regarding the perceived intelligence.
The RF-Pro agent was rated as more intelligent than the Rand
and Avg agents but the difference was not significative. Considering our number of subjects, we could not say if the nonsignificativity is due to a lack of data or to a real difference
due to the agent’s strategy. Nevertheless, we found no differences in likeability. Participants orally reported difficulties
to evaluate likeability, because they found that the interaction was not sufficient to judge on the agents sympathy. This
result also raised a fundamental question: how are we measuring such a concept?
Our third hypothesis, observing an effect of regulatory fit
between the user’s and the agent’s chronic regulatory focus
(H3) is also partially validated. We found an interaction between the user’s focus and the type of agent regarding the
likeability score: prevention-oriented users found the RF-Pre
agent and the Rand agent more likeable than the RF-Pro agent
and the Avg agent. Because RF-Pre and Rand agents were
both perceived as prevention-oriented, we could say that regulatory fit happened for prevention-focus users. We did not
find such effect for promotion-focus users. This result raised
an other question: should we focus on the user’s perception
of the personality we tried to convey or only on the effect of
the agent perceived personality (whatever it is) on the user?
To conclude, we have shown that it is possible to successfully endow artificial agents with regulatory-focus and that

666

Faur, C., Clavel, C., Pesty, S., & Martin, J.-C. (2013).
Perseed: a self-based model of personality for virtual
agents inspired by socio-cognitive theories. In Proceedings
of affective computing and intelligent interaction (ACII
2013). humaine association conference on. (pp. 467–472).
Geneva, Swiss.
Finn, R. H. (1970). A note on estimating the reliability of
categorical data. Educational and Psychological Measurement.
Gmytrasiewicz, P. J., & Lisetti, C. L. (2002). Emotions and
personality in agent design and modeling. In Game theory
and decision theory in agent-based systems (pp. 81–95).
Springer.
Gratch, J., Marsella, S., Wang, N., & Stankovic, B. (2009).
Assessing the validity of appraisal-based models of emotion. In Proceedings of the 3rd international conference on
affective computing and intelligent interaction and workshops (ACII 2009) (pp. 147–154).
Higgins, E. T. (1997). Beyond pleasure and pain. American
psychologist, 52(12), 1280–1300.
Higgins, E. T. (2005). Value from regulatory fit. Current
Directions in Psychological Science, 14(4), 209–213.
Holmes, G., Pfahringer, B., Kirkby, R., Frank, E., & Hall, M.
(2002). Multiclass alternating decision trees. In Machine
learning: ECML 2002 (pp. 161–172). Springer.
Isbister, K., & Doyle, P. (2002). Design and evaluation of
embodied conversational agents: A proposed taxonomy.
In The first international joint conference on autonomous
agents & multi-agent systems.
Johansson, M., & Verhagen, H. (2014). Social believability in games - the early years. In Proceedings of social
believability in games workshop, colocated with the 9th international conference on the foundations of digital games
(FDG2014).
Joosse, M., Lohse, M., Perez, J. G., & Evers, V. (2013). What
you do is who you are: The role of task context in perceived social robot personality. In Robotics and automation (ICRA), 2013 IEEE international conference on (pp.
2134–2139). IEEE.
Karwowski, M. (2011). Teacher personality as predictor of
perceived climate for creativity. IJCPS-International Journal of Creativity and Problem Solving, 21(1), 37–52.
Lee, A. Y., & Aaker, J. L. (2004). Bringing the frame into
focus: The influence of regulatory fit on processing fluency
and persuasion. Journal of Personality and Social Psychology, 86(2), 205–218.
Leys, C., & Schumann, S. (2010, July). A nonparametric
method to analyze interactions: The adjusted rank transform test. Journal of Experimental Social Psychology,
46(4), 684–688.
Liu, K., Tolins, J., Tree, J. E. F., Walker, M., & Neff, M.
(2013). Judging IVA personality using an open-ended question. In Intelligent virtual agents (pp. 396–405). Springer.
Ludolph, R., & Schulz, P. J. (2015). Does regulatory fit
lead to more effective health communication? a systematic

review. Social Science & Medicine.
Mischel, W., Shoda, Y., & Smith, R. (2004). Introduction to
personality: Towards an integration (7th ed.). John Wiley
& Sons.
Nahrgang, J. D., Morgeson, F. P., & Ilies, R. (2009, March).
The development of leadermember exchanges: Exploring how personality and performance influence leader and
member relationships over time. Organizational Behavior
and Human Decision Processes, 108(2), 256–266.
Nakajima, H., Yamada, R., Brave, S., Morishima, Y., Nass,
C., & Kawaji, S. (2003). The functionality of humanmachine collaboration systems-mind model and social behavior. In Systems, man and cybernetics, 2003. ieee international conference on (Vol. 3, pp. 2381–2387).
Nass, C., & Lee, K. M. (2001). Does computer-synthesized
speech manifest personality? experimental tests of recognition, similarity-attraction, and consistency-attraction. Journal of Experimental Psychology: Applied, 7(3), 171–181.
Nass, C., & Moon, Y. (2000). Machines and mindlessness:
Social responses to computers. Journal of Social Issues,
56(1), 81–103.
Niewiadomski, R., Demeure, V., & Pelachaud, C. (2010).
Warmth, competence, believability and virtual agents. In
Proceedings of the 10th international conference on intelligent virtual agents (pp. 272–285).
Park, E. S., Hinsz, V. B., & Nickell, G. S. (2015). Regulatory
fit theory at work: prevention focus’ primacy in safe food
production. Journal of Applied Social Psychology.
Revelle, W., & Scherer, K. R. (2009). Personality and emotion. Oxford companion to emotion and the affective sciences, 304–306.
Robins, R. W., Caspi, A., & Moffitt, T. E. (2000). Two
personalities, one relationship: both partners’ personality
traits shape the quality of their relationship. Journal of personality and social psychology, 79(2), 251.
Shermer, M. (2012). The believing brain. New York: Times
Books.
Sviatlana, D., Busemann, S., & Schommer, C. (2012). Artificial conversational companions: A requirements analysis. In Proceedings of the 4th international conference
on agents and artificial intelligence (pp. 282–289). Vilamoura, Portugal.
Tapus, A., Tapus, C., & Matari, M. J. (2008). Userrobot personality matching and assistive robot behavior adaptation
for post-stroke rehabilitation therapy. Intelligent Service
Robotics, 1(2), 169–183.
Tay, B., Jung, Y., & Park, T. (2014, September). When stereotypes meet robots: The double-edge sword of robot gender
and personality in humanrobot interaction. Computers in
Human Behavior, 38, 75–84.
Vinciarelli, A., & Mohammadi, G. (2014). A survey of personality computing. IEEE Transactions on Affective Computing, 5(3), 273–291.

667

