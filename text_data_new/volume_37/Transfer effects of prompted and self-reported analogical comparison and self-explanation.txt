Transfer Effects of Prompted and Self-Reported
Analogical Comparison and Self-Explanation
J. Elizabeth Richey (jes1235@pitt.edu)
Cristina D. Zepeda (cdz7@pitt.edu)
Timothy J. Nokes-Malach (nokes@pitt.edu)
Department of Psychology, Learning Research and Development Center, 3939 O’Hara St.
University of Pittsburgh, Pittsburgh, PA 15260 USA

& Cox, 2013), and the wide variety of tasks, scaffolding,
and measurement employed in prior work make it difficult
to compare experiments examining each process separately.
Consequently, there is little evidence to suggest which
process is most appropriate based on instructional goals
(e.g., near or far transfer). We directly compare the two
processes to identify differences, if any, in the knowledge
representations acquired through each process.
It is also possible that instructions to engage in either
analogical comparison or self-explanation promote use of
both processes (Edwards, 2014). For example, comparisons
often involve explicit explanations of features and their
relations within examples, and explanation invites
comparisons between prior knowledge and new information
or different pieces of information. Thus, it is interesting to
explore the degree to which students report engaging in both
processes after receiving prompts for either self-explanation
or analogical comparison. We investigate the relationship
between instructional prompts, knowledge outcomes, and a
new questionnaire measure targeting learners’ self-reported
use of self-explanation and analogical comparison.

Abstract
We compared types of transfer facilitated by instructions to
engage in analogical comparison or self-explanation.
Participants received learning materials and worked examples
with prompts supporting analogical comparison, selfexplanation, or instructional explanation study. Learners also
self-reported their use of analogical comparison and selfexplanation on a series of questionnaires. We evaluated
condition effects on self-reports and transfer, and the relations
between self-reports and transfer. Receiving materials with
analogical-comparison support and reporting greater levels of
analogical comparison were both associated with worse
transfer performance, while reporting greater levels of selfexplanation was associated with better performance.
Learners’ self-reports of analogical comparison and selfexplanation were not related to condition assignment,
suggesting that the questionnaires did not measure the same
processes promoted by the intervention, or that individual
differences are robust even when learners are instructed to
engage in analogical comparison or self-explanation.
Keywords: analogical comparison; self-explanation; learning;
transfer

Introduction

Analogical comparison

One goal of cognitive science is to examine the instructional
techniques that support learning and transfer, or the
application of knowledge to a new situation or problem.
Analogical
comparison
and
self-explanation
are
hypothesized to be two constructive, sense-making
techniques for acquiring knowledge that transfers (Chi,
2009; Koedinger, Booth, & Klahr, 2013; Richey & NokesMalach, 2015), and both have shown consistent benefits for
learning in the laboratory as well as the classroom. While
they appear to rely on some of the same mechanisms (e.g.,
inference generation), they may also involve different
mechanisms (e.g., mental model revision versus relational
abstraction), and the exact nature of the knowledge acquired
through each is not clear. Understanding differences in
knowledge outcomes associated with each process has
important implications for cognitive theory and instructional
practice, particularly if there are instructional scenarios to
which one approach is better suited than the other.
Little work has systematically compared the knowledge
acquired through analogical comparison and selfexplanation (cf. Edwards, 2014; Gadgil, Nokes-Malach, &
Chi, 2012; Nokes-Malach, VanLehn, Belenky, Lichtenstein,

Analogical comparison is an instructional technique in
which learners receive multiple exemplars and engage in
mapping features and relations between them, which leads
to better encoding of abstract relations that can be applied to
novel cases (Gentner, Loewenstein, & Thompson, 2003;
Gick & Holyoak, 1983). Much prior research has shown that
analogical comparison of examples can lead to generating
inferences and encoding abstract information, which may
make analogical comparison especially well-suited for
supporting far transfer (Alfieri, Nokes-Malach, & Schunn,
2013). Because it emphasizes abstraction across examples
and minimizes surface features, some evidence suggests it
may not be as beneficial as other instruction, including selfexplanation and worked-example study, for facilitating
knowledge of specific problem-solving procedures (NokesMalach et al., 2013). Research has also shown a great deal
of individual variability in the extent to which learners
engage in analogical comparison, and learners sometimes
fail to make fruitful comparisons across cases even when
instructed to do so (Gick & Holyoak, 1983). Carefully
selecting cases to highlight critical features and scaffolding
comparison can improve outcomes (Gentner et al., 2003).

1985

Developing an unobtrusive measure of analogical
comparison suitable for use across a variety of academic
settings could improve understanding of how frequently
learners engage in it, and it could help explain why some
students learn and transfer deep concepts more successfully
than others. Prior work has assessed analogy use through
verbal protocols (e.g., Richland, Holyoak, & Stigler, 2004)
and experimental manipulations (e.g., Gick & Holyoak,
1983), but to our knowledge no work has related a multiitem questionnaire assessing students’ use of analogical
comparison to the effects of an instructional intervention.

Self-explanation
Self-explanation is another constructive instructional
technique. Although it can take a variety of forms, two of
the most fruitful types of self-explanation focus on filling in
knowledge gaps through inference generation and revising
errors in prior knowledge (Nokes, Hausmann, VanLehn, &
Gershman, 2011). Self-explanation typically focuses on one
example at a time and may better support encoding concrete
problem features, which could result in better declarative
memory of procedures. Self-explanation can support deep
learning, conceptual change, and transfer, but like
analogical comparison, there is much variability in volume
and quality of self-explanations, whether they are
spontaneous (Chi, Bassok, Lewis, Reimann, & Glaser,
1989) or prompted (Chi, Slotta, & de Leeuw, 1994).
Additionally, the knowledge derived from self-explanation
depends on both the content being explained and the types
of explanations the learner generates, making selfexplanation potentially more flexible than analogical
comparison but perhaps also less structured.
Most studies of self-explanation involve extensive
analysis of written or verbal protocols, constraining research
to environments or tasks developed for the purpose of
collecting protocols. A self-explanation questionnaire could
be deployed more easily in a variety of academic settings
and, similar to an analogical-comparison questionnaire,
might improve understanding of why some students are
more successful in acquiring concepts and revising
misconceptions than others. Again, no work that we know
of has attempted to relate an instructional intervention
targeting self-explanation to self-reports on a multi-item
self-explanation questionnaire.

The Present Study
Although analogical comparison and self-explanation are
often studied separately, some recent work has compared
the two (Edwards, 2014; Gadgil et al., 2012; Nokes-Malach
et al., 2013). Gadgil et al. (2012) found that learners with
misconceptions about the circulatory system were more
likely to undergo conceptual change when they compared
flawed mental models to an expert model, rather than selfexplaining the expert model alone. This suggests analogical
comparison can facilitate conceptual change, but it is not
clear whether change was driven by analogical comparison
or by drawing learners’ attention to flawed mental models,

which were not targeted for self-explanation. Nokes-Malach
et al. (2013) compared self-explanation and analogical
comparison of worked examples against worked examples
with instructional explanations and found that analogical
comparison led to less robust near-transfer performance than
self-explanation or instructional explanations. Participants
performed equally well on intermediate-transfer measures,
and self-explanation and analogical comparison prompts led
to greater far transfer than instructional explanations.
The present study aimed to compare the types of transfer
supported by self-explanation and analogical comparison
prompts, while exploring questionnaires as an alternative for
quantifying the degree to which learners engage in selfexplanation and analogical comparison. For both
techniques, learning depends on the design of the materials
including the amount of scaffolding to support analogical
comparison (Gentner et al., 2003) or the focus of the selfexplanation prompts (Nokes et al., 2011). We aimed to
control factors such as the amount of scaffolding provided
(introduction to the process, modeling, and prompting) and
the target of the prompts (worked examples). Controlling
these factors should provide clearer evidence about types of
knowledge each technique supports.
We conducted an experiment in which learners studied
text about electricity and electric circuits; received worked
examples illustrating relevant concepts with prompts to selfexplain, engage in analogical comparison, or study
instructional explanations; and solved practice problems. All
participants self-reported their use of self-explanation and
analogical comparison after the conclusion of the learning
phase, and they completed a test with items targeting near,
intermediate, and far transfer, as well as preparation for
future learning (PFL) transfer, which examines how well
participants were prepared to learn from a new instructional
resource about a related topic (Bransford & Schwartz,
1999). Specifically, we tested the following hypotheses:
(H1) Prompts to self-explain or compare worked
examples will lead to greater far and PFL transfer than
prompts to study instructional explanations, as both selfexplanation and analogical comparison support the
generation of abstract, flexible knowledge that transfers to
new situations. By minimizing surface features, analogical
comparison may reduce near transfer.
(H2): Prompts to self-explain and compare will lead to
greater self-reports of self-explanation and analogical
comparison, respectively.
(H3) Self-reports of self-explanation and analogical
comparison will predict transfer beyond the differences
explained by condition assignment. Self-reported analogical
comparison and self-explanation will be associated with
more far and PFL transfer, while self-reported analogical
comparison may also be associated with less near transfer.

Methods
The experiment had a between-subjects design with
participants randomly assigned to one of three conditions:
self-explanation, analogical comparison, or instructional

1986

explanation. Participants received the same questionnaires,
tests, and basic learning materials. We describe differences
across the conditions below.

Participants
One hundred and one students enrolled in an introductory
psychology course at the University of Pittsburgh took part
in the study. Participants received credits toward a research
participation requirement associated with the course.

Materials
Questionnaires Drawing from theory and prior research,
we identified critical features of analogical comparison and
self-explanation to develop questionnaires asking students
about their use of these processes. Ten items targeted selfexplanation, e.g., “During the activity, as I solved a problem
I would explain to myself what concepts were being applied
and why,” and 11 items examined analogical comparison,
e.g., “During the activity, I compared the different problems
to one another to improve my understanding of how to solve
them.” All items were framed at the task level, and
participants rated how much they agreed or disagreed with
each item on a 7-point Likert scale from 1 (strongly
disagree) to 7 (strongly agree). Zepeda and Nokes-Malach
(2015) examined the validity of these questionnaires and
found that seven self-explanation items loaded onto one
factor (CFI = .924, α = 0.81) and six analogical comparison
items load onto one factor (CFI = .987, α = 0.89).
Therefore, we examine only those items.
Learning materials Four booklets of instructional
materials were adapted from a prior study by Richey and
Nokes-Malach (2013) and covered concepts related to
electricity and electric circuits. Most college students have
had prior exposure to these concepts yet still hold a number
of misconceptions about the topic (Slotta & Chi, 2006). The
topic was well suited for examining types of transfer and
included concepts and relations that could be identified
through analogical comparison or self-explanation.
Each booklet contained several pages of instructional text
followed by worked examples and practice problems related
to the preceding text. Booklets differed across conditions in
the instructions participants received while studying worked
examples and solving problems. The analogical comparison
condition was instructed to compare worked examples
(“What is similar across problems? What is different? What
do the similarities and differences tell you about the
concepts involved?”); the self-explanation condition was
instructed to generate explanations of worked examples
(“Self-explain the reasoning or justification for this solution.
Write out words to describe any symbols, and provide
conceptual justifications and principled reasoning to explain
the solution”); and the instructional explanations condition
was instructed to study the examples (“Remember to take
your time and study each worked example carefully”).
Participants in the self-explanation and analogical
comparison conditions studied and elaborated on a modeled

response to the prompt after the first worked example in the
first booklet. For example, in the self-explanation condition,
participants read examples of elaboration, monitoring, and
bridging statements and wrote statements of their own.
Modeling self-explanation has been shown to improve the
quality and effectiveness of responses (McNamara, 2004).
Worked examples were created in pairs with surface
dissimilarities (e.g., different values, cover stories) and
either the same or contrasting relations. Each pair of worked
examples also had a corresponding practice problem with
surface dissimilarities but the same relations. Worked
example pairs were presented side-by-side on the same page
in the analogical comparison condition. To suppress
spontaneous comparison, they were presented on sequential
pages in the self-explanation and instructional explanation
conditions. Instructional explanations focused on concepts
related to each example step and were similar to elaborative
explanations participants in the self-explanation condition
were expected to generate on their own (Schworm & Renkl,
2006). They were included to suppress spontaneous selfexplanation in the instructional explanation condition and
control the amount of information reviewed across
conditions while manipulating the processes (reading, selfexplaining, comparing).
Figure 1 shows a worked example from the instructional
explanations condition; the self-explanation and analogical
comparison conditions saw the same example with the stepby-step solution (right column) but without the instructional
explanations (left column). The analogical comparison
condition saw the example side-by-side with the next
example, which asked the same question and included a
diagram of a series circuit with two 3-ohm light bulbs. This
example corresponded to several test problems, including a
near-transfer question asking about current in a two-loop

Figure 1. Worked example with instructional explanations.

1987

1
0.8
0.6
0.4
0.2
0

parallel circuit with new values for resistance; an
intermediate-transfer question asking about resistance in a
three-loop parallel circuit; and a far-transfer question asking
how total current changes in a parallel circuit when
additional branches are added.
Test materials A five-item pretest and 36-item posttest
measured knowledge and transfer. The posttest included
multiple-choice and short-answer questions, with 13 neartransfer items (α = .33), 17 intermediate-transfer items (α =
.61), 12 far-transfer items (α = .44), and nine PFL transfer
items (α = .53). A learning resource about power was
embedded in the test and provided information for all PFL
questions. Two independent coders coded all short-answer
items using a rubric, discussed any differences, and reached
100 percent agreement for all items.

Procedure
Participants completed the experiment individually in
sessions of three to five students at a time. After completing
a brief pretest, participants worked through the self-paced
learning booklets. Participants were notified of a time limit
for each booklet (15 minutes for the first, 20 for the second,
25 for the third, and 30 for the fourth) and booklets were
distributed one at a time. While participants could flip back
or ahead within each booklet, they could not go back to a
previous booklet and could not move ahead until everyone
in the room had finished the current materials. Upon
completing the learning booklets, participants responded to
the questionnaires, as well as metacognition and taskframed achievement goal questionnaires. Participants then
were given 55 minutes to complete the posttest, followed by
domain-framed achievement goals and demographic
questionnaires. Given space constraints, we do not discuss
the metacognition, achievement goal, or demographic
questionnaires further. Most sessions used the majority of
the time allotted, and there were no effects of condition on
learning time, F(2, 98) = 1.40, p = .25, ηp2 = .028, or test
time, F(2, 98) = .25, p = .78, ηp2 = .005.

Results
Analyses focused on testing the effects of learning condition
on each type of posttest transfer and on questionnaire
responses. We also examined relations between participants’
questionnaire responses and posttest performance. Posttest
transfer is reported as the number of correct items out of the
total number of items for each type of transfer. Post hoc
comparisons were conducted using the Tukey HSD test.

Near

†

Intermediate

*

Far

Selfexplanation
Analogical
comparison
Instructional
explanation

PFL

Figure 2. Learning condition effect on posttest accuracy. *
indicates p < .05, † indicates p < .10.
effect of condition on near transfer, F(2, 98) = 2.91, p =
.059, ηp2 = .056. Post hoc comparisons indicated that the
mean score for the instructional explanation condition (M =
.75, SD = .12) was marginally different from the selfexplanation condition (M = .68, SD = .14; p = .051). The
analogical comparison condition (M = .70, SD = .12) did not
differ from the instructional explanation (p = .26) or selfexplanation conditions (p = .70).
There was a marginal effect of condition on intermediate
transfer, F(2, 98) = 2.89, p = .060, ηp2 = .056. Post hoc
comparisons indicated that the mean score for the analogical
comparison condition (M = .60, SD = .16) was marginally
different from the self-explanation condition (M = .68, SD =
.12; p = .081). The instructional explanation condition (M =
.67, SD = .15) did not differ from the self-explanation (p =
.98) or analogical comparison conditions (p = .12). There
was no effect of condition on far transfer, F(2, 98) = 0.83, p
= .44, ηp2 = .017.
There was a medium effect of condition on PFL transfer,
F(2, 98) = 3.34, p = .039, ηp2 = .064. Post hoc comparisons
indicated that the mean score for the instructional
explanation condition (M = .69, SD = .20) was significantly
different from the analogical comparison condition (M =
.57, SD = .22: p = .040). However, the self-explanation
condition (M = .66, SD = .18) did not differ from the
instructional explanation (p = .81) or analogical comparison
conditions (p = .15).

H2: Condition effects on processing
Next, we conducted ANOVAs to test the effect of condition
on participants’ self-reported use of self-explanation and
analogical comparison (Figure 3). There was no effect of
condition on self-reported self-explanation, F(2, 98) = .77, p
= .47, np2 = .015, or on self-reported analogical comparison,
F(2, 98) = 0.35, p = .71, np2 = .007.
7
6
5
4
3
2
1

H1: Condition effects on learning
We conducted a series of one-way analyses of variance
(ANOVAs) to assess the effect of condition on the pretest
and type of transfer the posttest (Figure 2). There was no
effect of condition on pretest accuracy, F(2, 98) = .64, p
=.53, np2 = .013, so we did not control for pretest in the
posttest analyses. A one-way ANOVA revealed a marginal

†

Selfexplanation
Analogical
comparison
Instructional
explanation
Explanation
questionnaire

Comparison
questionnaire

Figure 3. Results of learning condition effect on selfreported use of self-explanation and analogical comparison.

1988

H3: Strategy use and learning
To test the amount of variance in posttest performance
explained by self-reported self-explanation and analogical
comparison, variance due to the condition assignment was
removed using hierarchical multiple regression. Condition
was dummy-coded with the worked examples-only
condition as the reference group. Self-reported levels of
self-explanation and analogical comparison were entered in
a step-wise fashion into the second model with the first
model containing the condition assignment variables.
The model predicting near transfer explained 14.7% of
the variance as indexed by the adjusted R2 statistic, F(4, 96)
= 5.32, p = .001. Within the model, there was an effect of
self-reported analogical comparison, β = -.38, t = 3.39, p =
.001, and of self-reported self-explanation, β = .38, t = 3.40,
p = .001, independent of condition assignment. Controlling
for self-reported processing, there was an effect of selfexplanation condition, β = -.22, t = 2.06, p = .043, and a
marginal effect of analogical comparison condition, β = .19, t = 1.77, p = .080. The model predicting intermediate
transfer explained 12.3% of the variance as indexed by the
adjusted R2 statistic, F(4, 96) = 4.51, p = .002. Within the
model, there was an effect of self-reported analogical
comparison, β = -.23, t = 2.05, p = .044, and of self-reported
self-explanation, β = .39, t = 3.41, p = .001, independent of
condition assignment. Controlling for self-reported
processing, there was an effect of analogical-comparison
condition, β = -.22, t = 2.03, p = .045, and no effect of selfexplanation condition, β = .072, t = 0.66, p = .51. The model
predicting far transfer explained 2.8% of the variance as
indexed by the adjusted R2 statistic, F(4, 96) = 1.71, p = .15.
The model predicting PFL transfer explained 7.0% of the
variance as indexed by the adjusted R2 statistic, F(4, 96) =
2.88, p = .027. Within the model, there was an effect of selfreported analogical comparison, β = -.25, t = 2.13, p = .036,
and no effect of self-reported self-explanation, β = .18, t =
1.52, p = .13, independent of condition assignment.
Controlling for self-reported processing, there was an effect
of analogical-comparison condition, β = -.29, t = 2.60, p =
.011, and no effect of self-explanation condition, β = -.048, t
= 0.43, p = .67.

Discussion
In summary, instructing participants to study worked
examples with instructional explanations led to greater PFL
transfer compared to instructions to compare worked
examples. There was no relation between learning condition
and self-reported levels of self-explanation and analogical
comparison. However, participants’ self-reports of
analogical comparison were significant, negative predictors
of near, intermediate, and PFL transfer on the posttest. Selfreports of self-explanation were significant, positive
predictors of near and intermediate transfer and a marginal,
positive predictor of PFL transfer. Finally, when controlling
for participants’ self-reported behaviors, condition effects
emerged such that self-explanation predicted marginally less
near transfer compared to instructional explanations, and

analogical
comparison predicted
marginally less
intermediate transfer and significantly less PFL transfer
compared to the instructional explanation condition.
These results raise several important questions. First, why
was there no relationship between instructional condition
and self-reported levels of self-explanation and analogical
comparison? Prior work has shown that self-explanation and
analogical comparison are effortful and subject to much
individual variation, even when explicit instructions are
given to engage in these processes (e.g., Chi et al., 1994;
Gick & Holyoak, 1983). It is possible that individuals’
spontaneous strategy-use tendencies and study preferences
guided their learning processes more than condition
assignment. This is supported by evidence showing that
self-reported use of analogical comparison and selfexplanation predicted performance, suggesting these
measures were meaningful. However, the lack of any
relationship between condition assignment and self-reported
explanation and comparison behaviors suggests either a
problem with the manipulation (e.g., that the prompts and
modeled responses were not specific enough to guide
participants’ behaviors as intended) or the questionnaire
(e.g., some items may have been misaligned to the task).
Many students have poor awareness of their own cognitive
strategy use and may have struggled to report what they
actually did during the learning phase (Metcalfe, Eich, &
Castel, 2010). Prior research also shows that not all selfexplanations or analogical comparisons lead to robust
knowledge. The questionnaire focused on frequency but not
quality of self-explanations or analogical comparisons.
Analysis of participants’ responses to the prompts in the
learning booklets could clarify these possible explanations.
Second, why did analogical comparison lead to worse
performance, regardless of whether it was assigned (through
condition) or spontaneous (as reflected in self-reported
levels)? Some prior work has reported similar results on
certain types of tasks. Nokes-Malach et al. (2013) found that
analogical comparison of physics problems led to worse
near-transfer performance compared to self-explanation and
studying instructional explanations, although the
disadvantage did not persist on intermediate- or far-transfer
items. Edwards (2014) found that instructions to compare
exemplars in a group were less effective for category
learning than instructions to explain because the comparison
prompts constrained the types of comparison learners made.
More broadly, prior work has shown that adding scaffolding
that identifies key features leads to greater learning from
analogical comparison, as learners may struggle to align
structural features without guidance (Gentner et al., 2003).
Thus, one possible explanation for the negative relationship
between analogical comparison and performance could be
that neither the experimental manipulation to support
analogical comparison nor the learners’ spontaneous
comparisons consistently targeted structural relations.
Edwards (2014) also found that participants instructed to
engage in explanation reported greater levels of explanation
and comparison when asked to rate their behaviors on a

1989

single-item scale. Although these results differ from our
findings that neither condition reported greater levels of
explanation or comparison, they are similar in showing that
participants’ self-reported behaviors differed from the
processes the experimental manipulations were intended to
support. These results suggest that instructions to compare
or explain likely alter learners’ behaviors in a broader range
of ways and encourage changes (or perceived changes) in
multiple cognitive processes. Materials were designed to
suppress spontaneous comparison or explanation outside the
targeted conditions, but it is possible students still engaged
in analogical comparison across pages or elaborated on
worked examples. Self-explanation and analogical
comparison prompts may have led to more variation in what
learners did while studying the worked examples. If learners
in the instructional explanation condition more consistently
attended to the information in the examples, they might
have better learned the basic content.
Future work should continue to investigate how
analogical comparison and self-explanation operate and
interact to promote transfer. Questionnaires capturing
specific sub-processes of analogical comparison and selfexplanation might improve understanding of how each
facilitates learning. By improving understanding of
differences between analogical comparison and selfexplanation, we hope to learn when and how instructors can
support each process based on their instructional goals.

Acknowledgments
This research was supported by Grant SBE00354420
from the National Science Foundation to the Pittsburgh
Science of Learning Center (http://www.learnlab.org). We
thank Kelly Boden for her assistance in coding data.

References
Alfieri, L., Nokes-Malach, T. J., & Schunn, C. D. (2013). Learning
through case comparisons: a meta-analytic review.
Educational Psychologist, 48(2), 87–113.
doi:10.1080/00461520.2013.775712
Bransford, J. D., & Schwartz, D. L. (1999). Rethinking transfer: a
simple proposal with multiple implications. In A. Iran-Nejad
& P. D. Pearson (Eds.), Review of Research in Education
(Vol. 24., pp. 61–100). Washington, D.C.: American
Educational Research Association.
Chi, M. T. H. (2009). Active-constructive-interactive: a conceptual
framework for differentiating learning activities. Topics in
Cognitive Science, 1, 73–105. doi:10.1111/j.17568765.2008.01005.x
Chi, M. T. H., Bassok, M., Lewis, M. W., Reimann, P., & Glaser,
R. (1989). Self-Explanations: How Students Study and Use
Examples in Learning to Solve Problems. Cognitive
Science, 13(2), 145–182. doi:10.1207/s15516709cog1302_1
Chi, M. T. H., Slotta, J. D., & de Leeuw, N. (1994). From things to
processes: a theory of conceptual change for learning
science concepts. Science, 4, 27–43. doi:10.1016/09594752(94)90017-5
Edwards, B. J. (2014). Explanation and Comparison Interact to
Support Learning. Northwestern University.

Gadgil, S., Nokes-Malach, T. J., & Chi, M. T. H. (2012).
Effectiveness of holistic mental model confrontation in
driving conceptual change. Learning and Instruction, 22(1),
47–61. doi:10.1016/j.learninstruc.2011.06.002
Gentner, D. (1983). Structure-mapping: a theoretical framework
for analogy. Cognitive Science, 7(2), 155–170.
doi:10.1016/S0364-0213(83)80009-3
Gentner, D., Loewenstein, J., & Thompson, L. (2003). Learning
and transfer: a general role for analogical encoding. Journal
of Educational Psychology, 95(2), 393–405.
doi:10.1037/0022-0663.95.2.393
Gick, M. L., & Holyoak, K. J. (1983). Schema induction and
analogical transfer. Cognitive Psychology, 15(1), 1–38.
doi:10.1016/0010-0285(83)90002-6
Koedinger, K. R., Booth, J. L., & Klahr, D. (2013). Instructional
complexity and the science to constrain it. Science, 342(22),
935–937. doi:10.1126/science.1238056
McNamara, D. S. (2004). SERT: Self-Explanation Reading
Training. Discourse Processes, 38(1), 1–30.
doi:10.1207/s15326950dp3801_1
Metcalfe, J., Eich, T. S., & Castel, A. D. (2010). Metacognition of
agency across the lifespan. Cognition, 116(2), 267–282.
Nokes, T. J., Hausmann, R. G. M., VanLehn, K. A., & Gershman,
S. (2011). Testing the instructional fit hypothesis: the case
of self-explanation prompts. Instructional Science, 39(5),
645–666. doi:10.1007/s11251-010-9151-4
Nokes-Malach, T. J., VanLehn, K. A., Belenky, D. M.,
Lichtenstein, M., & Cox, G. (2013). Coordinating principles
and examples through analogy and self-explanation.
European Journal of Psychology of Education, 28(4), 1237–
1263. doi:10.1007/s10212-012-0164-z
Richey, J. E., & Nokes-Malach, T. J. (2013). How much is too
much? Learning and motivation effects of adding
instructional explanations to worked examples. Learning
and Instruction, 25, 104–124.
doi:10.1016/j.learninstruc.2012.11.006
Richey, J. E., & Nokes-Malach, T. J. (2015). Comparing four
instructional techniques for promoting robust knowledge.
Educational Psychology Review, 27(1), 181–218.
doi:10.1007/s10648-014-9268-0
Richland, L. E., Holyoak, K. J., & Stigler, J. W. (2004). Analogy
use in eighth-grade mathematics classrooms. Cognition and
Instruction, 22(1), 37–60. doi:10.1207/s1532690Xci2201
Schworm, S., & Renkl, A. (2006). Computer-supported examplebased learning: when instructional explanations reduce selfexplanations. Computers & Education, 46(4), 426–445.
doi:10.1016/j.compedu.2004.08.011
Slotta, J. D., & Chi, M. T. H. (2006). Helping students understand
challenging topics in science through ontology training.
Cognition and Instruction, 24(2), 261–289.
doi:10.1207/s1532690xci2402_3
Zepeda, C. D., & Nokes-Malach, T. J. (2015, accepted). Capturing
the relations between metacognition, self-explanation, and
analogical comparison: An exploration of two
methodologies. Poster submitted to the Thirty-Seventh
Annual Conference of the Cognitive Science Society,
Pasadena, CA.

1990

