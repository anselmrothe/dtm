More than Meets the Eye: Gesture Changes Thought, even without Visual Feedback
Kensy Cooperrider (kensy@uchicago.edu)
Elizabeth Wakefield (ewakefield@uchicago.edu)
Susan Goldin-Meadow (sgm@uchicago.edu)
Department of Psychology, 5848 S. University Avenue
Chicago, IL 60637 USA
Abstract

gesture drive these observed effects, and which are merely
incidental? One possibility is that certain types of feedback
from gesture are more important than others. Gestures, like
all actions, are very often both seen and felt. When we turn
a knob, lift a book, or push a button, we receive both visual
and proprioceptive feedback from these actions as they
unfold. In the same way, when we gesture in the air to
represent turning a knob, lifting a book, or pushing a button,
we receive both visual and proprioceptive feedback, albeit
different feedback than from action itself. Is one of these
types of feedback—visual or proprioceptive—more
important than the other in shaping mental representation, or
are both necessary?
On the one hand, there are reasons to think that gesture’s
thought-changing effects may require visual feedback.
Seeing other people’s gestures changes thought (Singer &
Goldin-Meadow, 2005), and seeing one’s own may have
similar effects. Adults’ understanding of spoken messages is
heavily influenced by the speaker’s co-speech gestures (e.g.,
Kelly et al., 2014). For example, even when told to focus
solely on the spoken message, individuals are quicker to
understand that message with a congruent gesture (e.g.,
“She chopped onions,” accompanied by a chopping gesture)
than with an incongruent gesture (e.g., “She chopped
onions,” accompanied by a sweeping gesture). In fact,
people are not just affected by qualitative properties of
others’ gestures, such as the handshape in the above
examples, but by quantitative properties as well. For
example, Cook and Tanenhaus (2009) showed that when
listeners view explanations of the Tower of Hanoi puzzle,
the height of the speakers’ gestures influences the height of
listeners’ movements when they later solve the puzzle
themselves. The fact that people integrate information from
others’ gestures just by seeing them provides indirect
support for the possibility that visual feedback may be the
route through which speakers’ integrate information from
their own gestures.
At the same time, there are reasons to think that gesture
might not rely on visual feedback. Blind speakers gesture,
even when talking to listeners they know to be blind
(Iverson & Goldin-Meadow, 1998). The fact that blind
individuals cannot see their gestures, but still produce them,
suggests that gestures have the potential to be cognitively
effective even when they are felt and not seen. Research on
signers also suggests a privileged role for proprioceptive
over visual feedback. Signers do not self-monitor their signs
via visual feedback and may even be distracted by it
(Emmorey, Bosworth, & Kraljic, 2009). In sum, although

When speakers gesture, their gestures shape their thoughts,
but how this happens remains unclear. What kinds of
feedback from gesture—visual, proprioceptive, or both—
drive these cognitive effects? Here we address this question
using a test bed previously employed to explore gesture’s
cognitive effects (Beilock & Goldin-Meadow, 2010).
Participants solved the Tower of Hanoi puzzle, explained
their solutions in speech and gesture, and solved the puzzle a
second time. Previous studies using this paradigm have
demonstrated that the gestures participants produce during the
explanation phase affect their ability to solve the problem the
second time. Unlike these prior studies, however, participants
in the present study were blocked from seeing their hands
while they gestured. Despite this absence of visual feedback,
our results replicate previous studies in which visual feedback
was available. These findings suggest that gesture may shape
thought through proprioceptive feedback alone.
Keywords: gesture; problem solving; Tower of Hanoi;
embodied cognition

Introduction
Our thoughts shape our actions, but only recently has it
become clear that the reverse is also true: our actions feed
back to shape our thoughts. Motor experience changes how
we perceive actions we see later on (Calise & Giese, 2006),
how we learn (James & Swain, 2011) and comprehend
language (Beilock et al., 2008), how we assign valence
(Casasanto & Chrysikou, 2011), and even how we solve
problems (Thomas & Lleras, 2009). Interestingly, however,
not all actions change thought to the same degree or in the
same way. One kind of action—gesture, produced whenever
people talk and reason—has been found to have particularly
strong effects on subsequent mental representations. For
example, teaching children a particular gesture gives them
new ideas about how to solve math problems (GoldinMeadow et al., 2009), and encouraging adults to gesture
leads them to do better on mental rotation problems (Chu &
Kita, 2011). In fact, recent results suggest that gesture may
be more powerful in shaping mental representation than
actions performed on objects (Goldin-Meadow & Beilock,
2010; Trofatter et al. 2014), and, in particular, may be more
powerful than action in promoting generalization to new
types of problems (Novack, et al. 2014).
The thought-changing power of gesture has been
demonstrated across several paradigms and in both children
and adults, but the source of gesture’s power remains
unknown (c.f. Clark, 2013; Pouw, et al. 2014). How does
gesture feed back to shape thought? Which features of

441

Method

prior findings hint at the importance of both seeing and
feeling gesture, it remains an open question as to whether
both are required for gesture to have an effect on mental
representation. Note that, importantly, it is not possible to
experimentally eliminate proprioceptive feedback. Our task
instead is to eliminate the visual feedback that speakers
receive from their own gestures to determine whether doing
so will eliminate the effects of gesture on mental
representation.
To examine these questions, we turned to a paradigm—
the Tower of Hanoi puzzle—that has been previously
established as a test bed for understanding the cognitive
effects of gesture. In a series of recent studies using the
Tower of Hanoi puzzle, gesture at one phase of the
paradigm has been shown to affect how people perform at a
later stage of the paradigm (Beilock & Goldin-Meadow,
2010; Goldin-Meadow & Beilock, 2010; Trofatter, et al.
2014). In the paradigm, participants first solve a four-disk
version of the classic Tower of Hanoi puzzle involving
weighted disks and a wooden apparatus. Next, they explain
how they solved the puzzle, with encouragement to gesture
along with their explanations. Finally, they solve the puzzle
a second time. The manipulation is in the second solution
attempt. Participants in one group (the “No-Switch” group)
are given the same version of the puzzle that they solved
initially, whereas participants in the other group (the
“Switch” group) are given a version of the puzzle in which
the weights of the disks have been reversed: the smallest
disk is now the heaviest, and the biggest disk is now the
lightest. Previous studies using this paradigm have
consistently found that, during this second solution, the
performance of those in the Switch group suffers compared
to the performance of those in the No-Switch group—a
pattern of results we refer to as the “switch effect.” This is
the basic effect, but prior studies have also used additional
conditions and analyses to confirm that it is the participants’
gestures during the explanation phase that drives this switch
effect. For example, the “switch effect” disappears when the
explanation phase is removed altogether (Beilock & GoldinMeadow, 2010), when the explanation phase is replaced
with additional experience solving the physical puzzle
(Goldin-Meadow & Beilock, 2010), and when the
explanation involves demonstrating the solution with the
actual disks rather than with gestures (Trofatter, et al. 2014).
In all previous studies involving gesture during the
explanation phase, participants gestured under natural
conditions— that is, they could both see and feel their
gestures and thus received visual and proprioceptive
feedback from them. In the present study, participants were
prevented from seeing their gestures by an opaque screen,
which we call the “visual blind” (Figure 1). If participants
under these “blind” conditions still show the switch effect,
we can conclude that visual feedback from gesture is not
necessary and perhaps that gesture shapes thought through
proprioceptive feedback alone. If the switch effect
disappears, we can conclude that visual feedback is critical
to the previously seen effects of gesture on thought.

Participants
Data from 26 participants (10 males; No-Switch group: n =
12; Switch group: n = 14) were analyzed in the present
study. Participants were between the ages of 18 and 36 (M =
21 years), and were recruited for a puzzle-solving study. All
participants gave informed consent.

Materials
Tower of Hanoi apparatus. The Tower of Hanoi (TOH)
apparatus was identical to that used in previous studies. It
consisted of three evenly spaced wooden pegs on a wooden
base. Two identically sized sets of four smooth, white disks
were created. In each set, disks were four different sizes; in
one set the weights were positively correlated with the disk
sizes (smallest disk is also the lightest), and in the other they
were negatively correlated (smallest disk is the heaviest).
Visual Blind. A large black piece of felt was attached to a
wooden frame that was sized to fit comfortably around
participants’ torsos. The frame could be lowered to rest just
below shoulder height, thus obstructing participants’ view
of their hands while still allowing full range of movement
and thus full use of gesture space (see Figure 1).

Figure 1. Participant under the visual blind.

Procedure
All participants were tested individually and sessions were
videotaped. At the beginning of the session, the
experimenter explained the general rules of the TOH task.
Participants were told that their goal was to move the disks
from one peg on the puzzle board to another peg, while
following two rules. First, only one disk could be moved at
a time. Second, a larger disk could never be placed on top of
a smaller disk. After learning the rules, participants
practiced completing a simple three-disk version of the
Tower of Hanoi puzzle three times. At this stage of the
session, the disk size and weights were correlated such that
the smallest disk was the lightest, and the largest disk was
the heaviest. After the third completion of the three-disk

442

puzzle, the experimenter added a fourth disk and asked the
participant to practice solving this puzzle using the same
basic rules.

which participants explained their solutions without a visual
blind.
Speech Coding. Explanations were coded for overall
length, as well as for references to the disks in speech. The
explanation length was used to calculate the gesture rate
(gestures/minute) in the current data and in the data from
Beilock and Goldin-Meadow (2010). Each reference to one
of the disks was also coded for whether or not it mentioned
size (e.g. “the smallest disk”).

TOH1. Participants then completed the first timed solution
of the four-disk puzzle (TOH1). Participants who completed
the puzzle in less than 65 seconds were disqualified and did
not continue. This criterion was used because previous
studies using the same version of the TOH task (Beilock &
Goldin-Meadow, 2010; Goldin-Meadow & Beilock, 2010)
have shown that participants are at ceiling and unable to
improve on the task if they solve TOH1 in less than 65
seconds. As we were interested in determining whether
participants showed an improvement or decrement from
TOH1 to TOH2, we used the same established criterion.

Results
Gestures under the Blind
A comparison of the gestures during the Explanation Phase
of the present study with gestures in the original study
(Beilock & Goldin-Meadow, 2010) showed that the visual
blind had little effect on gesture production. In the current
study, we found a gesture rate of 6.46 (SD = 2.65) gestures
per minute, which was very similar to the gesture rate in the
original study, 7.35 (SD = 3.14). A linear regression
confirmed that the study in which a person participated
could not be predicted by gesture rate (β = 0.89, SE = 0.81, t
= 1.10, ns). Similarly, the proportion of one-handed gestures
produced did not differ between the current study (M = 0.71,
SD = 0.37) and the original study (M = 0.69, SD = 0.37; β =
0.02, SE = 0.10, t = 0.18, ns). Finally, the proportion of
grasping gestures (out of all gestures) was marginally higher
in the current study (M = 0.89, SD = 0.15) than in the
original study (M = 0.78, SD = 0.27), β = 0.11, SE = 0.06, t
= 1.84, p = 0.07. Given these findings, any differences that
we find between the Switch and No-Switch groups are not
likely to be attributable to differences in how participants
gestured under the blind, compared to how they gestured
under more natural conditions.

Explanation Phase. Next, participants were situated under
the blind. Again, the apparatus did not restrict movement in
any way, but blocked the participants’ view of their own
hands. They were asked to explain how they solved the
four-disk puzzle to another participant (in fact, a
confederate), making sure to mention each step they took
and to use their hands. Participants were also told that, from
the listener’s perspective, the blind created a visual
disconnect between head and body. The stated rationale of
the set-up was that we were interested in whether this visual
disconnect would interfere with the listener’s ability to
understand the participant’s explanation of the puzzle.
TOH2. After explaining their solution to the confederate,
participants completed a short demographic questionnaire
and a distractor task (Visualization of Viewpoints). They
then solved the four-disk puzzle a second time (TOH2). For
half the participants, the four-disk puzzle was identical to
the puzzle they had used during TOH1 (No-Switch group).
For the other half, the weights of the disks were reversed,
such that the smallest disk was now the heaviest, and the
biggest disk was now the lightest (Switch group). After
solving the puzzle, participants were debriefed and
compensated for their time.

Performance on the TOH puzzle
The two main measures of interest were the change in
number of moves and the change in time (in seconds)
between participants’ first and second solution attempts
(TOH2-TOH1) (see Figure 2). Whereas participants in the
No-Switch condition solved TOH2 in fewer moves than
TOH1 (M = -8.92, SD = 11.13), on average, participants in
the Switch condition took more moves to solve TOH2 (M =
1.36, SD = 5.18). We see the same pattern for the change in
solution time from TOH1 to TOH2 (No-Switch: M = -62.25
sec, SD = 59.64; Switch: M = 16.29 sec, SD = 25.60).
Regression analyses revealed that both change in number of
moves and change in time from TOH1 to TOH2 were
predicted by condition (Moves: β = 10.27, SE = 3.32, t =
3.09, p < 0.01; Time: β = 78.54, SE = 17.53, t = 4.48, p <
0.001).
In previous studies that have employed the switch
manipulation, researchers suggested that the Switch group
performs poorly at TOH2 because their gestures during the
Explanation Phase influence their mental representation of
the task. Gesturing about the disks with either one or two
hands reinforces and thus strengthens the mental

Coding
Movement and Gesture Coding. Participants’ movements
(i.e., actions used to transfer disks from one peg to another
during TOH1 and TOH2) and gestures (i.e., participants’ cospeech gestures during the explanation of their solutions to
the confederate) were coded from video. For the
movements, we coded: (1) the hand or hands used (right
hand, left hand, or both hands); and (2) the disk moved
(smallest, etc.). For gestures, we coded: (1) the hand or
hands used (right hand, left hand, or both hands); (2)
whether the gesture depicted grasping a disk or merely
pointed to a location; and (3) the disk referenced (smallest,
etc.) To determine whether the blind apparatus affected how
participants in the present study gestured, we used these
same coding criteria to recode the explanations from the
original TOH study (Beilock & Goldin-Meadow, 2010) in

443

Figure 2. Change in performance between TOH1 and TOH2. (a) Change in moves (b) Change in time (sec).
representation of their weight as either relatively light or
heavy. For the Switch group, strengthening the mental
representation of weight highlights just the feature of the
puzzle that will change in TOH2, particularly for the
smallest disk. In TOH1, participants in both conditions are
able to move the smallest disk with one hand; in TOH2,
participants in the No-Switch group can continue to use
only one hand, whereas those in the Switch group cannot
because the smallest disk is now too heavy. Consistent with
this interpretation, previous work has shown a significant
correlation between the proportion of one-handed gestures
used to represent the smallest disk during the Explanation
Phase (one-handed gestures reinforce the mental
representation of the disk as light) and the decrement in
performance from TOH1 to TOH2. A similar analysis
revealed a trend towards a significant correlation between
proportion of one-handed gestures and change in moves
from TOH1 to TOH2 in the Switch group in the present
study (r = 0.44, p = 0.11); this correlation is non-significant
in the No-Switch group (r = -0.01, ns). However, neither
correlation was significant for time (Switch: r = -0.08, ns;
No-Switch: r = -0.26, ns). Given the correlation between
proportion of one-handed gestures and change in moves for
participants in the Switch group, we suggest that, as in
previous studies, the switch effect is driven by gesture’s
ability to influence an individual’s mental representations of
a task. Importantly, this effect could not be attributed to the
number of one-handed moves used during TOH1 (r = 0.002,
ns) or to the number of times that disk weight was
mentioned in speech during the explanation (r = 0.30, ns).

Discussion
Here we investigated the mechanisms by which gesture
changes mental representation. Under natural circumstances,
people both see and feel their gestures. These two types of
feedback—visual and proprioceptive—might both be crucial
for gesture to have an effect on cognition; alternatively, one
type of feedback might be more important than the other. To
explore these possibilities, in the present study, we asked:
Does blocking speakers from seeing their own gestures also
block the effects of gesture on thought? The answer is no.
Participants in the Switch group performed worse on the
TOH puzzle after explaining it in gesture and speech,
whereas participants in the No-Switch group performed
better. This pattern of results replicates previous findings in
which participants could see their own gestures. Visual
feedback, at least in this paradigm, is not necessary for
gesture to change thought.
On a cautionary note, the non-importance of visual
feedback that we find in the present study could be specific
to our task. When producing actions involving physical
objects, people rely on different types of feedback
depending on particulars of the context (Sober & Sabes,
2005), and the same may be true when producing gestures.
The Tower of Hanoi puzzle is a logical problem in which
the weight of the disks is irrelevant. But the way in which
we designed the paradigm created a potential mismatch for
participants in the Switch group between how weight is
represented in gesture in the explanation phase and how it is
later experienced in the second solution attempt. Indeed, this
weight mismatch is what underlies the switch effect and,
moreover, weight information may be better felt than seen.

444

Thus it is possible that, by isolating weight as the dimension
along which the mismatch is experienced, we may have
made proprioceptive feedback from gesture more important
than visual feedback.
However, a recent study, using a different test bed for
examining gesture’s cognitive effects, has also found no
effects of visual feedback from gesture. Brooks et al. (under
review) studied abacus experts as they solved difficult
addition problems without a physical abacus present—a
technique known as mental abacus (MA). During MA,
experts gesture copiously. Note that, in abacus, what matters
is not the weight of the individual beads but their overall
configuration in space. Visual feedback from gesture during
MA might thus be expected to be critical to performance.
But the researchers found no performance decrement when
experts were blindfolded. Results from this study and our
own thus converge on the conclusion that, whatever it is that
drives gesture’s cognitive effects, it is not what meets the
eye.
Current evidence thus points to proprioceptive feedback
as the source of gesture’s cognitive effects. But this
conclusion remains indirect, as, again, proprioceptive
feedback cannot be manipulated experimentally in healthy
adults. We may, however, gain insights from a case study
that explores action and gesture in the absence of
proprioception. Cole, Gallagher, and McNeill (2002)
examined IW, a man who lost all proprioceptive feedback
from the neck down following an illness as a young man
(see also McNeill, 2005). IW taught himself to control his
instrumental actions through visual feedback, but when he
could not see his body, he lost control of his actions and
could not move. What about gesture? Would IW be able to
gesture if he were not able to see his hands? To examine this
question, the researchers built a visual blind, and compared
IW’s ability to execute instrumental actions (such as
opening a jar) with his ability to gesture while speaking
(talking and gesturing about opening a jar). They found that,
as expected, IW’S instrumental actions were severely
compromised under the blind. However, his gestures were
unaffected by the blind. This surprising result suggests that
IW’s gestures were guided not by visual feedback (which
was blocked experimentally), and not by proprioceptive
feedback (which he no longer experienced), but by some
other pathway. Do IW’s gestures still serve cognitive
functions? We may never know given the uniqueness of
IW’s case, but future work using novel experimental
techniques may bring us closer to an answer.

to the cognitive effects of a special kind of action—
gesture—what we feel may matter more than what we see.

Acknowledgments
Funding for this study was provided by NICHD (R01HD47450, to Goldin-Meadow) and the Spatial Intelligence
and Learning Center (SBE 0541957, Goldin-Meadow is a
co-PI) through the National Science Foundation. The
authors would also like to thank Calla Trofatter and Cassie
Sarnell for help with data collection, and Gwendolyn
Sandoboe for data coding.

References
Beilock, S. L., & Goldin-Meadow, S. (2010). Gesture
changes thought by grounding it in action. Psychological
Science, 21, 1605–1610. doi:10.1177/0956797610385353
Beilock, S. L., Lyons, I. M., Mattarella-Micke, A.,
Nusbaum, H. C., & Small, S. L. (2008). Sports experience
changes the neural processing of action language. PNAS,
105, 13269–73. doi:10.1073/pnas.0803424105
Brooks, N., Barner, D., Frank, M., & Goldin-Meadow, S.
(under review). Motor planning of gesture supports
numerical computation in mental abacus.
Casasanto, D., & Chrysikou, E. G. (2011). When left is
“right”: Motor fluency shapes abstract concepts.
Psychological Science, 22, 419-422. doi:10.1177/
0956797611401755
Casile, A., & Giese, M.A. (2006). Nonvisual motor training
influences biological motion
perception.
Current
Biology, 16, 69–74. doi: 10.1016/j.cub.2005.10.071
Clark, A. (2013). Gesture as Thought? In Z. Radman (Ed.),
The Hand, an Organ of the Mind: What the Manual Tells
the Mental (pp. 255–268). Cambridge, MA: MIT Press.
Chu, M., & Kita, S. (2011). The nature of gestures’
beneficial role in spatial problem solving. Journal of
Experimental Psychology: General, 140, 102–116.
doi:10.1037/a0021790
Cole, J., Gallagher, S., & McNeill, D. (2002). Gesture
following deafferentation: A phenomenologically
informed experimental study. Phenomenology and the
Cognitive Sciences, 1, 49–67. doi:10.1023/
A:1015572619184
Cook, S. W., & Tanenhaus, M. K. (2009). Embodied
communication: Speakers’ gestures affect listeners'
actions. Cognition, 113, 98–104.
doi:10.1016/j.cognition.2009.06.006
Emmorey, K., Bosworth, R., & Kraljic, T. (2009). Visual
feedback and self-monitoring of sign language. Journal of
Memory and Language, 61, 398–411. doi:10.1016/
j.jml.2009.06.001
Goldin-Meadow, S., Cook, S. W., & Mitchell, Z. A. (2009).
Gesturing gives children new ideas about math.
Psychological Science, 20, 267–272. doi:10.1111/j.14679280.2009.02297.x
Goldin-Meadow, S., & Beilock, S. L. (2010). Action’s
influence on thought: The case of gesture. Perspectives on
Psychological Science, 5, 664–674. doi:10.1177/1745

Conclusion
Gesture, like other kinds of action, has the power to shape
our thoughts. In recent years, demonstrations of gesture’s
cognitive functions have proliferated in different paradigms
and populations, but the mechanisms underlying these
cognitive functions have remained mysterious. The results
of the present study help to zero in on these mechanisms.
When it comes to guiding action in the world, both visual
and proprioceptive feedback are critical. But when it comes

445

691610388764
Iverson, J. M., & Goldin-Meadow, S. (1998). Why people
gesture when they speak. Nature, 396, 228. doi:10.1038/
24300
James, K. H., & Swain, S. N. (2011). Only self-generated
actions create sensorimotor systems in the developing
brain. Developmental Psychology, 14, 1-6. doi: 10.1111/
j.1467-7687.2010.01011.x
Kelly, S., Healey, M., Ozyürek, A., & Holler, J. (2014). The
processing of speech, gesture, and action during language
comprehension. Psychonomic Bulletin & Review.
doi:10.3758/s13423-014-0681-7
McNeill, D. (2005). Gesture and Thought. Chicago:
Chicago University Press.
Novack, M. A., Congdon, E. L., Hemani-Lopez, N., &
Goldin-Meadow, S. (2014). From action to abstraction:
Using the hands to learn math. Psychological Science.
doi:10.1177/0956797613518351
Pouw, W. T. J. L., de Nooijer, J. a., van Gog, T., Zwaan, R.
a., & Paas, F. (2014). Toward a more embedded/extended
perspective on the cognitive function of gestures.
Frontiers in Psychology, 5, 1–14. doi:10.3389/
fpsyg.2014.00359
Singer, M., & Goldin-Meadow, S. (2005). Children learn
when their teachers’ gestures and speech differ.
Psychological Science, 16, 85-89. doi: 10.1111/j.09567976.2005.00786.x
Sober, S. J., & Sabes, P. N. (2005). Flexible strategies for
sensory integration during motor planning. Nature
Reviews. Neuroscience, 8, 490-497. doi: 10.1038/nn1427
Thomas, L. E., & Lleras, A. (2009). Swinging into thought:
Directed movement guides insight in problem solving.
Psychonomic Bulletin & Review, 16, 719–23.doi:10.3758/
PBR.16.4.719
Trofatter, C., Kontra, C., Beilock, S., & Goldin-Meadow, S.
(2014). Gesturing has a larger impact on problem-solving
than action, even when action is accompanied by words.
Language, Cognition and Neuroscience, 30, 1–10.
doi:10.1080/23273798.2014.905692

446

