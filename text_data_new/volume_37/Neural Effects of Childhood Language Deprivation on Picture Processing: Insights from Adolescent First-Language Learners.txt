Neurral Effects of Childh
hood Lang
guage Deprrivation oon Picture Processin
ng:
Inssights from
m Adolesceent First-L
Language Learners
Trista
an S. Davenp
port (trdaven
np@ucsd.edu
u)
Department of Linguistics,, UC San Dieggo, 9500 Gilmaan Drive
San Dieg
go, CA 92093 U
USA
Naja
N
Ferjan Ramirez
R
(naja@
@uw.edu)
Institutee for Learning and Brain Scieences, Universsity of Washinggton, Box 3579988
Seattle, WA
W 98195-79888 USA
K Leonard (L
LeonardM@n
neurosurg.ucsff.edu)
Matthew K.
Departm
ment of Neurollogical Surgery
y, UC San Franncisco, 675 Neelson Rising Laane
San Franciisco, CA 941588 USA

Rachel Mayberry
y (rmayberryy@ucsd.edu) *
Department of Linguistics,, UC San Dieggo, 9500 Gilmaan Drive
San Dieg
go, CA 92093 U
USA
Eric
E Halgren (ehalgren@uccsd.edu) *
Multimodal
M
Imaging Laborato
ory, UC San D
Diego, 9500 Gillman Drive
San Dieg
go, CA 92093 U
USA
* These authors contriibuted equally tto this manusccript
(termedd “deaf native signers”) grow
w up among deeaf, signing
adults and begin too acquire a sign language beginning
shortly after birth. Hoowever, many other deaf children grow
up withhout access to sign languagees, typically beecause they
are borrn in a commuunity without sign languagee users and
their paarents are unaable to access social servicees for deaf
childrenn. Such individduals, termed “late learners”” here, may
not beggin to acquire llanguage until they enter schhool, and in
rare ca ses, not until aadolescence. Inndividuals whho began to
acquiree their first language, Am
merican Sign Language
(ASL), in late childhoood show deficits plateau in their adult
languagge processingg skills and their ultimatee language
proficieency. The effeccts of late firstt language acquuisition are
quantitaatively strongeer than those of late secondd language
acquisiition. Late firsst language accquisition is pparticularly

Absstract
The developm
mental relationsh
hip between ling
guistic semanticc
processing and non-linguistic semanttic processing
g
(interpreting pictures) is in
nvestigated in a longitudinall
neuroimaging study of two deaf individualls who did nott
begin acquirin
ng their first lan
nguage until thee age of 14. 1-2
2
years after theey began learning
g language, the two
t case studiess
performed
a
picturre-sign
priming
task..
Magnetoencep
phalography was localized to
t the corticall
surface, showiing that picture processing
p
was initially
i
bilaterall
or focused in the
t canonical lefft hemisphere lan
nguage network,,
while single siign processing was
w initially focu
used in the rightt
hemisphere. After 15 months of additional languagee
he neural respon
nses to both picttures and singlee
experience, th
signs reversed
d in lateralization, becoming more
m
similar to
o
those observeed in a control group of nativ
ve signers. Thee
results shed new light on the interdepen
ndence between
n
linguistic an
nd non-linguistic semantics in cognitivee
development, as well as the neeural underpinniings of semanticc
processing.
nguistics; neurosscience; cognitiv
ve development;;
Keywords: lin
language acqu
uisition; semantiics; experimentaal research with
h
children; neuro
o-imaging; case studies; sign lan
nguage.

Introd
duction
E
Exposure to lan
nguage during early childhoo
od is essential for
f
ffluent linguistiic skill later in
i life. It is difficult
d
to stu
udy
eexactly how eaarly language in
nput influencess both behavio
oral
aand neural lin
nguistic outcom
mes, primarily
y because earrly
laanguage deprrivation is extremely
e
unccommon amo
ong
hhearing childreen, who are exposed to langu
uage even befo
ore
bbirth (Moon & Fifer, 2000). Likewise, som
me deaf childrren

Figurre 1: Schemaatic diagram of task desiggn. Each
picturre and sign aappeared in booth the congruuent and
inconngruent conditiions.

507

that the neural correlates of single sign processing can be
relatively similar to those of deaf native signers following so
little language exposure, while behavioral linguistic skills
remain so far outside the normal range. To understand this
disconnect, we examined the effects of late language
acquisition on a non-linguistic aspect of the semantic
system, the interpretation of meaningful pictures. The
experimental design included two presentations of each
picture prime, allowing us to measure a picture repetition
(novel-repeated) effect on the N400m.
These neural responses allow us to investigate whether
late acquisition of language affects the semantic processing
of non-linguistic stimuli, namely pictures. We considered
two hypotheses. First, it is possible that the linguistic and
non-linguistic aspects of the semantic system develop in
relative isolation from one another. If this is the case, then
non-linguistic semantic processing would follow a similar
developmental trajectory regardless of the presence or
absence of linguistic input. We would also expect Carlos’s
and Shawna’s brain responses to pictures to look similar to
those of the deaf native signing controls, and to be
unaffected by additional language experience between
Visits 1 and 2. Alternatively, it is possible that the
development of the linguistic and image-based semantic
systems is coupled, and that the cortical localization of one
system depends to some degree on the activity of the other.
This hypothesis predicts that Carlos’ and Shawna’s
responses to pictures would change from Visit 1 to Visit 2,
resembling those of the deaf native signers more closely in
Visit 2.

deleterious when no formal language has been available
until late childhood or the early teenage years (Mayberry,
1993; Mayberry, Lock & Kazmi, 2002; Ferjan Ramirez,
Lieberman & Mayberry, 2013).
It is unknown why late first language acquisition creates
such serious deficits in language learning. One possibility is
that areas of the brain that are normally specialized for
language use early in life – mainly structures in the left
perisylvian cortex – become specialized for non-linguistic
processes in children deprived of early language input, but
who still interact with their environment through visual and
tactile means. This possibility raises the question of how the
adolescent brain adapts to language, and what happens to
these areas that were previously specialized for nonlinguistic processes. To understand the neural mechanisms
involved in late learners’ linguistic and non-linguistic
semantic processing abilities, our group has conducted a
longitudinal imaging study on a unique pair of extreme
cases of childhood language deprivation. “Carlos” and
“Shawna” are two deaf teenagers who did not begin to
acquire their first language, ASL, until roughly the age of 14
when they were placed in a group home for the deaf.
Investigations into the neural underpinnings of language
in these two adolescent deaf late learners were conducted
using a picture-sign priming task (Ferjan Ramirez et al.,
2013a; 2014). In two experiments, 15 months apart,
participants viewed line drawings of objects followed by
matching or mismatching ASL signs (Fig. 1) while
magnetoencephalographic (MEG) brain responses were
recorded. The experimental task was designed to evoke the
N400m response, the MEG index of the N400 (Kutas &
Hillyard, 1980; Kutas & Federmeier, 2011; Halgren et al.,
2002). The N400 is an electrophysiological response that is
reliably evoked by a meaningful stimulus, is measurable at
the scalp, and is attenuated by supportive contextual factors
such as semantic overlap with recent stimuli, predictability,
and repetition. The dependent variable was therefore the
difference in the N400m magnitude between the congruent
and incongruent ASL signs.
Figure 2 summarizes the results of that study for the two
adolescent late learners, Carlos and Shawna, described
above. At Visit 1, Carlos’ and Shawna’s N400m effects of
sign congruency were primarily lateralized to the right
hemisphere (RH) and included large areas of cortex outside
of the canonical left hemisphere (LH) perisylvian language
network. At Visit 2, after 15 months of additional language
experience, their neural activation patterns were
substantially different. Neural responses to ASL signs were
focused in bilateral (Carlos) and left hemisphere (LH)
perisylvian cortex (Shawna). Compared to the pattern of
neural activity observed at Visit 1, the neural responses at
Visit 2 were substantially more similar to those observed in
a control group of 12 deaf native ASL signers who
performed the same task.
These results demonstrate that early language deprivation
has profound impacts on the neural processing of linguistic
input, and that continued exposure to language, even later in
life, changes these representations. However, it is surprising

Methods
Participants
The study focused on two right-handed adolescent late
learners (Carlos and Shawna) whose language input was
delayed until adolescence. For a full description of
Shawna’s and Carlos’s backgrounds, see Ferjan Ramirez et
al. (2013a). In brief, they began to acquire their first
language, ASL, at the age of 14 in the full immersion
environment of a group home for deaf children. Despite
their lack of language exposure and schooling prior to their

Figure 2: Anatomically constrained MEG (aMEG) maps
of the sign congruence effect 300-350 ms after sign onset
in the two case studies.

508

placement in the group home, they both had otherwise
healthy upbringings, free of the abuse and social isolation
typical in hearing late learners (Curtiss, 1976). At the time
of their placement in the group home for their deaf, Shawna
communicated through demonstration and limited use of
non-linguistic gestures. Carlos knew a small number of ASL
signs. Neither Carlos nor Shawna have ever been observed
to use any signs indicative of a homesign system, though it
is unknown whether they used a homesign system with their
family members in the past. Additionally, the ASL-fluent
social workers who have worked with Carlos and Shawna
report that they have no knowledge of any conventional
spoken language, that they are illiterate, and that they were
unable to lipread.
At the time of Visit 1, Carlos and Shawna had lived in full
ASL immersion for 1 year in Shawna’s case and 2 years in
Carlos’s case. At this time, their vocabulary was assessed
against the MacArthur-Bates Communicative Development
Inventory for ASL. Their vocabulary was similar in
composition to that of a typically developing deaf 2 year-old
(i.e., with a preponderance of nouns and few verbs and
function words), although somewhat larger in terms of the
overall number of signs. Visit 2 was 15 months later.
In addition to Shawna and Carlos, 12 deaf native ASL
signers (6 male, age 17-36) with no neuropsychological
impairment participated in the study. These individuals were
right-handed, profoundly deaf, and acquired ASL as the
main language of communication beginning at birth from
their deaf parents. Due to the difficulty of finding native
signing participants who meet the criteria for MEG and MRI
scanning, it was not possible to match the late learners and
the native signers on factors such as age.

Figure 3: Average normalized aMEG responses to
meaningful pictures in 12 deaf native signers. Red and
yellow areas represent areas where picture repetition
modulated neural activity between 350 and 450 ms.
implemented a separate set of stimuli that was not part of
the experimental stimuli. All controls and both cases
understood the task quickly. No participant required
repetitions of the practice block.

Procedure
MEG was recorded in a magnetically shielded room
(IMEDCO-AG, Switzerland), with the head in a Neuromag
Vectorview dewar containing 102 magnetometers and 204
planar gradiometers (Elekta AB, Helsinki, Finland). Data
were collected at a continuous sampling rate of 1000 Hz
with minimal filtering (0.1–200 Hz). The positions of 4
nonmagnetic coils affixed to the subjects’ heads were
digitized along with the main fiduciary points such as the
nose, nasion, and preauricular points for subsequent
coregistration with high-resolution MRI images. Structural
MRI was acquired on the same day after MEG, and
participants were allowed to rest in the MRI scanner.

Materials
The task stimuli were a set of ASL signs that Shawna and
Carlos knew well at Visit 1 (Ferjan Ramirez et al., 2013), as
well as a set of matching line drawings to use as primes.
Carlos, Shawna, and all control participants performed a
semantic decision task intended to elicit an event-related
brain response known as the N400 (Kutas & Hillyard, 1980;
1984; Kutas & Federmeier, 2011) or N400m in MEG
(Halgren et al., 2002). While we recorded MEG,
participants saw a line drawing of an object for 700 ms,
followed by a sign (mean length: 515.3 ms; length range:
340–700 ms) that either matched (congruent; e.g. “cat-cat”)
or mismatched (incongruent; e.g., “cat-ball”) the picture in
meaning (Fig. 1). To measure accuracy and maintain
attention, participants pressed a button when the word
matched the picture; response hand was counterbalanced
across blocks within participants.
Native signers saw 6 blocks of 102 trials each. Shawna
and Carlos each saw 5 blocks of 102 trials due to vocabulary
size and equipment malfunction, respectively (Ferjan
Ramirez et al. 2013a). Prior to testing, Carlos and Shawna
participated in a separate acclimation session during which
they were familiarized with the MEG and MRI scanners and
practiced the task. Before scanning began, all participants
performed a practice run in the scanner. The practice run

Analysis
The data were analyzed using a multimodal imaging
approach, anatomically constrained MEG (aMEG), that
constrains the MEG activity to the cortical surface as
determined by high-resolution structural MRI (Dale et al.
2000). This noise-normalized linear inverse technique has
been used extensively across a variety of paradigms,
particularly language tasks that benefit from a distributed
source analysis (Marinkovic et al. 2003), and has been
validated by intracranial recordings (McDonald et al. 2010).
The data acquisition methods are described in more detail
by Ferjan Ramirez and colleagues (2013a; 2014). In brief,
the cortical surface was reconstructed from a T1-weighted
structural MRI, and MEG activity at each vertex on this
surface model was estimated every 4 ms, and the Fdistributed noise sensitivity at each location was estimated
using the average prestimulus baseline from -190 to -20 ms.
This activity is plotted on the cortical surface on a
normalized scale represented as a fraction of the peak
aMEG value. aMEG of the N400m effect was produced by
subtracting repeated from novel trials.

509

The data were inspected for bad channels (channels with
excessive noise, no signal, or unexplained artifacts), which
were excluded from further analyses. Additionally, trials
with large (>3000 fT/cm) transients were rejected. Blink
artifacts were removed using independent components
analysis (Delorme and Makeig 2004).
Individual subject aMEG movies were constructed from
the averaged data in the trial epoch for each condition using
only data from the gradiometers; these data were combined
across subjects by taking the mean activity at each vertex on
the cortical surface and by plotting it on a template brain at
each latency in the normalized units described above.

Results
We examined the aMEG results at the group level (deaf
native signers) and at the individual level (Shawna and
Carlos) from 350 to 450 ms after the presentation of the
picture, a time window during which pictures are known to
elicit N400 effects (Kutas & Federmeier, 2011).
For the deaf native controls, it was hypothesized that the
effect of picture repetition would be largest in bilateral
perisylvian cortex, in keeping with prior work showing a
larger RH role for processing meaningful pictures compared
to words (Liljestrom et al., 2009; Chee et al., 2000). Indeed,
the picture repetition N400m effect in deaf native signers
was localized to several bilateral cortical areas, including
the superior temporal sulcus, the planum temporale, and the
intraparietal sulcus. In all of these areas, the effect was
larger in RH (Fig. 3).
For the cases, Carlos and Shawna, we considered two
hypotheses, discussed previously in the Introduction. The
first hypothesis was that if the development of the linguistic
and non-linguistic aspects of the semantic system were
largely uncoupled, then aMEG maps of the picture
repetition effect would look similar to those of the deaf
native signing control participants, and would not change
appreciably as participants became more experienced in
communicating with language. The second hypothesis
posited interdependence in development between the
linguistic and non-linguistic semantic processing systems.
This hypothesis predicts an atypical cortical distribution of
picture processing in the two cases, as well as a change in
that distribution between Visit 1 and Visit 2.
The cases’ neural responses to pictures support the second
hypothesis. Figure 4 shows that for both Carlos and
Shawna, the N400 effect of picture repetition increased in
RH and decreased in LH from Visit 1 (panels A and D) to
Visit 2 (panels B and E). Carlos’s picture N400m effect was
localized to bilateral temporal cortex at Visit 1 (Figure 4A)
and to RH temporal cortex at Visit 2 (Figure 4B). Shawna’s
picture repetition effect was larger in LH at Visit 1 (Figure
4D), and by Visit 2, the lateralization of this effect had
reversed and now covered much of perisylvian and parietal
cortex in RH (Figure 4E). Together, these results suggest
that in both case studies, neural responses to pictures
underwent a LH-to-RH shift over time. This is in contrast to
sign processing, where both cases showed increased LH
activity with increased linguistic experience (Figure 2).

Figure 4: aMEG maps of the picture repetition effect in
Carlos (A, B & C) and Shawna (D, E & F).
To quantify the changes from Visit 1 to Visit 2 at each
vertex on the cortical surface, we converted the aMEG
values of the difference between conditions (novel vs.
repeated pictures) to z-scores separately at Visit 1 and Visit
2 (Fig. 4, panels C & F). These z-score maps show the brain
areas where semantic modulation in Carlos and Shawna is
greater in Visit 1 compared with Visit 2 (shown in blue and
cyan) and areas where semantic modulation is greater in
Visit 2 compared with Visit 1 (shown in yellow and red) in
normalized units. Both subjects showed increased activity at
Visit 2 greater than 2 standard deviations in the RH anterior
and superior temporal cortices. In addition, Shawna showed
increased activity of at least 2 standard deviations in similar
RH parietal areas (Figure 4F) as is normal in the native deaf
signer group (Figure 3). Areas with activity at least 1
standard deviation greater at Visit 1 than at Visit 2 were
mostly confined to the left hemisphere.

Discussion
We examined semantic processing of non-linguistic visual
stimuli in two individuals who were deprived of language
until adolescence. In the context of previous work
examining linguistic processing in the same individuals
(Ferjan Ramirez et al., 2013a; 2014), the present study
provides novel insights into the relationship between
language experience in early life and the neural architecture
of the semantic system, in both its linguistic and nonlinguistic aspects. Carlos and Shawna became immersed in
an ASL-signing community around age 14. Until that time,
they had little or no language input, but they had interacted
with meaningful objects in non-linguistic ways. Previous
studies with other late L1 learners of sign language have
shown that delayed L1 acquisition is associated with
lifelong low language proficiency, as well as anomalous
patterns of language processing in the brain (Newport 1990;
Mayberry 1993; Mayberry et al. 2011; Emmorey et al. 1995;
Ferjan Ramirez et al., 2014). The present study asks how
this early language deprivation affects other aspects of

510

images. This suggests that LH perisylvian networks are
tuned, perhaps from birth, for extracting semantic
information from input. However, as linguistic information
becomes available, the LH perisylvian network gradually respecialized to process language in preference to visual
objects. This change indicates that regardless of an
individual’s experience, LH perisylvian cortex remains
capable of adapting quite rapidly to a new, perhaps
semantically richer, form of input.
This finding is consistent with recent investigations of
changes in the brain due to learning to read late in life.
Dehaene and colleagues (2010) conducted an fMRI study on
illiterate and literate adults, including groups of literate
adults who learned to read in adulthood (“ex-illiterate
subjects”) and others who learned to read in childhood
(“literate subjects”). They found that illiterate subjects, and
to a lesser extent ex-illiterates, showed larger responses to
faces and smaller responses to written sentences in the LH
visual word form area in basal occipito-temporal cortex.
Likewise, literates showed greater specialization for faces in
the RH homologue of the visual word form area, compared
to illiterates and ex-illiterates. This result was interpreted to
reflect a process of “cortical recycling,” whereby a given
cortical area or network can be trained by structured,
interpretable input to take on a new function similar to its
previous specialization. This process can cause conflict
between the area’s old function and its new function,
prompting another brain areas with similar properties to
become more specialized for the old function.
In the case of the semantic system for adolescent late
learners like Shawna and Carlos, a similar type of cortical
recycling appears to have occurred during the interval
between Visits 1 and 2. In response to consistent language
input, LH and RH perisylvian cortex gradually became more
functionally specialized for language and visual object
processing, respectively. This response is suggestive about
the nature of the semantic system in ways that have
previously been difficult to test experimentally. Our results
suggest that the linguistic and non-linguistic aspects of the
semantic system are partially but not completely
dissociable. They are similar in that the same neural
substrate, the LH perisylvian cortex, is able to process visual
objects in the absence of language input; in addition, images
in particular are processed bilaterally in deaf native signers,
albeit with a RH bias (Fig. 3). However, linguistic and nonlinguistic semantics must also be distinct because when both
forms of input are present, their processing is biased to the
LH and RH perisylvian regions, respectively.
One possibility that bears further investigation is that the
LH perisylvian cortex specializes in extracting semantic
information from the environment, using whatever type of
stimulus is most reliably meaningful. If a new, richer mode
of extracting meaning from the environment becomes
available (e.g., by becoming immersed in a signed language
for the first time), the new source of semantic information
gradually “takes over” the LH perisylvian network. This
hypothesis, although quite underspecified, is intended to
capture the generalization that in early learners of signed

semantic processing, namely the processing of meaningful
pictures, and how that processing changes when formal
language becomes available in adolescence.
At Visit 1, aMEG recordings of Carlos and Shawna
indicated that their neural processing of pictures was
atypical. They both displayed a greater LH focus than that
observed in deaf native signers, and they also differed
strikingly from one another. In particular, Carlos’s
activation was confined to the bilateral temporal and inferior
prefrontal cortex, while Shawna’s was strongly leftlateralized in the temporal lobe. (Fig. 4). Although a rich
fMRI literature suggests that semantic processing is not
localized to the left anterior temporal lobe (Binder et al.,
2009), these results appear to be artifacts of signal dropout
in the anterior temporal lobes caused by nearby sinuses.
Later investigations with fMRI protocols specifically
designed to detected anterior temporal activations have
shown that semantic processing does indeed modulate left
anterior temporal lobe (Binder et al., 2011).
We considered two hypotheses concerning longitudinal
changes in these response patterns. The first hypothesis,
predicated on the developmental independence of linguistic
and image-based semantic systems, predicted that Carlos’s
and Shawna’s neural responses to pictures would look
similar to those of deaf native signers and would not change
between Visit 1 and Visit 2. The second hypothesis posited
interdependence of the two systems, predicting that as the
cases experienced more language, their responses to both
linguistic and non-linguistic material would become more
like those of the deaf native signers at Visit 2 than at Visit 1.
Our results support the second hypothesis. In both
Carlos’s and Shawna’s aMEG maps, the sign congruence
effect became more left-lateralized and localized to the
perisylvian cortex at Visit 2 (Fig. 2), and the picture
repetition effect became more right-lateralized (Fig. 4). This
suggests that the effect of additional language experience
was not confined to linguistic processing, but also affected
the processing of visual objects.
As Carlos and Shawna gained additional language
experience, the neural substrate of picture processing as
revealed by aMEG became less similar to that of language
processing, rather than more similar. As their linguistic
knowledge developed, the neural substrates recruited to
interpret pictures and ASL signs diverged. The reason for
this shift in neural activation patterns remains unclear,
particularly since Carlos and Shawna have not exhibited
large changes in their linguistic performance. We have
observed no evidence of the explosive growth in vocabulary
and morphology that young children undergo, nor have their
syntactic abilities have increased appreciably, either (Ferjan
Ramirez et al., 2013; 2013a; 2014).
The observed shifts in neural activation patterns are
presumably related to their additional language experience
during the 15 months between Visits 1 and 2. These results
suggest that in the absence of early input, the LH perisylvian
structures that normally process language are instead
utilized for the most reliably meaningful signal available to
deaf individuals without language exposure, namely visual

511

Emmorey, K., Bellugi, U., Friederici, A. & Horn P. (1995).
Effects of age of acquisition on grammatical sensitivity:
evidence from on-line and off-line tasks. Applied
Psycholinguistics, 16, 1–23.
Ferjan Ramirez, N., Lieberman, A., & Mayberry, R. (2013).
The initial stages of language acquisition begun in
adolescence: When late looks early. Journal of Child
Language, 40(2), 391-414.
Ferjan Ramirez, N., Leonard, M., Davenport, T., Torres, C.,
Halgren, E. & Mayberry, R. (2014). Neural Language
Processing in Adolescent First-Language Learners:
Longitudinal Case Studies in American Sign Language.
Cerebral Cortex, doi:10.1093/cercor/bhu273.
Ferjan Ramirez, N., Leonard, M., Torres, C., Hatrak, M.,
Halgren, E. & Mayberry, R. (2013a). Neural Language
Processing in Adolescent First-Language Learners.
Cerebral Cortex, 24 (10), 2772-2783.
Halgren, E., Dhond, R., Christensen, N., Van Petten, C.,
Marinkovic, K., Lewine, J. & Dale, A. (2002). N400-like
Magnetoencephalography Responses Modulated by
Semantic Context, Word Frequency, and Lexical Class in
Sentences. NeuroImage, 17(3), 1101-1116.
Kutas, M. & Federmeier, K. (2011). Thirty Years and
Counting: Finding Meaning in the N400 Component of
the Event-Related Brain Potential (ERP). Annual Review
of Psychology, 62, 621–47.
Kutas, M. & Hillyard, S. (1980). Reading senseless
sentences: brain potentials reflect semantic incongruity.
Science 207, 203–205.
Liljestrom, M., Hulten, A., Parkkonen, L. & Salmelin, R.
(2009). Comparing MEG and fMRI Views to Naming
Actions and Objects. Human Brain Mapping, 30, 18451856.
Marinkovic, K., Dhond, R., Dale, A., Glessner, M., Carr V.
& Halgren, E. (2003). Spatiotemporal dynamics of
modality-specific and supramodal word processing.
Neuron, 38 (3), 487–497.
Mayberry R. (1993). First-language acquisition after
childhood differs from second-language acquisition: the
case of American Sign Language. Journal of Speech and
Hearing Research, 36:1258–1270.
Mayberry, R., Chen J-K., Witcher, P. & Klein, D. (2011).
Age of acquisition effects on the functional organization
of language in the adult brain. Brain and Language, 119
(1), 16-29.
Mayberry R, Lock E & Kazmi H. (2002). Linguistic ability
and early language exposure. Nature, 417:38.
McDonald, C., Thesen, T., Carlson, C., Blumberg, M.,
Girard, H., Trongnetrpunya, A., Sherfey, J., Devinsky, O.,
Kuzniecky, R., Doyle, W., Cash, S., Leonard, M., Hagler,
D., Dale, A. & Halgren, E. (2010). Multimodal imaging of
repetition priming: using fMRI, MEG, and intracranial
EEG to reveal spatiotemporal profiles of word
processing. NeuroImage. 53(2), 707–717.
Moon C & Fifer W. (2000). Evidence of transnatal auditory
learning. Journal of Perinatology, 20:S37–S44.
Newport, E. (1990). Maturational constraints on language
learning. Cognitive Science, 14, 11–28.

and spoken languages, the LH is typically specialized for
language. In Carlos and Shawna, and perhaps in other
adolescent late learners, LH perisylvian cortex is initially
more responsive to meaningful pictures – a route to
semantics that late learners have been using for their entire
lives. Then, as they gain more language experience, this LH
perisylvian network changes in function and becomes more
sensitive to linguistic meaning and less sensitive to
meaningful images. In tandem with that change, picture
processing becomes more localized to perisylvian areas in
the right hemisphere.
In summary, the present results suggest that the brain
remains sensitive to different forms of semantic input
throughout young adulthood, even if language acquisition is
delayed until relatively late in life. However, the neural
substrates of linguistic and nonlinguistic semantic processes
may change with late-onset language experience. The two
adolescent late learners described here displayed single-sign
processing predominantly in RH initially, shifting primarily
to LH after 15 months of additional language experience.
Likewise, processing of meaningful pictures was initially
bilateral or LH biased, and became strongly RH biased after
15 months of additional language experience. Whether this
pattern of change is typical of late learners or idiosyncratic
to these subjects remains an open question, requiring further
research on late learners with different ages of language
acquisition and different lengths of language exposure.

References
Binder, J. R., Desai, R. H., Graves, W. W., & Conant, L. L.
(2009). Where is the semantic system? A critical review
and meta-analysis of 120 functional neuroimaging
studies. Cerebral Cortex, 19(12), 2767-2796.
Binder, J. R., Gross, W. L., Allendorfer, J. B., Bonilha, L.,
Chapin, J… & Weaver, K. E. (2011). Mapping anterior
temporal lobe language areas with fMRI: a multicenter
normative study. NeuroImage, 54 (2), 1465-1475.
Chee, M.W.L., Weekes, B., Lee, K.M., Soon, C.S.,
Schreiber, A., Hoon, J.J. & Chee, M. (2000). Overlap and
Dissociation of Semantic Processing of Chinese
Characters, English Words, and Pictures: Evidence from
fMRI. NeuroImage, 12, 392-403.
Curtiss, S. (1976). Genie: A Psycholinguistic Study of a
Modern-Day ‘wild child’. New York: Academic Press.
Dale, A. M., Liu, A. K., Fischl, B. R., Buckner, R. L.,
Belliveau, J. W., Lewine, J. D., & Halgren, E. (2000).
Dynamic statistical parametric mapping: combining fMRI
and MEG for high-resolution imaging of cortical activity.
Neuron, 26(1), 55-67.
Dehaene, S., Pegado, F., Braga, L. W., Ventura, P., Nunes
Filho, G., Jobert, A., Dehaene-Lambertz, G., Kolinsky,
R., Morais, J. & Cohen, L. (2010). How learning to read
changes the cortical networks for vision and language.
Science, 330(6009), 1359-1364.
Delorme A, Makeig S. (2004). EEGLAB: an open source
toolbox for analysis of single-trial EEG dynamics
including independent component analysis. Journal of
Neuroscience Methods. 134, 9–21.

512

