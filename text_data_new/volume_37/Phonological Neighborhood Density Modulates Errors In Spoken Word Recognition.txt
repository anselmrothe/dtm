Phonological Neighborhood Density Modulates Errors In Spoken Word Recognition

1

Mona Roxana Botezatu1,2 (botezatr@einstein.edu)
Jon-Frederick Landrigan1 (jl3456@drexel.edu)
Qi Chen3 (chenqi.research@gmail.com)
Daniel Mirman1,2 (dan@danmirman.org)
Department of Psychology, Drexel University, 3141 Chestnut Street, Philadelphia, PA 19104, USA
2
Moss Rehabilitation Research Institute, 50 Township Line Road, Elkins Park, PA 19027, USA
3
School of Psychology, South China Normal University, 510631 Guangzhou, China
Abstract

two phonemes), so they are activated early in processing
and are associated with a larger competition effect relative
to rhyme competitors, which share the offset of the spoken
word (i.e., vowel and coda), and consequently become
active later, when the target word (along with its cohort
competitors) is already highly activated and therefore more
strongly suppressing any new competitors (e.g., Allopenna,
Magnuson & Tanenhaus, 1998; Magnuson et al., 2007).
The addition of noise tends to increase competition from
offset neighbors more than onset neighbors, regardless of its
source (broadband noise: Brouwer & Bradlow, 2011; rhyme
neighbors spoken in the background: Brouwer & Bradlow,
in press) and locus of occurrence (concurrently with the
target: Brouwer & Bradlow, 2011; somewhere in the
sentential context: McQueen & Huetting, 2012). Moreover,
older adults experience more competition from rhymes in
noisy backgrounds than younger adults do (Ben-David et
al., 2011), suggesting that age-related declines in hearing
acuity may have a similar “noise” effect (Lash, Rogers,
Zoller & Wingfield, 2013).
Analyses of error types have provided unique insights into
the cognitive and neural architecture of spoken word
production (e.g., Dell, Schwartz, Martin, Saffran & Gagnon,
1997; Schwartz, Dell, Martin, Gahl & Sobel, 2006; see
Schwartz, 2014 for a review). To our knowledge, a similar
analysis of overt error types in spoken word recognition has
not been attempted. In the current study, we examined the
relative proportion of cohort and rhyme errors during
spoken word recognition as a function of cohort and rhyme
neighborhood density.
Phonological neighbors have been generally found to
exert an inhibitory effect on recognition of a spoken target
word. However, they should also exert a facilitative effect
through excitatory feedback connections that support the
shared phonological units such as phonemes. For example,
“beet” competes with “heat”, but also sends feedback
excitation to /i/ and /t/ phonemes, which send feedforward
excitation to “heat”, thus producing an indirect facilitative
effect. In spoken word recognition this facilitative effect is
generally weaker than the direct inhibitory effect, though
this is different in other tasks (e.g., visual word recognition)
and can be modulated by preview of response options (see
Chen & Mirman, 2012; 2015). Recurrent facilitation may
increase cohort errors for targets from dense cohort
neighborhoods and increase rhyme errors for targets from
dense rhyme neighborhoods. Bormann, Kulke, Wallesch
and Blanken (2008) report an analogous error pattern in

The present study examined how differences in onset (cohort)
and offset (rhyme) neighborhood density influence the types
of spoken word recognition errors made by listeners.
Simulations of the TRACE model were used to derive
preliminary predictions. Younger (N=15) and older (N=15)
adults identified spoken words presented in moderate noise.
Participants exhibited the standard inhibitory effect of
phonological neighborhood density: slower recognition of
spoken words from denser neighborhoods, with a larger effect
for older adults. Most errors were phonological neighbors
with few unrelated errors. However, the manipulation of
cohort and rhyme density produced an unexpected reversal:
the relative proportion of cohort vs. rhyme errors was biased
toward cohorts when cohort density was low or when rhyme
density was high, and toward rhymes when cohort density
was high or rhyme density was low. These results are not
consistent with the TRACE simulations and suggest a more
complex pattern of lexical competition.
Keywords: neighborhood density; spoken word recognition;
lexical selection; error type.

Introduction
Spoken word recognition requires listeners to map
sequential phonological input onto stored lexical candidates.
It is widely agreed that this mapping occurs incrementally,
sequentially, and interactively: starting with the onset of
speech input, proceeding along with the sequential speech
input, and involving both bottom-up and top-down
information flow (for a review see, e.g., Magnuson,
Mirman, & Myers, 2013). One consequence of the
incremental nature of spoken word recognition is the
parallel activation of multiple lexical candidates based on
partial match to the unfolding speech input and competition
between those candidates. This competition can be easily
demonstrated by phonological neighborhood density effects:
words with many phonological neighbors are recognized
more slowly and less accurately than words with fewer
phonological neighbors (e.g., Luce & Large 2001; Luce &
Pisoni 1998; Luce, Pisoni & Goldinger, 1990; Magnuson,
Dixon, Tanenhaus & Aslin, 2007; Sommers, 1996).
The most common definition of phonological neighbors is
known as the “one phoneme rule”: a neighbor differs from
the target word by no more than one phoneme through
deletion, addition, or substitution (also called the DAS rule).
Due to the sequential nature of speech input, the location of
overlap also influences competition. For example, cohort
competitors share the onset of the spoken word (i.e., first

250

individuals with aphasia, who produced semantic errors
more frequently for targets with many semantic neighbors,
while omissions were more frequent for targets with few
semantic neighbors. On the other hand, a dense cohort
neighborhood may increase cohort ambiguity, possibly
making rhyme errors more likely (and vice versa for rhyme
neighborhoods). Further, since older adults exhibit increased
rhyme competition relative to younger adults, younger
adults may experience more competition from onsets,
therefore producing more onset errors than older adults do.
As the above demonstrates, it is difficult to intuit the net
effect of the combination of direct inhibition and recurrent
facilitation on error types. Therefore, we conducted
preliminary simulations of the TRACE model (McClelland
& Elman, 1986) in order to empirically determine an initial
set of predictions from a widely-accepted interactive
activation and competition model of spoken word
recognition.

link between TRACE lexical unit activations and word
recognition errors. The preliminary predictions were based
on averages over cycles 5 to 40 because response
probabilities were at baseline before cycle 5 and
competition was essentially eliminated after cycle 40.
Figure 1 shows the TRACE-predicted patterns of cohort
errors (top panel), rhyme errors (middle panel), and
unrelated errors (bottom panel) as a function of increasing
rhyme density (red lines) or cohort density (blue lines), for
both no-noise (solid lines) and with-noise (dotted lines)
simulations. Because the goal of these simulations was to
derive preliminary predictions using highly simplified
lexicons, the specific predicted values are not as important
as the qualitative pattern of error types.

Simulations
The simulations were conducted using the jTRACE
implementation (Strauss, Harris & Magnuson, 2007) of the
TRACE model of speech perception and spoken word
recognition (McClelland & Elman, 1986). For each
simulation, a target word was presented and response
probabilities were computed using the R. D. Luce (1959)
choice rule for four response options: the target word, a
cohort competitor, a rhyme competitor, and a
phonologically unrelated word. Minimal artificial lexicons
were constructed to provide a simple context for testing
effects of cohort and rhyme density. Each lexicon contained
the same three critical quartets of words (target, cohort,
rhyme, and unrelated). The base lexicon consisted of only
those 12 words. Two additional lexicons were created by
adding either four cohort or four rhyme competitors (to
bring the total to 5 cohort or 5 rhyme competitors), and
another two lexicons had an additional 5 cohort or 5 rhyme
competitors (for a total of 10 cohort or 10 rhyme
competitors). When the number of one kind of competitor
was increased, the other competitor type was held constant
(i.e., the lexicons with 1, 5, and 10 cohort neighbors
contained only 1 rhyme neighbor; the lexicons with 1, 5,
and 10 rhyme neighbors contained only one cohort
neighbor). That is, we tested the same three sets of critical
items at separately increasing numbers of cohort or rhyme
competitors. Simulations were conducted using the default
TRACE parameter set and with the addition of Gaussian
noise (SD=0.5). The with-noise simulations were repeated
10 times to average over idiosyncratic noise samples.
Because participants in the behavioral experiment would
be making forced-choice decisions between the target and
specific cohort, rhyme, and unrelated distractors, for the
simulations, lexical unit activation was converted into
response probabilities among the defined set of four
alternatives using the Luce choice rule. The Luce choice
rule quantifies the activation of each response option
relative to all other options and thereby provides one simple

Figure 1: TRACE model predictions for effect of
increasing rhyme density (red lines) or cohort density
(blue lines) on probability of cohort errors (top panel),
rhyme errors (middle panel), and unrelated errors
(bottom panel). Solid lines show results of no-noise
simulations, dotted lines show with-noise simulations.
Note that the vertical axis scale differs in the top panel
because cohort activations are substantially higher than
rhyme and unrelated activations.
The simulation results predict that increasing cohort
density (blue lines) should have a minimal (possibly
increasing) effect on cohort errors (top panel) while
producing more rhyme and unrelated errors (middle and
bottom panels). Increasing rhyme density (red lines) should
substantially decrease cohort errors while moderately
increasing rhyme and unrelated errors.
The experiment was designed to provide new insights into
the dynamics of lexical competition by considering error
types in the context of these predictions.

251

Experiment

presented and remained on the screen until a response was
made.
Table 1: Mean (SD) target word characteristics.
Cohort Density
Rhyme Density
Measure
High
Low
High
Low
Auditory file
626.3
622.8
613.5
600.4
length (ms)
(95.19)
(90.7)
(98.66) (102.85)
Number of
3.40
3.43
3.40
3.43
phonemes
(0.5)
(0.5)
(0.62)
(0.68)
Log frequency
1.24
1.29
1.06
1.02
(0.68)
(0.54)
(0.33)
(0.28)
Number of
19.03
14.97
20.33
10.80
neighbors
(9.69)
(8.34)
(8.99)
(5.33)
Summed freq.
23.24
18.04
22.91
11.04
neighbors
(14.02)
(11.61) (11.59)
(6.19)
Number cohort
96.37
35.27
48.63
57.60
neighbors
(73.49)
(19.8)
(32.6)
(41.21)
Summed freq.
64.83
25.75
34.27
39.58
cohort neigh
(48.8)
(13.48) (22.75)
(27.34)
Number rhyme
18.97
14.60
24.47
4.70
neighbors
(11.90)
(8.62)
(10.16)
(1.95)
Summed freq.
24.71
17.88
31.04
4.35
rhyme neigh
(23.44)
(12.41) (21.19)
(2.30)

Method
Participants Two groups of participants with no history of
neurological, language, or reading disorders completed the
study: (1) 15 young adults (6 male, mean age = 21.5, age
range = 18-38) recruited from Drexel University and (2) 15
older adults (8 male; mean age = 67.9, age range = 61-79
years) recruited from the MRRI Cognitive Rehabilitation
Research Registry (Schwartz, Brecher, White & Klein,
2005), who showed no signs of cognitive impairment based
on the Mini Mental State Examination (Folstein, Folstein &
McHugh, 1975; mean score = 28.1).
Materials Stimuli were 600 monosyllabic English open
class words (nouns and verbs), which were divided into 120
targets and 480 distractors. The phonological neighborhood
of target words was separately manipulated at word onset
(first two phonemes, i.e., cohort) and word offset (vowel
and coda, i.e., rhyme). Cohort density (high vs. low) was
operationalized as the number, t(58) = 4.4, p < 0.0001, and
summed frequency, t(58) = 4.23, p < 0.0001, of onset
neighbors, while the number and summed frequency of
offset neighbors was held constant (all p > 0.05). Rhyme
density was operationalized as the number, t(58) = 10.47, p
< 0.0001, and summed frequency, t(58) = 6.86, p < 0.0001,
of offset neighbors, while the number and summed
frequency of onset neighbors was held constant (all p >
0.05). The manipulations of phonological neighborhood
type and density resulted in four conditions of interest with
30 trials each: high-density cohorts, low-density cohorts,
high-density rhymes and low-density rhymes (see Table 1).
The conditions were matched on number of phonemes and
lexical frequency using the American National Corpus (Ide
& Suderman, 2004), as well as on the length of the auditory
file (all p > 0.05). Distractors were of four types: cohort
neighbors, rhyme neighbors, cohort neighbors of rhyme
distractors and rhyme neighbors of cohort distractors, and
did not differ in number of phonemes, frequency,
phonological neighborhood density and cohort density from
targets (all p > 0.05). All auditory targets were recorded by
a female native English speaker in a quiet room and
normalized at 60 dB prior to adding 62 dB of white noise to
make word recognition more difficult.

The response array contained the target (e.g., CAP), a
cohort distractor (e.g., CAT), a rhyme distractor (e.g., LAP),
a cohort neighbor of the rhyme distractor (e.g., LAG), a
rhyme neighbor of the cohort distractor (e.g., MAT), and an
undecided response option (i.e., ?) to reduce guessing. See
Table 2 for examples. This made it difficult to guess the
target simply from the structure of the response array (i.e.,
the target was not the only option with phonologically
related distractors; there were two other response options
that also had cohort-related and rhyme-related distractors).
The response options were presented in black capital letters
against a white background and their locations were
randomized on each trial.
Participants were instructed to select the cell containing
the word they heard either using a mouse (younger adults)
or using their hand on a touch-sensitive monitor (older
adults). They were also encouraged to select the “?”
response option whenever they were unable to recognize the
target. Both speed and accuracy were stressed. A set of 20
practice trials preceded the experimental set.

Procedure Participants were seated at a comfortable
distance (about 15 inches) from a computer monitor and
asked to perform a spoken-to-written word matching task,
consisting of 120 trials with a mid-way break. The task was
modeled on identification of words in noise (e.g., Luce &
Pisoni, 1998). Each trial began with a trial preparation
screen presented for 2000 ms with a red circle in the center
that decreased in size until it disappeared, at which point the
auditory stimulus was presented over headphones. This was
followed by a 1000 ms blank screen to allow auditory word
recognition without bias from visually-presented response
options. Finally, a 2 x 3 array of six response options was

Table 2: Stimulus examples.
Response
Target
Cohort Distractor (CD)
Rhyme Distractor (RD)
Cohort Neighbor of RD
Rhyme Neighbor of CD

High Density
CAP
CAT
LAP
LAG
MAT

Low Density
FOX
FOG
BOX
BOSS
JOG

Results
Reaction Times Correct-response latencies were analyzed
using linear mixed-effects models with crossed random

252

effects of subjects and items (Baayen, Davidson & Bates,
2008; Barr, Levy, Scheepers & Tily, 2013) implemented in
R version 3.0.2 (R Core Team, 2013) using the lme4
package version 1.0-5 (Bates, Maechler, Bolker & Walker,
2013). The models included fixed effects of Density Level
(High vs. Low), Density Type (Cohort vs. Rhyme), and
Age, and maximal random effect structures (random
intercepts and slopes of Density Type and Level by subjects
and of Age by items). Degrees of freedom for parameterspecific significance tests were estimated using the
Kenward-Roger approximation implemented in the pbkrtest
package version 0.4-2 (Halekoh & Højsgaard, 2014).
Average naming latencies are shown in Table 3. Overall,
older adults were substantially slower to respond than
younger adults were (t(36) = 4.7, p < 0.001), though recall
that older adults used a touch-screen to respond whereas
younger adults used a mouse, which may also have affected
response times. Responses were slower for high
phonological neighborhood density words than for low
neighborhood density words (t(36) = 2.2, p < 0.05),
consistent with many prior reports of inhibitory effects of
phonological neighborhood density in spoken word
recognition. This main effect must be interpreted in the
context of a statistically significant interaction: across both
types of neighborhood density, the effect of density for
older adults was significantly larger than for younger adults
(t(36) = 2.4, p < 0.05).

Younger

Number of Errors

100

Low
1952
(118)
1358
(102)

High
2198
(137)
1405
(123)

50

Error Types
Cohort Distractor (CD)
Rhyme Distractor (RD)

0
150

Cohort Neighbor of RD
Rhyme Neighbor of CD

100

Undecided

50
0
High

Low

High

Low

Density

Figure 2: Cumulative total errors by type for younger
adults (top panels) and older adults (bottom panels).

Table 3: Mean (SE) response times.
Cohort Density
Rhyme Density
High
2252
(132)
1505
(118)

Rhyme

Older

Older

Cohort
150

Younger

Age Group

the base of each bar stack in Figure 2. Cohort errors appear
to be more likely when cohort density is low or when rhyme
density is high. Conversely, rhyme errors appear to be more
likely when cohort density is high or when rhyme density is
low.
To quantify this trade-off directly and to mitigate the
sparseness of the individual trial data, we computed the
empirical log-odds (e.g., Barr, 2008) of cohort vs. rhyme
errors for each participant in each condition (high vs. low
cohort density, high vs. low rhyme density), which are
plotted in Figure 3.

Positive values (right of vertical black line) indicate that
cohort errors were more likely than rhyme errors; negative
values (left of vertical black line) indicate that rhyme errors
were more likely than cohort errors. The vertical axis
(Condition) refers to density type, the colors indicate
density level within each type, and the age groups are shown
in separate panels although the pattern is essentially the
same for both. These data were analyzed using linear
mixed-effects models with fixed effects of age, density type
(cohort vs. rhyme) and density level (high vs. low) and
random effects of participants and by-participant random
slopes of density type and level.

Low
2069
(123)
1460
(108)

Accuracy Accuracy was analyzed using logistic mixedeffects models with crossed random effects of subjects and
items (Baayen et al., 2008; Barr et al., 2013; Jaeger, 2008).
The full model included fixed effects of Density Level
(High vs. Low), Density Type (Cohort vs. Rhyme), and
Age, and maximal random effect structures (random
intercepts and slopes of Density Type and Level by subjects
and of Age by items). The only statistically significant
effect was higher accuracy for younger adults compared to
older adults (χ2(1) = 4.89, p < 0.05; 95% confidence
intervals: Older adults: 79.6% - 89.7%; Younger adults:
86.4% - 94.3%).

Younger

Cohort

●

●

●

●

Condition

Rhyme

Error Types Figure 2 shows the error type totals by Age
Group, Density Type (Cohort Density in left panels, Rhyme
Density in right panels), and Density Level (High vs. Low).
Almost all errors were of one of three types: cohort
distractor, rhyme distractor, or undecided (i.e., very few
unrelated errors).
A striking pattern of trade-offs between cohort and rhyme
distractor errors is clear from the blue and pink segments at

Older

Cohort

●

●

●

Rhyme

−0.5

Density

●

0.0

0.5

●

High

●

Low

1.0

Empirical Log−Odds
(Cohort/Rhyme)

Figure 3: Empirical log-odds of cohort vs. rhyme errors.

253

There was a significant density type by density level
interaction (χ2(1) = 41.97, p < 0.0001), confirming that
when cohort density was high, rhyme errors were more
common than cohort errors but when cohort density was
low, cohort errors were more common than rhyme errors.
The pattern for rhyme density was the exact opposite: when
rhyme density was high, cohort errors were more common
than rhyme errors but when rhyme density was low, rhyme
errors were more common than cohort errors. This overall
pattern was marginally modulated by age (age by density
type by density level interaction: χ2(1) = 3.00, p = 0.08):
younger adults showed a marginally larger density type by
density level interaction (points in the top panel of Figure 3
are somewhat more widely spaced than points in the bottom
panel).

for the error pattern humans produce in spoken word
recognition. However, the model failure must be interpreted
with care, as there are a number of reasons why the
mismatch between model and human behavior may have
occurred (see Magnuson et al., 2012 for discussion of
assessing model failures). The TRACE model is a general
model of speech perception and spoken word recognition
and includes a (simple) system for producing forced-choice
responses. It is possible that some properties of our spokento-written word matching task modulate lexical activation,
competition, or selection in a way that is not captured by the
TRACE model.
It is also possible that the simple artificial lexicon used for
our preliminary simulations did not capture aspects of the
true English lexicon that give rise to these effects, though it
is not apparent what those aspects are. Further, the restricted
phonemic inventory of the TRACE model makes it
impossible (or at least very difficult) to model a realistic
English lexicon. For the preliminary simulations reported
here, we opted for the tractability of a simple lexicon, but
future simulations should consider whether the critical
reversal would be produced by a more complex and realistic
lexicon.
An alternative possibility is that the single inhibition
parameter that determines lexical inhibition in the TRACE
model does not fully capture lexical inhibition dynamics.
Future simulations will explore alternative formulations of
lexical inhibition.

Discussion
The current study evaluated how differences in cohort and
rhyme neighborhood density influence the types of errors
made by younger and older adults in identifying spoken
words presented in moderate noise. We replicate the latency
patterns previously reported in the literature, showing
overall slower recognition of spoken words from denser
neighborhoods (see Luce and colleagues), with a larger
effect for older adults (Sommers, 1996). Younger adults
were overall more accurate than older adults. The key novel
finding was that the relative proportion of cohort vs. rhyme
errors was shifted toward cohorts when rhyme density was
high, and toward rhymes when cohort density was high.
Younger adults showed a marginally larger density type by
density level interaction.
The observed error patterns depart from the TRACE
model simulations in two important respects. First, overall
there were nearly as many rhyme errors as cohort errors,
whereas the simulations predicted substantially more cohort
errors than rhyme errors. Adding noise increased rhyme
error probability in the TRACE model (as we have
previously found: Mirman et al., 2011) -- not quite to the
level of cohort errors, but a larger amount of noise might be
able to accomplish that. However, adding noise also
increased unrelated error probability, keeping them at nearly
the same level as rhyme errors. In the behavioral data,
unrelated errors were very rare, substantially more rare than
cohort and rhyme errors. That is, the simulations incorrectly
predicted the overall relative rates of cohort, rhyme, and
unrelated errors.
Second, the simulations incorrectly predicted that rhyme
errors would increase slightly in both high cohort and high
rhyme density conditions, and that cohort errors would
decrease in the high rhyme density condition. Instead, the
behavioral data showed a very symmetric reversal: words
with higher rhyme density and words with lower cohort
density both elicited increased cohort errors and reduced
rhyme errors.
The discrepancy between the behavioral results and the
predictions generated by the TRACE model is striking and
suggests that in its current form, the model fails to account

Acknowledgments
This research was supported by NIH grant R01DC010805 to
DM. We thank Myrna Schwartz and Gary Dell for helpful
discussions, as well as Kristen Graziano and Allison Britt
for help with participant recruitment and data collection.

References
Allopenna, P. D., Magnuson, J. S., & Tanenhaus, M. K.
(1998). Tracking the time course of spoken word recognition using eye movements: Evidence for continuous
mapping models. Journal of Memory and Language, 38,
419–439.
Baayen, R. H., Davidson, D. J., & Bates, D. M., (2008).
Mixed-effects modeling with crossed random effects fur
subjects and items. Journal of Memory and Language,
59(4), 390–412.
Barr, D. J. (2008). Analyzing ‘visual world’ eyetracking
data using multilevel logistic regression. Journal of
Memory and Language, 59(4), 457–474.
Barr, D. J., Levy, R., Scheepers, C., & Tily, H. J. (2013).
Random effects structure for confirmatory hypothesis
testing: Keep it maximal. Journal of Memory and
Language, 68(3), 255–278.
Bates, D., Maechler, M., Bolker, B., & Walker, S. (2013).
lme4: Linear mixed-effects models using Eigen and S4. R
package
version
1.0-5.
http://CRAN.Rproject.org/package=lme4

254

Ben-David, B. M., Chambers, C. G., Daneman, M., PichoraFuller, M. K., Reingold, E. M., & Schneider, B. A.
(2011). Effects of aging and noise on real-time spoken
word recognition: Evidence from eye movements.
Journal of Speech, Language, and Hearing Research,
54(1), 243–262.
Bormann, T., Kulke, F., Wallesch, C., & Blanken, G.
(2008). Omissions and semantic errors in aphasic naming:
Is there a link? Brain and Language, 104(1), 24–32.
Brouwer, S., & Bradlow, A. R. (In press). The temporal
dynamics of spoken word recognition in adverse listening
conditions. Journal of Psycholinguistics Research.
Brouwer, S., & Bradlow, A. R. (2011). The influence of
noise on phonological competition during spoken word
recognition. Proceedings of the International Congress of
Phonetic Sciences. International Congress of Phonetic
Sciences, 2011, 364–367.
Chen, Q., & Mirman, D. (2015). Interaction between
phonological and semantic representations: Time matters.
Cognitive Science, 39, 538–558.
Chen, Q., & Mirman, D. (2012). Competition and
cooperation among similar representations: Toward a
unified account of facilitative and inhibitory effects of
lexical neighbors. Psychological Review, 119(2), 417–
430.
Dell, G. S., Schwartz, M. F., Martin, N., Saffran, E. M., &
Gagnon, D. A. (1997). Lexical access in aphasic and
nonaphasic speakers. Psychological Review, 104(4), 801–
838.
Folstein, M., Folstein, S. E., & McHugh, P. R. (1975).
“Mini-Mental State” a practical method of grading the
cognitive state of patients for the clinician. Journal of
Psychiatric Research, 12(3), 189–198.
Halekoh, S. & Højsgaard, S. (2014). A Kenward-Roger
Approximation and Parametric Bootstrap Methods for
Tests in Linear Mixed Models - The R Package pbkrtest.
Journal of Statistical Software, 58(10), 1–30.
http://www.jstatsoft.org/v59/i09/
Jaeger, T. F. (2008). Categorical data analysis: Away from
ANOVAs (transformation or not) and towards logit mixed
models. Journal of Memory and Language, 59(4), 434–
446.
Ide, N., & Suderman, K. (2004). The American National
Corpus First Release. In M. T. Lino, M. F. Xavier, F.
Ferreira, R. Costa, & R. Silva (Eds.), Proceedings of the
Fourth Language Resources and Evaluation Conference
(LREC) (pp. 1681–1684). Lisbon: ELRA - European
Language Resources Association.
Lash, A., Rogers, C. S., Zoller, A., & Wingfield, A. (2013).
Expectation and entropy in spoken word recognition:
Effects of age and hearing acuity. Experimental Aging
Research, 39(3), 235–253.
Luce, P. A. (1986). Neighborhoods of words in the mental
lexicon. Research on Speech Perception, Technical
Report No. 6. Bloomington: Indiana University.
Luce, R. D. (1959). Individual Choice Behavior: A
Theoretical Analysis. New York: Wiley.

Luce, P. A., & Large, N. (2001). Phonotactics,
neighborhood density, and entropy in spoken word
recognition. Language and Cognitive Processes, 16(5/6),
565–581.
Luce, P. A., & Pisoni, D. B. (1998). Recognizing spoken
words: the neighborhood activation model. Ear and
Hearing, 19(1), 1–36.
Luce, P.A., Pisoni, D.B., & Goldinger, S.D. (1990).
Similarity neighborhoods of spoken words. In G. T. M.
Altmann (Ed.), Cognitive models of speech processing:
Psycholinguistic and computational perspectives (pp.
122–147).
Magnuson, J. S., Dixon, J. A., Tanenhaus, M. K., & Aslin,
R. N. (2007). The dynamics of lexical competition during
spoken word recognition. Cognitive Science, 31(1), 1–24.
Magnuson, J. S., Mirman, D., & Harris, H. D.
(2012). Computational models of spoken word
recognition. In M. Spivey, K. McRae, & M. Joanisse
(Eds.), The Cambridge Handbook of Psycholinguistics.
Cambridge University Press.
Magnuson, J. S., Mirman, D., & Myers, E. (2013). Spoken
word recognition. In D. Reisberg (Ed.), The Oxford
Handbook of Cognitive Psychology (pp. 412–441). New
York, USA: Oxford University Press.
McClelland, J. L., & Elman, J. L. (1986). The TRACE
model of speech perception. Cognitive Psychology, 18(1),
1–86.
McQueen, J. M., & Huettig, F. (2012). Changing only the
probability that spoken words will be distorted changes
how they are recognized. The Journal of the Acoustical
Society of America, 131(1), 509–517.
Mirman, D., Yee, E., Blumstein, S., & Magnuson, J.S.
(2011). Theories of spoken word recognition deficits in
aphasia: Evidence from eye-tracking and computational
modeling. Brain & Language, 117, 53–68.
Schwartz, M. F. (2014). Theoretical analysis of word
production deficits in adult aphasia. Philosophical
Transactions of the Royal Society B. 369: 20120390.
Schwartz, M. F., Brecher, A. R., Whyte, J., & Klein, M. G.
(2005). A patient registry for cognitive rehabilitation
research: A strategy for balancing patients' privacy rights
with researchers' need for access. Archives of Physical
Medicine and Rehabilitation, 86(9), 1807–1814.
Schwartz, M. F., Dell, G. S., Martin, N., Gahl, S., & Sobel,
P. (2006). A case-series test of the interactive two-step
model of lexical access: Evidence from picture naming.
Journal of Memory and Language, 54(2), 228–264.
Sommers, M. S. (1996). The structural organization of the
mental lexicon and its contribution to age-related declines
in spoken-word recognition. Psychology and Aging,
11(2), 333–341.
Strauss, T. J., Harris, H. D., & Magnuson, J. S. (2007).
jTRACE: A reimplementation and extension of the
TRACE model of speech perception and spoken word
recognition. Behavior Research Methods, 39(1), 19–30.

255

