The Effects of Criticism on Creative Ideation
Yuko Tanaka (yuko-tanaka@nii.ac.jp)
Research Organization of Information and Systems
4-3-13 Toranomon Minatoku, Tokyo 105-0001 JAPAN

Yasuaki Sakamoto (ysakamot@stevens.edu)
Stevens Institute of Technology
Castle Point on Hudson, NJ 07030 USA

Noboru Sonehara (sonehara@nii.ac.jp)
National Institute of Informatics
2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430 JAPAN

Abstract
In a typical brainstorming method, criticism must be withheld
for creative ideation. We envisage a web-based system that is
designed to avoid possible negative influences of, and make
good use of, critical thinking to generate creative ideas. To
investigate its plausibility, we developed a system in which
people participate collectively in a sequence of processes
including generating, criticizing, modifying, and evaluating
creative ideas. Here we report the results from conducting an
experiment with 238 participants to compare the critical
thinking (CT) design with a criticizing phase against the
brainstorming (BS) design without it. The main finding was
that the CT design resulted in the generation of higher quality
ideas than the BS design without sacrificing fluency with
respect to response time and the number of characters.
Keywords: critical thinking; creativity; idea generation;
computer-mediated communication (CMC).

Introduction
Creative thinking has been sometimes contrasted to
critical thinking. The former is expansive, innovative, and
unconstrained, while the latter is focused, logical, and
constrained.
Osborn (1953), who proposed the famous rules of
brainstorming to generate creative ideas, included the rule to
prohibit making critical comments during a brainstorming
session. As for the reason why he adopted this rule, he
mentions, “if you try to criticize and create at the same time,
you can’t turn on either cold enough criticism or hot enough
ideas.” That is, the two processes interfere with each other.
On the other hand, some approaches to creativity consider
critical thinking as playing an important role in creativity
(De Bono, 1985; Runco & Chand, 1995; Treffinger, 1995).
For example, De Bono (1985)’s Six Thinking Hat includes
both Green Hat for creative thinking and Black Hat for
critical thinking. Similarly, Isaksen, Dorval, & Treffinger
(2011) emphasize the use of both creative and critical
thinking to solve a problem.
These previous studies imply both negative and positive
influences of critical thinking on creativity. On the one hand,

critical thinking can negatively influence performance
because it interferes with creative thinking and it facilitates
negative evaluation, which can cause productivity loss
(Diehl & Stroebe, 1987). On the other hand, critical thinking
can positively influence output because it involves analysis
and evaluation processes. However, little is known about
how to make good use of critical thinking while avoiding its
negative influences.
The work reported in the current paper examined how
critical thinking influences creative ideation in an
environment designed to curb its negative influences. To
avoid the negative influences of and capitalize on critical
thinking, we developed a web-based system for creative
ideation with two main features: crowdsourcing and
anonymity.
Crowdsourcing is a coined word, which combines “crowd”
and “outsourcing” (Howe, 2006). It is a mechanism where a
large number of people collectively collaborate through
information
communication
technologies.
Since
crowdsourcing makes people take a small part of task to
accomplish a large task collectively, each individual does
not have to think both creatively and critically. Thus, the
interference problem, which Osborn worried about, would
not occur. In a crowdsourcing environment, some people
carry out critical thinking, while other people carry out
creative thinking. In this way, we can avoid the negative
influence he suggested.
In addition, crowdsourcing is expected to increase the
chance to have diverse participants. Diversity is an
important factor for creative ideation (Fleming, 2004;
Nijstad, Stroebe, & Lodewijkx, 2002). Crowdsourcing has
been applied as a tool to collect creative ideas (Kittur et al.,
2013; Sakamoto & Bao, 2011).
The other feature we adopted is anonymity. In a typical
brainstorming procedure, participants are instructed not to
hesitate to generate unusual ideas and any ideas are
welcomed (Osborn, 1953). However, past studies showed
that some participants experienced the fear of negative
evaluation from other group members (Camacho & Paulus,
1995; Collaros & Anderson, 1969; Shepperd, 1993). This is

2344

called evaluation apprehension. For example, Collaros &
Anderson (1969) demonstrated that perceived expertise of
other members discouraged participants from generating
ideas.
One solution to mitigate the negative effect of evaluation
apprehension is to adopt anonymity. An anonymous
environment can reduce the threat of being negatively
evaluated by others (Michinov & Primois, 2005) and lead to
a greater ease in sharing one’s opinion and critical feedback,
relative to an non-anonymous environment (Jessup,
Connolly, & Galegher, 1990).
Considering crowdsourcing and anonymity, we conducted
a pilot experiment in a laboratory using an offline computer
and some designed excel spreadsheets as a substitute tool of
a system (Tanaka, Sakamoto, & Kusumi, 2011). The results
showed that the design in which critical thinking and
creative thinking were carried out collectively with
anonymity had a potential for creative ideation.
However, this study was conducted in a laboratory setting
with a limited sample of students from a university. The
task assignment process was not automated by computers
but instead was manual by the experimenter, inconsistently
with the spirit of crowdsourcing. In addition, there was a
problem with the reliability of the evaluation method that
required participants to evaluate a large number of ideas,
which also went against the norm of crowdsourcing.
To overcome these problems, we developed a web-based
system, in which people generated creative ideas and
criticized them collectively with anonymity. We also
changed the load of the evaluation task to be smaller than in
the pilot study, keeping in line with typical crowdsourcing.
We also measured the response time each participant spent
on producing an output as an indication of the fluency of
creative ideation.
In the current study, we used this system to examine how
critical thinking might influence creative ideation. The
hypothesis of this study is that critical thinking does not
give negative effects on creative ideation in an environment
that adopts crowdsourcing and anonymity. We measure the
effects of critical thinking in terms of the fluency of creative
ideation, defined by response time and the number of
characters, and the quality of idea, defined by novelty and
practicality.

Method
Participants
In total, 238 people (141 men, 97 women) participated in
this experiment through the Internet from different locations
across Japan, with the mean age of 23.7 (SD = 6.94). Each
participant received a gift card in the amount of 500
Japanese yen (about five USD).

System design
Based on the design of the pilot study that was conducted in
a laboratory (Tanaka et al., 2011), we developed a webbased system called CONSIDER: Crowdsourced ONline

System for IDEa Radiation. It consists of four different
subtasks; idea generation, critical thinking, idea
improvement, and idea evaluation. Through all the phases,
the system considers creative solutions for an ill-defined
social problem. As an example, in this experiment, the
following social problem was considered: “There is diverse
information on the Internet, including wrong information,
deceptive information, and information that has no evidence.
What can we do to avoid or reduce the negative influences
of misinformation on Internet users?”
All participants tried to complete their own task referring
to this social problem. This problem was always shown in
text on computer screen. Each participant was assigned to
one of the following crowds (phases).
Crowd 1 (Idea generation)
Crowd 1 took part in a phase to collect original seed ideas.
For each idea, a participant filled in the following three
blanks; “One way to avoid or reduce the negative influences
of misinformation on Internet users is to [blank 1]. An
example is to [blank 2]. The advantage of this is that [blank
3]”. Each participant was asked to generate three different
ideas. In total, 21 people participated in Crowd 1, resulting
in 63 seed ideas.
Crowd 2 (Critical thinking)
Crowd 2 participated in a phase to point out problem of idea
logically. Each participant was shown three different ideas
generated in Crowd 1, one by one, and asked to criticize
each idea by filling the following blank; “The problem of
this idea is that [blank]. Therefore, it is difficult to avoid or
reduce the negative influences of misinformation”. It was
important for this structure to emphasize, first, that
participants were not urged to criticize the person who
generated this idea, but to point out problem of the idea
itself. Second, participants were supposed to do so logically
because the blank was followed by “therefore”. This
structure was designed with the aim that participants refrain
from unessential criticisms such as nitpicking.
Crowd 3 (Idea improvement)
Crowd 3 completed a phase to modify and improve the
original seed ideas of Crowd 1 with the help of critical
thinking of Crowd 2. In this phase, each seed idea was
paired with its corresponding criticism. Three pairs of these
two ideas were shown, one at a time, to participants in this
phase. Each participant was asked to generate a new idea
from each pair by filling the identical blanks to those of
Crowd 1 and to repeat the same procedure three times with
three different pairs.
Crowd 4 (Idea evaluation)
One of the main differences of this system from the design
in the previous laboratory study (Tanaka et al., 2011) is the
evaluation phase. The previous study asked participants to
evaluate 179 ideas. This design likely made participants
tired, and, consequently, made the evaluation less reliable.
In the new system, as people take part in this phase through
the Internet from their convenient location at their
convenient time, unlike in a laboratory experiment,
participants could easily discontinue their task. With this

2345

risk in mind, we reduced the number of ideas to give each
participant from 179 in the previous study to 15.
Fifteen ideas were randomly selected from all the ideas
generated in Crowd 3, and shown to each participant one by
one. Each idea was evaluated in terms of novelty and
practicality by using 7-point scales ranging from 1 (Not at
all) to 7 (Highly). Novelty and practicality are common
measures for evaluating creativity (Gallupe & Dennis, 1992;
Sternberg, 2006; Thagard & Stewart, 2011; Ward, 2004).
To avoid the effect of individual differences in evaluation
tendency, and to make the evaluation values given by
different participants comparable, we used the following
idea as a reference for the evaluation: “Educate students so
that they develop an awareness that wrong information,
deceptive information, and information that does not based
on the fact exist on the Internet, the ability to check the truth
of such information, and the skill to judge and criticize
whether the information is useful for solving the problem at
hand.” Participants were instructed to evaluate each idea
supposing that this reference idea was moderately novel and
practical: the ratings of 4 for both novelty and practicality.

System requirements
The system was written in PHP and required every
participant to join through the Internet, ideally from a laptop
or a desktop computer instead of a mobile phone. The
system has been tested in Internet Explorer 10, FireFox, and
Chrome on Windows and Mac OS.

Experiment
To examine the effect of the system design that included the

critical thinking crowd for creative ideation (CT design), we
included a control design into the experiment. The control
design did not include the critical thinking crowds in Crowd
2. Instead, the task of Crowd 2 was replaced by idea
generation task, which was identical to Crowd 1. Further,
the task of Crowd 3 was to combine two randomly selected
ideas from Crowd 1 and 2. Since this task followed the
procedure of brainstorming, which recommends combining
several ideas into another idea (Osborn, 1953), we called
this the BS design. The CT design and the BS design share
Crowd 1 and Crowd 4. That is, both designs started from the
same seed ideas generated in Crowd 1, and ended with
evaluation by the same participants in Crowd 4. Figure 1
summarizes the experimental design. In Crowd 4, all the
ideas generated in Crowd 3 from both designs were mixed
and randomly shown to the participants so that they
evaluated each idea without knowing in which design the
idea was generated.
The dependent measures were two dimensions of
creativity: the fluency of ideation and the quality of idea.
Fluency is the productivity with respect to ideas. It is often
measured by counting the number of ideas in the previous
studies (Almeida, Prieto, Ferrando, Oliveira, & Ferrándiz,
2008). However, since the number of ideas that each
participant was asked to generate was fixed at three, we
used, instead, response time and the number of characters to
measure fluency in the current study. We assumed that the
fluency of ideation was high when an idea was generated in
a short period of time or in a large number of characters. For
quality, we used novelty and practicality values that were
evaluated by Crowd 4 as mentioned previously.

Figure 1. Experimental design

2346

Participants were assigned to one of the four crowds in
the order received their application, and then randomly
assigned to one of the two designs. We instructed all
participants to complete all the assigned tasks in 30 minutes.
In addition, the participants whose tasks were to generate
ideas were instructed to generate ideas that were as creative
as possible and that creativity would be evaluated with
respect to novelty and practicality.

Results
In Crowd 3, the CT design resulted in 141 ideas by 50
participants, and the BS design resulted in 171 ideas by 59
participants. The number of ideas differed because of the
assignment of participants. In both designs, each participant
was asked to generate three ideas, and, thus, the number of
ideas does not reflect fluency.
Considering the procedure in which participants were
asked to generate three ideas in 30 minutes, we excluded an
idea from analysis when its response time was over 30
minutes. We also excluded an idea whose response time was
less than one minute. After removal, 138 ideas in the CT
design and 159 ideas in the BS design remained for further
analyses.

Fluency of ideation
We measured the fluency of ideation in terms of response
time and the number of characters, and examined the
differences between the CT design and the BS design.
Response time was calculated by taking the difference in the
timestamps recorded by the system when participant was
shown a task to generate an idea and he/she submitted the
idea. In the case that a participant once submitted an idea,
came back later, and modified the idea, we used total
response time.
As an overall tendency, participants spent 9.21 (SD =
5.65) minutes to generate an idea. It was a reasonable
duration for completing the task to generate three ideas in
the given time limitation of 30 minutes. To examine the
difference between the two designs, we conducted a oneway analysis of variance (ANOVA) on response time. The
result showed no significant difference between the two
designs (Table 1).

To measure fluency, we also counted the number of
characters per idea in Japanese. The average number of
characters per idea was 174 (SD = 80.42). The result of a
one-way ANOVA showed no significant difference between
the two designs (Table 1).

Quality of idea
To examine the difference in the quality of idea generated in
Crowd 3 between the CT design and BS design, we
calculated novelty and practicality for each idea based on
the evaluation values in Crowd 4. As each idea was
evaluated by three or four participants, we used the average
rating as a representative value. Each idea had two quality
scores, novelty and practicality. We used these scores as
dependent measures to examine the difference in the quality
of idea between the CT design and BS design. Table 1
shows the means and standard deviations for novelty and
practicality as well as the response time and the number of
characters in each design.
We conducted a one-way ANOVA on novelty and
practicality. As for novelty, the result showed no significant
difference between the two designs. On the other hand, a
one-way ANOVA on practicality, F (1, 312) = 7.47, p < .01,
η2 = .02, demonstrated statistically significant difference
between the two groups. The practicality of ideas generated
in the CT design (M = 4.39, SD = 0.92) was higher than that
of the BS design (M = 4.04, SD = 1.23).

Discussion
The current study investigated whether or not criticism
interferes with creative ideation. We compared two designs;
the CT design, in which the seed ideas were criticized and
then a separate set of participants used the criticisms to
improve the seed ideas, allowing participants to be free from
the risk of being directly criticized, against the BS design,
which did not include the criticism phase. We measured the
fluency of ideation and the quality of idea as dependent
variables. We expected that if criticism disturbed creative
ideation, both the fluency of ideation and the quality of
ideas would be lower in the CT design than the BS design.

Table 1 Means, standard deviations, and ranges for the quality of idea, response time, and the number of characters
a

a

CT design (n =138 )
M
Fluency
- Response time (min)
- Number of characters
Quality of idea
- Novelty
- Practicality

b

SD

BS design (n = 159 )

Range

8.75

5.56

1.90-27.65

165.63

79.49

44-456

3.97

0.95

4.39

0.92

M

SD

Range

F

p

9.60

5.62

1.23-28.13

1.65

.200 **

181.26

80.77

46-545

2.81

.095 **

1.67-6.00

4.08

1.14

1.67-6.67

0.87

.353 **

2.00-7.00

4.04

1.23

1.33-7.00

7.47

.007**

Note. ** p < .01. a) n = the number of ideas generated in Crowd 3. b) Number of characters was counted in Japanese.

2347

On the other hand, if criticism did not disturb creative
ideation, we would find no statistical differences or an
opposite pattern of differences between the two designs.
First, we examined the differences in the fluency of
ideation. The results did not show any significant
differences in neither response time nor the number of
characters between the two designs. That is, the criticism
phase did not make creative ideation process takes longer or
the length of each idea shorter. Consequently, the results
showed that criticism had no negative influence on the
fluency of creative ideation.
Next, we examined the differences in the quality of idea
generated through the two designs. The result showed no
significant difference in novelty. This result implies that
including criticism phase into creative ideation process does
not have a negative influence on the novelty of ideas.
These results may seem contradictory to the Osborn’s rule
for brainstorming that asks for participants to withhold
criticism during sessions (Osborn, 1953). However, in the
current system, a single individual did not criticize and
create at the same time. These two tasks were completed by
separate crowds. Thus, the rule for refraining from criticism
did not apply to our system.
Considering the number of original seed ideas, the
novelty of ideas in the BS design should be higher because
the ideas of crowd 3 in the BS design originated from the
ideas generated from Crowd 1 and Crowd 2. That is, the BS
design had about twice as many seed ideas than the CT
design. Thus, the chance of having novel ideas should be
higher in the BS design than the CT design. In this sense, it
was unexpected that the CT design, with fewer ideas
generated, and resulted in ideas that were as novel as the BS
design. Accordingly, if the procedure is well designed for
people to think critically and creatively separately, criticism
could generate ideas as novel as brainstorming.
Our most noteworthy finding was that more practical
ideas were generated in the CT design, not in the BS design.
Considering that psychological models of creativity, which
assume that the process of finding problems plays an
important role in problems solving (Runco & Chand, 1995;
Treffinger, 1995; Treffinger, Selby, & Isaksen, 2008), it
makes sense why the CT design contributed to producing
highly practical ideas. It included the phase, which
concentrated on finding and pointing out the problems of
generated ideas, while the BS design did not have such a
phase. Each participant in Crowd 3 in the CT design was
given a seed idea and a corresponding criticism, and asked
to produce a new creative idea from them. Naturally, it
would be difficult for the participant to ignore the problem
that the criticism pointed out, and, thus, he/she was drove to
consider how to overcome the problem. This overcoming
process presumably made the ideas of Crowd 3 in the CT
design more practical.
It is also important to emphasize that the participants in
the CT design did not have to worry about being criticized
by others; the participants who generated seed ideas
completed their task when they submitted their ideas, they

did not see their ideas being criticized. Instead, the CT
design makes good use of the essence of criticism.
Consequently, the presence of the critical crowd resulted in
higher quality ideas at least with respect to practicality.

Limitation and future step
The current study is not the one that examines the difference
between an electronic method and a face-to-face method.
According to previous studies in brainstorming, where some
showed that the former would be better (Michinov &
Primois, 2005; Michinov, 2012), others cast doubt upon the
superiority of electronic brainstorming (Pinsonneault, Barki,
Gallupe, & Hoppen, 1999). Thus, it is unclear whether or
not the proposed CT design of CONSIDER works better
than a face-to-face brainstorming. One possible next step is
to compare the outputs between the current system and faceto-face brainstorming.

Concluding remarks
Worried about thinking critically and creatively at the same
time, the founder of brainstorming adopted the rule that
criticism must be withheld during a brainstorming session
(Osborn, 1953). However, more than a half-century later,
advances in technologies now allow us to join creative
ideation process collectively through a web-based system.
Relying on such a system, we proposed a critical thinking
design, in which some people take creative part and others
take critical part. The results showed that this design
resulted in more practical ideas than a brainstorming design,
which was in line with Osborn’s brainstorming rules. We
conclude that, in a well-designed environment, it is
promising to capitalize on the critical thinking of crowds for
creative ideation.

Acknowledgements
This research was supported by MEXT and
Transdisciplinary Research Integration Center of ROIS, and
partially by JSPS KAKENHI Grant Number 26780376. The
authors thank all researchers who helped conducting this
research and all participants. We also thank three
anonymous reviewers for their helpful comments and
suggestions.

References
Almeida, L. S., Prieto, L. P., Ferrando, M., Oliveira, E., &
Ferrándiz, C. (2008). Torrance Test of Creative
Thinking: The question of its construct validity.
Thinking Skills and Creativity, 3(1), 53–58.
doi:10.1016/j.tsc.2008.03.003
Camacho, L. M., & Paulus, P. B. (1995). The role of social
anxiousness in group brainstorming. Journal of
Personality and Social Psychology, 68(6), 1071–1080.
doi:10.1037/0022-3514.68.6.1071

2348

Collaros, P., & Anderson, L. (1969). Effect of perceived
expertness upon creativity of members of
brainstorming groups. Journal of Applied Psychology,
53, 159–163. doi:10.1037/h0027034

Exposure effects in an idea generation task. Journal of
Experimental Social Psychology, 38(6), 535–544.
doi:10.1016/S0022-1031(02)00500-0
Osborn, A. (1953). Applied Imagination (rev.ed.). New
York: Scribner’s.

De Bono, E. (1985). Six thinking hats. New York: Little,
Brown and Company.

Pinsonneault, A., Barki, H., Gallupe, R. B., & Hoppen, N.
(1999). Electronic brainstorming: The illusion of
productivity. Information Systems Research, 10(2),
110–133. doi:10.1287/isre.10.2.110

Diehl, M., & Stroebe, W. (1987). Productivity loss in
brainstorming groups: Toward the solution of a riddle.
Journal of Personality and Social Psychology, 53(3),
497–509. doi:10.1037/0022-3514.53.3.497

Runco, M. A., & Chand, I. (1995). Cognition and creativity.
Educational Psychology Review, 7(3), 243–267.
doi:10.1007/BF02213373

Fleming, L. (2004). Perfecting cross-pollination. Harvard
Business Review, 22–24. Retrieved from
http://elibrary.ru/item.asp?id=8441054

Sakamoto, Y., & Bao, J. (2011). Testing tournament
selection in creative problem solving using crowds. In
Thirty Second International Conference on
Information Systems (pp. 1–17).

Gallupe, R., & Dennis, A. (1992). Electronic brainstorming
and group size. Academy of Management Journal,
35(2), 350–369. doi:10.2307/256377
Howe, J. (2006). The rise of crowdsourcing. Wired
Magazine, (14), 1–5. Retrieved from
http://www.wired.com/wired/archive/14.06/crowds_pr
.html
Isaksen, S. G., Dorval, K. B., & Treffinger, D. J. (2011).
Creative approaches to problem solving: A
Framework for Innovation and Change. Thousand
Oaks, CA: Sage Publications, Inc.
Jessup, L., Connolly, T., & Galegher, J. (1990). The effects
of anonymity on GDSS group process with an ideagenerating task. Mis Quarterly, 14(3), 313–321.
doi:10.2307/248893
Kittur, A., Nickerson, J. V., Bernstein, M., Gerber, E., Shaw,
A., Zimmerman, J., … Horton, J. (2013). The future
of crowd work. In Proceedings of the 2013
Conference on Computer Supported Cooperative
Work (CSCW ’13) (pp. 1301–1318). New York, NY:
ACM Press. doi:10.1145/2441776.2441923
Michinov, N. (2012). Is electronic brainstorming or
brainwriting the best way to improve creative
performance in groups? An overlooked comparison of
two idea-generation techniques. Journal of Applied
Social Psychology, 42(S1), E222–E243.
doi:10.1111/j.1559-1816.2012.01024.x
Michinov, N., & Primois, C. (2005). Improving productivity
and creativity in online groups through social
comparison process: New evidence for asynchronous
electronic brainstorming. Computers in Human
Behavior, 21(1), 11–28.
doi:10.1016/j.chb.2004.02.004

Shepperd, J. (1993). Productivity loss in performance
groups: A motivation analysis. Psychological Bulletin,
113(1), 67–81. doi:10.1037/0033-2909.113.1.67
Sternberg, R. (2006). The Nature of Creativity. Creativity
Research Journal, 18(1), 87–98.
doi:10.1207/s15326934crj1801
Tanaka, Y., Sakamoto, Y., & Kusumi, T. (2011).
Conceptual combination versus critical combination  :
Devising creative solutions using the sequential
application of crowds. In Proceedings of the 33rd
Annual Conference of the Cognitive Science Society.
Boston, MA: Cognitive Science Society (pp. 3116–
3121). Boston, MA.
Thagard, P., & Stewart, T. C. (2011). The AHA!
experience: creativity through emergent binding in
neural networks. Cognitive Science, 35(1), 1–33.
doi:10.1111/j.1551-6709.2010.01142.x
Treffinger, D. J. (1995). Creative problem solving:
Overview and educational implications. Educational
Psychology Review, 7(3), 301–312.
doi:10.1007/BF02213375
Treffinger, D. J., Selby, E. C., & Isaksen, S. G. (2008).
Understanding individual problem-solving style: A
key to learning and applying creative problem solving.
Learning and Individual Differences, 18(4), 390–401.
doi:10.1016/j.lindif.2007.11.007
Ward, T. (2004). Cognition, creativity, and entrepreneurship.
Journal of Business Venturing, 19(2), 173–188.
doi:10.1016/S0883-9026(03)00005-3

Nijstad, B. A., Stroebe, W., & Lodewijkx, H. F. M. (2002).
Cognitive stimulation and interference in groups:

2349

