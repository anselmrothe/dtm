Some Probability Judgments may Rely on Complexity Assessments
Antoine Saillenfest (antoine.saillenfest@telecom-paristech.fr)
Jean-Louis Dessalles (jean-louis.dessalles@telecom-paristech.fr)
Telecom ParisTech, 46 rue Barrault,
F-75013 Paris, France
solve these issues, but to show that complexity should not be
ruled out as a candidate to account for uncertainty
judgments, and that contrary to a common opinion, it is
cognitively plausible, perhaps no less than probability itself.
We will first consider the notion of complexity and show
how it can be turned into a cognitive notion. Then we will
see how notions like condition, independence and subjective
probability are reformulated in the framework of Simplicity
Theory. We will use an example, a story of plagiarism, to
show that individuals are sensitive to complexity. Lastly, a
small experiment based on this example will be presented.
Its purpose is to test some predictions of the theory.

Abstract
Human beings do assess probabilities. Their judgments are
however sometimes at odds with probability theory. One
possibility is that human cognition is imperfect or flawed in the
probability domain, showing biases and errors. Another
possibility, that we explore here, is that human probability
judgments do not rely on a weak version of probability
calculus, but rather on complexity computations. This
hypothesis is worth exploring, not only because it predicts some
of the probability ‘biases’, but also because it explains human
judgments of uncertainty in cases where probability calculus
cannot be applied. We designed such a case in which the use of
complexity when judging uncertainty is almost transparent.
Keywords: Probability, Kolmogorov complexity, simplicity,
unexpectedness.

Cognitive Complexity

Introduction
Human beings have a natural intuition of ‘probability’. They
use it, not only to anticipate risks, but much more often
when they get the point of narratives based on unexpected
events (Dessalles, 2008a). For instance, people are very
good at noticing all factors that control unexpectedness in
coincidences (Griffiths & Tenenbaum, 2001 ; Dessalles,
2008b) and in near-miss experiences (Teigen, 2005;
Dessalles, 2010). Even if unexpectedness does not always
match the presence of low probability (Teigen & Keren,
2003; Maguire & Maguire, 2009), the two notions are
strongly linked, in a way that will be explored here.
This definite and consistent ability to assess probability
appears quite mysterious in the light of the many apparent
‘biases’ that have been revealed in the past decades. For
instance, people wrongly assign low probability to nonrepresentative sequences of similar events (Kahneman &
Tversky, 1972; Tenenbaum & Griffiths, 2001). Let’s
mention some other errors of judgments: the gambler’s
fallacy (Terrell, 1994), the base-rate fallacy (Bar-Hillel,
1980), the conjunction fallacy (Tversky & Kahneman,
1983) or the simplicity bias in causal explanations
(Lombrozo, 2007). What kind of computation can be so
wrong that it fails on basic tests and yet is so precise when it
comes to judging uncertainty for everyday purposes?
This issue, quite surprisingly, has not been considered a
priority. In many psychology experiments, for instance in
decision theory, probabilities are provided as input to
participants, with the tacit hypothesis that they are able to
process them directly. Could it be that judgments of
uncertainty are spontaneously achieved through a
fundamentally different form of computation? Could it be
that probability is no more than a mathematical notion with
no cognitive counterpart? The purpose of this paper is not to

The mathematical notion of complexity, known as
Kolmogorov complexity, emerged in the last fifty years to
deal with issues such as randomness, induction in learning
and computability. The complexity of a situation is the size of
its shortest summary. Or, in other words, its size when it has
been maximally compressed. This definition can be made
formal by coding situations as binary strings and by finding
computer programs that generate them. The complexity C(s)
of s is the length of the shortest program that outputs s.
The transposition to cognitive science seems straightforward
(Chater, 1999). It is indeed known since Gestalt Theory that
human individuals are sensitive to simplicity. The use of
complexity in cognitive science has however been hindered by
an obvious objection: it is not computable. It is easy to prove
that no program can output C(s) when s is given as input. Ideal
compression is well-defined, but cannot be computed. This
observation led to the conclusion that human minds have no
access to complexity. Some authors decided to abandon it
altogether in favour of statistical inference (Griffiths &
Tenenbaum, 2003), while others attempted to consider
computable alternative measures of complexity, such as pattern
complexity or Boolean complexity (Simon, 1972; Feldman,
2004). We just need, however, to consider a bounded-resource
version of complexity (Chater, 1999). Human beings do have
computational power that allows them to detect, for instance,
pattern repetition. They are therefore able to perform some
compression on perceived situations. For instance, anyone who
knows about numbers can detect a pattern in the series
122333444455555, namely “n repeated n times”, which leads
to significant compression.1 More generally, any detection of
Using concatenation, the series can be written nn, n < 5. This
is much more compact than the independent specification of 15
numbers: two instructions (loop and repeat) and an upper limit on
the one hand, 15log2(10) = 50 bits on the other hand. If we spare
three bits to designate each instruction in the number sequence

2069

1

structure achieves a compression. Let’s call Ci,t(s) the size of
the best compression that an individual i has been able to
produce within time t. This notion is, by definition, computable
as soon as a computable cognitive model is available. In what
follows, C(s) will be used to designate Ci,t(s). In this sense, C(s)
is computable.

Note that this definition of generation complexity provides a
simple notion of independence. Two situations s1 and s2 are
independent iff Cw(s1&s2) = Cw(s1) + Cw(s2).
ST defines unexpectedness U(s) as the difference between
generation and description complexity.

Description vs. Generation

This definition is congruent with Teigen and Keren’s
observation that surprise corresponds to contrasts between
actual outcomes and expectations (Teigen & Keren, 2003;
Saillenfest & Dessalles, 2014). Here, expectations correspond
to Cw(s) and outcomes to C(s). The above definition of
unexpectedness aims at capturing exactly what people regard
as surprising, as unlikely, as ‘improbable’ (in the naïve
sense). The correspondence with probability is explored now.

Links between complexity and probability have been
noticed from the outset (Solomonoff, 1964). The basic idea
is that simpler patterns are more probable. Algorithmic
Information Theory (AIT) offers several definitions of
algorithmic probability, including p(s) = 2C(s), which
amounts to converting each complexity bit into the flip of a
fair coin.2 This definition matches the subjective uncertainty
attached to explanatory scenarios: complicated explanations
involving many choice points are perceived as less likely.
This definition cannot be the answer, however, as
subjective probability sometimes functions the other way
around. Lottery draws such as 1-2-3-4-5-6 or 5-10-15-2025-30 are intuitively felt as much more improbable than 1719-24-35-38-43, not because the former are more complex,
but on the contrary because they are less complex
(Dessalles, 2006; Maguire et al., 2013). AIT accounts for
this effect by introducing a new notion, randomness
deficiency (Li & Vitányi, 1994). Within the framework of
Simplicity Theory (ST), randomness deficiency is a special
case of complexity drop (Dessalles, 2008a).
Why is improbability sometimes attached to complexity
(as for causal explanation) and sometimes to simplicity (as
for lottery draws)? According to ST, unexpectedness does
not correspond to one measure of complexity, but to the
difference between two measures of complexity: generation
complexity and description complexity. The latter matches
the usual definition of C(s). Note that each individual is
regarded as a different computing ‘machine’: if a lottery
draw matches an individual’s telephone number, it will be
very simple for her, but not for other people.
Generation complexity, on the other hand, is defined as
the simplest causal scenario that the individual can figure
out to explain a situation. In a lottery, all numbers are
believed to be generated by equally complex causal
processes. Generation complexity Cw(s) can be measured by
the number of choice points and the number of options in
the minimal scenario that generates s. For instance, most
individuals consider that the presence of a famous actor in
their kitchen would require a complex causal scenario.3
context, the first code would need only 23+log2(5) < 9 bits.
2
This definition is sometimes regarded as problematic. If we code
situations s as numbers ns, then for most situations, C(s)  log2(ns),
and p(s) =  instead of 1. This problem is avoided, either by
considering prefix-free codes, or by regarding numbers like 297 and
2971 as non exclusive (as the latter contains the former).
3
See www.simplicitytheory.org for further details. The site
answers some frequently asked questions about ST, including why
a situation that is the most complex in its class turns out to be
simple for that reason; or the converse: why a standard object, like

U(s) = Cw(s)  C(s).

(1)

Simplicity Theory and Probability ‘Biases’
The main hypothesis explored in this paper is that human
beings, in many judgments about uncertainty, rely on
unexpectedness rather that on probability. Let’s consider the
above mentioned ‘fallacies’ in turn to see if they are
compatible with this hypothesis.
In the gambler’s fallacy (Terrell, 1994), people are reluctant
to bet on recently drawn numbers. This behavior is deviant in
the eyes of Probability Theory (PT). Why would a memoryless lottery avoid recent numbers? If 571 was drawn four
weeks ago in a weekly lottery, people behave as if they
considered the probability that 571 be drawn, not twice at a
four week distance, but twice within a four week interval. PT
explains neither the phenomenon nor the ‘within’ hypothesis
required to account for its fading with time. According to ST,
gamblers bet on the least unexpected outcome. If 571 was
recently drawn, it is much simpler to describe than log2(1000) 
10, which is the number of bits required to distinguish among
the 1000 options in the lottery studied by Terrell. The simplest
description of 571 now amounts to 2 bits, as it consists in giving its rank in the list of past winning numbers. The gambler’s
fallacy results from a decrease in C(s), while Cw(s) remains
constant. This makes recent winning numbers too unexpected
to be bet on. The effect lasts as long as the complexity of
locating 571 in the winning list remains small enough.
As observed by H. Simon (1972), simplicity accounts for
biases of representativeness as well. People would consider
a series of eight births like GGGGBBBB, where four girls
and then four boys are born in the family, as less ‘probable’
than a more complex pattern like GGBGBBGB. Here also,
Cw(s) is kept constant while C(s) varies. The effect is a
mystery for PT, but it is again predicted by ST if we
suppose that individuals are sensitive to unexpectedness. As
(1) shows, simple structures make U(s) larger, hence the
feeling of improbability. This simplicity effect can be
quantified and matches experimental results (Simon, 1972).
For the same reason, remarkable lottery draws like 1-2-3-45-6 are regarded as virtually impossible by most people
a common window, turns out to be complex, as it requires a
lengthy description to be distinguished from all other windows.

2070

(Dessalles, 2006). Note that contrary to PT, ST does not
invoke here any ad hoc notion such as representativeness.
In the conjunction fallacy (Tversky & Kahneman, 1983),
people find it less probable that Paul, a former Green
activist, would drive a big SUV rather than if he drived a
big SUV functioning with LPG (SUV are known to waste
more energy than standard cars and LPG is known to be less
polluting than gasoline). Within the set-theoretic framework
of PT, this seems absurd, as the set of SUV drivers includes
the set of LPG-SUV drivers. How does ST account for this
phenomenon? By noticing that the causal generation of the
SUV case is more complex than for the LPG-SUV case.
The two situations: Paul driving a SUV (s1) and Paul
driving a LPG-SUV (s2), differ both by their description and
their generation. Assuming that Paul is already in the
context, situation s1 can be described using the concept of
green activist (G) and the concept of SUV (f1).

distributions. (2) shows that the phenomenon can be
parsimoniously analyzed in terms of complexity
exclusively. The detour through probability is unnecessary.
If individuals judge uncertainty based on complexity
rather than on probability, several other ‘fallacies’ are no
longer problematic. Simplicity bias in causal explanations
(Lombrozo, 2007) and base-rate neglect (Bar-Hillel, 1980)
rely on experiments in which probabilities are provided as
numbers (percentages) to participants. While educated
individuals may be able to translate unexpectedness into
probability estimates, it is a too strong assumption to
suppose that the converse might be true.

C(s1) = C(G) + C(f1|G).

p(s) = 2U(s).

The vertical bar in C(a|b) denotes conditionality. It means
that b is available to describe a. For instance, C(a|a) = 0. s2
requires an additional feature f2 = ‘LPG’ to be described.

Formula (3) explains why a simple sequence like 1-2-3-45-6 is felt as much more improbable than a complex one
like 17-19-24-35-38-43. It also explains why events that are
rare, unique or extreme according to a simple criterion are
perceived as improbable when they occur; it explains why
rare events (like a fire) are regarded as less probable when
they occur in the vicinity; it explains recency effects in the
news; it also explains why coincidences are exaggeratedly
perceived
as
improbable
(Falk,
1983)
(see
simplicitytheory.org for a review). In all these examples,
probability judgments are performed ex-post, after the fact.
In all the above mentioned classical studies on probability
bias, individuals were asked whether a situation was more
‘probable’ than another. This corresponds to an ex-ante
judgment. Ideally, from the ex-ante perspective, s is already
determined: C(s) = 0, and ex-ante unexpectedness is Ua(s) =
Cw(s). The central thesis of this paper is that people translate
the word ‘probable’ by considering both Ua(s) and U(s). In
our lottery examples, Ua(s) is constant and only U(s) varies.
In the SUV example, Ua(s) and U(s) vary in the same
direction. But only for a relevant feature like LPG.
ST predicts that individuals’ behavior will be different if
f2 is a neutral feature such as ‘the SUV was red’. Suppose
there are 16 possible SUV colors. One needs C(f2|f1) = 4 bits
to designate the actual color. On the generation side, 4
additional bits are also required in a causal scenario to orient
the choice among the 16 colors: Cw(s2) = Cw(s1) + 4. We get:
U(s2) = U(s1), and s2 will be judged no more unexpected
than s1. In a narrative like: “Remember Paul, the former
Green activist?”, the two mentions “I saw him driving a big
SUV” and “I saw him driving a big red SUV” offer exactly
the same unexpectedness. The detail about the color is
irrelevant,7 if relevance is defined as: ‘contributing to

C(s2) = C(G) + C(f1|G) + C(f2|G, f1).
(we ignored other features, such as ‘drive’, that are
common to s1 and s2). Here, concepts4 are prototypical
situations evoked by words. Considering prototypes instead
of sets is presented as a human flaw by Tversky and
Kahneman (1983). But the hypothesis that words be
associated with sets rather than prototypes is a constraint
imposed by PT and has little cognitive support.5
If we abandon PT’s extensional constraint, we can compute
how s1 and s2 differ on the generation side. s1 evokes a typical
situation, i.e. a gasoline SUV. Since LPG is supposed to be
more Green-friendly than standard gasoline, the contradiction
with Paul’s past as Green activist is less flagrant in s2 than in
s1. This means that the minimal causal scenario explaining s2
is less complex than the minimal causal scenario leading to s1.
In other words: Cw(s2) < Cw(s1). We get:
U(s1)  U(s2) = Cw(s1)  Cw(s2) + C(f2|G, f1) > 0.

(2)

ST correctly predicts that s1 will appear more unexpected,
and therefore less probable, than s2. This prediction matches
the so-called ‘conjunction fallacy’. Note that this account,
derived from ST, is not unrelated to Maguire et al.’s (2013)
explanation. These authors introduce different ‘models’,
which correspond to the causal scenarios underlying Cw(s1)
and Cw(s2). Though adopting a complexity-based approach,
their description is expressed in terms of probability
For any concept x, C(x) can be approximated as C(x)  log2(r),
where r is the rank of a word expressing x in a list of words sorted
by frequency of occurrence in a corpus. Assuming Zipf’s law, r
can also be the frequency itself, or the relative number of hits on a
Web search engine (Cilibrasi & Vitányi, 2007). A specific corpus
can be used to refine estimates for given individuals.
5
The set of all SUVs is a mathematical abstraction which is not
computable, either objectively or cognitively.
4

Unexpectedness and Subjective Probability
ST has been developed to account for the human ability to
assess the unexpectedness of events after they have
occurred. Ex post probability6 is defined as:
(3)

6
Technically, ex-post probability p(s) as defined by (3)
corresponds to Prob(happens(s) | s). It is not itself a probability
measure: the sum of p(si) for different events si may exceed 1.
7
Unless it is used to emphasize that the story is true.

2071

unexpectedness’ (Dessalles, 2013). However, Ua(s2) is
larger than Ua(s1) by 4 bits. This may lead most people to
regard ‘red-SUV’ as less probable than mere ‘SUV’, thus
respecting the conjunction axiom this time. Note that PT is
unable to take the relevance of the feature into account.

The Plagiarism Story
To make the case of complexity even stronger, we searched
for a situation in which individuals make a definite
judgment of uncertainty that cannot be explained by
probability calculus. Consider the following story.
Story 1: Ms S. is accusing Mr D. of having stolen her manuscript
and of having published it under his name. Fortunately, she hid
her name in the book. Her name is (option n1: Sami); (option n2:
Schildget). It can be retrieved by taking (option r1: the first letter
of each chapter); (option r2: the first or the second letter of each
chapter, depending on the chapter’s parity).

We could not find anyone, in informal inquiries among
students, who chose options other than n2 and r1 when asked
to maximize Ms S.’s chances to win her case. Why do the
more complex name and the simpler retrieving algorithm
make plagiarism so obviously more likely in this story?
PT would merely predict that a shorter name is more
likely to ‘occur’ by chance in the book, without any
precision about what ‘occur’ means. It is unable to account
for the role of the algorithm used to retrieve the name.
ST’s explanation is straightforward: plagiarism is
probable if the co-occurrence by chance of Ms S.’s name
(N) and Mr D.’s book (B) is highly unexpected, i.e. if
U(N & B) is large. ‘By chance’ here means that N and B are
supposed to be independent. By definition of independence,
Cw(N & B) = Cw(N) + Cw(B). On the description side,
C(N & B) < C(B) + C(N|B). The algorithm A provided by
Ms S. to retrieve her name in the book gives an upper bound
of C(N|B): C(N|B) < C(A). If we assume that neither B nor N
is unexpected by itself, we get by applying (1):
U(N & B) > C(N)  C(A).

Can we predict how parameters S, S1, S2, p1, p2 and the two
options influence plagiarism probability? PT has something
to say about this. It will predict that the probability of T1
appearing in B2 by chance would decrease with S and increase
with S1 and S2. But in the absence of any specific knowledge
about the borrowing mechanism, it would assume uniform
probability for p1 and p2, and their value would be irrelevant.
Comparing options 1 and 2 would be somewhat tedious. One
would need to imagine all ways of splitting T1 into several
pieces to determine the probability that T1 would end up in
three, instead of one, two or more than three pieces.
In the ST framework, plagiarism is blatant when the
coincidence between the content of B1 and of B2 is too
unexpected. There is coincidence if these contents are
supposed to be independent:
Cw(B1&B2) = Cw(B1) + Cw(B2).
On the description side:
C(B1&B2) < C(B1) + C(B2|B1).

(6)

Following (1), the unexpectedness of the coincidence,
U(B1&B2), corresponds to the complexity drop between
generation (5) and description (6). Assuming that neither B1
nor B2, as sequence of words, is unexpected by itself8
(Cw(Bi) = C(Bi)), we get:
U(B1&B2) > C(B2)  C(B2|B1).

(7)

The right-hand side of (7) is the compression of B2 allowed
by the knowledge of B1. This compression is due to the
resemblance between T1 and T2. Ideally, C(T2) could be
spared in the description of B2. There is a tax to pay, however,
which is the complexity of the procedure needed to get T2
from B1. To compute a lower bound of the compression, we
may compute the complexity of the following procedure:
locate T1 in B1; use algorithm A to transform T1 into T2;
determine target location in B2; insert T2. From (7), we get:
U(B1&B2) > C(T2)  (C(l1) + C(A) + C(l2)).

(4)

ST thus explains why a complex (i.e. long) name and a
simple algorithm make plagiarism more probable in story 1.
The complexity of the retrieving algorithm, A, is directly
understood to play a crucial role. A probability-based model
could not account for this effect without many ad hoc
assumptions. It is more parsimonious to consider that
individuals have direct access to complexity assessments.
We designed a small experiment as a first attempt to
explore the Plagiarism story in more details and try to test
finer grain phenomena. This time, we introduce new variables, such as the size of the book. Here is the second story.

(5)

(8)

l1 and l2 designate the precise locations of T1 and T2 in B1
and B2. If there are about n words in a page, then:
U(B1&B2) > C(T2)  (C(p1) + C(A) + C(p2) + 2 log2(n)). (9)
In option 1, if texts are strictly identical, then A1 is a mere
copy and C(A1) = 0. In option 2, C(A2) has a definite value, as
it requires at least four numbers: two cut points in T1 to make
the three pieces, and the size of two gaps to specify how to
insert the pieces in the target text. To make things concrete,
we may say that C(A2) ~ 4 log2(n). Formula (9) allows us to
draw the following predictions. Plagiarism is more likely if:
[1] T2 is a long excerpt, making C(T2) large
[2] A is simple
[3] Sizes Si are small, as C(pi) < log2(Si), while n is not too
large.

Story 2: Ms Schmidt is accusing Mr Durand of having

plagiarized in his book B2 a passage T2 of size S that is almost
identical to a passage T1 from her book B1. The sizes of the two
books are S1 and S2. T1 is located at page p1 of B1 and T2 at
page p2 in B2. T2 is found in one piece (option 1) / in three
pieces distributed over three paragraphs in p2 (option 2).

8
One way to be unexpected in this way would be to be more
compressible than exepected, as Georges Perec’s Grand palindrome.

2072

Figure 1: Answers for each alternative of the 6 propositions in Story 2
[4] pi is small (while n is not too large), as in this case
C(pi) ~ log2(pi) < log2(Si).
If B1 is not known in advance, C(B1) is augmented by the
determination of Ms Schmidt and by the determination of B1
in her works. We could then add the two following
predictions:
[5] Ms Schmidt is a famous author
[6] She has written few books.
Note that prediction [1] has a massive effect, as compared
with predictions [2]-[4]. Each word in T2 contributes by
log2(N) bits to unexpectedness, where N is the size of the
lexicon (if one compares text creation to a uniform lottery
among words). In comparison, [4] may spare 6 bits only if
p1 = 3 and S1 = 250. The following small experiment is an
attempt to put predictions [1]-[4] to the test.

Experiment
Participants were presented Story 2 (in French) with the
following options:
o Ms Schmidt’s book is a 154/654 -page book.
o Mr Durand’s novel is a 162/443 -page book.
o The passage mentioned by Ms Schmidt is located page
number 3/43 in her collection of short stories.
o The passage mentioned by Ms Schmidt is 9/19 lines long.
o The passage mentioned by Ms Schmidt can be found in
one part / spread over 3 paragraphs in Mr Durand’s novel.
o The passage mentioned by Ms Schmidt can be located
page number 5 / 122 in Mr Durand’s novel book.
A total of 352 individuals (aged from 16 to 63, mean 28.64
(std. dev. 6.66), 276 females, 91 males, 15 unknown gender)
participated to the test online. Participants were recruited via
social networks and billposting. We manually checked the
answer files for individuals who provided incomplete results
or whose response time was less than 30 seconds.

Results and discussion
Percentages of answers for each alternative proposed are
presented in Figure 1. We tested for significance using

binomial tests. Results indicate a significant effect (p <
0.05) for the number of pages of the books, the size of the
passage, its location in Mr Durand’s book and the
complexity of the algorithm that leads from one text to
another. The location of the passage in Ms Schmidt’s book
did not lead to a significant effect (p  0.11). These results
agree with our predictions [1], [2], [3] and [4]. Note that a
probabilistic model would predict [1] and [3], perhaps [2],
but not [4].
The non-significant result for the localization in Ms
Schmidt’s book is due in part to its small expected
contribution in comparison with [1]. Moreover, an informal
inquiry among additional participants suggests that some
individuals may have performed second-order reasoning:
borrowing a passage from Ms Schmidt’s first pages would
be too conspicuous and would make plagiarism not rational
and therefore less likely. Due to its design that did not
anticipate this reaction, Story 2 turns out to be less
convincing than Story 1.
In further work, we plan to test predictions [5] and [6], as
the contribution is larger (~ log2(A) where A is the number
of authors), and also because probability calculus would not
naturally take the author’s celebrity into account.

Conclusion
The first aim of this paper is to question the human ability to
process probability as such. Despite the existence of
numerous human ‘biases’, the fact that uncertainty
judgments rely on some form of probability calculus is often
taken for granted without questioning its cognitive
plausibility.
Our second aim is to put forward the possibility that
complexity can be directly assessed by individuals.
Complexity has not been sufficiently considered as a good
candidate to explain judgments of uncertainty, due to
prejudices
concerning
its
non-computability,
to
misconceptions about how it should be computed (see
note 3), and to the (wrong) belief that probability itself is
always computable (see note 5). Notions which are quite
intricate when expressed in probabilistic terms are more

2073

intuitively defined in terms of complexity: independence
and causal indeterminism are captured by generation
complexity; conditionality and simplicity come naturally
with description complexity.
We hypothesized that unexpectedness, as defined in
Simplicity Theory as the difference between generation and
description complexity, is used by individuals to judge
about uncertainty. This hypothesis has two advantages. (1)
It offers new and parsimonious accounts of the various
cognitive ‘biases’; (2) It accounts for situations in which
probability theory would be partially silent. We designed
two versions of the Plagiarism story to make up cases in
which judgments of uncertainty seem to rely on complexity
rather than on probability.
Simplicity Theory has been designed in an unrelated
context: to account for interest and relevance in narratives
(Dessalles, 2008; Saillenfest & Dessalles, 2014). Quite
remarkably, as we showed here, it can be successfully
applied with no modification to judgments of uncertainty.
No ad hoc hypotheses, such as recency avoidance,
representativeness or randomness deficiency, have been
introduced. This invites us to consider complexity as a
plausible dimension of cognitive processing.

Acknowledments
This study is supported by grants from the programme
Futur&Ruptures and from the “Chaire Modélisation des
Imaginaires, Innovation et Création”.

References
Bar-Hillel, M. (1980). The base-rate fallacy in probability
judgments. Acta Psychologica, 44 (3), 211-233.
Chater, N. (1999). The search for simplicity: A fundamental
cognitive principle? The Quarterly Journal of
Experimental Psychology, 52, 273-302.
Cilibrasi, R. & Vitányi, P. (2007). The Google similarity
distance. IEEE Transactions on Knowledge and Data
Engineering, 19 (3), 370-383.
Dessalles, J-L. (2006). A structural model of intuitive
probability. In D. Fum, F. Del Missier & A. Stocco
(Eds.), seventh International Conf. on Cognitive
Modeling, 86-91. Trieste, IT: Edizioni Goliardiche.
Dessalles, J-L. (2008a). La pertinence et ses origines
cognitives. Paris: Hermes-Science Publications.
Dessalles, J-L. (2008b). Coincidences and the encounter
problem. In B. C. Love, K. McRae & V. M. Sloutsky
(Eds.), 30th Annual Conf. of the Cognitive Science Soc.,
2134-2139. Austin, TX: Cognitive Science Soc.
Dessalles, J-L. (2010). Emotion in good luck and bad luck:
predictions from simplicity theory. In S. Ohlsson & R.
Catrambone (Eds.), 32nd Annual Conf. of the Cognitive
Science Soc., 1928-1933. Austin, TX.
Dessalles, J-L. (2013). Algorithmic simplicity and
relevance. In D. L. Dowe (Ed.), Algorithmic probability
and friends - LNAI 7070, 119-130. Berlin, D: Springer
Verlag.

Falk, R. & Macgregor, D. (1983). The surprisingness of
coincidences. In O. Svenson & A. Vári (Eds.), Analysing
and aiding decision processes, 489-502. Budapest:
Adadémiai Kiadó.
Feldman, J. (2004). How surprising is a simple pattern?
Quantifying 'Eureka! Cognition, 93, 199-224.
Griffiths, T. L. & Tenenbaum, J. B. (2001). Randomness
and coincidences: Reconciling intuition and probability
theory. In J. D. Moore & K. Stenning (Eds.), 23rd annual
Conf. of the Cognitive Science Soc., 370-375. Edinburgh.
Griffiths, T. L. & Tenenbaum, J. B. (2003). Probability,
algorithmic complexity, and subjective randomness. In R.
Alterman & D. Kirsh (Eds.), 25th annual Conf. of the
Cognitive Science Soc., 480-485. L.E.A.
Kahneman, D. & Tversky, A. (1972). Subjective
probability: A judgement of representativeness. Cognitive
Psychology, 3, 430-454.
Li, M. & Vitányi, P. (1994). Statistical properties of finite
sequences with high Kolmogorov complexity.
Mathematical Systems Theory, 27, 365-376.
Lombrozo, T. (2007). Simplicity and probability in causal
explanation. Cognitive Psychology, 55, 232-257.
Maguire, P. & Maguire, R. (2009). Investigating the
difference between surprise and probability judgements.
In N. A. Taatgen & H. van Rijn (Eds.), 31st Annual Conf.
of the Cognitive Science Soc. Amsterdam.
Maguire, P., Moser, P., Maguire, R. & Keane, M. T. (2013).
A computational theory of subjective probability. In M.
Knauff, M. Pauen & N. Sebanz (Eds.), 35th Annual Conf.
of the Cognitive Science Soc., 960-965. Austin, TX.
Simon, H. A. (1972). Complexity and the representation of
patterned sequences of symbols. Psychological Review,
79 (5), 369-382.
Solomonoff, R. J. (1964). A Formal Theory of Inductive
Inference. Information and Control, 7 (1), 1-22.
Saillenfest, A. & Dessalles, J-L. (2014). Can Believable
Characters Act Unexpectedly?. Literary & Linguistic
Computing, 29 (4), 606-620.
Teigen, K. H. (2005). When a small difference makes a big
difference - Counterfactual thinking and luck. In D. R.
Mandel, D. J. Hilton & P. Catellani (Eds.), The
psychology of counterfactual thinking, 129-146. Oxon,
UK: Routledge.
Teigen, K. H. & Keren, G. (2003). Surprises: low
probabilities or high contrasts? Cognition, 87, 55-71.
Tenenbaum, J. B. & Griffiths, T. L. (2001). The rational
basis of representativeness. In J. D. Moore & K. Stenning
(Eds.), 23rd annual Conf. of the Cognitive Science Soc.,
1036-1041. Edinburgh.
Terrell, D. (1994). A test of the gambler's fallacy: Evidence
from pari-mutuel games. Journal of risk and uncertainty,
8 (3), 309 - 317.
Tversky, A. & Kahneman, D. (1983). Extensional versus
intuitive reasoning: The conjunction fallacy in probability
judgment. Psychological Review, 90 (4), 293-315.

2074

