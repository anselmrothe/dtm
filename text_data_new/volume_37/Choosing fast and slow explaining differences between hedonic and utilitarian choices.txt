Choosing fast and slow: explaining differences between hedonic and utilitarian
choices
Nisheeth Srivastava (nsrivastava@ucsd.edu), Edward Vul (evul@ucsd.edu)
Department of Psychology, UC San Diego
La Jolla, CA 92093 USA
Abstract
This paper examines the psychological differences between
hedonic and utilitarian patterns of preference behavior. Instead of using latent variables like self-control and emotion
to explain these differences, we show that they emerge as natural consequences of solving two different, but related problems within an inductive framework of preference learning.
We show that hedonic decisions involve tracking the variability of a binary variable, whereas utilitarian decisions require
the maintenance of a distribution over a vector of object labels.
Computational experiments show that this difference in cognitive representation ensures that hedonic decisions have a lower
cognitive sampling cost, which makes them less effortful. Further experiments reveal differences in error rates as a function
of deliberative effort between the two paradigms. Deliberative
effort benefits utilitarian choices, but not hedonic ones. Overall, our work demonstrates the critical role of cognitive representations in extracting strikingly different behavior patterns
from simple models of information processing.
Keywords: consumer choice; preference formation; cognitive
modeling; agent-based modeling

Introduction
Consumer research has identified separate patterns of consumption for items that people ostensibly judge useful and
those that they consider pleasurable. For instance, buying a bar of soap can be considered a utilitarian choice,
whereas buying an oil painting would be considered a hedonic choice (Alba & Williams, 2013). Naturally, such labeling
is not rigorous: it is perfectly possible for the purchase of an
expensive brand of soap to be a hedonic decision, whereas
the bulk purchase of oil paintings for an interior decoration
company would be a utilitarian decision. Despite the lack
of a clear delineation between hedonic and utilitarian goods,
the psychological difference between hedonic and utilitarian
modes of purchase and consumption is intuitive.
The distinction between hedonic and utilitarian decisions
has been of considerable practical interest in the field of marketing, and has motivated theoretical and empirical scrutiny
by psychologists. In psychology, this distinction has been attributed to two “systems” of choice: the implicit System 1
that automatically and instinctually makes quick decisions,
and the explicit System 2 that slowly, but deliberatively arrives at a more thoughtful answer. The psychological distinction between hedonic (System 1) and utilitarian (System
2) has been characterized primarily by two empirical distinctions. First, hedonic decisions are easier to make while utilitarian decisions are more effortful and deliberate. Second,
hedonic judgments tend to be more error-prone than utilitarian ones (Kahneman, 2011). Although a view of two systems
with these decision properties is appealing, such an account

does not offer a formal characterization of how prior experience is used to inform either kind of decision, nor does it offer
a predictive account of which situations will encourage one
or another system, and what judgments those systems might
prefer in consumer decisions.
In contrast to psychology, marketing research has been less
concerned with characterizing the difference between hedonic and utilitarian decisions, but rather with encouraging hedonic consumption. The general substance of this research
is that, because short-term pleasure is the appeal of a hedonic product, those aspects of a choice that increase the influence of emotions or urges on decision making and decrease
self-control will increase hedonic behavior (Keinan & Kivetz,
2008). However, this view remains underspecified: What is
self-control, why does it apply to hedonic decisions and utilitarian decisions differently, and how can emotions and urges
be operationalized meaningfully in formal treatments?
Our general goal in this paper is to develop a formal account of what it means to make hedonic and utilitarian decisions that can explain how the same same set of prior experiences can yield such discrepant patterns of behavior and
preference when subject to different decision rules.

Our contribution
We adapt a recently developed a computational account of
preference formation (Srivastava & Schrater, 2012). By augmenting this computation with simple algorithmic specifications we clarify the difference between hedonic and utilitarian preferences while simultaneously explaining many effects
described in consumer research and social psychology.
Our primary contribution is the demonstration that hedonic
decisions require agents to make stochastic decisions about a
binary variable (“do I want this?”), whereas utilitarian decisions require them to make such decisions about a more complex value distribution (“how much do I value this?”). This
computational difference immediately forces utilitarian decisions to have greater sample complexity, with interesting and
wide-ranging consequences. Further, very general algorithmic methods for computing both types of decisions suffer varieties of regret that are congruent with the ‘hot’ and ‘cold’
regret distinctions outlined by (Keinan & Kivetz, 2008).
The fit between our theory and a diverse set of research
findings suggest that it captures fundamental features of the
distinction between hedonic and utilitarian decisions, which
makes it a useful tool for deriving policy insights for influencing decisions in one direction or another. Our results also
formalize an intuitive link between the hedonic/utilitarian divide in consumer research and fast/slow dual-process cogni-

2272

tive theories.

A cognitive account of consumer preferences
It is widely acknowledged that consumers are not economically rational in expressing their preferences. The most predictive thing we can say about consumption preferences is
that they are arbitrary, but coherent (Ariely, Loewenstein, &
Prelec, 2003). A researcher cannot know what preference
a subject will express for a particular object in a particular
choice context, but ceteris paribus, they can be reasonably
sure that if the subject has expressed preference for one object over another once, they will do so again.
The existence of idiosyncratic but consistent preferences
seems to suggest that they are dynamically constructed, an
idea that has been expressed prominently in the heuristics literature that has proceeded from Tversky’s EBA theory (Tversky, 1972). However, process theories of changing
preferences have not historically been very predictive, relying on large numbers of latent parameters to describe, but not
predict data (Busemeyer & Townsend, 1993; Brown & Heathcote, 2008). We believe that this stems, in large part, because
such theories are predicated on a psychophysical value representation (often termed ‘subjective utility’). If we assume
that a person assigns some psychophysical ‘utile’ to various
objects, then we have two problems in constructing a learning
theory of preferences, (i) how to develop a scale for comparing utiles of two different options, and (ii) how to determine
the normalization constant that tells us how much to credit
each new experience for changing the underlying ‘utile’ state.
These problems have made such ‘subjective utility’ learning
accounts struggle with the idiosyncratic non-transitivity of
preferences.
Our own recent work (Srivastava & Schrater, 2012) has offered a solution by showing how option desirability can be
learned from experience without using option-specific subjective utilities, and how doing so solves both the value representation and credit assignment problems endemic to older
solutions. All that is needed is to let go of the assumption
that people track hedonic value on some internal scale, and
to postulate that they track multiple samples of a single binary ‘like/don’t like’ variable instead. In this paper, we build
upon this theoretical base to make specific predictions about
consumer preferences, which explains, as we shall see, the
principal differences between hedonic vs utilitarian choice.
Our account hinges on the crucial representational distinction between binary hedonic decisions, and high-dimensional
utilitarian ones which typically consider costs, benefits, and
tradeoffs associated with a choice. We begin with a Marrian
specification of our model at both the computational and algorithmic levels.

Computational specification
We model preference formation as a Bayesian observer directly learning which option among the ones offered is ‘best’
from memories of previous decisions: what was chosen and

what were the options. This learning is bootstrapped by inferring the situational context of the underlying choice from the
set of options available, thus allowing for some generalization
across option sets.
Computing magnitude of desire. How desirable a particular option is takes on a probabilistic interpretation in this
account, formally expressed as p(r|x, o), where r is a binary
variable indicating preference (‘this option was chosen/best’),
x is the option, and o is the current observation (primarily the
set of options available right now). Our theory predicts that
this quantity is obtained by marginalizing over evidence contained in the set of latent contexts C ,
D(x) = p(r|x, o) =

∑Cc p(r|x, c)p(x|c)p(c|o)
,
∑Cc p(x|c)p(c|o)

(1)

where it is understood that the context probability p(c|o) =
p(c|{o1 , o2 , · · · , ot−1 }) is a distribution on the set of all possible contexts incrementally inferred from the agent’s observation history. Here, p(r|x, c) encodes the probability that
the item x was preferred to all other items present in choice
instances linked with the context c, p(x|c) encodes the probability that the item x was present in choice sets indexed by
the context c and p(c) encodes the frequency with which the
observer encounters these contexts.
The observer also continually updates p(c|o) via recursive
Bayesian estimation,
p(c(t) |o(1:t) ) =

p(o(t) |c)p(c|o(1:t−1) )
,
∑c p(o(t) |c)p(c|o(1:t−1) )
C

(2)

reflecting adaptations in situational frequencies as a function
of movement through the world.
But how can such a theory account for economic decisions,
where objects are not abstract, but have concrete monetary
values associated with them? In (Srivastava, Vul, & Schrater,
2014), we show how augmenting the framework above with a
set of categorical labels m ∈ M denoting money magnitudes
yields a workable theory of money-minded economic decisions without committing to psychophysical evaluation of the
hedonic worth of money. In this extended account, following
a similar probabilistic calculus as in Equation 1, the inferred
value of x becomes p(r|x) can be calculated as,
p(r|x, o) =

∑M
m ∑C p(r|x, m, c)p(x|m)p(m|c)p(c|o)
,
∑M
m ∑C p(x|m)p(m|c)p(c|o)

(3)

with the difference from the earlier expression arising from an
additional summation over the set M of monetary labels that
the agent has experience with. Natural interpretations for the
computations involved in this theory are visually schematized
in Figure 1.
Computing what to pay. Asking how much someone desires an option, the quintessential hedonic question, is different from asking if they would be willing to buy it at a particular price, which is the typical framing of a utilitarian decision. The former corresponds to the term p(r|x), as we define

2273

p(m|c)
What distribution of
price labels do I
see in context c?

where to go?

Shopper

Muﬃn

p(x|m,c)
Are x available
at price level
m in context
c?

X = all muﬃns

C

thrift

m
cafe

ic
ot
ex al
m

p

ea

or

ch

n

ic
ot
ex al

p

m

or

ea
ch

Cafe

n

Grocer

ic
ot
ex al
m
or
p

ea
ch

Thrift store

cafe

grocer

thrift

n

p(r|x,m,c)

grocer

(pmf for all x's with one m shown in one bar)
(value for money)
(on sale!)
(too pricey!)
grocer
cafe
thrift
What is my
purchase
history in
these shops?

X
p(r|x)
grocer

thrift

cafe

(grocer is on
work-home
route)

p(c)
for

Cheap

Normal

Exotic
fe
ca r
ce
ro
ft
ri

th

g

Prediction: buy normal muﬃn at grocer's

Figure 1: An illustration of the interplay between the stochastic components of our model of preference formation.

above. We suggest that the latter corresponds to assessing
p(m|r = 1, x), a probability distribution on the set of money
labels M conditioned on prior experience with having seen
successful transactions (r = 1) of the option x. Since the contribution of all terms where r = 0, i.e. the transaction is not
completed, is identically zero this term can be computed as,

work (Srivastava & Schrater, 2014), we model the process of
memory recall as the activation of a subset Q of decisionrelevant memory particles. Using this notation, a general belief formation model could be expressed as,
p(c) =

∑ p(c|q)p(q),

(5)

q∈Q

p(m|r, x) =

∑C p(x|m, c)p(m|c)p(r|c)p(c)
,
∑M
m ∑C p(x|m)p(m|c)p(c)

(4)

where p(m|c, r) = p(m|c) because the distribution of money
labels in a context has no causal relationship with subject
preferences and p(x|m, r, c) = p(x|m, c) because the prior history of purchases is contingent on r being 1 in all relevant
cases.
This quantity corresponds to a stochastic representation of
the willingness to pay (WTP) various amounts of money m
to purchase an object x. Since utilitarian decisions are made
keeping cost considerations up front, it is reasonable to believe that this quantity is more salient in making them.

Algorithmic specification
The computational goals of preference formation we have described above require accumulation of evidence associated
with all previous contexts at the time a new decision is to
be made. Clearly, this is not realistic - it is more likely that
animals sample evidence from a subset of previous experience. Which samples are recalled and which aren’t is best
specified at the algorithmic level of description, in the shape
of a rudimentary memory model.
A simple memory model.The basic mechanism of evidence accumulation influences the shape of the distribution p(c|o) via memory sampling. Following our own prior

where c ∈ C are the latent contexts available in memory and
q ∈ Q are memory particles corresponding to past choice selections. Here, the probability distribution p(q) - which we
call the memory prior - encodes the likelihood of recalling
the memory of experience q, while the distribution p(c|q) encodes beliefs about outcomes learned during the experience
corresponding to the memory particle q. For our purposes,
we assume a trivial bijective mapping between c and q - each
memory particle is assumed to be associated with a unique
context.
This memory-sampling variant of p(c|o) plugs directly as
the prior in the Bayesian context probability update for p(c|o)
in Equation 2, which then itself plugs into the two computations in Equations 1 and 4 that we are interested in analyzing.
Note, though, that we are able to use the memory model so
easily because of one additional assumption: that the contextspecific memories recalled are episodic, and therefore convey all context-relevant information once the context itself
has been activated in memory1 .
1 This assumption simplifies our analysis by ignoring the memory
dependence of our other intermediate probability terms. While it is
likely that such dependence exists, its effects will work in the same
direction as the basic results of our approach, since it would further
impoverish the preference representation we are already imposing
sampling constraints on.

2274

Specifying an endogenous decision rule. The final step
in our algorithmic specification involves specifying the decision rules that agents forming preferences via our account
would use to make decisions. One strategy would be to use a
race-to-threshold approach, wherein evidence in favor of various alternatives accumulates until the most likely candidate
reaches a threshold, at which point it is emitted as the choice.
This basic intuition is shared by several existing computational models of the choice process, but because thresholds
and differential evidence accumulation rates are usually free
parameters, such an approach would reduce our ability to obtain model predictions.
Instead, we adopt a volatility-sensitive decision rule. Since
our account proposes that preferences are dynamically generated at the time of a decision, choosing to stop accumulating evidence when the currently accumulated preference
has stabilized is a rational strategy. For the case where we
are considering simply whether we want an option or not
p(r|x), measuring this volatility is simply a question of tracking ∆p(r|x)/∆k, the rate of change of desirability as a function of sample count. For decisions about a suitable price to
pay for an option, we can measure volatilty as the KL divergence between successive p(m|x) values.
100
Hedonic
Utilitarian
50

Average # of samples

Number of decisions

80

60

40

40

30

20

10

0

0.25

0.50

0.75

ν

20

0
0

20

40

60

Number of samples

80

Figure 2: Hedonic decisions require fewer memory samples than
utilitarian decisions, based on the set of computations defined by our
theory. This explains the phenomenology of easy hedonic decisions,
and effortful utilitarian ones.

Finally, even these criteria ultimately require thresholds.
We use the large-sample (n = 1000) volatility of both these
measures to endogenously estimate thresholds δ for our
volatility estimates. Since the large-sample estimate is expected to converge to the true posterior distribution, we can
assume that the minimal volatility δmin seen in this regime is
simply noise, and so can be generalized across multiple decisions. On the other hand, volatility seen in the first 5 samples
can be taken as an upper bound δmax for either measure. Then,
we define the volatility threshold to be δmin + ν(δmax − δmin ).
Setting ν to aggressively low values will yield highly conservative agents, while setting it high will yield much more

impulsive ones.

Experiments
Having set up our decision model, we now turn to operationalizing the specific questions we want to ask it. As we
anticipated in the introduction, two questions stand out: (i)
why are hedonic decisions fast/easy and utilitarian decisions
slow/difficult? (ii) why are hedonic decisions more error
prone?. We probe these questions using two separate computational experiments.

Decision complexity as a function of sample size
In our framework, the effortfulness of decisions is related to
the number of memory samples needed to make them. Thus,
we can directly compare the number of samples necessary for
a hedonic how much do I want this? decision with that needed
for a utilitarian how much should I pay for this? decision.
Figure 2 shows the result of a simulation experiment we
conducted to make this comparison2 . We randomly3 initialized the input probability distributions for our model to
construct 1000 different agent histories associated with preferences in a world with 5 unique contexts and 5 unique
money labels, and calculated the minimum number of samples needed for the corresponding output distributions to trigger our decision rules.
It is immediately obvious that our model replicates the basic phenomenology of decisions involving the hedonic p(r|x)
being easier, and utilitarian p(m|r, x) decisions being effortful. This conclusion holds across a wide range of values for
the parameter ν (see inset in Figure 2) and across a large
randomized repertoire of agent histories. A possible concern
here could be the fact that we are using two different decision
rules for both decision categories, using a first order derivative to compute volatility for the hedonic decision, and a KL
divergence for the utilitarian one. In the absence of a common quantitative scale, how can we possibly compare results
across two separate measurement instruments? We agree that
it would have been nicer if there could have been a single
quantitative basis for measuring volatility in both cases, but
note that we have been careful in designing both stopping
rules as functions of the range of the individual measures
themselves, obviating the need for a common measurement
scale. Thus, these empirical results are valid and, in emerging from the operation of a general parameter-free preference
formation model, render transparent the previously opaque
distinction between the two classes of consumption decisions
we are studying.
2 y-axis is artificially truncated at 100 to show details of the sample distribution; the first bar in the original figure rises as high as
600, reflecting the need for very few samples to reach stable desirability inferences.
3 The context probability p(c) was generated via 5 draws from
a U(0, 1) distribution, followed by normalization; the money distribution p(m|c) was initialized similarly, and normalized across contexts; the price distribution p(x|m, c) was first initialized as a 5 × 5
matrix that was identically 0.1 and then randomly seeded with a single high value in each column, then normalized; the prior choice
distribution p(r|x, m, c) was initialized similarly.

2275

(A)0.4

(B)

5 samples

0.2
2

3
10 samples

4

3
20 samples

4

5

p(c)

0.2
0

1

2

0.4

5

0.2
0

1

2

0.4

3
True distribution

4

5

0.4
0.3

0.1

0.35
0.3
0.25

2

3

m

4

5

p(r|x)
p(m*|x)
p(m’|x)

0.1

0

1

m'

0.2
0.15

0.05

0.2
0

m*

0.4

0.2

p(m|r,x)

1

0.4

Probability

0

Alternate value m'
dominating optimal m*
temporarily

0.5

m’

m*

Money label

0
0

5

10

15

Number of samples

Figure 3: (A)Sampling from memory can introduce short-term biases in estimates of quantitites used in preference inference, (B) Such biases
influence decisions involving money labels more than decisions involving desirability, since multiple money labels compete for viability, and
memory biases make determining the distribution mode difficult.

Error-proneness as a function of impulsivity
The second computational experiment we conducted analyzed patterns for errors in both classes of decisions. To do
this, we first had to operationalize errors in our framework.
For the utilitarian case, this was simple: we compared the
mode of the p(m|x) distribution at the stopping point with that
in the large sample limit, and counted all situations wherein
they did not match up. For the hedonic case, we sampled a
binary choose/don’t choose outcome from both the stopping
point desirability and the large sample limit, and counted all
situations where they did not match up.
In both classes of decisions, errors would cause regret that
was either of the ‘miss’ variety, viz. ‘I wish I had chosen this’
or of the ‘guilt’ variety, viz. ‘I wish I hadn’t chosen this’,
reflected symmetrically in the relationship between the small
and large sample predictions. Further, the error fraction, the
fraction of simulations in which error of any of these four

0.25

0.20

Error fraction

Figure 3 further clarifies the mechanism responsible for
this difference. It should be intuitively evident that dynamic
accumulation of choice information will create a series of intermediate probability densities that do not reflect the asymptotic ‘true’ distributions that people would arrive at given infinite time and infallible memory (see panel A for an illustration of a run through one such sampling trial). Deviations
from true intermediate distributions will lead inevitably to
distortions in the preference formation process. In the example shown in panel B, the blue line plots the time course
of the hedonic p(r|x) distribution. Because the accumulation
process for this distribution tracks only the volatility of a binary variable, it has fewer ways of failing to converge than
the process for the utilitarian p(m|r, x) distribution, which requires an entire vector of stochastic variables to behave nicely
for a useful decision to emerge. Thus, in a nutshell, we propose that utilitarian decisions are harder because the measure
of the stochastic cognitive representation that people use to
make them has a much greater cardinality than the one they
use for making hedonic decisions.

Hedonic

0.15

0.10
Miss
0.05

Guilt

Utilitarian

Miss
Guilt
0
0

0.2

0.4

0.6

Impulsivity(ν)

0.8

1

Figure 4: Greater impulsivity leads to more errors in utilitarian calculations, but not in hedonic ones. However, the base rate for error in
hedonic calculations remains higher than in utilitarian calculations.

varieties was seen, is expected to depend on the impulsivity
parameter ν; more impulsive decisions should be more errorprone.
In a further series of 1000 × 9 randomized simulations, we
assessed the frequency with which these errors occur in our
sample for 9 evenly spaced values of ν using the endogenous
stopping rules as before. Our simulations results follow a
pattern previously observed empirically by (Frederick, 2005).
As illustrated in Figure 4, we find that (i) hedonic judgments
are more error-prone, but (ii) this error-proneness does not
reduce with greater deliberative effort (measured as the inverse of the impulsivity parameter ν). In contrast, (iii) utilitarian judgments are less error-prone overall, and (iv) grow
less error-prone with greater deliberative effort.
This overall pattern of results is also congruent with our
earlier finding that the informational sample complexity of
hedonic decisions being extremely low, which makes them
more sensitive to sample bias, and also indifferent to the availability of greater cognitive resources. Once somebody’s mind

2276

is made up about the hedonic aspects of a consumption decision, further thinking won’t budge them. In contrast, utilitarian decisions, due to their greater sample complexity, benefit
through greater opportunity for deliberation.
Finally, a speculative point: if someone is implicitly aware
of the differential sensitivity to deliberative effort in the two
paradigms, regret caused by failing to compute utilitarian
calculations correctly will be ‘hot’, since they will perceive
this to be a personal failure, while that experienced by anhedonia will be ‘cold’, since no amount of extra effort could
have made things better. This distinction tracks the varieties
of counterfactual regret previously outlined by (Kahneman,
1995).

Discussion
Thanks in part to Kahneman’s lucid book (Kahneman, 2011),
it has become fashionable to describe cognition as consisting
of two systems: one quick, automatic, and habitual, and one
slow, deliberate and cogitative. Remarkably, our results are
generally convergent with such two system descriptions, but
derive the differences in the two systems from task-relevant
information-processing requirements within the same overall
cognitive model. Thus, these results, while presented here
specifically in the context of preference formation, also support a more general view that the two system description
is not ontologically deep - it describes phenomena that can
equally well be encompassed by single-process theories.
Our analysis also ties into a body of consumer and social
psychology research that tracks adaptations in impulse regulation when people face series of decisions (Keinan & Kivetz,
2008). Theories of self-control have chiefly revolved around
the observations that when people feel that they have been
too prudent, they experience ‘miss’ regret and subsequently
choose to indulge themselves, and when they think they have
been too indulgent, they experience ‘hot’ guilt and become
more calculating (Baumeister, 2002).
While our current model does not directly address these behaviors, it could do so if we posit that people can over-ride the
endogenous volatility-based threshold we used. For instance,
somebody who is stressed for time will make a quick decision
that he may immediately afterward try to change, suggesting
that his decision was made while the underlying preference
was still volatile. In such an extended account, the volatility
criterion would serve as the default controller, but could be
adjusted or over-ridden by executive control to account for
other task requirements. In such a setting, Bayesian learning of the threshold itself, working on top of the model we
have defined, would accommodate the self-regulatory behaviors outlined above by increasing the desirability threshold to
account for misses and decreasing the WTP threshold to account for guilt.
Multiple other tangential findings from the consumer research literature can also be accommodated within our theory. For instance, the facts that consumers placed under cognitive load make more hedonic decisions (Shiv & Fedorikhin,

1999), and that they do so when choices are temporally proximal (Milkman, Rogers, & Bazerman, 2010) are explained directly via the differential sample complexity of the two types
of choices: Given limited time, people will rationally prefer the low complexity choice strategy. A more intriguing
phenomenon is that subjects are less likely to make hedonic
choices under simultaneous presentation of options than sequential (Read, Loewenstein, & Kalyanaraman, 1999). Under our account, since simultaneous choice expands the size
of the sample space required to make a desirability computation, it increases the sample complexity of the hedonic approach, thus making people less likely to use it.
To conclude, in this work, we show that differences in hedonic vs utilitarian preference patterns can be explained simply by differences in how evidence for both classes of decisions accumulates via sequential memory sampling.
Acknowledgments: NS was funded by the Institute of New
Economic Thinking; NS and EV were funded NSF CPS Grant
#1239323.

References
Alba, J. W., & Williams, E. F. (2013). Pleasure principles: A review of research on hedonic consumption. Journal of Consumer
Psychology, 23(1), 2–18.
Ariely, D., Loewenstein, G., & Prelec, D. (2003). ” coherent arbitrariness”: Stable demand curves without stable preferences. The
Quarterly Journal of Economics, 118(1), 73–105.
Baumeister, R. F. (2002). Yielding to temptation: Self-control failure, impulsive purchasing, and consumer behavior. Journal of
Consumer Research, 28(4), 670–676.
Brown, S. D., & Heathcote, A. (2008). The simplest complete model
of choice response time: linear ballistic accumulation. Cognitive
psychology, 57(3), 153–178.
Busemeyer, J. R., & Townsend, J. T. (1993). Decision field theory:
a dynamic-cognitive approach to decision making in an uncertain
environment. Psychological review, 100(3), 432.
Frederick, S. (2005). Cognitive reflection and decision making.
Journal of Economic perspectives, 25–42.
Kahneman, D. (1995). Varieties of counterfactual thinking. What
might have been: The social psychology of counterfactual thinking, 375–396.
Kahneman, D. (2011). Thinking, fast and slow. Macmillan.
Keinan, A., & Kivetz, R. (2008). Remedying hyperopia: The effects
of self-control regret on consumer behavior. Journal of Marketing
Research, 45(6), 676–689.
Milkman, K. L., Rogers, T., & Bazerman, M. H. (2010). Ill have the
ice cream soon and the vegetables later: A study of online grocery
purchases and order lead time. Marketing Letters, 21(1), 17–35.
Read, D., Loewenstein, G., & Kalyanaraman, S. (1999). Mixing
virtue and vice: Combining the immediacy effect and the diversification heuristic. Journal of Behavioral Decision Making, 12(4),
257–273.
Shiv, B., & Fedorikhin, A. (1999). Heart and mind in conflict: The
interplay of affect and cognition in consumer decision making.
Journal of consumer Research, 26(3), 278–292.
Srivastava, N., & Schrater, P. R. (2012). Rational inference of relative preferences. In Advances in neural information processing
systems (pp. 2303–2311).
Srivastava, N., & Schrater, P. R. (2014). Frugal preference formation. In Proceedings of the 36th annual meeting of the cognitive
science society.
Srivastava, N., Vul, E., & Schrater, P. R. (2014). Magnitudesensitive preference formation. In Advances in neural information
processing systems (pp. 1080–1088).
Tversky, A. (1972). Elimination by aspects: A theory of choice.
Psychological review, 79(4), 281.

2277

