UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Stable Self-to-Object Spatial Relations Acquired from Sequential Spatial Learning

Permalink
https://escholarship.org/uc/item/51611997

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Xiao, Chengli
Chen, Fudan

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Stable Self-to-Object Spatial Relations Acquired from Sequential Spatial Learning
Chengli Xiao (xiaocl@nju.edu.cn)
Department of Psychology, Nanjing University, 22 Hankou Road
Nanjing 210093, P.R. China

Fudan Chen (cfdchashao@163.com)
Department of Psychology, Nanjing University, 22 Hankou Road
Nanjing 210093, P.R. China

Abstract
Self-to-object spatial relations are generally considered to be
transient and supported primarily by perceptual processes.
The present study investigates whether people can acquire
stable self-to-object spatial relations that are not disrupted by
disorientation. Participants either simultaneously or
sequentially viewed the object locations from a learning
position amidst a geometrically irregular array. Next they
were blindfolded and pointed to the objects under three
conditions: before turning (baseline), after rotating 240°
(updating), and after disorientation (disorientation). Finally,
all participants were taken to another room to perform
judgments of relative direction (JRDs) among remembered
object locations. The internal consistency of pointing among
objects was disrupted by disorientation following
simultaneous viewing but not sequential viewing. However,
participants’ memories of object-to-object relations were
equivalent in the two viewing conditions. Together, these
results suggest that people construct stable self-to-object
spatial relations when they sequentially view each object of
the irregular layout.
Keywords: self-to-objection spatial relations; sequential
learning; disorientation

Introduction
In everyday life, people use self-to-object (egocentric) and
object-to-object (allocentric) spatial relations to encode the
location of objects or landmarks in the environment,
navigate effectively to significant places, and reorient
themselves when getting lost. In a self-to-object reference
system, locations are represented with respect to the
particular perspective of a perceiver, whereas in an objectto-object reference system, locations are represented within
a framework external to the holder of the representation and
independent of his or her position e.g., Easton & Sholl, 1995;
Klatzky, 1998).
Generally, it is believed that self-to-object spatial
relations are transient and supported primarily by the
perceptual processes, and that object-to-object spatial
relations are stable and can be preserved in the memory
system (e.g., Burgess, 2006; Holmes & Sholl, 2005; Mou,
McNamara, Valiquette, & Rump, 2004). When moving
around the environment, if people navigate by means of the
self-to-object spatial relations, one has to add a common
vector to each individual target vector to compute the new
egocentric coordinates of the target locations. If this
updating process is disrupted through procedures that induce

a state of disorientation, the coherence of relative locations
among different targets is reduced. Therefore, a disoriented
participant's pointing response will show an inconsistency
among different targets (disorientation effect). To the
contrary, if people navigate by means of the object-to-object
spatial relations, which remains the same regardless of
people’s movements, the state of disorientation cannot
reduce the coherence of relative locations among different
targets. Therefore, the consistency of the pointing response
among different targets will be equal between oriented and
disoriented participants (absence of disorientation effect).
By measuring the standard deviation across target objects of
the mean signed pointing errors (configuration error), the
accuracy of the localization of each target in relation to the
others can be assessed. Following this logic, recent research
has indicated that people can navigate by means of either
the transient self-to-object or stable object-to-object spatial
representations (Holmes & Sholl, 2005; Mou, McNamara,
Rump, & Xiao, 2006; Sargent, Dopkins, Philbeck, &
Modarres, 2008; Waller & Hodgson, 2006; Wang & Spelke,
2000). In most situations, people acquire both self-to-object
and object-to-object spatial representations, and can
navigate by means of one of them according to the layout
geometry or instruction (Xiao, Mou, & McNamara, 2009).
However, in all the previous research, which indicated
that people were able to navigate by means of transient selfto-object spatial representations, the pointing responses of
disoriented participants still had a relatively high
consistency among different targets. The configuration
errors in the disorientation condition were no more than 30°,
which were much less than the expected configuration error
of randomly pointing (approaching 104°). It is possible that
disorientation does not totally disrupt the self-to-object
spatial representations, and that the disoriented participants
can still locate objects based on the impaired self-to-object
spatial representations that persist in their memory. One of
our recent experiments provided circumstantial evidence for
this hypothesis (Xiao, et al., 2009). After visually learning
object locations amidst, or at the periphery of an irregular
array (see Figure 1), blindfolded participants pointed to the
objects before turning (baseline), after rotating 240°
(updating), and after disorientation (disorientation). In both
learning conditions, the configuration error significantly
increased after disorientation, indicating that the participants
located objects by means of the self-to-object spatial
relations. When explicitly instructed to use the object-to-

1173

object spatial relations (e.g., “Please keep track of all of the
locations of the objects relative to other objects while you
are turning to face the ball.”), after the baseline pointing test
and before rotation, the participants who learned at the
periphery of the irregular array could follow the instruction
to prevent the disorientation effect, while the participants
who learned amidst the irregular array could not follow the
instruction to prevent the disorientation effect. These results
suggest that after visually learning object locations at the
periphery of the irregular array, the participants established
both self-to-object and object-to-object spatial relations, but
updated self-to-object spatial relations during rotation by
default. They could also update object-to-object spatial
relations when required. However, after visually learning
the object locations amidst an irregular array, the
participants can only establish the self-to-object spatial
relations. They may only represent minimally, if at all,
object-to-object spatial relations, which cannot be used
during rotation. Therefore, there is little possibility that the
participants used the object-to-object spatial relations after
disorientation. The disoriented participants can only locate
objects by means of the self-to-object rather than the objectto-object spatial relations, suggesting that the self-to-object
spatial relations are preserved, to some extent, over
disorientation in memory.
In the object-to-object spatial relations, object locations
are represented with respect to another object or set of
objects, while in the self-to-object spatial relations object
locations are represented with respect to the perceiver (e.g.,
Easton & Sholl, 1995; Klatzky, 1998; Mou, Xiao, &
McNamara, 2008). If the perceiver takes him or herself as a
stable object, and refers every other object location relative
to him or herself, a special kind of object-to-object spatial
representation is built, and can be well preserved in memory
as another kind of object-to-object spatial representation. In
other words, the perceiver establishes a stable self-to-object
spatial representation. After disorientation, the perceiver can
recover object locations by retrieving the remembered selfto-object spatial information. In Xiao et al. (2009), the
participants visually learned object locations amidst the
irregular array, where they could not perceive the whole
layout from a single viewpoint. However, participants could
directly view inter-object spatial relations between objects
separated by small angular distances, and thus fragmentary
object-to-object spatial representations might be acquired
(Sargent, Dopkins, Philbeck, & Chichka, 2010). Attending
to and memorizing neighboring object-to-object spatial
relations might interfere with the acquisition of self-toobject spatial relations. Therefore, participants might
develop unstable self-to-object spatial representations after
they visually learned amidst the irregular array. There is a
high possibility that participants will construct more stable
self-to-object spatial representations through the new
learning methods, by which they can only directly perceive
the self-to-object spatial relations but not the inter-object
ones, such as through sequential learning. Previous research
has demonstrated that participants can learn spatial locations

by viewing one object at a time (e.g., Yamamoto & Shelton,
2007, 2009). Compared with visually learning object
locations amidst the array, sequentially viewing each object
prevents participants from directly perceiving any interobject relations, but compels them to focus on each object’s
location relative to themselves. Therefore, the acquisition of
object-to-object spatial representations is maximally
reduced and the salience of self-to-object spatial relations is
enhanced, and the participants may develop stable self-toobject spatial representations and minimal object-to-object
spatial relations.
In the present study, participants either sequentially or
simultaneously viewed object locations from a learning
position amidst the same irregular layout as in Xiao et al.
(2009). After learning, all participants were blindfolded and
pointed to object locations in baseline, updating, and
disorientation conditions. Before rotating to a new heading
in the updating condition, half of the participants were
explicitly instructed to use object-to-object spatial relations
during locomotion as in Xiao et al. (2009). At last, all
participants were taken to another room to perform
judgments of relative direction (JRDs), which have been
commonly used to assess the memory of the object-to-object
relations in an environment (e.g., Mou, et al., 2004; Shelton
& McNamara, 2001; Waller & Hodgson, 2006). Because we
hypothesized that participants would use self-to-object
spatial relations to locate objects before and after
disorientation when learning amidst the irregular layout, and
that the participants would establish more stable self-toobject spatial relations following sequential viewing than by
following simultaneous viewing, we expected that the
configuration error in sequential viewing condition would
be smaller than that in the simultaneous viewing condition,
and that the disorientation effect would be absent in the
sequential viewing condition but present in the simultaneous
viewing condition. Meanwhile, since we hypothesized that
the participants would establish minimal object-to-object
spatial relations in both the simultaneous and sequential
viewing condition, we expected that the participants could
not use the object-to-object spatial relations during
locomotion and after disorientation. As in Xiao et al. (2009),
the participants could not follow the object-to-object
instruction to prevent the disorientation effect after
simultaneous learning of the layout. Because we predicted
that the participants would use the stable self-to-object
spatial relations after sequentially learning the layout, we
expected that there will be no disorientation effect in both
the object-to-object instruction and the non-instruction
group. Because the participants established minimal objectto-object spatial relations, a floor effect might be present,
and the performance on JRDs in the sequential learning
group might be equivalent or inferior to that in the
simultaneous learning group.

1174

Method
Participants
Thirty-two university students (16 men and 16 women)
participated in this experiment in return for monetary
compensation.

Materials
The irregular layout of Xiao et al. (2009) was used in this
experiment. As illustrated in Figure 1, nine objects were
presented on the floor in a cylinder that was located in an
experiment room. The cylinder was 3.0 m in diameter, made
by black fabric and reinforced cloth. Objects were chosen
with the restrictions that they were visually distinct, fit with
approximately 0.3 m on each side, were familiar to people,
and shared no obvious semantic association. The scissors,
the hat, and the brush were placed in a line. Participants
were standing 1 meter away from the brush, facing the
scissors. The floor was covered with gray carpet. Four lights
were placed on the ceiling near the side of the cylinder to
illuminate the area. They were placed at equal intervals and
at equal distance from the center of the cylinder to minimize
directional illumination cues.

Figure 1: Layout of objects used in the study.
Test trials were presented by a computer via wireless
earphone. A joystick was used as the pointing apparatus.

Procedures and Design
Before entering the study room, each participant was
instructed to learn the location of objects for a spatial
memory test and trained in how to use a joystick. After that,
the objects that would be encountered in the experiment
layout were presented individually to all participants and the
name of each object was given. Then, the blindfolded
participants were escorted to the study room and led to the
learning position by the experimenter. The participant was
then asked to remove the blindfold.
Simultaneous Viewing All nine objects were presented on
the floor. Half of the participants viewed the layout for 30 s
and then closed their eyes and named and pointed to each

object with one of their fingers. Throughout the learning
phase, the participants were stationary at the learning
position. They were allowed to turn their heads to review
the layout but were required to maintain their body
orientation.
Sequential Viewing The other half of the participants
viewed each object presented alone for 3 s in a spatially
random sequence. To control the viewing time, the
participant was asked to close his/her eyes while the
experimenter replaced the just-viewed object on the floor
with a new object in a new location. After viewing the last
object, the participant was asked to close his/her eyes and to
name and point to each object with one of their fingers. The
learning sequence of the objects was randomized.
In both learning conditions, the learning-pointing session
was repeated until participants could fluently name and
point to the correct object locations twice in a row. (Fluency
and accuracy were determined by the experimenter’s visual
inspection of the pointing performance.) The number of
repetitions needed to achieve the learning criterion was
recorded. During training and learning, the participants were
not aware of what particular tasks they would perform in the
testing stage.
Egocentric Pointing Tasks After learning the layout, all of
the participants put on the wireless earphone, and held the
joystick against their front waist. All of the participants
were blindfolded and tested in the order of the baseline,
updating, and disorientation conditions. In the baseline
condition, participants maintained their heading to the
scissors. In the updating condition, participants rotated 240°
by themselves (e.g., “Please turn right until you are facing
the candle”). Half of the participants turned right to face the
candle, and half turned left to face the ball. Within each
group, immediately before rotation, half of the participants
were explicitly instructed to use object-to-object spatial
relations during rotation (e.g., “Please keep track of all of
the locations of the objects relative to other objects while
you are turning to face the candle”). The other half were not
given this instruction. In the disorientation condition, the
participants rotated in place for 1 minute. Then they pointed
to the location of an object named by the experimenter (e.g.,
“Please point to the ball”). This rotation and pointing
procedure was repeated until the absolute pointing error was
larger than 90°. Then the participants were instructed to turn
to face the ball (or candle) if they faced the candle (or ball)
in the updating condition (“Please turn right until you
believe you are facing the ball”). They were allowed to
adjust their position by themselves if they thought they had
drifted off the testing location while rotating. A recovery
period was given before the final pointing test.
In each rotation condition, four blocks of trials were
included, and each block involved pointing to all nine
objects once in a random order. After hearing the warning
indication (“Start”), the participants pulled the joystick
trigger, and the target object was immediately announced
(e.g., “Please point to the candle”). Then the participants
used the joystick to point to the direction of the target object.

1175

The configuration error was measured as in Xiao et al. (see
Table 1), which defined as the standard deviation of the
means per target object of the signed pointing errors, which
indicated the internal consistency of pointing response
among different targets. As pointing data is inherently
circular data, circular statistics (e.g., Jammalamadaka &
SenGupta, 2001) were used.

of eight imagined headings. The dependent measures were
the angular error of the pointing response, measured as the
absolute angular difference between the judged pointing
direction and the actual direction of the target.
In both egocentric pointing and JRDs tasks, pointing
accuracy but not speedy response was emphasized.

Results
Table 1: Definitional Formulas for Dependent Variables

Egocentric pointing

Variable

Formula

Signed pointing error
for object i on trial j

eij = judged direction –

Configuration error on egocentric pointing were subjected
to mixed-model analyses of variance (ANOVAs), with the
rotation condition (baseline, updating, and disorientation) as
the within subject variable, the viewing type (sequential,
simultaneous) and object-to-object instruction (yes, no) as
the between subjects variables. The results revealed no main
effect or interactions of the object-to-object instruction.
Data were therefore collapsed across this factor for
subsequent analyses.

actual direction

∑e

Mean signed
pointing error for
object i

ei. =

Configuration error


∑i ei. 

∑i  ei. − N 




N −1

ij

j

T
2

Note: T = number of pointing trials per object;
N = number of target objects.
JRDs Task After finishing the egocentric pointing tasks,
the blindfolded participants were escorted to another room
to perform JRDs. They were allowed to remove the
blindfold and take a short break before proceeding to the
JRDs. The participants first initiated each trial by pressing a
button of the joystick. Trials began with the imagined
standing location and facing object given aurally (e.g.,
“Imagine you are at the mug facing the ball”). After having
a clear mental image of where he or she was standing and
what he or she was facing, participants pulled the joystick
trigger, and the target object was immediately presented
(e.g., “Please point to the scissors.”). Then the participants
used the joystick to point to where the target would be if he
or she occupied the standing location and facing the
direction as presented. The participants were instructed to
hold the joystick exactly in the front of his or her waist and
to keep the joystick forward when he or she pointed.
The JRDs test included 8 imagined headings. To facilitate
exposition, we arbitrarily labeled headings counterclockwise
from 0° to 315° in 45° steps. The learning direction was
defined as 0°. Because the geometry of the layout was
irregular, there were little pairs of objects established the
imagined heading parallel to above 8 directions. Therefore,
the imagined heading established by any pair of objects
varied within ± 15° (that is, 0° ± 15°, 45° ± 15°, 90° ± 15°,
135° ± 15°, 180° ± 15°, 225° ± 15°, 270° ± 15°, and 315° ±
15°) was included in the 8 imagined headings (e.g., at the
candle facing the mug established the imagined heading
1.56°, and were taken as the imagined heading 0°). The
participants were given a total of 48 trials, six trials at each

Figure 2: Configuration errors in egocentric pointing as a
function of rotation condition and viewing type. Error bars
are confidence intervals corresponding to ± 1 SEM.
The main effect of the rotation condition was significant,
F (2, 60) = 13.13, p < .001, MSE = 24.92, the main effect of
the viewing type was significant, F (1, 30) = 7.83, p < .01,
MSE = 16.88, and the interaction of the rotation and the
viewing type was significant, F (2, 60) = 6.09, p < .005,
MSE = 24.92. As shown in Figure 2, three major findings
were revealed. First, as in Xiao et al. (2009), the
configuration error increased after disorientation when
participants simultaneously viewed the layout, which
indicated that participants had used the transient self-toobject spatial relations during rotation. This observation was
supported statistically by a planned contrast comparing the
participants’ configuration errors in the updating condition
with that in the disorientation condition following
simultaneously viewing, F (1, 30) =17.18, p < .001, MSE =

1176

59.05. Second, the configuration errors were equivalent
before and after disorientation when participants
sequentially viewed the layout, which indicated that
participants used a kind of stable spatial relations before and
after disorientation. This observation was supported
statistically by a planned contrast comparing participants’
configuration error for the updating condition with that for
the disorientation condition following sequential viewing, F
(1, 30) < 1. Third, the configuration errors were
indistinguishable for simultaneous and sequential viewing in
the baseline and updating conditions, but significantly
higher for simultaneous viewing than for sequential viewing
in the disorientation condition. These observations were
supported statistically by planned contrast comparing
participants’ configuration errors for simultaneous viewing
with those for sequential viewing at each rotation condition.
There were no differences in the baseline and updating
conditions, Fs (1, 30) ≤ 1.39, ps ≥ .24, but there was a
significant difference in the disorientation condition, F (1,
30) = 15.01, p < .001, MSE = 43.69.

JRDs
Performance data on JRDs were subjected to mixedmodel analyses of variance (ANOVAs), with the imagined
heading (0° to 315° in 45° steps) as the within subject
variable, viewing type (sequential, simultaneous) and
object-to-object instruction (yes, no) as the between subjects
variables.

Figure 3: Mean absolute angular errors in JRDs as a
function of imagined heading and viewing type. Error bars
are confidence intervals corresponding to ±1 SEM.
Three major findings were revealed. First, as shown in
Figure 3, the participants’ performance on JRDs was
indistinguishable for simultaneous viewing and sequential
viewing, which indicated that participants had constructed
object-to-object spatial representations of equivalent fidelity
through simultaneous viewing and sequential viewing. This
observation was supported statistically by no main effect or

interactions of the viewing type, Fs ≤ 1.36, ps ≥ .25.
Second, the participants’ performance on JRDs was
sensitive to the imagined headings, as supported statistically
by the significant main effect of the imagined heading, F (7,
210) = 3.75, p < .001, MSE = 147.10. Third, the instruction
before the updating condition affected the participants’
performance on JRDs. The performances on JRDs were
more accurate for the participants following object-to-object
updating instruction than those following no instruction.
This observation was supported statistically by the main
effect of instruction, F (1, 28) = 5.30, p < .05, MSE =
727.92. The interaction between the imagined heading and
instruction was marginally significant, F (7, 196) = 1.93, p
= .067, MSE = 147.10. The simple effect of instruction was
significant within the headings of 135°, 180°, and 225°, Fs
(1, 28) > 4.93, ps < .05, but not significant within the
headings of 0°, 45°, 90°, 270°, 315°, Fs (1, 28) < 2.21,
ps > .14.

Discussion
The absence of the disorientation effect has been
interpreted as evidence that object-to-object spatial relations
have been used during rotation (Holmes & Sholl, 2005;
Mou, et al., 2006; Sargent, et al., 2008; Xiao, et al., 2009).
However, in the present study, the absence of the
disorientation effect following sequential viewing can
unlikely be explained by using the object-to-object spatial
relations. The participants’ performance on JRDs was
equivalent across sequential and simultaneous viewing,
suggesting that the participants established equivalent
object-to-object spatial relations among each viewing group.
If the object-to-object spatial relations could be used in one
viewing group, there is little possible that the object-toobject spatial relations could not be used in another group.
If the participants in the sequential viewing condition used
the object-to-object spatial relations to prevent the
disorientation effect, the participants in the simultaneous
viewing condition should also be able to use them to prevent
the disorientation effect. However, in the simultaneous
viewing condition, the disorientation effect consistently
appeared, even when the participants were explicitly
required to use the object-to-object relations during rotation.
This result is consistent with Xiao et al. (2009), indicating
that the participants could not have used the object-to-object
but rather used self-to-object spatial relations to perform
egocentric pointing during rotation and after disorientation.
Therefore, it is unlikely that the participants could have used
the object-to-object spatial relations to perform egocentric
pointing in the disorientation condition following sequential
viewing. The absence of the disorientation effect following
sequential viewing can only be explained by using the stable
self-to-object spatial relations.
As the transient self-to-object spatial representation, the
stable self-to-object spatial representation may make use of
a special polar coordinate system in which the origin is at
the participant and the reference direction is participant's
front. Object locations are specified by egocentric distance

1177

and egocentric bearing. During locomotion, the sensoryperceptual input enables the participant to update multiple
self-to-object spatial relations. Although the procedures that
induce a state of disorientation will disrupt this updating
process, and the coherence of relative locations among
different targets will plummet if the participant still relies on
the sensory-perceptual system; the participant could recover
object locations by retrieving the remembered angular and
distance information from the learning view. If the test
heading misaligned with the learning view, a mental
rotation process would be involved to align the remembered
self-to-object spatial representation with respect to the test
heading. This retrieving process is similar to retrieving
object-to-object spatial representations (Mou, Fan,
McNamara, & Owen, 2008; Mou, Xiao, et al., 2008). At this
point, the differences between object-to-object and stable
self-to-object spatial representations become less dramatic,
because both representations could be preserved in memory
and be retrieved from a novel heading after disorientation.
However, unlike the object-to-object spatial relations, it is
difficult to use the stable self-to-object spatial relations to
judge inter-object spatial relations. Because every single
object is represented with respect to the self, the participants
have to compute an inter-object spatial relation, and this
computation process will introduce error (Klatzky, 1998).
Therefore, in present study, the participants in the sequential
learning condition could use the stable self-to-object spatial
relations to avoid disorientation effect, but could not use
them to improve their JRDs performance. Their
performance on JRDs was not superior to the simultaneous
viewing condition.
In summary, the present research indicates that by
sequentially viewing every object location from a learning
position, the participants constructed stable self-to-object
spatial relations which could be preserved over
disorientation. These results suggest that self-to-object
spatial relations are not only transient and supported
primarily by perceptual systems, but can also be stable and
preserved in memory.

Acknowledgements
Preparation of this article and the research reported in it
were supported by a grant from the National Natural
Science Foundation of China Grant 31000457 to Chengli
Xiao. Correspondence concerning this article should be
addressed to Chengli Xiao, Department of Psychology,
Nanjing University, 22 Hankou Road, Nanjing 210093,
China. E-mail: xiaocl@nju.edu.cn

References
Burgess, N. (2006). Spatial memory: How egocentric and
allocentric combine. Trends in Cognitive Sciences, 10,
551-557.
Easton, R. D., & Sholl, M. J. (1995). Object-array structure,
frames of reference, and retrieval of spatial knowledge.
Journal of Experimental Psychology: Learning, Memory,
and Cognition, 21, 483-500.

Holmes, M. C., & Sholl, M. J. (2005). Allocentric coding of
object-to-object relations in overlearned and novel
environments. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 31, 1069-1087.
Jammalamadaka, S. R., & SenGupta, A. (2001). Topics in
circular statistics. Singapore: World Scientific Publishing
Co. Pte. Ltd.
Klatzky, R. L. (1998). Allocentric and egocentric spatial
representations:
Definitions,
distinctions,
and
interconnections. In C. Freksa, C. Habel & K. F. Wender
(Eds.), Spatial cognition: An interdisciplinary approach
to representing and processing spatial knowledge LNAI
1404 (pp. 1-17). Berlin: Springer-Verlag.
Mou, W., McNamara, T. P., Rump, B., & Xiao, C. (2006).
Roles of egocentric and allocentric spatial representations
in locomotion and reorientation. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 32, 12741290.
Mou, W., McNamara, T. P., Valiquette, C. M., & Rump, B.
(2004). Allocentric and egocentric updating of spatial
memories. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 30, 142-157.
Mou, W., Xiao, C., & McNamara, T. P. (2008). Reference
directions and reference objects in spatial memory of a
briefly viewed layout. Cognition, 108, 136-154.
Sargent, J., Dopkins, S., Philbeck, J., & Chichka, D. (2010).
Chunking in spatial memory. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 36, 576589.
Sargent, J., Dopkins, S., Philbeck, J., & Modarres, R. (2008).
Spatial memory during progressive disorientation.
Journal of Experimental Psychology: Learning, Memory,
and Cognition, 34, 602-615.
Shelton, A. L., & McNamara, T. P. (2001). Systems of
spatial reference in human memory. Cognitive
Psychology, 43, 274-310.
Waller, D., & Hodgson, E. (2006). Transient and enduring
spatial representations under disorientation and selfrotation. Journal of Experimental Psychology: Learning,
Memory, and Cognition, 32, 867-882.
Wang, R. F., & Spelke, E. S. (2000). Updating egocentric
representations in human navigation. Cognition, 77, 215250.
Xiao, C., Mou, W., & McNamara, T. P. (2009). Use of selfto-object and object-to-object spatial relations in
locomotion. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 35, 1137-1147.
Yamamoto, N., & Shelton, A. L. (2007). Path information
effects in visual and proprioceptive spatial learning. Acta
Psychologica, 125, 346-360.
Yamamoto, N., & Shelton, A. L. (2009). Sequential versus
simultaneous viewing of an environment: Effects of focal
attention to individual object locations on visual spatial
learning. Visual Cognition, 17, 457-483.

1178

