UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Gesture structure affects syntactic structure in speech

Permalink
https://escholarship.org/uc/item/3sd7917s

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Mol, Lisette
Kita, Sotaro

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Gesture Structure Affects Syntactic Structure in Speech
Lisette Mol (l.mol@uvt.nl)
Tilburg center for Cognition and Communication (TiCC), School of Humanities, Tilburg University
P.O. Box 90135, NL-5000 LE Tilburg, The Netherlands

Sotaro Kita (s.kita@bham.ac.uk)
University of Birmingham, School of Psychology, Birmingham B15 2TT, UK
Abstract

and linguistic processing. Thus, in this view, gesture and
speech are two outcomes of a single process.
In addition to the line of thought that gestures are intended
communicatively, it has also been proposed that there are
speaker-internal motivations for gesture production. Some
propose that gesture production facilitates cognitive
processes in general, by lightening cognitive load (GoldinMeadow, Nusbaum, Kelly & Wagner, 2001). Others
propose that gesture production facilitates a specific process
in speech production. In this article, we focus on the latter
class of proposals. There are three prominent proposals in
the literature: The Lexical Retrieval Hypothesis, the Image
Activation Hypothesis, and the Information Packaging
Hypothesis.
The Lexical Retrieval Hypothesis (LRH) states that
gestures facilitate the retrieval of lexical items from the
mental lexicon (Krauss, Chen, & Gottesman, 2000). In this
view, gesture production is based on spatial imagery in
working memory. Rather than there being an interplay
between the processes of gesture and speech production, the
execution of a gesture is thought to activate spatio-dynamic
features, which in turn activate conceptual information.
Through cross-modal priming, this aids the retrieval of
lexical items. Thus, gesture production precedes speech
formulation entirely.
The Image Activation Hypothesis (IAH) states that
gesturing serves to keep an image (Freedman, 1977) or
certain spatial features (De Ruiter, 1998) activated while
they are encoded by the process of speech formulation.
The Information Packaging Hypothesis (Kita, 2000)
critically differs from the Lexical Retrieval Hypothesis and
the Image Activation Hypothesis in its assumptions on the
for-speaker motivations of gesture production, and on the
interplay between gesture and speech production. Rather
than simply activating information or maintaining the
activation of spatial information, gesture production is
thought to structure information, and to package it into units
that are suitable for the speech formulation process.
Like Growth Point Theory, the Information Packaging
Hypothesis (IPH) assumes that different forms of processing
underlie gesture and speech. It is proposed that gesture is
based on spatio-motoric processing and speech on analytic
processing. The IPH assumes that "[s]patio-motoric
thinking, which underlies representational gestures, helps
speaking by providing an alternative informational

Different functions have been proposed for the hand gestures
speakers spontaneously produce while speaking. The
Information Packaging Hypothesis (Kita, 2000) states that
gestures can structure rich spatio-motoric information into
packages suitable for speaking. It therefore predicts that how
information is divided over different gestures affects how it is
divided over different processing units in speech: clauses. We
indeed found that if participants were asked to express the
manner and path of a motion in one gesture, they were also
more likely to conflate this information into one clause in
speech, whereas if they were asked to produce separate
gestures, they were more likely to express manner and path in
separate clauses too. These results support the view that there
are speaker-internal motivations for gesture production. They
confirm predictions made by the Information Packaging
Hypothesis, which the Lexical Retrieval Hypothesis and the
Image Activation Hypothesis do not make.
Keywords: Gesture; Speech; Production; Motion Event

Introduction
When speaking, most people tend to produce hand gestures
that are closely synchronized with their speech semantically
(e.g. McNeill, 2005), temporally (e.g. Chui, 2005), and
structurally (e.g. Kita & Özyürek, 2003). Because of this
careful coordination, it is generally assumed that the
processes of speech and gesture production are somehow
related. Yet what is the exact role of gesture production in
relation to speech production?

Gesture and Speech Production
In this paper, we focus on representational hand gestures
(McNeill, 1992). Representational gestures either depict
action, motion or shape ("iconic gestures") or indicate a
location or direction ("deictic gesture"). Much evidence has
been gathered in support of a theory that (representational)
gestures, like speech, are part of a speaker's communicative
effort (Kendon, 2004). In line with this view, Growth Point
Theory (McNeill, 2005; McNeill & Duncan, 2010) starts
from the observation that gesture and speech co-express
idea units, each using a different form of semiosis. While
gesture employs a global/synthetic form of representation,
speech is expressed in an analytic/ combinatoric form. It is
assumed that gesture and speech production share a
common origin: the growth point. From this origin, a
bimodal utterance develops from the interplay of imagistic

761

organization that is not readily accessible to analytic
thinking, the default way of organizing information in
speaking" (Kita, 2000, p. 163). Furthermore, it assumes that
"[s]patio-motoric thinking and analytic thinking have ready
access to different sets of informational organizations"
(Kita, 2000, p. 163). The representations in these two modes
of thinking are thought to be coordinated online during
language production, such that they tend to converge.
The Information Packaging Hypothesis is implemented in
the Interface Model (Kita & Özyürek, 2003), which adds
gesture production components to Levelt's (1989) model of
speech production. In the Interface model, what needs to be
expressed is determined in the communication planner. This
module informs the action generator, where gestural
contents are determined, as well as the message generator,
where the preverbal message is determined. Importantly, the
action and the message generator are bi-directionally linked
to each other, allowing for gesture and speech to coordinate
their contents during language production. Lastly, the
message generator is also linked bi-directionally to the
formulator, which converts a preverbal message into an
utterance, through accessing the mental lexicon and
retrieving and processing morphological, syntactic and
phonological information. This way, the formulator can pass
on information to the action generator, via the message
generator. Thus, the bidirectional link between the action
and message generator allows for gesture and speech
production to be coordinated semantically and structurally.
It is assumed that the processes of speech and gesture
generation constantly exchange information, which is
transformed from one format into another, such that the
content of both modules tends to converge.
What is the evidence for this convergence of information
packaging in speech and gesture? The evidence for the
speech-to-gesture influence comes from studies of motion
event descriptions (Kita, 2000; Kita & Özyürek, 2003;
Özyürek, Kita, Allen, Furman, & Brown, 2005). It was
found that whether speakers used a single or multiple
clauses to verbally describe the manner and path of a motion
tended to match whether they expressed manner and path in
a single or in separate gestures. For example, "he rolled
down the hill" would likely be accompanied by a gesture in
which the hand describes circular motions as it is moved
down diagonally, while "he rolled, as he went down the hill"
would be more likely to be accompanied by one gesture
illustrating the rolling and another gesture illustrating the
downward path. In one study on English speakers (Kita, et
al., 2007), different clausal structures in speech were elicited
by varying whether a manner was incidentally or causally
related to the path of a motion in the stimulus animations.
Different clause structures lead to the predicted different
patterns of packaging of manner and path in gestures.
The evidence for the gesture-to-speech influence comes
from studies in which the availability of gestures was
manipulated (Alibali & Kita, 2010; Alibali, Spencer, Knox,

& Kita, 2011). It was found that the availability of gestures
changed the type of information encoded in speech. More
specifically, when gestures are produced, speakers tended to
encode spatial information that gestures readily had access
to. To date, there is no study that manipulated gesture
structure (as opposed to gesture availability) to examine its
influence on speech production.

Present Study
We will test the prediction made by the IPH (but not by the
LRH and IAH), that the information structure underlying
gesture production can influence the information structure
underlying speech. In doing so, we will use the task of
describing motion events, as in the study described above
(Kita, et al., 2007). Yet how can we measure the analytic
representations underlying speech production?
Bock and Cutting (1992) propose that syntactic processing
units comprise of (finite) clauses. Using a procedure to elicit
verb agreement errors, they found that these errors occurred
more frequently when the head noun and its verb were
separated by a phrase (e.g. "The claim about the stolen
babies was rejected", p. 104) than when they were separated
by a relative clause (e.g. "The claim that wolves were
stealing babies was rejected", p. 104). Assuming a
hierarchical processing structure, they explain this as that
the more information is introduced within a single
processing unit, the more sources of interference there are
between similar, concurrently active elements. In this
example, when the head noun and the local noun are part of
a single clause, their numbers are more likely to interfere
than when they are part of separate clauses. Thus, within a
clause, elements are more likely to interfere than across
clauses. This supports the notion that clauses are the units of
syntactic processing. Following Bock and Cutting (1992),
we will assume finite clauses to be indicative of the
processing units underlying speech.
We instructed participants to either conflate the manner
and path of a motion into a single gesture (Conflated
condition), or to produce one gesture for the manner and a
separate gesture for the path of the motion (Separate
condition) and observed the syntactic packaging of manner
and path in speech. Since the IPH assumes that the
processing units underlying speech and gesture are
coordinated, it predicts this manipulation will affect the
clausal structure of speech, such that conflated gestures tend
to go with single, conflated clauses, whereas separate
gestures tend to go with separate clauses for manner and
path.
The Image Activation Hypothesis may not make specific
predictions as to the difference between the conflated vs.
separate gesture condition. Both the conflated gesture and
separate gesture condition should equally boost the
activation of the imagery of manner and path. More
crucially, the hypothesis does not propose any mechanism
as to how linguistic expressions are influenced by gesture

762

production, aside from the assumption that more strongly
activated imagery leads to better quality descriptions.
The Lexical Retrieval Hypothesis may predict an effect of
gesture production on speech production. Yet this effect is
different from the effect predicted by the IPH. Rather than
the clausal structure of speech being affected by the way
speakers gesture, it may predict that speakers who use
different gestures would activate different lemmas and
would thus use different words.

gesture illustrating the path, while the other gesture shows
the manner of movement'. Note that participants were asked
to gesture differently only. Otherwise, the instructions were
exactly the same in both conditions.
Participants were seated next to a table with a laptop on it,
which showed a Powerpoint presentation. Upon pressing a
button, an animated cartoon played twice, after which the
participant was to describe it to the experimenter, who was
seated across from the participant. Behind the experimenter
was a camera, capturing the participant. The first clip was a
practice clip. If needed, the experimenter gave additional
instructions on how to do the task, by asking specific
questions (e.g. "And how exactly did the figure go around
the tree?") or by describing how the gestures produced by
the participants differed from the gestures requested. The
participant then proceeded to watch and describe the ten
stimulus clips. Afterward, the participant filled out a short
questionnaire, which asked for participants' native language
and whether they were left or right handed. Lastly, they
filled out a consent form. All participants permitted their
data to be used for research and educational purposes.

Method
Participants
Twenty-one native Dutch first-year students (4 male) from
Tilburg University participated in our study as part of their
curriculum. They were aged between 18 and 24 years old
(M = 21.24, SD = 1.61). Four participants were left-handed.
The number of male and left-handed participants was equal
in the two conditions.

Material
The ten stimulus clips that our participants described were
from a set of animated cartoons known as 'the Tomato Man
movies' (Özyürek, Kita, & Allen, 2001). Each clip consisted
of an initial entry event, followed by a target event in which
one of the two figures completes a motion along a certain
path and in a certain manner, and finally a closing event (see
Figure 1).

Coding and Analysis
All recordings were analyzed using Elan (Max Planck
Institute for Psycholinguistics; Wittenburg, Brugman,
Russel, Klassmann, & Sloetjes, 2006). For each description
of a target event, speech was transcribed into finite clauses
and gestures were coded. We used finite verbs to decide on
clause boundaries. Each clause contained one conjugated
verb. Hence, the first two examples in Table 1 (next page)
were both coded as a single clause. Few utterances
contained a praedicativum, as in (1). Al springend is linked
both to the verb and to the noun. Its status is therefore not
entirely clear. It can be thought of as an adjective, a verb or
an adverb (Jansen & Lentz, 2002). Because of this and since
these cases were few, we excluded them from our analyses.
(1) "Al springend
gaat hij omhoog."
while in a jumping manner goes he up.
"(While) jumping he goes up."

Figure 1: Example of a stimulus clip, taken from (Kita, et
al., 2007).

Procedure

For each clause and each gesture, it was determined whether
it contained information on manner, on path, or on both.
Verbal descriptions in which manner and path were solely
expressed in a single clause were coded as conflated.
Descriptions in which there were separate clauses for
manner and path were coded as separate, even if the
description also contained a clause in which the two were
conflated. Descriptions in which either manner or path was
described in a separate clause, yet not both, and in which
there was a conflated clause as well were coded as mixed.
Table 1 provides some of participants' utterances and our
coding. Gestural descriptions were coded analogously, for
whether manner and path were conflated into a single
gesture, expressed in separate gestures or a mixture of both.

Participants came to the lab and were randomly assigned to
one of the two gesture conditions. They first received a
written instruction, after which they were allowed to pose
clarification questions. The instruction explained that the
participant was to watch animated cartoons in which a
cartoon figure sometimes conducted a motion involving
both a certain manner and a certain path of movement. In
the Conflated condition, participants were asked to produce
a hand gesture with their description of such motions, such
that 'the gesture illustrates both the path and manner of
movement at the same time'. In the Separate condition,
participants were requested to produce two different
gestures with their description of the motion, with 'one

763

Table 1: Examples of utterances and our coding. Coded clause boundaries are indicated by forward slashes.
Utterance:

Label:

"het
rode rondje
draait dan
zo
omhoog"
/the
red
circle (+diminuative) turns
then
like this
upwards/
the red circle then twists upwards like this
"en
hij
gaat
zo
springend
omhoog"
/and he
goes
like this
in a jumping manner
upwards/
and he goes jumping upwards like this
"en
die
draait
terwijl
die
naar
boven
gaat"
/and that (pronoun feminine/masculine) turns/
while
that
to
up
goes/
and he turns as he goes up
"en
de
driehoek gaat
omhoog
en
dat
doet
ie door
uh te
springen"
/and the
triangle
goes
up/
and that does
he by
uh to
jump/
and the triangle goes up and that he does by uh jumping
"de
appel die
rolt
en
hij
rolt
van
links
naar rechts omhoog"
/the
apple that rolls/
and he
rolls
from
left
to
right
upwards/
the apple rolls and it rolls upwards from left to right
Occasionally, participants failed to describe both the manner
and the path of a motion in gesture and speech (8 cases).
Also, participants sometimes failed to comply with the
instructions, only producing separate gestures for manner
and path in the Conflated condition (3 cases), or only
producing a conflated gesture in the Separate condition (24
cases). These cases were discarded from our analyses. The
more frequent problems in the Separate condition may
indicate that conflated gestures (along with conflated
speech) are more common among Dutch speakers, similarly
to English speakers (Kita & Özyürek, 2003). The remaining
dataset contained 175 descriptions (verbal and gestural) by
21 participants. To ensure fair comparison between
participants and between conditions, despite an unequal
number of descriptions, we computed the proportion of
verbal expressions of a certain type (conflated, separate,
mixed) for each participant, rather than using the raw
counts. The means of both conditions were compared using
independent-samples T-tests. When Levene's test for
equality of variances was significant, we report the adjusted
statistics.

conflated

conflated
separate:
(manner,
path)
separate:
(path,
manner)
mixed:
(manner,
conflated)

than when they were asked to express manner and path in
two separate gestures (M = .19, SD = .31), t(19) = 6.26, p <
.001. The reverse pattern was found for descriptions in
which manner and path were expressed in separate clauses
(see Table 2). Similar results were obtained when
descriptions on which participants failed to comply with the
instruction were included. We did not find any effects of
gender, or left or right-handedness.

Discussion
Our results show that the way people gesture influences the
way they speak. When asked to divide manner and path
information over two gestures, participants were more likely
to also use two clauses for manner and path. These results
are in line with the Information Packaging Hypothesis (Kita,
2000). Being required to separate manner and path into two
gestures forced speakers to think about the event in a certain
way spatially. That is, it requires them to separately focus
on the path of the motion and the manner of the motion
sequentially, as each unit of information is the base of one
unit in gesture. This differs critically from the conflated
condition, in which participants were asked to conflate
manner and path into a single gesture, which calls for
spatially processing the motion as a whole, that is, a single
unit of information. The Information Packaging Hypothesis
predicts that the analytic processing units underlying speech
tend to converge with the spatio-motoric processing units

Results
Participants produced greater proportions of verbal
descriptions in which manner and path were conflated into a
single clause when they were asked to produce a single
conflated gesture for manner and path (M = .88, SD = .18),

Table 2: The effects of gesture condition (Conflated vs. Separate) on the mean proportions (SD) of verbal descriptions in
which manner and path were expressed in a single clause (conflated), separate clauses (separate) or a combination (mixed).
Verbal descriptions
proportion conflated
proportion separate
proportion mixed

Conflated gesture (N=10)
.88 (.18)
.09 (.11)
.03 (.07)

Separate gestures (N=11)
.19 (.31)
.63 (.31)
.18 (.24)

764

Statistics
t(19) = 6.25, p < .001
t(12.7) = 5.46, p < .001
t(19) = 1.85, p = .08

underlying gesture. We have taken clauses to be a measure
of the analytic processing units (Bock & Cutting, 1992).
When gesture production forced participants to spatially
process the motion as a whole, manner and path were more
frequently conflated into a single clause, reflecting one
analytic processing unit. Yet when gesture forced
participants to process the manner and the path of the
motion separately, they more frequently expressed manner
and path in two separate clauses, reflecting two units in
analytic processing. This supports the prediction made by
the Information Packaging Hypothesis, that the processing
units underlying speech can be adapted to the processing
units underlying gesture.
Our results also support the Interface Model of gesture and
speech production (Kita & Özyürek, 2003). Specifically,
they confirm that the link between the action generator and
the message generator is bidirectional in nature. Earlier
work had already shown that the constraints a language
imposes on what information can be linguistically expressed
within a clause affect gesture production (Kita & Özyürek,
2003) and that the structure of speech could affect the
structure of gesture (Kita, et al., 2007; Özyürek, et al.,
2005). Our current study shows that when gesture
formulation is constrained, this affects speech formulation
as well, exactly as the model would predict.
Since gesture is generally assumed to be less
conventionalized than speech, it may not be as straightforward to see in what kind of naturalistic situations gesture
would impose constraints on speech formulation. However,
there is a growing body of evidence that speakers adapt their
gestures to one another (Holler & Wilkin, 2011; Kimbara,
2008; Mol, Krahmer, Maes, & Swerts, 2012; Parrill &
Kimbara, 2006). When a gesture shape or a structure in
gesture is imitated from another speaker, this may in turn
influence the speech formulation process, potentially
causing speech to converge across interlocutors as a result.
Also, there can be cultural and pragmatic constraints on
gesture (Enfield, Kita, & De Ruiter, 2007; Kita & Essegbey,
2001). More importantly though than gesture imposing
constraints on how information can be expressed, it can
open up new possibilities of organizing information, by
supporting spatio-motoric thinking (Chu & Kita, 2008; Kita,
2000). Our results confirm that speech production can
benefit from gesture this way. This supports theories in
which gesture results from speaker-internal motivations.
Can the current findings on clause structure be accounted
for by the Lexical Retrieval Hypothesis? The Lexical
Retrieval Hypothesis may be supported if the manipulation
of gestures caused different choices of manner verbs in the
two conditions, which in turn lead to different clause
structures. Though, in principle, any Dutch manner verb can
be used in both clausal structures, we examined the manner
verbs in the two conditions. We included all inflections of
manner verbs, such as in (2), as well as manner adverbs, as
in (3).

(2) hij rolt zo
omhoog
he rolls like this upwards
"he rolls up like this"
(3) hij gaat rollend
van de helling
he goes in a rolling manner from the hill
"he goes rolling off the hill"

af
off

The numbers of manner (ad)verbs used in the two
conditions were highly correlated, R(11) = .90, p < .001, see
Table 3. This indicates that the compositions of (ad)verbs
used in the two conditions were very similar. Thus, there is
no support for the idea that gesture affected clause structures
via different choices of manner (ad)verbs.
Can the current findings be accounted for by the Image
Activation Hypothesis? According to this hypothesis,
gestures boost the activation level of the imagery that is
intended to be communicated. This hypothesis does not
specify the relationship between clause structures and
imagery; thus, gesture's effect on clause structure cannot be
accounted for.

Conclusion
Our results demonstrate that gesture production can
influence speech production. Specifically, the way
information was divided over individual gestures affected
the way information was divided into clauses. This supports
the Information Packaging Hypothesis (Kita, 2000), in
which gesture production serves to organize rich spatiomotoric information into packages suitable for speaking,
and the spatio-motoric processing units underlying gesture
production are coordinated with the analytic processing
units underlying speech production. Therefore, these results
also support the view that there are speaker-internal
motivations for gesture production.

Table 3: Manner (ad)verbs used in each condition.

765

Lemma:

Translation:

draaien
springen
rollen
stuiteren
cirkelen
huppen/hoppen
twisten
tuimelen
koprollen
kantelen
buitelen
Total:

turn
jump
roll
bounce
circle
hop
twist
tumble
rollover
topple
tumble

Number of
occurrences:
Conflated
Separate
34
34
13
23
12
16
11
3
8
0
5
6
0
1
0
3
0
1
0
1
0
1
83
89

Acknowledgements

Kita, S., & Özyürek, A. (2003). What does cross-linguistic
variation in semantic coordination of speech and gesture
reveal?: Evidence for an interface representation of spatial
thinking and speaking. Journal of Memory and Language,
47, 16-32.
Kita, S., Özyürek, A., Allen, S., Brown, A., Furman, R., &
Ishizuka, T. (2007). Relations between syntactic encoding
and co-speech gestures: Implications for a model of
speech and gesture production. Language and Cognitive
Processes, 22(8), 1212-1236.
Krauss, R. M., Chen, Y., & Gottesman, R. F. (2000).
Lexical gestures and lexical acces: A process model. In D.
McNeill (Ed.), Language and gesture. New York:
Cambridge University Press.
Levelt, W. J. M. (1989). Speaking. Cambridge, MA: MIT
Press.
Max Planck Institute for Psycholinguistics, Nijmegen, The
Netherlands. http://www.lat-mpi.eu/tools/elan/
McNeill, D. (1992). Hand and Mind: What gestures reveal
about thought. Chicago and London: The University of
Chicago Press.
McNeill, D. (2005). Gesture and Thought. Chicago and
London: University of Chicago Press.
McNeill, D., & Duncan, S. (2010). Gesture and growth
points in language disorders. In J. Guendouzi, F. Loncke
& M. J. Williams (Eds.), The handbook of
psycholinguistic and cognitive processes. New York,
London: Psychology Press.
Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2012).
Adaptation in gesture: Converging hands or converging
minds? Journal of Memory and Language, 66(1), 249264.
Özyürek, A., Kita, S., & Allen, S. (2001). Tomato Man
movies: Stimulus kit designed to elicit manner, path and
causal constructions in motion events with regard to
speech and gestures. Nijmegen, The Netherlands: Max
Planck Institute for Psycholinguistics, Language and
Cognition group.
Özyürek, A., Kita, S., Allen, S., Furman, R., & Brown, A.
(2005). How does linguistic framing of events influence
co-speech gestures? Insights from cross-linguistic
variations and similarities. Gesture, 5(1), 215-237.
Parrill, F., & Kimbara, I. (2006). Seeing and hearing double:
The influence of mimicry in speech and gesture on
observers. Journal of Nonverbal Behavior, 30(4), 157166.
Wittenburg, P., Brugman, H., Russel, H., Klassmann, A., &
Sloetjes, H. (2006). ELAN: a Professional Framework for
Multimodality Research. Paper presented at the LREC
2006, Fifth International Conference on Language
Resources and Evaluation.

We gratefully acknowledge all participants for allowing us
to analyze their data, we thank Pieter Spronck for helping
with the analysis of word frequencies and Maria Mos, Jorrig
Vogels and Joost Schilperoord for sharing their knowledge
on clause structures in Dutch. We thank the anonymous
reviewers for their comments and suggestions.

References
Alibali, M. W., & Kita, S. (2010). Gesture highlights
perceptually present information for speakers. Gesture,
10(1), 3-28.
Alibali, M. W., Spencer, R. C., Knox, L., & Kita, S. (2011).
Spontaneous Gestures Influence Strategy Choices in
Problem Solving. Psychological Science, 22(9), 11381144.
Bock, K., & Cutting, J. C. (1992). Regulating mental
energy: Performance units in language production.
Journal of Memory and Language, 31, 99-127.
Chu, M., & Kita, S. (2008). Spontaneous gestures during
mental rotation tasks: Insights into the microdevelopment
of the motor strategy. Journal of Experimental
Psychology: General, 137(4), 706-723.
Chui, K. (2005). Temporal patterning of speech and iconic
gestures in conversational discourse. Journal of
Pragmatics, 37(6), 871-887.
De Ruiter, J. P. (1998). Gesture and Speech Production.
Unpublished Doctoral Dissertation. University of
Nijmegen.
Enfield, N. J., Kita, S., & De Ruiter, J. P. (2007). Primary
and secondary pragmatic functions of pointing gestures.
Journal of Pragmatics, 39, 1722-1741.
Freedman, N. (1977). Hands, words, and mind: on the
structuralization of body movements during discourse and
the capacity for verbal representation. In N. Freedman &
S. Grand (Eds.), Communicative Structures and Psychic
Structures: A Psychoanalytic Approach. New York and
London: Plenum Press.
Holler, J., & Wilkin, K. (2011). Co-speech gesture mimicry
in the process of collaborative referring during face-toface dialogue. Journal of Nonverbal Behavior, 35, 133153.
Jansen, F., & Lentz, L. R. (2002). Braad dikwijls
bedruipende. Twee manieren om gelijktijdige handelingen
aan
te
duiden:
deelwoordconstructies
en
onderconstructies. Neerlandistiek.nl, 6(2), 1-26.
Kendon, A. (2004). Gesture: Visible action as utterance.
Cambridge: Cambridge University Press.
Kimbara, I. (2008). Gesture form convergence in joint
description. Journal of Nonverbal Behavior, 32(2), 123131.
Kita, S. (2000). How representational gestures help
speaking. In D. McNeill (Ed.), Language and Gesture.
Cambridge: Cambridge University Press.
Kita, S., & Essegbey, J. (2001). Pointing left in Ghana: How
a taboo on the use of the left hand influences gestural
practice. Gesture, 1, 73-94.

766

