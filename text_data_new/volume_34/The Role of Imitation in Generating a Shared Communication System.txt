UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Role of Imitation in Generating a Shared Communication System

Permalink
https://escholarship.org/uc/item/1zm532mm

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Morita, Junya
Konno, Takeshi
Hashimoto, Takashi

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Role of Imitation in Generating a Shared Communication System
Junya Morita, Takeshi Konno, Takashi Hashimoto
{j-morita,t-konno,hash}@jaist.ac.jp
School of Knowledge Science, Japan Advanced Institute of Science and Technology
1-1 Asahidai, Nomi, Ishikawa 923-1292, Japan
that a type of imitation called “role-reversal”, in which the
child aligns herself with the adult speaker, is essential for producing a communicative symbols.
However, there is an important difference between language acquisition and forming a new communication system.
In language acquisition, there is a clear distinction between
a learner and an instructor (or a demonstrator). On the other
hand, a new communication system usually emerges from a
situation where no predeﬁned roles exist. Although several
studies concerning imitation exist, only few studies have dealt
with this situation.
We argue that the model-based approach is the best method
to explore the role of imitation in an interactive situation.
From this perspective, we present a computational model, in
which two agents autonomously assign roles to themselves.
Agents also posses general learning mechanisms such as reinforcement learning and instance-based learning to form a new
communication system. By incorporating imitative learning
into these general learning mechanisms, we investigate the
role of imitation in the process of forming a new communication system. Furthermore, we compare the constructed model
against a human experiment. The results of this comparison
reveal the cognitive mechanism involved in the formation of a
human communication system. Before presenting our model,
we will provide an overview of our previous experiment.

Abstract
What types of learning or reasoning are involved in forming a new communication system? To answer this question,
this paper presents a computational model for forming a new
communication system. The model was developed with ACTR (Adaptive Control of Thought-Rational). In the model,
two agents autonomously assign their roles to themselves.
Agents also posses general learning mechanisms implemented
in ACT-R. By incorporating imitative learning into these general learning mechanisms, this paper studies the role of imitation in the process of forming a new communication system.
Finally, we compared the proposed model against a human experiment. The results of the simulation indicate that through
imitation, after a short period of interaction, an isomorphic
system is created. The result of the simulation also suggests
the existence of imitation in the process of forming a human
communication system.
Keywords: Communication; Imitation; ACT-R

Introduction
People try to communicate with others even when they do
not have a common language. They also understand intentions of others through repeated interactions. Apparently, humans have the ability to develop a new communication system where only a few common ground rules are shared in
advance. How can a new communication system be developed? What types of learning or reasoning are involved in
this process? Addressing these questions will contribute not
only to understand the origins of our communication but also
to predict changes in our communication in this era of globalization.
Some researchers have examined these questions by designing communication environments in the laboratory (for
a review Scott-Phillips & Kirby, 2010). For example,
Galantucci (2005) conducted an experiment to observe the
formation of communication systems in which a pair of participants communicated through a medium that restricted the
use of standard communication means such as utterances and
letters. He observed the process of forming a new communication system, and discussed that implicit information was
conveyed through routine behavior, and reported that a temporal order of messages was built into communication systems. However, this study cannot answer the questions above
because he did not identify the cognitive mechanism involved
in this process.
The present study focuses on imitation as the type of
reasoning in forming a new communication system. Imitation has been investigated in various ﬁelds of cognitive
science (Barnes & Thagard, 1997; Gergely, Bekkering, &
Király, 2002; Tomasello, 1999; Thagard, 2001). For example, Tomasello (1999) described the role of imitation in language acquisition by the infant/child. He especially argued

Experiment
The present study simulates the experiment reported in
Konno, Morita, and Hashimoto (in press), where we modiﬁed and used a coordination game taken from Galantucci
(2005). As in Galantucci’s study, the game environment contained two characters, each controlled by a players, and four
intercommunicating rooms. The game was composed of several repeated rounds. At the beginning of a round, characters were randomly placed in two different rooms. Players
were unaware of the location of each other and aimed to bring
their characters to the same room. The characters could not
move to rooms that were located diagonally. Owing to this
constraint, players need to communicate before moving their
characters.
Figure 1 presents the ﬂow of each round consisting of three
steps: step 1 for exchanging messages; step 2 for moving
characters; and step 3 for conﬁrming the result of the movement. Among these steps, step 1 is the most crucial for the
success of this task. In this step, the two players construct
”
their own messages composed of two ﬁgures such as “
using six available ﬁgures: , , , , , and . The
meanings and usage of the ﬁgures were not shared among

779

Figure 2: Schema of the model.
The results of the experiment conﬁrmed the success of
forming a shared symbol communication system, indicating
the differences of the performance between the three tests.
The detailed results are shown in a latter section.

Figure 1: A round of the coordination game consists of three steps.
In step 1, to create a message, participants select ﬁgures by clicking
the segments indicated by “Yours”. Each time a participant clicks a
segment, a ﬁgure appears in the order of , , , , , and .
In step 2, a character (blue boxes indicated by “You”) is moved by
drag-and-drop. In step 3, the result of the movement are shown to
the participants. Blue boxes (“You-Pre” and “You-Post”) and green
boxes (“Pat-Pre” and “Pat-Post”) represent a movement made by the
participant and the partner, respectively. In the case of this ﬁgure,
they succeeded in moving to the same room (the upper-right room).

Model
Architecture
The task presented in the previous section requires symbolic
learning for constructing a new symbol system. In addition,
according to Galantucci (2005)’s report, implicit learning,
which is not present in symbolic systems, possibly plays a
role in this task. In this study, we construct a model using
ACT-R (Adaptive Control of Thought-Rational: Anderson,
2007), which integrates symbolic and subsymbolic learning
mechanisms.
ACT-R is composed of several independent modules. The
modules used in this study are presented in Figure 2. Except
for the production module, each module has a buffer to temporarily store information called a chunk (a set of slot-value
pairs). The production module integrates the other modules
using production rules, which consist of a condition-action
pair that is used in sequence with other productions to perform a task. The conditions and actions in production rules
are speciﬁed along with buffer contents of each module.
In our model, two independent agents interact through a
simulated task environment developed in the ACT-R graphical user interface (AGI). AGI provides screens that hold visual information as chunks. In this study, the locations of the
characters and messages associated with each agent are displayed on the screen. An agent’s visual module searches for
a character and stores its location (room) into a visual buffer.
The visual buffer also stores the symbols that compose a message, attending to the screen locations where the ﬁgures appear. The simulated task environment also provides a virtual
mouse to change the ﬁgures and move the characters on the
screen.
Visual information stored in the visual buffer are transferred to the goal buffer through the production module. The
goal buffer holds the goal of the current task and other taskrelated information. Speciﬁcally, our model has nine slots for

the participants in advance. Each player could send only one
message per round, but they could take turns in exchanging
messages. A message sent by the ﬁrst sender instantly appeared on the screen of the other player. The second sender
could compose her/his message after observing the message
of her/his partner (see the participant 2 in Figure 1). By
this turn-taking approach (role-settings), the ﬁrst sender could
transmit her/his current room location, and the second sender
could transmit the destination while taking into account the
current room location of her/his partner. Importantly, the participants were not assigned their roles by the experimenter.
They were required to assign their roles by themselves.
The experimental procedure consisted of one trial session
and three test sessions. In the trial session, the participants
(21 pairs) attempted to develop a communication system
within one hour time limit. When characters moved to the
same room, players received two points, otherwise they lost
one point, but the scores did not drop below zero. The trial
session was terminated when the score reached 50 points.
Test sessions were conducted subsequently. The TNM (Test
with No Message exchanges) did not allow message exchanges. In the TSM (Test with Simultaneous Message exchanges), messages were displayed on the screen of each
player after both players had sent their messages. Thus, taking turns in sending messages was prevented in this test session. The TIM (Test with Immediate Message exchanges) was
conducted under the same conditions as in the trial session.
Each test had 12 rounds that contained all possible room combinations for two characters. The order of appearances was
set at random.

780

Figure 3: Process of the model. Circles indicate decisions
based on conﬂict resolution.
the goal buffer: four slots for storing room locations (initial
(from)-destination (to) × self-partner), four slots for storing
the symbols (left-right × self-partner), and a slot for encoding
the order for exchanging messages.
The declarative module stores past states of the goal
buffer as instances. It also stores chunks representing task
constraints such as path information indicating a room the
characters can move to (e.g., f rom
to
isa path) or
ﬁgures the agent can use to construct a message (e.g.,
isa f igure). An agent uses these chunks (i.e., declarative
knowledge) to chose its destination and construct a message.

Figure 4: Three types of decision strategies.
and their messages. Concurrently, the ﬁrst sender predicts
the message that s/he will receive from her/his partner. The
predicted message is checked against the message received
in step 2. When the received message is inconsistent with
the predicted message, the agent makes a new decision about
her/his destination.
Summarizing, there are three situations where agents make
decisions. In these situations, agents apply one of the three
decision strategies shown in Figure 41 . Every decision strategy begins by retrieving chunks from the declarative module
by using the current goal buffer as a cue. In the trial-error
strategy, chunks concerning task constraints (chunks representing a path and symbols) are retrieved, and are used to ﬁll
in the blank goal slots. In the instance-based strategy, the
agent retrieves an instance that is consistent with the current
goal buffer. The retrieved instance is used to ﬁll slots concerning a destination and symbols. The imitation strategy
also uses an instance, but the roles of an agent and her/his
partner are reversed when retrieving and ﬁlling slots.
The implementation of the trial-error and instance-based
strategies follow a past study on decision making using ACT-

Process of the model
Overview We prepared 169 productions that construct the
process presented in Figure 3. This process is divided into
three steps just as in the original experiment (Figure 1).
In addition, the operation of taking turns to send a message is autonomously managed by this process. There are
two paths in this process. The left path is for the ﬁrst sender
and the right path is for the second sender. The choice of
path is made by conﬂict resolution, which is a comparison
of two conﬂicting productions with noise added utilities. In
each phase of the path of the ﬁrst sender, there is a conﬂict
(indicated by circles) between keeping the path of the ﬁrst
sender and changing to the path of the second sender. If in
any of these the agent selects the path of the second sender,
the agent tries to perceive the message of her/his partner from
the screen. When the agent obtains the message of her/his
partner, s/he realizes that s/he is the second sender (ﬁlls the
order slot with “2nd”). Otherwise, s/he resolves a conﬂict by
waiting for the message of her/his partner and changing to the
path of the ﬁrst sender. This conﬂict loop continues until one
of the agents sends a message.

1 Figure 4 explains each strategy by using an example of the ﬁrst
sender in step 1. In the case of the second sender in step 1, a partner’s
message is added to the retrieval cue. The ﬁrst sender in step 2 uses
a message as a cue to retrieve an instance and make a new decision
about the destination.

Decision making In step 1, regardless of the contents of the
order slot, both agents make decisions about their destinations

781

R (Lebiere, Gonzalez, & Martin, 2007; Reitter & Lebiere,
2011). The imitation strategy is constructed according to the
role-reversal imitation described by Tomasello (1999).

Table 1: The performance in the trial session. The numbers
in parentheses indicate standard deviation.
Success rates
Round

Learning The decision making strategy implemented in
this model changes through a learning process. This model
uses the standard symbolic and subsymbolic learning mechanisms of ACT-R. Symbolic learning includes instance-based
learning and production compilation. Subsymbolic learning
includes utility learning and activation updating.
Instance-based learning and utility learning occur at the
end of each round (see Figure 3). In a success round (two
characters meet in the same room), the agent stores a state of
the goal buffer into the declarative module. Conversely, in a
failure round (two characters move to different rooms), the
agents do not store an instance. Regardless of the results of
the movement, the utilities, which are used in conﬂict resolution, are updated by the following formula.
Ui (n) = Ui (n − 1) + α[Ri (n) −Ui (n − 1)])
(1)

Trial-error
0.00
NA
(NA)

Instance
1.00
72.08
(16.95)

Imitation
1.00
54.50
(15.93)

Simulation
Simulation conditions
To explore the cognitive process behind forming a communication system, we set up the following three models controlling the decision strategies presented in Figure 4.
• Trial-Error model: This model does not have a decision
strategy other than the trial-error strategy. The agent tries
to construct a communication system from subsymbolic
learning and production compilation.
• Instance model: This model, in addition to the trial-error
strategy, also has the instance-based strategy. The agent
ﬁrst tries the instance-based strategy. If the instance-based
strategy fails, the agent chooses her/his destination and
message based on the trial-error strategy.
• Imitation model: This model extends the instance model
by adding the imitation strategy. The agent ﬁrst tries to
chose her/his destination and message using the instancebased strategy. If the agent fails to retrieve an instance,
the imitation strategy is applied. When all other decision
strategies fail, the agent uses the trial-error strategy.
By comparing the imitation model with the other two models,
we can identify the role of imitation in forming a shared communication system. We also identify the required learning
mechanism from the difference between the trial-error model
and the other models. Furthermore, by comparing the experimental data, we reveal the features of human communication
systems.
In this simulation, each model runs 100 times. In each run,
the model continued the trial session for 3,600 sec4 or until
the scores reached 50 points. Following the trial session, the
model was engaged in three test sessions similar to the experiment presented in the section 2.

where α is the learning rate and Ri (n) is the reward value
given to production i at time n. In a success round, productions used in the round receive positive rewards (Ri(n) = 10).
Otherwise, productions used in the round receive negative rewards (Ri(n) = 0).
As instances are accumulated, the chance to retrieve an
instance increases, but utility learning does not directly affect decision making. In each decision strategy, there are
no conﬂicting productions. Instead, each decision strategy
needs to select declarative chunks because a single state of
the goal buffer usually matches several chunks. The selection of chunks is controlled by the activation values of the
chunks2 . In ACT-R, an activation value is updated by the following formula.
n

Bi = ln( ∑ t −d
j ) + βi

Data
0.66
48.42
(13.36)

(2)

j=1

where n is the number of presentations of chunk i, t j is the
time since the jth presentation, and d is the decay parameter3 . This value is determined by the frequency and recency
of a particular chunk. Therefore, an agent usually retrieves
a chunk that has been frequently observed or retrieved in the
past round.
Even though utility learning does not directly affect decision strategies, there is a possible effect that occurs through
production compilation. Production compilation is a mechanism that creates a new production integrating sequentially
ﬁring two productions. It typically occurs when the ﬁrst production requests a retrieval and the second harvests it. The
resulting production is specialized to include the retrieved
information. In other words, the declarative knowledge is
proceduralized into the production. Because compiled productions receive rewards, it is possible to change behavior
through production compilation and utility learning.

Results
Performance of trial session Table 1 shows the proportion
of runs/pairs whose scores reached 50 points, which is a termination condition for the trial session. It also presents the
numbers of rounds required to reach the termination condition. All runs with the trial-error models failed to form a
communication system whereas all runs with the instance and
imitation models succeeded in completing the session. Even
though there were some pairs that did not reach the termination condition, the number of rounds required to complete
the session in the experiment (data) was smaller than that in
the instance and imitation models. Compared to the instance
model, the imitation model ﬁnished the session in less number of rounds, and the difference in the number of rounds

2 The simulation uses a summation of this base-level activation
and the spreading activation values
3 In this study, we use d = 0.50 and β = 0.00

4 We

782

used the simulation time estimated by ACT-R.

Sucess ratio
0.0 0.2 0.4 0.6 0.8 1.0

Table 2: Indices of sharing when using symbols.
Trial−Error (n = 100)
Instance−based (n = 100)
Imitation (n = 100)

Data (n = 21)
Chance

Single
Combination

Data
0.80
(0.25)
0.63
(0.31)

Trial-error
0.92
(0.04)
0.52
(0.19)

Instance
0.76
(0.14)
0.28
(0.19)

Imitation
0.94
(0.07)
0.84
(0.11)

Table 3: Bias of using symbols.
TNM
Tnm

TSM
Tsm

Single

T
Tim
IM

Figure 5: Performance of three test sessions. Solid lines in the

Combination

Usage rate
0.0 0.1 0.2 0.3 0.4 0.5

graph indicate the results of the experiment. Error bars and dashed
thin lines represent the standard error of means. The dashed thick
line indicates chance-level performance (2/9).

Trial−Error (n = 100)
Instance−based (n = 100)
Imitation (n = 100)

1:

2:

Trial-error
0.07
(0.02)
0.43
(0.07)

Instance
0.31
(0.12)
1.43
(0.26)

Imitation
0.33
(0.17)
1.57
(0.30)

and computed symbol sharing indices within pairs. The indices were computed as the dot-product of two unit-vectors
that consisted of the frequencies of using each symbol. These
indices were computed not only for single symbols (e.g., ,
) but also for combinations of symbols (e.g.,
).
Table 2 shows the computed indices of symbol sharing.
The imitation model has the highest indices for both the single symbol and combination of symbols. Conversely, the indices in the instance model are the lowest. This suggests that
an agent in the imitation model created an isomorphic symbol
system with a partner. The values obtained in the experiment
are between those of the instance and imitation model, implying that imitation certainly occurred in the experiment.
The other explanation of the high indices of sharing symbols is that agents/participants chose symbols according to
a uniform-distribution. To exclude this possibility, we computed a bias index using the geometric mean of two KullbackLeibler divergences of the probability distributions P and E.
√
B = DKL (P1 ||E) · DKL (P2 ||E) ,

Data (n = 21)

3:
4:
5:
Order of the ﬁgures

Data
0.48
(0.22)
1.81
(0.48)

6:

Figure 6: Rate of using each symbol. Solid lines in the graph indicate the data obtained in the experiment. Error bars and dashed thin
lines represent the standard error of means.

between the experimental data and the imitation model is
quite small (i.e., 48.42 and 54.50 respectively, compared with
72.08 in the instance model).
Performance of tests sessions Figure 5 presents the results
of the three tests. The experimental data reveals signiﬁcant
differences between the three tests. The imitation and the
instance models reproduced these differences well. From
the difference between TNM and TIM , we conﬁrmed that the
pairs/models formed effective symbol communication systems. In addition, from the difference between TSM and TIM ,
we conﬁrmed that the pairs/models take turns in transmitting
messages. In contrast to the other models/data, we did not observe the differences of the three tests in the trial-error model.

DKL (Pi ||E) =

N

∑ Pi (n) log

n=1

Pi (n)
,
E

(3)

where Pi is the probability distribution of the use of symbols
of agent/participant i, E is the uniform distribution, and N is
the number of bins of the probability distributions5 . If the distribution P deviated from the uniform distribution, the index
would increase.
The results are presented in Table 3. The trial-error model,
which had the high symbol sharing indices, has the lowest
values for both the single symbol and combination of symbols, indicating that the choice made in the trial-error model
was less biased. Contrary to the trial-error model, the other
two models and the experiment were biased towards using
speciﬁc symbols, indicating that they communicated with a
small number of symbols.

Messages constructed in the trial session To examine the
messages created in each model/experiment, we ﬁrst computed the frequency of using each symbol in the trial session.
From Figure 6, we can observe the decrease in the frequencies with respect to the order of the ﬁgures (see the caption of
Figure 1). Using the symbols listed in the earlier order is considered as an adaptive behavior that reduces the time to construct a message. The three models reproduced this behavior.
We postulate that this behavior is derived from the activation
updating mechanism. As shown in formula 2, activation values are inﬂuenced by the frequencies of observing/retrieving
chunks. Hence, symbols listed in the earlier order usually
receive higher activation values.
We examined this distribution for each participant/agent

Discussion and Conclusions
This study constructed a model that forms a new communication system through interactive coordination. To date, many
5 For the distribution of using a single symbol, E = 1/6 and N =
6. For the distribution of using a combination of symbols, E = 1/36
and N = 36

783

models for language evolution have been developed (for a review Steels, 2011). In addition, there exists a research work
that uses ACT-R to simulate experiments of forming a communication system (Reitter & Lebiere, 2011). However, these
researchers did not deal with a situation with spontaneous
turn-taking or role-setting operations. Most of the previous
models assign roles to agents, such as director or matcher,
using simulation parameters.
Unlike the previous studies, we dealt with a situation where
roles are autonomously assigned. In such a situation, agents
efﬁciently develop a shared communication system through a
two-way imitation, which uses a single instance in two ways
by reversing roles. It reduces trial-errors, and results in a
faster forming process as presented in Table 1. In addition,
differently from the instance model, the imitation model create an isomorphic symbol system as indicated by Table 2.
Summarizing these results, we conclude that with few interactions, imitation can create an isomorphic symbol system.
Moreover, the comparison of the models with the experiment revealed the existence of imitation in the formation of
a human communication system. Table 2 showed the apparent difference in the sharing index between the instance
model and the experimental data. This result is consistent
with previous laboratory experiments, in which participants
used similar symbols in pairs through interactions (Fay, Garrod, Roberts, & Swoboda, 2010; Garrod, Fay, Lee, & Oberlander, 2007).
An additional ﬁnding was observed from the trial-error
model. Unlike the imitation and the instance models, the trialerror model failed to construct a communication system. All
models possess a common subsymbolic learning that updates
activations of chunks and utilities of compiled productions.
Therefore, this difference indicates an advantage of symbolic
learning. Our results suggest that subsymbolic learning by
itself have a limitation in constructing a communication system. Rather, subsymbolic learning are used to adapt to the
structure of the environment as shown in Figure 6. We consider that this adaptivity provides a scaffold for forming a new
symbolic communication system (Konno et al., in press).
There are several limitations in this study. We could examine neither the syntax (combination rules of symbols) nor the
symbol-meanings mappings. These important features of human communication systems, namely language, are difﬁcult
to be captured by simple statistics. We need analysis methods
to understand how a new language emerges in an experiment
or computer simulation.
To extend our model to more complex situations, the goal
buffer of the model should be hierarchically decomposed.
The current design of the goal buffer cannot be applied to
a complex situation where many symbols are combined. Imitation strategy also needs to include more detailed processes.
We believe that the theory of analogical reasoning (Gentner,
1983) can be applied to a model of a complex imitation strategy. There is some previous research that point out that imitation is a type of analogical mapping (Barnes & Thagard,

1997; Thagard, 2001). It is a big challenge for the broad cognitive science community to examine how analogical mapping is changed through symbolic and subsymbolic learning
when forming a new language.

Acknowledgment
This work was supported by a Grant-in-Aid for Scientiﬁc Research on Innovative Areas “The study on the neural dynamics for understanding communication in terms of complex
hetero systems (No.4103)” (21120011) of The Ministry of
Education, Culture, Sports, Science, and Technology, Japan.

References
Anderson, J. R. (2007). How can the human mind occur
in the physical universe? New York: Oxford University
Press.
Barnes, A., & Thagard, P. (1997). Empathy and analogy.
Dialogue: Canadian Philosophical Review, 705–720.
Fay, N., Garrod, S., Roberts, L., & Swoboda, N. (2010).
The interactive evolution of human communication systems. Cognitive Science, 34(3), 351–386.
Galantucci, B. (2005). An experimental study of the emergence of human communication systems. Cognitive Science, 29(5), 737–767.
Garrod, S., Fay, N., Lee, J., & Oberlander, J. (2007). Foundations of representation: Where might graphical symbol
systems come from? Cognitive Science, 31, 961–987.
Gentner, D. (1983). Structure-mapping: A theoretical framework for analogy. Cognitive Science, 7, 155–170.
Gergely, G., Bekkering, H., & Király, I. (2002). Rational
imitation in preverbal infants. Nature, 415, 755.
Konno, T., Morita, J., & Hashimoto, T. (in press). Symbol communication systems integrate implicit information
in coordination tasks. In Advances in cognitive neurodynamics (iii). Springer.
Lebiere, C., Gonzalez, C., & Martin, M. (2007). Instancebased decision making model of repeated binary choice.
Proceedings of the 8th International Conference on Cognitive Modeling.
Reitter, D., & Lebiere, C. (2011). How groups develop a
specialized domain vocabulary: A cognitive multi-agent
model. Cognitive Systems Research, 12, 175–185.
Scott-Phillips, T. C., & Kirby, S. (2010). Language evolution
in the laboratory. Trends in Cognitive Sciences, 14(9), 411–
417.
Steels, L. (2011). Modeling the cultural evolution of language. Physics of Life Reviews, 8(4), 339–356.
Thagard, P. (2001). Emotional analogies and analogical inference. In D. Gentner, K. J. Holyoak, & B. N. Kokinov
(Eds.), (pp. 335–362). The analogical mind Perspectives
from cognitive science.
Tomasello, M. (1999). The cultural origins of human cognition. Harvard University Press.

784

