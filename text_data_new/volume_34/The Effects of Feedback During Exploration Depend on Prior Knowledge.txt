UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Effects of Feedback During Exploration Depend on Prior Knowledge

Permalink
https://escholarship.org/uc/item/80g2f0cj

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Fyfe, Emily
Rittle-Johnson, Bethany

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Effects of Feedback During Exploration Depend on Prior Knowledge
Emily R. Fyfe (Emily.R.Fyfe@Vanderbilt.Edu)
Bethany Rittle-Johnson (Bethany.Rittle-Johnson@Vanderbilt.Edu)
Department of Psychology and Human Development, Vanderbilt University, Peabody College #552, 230 Appleton Place
Nashville, TN 37203-5701 USA
Abstract

1998; Schwartz & Martin, 2004; Schwartz, Chase, Oppezzo,
& Chin, 2011). For example, college students who explored
novel examples learned more from a subsequent lecture than
students who merely summarized a relevant text prior to the
lecture (Schwartz & Bransford, 1998). Further, the timing of
exploration and instruction matters. For example, children
in elementary school benefited more from solving
unfamiliar math problems before receiving instruction rather
than vice versa (DeCaro & Rittle-Johnson, 2011).
However, questions remain regarding how and for whom
this form of guided discovery is effective. First, should any
guidance be provided during the exploratory activity?
Mayer’s review (2004) indicates that it is the guidance
provided during exploratory problem solving that is crucial.
Second, for whom is this guidance during exploration most
advantageous? As noted by Cronbach and Snow (1977),
often “the instructional approach that is best on the average
is not best for all persons” (p. 1).

Providing exploratory activities prior to instruction has been
shown to facilitate learning. However, questions remain
regarding the provision of guidance during the exploration
phase. In this study, we replicated and extended a previous
experiment by examining the effects of feedback during
exploratory problem solving for children with varying levels
of prior knowledge. Ninety-five children (M age ≅	  8 yrs)
solved 12 novel math problems and then received brief
conceptual instruction. After solving each problem, they
received (a) no-feedback, (b) outcome-feedback, or (c)
strategy-feedback. Consistent with the previous experiment,
the results resembled an aptitude by treatment interaction.
Feedback during exploration prior to instruction improved
children’s procedural knowledge, but only for those with low
prior knowledge. For children with higher prior knowledge,
no feedback resulted in better procedural knowledge. Results
suggest that providing feedback may not always be optimal.
Keywords: Guided Discovery Learning; Feedback; Aptitude
by Treatment Interaction; Math Equivalence.

Feedback and Prior Knowledge

Guided Discovery Learning

Feedback is touted as one form of guidance that may be
particularly beneficial during exploration. Feedback is any
information about performance or understanding that the
learner can use to confirm, reject, or modify prior
knowledge. For example, Alfieri et al. (2011) specifically
recommend “providing timely feedback” as an optimal
approach to learning (p. 13). Similarly, Mayer (2004) cites
feedback as an effective tool (among others) for keeping
learners on track. Further, past research indicates that
feedback’s primary function is to identify errors and
encourage the adoption of correct alternatives (e.g.,
Kulhavy, 1977), which may be particularly helpful when
exploring a novel problem space. Given these positive
effects, it seems likely that providing feedback during
exploration would be universally beneficial.
However, a growing body of research indicates that the
effects of feedback depend on learners’ prior domain
knowledge (e.g., Fyfe, Rittle-Johnson, & DeCaro, 2011;
Kraise, Stark, & Mandl, 2009; Luwel et al., 2011). For
example, college students with low prior knowledge learned
more about statistics if they received feedback during
problem solving than if they did not. However, students
with higher prior knowledge did not benefit from such
feedback (Kraise et al., 2009). Similarly, Luwel et al. (2011)
examined children’s performance on a numerosity judgment
task that could be solved using one of two correct strategies.
Children who knew neither strategy at pretest benefited
greatly from feedback in terms of correct strategy selection,

An emerging consensus suggests that people learn best
through some form of guided discovery, which is defined as
exploratory learning with supplemental instructional
guidance. Learning tasks are exploratory if learners have not
received instruction on how to complete them and
instructional guidance encompasses a variety of tools, from
in-depth instruction manuals to minimal feedback or hints.
For example, Mayer’s review (2004) suggests a “mixture of
guidance and exploration is needed” (p. 17). Additionally,
Alfieri et al.’s (2011) recent meta-analysis revealed the
superiority of guided discovery over both pure discovery
learning and pure direct instruction.
Providing exploratory activities prior to instruction is one
form of guided discovery that has been recommended by
researchers in education and cognitive psychology alike
(e.g., Hiebert & Grouws, 2007; Schwartz & Bransford,
1998), and it is the form we focus on in this study. For
example, several mathematics education researchers
suggest, “each person must struggle with a situation or
problem first in order to make sense of the information he or
she hears later” (Stigler & Hiebert, 1998, p. 3). Similarly,
Schwartz and Bransford (1998) suggest that exploratory
activities facilitate the development of differentiated
knowledge of the target problem space, which prepares
learners for subsequent instruction.
There is a growing body of evidence to support the claim
that exploration prior to instruction is beneficial (e.g.,
DeCaro & Rittle-Johnson, 2011; Schwartz & Bransford,

348

but feedback had a much weaker effect for children who
already knew the strategies at pretest. Together, these
studies suggest that learners with low prior knowledge
should benefit from feedback during exploration, but
learners with higher prior knowledge may not.
This idea is consistent with past work on aptitude by
treatment interactions (Cronbach & Snow, 1977), which
occur when instructional treatments have positive effects for
one kind of person, but neutral or even negative effects for
another. Importantly, these interactions often occur in the
context of differing levels of external guidance. For
example, Snow and Swanson (1992) suggest tutors “should
provide more scaffolding for less able learners and less
scaffolding for more able learners” (p. 610). A large number
of aptitude by treatment interactions involve interactions
between instructional guidance and learners’ prior
knowledge in the target domain (Kalyuga, 2007). For
example, learners with low prior knowledge learn more
from studying structured worked examples than from
solving problems on their own. However, as knowledge
increases, independent problem solving becomes the
superior learning activity (e.g., Kalyuga & Sweller, 2004).
In general, this work supports the notion that providing
guidance (i.e., feedback) during exploration prior to
instruction may help learners with low prior knowledge, but
learners with higher prior knowledge may not need it.

by brief conceptual instruction (Fyfe et al., 2011). The
session was identical for all children with the exception that
the feedback provided after each problem differed by
condition. In the strategy-feedback condition, children
received feedback on how they solved each problem. In the
outcome-feedback condition, children received feedback on
their answer to each problem. In the no-feedback condition,
children did not receive feedback and were simply told to go
on to the next problem. After the tutoring session, children
completed a posttest (immediately and after a 2-week delay)
that assessed conceptual and procedural knowledge of math
equivalence. Conceptual knowledge is an understanding of
the principles governing a domain and procedural
knowledge is the ability to execute action sequences to
correctly solve problems (e.g., Rittle-Johnson et al. 2011).
In line with our hypothesis, the effects of feedback on
procedural knowledge depended upon prior knowledge. For
low-knowledge children, feedback during exploration
improved their procedural knowledge relative to no
feedback. In contrast, for children with higher prior
knowledge, no feedback resulted in superior performance
than feedback, though this effect was slightly stronger for
strategy-feedback than outcome-feedback. There were few
effects on children’s conceptual knowledge. Thus, the
results resembled an aptitude by treatment interaction.
Children with low knowledge benefitted from receiving
feedback, but children with higher knowledge benefitted
more from exploring independently without feedback.
Although we predicted that prior knowledge would
moderate the impact of feedback, we did not have a prior
reason to expect a reversal such that feedback would
actually harm learning for children with higher prior
knowledge. Also, several limitations in the design
constrained the strength of the conclusions. First, the
manipulation was not as clean or as strong as it could have
been. For example, all children were asked to report how
they solved each problem, which inevitably guided all
children’s attention to their strategies. The strategy-feedback
manipulation would be stronger if only children in the
strategy-feedback condition were encouraged to attend to
their strategy use. Also, the feedback provided in both
feedback conditions was relatively vague and not specific to
the child’s response. For example, in the strategy-feedback
condition, incorrect strategies were referred to as “not a
correct way,” which may have been unclear. Further,
children in both the strategy-feedback and outcomefeedback conditions were told if their target response
(strategy or answer, respectively) was correct, but only
children in the outcome-feedback were given additional
information (i.e., the correct answer). The contrast between
the two feedback conditions could be improved.
Second, we sought to clarify the influences of feedback
type during exploration prior to instruction. Given the
paucity of research comparing outcome-feedback to
strategy-feedback, we wanted to confirm that feedback type
is not central to children’s learning during exploration. To
address these concerns, we conducted a second experiment

Previous Experiment
Thus, we compared the effects of feedback (i.e., guidance
during exploration) to no feedback (i.e., no guidance during
exploration) prior to instruction. We hypothesized that
feedback during exploration would result in higher learning
than no feedback. However, we expected the effect to be
stronger for children with low prior knowledge.
We also explored whether the type of feedback mattered.
Outcome feedback provides a judgment about the accuracy
of the learner’s response, whereas strategy feedback
provides a judgment about how the learner obtained that
response. Outcome feedback has been studied extensively
and is generally related to positive outcomes (e.g., Kluger &
DeNisi, 1996). In contrast, few empirical studies have
examined the effects of strategy feedback (e.g., Luwel et al.,
2011). The limited evidence suggests strategy feedback can
benefit strategy selection, but more research is needed to
examine its effects across tasks and outcome measures.
We examined the effects of feedback in the context of
children exploring math equivalence problems (problems
with operations on both sides of the equal sign, such as 3 +
4 + 5 = 3 + __). These problems are not typically included
in elementary mathematics curricula (Rittle-Johnson et al.,
2011), and research shows that U.S. children exhibit poor
performance on math equivalence problems (e.g., Alibali,
1999; McNeil, 2008). Thus, these problems are novel and
difficult for elementary school children, providing an apt
domain to investigate exploratory problem solving.
In an initial experiment, children received a tutoring
session that included exploratory problem solving followed

349

similar to Experiment 1, but with several modifications
intended to strengthen the design.

knowledge of math equivalence. Six additional children
were excluded from analysis for not completing all
activities. The final sample contained 95 children (M age =
7 yrs, 11 mo; 60 girls, 35 boys; 97% Black, 3% White).

The Current Experiment
The current experiment was designed to strengthen the
condition manipulation in Fyfe et al. (2011) and verify the
results with an independent sample. Specifically, we
attempted to replicate the finding that low-knowledge
children benefit from feedback during exploration prior to
instruction, whereas children with higher prior knowledge
benefit from no feedback. Additionally, we sought to clarify
the influences of outcome-feedback and strategy-feedback
to confirm that feedback type did not impact children’s
learning during exploratory problem solving.
We strengthened the condition manipulation in three
ways. First, to differentiate the conditions, we only had
children in the strategy-feedback condition report how they
solved each problem. Children in the other conditions were
asked to report other information to mimic the interaction
with the experimenter (i.e., their answer in the outcomefeedback condition and their completion of the problem in
the no-feedback condition). Second, we made the feedback
more specific by re-voicing the child’s response. In the
strategy-feedback condition we restated the child’s strategy
and in the outcome-feedback condition we restated the
child’s answer. Finally, we did not provide the correct
answer in the outcome-feedback condition. In Fyfe et al.
(2011), only children in the outcome-feedback condition
received additional information (i.e., the correct answer). An
alternative solution was to provide children in the strategyfeedback condition with additional information (i.e., a
correct strategy). But, telling people how to solve a problem
is a form of direct instruction, and we were interested in the
guidance provided prior to direct instruction. So we
eliminated the correct answer in the outcome-feedback
condition to enhance parallelism across conditions.
Consistent with Fyfe et al. (2011), we predicted that
children who received feedback during exploratory problem
solving prior to instruction would exhibit better procedural
knowledge of math equivalence than children who did not.
However, we expected this effect to be larger for children
with lower prior knowledge and to reverse for children with
higher prior knowledge Further, we did not expect any
differences in children’s conceptual knowledge.

Design and Procedure
We used a pretest – intervention – posttest design with a
two-week retention test. For the intervention, children were
randomly assigned to one of three conditions: strategyfeedback (n = 31), outcome-feedback (n = 33), or nofeedback (n = 31). Children completed the pretest in their
classrooms in a 20-minute session. Within 1 week they
completed a one-on-one tutoring intervention and posttest in
a single session lasting approximately 45 minutes.
Approximately two weeks after the intervention session,
children completed the retention test in their classrooms.
The intervention began with exploratory problem solving.
Children solved 12 novel math equivalence problems (e.g.,
9 + 7 + 6 = __ + 6). In Fyfe et al. (2011), the problem were
presented one at a time on a computer screen. In this study,
we presented the problems in paper/pencil format to
simulate a more typical classroom activity.
In the strategy-feedback condition, children reported how
they solved each problem and received feedback on the
strategy, which included a re-voicing of their report (“Good
job! That is one correct way to solve that problem. [Child’s
strategy] was a correct way to solve it. / “Good try, but that
is not a correct way to solve the problem. [Child’s strategy]
is not a correct way to solve it.”). The experimenter revoiced the strategy just as the child reported it to ensure no
added information was provided. In the outcome-feedback
condition, children reported their numerical answer and
received feedback on it, which included a re-voicing of their
report, but not the correct answer (“Good job! You got the
right answer, [child’s answer] is the correct answer.” /
“Good try, but you did not get the right answer, [child’s
answer] is not the correct answer.”). In the no-feedback
condition, children reported when they completed each
problem and were then told to move on.
After exploratory problem solving all children received
brief conceptual instruction on the relational function of the
equal sign. The experimenter provided a definition of the
equal sign and explained how the left and right side of a
problem were equal, using number sentences as examples
(e.g., 3 + 4 = 3 + 4). Between the exploratory problem
solving and instruction, children completed a brief form of
the assessment (midtest) to gauge the immediate effects of
exploration prior to instruction.

Method
Elementary school children received a tutoring session that
included exploratory problem solving followed by brief
conceptual instruction about math equivalence. The
presence and type of feedback was manipulated during the
exploratory problem solving.

Math Equivalence Assessment
The math equivalence assessment, adapted from past
work (Rittle-Johnson et al., 2011) was administered at
pretest, posttest, and retention test. It included both
conceptual (10 items) and procedural (8 items) knowledge
subscales. Conceptual items assessed knowledge of the
meaning of the equal sign and the structure of equations.
Procedural items consisted of math equivalence problems,

Participants
Participants were 111 second- and third-grade children. Ten
were excluded from participation because they scored above
80% on pretest measures designed to assess children’s prior

350

Procedural Knowledge

and scores were based on children’s use of a correct strategy
to solve the problem. Example items and scoring are
presented in Table 1. A brief version of the assessment (5
more difficult items) was used as the midtest.

Children’s procedural knowledge increased from midtest
(M = 26%, SE = 3%) to posttest (M = 37%, SE = 3%), and
stayed similar two weeks later (M = 32%, SE = 3%).
There were no main effects of feedback or feedback type,
nor did feedback type interact with prior knowledge, F’s<1.
However, consistent with Fyfe et al. (2011), there was a
feedback by prior knowledge interaction, F(1, 87) = 4.67, p
= .03, ηp2 = .05. As prior knowledge increased, the benefits
of feedback decreased (B = –1.06, SE = 0.49). To help
interpret the interaction, we categorized children as having
higher prior knowledge (scored above the median on the
procedural knowledge pretest measure) or low prior
knowledge and examined the main effects of feedback for
each group (see Figure 1). For the low-knowledge group,
children who received feedback exhibited higher procedural
knowledge (M = 33%, SE = 4%) than children who did not
receive feedback (M = 20%, SE = 5%), F(1, 87) = 4.00, p =
.05, ηp2 = .04. For the higher-knowledge group, children
who received feedback exhibited lower procedural
knowledge (M = 28%, SE = 5%) than children who did not
receive feedback (M = 50%, SE = 6%), F(1, 87) = 7.54, p =
.007, ηp2 = .08. Feedback during exploration was more
beneficial than no feedback for children with low prior
knowledge, but for children with higher prior knowledge,
the reverse was true. Feedback type did not matter,
suggesting that both types of feedback were beneficial for
low-knowledge children, and both types of feedback were
detrimental for higher-knowledge children.

Table 1: Example items on the assessment.
Task

Scoring

Procedural Knowledge
Solve 8 = 6 + ☐
(operation on right side)
Solve 3 + 4 = ☐ + 5
(operations on both sides)
Solve ☐ + 6 = 8 + 6 + 5
(blank on left)
Conceptual Knowledge
Define equal sign
Judge equations such as
3 = 3 as true or false
Select choice that shows
10¢ is same as 1 dime

Use correct strategy (if
unclear, response must be
±1 of correct answer)
Same as above
Same as above
Provide relational
definition (same amount)
Correctly judge equations
Select equal sign

Analysis and Results
We used a planned contrast analysis of variance model.
Because our condition variable had three groups (nofeedback, outcome-feedback, strategy-feedback), we created
two coded variables. The first variable (feedback) compared
no-feedback to the two feedback conditions combined. This
allowed us to address our primary hypothesis regarding the
presence or absence of guidance during exploration. The
second variable (feedback type) compared outcomefeedback to strategy-feedback and allowed us to explore
differences in the type of guidance provided. To evaluate
whether condition effects depended on prior knowledge, we
included two interaction terms: feedback by prior
knowledge and feedback type by prior knowledge. We used
procedural knowledge pretest scores as the prior knowledge
measure as it is the most relevant domain knowledge for
learning during exploratory problem solving. Finally, we
included three covariates (children’s age as well as
procedural and conceptual knowledge pretest scores).
To evaluate children’s performance on the assessment we
conducted repeated measures ANCOVAs with feedback
(feedback vs. none) and feedback type (outcome vs.
strategy) as between-subject variables and time (midtest,
posttest, retention test) as the within-subject variable. The
two interactions and three covariates were also included. We
examined procedural and conceptual knowledge separately.

Figure 1: Percent correct on procedural knowledge
assessment by condition and prior knowledge. Scores are
estimated marginal means based on midtest, posttest, and
retention test scores.

Conceptual Knowledge
Children’s conceptual knowledge increased from midtest (M
= 21%, SE = 2%) to posttest (M = 50%, SE = 2%) and
stayed similar at retention test (M = 43%, SE = 2%).
There were no main effects of feedback or feedback type,
nor did feedback type interact with prior knowledge, F’s<1.
However, there was a marginal feedback by prior
knowledge interaction, F(1, 87) = 3.63, p = .06, ηp2 = .05.

Pretest
On the pretest, children answered few procedural (M =
20%, SD = 18%) and conceptual (M = 19%, SD = 18%)
items correctly. Importantly, there were no differences
between conditions on either scale at pretest, F’s < 1.

351

As prior knowledge increased, the benefits of feedback
tended to decrease (B = –0.70, SE = 0.37). To help interpret
the marginal interaction, we examined the effect of feedback
for low- and higher-knowledge children separately (based
on a median split of procedural knowledge pretest scores;
see Figure 2). For the low-knowledge group, children who
received feedback exhibited somewhat higher conceptual
knowledge (M = 44%, SE = 3%) than children who did not
receive feedback (M = 37%, SE = 4%), F(1, 87) = 2.56, p =
.11, ηp2 = .03. For the higher-knowledge group, children
who received feedback exhibited somewhat lower
conceptual knowledge (M = 29%, SE = 3%) than children
who did not receive feedback (M = 39%, SE = 5%), F(1, 87)
= 2.60, p = .11, ηp2 = .03. Although not reliable, particularly
when dichotomizing prior knowledge, these results resemble
the pattern of findings found for procedural knowledge.

There was a similar, but weaker effect for conceptual
knowledge. Feedback type had little effect in general.
Overall, we replicated the previous findings and provided
evidence for the reliability of the results.
The results are consistent with prior work demonstrating
aptitude by treatment interactions, which demonstrate that a
single instructional method is often not best for learners
with varying levels of prior knowledge (Cronbach & Snow,
1977; Kalyuga, 2007). In particular, a common conclusion
is that low-knowledge learners benefit from more guidance,
while high-knowledge learners benefit from less guidance
(Snow & Swanson, 1992). Aptitude by treatment
interactions have been found in a variety of domains
including math, science, and problem solving (see Kalyuga
et al., 2003). The current study (coupled with Fyfe et al.,
2011) extends the aptitude by treatment interaction work to
the presentation of feedback during exploratory problem
solving. Children who enter the situation with low
knowledge of the domain need feedback to improve their
knowledge of correct procedures. Children with higher
domain knowledge, on the other hand, do not need this
feedback and actually perform better without it. This
occurred even though higher knowledge children in our
study were far from experts and still had a lot to learn.
Despite the growing evidence that prior knowledge
moderates the impact of feedback during problem solving
(e.g., Fyfe et al., 2011; Kraise et al., 2009; Luwel et al.,
2011), the reasons underlying this effect remain unclear.
One potential explanation relies on the learner’s experience
of cognitive load (Paas, Renkl, & Sweller, 2003). For lowknowledge learners, novel tasks can easily overload their
working memory; thus, they often need some form of
external guidance to reduce cognitive load. In contrast,
higher-knowledge learners can use their existing, relevant
schemas to help them complete the task without cognitive
overload; thus, they often do not need external guidance.
This may explain why low-knowledge learners benefited
from feedback, but high-knowledge learners did not. It is
also possible that differences in motivation would help
explain the findings. Children who are more knowledgeable
may also be more motivated to learn. In turn, those who are
more motivated may thrive in less structured, challenging
environments whereas children who are less motivated may
not (Schnotz, 2010). Finally, changes in children’s strategy
knowledge may also play a role. For low-knowledge
children, the constraining effects of feedback may have sped
up the process of strategy acquisition, which in turn could
jumpstart subsequent strategy changes including the
strengthening of correct strategies (Siegler, 1996). However,
for higher-knowledge children, the constraining effects of
feedback may not have been necessary since these children
already knew a correct strategy. More work is needed to
tease apart these alternative explanations.
Our results also have important implications for research
on guided discovery learning. They suggest that prior
knowledge (and other learner characteristics) should be
considered when evaluating the efficacy of guided discovery

Figure 2: Percentage correct on conceptual knowledge
assessment by condition and prior knowledge. Scores are
estimated marginal means based on midtest, posttest, and
retention test scores.

Discussion
Guided discovery generally facilitates deeper learning than
discovery or instruction alone (e.g., Alfieri et al., 2011;
Mayer, 2004). For example, providing exploratory activities
with subsequent instruction can be beneficial (e.g., DeCaro
& Rittle-Johnson, 2011; Schwartz & Bransford, 1998).
However, the amount of guidance provided during the
exploratory activities has largely gone unstudied, leaving
questions as to how and for whom the guidance can work.
In a previous experiment, we attempted to address these
questions by examining the effects of feedback during
exploratory problem solving prior to instruction. Some
children received feedback (on their answer or on their
strategy) after solving each problem, while others did not. In
this study, we strengthened the condition manipulation and
verified the results with an independent sample of children.
Our results were consistent with those in Fyfe et al.’s
original report. For children with low prior knowledge,
feedback led to higher procedural knowledge than nofeedback. But for children with higher prior knowledge,
feedback hindered performance relative to no-feedback.

352

methods (Cronbach & Snow, 1977). They also highlight the
need to evaluate and optimize different aspects of guided
discovery techniques. We examined the amount of guidance
provided during exploration prior to instruction and found
that more was not always better. Unfortunately, even when
researchers recognize the benefits of combining exploration
and instruction, the recommendation is usually to include
more guidance (e.g., Alfieri et al. 2011).
Despite the positive contributions of the current study,
future research is needed. For example, researchers should
continue investigating the effects of feedback type. We did
not detect many differences between outcome feedback and
strategy feedback, but past research suggests strategyfeedback can be more beneficial, at least in terms of strategy
selection (Luwel et al. 2011). Further, research should more
carefully address what counts as sufficient prior knowledge.
As more research finds that the effectiveness of instruction
depends on prior knowledge, instructors will need guidance
on how to choose instructional techniques for particular
children with particular levels of prior knowledge.
This study extends research on guided discovery learning
in which exploration is provided prior to direct instruction.
Providing feedback during the initial exploration facilitates
learning for low- but not higher-knowledge children. Thus,
providing feedback may not always be optimal.

Second handbook of research on mathematics teaching
and learning. Charlotte, NC: Information Age Publishing.
Kalyuga, S. (2007). Expertise reversal effect and its
implications for learner-tailored instruction. Educational
Psychology Review, 19, 509-539.
Kalyuga, S., & Sweller, J. (2004). Measuring knowledge to
optimize cognitive load factors during instruction.
Journal of Educational Psychology, 96, 558-568.
Kalyuga, S., Ayres, P., Chandler, P., & Sweller, J. (2003).
The expertise reversal effect. Educational Psychologist,
38, 23-31.
Kluger, A. N., & DeNisi, A. (1996). Effects of feedback
intervention on performance: A historical review, a metaanalysis, and a preliminary feedback intervention theory.
Psychological Bulletin, 119, 254-284.
Kraise, U.-M., Stark, R., & Mandl, H. (2009). The effects of
cooperative learning and feedback on e-learning in
statistics. Learning and Instruction, 19, 158-170.
Kulhavy, R. W. (1977). Feedback in written instruction.
Review of Educational Research, 47, 211-232.
Luwel, K., Foustana, A., Papadatos, Y., & Verschaffel, L.
(2011). The role of intelligence and feedback in children’s
strategy competence. Journal of Experimental Child
Psychology, 108, 61-76.
Mayer, R. E. (2004). Should there be a three-strikes rule
against pure discovery learning? The case for guided
methods of instruction. American Psychologist, 59, 14-19.
McNeil, N. M. (2008). Limitations to teaching children 2 +
2 = 4: Typical arithmetic problems can hinder learning of
math equivalence. Child Development, 79, 1524-1537.
Paas, F., Renkl, A., & Sweller, J. (2003). Cognitive load
theory and instructional design: Recent developments.
Educational Psychologist, 38, 1-4.
Rittle-Johnson, B., Matthews, P., Taylor, R., & McEldoon,
K. (2011). Assessing knowledge of math equivalence: A
construct modeling approach. Journal of Educational
Psychology, 103, 85-104.
Schnotz, W. (2010). Reanalyzing the expertise reversal
effect. Instructional Science, 38, 315-323.
Schwartz, D., & Bransford, J. D. (1998). A time for telling.
Cognition and Instruction, 16, 475-522.
Schwartz, D., & Martin, T. (2004). Inventing to prepare for
future learning: The hidden efficiency of encouraging
original student production in statistics. Cognition and
Instruction, 22, 129-184.
Schwartz, D., Chase, C., Oppezzo, M., & Chin, D. (2011).
Practicing versus inventing with contrasting cases: The
effects of telling first on learning and transfer. Journal of
Educational Psychology, 103, 759-775.
Siegler, R. (1996). Emerging minds: The process of change
in children’s thinking. NY: Oxford University Press.
Snow, R. E., & Swanson, J. (1992). Instructional
psychology: Aptitude, adaptation, and assessment. Annual
Reviews in Psychology, 43, 583-626.
Stigler, J. W., & Hiebert, J. (1998, Winter). Teaching is a
cultural activity. American Educator, 1-10.

Acknowledgments
The first author is supported by a predoctoral training grant
provided by the Institute of Education Sciences, U.S.
Department
of
Education,
through
Vanderbilt’s
Experimental Education Research Training grant (ExpERT;
David S. Corday, Director; grant number R305B080025).
This work was also supported by an NSF CAREER grant
(#DRL-0746565) awarded to Bethany Rittle-Johnson.

References
Alfieri, L., Brooks, P. J., Aldrich, N. J., & Tenenbam, H. R.
(2011). Does discovery-based instruction enhance
learning? Journal of Educational Psychology, 103, 1-18.
Alibali, M. W. (1999). How children change their minds:
Strategy chance can be gradual or abrupt. Developmental
Psychology, 35, 127-145.
Cronbach, L. J. & Snow, R. E. (1977). Aptitudes and
instructional methods: A handbook for research on
interactions. New York: Irvington.
DeCaro, M., & Rittle-Johnson, B. (2011, March). Preparing
to learn from math instruction by solving problems first.
In B. Rittle-Johnson and M. DeCaro (chairs), When are
times for telling? Preparing students to learn from
instruction. Symposium presented at the Society for
Research in Child Development Conference, Montreal.
Fyfe, E. R., Rittle-Johnson, B., & DeCaro, M. S. (2011,
Sept.). The effects of feedback during exploratory math
practice. Paper presented at the Society for Research on
Educational Effectiveness Conference, Washington, DC.
Hiebert, J., & Grouws, D. (2007). The effects of classroom
mathematics teaching on student learning. In F. K. Lester,

353

