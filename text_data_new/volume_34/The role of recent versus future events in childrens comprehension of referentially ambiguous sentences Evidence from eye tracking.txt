UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The role of recent versus future events in children’s comprehension of referentially
ambiguous sentences: Evidence from eye tracking

Permalink
https://escholarship.org/uc/item/1h11q8c1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Zhang, Lu
Kornbluth, Lily
Knoeferle, Pia

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The role of recent versus future events in children’s comprehension of
referentially ambiguous sentences: Evidence from eye tracking
Lu Zhang (lzhang@cit-ec.uni-bielefeld.de)
Lily Kornbluth (lilykornbluth@fulbrightmail.org)
Pia Knoeferle (knoeferl@cit-ec.uni-bielefeld.de)
Cognitive Interaction Technology Excellence Center, University of Bielefeld,
Bielefeld, Germany

Abstract
Findings from recent eye-tracking studies suggest that adults
prefer to rely more on recently seen events than possible future
events during sentence comprehension: When the verb in an
NP1-VERB-ADV-NP2 sentence was referentially ambiguous
between a recent action and an equally possible future action,
adults fixated the target of the recent action more often than
the not-yet-acted upon object (Knoeferle & Crocker, 2007;
Knoeferle, Carminati, Abashidze, & Essig, 2011). We
examined whether this preference for the recent event
generalizes to five-year-old children. In an eye-tracking study,
five-year-olds were presented a display with an animal and two
other objects. On the next picture frame, the animal was
depicted as performing an action (e.g., a horse galloped to a
blue barn). Next, a spoken sentence referred either to an event
involving the acted upon target object (the blue barn) or to an
equally plausible future action event (e.g. galloping to the red
barn). At the adverb in NP1-VERB-ADV-PP sentences,
children fixated more often the recent (vs. future) event target.
This result replicates the findings from the adult studies and
suggests that, just like adults, children rely more on the recent
event than expectations of an event that could happen next. At
the same time, visual context effects of the recent events were
subtly delayed for children (vs. adults). For adults, the
recent-event preference emerged during the verb; for children,
by contrast, it emerged post-verbally during the adverb. Thus,
similar attentional mechanisms underlie visual context effects
in both 5-year old children and adults but their time course
differs.
Keywords: eye tracking; child language comprehension;
visual context; depicted events.

Introduction
Adults have been shown to rapidly and efficiently integrate
all sorts of contextual cues during real-time spoken
language comprehension. Referential contrast between
objects
can
incrementally
influence
syntactic
disambiguation (e.g., Tanenhaus, Spivey, Eberhard, &
Sedivy, 1995), as well as semantic interpretation (Sedivy et
al., 1999). Object affordances (Chambers et al., 2004) and
depicted events (Knoeferle et al., 2005; Knoeferle et al.,
2008) can also rapidly affect structural disambiguation.
Sometimes contextual information can even permit adult
comprehenders to actively derive expectations about
upcoming information. One source of evidence for
predictive processes has been “anticipatory” eye movements
to target objects (i.e., eye movements to objects just before
they are mentioned). Verb selectional restrictions (Altmann
& Kamide, 1999), compositional noun and verb meaning

and associated world knowledge (Kamide et al., 2003a,b),
prosody (Weber et al., 2006), and information structure
(Kaiser & Trueswell, 2005) can each restrict the range of
target objects that can be mentioned next, as evidenced by
participants inspecting a target object before its mention
relative to a control condition.
Like adults, children have also been shown to derive
expectations about upcoming information. When children
(aged 10-11) listened to a sentence in which the verb eat
restricted the domain of reference to edible objects, they
fixated the only edible object in context shortly after hearing
eat and before that object was actually mentioned (Nation,
Marshall, & Altmann, 2003). This was true for both
(verbally and visually) less-skilled children as well as for
normally developing children although the former (vs. the
latter) made more and shorter fixations to the edible object.
At first glance this might give the impression that child
and adult language comprehension and expectation
formation are governed by similar mechanisms. Results
from another study with younger children (mean age of 4.7),
by contrast, suggest marked differences between child and
adult language comprehension. In a study by Trueswell et al.
(1999), children either heard a locally structurally
ambiguous sentence such as Put the frog on the napkin in
the box or an unambiguous sentence such as Put the frog
that’s on the napkin in the box. For the ambiguous sentence,
the prepositional phrase on the napkin can either modify the
noun indicating the location of the frog, or attach into the
verb phrase and specify the destination of the action.
Children saw either only one possible referent for frog in the
1-referent condition (e.g. a frog on the napkin, an empty
napkin, a distractor object and a box) or two referents in the
2-referent condition (e.g. a frog on the napkin, another frog,
an empty napkin and a box). A 2-referent context should
bias comprehenders to look at the frog on the napkin upon
hearing on the napkin rather than to the empty napkin.
However, five-year old children frequently looked at the
incorrect destination (the empty napkin) in both
one-referent and two-referent contexts. Adults, by contrast,
looked first at the correct target (the frog on the napkin)
when hearing Put the frog on the napkin and then to the
correct destination (the box) rather than the empty napkin in
a context with two frogs. These findings were taken as
support for the claim that children – unlike adults –
incorrectly interpreted the prepositional phrase on the
napkin as the destination for put, and that they were unable

1227

to use the referential contrast (between two frogs) for
structural disambiguation. Moreover, children’s actions
indicated that they never revised this initial misanalysis: On
60% of the trials they performed an action that involved the
incorrect destination (e.g., moving a frog to the empty
napkin before putting it in the box).
Accordingly, at least some aspects of 5-year-old
children’s and adults’ real-time language comprehension
appear to differ. What is not clear, however, is to what
extent children’s (vs. adults’) use of (visual) context for
spoken language comprehension is indeed limited, and,
more broadly, what demarcates child-adult comprehension
differences. Perhaps 5-year-old children and adults are not
that dissimilar in their comprehension mechanisms and only
employ different (attention) mechanisms in a few isolated
instances. Alternatively, children at that age still differ
fundamentally from adults in how they use (visual)
contextual cues for language comprehension. This is an
interesting research question since processing accounts of
situated language comprehension (e.g., Knoeferle &
Crocker, 2006, 2007) will ultimately want to accommodate
language processing from infancy to young-adulthood to
older age.
Existing findings suggest similarities in how children
versus adults process language in (visual) context, but there
are also some differences. Just like adults, infants as young
as six months of age can track moving objects with their
gaze (Richardson & Kirkham, 2004). 36-month-olds also
exhibit adult attention behavior in that they shift their visual
attention more quickly to a target picture when they hear
blue car in a context with a blue and a red car than when the
context shows a blue car and a blue house (Fernald, Thorpe,
& Marchman, 2010). This suggests that they can rapidly use
linguistic input to fixate relevant referents. In younger
children, by contrast, this behavior is not yet apparent.
Furthermore, when 19-months-old infants listened to nouns
as they saw matching (vs. mismatching) objects, their
event-related brain potentials to the noun exhibited an N400
(a negativity approximately 400 ms after stimulus onset, see
Kutas & Hillyard, 1984) that was larger for mismatches than
matches. That negativity was also found in adults, but the
scalp distribution and latency of that effect differed in
children relative to adults (Friedrich & Friederici, 2004). In
summary, it is unclear to what extent children throughout
language development and adults share the same
mechanisms in language comprehension, language-mediated
visual attention, and visual context effects on
comprehension.
The present research contributes to this emerging
evidence about real-time situated language processing in
children by examining how recently-depicted action events
guide children’s visual attention and spoken language
comprehension. We know that adults can rapidly draw on
recent action events in informing language comprehension
and in interrogating visual context (Knoeferle & Crocker,
2007). Participants saw a character (a waiter) move toward
an object, interact with it (e.g., polish candelabra), and move

away from it. They then listened to an utterance that referred
either to the recent action (polishing the candelabra: simple
past tense: Der Kellner polierte kürzlich die Kerzenleuchter,
“The waiter recently polished the candelabra”) or to an
equally plausible action that hadn’t yet been performed (e.g.,
polishing crystal glasses; present tense with future meaning:
Der Kellner poliert sogleich die Kristallgläser, ‘The waiter
will soon polish the crystal glasses’). At the verb poliert . . .
(‘polish…’) the comprehension system and visual attention
had a choice between anticipating the recent action target
versus anticipating (and thus inspecting) the target of the
as-yet-unseen future action. Adult participants preferentially
anticipated the target of the recent (vs. the other, future)
action, a gaze pattern that continued even as future tense
information became available through the adverb (e.g.,
sogleich, ‘soon’). Verb meaning and future tense
information did not elicit expectations of future events, and
adults relied on the recently inspected events. Recent
research has replicated these results with real-world stimuli.
In addition, the recent-event preference replicated even
when both ‘recent’ and ‘future’ events were equally
frequent but tense effects were then more pronounced (i.e.,
participants always saw one action before and another
action after sentence comprehension, Knoeferle, Carminati,
Abashidze, & Essig, 2011).
The present experiment used eye tracking to see to what
extent 5-year-olds can also rely on recent events in directing
their visual attention and language comprehension. To this
end, 5-year-olds saw clipart depictions such as a horse and
two stables, one red and one blue (see Fig. 1). The horse
moved to the blue stable (Fig. 1b). Subsequently the child
would hear Das Pferd galoppierte gestern zu der blauen
Scheune, (literal translation: ‘The horse galloped yesterday
to the blue barn’, “Yesterday, the horse galloped to the blue
barn”) or Das Pferd galoppiert morgen zu der roten
Scheune (literal translation: ‘The horse gallops tomorrow to
the red barn’, “Tomorrow, the horse will gallop to the red
barn”). If 5-year-olds rely on recent events with the same
time course as adults, then we should see them inspect the
target of the recent event (the blue barn) more often than the
target of the future event (the red barn) during the verb and
post-verbal adverb. While tense information is available
post-verbally, there was only a (non-reliable) tendency for
tense effects post-verbally in the adults (Knoeferle &
Crocker, 2007, Experiment 3; Knoeferle et al., 2011,
Experiment 1). Inspections to the target of the future event
(the red barn) in children should thus only increase as that
target is mentioned.

Experiment
Participants
24 kindergarten children (10 4-year-olds and 14 5-year-olds,
range: 4-5;9) took part in the Experiment and received a
small toy for their participation. All participants had
German as their only mother tongue and normal or

1228

corrected-to-normal vision. All were unaware of the
experiment purpose. Children and one of their parents gave
informed consent.

object presentation side led to eight basic lists. Lists were
pseudo-randomized and each participant saw an
individually randomized version of one of the eight
experimental lists.

Materials and Design
There were sixteen items, and two sentence conditions
(Figure 1 and Table 1). Each item consisted of a series of
three clipart scenes and four sentences. We created the
pictures by using commercially available clipart and
graphics programs. The first frame of the scene displayed a
central animal agent (a horse) and two objects (e.g., a blue
barn and a red barn, Figure 1a). The objects on either side
of the animal were identical mirror images that only
differed in their color or size (e.g., red barn, blue barn).
The verb of the sentence (e.g., galoppieren ‘gallop’, see
example in Table 1) was always a motion verb. Both of the
two objects (e.g. the blue barn and the red barn) were
equally plausible targets of the event (e.g. horse-galloping).
However, the agent approached only one of the two objects
(e.g. galloping to the blue barn, Figure 1b) and then moved
back to another center position (Figure 1c). Each frame was
presented for 1500 ms. The sentence could either refer to a
past event (Table 1a, Das Pferd galoppierte gestern zu der
blauen Scheune. ‘The horse galloped yesterday to the blue
barn.’) or a future event (Table 1b, Das Pferd galoppiert
morgen zu der roten Scheune. ‘The horse gallops tomorrow
to the red barn.’) Figure 1a’-c’ and Table 1a’-b’ were the
counterbalanced version in which the red barn was the
target of the recent action. Therefore, each object was the
target of a past and a future action once. This ensured that
visual characteristics of the post-verbally referenced target
object contributed equally to each critical condition.
We also counterbalanced the presentation side of each
object. As shown in Figure 1, the blue barn was on the left
side and the red barn was on the right side. In the
counterbalancing version (not shown), the red barn was on
the left side and the blue barn was on the right side.
In addition to the 16 experimental items, we created 8
filler items to ensure that children were exposed to a range
of other sentence structures and actions. The two conditions
of the sentence (past vs. future tense), the counterbalancing
of the target object, and the counterbalancing of the target

Procedure
An EyeLink1000 remote eye-tracker with a sampling rate
of 500 Hz monitored participants’ eye movements. Images
were presented on a 22" LCD color monitor at a resolution
of 1680×1050 pixels concurrently with a spoken sentence.
We only tracked the right eye, but viewing was binocular.
At the beginning of the experiment, each child was
instructed to play a game. In this game, children were asked
to inspect the images and to listen to the sentences. After
each trial, they heard a question about the previous sentence
and were asked to try to answer it correctly.
Each trial started with the display of a series of three
frames which depicted an action (e.g., Fig. 1a-c). Each of
the three frames in Fig. 1 was presented for 1500 ms
(totaling 4500 ms). After that, the third image remained on
the screen and the sentence was played via speakers. Five
hundred milliseconds after the offset of the sentence, a
spoken question asked for the target object of the verb in
the previous sentence (for example, Wohin galoppierte das
Pferd?/Wohin galoppiert das Pferd? ‘Where did the horse
gallop?/Where does the horse gallop?’). Participants’ task
was to answer the question by naming the correct
destination.
At the start of the experiment, each participant was
shown two example image sequences and sentences. Next,
participants were set up and calibrated manually using a
five-point fixation stimulus. The black dot that is used to
calibrate adults was replaced by a smiley face to attract
children’s attention. The EyeLink software validated
calibration; if validation was poor, the calibration procedure
was repeated until validation was good. Between the
individual trials, participants saw a centrally-located smiley
on the screen which they were asked to fixate. This allowed
the eye-tracking software to perform a drift correction if
necessary. The entire experiment lasted approximately 25
minutes.

Table 1: Example item sentences
Picture

Condition

Sentence

Figure 1a-c

Past tense

(a) Das Pferd galoppierte gestern zu der blauen Scheune..
The horse galloped yesterday to the blue barn.

Future tense

(b) Das Pferd galoppiert morgen zu der roten Scheune.
The horse gallops tomorrow to the red barn.

Past tense

(a’) Das Pferd galoppierte gestern zu der Roten Scheune..
The horse galloped yesterday to the red barn.

Future tense

(b’) Das Pferd galoppiert morgen zu der blasuen Scheune.
The horse gallops tomorrow to the blue barn.

Figure 1a’-c’

1229

c

a’

b’

c’

Figure 1: Example item pictures. In Figure 1 a-c, the horse
gallops to the blue barn. To counterbalance visual
characteristics of the target (e.g., its color), the horse gallops
to the red barn in Figure 1 a’-c’.

Analysis

adv

furture
recent
b

PP

5000

4500

adv

4000

3500

3000

2500

2000

1500

1000

verb

furture
recent
b

PP

5000

4500

4000

3500

3000

2500

2000

1500

1000

500

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

verb

500

Figures 2a) and 2b) plot the mean proportion of fixations to
the two objects in the future and past tense conditions using
time slots of 250ms. Figure 3 zooms in on one region of

b)

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0

0

Results

a)

0

For the purpose of inferential analyses, we defined three time
windows: an exact verb region (from verb onset until its
offset); the extended adverb region (from verb offset until
adverb offset) and the PP region (from preposition onset until
sentence end). We coded participants’ fixations to four areas
of interest in the scene: the agent (e.g., the horse in Figure 1);
the recently acted upon object (e.g., the red barn in Figure
1a-c); the future object (e.g. the blue barn in Figure 1a-c); and
the background. Of those, the recent and future objects were
our target areas of interest.
The proportions of fixation on the target areas of interest
(the recent and the future targets) were entered into log-ratio
analyses (c.f., Arai, van Gompel & Scheepers, 2007;
Carminati, van Gompel, Scheepers, & Arai, 2008; Knoeferle
et al., 2011). We computed mean log gaze probability ratios
for the recent object relative to the future object ln (P (future
target)/P (recent target)) for each condition and for each
time window. Then we entered the log probability ratios
into a one-factor (tense) ANOVA. Separate models were
fitted for log-ratios averaged over participants and items
respectively. We report the p-values for these analyses. To
test whether the log probability ratios of each condition
differs significantly from zero, we conducted simple t-tests.
We adujusted the significance level of the p-values using the
Bonferroni correction.
For the descriptive overview of the time course of the
eye-movement data, we divided the utterance from sentence
onset into time slots of 250 ms each. For each time slot and
target object, we computed the number of fixations that fell
within a given time slot. Then we plotted the mean
proportion of fixation counts per time slot separately for
each sentence condition and each target object.

mean fixation proportion

b

mean fixation proportion

a

interest and presents the mean log gaze probability ratios
(ln(P(future target)/P(recent target)) per condition for the
adverb region.
Figures 2a) and 2b) illustrate an overall preference for
fixating the acted-upon object rather than the not-acted-upon
object from the offset of the verb until well into the NP2,
irrespective of tense condition. As illustrated in Figure 2, the
preference for looking at the acted-upon object is much
reduced and reverses as children hear the second noun
phrase in the future compared to the past tense condition.
In agreement with the descriptive pattern, the inferential
analysis revealed no significant main effect of tense at both
the verb and the adverb region. To test whether children had
a preference to inspect one of the two targets, we examined
whether the intercept was significantly different from zero.
At the verb region this was not the case. By contrast, simple
t-tests confirmed that log probability ratios of both the
future tense condition and the past tense condition by
subjects (ps < 0.05) and of the past tense condition by items
(p < 0.005) were significantly different from zero for the
adverb region (see Figure 3). This corroborates the findings
from the descriptive analysis and indicates that children
looked more often at the recently-acted-upon object than at
the not-yet-acted-upon object in both the past and future
tense conditions. For the PP region, by contrast, analyses
confirmed that the children inspected the target objects as
they were named (both ps < 0.002).

Figure 2: Eye movements to the target of the recent event
(recent target: blue lines) and the target of the future event
(future target: red lines) from sentence onset to sentence end
for a) future tense condition and b) past tense condition

1230

mean log gaze probability ratio

0.3
0.2
0.1
0
-0.1
-0.2
-0.3
-0.4
-0.5
-0.6
-0.7
-0.8

future
past

tense

Figure 3: Children’s mean log gaze probability ratios
(ln(P(future target)/P(recent target)) per condition for the
adverb region (Error bars represent the standard error of the
mean log gaze probability ratios)

Discussion
The present research assessed whether 5-year-old children
resemble adults in how and when they make use of
recently-inspected clipart events during spoken language
comprehension. We conducted an eye-tracking experiment
in which we monitored 5-year-olds’ eye movements to
target objects in a clipart picture as they listened to related
sentences. The children saw an animal move towards one of
two equally plausible objects (e.g., the horse would gallop
to the blue barn when a blue and a red barn were depicted).
When the motion verb in an ensuing spoken sentence
referred either to that recent action or to another action that
hadn’t yet happened, children preferred to inspect the target
of the recent event (e.g., the blue barn) over the target of the
as-yet-unseen but plausible other event (e.g., the red barn).
This finding confirmed clear similarities in how children
and adults (Experiment 3 in Knoeferle & Crocker, 2007)
direct their visual attention during spoken language
comprehension: both of these participant groups preferred to
inspect the recent-event (vs. future-event) target. The time
course of visual attention, however, was delayed for
children relative to adults. While adults in Experiment 3 by
Knoeferle and Crocker (2007) began to inspect the
recent-event target more often during the verb, the
recent-event inspection preference only emerged
post-verbally for children.
One open question is what underlies the recent-event
preference in both children and adults. The experiment
procedure introduced a frequency bias for the recent events.
While participants in Experiment 3 by Knoeferle and
Crocker (2007) and in the present study saw an event before
each experimental trial, they never saw a post-sentence
future event acted out. The procedure of never depicting the
future event may have created a within-experiment

frequency bias toward relying more on recently depicted
than on equally plausible future events for comprehension.
It is possible that this bias led participants to preferentially
inspect the recent (vs. future) event target.
Indeed, statistical regularities play an influential role in a
range of cognitive processes for both children and adults. At
8 months of age, children can already use statistical
regularities in linguistic input to segment words in fluent
speech (Saffran, Aslin, & Newport, 1996). Statistical factors
also play a role in children’s visual attention to novel (vs.
known) object patterns. When circles appeared in a pattern,
infants at 11 months inspected novel (vs. known) circle
sequences longer; by contrast, that behavior was not yet
present at 8 months of age (Kirkham, Slemmer, Richardson,
& Johnson, 2007, Experiment 1). For adults, statistical
regularities play a role in language processing and other
cognitive and motor processes. Adults’ short-term linguistic
experience can modulate their language production
(Kaschak, Loney, & Borreggine, 2006; Haskell, Thornton,
& MacDonald, 2010) and sentence reading (Wells,
Christiansen, Race, Acheson, & MacDonald, 2009). It also
affects adults’ action execution (e.g., Chapman, Gallivan,
Wood, & Milne, 2010) and visual perception (e.g., Chun &
Jiang, 1999).
For the recent-event inspection bias in adults, however,
frequency biases appear to play no causal role. When recent
and future events were performed equally frequently within
the experiment, effects of tense appeared somewhat earlier
than in Knoeferle and Crocker (2007, Experiment 3), during
the post-verbal adverb. By contrast, adults’ recent-event
inspection bias during the verb remained largely unchanged
(Knoeferle et al., 2011, Experiment 2).
To what extent this preference generalizes to 5-year-olds
when both recent and future events are equally frequent is
unclear. What is clear, however, is that children, like adults,
rapidly used recently inspected clipart events during
comprehension, but that the time course of these event
effects was delayed in children. For accounts of situated
language comprehension (e.g., Coordinated Interplay
Account, Knoeferle & Crocker, 2006, 2007), the present
findings together with the other results that we discussed
suggest that the closely temporally coordinated interplay of
language comprehension, visual attention, and visual
context effects on comprehension has a developmental
basis.

Acknowledgments
This research was funded by the Cognitive Interaction
Technology Excellence Center (German Research
Foundation, DFG). We thank Linda Krull and Eva Mende for
their assistance with preparing the stimuli and collecting data.
We thank Maria Nella Carminati for advice regarding the
analyses and Helene Kreysa for help with the Experiment

1231

Builder software. We also thank all the participating families
and students for their support.

References
Altmann, G. T. M., & Kamide, Y. (1999). Incremental
interpretation at verbs: restricting the domain of
subsequent reference. Cognition, 73, 247–264.
Arai, M., van Gompel, R., & Scheepers, C. (2007). Priming
ditransitive structures in comprehension. Cognitive
Psychology, 54, 218–250.
Carminati, M. N., Gompel, R. P. G. van, Scheepers, C., &
Arai, M. (2008). Syntactic priming in comprehension: the
role of argument order and animacy. Journal of
Experimental Psychology: Learning, Memory, and
Cognition, 34, 1098–1110.
Chambers, C. G., Tanenhaus, M. K., & Magnuson, J. S.
(2004). Actions and affordances in syntactic ambiguity
resolution. JEP: LMC, 30, 687–696.
Friedrich, M. & Friederici, A.D. (2004). N400-like semantic
incongruity effect in 19-month olds: processing known
words in picture contexts. Journal of Cognitive
Neuroscience, 16, 1465-1477.
Chapman, C. S., Gallivan, J. P., Wood, D. K., & Milne, J. L.
(2010). Reaching for the unknown: Multiple target
encoding and real-time decision-making in a rapid reach
task. Cognition, 116, 168–176.
Chun, M. M., & Jiang, Y. (1999). Top-down attentional
guidance based on implicit learning of visual covariation.
Psychological Science, 10, 360–365.
Haskell, T. R., Thornton, R., & MacDonald, M. C. (2010).
Experience and grammatical agreement: statistical
learning shapes number agreement production. Cognition,
114, 151–164.
Kaiser, E., and Trueswell, J. C. (2005). The role of
discourse context in the processing of a flexible
word-order language. Cognition, 94, 113–147.
Kamide, Y., Scheepers, C., & Altmann, G. T. M. (2003b).
Integration of syntactic and semantic information in
predictive processing: cross-linguistic evidence from
German and English. JPR, 32, 37–55.
Kamide, Y., Altmann, G. T. M., & Haywood, S. (2003a).
The time course of prediction in incremental sentence
processing. Journal of Memory and Language, 49,
133–156.
Kaschak, M. P., Loney, R. A., & Borreggine, K. L. (2006).
Recent experience affects the strength of structural priming.
Cognition, 99, B73–B82.
Kirkham, N., Slemmer, P., Richardson, D., & Johnson, S. P.
(2007) Location location location: Development of
spatiotemporal sequence learning in infants. Child
Development, 78, 1559-1571.
Knoeferle, P. 2007. “Comparing the time-course of
processing initially ambiguous and unambiguous German
SVO/OVS sentences in depicted events”, in: R. Gompel
van, M. Fischer, W. Murray, & R. Hill (Eds.), Eye

movement research: insights into mind and brain. Oxford:
Elsevier, 517 – 533.
Knoeferle, P., Crocker, M. W., Scheepers, C., & Pickering,
M. J. (2005). The influence of the immediate visual context
on incremental thematic role-assignment. Cognition, 95,
95-127.
Knoeferle, P., & Crocker, M.W. (2006). The coordinated
interplay of scene, utterance, and world knowledge:
evidence from eye tracking. Cognitive Science, 30(3), 481
- 529.
Knoeferle, P., & Crocker, M. W. (2007). The influence of
recent events on spoken language comprehension:
evidence from eye movements. JML, 57 (2), 519-543.
Knoeferle, P., Habets, B., Crocker, M. W., & Münte, T. F.
(2008). Visual Scenes Trigger Immediate Syntactic
Reanalysis: Evidence from ERPs during Situated Spoken
Comprehension. Cerebral Cortex, 18, 789-795.
Knoeferle, P., Carminati, M., Abashidze, D., & Essig, K.
(2011). Preferential inspection of recent real-world events
over future events: evidence from eye tracking during
spoken sentence comprehension. Front. Psychology 2:376.
doi: 10.3389/fpsyg.2011.00376
Kutas, M., & Hillyard, S. A. (1984). Brain potentials during
reading reflect word expectancy and semantic association.
Nature, 307, 161– 163.
Nation, K., Marshall, C. M., & Altmann, G. (2003).
Investigating individual differences in children’s real-time
sentence comprehension using language-mediated eye
movements. Journal of Experimental Child Psychology,
86, 314–329.
Tanenhaus, M. K., Spivey-Knowlton, M. J., Eberhard, K. M.,
& Sedivy, J. C. (1995). Integration of visual and linguistic
information in spoken language comprehension. Science,
268, 1632–1634.
Trueswell, J., Sekerina, I., Hill, N., & Logrip, M. (1999). The
kindergartenpath effect: Studying on-line sentence
processing in young children. Cognition, 73, 89 –134.
Richardson, D. C. & Kirkham, N.Z. (2004). Multi-modal
events and moving locations: Eye movements of adults and
6-month-olds reveal dynamic spatial indexing. JEP:
General, 133, 46-62.
Saffran, J., Aslin, R. N., & Newport, E. (1996). Statistical
learning by 8-month old infants. Science, 274, 1926–1928.
Sedivy, J. C., Tanenhaus, M. K., Chambers, C. G., and
Carlson, G. N. (1999). Achieving incremental semantic
interpretation through contextual representation. Cognition,
71, 109–148.
Weber, A., Grice, M., & Crocker, M. W. (2006). The role of
prosody in the interpretation of structural ambiguities: A
study of anticipatory eye movements. Cognition, 99,
B63–B72.
Wells, J. B., Christiansen, M. H., Race, D. S., Acheson, D. C.,
& MacDonald, M. C. (2009). Experience and sentence
processing: statistical learning and relative clause
comprehension. Cognition, 58, 250–271.

1232

