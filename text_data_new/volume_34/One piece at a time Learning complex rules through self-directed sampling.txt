UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
One piece at a time: Learning complex rules through self-directed sampling

Permalink
https://escholarship.org/uc/item/79c5793c

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Markant, Doug
Gureckis, Todd

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

One piece at a time: Learning complex rules through self-directed sampling
Doug Markant (doug.markant@nyu.edu)
Todd M. Gureckis (todd.gureckis@nyu.edu)
New York University
Department of Psychology
6 Washington Place, New York, NY 10003 USA
Abstract

How do people make information sampling decisions?

Self-directed information sampling—the ability to collect information that one expects to be useful—has been shown to
improve the eﬃciency of concept acquisition for both human
and machine learners. However, little is known about how people decide which information is worth learning about. In this
study, we examine self-directed learning in a relatively complex
rule learning task that gave participants the ability to “design
and test” stimuli they wanted to learn about. On a subset of
trials we recorded participants’ uncertainty about how to classify the item they had just designed. Analyses of these uncertainty judgments show that people prefer gathering information about items that help re ne one rule at a time (i.e., those
that fall close to a pairwise category “margin”) rather than items
that have the highest overall uncertainty across all relevant hypotheses or rules. Our results give new insight into how people
gather information to test currently entertained hypotheses in
complex problem solving tasks.
Keywords: self-directed learning, categorization, active learning, information search, rule learning

In light of evidence that self-directed sampling can speed
learning, it is important to understand how people decide
what data to collect. Given a potential observation, what information do people rely on to decide if it will be useful?
One aspect that may help explain a person’s decision to
sample an item is their uncertainty in how to classify it (or
more generally, their uncertainty about the outcome of any
test performed on the item). Intuitively, a self-directed learner
should direct their attention to items that are high in uncertainty while ignoring items that can already be con dently
classi ed or predicted. Consistent with this strategy, the pattern of stimuli sampled by self-directed learners in our previous study (see Figure 1) revealed that participants systematically directed their samples toward the category boundary
as the task progressed. Intuitively, the learner is mostly likely
to be uncertain about these items (e.g., most of the errors in
classi cation occur near the category boundary).
In the current study, we examine how subjective uncertainty in how to classify an item can be used to predict whether
or not it is sampled. We begin by presenting three psychologically motivated proposals for how sampling decisions relate
to judgments of uncertainty, and then test these models in a
new experiment that extends the “self-directed” classi cation
learning paradigm used in Markant and Gureckis (2010). Our
results highlight the need for models of sampling behavior that
go beyond monolithic measures of information value to consider how people collect and use data during the sequential
learning of concepts.

Introduction
A cornerstone of many educational philosophies is that people
learn more eﬀectively when they direct or control their own
learning experiences (Bruner, 1961). While there are many
ways that control might in uence learning, an important factor is the ability to actively gather information that one considers potentially useful while avoiding data that is potentially redundant, a behavior referred to as self-directed sampling (Gureckis & Markant, in revision).
One recent study directly examined the interaction of
self-directed information sampling and learning (Markant &
Gureckis, 2010, in revision). In this study, people attempted
to learn simple dichotomous categories of objects that varied
along two perceptual dimensions (circles that diﬀered in size
and the orientation of a central line segment, see Figure 1).
In contrast to traditional categorization training procedures,
we allowed participants to “design” stimuli that they wanted
to learn more about on each trial. Like a child asking their
parent to label an unfamiliar object, self-directed “designing”
or “sampling” allows the learner to focus on information they
want rather than be limited by the ow of passive experience.
e major nding from this study was that for simple unidimensional rules, self-directed learners acquired the correct
category rule faster than “passive” participants who were provided samples from an experimenter-de ned distribution. In
addition, self-directed learners out-performed a set of “yoked”
learners who viewed the same examples but did not get to
make information sampling decisions themselves (consistent
with studies of causal learning with similar yoked comparisons, Lagnado and Sloman, 2004; Sobel and Kushnir, 2006).

ree models for relating uncertainty and
information sampling decisions
e following sections lay out three possible ways in which
uncertainty might guide information sampling decisions.

Model 1: Sampling to reduce global uncertainty
Prior work on how people gather information has oen focused on diagnostic reasoning problems in which the learner
is given a set of alternatives (e.g., diﬀerent diseases) and asked
to sample observable features (e.g., symptoms) in order to
identify the true diagnosis (Nelson, McKenzie, Cottrell, & Sejnowski, 2010; Skov & Sherman, 1986; Trope & Bassok, 1982).
From a computational perspective, various authors have proposed sampling norms that attempt to predict information
sampling decisions based on a learner’s representation of the
task (Nelson, 2005; Nelson et al., 2010; Oaksford & Chater,

725

Stimuli sampled by
self-directed participants
(by training block)

B
Orientation

A
A B

Size

1

2

3

4

5

6

7

8

“Adjust the antenna and
click the mouse button
to learn the station”

Figure 1: A: Abstract stimulus space used in Markant and Gureckis (2010, in review) and which is adapted for the current study. Stimuli were

circles which varied in size and orientation of a central diagonal. In Markant and Gureckis, these objects were assigned to one of two categories
(“A” or “B”). Participants “designed” a stimulus they wanted to learn about using the mouse. Clicking the mouse button reveals the category
membership of the item. B: e pattern of sampling behavior observed by self-directed learners in Markant and Gureckis (2010) across eight
training blocks. Each dot represents a single stimulus which was selected by a participant. In the rst block, participants distributed their
samples widely over the entire stimulus space but then gradually focused their choices on the region surrounding the category boundary.

tain, might be to decompose a complex task into a series of
simpler problems. For example, when multiple features may
be related to an outcome, a learner might choose to hold one
feature constant while varying the other across multiple samples (Rottman & Keil, 2012). Such a strategy is related to the
“control of variables” strategy which is essential to scienti c
reasoning. Isolating variables oen helps people to more efciently search the space of potential hypotheses (Klahr &
Dunbar, 1988) and is a key part of “learning to learn” about
complex concepts (Kuhn & Dean, 2005). In an experiment
similar to that of Markant and Gureckis (2010), Avrahami et
al. (1997) had participants choose samples to teach a partner
about a single-dimensional rule and found that the “teachers” frequently used a strategy of isolating individual features.
Moreover, their students learned better from this strategy than
when given items that were closest to the category boundary.
We can formalize the strategy of focusing on separate components in a sampling model that values uncertainty about
any individual boundary between only two categories. Label margin predicts that the learner will prefer instances for
which the likelihood of any two categories is similar, independent of any other categories. For example, when there
are three categories and the marginal distribution is de ned
as P (y∣x) = (p1 , p2 , p3 ):

1994). Much of this work has focused on what we will call
“prospective” models (e.g., probability gain, information gain,
etc.) that estimate the expected drop in uncertainty that will
result from making an observation (taking into account all
possible outcomes). While in many contexts these models
make similar predictions, Nelson et al. (2010) designed a diagnostic reasoning task which found that participants’ choices
were best t by probability gain, which values a potential observation according to how much it increases the chance of
classifying an item correctly.
In the context of learning a classi cation rule, this approach
is consistent with a preference for sampling items that the
learner is least certain about how to classify. Assume that for
a given stimulus x = (f1 ...fd ) with d observable features the
learner represents the probability that x is a member of each
possible category y in the distribution P (y∣x). We can then
de ne the least certain measure as:
LC(x) = 1 − max(P (y∣x))

(1)

for all stimuli x. Note that there are alternative norms that
make similar predictions to least certain, such as using the
Shannon entropy of the marginal distribution to calculate uncertainty (see Settles, 2009 for a review). Regardless of the particular form, the important property of this approach is that
the most valuable observation is always an item that is considered equally likely to belong to all possible categories. In
general, choosing items which maximize LC(x) should convey the greatest amount of information to the learner.

LM (x) = 1 − min[∣p1 − p2 ∣, ∣p1 − p3 ∣, ∣p2 − p3 ∣]

(2)

Critically, label margin does not preferentially select items for
which the learner is globally uncertain. Instead, by this approach, a learning problem is decomposed into simpler problems and items are selected which are expected to resolve uncertainty about the sub-components.

Model 2: Isolating individual rule components
through margin sampling
While focusing on items that are the most “globally” uncertain or unpredictable seems intuitively useful, there is reason
to expect that it may not be the sampling strategy humans
use, particularly when learning in complex, multivariate environments. One natural strategy, not captured by least cer-

Model 3: Seeking con rmation
While the previous two models propose that people search for
uncertain items, previous work on hypothesis testing suggests
that people may prefer items that they already know how to

726

Category Feedback
(Stimulus space)
Binary
Classification

A

B

f2

Space of probability
judgments
A

B

(1.0, 0.0)

f1

Ternary
Classification

B
f2

C

Least Certain

(0.5, 0.5)

A

Most Certain

Label Margin
B

A

B

A

B

(0.0, 1.0)

B

B

B

B

(0, 0.5, 0.5)

A
(0.3, 0.3, 0.3)

f1

A

(1, 0, 0)

C

A

C

A

C

A

C

Figure 2: Comparing predictions of sampling norms (red = more highly valued choices, blue = less valued choices) Top: For a binary classi -

cation problem, a new observation in stimulus space will correspond to a location on the probability judgment scale, where the lemost point
re ects con dence that the observation will be classi ed “A” and the rightmost point re ects con dence it will be classi ed “B”. For the binary
problem, the predictions of least certain and label margin are identical. Bottom: In a ternary classi cation problem, an item in stimulus space
will correspond to a location in the 3-category simplex depending on the learner’s uncertainty. Here the predictions of least certain and label
margin diverge, allowing us to test which of the two models better account for sampling behavior.

classify. For example, people have a well-documented bias toward seeking positive evidence of the hypothesis they are considering (Klayman & Ha, 1989; Wason, 1960), a strategy that
in certain conditions is aligned with the goals of maximizing
uncertainty reduction (Austerweil & Griﬃths, 2011; Navarro
& Perfors, 2011; Nelson & Movellan, 2001). To quantify this
strategy, we de ne the most certain measure as:
M C(x) = max(P (y∣x))

category is highly unlikely but the learner is uncertain about
the other two (shown in Figure 2 by the high predicted value
along the radial axes of the simplex, including the midpoints
of each edge). In short, this model predicts that samples are
likely to be allocated close to any boundary (i.e., “margin”) between two categories. In contrast, least certain predicts sampling close to the junction of the category boundaries, where
all three classes are likely.

(3)

Overview of the current study

e predictions of this model directly contrast those of least
certain, with the highest value assigned to items that can already be classi ed with con dence. One may also think of the
most certain measure as instantiating con rmation bias—it
shows a preference for items for which the learner has a strong
prediction about the category label.

e design of our experiment capitalizes on the distinction
described in the previous section by extending the paradigm
used in Markant and Gureckis (2010) to a ternary classi cation problem. In the experiment participants collect data by
sampling new instances and receiving feedback about their
category membership. As shown above, using the ternary
classi cation problem allows us to separate the predictions of
the three sampling models, two of which were confounded
in our previous design. In order to obtain an estimate of the
learner’s uncertainty at any point in time, on a subset of sampling trials participants report how likely they believe the instance they created will belong to each of the three categories
(before receiving feedback). e goal of our analysis is to use
these subjective judgments to test which model provides the
best account of their sampling decisions.

Empirically distinguishing these alternatives
Given these various approaches, a key question is if they are
distinguishable based on empirical data. e predictions of
each model are shown for a binary classi cation problem (like
the task used in Markant and Gureckis, 2010) in the top row of
Figure 2. Each heatmap describes the value assigned to a potential observation depending on the learner’s uncertainty in
how to classify it. For example, an item that can be con dently
classi ed (e.g., p(y∣x) = (1, 0)) would be assigned a high value
by most certain and a low value by least certain. Note that for
the binary classi cation problem, least certain and label margin make identical predictions about how items will be valued (i.e., items close to the center of the space are preferred),
making it impossible to separately test these models. However, an interesting observation made by Settles (2009) is that
the predictions of these models strongly diverge when considering more complex categorization tasks. For example, in a
ternary classi cation task (see bottom row of Figure 2), label
margin assigns the maximum value to any items for which one

Experiment
Participants Fiy-seven undergraduates at New York University
participated in the study for course credit. e experiment was run
on standard Macintosh computers in a single 1-hour session.

Stimuli Stimuli were de ned by a two-dimensional continuous-

valued feature space corresponding to the size (radius) of a circle and
the angle of a central diameter. ese feature values were mapped
to a limited range of orientations and sizes on the display. Orientation could vary over only  degrees, ensuring that a full rotation of
the stimulus was not possible. e two halves of the central diameter were given diﬀerent colors, further reducing the perceptual similarity of stimuli at the two extremes of the orientation dimension.

727

Probability judgment

Probability judgments. Half of the training trials in each block
were randomly selected to include probability judgments. On
these trials, aer participants had designed an antenna but before
the category label was shown, they judged the likelihood that the
antenna would receive each of the three channels using a sequence
of rating scales (shown in Figure 3). e three scales were presented
independently such that only one was visible at a time. When
each scale appeared, the participant clicked on a location in the
scale according to their belief that the antenna they had designed
would receive that channel. A response was required for each scale,
and there was no time limit for entering the response. e initial
position of the mouse cursor within each scale was randomized,
allowing us to record whether responses were in uenced by the
starting position. Aer probability judgments were recorded,
they were displayed alongside the category label for the same
duration as in regular training trials. is allowed the participant to
evaluate the accuracy of their prediction given the true category label.

Feedback

Test Trials. Each block of  training trials was followed by  test trials.
On each test trial, a single item was presented in the center of the display and the participant classi ed the item according to the channel
they believed it was most likely to receive. A response was required to
complete the trial, and participants responded at their own pace. No
feedback was provided on individual test trials. At the end of each
block participants were told their accuracy during the block they just
completed, as well as the number of consecutive correct responses.

CH1

Results
Figure 3: Top: Probability judgments were entered by clicking on

ree participants were excluded from analysis for failing to
complete the task, leaving N = 54. irty-one people reached
the goal of correctly classifying  items in a row. However,
there were a number of additional people who achieved similarly high rates of accuracy. For each subject we computed a
moving average of their classi cation accuracy with a window
of  blocks, and found  people for whom this average exceeded 83% at any point in the experiment (i.e., they correctly
classi ed  of  items within any three consecutive blocks).

a scale for each of the three categories (CH, CH, and CH). Bottom: Probability judgments were displayed alongside the category
label during feedback.

e minimum radius and orientation were randomized so that the
boundary between the categories corresponded to a unique boundary in perceptual space for each participant. A total of 256 stimuli
were sampled from a uniform grid over the feature space and used as
test items for all participants, presented in random order.
e category label associated with each stimulus was deterministically de ned by a conjunctive, ternary classi cation rule of the form
shown in Figure 2. In addition to the structure that is shown, three
more rules were created through diﬀerent rotations (, , and 
degrees) of the same boundaries in stimulus space. Each participant
was randomly assigned to one of the four rules.

Probability judgments. On half of participants’ sampling
trials they judged how likely the stimulus they selected belonged to each of the three categories, resulting in three values between  and . In order to verify that participants were
not simply responding based on the position of the cursor,
for each rating we measured the diﬀerence between the initial
(random) position and the participant’s response. One participant was excluded from further analysis because the majority of their ratings (82%) did not change by more than 0.01%
from the initial values (for the remaining subjects, the average proportion of samples that met the same condition was
M = 0.04, SD = 0.05).

Procedure Participants were instructed that the stimuli in the

experiment were television “loop antennas” and that each unique
antenna received one of three channels (CH, CH, or CH). eir
goal was to learn the diﬀerence between the three types of antennas
so that they could correctly classify new antennas during the test
blocks. Participants were told that the experiment would end when
they correctly classi ed  consecutive test items. If a participant
failed to reach that goal the experiment ended aer  blocks or at
the end of an hour (whichever occurred rst).

Fitting the alternative sampling models. Our rst goal was
to assess the overall t of the three sampling models to each
participant’s full set of probability judgments. For each model
we computed the normalizing constant necessary to de ne the
probability density function. Each triplet of ratings was normalized so that they summed to one. We then calculated the
log-likelihood of each judgment made by a participant and
summed across all trials to get an overall score for each model.
Classifying participants according to the model with the
highest log-likelihood, we found that 3 people were best- t by
least certain, 25 people were best- t by label margin, and the

Training Trials. Participants “designed” antennas by adjusting the
size and orientation and receiving feedback about which channel was
received. ey were instructed that they should design antennas they
thought were useful and that would help them to predict the TV
channel for other designs they had not yet tested.
Each trial began with the presentation of a randomly generated
antenna. Participants then adjusted the size and orientation by
moving the mouse from le to right while holding either the ‘Z’ or
‘X’ key, respectively. Only one dimension could be changed at a
time, but participants could make any number of changes and were
self-paced. When the stimulus was the desired size and orientation,
they pressed the mouse button to reveal the channel received,
displayed above the stimulus for 4 seconds.

728

A

B

Probability judgments
(by best fit model)

Overall proportion of samples by region
0.6

fast
slow

Least certain
Label margin

least certain
(3 participants)

label margin
(25 participants)

most certain
(25 participants)

Most certain

Proportion

0.5
0.4
0.3
0.2
0.1
0.0

LC

LM

MC

Region

Figure 4: A: Probability judgments are plotted using the 3-category simplex for participants best- t by each of the three models (see Figure 2

for reference). Each point represents a single judgment aer normalization. B: Each judgment was classi ed according to the model assigning
it the highest likelihood, eﬀectively dividing the probability space into three regions. Participants were divided into two groups based on the
number blocks they required to complete the task (“fast” and “slow”), and the relative frequency of sampling in each region is shown at right.

Discussion

remaining 25 people were best- t by most certain. Judgments
made by participants, separated by the best- tting model, are
plotted using the 3-category simplex in Figure 4A, with each
point a single sample chosen by a participant. A higher density
of points re ects an increased tendency (as a group) to sample stimuli in a given region of probability space. Upon visual
inspection, the overall pattern for each group corresponds to
the predictions of the best- tting model (Figure 2).

eories of rational information acquisition propose that the
decision to make an observation is related to the amount of
information it conveys (Nelson, 2005; Oaksford & Chater,
1994). Sampling norms such as probability gain prospectively
evaluate the change in uncertainty that is expected to occur
following an observation, and a rational learner should choose
the data that maximizes that measure. Our results illustrate
the relative inadequacy of these models when applied to even
a basic rule learning task. Very few of our participants were
best t assuming they preferentially selected observations they
were least certain about. In addition, the heterogeneity of participants’ sampling strategies is a noteworthy nding. For example, about 20% of samples in the rst 4 blocks were “con rmatory” (i.e., data that the learner could already classify with
relative con dence), and overall there was no diﬀerence in
the frequency of this kind of sampling between fast and slow
learners. Con rmatory sampling could serve a number of
purposes, including helping to organize the representation of
a rule in mind (Mathy & Feldman, 2009) or to facilitate comparisons between successive observations, but further work is
required to understand its exact role in this task.

Relating sampling decisions to learning eﬃciency. We next
tested whether a participant’s overall success at learning the
target concept was related to the sampling behavior re ected
in their probability judgments. Our approach was to divide
participants into two groups based on the number of blocks
they required to complete the task. We performed a median
split on the number of blocks (median = 16) to create a group
of “fast” (N = 26) and “slow” (N = 27) learners. With respect to overall model ts, however, there was no diﬀerence in
the proportion of participants best t by each model between
groups (fast learners: NLC = 1, NLM = 12, NM C = 13; slow
learners: NLC = 2, NLM = 13, NM C = 12).
While overall model ts provide a measure of each participant’s sampling behavior in general, inspection of the data
showed that most subjects had relatively mixed strategies. For
example, a participant best- t by most certain may have made
a number of judgments consistent with label margin. Given
this heterogeneity, we classi ed individual probability judgments according to the model that assigned it the highest likelihood, eﬀectively dividing the probability space into three regions corresponding to each model (Figure 4B). Multinomial
logistic regression was used to test for diﬀerences between the
relative frequency with which fast and slow learners sampled
in each of the three regions. Overall frequency diﬀered significantly between the two groups (χ2 = 24.7, df = 2, p < .001).
Post-hoc tests showed that fast learners sampled somewhat
more frequently in the label margin region (t(51) = 1.68,
p = .09) and less frequently in the least certain region overall (t(51) = −1.91, p = 0.06), suggesting that this pattern of
sampling was related to success in the task.

Margin sampling vs. information maximization A second
way in which participants’ behavior diverged from the “rational” prediction was their preference for samples that fell
along the category margins over items that oﬀered information about all three categories (i.e., those located at the junction of the boundaries). From the perspective of an ideal observer (i.e., a model that can represent the full set of possible
hypotheses and use Bayesian inference to update its beliefs),
the most eﬃcient strategy is to maximize the amount of information contained in each observation. Sampling at the category margins should only decrease the eﬃciency of learning
since it will tend to rule out a smaller number of hypotheses,
which raises the question of why this kind of behavior was so
common in our task.
In our discussion we motivated the margin sampling model
by noting that people might decompose a complex prob-

729

lem into simpler pieces. e use of such a strategy may reect a participant’s limited ability to simultaneously represent
all possible alternatives and to remember prior observations.
us, margin sampling may re ect an adaptation whereby
people isolate individual components to learn in succession.
Separately testing the role of diﬀerent features is an important
part of scienti c thinking in general (Klahr & Dunbar, 1988;
Kuhn & Dean, 2005), particularly when intervention is necessary to remove the eﬀect of confounding variables. Importantly, our results do not reveal the particular cognitive processes underlying participants’ decisions, but merely provide
a descriptive account of their overall behavior. Nonetheless,
they provide a useful constraint for theories of information
sampling, particularly when applied to more complex tasks
that involve sequential learning and memory demands.

any copyright annotation thereon. e views and conclusions contained herein are those of the authors and should not be interpreted
as necessarily representing the oﬃcial policies or endorsements, either expressed or implied, of IARPA, DOI, or the U.S. Government.

References
Austerweil, J., & Griﬃths, T. (2011). Seeking Con rmation Is Rational for Deterministic Hypotheses. Cognitive Science, 35, 499–
526.
Avrahami, J, Kareev, Y, Bogot, Y, Caspi, R, Dunaevsky, S, & Lerner,
S. (1997). Teaching by examples: Implications for the process
of category acquisition. e Quarterly Journal of Experimental
Psychology Section A, 50(3), 586–606.
Bruner, J. (1961). e act of discovery. Harvard Educational Review,
31(1), 21–32.
Gureckis, T., & Markant, D. (in revision). A cognitive and computational perspective on self-directed learning. Perspectives in
Psychological Science.
Klahr, D, & Dunbar, K. (1988). Dual space search during scienti c
reasoning. Cognitive Science, 12, 1–48.
Klayman, J, & Ha, Y. (1989). Hypothesis testing in rule discovery:
strategy, structure, and content. Journal of Experimental Psychology: Learning, 15(4), 596–604.
Kuhn, D., & Dean, D. (2005). Is developing scienti c thinking all
about learning to control variables? Psychological Science,
16(11), 866.
Lagnado, D. A., & Sloman, S. (2004). e advantage of timely intervention. Journal of Experimental Psychology: Learning, Memory, and Cognition, 30(4), 856–876.
Markant, D., & Gureckis, T. (2010). Category Learning rough Active Sampling. In S. Ohlsson & R. Catrambone (Eds.). Austin,
TX: Cognitive Science Society.
Markant, D., & Gureckis, T. (in revision). e impact of self-directed
information sampling on learning. Journal of Experimental
Psychology: General.
Mathy, F., & Feldman, J. (2009). A rule-based presentation order
facilitates category learning. Psychonomic bulletin & review,
16(6), 1050–1057.
Navarro, D., & Perfors, A. (2011). Hypothesis generation, sparse categories, and the positive test strategy. Psychological review,
118(1), 120.
Nelson, J. (2005). Finding useful questions: On Bayesian diagnosticity, probability, impact, and information gain. Psychological
Review, 114(3), 677.
Nelson, J, & Movellan, J. (2001). Active inference in concept learning.
Advances in Neural Information Processing Systems, 45–51.
Nelson, J., McKenzie, C., Cottrell, G., & Sejnowski, T. (2010). Experience Matters: Information acquisition optimizes probability
gain. Psychological Science, 21(7), 960.
Oaksford, M, & Chater, N. (1994). A rational analysis of the selection
task as optimal data selection. Psychological Review, 101(4),
608–630.
Rottman, B., & Keil, F. (2012). Causal structure learning over time:
observations and interventions. Cognitive Psychology, 64(1),
93–125.
Settles, B. (2009). Active Learning Literature Survey (tech. rep.
No. 1648).
Skov, R, & Sherman, S. (1986). Information-gathering processes:
diagnosticity, hypothesis-con rmatory strategies, and perceived hypothesis con rmation. Journal of Experimental Social Psychology, 22(2), 93–121.
Sobel, D., & Kushnir, T. (2006). e importance of decision making
in causal learning from interventions. Memory and Cognition,
34(2), 411.
Trope, Y, & Bassok, M. (1982). Con rmatory and diagnosing strategies in social information gathering. Journal of Personality and
Social Psychology, 43(1), 22–34.
Wason, P. (1960). On the failure to eliminate hypotheses in a conceptual task. e Quarterly Journal of Experimental Psychology,
12(3), 129–140.

Measuring subjective uncertainty. It is important to consider that the probability judgments we collected provide an
incomplete picture of participants’ uncertainty over the course
of the task. Although we found some evidence that fast and
slow learners diﬀered in the kinds of samples they collected,
because uncertainty judgments were assessed on only half
of sampling trials it is diﬃcult to draw strong conclusions
about the impact of those samples on classi cation accuracy.
Moreover, we cannot be sure that the judgments reported by
participants accurately re ected their subjective belief since
there were no costs for failing to report accurately1 . ese issues arise whenever considering sampling models based on a
learner’s subjective uncertainty rather than objective measures
of value such as information gain, and as such present an important challenge to be addressed in future work.

Conclusion
Past accounts of information sampling have suggested that a
single normative model might account for people’s decisions
across many learning problems, and that people tend to seek
out data that lead to the greatest reduction in uncertainty. In
contrast, we found little evidence of a single sampling norm
that was consistently applied across individuals. Instead, participants’ sampling choices seem to re ect ongoing aspects of
constructive problem solving. Our approach highlights the
need for theories of self-directed learning to move beyond individual measures of information value to capture interactions
with task demands and cognitive constraints.

Acknowledgments
e authors wish to thank the reviewers for their helpful comments.
is work was supported by the Intelligence Advanced Research
Projects Activity (IARPA) via Department of the Interior (DOI) contract D10PC20023. e U.S. Government is authorized to reproduce
and distribute reprints for Governmental purposes notwithstanding
1
Two aspects of our procedure may lessen the impact of this concern. First, we were able to measure a failure to respond by randomly
initializing the cursor position before each rating, and found that
people changed the position in about 95% of ratings. Second, because
judgments were displayed alongside the category label feedback, participants may have been encouraged to respond accurately in order
to facilitate processing of that feedback

730

