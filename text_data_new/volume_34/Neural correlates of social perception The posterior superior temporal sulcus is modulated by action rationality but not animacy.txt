UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Neural correlates of social perception: The posterior superior temporal sulcus is modulated
by action rationality, but not animacy

Permalink
https://escholarship.org/uc/item/8hv366nw

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Deen, Ben
Saxe, Rebecca

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Neural correlates of social perception: The posterior superior temporal sulcus is
modulated by action rationality, but not animacy
Ben Deen (bdeen@mit.edu) and Rebecca R. Saxe (saxe@mit.edu)
Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology
Cambridge, MA 02139
Abstract

Pelphrey, Morris, & McCarthy, 2004; Pelphrey, Singerman,
Allison, & McCarthy, 2003; Saxe, Xiao, Kovacs, Perrett, &
Kanwisher, 2004; Vander Wyk, Hudac, Carter, Sobel, &
Pelphrey, 2009). Such actions have been referred to as
incongruent, irrational, or unexpected.
This effect has been interpreted as evidence that the pSTS
is sensitive to the goals or intentions underlying human
motion. For instance, Pelphrey et al. (2004) argued that the
pSTS is involved in predicting actions in a given context
based on an “intentional stance,” in which actions are
determined by a goal state and an assumption that the agent
will choose the most efficient means to achieve the goal
given situational constraints. They proposed that when this
prediction is violated, the pSTS must engage in extra
processing to explain the observed action in other terms,
which would explain its stronger response to unexpected
actions.
Another line of research supporting the role of pSTS in
action understanding as employed animations of simple
geometric shapes as stimuli (Castelli, Happé, Frith, & Frith,
2003; Gobbini, Koralek, Bryan, Montgomery, & Haxby,
2007). These studies have found a stronger pSTS response
to animations depicting social interactions between animate
shapes, compared with animations of shapes moving as
inanimate physical objects. This demonstrates that the role
of the pSTS extends to animations that lack the form and
motion kinematics of humans, but imply intentional action.
However, such comparisons have been largely visually
uncontrolled, and could also reflect one of a number of
processes: detecting agents, processing of their motion or
intentions, or processing of interactions between multiple
agents.
The present study aimed to investigate the neural
correlates of social perceptual processes, using geometric
shape stimuli. In particular, we use dot-chain stimuli
perceived as slithering snakes or worms, which provide a
strong percept of animacy without the need for multiple,
interacting agents (Gao, New, & Scholl, 2011). This
ensures that any effects observed do not relate to processing
interactions between agents (c.f. Centelles, Assaiante,
Nazarian, Anton, & Schmitz, 2011). To investigate each of
the subprocesses listed above, we separately manipulated
the perceived animacy, goal-directedness, and path
rationality (or expectedness) of the animations. We first
performed a behavioral study, eliciting judgments about
these animations on various dimensions. The animations
were then used as stimuli for an fMRI experiment, to
investigate the response of the pSTS, as well as motionsensitive area MT+, as a control region.

Recent research has investigated the neural basis of social
perception, the ability to make high-level social inferences
from perceptual information. The right posterior superior
temporal sulcus (pSTS) has been identified as a candidate
region for this ability, but the specific processes to which the
pSTS contributes remain unclear. In the present study, we
investigated the neural correlates of social perception using
simple animated geometric shape stimuli, separately
manipulating the perceived animacy, goal-directedness, and
path rationality in the animations. We did not find an
increased pSTS response to animate or goal-directed
animations. However, we found that across conditions, the
pSTS response tracked path rationality, with stronger
responses to irrational paths. This is consistent with prior
neuroimaging research on the perception of human actions,
and supports the claim that the pSTS is involved in action
understanding.
Keywords: social perception, fMRI, superior temporal sulcus

Introduction
Humans have a remarkable ability to infer the dispositions
and intentions of other agents from perceptual information,
and specifically from motion patterns such as hand and
body motion, gaze shifts, and facial motion. This ability,
termed social perception, comprises a number of
subprocesses: the detection of agents in an environment,
perceptual analysis of their motion, inference about social
properties from the agent’s actions and their context, and
prediction of future actions based on these properties.
Recent research has begun to probe the neural basis of
these processes, although the relevant brain regions and
their specific functional role is still debated. One line of
research has pointed to the right posterior superior temporal
sulcus (pSTS) as a critical region for social perception
(Allison, Puce, & McCarthy, 2000). This region responds
more strongly to (human) biological motion than motion of
inanimate objects (e.g. Grossman et al., 2000; Pelphrey et
al., 2003). These responses might relate to the detection or
perceptual analysis of biological motion, to higher-level
processing of the intentions underlying the actions, or to
some combination thereof.
Another set of studies indicates that the pSTS response to
human actions is modulated by inferred intentions.
Specifically, actions that violate inferred intentions in a
given context, such as twisting empty space next to a gear
rather than a gear itself, elicit a stronger pSTS response than
the expected actions, across a range of contexts and specific
actions (Brass, Schmitt, Spengler, & Gergely, 2007;

276

Methods
Experiment 1: Behavioral study
Participants For the behavioral study, responses were
gathered using Amazon Mechanical Turk. There were 16
types of animation per condition, and 15 responses were
elicited for each animation, yielding a total of 240 responses
per condition. Participants were constrained to be from the
United States, and to have a minimum 95% approval rating
from prior Turk studies. The survey included several foil
questions (e.g., what is the color of the dots?), and responses
with incorrect answers to these questions were rejected.
Figure 1: Schematic illustrations of the animation stimuli (not to
scale). Note that the actual trajectories were not straight lines, but
winding paths (see Methods section).

Stimuli The stimuli consisted of a set of 4s-long animations
of dots (i.e. circles) and dot-chains moving within a squareshaped environment, with walls present in some conditions
as obstacles. For the head dot of the snake, motion was
determined using the chase-subtlety algorithm from Gao,
Newman, & Scholl (2009). In this algorithm, the velocity of
the dot has a fixed magnitude, with a direction that updates
periodically (every 5 frames or .167s, in the present study).
The direction is chosen probabilistically: if the angle that
directs the dot toward its goal is denoted α and the subtlety
parameter is denoted γ, the new direction is chosen from a
uniform distribution over the interval [α-γ,α+γ], where
γ=π/12 in this study. This results in a dot that takes a
slightly winding path toward a goal. Tail dots in the chain,
if present, followed the path taken by the head dot with a
slight lag.
Conditions 1-4 were intended to manipulate animacy and
goal-directedness in a 2x2 design (see figure 1 for a
schematic depiction of each condition). Animacy was
modulated by the presence or absence of six tail dots,
leading to the percept of a worm or snake. Goaldirectedness was modulated by the presence of a goal-dot at
the end of the trajectory.
Conditions 5-8 were intended to manipulate path
rationality. Stimuli in conditions 5-7 were considered
animate and goal-directed, but involved trajectories with a
bend, which was either around a wall or around nothing.
These conditions were 5) rational (full wall), 6) semirational (half of a wall), and 7) irrational (no wall). As a
visual control, walls were added to conditions 1-4 and 7-8,
which were not relevant to the paths. In condition 8
(wander), the dot-chain had no goal and increased subtlety
(γ=π/4), leading to a percept of a randomly wandering
snake, intended as a highly irrational, unexplainable action.
For each condition, 4 specific animations were designed
with distinct trajectories; these stimuli were rotated 0°, 90°,
180°, and 270° to create 16 animations per condition. Two
visual confounds should be noted: the animate condition had
more dots and therefore more motion than the inanimate
condition; and the wander condition had more changes in
motion than all other conditions. These issues are further
discussed below.

Behavioral measures Participants viewed the animations
and were asked to respond to the following questions on a
seven-point scale: 1) How much did the moving dot look
like a living, animate thing, as opposed to an inanimate
physical object? 2) To what extent did the moving dot
appear to have a goal or goals? 3) To what extent did the
dot’s path seem strange or irrational? Additionally, several
foil questions were asked to ensure meaningful responses.
Data analysis We performed several planned unpaired twosample t-tests to test the specific effects of interest. We first
tested the effect of having a tail (conditions 3 and 4 versus 1
and 2) on animacy ratings. We then tested the effects of
having a goal dot (2 and 4 versus 1 and 3), of path
irrationality (7 versus 5), and of wandering over irrationality
(8 versus 7), on both goal-directedness and irrationality
ratings. Additionally, we performed a post-hoc test for the
effect of having a goal dot for animations with a tail (4
versus 3) on animacy ratings.

Experiment 2: fMRI study
Participants 20 subjects (aged 19-28, mean 23.1; 10
female) were recruited for the fMRI study. All participants
had normal or corrected-to-normal vision and no history of
neurological or psychiatric disorders, and gave written,
informed consent in accordance with the requirements of the
MIT institutional review board.
Stimuli The animations used in the fMRI experiment were
the same as those used in the behavioral study. Stimuli
were presented in a jittered, event-related design, with a
variable inter-stimulus interval of 0-15 seconds, during
which a central fixation cross was presented.
The
experiment comprised 8 blocks lasting 9 minutes and 44
seconds, each containing 8 stimuli per condition, for a total
of 64 stimuli per condition. Participants performed a oneback task on animations during the scan, to maintain
attention; repeat trials were not included in the analysis.

277

Additionally, each subject received a localizer scan
intended to define the pSTS and motion-sensitive area MT.
This consisted of three conditions in a blocked design:
biological motion (point-light displays [PLDs] depicting
human motion; cf Grossman et al. 2000), scrambled motion
(PLDs with initial dot positions scrambled), and static
luminance change (static dots changing in luminance). Each
subject received 2 or 3 runs lasting 7 minutes and 24
seconds each, and comprising 6 12s-long blocks per
condition separated by a 12s interstimulus interval.
Participants performed a one-back task on individual
animations within the blocks, to maintain attention.
fMRI Data Acquisition Data were acquired on a 3T
Siemens Tim Trio scanner, with a 32-channel head coil.
Following high-resolution anatomical scans, functional
images were acquired with an echo planar imaging pulse
sequence sensitive to blood-oxygen-dependent (BOLD)
contrast (repetition time [TR] = 1s, echo time [TE] = 30ms,
flip angle = 70°, voxel size 3x3x3mm, matrix 64x64, 16
axial slices). Because of our interest in specific brain
regions, we used a sequence with limited coverage (of
visual cortex and the STS), but a TR of 1s for increased
power and temporal resolution. The first four volumes of
each acquisition were discarded to allow the system to reach
steady state. For localizer scans, a similar pulse sequence
was used, but with TR=2 and full brain coverage (32 axial
slices).
fMRI Data Analysis Preprocessing and analysis of fMRI
data was carried out using the FMRIB Software Library
(FSL) version 4.1.8, supplemented with Freesurfer 4.5.
Preprocessing steps included rigid-body motion correction,
correction for interleaved slice timing, brain extraction,
spatial smoothing (5mm FWHM Gaussian kernel), and
highpass temporal filtering (100s cutoff).
Functional
images were registered to anatomical images using
Freesurfer’s bbregister; anatomical images were in turn
normalized to MNI space using FSL’s nonlinear registration
image registration tool (FNIRT).
For data analysis, whole-brain general linear model-based
analyses were initially performed for the main task and
localizer, for the purpose of defining regions-of-interest
(ROIs) in individual subjects. Regressors were defined as
boxcar functions with nonzero values during the duration of
the stimuli; these were then convolved with a canonical
double-gamma hemodynamic response function. FSL’s
FILM prewhitening was applied to account for residual
autocorrelation. Statistical maps were thresholded with an
initial cutoff of Z > 2.3, followed by Gaussian random field
theory-based thresholding with a cluster-wise threshold of P
< .05, to correct for multiple comparisons.

Figure 2: Behavioral responses. Plot of responses to three
questions—regarding
animacy,
goal-directedness,
and
irrationality—for the eight conditions. Error bars give standard
error.

To define the right pSTS, the main task was used rather
than the localizer, because the latter did not consistently
yield pSTS responses in individual subjects. The contrast of
all conditions versus rest in the main task was used to define
the pSTS, because this contrast is orthogonal to any
balanced between-condition comparison. As a control, we
investigated responses in right MT+, a motion-sensitive
region thought include retinotopic areas MT, MST, and
possibly others (Amano, Wandell, & Dumoulin, 2009).
This was defined using the localizer scan, by contrasting
scrambled motion with static luminance change. Regions
were defined as all active voxels within a 7.5mm-radius
sphere around the peak coordinate within an anatomical
search space, intersected with a gray matter mask derived
using Freesurfer. The search spaces consisted of the STS
(for pSTS), and lateral occipito-temporal cortex (for MT+).
Mean betas values across the ROI were extracted for each
subject. Planned, paired two-sample t-tests were performed

278

for each ROI, testing for effects of 1) animacy (conditions 3
and 4 vs 1 and 2), 2) goal-directedness (2 and 4 vs 1 and 3),
3) irrationality (7 vs 5), and 4) wandering over irrationality
(8 vs 7). Responses were averaged when combining two
conditions. Additionally, a post-hoc test assessed the effect
of goal-directedness for animations with a tail (condition 4
versus 3) on the pSTS response.

Results
Behavioral results
The behavioral results are shown in figure 2. As predicted,
the presence of a tail or dot-chain significantly increased the
percept of animacy (t[958] = 19.43, p < 10-70). In
spontaneous post-scan self-reports from subjects who
participated in the fMRI experiment (a separate group of
subjects), many described the dot-chain stimuli as either a
“worm,” “snake,” or “tadpole,” that was “swimming” or
“wiggling.” Additionally, we observed that for stimuli with
tails, animations that contained a visible goal dot were rated
as more animate than those without. A post-hoc test of this
difference was significant (t[478] = 2.56, p < .02).
Ratings of goal-directedness were increased by the
presence of a goal dot, as expected (t[958] = 25.40, p <
10-108). Additionally, goal-directedness ratings were lower
for irrationality than rational stimuli (t[478] = -13.86, p <
10-36), and for wandering than irrational stimuli (t[478] =
-24.79, p < 10-87).
Ratings of irrationality were higher for irrational than
rational paths, as expected (t[478] = 18.00, p < 10-54).
Additionally, they were higher for wandering than irrational
paths (t[478] = 8.96, p < 10-17). The presence of a goal dot
also influenced irrationality ratings, with higher ratings for
stimuli without a visible goal (t[958] = -11.27, p < 10-27).
Thus, we found an inverse relationship between ratings of
goal-directedness and irrationality: namely, animations
depicting an efficient path toward a clear goal were rated as
highly goal-directed and rational, while paths that lacked a
clear goal or used an inefficient trajectory were rated as less
goal-directed and more irrational.

fMRI results
Results from the right pSTS ROI analysis are shown in
figure 3. The ROI was found in 19 out of 20 subjects. We
found no effect of the animacy manipulation (t[18] = -.03, p
= .98), nor the goal dot manipulation (t[18] = -1.17, p = .26).
However, the pSTS did respond more strongly to irrational
than rational stimuli (t[18] = -2.25, p < .05), and to
wandering than irrational stimuli (t[18] = 3.03, p < .01).
Additionally, we observed that among animate stimuli, or
stimuli with a tail, the pSTS had a lower response to
animations with a visible goal dot. A post-hoc test for this
comparison was significant (t[18] = -2.30, p < .05). Thus,
the pSTS response to animate stimuli tracked behavioral
ratings of irrationality, but did not correspond to ratings of
animacy or goal-directedness.

Figures 3 (above) and 4: Mean beta values extracted from right
posterior superior temporal sulcus (pSTS, figure 3) and right MT+
(figure 4) regions of interest (ROIs). Error bars give standard
error. The images above the bar plots show the locations of ROIs
across subjects: for each voxel, the value plotted is the fraction of
subjects whose ROI contained this voxel.

279

Results from the right MT+ ROI analysis are shown in
figure 4. The ROI was found in 19 out of 20 subjects. For
this ROI, there was a main effect of the animacy
manipulation (t[18] = 5.57, p < 10-4). This is to be expected
for a retinotopic region, insofar as the dot-chain stimuli
occupied more of the visual field than the individual dot
stimuli, and therefore this difference may not reflect the
processing of animacy.
There was no effect of goal-directedness (t[18] = .52, p =
.61) or irrationality (t[18] = .97, p = .34) on the MT+
response. These comparisons were tightly controlled for the
magnitude and direction of motion, so no differences
relating to motion processing were expected.
There was an effect of wandering over irrational stimuli
in MT+ (t[18] = 2.71, p < .02). This effect may also result
from motion processing. Although the magnitude of motion
is equated across wander and irrational conditions, the
direction and derivatives thereof are not controlled. A
larger number of changes in motion direction in the wander
condition may have lead to decreased adaptation of
direction-specific neural responses in MT+, and therefore an
increased BOLD signal.

consisting of Mechanical Turk responses to similar stimuli,
in which this effect was also observed.
Our imaging results show that with these stimuli, the
pSTS response is not modulated by a large difference in
perceived animacy between dot-chain and individual dot
stimuli. This result appears inconsistent with claims that the
pSTS is generally involved in the detection of agents or
animate beings (e.g. Gobbini et al., 2011; Shultz and
McCarthy, 2011). This finding is not directly inconsistent
with any prior empirical result in the literature, to our
knowledge, because prior contrasts involving animacy (e.g.
faces versus nonfaces, biological motion versus scrambled
motion, Heidel-Simmer animations versus control
animations) have been confounded with other factors (such
as specific static or dynamic visual properties, the presence
of a human, or the presence of an interaction), and thus
cannot be considered pure animacy contrasts.
Another interpretation of these data is that the pSTS is
involved in the detection of animacy, but relies on local cues
such as the motion of individual dots in our animations,
which are similar for the animate and inanimate conditions.
This interpretation must invoke other processes to explain
the large behavioral difference in animacy judgments for
dots and dot-chains. However, this explanation appears
inconsistent with the fact that the pSTS response to human
motion is modulated by global form, and not just local cues
(e.g. Grossman et al. 2000), unless this modulation relates to
a process separate from agent detection.
The pSTS response in our data was also not increased by
perceived goal-directedness.
This is consistent with
findings that the right pSTS responds similarly to intentional
and externally caused human movements (Morris, Pelphrey,
& McCarthy, 2008), and to goal-directed and non-goaldirected actions by robots (Shultz and McCarthy, 2011).
This result might be interpreted as evidence against a role of
pSTS in processing action goals. However, given the
inverse relationship observed between ratings of goaldirectedness and irrationality, there is another potential
explanation. This region may apply an assumption that
actions by animate beings are intentional, and attempt to
explain all such actions. In this case, actions with a visible
goal may be easier to explain, and thus evoke a weaker
pSTS response, as observed for animate stimuli.
While the pSTS response in the present study did not
increase with animacy or goal-directedness, it did track the
perceived irrationality of the actions depicted. This is
consistent with prior findings of irrationality effects during
the perception of human actions, as described above, and
extends these results to nonhuman agents depicted by
simple geometric shape animations.
Thus, whatever
computations underlie this irrationality effect are likely
similarly applied to the actions of human and nonhuman
agents.
We note that animations in the rational, irrational, and
semirational conditions were perfectly controlled for visual
motion; therefore motion cannot be driving the differences
observed. The wander condition did have a motion change

Discussion
We have shown behaviorally that dot-chain stimuli
governed by a simple motion algorithm can evoke a strong
percept of animacy, and in certain conditions, goaldirectedness, replicating and extending the findings of Gao
et al. (2011). Furthermore, we found that the right pSTS
response to these stimuli is not stronger for stimuli rated as
animate or goal-directed. However, this response was
modulated by path irrationality: for conditions 3-8 (the
conditions rated as highly animate), pSTS activity
corresponds well with irrationality ratings, as can be seen by
comparing figures 2 and 3. By comparison, activity in right
MT+ was not generally modulated by irrationality, instead
tracking the amount of motion and change in motion in the
stimuli, as expected.
Several results of interest came from our behavioral
analysis. We found that ratings of goal-directedness and
path irrationality had an inverse relationship. Straight paths
without goal dots were rated as more irrational than those
with visible goals, and inefficient trajectories toward a goal
were rated as less goal-directed than efficient trajectories.
Thus, these ratings may have both derived from a common
implicit quantity, perhaps corresponding to the extent to
which an action can be explained in terms of perceptible
goals and environmental constraints (e.g. Gergely & Csibra,
2003).
Furthermore, we found that for dot-chain stimuli, which
were perceived as highly animate, the presence of a goal dot
had a small but significant influence on ratings of animacy.
This is consistent with the hypothesis that goal-directedness
provides a cue to animacy (e.g. Shultz and McCarthy,
2011). This result was unexpected and assessed with a posthoc test, and thus should be independently replicated;
however, we note that we have another, unpublished dataset

280

confound, as noted above. However, given the similar
pSTS response to animate and inanimate conditions, which
had a substantial difference in visual motion, we consider it
implausible that the high response to the wander condition
in this region results from motion properties.
As discussed above, the irrationality effect has been
interpreted as supporting a role of the pSTS in action
understanding, or inferring goals of actions and predicting
future actions based on these goals. There are a number of
interpretations of the irrationality effect consistent with this
claim. For instance, this response might relate to the
inference of a more complex goal structure underlying
irrational actions. On this hypothesis, the pSTS tries to
rationalize all actions, including ostensibly irrational ones,
and simply requires a more complex explanation for the
latter, perhaps positing extra goals that weren’t immediately
inferred from the context. Another possible interpretation is
that this response constitutes an error detection signal for
actions. On this hypothesis, the pSTS response doesn’t
reflect a reappraisal of the causal structure behind an
irrational action, but simply reflects a signal indicating that
the inferred structure was not correct. Future research
should attempt to distinguish between these hypotheses.
Another question is of the specificity of this effect to
actions. Does the right pSTS respond to any unexpected
event, or more specifically, to unexpected visual motion
events? While our current data doesn’t speak to this
question, Saxe et al. (2004) showed that while the pSTS
responds more strongly when a walking human pauses
behind a bookshelf than when he walks without pause, this
isn’t the case for gliding objects. This provides some
preliminary evidence that this effect is specific to intentional
actions, but this question should be followed up in
subsequent studies.
In sum, we have shown that the pSTS response to
animations of geometric shape motion is not increased by
animacy or goal-directedness, but is modulated by action
rationality.
Future research should explore the
computations that underlie this effect, and their precise
contribution to action understanding.

Castelli, F., Happé, F., Frith, U., Frith, C. (2000). Movement and
mind: a functional imaging study of perception and
interpretation of complex intentional movement patterns.
NeuroImage 12(3), 314-325.
Centelles, L., Assaiante, C., Nazarian, B., Anton, J.-L., Schmitz, C.
(2011). Recruitment of both the mirror and the mentalizing
networks when observing social interactions depicted by pointlights: A neuroimaging study. PLoS One 6(1), e15749.
Gao, T., Newman, G.E., Scholl, B.J. (2009). The psychophysics of
chasing: A case study in the perception of animacy. Cognitive
Psychology, 59(2), 154-179.
Gao, T., New, J.J., Scholl, B.J. (2011). Perceived biological agency
in a slithering snake animation. Poster presented at the annual
meeting of the Vision Sciences Society, 5/10/11, Naples, FL.
Gergeley G., Csibra G. (2003). Teleological reasoning in infancy;
the naïve theory of rational action. Trends in Cognitive Science,
7(7), 287-292.
Gobbini, M.I., et al. (2011). Distinct neural systems involved in
agency and animacy detection.
Journal of Cognitive
Neuroscience, 23(8), 1911-1920.
Gobbini, M.I., Koralek, A.C., Bryan, R.E., Montgomery, K.J.,
Haxby, J.V. (2007). Two takes on the social brain: a comparison
of theory of mind tasks. Journal of Cognitive Neuroscience,
19(11), 1803-1814.
Grossman, E.D., Donnelly, M., Price, R., Pickens, D., Morgan, V.,
Neighbor, G., et al. (2000). Brain areas involved in perception of
biological motion. Journal of Cognitive Neuroscience, 12(5),
711-720.
Morris, J.P., Pelphrey, K.A., McCarthy, G. (2008). Perceived
causality influences brain activity evoked by biological motion.
Social Neuroscience, 3(1), 16-25.
Pelphrey, K.A., Mitchell, T.V., McKeown, M.J., Goldstein, J.,
Allison, T., McCarthy, G. (2003). Brain activity evoked by the
perception of human walking: Controlling for meaningful
coherent motion. The Journal of Neuroscience, 23(17), 68196825.
Pelphrey, K.A., Morris, J.P., McCarthy, G. (2004). Grasping the
intentions of others: The perceived intentionality of an action
influences activity in the superior temporal sulcus during social
perception. Journal of Cognitive Neuroscience, 16(10), 17061716.
Pelphrey, K.A., Singerman, J.D., Allison, T., McCarthy, G. (2003).
Brain activation evoked by perception of gaze shifts: The
influence of context. Neuropsychologia, 41(2), 156-170.
Saxe, R., Xiao, D.-K., Kovacs, G., Perrett, D.I., Kanwisher, N.
(2004). A region of right posterior superior temporal sulcus
responds to observed intentional actions. Neuropsychologia,
42(11), 1435-1446.
Vander Wyk, B.C., Hudac, C.M., Carter, E.J., Sobel, D.M.,
Pelphrey, K.A. (2009). Action understanding in the superior
temporal sulcus region. Psychological Science, 20(6), 771-777.

Acknowledgments
We are grateful to Hilary Richardson and Nicholas Dufour
for help with data collection, and Tao Gao for helpful
discussion. This research was funded by the David and
Lucile Packard foundation.

References
Allison, T., Puce, A., McCarthy, G. (2000). Social perception from
visual cues: Role of the STS region. Trends in Cognitive
Sciences, 4(7), 267-278.
Amano, K., Wandell, B.A., Dumoulin, S.O. (2009). Visual field
maps, population receptives field sizes, and visual field coverage
in the human MT+ complex. Journal of Neurophysiology,
102(5), 2704-2718.
Brass, M., Schmitt, R.M., Spengler, S., Gergely, G. (2007).
Investigating action understanding: Inferential processes versus
action simulation. Current Biology 17, 2117-2121.

281

