UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Knowledge and Political Categorization

Permalink
https://escholarship.org/uc/item/04t2n1k4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Heit, Evan
Nicholson, Stephen

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Knowledge and Political Categorization
Evan Heit (eheit@ucmerced.edu)
Stephen P. Nicholson (snicholson@ucmerced.edu)
School of Social Sciences, Humanities and Arts
University of California, Merced
Merced CA 95343 USA

Abstract
A nationally representative sample of US adults completed
two political categorization tasks. The first was to identify
the political parties for hypothetical candidates with
information given about demographics and stands on issues.
The second task was to decide whether to vote for each
candidate. On the identification task, judgments about
whether a person is a Democrat were almost a perfect mirror
image of judgments of whether a person is a Republican. In
general, respondents were very successful in the identification
task; there was a strong correlation with objective
probabilities. Likewise, respondents were successful at the
voting task, in terms of their own party interests. Success at
these two tasks was positively correlated with a measure of
political knowledge. The pattern of responses was also
influenced by the political party of the respondent; suggesting
that feature weights depended on party membership.
Implications for models of categorization and reasoning are
discussed.
Keywords: Categorization; Expertise; Probability Judgment;
Political Cognition.

Introduction
We propose that political parties should be conceived of as
categories. Following Rosch & Mervis’s (1975) seminal
work on categorization, political parties have a horizontal
dimension corresponding to typicality structure, e.g., Mitt
Romney is a more typical Republican than is Ron Paul. It is
then appropriate to ask what is the function of political
categories (cf., Anderson, 1991; Billman & Heit, 1988;
Markman & Ross, 2003), beyond labeling individuals as
party members. One key function is to support voting,
which can be seen as a category-based inference, e.g.,
knowing that Mitt Romney is a typical Republican would
lead many people to vote for him in a Presidential election.
In previous research (Heit & Nicholson, 2010) we have
collected typicality judgments for a set of real political
candidates. College students rated the individuals either on
typicality as a Democrat or typicality as a Republican. The
relation between the two sets of ratings was strong,
negative, and linear, with a remarkable correlation of
-0.9957. Essentially, whatever made an individual more
typical of one party was seen to make that individual less
typical of the other party (cf., Rosch & Mervis, 1975;
Verbeemen, Vanoverberghe, Storms, and Ruts, 2001). It
was not possible to be typical of both parties, or atypical of
both parties. The results contrasted with other opposing

pairs of categories, male versus female jobs and healthy
foods versus junk foods. We concluded that for political
categories, there is a highly systematic and polarized
representation of knowledge.
Although the results were extremely strong, the study
itself had limitations. For example, students may not be
representative of voters at large. We did not systematically
study the effects of demographic variables such as level of
political knowledge (which might be low for college
students) and party of the respondent. Because the stimuli
were simply names of public figures, we could not tell
which information about these figures was being used.
Also, the dependent variable, typicality, has disadvantages,
because it is not objective and it may not map directly onto
real political behavior such as voting.
Hence, the present experiments substantially improved
upon Heit and Nicholson (2010). Each experiment involved
several hundred adults from a nationally representative
sample of US adults, with information collected about
political knowledge and party membership. The stimuli
were descriptions of hypothetical candidates in terms of
demographic information (race, gender, number of children)
and stands on issues (government spending and abortion).
Information about each candidate’s political party was
omitted from the stimuli; however the objective probability
of being a Democrat or Republican based on demographics
and stands on issues could be determined from national
survey data. In Experiment 1, the task was to identify each
candidate’s party. In effect, we were examining whether
respondents could correctly categorize candidates as
Democrats or Republicans when this information is
withheld. In Experiment 2, the task was voting; respondents
were asked how likely they would be to vote for each
candidate.
A key measure of interest was whether
respondents voted the party line, i.e., Democrats voting for
Democrats and Republicans voting for Republicans. In
general, we were interested in whether performance on these
two tasks depended on political knowledge and party
membership of the respondent. We also examined the
influence of various cues, to see if different cues were used
for the two tasks and by different sub-groups of
respondents.
In the cognitive science literature on categorization,
perhaps the most closely related work addresses the effects
of expertise on biological categorization. For example,
Johnson and Mervis (1997) studied categorization of

1656

songbirds, reporting shifts due to expertise. In effect, what
was the subordinate level for non-experts became the basic
level for experts. Medin and Atran (2004) reviewed an
extensive set of studies showing effects of knowledge and
group membership on biological categorization, cautioning
against conclusions drawn just from Western college
students. For example, Medin, Lynch, Coley, and Atran
(1997) conducted a study of tree experts including
taxonomists, landscapers, and maintenance workers. They
reported differences in categorization and reasoning due to
the goals of each type of expert. These differences appeared
to be mediated by differences in feature weighting for
particular areas of expertise.
(See Hayes, Heit, &
Swendsen, 2010, for a further review of knowledge effects
on category-based reasoning.)
With regard to the issue of political knowledge, political
science research has generally been pessimistic. Political
scientists have emphasized that the US public is largely
ignorant of politics (e.g., Delli Carpini & Keeter, 1996).
The mass public is reported to have minimal levels of
political attention and information as well as incoherent and
unstable attitudes (e.g., Converse, 1964). Despite these low
levels of information and political understanding, most
citizens appear to make do with simple political heuristics
such as relying on single cues, e.g., party labels (e.g., Lau &
Redlawsk, 2006). Notably, in the present study, we require
participants to make judgments from multiple cues, while
information about party labels is withheld. Hence, we are
addressing whether the pessimistic view from political
science is supported.

both houses of the state legislature, adults from Nebraska
and Washington, DC were excluded.
Materials. The key stimuli were the nine hypothetical
candidate descriptions; examples are shown in Table 1.
Candidates were described in terms of gender, race, number
of children, position on government spending, and position
on abortion. The objective probability of each person being
a Democrat or a Republican was determined with survey
data from the 2008 American National Election Study
(ANES). Across the nine descriptions, the objective
probability ranged from 10% to 91% in increments of about
10%. On the survey itself, respondents were informed that
each candidate was either a Democrat or a Republican.
Approximately half of the respondents were asked to judge
the probability that each was a Democrat; the remainder
judged the probability that each was a Republican.
The knowledge measure was based on eight questions.
Four questions required the respondent to correctly identify
the party controlling the US Senate, the US House of
Representations, and the two legislative chambers in the
respondent’s home state. Four more questions asked
respondents if they recognized the names of public officials
(governor, two US senators, and US representative). Based
on a rough median split, respondents with seven or eight
correct responses were considered high knowledge, and the
remainder were considered low knowledge.
Procedure. Respondents participated at their own pace, as
part of a larger Internet-based survey.

Results and Discussion

Experiment 1
Method
Participants. A total of 598 US adults participated, in
September-October 2010, as part of the Cooperative
Congressional Election Study (CCES). Only self-identified
Democrats or Republicans were included, and because the
political knowledge measure referred to party control of

In a conceptual replication of Heit and Nicholson (2010),
the relation between these two kinds of judgments was
extremely strong, negative, and linear, r=-0.9977. (See
Figure 1.) Consistent with the findings of Tversky and
Koehler (1994), the results showed binary complementarity,
that is, there was neither evidence for subadditivity or
superadditivity, and complementary pairs summed to an
average of 99.2%.

Table 1: Sample Stimuli for Experiments 1 and 2.
Description
Joanna is a white female with no children who enjoys watching television, exercising, and
discussing politics with friends. In a recent political discussion he voiced the opinion that
government provides about the right amount of services and that, by law, abortion should never be
permitted.
Emily is a white female with no children who enjoys watching television, exercising, and
discussing politics with friends. In a recent political discussion she voiced the opinion that
government should provide many more services and that, by law, abortion should be allowed under
some circumstances.
George is an African-American male with no children who enjoys watching television, exercising,
and discussing politics with friends. In a recent political discussion he voiced the opinion that
government provides about the right amount of services and that, by law, a woman should always be
able to obtain an abortion.

1657

Obj. Prob. of
Democrat
20.9%

49.5%

72.7%

We next conducted analyses of the cues used by
respondents in each sub-group. The question addressed was
what information was used in making these political
categorization judgments, and whether use of information
varied across groups. Essentially, we conducted four
regression analyses, predicting probability judgments based
on the cues of gender, race, number of children, position on
government spending, and position on abortion for each
sub-group. Because each respondent contributed judgments
for nine items to the analysis, we used a version of the
generalized linear model that accommodates clustered data
(as implemented in the generalized estimating equation
module in SPSS Version 18). Gender was coded 0 for male
and 1 for female; race was coded 0 for white and 1 for
African-American; position on government spending was
arbitrarily coded as a 1, 2, or 3 with higher values indicating
a more favorable position; and position on abortion was
arbitrarily coded as a 1, 2, or 3 with higher values indicating
a more permissive position.

75

50

25

0
0

25

50

75

100

Subjective Probability (%) Candidate is Democrat

Figure 1. Subjective probability candidate is a Democrat
versus subjective probability candidate is a Republican.

100

Figure 2 shows average subjective probability judgments
plotted against objective probabilities. For this composite
measure, all judgments were pooled; judgments about
whether a candidate was a Republican were subtracted from
100% to put them on the same scale as judgments about
whether a candidate was a Democrat. The correlation
between subjective and objective probabilities is
remarkable, r=0.9557, indicating that collectively,
respondents were able to identify candidates’ party
affiliation based on very limited information. Most of the
data points fall above the main diagonal, indicating that the
proportion of Democrats in the stimulus set was somewhat
overestimated overall.
The subjective probability
judgments have a somewhat smaller range than the
objective probabilities.
Of course, the remarkable success of respondents at
judging party membership in the aggregate need not be
reflected at the individual level.
Still, individual
respondents were successful. The median correlation
between objective and subjective probability, at the
individual level, was 0.7523, and the mean correlation was
0.6203. The fact that the mean is lower than the median
reflects that a small number of respondents did very poorly
at this task.
The mean correlations varied as a function of knowledge
and partisanship of the respondents. The mean correlations
for high knowledge Democrats, low knowledge Democrats,
high knowledge Republicans, and low knowledge
Republicans were 0.7214, 0.5597, 0.6265, and 0.5575,
respectively. A two-way ANOVA revealed a main effect of
knowledge, with high knowledge respondents showing
higher correlations, F(1, 591)=15.32, p<.001. Neither the
effect of party membership or the interaction between
knowledge and partisanship reached the level of statistical
significance.

Subj. Comp. Probability (%) Candidate is Democrat

Subjective Probability (%) Candidate is Republican

100

75

50

25

0
0

25

50

75

100

Objective Probability (%) Candidate is Democrat

Figure 2. Objective probability candidate is a Democrat
versus subjective probability candidate is a Democrat.
Before describing the findings, it is worth noting that as in
the real world, within these stimuli there was
multicollinearity among the cues. We had created stimuli
with the aim of covering a wide range of probabilities in
intervals of 10%, rather than breaking up the usual
correlations. In some cases, the demographic and issue
variables were strongly correlated with each other. Hence,
regression coefficients should be interpreted with caution.
With this point made, Figure 3 shows the standardized
regression coefficients across the five cues. In general, the
regression coefficients are rather similar across sub-groups.
Perhaps the most interpretable difference is that stand on
abortion, a highly predictive cue, has more weight for high
expertise Democrats than for low expertise Democrats, and
for high expertise Republicans than for low expertise
Republicans. Paying more attention to this cue would lead

1658

to greater success for the high expertise respondents at the
identification task. Unexpectedly, the African-American cue
shows negative weights. In fact, this cue had a strong
positive correlation with identification as a Democrat. For
example, in a simple regression for all respondents,
predicting judgments from just the African-American cue,
the standardized regression coefficient was 23.16.
However, stand on abortion was correlated with AfricanAmerican, and acted as a suppressor variable. In a
regression with just these two predictor variables, the
standardized regression coefficient for abortion is 30.60 and
the coefficient for African-American drops to -13.69.
Therefore, we would emphasize the similarity of regression
coefficients across sub-groups, and avoid overinterpretation
of specific values.
As an interim summary, we note that so far there is
evidence for main effects of expertise, with higher
knowledge respondents being more successful at the
categorization task. There is little evidence for group
(party) differences or differences in feature weighting.
Overall, respondents’ success at using multiple cues to
identify party membership suggests a much more optimistic
view than the standard view from political science, that
people can, at best, make basic judgments if party label
information is supplied.
12.00

Experiment 1

8.00

4.00
LOW DEM
HI DEM

0.00
AA

F

CHILD

SERVICES

ABORT

LOW REP
HI REP

‐4.00

‐8.00

‐12.00

Figure 3. Estimated regression coefficients for lowknowledge and high-knowledge Democrats, and lowknowledge and high-knowledge Republicans.

Experiment 2
Having shown in Experiment 1 that respondents can
successfully identify party membership of hypothetical
candidates, in Experiment 2 we investigated voting
judgments on these same candidate and compared these
responses to identification judgments.

Method
From the same survey as in Experiment 1, a different set of
573 US adults participated, screened according to the same

criteria.
Political knowledge was measured as in
Experiment 1.
Again, the key stimuli were the nine candidate
descriptions shown in Table 1. However, respondents were
asked how likely they would be to vote for each candidate,
on a scale from 0% to 100%.

Results and Discussion
Figures 4 and 5 show the average voting probability
judgments across the nine descriptions as a function of
objective probability of being a Democrat, for respondents
who identified themselves as Democrats and Republicans,
respectively. For Democratic respondents, there was a
strong, positive relation between a candidate’s objective
probability of being a Democrat and the average probability
of voting to support. The correlation was 0.9000. The
figure is suggestive of a threshold function, with the three
candidates least likely to be Democrats attracting a low level
of votes, and the five candidates most likely to be
Democrats attracting a level of votes above 50%. For
Republican respondents, there was a negative relation,
although not quite as strong as for Democrats, r=-0.6606.
Hence, the results suggest that both Democrats and
Republicans tended to vote the party line (Democrats more
so), even when explicit party information was not given. It
is interesting to compare these correlations to the overall
correlation for Experiment 1, in which respondents’
probability judgments for party identification had a 0.9557
correlation with objective probability. Clearly, voting
judgments are not the same as party identification
judgments. Any lack of voting the party line in Experiment
2 is not due to respondents’ inability to identify candidates’
political parties.
We next examined these correlations at the level of
individual respondents.
For Democrats, the median
correlation was 0.7823, and the mean correlation was
0.5004. For Republicans, the median correlation was
-0.4057, and the mean correlation was -0.2971. As in
Experiment 1, the median and mean correlations at the
individual level are lower than the aggregate correlations,
but they still suggest more party-line voting by Democrats.
For a finer-grained analysis, we looked at mean correlations
as a function of knowledge and partisanship of the
respondents, with high or low knowledge operationalized as
in Experiment 1. The mean correlations for high knowledge
Democrats, low knowledge Democrats, high knowledge
Republicans, and low knowledge Republicans were 0.6009,
0.4013, -0.3351, and -0.2396, respectively. For the purpose
of an ANOVA examining tendency to vote the party line,
correlations for Republican participants were multiplied by 1, for this analysis only. A two-way ANOVA revealed a
main effect of knowledge, with high knowledge respondents
showing stronger correlations, F(1, 569)=11.09, p<.001, and
a main effect of party membership, with Democrats
showing stronger correlations, F(1, 569)=23.24, p<.001.
The interaction between knowledge and partisanship did not
reach the level of statistical significance.

1659

100

spending. Use of these issue cues appears to be greater for
high knowledge participants than for low knowledge
participants. Again, the African-American cue shows
negative weights for Democratic respondents. In fact,
Democrats were much more likely to vote for AfricanAmericans than for whites. For example, in a simple
regression for all Democrat respondents, predicting
judgments from just the African-American cue, the
standardized regression coefficient was 15.91. In a simple
regression for all Republican respondents, predicting
judgments from just the African-American cue, the
standardized regression coefficient was -0.86. Hence,
Republicans were barely influenced by this demographic
cue. Therefore, we would emphasize that cue utilization for
voting appeared to differ considerably as a function of
partisanship and political knowledge, and indeed the cues
for voting are not the same as the cues for party
categorization.

Democrats

Probability (%) of Voting

75

50

25

0
0

25

50

75

100

Objective Probability (%) Candidate is Democrat
12.00

Figure 4. Objective probability candidate is a Democrat
versus voting probability, for Democrats.

Experiment 2

8.00

100

Republicans
4.00
LOW DEM

Probability (%) of Voting

75

HI DEM

0.00
AA

F

CHILD

SERVICES

ABORT

LOW REP
HI REP

‐4.00

50
‐8.00

25
‐12.00

Figure 6. Estimated regression coefficients for lowknowledge and high-knowledge Democrats, and lowknowledge and high-knowledge Republicans.

0
0

25

50

75

100

Objective Probability (%) Candidate is Democrat

Figure 5. Objective probability candidate is a Democrat
versus voting probability, for Republicans.
As in Experiment 1, we next conducted analyses of the
cues used by respondents in each sub-group. Because of
multicollinearity, the results should be taken as suggestive
rather than definitive. Figure 6 shows the standardized
regression coefficients across the five cues.
Unlike
Experiment 1, the regression coefficients varied
considerably across sub-groups. It appears that Democrats
were more influenced by demographic cues such as gender
and number of children than are Republicans, although high
knowledge Democrats were less influenced by demographic
cues than low knowledge Democrats. It appears that
Democrats were more influenced by stand on abortion and
Republicans were more influenced by stand on government

In sum, like Experiment 1, Experiment 2 suggests an
optimistic view of US voters, using multiple cues to vote for
their party interests, even when party labels are omitted
from descriptions. Interestingly, the pattern of responses for
voting was different than for identification, so it did not
seem that respondents treated the two tasks as the same. In
Experiment 2, there were also robust differences in
responses due to expertise and party membership.

General Discussion
The results of the present experiments replicate Heit and
Nicholson (2010) in terms of showing a highly polarized
electorate. Just as our previous study found an almost
perfect negative correlation between typicality in Democrat
and typicality in Republican, here in Experiment 1 we found
an almost perfect negative correlation between estimated
probability that a candidate is a Democrat and estimated

1660

probability that a candidate is a Republican. In Experiment
2, we found that Democrats and Republicans not only
showed different patterns of voting for the same candidates,
but also used different cues or feature weights. Democrats
paid more attention to candidate’s personal information and
stand on the abortion issue, whereas Republicans focused on
government spending. Although we previously concluded
that “The opposite of Republican is Democrat,” here we
found that Democrats and Republicans did not simply
disagree with each other, but actually cared about different
issues and characteristics of candidates.
The respondents were remarkably successful at the
identification and voting tasks. In the aggregate, the
correlation between subjective judgments and objective
probabilities was nearly .96, and the correlation for the
median respondent very respectable, about .75. (We would
refer to the “wisdom of crowds” phenomenon documented
by Surowiecki, 2004, to explain the stronger performance at
the aggregate level.) On the voting task, respondents were
able to vote correctly—vote in their own party interests—
even when labels were omitted.
In terms of connections to categorization research, we see
commonalities with research on expertise in biological
categorization (e.g., Medin et al., 1997, Medin & Atran,
2004). Democrats and Republicans can be seen as experts
who see the same candidate but have different goals, just as
taxonomists, landscapers, and maintenance workers would
see the same tree with different goals. These differences are
mediated by the level of expertise of each voter, suggesting
there are different feature weights for identification and
voting tasks, and for Democrats and Republicans. At this
point, we can only pose the question of whether these
feature weights are optimized for the tasks in the sense of
Nosofsky (1986) and Kruschke (1992).
Indeed, what appears on the surface to be a feature
weighting effect might have a different underlying
explanation. For example, Heit (1998) showed that a
Bayesian model of inductive reasoning can explain what
appears to be a selective weighting effect in reasoning about
either anatomy or behavior of animals (Heit & Rubinstein,
1994) not in terms of selective weighting but in terms of a
hypothesis space that reflects feature co-occurrences. This
account can be generalized to address a variety of selective
effects in both induction and categorization (Kemp, Shafto,
& Tenenbaum, 2012).
To conclude, we believe that studies of political cognition
provide an interesting opportunity for the development and
testing of computational models of categorization and
reasoning.

References
Anderson, J. R. (1991). The adaptive nature of human
categorization. Psychological Review, 98, 409-429.
Billman, D., & Heit, E. (1988). Observational learning
without feedback: A simulation of an adaptive method.
Cognitive Science, 12, 587-625.

Converse, P. E. (1964). The nature of belief systems in mass
publics. In D. E. Apter (Ed.), Ideology and Discontent.
New York: Free Press.
Delli Carpini, M. X., & Keeter, S. (1996). What Americans
Know About Politics and Why It Matters. New Haven:
Yale University Press.
Hayes, B. K., Heit, E., & Swendsen, H. (2010). Inductive
reasoning. Wiley Interdisciplinary Reviews: Cognitive
Science, 1, 278-292.
Heit, E. (1998). A Bayesian analysis of some forms of
inductive reasoning. In M. Oaksford & N. Chater (Eds.),
Rational Models of Cognition.
Oxford: Oxford
University Press.
Heit, E., & Nicholson, S. (2010). The opposite of
Republican: Polarization and political categorization,
Cognitive Science, 34, 1503-1516.
Heit, E., & Rubinstein, J. (1994). Similarity and property
effects in inductive reasoning. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 20, 411422.
Johnson, K. E., & Mervis, C. B. (1997). Effects of varying
levels of expertise on the basic level of categorization.
Journal of Experimental Psychology: General, 126, 248277.
Kemp, C., Shafto, P., & Tenenbaum, J. B. (2012) An
integrated account of generalization across objects and
features. Cognitive Psychology. 64, 35-73.
Kruschke, J. K. (1992). ALCOVE: An exemplar-based
connectionist model of category learning. Psychological
Review, 99, 22-44.
Lau, R. R., & Redlawsk, D. P. (2006). How Voters Decide:
Information Processing During Election Campaigns. New
York: Cambridge University Press.
Markman, A.B., & Ross, B.H. (2003). Category use and
category learning. Psychological Bulletin, 129, 592-615.
Medin, D. L. & Atran, S. (2004). The native mind:
Biological categorization and reasoning in development
and across cultures. Psychological Review, 111, 960-983.
Medin, D. L., Lynch, E. B., Coley, J. D., & Atran, S.
(1997). Categorization and reasoning among tree experts:
Do all roads lead to Rome? Cognitive Psychology, 32, 4996.
Nosofsky, R. M. (1986). Attention, similarity, and the
identification-categorization relationship. Journal of
Experimental Psychology: General, 115, 39-57.
Rosch, E., & Mervis, C. B. (1975). Family resemblances:
Studies in the internal structure of categories. Cognitive
Psychology, 7, 573-605.
Surowiecki, J. (2004). The Wisdom of Crowds. New York:
Doubleday.
Tversky, A., & Koehler, D. J. (1994). Support theory: A
nonextensional representation of subjective probability.
Psychological Review, 101, 547-567.
Verbeemen, T., Vanoverberghe, V., Storms, G., & Ruts, W.
(2001). Contrast categories in natural language concepts.
Journal of Memory and Language, 44, 1-26.

1661

