UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A State-Event Transformation Mechanism for Generating Micro Structures of Story in an
Integrated Narrative Generation System

Permalink
https://escholarship.org/uc/item/9s56z1r8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 34(34)

Authors
Onodera, Kou
Akimoto, Taisuke
Ogata, Takashi

Publication Date
2012-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A State-Event Transformation Mechanism for Generating Micro Structures of Story
in an Integrated Narrative Generation System
Kou Onodera (g231i007@s.iwate-pu.ac.jp)
Graduate School of Software and Information Science, Iwate Prefectural University, 152-52 Sugo
Takizawa, Iwate 020-0193 Japan

Taisuke Akimoto (g236i001@s.iwate-pu.ac.jp)
Graduate School of Software and Information Science, Iwate Prefectural University

Takashi Ogata (t-ogata@iwate-pu.ac.jp)
Faculty of Software and Information Science, Iwate Prefectural University
Abstract

stories using a conceptual dictionary for noun/verb concepts
and transformation rules. We analyze and classify the
relationship between an action and the states in front and
behind for 689 verb concepts to develop a mechanism that
mutually transforms from an action to states or from states to
an action and cyclically repeats the process. The action means
an event in which a verb concept for an action is included as
the central element. A temporal sequence of events is
corresponding to a story. On the other hand, a collection of
states means a static narrative knowledge supporting events.

This paper describes the current version of state-event
transformation system to transform story lines and story worlds
each other using a knowledge base and a conceptual dictionary.
Moreover, we extend the basic framework to a circulative
generation mechanism with a simple mutation function.
Through the preliminary performance checks, we confirmed
that the transformation of story worlds and story lines is
approximately logically adequate and the circular process
produces the diversity of stories. The proposed system is a
module in an integrated narrative generation system and the
pilot version is already implemented. In the context of the
narrative generation system, the proposed system plays roles for
expanding the variation of discourse to be generated and
limiting possible narrative elements at any given time in a
narraive generation process.

Narrative Generation and Proposed Mechanism

Keywords: Narrative generation system; story generation;
state; action; conceptual dictionary.

Introduction
In the context of natural language processing in the wide
sense, the research of narrative generation system which aims
at automatic generation of narrative texts by computer has
been developing from 1960s. Meehan (1977) shows a
classical approach and Bringsjord and Ferrucci (2000) is an
example of the comparatively new result. Along with
traditional literary genres, narrative and story will play
important roles for digital entertainment genres such as
computer game. The mechanism we propose in this paper is a
part in an integrated narrative generation system we have
studied as a project. The applicable goal is creating novel
contents such as automatic generation game, which has not a
fixed story, and narrative generation based narrative or
literature, which is a form of novel containing narrative
generation mechanisms. Moreover, narrative is the strongest
method for organizing and structuring fragmentary
information and a kind of collective knowledge in human
being. The narrative generation system is also associated with
a variety of issues such as the organic formation of
fragmentary information, the diverse interpretation of an
event or events, and so on (Ogata & Kanai, 2010).
In this paper, we deal with a part of mechanism for
generating a story, which is a sequence of events to be
narrated, in the narrative generation process. In concrete
terms, we propose a system to make a correlation between
state and event (action) which are main elements to construct

Three main modules of our narrative generation system are
story generation mechanism, discourse mechanism, and
surface expression mechanism. Story means a sequence of
events to be narrated and discourse means the narrated
structure of events, and both are described with conceptual
representation. Expression contains surface representations
including natural language, animated movie, music, and so on.
The system has a conceptual dictionary and various narrative
knowledge bases used mainly in story and discourse parts.
Although our previous works was to develop the
comparatively independent modules, we are currently starting
to complete an integrated narrative generation system in
which a variety of mechanisms are synthesized by
standardizing data structure for event representation and
constructing a conceptual dictionary to be used in a lot of
modules commonly (Akimoto & Ogata, 2011). Figure 1
shows the overall structure of a pilot version of the system.
The proposed system in this paper is correnponding to both
“SL (story line)→SW (story world)” and ”SW→SL” in the
“Structual operation module”. As mentioned later in detaile, a
story line is a sequence of events and a story world is a
collection of states.

2150

Generative parameters (input by user)
Entire control
or

Control
mechanism
SL→SW
control

Story
control
SW→SL
control

PROPP
control

Discourse
control
CM
control

Expression
control
Music
NLG
mechanism control

Movie
control

Discourse
Movie
Structural SL→SW SW→SL PROPP
CM
NLG
techniques
generation
operation
mechanisms
- Each box is a function
Conceptual dictionary
- Each arrow means function call (and receive a result)
- verb concepts (around 12000)
- noun concepts (around 120000)

Figure 1: The overall structure of an integrated narrative
generation system

A story is represented as a tree structure as shown in Figure
2. Three types of components in a story tree are relation,
event, and state. An event forms a case frame with some
elements such as agent, object, location, and so on. A relation
semantically binds some events or the following part. The
generation mechanism in this level is described in Ogata,
Hori and Ohsuga (1994). The lowest layer of the tree is
formed by states. A state means the precondition and the
result of an event. Each state is represented with some kinds
of frames describing the values of case frames in the
corresponding event, namely it actually is a set of semantic
data. We call the layer of states “story world” and the layer of
events “story line”. An event produces two states and two
states are corresponding to an event. This paper describes the
detailed structures and proposes the mechanism of mutual
transformation processing by refining and expanding previous
studies (Nakashima & Ogata 2008; Onodera, Oishi & Ogata,
2011). In the context of narrative generation system, the
primary roles of this mechanism are providing a function for
generating narrative representations such as descriptions and
explanations besides events sequences and a construction for
limiting possible elements (like agent, object, and place) at
any given time in a narraive generation process, using the
detailed and explicit definition of states.

Research Background
In the research of “the history of narrave” by philosophers
(Noe, 2005), history is a kind of story to transform a chronicle
as chronologically arranged events into a sequence of events
sorted through the narrator‟s filter. As described above, we
devide a narrative gneration process into the information to be
narrated (story) and the narration itself (discourse and surface
expression). It may be thought that the part of state and event
in this paper is corresponding to the chlonicle. One of the
characteristics in our narrative generation system research is
an interdisciplinary approach of the humanities such as
narratology & literary theories and computer science such as
AI. The materialization as a program of the conceptual idea
and theory contributes to give the new tools of thought to
such area. From thie point of view, the problem is that what
kinds of knowledge and techniques are used for executing the
transformation from states as a chronicle to events as a story.
Although we propose only the micro level‟s technique in this
paper, we are aiming at building the narraitve generation
sytem on such conceptual and philosophycal foundation.
In AI, this paper is related to the function of planning that
an agent automatically executes a goal through a goal
oriented process. Planning technique, which is a strong
foundation in many story or narrative generation systems
(Mueller, 1990; Okada & Endo, 1992), generates stories or
relation a

relation

relation b
event
state

event 1
state A
agent object time location

relation c

event 2

state B

plot lines to reach a goal through the recursive division of the
goal. Although the planning is a comparatively macro
framework for story generation, in this paper, we pay
attention to the part of micro transformation process between
states and events without a specific goal. Therefore, it is not
planning in a strict sense. As our narrative generation system
adopts a kind of modular approach in which a variety of
elements are organically integrated, the aspect of goal-based
planning can be incorporated into the system as a different
module.
Next, conceptual dependency theory by Schank (1975) is a
classical study regarding to the semantic categorization of
concepts and categorizes verb concepts into 11 types of
fundamental concepts. It is difficult to faithfully categorize
real diverse concepts in accordance with the theoretical
framework. However, we will able to partially apply it or the
idea as a reference, regarding to the part of especially abstract
actions. A verb thesaurus by Takeuchi (2011) also shows a
detailed system of semantic classification of verbs. It
classifies verbs into basic events (states and activities) and
complicated events (verbs for state change). Verbs for
transitioning among states in this thesaurus are corresponding
to verb concepts for changing states in this paper. Although
our resarch shows more detailed classification about the
caterogies of moving of agent and object, we may be able to
refer to this thesausus‟s classification about other categories,
namely, human relationships, body information such as
personal appearance and physial condition, psychological
information such as emotion, change of hardness and shape of
object, etc. In addition, FrameNet (Fillmore & Baker, 2010) and
Japanese FrameNet (Ohara, 2008) define the semantics of a word
by a semantic frame, which means the structured knowledge
about a typical scene, constructed with the frame elements. And,
VerbNet (Kipper-Schuler, Dang, & Palmer, 2000; KipperSchuler, 2005) is a hierarchical verb lexicon in which each class
is described by semantic predicates, thematic roles, and basic
syntactic frames. Because this research‟s purpose is not building
a conceptual lexicon itself and the implementation from the
viewpoint of the narrative generation system, we do not aim at
the direct use or the direct revision of above resources currently.
However, for revising the knowledge base mentioned later, the
more direct reference will be needed in the future.
Moreover, the proposed system uses a conceptual
dictionary to transform between states and events. As an
example of story generation systems by the use of conceptual
knowledge base, McIntyre and Lapata (2009) proposed a
system which generates stories by using a knowledge base of
compositions of an event sentence and chains of events.
Stories are generated by a kind of tree search of possible
stories. The system has several scoring criteria for pruning
low scored branches. Although this is a completed story
generation system, the proposed system is a mechanism in a
big framework of narrative generation system to be able to
add various other mechanisms such as a selection function
based on some specific criteria on the foundation of a simple
basic mechanism.

An Overview of the Mechanism

stateC

Figure 2: The structure of a story

Figure 3 draws an image of the state-event transformation
mechanism. The state of A (a place in this case) changes or

2151

does not change based on an event. A state includes some
kinds of information such as a place, an agent‟s features, and
object or objects, and so on. These elements in a state are
described by each frame. For example, an agent‟s frame
contains name, location, time, possession, and so on. The
each element is really corresponding to an instance as the
substantiation of each element in a conceptual dictionary. On
the other hand, an event is described by a conceptual
representation form shown in Figure 4. When the system
recognizes a change in the states of agent, object, place, and
time, it infers an event using “state-event transformation
knowledge base”. In contrast, the system can also infer two
states from an event using the same knowledge base. We call
a set of states “story world” and a sequence of events “story
line”. In summary, in a story line, each event is represented
with a case frame including agent, object, location, time, and
so on. In a story world, each state is represented with a set of
four types of frames of agent, object, location, and time
corresponding to above cases. And, each frame is constructed
with slots and the values. A state means static knowledge and
an event means dynamic one generated by the change of two
states. The system can also repeat a circulative transformation
process between states and events. The objective is to add
various changes to the flows of stories through the cyclical
process. However, as the state change and events are the
relationship of one-to-many, in the case of simple circulation,
the change of story worlds remains small compared with the
comparatively large change of story lines. To add a larger
change to story worlds, a kind of simple mutational function
is introduced. This system is implemented by Common Lisp
as with other main parts in the narrative generation system.
The conceptual dictionary is a hierarchical system for verb
and noun concepts developed referring to “Goi-Taikei: a
Japanese lexicon” (Ikehara et al., 1999) and “Japanese
WordNet” (Bond et al., 2009) mainly. It contains about 12000
verb concepts and about 120000 noun concepts. In the current
version in this paper, we limitedly treat only verb concepts
relevant to the “physical transfer” and “possessive transfer”.
The each verb concept is described as a case frame form
Event1

Event2

Taro goes from Morioka station
to a library

A librarian lends
a book to Taro

shown in Figure 4. Oishi and Ogata (2011, 2012) propose the
detailed explanation.

State-Event Transformation Knowledge Base
This stores rules for transforming two states and an event
mutually. As shown in Figure 5, a transformation rule
consists of following three elements: (1) The pattern of the
change of states, (2) a set of preconditions for the change, and
(3) A set of verb concepts associated with the change. This
example means “change of the place where a character exits”.
Above (2) is the condition to apply a transformation rule and
this example means “an agent exits at a place, and the place
and another place exists”. In above (3), a group of verb
concepts produce a same type of state change in common. In
the current step of implementation, 138 “transformation
rules” and 689 verb concepts are contained.
The transformation rules are hierarchically classified. The
highest layer is divided into “the change of location, address,
possession, health, durability, and posture” and “generation
and disappearance” according to the changing element in
each slot in agent, object, and place. Second layer shows the
concrete way of changing in a slot and is classifies into 27
kinds. For example, in the movement of place, there are the
movement among different places, the vertical movement,
and the high/low movement in a same place. And, one or
more rules according to each movement can be defined. For
example, in the movement among different places, an event
satisfies both slots of “from” and “to” in common and another
event satisfies only “from” or “to”. Table 1 lists defined
categories of state change. For example, the change of
location slot in an agent frame or an object frame is
corresponded to 11 types of categories. In this table, “large
classification” means it is based on what (or which slot) is
changed in a state and “small classification” means it is based
on how it changes. For about 4200 kinds of “physical actions
that an agent becomes the subject”, about 2000 kinds of
“other physical actions”, and about 4100 kinds of
“psychological actions”, we are currently proceeding this
expansion and revision by focus on what is changed in a state
(we need to expand frame as necessary), how a state changes,
and what kind of cases a verb concept has.
Type of state changes
(Change of location: instance moves from X to Y)

transformation

StateB

StateA
Morioka station

Library

Rule1: agent moves from X to Y

StateC

Pattern of the change of states (agentX‟s location changes from X to Y)
Precondition (condition1 (there is agentX in locationX))
(condition2 (there is locationX))
(condition3 (there is locationY))
Set of verb concepts (歩く(1)[walk(1)] 移動する(1)[move(1)] …)

Library

Figure 3: An image of the proposed mechanism
Figure 5: A state-event transformation rule

age1 goes loc2
(event 行く(1)[go(1)]
(type action)
(ID 1)
(time (time1 time2)
(agent age1)
(counter-agent nil)
(location loc1)
(object nil)
(instrument nil)
(from nil)
(to loc2))
Describe ID of each frame
in a slot value

Case

Function of case

type

Kind of event (action or happening)
(Prince, 1987)

ID

Identification of an event

time

A pair of starting time
and ending time of event

agent

Agent of the action

counter-agent

Object of the action (living thing)

location

Occurrence of the event

object

Object of the action (no living thing)

instrument

Instrument or tool used by the action

from

Starting position of the action

to

Ending position of the action

Table 1: The classification of transformation rules (the details
are omitted)
Large classification

Figure 4: The conceptual representation form of an event

2152

Small classification

Change of location

Move, Move[up], Move[down], Move[out], Move[in],
Move[near], Move[far], Carry, Go together, Near, Leave.

Change of posture

Stand, Sit, Lie.

Change of possession

Have, Relinquish, Give, Trade, Throw.

Change of health/durability

Death, Break, Damage, Heat.

Change of address

Migrate

Generation disappear

Generation, Disappear, Ingest

Two Processes of Generation
The flows of transformation are from a story line to a story
world (“story world generation”) and from a story world to
a story line (“story line generation”). In addition, these
transformations can be also repeated continuously or cyclically.

Story World Generation Process
The process of story world generation is as follows (Figure
6): (1) The user specifies a story line and each value of agents,
objects, and places in the story line. (2) The system searches a
rule in a state-event transformation knowledge base according
to a verb concept from first event in the story line. (3) The
system selects a rule which has the verb concept in the group
of verb concepts. (4) The system sets a state before the event
which is the precondition in the selected rule. If a state
already exists, the system simply overwrites by the new state.
(5) The system refers the pattern of the change of states in the
rule and makes a state after the event by changing the
previous state set in above (4). (6) The system refers next
event. If it exists, the process returns to above (2). If it does
not exist, the process finishes.

Story Line Generation Process
The flow of story line generation is as follows (Figure 7): (1)
The user specifies two or more states in a story world
according to the numerical order of ID. (2) The system
compares the changed frame(s) and slot(s) in the first two
states. (3) In the state-event transformation knowledge base,
the system searches a transformation rule in which the first
state & the precondition and the change in the second state &
the content of change respectively match. (4) The system
checks the constraints for each verb concept stored in the rule.
story line
A hunter goes from a
house to a mountain
(event go(3)
(time (time1 time2))
(agent Hunter#1)
(from House#1)
(to Mountain#1))

search transformation rules
by the verb concept

Agents, objects, and
locations appears in
the story line
(input by user)

state-event transformation
knowledge base
transformation rules
change of location：rule1

story world
House#1
time1

Mountain#1

Hunter#1

time2

frame
generation

Hunter#1

pattern of
the change
of states

agent is in the „from‟

precondition

agent move from
„from‟ to „to‟

set of verb
concepts

行く(3)[go(3)], …

Figure 6: The flow of story world generation
state-event transformation
knowledge base
transformation rules

story world
House#1
time1
time2

Hunter#1

search
transformation
rules by
two states

precondition
pattern of
the change
of states
set of verb
concepts

(event walk(1)
(time (time1 time2))
(agent Hunter#1)
(from House#1)
(to Mountain#1))

verb conceptual hierarchy
constraint of walk(1)
(agent =“human” or “animal”)

fill value
of each
case of
event

The system can repeat the transformation among story worlds
and story lines. For example, an event such as “Taro goes to
the park from the house” can be transformed into two states,
“Taro is in the house” and “Taro is in the park”. Next, these
states can be transformed into an event that is different from
the former such as “Taro comes to the park from the house”.
The system enables “circulative generation” in which two
types of transformations are repeated each other. A verb
concept in an event in a story line changes within a given
range through such circulative process. However, a story
world does not change from the initial story world because it is
knowledge to prescribe the story content. Story world and story
line have one-to-many relationship in the ordinary mechanism.
Moreover, we introduce a mechanism to produce larger
changes in both story line and story world through the
circulative generation process. Although we can imagine
various methods to actualize it, we implemented a function
using a simple mutation mechanism. In story world
generation, the function randomly changes a state and the
value of an agent or an object in a frame after the generation
process. On the other hand, in story line generation, it
randomly changes an event and a case‟s value in an event
concept after the generation process.

Execution Examples
First, as the input information, we prepare the summary of a
part of Mishima‟s “The sailor who fell from grace with the
sea” (1963) (Figure 8). Table 2 shows a generated story world.
In addition, Figure 9 shows the result of a story line based on
the story world. In these figures, we show the result by a
simple sentence generation program. Figure 8 is a scene that
Ryuji, Noboru, and a “don” move from a hill to a dry dock in
Yokohama. In Figure 9, some changes occur. For example,
Ryuji and Noboru move together in one event and the don
moves as if he comes after Noboru.
Second, circulative generation was attempted based on a tale
in Yanagita‟s “The legends of Tono” (1955) (a story that a
hunter forces a big priest to eat burned stones to punish the big
priest who ate the hunter‟s rice cakes without the permission).
E1: Ryuji#1 takes Sailor cap#1
in Ryuji#1's hand
E2: Ryuji#1 goes from Store#1 to Hill#1
E3: Don#1 goes to Hill#1
E4: Noboru#1 goes to Hill#1
E5: Ryuji#1 supplies Sailor cap#1
to Don#1
E6: Noboru#1 buys Sailor cap#1
E7: Noboru#1 delivers Sailor cap#1
to Ryuji#1
E8: Ryuji#1 leaves Hill#1 for Sugita#1
E9: Noboru#1 leaves Hill#1 for Sugita#1
E10: Don#1 leaves Hill#1 for Sugita#1
E11: Ryuji#1 goes around Slope#1
E12: Noboru#1 goes around Slope#1
E13: Don#1 goes around Slope#1
E14: Ryuji#1 gets to Tunnel#1
E15: Noboru#1 gets to Tunnel#1
E16: Don#1 gets to Tunnel#1

agent moves from
„from‟ to „to‟
歩く(1)[walk(1)], …

conceptual dictionary

story line
Hunter walks from
House to Mountain

Circulative Generation Process

change of location：rule1
agent is in the „from‟

Mountain#1

Hunter#1

Specifically, the system checks whether the agents and
objects are within the range of each constraint. And, the
system allocates agents, objects, and places to the case frame
for a verb concept that satisfies all constraints to generate an
event. (5) If one or more events remain, the process returns to
(2). And if no event, the process finishes.

Hunter#1
(is-a “man")

check
constraints
of each
verb
concepts

noun
human
conceptual
hierarchy people ･･･
person
･･･

gender
man

･･･
woman

E17: Ryuji#1 heads to Hill#2
E18: Noboru#1 heads to Hill#2
E19: Don#1 heads to Hill#2
E20: Ryuji#1 arrives at Dry dock#1
from Hill#2
E21: Noboru#1 arrives at Dry dock#1
from Hill#2
E22: Don#1 arrives at Dry dock#1
from Hill#2
E23: Ryuji#1 sits down in Dry dock#1
E24: Noboru#1 sits down in Dry dock#1
E25: Don#1 sits down in Dry dock#1
E26: Ryuji#1 supplies Sailor cap#1
to Noboru#1
E27: Noboru#1 parts with Sailor cap#1
E28: Noboru#1 takes Tea#1
in Noboru#1’s hand
E29: Noboru#1 supplies Tea#1 to Ryuji#1
E30: Ryuji#1 drinks Tea#1

Figure 8: Input information

Figure 7: The flow of story line generation process

2153

Table 2: A part of generated story world
Store#1
t1
t2
t3
t4

t5
t6
t7

Hill#1

Ryuji#1, Sailor
cap#1
Ryuji#1(have:
Sailor cap#1),
Sailor cap#1

Dry dock#1

generation of realistically possible events, and unrealistic and
fantastical events are generated on the basis of the advanced
rhetorical techniques such as the “defamiliarization”
processing by the relaxation and adjustment of conceptual
constraints using a conceptual dictionary (Zhang, Ono &
Ogata, 2011, 2012). Therefore, the proposed system aims at a
mechanism for generating realistic events and to the extent
possible. As this preliminary check, we confirmed that the
system could generate comparatively adequate and diverse
results in both generation mechanisms except that few
impossible events are generated in the story line processing.
To decrease the impossible events, the elaboration of the
conceptual dictionary is required.
Next, for circulative generation, we executed 15 cycles
from a story line to analyze the degree of change in the
generated story lines. As a result, we observed several types
of changes such as the appearance of new event(s) and the
disappearance of event(s). Table 3 shows the result of
comparison between the 5th story line and the 15th one.
At last, we investigated the naturalness of story lines. The
naturalness simply means that a story has not any realistic
contradiction. We analyzed 10 story lines by a circulative
generation process. As a result, we discovered some types of

…

Noboru#1,Don#1,
Tea#1
Noboru#1,Don#1,
Tea#1
Ryuji#1(have: Sailor cap#1),
Sailor cap#1
Ryuji#1(have: Sailor cap#1),
Noboru#1, Don#1, Sailor cap#1
Ryuji#1, Noboru#1, Don#1 (have:
Sailor cap#1), Sailor cap#1
Ryuji#1, Noboru#1(have: Sailor
cap#1), Don#1, Sailor cap#1
Ryuji#1(have: Sailor cap#1),
Noboru#1,Don#1, Sailor cap#1

Noboru#1,Don#1,
Tea#1
Tea#1
Tea#1
Tea#1
Tea#1

…

E1: Ryuji#1 gets Sailor cap#1
E2: Ryuji#1 escorts Sailor cap#1 to Hill#1
E3: Noboru#1 follows Don#1
from Dry dock#1 to Hill#1
E4: Don#1 buys Sailor cap#1
E5: Noboru#1 buys Sailor cap#1
E6: Ryuji#1 buys Sailor cap#1
E7: Ryuji#1 escorts Noboru#1 to Sugita#1
E8: Don#1 strolls around Sugita#1
E9: Ryuji#1 escorts Noboru#1 to Slope#1
E10: Don#1 advances to Slope#1
E11: Ryuji#1 moves Noboru#1
from Slope#1 to Tunnel#1
E12: Noboru#1 posts Don#1 at Tunnel#1

E13: Ryuji#1 carries Noboru#1
from Tunnel#1 to Hill#2
E14: Don#1 leaves Tunnel#1
E15: Ryuji#1 follows Noboru#1
from Hill#2 to Dry dock#1
E16: Don#1 chases Ryuji#1
E17: Ryuji#1 sits down in Dry dock#1
E18: Noboru#1 sits down in Dry dock#1
E19: Don#1 sits down in Dry dock#1
E20: Ryuji#1 supplies Sailor cap#1
to Noboru#1
E21: Noboru#1 parts with Sailor cap#1
E22: Noboru#1 wins Tea#1 in “lottery”
E23: Noboru#1 supplies Tea#1 to Ryuji#1
E24: Ryuji#1 drinks Tea#1

Input story line

Figure 9: A generated story line

2154

E1: Hunter#1 burns Rice cake#1
E2: Hunter#1 burns Rice cake#2
E3: Hunter#1 burns Rice cake#3
E4: Hunter#1 wins Rice cake#1 in award
E5: Big priest#1 gets to House#1
E6: Big priest#1 collects Rice cake#2
E7: Big priest#1 chews Hunter#1
E8: Hunter#1 abandons Rice cake#1
E9: Hunter#1 buys Rice cake#3
E10: Big priest#1 confiscates Rice cake#3
E11: Hunter#1 chews Big priest#1
E12: Hunter#1 burns Rice cake#4
E13: Hunter#1 abandons Rice cake#3
E14: Hunter#1 burns Stone#1

40th generation

E15: Hunter#1 acquires Stone#1
E16: Big priest#1 abandons Rice cake#4
E17: Big priest#1 brings Rice cake#4
into Mountain#1
E18: Big priest#1 confiscates Rice cake#4
E19: Hunter#1 transports Rice cake#4
to House#1 by dump truck
E20: Big priest#1 abandons Rice cake#4
E21: Big priest#1 collects Rice cake#4
E22: Hunter#1 damages Klin#1
E23: Big priest#1 parts with Stone#1
E24: Hunter#1 takes Big priest#1
out of House#1
E25: Big priest#1 dies of road game

…

Performance Checks
We show some preliminary checks of the system‟s basic
performance using the result of “The legends of Tono” as
mentioned above. First, we analyzed 20 samples which were
generated from a same story line to investigate the correctness
and the diversity of generated states in the story world.
Second, for the story line generation, we analyzed 20 samples
which were generated from a same story world to confirm the
possibility and the diversity of events. In both experiments,
we did not consider the naturalness of context and adopted
whether each event simply physically occur as the evaluation
criterion. For example, a sample story has a scene in which a
big priest eats a burned stone. In spite of actual unnaturalness,
this scene is physically possible. In addition, in many stories,
physically impossible events and fantastical events also occur.
A basic policy of our narrative generation system is the

4th generation

E12: Hunter#1 burns Rice cake#4
E13: Hunter#1 burns Stone#1
E14: Hunter#1 acquires Stone#1
E15: Hunter#1 abandons Stone#1
E16: Big priest#1 chases Hunter#1
E17: Big priest#1 gets Rice cake#4
E18: Big priest#1 eats Rice cake#4
E19: Big priest#1 acquires Stone#1
E20: Big priest#1 gnaws on Kiln#1
E21: Big priest#1 parts with Stone#1
E22: Big priest#1 slips away from House#1
E23: Big priest#1 loses Big priest#1's life

…

In this circulative generation, we implemented a simple
mutation function. It randomly changes the generated values
for frames of agents and objects or values for case frames of
event concepts to other values for agents, objects, and places in
the story. In this time, we attempted the mutation probability,
0.1. Figure 10 shows an input story line and two story lines of 4
times and 40 times. As a result, in 4th generation, a scene in
which the hunter and the priest bite each other is inserted and
various events occur over the rice cakes. In 40th generation,
objects in the story are only two rice cakes and a scene in
which the big priest dies is omitted. The reason of outstanding
reduction of the number of events and the simplification of
generated stories are basically by that elements which are
introduced in the simple mutation are only ones appeared in the
generated stories already. We plan to attempt another
circulative experiment by the arbitrary introducing of elements
that do not exist in the already generated stories.

E1: Hunter#1 burns Rice cake#1
E2: Hunter#1 burns Rice cake#2
E3: Hunter#1 burns Rice cake#3
E4: Hunter#1 gets Rice cake#1 from Patrol
E5: Big priest#1 advances to House#1
E6: Big priest#1 gets Rice cake#1
from Omitted letter
E7: Big priest#1 eats Rice cake#2
E8: Hunter#1 acquires Rice cake#3
E9: Big priest#1 buys Rice cake#3
E10: Hunter#1 bites Big priest#1
E11: Big priest#1 runs in Mountain#1

E1: Big priest#1 strolls around House#1
E2: Hunter#1 chews Rice cake#1
E3: Hunter#1 escapes from House#1
E4: Hunter#1 chews Rice cake#2
E5: Hunter#1 leaves Mountain#1
E6: Hunter#1 escorts Big priest#1
to Mountain#1
E7: Big priest#1 travels around House#1

E8: Hunter#1 drifts in House#1
E9: Hunter#1 carries Rice cake#1
to Mountain#1
E10: Hunter#1 brings Rice cake#1
in House#1
E11: Big priest#1 escapes from House#1
E12: Big priest#1 runs the whole House#1
E13: Big priest#1 abandons Rice cake#1

Figure 10: An example of circular generation
Table 3: The change of story lines through circulation
Appearing
agent
Appearing
object
Location of
agent (Hunter)
Location of
agent
(Big priest)
Contradiction
of the story
Number of
event

Input story line
5th story line
Hunter and Big priest Hunter is two-thirds
are half-and-half
Stone and kiln appear Stone and kiln appear
once
more than once
a round trip to
Stay in the House from Do
House and Mountain
beginning to end
many times
Do a round trip to
Do a round trip to
House and Mountain House and Mountain
two times
one times

none

none

23

21

15th story line
Hunter is mostly
Stone is mostly
Do a round trip to
House and Mountain
many times
Do a round trip to
House and Mountain
one times
Hunter moves to the
same location many
times
19

contradictions. In an example, an agent moved to the location
X from location Y and again moves to a different place from
the X. Such contradiction is brought from the random choice
of a location by the mutation function. It is necessary to adjust
the mutation function so that contradictions do not arise
completely or if a contradiction occurs, a kind of complement
mechanism rewrites state(s) and event(s) after the story line
or the story world were made. We prepared two methods for
such ex-post solution. First method is “the rewrite of
information” and second one is “the complement of
information”. The former is a method that when a
contradiction among some events occurs, the description of a
state is changed to generate a new story. In the latter, when a
contradiction arises, a new state is inserted into the existing
states to generate a new story. In the former, an event‟s
content changes but the story line‟s length does not change.
On the other hand, in the latter, as a new state and a new
event are inserted, the story line‟s length gets longer. As
another contradiction, a dead agent acts. For such case, we
partially alter the mechanism so that a dead man or a
disappearing object is not chosen as an agent or an object by
changing the category to which the noun concept is belonged.
For example, in the event like “Taro (dead-man) walks”, the
constraint of agent in verb concept “walk” was originally the
category of “human” except for “dead-man”. Accordingly,
the system can alter the category to which Taro belongs from
“human” to “dead-man”. Of course, for narratives and stories,
such contradiction or unreality is certainly necessary and
rather very important and essential element. Again, our policy
is that we regard the knowledge and mechanism prepared
based on the realism or physical possibility in a narrow sense
as a standard and basic method, and introduce the processing
of rhetorical knowledge and techniques to adjust the reference
range in the conceptual dictionary.

Conclusions
This paper reported the current version of state-event
transformation system to transform story lines and story
worlds each other using a knowledge base and a conceptual
dictionary. Moreover, we extended the basic framework to a
circulative generation mechanism with a simple mutation
function. Through the preliminary performance checks, we
confirmed that the transformation of story worlds and story
lines is approximately logically adequate and the circular
process produces the diversity of stories. The proposed
system is a module in an integrated narrative generation
system and the pilot version is already implemented. In the
context of the narrative generation system, the proposed
system plays roles for expanding the variation of discourse to
be generated and limiting possible narrative elements at any
given time in a narraive generation process.

References
Akimoto, T., & Ogata, T. (2011). A consideration of the elements
for narrative generation and a trial of integrated narrative
generation system. Proc. of the 7th NLPKE (pp.369-377).
Bringsjord, S. and Ferrucci, D. A. (2000). Artificial Intelligence
and Literary Creativity: Inside the Mind of BRUTUS, a
Storytelling Machine. Mahwah, NJ: Lawrence Erlbaum.
Bond, F., Isahara, H., Fujita, S., Uchimoto, K., Kuribayashi, T.,
& Kanzaki, K. (2009). Enhancing the Japanese WordNet,

The 7th Workshop on Asian Language Resources, ACLIJCNLP 2009 (pp.1-8).
Fillmore, C. J. & Baker, C. (2010). A frames approach to
semantic analysis. In Heine, B. & Narrog, H. (Eds.). The
Oxford Handbook of Linguistic Analysis. 313-339. Oxford
University Press.
Ikehara, S., Miyazaki, M., Shirai, S., Yokoo, A., Nakaiwa, H.,
Ogura, K., Ooyama, Y., & Hayashi, T. (1999). Goi-Taikei: a
Japanese lexicon CDROM, Tokyo: Iwanami Shoten. (in
Japanese)
Kipper-Schuler, K., Dang, G. T., & Palmer, M. (2000). Classbased construction of a verb lexicon. Proc. of AAAI-2000
(pp. 691-696).
Kipper-Schuler, K. (2005). VerbNet: A broad-coverage,
comprehensive verb lexicon. Ph.D. thesis, Computer and
Information Science Dept., University of Pennsylvania.
McIntyre, N. & Lapata, M. (2009). Learning to tell tales: A
data-driven approach to story generation. Proc. of the 47th
Annual Meeting of the ACL and the 4th IJCNLP of the
AFNLP (pp. 217-225).
Meehan, J. R. (1977). Tale-spin, an interactive program that
writes stories, Proc. of the 5th IJCAI, 1(5), 91-98.
Mishima, Y. (1963). The sailor who fell from grace with the
sea, Tokyo: Kodansya. (in Japanese)
Mueller, E. T. (1990). Daydreaming in humans and machines: a
computer model of the stream of thought, Norwood, NJ: Ablex.
Nakashima, M., & Ogata, T. (2008). The structure of a story,
Proc. of the 22nd JSAI (1C2-3). (in Japanese)
Noe, K. (2005). Philosopy of narrative, Tokyo: Iwanami
Shoten. (in Japanese)
Ogata, T., Hori, K., & Ohsuga, S. (1994). Towards narrative
text generation based on narrative techniques and strategies.
Proc. of International Federation for Information and
Documentation (pp.296-300).
Ogata, T., & Kanai, A. (2010). An introduction of informatics
of narratology: on thought and technology of narrative
generation. Tokyo: Gakubunsha. (in Japanese)
Ohara, K. H. (2008). Lexicon, grammar, and multilinguality in the
Japanese FrameNet. Proc. of the 6th International Conference on
Language Resources and Evaluation (pp. 3264-3268).
Oishi, K. & Ogata, T. (2011). Towards the development of
conceptual dictionary for narrative generation system. Proc.
of the 7th NLPKE (pp. 351-358).
Oishi, K. & Ogata, T. (2012). The development of conceptual
dictionary for narrative generation system: The structure
and functions. Proc. of the 4th DIGITEL (pp. 168-170).
Okada, N., & Endo, T. (1992). Story generation based on dynamics
of the mind. Computational Intelligence, 8(1), 123-160.
Onodera, K., Oishi, K., & Ogata, T. (2011). The generation of event
sequences in story based on states-actions transformation and
conceptual system. Proc of the 28th JCSS (P2-42). (in Japanese)
Prince, G. (1987). A Dictionary of Narratology. Lincoln,
Nebraska: University of Nebraska Press.
Propp, V. (Пропп, В. Я.) (1969). Морфология скаэки, Иэ, 2е.
Москва: Наука. (Morphology of the Folktale. Austin, Texas:
University of Texas Press. 1968.)
Schank, R. C. (1975). Conceptual Information Processing.
Amsterdam, NewYork: Elsevier Science.
Takeuchi, K. (2011). Construction of a verb thesaurus for
language processing considering synonym and difference of
verbs in the level of argument structure. The Proc. of the 25th
LCCII in JCSS (25G-05). (in Japanese)
Yanagita, K. (1955). The legends of Tono, Tokyo: Kadokawa
Shoten. (in Japanese)
Zhang, Y., Ono, J., & Ogata, T. (2011). An advertising rhetorical
mechanism for single event combined with conceptual
dictionary in narrative generation system, Proc. of the 7th
NLPKE (pp. 340-343).

2155

