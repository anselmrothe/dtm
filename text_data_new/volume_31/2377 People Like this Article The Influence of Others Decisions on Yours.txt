UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
2377 People Like this Article: The Influence of Others’ Decisions on Yours

Permalink
https://escholarship.org/uc/item/9qg55883

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Ma, Jing
Nickerson, Jeffrey
Sakamoto, Yasuaki

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

2377 People Like this Article: The Influence of Others’ Decisions on Yours
Yasuaki Sakamoto (ysakamot@stevens.edu)
Jing Ma (jma1@stevens.edu)
Jeffrey V. Nickerson (jnickerson@stevens.edu)
Center for Decision Technologies
School of Technology Management, Stevens Institute of Technology
Hoboken, NJ 07030 USA
Abstract

like. Other users can digg or bury the submitted stories to
vote for or against the stories. Users cannot digg the same
story twice. Each digg reflects a user’s liking of a story, and
the total number of diggs for a story represents the
popularity of the story. Digg displays the total number of
diggs associated with each story. Digg promotes a story to
the front page once it gains a certain number of supporters
within a certain timeframe, and the story becomes
prominent. Through this process, some stories collect a
large number of votes.
What drives people’s voting behavior? Do they vote for
stories based on the interestingness of the stories? Or do
they vote for stories based on how many others already
support the stories? Does the information about the number
of supporters a story already has influence one’s perception
of the interestingness of the story? We address these
questions.

How do people make decisions about their preferences? We
examine how others’ opinions affect one’s decisions. In
Experiment 1, we found that popular online news stories were
not inherently interesting, suggesting that something other
than the content of the stories was driving people’s liking of
the stories. In Experiments 2 and 3, we manipulated
information about how previous readers rated the stories.
Participants in Experiment 2 rated the same stories as more or
less interesting depending on whether they were told that
those stories were rated high or low by others. In Experiment
3, more participants preferred the stories that were actually
less popular when they received pseudo-information that
more people liked those stories. Taken together, our results
suggest that others’ decisions can greatly influence not only
people’s decisions but also their actual liking and opinions.
Examining how people’s decisions influence and are
influenced by others’ decisions can shed light on how trend,
culture, and community develop.

The Influence of Others

Keywords: Social learning; trends; conformity; decision
making; interestingness; preference; social networks

Introduction
Did you like this story? Which wine do you like? Many
online sites ask this type of question to gather data on
people’s opinions. Through these collective opinions, some
items become widely popular and trends emerge.
How do people make decisions about their preferences?
Some stories and wines may be inherently better than
others, and people may prefer those with higher quality. In
many situations, however, the quality of the items may be
similar, and people may make decisions based on what
others think about the items, rather than the content of the
items. Furthermore, other individuals’ opinions may
influence one’s perception of the item.
In the present work, we examine how others’ opinions
affect one’s decisions. One unique aspect of the present
work is that we examine decision-making behavior in an
online community. Better understanding of how people
make decisions in online environments is important because
many individuals now use community-based Web services,
such as Digg and Delicious. These new technologies allow
users to share information with other individuals (Glushko
et al., 2008), and thus the opinions of others are readily
available in online environments.
We use Digg (digg.com) as an example. In Digg, users
submit the Uniform Resource Locators of Web stories they

People often rely on other individuals’ decisions to make
their own (e.g., Cialdini & Goldstein, 2004). People may
conform to other people’s decisions because of their desire
to make correct decisions under uncertainty (Sherif, 1935).
Alternatively, people may adopt other people’s decisions
due to their desire to be liked and to not appear deviant
(Asch, 1951). Another possibility is that people simply
imitate the behavior of others (e.g., Gureckis & Goldstone,
2006). Imitation can increase people’s efficiency by
allowing them to try out solutions that they would not have
considered otherwise (Bandura, 1965). Frequently imitated
solutions are usually useful, and thus people may develop
the expectation that solutions selected by more people are
the useful ones. Indeed, organizations tend to adopt changes
that are adopted most frequently by other organizations
(Kraatz, 1998). People develop culture by adopting others'
innovations (Dennett, 1995).
Consistent with these previous findings from social
influence research, Salganik, Dodds, and Watts (2006)
found that whereas good music was always popular (i.e.,
downloaded by many) and bad music was always
unpopular, the popularities of the pieces in between could
vary depending on whether or not the number of downloads
the pieces had was publicly available. In our previous
computer simulation work, a model that assumed that users
followed other users’ decisions did a good job of accounting
for the popularity of news stories in Digg (Sakamoto et al.,

1959

2008). Although the previous studies of social influence
show that people are influenced in their decisions to
download music, vote for a story, adopt frequent solutions,
etc., these studies do not address whether or not people’s
actual liking and opinions are changed. Social comparison
theory proposes that people have a drive to compare their
opinions with others (Festinger, 1954), but it does not
consider how opinions are changed.
Thus, the present work is a psychological extension of the
previous work. We predict that information about how many
supporters a story already has will not only influence
people’s decisions to vote for a story but also change their
actual preferences and opinions about the interestingness of
the story. This will produce a robust positive feedback loop.
In contrast to the past studies analyzing people’s natural
behavior in online environments, we conduct controlled
experiments using materials from real environments. In
Experiment 1, we examine a possible role of interestingness
of Digg news stories in people’s decisions. In Experiment 2,
we investigate the extent to which the previous ratings of
others influence people’s ratings on the interestingness of
news stories. In Experiment 3, we examine the role that the
existing number of supporters plays in people’s preferences
for news stories.

thought the stories were, using a 5-point scale. They
indicated their responses by circling the appropriate value.
Figure 1 displays two stories used in Experiment 1.
Information about the number of supporters was not
provided to the participants. The order of the stories was
determined randomly.

Figure 1: Two of the ten news stories from Digg used in
Experiment 1 are shown (Shipman, 2008; Daily
Galaxy, 2008). Participants rated how interesting they
thought the stories were.

Experiment 1
In Experiment 1, we test the possibility that some news
stories become widely popular in Digg because they are
inherently interesting and everyone votes for these
interesting stories. If this is the case, stories with more past
diggs or supporters should be rated more interesting by new
raters than stories that fewer people supported. We selected
some news articles in Digg with varying number of
supporters. We asked participants to rate how interesting
they thought the articles were, withholding the information
about the number of diggs associated with the stories.

Method
Participants Twenty-one Stevens Institute of Technology
undergraduates completed the experiment.
Materials Ten news stories were selected randomly from
Digg with four constraints: they were not about exceptional
events (e.g., the US election, the plane landing on Hudson
river near Manhattan), they were promoted to the front page,
they were submitted to Digg two to four days ago, and they
differed in the number of supporters. We used stories that
were promoted to the front page because most stories that
are not promoted only receive a few diggs, and the
variability in the number of supporters would be low.
Because activities tend to settle down after one day of
submission, we used articles that had been in Digg for two
to four days. The number of supporters associated with the
news stories (and the number of days in Digg) were: 7321
(3), 2388 (4), 1961 (2), 1209 (3), 823 (3), 613 (3), 514 (3),
426 (4), 320 (2), 223 (2).
Design and Procedure Participants were asked to read ten
brief online news stories and indicate how interesting they

Figure 2: Participants’ interestingness ratings in
Experiment 1 are shown for each of the ten news
stories. Actual number of supporters indicates the
number of diggs for each story. Error bars represent the
95% confidence intervals (Loftus & Masson, 1994).

Results and Discussion
All participants were included in the analyses. Our main
interest is whether people give higher interestingness ratings
for stories that are supported by more Digg users than those
that are supported by fewer users.
Surprisingly, the correlation between the number of
supporters and interestingness ratings was negative (r = .47). As suggested in Figure 2, the mean interestingness

1960

ratings of the three stories associated with most supporters
(2.94), the four stories associated with moderate number of
supporters (3.21), and the three stories associated with
fewest supporters (3.37) did not differ significantly, F(2, 40)
= 2.37, p = .11.
Although a sample of undergraduate students may not be
representative of the Digg population, the negative
correlation between the number of supporters and
interestingness ratings is clearly inconsistent with the idea
that some Digg stories are inherently interesting, and people
are supporting these interesting stories. There is no reason to
believe that the students and the Digg users have opposite
interests. On the contrary, if a story becomes popular
because it is inherently interesting and appealing to a wide
audience, it should be interesting to the students as well as
the Digg users.
The stories used in Experiment 1 were all popular stories
that were promoted to the front page in Digg. The
participants might have been familiar with some of the
stories, which influenced their decisions. We deal with this
issue in Experiment 2.

stories that were not promoted to the front page to minimize
the possibility raised in Experiment 1 that participants might
be already familiar with the promoted stories.
Two sets of stories were created. For both sets, the first
and second stories had no information about the average
ratings of previous readers. In the low-high set, the previous
rating of the third story was 2, the fourth was 4, the fifth
was 2, and the sixth was 4. Figure 3 shows the third and
fourth stories from the low-high set. The experimenter
determined these values. For the high-low set, the ratings
were reversed – the third story had the previous rating of 4,
the fourth 2, the fifth 4, and the sixth 2. There were
questions that gathered demographic information, such as
gender and age, at the end of the experiment.

Experiment 2
The negative correlation between the story's interestingness
and its popularity in Experiment 1 suggests that the inherent
interestingness of stories is not the reason people vote for
the stories. One possibility is that people are supporting
stories that many others support (Sakamoto et al., 2008). In
particular, it may be that people’s perceptions of stories
change according to the opinions of others. When people
have no strong feeling about a story, they may rely on how
others feel about the story to make their own judgment.
In Experiment 2, we examine how one’s decisions are
affected by previous opinions of others. As in Experiment 1,
we chose some news articles from Digg and asked
participants to rate how interesting they thought the articles
were. Unlike Experiment 1, we presented pseudoinformation about the average ratings of previous readers
for some of the stories. For example, Figure 3 shows two
stories we used in Experiment 2. The top story has a
previous rating of 2. The bottom story has a previous rating
of 4. We reversed the ratings for half of the participants. We
want to know if this manipulation will cause participants to
flip their interestingness ratings, which would suggest that
their decisions are influenced by the ratings of others.

Method
Participants Ninety-eight (37 females and 61 males)
members of an online community (https://www.mturk.com)
completed the experiment in return for a nominal stipend.
Their ages ranged from 16 to 59 (M = 32.5, SD = 10.9,
Median = 30).
Materials Six news stories were selected randomly from
Digg with the constraints that they (1) were not about
exceptional events, (2) were not promoted to the front page,
(3) were submitted to Digg one day ago, and (4) had
between 3 and 5 supporters. For Experiment 2, we used

Figure 3: Two of the six news stories from Digg used in
Experiment 2 are shown (Simple solutions, 2009; Mpak
V, 2007). The third and the fourth stories had
information about other people’s previous ratings.
Participants rated how interesting they thought the
stories were.
Design and Procedure One group of participants, the lowhigh group, completed the low-high set, and another group,
the high-low group, completed the high-low set. If people’s
decisions are influenced by previous ratings, there will be an
interaction between Group (low-high vs. high-low) and
Story (3/5 and 4/6) – compared to the low-high group, the
high-low group will rate the third and fifth stories more
interesting relative to fourth and sixth. The first and second
stories with no previous ratings were used to measure
whether the two groups differ in their interests.
Participants completed Experiment 2 online. They were
instructed to read six brief online news stories and indicate
how interesting they think the stories were using a 5-point
scale. Unlike Experiment 1, information about the previous
ratings of others was presented to the participants for some
stories as described previously.

1961

Results and Discussion
All participants were included in the analyses. A two-way
Analysis of Variance (ANOVA) on participants’
interestingness ratings on the first and second stories, with
Group (low-high vs. high-low) and Story (first vs. second)
as independent variables revealed no significant effects (F <
1 on the two main effects and the interaction effect). The
two groups seem to have similar interests.

The results from Experiment 2 strongly suggest that
people’s decisions about the interestingness of stories are
greatly influenced by the previous decisions of others.
Stories were rated less interesting when we provided
pseudo-information suggesting that they received low
ratings from previous readers. The same stories were rated
more interesting when we provided misinformation that
suggested they received high previous ratings.

Experiment 3

Figure 4: Participants’ interestingness ratings in
Experiment 2 are shown for stories 3/5 and 4/6. Stories
3/5 had previous ratings of 2 for the low-high group and
previous ratings of 4 for the high-low group. Stories 4/6
had the reverse. Error bars represent the 95%
confidence intervals (Loftus & Masson, 1994).
We are interested in an interaction between Group (lowhigh vs. high-low) and Story (3/5 and 4/6). For the purpose
of analysis, we combined the ratings for the third and fifth
stories (3/5) because they are the same type – low previous
ratings for the low-high group, and high previous ratings for
the high-low group. For the same reason, we combined the
ratings for the fourth and sixth stories (4/5). We conducted a
two-way ANOVA on participants’ interestingness ratings on
the 3/5 and 4/6 stories, with Group (low-high vs. high-low)
and Story (3/5 and 4/6) as independent variables. As
predicted, the interaction was significant, F(1, 96) = 14.51,
MSe = .49, p < .001. As shown in Figure 4, whereas the
low-high group rated stories 3/5 less interesting than stories
4/6 (3.19 vs. 3.39), the high-low group rated stories 3/5
more interesting than stories 4/6 (3.69 vs. 3.12). The main
effect of Story approached significance, F(1, 96) = 3.53,
MSe = .49, p = .06. The main effect of Group was not
significant (F < 1).
As predicted, collapsing across Group and Story, the
stories with previous ratings of 4 were rated significantly
more interesting than the stories with previous ratings of 2
(3.54 vs. 3.16), t(97) = 4.05, p < .001. Thus, the participants
gave lower ratings to the stories that had lower previous
ratings and gave higher ratings to the stories that had higher
previous ratings.

Taken together, the results from Experiments 1 and 2
demonstrate that popular stories are not inherently
interesting and that people rely on others’ opinions to make
decisions about the interestingness of the stories. Although a
widely supported story may not be inherently interesting,
people may think that it is interesting because numerous
people are voting for it. The results from Experiment 2
suggest that how you perceive the quality of an item may
change depending on other people’s opinions.
In Experiment 3, we examine people’s preference. In
many situations we select one choice over the others. For
instance, we need to choose which restaurant to go to for
lunch. Similarly, Digg users are supposed to vote for stories
they like instead of rating how interesting they find the
stories.
In Experiment 3, two-alternative forced-choice questions
were used to measure how people’s preference might be
affected by the previous decisions of others. As in the
previous two experiments, we selected some news articles
from Digg. Unlike the previous experiments, we asked
participants to decide which of the two articles they liked
better. Figure 5 shows a two-alternative forced-choice
question we used in Experiment 3. Many more people liked
the top story better than the bottom story. This pseudoinformation is the reverse of the actual popularity of the
stories in Digg. Information about how many others liked
the story was not presented for the other question. Thus we
are replicating Experiments 1 and 2 using the preference
measure rather than the interestingness rating.

Method
Participants Seventy-eight (37 females and 41 males)
members of an online community (https://www.mturk.com)
participated in return for a nominal stipend. Their ages
ranged from 17 to 60 (M = 32.6, SD = 12.2, Median = 29.5).
Materials Four news stories were selected randomly from
Digg as in Experiment 1. For Experiment 3, we used stories
that were promoted to the front page so that the stories vary
in the number of supporters.
Two two-alternative forced-choice questions were
created. Figure 5 shows one of them, in which we suggested
that 2377 people liked one story and 827 people liked the
other story. This false information was the reverse of the
actual number of supporters associated with the stories in
Digg. For the other question, in which no information about
the number of people who liked the stories was provided,
2304 Digg users liked one story and 666 users liked the

1962

other. There were also questions that gathered demographic
information, such as gender and age, at the end of the
experiment.
Design and Procedure The design and procedure for
Experiment 3 were identical to those of Experiment 2 except
that people indicated which story they liked rather than
indicating the interestingness rating. Furthermore, there was
only one condition in Experiment 3.

pattern of preference (56% and 44%) was significantly
different from the pattern expected by the actual number of
supporters (78% and 22%), χ2(1, N = 78) = 20.09, p < .001,
as displayed in Figure 6B.
The results from Experiment 3 suggest that, like
interestingness, the decisions of others can greatly affect
one’s preferences. People are not focusing exclusively on
the content of the stories.

Figure 6: % of participants who liked the stories in
Experiment 3 (observed) and % of participants
expected from the actual number of supporters in Digg
(expected) are shown for the question in which the
pseudo-information about the number of supporters was
given (A) and for the question in which the information
about the number of supporters was not provided (B).
For A, the pseudo-information said 2377 people liked
story 1 and 827 people liked story 2. The actual
numbers of diggs were reverse in Digg. For B, story 1
had 2304 diggs and story 2 had 666 diggs in Digg.

Figure 5: One of the two questions used in Experiment
3 is shown (the articles are Parsa, 2009 and Lah, 2009).
Unlike Experiments 1 and 2, two-alternative forcedchoice questions were used to measure how previous
decisions of others might affect people’s preference.

General Discussion

Results and Discussion
All participants were included in the analyses. Our main
interest is whether the information about the number of
supporters influences the participants’ preference. Whereas
49 participants (63%) chose the story that they thought more
people liked, 29 (37%) selected the story that they thought
fewer people liked. As shown in Figure 6A, this pattern was
the opposite of what was expected from the actual number
of supporters in Digg (26% and 74%), χ2(1, N = 78) =
55.79, p < .001, suggesting that the information about the
number of supporters played a major role in people’s
judgment about their own preference. This result replicates
the finding of Experiment 2 using a different measure.
For the question without the information about the
number of supporters, 44 participants preferred the story
that was actually supported by 2304 users in Digg, and 34
preferred the story that was actually supported by 666 users.
Replicating the results from Experiment 1, the observed

The current study examined how people’s decisions and
opinions are influenced by others’ decisions. We found a
negative correlation between the interestingness ratings and
the popularity of the stories in Experiment 1. Participants in
Experiment 2 gave stories lower interestingness ratings
when they were misinformed that the stories were
associated with low average ratings from previous readers.
Interestingly, participants gave the same stories higher
interestingness ratings when they were falsely informed that
the previous ratings for those stories were high. In
Experiment 3, more participants preferred the stories that
were actually less popular in Digg when they were
misinformed that more people liked those stories.
Taken together, our results demonstrate that people’s
liking of online news articles is not guided by the
interestingness of the articles, but by the previous likings of
others. Popular stories are not necessarily inherently
interesting, and people rely on other people’s opinions to
make decisions. Although a widely supported story may not
be inherently interesting, people may perceive it as
interesting because many people like it. Our finding that

1963

people prefer stories that are already popular is consistent
with the principle of preferential attachment, which can
characterize many social networks present in the real world
(Barabási & Albert, 1999). Our work provides a
psychological extension of previous work by showing that
other people’s opinions can actually change one’s
perception of an item. For instance, information about how
many times a piece of music is previously downloaded may
not only influences people’s download decisions (Salganik
et al., 2006), but also change their actual liking of the piece.
The interactions among people’s decisions may play a
major role in the emergence of trends. Many Websites allow
people to share their opinions and learn from others. The
collective opinions of a community can be more informative
than the opinions of a few experts (cf. Surowiecki, 2004).
Many people are attracted to online stores, such as eBay and
Amazon, which provide information about collective
preferences by listing the top selling items or the number of
items available in stock. Furthermore, online shoppers can
learn from other shoppers by consulting previous shoppers’
ratings on products and their opinions about the products.
Website users’ interactions may also involve reciprocity
(Sadlon et al., 2008). Users may purchase products from
someone or vote for stories written by someone with the
expectation that others will respond in kind. We are
currently examining how some users follow particular
others, and how influential individuals may emerge through
this process of following.
While the present work used Digg as an example, our
findings have broader relevance. When deciding where to
eat lunch or which book to buy, information about other
individuals’ decisions is available. Crowding in a store
indicates where everyone is going. The number of products
left indicates which products people are buying. Although
people may not be explicitly processing the information
about others’ choices, they may be unconsciously
influenced by it. Examining how people’s decisions
influence and are influenced by others’ decisions can shed
light on how trend, culture, and community develop.

References
Asch, S. E. (1951). Effects of group pressure upon the
modification and distortion of judgment. In H. Guetzkow
(Ed.) Groups, leadership and men. Pittsburgh, PA:
Carnegie Press, pp.177–190.
Asch, S. E. (1956). Studies of independence and
conformity: A minority of one against a unanimous
majority. Psychological Monographs, 70 (Whole no.
416).
Bandura, A. (1965). Behavioral modification through
modeling procedures. In L. Krasner & L. P. Ulmann
(Eds.), Research in behavior modification: New
development and implications (pp. 310–340). New York:
Rinehart and Winston.
Barabási, A. L., & Albert, R. (1999, October 15).
Emergence of scaling in random networks. Science, 286,
509–512.

Cialdini, R. B., & Goldstein, N. J. (2004). Social influence:
Compliance and conformity. Annual Review of
Psychology, 55, 591–621.
Daily Galaxy (2008). Harvard Team Unlocks Clues to
Genes that Control Longevity. Daily Galaxy.
Dennett, D. C. (1995). Darwin’s dangerous idea. New
York: Touchstone.
Festinger, L. (1954). A theory of social comparison
processes. Human Relations, 7, 117-140.
Glushko, R. J., Maglio, P. P., Matlock, T., and Barsalou, L.
W. (2008). Categorization in the wild. Trends in
Cognitive Sciences, 12, 129–135.
Gureckis, T. M., & Goldstone, R. L. (2006). Thinking in
groups. In S. Harnad & I. Dror (Eds.), Distributed
cognition: Special issue of pragmatics & cognition, 14
(pp. 293–311). Amsterdam, The Netherlands: John
Benjamins.
Kraatz, M. S. (1998). Learning by association?
Interorganizational networks and adaptation to
environmental change. Academy of Management Journal,
41, 621–643.
Lah, K. (2009). Dad impersonating son in exam arrested.
CNN.com/asia. January 15.
Loftus, G. R., & Masson, M. E. J. (1994). Using confidence
intervals in within-subject designs. Psychonomic Bulletin
& Review, 1, 476–490.
Mpak V (2007). Great Vacation Ideas – Be Creative With
Your Meals, http://www.mpakvngwl.org/category/traveland-leisure.
Parsa, A. (2009). Exclusive: Belkin’s Development Rep is
Hiring People to Write Fake Positive Amazon Reviews.
The Daily Background. January 16.
Sadlon, E., Sakamoto, Y., Dever, H. J., Nickerson, J. V.
(2008). The Karma of Digg: Reciprocity in Online Social
Networks. In Proceedings of the 18th Annual Workshop
on Information Technologies and Systems.
Sakamoto, Y., Sadlon, E., & Nickerson, J. V. (2008).
Bellwethers and the emergence of trends in online
communities. In Proceedings of the 30th Annual
Conference of the Cognitive Science Society.
Salganik, M. J., Dodds, P. S., and Watts, D. J. (2006).
Experimental study of inequality and unpredictability in
an artificial cultural market. Science, 311, 854-856.
Sherif, M. (1935). A study of some social factors in
perception. Archives of Psychology, 27, 1–60.
Shipman, T. (2008). Pentagon hires British scientist to help
build robot soldiers that 'won't commit war crimes'. UK
Telegraph, December 1.
Simple Solutions, (2009).
http://simples.in/2009/01/20/browse-the-itunes-storewithout-installing-itunes-software/
Surowiecki, J. (2004). The wisdom of crowds: Why the
many are smarter and how collective wisdom shapes
business, economies, societies, and nations. New York:
Random House.

1964

