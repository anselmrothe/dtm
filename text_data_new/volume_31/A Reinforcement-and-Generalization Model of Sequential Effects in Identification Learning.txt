UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Reinforcement-and-Generalization Model of Sequential Effects in Identification Learning

Permalink
https://escholarship.org/uc/item/6z46n85r

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Author
Jones, Matt

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Reinforcement-and-Generalization Model of
Sequential Effects in Identification Learning
Matt Jones (mcj@colorado.edu)
University of Colorado, Department of Psychology, 345 UCB
Boulder, CO 80309 USA

Abstract
Responses in identification-learning tasks depend on events
from recent trials. A model for these sequential effects is
proposed, based on previous work in category learning and
founded on theories of reinforcement learning and generalization. The model is compared to two other theories in their
predictions of the influence of previous stimuli and previous
feedback. Two experimental paradigms are introduced that
allow separate assessment of these two effects. Results
support the reinforcement-and-generalization model.
Keywords:
Identification;
reinforcement
learning;
generalization; sequential effects; mathematical models.

Introduction
Sequential effects arise in essentially any repeated
psychological task. Although the majority of experimental
designs and statistical analyses aim to average out these
effects, they often contain useful information. Sequential
effects can facilitate inferences about perceptual
representations (Jones, Maddox, & Love, 2005), concept
representations (Jones, 2009), and learning and decision
processes that integrate knowledge from past experience
(Sakamoto, Jones, & Love, 2008).
This paper focuses on sequential effects in identification
learning, a well studied task in which subjects learn to
assign a unique response to each of a given set of stimuli.
Sequential effects are well established in this domain (e.g.,
Garner, 1953), and several extant models attempt to explain
these phenomena (e.g., Holland & Lockhead, 1968; Luce &
Green, 1974; Stewart, Brown, & Chater, 2005). A new
model is proposed here, based on theories of reinforcement
learning and generalization, that attempts to unify sequential
effects in identification with previous work on sequential
effects in category learning (Jones, Love, & Maddox, 2006;
Jones et al., 2005). Two experiments test the predictions of
this model and compare it to previous proposals.
Models of sequential effects in identification can be
distinguished by the separate influences they ascribe to past
stimuli and past feedback. However, disentangling these is
difficult in a standard identification task, because the
stimulus and feedback observed on any past trial are
perfectly confounded. The present experiments offer two
new solutions to this problem, by using probabilistic
feedback and irregular stimulus-response mappings that
varied across subjects. Analyses of sequential effects in
both experiments support the reinforcement-andgeneralization model. Implications for other benchmark
phenomena of identification learning are also discussed.

Sequential Effects in Identification Learning
On each trial in a standard identification-learning task, the
subject is presented with a single stimulus, selects a
response, and is given feedback with the correct answer.
Often the stimuli are arranged along a single perceptual
dimension, such as loudness or line length, the responses are
numbers on a keypad (e.g., 1-9), and the assignment
preserves the natural ordering of the stimuli (e.g., the
shortest line is mapped to response 1, etc.). This basic
paradigm has been used for decades to explore perceptual
representations as well as the decision processes that allow
people to discriminate items in their environment.
Identification learning has long been known to exhibit
sequential effects, whereby the identities of the stimuli on
recent trials systematically bias the current response. The
first such finding was in a loudness-judgment task by
Garner (1953), who observed an assimilation effect,
whereby the current response was biased toward the correct
answer on the previous trial.
The assimilation effect has played an important role in the
development of models of identification learning. Two
broad explanations for this phenomenon have been
proposed. The first ascribes the effect to the previous
stimulus, by assuming the representation of the current
stimulus is confused with or contaminated by other stimuli
in memory, so that its perceived value is biased toward
those past stimuli (DeCarlo & Cross, 1990; Garner, 1953).
The second explanation contends that assimilation is due
not to the previous stimulus, but to the previous feedback.
These theories propose a relative judgment (RJ) strategy, in
which subjects base the current response on the feedback
they received on the previous trial, combined with an
adjustment for the difference between successive stimuli
(Holland & Lockhead, 1968; Luce & Green, 1974; Stewart
et al., 2005). For example, if the previous feedback was 6
and the current stimulus appears two steps greater, then the
subject will respond 8 on the current trial. This strategy
alone does not produce assimilation, but it does if one also
assumes subjects systematically underestimate the
differences between stimuli (e.g., stimuli 3 steps apart can
lead to a response adjustment of only 2 steps). In this case
the response becomes biased in the direction of the previous
feedback (Stewart et al., 2005).

Reinforcement -and-Generalization Model
Assimilation in identification learning can also be
interpreted as a manifestation of a broader phenomenon that

1180

Jones et al. (2006) termed the decisional recency effect.
This is a general tendency to select responses or perform
actions that have been recently reinforced, and it arises in
essentially any repeated task involving rewards or feedback
(see Jones et al., 2006, for a review). Decisional recency is
also a natural prediction from the framework of
reinforcement learning, in which the values of actions are
updated based on the rewards they induce (e.g., Sutton &
Barto, 1998). When such updates are made in proportion to
the difference between predicted and observed outcomes
(known as delta-rule learning), estimated reward values
depend primarily on more recent feedback (Estes, 1957).
Investigations of sequential effects in category learning
have found evidence for both the decisional recency effect
and a separate perceptual recency effect arising from the
previous stimulus (Jones et al., 2005, 2006). These two
effects can be dissociated using a probabilistic task, in
which different occurrences of the same stimulus can lie in
different categories. This allows separate assessment of the
influences of past stimuli and past feedback.
Perceptual recency is observed in analyses that hold the
previous feedback constant and examine the influence of the
previous stimulus. For example, subjects categorizing
rectangles by height will respond to the current stimulus as
though it were taller than it actually is , if the previous
stimulus was short (Jones et al., 2006). This suggests the
representation of the current stimulus is biased away from
the values of recent stimuli, consistent with the large body
of physiological evidence that sensory processing is founded
on adaptation and contrast (e.g., Sekuler & Blake, 1994).
However, it is in direct opposition to the stimulus-confusion
account for assimilation in identification learning.
Decisional recency is observed in analyses that hold the
previous stimulus constant and examine the effect of the
previous feedback. These show a bias towards selecting the
category that was reinforced on the previous trial (Jones et
al., 2005, 2006). Furthermore, this effect is moderated by
the similarity between present and previous stimuli. When
successive stimuli are identical or highly similar, the current
response depends very strongly on the previous feedback,
whereas the effect becomes null or slightly negative as the
stimuli become increasingly dissimilar.
The dependence of decisional recency on similarity
further supports the reinforcement-learning interpretation.
In reinforcement learning, expectations about a given
stimulus cannot normally be based on prior knowledge
about that exact case but must rely on past experience with
other, similar stimuli. This is the problem of generalization.
A large body of research on generalization shows that
people and other animals generalize between stimuli to the
extent they perceive them as similar (e.g., Shepard, 1987).
Nearly all reinforcement-learning models embody this
principle.
Therefore, if decisional recency reflects
reinforcement learning from the previous trial, we should
expect its magnitude to depend on how strongly the subject
generalizes between the previous and present stimuli, which
in turn will depend on their similarity.

Drawing on the above evidence, Jones et al. (2006)
developed a mathematical model of sequential effects in
category learning that embodies both decisional and
perceptual recency effects. This paper proposes a natural
adaptation of that model to identification learning, referred
to as the reinforcement-and-generalization (RG) model.
The model’s two primary assumptions are that the
perception of the current stimulus is biased away from the
previous stimulus, and the current response is biased toward
the previous feedback to a degree determined by the
similarity between present and previous stimu li.
The perceptual portion of the identification model is
unchanged from that of the categorization model. The
perceived value of the current stimulus, Ψ n , is assumed to
depend on both the present and previous stimuli, S n and Sn-1 .
Provided that stimuli are scaled linearly with their perceptual representations, a reasonable assumption is that the
effect of the previous stimulus is also linear (e.g., DeCarlo
& Cross, 1990). The coefficient c is negative if the perceptual effect is contrastive and positive if it is assimilative.
Ψ n = S n + c⋅S n-1

(1)

The decision portion of the model assumes the response
depends on two sources of evidence. The first is the current
percept, mapped onto the response scale by the learned
stimulus-response map f. The second is generalization of
reinforcement from the previous feedback, Fn-1 , whose
impact depends on the similarity between successive stimuli, sim(S n , S n-1 ), together with a scaling parameter, β. The
only change in the identification model is that it predicts the
expected value of the response, E(Rn ), rather than the
probabilities of selecting among (nominal) category labels.
E(Rn ) = f(Ψ n ) + β⋅sim(S n , S n-1 )⋅(Fn-1 – f(Ψ n ))

(2)

Experiment 1: Variable Feedback
The three models discussed above differ in how they ascribe
sequential effects to the previous stimulus and feedback.
Experiment 1 tested the models’ predictions using a
probabilistic identification task, which allowed separate
assessment of these two influences on the current response.
Stimuli were horizontal lines of varying length, and
responses were the numbers 1 through 9. Subjects were told
there was one line length for each response, but in fact there
were ten lengths, referred to here as A through J. Each
feedback value followed two different stimuli equally often
– A and B for 1, B and C for 2, and so on.
Experiment 1 also included a between-subjects manipulation of sequential dependencies among trials, designed to
affect subjects’ use of the RJ strategy. The 18 possible
stimu lus-feedback pairings were partitioned into two types:
Lower trials, in which the stimulus was the shorter of the
two possible values for the feedback given (A-1, B-2,…
H-9), and Upper trials, in which the stimulus was the longer
possible value (B-1, C-2,…J-9).
In the Independent
condition, all trials were sampled independently. In the
Autocorrelated condition, 80% of trials were of the same

1181

5
4

C

3

B
A

2
1

0.8
0.6
0.4

6

0.2

Mean
response

7

Ind. Auto.
Feedback (+)
Stimulus (–)

-0.2 0.0

J
I
H
G
F
E
D

8

Mean
error

Effect on Mean Response

9

0

0

All stimuli

1

2

3

4

5

6

7

8

9

Difference between successive stimuli

-1

F n-1:
S n-1:

Figure 2.
Dependence of sequential effects on
similarity between present and previous stimuli in
Experiment 1. Previous-stimulus effect is negative but
is inverted for comparison to previous-feedback effect.

1
2
3
4
5
6
7
8
9
A B
C
D
E
F
G H
I J

Figure 1. Mean response in Independent condition of
Experiment 1, as a function of present stimulus
(separate curves), previous stimulus (S n-1 ), and previous
feedback (Fn-1 ). Lower section shows mean error
collapsed over present stimulus.
type as their predecessors. Because the RJ strategy is only
reliable (i.e., produces the correct answer) when successive
trials are of the same type, it was predicted that
autocorrelation would serve to induce or increase subjects’
use of RJ. The results below support this assumption.

Method
33 and 35 undergraduates were randomly assigned to the
Independent and Autocorrelated conditions, respectively.
Stimuli were horizontal lines with lengths from 2.54 to 5.08
cm in steps of 0.28 cm. The stimulus on each trial was
presented in a random position on an LCD monitor, and
once the subject pressed a response key (1-9), the chosen
and correct responses were both displayed. Stimulus and
feedback remained for 1000 ms. Trials were separated by
500 ms of blank screen. Each subject completed 400 trials
in blocks of 50.

Results and Discussion
Sequential effects were assessed by computing the mean
response as a function of the present stimulus, previous
stimulus, and previous feedback. The results for the
Independent condition are shown in Figure 1 (Autocorrelated results are discussed below). Different curves correspond to values of the current stimulus, and the abscissa
shows all 18 possibilities for the stimulus-feedback pair on
the previous trial. Each grey segment represents a comparison of two values of S n-1 , with Fn-1 and S n held fixed. These
segments tend to slope downward, indicating a negative
effect of the previous stimulus. Each black segment represents a comparison of two values of Fn-1 , with S n-1 and Sn
held fixed. These segments tend to slope upward, indicating
a positive effect of the previous feedback. The pattern is
clearest in the lowest curve, which shows average error
collapsed over S n . All nine S n-1 comparisons are negative

and all eight Fn-1 comparisons are positive. Both patterns
are reliable by binomial tests (ps < .01). The net slope of
this curve is positive, replicating the classic assimilation
effect, which is now be seen to result from a stronger positive effect of Fn-1 compared to the negative effect of S n-1 .
The negative influence of the previous stimulus rules out
the stimulus-confusion model, so it is not considered
further. However, both RJ and RG models predict this
result, as well as the positive influence of the previous
feedback. To distinguish these models, we consider how
the sequential effects depend on the autocorrelation
manipulation and on the similarity between successive
stimuli.
The effect of stimulus similarity can be seen in Figure 1
as the increased jaggedness of the curves near the main
diagonal, indicating that both sequential effects are stronger
when Sn is more similar to Sn-1 . This can be formalized as
follows. For the previous-feedback effect, the influence of
Fn-1 (corresponding to the slope of each black segment in
Figure 1) can be averaged over all [S n-1 ,Sn ] pairs that differ
by a given number of steps. This yields the average effect
of the previous feedback on the current response,
conditioned on the difference between present and
previous stimuli. A parallel approach can be used for the
previous-stimulus effect, except that each comparison
involves two values of S n-1 (e.g., S n-1 = A vs. B, conditioned
on Fn-1 = 1 and Sn = C), and thus two differences between
S n-1 and Sn . For ease of exposition, I use the average of
these two differences (1.5 in the above example), so that
stimulus differences for the previous-stimulus effect range
from .5 to 8.5.
Figure 2 shows the previous-feedback and previousstimulus effects as a function of the difference between
successive stimuli. The previous-stimulus effect is negative, but it is inverted to facilitate comparison. Four
significant aspects of this graph are discussed in turn: the
curves all slope downward, the feedback effect has a steeper
slope than the stimulus effect, the Autocorrelated curves lie
above the Independent curves, and the curves for the two
conditions are parallel. To test the reliability of these

1182

Table 1: Sequential effects as functions of similarity,
from individual-subject fits to Experiment 1
Previous-feedback Previous-stimulus
Condition
Intercept Slope
Intercept Slope
Independent
.488
-.057
-.231
.019
Autocorrelated
.637
-.069
-.389
.027
patterns, separate curves were estimated for each subject
with the simplifying constraint that all curves be linear.
Thus a slope and intercept for the previous-stimulus and
previous-feedback effects (as functions of stimulus
dissimilarity) were estimated for each subject. Mean values
by condition are displayed in Table 1.
Starting with the Independent condition, the mean slope
for the previous-feedback effect is significantly negative (t32
= 6.18, p < 10-6 ), indicating this effect decreases as
successive stimuli become dissimilar. This is a central
prediction of the RG model. The mean slope for the
previous-stimulus effect is marginally positive (t32 = 1.83, p
= .076), suggesting this effect may also weaken with
similarity.
Under the RG model, this suggests that
perceptual contrast levels off as stimulus differences
become large, rather than continuing to increase at a
constant rate. Equation 1 does not predict this, but it is a
natural elaboration of the model that is consistent with more
detailed studies of perceptual contrast (e.g., Petzold, 1981).
The simple version of the RJ model does not predict
either sequential effect to depend on similarity. However,
DeCarlo and Cross (1990) proposed that people rely more
on this strategy (as opposed to responding to the absolute
value of the current stimulus) when successive stimuli are
similar, and this assumption predicts the pattern seen here.
Direct comparison shows that the previous-feedback
effect has a steeper (absolute) slope than the previousstimulus effect (t32 = 7.16, p < 10-7 ). This is consistent with
the RG model (although the opposite pattern is also),
because it assumes perceptual contrast and generalization
are unrelated processes. The RJ strategy alone does not
predict the slope difference, but recall that Stewart et al.
(2005) proposed people underestimate stimulus differences
in mapping them to response differences. This is the as sumption needed for the model to predict the overall assimilation effect, and it also causes the effect of the previous
stimulus (and hence its dependence on similarity) to be
attenuated relative to the effect of the previous feedback.
Turning to a comparison between conditions, the intercepts for both sequential effects were greater in the Autocorrelated condition (ts > 3, ps < .01). There was no significant interaction between effect type (feedback vs. stimulus)
and condition (F1,66 = .12, p > .5). For slopes, there was no
difference between conditions for either sequential effect (ts
< 1, ps > .1), and there was no condition-by-effect
interaction (F1,66 = .41, p > .5). Therefore, the effect of
autocorrelation was a uniform increase in both sequential
effects, to equal degrees, independent of stimulus similarity.
The difference between conditions supports the
assump tion behind the autocorrelation manipulation, that it

would increase reliance on RJ. However, it also reveals two
aspects of the RJ strategy that are incompatible with it as an
e xplanation for sequential effects. First, the fact that the
slopes of the similarity effects were unchanged implies that
reliance on RJ is independent of similarity. This directly
contradicts the assumption needed for RJ to explain the
similarity effect to begin with. Second, the fact that the two
sequential effects are strengthened equally implies that
subjects correctly scale stimulus differences to response
differences.
This directly contradicts the assumption
needed for RJ to explain the overall assimilation effect. To
be clear, the data do not rule out RJ altogether. Subjects do
seem to engage this strategy when it is reliable (as it would
be in a standard, deterministic identification task). The
point, however, is that RJ cannot explain the observed
sequential effects. Therefore this strategy must act on top of
more fundamental mechanisms operating separately on
stimulus and response representations, as in the RG model.

Experiment 2: Variable Mappings
Experiment 2 varied the stimulus-response map between
subjects, so that stimuli and feedback would be decoupled
when considering the data for all subjects together.
Subjects’ task was to learn to assign the numerals 1 through
9 to the letters A through I. The assignments were irregular,
which renders strategies such as RJ useless (e.g., knowing
that 3 maps to G is irrelevant to the answer for 4) and allows
us to assume that processing consists of stimulus identification, retrieval of stimulus-response associations, and
response selection. Our interest is in the errors that occur at
the stimulus and response stages, due to processes such as
perceptual or motor confusion, generalization, encoding and
retrieval errors, and sequential effects. These processes can
all be summarized by a confusion matrix among stimuli,
specifying the distribution over which stimuli are accessed
given the stimulus actually presented, and a confusion
matrix among responses, specifying the distribution over
which response is selected given the one that is retrieved.
The experiment hinges on a counterbalancing of stimulusresponse maps, due to Shepard (1957), that allows separate
estimation of the stimulus and response confusion matrices.
To estimate the response-confusion matrix, one considers
the distribution of actual responses conditioned on which
response was correct.
When these probabilities are
averaged over subjects, patterns of stimulus confusion
average out to a constant, because for any pair values for the
actual and correct responses, the associated stimuli are
counterbalanced over subjects. The stimulus-confusion
matrix is estimated in a similar way, by computing the
distribution over the correct stimulus for the response that
was chosen (i.e., f −1 ( R ), where f is the mapping),
conditioned on the stimulus that was actually presented.
The primary aim of Experiment 2 was to test the RG
model’s predictions for how stimulus and response
distributions are affected by the previous trial. However,
because the use of irregular mappings necessitated symbolic

1183

Effect of previous feedback (Γ)

Generalization

0.05
0.04
0.03
0.02

1 2 3 4 5 6 7 8

1 2 3 4 5 6 7 8

Stimulus difference

Response difference

Figure 3.
Generalization gradients for stimuli
(numerals) and responses (letters) in Experiment 2.
stimuli, it was uncertain whether perceptual contrast effects
would be observed. Therefore, this experiment served
primarily as a test of the decision portion of the model.

Results and Discussion
The response-confusion matrix was estimated by computing
P(R = j | f(S) = i) for all responses i and j, where f(S) is the
correct response for the current stimulus. The stimulusconfusion matrix was estimated by computing P(R = f(j) | S
= i) for all stimuli i and j. Generalization gradients were
obtained from the confusion matrices by averaging over all
pairs of stimuli or responses differing by the same number
of steps. These differences were determined by the standard
numeric and alphabetic orderings (123…, ABC…). As
Figure 3 shows, these gradients are remarkably regular, even
though the psychological similarity structure of numbers
and letters is likely more complex than just that induced by
their orderings.
Unfortunately, conditioning the confusion matrices on the
previous stimulus and feedback breaks the symmetry from
the counterbalancing of stimulus-response maps. Therefore
sequential effects were evaluated using a formal modeling
approach, in which the RG model was combined with the
standard Luce-Shepard identification-choice model (Luce,
1963; Shepard, 1957). This model assumes processing
occurs in three stages: stimulus generalization, stimulusresponse mapping, and response generalization and
selection. The first stage was modified to accommodate
perceptual recency by assuming that stimulus generalization
is based not on Sn but on Ψ n as given by Equation 1. Here s
represents any stimulus, and A(s) is its activation.

0.1

0

-0.1

-0.2

1

2

3

4

5

6

7

8

Difference between succesive stimuli

Figure 4. Effect of previous feedback on current
response as function of stimulus similarity, from fit of
nonparametric model to Experiment 2.

Method
72 undergraduates were assigned stimulus-response maps
such that, for any two stimuli, S 1 and S 2 , and responses, R1
and R2 , exactly one subject had S1 mapped to R1 and S2
mapped to R2 . The stimulus on each trial was a numeral 1-9
presented in the center of a monitor. The responses, letters
A-I, were arranged in a circle (2.54 cm radius) around the
stimulus, in a different random configuration on each trial.
The subject used a mouse to click on a response, and was
then shown the correct answer. This feedback remained for
750 ms. Trials were grouped into blocks of 36, containing
four repetitions of each stimulus. The experiment ended
when a block was completed with at most two errors.

0.2

A(s) ∝ sim(s,Ψ n )

(3)

The stimulus-response mapping stage involves retrieving
the correct response for each stimulus, or else guessing with
probability g. This determines the activation of responses.1
A(f(s)) = g + (1-g )⋅A(s)

(4)

In the response stage of the Luce-Shepard model,
activation is generalized among responses according to
similarity. The effect of reinforcement from the previous
trial was incorporated by assuming initial activations are
biased towards the previous feedback by the same formula
as Equation 2. This leads to the following response rule
(where Luce-Shepard has just sim[R,r] for the final term).

P( R) ∝ ∑ A( r ) ⋅ sim[R, r + β ⋅ sim( Sn , S n −1 ) ⋅ (Fn −1 − r )] (5)
r

Similarity was assumed to be an exponential function of
distance (Shepard, 1987), sim(x,y) = exp(-α⋅|x-y|), where α
equals αstim for stimuli and αresp for responses. Distance
was again determined by the numeric and alphabetic
orderings, as a simple working assumption. Thus there
were three parameters for the base identification model –
similarity parameters (αstim, αresp) and guessing probability
(g) – and two more for sequential effects: perceptual
assimilation or contrast (c) and reinforcement effect (β).
The principal predictions to be tested were c < 0 and β > 0.
The best-fitting value of β was .117, indicating a positive
bias of the response towards the previous feedback.
Comparison to a model with β fixed to 0 showed this effect
is highly reliable (χ 12 = 45.64, p < 10-10 ). As a more
rigorous test of the dependence of the previous-feedback
effect on similarity, the model was refit with the β⋅sim(S n ,
1

The internal variables A(s) and A(r) can be interpreted either as
probabilities of which value is activated or as distributed representations, without change in the formalism or predictions. This
allows evaluation of sequential effects with minimal theoretical
commitment regarding the architecture underlying the task.

1184

S n-1 ) term in Equation 5 replaced by a nonparametric
function, Γ(|S n – S n-1 |), allowing a different free parameter
for each possible dis tance. The best-fitting values of Γ are
plotted in Figure 4, which shows a clear decrease in the
effect of the previous feedback with increasing distance
between successive stimuli. Comparison to a model in
which Γ was constant showed this relationship to be reliable
(χ 27 = 16.44, p < .05). However, the nonparametric model
did not fit significantly better than the original model of
Equation 5 (χ 27 = 7.87, p > .1), indicating similarity
provides an adequate fit to the pattern in Figure 4. This
supports the core principle of the RG model, that previous
reinforcement is generalized to the current trial to a degree
determined by the similarity between successive stimuli.
The best-fitting value of c was .005, which was not
reliably different from zero (χ 12 = .008, p > .5). Therefore
there was no evidence for an effect of the previous stimulus
on the perception of the current stimulus. Given that the
stimuli were symbolic (numerals), this is not necessarily a
concern for the model. We are currently piloting a version
of this experiment using more perceptual stimuli to
determine whether a contrast effect is observed in that case.

General Discussion
Sequential effects in learning provide important clues to
how stimuli are represented and the decision process used to
identify them. The reinforcement-and-generalization (RG)
model proposed here posits that separate sequential effects
operate at both of these levels. The perception of the current
stimulus is contrasted away from the previous stimulus, and
the current response is biased towards the previous feedback
to a degree determined by the similarity between successive
stimuli.
The latter effect derives from fundamental
principles of reinforcement learning and generalization (e.g.,
Sutton & Barto, 1998).
An important next step in testing the RG model is to
identify factors that separately influence the two recency
effects. One factor that seems to influence perceptual
contrast is the nature of the stimuli. Contrast was observed
for the perceptual stimuli in Experiment 1 but not for the
symbolic stimuli in Experiment 2. One factor that has been
seen to influence the reinforcement effect (decisional
recency) is selective attention. Stimulus differences on a
task-irrelevant dimension do not attenuate the reinforcement
effect as much as differences on the relevant dimension
(Jones et al., 2005), consistent with established effects of
selective attention on similarity (e.g., Tversky, 1977).
The RG model is not a complete model of identification,
but an account of sequential effects (in this task and others).
However, it may shed light on other phenomena in this
domain. For example, one consistent finding is the bow
effect, whereby discrimination is better between stimuli near
the ends of the range than near the middle (Murdock, 1960).
Another is the spacing effect, whereby discrimination
between two fixed stimuli is worse if the spacing between
other stimuli is increased. Many explanations for these

phenomena rely on assumptions about stimulus representations, for example that they are based on position relative
to the endpoints of the stimulus range (Parducci, 1965).
These theories lead to specific predictions regarding
similarity, which can be tested with the RG model by using
the decisional recency effect as an index of similarity. Thus
the present theory offers a useful window onto how stimulus
representations adapt to the task at hand.

References
DeCarlo LT, & Cross DV (1990). Sequential effects in
magnitude scaling: Models and theory. J Exp Psychol
Gen, 119, 375–396.
Estes WK (1957). Theory of learning with constant,
variable, or contingent probabilities of reinforcement.
Psychometrika, 22, 113–132.
Garner, W. R. (1953). An informational analysis of absolute
judgments of loudness. J Exp Psychol, 46, 373-380.
Holland MK, & Lockhead GR (1968). Sequential effects in
judgments of loudness. Percept Psychophys, 3, 409–414.
Jones M (2009). Identifying category representations
through sequential effects in learning. In prep.
Jones M, Love BC, & Maddox WT (2006). Recency as a
window to generalization: Separating decisional and
perceptual sequential effects in categorization. J Exp
Psychol Learn, 32, 316-332.
Jones M, Maddox WT, & Love BC (2005). Stimulus
generalization in category learning. Proc 27th Meeting
Cognitive Science Society, 1066–1071.
Luce RD (1963). Detection and recognition. In RD Luce,
RR Bush, & E Galanter (Eds.) Handbook of
Mathematical Psychology, I. New York: Wiley.
Luce RD, & Green DM (1974). Response ratio hypothesis
for magnitude estimation. J Math Psychol, 11, 1–14.
Murdock BB (1960). The distinctiveness of stimuli. Psych
Rev, 67, 16–31.
Parducci A (1965). Category judgment: A range-frequency
model. Psych Rev, 72, 407-418.
Petzold P (1981). Distance effects on sequential
dependencies in categorical judgments. J Exp Psychol
Human, 7, 1371–1385.
Sakamoto Y, Jones M, & Love BC (2008). Putting the
psychology back into psychological models: Mechanistic
vs. rational approaches. Mem Cognition, 36, 1057-1065.
Sekuler R, & Blake R (1994). Perception. New York:
McGraw-Hill.
Shepard RN (1957). Stimulus and response generalization:
A stochastic model relating generalization to distance in
psychological space. Psychometrika, 22, 325-345.
Shepard RN (1987). Toward a universal law of generaliza tion for psychological science. Science, 237, 1317–1323.
Sutton RS, & Barto A G (1998). Reinforcement Learning:
An Introduction. Cambridge, MA: MIT Press.
Stewart N, Brown GDA, & Chater N (2005). Absolute identification by relative judgment. Psych Rev, 112, 881–911.
Tversky A (1977). Features of similarity. Psych Rev, 84,
327-352.

1185

