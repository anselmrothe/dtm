UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An ART Neural Network Model of Discrimination Shift Learning

Permalink
https://escholarship.org/uc/item/639417gw

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Berkeljon, Arjan
Coffey, Emily
Raijmakers, Maartje
et al.

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

An ART Neural Network Model of Discrimination Shift Learning
Maartje E. J. Raijmakers (m.e.j.raijmakers@uva.nl)
Department of Psychology, University of Amsterdam
Emily Coffey (emily@flighteducation.net)
CSCA, University of Amsterdam
Claire Stevenson (CStevenson@fsw.leidenuniv.nl)
CSCA, University of Amsterdam
Jasper Winkel (jasperwinkel@gmail.com)
CSCA, University of Amsterdam
Arjan Berkeljon (Arjan@Berkeljon.com)
Brigham Young University (BYU) in Provo, UT, USA
Abstract

(non)reversal-shift learning and reviews by [4-7]). In the
current paper we focus on the developmental findings
related to the difference between reversal shifts (RS) and
nonreversal shifts (NRS). After a RS, all contingency
relations are reversed leaving the same stimulus dimension
relevant for discrimination (e.g., black is correct instead of
white). A NRS makes a formerly irrelevant dimension
relevant, shifting only two out of four contingency relations
(e.g., circle is correct instead of white).
Developmental differences in discrimination learning, the
first phase of the task, are mainly manifested as an increase
in learning efficiency from childhood to young adulthood
[6]. In the Levels-of-function theory two distinct learning
modes are posited to account for the observed difference:
(1) an hypothesis-testing, rational learning mode; and (2) a
slow and incremental learning mode.
Subsequent analysis of these hypothesized learning modes
has led to a refining of their proposed nature. A finite
mixture model analysis on the error distribution of simple
discrimination learning data gathered from subjects aged 6
to 10 was conducted in [8]. The error distribution was found
to be bimodal, i.e. the distribution was best described as
composed of two components. One component best
describes a model of learning through hypothesis testing.
The other component included slow learners who did not
show any increase in performance during the first 16 trials
(although criterion was reached in 48 trials).
These findings are extended by a more detailed
investigation of the aforementioned learning modes [1].
Data from a simple discrimination-learning task (230
subjects, ages 4--20) was analyzed by fitting several
mathematical learning models to the sequences of responses
produced by the participants, i.e. the trial-by-trial learning
process was modeled. Learning models were specified as
latent Markov models (or mixtures thereof). The best fit on
the data was obtained by a mixture model with a component
of discontinuous rational learning through hypothesis testing
and a component of slow, yet discontinuous learning (as
opposed to incremental learning). The relative proportions
of the components depend on age and relevant dimension
(with respect to reinforcement contingencies) in the
following two ways: (1) the proportion of rational learners

We present an ART-based neural network model (adapted from
[2]) of the development of discrimination-shift learning that
models the trial-by-trial learning process in great detail. In
agreement with the results of human participants (4–20 years of
age) in [1] the model revealed two distinct learning modes in the
learning process: (1) a discontinuous rational learning process by
means of hypothesis testing; and (2) a slow, yet discontinuous
learning process. Categorical differences in behavior are the result
of uniformly distributed dimensional preferences. In addition, it
models the developmental differences between reversal and
nonreversal-shift learning. The network implements attentionguided learning by selective sensory processing based on
dimensional preferences mediated through reinforcement. The
developmental differences consist of separate adjustment of the
valuation of negative reinforcement, which is proposed in the
empirical neuroscience literature [3].
Keywords:
discrimination-shift
development, neural network.

learning,

cognitive

Introduction
Discrimination-shift learning is a long-standing paradigm
in the investigation of human category learning and concept
formation. A typical discrimination-shift learning task
consists of two phases: discrimination learning and shift
learning. Discrimination learning requires participants to
choose the correct stimulus from a pair of stimuli. The
stimuli presented differ on two or more dimensions (e.g.
color and shape). Each of the dimensions has two possible
values (e.g. white and black; circle and triangle), resulting in
four possible stimuli. Reinforcement contingencies are such
that only the choice of one value on a particular dimension,
the so-called relevant dimension, is reinforced positively.
Choosing the opposing value on the relevant dimension
leads to negative reinforcement. The other dimension is
irrelevant with respect to reinforcement and thus choices
based on either value on this dimension lead to positive
reinforcement in 50% of the choices made.
During the second, shift phase of the task, which starts
once a specified learning criterion has been reached in the
first phase, reinforcement contingencies are shifted.
Numerous developmental differences have been found in
comparing performance of children and adults on
discrimination-shift tasks (see the literature on

791

increases with age; and (2) in the younger age groups, the
proportion of rational learners is higher when the relevant
dimension is color than when the relevant dimension is
shape. In the older age groups there was no such difference.
Several phenomena in childrens’ and adults’
discrimination-shift learning (DSL) are evident in the
literature. One basic effect, with regard to discrimination
learning in adults (and children older than 10), is that RS are
executed more quickly than NRS.
In contrast, for children below 10, some studies show that
the NRS require fewer trials to learn than the RS, whereas
other studies fail to show any difference [5,6,9,12]. Another
relevant finding is that learning RS on a child’s ‘preferred’
dimension (e.g. color as opposed to shape) results in better
performance than on a relatively less salient dimension
relative to NRS; this was not found in experiments with
adult subjects. Finally, the overtraining effect is also
apparent, where training, continued after the learning
criterion is reached, facilitates RS but not NRS in children.
The purpose of this paper is to model the two modes of
discontinuous learning and the basic developmental results
of discrimination-shift learning using a neural network
architecture with incremental-learning rules. The network
architecture will be implemented such that a cognitively
plausible and developmentally relevant parameter accounts
for systematic variation in learning behavior.

researchers argue that overtraining leads to differences in
children and adults on these tasks. This coincides with
findings in which overtraining preschoolers leads task
performance similar to that of older subjects [5,6]. This is
implemented in the network through a lowering of the
allowed discrepancy between desired input and output. This
lowered score-threshold fine-tunes pattern discrimination
through extensive training, leading to fewer learning trials
for child as opposed to adult networks; this is in contrast
with humans. The results do reflect empirical data in that RS
are learned more quickly than NRS in adult networks and
equally quickly in child networks. The authors did not
compare the trial-by-trial learning in the pre-shift phase of
the network. However, it is typically expected that these
incremental learning models show an incremental learning
process in contrast to the all-or-none learning observed by
humans, both children and adults.

Model specification
To model sequential learning behavior on a simple
discrimination task, an ART (Adaptive Resonance Theory,
[23]) neural network architecture was chosen that was
adapted to simulate perseveration behavior on the
Wisconsin Card Sorting Task (WCST) [2]. The original
architecture consists of an input-to-category node structure
mediated by an attentional gating system of biases acting
selectively on dimensional attributes in the input. Biases are
mediated by so-called habit nodes which detect how often
classifications have been made irrespective of feedback.
Bias activation is controlled by a reinforcement signal. This
signal is mediated by the reinforcement gain parameter.
Lowering the value of this parameter will increase the
likelihood of dimensional perseveration through the bias
nodes. It thus models a decrease in the ability to adjust
categorization behavior based on changing reinforcement
contingencies.
The model was adapted to perform a simple discrimination
task. Two major structural changes were made:
1. The reinforcement gain parameter was split in two to
reflect the different influences of positive (α+) and
negative (α-) reinforcement on responding. Frank et al.
[15] made a similar distinction. They report empirical
support for the dissociation between learning from
positive reinforcement and learning from negative
reinforcement in a study on how dopamine affects these
distinct learning processes in Parkinson's patients. They
present a computional model [16, 17] that accounts for
this dissociation by proposing that two distinct
dopamine-dependent pathways exist in the basal
ganglia (BG), one excitatory pathway for positive
reinforcement learning and one inhibitory pathway for
negative reinforcement learning. These pathways are
part of a larger model incorporating cortical structures
as well as the basal ganglia and thalamus. The basal
ganglia are influenced top-down by the orbitofrontal
cortex (OFC) which represents positive and negative

Models of Discrimination-Shift Learning
Krushke [9] developed the AMBRY connectionist model of
DSL that qualitatively fits adult data. Two important
components are contextual bias and response-to-category
mapping. The biased attention to input leads to preservation
of dimensional attention, which would account for ease of
RS over NRS. The separation of responses from the internal
category structure is considered essential for shift learning.
Raijmakers, et al. [10] created a neural network utilizing
the backpropagation error correction algorithm and one
hidden layer to model DSL. The networks often learned
NRS faster than RS, although a trial-by-trial analysis
performed similarly to preschool children during shift
learning. Overtraining however did not help the network to
perform as adults, but also not as children. This lead to the
conclusion that these particular feedforward networks that
have been applied as models of higher cognitive tasks such
as balance-scale learning, being bottom-up associative
systems, are inadequate models of human learning as it is
involved in discrimination learning, as they cannot
incorporate the top-down categorization of adults and
children on discrimination shift learning.
Sirois & Shultz [12] use a cascade-correlation algorithm
to overcome the shortcomings of previous DSL neural
network models. Given that these feedforward networks can
adapt their topology, and therefore allow for structural
plasticity, they are of great relevance in modeling
developmental phenomena. Essentially, the architecture of
the adult and child networks do not differ in DSL modeling
as discrimination shifts are linearly separable problems. The

792

reinforcement values separately in the medial OFC and
lateral OFC, respectively.
2. A layer of two response nodes was added on top of the
category layer. This allows the network to differentiate
not only between categories, but also between
responses to categories (as in AMBRY where internal
category knowledge is separated from overt category
responses in a similar manner). A stochastic process
based on the negative reinforcement gain parameter (α-)
controls the update of the connections between the
category nodes and the response nodes.
Learning in the ART network takes place in two ways: (1)
updating the bias nodes and (2) updating the weights from
category to response nodes. The final network topology is
given in figure 1 (A full specification is supplied as an
appendix). As can be seen a total number of four nodes code
for input features. There are two nodes per dimension of the
discrimination task (color and shape). Input signals
propagate to category nodes, one for each of the four
possible stimuli (white circle, white triangle, black circle,
and black triangle). The category nodes mutually inhibit
each other. Signals from the input to the category nodes are
mediated by attentional gating through bias node activation.
Response nodes determine the response of the network by
comparing the activation values of the category nodes using
weighted connections between category and response nodes.
These weights are randomly initialized per dimensional pair
as either zero or one. This thus expresses a response
preference within each dimension.

dimensional preference of the network. Bias activation is
determined by six factors. A bias node is excited by (1) its
own activation, (2) positive reinforcement mediated by the
learning parameter, (3) by a match-signal computed
between input and the category node with the highest
activation value, and (4) by the corresponding habit node
(provided its activation exceeds a specified threshold). It is
inhibited by (5) the competing bias node and by (6) negative
reinforcement. The separation of bias and habit subsystems
in the current model is an implementation of the idea that
memory for reinforcement value and (motor) response
memory are functions of interacting, but distinct,
subsystems in the brain [2]. A similar distinction has been
shown to account for different types of errors subjects make
on the WCST, namely failures to maintain set and
perseverative errors [14]. Cortical-subcortical computational
models have also been developed that make a similar
distinction (e.g. [13,16,17]; see also [20] for a
neurobiological discussion).
In [18] a neural model of perseveration is developed based
on a distinction between active (in the prefrontal cortex) and
latent memory representations (in the posterior cortex). This
is comparable to, although not identical with, the distinction
between active bias memory and latent habit memory in the
current model. For any category-learning task (e.g. WCST,
discrimination learning etc.) distinguishing between
perseverative errors and errors of set-maintenance seems to
require a distinction between a memory system that can
implement active and flexible responses and a memory
system for latent representations of previous responses. This
is what we have attempted to implement using the bias and
habit subsystems.
With respect to the current model, these two views are not
radically different. The bias system is the driving force
behind dimensional preference and thus responding in the
network. Mediation through reinforcement controls
response shifting (i.e. new response-behavior). The habit
system keeps track of the responses gives and influences the
bias-system to continue in its previous response-behavior
(i.e. maintaining response-behavior).
Modeling Development Whereas originally reinforcement
mediation was used to model differences in perseveration
behavior on the WCST between healthy subjects and frontal
patients [2], in the current study such mediation is used to
model developmental differences in simple discriminationshift learning. It has been observed that the perseverative
errors seen in frontal patients behavior are comparable to the
mistakes children make [21]. Our hypothesis is that these
mistakes are the result of a reduced effect of corrective
feedback, i.e. children have trouble shifting from one rule to
another because responding to changing reinforcement
contingencies is not as efficient in children as it is in adults.
We test this hypothesis by modeling a simple discrimination task (which is similar to the WCST) using the
specified neural network model. Developmental differences

Figure 1: ART discrimination network.
Attentional gating of signals from input to category nodes
is done through bias nodes acting on input dimensions. Bias
nodes are initialized uniformly random as either high or low
such that if one bias has a value greater than two, the other
bias node is smaller than two by the same amount. The
deviation from two is uniform. This expresses an initial

793

are modeled using different values for the negative feedback
component of the reinforcement gain parameter.
As mentioned, individual networks differ with respect to
their dimensional preference (bias) and response preference
per dimension (response nodes). These differences are not,
however, related in any systematic way to the value of the
reinforcement gain parameter. Therefore, any difference in
performance between adult and child networks will be the
result of a difference in negative reinforcement gain.

the data. For the simulation data generated by the adult
networks, a single component discontinuous-learning model
provided the best fit. The learning parameter, i.e. the
probability of moving from the presolution state to the
learned state, was estimated at 0.19. For the data generated
by the child networks, a two-component model consisting of
two discontinuous learning modes provided the best fit. For
the slow, discontinuous learning component (describing
70% of the data), the learning parameter was estimated at
0.064. For the fast learning component the learning
parameter was estimated at 0.35. Estimated parameters were
very similar to the parameter estimates in [1].

Simulations and Results
The networks were submitted to RS and NRS shift tasks.
Stimuli follow one of four learning rules: (1) black maps to
A, white maps to B, (2) white maps to A, black maps to B,
(3) triangle maps to A, circle maps to B and (4) circle maps
to A, triangle maps to B. Through a binary encoded vector
of one of four stimuli, a black or white triangle or circle,
was presented to the network. The network then chooses
response category A or B and is given reinforcement
dependent upon correct categorization. One fourth of each
developmental group began with each rule. Initial
dimensional preference was uniformly distributed over all
networks via random initialization. The networks were
given 48 trials to reach a learning criterion of 10
consecutive correct responses for this initial discriminationlearning rule. The rule was then shifted with either a
reversal or non-reversal rule and 48 trials were presented.
Networks that failed to reach the 10 sequentially correct
criteria were removed from analyses (as is standard
procedure in human studies). Further details and parameter
values are presented in the Appendix.

Figure 2: Backward learning curves of simulation data.
Note that the peak at trial 0 is an artifact of the method
because all sequences are aligned at the last error.
Backward Learning Curves The discontinuity of the
learning process is apparent from the backward learning
curves. As can be seen from figure 3 for both adult (a) and
child (b) networks the curve is flat at the 0.5 level before
learning (left of the dashed line). It then jumps to near zero
once the criterion is mastered (right of the dashed line). This
clearly indicates the existence of a discontinuous learning
process.

Discrimination Learning An analysis of variance on the
number of trials in the preshift phase reveals a main effect
of age (i.e. adult versus child) on the number of trials. Adult
networks learn significantly faster than child networks. F(1;
418) = 466.46, p < 0.001. An interaction effect between
initial bias and rule was also found. Networks with an initial
bias-matching rule (i.e. the initial bias matches the rule to be
learned) learn significantly faster than networks with an
initial bias not matching rule (non-matching networks). F(3;
418) = 160.63, p < 0.001. Finally, an interaction effect was
found between age, initial bias and rule. F(3; 418) = 67.09,
p < 0.001. That is, the difference in number of trials to
criterion between matching and non-matching networks is
greater for child networks than for adult networks (a similar
effect is reported in [1]). The reduced effect of corrective
feedback for child networks thus magnifies, as expected, the
differences in learning rate between matching and nonmatching networks.
Markov Model Analysis Several hidden Markov models
were fit to the trial-by-trial data generated by adult and child
networks. These statistical models include single component
models of incremental learning and of discontinuous
learning. In addition also combination of all single
component models, i.e. two-component models, are fitted to

Figure 3: Shift learning in adult and child networks

794

Discrimination-Shift Learning The mean number of trials
to learning criterion post-shift is less for adult than child
networks. An ANOVA with number of trials to learning
criterion as dependent variable and age (adult/child), rule
matching bias (yes/no) and shift type (reversal/non-reversal)
revealed a significant main effect for age: F(1,625)=586.22,
p<.001. Matching nor shift type revealed main effects,
F(1,625)=1.83, p=.176 and F(1,625)=1.92, p=.678
respectively. A significant effect of shift type on trials-tocriterion is found for adult networks: F(1,398)=67.15,
p<.001. No significant result for child networks was found:
F(1,398)=.869, p=.176. See Figure 3.

whereby child networks with further training beyond
criterion would perform like adult networks.

Acknowledgments
The work of Maartje Raijmakers was funded by the
Netherlands Organisation of Dutch research (NWO). We
thank Meindert Kamphuis and Vincenzo Truppo, Master
students of the Cognitive Science Center Amsterdam, for
their valuable contributions.

References
[1] V. Schmittmann, I. Visser, and M. Raijmakers,
“Multiple learning modes in the development of
performance on a rule-based category learning task,”
Neuropsychologia, vol. 44, pp. 2079–2091, 2006.
[2] D. Levine and P. Prueitt, “Modeling some effects of
frontal lobe damage—novelty and perseveration,” Neural
networks, vol. 2, pp. 103– 116, 1989.
[3] van Duijvenvoorde, A.C.K., Zanolie K., Rombouts,
S.A.R.B., Raijmakers, M.E.J., and Crone E.A. (2008).
Evaluating the Negative or Valuing the Positive? Neural
Mechanisms Supporting Feedback-Based Learning across
Development. J. Neurosci. 28: 9495-9503 .
[4] J. Wolff, “Concept-shift and discrimination-reversal
learning in humans,” Psychological Bulletin, vol. 68, no. 6,
pp. 369–408, 1967.
[5] N. Esposito, “Review of discrimination shift learning in
young children,” Psychological Bulletin, vol. 82, pp. 432–
455, 1975.
[6] T. Kendler, “The development of discrimination
learning: A levels-of-functioning explanation,” Advances in
Child Development and Behavior, vol. 13, pp. 83–117,
1979.
[7] T. Kendler, Levels of cognitive development. Mahwah,
NJ: Erlbaum, 1995.
[8] M. Raijmakers, C. Dolan, and P. Molenaar, “Finite
mixture distribution models of simple discrimination
learning,” Memory & Cognition, vol. 29, no. 5, pp. 659–
677, 2001.
[9] J. Kruschke, “Dimensional relevance shifts in category
learning,” Connection Science, vol. 8, pp. 201–223, 1996.
[10] Raijmakers, M.E.J., Van Koten, S., & Molenaar,
P.C.M. (1996): On the validity of Simulating Stagewise
Development by means of PDP Networks: Application of
Catastrophe Analysis and an Experimental Test of RuleLike Behavior. Cognitive Science, 20 (1): 101-136.
[11] J. Kruschke, “Alcove: An exemplar-based
connectionist model of category learning,” Psychological
Review, vol. 99, pp. 22–44, 1992.
[12] S. Sirois and T. Shultz, “Neural network modeling of
developmental effects in discrimination shifts,” Journal of
Experimental Child psychology, vol. 71, pp. 235–274, 1998.
[13] R. O’Reilly, D. Noelle, T. Braver, and J. Cohen,
“Prefrontal cortex and dynamic categorization tasks:
Representational organization and neuromodulatory
control,” Cerebral Cortex, vol. 12, pp. 246–257, 2002.

Conclusion
We have presented a neural network model of the
development of discrimination-shift learning that shows
discontinuous learning in distinct learning modes. The
effectiveness of negative reinforcement was varied between
adult networks (high) and child networks (low). Networks
modeling adult performance learn fast and are modeled by a
fast, discontinuous learning process. The learning process is
discontinuous for all child networks, and is best modeled by
a two-component model with components for fast and slow
learners. That is, only a subset of the child networks learn
slower than the adult networks. Differences in learning rate
were caused by an interaction between initial bias and the
rule to be learned. Child networks are less able to switch
dimensional preference and category-to-response connections because of the decreased influence of negative
reinforcement compared to the adult networks. For child
networks this results in a mixture of learning modes as
found in the empirical study [1]. Note that the twocomponent structure of the trial-by- trial learning data of the
child networks is the result of a uniform distribution of
initial dimensional preferences. That is, a continuous
variation in networks’ initial state results in categorical
difference in performance.
The implementation of the stochastic process within the
category-to-response connection based on the negative
reinforcement parameter provided the required differenttiation between stages of development after the shift has
occurred. As expected, child networks executed shifts
slower than adult networks. Also, reversal shifts were easier
than non-reversals for adult networks, yet for child networks
no significant difference was found. These results concur
with empirical evidence (e.g. Espirito, 1975). From the
model we can predict that children have a larger variation in
the number of trials they need for shift learning than adults.
This would also explain the inconsistent results presented in
literature.
A next step towards a more complete model of
discontinuous discrimination-shift learning is a network that
is able to induce its own representational categories based
purely on input. In addition, future research could examine
whether the overtraining effect can also be reproduced,

795

Feature nodes xi activate category nodes yj weighted by zij
and bias nodes Ωk (k=1,2: 1=color, 2=shape):

[14] I. Visser, M. Raijmakers, and P. Molenaar, “Fitting
hidden markov models to psychological data,” Scientific
Programming, vol. 10, pp. 185–199, 2002.
[15] M. Frank, L. Seeberger, and R. O’Reilly, “By carrot or
by
stick:
Cognitive
reinforcement
learning
in
parkinsonism,” Science, vol. 306, pp. 1940–1943, 2004.
[16] M. Frank, B. Loughry, and R. O’Reilly, “Interactions
between frontal cortex and basal ganglia in working
memory: a computational model,” Cognitive, Affective and
Behavioral Neuroscience, vol. 1, pp. 137–160, 2001.
[17] M. Frank and E. Claus, “Anatomy of a decision:
Striato-orbitofrontal interactions in reinforcement learning,
decision making and reversal,” Psychological Review, vol.
113, pp. 300–326, 2006.
[18] Morton, J.B. & Munakata, Y. (2002). Active versus
latent representations: A neural network model of
perseveration, dissociation, and decalage. Developmental
psychobiology, 40, 255 – 265.
[19] G. Kaplan, N. Sengör, H. Gürvit, I. Genc¸, and C.
Güzelis¸, “A composite neural network model for
perseveration and distractibility in the Wisconsin card
sorting test,” Neural Networks, vol. 19, pp. 375–387, 2006.
[20] H. Atallaha, M. Frank, and R. O’Reilly, “Hippcampus,
cortex and basal ganglia: Insights from computational
models of complementary learning systems,” Neurobiology
of Learning and Memory, vol. 82, pp. 253–267, 2004.
[21] E. Crone, K. Ridderinkhof, M. Worm, R. Somsen, and
M. van der Molen, “Switching between spatial stimulusresponse mappings: a developmental study of cognitive
flexibility,” Developmental Science, vol. 7, no. 4, pp. 443–
455, 2004.
[22] Berkeljon, A. & Raijmakers, M.E.J. (2007). An ART
Neural Network Model of Discrimination Learning.
Proceedings of the IEEE ICDL, Imperial college London,
11 – 13 july 2007.
[23] G. Carpenter and S. Grossberg, “A massively parallel
architecture for a self-organizing neural pattern recognition
machine,” Computer, Vision, Graphics and Image
Processing, vol. 37, pp. 54–115, 1987.

(3)
with I=100 and g defined by:
(4)
Weights zij and zji between x and y are fixed. If i=j , zij=5
and otherwise zij=0.; zji=zij/5 resulting in 0 and 1 values. The
category node yi with the highest activation value and the
negative reinforcement gain α-determines the response a
weighted by the weights between the two, initialized randomly
at 1 or 0 and updated by:
(5)
with S=6.5 and ychoice represents y node activity where
ychoicej=1 if yj=max(y) and 0 otherwise. The stochastic
process added to augment response choice samples from a
uniform random distribution between 0 and 6.5; if the value is
< α- then σ is 1 and otherwise 0. Weights wyr are updated as
follows:
(6)
with tr set to 1 if response is correct and 0 if incorrect. The
bias node activates itself, is inhibited by the competing bias
node and is activated by the corresponding habit node and the
reinforcement value mediated by positive and negative
reinforcement, α+ and α- respectively.
(7)

with E=.01, F=3, G=1.1 and θ1=1. The reinforcement
value is 1 for correct and -1 for incorrect response. Initial bias
values are sampled from a uniform random distribution
between 1.7 and 2.3 for adult and child networks. Positive and
negative reinforcement gain is set to 1.2 and 8 for adult
networks and 1.2 and .8 for child networks. Variable is a
match signal occurring between input I and category node y:

Appendix: Network Specification
The network specification agrees with [22] with a few
modifications for this DSL model. Input Ii is set to 5 when
feature i (i=1,2,3,4: 1=black, 2=white, 3=triangle, 4=circle) is
present in the stimulus and 0 otherwise. The feature nodes
xi=1,2,3,4 are activated depending on Ii and category node
activation, represented by yj (j=1,2,3,4: 1=black, 2=white,
3=triangle, 4=circle) and weighted by zji:

(8)
in which i is the index of feature node x. J is the index of
max(y), and k the index of the corresponding bias node. Ii is
the input signal (5 or 0). Activation of the habit nodes is given
by with H=.1, J=3 and θ2=.5.

(1)

(9)
with A=10, B=5, C=1, D=1 and f defined by:
(2)

796

