UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Distance Estimation as a Process of Generating Ad-Hoc Metrical Systems

Permalink
https://escholarship.org/uc/item/6427d9ds

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Davies, Jim
Thomson, Robert

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Distance Estimation as a Process of Generating Ad-Hoc Metrical Systems
Robert Thomson (rthomson@connect.carleton.ca)
Institute of Cognitive Science, Carleton University
1125 Colonel By Drive, Ottawa, ON K1S5B6 Canada

Jim Davies (jim@jimdavies.org)
Institute of Cognitive Science, Carleton University
1125 Colonel By Drive, Ottawa, ON K1S5B6 Canada
blindness (Rensink, O’Regan & Clark, 1997) suggests that
observers do not necessarily use an independent metric of
space to consolidate successive views, but instead rely on
local information (Intraub, 1997). We will now examine the
evidence behind two processes implicated in representing
distance: metrical and categorical accounts.

Abstract
The present research utilizes a change detection paradigm to
contrast two candidate processes by which distance is
encoded. The first process is an intrinsic absolute metrical
system, where distance is encoded in an underlying universal
matrix, such as visual co-ordinates. The alternative is a local
ad-hoc metrical system where distance is encoded as a ratio
of the size of a salient object in the scene. Manipulating
object size differentiated between these candidate processes.
A forced-choice change detection task modeled after Cole,
Kentride, Gellatly & Heywood (2003) and a mouse dragging
task tested memory for recognition and production of distance
respectively, with results indicating that changes in object
size affected both memory for the recognition of- and the
subsequent reproduction of past perceived distances.
Keywords: spatial cognition; change detection; distance

Introduction
Rodney Brooks (1991) has argued that the world acts as its
own best representation, where much of behaviour can be
governed by what is directly perceived. On the other hand,
we have the ability to accurately store visuospatial
information, with limitation. For example, after viewing a
scene it is possible to recall the location of several objects
(Vogel, Woodman, & Luck, 2001; 2006), estimate their
approximate size (Baird & Wagner, 1991), and their
approximate distance to each other (Frenz & Lappe, 2006).
When spatial information is recalled in the absence of
visual perception, it is evident that the processing system
relies solely on memory. What is less understood is the
nature of the information being stored. There is strong
evidence that an object’s perceived size and distance are
influenced by the size and distance of other objects that
were recently the focus of attention (Makovski & Jiang,
2008), and which have also been perceived in conjunction
with the object in question (Baird & Wagner, 1991).

Theories of Distance Encoding
While there is no question that we can estimate distance
with varying accuracy when a task demands it, it is not clear
whether we necessarily store metrical distance information.
We encode very little of a perceived scene unless we are
explicitly attending to the items in question (Henderson &
Hollingworth, 1999), even though our subjective experience
of the scene is robust. Evidence from transsaccadic memory
shows that even when a visual image is shifted by up to 1.2°
of visual angle or contracted by 20%, these changes often go
unnoticed (McConkie & Currie, 1996). This change

Metrical Distance: Mental Scanning Paradigms
The most influential evidence that metrical distance
information is stored during visual perception comes from
studies on mental scanning (Kosslyn, Ball, & Reiser, 1978).
In the predominant version of the mental scanning
paradigm, several landmarks are studied in a pre-arranged
configuration until their locations are memorized. This is
generally referred to as generating a ‘cognitive map’ of the
scene. For each trial, a landmark from the map is visualized
and, when hearing the name of a second landmark, the
participant has to mentally scan the distance between
landmarks and press a button when scanning is complete.
Multiple studies have found a linear correlation between
response time and distance between landmarks (Kosslyn, et
al., 1978; Kosslyn, 1994; Cocude, Mellet, & Denis, 1999).
This linear increase in response times has further been
correlated with the actual visual scanning times in some
participants (Cocude et al., 1999), and has also been found
when the perceived map was described textually as hourly
positions around an imaged clock (Denis & Cocude, 1992).
There are limitations to the theory that visual memory and
imagery are in some way isomorphic with perception. The
linear correlation between mental scanning and distance has
been shown to be highly task and instruction-dependent.
When the participant is asked to trace distance path by
mentally following a dot along the distance, then the mental
scanning times are linearly correlated with distance with a
coefficient of determination up to 0.97 (Kosslyn et al.,
1978). When this dot-following heuristic is left out of the
instruction, however, a much lesser (or no) linear correlation
is evidenced (Pylyshyn, 1981). Furthermore, if a participant
is asked to imagine ‘jumping’ from one landmark to another
rather than ‘scanning,’ no correlation between response
times and landmark distance are found, presumably because
no ‘scanning’ occurred within the participant’s mental
representation (Pylyshyn, 2002). This stands in contrast
with previous research indicating that it was not possible to
eliminate mental scanning effects (Kosslyn, 1994). Still, the
fact that it is possible to exhibit a linear correlation between
response time and distance implies that metrical distance is
at least implicitly represented in memory (Pylyshyn, 2002).

2932

Categorical Distance: Mental Model Theory
Mental models claim that distance is generally encoded
categorically in a symmetrical mental array where ‘cells’
contain object labels. Adjacent cells represent categorical
spatial relations (e.g., above, left-of) equidistant to each
other, with no metrical distance (Johnson-Laird & Byrne,
1991; Knauff et al., 2004). While some instantiations of this
model take a more literal interpretation of the representation
as array-like (see Glasgow & Papadias, 1992) the notion of
a mental array is generally presented as a heuristic to
explain certain consistencies in experimental results.
Spatial mental model theories have their own predictions
about stored spatial information. These theories hold that
metrical distance information is not generally necessary
(and thus not always stored) for much of spatial reasoning.
This is especially true for simple environments or situations
where the underdetermined spatial information leads to
multiple possible interpretations. To take an example from
driving directions, if we need to know to turn left at the gas
station, then we don’t need to know the exact distance to it.
While mental models focus on the categorical links
between objects in representations of spatial configurations,
there is an implicit notion of distance estimation within their
array-like behaviour. The assumption that ‘cells’ (or for a
less leading term, indexes) are symmetrical leads to several
consequences. The first is that a limited distance metric is
available. Symmetry implies that there is the possibility of
empty cells to maintain consistency within the configuration
of the data structure, strengthening the analogy of the
mental model as array-like. Any array-like data structure,
especially a 2D one, is functionally analogous to a Cartesian
co-ordinate system. Along a single ‘row’ it is possible to
judge whether an object is farther away than another by
examining how many indexes apart two objects are. While
this judgment is not metrical in an absolute sense (i.e., the
size of cells does not necessarily conform to the same length
across trials), the use of tacit knowledge (e.g. knowledge of
object size or scale) can consolidate this sparse distance
information into a judgment of metrical distance.

Neuro-physiological Evidence
fMRI studies have found that many regions in the primary
visual cortex implicated in perception are also implicated in
visual mental imagery. However, this overlap is not uniform
with Borst & Kosslyn (2008) finding less activation in the
primary visual cortex during imagery. Additionally, they
found increased activation in the frontal and parietal regions
implicated in top-down processing. This implies that some
memory (re-)construction is occurring. Still, there is enough
evidence to assume some representational similarities
between our perception and our mental image of a percept.
Located within the entorhinal cortex is a region where
topological spatial information appears to be consolidated
within two layers of cells, aptly named grid cells and place
cells (Fyne et al., 2004). Grid cells are topologicallyencoded bundles of neurons arranged in a periodic
hexagonal grid. Different ‘levels’ of grid cells activate in

terms of different ‘sizes’ of their corresponding receptive
fields, indicating that the brain processes signals into
progressively more precise spatial regions. At first glance, it
therefore appears that some preference should be afforded to
spatial layouts whose objects fall into specific spatial
regions denoted by the firing rate of a specific bundle of
grid cells. Grid cells at different levels appear to have
different firing patterns, limiting a purely topographical
interpretation (O’Keefe & Nadel, 1978).
Place cells, on the other hand, do not exhibit any periodic
properties and instead fire only when an object occupies a
specific region of the visual field. When experiencing a
novel environment, the organization of place cells is rapidly
determined, although not in any topological organization.

Ad-Hoc Metrics
If people encode spatial information in an absolute
metrical system, then having knowledge of even basic
coordinate information would make it possible to generate
complete spatial information of a given scene (Ligozat &
Edwards, 2002). It would also be a simple matter to
compare distances across scenes as it is simply a matter of
scalar comparison. From the evidence previously outlined, it
is evident that people do not exhibit perfect spatial recall,
especially with regards to distance.
In a system of locally-generated ad-hoc metrics, it is
difficult to directly compare distances across scenes because
the metrics used are usually different, since different objects
are present. Inter-scene comparison is possible by using
additional (e.g., tacit) reasoning to scale the relative sizes of
the objects forming the metrics. This could occur at a
semantic level (e.g., knowing that a car is approximately
16ft long so 3 car lengths is approximately 50ft away) or
from past experience (e.g., knowledge that a bicycle is about
1/3 the size of a car thus 6 bicycle lengths is 2 car lengths).
Within the ad-hoc theory, errors can occur at multiple
points, for example: semantic information involved might
be incorrect (e.g., cars can be as short as 8ft long in the case
of a compact, or 30ft long in the case of a limousine), or the
visual estimate of distance might be incorrect (e.g. it was
actually 4 car lengths). This theory does not make the strong
claim that we only store distance in terms of object-ratios,
but simply that this is one heuristic used which is as valid
as, or can be seen as an extension of, mental model theory.

Present Research
The present research will provide empirical evidence to
determine the role object size plays in estimating distance. If
object-size does not significantly impact judgments of
distance, then the results would be consistent with a theory
of absolute distance, otherwise if object-size impacts
distance judgments then results would be consistent with a
theory of ad-hoc metrics.
The one-shot change detection paradigm (Cole et al.,
2003) was adapted to measure which visuospatial aspects of
a scene are initially encoded and available for future
comparison. In the present experiments, distances are

2933

compared between sequentially-presented images of two
monochrome squares symmetrically located around the
center of the display. These simple squares were used to
control for semantic effects and have stimuli which are
symmetric around both horizontal and vertical planes.
Experiment 1 is a forced-choice task with object size and
distance systematically varied to examine the interaction of
object size on distance judgments. Judgments are made
using a trinary CLOSER-SAME-FARTHER decision tree.
Experiment 2 expands upon this exploration of distance
encoding through the use of a mouse dragging task. After
presentation of the same first image as in Experiment 1,
with one square anchored, participants drag the other square
to re-create the distance from the first image. This dragging
will allow more fine-grained examination of the influence
object size has on perceived distance and compare memory
for recognition versus memory for production.

Experiment 1: Forced-Choice Task
The objective of this forced-choice change detection task is
to provide reasonable evidence about the nature and
accuracy of observers’ preliminary processing of distance
between objects in a visual scene. Object size was
manipulated between images to determine its effect on
distance judgments. The use of the one-shot change
detection paradigm minimizes the role of eye movement and
long-term memory (Rensink, 2002).
If participants underestimate distance when object size is
increased (and overestimate when object size is decreased)
then the ad-hoc metric hypothesis will be supported. In
contrast, if distance judgments are unaffected by object size,
then evidence would point towards an absolute metrical
system where distance is encoded irrespective of object size.
The use of the trinary CLOSER-SAME-FARTHER
judgment served to further address the accuracy of people’s
change detection that a simple SAME-DIFFERENT binary
judgment could not. Binary judgments only determine that a
size change has been made, but not its exact influence (i.e.
increase/decrease) on perceived distance. In this experiment,
both accuracy and response times were recorded.

Method
Participants
Twenty-nine undergraduate students with normal or
corrected-to-normal vision were provided with course credit
for their participation. One participant was excused for
repeatedly failing to follow task procedures.
Materials
The first image (see Figure 1) was presented for 1200ms. A
white-noise mask was presented for 600ms, followed by the
second image until a response was received. Durations for
the stimuli were derived from a one-shot change detection
methodology from Cole et al., (2003).
Each stimulus consisted of sequentially-presented paired
images, with two identically-sized squares in each image.
This study was conducted with stimuli of nine different
sizes between 0.65° - 2.25° in 0.20° increments. The first
image presented consisted of three different stimuli sizes
(1.05°, 1.45°, and 1.85°) and the size was varied in the
second image presented by 0°, +/- 0.20°, or 0.40°. The size
of the objects was determined from change detection studies
(Vogel, Woodman, & Luck 2001; Cole et al., 2003) which
ranged from 0.65°- 2.8° of the visual field. The white noise
mask eliminated any retinal afterimage, which might have
provided an index for spatial position.
Distances between objects ranged from 2, 3, or 4 objectsizes apart, calculated from the inner edge of the objects.
The distance metric was also varied, with distances in the
second image remaining unchanged or changing to the
object-ratio of the object size in the second image. In
addition to distance, the orientation of the stimuli was also
varied (horizontal and vertical presentation). Due to the
majority of distance estimations occurring along the
horizontal plane (i.e., ground level) it is possible that
horizontal distance judgments would be more accurate.
In total, 180 experimental trials were completed. In
addition to the experimental trials, 36 control trials were
also developed where distance varied but object size did not.
The experiment was divided into two blocks with half the
trials consisting of horizontally-oriented stimuli and the
other half vertically-oriented, with the corresponding
vertically- and horizontally-oriented stimuli in the other
block. Trial order was randomized between participants.
Apparatus
The experiment was developed using the VisionEgg 1.1
wrapper for Python. Stimuli were presented on a 24” LCD
monitor at a resolution of 1920x1200. Responses were
recorded on a three-button mouse.

Figure 1. Sample paired stimulus from Experiment 1. 1b)
and 1c) identify how the change in distance metric is seen.

Procedure
The experimental room was setup such that the computer
monitor was the only object visible on the desk. To control
for lights and to reduce the possibility that the texture of the
wall in the background would be used as a heuristic for
determining relative distance, the desk and walls were
covered with a minimally-reflective black plastic.

2934

Participants entered the experiment room and sat in an
adjustable chair such that their eyes are centred 60cm (~25”)
from the screen. They were instructed to focus their gaze to
the centre of the screen and to minimize head and body
movements as much as comfortably possible. They then
underwent four practice trials to learn the task procedure,
with no feedback provided about the accuracy of their
response. Speed and accuracy were equally stressed, as was
the requirement to judge distances from the inner edge of
the stimuli. Responses were recorded on a three-button
mouse as follows (from left-button to right-): CLOSER,
SAME, and FARTHER. The spacebar was pressed to
advance between trials. Response times were recorded from
the onset of the second image to the pressing of the mouse
button.

Results and Discussion
A repeated-measures ANOVA was conducted with accuracy
and response time as the dependent variables. The
independent variables examined include the change in
object size, the metric (whether distance changed or not
between images), and orientation. Initial size and distance
were aggregated to focus on the main prediction that object
size influences distance judgments, and neither had
exhibited any significant effect in preliminary analyses.
The main effect of changing object size exhibited the
strongest influence on both accuracy and response time,
F(2.878, 28) = 36.757, MSE = 2.331, p < .001, η2 = .472
and F(2.719, 28) = 14.403, MSE = 1220000, p < .001, η2 =
.659 respectively (Greenhouse-Geisser adjusted). This
supports the hypothesis that object size is a determining
factor in the judgment of distance. Additionally, larger
absolute changes in object size caused an linearly increasing
latency irrespective of object size increasing or decreasing.
Interestingly, there was no main effect of distance metric
on response times, F(1, 28) = .053, MSE = 3479, p = .820,
implying that the mental processing demands are similar
whether distance changes or not. On the other hand
changing the distance metric negatively impacted accuracy,
F(1, 28) = 8.315. MSE = 1.456, η2 = .103, which implies
that changing the size of the object was not the only visual
process at work. Another visual process is likely at work
detecting when the distance is the same, such as a visual
indexing mechanism. It is possible, however, that people are
exhibiting a SAME bias when uncertain of distance change.
To attempt to respond to a ‘SAME’ bias argument, a
significant change x distance metric interaction occurs in the
accuracy data, F (4, 28) = 43.672, MSE = 1.753, η2 = .412,
and to a lesser degree in the response time data, F(4, 28) =
2.453, MSE = 155600, p = 0.50, η2= .084. As seen in Figure
2, when the distance did not change, participants remained
highly accurate at maintaining an index of the distance with
the smaller 0.20° changes, with accuracy dropping off at the
larger 0.40° changes. When the distance metric does not
change, all correct responses are SAME. When the distance
metric does change at the smaller 0.20° size changes,
participants incorrectly report a SAME response.

Figure 2: The effect of Change in Object Size on Accuracy
Examining a subset of trials where the absolute distance
change is the same as in the control trials (where distance
changes but object size remains constant), participants
respond with an accuracy of .7443 (SD = .4369, N = 348) in
the control trials as opposed to .4871 (SD=.5001, N = 696)
in the experimental trials, a highly significant result; t(1042)
= 8.1608, p < 0.0001. This significant result indicates that, if
a SAME bias occurs, it is not due an inability to perceive
the distance change.
Another possible interpretation is that participants are
automatically scaling the second image when the distance
metric changes. Since the distance is the same proportion as
in the first image, participants will respond SAME. If this
was the case, then we would expect to see larger relative
error rates when object size changes and distance does not,
since the distance metric is no longer in the same
proportion. As seen in Figure 2, accuracy does not drop to
the same extent at +/- 0.20° object size when distance does
not change, indicating that scaling could not be the only
participants are not scaling the image. However, a strategy
involving both scaling and visual indices and processes
would be consistent with the above results. Still, the
‘scaling’ argument would imply that participants were
unaware of the size change. Post-test questionnaires and
experimenter discussion with participants detail that
participants were aware of the object size change.
Participants exhibited similar performance in both
horizontal and vertical presentation: orientation exhibited no
main effect on either accuracy or response time, F(1,28) =
0.006, MSE = .000, p > .939; F(1,28) = 0.092, MSE = 6690,
p > .764 respectively. No significant cognitive preference
given to horizontally-presented stimuli.
A significant distance metric x orientation interaction was
found only for response time, F(1, 28) = 16.589, MSE =
1180000, p < .001, η2 = .160, where responses were quicker
when vertical stimuli were judged with a distance change, as
opposed to horizontal stimuli where responses were slower
when a distance change occurred. This was later found to

2935

be an artefact of practice effects due to an error in the
randomization of stimuli, where more vertical stimuli with
no distance changes were present in the first block of trials.
Similarly, this confounding artefact also accounts for the
significant change x metric interaction with regards to
response times.
This initial experiment provided evidence that changes in
object size inhibits accuracy of responses in this forcedchoice change detection task. The nature of change
detection tasks further implies that a more absolute
encoding of distance (e.g. natural visual coordinates) is
either not present or not accessible in the time-course
allowed by this methodology. A limit of this methodology
is that it only tests memory for recognition, and does not
provide any quantitative estimates about changes in object
size influencing distance.

Experiment 2: Drag-and-Drop Task
To examine in more detail the effects of object size on
distance judgments, a follow-up experiment was conducted
using a drag-and-drop change detection methodology. The
main limitation in change detection tasks is that they are
equally consistent between accounts due to a deficit in
encoding or a deficit in comparing encodings (Cole et al.,
2003; Rensink, 2002). To explain, it may be the case that
the distance encoded from the initial image is either blended
with- or overridden by the distance perceived in the second
image, due in part to the similarities of both images.
Furthermore, Experiment 2 involves the production of
distance, which provides a more quantitative measure of
distance encoding than the forced-choice methodology in
Experiment 1, to determine whether changing object size
influences distance judgments proportionately.

Method
Participants
Twenty-three undergraduate students with normal or
corrected-to-normal vision were provided course credit for
their participation.
Materials and Procedures
Materials consist of the same stimuli as Experiment 1 but
with the following procedural difference: in the second
image the objects were initially adjacent to each other with
one anchored and the participant was instructed to drag the
other object the same distance apart as they recalled from
the first image (see Figure 2). The anchored object was
always in the same location as was presented in the first
image. It is important to remember that the initial image is
centered in the screen with the stimuli symmetrical in both
the horizontal and vertical planes. To control for any
dragging preferences, trials included both the left and right
object being anchored. The control trials were eliminated as
there was no change in distance between images.
Both accuracy and response times were recorded for this
experiment. Accuracy was considered the dragged object’s
%deviation from its distance as seen in the first image.

Figure 2: Paired stimulus from Experiment 2

Results and Discussion
A repeated-measures ADNOVA was conducted with
accuracy and response time as the dependent measures.
Initial size, orientation, and anchor (left or right object) were
aggregated after finding no significant main effects.
Supporting the results of Experiment 1, there was a strong
main effect of changing object size, F(4,23) = 305.236,
MSE = 12.761, p < .001, η2 = .821, indicating that changing
object size influences distance production such that
reducing object size leads to underestimation of distance
and conversely increasing object size causing distance
overestimation. There was a smaller main effect of distance,
F(2,23) = 55.529, MSE = 3.472, p < .001, η2 = .165, due to
the fact that the critical accuracy measure is %deviation, so
similar deviation in terms of absolute screen co-ordinates
will result is smaller %deviation with larger stimuli and
distances.
While changing object size affected %deviation, it did not
do so in perfect linear proportion. Changes in object size
explained a significant proportion of unique variance in
%deviation scores, R2 = .466, F(4,23) = 601.523, p < .001,
but was not sufficient to be the only factor involved.
Interestingly, the only significant response time measure
was a main effect of distance, F(2,23) = 9.929, MSE =
39347181.04, p < .003, η2 =.735, indicating simply that it
took longer to drag the mouse cursor larger distances. While
puzzling, it is important to note that all judgments took
relatively longer in this task than Experiment 1. It is
possible that changes in response times have been subsumed
by the time it takes to drag the objects in the second image.
In future work, response times will be gathered from the
initial mouse-button press to see if participants are making
their decision while dragging, or simply refining their
decision before pressing any mouse-button.
Another possibility is that with larger distances the visual
system has only a limited visual resolution in the periphery
of the stimuli (Borst & Kosslyn, 2008), and has increased
difficulty maintaining any visual index without reference to
any other point, such as the edge of the screen (Pylyshyn,
2002). Thus, it is difficult to maintain fixation in blank
space as the eye has little information to focus on,
compounding error across saccades.

General Discussion
Taken together, the results from Experiments 1 and 2 have
identified that changes in object size affect distance
judgments both in tasks involving memory for recognition
and memory for production.

2936

If distance perception is regarded as a predominantly
categorical system as defined in the ad-hoc metrical theory,
then in Experiment 2 any change in object size should cause
a proportional change in produced distance. Similarly, in
Experiment 1 there should a bias towards increases in object
size in the second image causing a false CLOSER response
when distance is actually the same, and decreases in object
size should cause a false FARTHER response.
Evidence has been presented detailing the strong effect
object size plays in distance perception, but changes in
distance did not elicit a perfectly proportional change in
distance perception. Our results support a multiple process
interpretation, where the ad-hoc metrical theory is one
encoding process receiving feedback from a visual indexing
mechanism, such as in FINST theory (Pylyshyn, 2002)
The advantage of ad-hoc metrics is in parsimony: neither
the perceived size of the object nor any precise distance
measure need be encoded to accurately gauge relative
distances, only the ratio of object-size to distance is needed.
The constancy of the external environment serves as the
medium with which much of spatial information resides.
From this point, distance can be accurately recalled using
tacit knowledge about object size and performing a simple
calculation to estimate a more precise distance.
Further data analysis needs to be completed to determine
whether participants adopted different strategies, which
would also have implications as to whether the application
of ad-hoc metrics is a function of visual memory or a task
heuristic. Additionally, space limitations have precluded the
discussion of visual illusion and the role of size constancy in
this methodology (McKee & Welch, 1992)

Acknowledgements
We would like to thank Dr. Aryn Pyke for her assistance
with experimental design and early drafts of this paper.

References
Baird, J.C., & Wagner, M. (1991). Transformation theory of
size judgment. Journal of Experimental Psychology:
Human Perceptual Performance, 17 (3), 852-64.
Borst, G., & Kosslyn, S. M. (2008). Visual mental imagery
and visual perception: structural equivalence revealed by
scanning processes. Memory & Cognition, 36, 849-862.
Brooks, R. A. (1991). Intelligence Without Representation.
Artificial Intelligence, 47, 139–159.
Cocude M., Mellet E., & Denis M. (1999). Visual and
mental exploration of visuospatial configurations:
behavioural and neuroimaging approaches. Psychological
Research 62 (2-3), 93-106.
Cole, G.G., Kentridge, R.W., Gellatly, A.R.H., & Heywood,
C.A. (2003) Detectability of onsets versus offsets in the
change detection paradigm. Journal of Vision, 3, 22-31.
Denis, M., & Cocude, M. (1992). Structural properties of
visual images constructed from poorly or well-structured
verbal descriptions. Memory & Cognition, 20, 497-506.

Frenz, H., & Lappe, M. (2006). Visual Distance Estimation
in Static Compared to Moving Virtual Scenes. The
Spanish Journal of Psychology, 9 (2), 321-331.
Fyhn, M., Molden, S., Witter, M., Moser, E., & Moser, M.
(2004). Spatial representation in the entorhinal cortex.
Science, 305, 1258-64.
Glasgow, J. I., & Papadias, D. (1992). Computational
imagery. Cognitive Science, 16, 355–394.
Henderson, J. M., & Hollingworth, A. (1999). The role of
Fixation Position in Detecting Scene Changes Across
Saccades. Psychological Science, 10 (5), 438-443.
Intraub, H. (1997). The representation of visual scenes.
Trends in Cognitive Science, 1 (6), 217-222.
Johnson-Laird, P. N., & Byrne, R. M. J. (1991). Deduction.
Hillsdale, N.J.: Erlbaum.
Knauff, M., Strube, G., Jola, C., Rauh, R., & Schlieder, C.
(2004). The Psychological Validity of Spatial Reasoning in One
Dimension. Spatial Cognition and Computation, 4 (2), 167-188

Kosslyn, S. M. (1994). Image and Brain: The Resolution of
the Imagery Debate. Cambridge: MIT Press.
Kosslyn, S. M., Ball, T. M., & Reiser, B. J. (1978). Visual
Images Preserve Metric Spatial Information: Evidence
from Studies of Image Scanning. Journal of Experimental
Psychology: Human Perception and Performance, 4 (1),
47-60.
Ligozat, G., & Edwards, G. (2002) Implicit spatial reference
systems using proximity and alignment knowledge.
Spatial Cognition and Computation, 2, 373-392.
Makovski, T., & Jiang, Y.W. (2008). Proactive interference
from items previously stored in visual working memory.
Memory & Cognition, 36 (1), 43-52.
McConkie, G.W., & Currie, C.B. (1996). Visual stability
across saccades while viewing complex pictures. Journal
of Experimental Psychology: Human Perception and
Performance, 22, 563-581.
McKee, S.P., & Welch, L. (1992). The Preciison of Size
Constancy. Vision Research, 32 (8), 1447-1460.
O’Keefe, J., & Nadel, L. (1978). The Hippocampus as a
cognitive map. Claredon Press: Oxford.
Pylyshyn, Z. W. (1981). The Imagery Debate: Analogue
Media versus Tacit Knowledge. Psychological Review
88:16-45.
Pylyshyn, Z. (2002). Mental imagery: In search of a theory.
Behavioral and Brain Sciences, 25, 157-182.
Rensink, R.A. (2002). Change Detection. Annual Review of
Psychology, 53, 245-277.
Rensink R. A., O'Regan J. K., & Clark J. J. (1997). To see
or not to see: The need for attention to perceive changes
in scenes. Psychological Science, 8, 368-373.
Vogel, E. K., Woodman, G.F., and Luck, S. J. (2001).
Storage of Features, Conjunctions, and Objects in Visual
Working Memory. Journal of Experimental Psychology:
Human Perception and Performance, 27 (1), 92-114.
Vogel, E. K., Woodman, G. F., & Luck, S. J. (2006). The
Time Course of Consolidation in Visual Working
Memory. Journal of Experimental Psychology: Human
Perception and Performance, 32 (6), 1436-1451.

2937

