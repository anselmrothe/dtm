UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The hands and mouth do not always slip together in British Sign Language: Dissociating
articulatory channels in the lexicon

Permalink
https://escholarship.org/uc/item/7z67h6v9

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Fox, Neil
Skinner, Robert
Thompson, Robin
et al.

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The hands and mouth do not always slip together in British Sign Language:
Dissociating articulatory channels in the lexicon
David P. Vinson (d.vinson@ucl.ac.uk)
Robin L. Thompson (robin.thompson@ucl.ac.uk)
Robert Skinner (robert.skinner@ucl.ac.uk)
Neil Fox (neil.fox@ucl.ac.uk)
Gabriella Vigliocco (g.vigliocco@ucl.ac.uk)
Deafness, Cognition and Language Research Centre, Department of Cognitive, Perceptual and Brain Sciences
University College London, 26 Bedford Way, London, WC1H 0AP, UK
LUNCH1 are distinguished only by English-derived
mouthings), but they are also commonplace in
nonambiguous signs, occurring very frequently in
spontaneous conversation, and are often considered to be
part of the signs themselves (see Boyes Braem & SuttonSpence, 2001, for further discussion)2.
However, there is little evidence concerning the precise
nature of the link between mouthings and manual elements
of lexical signs in language production, and the nature of the
systems underlying their retrieval and production. It is
certainly the case that the two must diverge at some point,
because they rely upon different articulatory systems (hands
vs. mouth). Our primary question concerns the extent to
which these representations are linked before this
divergence takes place. On one hand, mouthings might
reflect the activation of representations based on a spoken
language, which are accessed relatively independently from
the sign language representations driving the manual
component of signs. As such they would be incidental to the
retrieval of the manual form, rather than being integrated
before phonological and especially phonetic encoding.. On
the other hand, although mouthings historically originated
as a borrowed form from the surrounding spoken language,
they may have become fully embedded within the sign
language production system and thus completely integrated
with the manual component of signs.
In order to test these two alternatives, we employed a
lexical retrieval task targeting the semantic level of
representation: cyclic semantic blocking (Kroll & Stewart,
1994). In this task, participants repeatedly name objects
presented in contexts of other objects that are either
semantically related or unrelated to each other. In spoken
languages, speakers are slower to name pictures when they
are presented in the context of semantically related items, an

Abstract
We investigate the extent of integration between the hands
and mouthing for lexical signs in British Sign Language,
using picture naming and translation tasks that are sensitive to
semantic similarity effects in lexical retrieval. Semantic errors
in sign forms due to semantically related contexts were more
common in translation from English than in picture naming,
while semantic errors in mouth patterns were sensitive to
semantic context only in picture naming, and not in
translation from English. These results are consistent with an
account whereby mouthing is accessed through a largely
separable channel from manual components of the sign
lexicon, rather than being bundled with manual components
and incorporated into the sign language lexicon despite its
original relationship to English. Effects did not differ between
Deaf and hearing native signers, suggesting that stronger links
between orthography and phonology in the hearing group do
not play a role.
Keywords: lexical retrieval, production, sign language,
mouthing, semantic competition

Introduction
Signed language production involves the simultaneous
use of multiple articulators; not only the two hands
themselves, but also other articulators such as the body,
face, and the mouth have both lexical and grammatical
functions (e.g., to convey adjectival or adverbial
information, or to mark negation, yes-no questions or
relative clauses). In addition to mouth patterns that can be
used to express adjectival or adverbial information, many
lexical signs are associated with specific mouth patterns
which are integral to a specific sign and are time-locked to
production of the sign's manual component (i.e., the
movement of the hands, Boyes Braem & Sutton-Spence,
2001). These mouth patterns are of two types: those
originating within the sign language system, and those
derived from a spoken language. The former, sometimes
termed "mouth gestures", use abstract vocal properties (e.g.,
inhalation/exhalation, mouth shape, or articulation) to
reflect properties of the manual signs themselves (Woll &
Sieratzki, 1998). The latter, instead (often termed
"mouthings"), are derived from the pronunciation of words
in a spoken language. Sometimes mouthings are used to
distinguish between ambiguous sign forms (for example, the
British Sign Language (BSL) signs BREAKFAST and

1

Signs in BSL are customarily represented as English glosses in
capital letters.
2
For example, in a set of 300 lexical signs produced by Deaf
BSL signers for use in a lexical norming study (Vinson, et al.
2009), more than 90% included mouthing, although the sign
models were given only general instructions to produce the signs
as naturally as possible, and no mention was made of mouthing.
This is likely an overestimate of the rate at which mouthing occurs
in discourse (these signs were produced in isolation) but gives an
impression of the importance of mouthing.

160

effect that can be explained by increased semantic
competition during lexical retrieval (Damian, Vigliocco &
Levelt, 2001). The same kind of semantic interference is
also observed when bilingual participants are presented with
a word in L2, and must translate it into L1 (Vigliocco,
Lauer, Damian & Levelt, 2002), thus illustrating that the
same kind of semantic competition occurs when lexical
retrieval is based on translation rather than picture naming.
Crucially, a different pattern is observed for word naming.
When participants are presented with semantically related or
unrelated blocks of words, and are asked to name them in
the same language (i.e., read them), the effect of
semantically related contexts is facilitatory (faster word
naming for semantically related than unrelated blocks), in
contrast to picture naming and translation (Damian et al.,
2001).
Here we use the cyclic naming paradigm with BSL
signers. In one session, signers were asked to name pictures,
in another they were asked to translate English prompt
words into BSL. If mouthings and the manual component
of signs are fully integrated, a single lexico-semantic
representation should be retrieved, hence semantic effects
on mouthings and manual components should pattern
together. Importantly, this should be the case both when
signers are naming pictures as well as when they translate
from English to BSL. If however, BSL manual production
and mouthing are separable, with the latter being based on
the English production system to some extent, we should
see a dissociation of these two error types in the word
translation task. This is because in the picture task, both
manual and mouthing semantic errors should be more likely
in semantically related contexts than unrelated contexts
(reflecting lexical competition at the semantic level, in line
with results of picture naming tasks in spoken languages
(Damian et al., 2001; Vigliocco et al., 2002). In the word
task, however, semantic interference should be stronger for
manual semantic errors, while mouthing errors should resist
the effects of semantic context, in line with the results of
word naming (Damian et al., 2001) whereby the
orthographic-phonological mapping in English permits
retrieval to avoid semantic competition. In other words, the
translation task should be more like word reading for
mouthing, but more like picture naming for manual sign
production.
In addition to native deaf signers, we investigated hearing
BSL signers who learned BSL natively from Deaf parents.
For this group of signers (who are bimodal bilinguals) we
reasoned that the manual and mouthing components may be
less integrated than for native Deaf signers. This is because
mouthing can be more closely linked to English phonology.
Moreover, for these individuals, the link between
orthography and phonology should be stronger. If so, we
would expect hearing signers to show the same pattern of
results as Deaf signers in the picture naming task, but
exhibit more resistance to semantic interference in word
naming.

Method
Subjects
Eight native Deaf BSL signers (four women; average age
23.4, SD = 5.9) and seven hearing native BSL signers
(average age 26.1, SD=6.2) participated in the study. All of
the hearing signers were employed as BSL-English
interpreters at the time of testing. Subjects were paid £20 for
their participation.

Materials and Design
Twenty-five items were chosen, with the following
restrictions: they had to be clearly picturable, and named
with a single word in English and a single BSL sign. Where
possible, visually dissimilar pictures were selected for each
category. Items came from five semantic categories: animals
{dog, snake, mouse, sheep, spider}, artefacts {comb, drill,
saw, scissors, spanner}, clothing {belt, glove, shirt, shoe,
sock}, fruit {apple, banana, cherry, grape, melon} and
vehicles {aeroplane, bicycle, boat, bus, skateboard}.
Pictures were obtained from Snodgrass and Vanderwart
(1980) or created in similar style.
Five semantically related sets of items were prepared by
selecting all five members of a given category; five
semantically unrelated sets were prepared by randomly
selecting one member of each category. Blocks of 25 trials
each were created, randomly selecting from the items in a
set without replacement, five times successively so that each
item would appear in a cycle before any item appeared
again. Two blocks for each set of items were created, each
with a different pseudorandom order of trials. The order of
blocks was randomized for each subject. This same design
was used for both the picture naming and the translation
tasks.
Dependent measures of interest were semantic errors in
either the manual modality (i.e., participant mistakenly
produced a sign or part of a sign that was semantically
related to the correct target sign), or the mouthing modality
(i.e., participant mistakenly produced an English mouth
pattern or part of a mouth pattern that was semantically
related to the correct target mouth pattern). These were
analyzed using factorial ANOVA investigating the effects of
Group (Deaf, hearing) x Task (picture, word) x Block Type
(semantically related, unrelated) treating subjects as random
factors.

Procedure
Participants were told that the experiment investigated sign
production, and that they would see a series of pictures or
words. For each trial, they were start with their hands flat on
a desktop, and then produce the BSL sign as quickly as
possible, returning to the desktop before the next trial. Each
experimental session started with a series of untimed
naming trials: a single picture or English word would appear
on the screen, and participants were asked to produce their
BSL sign for each one. This was to ensure that the items

161

were familiar, and in the event of ambiguity, they could
decide on their preferred sign before the experiment began.
All instructions were given in BSL.
After this was a series of 25 practice trials, one repetition
of each item, presented at the same rate as the experimental
trials. Participants had an opportunity to ask questions
before starting the experimental trials. Each trial began with
a 500ms blank screen, followed by a fixation cross
displayed for 1000ms. The picture or word appeared
immediately thereafter, remaining on the screen for 2000ms.
A 1000ms blank screen ended each trial. Participants were
given the opportunity to take breaks after each block of 25
trials. All trials were recorded using a digital video camera,
and transferred to desktop computers for analysis.
The word and picture tasks were conducted in separate
sessions separated by at least a week. All participants
performed the word task before the picture task.

Importantly, the main effect of group was not significant
(F<1), nor were any of the interactions involving group (all
F<1.4, p>.25).
Table 1: Manual errors: number of semantic errors as a
function of task, block type and group.
Group
Deaf
Hearing

Picture task
Related Unrelated
44
9
25
7

Word task
Related
Unrelated
63
9
52
10

Other errors For erroneously-produced signs that were not
semantically related to the target sign, ANOVA revealed no
main effects or interactions (all F<1.6, p>.20).
Table 2. Manual errors: number of Other errors as a
function of task, block type and group.

Results
Manual production

Group
Deaf
Hearing

Sign productions were individually analyzed frame-byframe, and divided into the following response categories.
Correct signs: Participant produced the target sign without
any kind of disfluency or inaccuracy. Most trials were
correct (95.2% of all trials), reflecting the ease of this task.
Semantic errors: Erroneous productions that were from
the same semantic category as the target word (219
instances; 1.46% of all trials). This included partial errors
where the target was identifiable.3
Purely phonological errors: Erroneous productions that
were semantically unrelated to the target word but shared
some elements of its form (30 instances; 0.02%).
Other errors: These included dysfluencies of various
kinds including subtly incorrect movements or delayed
movements of the non-dominant hand (2.11%), and errors
of other kinds such as unrelated lexical errors, blends and
perseverations (370 instances; 0.56%).

Picture task
Related Unrelated
37
40
56
46

Word task
Related
Unrelated
58
44
44
45

Mouthing production
Mouthing productions were individually analyzed frame-byframe, independently from analysis of manual productions.
Participants produced a mouth pattern of some kind on
79.9% of trials, but tendencies to produce mouthing differed
drastically between individuals. Eleven subjects (five
hearing, six Deaf) produced mouthing on more than 95% of
trials in both picture and word tasks. One hearing subject
virtually never mouthed (less than 10% of all trials), and
another Deaf subject seldom mouthed (less than 25% of all
trials). Finally, two subjects (one Deaf, one hearing)
mouthed much more in the picture task than in the word
task (72 and 99% vs 35% and 50% respectively).

Semantic errors 2x2x2 ANOVA (Group x task x block
type) on number of semantic manual errors revealed a main
effect of block type (F(1,13)=27.394, p<.01); participants
made more errors in semantically related blocks than in
unrelated blocks. There was also a main effect of task
(F(1,13)=6.942, p.021): more semantic errors in the word
task than in the picture task. These main effects were
modulated by an interaction (F(1,13)=5.801, p.032); the
effects of semantic blocking were greater in the word task
than in the picture task.

Trials with mouthing were then further divided into the
following response categories.
Correct mouthing: Participant produced a mouth pattern
that visually corresponded to production of the English
word (10,019 instances; 71.77% of all naming trials).
Semantic errors: Participant produced a mouth pattern
that visually corresponded to a different English word in the
same category as the target word (70 instances; 0.43%)
Hesitations and stutters: Participant hesitated before
producing a mouth pattern or stuttered, repeating all or some
of the mouth pattern (522 instances; 3.27%)
Reduced forms: Participant produced a mouth pattern that
is an incomplete version of the English word, e.g. "sizz" for
"scissors" (706 instances; 4.43%). Many of these should not
actually be considered erroneous utterances, as many mouth
patterns exhibit such characteristics in everyday speech.

3

We also distinguished between mixed errors (errors sharing
elements of both meaning and form with the target) and purely
semantic errors (sharing meaning only) but collapsed them both
into a single category for analyses reported here, as they did not
differ.

162

should be very tightly linked when it comes to semantic
errors.
As shown in Table 5, however, there were strong
dissociations between errors in the two modalities. There
were 190 manual semantic errors which also had some kind
of mouthing, and only 70 trials in which mouthing
substitutions occurred. Crucially there were only 19
instances of trials in which both types of errors occurred
together, a very low proportion if the two types of errors are
meant to arise from mis-selection of a single, shared lexical
representation. Further, many of these errors in one
modality were accompanied by correct utterances in the
other (34 correct manual production accompanied by
mouthing substitution errors, and 72 correct mouthing
production accompanied by manual semantic errors), events
which should not occur if the two modalities share a lexicosemantic representation.

For the analyses involving particular categories of
mouthing, the four subjects who exhibited low levels of
mouthing overall were excluded, leaving six Deaf and five
hearing subjects for analysis.
Semantic mouthing errors 2x2x2 ANOVA on
proportion of semantic errors was carried out. The main
effects of task (F(1,9)=2.692, p=.135) and block type
(F(1,9)=2.000, p=.191) were not significant. However, there
was a significant task x block type interaction
(F(1,9)=6.085, p=.036). In the picture task, there were more
errors for semantically related blocks (1.0%) than unrelated
blocks (0.5%). In the word task, however, there was no such
effect (related: 0.3%, unrelated, 0.4%). This was different
from manual errors for which a greater semantic blocking
effect was observed in the word task.
Again, neither the main effect of group nor any
interactions involving group reached significance (task x
group F(1,9)=2.692, p=.135; all other F<1).

Table 5. Number of trials in each mouthing category as a
function of the type of manual production.

Table 3. Mouthing errors: number of semantic errors as a
function of task, block type and group.

Group
Deaf
Hearing

Picture task
Related Unrelated
18
9
9
4

Mouthing
production
Substitution
Correct
Other errors
No mouthing

Word task
Related
Unrelated
5
4
8
7

Reduced forms 2x2x2 ANOVA on proportion of reduced
forms was carried out. The main effect of group approached
significance (F(1,9)=3.979, p=.077) reflecting a tendency
for Deaf subjects to use reduced forms more often than
hearing subjects. None of the other main effects or
interactions was significant (all F<1.2, p>.3); intersubject
variability was extensive enough to mask any possible
effects here.

Picture task
Related Unrelated
132
123
97
85

Manual production
Non-semantic
Correct
error
response
17
34
206
9741
138
991
39
2563

Discussion
The main findings from the experiment are as follows.
First, broadly speaking, the manipulation of semantic
context had consequences for production in BSL:
semantically related contexts led to more semantic errors in
signing. As no such effect was observed for other sorts of
manual errors, this finding fits well with results from studies
of spoken languages (e.g. Damian et al., 2001; Kroll &
Stewart, 1994; Vigliocco et al., 2002), which highlight the
role of semantic competition during lexical retrieval
processes.
The lack of substantive differences in the effects of
semantic contexts for Deaf and hearing signers strongly
points to commonality in processes despite the differences
in the groups' English language experience (i.e., Deaf
signers experience little or no auditory input from English).
The possible differences between the ways Deaf and hearing
signers learn English did not have consequences for their
sign retrieval in the word translation study, nor did it have
consequences on the degree to which their mouthing was
affected by the task and semantic blocking manipulations.
This suggests that Deaf signers may also have strong
associations between English orthography and phonology
although this would not be based on sound, but rather on the
mouth and tongue actions that correspond to production of
English words. Evidence for this comes from studies of
phonological awareness in Deaf signers. For example, Deaf
adult signers (American college students) have been shown

Table 4. Mouthing: number of reduced forms as a
function of task, block type and group.

Group
Deaf
Hearing

Semantic
error
19
72
99
29

Word task
Related
Unrelated
214
196
156
148

Relation between manual and mouth errors
An interesting question concerns the relationship between
manual semantic errors and mouthing semantic errors. A
straightforward prediction from the hypothesis under which
mouthing is integrated into the sign lexicon is that mouthing
errors and manual errors should tend to occur on the same
trials and seldom dissociate from each other. If both are
derived from retrieval of a single lexico-semantic
representation, and semantic competition leads to misselection of a related representation, the two modalities

163

to possess sufficient phonological awareness to produce
English rhymes that do not share orthography (Hanson &
McGarr, 1989). Deaf children also can show awareness of
spoken phonology (syllables, rhymes and pronunciation of
nonsense words; Sterne & Goswami, 2000).4
Most important, however, is the extent to which manual
and mouthing errors exhibited different patterns of
performance across tasks. In the manual channel,
semantically-related contexts led to greater likelihood of
semantic errors in the English word condition than in
picture naming. On the other hand, semantic errors in mouth
patterns were sensitive to semantic context only in picture
naming, and not at all in the English word condition. This
latter finding suggests that the presence of English
orthography provided resistance in the mouthing channel to
semantic competition in lexical retrieval. This can be
attributed to the reliable mapping between orthography and
mouthing (if not overtly articulated phonology) during
naming in BSL. Also relevant here is the extremely limited
co-occurrence of mouthing and manual semantic errors as
illustrated in Table 5. These errors should have been much
more closely yoked if they arise due to retrieval of the same
lexico-semantic representation.
At a theoretical level, this pattern of results provides
strong evidence against an account of the BSL lexicon
under which mouthings are fully isolated from their English
origins and instead are fully integrated into the sign lexicon,
diverging only during retrieval of phonological features and
not before. Were this to be the case, the same effects of
semantic blocking should have occurred for manual and
mouthing errors in both picture naming and translation from
English, because both production modes are accessed via
retrieval of a single lexico-semantic representation. Instead,
results favor separate representations at this level for manual
and mouthing production components of lexical signs, with
mouthing being based on the English production system to
some extent. This would suggest that the mouthing system
in BSL comes about via the bilingual status of signers who
read and speak English (or at least have learned English
phonological awareness), and is not just historically based
upon English vocabulary.
Of course, these findings apply only to those mouthings
that are derived from English words; mouth gestures related
to properties of BSL signs are much more likely to be
tightly integrated into the sign lexicon. Some evidence
compatible with a possible dissociation between mouthings
and mouth gestures comes from an fMRI study by Capek et
al. (2008), where comprehension of signs accompanied by
mouthings generated activations similar to comprehension

of speechreading (i.e., seeing but not hearing English
words), while comprehension of signs accompanied by
vocal gestures generated activations more similar to
comprehension of manual signs that were not accompanied
by any mouth movement.

Acknowledgments
This research was supported by Economic and Social
Research Council Grant (ESRC) RES000230038, by ESRC
Grant RES620286001 to the Deafness, Cognition, and
Language Research Centre, and by a Wellcome Trust VIP
award. Special thanks to Tyron Woolfe for his help with
implementing and running the initial study with Deaf
participants.

References
Boyes Braem, P., & Sutton-Spence, R. (Eds.) (2001). The
hands are the head of the mouth: The mouth as
articulator in sign language. Hamburg: Signum.
Capek, C.M., Waters, D., Woll, B., MacSweeney, M.,
Brammer, M.J., McGuire, P.K, et al. (2008). Hand and
mouth: Cortical correlates of lexical processing in British
Sign Language and speechreading English. Journal of
Cognitive Neuroscience, 20, 1220-1234.
Damian, M.F., Vigliocco, G. & Levelt, W.J.M. (2001).
Effects of semantic context in the naming of pictures and
words. Cognition, 81, B77-B86.
Friedman Narr, R.A. (2006). Teaching phonological
awareness with Deaf and Hard-of-hearing students.
Teaching Exceptional Children, 38, 53-58.
Hanson, V.L. & McGarr, N.S. (1989). Rhyme generation by
deaf adults. Journal of Speech and Hearing Res, 32, 2-11.
Kroll, J. F., & Stewart, E. (1994). Category interference in
translation and picture naming: evidence for asymmetric
connections between bilingual memory representations.
Journal of Memory and Language, 33, 149-174.
Snodgrass, J. G., & Vanderwart, M. (1980). A standardized
set of 260 pictures: Norms for name agreement,
familiarity and visual complexity. Journal of
Experimental Psychology: Human Learning and Memory,
6, 174–215.
Sterne, A. & Goswami, U. (2000). Phonological awareness
of syllables, rhymes and phonemes in deaf children.
Journal of Child Psychology and Psychiatry, 41, 609-625.
Vigliocco, G., Lauer, M., Damian, M.F. & Levelt, W.J.M.
(2002). Semantic and syntactic forces in noun phrase
production. Journal of Experimental Psychology:
Learning, Memory and Cognition, 28, 46-58.
Vinson, D.P., Cormier, K., Denmark, T., Schembri, A. &
Vigliocco, G. The British Sign Language (BSL) norms for
age of acquisition, familiarity and iconicity. Behavior
Research Methods, 40, 1079-1087.
Woll, B. & Sieratzki, J.S. (1998). Echo phonology: Signs of
a link between gesture and speech. Behavioral and Brain
Sciences, 21, 531-532.

4

There are various ways in which phonological awareness can
come about in the absence of auditory input. It is likely that a very
substantial role is played by visual exposure to spoken English. In
many cases this is supplemented by explicit instruction in
education, not only in order to facilitate actual production of a
spoken language (e.g. communicating with hearing non-signers),
but also in contexts of teaching literacy. A variety of different
approaches are used (for an overview see Friedman Narr, 2006).

164

