UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Locating Targets from Imagined Perspectives: Labeling vs. Pointing

Permalink
https://escholarship.org/uc/item/74c675vf

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Avraamides, Marios N.
Ioannidou, Louiza M.

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Locating targets from imagined perspectives: labeling vs. pointing
Marios N. Avraamides (mariosav@ucy.ac.cy)
Louiza M. Ioannidou (se02iL1@ucy.ac.cy)
Department of Psychology, University of Cyprus
P.O Box 20537, Nicosia CYPRUS

imagined viewpoint is not one that we carry out
spontaneously in our daily lives and it is therefore not very
well practiced.
May (2004) has suggested that locating objects in space is
more difficult when it is done from imagined viewpoints
that are misaligned with the orientation of the physical body
because, in that case, conflicts between the objects´ physical
(sensorimotor) and the objects’ imagined egocentric (i.e.,
relative to one’s self) locations occur. For example, an
object that is directly to the front of an observer would
require a response toward the left if the observer is
requested to imagine rotating 90 degrees in place to the
right. According to May, the physical location of the object
(front) interferes with its imagined location (left) which
specifies the correct response and the observer is left with
the task of having to choose the appropriate action vector
from the two. May’s data corroborate this sensorimotor
interference hypothesis by showing that reaction times for
pointing toward targets from imagined viewpoints vary as a
function of the extent of the conflict (i.e., the angular
difference between the real and the imagined egocentric
positions of the target object). However, even when the
correct action vector is chosen, the observer still needs to
specify it from her physical reference frame. This latter
problem is referred to by May (2004) as head-direction
disparity and is considered an additional source of
interference.
Compatible with May´s hypothesis are the combined
results from two other studies (Klatzky, Loomis, Beall,
Chance, & Golledge, 1998; Avraamides, Klatzky, Loomis,
& Golledge, 2004). Both studies included conditions in
which participants were requested to navigate either
physically or by imagination various triangular paths (e.g.,
“walk 3 meters to the front, turn 90 degrees to the right,
walk another 2 meters”) and then point to the origin by
turning their body towards its direction. Results in the
imagery conditions showed that participants made
systematic errors; they overshot the correct angle by the
extent of the intervening turn. That is, participants seemed
to ignore the discrepancy between their physical and
imagined facing direction. Avraamides et al. (2004)
attributed this to the strong dependence of the manual
response to participants´ physical body. These systematic
errors evidenced in the imagery conditions did not replicate
in the physical movement conditions. Furthermore, in an
additional condition, included in Avraamides et al. (2004),
in which verbal responses replaced manual responding, the

Abstract
Participants in one experiment adopted imagined perspectives
in a perceptually available spatial scene and located targets by
using either verbal terms (labeling) or arrows (pointing).
Results revealed that performance was faster and more
accurate for labeling than pointing and more so when the
adopted perspectives were misaligned with the physical
orientation of the participant. We argue that language
provides a more flexible medium than pointing for responding
from imagined perspectives because it relies less on the
physical body.

Introduction
The cognitive process that allows us to know at all times
where the elements that constitute our environment are
located in relation to our body is known as spatial updating
(Avraamides, 2003; Farell & Thomson, 1999; Farell &
Robertson, 1998; Loomis, Lippa, Klatzky, & Golledge,
2002; Rieser, Guth, & Hill, 1986). A typical study on spatial
updating involves asking participants to point without vision
toward a set of targets, first from their current standpoint
and then from a novel standpoint they adopt after physical
or imagined movement which may include a rotation, a
translation or a combination of the two (e.g., Presson &
Montello, 1994; Rieser, 1989, Rieser et al., 1986). Results
generally show that when physical movement is carried out
performance is equally good from the original and the novel
standpoints. However, when the movement is only imagined
(at least when the movement involves a rotation),
participants are faster and/or more accurate pointing to the
targets from the original than the novel standpoint. This
dissociation suggests that information that is present only
during physical movement -- proprioceptive information,
vestibular feedback and efference copy -- is an important
prerequisite for successful spatial updating (Loomis,
Klatzky, Golledge, & Philbeck, 1999; but see Riecke, van
Veen, & Bülthoff, 2002).
However, results from a number of recent studies suggest
another possibility. Perhaps, pointing to targets from
imagined viewpoints is more difficult because the task of
responding is itself unnatural and awkward. Manual
responses such as pointing with the arm or turning one’s
body toward a target seem strongly attached to the physical
body. This strong dependence to the physical body may
pose difficulties when the physical body should be ignored
in order to respond from an imagined viewpoint.
Furthermore the task of responding manually from an
175

a task that entails adopting imagined viewpoints. The task
deviates significantly from the spatial updating paradigm as
the focus of the experiment is to contrast the two response
modes; nevertheless, our results have important implications
for spatial updating studies.

systematic errors were absent from the imagery condition as
well. These results suggest that there is a difficulty in
responding from imagined viewpoints but this difficulty
occurs only when responding manually.
Results compatible with this possibility are also provided
by Wraga (2003). In one experiment in which participants
used a pointer to locate targets after physical or imagined
rotations, performance followed the typical pattern;
participants were faster pointing to targets after physical
than after imagined rotations. However, in a subsequent
experiment in which pointing was replaced with verbal
responding, the pattern of results was the opposite;
performance was superior after imagined rotations. These
results suggest that pointing performance from imagined
standpoints typically suffers, not because of failure to
update during the imagined movement, but because the act
of pointing is itself problematic when carried out from a
standpoint other than the one occupied by the physical body
of the person. Similar findings are provided by an earlier
study by DeVega & Rodrigo (2001) which used described
rather than perceptual scenes.
It follows from the above studies that language might be
a more flexible, and thus more appropriate, means for
responding than manual pointing. Language is used very
frequently in daily life to locate objects from the
perspectives of others and indeed, there is evidence that
people prefer to adopt the perspectives of others when
communicating locations (Shober, 1993).
We argue that because pointing is strongly anchored on
the physical body, the problem of head-direction disparity is
created. Participants are first called to ignore the orientation
of their physical body in order to determine the response
vector from an imagined reference frame, but then they are
called to use their physical body to execute that vector. This
creates a rather complex and unnatural situation and it is not
surprising then that participants often find the task of
pointing from imagined positions awkward and difficult to
understand. As Presson and Montello (1994) revealed 9 out
of the 40 participants in their imagined rotation condition,
compared to none in their physical rotation condition,
“…expressed some difficulty during the debriefing about
how they should have pointed after the transformation”
(p.1454). On the other hand, the problem of head-direction
disparity should not occur with verbal responding. Of
course, using deictic verbal terms such as “left”, “back” etc,
should not be expected to be devoid of any sensorimotor
interference. These terms are also specified egocentrically
and as shown by Avraamides (2003; Avraamides &
Carlson, 2003) they are also used more easily from physical
than imagined perspectives. However, once the response is
determined it can be executed without any reference to the
physical body.
If indeed language can be used more flexibly than
pointing from imagined perspectives, performance at
locating objects in the same task should be superior for
verbal than manual responding. The purpose of the present
study is to compare directly manual and verbal responses in

Experiment
The purpose of the Experiment is to contrast performance
for locating targets using either verbal labels or a response
that depends more strongly on the physical body.
Participants viewed displays in which they had to
imagine adopting the perspective of a character depicted
sitting around a table and indicate the relative position of a
target character by selecting with the mouse the appropriate
verbal term or arrow displayed on the screen depending on
condition. This response procedure was adopted (instead of
real pointing and oral responding) to equate the motor
demands of the two response modes. As seen in Figures 1
and 2, the two tasks were identical except for the nature of
the response mode.
We expected that overall accuracy would be lower and
latencies would be longer in the pointing than in the labeling
task due to the strong attachment of manual pointing to the
physical body. Therefore, we also expected that the
difficulty with pointing would be exemplified in those trials
in which the perspective participants had to adopt was
misaligned with the orientation of their own body.

Method
Participants Twenty participants (10 males) volunteered to
participate in the experiment.
Materials. Stimuli were presented on a laptop computer.
The task was programmed and presented using E-Prime
(2000). The computer screen was rotated in depth to a near
horizontal position so that participants would experience an
oblique view of the display. Participants responded to each
trial of the experiment by using an external mouse attached
to the USB port of the computer.
Design The experiment followed a 2 x 3 within subjects
design with task (labeling and pointing) and perspective
misalignment (0°, 90°, and 180°) being the two factors. The
order in which the two tasks were completed was
counterbalanced across subjects.
Procedure Before beginning the experimental trials for
each task participants were given a number of practice trials
aiming at familiarizing them with using the mouse to select
the appropriate response from the set of alternatives. For the
labeling task, arrows were presented on the screen as probes
and participants had to select as fast as possible the verbal
label describing the direction the arrow pointed towards.
Similarly, for the pointing task, participants selected from
the set of alternatives the arrow that matched the orientation
of the probe. Before the pointing task participants were
shown trials of the experimental task on paper, and they
were instructed to imagine being at the position of a given
176

character and then point with their arm towards the target.
Then they were asked to indicate the arrow that pointed the
same way. This was done to ensure that participants
understood how they were expected to point and also to
establish the meaning of the response alternatives.
Furthermore, because the response alternatives were
presented in the same order throughout the experiment, the
practice trials also served to offer practice at locating the
desired response without extensive visual search among the
alternatives.
The practice trials were given before each experimental
task and each time were followed by 22 real trials. In both
tasks trials displayed an orthogonal table depicting six
characters sitting around it (Figures 1 and 2). The depicted
facing direction of two characters was aligned with the
physical orientation of the participant (0° perspective
misalignement), that of 2 others was misaligned by 90° (one
clockwise and one counterclockwise), and that of another 2
was misaligned by 180°. Each character sitting around the
table was accompanied by a common greek name printed
underneath its depiction. Participants were instructed to
imagine adopting the perspective of the character named
“ANTREAS” (spelled ΑΝΤΡΕΑΣ in greek) which was
always printed in blue ink and then report the relative
position of the character whose name appeared in red ink
(all other names appeared in black ink).
In the labeling task participants indicated their response
by selecting via a mouse-click one out of 8 possible verbal
labels (greek equivalents for “front”, “back”, “left”, “right”,
“front-left”, “front-right”, “back-left”, and “back-right”) that
were presented at the bottom part of the display (Figure 1).

Figure 2: Sample display from the pointing task. In this trial
the name ΑΝΤΡΕΑΣ is in blue ink and the name ΧΑΡΗΣ in
red.

Results
Accuracy data and latencies for correct responses were
analyzed using a repeated measures analysis of variance
(ANOVA) with task and perspective misalignment as
factors1.
Accuracy
Accuracy was higher in the labeling task than in the
pointing task (94% and 78% respectively), F(1,19)=20.23,
MSE=.04, p<.001. Furthermore, performance varied as
function of perspective misalignment, F(2,38)=21.40,
MSE=.01, p<.001. However, as shown by the significant
task x perspective misalignment interaction this was the
case only in the pointing condition, F(2,38)=14.82,
MSE=.02, p<.001 (Figure 3).
1

Accuracy

0,9
0,8
labeling

0,7

pointing

0,6
0,5
0,4
0°

90°

180°

Perspective M isalignment

Figure 1: Sample display from the labeling task. In this
trial the name ΑΝΤΡΕΑΣ is in blue ink and the name
ΑΝΤΩΝΗΣ in red.

Figure 3: Accuracy as a function of task and perspective
misalignment. Error bars indicate standard errors.

The procedure was identical for the pointing task except
that participants selected arrows pointing toward these 8
directions (Figure 2).

1

Initial analyses indicated no differences in either accuracy or
latency between the two positions with the same angular difference
from the physical orientation of the participant (e.g 90° clockwise
and 90° counterclockwise. Therefore accuracy and latency data
were average to form means for each angle (0°, 90°, and 180°)
177

Pair-wise comparisons using 2-tailed t-tests revealed that
the accuracy in the pointing task was substantially higher in
the 0° misalignment condition than both the 90° and 180°
conditions, t(19)=4.78, p<.001 and t(19)=5.57, p<.001
respectively. Accuracy was higher in the 90° than the 180°
condition but the difference did not reach statistical
significance, p=.26.
None of the pair-wise tests revealed any differences
among the three perspective misalignment levels in the
labeling task. Furthermore, while accuracy for the 0°
misalignment condition was higher for pointing than
labeling, this difference was only marginally significant,
p=.10.
Finally, male participants tended to perform more
accurately than females (89% vs 85%). Again, this
difference was not statistically significant, p=.17.
Latency
Overall, latencies in the pointing task were longer than
those in the labeling task (4690 ms and 3739 ms
respectively), F(1,19)=13.26, MSE=2046170, p<.01.
Furthermore, latencies generally increased with greater
perspective misalignment, F(2, 38)=23.40, MSE=597092,
p<.001. However, a significant interaction between task and
perspective misalignment was obtained, F(2,38)=3.61,
MSE=437563, p<.05. As seen in Figure 3, the increase of
latency with greater perspective misalignment was steeper
in the pointing than the labeling condition. In fact, pair-wise
t-tests revealed that the difference between 0 and 90 in the
labeling condition was not significant, t(19)=1.31, p=.21.
All other differences were significant except for the
difference between labeling and pointing in the 0
perspective misalignment which was only marginally
significant, t(19)=1.88, p=.08.

Discussion
The present experiment compared two modes of responding,
pointing and labeling, in a task that required localizing
targets after adopting imagined perspectives in a
perceptually available spatial scene. Our findings
corroborated our expectation that performance would be
inferior when participants pointed to the targets with arrows
than when they described their relative positions by
selecting verbal terms.
Furthermore, our results showed that the difficulty with
pointing is enhanced when the perspectives to be adopted
are misaligned with respect to the physical orientation of the
participant. Latencies in the pointing condition increased as
perspective misalignment increased from 0° to 90° and then
to 180°. Also, accuracy in the pointing task diminished with
greater perspective misalignment. In contrast, the increase
of latencies in the labeling condition was not very steep. In
fact, only latencies for misalignments of 180° were longer
than the rest. One possible explanation for this finding is
that for the 180° the mapping of the verbal labels “left” and
“right” to the appropriated regions of space is reversed (i.e.,
imagined left is where physical right is). Furthermore,
accuracy was equally high for all levels of perspective
misalignment.
Of course, the decrement of performance as perspective
misalignment increased in the pointing task can be
explained by a mental rotation account. The classic mental
rotation studies (e.g., Cooper & Sheppard, 1971) have
established that latencies for certain judgments (e.g., normal
vs mirrored alphanumeric characters) increase with greater
angular deviations of the stimuli from the upright position.
Similarly, Parsons (1996) has shown that similar results are
found when participants make judgments on human figures
presented at various orientations. Presumably, this occurs
because participants mentally adopt the orientation of the
presented human figure in order to make the judgment.
Based on these findings, it should not be surprising that
latencies in the present study increased with greater
perspective misalignment. However, if we assume that the
slope of the mental rotation function is the same for the
labeling and pointing tasks then our finding of a steeper
increase of latency in the pointing task should be indicative
of the presence of an additional cost exclusive to pointing.
Nevertheless, it seems imperative that further research -possibly with an experiment that separates the time to adopt
the orientation from the time to locate the target -disambiguates the two possible sources of latency cost.
Our results clearly indicate that pointing and verbal
responding are not equivalent tasks in terms of difficulty.
When the perspective to be adopted was aligned with the
orientation of the physical body the two tasks did not differ
much. While pointing was marginally faster than labeling in
the 0° perspective misalignment level, accuracy was higher
for labeling. This possible speed-accuracy trade off could be
attributed to the fact that the 0° trials were inter-mixed with
misaligned trials and participants adopted a strategy of
being more careful and cautious in the pointing task as a

Latency (ms)

6000

5000
labeling

4000

pointing

3000

2000
0°

90°

180°

Perspective M isalignment

Figure 4: Mean latencies as a function of task and
perspective misalignment. Error bars indicate standard
errors.
Furthermore, an analysis examining gender effects
revealed that males were faster than females (3739 ms vs
4690 ms), F(1,18)=5.30, MSE=6160557, p<.05. Gender did
not interact with any other factors.

178

whole. In contrast, when the perspective to be adopted was
misaligned from the participants’ physical orientation,
performance in the pointing task was both less accurate and
fast.
We attribute this difficulty with pointing to the fact that
manual responses are by definition strongly attached to the
physical body and are therefore more dependent on the
body’s orientation. Even when participants are able to
determine the vector that locates a target from their
imagined position, they still need to execute that vector
using a reference frame that is based on their physical body.
We believe that the difficulty with pointing lies at the level
of translating the response vector from the imagined
egocentric reference frame to the misaligned physical
egocentric reference frame in order to execute the response.
This translation is a deliberate process demanding of
cognitive resources and it could be similar to the processes
involved in the mental rotation of external objects2.
Results compatible with the premise that performance in
spatial tasks is affected by the orientation of the physical
body are also provided by May (1996) and Waller,
Montello, Richardson, and Hegarty (2002). Both studies
have used disorienting conditions that reduced sensorimotor
awareness by rotating the blindfolded participants for a few
seconds before asking them to perform a localization task.
May (1996) reported that although performance in the
disorienting condition was worse compared to a physical
rotation condition, it was substantially better than
performance in an imagined rotation condition. Similarly,
Waller et al. (2002) showed that the alignment effect -- that
is, the performance difference between trials in which the
imagined perspective was aligned with the orientation of the
body and those that it was misaligned --was attenuated in
the disorienting condition. Both studies used pointing as the
response medium and their results suggest that being
unaware of the orientation of the physical body is beneficial
for responding from an imagined perspective.
The present results have important implications for
studies aimed at assessing spatial updating failures with
imagined movements. Because most of the studies in this
field of research employ some kind of manual responding,
an ambiguity in interpreting the findings is created: is the
inferior performance with misaligned trials due to spatial
updating failures or is it simply a result of a difficulty with
the response mode?
Related to spatial updating is the literature that examines
the organizational structure of spatial memory. A vast
number of studies have concluded that memory is
orientation specific; that is, people store memories that have
a preferred direction (see McNamara, 2003 for a review).
The typical paradigm for spatial memory studies is as
follows. First, participants experience an arrangement of

objects from a particular viewpoint and they are given time
to study it. Then, with their vision occluded, they are asked
to make judgments from memory about the locations of
objects by responding to statements of the form “you are at
x facing y, point to z” where x, y, and z are objects
contained in the layout. For some trials, called aligned trials,
the orientations participants adopt in imagination are
parallel to the studied viewpoint. For other trials, called
misaligned trials, the orientation are not parallel to the
studied view. With a few exceptions (e.g., Presson &
Hazelrigg, 1984; but see Sholl & Nolin, 1997), studies show
that performance is better for aligned than misaligned trials
(Waller et al., 2002; Christou & Bulthoff, 1999; Richardson,
Montello, & Hegarty, 1999). Most of these studies test
participants in the same room in which learning occurred
(but see Avraamides & Kelly and the work of McNamara
and colleagues -- e.g. Shelton & McNamara, 1997 -- for
exceptions). As with the spatial updating, a question is
raised: Is performance for aligned trials better because
memory is viewpoint-dependent3 or is it because aligned
views are free of any reference frame conflicts?
At this point, we should clarify that the evidence for
sensorimotor conflicts and head-direction disparity effects
does not necessarily dispute the widely-accepted views that
spatial updating occurs effortlessly only with physical
movements and that spatial memories are organized in
preferred directions. With regards to spatial updating, we, in
fact, believe that the sensorimotor interference occurs as
result of a spatial updating failure with imagined movement.
In our view, if participants could truly update the locations
of targets during the imagined movement and as a result
were able to experience full presence at the imagined
position they would face no interference from their physical
body.
In closing, we should note the gender effect that was
found in our latency data (the effect was in the same
direction for accuracy but it was not statistically
significant). This effect is in line with previous findings
showing that males tend to perform better in active spatial
tasks such as following mental paths (Vecchi & Girelli,
1998).

Acknowledgments
We thank Jack Loomis and Thomas Wolbers for providing
valuable comments on an earlier draft of this article. We are
also grateful to Roberta Klatzky and Jonathan Kelly for
useful discussions on this and related topics.

2

if the process of translating the response vector to the physical
reference frame is indeed done with mental rotation, this could
account for the finding that latency varies as a function of objectdirection disparity (i.e., the angular difference between actual and
imagined egocentric positions) that is reported by May (2004)

3
McNamara (2003) discusses evidence that spatial memory is not
viewpoint dependent. Instead he argues that we use intrinsic axes
to organize it and we orient this axes based on cues that might
exist; egocentric experience is one of various possible cues.

179

McNamara, T. P. (2003). How are the locations of objects in
the environment represented in memory? In C. Freksa,
W. Brauer, C. Habel, & K. Wender (Eds.), Spatial
cognition III: Routes and navigation, human memory and
learning, spatial representation and spatial reasoning (pp.

References
Avraamides, M. N. (2003). Spatial updating of
environments described in texts, Cognitive Psychology,
47, 402-431.
Avraamides, M. N., & Carlson, R. A. (2003). Egocentric
organization of spatial activities in imagined navigation.
Memory & Cognition, 31, 252–261.
Avraamides, M. N. & Kelly, J.W. (2005). Imagined
perspective-changing within and across novel
environments. In C. Freksa, B. Nebel, M. Knauff, B.
Krieg-Brückner (Eds.), Spatial Cognition IV, Lecture
Notes in Artificial Intelligence. (pp.246-259).Berlin:
Springer.
Avraamides, M. N., Klatzky, R. L., Loomis, J. M., &
Golledge, R. G. (2004). Use of cognitive vs. perceptual
heading during imagined locomotion depends on the
response mode. Psychological Science, 15, 403-408.
Christou, C. & Bülthoff, H. H. (1999). View dependence in
scene recognition after active learning. Memory &
Cognition, 27, 996-1007.
Cooper, A.N., & Shepard, R.N. (1973). The time required to
prepare for a rotated stimulus. Memory & Cognition, 1,
246-250.
De Vega, M., & Rodrigo, M. J. (2001). Updating spatial
layouts mediated by pointing and labelling under
physical and imaginary rotation. European Journal of
Cognitive Psychology, 13, 369-393.
E-Prime 1.0 [Computer Software]. (2000). Pittsburgh, PA:
Psychology Software Tools.
Farrell, M. J., & Robertson, I. H. (1998). Mental rotation
and the automatic updating of body-center spatial
relationships. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 24, 227–233.
Farrell, J. J., & Thomson, J. A. (1999). On-line updating of
spatial information during locomotion without vision.
Journal of Motor Behavior, 31, 37–53.
Klatzky, R., L, Loomis, J., M, Beall, A., C, Chance, S., S, &
Golledge, R., G. (1998). Spatial updating of self-position
and orientation during real, imagined, and virtual
locomotion. Psychological Science, 9, 293-298.
Loomis, J. M., Klatzky, R. L., Golledge, R. G., & Philbeck,
J. W. (1999). Human navigation by path integration. In
R. G. Golledge (Ed.), Wayfinding: Cognitive mapping
and other spatial processes (pp. 125-151). Baltimore,
MD: Johns Hopkins University Press.
Loomis, J. M., Lippa, Y., Klatzky, R. L., & Golledge, R. G.
(2002). Spatial updating of locations specified by 3-D
sound and spatial language. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 28, 335–
345.
May, M. (1996). Cognitive and embodied modes of spatial
imagery. Psychologische Beiträge, 38, 418-434.
May, M. (2004). Imaginal perspective switches in
remembered environments: Transformation versus
interference accounts. Cognitive Psychology, 48, 163206.

174-191). Berlin: Springer-Verlag.

Parsons, L. M. (1987). Imagined spatial transformations of
one’s body. Journal of Experimental Psychology:
General, 116, 172–191.
Presson, C. C., & Hazelrigg, M. D. (1984). Building spatial
representations through primary and secondary learning.
Journal of Experimental Psychology: Learning, Memory,
and Cognition, 10, 716-722.
Presson, C. C, & Montello, D. R. (1994). Updating after
rotational and translational body movements: Coordinate
structure of perspective space. Perception, 23, 14471455.
Richardson, A. E., Montello, D. and Hegarty, M. (1999).
Spatial knowledge acquisition from maps, and from
navigation in real and virtual environments. Memory &
Cognition, 27, 741-750.
Riecke, B. E., van Veen, H. A. H. C., & Bülthoff, H. H.
(2002). Visual homing is possible without landmarks–A
path integration study in virtual reality. Presence:
Teleoperators and Virtual Environments, 11, 443–473.
Rieser, J. J. (1989). Access to knowledge of spatial structure
at novel points of observation. Journal of Experimental
Psychology: Learning, Memory, & Cognition, 15, 11571165.
Rieser, J. J, Guth, D. A, & Hill, E. W. (1986). Sensitivity to
perspective structure while walking without vision.
Perception, 15, 173-188.
Schober, M. F. (1993). Spatial perspective taking in
conversation. Cognition, 47, 1-24.
Shelton, A. L., & McNamara, T. P. (1997). Multiple views
of spatial memory. Psychonomic Bulletin & Review, 4,
102-106.
Sholl, M. J., & Nolin, T. L. (1997). Orientation specificity
in representations of place. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 23,
1494-1507.
Vecchi, T., & Girelli, L. (1998). Gender differences in
visuo-spatial
processing:
The
importance
of
distinguishing between passive storage and active
manipulation. Acta Psychologica, 99, 1-16.
Waller, D., Montello, D. R., Richardson, A. E., & Hegarty,
M. (2002). Orientation specificity and spatial updating of
memories for layouts. Journal of Experimental
Psychology: Learning, Memory, & Cognition, 28, 10511063.
Wraga, M. (2003). Thinking outside the body: An
advantage for spatial updating during imagined versus
physical self-rotation. Journal of Experimental
Psychology: Learning, Memory, & Cognition, 29, 9931005.

180

