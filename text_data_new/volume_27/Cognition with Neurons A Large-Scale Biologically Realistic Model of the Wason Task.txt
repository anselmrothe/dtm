ence to be performed in a specific context has merely been
learned in a similar context (regardless of its status as deontic
or not). As well, it is assumed that the necessary inference
need not be spelled out as a complex, multi-step schema, but
is rather a direct mapping between the presented rule and appropriate responses in that context.
Notably, Cosmides (1989) challenges any theory based
on induction, like that underlying BioSLIE, to lay out the
mechanistically defined domain-general procedures that can
take modern human experience as statistically encountered
as input, and produce the observed domain specific performance in the selection task as output. This is a challenge that
BioSLIE meets.

Context (x)
(VMPFC)

T
Assoc
Memory

A

Motor areas

Determine
Response

Correct Answer (A*)
Response
Goodness

Rule (R)
(Wernicke)

Valence (V)

Right Inferior Frontal

Figure 1: Functional decomposition and anatomical mapping
of the model. The letters in bold indicate the vector signals in
the model associated with the area.

Model description
BioSLIE integrates advances in structured vector representations, relevant physiological and anatomical data from frontal
cortices (Wharton & Grafman, 1998), and the NEF, to explain
human performance on the Wason task.
Since the early 1990s, there have been a series of suggestions as to how to incorporate structure-sensitive processing in models employing distributed representations (including Spatter Codes (Kanerva 1994); Holographic Reduced
Representations (HRRs; Plate 1991); and Tensor Products
(Smolensky 1990)). Few of these approaches have been used
to build models of cognitive phenomena (although see Eliasmith & Thagard 2001). However, none of these methods
have been employed in a biologically plausible computational
setting. As described in the next section, I extend the NEF to
incorporate HRRs, in order to integrate the structure sensitivity of the latter with the biologically plausibility of the former.
Of course, to use this characterization of structure-sensitive
processing in an explanatorily useful model, it is essential to
suggest which anatomical structures may be performing the
relevant functions. Only then is it possible to bring to bear
the additional constraints of (and make predictions relating
to) single cell physiology and functional imaging data. Figure 1 shows how BioSLIE is mapped to functional anatomy.
Specifically, the network consists of: a) input from ventromedial prefrontal cortex (VMPFC) which provides familiarity,
or context, information that is used to select the appropriate
transformation (Adolphs et al. 1995); b) left language areas which provide representations of the rule to be examined
(Parsons, Osherson, & Martinez 1999); and c) anterior cingulate cortex (ACC) which gives an error signal consisting of
either the correct answer, or an indication that the response
was correct or not (Holroyd & Coles 2002). The neural populations that make up BioSLIE itself model right inferior
frontal cortex, where VMPFC and linguistic information is
combined to select and apply the appropriate transformation
to solve the Wason task (Parsons & Osherson 2001). It is during the application of the transformation that learning is also
presumed to occur.

operations are defined as:
C =
cj =

A⊗B
Pn−1
k=0 ak bj−k

and

B
bj

≈
=

A⊕C
Pn−1
k=0 ak cj+k

where subscripts are modulo n. Conveniently, correlation can
be defined in terms of convolution: A ⊕ C = A0 ⊗ C, where
0
indicates an approximate inverse.
To implement convolution in a spiking network using the
NEF, we must first define the encoding and decoding for a
vector x in a population a of neurons ai . The encoding describes the biophysical processes that result in a series of
rapid neural voltage changes (i.e., neural spikes). The decoding determines how much information those spikes carry
about the original signal x, by determining an estimate of that
signal, x̂:
Encoding
h D
E
i
PN
ai (t) = n=1 δ(t − tin ) = Gi αi x · φ̃i m + Jibias
Decoding
PNt ,N
x̂ = i=1,n=1
hi (t − tn )φxi
where δi (·) are the Nt spikes at times tn for neuron ai , generated by the spiking nonlinearity Gi in the population with
N neurons. The neuron parameters αi , φ̃i , and Jibias are the
gain, preferred direction vector in stimulus space, and bias
current respectively, which are chosen to reflect the heterogeneity of neuron responses observed in cortex (Eliasmith
and Anderson, 2003). For the decoding, hi (t) are the linear
decoding filters, which for reasons of biological plausibility,
are taken to be the post-synaptic currents (PSCs) generated in
the subsequent neuron’s dendrites, and the decoding vectors,
φxi , determine the importance of that neuron’s response to the
estimate of x. Notably, the neural nonlinearity Gi can be as
complex (i.e. biologically realistic) as desired. In BioSLIE
we use a standard leaky integrate-and-fire (LIF) model.
Assuming this kind of vector representation in four populations, a, b, c, and d, it is possible to implement circular
convolution. Using the convolution theorem, we know that
any convolution in a domain x is equivalent to multiplication
in its Fourier domain. Thus, the two vectors to be convolved
are projected through the Fourier matrix into a middle layer
(using the encoding defined earlier):

Model derivation
HHRs in spiking networks
Following Plate (1991) BioSLIE encodes structure in a distributed vector representation using circular convolution (⊗),
which implements a kind of vector binding. In order to decode the structure, circular correlation (⊕) is used. These

625

a)

b)

x

A

0.5

x

0

T
y

-0.5
0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

0

0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

A

B

0.5

z

0

-0.5

B

A⊗B

0.5

0

-0.5

Figure 3: The network structure for associative learning.
Here, the transformation T in a context x is learned by changing the weights between neurons in populations x and y based
on information in population z.

time (s)

Figure 2: The convolution over time of two sets of vectors.
The input vectors change after 0.5 seconds. a) The solid lines
indicate the decoded estimates of the signal value from the
neural spikes. The dashed lines indicate the ideal values. b)
The neural spikes generated during the same run.

its constituents. Essentially, the HRR constituents are blurred
upon being used to encode this structure. This is not the case
for a classical representation.
A transformation vector that provides the typical human
response to this rule is T1 = ante0 +impl0 ⊗rel0 +cons0 ,
which results in T1 ⊗ R ≈ vowel + even. However, we
cannot build this kind of transformation into the model if we
want it to learn to behave differently given varying context
signals from VMPFC.
To model learning of different transformations in different
contexts, we need to derive a biologically plausible learning
rule that can infer these transformations. Neumann (2001)
noted that to find some unknown transformation T between
two vectors A and B, we can solve

ck ([AF F T , BF F T ])
h
i
= Gk αk φ̃k ([AF F T , BF F T ]) + Jkbias


X
X
= Gk 
ωik ai +
ωjk bj + Jkbias 
i

j

where ωik = αk φk1˜...kN WF F T φA
i . This equation determines the connection weights from a and b to c that result
in spikes in the middle layer (c) that encode the Fourier transform of vectors A and B. Once in this space, the the elementwise product can be extracted and the inverse Fourier matrix
applied, giving
dl (A ⊗ B)
" Ã
= Gl αl
"
= Gl

φ̃l WIF F T

X

T = circ

+

!−1 Ã
Bi ⊕ Bi

m
X

!
Bi ⊕ Ai

i

where circ(·) is the circulant matrix and m is the number of
examples.
Pm Noting Bi ⊕ Bi ≈ 1 this can be simplified to T =
1
i Bi ⊕Ai . The resulting rule can be implemented using
m
a standard delta rule Ti+1 = wi (Ti − Bi ⊕ Ai ), where wi
is an adaptive learning rate inversely proportional to i.
Of course, this rule is not useful for BioSLIE as it stands
because it does not determine how connection weights of the
individual neurons representing these vectors are to be updated. So, I have derived (derivation not shown) the following neuron-level rule in terms of the network shown in figure
3:

Jkbias

k

X

m
X
i

#

!
ck φA.B
k

Ã

#

ωlk ck + Jlbias

k

where ωlk = αl φ̃l WIF F T φA.B
. Thus, this four layer netk
work will result in the circular convolution of Aand B being
represented in the output layer d. Generally speaking, this
derivation demonstrates how spiking networks can compute
complex, nonlinear functions like convolution. The result of
convolving two 6-dimensional vectors is shown in figure 2.

δE
∆ωjl = κ
δωjl


X
X
ωjk zk −
ωj 0 j yj  (yj > 0)xl
= κ

Learning HRR transformations

k

In order to explain the results of the Wason task, it is essential to transform HRRs encoding the rule being examined into the appropriate response given a context. For example, to encode the rule “If there’s a vowel then there’s an
even number,” we can construct the following HRR vector:
R = ante ⊗ vowel + rel ⊗ impl + cons ⊗ even. This is
similar to the structure Implies(vowel, even), in a classical
cognitive system. However, the HRR representation is simply a vector R which is of the same dimensionality as each of

j0

where κ is the learning rate, neurons yj carry the current prediction for the transformation T, zk neurons carry the correlation of the encoded A and B vectors, and xl carries the
context signal. This is a form of Hebbian learning, a class of
learning rules known to be biologically plausible.
As demonstrated in figure 4, this rule leads to successful
learning, and allows for the switching of learned transformations based on the context signal.

626

1.5

x
Context Signal

Learning

Recall

A=T⊗R

T
a

b

f

1

A*
R’⊗A*
c

0.5

m

h

i

0

R
e

-0.5

Transformation
Signal
-1

A·A*
<V,A·A*>

1
2
3
4
5
6

l

V
j

Figure 5: The complete network at the population level. The
lower case letters indicate populations of approximately 2000
neurons each. Upper case letters indicate the signals being
sent along the relevant projections. The dotted boxes indicate
how this diagram relates to figure 3, and hence the anatomical
mapping discussed earlier.

-1.5

Figure 4: Learning and retrieval of a 6-dimensional vector in
a spiking network. During the first two-thirds of the simulation, the context signal is changed while the input from z is
changed to associate the context with the vector represented
by z. In the last third, learning is turned off, and successful
retrieval of the vectors is displayed given a context signal.

the network’s answer is a and not-b. BioSLIE has learned to
perform different inferences in different contexts, resulting in
similar performance to human subjects on the Wason task.

Results on the Wason task
Performance in different contexts

Generalization within a context

BioSLIE combines these subnetworks as shown in figure 5,
resulting in a model that consists of ten interconnected neural
populations, for a total of approximately twenty thousand
neurons. The representations in this network have been scaled
up to 100 dimensions, in order to encoded the vectors needed
to perform the task.
The model is able to reproduce the typical results from the
Wason task under both the abstract and permissive contexts,
as shown in figure 6. In order to classify the results produced by the model, the resulting vectors must be ‘cleanedup’. That is, they are compared to all possible labeled answers by taking a similarity measure (dot product) between
the resulting vector and items in the ‘clean-up’ memory (i.e.,
all labeled vectors used in any simulation presented; 19 vectors). The labels on the graph indicate the similarity measures (maximum of 1). The top three responses are displayed
to demonstrate the large difference in similarity between the
provided answers and the next most similar vector. Simple
thresholding can thus be used to determine what counts as an
answer and what does not.
When the run in figure 6 begins, learning is initiated, the
context is set to ‘abstract’ (i.e. 1), and the correct result in that
context is present to the network. The network then learns to
infer (in this context) the expected (incorrect) result (i.e., a
and b). Both the context and expected result is then changed
for the second phase, and the network learns a different transformation in the new ‘permissive’ context (i.e., -1; resulting
in a and not-b). Learning is then turned off, and the expected
result is no longer presented to the network. Only the context
signal is changed. As expected, in the abstract context the
network’s answer is a and b, and in the permissive context

To demonstrate that the network is truly learning a languagelike transformation in a context, figure 7 shows that it generalizes learned, structure-sensitive transformations to new representations. This demonstrates that the system has learned a
systematic regularity. That is, it can transform the structured
representation based solely on the syntax of that representation.
This simulation is similar to that presented previously, except the context signal is kept constant and there are three separate rules that are presented to BioSLIE. During the learning ’on’ phase, the rules Implies(a,b) and Implies(c,d) along
with their expected answers are presented to the network.
The learning is then turned off, and it is presented with Implies(e,f). As expected, since the context is the same as the
previous examples, the same transformation is applied, and
BioSLIE infers that e and f are the expected answer. In the
last quarter of the simulation, no rule is presented and thus
no answer is produced (i.e., all similarity measures are very
low). The similarity measures of the top three most similar
vectors in the clean-up memory are displayed to demonstrate
that the top two responses are the appropriate answers in this
context.

Conclusion
I have successfully built and simulated BioSLIE, a low-level,
spiking neuron model of a high-level cognitive behavior, the
Wason task. Compared to past models of the Wason task,
this model has a number of advantages. In contrast to Cosmides’ explanation, I have presented a detailed computational
model that demonstrates that a domain general mechanism
can indeed account for the observed phenomena. As well, this

627

0.2
0.15

d,
c,
b,

0.40
0.33
0.16

cons, 0.018
~a, 0.014
~b, 0.013

Smoothed Spike Activity

0.1

a)
0.3
2

1

1

2

b, 0.62
a, 0.55
not, 0.050

0.2

0.1

-0.05

-0.15

b, 0.56
a, 0.28
impl, 0.16

f, 0.42
e, 0.17
~a, 0.14

Learning on

-0.1

-0.2
0
b, 0.56
a, 0.48
not, 0.055

not-b, 0.36
a, 0.29
f, 0.089
not-b, 0.37
a, 0.36
f, 0.08

-0.3

20

40

60
Time

80

100

20

Learning off
40

60
Time

80

100

120

Figure 7: Generalization across different rules in the same
context. See text for discussion.

Learning off

Learning on
-0.4
0

0

-0.1

0

-0.2

0.05

120

b)

Neuron Number

model offers an advantage over pragmatic reasoning schemas,
in that the transformations used to solve the problem are not
limited to a pre-specified, discrete group of “schemas” which
are identical for all subjects. Instead, each individual can
solve the problem using her own estimation of the correct
transformation in the given context, as determined by her
idiosyncratic learning history in that context. BioSLIE is thus
not restricted to the binary “deontic” and “non-deontic” distinctions made by Cheng and Holyoak.
More generally, because BioSLIE spans what are often
considered disparate levels of description of cognitive phenomena, it is also able to support predictions at those various
levels. I believe it is the first model to do so.
At the single neuron level, BioSLIE helps clarify the kinds
of properties neurons involved in these computations need
to have. For instance, in order to implement the highdimensional nonlinear vector transformation necessary to
capture structure-sensitive behavior, neurons in the simulation need to respond to at least two dimensions at the same
time (one from each vector being convolved). However, despite the size of the vectors being convolved, no more than
two dimensions need to be represented either (suggesting that
the model will scale very well). As well, the learning rule derived to implement the network has implications for neuron
connectivity. Specifically, it suggests that information carried by projections from one of the associative populations
serves to direct the modification of synaptic weights between
the memory population, and the other associative population.
Thus the biophysical mechanisms (e.g. NO transport) that
can support this kind of learning should be prevalent in these
areas. Finally, examining the spike trains produced by the
model show that despite the model being deterministic, the
nonlinearities in the model serve to generate very randomlooking spike trains, like those observed in cortex. This suggests that perhaps nonlinearities, not noise, are largely responsible for spike train variability in frontal areas.
At the behavioral level, the model not only meets Cosmides’ challenge of specifying an inductive, domain general

Figure 6: Results of the Wason task for the complete network. a) This is the decoded neural output representing the
100-dimensional vector. Results have been smoothed for legibility. The similarity measures for labeled vectors are written
above the decoded neural output. These similarity measures
indicate which answers are returned (and hence which inferences are performed) in those contexts. The numbers in boxes
indicate the context (1 for abstract, 2 for permissive). This
diagram shows that in the first two contexts, two different
transformations are learned. Then, these transformations are
appropriately applied when those contexts are later encountered. b) The neural spikes produced by every 100th neuron
in the population representing these results.

628

[7] Holroyd, C., and Coles, M. 2002. “The neural basis
of human error processing: Reinforcement learning,
dopamine, and the error-related negativity.” Psychological Review 109:679–709.

inference mechanism, it also makes it possible to predict behavioral variations on the task given a learning history. For
instance, it should be possible to predict the effects of varying
the kind of feedback that a subject receives in similar and dissimilar contexts. As well, I have not discussed the differing
effects of explicit (i.e., the answer) versus implicit (i.e. ‘right’
or ‘wrong’) feedback on learning transformations. However,
the model includes a valence signal that can be used to examine these differences. Finally, the ability of the model to
generalize helps explain why those trained in logic do better on the content-independent tasks (Rinella, Bringsjord, &
Yang 2001).
More theoretically, the model is at the very least an existence proof that understanding neural computation might
have important implications for understanding cognitive behavior, contra Fodor, Pylyshyn, and Jackendoff. This is because HRRs, unlike classical symbols, are noisy representations. Thus, there are serious limitations on memory size,
depth of structure, etc., that can be encoded by BioSLIE, just
as there are for people. Understanding how well such noisy
representations can be processed by a realistic neural system
helps pave the way to better understanding these limitations.
These same properties show how this model is also not a
‘mere’ implementation of a classical system. Classical systems are perfectly compositional and systematic. However,
BioSLIE clearly is not, since encoding essentially blurs the
represented constituents. Nevertheless, BioSLIE has enough
compositionality and systematicity to model human cognitive performance. Thus, neurocomputational models, like
BioSLIE, can help us understand the degrees of systematicity
and compositionality possessed by real cognitive systems in
ways that classical models cannot.

[8] Jackendoff, R. 2002. Foundations of Language: Brain,
Meaning, Grammar, Evolution. Oxford University
Press.
[9] Kanerva, P. 1994. “The spatter code for encoding concepts at many levels.” Proceedings of International
Conference on Artificial Neural Networks 46:226–229.
[10] Neumann, J. 2001. Holistic Processing of Hierarchical
Structures in Connectionist Networks. PhD dissertation,
University of Edinburgh, Department of Computer Science.
[11] Oaksford and Chater, 1994, "A rational analysis of the
selection task as optimal data selection," Psychological
Review, 101(4), 608–631.
[12] Oaksford and Chater, 1996. "Rational explanation of the
selection task" Psychological Review 103(2):381–391
[13] Parsons, L., and D. Osherson. 2001. “New evidence for
distinct right and left brain systems for deductive versus
probabilistic reasoning.” Cerebral Cortex 11:954–965.
[14] Parsons, L., D. Osherson and M. Martinez. 1999. “Distinct neural mechanisms for propositional logic and
probabilistic reasoning.” Proceedings of the Psychonomic Society Meeting 61–62.
[15] Plate, A. 1991. “Holographic reduced representations:
Convolution algebra for compositional distributed representations.” In Mylopoulos, J., and Reiter, R., eds.,
Proceedings of the 12th International Joint Conference on Artificial Intelligence. San Mateo, CA: Morgan
Kaufmann.

References
[1] Adolphs, R., A. Bechara, D. Tranel, H. Damasio, and
A. Damasio, 1995. “Neuropsychological approaches
to reasoning and decision-making.” In A. Damasio,
H. Damasio and Y. Christen., eds., Neurobiology of
Decision-Making. New York: Springer Verlag.

[16] Rinella, K., S. Bringsjord, Y. and Yang. 2001. “Efficacious logic instruction: People are not irremediably
poor deductive reasoners.” In Moore, J., and Stenning,
K., eds., Proceedings of the 23rd Annual Conference of
the Cognitive Science Society, Mahwah, NJ: Lawrence
Erlbaum Associates. 851–856.

[2] Cheng, P. W., and Holyoak, K. J. 1985. “Pragmatic reasoning schemas.” Cognitive Psychology 17:391–416.
[3] Cosmides, 1989. "The logic of social exchange: Has
natural selection shaped how humans reason? Studies
with the Wason selection task." Cognition, 31:187–276,

[17] Smolensky, P. 1990. “Tensor product variable binding
and the representation of symbolic structures in connectionist systems.” Artificial Intelligence 46:159–217.

[4] Eliasmith, C., and Anderson, C. H. 2003. Neural engineering: Computation, representation, and dynamics in
neurobiological systems. Cambridge, MA: MIT Press.

[18] Sperber, Cara, and Girotto, 1995. "Relevence theory explains the selection task." Cognition 57: 31–95.

[5] Eliasmith, C., and Thagard, P. 2001. “Integrating structure and meaning: A distributed model of analogical
mapping.” Cognitive Science 25:245–286.

[19] Wason, P. C. 1966. “Reasoning.” In Foss, B. M., ed.,
New horizons in psychology. Harmondsworth: Penguin.

[6] Fodor, J., and Pylyshyn, Z. 1988. “Connectionism and
cognitive science: A critical analysis.” Behavioral and
Brain Sciences 28:3–71.

[20] Wharton, C., and Grafman, J. 1998. “Deductive reasoning and the brain.” Trends in Cognitive Sciences 2:54–
59.

629

