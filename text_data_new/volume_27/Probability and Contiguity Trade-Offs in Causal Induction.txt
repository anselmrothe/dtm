UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Probability and Contiguity Trade-Offs in Causal Induction

Permalink
https://escholarship.org/uc/item/48j4h72c

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Buechner, Marc J.
McGregor, Stuart

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Probability and Contiguity Trade-Offs in Causal Induction
Marc J Buehner (BuehnerM@Cardiff.ac.uk) & Stuart McGregor (Stuart.McGregor1@ntlworld.com)
School of Psychology, Cardiff University, Tower Building, Park Place
Cardiff, CF10 3AT, Wales, UK.
1980; Jenkins & Ward, 1965) to more sophisticated
judgment rules (e.g. Anderson & Sheu, 1995; Mandel &
Lehman, 1998; White, 2003). An alternative suggestion
(Shanks & Dickinson, 1987) is that causal learning may be
no different from associative learning as exemplified by
Rescorla & Wagner’s (1972) model of Pavlovian
conditioning. More recently, however, Cheng (1997)
showed that all the above approaches fall short of
representing causality as an unbound variable (Holyoak &
Hummel, 2000), and suggested a computational causal
power approach. A related approach (Buehner & Cheng,
2005) has been to model causal induction as Bayesian
inference (e.g. Steyvers et al., 2003; Tenenbaum &
Griffiths, 2001).
In the midst of the vigorous debate over the computational
details of covariation assessment, the second Humean cue –
contiguity - got largely overlooked (but see Young, 1997).
The majority of recent experimental studies have
investigated how variations in contingency influence causal
assessment; contiguity was never manipulated in these
studies, and was usually kept at an immediate level.
Earlier work on causal reasoning, however, often focused on
contiguity. Michotte (1946/1963) observed that even very
short delays render an illusion of causal launching noncausal. In a completely different domain, Shanks, Pearson &
Dickinson (1989) reported that people fail to distinguish
causal from non-causal actions in an instrumental learning
task when the action-outcome delay exceeded two seconds.
The importance of Hume’s second principle was
acknowledged in early, non-computational psychological
theories of causal induction (Einhorn & Hogarth, 1986;
Young, 1995).

Abstract
Two experiments investigated the roles of contingency and
temporal contiguity in causal reasoning, and the trade-off
between them. Participants observed an ongoing, continuous
stream of events, which was not segmented into discrete
learning trials. Four potential candidate causes competed for
explanatory strength with respect to a single dichotomous
effect. The effect was contingent on two of these causes, with
one of these (A) having a higher probability of producing the
effect compared to the other (B), while B was more
contiguous to the effect than A. When asked to identify the
strongest cause of the effect, participants consistently and
reliably selected A, as long as it was not separated from the
effect by more than 2.5s. The extent of preference diminished,
however, as the contiguity gradient between A and B
increased. Beyond 2.5s, the high-probability, but lowcontiguity cause A was seen as equally strong as the lowprobability, but high-contiguity cause B, and both reliably
stood out compared to the remaining two non-contingent
distracter items. This apparent trade-off between contingency
and contiguity, rooted in contrasting two of David Hume’s
(1739/1888) fundamental cues to causality, has important
implications for psychological and statistical models of causal
discovery, learning theory, and artificial intelligence.
KEYWORDS: Causality, Probability, Contiguity, Learning,
Human Experimentation, Causal Inference.

Introduction
How do humans and other intelligent systems learn that one
thing causes another? The contemporary cognitive science
approach to this problem of induction can be traced back to
David Hume (1739/1888), who famously argued that our
sensory system is not equipped to directly perceive
causality. Instead, he argued, reasoners have to interpret
sensory experiences to create a mental representation of
causality. Hume identified three principles underlying the
formation of causal impressions: i) temporal priority of the
cause c before the effect e, ii) temporal and spatial
contiguity between c and e, and iii) constant conjunction
between c and e. Only the latter two principles are of
relevance to cognitive scientists, as the need for temporal
priority of c over e is usually not debated (Reichenbach,
1956; but see also Savastano & Miller, 1998; and Tanimoto
et al., 2004 for discussion of bi-directional associations).
Computational approaches of causal induction have almost
exclusively focused on the third Humean principle, which is
commonly referred to as cause-effect contingency. Just how
exactly contingency gives rise to causal impressions is still
subject of a hot debate in the field. Suggestions range from
using contingency (∆P) - calculated by the difference
between the two conditional probabilities: P(e|c)-P(e|¬c) –
as a direct measure of causal strength (Allan & Jenkins,

Two Cues Towards Causality: Contingency vs.
Contiguity
Developmental psychologists attempted to determine which
of the two cues, contiguity or contingency, is more
important (Siegler & Liebert, 1974; Mendelson & Shultz,
1976; Shultz, 1982). These efforts were somewhat
inconclusive, as they were closely entangled with another
important principle of causal induction: understanding or
knowledge of mechanism (Bullock et al., 1982; Ahn et al.,
1995). Mendelson & Shultz, for instance, reported that
whether a non-contiguous but contingent cause was
preferred over a contiguous but non-contingent cause
depended on variations in the physical make-up of the
apparatus (i.e. mechanism), and whether such variations
were commensurate with the experienced delay.
The role of causal mechanisms. Considerations of
mechanism (and concomitant expectations of timeframes)
have been suggested to interact with contiguity (Einhorn &
360

Hogarth, 1986): if reasoners assume that the mechanism
linking cause and effect operates instantly, they should only
consider immediate cause-effect pairings as evidence
supporting a causal link; if the mechanism is thought to
involve a delay, only delayed pairings ought to give rise to
causal attributions. Buehner and May (2002, 2003, 2004)
found partial empirical support for this knowledge
mediation hypothesis: Delays were no longer detrimental in
a causal judgment task modeled after Shanks et al. (1989), if
participants expected a delayed relation. However,
immediate cause-effect pairings were consistently rated as
highly causal, irrespective of time-frame expectations.
These results suggest that knowledge of mechanism bridges
temporal gaps; at the same time, however, experienced
contiguity seems to override considerations of mechanism.
Schlottmann (1999), for instance found that young children
and adults readily learnt about two causal mechanisms with
different timeframes. They could a) successfully predict the
correct cause-effect timing for slow and fast mechanisms,
and b) correctly infer (based on the experienced timeframe
of the observed causal relation) which of the mechanisms
(fast vs. slow) was hidden in a “mystery box”. However,
when contiguity and mechanism were directly pitted against
each other in a forced choice task involving a contiguous
and a delayed cause, young children consistently preferred
the contiguous cause, even when this choice openly
conflicted with well-established knowledge of a delayed
mechanism. Experienced contiguity as a cue to causality
thus seems to operate on a more fundamental level than
higher-level considerations of mechanism.
Note that these studies did not vary the contingencies
associated with each cause. While they illuminated the role
of contiguity in causal induction, and how it interacts with
knowledge of mechanism, they did not address the
questions raised by developmental psychologists in the
1970s: Whether the two empirical cues to causality -contingency and contiguity -- are equally important for
causal induction.
A Computational Perspective. From a computational,
perspective, one would expect that contingency is more
fundamental than contiguity. After all, the ability to control
and predict our environment – the goal of causal induction
(Cheng, 1997) – is based on making use of regularity
information. On the other hand, it is also evident that
contiguity is vital for causal assessment. Time-lagged
regularities are harder to detect, because event information
needs to be kept in memory for longer; as the cause-effect
interval increases, the number of potentially intervening
(alternative) causes that need to be taken into account
increases. In short, identification of causal relation becomes
increasingly difficult as contiguity decreases.
Nonetheless, there is no causality without regularity (Cheng,
1993), and given sufficient computational resources,
contingency should be the essential cue. In realistic, realtime situations, however, where computational resources are
limited, one may well observe a tradeoff between the two
cues.

Experiment 1
We developed a new experimental methodology aimed at
studying the trade-off between contingency and contiguity
in causal induction. We adopted Mendelson & Shultz’s
(1976) idea to pitch two causes, each with a high value on
one, but a low value on the other dimension against each
other. More specifically, one cause (A) had a higher
contingency with respect to the effect than the other (B), but
at the same time A was less contiguous with the effect than
B. Unlike in Mendelson & Shultz’ study, however, A and B
were fully independent of each other and there was no
interactive causal influence (Novick & Cheng, 2004)
beyond the individual causal strengths. Furthermore, it was
important to couch the task in a novel context so that
participants would not have any pre-conceived notions of
mechanism or expectations of time-frames. This allowed us
to rule out any top-down influences and study contingencycontiguity trade-offs in a purely bottom-up manner.
To this end, we created a “Stargate” scenario: Participants
were told they would observe a group of UFOs orbiting
around a stargate; each UFO would attempt to open the
gate. Because each UFO would use a unique signaling
technique, some would be more successful than others at
opening the gate, and some could open the gate faster (if
successful) than others. Participants’ task was to determine
which UFO was most successful at opening the gate.
In designing the task, it was essential to avoid a discretely
marked trial structure. Trial structures either confound
contingency with contiguity (see Buehner & May, 2003) or
remove the event-parsing aspect of causal learning (Allan et
al., 2003), resulting in an artificial judgment task that bears
little resemblance with causal discovery. We used
Macromedia Director to present participants with
continuous event streams that were not divided into
individual learning trials. Although the event stream was
controlled by an underlying trial structure, the appearance to
the participant was one of a continuous sequence of events.
We strongly encourage readers to watch sample stimuli
provided at
http://www.cardiff.ac.uk/psych/home/buehnerm/Stimuli

Method
Participants. Ninety-nine undergraduate students from
Cardiff University participated to fulfill part of a course
requirement.
Apparatus and Procedure. Event sequences were
programmed using Macromedia Director, and displayed on
a computer screen. The displays represented a ‘stargate’ in
the middle of the screen, which was either open or closed,
and four static UFOs, arranged near each corner of the gate.
Each UFO had a unique color scheme for its two windows.
A ‘signalling’ UFO was displayed with an overlay of
colored stripes, with the color pattern matching the color
scheme of the windows. By default, the stargate was closed,
and UFOs were inactive. Activity (open gate, active UFO)

361

the gate with a higher probability than B. The extent of the
probability gradient between A and B was manipulated
between participants in five conditions: a) 75% vs. 25%; b)
75% vs. 50%; c) 100% vs. 25%; d) 100% vs. 50%; and e)
100% vs. 75%. Participants were randomly allocated to one
of these pairs of probabilities.
The cause-effect contiguity of the low-probability cause (B)
was always set to 500ms. The contiguity of the highprobability cause (A) varied within participants across four
conditions, and took values of 500ms, 1000ms, 1500ms, and
2000ms.

was scheduled by the program and lasted 500ms. Figure 1
displays sample stimulus materials.

Results
For sake of brevity, analyses are only reported for data
collapsed across the five probability gradients.1 All
statistical analyses are based on an alpha-level of .05 with
Bonferroni-corrections for multiple tests, where applicable.
.9

Figure 1. Stimulus Materials. The top right UFO is
“active” in this screenshot, and the gate is closed.

.8
.7

Each participant worked on four conditions presented in
random order, each consisting of a sequence of trials,
presented in random order. The appearance to the
participant was one of a continuous stream of events; trial
delineation was not made explicit to the participant, and
trials were not marked.
In each condition, activity of two UFOs (A&B) was
probabilistically linked to the opening of the gate, with A
always having a higher probability of opening the gate than
B as specified in the Design section. The other two UFOs
(C&D) were programmed to activate on 25% of the trials, at
a random time throughout each trial; activity in these UFOs
was unrelated to the gate opening. The base-rate of the gate
opening was zero, i.e. it only opened conditional on activity
in A or B. The locations and color schemes of each of the
four UFOs were randomized for each condition.
The event-structure was organized as follows: If A or B
were scheduled to be active on a given trial, they would
emit a signal at a random point during the first 5 seconds of
that trial. If the signaling was successful, the gate opened
for 500ms after the relevant delay. Activity in A and B was
independent of each other, so that on some trials both A and
B would signal; on such trials, A and B would both produce
the effect according to their respective probability and
delay. In other words, A and B were truly independent of
each other and did not interact to produce the effect (Novick
& Cheng, 2004).
Participants observed the event streams for each condition,
and then had to indicate which UFO was most successful in
opening the gate. To this end, they were told to imagine
they could “zap” one of the UFOs to emit a signal, and were
asked to decide which UFO they would zap in order to open
the gate. The experiment lasted about 30 minutes.
Design. The two variables of interest, Contingency and
Contiguity, were controlled as follows. A always opened

.6
.5
.4
.3
.2

A
B
C& D

.1
0

500

1000

1500

2000

Contiguity of A in ms

Figure 2. Experiment 1: Percentage of Participants
(N=99) choosing Causes A or B or one of the two unrelated
events (C&D).
Inspection of Figure 2 suggests that participants consistently
selected the high-probability cause A, even when its
contiguity with respect to the effect was degraded.
However, the degree of preference of A over B seems to
diminish as the contiguity of A decreased. Choices for the
unrelated distracter causes (C&D) were below 10% in all
conditions, and thus well below the chance level of 50%,
(all ps <.001 on a Binomial test).
We constructed three separate and mutually exclusive
dichotomous choice variables for causes A and B, and the
two unrelated events (C&D). The proportion of choices for
A was significantly higher than that for B across all four
levels of contiguity (all ps<.001 by sign test). Cochran’s Q
tests with corrected alpha-level (p=.017) were conducted to
assess the influence of contiguity on choice patterns.
1
Preliminary analyses revealed no effects or interactions
associated with probability gradient, suggesting that participants
distinguished equally well between high (A) and low (B)
contingencies in all five conditions.

362

Choices for A significantly decreased as A’s contiguity with
respect to the effect decreased, Q(3,99)=13.541, while
choices for B significantly increased, Q(3,99)=14.415.
Choices for the two unrelated causes were not affected by
variations in A’s contiguity, Q(3,99) = 2.561.

Method
Participants. Sixty-five undergraduate students from
Cardiff University participated to fulfill part of a course
requirement.
Apparatus, Procedure, and Design. The same design and
procedure as in Experiment 1 was employed, except that the
contiguity of A could take on values of 2500ms, 3250ms,
and 4000ms (varied within-subjects), while the contiguity of
B remained at 500ms. The same five probability gradients
as in Experiment 1 were varied between subjects.

Discussion
Participants were clearly able to extract contingency
information from a continuous stream of events that
contained no observable trial boundaries. They reliably and
consistently identified the cause that was followed by the
effect with the highest probability among a choice of four.
Moreover, this preference for a high-probability cause was
maintained in the face of degraded contiguity: although B
was highly contiguous with the effect (500ms), A was
consistently preferred as the stronger and more effective
cause due to its higher probability, even when A was
separated from the effect by as much as 2s. The extent of
this overall preference decreased, however, as the contiguity
contrast between A and B increased. Experiment 1 thus
suggests that people put more importance on contingency
than on contiguity as reliable cues towards causality; at the
same time, there seems to be some trade-off between the
two, with participants shifting more weight on contiguity, as
the contiguity contrast increases.

Results
Results and Discussion
Inspection of Figure 3 suggests that A is no longer preferred
over B when A’s delay exceeds 2.5s. As in Experiment 1,
choices for distracter items C&D never exceeded 10% in
any of the conditions, again well below the chance level of
50% (all ps < .001 on a Binomial test).
The proportion of choices for A was significantly higher
than choices for B in the 2500ms condition, Z=4.032,
p<.001 on a Sign test; no significant difference in choice
patterns was obtained in the 3250ms and 4000ms
conditions, Z=.768 and Z=.645, respectively. Choices for A
significantly declined as the contiguity of A decreased,
Q(2,65)=15.630, while choices for B significantly increased,
Q(2,65)=9.600; choices for C were not affected by
variations in A’s contiguity, Q(2,65)=2.000.
As expected, with a steeper contiguity gradient, contingency
no longer dominated choice patterns. Both cues were
equally important in determining choice patterns.
Remarkably, B never was preferred over A, suggesting that
contiguity was never more important than contingency, at
least not within the parameters of this design.

Experiment 2
Shanks et al. (1989) reported that participants failed to
distinguish causal from non-causal actions when the actionoutcome interval exceeded two seconds (but see Buehner &
May, 2003). Perhaps the contiguity gradient in Experiment
1 was not steep enough to observe a shift from contingency
to contiguity. Experiment 2 thus replicated Experiment 1,
but employed a larger contiguity contrast between causes A
and B: while B was still associated with a 500ms delay, A’s
delay could take on values of 2500ms, 3250ms, and
4000ms.

General Discussion
The goal of this paper was to investigate how contiguity and
contingency relate to each other in causal induction. In
particular, we wanted to find out whether people selectively
weigh one cue as more important than the other. Towards
this end we created a novel experimental setup, which
allowed us to study causal induction under ecologically
valid conditions: events were presented in one continuous
flow, with no discrete trial boundaries. Within this
framework, event parsing becomes part of causal induction,
as it does in real life. Our choice of scenario furthermore
ruled out recruitment of prior knowledge of mechanism and
associated timeframes. Previous experiments investigating
the role of contiguity within demarcated learning trials
examined contrasts between experienced and expected
timeframes (e.g. Allan et al., 2003). In such studies,
variations of contiguity determined whether each individual
trial was seen as evidence for or against the causal relation
in question. In our design, the absence of trials made such
evaluations immaterial. Instead, participants had to consider
the entire stream of events when making causal judgments.

.9
.8
.7
.6
.5
.4
.3
.2
.1
0

A
B
C& D

2500

3250

4000

Contiguity of A in ms

Figure 3. Experiment 2: Percentage of Participants
(N=65) choosing Causes A or B or one of the two unrelated
events (C & D).

363

information in causal attribution. Cognition, 54, 299352.
Allan, L. G., & Jenkins, H. M. (1980). The judgment of
contingency and the nature of response alternatives.
Canadian Journal of Psychology, 34(1), 1-11.
Allan, L. G., Tangen, J. M., Wood, R., & Shah, T. (2003).
Temporal contiguity and contingency judgments: A
pavlovian analogue. Integrative Physiological and
Behavior Science, 31(2), 205-211.
Anderson, J. R., & Sheu, C. F. (1995). Causal inferences as
perceptual judgments. Memory and Cognition, 23(4),
510-524.
Buehner, M. J., & Cheng, P. W. (2005). Causal learning. In
K. J. Holyoak & R. Morrison (Eds.), Handbook of
thinking & reasoning (pp. 143-168). Cambridge,
England.: Cambridge University Press.
Buehner, M. J., & May, J. (2002). Knowledge mediates the
timeframe of covariation assessment in human causal
induction. Thinking and Reasoning, 8(4), 269-295.
Buehner, M. J., & May, J. (2003). Rethinking temporal
contiguity and the judgment of causality:Effects of prior
knowledge, experience, and reinforcement procedure.
Quarterly Journal of Experimental Psychology, 56A(5),
865-890.
Buehner, M. J., & May, J. (2004). Abolishing the effect of
reinforcement delay on human causal learning.
Quarterly Journal of Experimental Psychology, 57B(2),
179-191.
Bullock, M., Gelman, R., & Baillargeon, R. (1982). The
development of causal reasoning. In W. J. Friedman
(Ed.), The developmental psychology of time (pp. 209254). New York: Academic Press.
Cheng, P. W. (1993). Separating causal laws from casual
facts: Pressing the limits of statistical relevance. In D. L.
Medin (Ed.), The psychology of learning and motivation.
Advances in research and theory (Vol. 30, pp. 215-264).
San Diego, CA, USA: Academic Press, Inc.
Cheng, P. W. (1997). From covariation to causation: A
causal power theory. Psychological Review, 104(2), 367405.
Einhorn, H. J., & Hogarth, R. M. (1986). Judging probable
cause. Psychological Bulletin, 99(1), 3-19.
Gallistel, C. R., & Gibbon, J. (2000). Time, rate, and
conditioning. Psychological Review, 107(2), 289-344.
Holyoak, K. J., & Hummel, J. E. (2000). The proper
treatment of symbols in a connectionist architecture. In
E. Dietrich & A. Markman (Eds.), Cognitive dynamics:
Conceptual change in humans and machines. (pp. 229263). Mahwah, NJ: Erlbaum.
Hume, D. (1739/1888). A treatise of human nature. In L. A.
Selby-Bigge (Ed.), Hume's treatise of human nature.
Oxford, UK: Clarendon Press.
Jenkins, H., & Ward, W. (1965). Judgment of contingencies
between responses and outcomes. Psychological
Monographs, 7, 1-17.
Mandel, D. R., & Lehman, D. R. (1998). Integration of
contingency information in judgments of cause,
covariation, and probability. Journal of Experimental
Psychology: General, 127(3), 269-285.

This trial-free notion of causal learning is similar to ratebased accounts of learning (Anderson & Sheu, 1995;
Gallistel & Gibbon, 2000). Anderson & Sheu, for instance,
found that causal judgments followed a grating contrast
based on the rates of effect occurrence conditional on the
presence vs. the absence of the cause. In their instrumental
learning task, Anderson & Sheu varied response-outcome
intervals while keeping contingencies constant. While they
reported sensitivity to both contiguity and contingency, their
design did not allow systematic investigations of the
interaction between the two cues (for a related argument on
relative contiguity, see also Wasserman & Neunaber, 1986).
As we have argued in the introduction, degradations in
causal judgment due to reductions in contingency follow
readily from a computational analysis of the inductive
problem; degradations due to reduced contiguity may
appear non-normative (apart from mis-matches between
expected and experienced time-frames), but nonetheless are
to be expected under realistic circumstances involving
limited memory and computational resources. What was
less clear, however, was how these two cues interact to
determine causal induction. Our results suggest a dominance
of contingency over contiguity. This dominance is
moderated by a trade-off curve, however, such that
contingency gradually loses its dominance when the causeeffect delay increases.
When considering such trade-offs, it is important to separate
utility from causality (Oaksford & Chater, 1998). A
response may have perfect contingency with a desired
outcome, but produce the outcome only after a long delay.
An alternative response may produce the outcome right
away, but unreliably. Depending on the cost of responding
and the time available to interact with the environment, it
may be more beneficial for the organism to engage in the
low-contingent response. Our experiment asked participants
to select the cause that is most successful in producing the
effect (without any reference to time). The one-shot nature
of our dependent measure clearly requested an answer based
on causality, rather than utility, and our results show that
people were aware of this.
We hope that our empirical results will inform and constrain
modeling efforts in event parsing and statistical learning.
Our current results indicate that contiguity at best is equally
important as contingency, but never outweighs it. Future
research will need to investigate whether this parameter
ordering also holds in situations involving steeper contiguity
gradients.

Acknowledgments
We thank Jacky Boivin and Todd Bailey for helpful
discussion of statistical methods to analyze choice data.

References
Ahn, W.-K., Kalish, C. W., Medin, D. L., & Gelman, S. A.
(1995). The role of covariation vs. Mechanism

364

Shultz, T. R. (1982). Rules of causal attribution.
Monographs of the Society for Research in Child
Development, 47(1), 1-51.
Siegler, R. S., & Liebert, R. M. (1974). Effects of
contiguity, regularity, and age on children's causal
inferences. Developmental Psychology, 10(4), 574 579.
Steyvers, M., Tenenbaum, J. B., Wagenmakers, E. J., &
Blum, B. (2003). Inferring causal networks from
observations and interventions. Cognitive Science, 27(3),
453-489.
Tanimoto, H., Heisenberg, M., & Gerber, B. (2004). Event
timing turns punishment to reward. Nature, 430, 983.
Tenenbaum, J. B., & Griffiths, T. L. (2001). Structure
learning in human causal induction. In T. G. Dietterich
& V. Tresp (Eds.), Advances in neural processing
systems (Vol. 13, pp. 59-65). Cambridge, MA: MIT
Press.
Wasserman, E. A., & Neunaber, D. J. (1986). College
students' responding to and rating of contingency
relations: The role of temporal contiguity. Journal of the
Experimental Analysis of Behavior, 46(1), 15-35.
White, P. A. (2003). Making causal judgments from the
proportion of confirming instances: The pci rule.
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 29(4), 710-727.
Young, M. E. (1995). On the origin of personal causal
theories. Psychonomic Bulletin and Review, 2(1), 83104.
Young, M. E. (1997). Implicit processes in the development
of causal knowledge: A connectionist model of the use
of humean cues. In P. W. van den Broek, P. J. Bauer &
T. Bourg (Eds.), Developmental spans in event
comprehension and representation: Bridging fictional
and actual events. (pp. 29-50). Hillsdale, NJ: Lawrence
Erlbaum Associates, Inc.

Mendelson, R., & Shultz, T. R. (1976). Covariation and
temporal contiguity as principles of causal inference in
young children. Journal of Experimental Child
Psychology, 22(3), 408-412.
Michotte, A. E. (1946/1963). The perception of causality (T.
R. Miles, Trans.). London, England: Methuen & Co.
Novick, L. R., & Cheng, P. W. (2004). Assessing interactive
causal influence. Psychological Review, 111(2), 455485.
Oaksford, M., & Chater, N. (Eds.). (1998). Rational models
of cognition. New York: Oxford University Press.
Reichenbach, H. (1956). The direction of time. Berkeley &
Los Angeles: University of California Press.
Rescorla, R. A., & Wagner, A. R. (1972). A theory of
pavlovian conditioning: Variations in the effectiveness
of reinforcement and nonreinforcement. In A. H. Black
& W. F. Prokasy (Eds.), Classical conditioning ii:
Current theory and research (pp. 64-99). New Yowk:
Appleton-Century Crofts.
Savastano, H. I., & Miller, R. R. (1998). Time as content in
pavlovian conditioning. Behavioural Processes, 44(2),
147-162.
Schlottmann, A. (1999). Seeing it happen and knowing how
it works: How children understand the relation between
perceptual causality and underlying mechanism.
Developmental Psychology, 35(5), 303-317.
Shanks, D. R., & Dickinson, A. (1987). Associative
accounts of causality judgment. In G. H. Bower (Ed.),
Psychology of learning and motivation-advances in
research and theory (Vol. 21, pp. 229-261). San Diego,
CA: Academic Press.
Shanks, D. R., Pearson, S. M., & Dickinson, A. (1989).
Temporal contiguity and the judgment of causality by
human subjects. Quarterly Journal of Experimental
Psychology Section B- Comparative and Physiological
Psychology, 41(2), 139-159.

365

