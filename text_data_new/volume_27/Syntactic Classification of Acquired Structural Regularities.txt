UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Syntactic Classification of Acquired Structural Regularities

Permalink
https://escholarship.org/uc/item/7dk9v298

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Forkstam, Christian
Petersson, Karl Magnus

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Syntactic Classification of Acquired Structural Regularities
Christian Forkstam (christian.forkstam@cns.ki.se)

Cognitive Neurophysiology Research Group, Karolinska Institutet
Karolinska hospital N8, 171 76 Stockholm, Sweden.
F.C. Donders Centre for Cognitive Neuroimaging
Radboud University Nijmegen, The Netherlands.

Karl Magnus Petersson (karl.magnus.petersson@fcdonders.ru.nl)
F.C. Donders Centre for Cognitive Neuroimaging
Radboud University Nijmegen, The Netherlands.
Cognitive Neurophysiology Research Group, Karolinska Institutet
Karolinska hospital N8, 171 76 Stockholm, Sweden.
CSI, Center for intelligent systems, Universidade do Algarve, Faro, Portugal.

from artificial grammars (e.g., Seger, Prabhakaran,
Poldrack, & Gabrieli, 2000; Skosnik et al., 2002). For
example, Petersson et al. (2004) investigated a
grammaticality classification task using an implicit
acquisition paradigm without feedback in which the
participants were only exposed to positive examples (i.e.,
well-formed consonant strings) generated by the Reber
grammar. The results showed that artificial syntactic
violations activated Broca’s region (Brodmann’s area (BA)
44/45). In the current study we tested the validity of this
finding in a modified experimental design, using
classification strings that were balanced for substring
familiarity relative the acquisition string-set, independent of
grammatical status; and sequential instead of whole string
presentation paradigm for the strings.

Abstract
In this paper we investigate the neural correlates of syntactic
classification of an acquired grammatical sequence structure
in an event-related FMRI study. During acquisition,
participants were engaged in an implicit short-term memory
task without performance feedback. We manipulated the
statistical frequency-based and rule-based characteristics of
the classification stimuli independently in order to investigate
their role in artificial grammar acquisition. The participants
performed reliably above chance on the classification task.
We observed a partly overlapping corticostriatal processing
network activated by both manipulations including inferior
prefrontal, cingulate, inferior parietal regions, and the caudate
nucleus. More specifically, the left inferior frontal BA 45 and
the caudate nucleus were sensitive to syntactic violations and
endorsement, respectively. In contrast, these structures were
insensitive to the frequency-based manipulation.

Implicit statistical learning

Keywords: Artificial Grammar; Functional Neuroimaging;
FMRI; Inferior Frontal Cortex; Caudate Nucleus.

A complementary perspective on AGL views this as a
model for investigating implicit learning (Forkstam &
Petersson, 2005). Reber (1967) defined implicit learning as
the process by which an individual comes to respond
appropriately to the statistical structure inherent in the input.
Thus, he argued, the capacity for generalization that the
participants show in grammaticality classification is based
on the implicit acquisition of structural regularities reflected
in the input sample. Reber (1967) suggested that humans
acquire implicit knowledge of the underlying structure
through an inductive statistical learning process and that this
knowledge is put to use during classification. Support for
the implicit character of AGL comes for example from
lesion studies on amnesic patients. Knowlton and Squire
(1996) investigated amnesic patients and normal controls on
a classical and a transfer version of the AGL task. The
patients and their normal controls performed similarly on
both AGL tasks while the amnesic patients showed no
explicit recollection of whole-item or fragment (i.e., bi- or
tri-gram) information. Based on the results from the transfer
version they argued that AGL depends on the implicit
acquisition of both abstract and exemplar-specific
information. Knowlton and Squire (1996) suggested that the
latter indicates that distributional information of local
sequential regularities is acquired, while the former suggests

Introduction
Humans possess adaptive mechanisms capable of implicitly
extracting structural information solely from observation
(Stadler & Frensch, 1998), as indicated by for example
artificial grammar learning (AGL). Reber (1967) suggested
that humans can learn artificial grammars implicitly by an
abstraction process intrinsic to natural language acquisition.
Chomsky, following von Humboldt, suggested that natural
language is an example of the ‘infinite use of finite means’.
The simplest relevant formal model incorporating this idea
is represented by the family of right-linear phrase structure
grammars, which can be implemented in the finite-state
architecture (FSA), are typically used in AGL.
It has recently been suggested that AGL is a relevant
model for investigating aspects of language learning in
infants (Gomez & Gerken, 2000), and second language
learning in adults (Friederici, Steinhauer, & Pfeifer, 2002).
Recent functional magnetic resonance imaging (FMRI)
results indicate that language related brain regions are
engaged in artificial grammar processing (Petersson,
Forkstam, & Ingvar, 2004) and a number of FMRI studies
have investigated implicit learning of material generated
696

that abstract (i.e., ‘rule-based’) representations are also
formed. Moreover, recent studies provide evidence that
rapid (on the order of 2 – 10 min) ‘rule-abstraction’
(Marcus, Vijayan, Bandi Rao, & Vishton, 1999), learning of
transition probabilities in artificial syllable sequences
(Saffran, Aslin, & Newport, 1996), and AGL (Gomez &
Gerken, 1999) also occur in young infants. Furthermore, the
study of Gomez and Gerken (1999) also demonstrated that
infants show some transfer capacity, suggesting that they
were abstracting beyond the acquisition material. In
addition, learning of long distance dependencies has been
demonstrated in both sequence learning as well as in AGL
(Ellefson & Christiansen, 2000; Poletiek, 2002). Thus, it has
been suggested that induction cannot be explained entirely
in terms of the acquisition of local sequential regularities
(Meulemans & Van der Linden, 1997), and while Reber
(1967) originally argued that the implicit learning process
abstracted ‘rule-based’ knowledge (see Reber, 1993 for a
modification of his position), these more recent studies
suggest that dual mechanisms may be at play (cf. e.g.,
Forkstam & Petersson, 2005).

Experimental design
In the present event-related FMRI study we employed a
modified AGL paradigm. As in the classical AGL paradigm
there were both acquisition and classification phases, but
with the modification that the participants participated in
repeated acquisition phases over 8 days. During each
acquisition phase, the 12 participants (dutch-speaking with
university background, 8 females, mean age ± sd = 23 ± 3
years) were engaged in a short-term memory task without
performance feedback. They were presented with letter
strings from an acquisition sample generated from the Reber
grammar and had to retrieve these by typing each string on a
keyboard immediately after presentation. The participants
were informed before the acquisition session on day 1 that
they would be asked to classify (i.e., guess based on ’gut
feeling’) new items as grammatical (G) or non-grammatical
(NG), subsequent to the acquisition sessions on day 1 and
day 8. EPI-BOLD FMRI data were acquired (TR = 2.8 s and
3.5x3.5x3.5 mm3 resolution; at 3T) during the classification
sessions on day 1 and 8.
Grammatical strings of 5-12 consonants were generated
from the Reber grammar. The frequency distribution of biand trigrams (2 and 3 letter chunks) for both terminal and
whole string positions were calculated for each string in
order to derive the associative chunk strength (ACS) for
each item (cf., Knowlton & Squire, 1996; Meulemans &
Van der Linden, 1997). An acquisition set was selected as
well as G and NG classification test strings. The NG strings
were generated by a switch of letters in two non terminal Gstring positions. The classification set was further divided
into high and low ACS items relative the acquisition string
set. We thus manipulated two independent stimulus factors
with respect to the classification set, grammaticality (G/NG)
and ACS (H/L) in a 2x2 factorial experimental design.
It has been argued that sensitivity to the level of ACS is a
reflection of a statistical fragment-based learning
mechanism while sensitivity to grammaticality status
independent of ACS is related to a structure-based
acquisition mechanism (Knowlton & Squire, 1996;
Meulemans & Van der Linden, 1997). Consequently, it has
been argued that sensitivity to ACS reflects an explicit
declarative learning mechanism dependent on the medial
temporal lobe (cf. e.g., Opitz & Friederici, 2003; Strange,
Henson, Friston, & Dolan, 2001), while sensitivity to
grammaticality status independent of ACS reflects an
implicit procedural learning mechanism, which might be
dependent on the interaction between prefrontal regions and
the basal ganglia.

The Reber grammar
In general, formal (artificial) grammars serve as an
intentional definition of languages (Chomsky, 1986). These
represent the formal specification of mechanism(s) that
generate various types of structural regularities (cf. e.g., the
Chomsky hierarchy, Davis, Sigal, & Weyuker, 1994), and
they are relevant for any cognitive domain which engages
processes operating on structured representations, including
for example the temporal organization of actions (i.e.,
planning), language, and perception/generation of musical
sound patterns (Petersson, 2005a; Petersson et al., 2004). A
formal grammar, as the one used in this AGL study, thus
represents a specification of a finite generating/recognizing
mechanism for a particular language; in our case the Reber
language. The transition graph representation of the Reber
machine (Figure 1) is thus an explicit generating and
recognition mechanism for the Reber language (e.g., Davis
et al., 1994).

Data analysis
The FMRI data was pre-processed and anatomically
normalized to a common stereotactic space, and statistically
analyzed with a mixed effect procedure to allow for group
level inferences in a factorial ANOVA design with nonsphericity correction. Statistical inference was based on
relevant condition contrasts (correct trials only) and we used
the supra-threshold cluster-size test-statistic using a
significance level of P < 0.05 corrected for multiple nonindependent comparisons based on the family-wise error

Figure 1: The Reber grammar is an example of a rightlinear phrase structure grammar. This can be implemented
in a finite-state architecture, here represented by its
transition graph (cf., Reber & Allen, 1978).
697

rate (Worsley et al., 1996). We explored the observed local
maxima in the omnibus F-test (i.e. effects related to
grammaticality and ACS manipulations, for within and
between test days) with a region of interest (ROI) analysis.

Table 1: Local maxima of significantly activated clusters in
the omnibus F-test (threshold: P = 0.05, false discovery rate
(FDR) corrected). Right part of the table describes the posthoc ROI analysis of the observed local maxima (radius = 5
mm). G = grammatical string; NG = non-G; ACS =
associated chunk strength; H = high ACS; L = low ACS;
BA = Brodmann'
s area; significant interactions during test
day 1 (†) or 8 (‡).

Results
The behavioral results showed a significant sensitivity on
both test days to grammaticality (F(11, 36) > 49, P < 0.001)
and ACS (F(11, 36) > 19, P < 0.001) while the interaction
was non-significant. We also observed a significant increase
in sensitivity to grammaticality over test days (F(11, 84) =
117, P < 0.0001; Figure 2). In contrast, this was not the case
for ACS. Thus, already on the first classification test, most
of the participants classified items reliably above chance
and their performance improved with repeated acquisition
sessions (Figure 2).

Region (BA) Z99
L 45
L 47
R 46
R 47
R 32
R 39
R 22
L 23/31
31
NC
R hipp
L hipp

x

y

z

4.2 -45 24 18
4.3 -33 18 -9
4.2 45 27 21
5.4 33 21 -6
4.5
6 27 33
3.5 54 -51 33
3.4 51 -48 18
3.5 -12 -51 30
4.1
0 -30 45
3.7
3 15 -3
28 -30 -2
-28 -30 -2

ACS GRAM
d1 d8 d1 d8
NG NG ‡
L
NG NG
L L NG NG
L
NG NG
L
NG NG
NG
†
L NG NG
H
G
H
G G
H
G
L
H L

Figure 2: Endorsement grammaticality rates as a
function of grammaticality status (G = grammatical, NG =
non-G) as well as associative chunk strength (H = high, L
= low). Error bars correspond to one standard deviation.
The FMRI results showed that the grammaticality
classification in comparison to baseline activated a similar
set of brain regions during both day 1 and 8. A subset of this
network was significant with respect to the omnibus F-test
including the factors: grammaticality, ACS, and test day.
This subset included regions in the ventrolateral prefrontal
cortices bilaterally, centered on inferior frontal (BA 45/47)
extending into middle frontal cortex (BA 46) and frontal
operculum/anterior insula (BA 47). It further included
regions in the anterior (BA 24/32) and posterior cingulate
(BA 23/31), the right inferior parietal (BA 39) and superior
temporal (BA 22) cortex, as well as the head of the caudate
nucleus, bilaterally (Table 1, left; see also Figure 3 for
regions sensitive to grammaticality status).

Figure 3: Regions significantly sensitive to grammatical
status (G > NG in red, NG > G in blue; correct responses
only). Left: test day 1. Right: test day 8. Threshold
corresponding to P = 0.05 corrected for false discovery
rate. (x = -45; z = -3).

698

In the ROI analysis of the network outlined above (Table 1,
right), the left BA 45 was specifically and selectively
sensitive to NG vs. G strings on both day 1 and 8. However,
this was not the case for the ACS manipulation.
Interestingly, the right inferior frontal (BA 45/46/47) and
the anterior cingulate cortices (BA 32) regions were
sensitivity to the level of ACS on test day 1. On test day 8,
this was also the case for some right inferior frontal regions.
Furthermore, the caudate nucleus was sensitive to G vs. NG
strings on day 8. Finally, we observed hippocampal
activations bilaterally related to the ACS manipulation on
both test days (the MTL target regions were derived from a
similar AGL study of Lieberman, Chang, Chiao,
Bookheimer, & Knowlton, 2004).

only frontal region which did not show any sensitivity to the
level of associative chunk strength on either of the test days
(i.e., day 1 and day 8). This lends further support to the
suggestion that the left inferior frontal region (BA 45) has a
specific role in the processing structural regularities, while
the right inferior frontal gyrus might be involved in more
generic error detection processes (cf., Indefrey, Hagoort,
Herzog, Seitz, & Brown, 2001).

Recurrent corticostriatal networks
The present results show that grammaticality endorsement
(i.e., G vs. NG) correlates with caudate nucleus activity
while syntactic violations (NG vs. G) correlate with the left
inferior frontal cortex activation. This might result from
integration (i.e., parsing) difficulties during processing of
NG strings. These findings are in line with a procedural
mechanisms for recursive integration of structured
representations and it might be the case that the involvement
of the basal ganglia reflect automatic aspect of the
integration and the processing syntactic form, perhaps in
interaction with the left inferior frontal region. For example,
it has been suggested that neural systems supporting
procedural learning and that are important for the on-line
governing of the parsing process depend on recurrent
networks implemented in corticostriatal loops (cf. e.g.,
Luciana, 2003; Nelson & Webb, 2003). Taken together, it
might be suggested that the processing of inherently
meaningless artificial grammar strings is dependent on the
neural architecture for procedural learning, as well as
regions implicated in general integrative processes in the
analysis of linguistic form (left BA 44/45), and when
aspects of this integration process becomes automatic, also
on the head of the caudate nucleus.

Structural vs. fragment knowledge
We then investigated performance and regional specificity
with respect to structural vs. fragment knowledge. More
specifically, we investigated the performance differences
between low ACS grammatical (LG) and high ACS nongrammatical strings (HNG). Correct classification of the LG
items depend maximally on the grammaticality status while
the support from ACS information (if used at all) is
minimized and hence this should maximize the sensitivity to
structurally
('
rule'
)
based
processes.
Conversely,
classification of the HNG items depend on the ACS status
while the grammaticality status works in the opposite
direction and hence correct classification maximizes the
utilization of fragment or frequency based knowledge. This
suggests that the LG vs. HNG contrast is selective for
structurally based processes, while the HNG vs. LG contrast
is selective for fragment/frequency based processes.
In the behavioral data, we observed a clear preference for
LG over HNG strings during test day 8 (only a trend during
test day 1). This result lends support to the notion that
structural (syntactic) regularities are used independent of
fragment/frequency
features
during
grammaticality
classification. With respect to the FMRI data, we observed a
significant caudate nucleus activation on day 8 (LG > HNG;
x/y/z = 3/18/-3, cluster P = 0.023, Z99 = 4.3), suggesting
that this region is selectively sensitive to structural
processing. Conversely, we found the right frontal
operculum to be significantly more sensitive to ACS (HNG
> LG; BA 47, x/y/z = 36/24/-6, cluster P = 0.04, Z99 = 3.4),
indicating that this region is related to fragment/frequency
based processing.

Grammar learning
As previously noted in the introduction, Reber (1967)
defined implicit learning as the process by which an
individual comes to respond appropriately to the structure in
the input ensemble. Thus, he argued, the capacity to
generalize is based on implicit acquisition of structural
regularities reflected in the input sample. However,
alternative theoretical frameworks have questioned the
abstract ('
rule'
) acquisition interpretation and instead suggest
that grammaticality classification utilizes exemplar-based
(Vokey & Brooks, 1992) or, alternatively, is based on chunk
(n-gram) representations (Perruchet & Pacteau, 1991). Thus,
grammar learning, whether natural or artificial, is commonly
conceptualized either in terms of structure-based ('
rule'
)
acquisition mechanisms or statistical learning mechanisms.
Some aspects of natural language (e.g., syntax) are
amenable to an analysis within the classical framework of
cognitive science, which suggests that isomorphic models of
cognition can be found within the framework of ChurchTuring computability (Davis et al., 1994). These language
models typically allow for a greater structural expressivity
than can be (strictly) implemented in the FSA. The FSA
supports unlimited concatenation recursion and can support
finite recursion of general type. These latter aspects are also
characteristic for human performance. From a

Discussion
A primary objective of the present study was to replicate our
previous finding (Petersson et al., 2004) showing that the
left inferior frontal cortex (BA 44/45) is sensitive to
artificial syntactic violations, using a 2x2 factorial design
with substring familiarity (ACS; high/low) relative to the
acquisition string set and grammatical status (G/NG) as
factors, as well as using a sequential instead of whole string
presentation paradigm. This was indeed the case, although
the activated frontal regions were more extensive in the
present study and also included right homotopic regions.
However, the left inferior frontal gyrus (BA 45) was the
699

neurophysiological perspective, it seems natural to assume
that the brain is finite with respect to its memory
organization. However, it should be noted that the FSA
behaves as a Turing machine as long as the memory
limitations are not encountered (Petersson, Grenholm, &
Forkstam, 2005). Now, if one assumes that the brain
implements a classical model of language, then it follows
immediately from the assumption of a finite memory
organization that this model can be implemented in a FSA,
although a context-sensitive or any other suitable formalism
might be used as long as the finite memory organization is
appropriately handled (Petersson, 2005b; Petersson et al.,
2004).

Prefrontal function and lexicalization
Prefrontal functions are commonly formulated within a
framework of cognitive control and executive attention.
Prefrontal working memory functions include on-line shortterm sustainability of representations ('
maintenance'
, e.g.,
Baddeley, 2003; Baddeley, Gathercole, & Papagano, 1998)
processing and integration of structured information
('
manipulation'and '
selection'
), as well as monitoring and
inhibition (Fuster, 1997; Mesulam, 1998, 2002). A simple
formalization of some aspects of these ideas takes advantage
of the fact that hierarchically structured information can be
represented in terms of nested bracketed expressions or
hierarchically structured trees (Petersson, 2005b; Petersson
et al., 2005). If one assumes that these representations are
recursively constructed from more primitive structures
stored in long-term memory, one possibility is to interpret
integration of structured information as resulting from the
retrieval of simple long-term memory representations for
on-line incremental integration by successive merging of
primitive structures ('
unification'
).
Returning to the issue of grammar learning, it is possible
to take a view that is placed somewhere between the two
more common conceptualizations. For example, the
generative mechanism of the Reber machine is easily
translated into a Minimalist-type or unification-based
framework (Chomsky, 1995; Joshi & Schabes, 1997). Given
a transition from state sj to sk when the terminal symbol T is
recognized (sj →T sk in the transition graph), this would
translate into a lexical item or feature vector [sj, T, sk],
where sj, T, and sk should be interpreted as '
syntactic'
features (e.g., '
specifier'feature sj, and '
complement'feature
sk) and T as a '
surface'or '
phonological'feature. A finite
transition graph thus generates a finite number of lexical
items. The syntactic features of these representations could
very well be generated or estimated based on a statistical
learning mechanism. Moreover, there is no need for a
specific '
rule'acquisition mechanism, because the parsing
process might use general structure integration mechanisms
already in place for merging or unifying structured
representations (e.g., in the left inferior frontal region), as
suggested in Petersson et al. (2004). Here, two lexical items,
[si, R, sj], [sk, Q, sl], are allowed to unify if and only if sj =
sk, or sl = si. We note that the syntactic features have
acquired a particular functional role in this picture. This can
be described in terms of monitoring or governing of the
integration process based on selecting the pieces of
700

information that can be merged. In other words, the finitestate control has been distributed over the mental lexicon
(long-term memory) among the lexical items in terms of
control features. This view is more akin to lexical
acquisition in that it suggests that simple structured
representations are created (i.e., lexical items [sj, T, sk])
during acquisition. In essence, this re-traces a major trend in
theoretical linguistics in which more of the grammar is
shifted into the mental lexicon and the distinction between
lexical items and grammatical rules is beginning to vanish
(cf. e.g., Jackendoff, 2002; Joshi & Schabes, 1997; Vosse &
Kempen, 2000).
In summary, the picture just outlined provides an
alternative view on AGL that is placed somewhere between
the two more common conceptualizations in terms of a rulebased acquisition or a statistical fragment (surface) based
learning mechanism. Instead, the '
lexicalized' picture
suggests that the acquisition of simple structured
representations is akin to lexical learning and might be
supported by statistical learning mechanisms. These
representations are then activated, by for example an input
string, and actively represented and integrated in a
unification space (e.g., working memory) during parsing.
The latter process is dependent on general integrative
mechanisms in the left inferior frontal cortex, and when
automaticity has developed, some aspects of this process
appears to engage the head of the caudate nucleus.

References
Baddeley, A. (2003). Working memory: looking back and
looking forward. Nat. Rev. Neurosci., 4, 829-839.
Baddeley, A., Gathercole, S., & Papagano, C. (1998). The
phonological loop as a language learning device. Psychol.
Rev., 105, 158-173.
Chomsky, N. (1986). Knowledge of Language. New York:
Praeger.
Chomsky, N. (1995). The Minimalist Program. Cambridge,
MA: MIT Press.
Davis, M. D., Sigal, R., & Weyuker, E. J. (1994).
Computability,
Complexity,
and
Languages:
Fundamentals of Theoretical Computer Science (2 ed.).
San Diego, CA: Academic Press.
Ellefson, M. R., & Christiansen, M. H. (2000). Subjacency
constraints without universal grammar: evidence from
artificial language learning and connectionist modeling.
Paper presented at the 22nd annual conference of the
Cognitive Science Society.
Forkstam, C., & Petersson, K. M. (2005). Towards an
explicit account of implicit learning. Accepted for
publication in Current Opinion in Neurology.
Friederici, A. D., Steinhauer, K., & Pfeifer, E. (2002). Brain
signatures of artificial language processing: Evidence
challenging the critical period hypothesis. Proc. Natl.
Acad. Sci. USA, 99, 529-534.
Fuster, J. M. (1997). The Prefrontal Cortex: Anatomy,
Physiology, and Neuropsychology of the Frontal Lobe (3
ed.). New York: Lippincott-Raven.

Gomez, R. L., & Gerken, L. (1999). Artificial grammar
learning by 1-year-olds leads to specific and abstract
knowledge. Cognition, 70, 109-135.
Gomez, R. L., & Gerken, L. (2000). Infant artificial
language learning and language acquisition. Trends Cogn.
Sci., 4, 178-186.
Indefrey, P., Hagoort, P., Herzog, H., Seitz, R. J., & Brown,
C. M. (2001). Syntactic processing in left prefrontal
cortex is independent of lexical meaning. NeuroImage,
14, 546-555.
Jackendoff, R. (2002). Foundations of Language: Brain,
Meaning, Grammar, Evolution. Oxford, UK: Oxford
University Press.
Joshi, A. K., & Schabes, Y. (1997). Tree-adjoining
grammars. In A. Salomaa (Ed.), Handbook of Formal
Languages (Vol. 3: Beyond words). Berlin: Springer
Verlag.
Knowlton, B. J., & Squire, L. R. (1996). Artificial grammar
learning depends on implicit acquisition of both abstract
and exemplar-specific information. J. Exp. Psychol.
Learn. Mem. Cogn., 22, 169-181.
Lieberman, M. D., Chang, G. Y., Chiao, J., Bookheimer, S.
Y., & Knowlton, B. J. (2004). An event-related fMRI
study of artificial grammar learning in a balanced chunk
strength design. J. Cogn. Neurosci., 16, 427-438.
Luciana, M. (2003). The neural and functional development
of human prefrontal cortex. In M. de Haan & M. H.
Johnson (Eds.), The Cognitive Neuroscience of
Development (pp. 157-179). New York: Psychology
press.
Marcus, G. F., Vijayan, S., Bandi Rao, S., & Vishton, P. M.
(1999). Rule learning by seven-month-old infants.
Science, 283(5398), 77-80.
Mesulam, M. M. (1998). From sensation to cognition.
Brain, 121, 1013-1052.
Mesulam, M. M. (Ed.). (2002). The Human Frontal Lobes:
Transcending the default mode through contingent
encoding. Oxford, UK: Oxford University Press.
Meulemans, T., & Van der Linden, M. (1997). Associative
chunk strength in artificial grammar learning. J. Exp.
Psychol. Learn. Mem. Cogn., 23, 1007-1028.
Nelson, C. A., & Webb, S. J. (2003). A cognitive
neuroscience perspective on early memory development.
In M. de Haan & M. H. Johnson (Eds.), The Cognitive
Neuroscience of Development (pp. 99-125). New York:
Psychology press.
Opitz, B., & Friederici, A. D. (2003). Interactions of the
hippocampal system and the prefrontal cortex in learning
language-like rules. NeuroImage, 19, 1730-1737.
Perruchet, P., & Pacteau, C. (1991). Implicit acquisition of
abstract knowledge about artificial grammar: Some
methodological and conceptual issues. J. Exp. Psychol.
Gen., 120, 112-116.

Petersson, K. M. (2005a). Learning and Memory in the
Human Brain. Stockholm, Sweden: Karolinska University
Press.
Petersson, K. M. (2005b). On the relevence of the
neurobiological analogue of the finite state machine.
Neurocomputing, 65-66, 825-832.
Petersson, K. M., Forkstam, C., & Ingvar, M. (2004).
Artificial syntactic violations activate Broca'
s region.
Cognitive science, 28, 383-407.
Petersson, K. M., Grenholm, P., & Forkstam, C. (2005).
Artificial grammar learning and neural networks.
Accepted for publication in the Proceeding of the
Cognitive Science Society.
Poletiek, F. H. (2002). Implicit learning of a recursive rule
in an artificial grammar. Acta Psychol. (Amst.), 111, 323335.
Reber, A. S. (1967). Implicit learning of artificial grammars.
J. Verb. Learn. Verb. Behav., 5, 855-863.
Reber, A. S. (1993). Implicit Learning and Tacit Knowledge
: An Essay on the Cognitive Unconscious. New York:
Oxford Univ. Press.
Reber, A. S., & Allen, R. (1978). Analogy and abstraction
strategies in synthetic grammar learning: A functional
interpretation. Cognition, 6, 189-221.
Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
Statistical learning by 8-month-old infants. Science, 274,
1926-1928.
Seger, C. A., Prabhakaran, V., Poldrack, R. A., & Gabrieli,
J. D. (2000). Neural activity differs between explicit and
implicit learning of artificial grammar strings: An fMRI
study. Psychobiology, 28, 283-292.
Skosnik, P. D., Mirza, F., Gitelman, D. R., Parrish, T. B.,
Mesulam, M. M., & Reber, P. J. (2002). Neural correlates
of artificial grammar learning. NeuroImage, 17, 13061314.
Stadler, M. A., & Frensch, P. A. (Eds.). (1998). Handbook
of Implicit Learning. London: SAGE.
Strange, B. A., Henson, R. N. A., Friston, K. J., & Dolan, R.
J. (2001). Anterior prefrontal cortex mediates rule
learning in humans. Cerebral Cortex, 11, 1040-1046.
Vokey, J. R., & Brooks, L. R. (1992). Salience of item
knowledge in learning artificial grammar. J. Exp. Psychol.
Learn. Mem. Cogn. 18, 328-344.
Worsley, K., Marrett, S., Neelin, P., Vandal, A. C., Friston,
K. J., & Evans, A. (1996). A unified statistical approach
for determining significant signals in images of cerebral
activation. Hum. Brain Map., 4, 58-73.
Vosse, T., & Kempen, G. (2000). Syntactic structure
assembly in human parsing: a computational model based
on competitive inhibition and a lexicalist grammar.
Cognition, 75, 105-143.

701

