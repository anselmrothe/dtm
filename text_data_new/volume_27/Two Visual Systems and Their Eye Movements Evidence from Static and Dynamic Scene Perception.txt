UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Two Visual Systems and Their Eye Movements: Evidence from Static and Dynamic Scene
Perception

Permalink
https://escholarship.org/uc/item/9nv0c661

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Helmert, Jens R.
Joos, Markus
Pannasch, Sebastian
et al.

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Two Visual Systems and their Eye Movements:
Evidence from Static and Dynamic Scene Perception
Boris M. Velichkovsky,
Markus Joos, Jens R. Helmert, and Sebastian Pannasch
(velich {joosy helmert pannasch}@psychomail.tu-dresden.de)
Dresden University of Technology
Applied Cognitive Research/ Psychology III
Mommsenstrasse 13
Dresden, D-01062 Germany
Abstract
The existence of two distinct visual pathways in the primate
brain is a persistent theme for evolutionary, neurophysiological, motor control and neuropsychological research. As
one of the most widely cited results in cognitive neuroscience,
this distinction has survived decades of critical analysis under
different guises (e.g. ambient vs. focal or visuomotor vs.
cognitive). However, the interplay between these two
processing streams in the solution of everyday tasks remains
to be an unresolved issue. In particular, how do they guide
eye movements, their most immediate output? Results from
our recent study on hazard perception in a simulated driving
environment demonstrated that specific combinations of eye
movement parameters are indicative to an involvement of
either of the two systems. In a further experiment, we tried to
validate these parameters by testing assumptions about
memory representations related to these two modes. After a
short presentation of various real world scenes, subjects had
to recognize cut-outs from them, which were selected
according to their fixation parameters. Random cut-outs from
not seen pictures (catch trials) were also presented. The
results confirmed our hypothesis: cut-outs corresponding to
presumably focal mode of processing were better recognized
than cut-outs similarly fixated in the course of ambient
exploration.
Keywords: Active Vision; Dorsal and Ventral Streams;
Ambient and Focal Attention; Scene Perception; Recognition;
Eye Movements.

Introduction
In contemporary studies of visual cognition, one can
discover several clusters of research that are only loosely
connected to each other (for similar arguments, see Simons
& Rensink, 2005). An intensive albeit still controversial
discussion is, for instance, how and even whether visual
information is retained across saccades while viewing a
scene (Bridgeman, Van der Heijden, and Velichkovsky,
1994).
Irwin's object file theory of transsaccadic memory
emphasises the crucial role of visual attention in what local
visual information from a scene is or is not represented
(Irwin, 1992). Attending an object in a visual scene allows
binding its features into a unified object description
(Treisman, 1988). This object description is linked to a
spatial position in a master map of locations, forming a
temporary representation in visual short-term memory
(VSTM). According to Irwin (1992) three to four discrete

objects can be hold at a time in VSTM. Finally, object files
are the primary content of transsaccadic memory providing
local continuity from one fixation to the next. More
recently, coherence theory (Rensink, 2000a, 2000b)
proposed a similar explanation of the fact that despite the
'snapshot-like' character of visual information acquisition
the world around us is experienced as being stable, coherent
and richly detailed. Just as in object file theory visual
attention is the premise to bind sensory features into a
coherent object representation, which can be hold in VSTM
preventing them from disruptions like saccades. Prior to
focused attention, proto-objects with only limited temporary
and spatial coherence are formed in parallel across the
visual field but being volatile and replaced on appearance of
a new stimulus at their position. On withdrawal of attention
a coherent object resolves into its constituent proto-objects
again leaving no or only little after-effect of attention
(Rensink, 2000a).
Both these visual transience hypotheses (Hollingworth &
Henderson, 2002) rely on the idea, that a complete metric
representation of a visual scene is neither possible nor
necessary. O'Regan and Noe (2001) go even further saying
(actually paraphrasing Brooks, 1991, p. 139) “the world
serves as its own memory”. One drawback of these
approaches to scene perception is, however, that they
consider eye movements as mechanical events of no further
interest. The classification is simply based on measuring
whether the subject is holding their eyes stable at a
designated position (fixation) or is doing a jerky eye
movement (saccade). Presentation or extinction of visual
stimuli (e.g. a scene or an object) is in the majority of cases
executed in relation to the start or end of a saccade. The
underlying processing, which may be reflected in the
variation of fixation durations, is neglected.
There is another line of research analyzing the duration of
visual fixations in terms of task complexity, levels of
processing or skills, especially for reading tasks
(Velichkovsky, 1999). In a recent study by Unema,
Pannasch, Joos, and Velichkovsky (2005) subjects viewed
computer generated images of rooms containing different
interior, in order to be able to answer questions about the
distribution of objects within the room or about the
presence/absence of particular objects. The authors found a
clear shift of the ratio of fixation durations and saccadic
amplitudes across the tasks and also over the viewing time.
At the beginning of image inspection fixations with shorter
durations and saccades with longer amplitudes were

2283

measured. With increasing inspection time they reported a
shift to shorter saccades (stabilized after ca. 2s) and longer
fixations (stabilized after ca. 3 to 4s). Similar results were
reported by Irwin and Zelinsky (2002), who discovered a
continuous increase of fixation duration over a period of 15
fixations, but no explanations were offered for the findings.
In fact, already Kahneman (1973, p. 59) discussed the
phenomenon as a kind of paradox: if fixation duration is a
measure of intensity of visual information processing, then
why at the beginning of perception of a new picture when
there is more information to be processed visual fixations
are shorter and not longer?
In still another line of research, visual processing has been
described in terms of two-stage models (Hoffman, 1999;
Norman, 2002; Velichkovsky, 1982). Though earlier
statements can be found (Bernstein, 1947), the distinction of
two routes of visual processing in the brain came to
prominence with a special issue of Psychologische
Forschung in 1967 (Held, Ingle, Schneider, & Trevarthen,
1967). In this publication and in the following years, a
number of dichotomies have been suggested, such as
evaluating-orienting (Ingle, 1967), what-where (Schneider,
1967), focal-ambient (Trevarthen, 1968), examiningnoticing (Weiskrantz, 1972), figural-spatial (Breitmeyer &
Ganz, 1976) and foveal-ambient (Stone, Dreher, &
Leventhal, 1979). Ungerleider and Mishkin (1982) later
argued that in primates vision is dominated by distinct
cortical mechanisms, ventral and dorsal pathways. This
work laid the foundations for the currently dominant model
of dual visual processing (Milner & Goodale, 1995), which
has been developed partly through studies of neurological
patients with selective lesions of brain (Milner et al, 1991;
2003). This later model emphasizes the sensorimotor and
cognitive character of dorsal versus ventral processing.
Surprisingly, the idea of two visual systems has never
been related to the major output of visual processing that is
eye movements. Is it possible that both visual pathways can
selectively influence oculomotor mechanisms and that the
balance of these influences can change flexibly? Assuming
there are indeed different processes accompanied by distinct
eye movement behavior it would be interesting to find a
method for their reliable distinction, for instance, by a
combined consideration of parameters of both, fixations and
saccades. Neurophysiology tells us that dorsal stream areas
can mediate large saccades throughout much of the visual
field on the basis of simple visual properties such as contrast
and location. In contrast to this, ventral stream areas receive
inputs chiefly from central regions of the retina (Falchier &
Kennedy, 2002), but construct a richer, memory-based
representation of the stimulus, including its semantic
properties (Creem & Proffitt, 1999; Milner & Goodale,
1995).
In a recent study of a simulated driving activity in
hazardous conditions, we received evidence that these three
lines of research – scene perception, eye movements and
visual pathways analysis – are much closer tighten together
than it seemed (Velichkovsky et al., 2002). Twelve healthy
and well-trained subjects had to drive in a dynamic virtual
environment fulfilling all the common rules and in
particular preventing accidents. The hazardous events were

sudden changes of traffic lights from green to red,
pedestrians’ appearance on the road and the behavior of
other drivers. The experiment, which lasted for five
consecutive weeks, has allowed collecting a large database
on parameters of eye movements in this dynamic situation
and on their correlation with correct or erroneous reactions
to dangerous events.
First of all, we found that there is a systematic
combination of the visual fixation duration with amplitude
of the following saccades. There have been two distinctive
segments on the scale of fixation durations. The first
segment, with fixations from 90 to about 260 ms, was
related to larger saccades of more than 5 deg that is beyond
the parafoveal region of retina. In other words, these
saccades aimed at targets seen as blobs not as individualized
objects – a strong case for the ambient mode of processing.
Fixations longer than 260–280 ms rather seemed to be
related to focal processing: they initiated saccades mainly
within the parafoveal region where objects are relatively
easily seen and continuously attended. The next major result
of the study was a strong relationship between parameters of
two to three visual fixations that immediately preceded a
hazardous event and subject performance: if such an event
hit them in their ambient processing mode there was a
significantly higher chance for an error than otherwise.

Experiment
In the present study, our goal was to validate the findings
from the previous experiments in a more traditional, static
scene setting. We tried to prove theoretical assumptions
about different memory representations linked with each
mode of processing. The focal mode has to be memorybased because its underlying ventral pathway utilizes stored
representations to identify objects. In contrast, there can be
no extensive storage of visual information in ambient mode
as its underlying dorsal pathway uses, at most, only a very
short-term storage necessary for the execution of immediate
motor behavior (see also Post, Welch & Bridgeman, 2003).
With these assumptions in mind we predicted, that if the
systems can be separated according to eye movement data,
the recognition of scene’s snapshots must differ for
‘ambient’ and ‘focal’ visual fixations.

Method
Subjects Nineteen participants were recruited from
psychology courses at Dresden University of Technology.
Five subjects were removed from the study for their high
false alarm rates in the recognition task (above 80%), and
two were removed due to technical problems with the eye
movement recording. The data reported below were
therefore based on the remaining 12 participants (6 males, 6
females). They either received course credit or € 8 for
participating in the experiment.

2284

Stimuli The materials for this experiment consisted of 48
photo realistic scenes of building interiors. Pictures were
paired (2 x 24) according to their semantic content, color
composition and brightness contrast. One picture of each
pair served as the study picture whereas the other was used

Apparatus Eye movements were recorded at 250 Hz by
using the SR Research Ltd. EyeLink eye tracking system
with on-line detection of saccades and fixations. Fixation
onset was detected and transmitted to the presentation
system with a delay of approximately 12 ms. Pictures were
displayed using a GeForce2 MX card and a CRT display
(19-inch Iiyama Vision Master 451) at 1152 by 864 pixels at
a refresh rate of 100 Hz.
Procedure Subjects began the experiment by reading the
instruction given on the stimulus screen. The same
instruction was presented orally from the computer. After
restating the instruction subjects performed a nine-point
calibration routine. Calibration was repeated if any fixation
point was in error by more than one deg or if the average
error for all points was above 0.5 deg. Subjects were given
initially two study trials in order to get acquainted with the
task. Calibration was repeated every second picture and
each picture presentation was preceded by a drift correction.
The experiment consisted of two blocks of study trials with
12 pictures each. A short break was given between the
blocks.
After 20 fixations (study phase) the picture was removed
and subjects were shown 30 cut-outs – intermixed 20 of the
original picture as well as 10 random cut-outs from the
corresponding catch-trial pair. Subjects had to decide
whether the given cut-out belongs to the previously seen
picture or not. They also had to indicate the certainty of
their answer on a five-point scale by choosing “0”, “25”,
“50”, “75” or “100”. Subjects were unaware that the cutouts were selected according to their fixation positions in
time or in space (see below). Following completion of the
experiment, the participants were given a questionnaire
asking for strategies of the task solution.
A given subject was tested with 24 pictures, 4 in each
condition (screen-centered/original order, screen-centered
/reversed order, screen-centered/random order, fixationcentered/original order, fixation-centered/reversed order,
fixation-centered/random order). Assignment of pictures to
conditions was counterbalanced so that each picture
appeared equally often in each condition across subjects.
The experiment lasted approximately 1 h 15 min.

than 1.5 deg within an image were recognized as refixations
and were also discarded from a further analysis. In sum, this
trimming process excluded 36.5% of all fixations.
As a consequence of the experimental setup subjects’
recognition responses could be classified as “hit”, “miss”,
“false alarm” or “correct rejection” in terms of signal
detection theory. Therefore we converted subjects’
performance data into measures of d’ to compare influences
of presentation order (original, reversed, random),
presentation position (screen-centered, fixation-centered)
and eye movement behavior (fixation duration, saccadic
amplitude, combination of fixation duration and saccadic
amplitude) on recognition performance.
In processing data, we firstly entered the d’ values into a
two-way repeated measures ANOVA to analyze the
influences of temporal order and spatial position. No
significant effects were found, neither for presentation
order, F (2,22) = 0.425, p = .659, nor for presentation
position, F (1,11) = 0.152, p = .704. The interaction of both
factors however was significant, F (2,22) = 3.649, p < .05,
revealing a recency effect that was apparent in reversedorder testing for screen-centered conditions and a spatial
compatibility effect of the cut-out’s position within the
picture but only for random-order presentation. This
interaction will not be discussed here further due to the
nonsignificant main effects.
Figure 1 shows the Median for subsequent saccade
amplitudes for all fixations up to 600 ms. A drop in the
amplitudes of saccades can be seen at around 180 ms.
Therefore fixations longer than 180 ms are labelled
henceforth as long fixations, whereas fixations shorter than
180 ms are categorized as short fixations. Due to the fact
that only objects within a region of circa 5 deg around the
center of the fovea can be processed by (para)foveal vision,
a second cut-off was made at this point (Figure 1, horizontal
dotted line).
9
8
Saccade Amplitude [deg]

to generate random cut-outs in the recognition task (catch
trials). The pictures subtended 25.6 deg horizontally and
19.8 deg vertically. The cut-outs for the recognition task
were 2 x 2 deg in size. Cut-outs were either presented in the
center of the screen (screen-centered condition) or
according to their initial fixation positions (fixationcentered) in the study picture. As a second factor the cutouts were presented either in the order of the fixation
sequence in the study phase (original-order condition), in
the reversed order (reverse-order) or in random order
(random-order). Thus the underlying design was 2 x 3
resulting in 6 conditions.

6
5
4
3
2
1
0
0

100

200
300
400
Fixation Duration [ms]

500

600

Figure 1: Saccadic amplitude as a function of fixation
duration.

Results
In the analysis of eye movement data, only fixations of
duration within the range from 20 ms to 600 ms were
further taken into account. Fixations with distances of closer

7

The one-way repeated measures ANOVAs revealed
significant differences for d’, F (1,11) = 23.967, p < .001,

2285

η2 = .685, for the categorization based on fixation duration
and F (1,11) = 5.416, p < .05, η2 = .330 for the
categorization based on saccade amplitudes. Values for d’
are smaller for shorter fixations (M = 0.78) and larger
saccades (M = 0.84), whereas longer fixations (M = 0.94)
and shorter saccades (M = 0.97) are accompanied by better
discrimination results. The combination of both parameters
again revealed significant differences for d’, F (3,33) =
9.199, p < .001, η2 = .455. As can be seen in Figure 2, the
combination of short fixations with subsequent long
saccades differs significantly from both long fixation
conditions, p < .005, whereas for short fixations followed by
short saccades the significance level is marginally exceeded,
p = .093.

Median of Response Certainty

80
70

50
40
30
20
10

1.6

d′ values

Long Fixations

**

Discussion

1

The results of the study testify that the particular version of
recognition task using very narrow cut-outs of initial scenes
could be afforded by subjects though only with efforts and
with a relatively high proportion of false alarms. It may be
of interest that 5 subjects that demonstrated excessive false
alarm rates and have to be discarded on this reason from
further consideration all had on average a remarkably large
proportion of short fixations, ca. 40 % more than the rest of
the group.
The essential result is of course the clear dependence of
recognition performance on the duration of fixations at
study phase and, to a slightly lesser extent, on their saccadic
context. Here the question is whether these results can be
explained by a gradual accumulation of information over
time of fixation what also could, on the first sight, explain
our results in a dynamic setting (Velichovsky et al., 2002) or
a more complex explanation is needed, one that takes into
account possible qualitative differences between modes of
processing between and perhaps also within separate
fixations.
There are at least two facts that, in our opinion, make this
second hypothesis more parsimonious. First of all, data on
short and long fixations in context of short-range saccades
demonstrate not only a relatively good recognition but also
a subjects’ significantly higher confidence in the correctness
of answers. This pattern of eye movements gives evidence
for focal processing mode so is the recognition performance
that presupposes an involvement of the ventral visual
pathway. An alternative explanation that short saccades may
permit a preview for information in immediate
neighborhood can be rejected because we excluded all
fixations related to saccades with amplitudes of less than 1.5
deg. The second fact is the changing pattern of saccades and
fixations over the time of scene viewing that has been
observed in this study and in a number of earlier works (e.g.
Kahneman, 1973; Unema et al., 2005). The fact is
compatible with the idea that the dorsal system – with its
function of exploring the spatial layout – dominates initially

0.8
0.6
0.4
0.2
0

Short Fixations

Figure 3: Median of Response Certainty relative to the
fixation duration and saccade amplitude combinations.

Long Subsequent Saccades
Short Subsequent Saccades

1.2

*

60

0

1.4

Long Subsequent Saccades
Short Subsequent Saccades

Short Fixations

Long Fixations

Figure 2: Mean d’-values for the four fixation duration and
saccade amplitude combinations.
Of particular interest are therefore data on how subjects
estimated the certainty of their responses in the recognition
task. We aggregated these subjective estimations using the
Median over the four eye movement categories described
above resulting in a pattern similar to that of d’ (see Figure
3). The application of the Friedman test again revealed
significant overall differences for the certainty judgements,
p < .005. Paired comparisons using the Wilcoxon rank
signed test demonstrated statistically significant differences
for the combination of short fixations and subsequent long
saccades from the other three conditions, p < .05.
In a further analysis, we checked up a possible
dependency of fixation durations and saccadic amplitudes
on the viewing time. Replicating previous reports (Irwin and
Zelinsky, 2002; Unema et al., 2005), this dependency has
been indeed confirmed but only for the first 2 to 3 fixations
(saccades) – probably due to a piecemeal character of our
testing procedure. A post-hoc comparison of average
temporal positions of fixation and saccades in the four
categories furthermore revealed that they belonged to the
middle part of the sequence of 20 fixations/ saccades at the
study phase.

2286

the processing of a scene. On this basis and with a time lag,
a more focal, object-directed processing emerges based on
the involvement of ventral visual stream. The hypothesis
that visual information gradually accumulates over time of
fixation would rather lead to wrong predictions (see above).
By comparing these results with data from our driving
simulation study (Velichkovsky et al., 2002), we can see
similarities as well as differences. Firstly, fixations were on
average longer in the dynamic environment. Secondly,
while demonstrating the same global shape, the function
related fixation durations and saccade amplitudes in
dynamic conditions was also extended towards longer times
so that the critical drop that differentiated the ‘short’ and the
‘long’ of fixation durations has been observed at about 300
ms. Both these facts can be naturally explained by a smooth
pursuit component of the most of fixations. Furthermore, in
a dynamic setting there is no asymmetry of eye movement
over time of viewing as the activity is continuous. The
phases of ambient processing (shorter fixations and longrange saccades) are also more apparent. Again, a
parsimonious explanation is that motion in the field biases
the balance of both underlying systems towards motionsensitive dorsal mechanisms. We cannot propose any
account of this fact from the hypothesis of a pure
accumulation of information during the time of fixation.
All evidence for a relationship between eye movements
and the brain mechanisms presented here is indirectly
demanding further studies with measurement of brain
activity. We believe that these studies will finally show that
different topics of the contemporary literature in visual
cognition are not insulated domains but approaches
converging on the same functional and structural
mechanisms.
A word of caution is that the ambient-focal model
certainly is a theoretical simplification as there are
controlling instances ‘above’ the object-oriented focal stage.
In particular, conceptually-driven (semantic), and selfreferential (metacognitive) processes characterize these
mechanisms that residue in the frontal structures of the brain
(Posner, 2004; Velichkovsky, 2002). Furthermore, training
and expertise can lead to the automatization of skills, so that
with time their components can be processed at lower
levels. Nevertheless the model is a useful first
approximation to consider eye movements from the
multilevel perspective. One can expect that higher levels of
encoding may be correlated with longer fixations. Indeed,
levels of encoding in visual memory tasks could be isolated
by the analysis of fixations (Velichkovsky, 1999).

Conclusions
Our data from studies of scene perception in static and
dynamic settings demonstrate a systematic relationship
between parameters of individual visual fixations and
recognition performance. This relationship can be
parsimoniously explained by a balanced control on the part
of dorsal and ventral visual pathways that have different
access to memory representations. If supported by further
studies, this conclusion may lead to a possibility of an online behavioral monitoring of relative dominance in
underlying neurophysiological mechanisms.

Acknowledgments
We gratefully acknowledge discussions with Bruce
Bridgeman, David Milner and Michael Posner. The study
was facilitated by grants from German Science Foundations
(DFG) and BMW AG, Munich.

References
Bernstein, N. A. (1947). O postrojenii dvizhenij [On the
construction of movements]. Moscow: Medgiz.
Breitmeyer, B., & Ganz, L. (1976). Implications of sustained
and transient channels for theories of visual pattern
masking, saccadic suppression and information processing.
Psychological Review, 83, 1-36.
Bridgeman, B., Van der Heijden, A. H. C., & Velichkovsky,
B. M. (1994). A theory of visual stability across saccadic
eye movements. Behavioral and Brain Sciences, 17(2), 247292.
Brooks, R. (1991). Intelligence without representation.
Artificial Intelligence, 47, 139-159.
Creem, S. H., & Proffitt, D. R. (1999). Separate memories for
visual guidance and explicit awareness. In B. H. Challis &
B. M. Velichkovsky (Eds.), Stratification in cognition and
consciousness (pp. 73-96). Amsterdam: John Benjamins
Publishing Company.
Falchier, A., & Kennedy, H. (2002). Connectivity of areas V1
and V2 in the monkey is profoundly influenced by
eccentricity. FENS Abst., 1, A051.058.
Held, R., Ingle, D., Schneider, G., & Trevarthen, C. (1967).
Locating and identifying: Two modes of visual processing.
A symposium. Psychologische Forschung, 31, 42-43.
Hoffman, J. E. (1999). Stages of processing in visual search
and attention. In B. H. Challis & B. M. Velichkovsky
(Eds.), Stratification in cognition and consciousness (pp.
43-71). Amsterdam: John Benjamins Publishing Company.
Hollingworth, A., & Henderson, J. M. (2002). Accurate Visual
memory for previously attended objects in natural scenes.
Journal of Experimental Psychology: Human Perception
and Performance, 28(1), 113–136.
Ingle, D. (1967). Two visual mechanisms underlying the
behavior of fish. Psychologische Forschung, 31, 44-51.
Irwin, D. E. (1992). Memory for position and identity across
eye movements. Journal of Experimental Psychology:
Learning, Memory, and Cognition, 18(2), 307-317.
Irwin, D. E., & Zelinsky, G. J. (2002). Eye movements and
scene perception: memory for things observed. Perception
& Psychophysics, 64(6), 882-895.
Kahneman, D. (1973). Attention and effort. Englewood Cliffs:
New Jersey: Prentice-Hall.
Milner, A. D., Dijkerman, H. C., McIntosh, R. D., Rossetti,
Y., & Pisella, L. (2003). Delayed reaching and grasping in
patients with optic ataxia. Progress in Brain Research, 142,
225-242.
Milner, A. D., & Goodale, M.-A. (1995). The visual brain in
action. Oxford, UK: Oxford University Press.
Milner, A. D., Perrett, D. I., Johnston, R. S., Benson, P. J.,
Jordan, T. R., & Heeley, D. W. (1991). Perception and
action in 'visual form agnosia'. Brain, 114 (Pt 1B), 405-428.

2287

Norman, J. (2002). Two visual systems and two theories of
perception. Behavioral and Brain Sciences, 25(1), 73-144.
O'Regan, J. K., & Noe, A. (2001). A sensorimotor account of
vision and visual consciousness. Behavioural and Brain
Sciences, 24(5), 939-973.
Posner, M.I. (2004). Progress in attention research. In M.I.
Posner (Ed.), Cognitive neuroscience of attention. New
York: The Guilford Press.
Post, R.B., Welch, R.B., & Bridgeman, B. (2003). Perception
and action: Two modes of processing visual information. In
J. Andre, D.A. Owens & L.O. Harvey (Eds.), Visual
perception: The influence of H.W. Leibowitz (pp. 143-154).
Washington, DC: APA.
Rensink, R. A. (2000a). The dynamic representation of scenes.
Visual Cognition, 7, 17-42.
Rensink, R. A. (2000b). Seeing, sensing, and scrutinizing.
Vision Research, 40(10-12), 1469-1487.
Schneider, G. E. (1967). Contrasting visuomotor functions of
tectum and cortex in the golden hamster. Psychologische
Forschung, 31(1), 52-62.
Simons, D. J., & Rensink, R. A. (2005). Change blindness:
past, present, and future. Trends in Cognitive Sciences, 9(1),
16-20.
Stone, J., Dreher, B., & Leventhal, A. (1979). Hierarchical and
parallel mechanisms in the organization of visual cortex.
Brain Research Review, 1, 345-394.
Treisman, A. (1988). Features and objects: The fourteenth
Bartlett memorial lecture. Quarterly Journal of
Experimental
Psychology:
Human
Experimental
Psychology, 40, 201-237.

Trevarthen, C.-B. (1968). Two mechanisms of vision in
primates. Psychologische Forschung, 31, 299-337.
Unema, P. J. A., Pannasch, S., Joos, M., & Velichkovsky, B.
M. (2005). Time course of information processing during
scene perception. Visual Cognition 12(3). 473-494.
Ungerleider, L., & Mishkin, M. (1982). Two cortical visual
systems. In D. J. Ingle, M. A. Goodale & R. J. W. Mansfield
(Eds.), Analysis of visual behavior (pp. 549-586).
Cambridge, MA: MIT Press.
Velichkovsky, B. M. (1982). Visual cognition and its spatialtemporal context. In F. Klix, J. Hoffmann & E. v. Meer
(Eds.), Cognitive research in psychology (pp. 63-79).
Amsterdam: North Holland.
Velichkovsky, B. M. (1999). From levels of processing to
stratification of cognition. In B. H. Challis & B. M.
Velichkovsky (Eds.), Stratification in cognition and
consciousness (pp. 203-235). Amsterdam: John Benjamins
Publishing Company.
Velichkovsky, B. M. (2002). Heterarchy of cognition: The
depths and the highs of a framework for memory research.
Memory, 10(5/6), 405-419.
Velichkovsky, B. M., Rothert, A., Kopf, M., Dornhoefer, S.
M., & Joos, M. (2002). Towards an express diagnostics for
level of processing and hazard perception. Transportation
Research, Part F, 5(2), 145-156.
Weiskrantz, L. (1972). Behavioral analysis of the monkey's
visual system. Proceedings of the Royal Society of London
(Biology), 182, 427-455.

2288

