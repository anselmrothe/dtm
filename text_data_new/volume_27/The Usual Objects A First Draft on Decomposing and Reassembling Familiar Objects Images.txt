UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Usual Objects: A First Draft on Decomposing and Reassembling Familiar Objects Images

Permalink
https://escholarship.org/uc/item/9044p7p8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Pomplun, Marc
Umali, Michelle

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Usual Objects: A First Draft On Decomposing and Reassembling Familiar
Objects Images
Fiora Pirri
Dipartimento di Informatica e Sistemistica,
Università di Roma “La Sapienza”,
Italy, email: fiora.pirri@dis.uniroma1.it

Abstract
We describe in this paper a novel approach to the recognition
of an object (an artifact) in a scene, in which the object appears in the foreground. We assume, in fact, that the camera
has already focused on the object, drawing the attention to it
on the basis of specific object features gathered from the initial
scene. We emphasize the integration of preliminary perceptual processing with reasoning, dealing with ”hypothesis formation”, in particular we introduce an algebra for composing
the elementary figures and a probabilistic graphical model for
reasoning about the composition.

interpret the hypothetical completion made by natural perception to overcome occlusions: resorting to symmetry is indeed
minimal inference. Symmetric views (see Figure 1) are also
useful in the decomposition process: primitive elements are
gathered in a symmetric fashion in the image, allowing for
a further modular, and mental, recomposition of the object
under consideration. In particular we are concerned with a
specific class of objects, namely the usual ones, the familiar
artifacts. Artifacts are composed by parts, even very fancy,
and using primitive components is a great advantage for the
reasoning process that is intrinsically compositional, while
the early image processing works to compact the information.
In this paper we briefly describe how from the very early perceptual processing the goal is to find these primitive components, which are then reassembled according to a model that
exploits the axiomatic structure of an algebra of figures (what
is known about the structure of objects) and a probabilistic
model that plays the role of an associative memory classifying objects according to their features. Finally we give some
conditions under which convergence, toward the recognition
of an object in the scene, is possible

Introduction
Those approaches that emphasize the reasoning process that
takes place in recognition, and are based on previous (not
necessary accurate) knowledge of the objects that have to be
recognized, are traditionally referred to as model based. In
his seminal paper on visual perceptual organization Pentland
[1986] has pointed out that perception is successful because
of an inner structuring of our environment and because of
the human ability to identify the connections between these
environmental regularities and primitive elements of cognition. The model-based approaches to perception have been
strongly influenced by this view (see e.g. Edelman [1997],
Wu and Levin [1993], Pope and Lowe [1993]), despite
more recent approaches address primarily statistical methods that seem to closely model the earlier phases of perception, that are inherently conjugated with learning. Among the
model-based approaches, the constructive approach, known
as recognition by components (RBC), was pioneered by Marr
and Nishihara [1978], Shapiro et al. [1984], Pentland [1986],
Biederman [1987], and finally by Wu and Levin [1993]. An
apparent drawback with the RBC approach is that it supports
a viewpoint-invariant notion of objects visual representation,
while psychological experiments have shown (see e.g. Hayward [1997]) that recognition performance might be affected
by relatively small perturbations in viewpoint. Recently Biederman [2001] has shown that depth rotation costs are predictable from the ease of extracting a matching Geon structural description from the image. We propose a model in
which two (or more) views support a decomposition process
followed by a recomposition one, in which inference is based
on components. Components play a crucial role in the perceptual inference, and their intrinsic symmetry takes advantage
of multiple views. Following the gestaltic emphasis on the
role of symmetry in visual perception, we mirror the image
into its symmetric one and compose the two images to get a
single one gathering the two different views. This seems to

Background concepts

1773

We assume that an early attentive process has directed the
focus of attention towards an “interesting object” (e.g those
illustrated in Figure 1). We also assume that the focus on an
object is not random, and thus different views of the same
object can be taken by the perceptual process, with some reference point in the scene. We make use of classical first order
logic, well known statistical methods from the classification
literature, and concepts from image analysis. More specifically we use the concepts of procrustean transformation (see
Schonemann [1966], Dorst [2005]), of the well-known Kmeans algorithm (see e.g. Duda et al. [2001]), and the notion
of SymGeon, introduced by Patel [2000], as part of a family of related concepts, that have been used in visual recognition, to describe the shape of an object in terms of a relatively few generic components, joined by spatial relationships. Symgeons (see Figure 3) are a generalization of parametric Geons introduced in Wu and Levin [1993], and have
their origins, in the qualitative Geons of Biederman [1987],
and in the computer graphic concept of Superquadrics of
Barr [1981]. The Biederman original Geons are 36 volumetric component shapes described in terms of symmetry, size,
edge, axis as qualitative attributes of generalized cylinders.
Patel [2000] extended the concept of the parametric Geons
considering the possibility to apply the tapering and bend-

Figure 1: From left two right: The picture of a chair (129 × 95, 30dpi) together with its mirror image. Segmentation with
4 clusters, via the k-means using a vector of 6-features (color+gradient) (the clusters number is dynamically assessed by the
image histogram). The image on the black background is obtained by isolating the dominant cluster. The image is regularized
by region growing exploiting the neighborhood variance of a pixel. Edge detection using the well known Canny method, with
0.6 of threshold and σ 2 = 0.7, where the edge pixel values are the gradient direction, see a magnified detail in the last image.
The new images are obtained by symmetry. Critical points are obtained by inspecting the gradient directions.
nel. The image n × m, is transformed into a vector s × 6,
where s = nm. Then according to the number of peaks in
the image histogram, suitably smoothed, we select the initial
centroids of the K-means. The K-means iteratively recompute the centroids according to correlation
between pixels in
p
each cluster, ρ(xi , xj ) = C(xi , xj )/ (C(xi , xi )C(xj , xj ).
Uncorrelated data have a correlation coefficient of 0, and thus
1 − ρ measures the distance of an element versus its centroid.
Let C 1 , . . . , C k be the obtained clusters, since no spatial information is provided in the clusterization, a cluster might
be separated in different patches, i.e. C r = {γr1 , .., γrm },
where γrk denotes a p × 2 vector of the positions (i, j), in
the image, of the pixels Xrk belonging to the k-th patch of
cluster C r . To determine whether further grouping is needed,
a dominant cluster is chosen on
the basis of three parameters.
P p
1) The distance dr = α k (µxk − cx )2 + (µyk − cy )2 )
from the center µk of each patch k belonging to cluster C r to
the center c = (cx , cy ), of the image, with α the normalizing
factor. 2) The area Ar of the maximal patch of the r-th cluster, and 3) the number br of patches in the cluster C r . Then
a dominant cluster C r is the one maximizing the function
f (r) = exp(−(1/2)(br dr /Ar ), note that Ar 6= 0, ∀r, since
empty clusters are deleted during the k-mean processing. Figure 1 illustrates the results of early segmentation when a single object is focused. Let us assume that the dominant cluster
is single-patched, so no further grouping is needed. A new
image X0 with only the chosen cluster is then formed (see
Figure 1). Each pixel x, of X0 , belonging to the dominant
cluster has an intensity value in the range [0, 255], while the
background pixels have value 0. To obtain a symmetric image
of the object components and their contours, for procrustean
analysis, edge detection is augmented with two steps. The
first is regularization and the second is critical points finding.
The regularization process amount to interpolating either intensity pixel or 0-pixels in order to make the image contour
regular. This is achieved, after convolving the image with a
Gaussian filter, by adding a cost q to the 8-connected neighbourhood of a pixel x, according to the following steps. Let:

0 if x > 0
v(x) =
(1)
1 otherwise

ing transformations at the same time, see Figure 3 for a 2d
representation of symgeon faces. We are giving emphasis to
symgeons, because they can be easily represented in 2D as a
composition of primitives made, in turns, by arc of lines and
straight segments, further they can be considered the essential
building blocks of a structuring process like the one we succinctly describe in these pages. We assume that several primitives shape elements are stored as low resolution images in
a background memory, together with axioms of composition
and macro definitions implementing the causal connections
in terms of probability densities. This background memory is
uploaded for three type of inferences: the procrustean transformation selecting the primitive components (called boundits, from the crasis of boundary primitives) that would participate in the mental reconstruction of the analysed object;
the composition process through the network (see the graph
in Figure 5), assigning a structuring composition (i.e. a specific connection operation), and a probability. The graphical
model relates to hierarchical aspect graphs, that were early
introduced in Dickinson et al. [1992], without reference to
probability and causal laws. Finally, inference is performed
by a perspicuous reasoning process concerning both the history of views and composition using the figures axioms. The
paper is organized as follows. In the next section, early segmentation of the foreground scene (in the hypothesis that the
image represents a focused object) is described. Then we introduce the procrustean transformation that would find the association with boundits, which are the primitive components
of the process. Then we show how to define a network of
aspects exploiting both causal laws and composition axioms,
finally we discuss the use of a background memory. Some
hints on the implementation conclude this short paper.

Early decomposition
Segmentation The main goal in the object decomposition
phase is to group non structural features, such as regions and
lines, to recover directions for the structural elements, such as
the boundits that we use as primitive components for geons.
In this section we propose early segmentation based on Kmeans (see Duda et al. [2001]), to circumscribe edge detection. Let X = {x1 , . . . , xn } be the pixels of the image where
x ∈ R3 , according to the three channels RGB. We augment
each pixel with the gradient ∇R, ∇G, ∇B over each chan1774

The cost of regularization of a pixel x, is q(x) = |(1 −
Q
P8
P
i v(xi ))
i>1 kv(xi−1 )v(xi+1 ) −
i=∈{2,4,,6,8} v(xi )|,

where k = mod(i, 2) + 1, i = 1 = 9 is the left-top
square in the 8-connected neighbourhood, and the direction
is clock-wise. For example if the neighborhood of pixel x
105 0 0
is: 111 x 0 Then v(x2 ) = v(x3 ) = v(x4 ) = 1, and for
68 72 46
i ∈ {1, 5, 6, 7, 8} v(xi ) = 0, hence q(x) = 2v(x2 )v(x4 ) −
v(x2 ) − v(x4 ) = 0, as in fact the border is smooth. To minimize the cost of a pixel x, w.r.t. its neighbourhood, the neighbour pixels xi are labelled with |v(xi ) − 1|.
Decomposition After regularization, the image borders are
more clean, and thus edge detection can be performed successfully. But to maximize the opportunity of finding components features the image is reflected, each of the two mirror
images are cut along the y-axis of symmetry, and two new
images are created (see Figure 1 for the RL(right-left) one).
Using Canny methods, that finds edges by looking for local
maxima of the gradient of X, using the derivative of a Gaussian filter, we keep the gradient direction of the image Eo ,
exploited for non maxima suppression, to find critical points:
see the last image in Figure 1, showing the magnification of
the detail of the gradient directions, appearing framed in the
last but one image. For the standard deviation of the Gaussian
filter we have used a value of 0.7 and for the high threshold
the value of 0.2. The pixels corresponding to critical points
are then labeled; the set of labeled pixels is denoted by S,
and we call these pixels cuts. Finally, after a further transformation of the image into a logical one, obtained by simply
setting intensity values > 0, to 1, a set of connected paths is
built for the successive Procrustes analysis as follows.
Definition 1 Given a logical (0, 1) image, s.t. each pixel is
at most 2-connected, a path of size k, denoted by ∼k , between
two pixels is defined as follows: xi ∼1 xj if they are both 1.
A path of size n, xi ∼n xj if there exists a pixel z = 1 s.t.
xi ∼1 z and z ∼n−1 xj .

Figure 2: Procrustes transformation: a component of the cutgraph (first picture) is transformed into an eal boundit depicted in the second image, the third image is the result of the
procrustean transformation, with weight 3.

Figure 3: On the left the set of 9 volumetric symgeons. On
the right the face-wise components of the symgeons.
in Figure 4. Therefore GOPT is not the case, because for simple matrices like those for boundits, E is always a matrix of
zeroes. For the simple orthogonal case the steps to compute
the transformation are the followings, obtained by adding to
EE > the Lagrangian λ(T > T − I), to ensure orthogonality,
and then equating to zero the derivative of the resulting function. Let X be the matrix of the graph of xi and let Y be
the matrix of the graph of any of the 7 boundits illustrated in
Figure 4, both matrices are transformed into array (i, j)> of
the position in the matrix of the pixels x = 1, suitably normalized; so let A and B be these corresponding n × 2 arrays:

We thus define the graph of a pixel x ∈ {0, 1} as follows:

A = A − 1n µ, B = B − 1n µ
>
M = AB
U ΛU > = svd(M > M )
V ΛV > = svd(M M > )
T = V U>
B ? = AT
E = B − B?

δ(x) = {y |∃z.x ∼k y ∧ y ∼n−k+1 z ∧ {x, z} ⊆ S and
∀w.x ∼k w ∧ w ∼n−k+1 z→w 6∈ S}
(2)
In other words we require that the graph of a pixel is between
two cuts, note also that ¬(x ∈ δ(y)→y ∈ δ(x)), but x ∈
δ(y)→∃z.z ∈ δ(y) ∧ z ∈ δ(x).

Fitting the primitives to memory
Primitives and Procrustes transformation The orthogonal Procrustes problem consists in transforming a matrix A
into a matrix B by an orthogonal transformation T so that
the sum of squares of the residual matrix E = AT − B is
a minimum (see Schonemann [1966], Dorst [2005]). The
problem can also be set in a more general way such as a
transformation accounting also for scaling and traslation, i.e.
E = cAT +1N t> −B, called the generalized orthogonal Procrustes transformation (GOPT). To find the set of primitives
in the images so as to build a network for components aggregation it is crucial to use the Procrustes transformation to get
a similarity measure between the graph δ(x) of pixel x (see
previous Section) and that of one of the 7 boundits illustrated

(3)

The results are illustrated in Figure 2.
E = [e1 e2 ] a similarity measure s is defined as s =
pGiven
P 2
( i ei1 + e2i2 ), where e is a n × 1 vector. The boundit for
which s is minimal is chosen.

Recomposition
The background knowledge and the structuring process
The structural relationships among terms (boundits, faces and
symgeons) and their underlying axiomatization constitutes an
Algebra of Figures F, which is a multi-sorted algebra defined
as follows:
Sorts: P = {B, F, G}. Here P is the set of primitives; in
particular B is the set of Boundits; F is the set of Faces; and
G is the set of SymGeons;

1775

Operations: Ω = { , ⊕P , ⊕E , ⊕F , {{? iX }i≤n }X∈R }
Here
is the concatenation operator; ⊕P is the pointwise
connection operator; ⊕E is the edgewise connection operator; and ⊕F is the facewise connection operator; finally,
{{? iX }i≤n }X∈R is a family of n-ary operators, specifically
used to describe the object construction: R is a set of relations between primitive elements, in the image scene. Given
the algebra, we define a theory of 2D shapes based on three
sets of axioms: FG ∪ FF ∪ FC , which are the Grouping Axioms, Figure Axioms, and Connection Axioms. The Grouping Axioms are introduced to specify the properties of the
terms, the properties of the operators, and the properties of
connections, so as to exclude non valid connections, e.g. the
end points of a boundit with the side of a cylinder, inducing
shapes formed by components which are represented in different dimensions, see Table 1. The grouping axioms are the
fundamental axioms of the algebra fixing the laws for building the figure terms. The Figure Axioms are used to specify
the shapes that can be obtained, by using primitives and operators. Finally, the Connection Axioms specify the metric over
the terms of the algebra, obtained introducing a notion of distance for each operator. Together with these axioms a set of
background knowledge axioms specify the way familiar objects are composed using the structuring elements.
For example the components of the armchair given in Figure 1 are legs, arms, back, seat and each of these components,
a part from the dimension, have several shapes, but essentially
few composition laws. In real life objects, any classification
has to deal with a tremendous variety of shapes, that would
make impossible any object recognition without some drastic simplification, which indeed can be dealt with by defining
structuring rules. Background axioms state how an object is
structured through connections, according to different views;
in fact, as we noted in the introduction, it has been shown that
the recognition of qualitatively distinct objects often relies on
viewpoint-dependent mechanisms; while the molar features
of view-based mechanisms are modeled through the background memory. A view is a term that is meant to capture
the viewpoint- dependent mechanism. The following axiom,
as an example of a background knowledge axiom, says that
an armchair is composed of four elements a back a seat, legs,
and arms which are seen under the current view, in the current observation state (snapshot) s, or the chair was already
perceived in the previous view. Finally the four components
are built through boundits, aspects and symgeons.
∀x view s. armchair(x, view ◦ s) ≡ ∃g1 g2 G3 g4 .
x = back(g1 ) ⊥(seat(g2 ) ⊥ legs(G3 ) aarm `arm)∧
G3 = k1 k2 k3 k4 ∧
a(k1 , k2 , view) ∧ `(k3 , k4 , view)∧
∃x0 view0 . `(x, g4 , view0 ) ∨ a(x, g4 , view0 )∧
x0 = x `arm’(g4 ) ∨ x0 = x aarm(g4 ) ∨ armchair(x, s)∧
back(g1 ) ∈ Γ1 ∧ seat(g2 ) ∈ Γ1 ∧ leg(g3 ) ∈ Γ1 ∪ Γ3 ∧
arm(g4 ) ∈ Γ1 ∪ Γ2
(4)
Here Γ1 = {cylindroid, cuboid}, Γ2 ={bended-cylinder,
bended-cuboid}, Γ3 = {horn,pyramid}.
Observe that
⊥(x, y, view) specifies the structuring relation between
two image components under a single view, while

Figure 4: The set of possible Boundits

Table 1: ⊕E linear connection, ⊕P connection, ⊕E elliptic
connection
back(g1 ) ⊥(seat(g2 ) ⊥legs(G3 )) specifies the connection
between the structuring elements (i.e. it is a function of the
points distance). We now illustrate the structuring relations
pointwise connection and linear edgewise connection, which
implicitly define also the operators ⊕P , ⊕E and ⊥. In particular, the ⊥ operator is binary, non transitive, non symmetric,
non reflexive, and non commutative. Table 1 illustrates connections between boundits, that are either pointwise, meaning that only the end points of the segments are connected,
or edgewise, that is, there is a whole segment in common between the two boundits.
Connections and the inference Network We introduce a
simple definition for the operators ⊕P and ⊕E , let the pointwise connection pwc and the linear edge-wise connection
ewc, be defined as follows, where the βs and αs are boundits, taking points on the plane, as arguments, and d is points
distance:
pwc(p, p0 , q1 , q2 ) = minij [d(p, qi ) + d(p0 , qj )], i 6= j
ewc(p, p0 , q1 , q2 ) = minij [l(p, p0 )l0 (qi , qj )+
m(p, p0 )m0 (qi , qj )] + pwc(α1 (p, p0 ), α2 (qi , qj )), i 6= j
(5)
Here l, m are the direction cosines of the lines through the
points p, q. The operators ⊕P and ⊕E are defined as follows
∆

β1 ⊕P β2 = ∃ s view.obs(β1 , β2 , view ◦ s)∧
∃x x0 y y 0 .{x, x0 } ∈ β1 ∧ {y, y 0 } ∈ β2 ∧
δ(x) = δ(x0 ) ∧ δ(y) = δ(y 0 ) ∧ (x ∈ δ(y) ∨ x0 ∈ δ(y))∧
∀z z 0 w w0 .z 6= x ∧ . . . ∧ w0 6= q.→
pwc(z, z 0 , w, w0 ) > pwc(x, x0 , y, y 0 )
(6)
The above sentence says that given the current view, two
boundits have a unique possible pointwise connection, in
their extreme points which are the closest. The composition

1776

say that T |=V γ, where V is the domain of the current view
(only symmetric) for the specific image. Figure 6 illustrates
the inference of a bended cuboid, which is the back of the
arm-chair.

of boundits is the basic step for structuring elements in the
image. The following specify the edge wise connection:
∆

α1 ⊕E α2 = ∃ s view.obs(α1 , α2 , view ◦ s)∧
∃x x0 y y 0 .{x, x0 } ∈ β1 ∧ {y, y 0 } ∈ β2 ∧ δ(x) = δ(x0 )∧
δ(y) = δ(y 0 ) ∧ ∃z.z ∈ δ(x) ∧ z ∈ δ(y)∧
∀z z 0 w w0 .z 6= x ∧ . . . ∧ w0 6= q→
ewc(z, z 0 , w, w0 ) > ewc(x, x0 , y, y 0 )
(7)
An inference network of figures T = (X, F, {βi }, π), is
a graphical model of the composition of the elements in the
image (see Figure5); here X is the binary symmetric image,
obtained by segmentation and edge detection, F is the algebra
of figures, defining the connection among each component
(boundits, aspects, symgeons) {βi } is the set of boundits in X
obtained by the Procrustes analysis, and π is the probability
density given for each βi . Nodes of T are labeled by figures
and edges are labeled by operators. Thus the root nodes of
the network are the βi ; two boundits are connected by a ⊕P
operator if some of their elements share the same graph (this
comes from the definition of ⊕P ). A node is labeled by an aspect α if there are boundits βi , βj that can form it according
to the rules in F. Analogously, a node is labeled by a symgeon γ if there are aspects allowing for its definition. Since
the boundits emerge from a complex perceptual process their
likelihoods depend on observing the graph of a set of pixels
X, while all other components are obtained by composition,
hence by conditional probability tables. The likelihood for
the boundits is specified as follows. Let X = {x1 , . . . , xn }
be a set of pixel, s.t. xi identifies the position (i, j), suitably
normalized, the probability that X will be classified as one of
the seven boundits βi , depends on the miss distances of each
point from the template tβ = {x01 , . . . , x0m }. By the Procrustes analysis we found that the residuals E1 , E2 are these
error distances. For any error distance e
fE1 (e1 )fE2 (e2 ) = h(e21 + e22 )

Background memory The background memory serves to
support or reject the inference in the network of figures, by
associating a probability model, to each familiar object, specified by a set of features. Note, in fact, that the network of
figures is used to compose symgeons not to arrange objects,
as it supports only composition laws (like pwc, ewc, etc..)
but not relational properties like orthogonality, parallelism
etc. Therefore, in some sense, the network of figures is a
low level inference process. For objects composition a more
complex network is needed, according to the composition axioms, as the one defined for the armchair (see 4). In order to
account for the probability concerning such an involved network of objects, we appeal to the features that can distinguish
an object, as a mean to disambiguate the structuring process,
and to support preferential reasoning. Indeed, let F be a
feature array, in a d-dimensional space, and let F1 , F2 and
F3 be three independent set of features, relative to any specific familiar object, which are aggregated because of some
specific component. For example F1 = {color, texture},
F2 = {connections, typology-of -components}, F3 =
{views, association-f eature-context}, F 0 = ∪i Fi is thus
a reduced array of features components. Clearly this is an
ideally defined feature space, actually one deal at most with
intensity, and texture, as already basic shapes are difficult to
associate with a distribution model. For each Fi we define the
state conditional probability distribution π(Fi |g, θ) depending on the state of nature identified by the familiar object g,
which can be classified, so that two objects g1 and g2 are similar or dissimilar according to the probability of explaining a
set of features. Therefore given a perception, memory is used
to establish the likelihood of the observed features, according to the suggested reconstruction. For example, suppose
that F = f1 , . . . , fk are the observed features which, under
the structuring process, would converge to object g, then if
π(g|F ) < π(g 0 |F ) one might want to reconsider the structuring process. Or the other way round, given a classification of
the observed data, the structuring process might further specify the classification.

Differentiating with respect to e1 and then to e2 , and dividing the result by the previous equation, we get fEi (ei ) =
(d/dei ) log fEi (ei ) = wei , with w a constant; integrating we
get that fEi (ei ) = k exp(we2i /2), and for w = −1/σ the
normal density is obtained. Since E1 and E2 are independent, then the probability for a single point in the plane to
match a boundit is a bivariate normal random variable. We
conclude that to each element βi ∈ T a normal distribution
is associated, with parameters µ = 0 and σ 2 estimated from
E, the residuals of Procrustes analysis. Then for any other
figure α in the network π(α|β1 , . . . , βn ) = π(α|βi , βj ) if
βi , βj ∈ δ(α), and for no other β 0 , β 0 ∈ δ(α) where, indeed,
δ(α) is the graph of the set of points belonging to the structural boundit elements of α. Note that for each node ν in the
network, but for the root nodes (the boundits), a conditional
probability distribution is specified, according to the laws of
composition. For example considering all the possible ways
two aspects, such as those depicted in the third line of Figure 3, can be chosen to compose a cylindroid, a multinomial
would be chosen.
We say that a figure network has a feasible solution γ if any
node belongs to a defined component and there exists a node,
labeled with γ, and such that γ ∈ F. If γ is a solution then we

Explaining the data

1777

The visual explanation process is essentially abductive (see,
e.g., Shanahan [2004]) since visual perception is hypothetical, non axiomatic and stochastic, as it depends on the state
of nature. Here we give a definition of the visual explanation process and state its possible uniqueness under different
views. In other words the process is correct if it converges
to the recognition of the same object under different views,
given the hypothesis that each view is determined by an attentional mechanism that it is not random, and focuses on
the same scene area. Let sk be the final perceptual state, i.e.
sk = viewk ◦ . . . view1 ◦ s0 . Let us define the scene as
S = I(sk ) ∪ F (sk ), where I(sk ) is the image under all the
views view1 , . . . , viewk and F (sk ) is the specification of the
real features of the scene determined by the observer and coherent with the background knowledge and the background

object obj whose probability of explaining the scene features
is given by π(F |obj, θ, sk ), furthermore π(F |obj, θ, sk ) >
π(F |obj 0 , θ, sk ) for any objects in the class of F .
After the constraints the proposition is pretty obvious,
however it ensures some criteria of soundness in the recognition process involving several phases, quite different in formal and analytical terms.

Discussion and conclusions
In this paper we have presented a novel method for amalgamating into a single experiment different steps of recognition concerning a single, usual, artifact. Obviously a huge
amount of open problems, remain to be solved. The method
have been implemented in Matlab and in Eclipse-prolog (ICPark). A further contribution of the paper is in trying to solve
the invariant-view problem that affects recognition by components, specifying how different views can build together a
history of views that reinforces, by making it cumulative, the
recognition process. The process has been experimented on
several single object in the center of the image. Images are
usually taken from the Corel Library.

Figure 5: A network of Figures: boundits, aspects and symgeons, the probability of the last shape depends on the probability of its parent. The probability of an initial element depends on the procrustean transformation.

References

memory. Let G = {g1 , . . . , gm } be elements obtained as a
result of inference in a T network, and obj(G, sj ) be the definition of an object in terms of G, as for example the definition
of armchair in (4). Let π(F |obj(G), θ, sj ) be the probability
that object obj(G, sj ) (where sj is suppressed) explains the
features under the model θ, let
π(F |obj(G), θ, sj )π(obj(G)|θ, sj−1 )
P
π(F |θ, sj )
whenever obj(G, sj ) = obj(G, sj−1 )
(8)
That is, the probability is Bayesian if the structuring process
is coherent, and two successive observations lead to the same
composition process. Now, let T be the network of figures
as described in the previous section, and let M be the background memory (as described in the previous paragraph.
We say that T ∪ M explains the scene S iff:
π(obj(G)|F, θ, sj ) =

1.
2.
3.
4.

T ∪ M |= obj(G, sk )
π(F |obj(G), θ, sk ) ≥ π(F |obj(G), θ)
for any object in the class of F
T ∪ M |= obj(G, si ) ≡ obj(G, sj ), i 6= j
π(F |obj(G), θ, sj ) = π(F |obj(G), θ, sj−1 ),

(9)

The last condition says that the process should be cumulative, and thus each view leads to the recognition of the same
object. The above requirements can be extended to more than
a single object.
If the properties described above are satisfied then the process will converge toward a unique object explaining the features indicated by the observer. Therefore:
Proposition 1 Let S be a scene, as defined previously. Let
R = T ∪ M be a recognition process, with T , and M specified as above, and let π be a state conditional density concerning the observed features, with parameters θ. If R satisfies the 4 conditions listed in 9 then R will recognize a unique
1778

A. Barr. Superquadrics and angle-preserving transformations, 1981.
Irving Biederman. Recognition by components - a theory of human image understanding. Psychological Review, 94(2):115–
147, 1987.
Irving Biederman. Recognizing depth-rotated objects: A review of
recent research and theory. Spatial Vision, 13:241–253, 2001.
S. Dickinson, A. Pentland, and A. Rosenfeld. 3d shape recovery
using distributed aspect matching. PAMI, 14(2):174–198, 1992.
Leo Dorst. First order error propagation of the procrustes method
for 3d attitude estimation. IEEE Transaction on Pattern analysis
and machine intelligence, 27(2):221–229, 2005.
R. O. Duda, P. E. Hart, and D. G. Stork. Pattern Classification. John
Wiley and Sons Inc., 2001.
S. Edelman. Computational theories of object recognition. pages
296–304, 1997.
Tarr Michael J. Hayward, William G. Testing conditions for viewpoint invariance in object recognition. Journal of Experimantal
Psychology, Human Perception and Performance, 1997.
D. Marr and H. Nishihara. Representation and recognition of the
spatial organization of three-dimensional shapes. In Proc. R. Soc.
Lond. B, vol. 200, pages 269–294, 1978.
P. O’B. Patel, L. N. & Holt. Modelling visual complexity using geometric primitives. Orlando, July 2000. Proceedings, Systemics,
Cybernetics and Informatics.
A. Pentland. Perceptual organization and the representation of natural form. Artificial Intelligence, 28(2):293–331, 1986.
A.R. Pope and D.G. Lowe. Learning object recognition models from
images. In ICCV93, pages 296–301, 1993.
Peter H. Schonemann. A generalized solution of the orthogonal procrustes problem. Psychometrika, 31(1):1–10, 1966.
M. Shanahan. A logic based formulation of active visual perception.
In Proceedings of KR2004. 2004.
L. G. Shapiro, J. D. Moriarty, R. M. Haralick, and P. G. Mulgaonkar.
Matching three-dimensional objects using a relational paradigm.
Pattern Recognition, 17(4):385–405, 1984.
Kenong Wu and Martine Levin. 3D object representation using parametric geons. Technical Report CIM-93-13, CIM, 1993.

