UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Longevities of Policy-Shifts and Memories Due to Single Feedback Numbers

Permalink
https://escholarship.org/uc/item/3k91m624

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Bachman, Mandy L.N.
Munnich, Edward L.
Ranney, Michael A.

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Longevities of Policy-Shifts and Memories Due to Single Feedback Numbers
Edward L. Munnich (emunnich@usfca.edu)
University of San Francisco, Psychology Department, 2130 Fulton Street, San Francisco, CA 94117

Michael A. Ranney (ranney@cogsci.berkeley.edu)
University of California, Graduate School of Education, 4533 Tolman Hall, Berkeley, CA 94720-1670

Mandy L. N. Bachman (mandybachman@hotmail.com)

University of California, Graduate School of Education, 4533 Tolman Hall, Berkeley, CA 94720-1670

Abstract
What proportion of people in the U.S. are imprisoned? Would
knowing this number affect one’s views on U.S. justice?
Policy-makers, voters, and consumers need a sense of such
quantities to help shape effective policies, and schools must
prepare students for such roles. Our past research has
documented changes in individuals’ numerical concepts—and
often their views on issues—after they received a single
critical number. In the experiment, we examined eighth grade
students within the Numerically-Driven Inferencing paradigm
(NDI), using an experimental method (EPIC) in which
participants: Estimate policy-relevant quantities, state
Preferences for these, briefly receive actual quantities as
feedback to Incorporate, and offer preferences again that may
exhibit any policy Changes. Students were then asked (postEPIC) to recall the actual number and indicate their current
preference for the quantity—either eight or 84 days after they
received the feedback. Memory for the actual values was
considerable after eight days, and still evident after 12 weeks.
Further, feedback-triggered policy shifts were also evident
after both eight and 84 days post-feedback. Therefore, recall
and policy shifts spawned by minimalist interventions––
briefly viewed solitary numbers––can have substantial
longevities.
Keywords: Belief Revision; Conceptual Change; Decision
Making; Estimation; Mental Models; Reasoning.

Please write down an answer to the following: Out of every
1000 U.S. residents, how many are currently incarcerated
(in prison, jail, or juvenile hall)? Next, reflect on how you
reached your estimate. Now, think of what you would prefer
the number to be. The true number is seven per thousand;
does learning this actual statistic change your preference
(whether massively or modestly)? Finally, to the extent that
your preference changed, how do you think your new
preference would persist or fade as you have time to digest
the number over the coming days or months? This last
question is the present work’s main focus.
Individuals differ greatly in their preferences for policyrelevant statistics, but there are some common patterns.
While some may protest that incarceration is an issue of
justice, and not “just” one of numbers, rhetoricians know
that a well-placed number can often sway opinion. If a
newspaper reports that Country X has achieved domestic
tranquility without incarcerating a single person, most of us
1553

would likely react with some mix of hopefulness that there
might be ways of accomplishing this in our own country,
and/or suspicion that the full truth was not told. Similarly, a
report that half of Country Y’s population is incarcerated
would likely provoke disbelief that such a large proportion
of people could be guilty of noteworthy crimes, and likely
outrage at a government that would yield such a situation. In
both examples, most readers would find the numbers
surprising, and—were the source of the numbers credible—
this surprise might provoke them to revise some of their
beliefs, and perhaps to become more or less active regarding
an issue.
Along these lines, Ranney, Cheng, Nelson, and Garcia
de Osuna (2001) and Munnich, Ranney, Nelson, Garcia de
Osuna, and Brazil (2003) have reported feedback-triggered
policy
shifts––changes
in
preference
that
are
disproportionate in regards to contemporaneous beliefs
about the value’s magnitude. To illustrate by way of
contrast, suppose a person thought that six people per 1000
were incarcerated and preferred the number to double to 12
per 1000; finding out that the true number is seven would
not be very surprising, and might lead to only a
proportional rescaling of the preference (i.e., still preferring
a doubling, thus 14). However, those whose estimates are
off by larger amounts often undergo policy shifts: Say, one
initially thought one out of every 1000 were incarcerated
and preferred that the number be three; upon learning that
the correct number was seven, a common response is to
indicate a revised preference that the number remain at
seven. In this case, it would certainly be correct to note a
shift in preference from three to seven, but this would miss
the more interesting point that the participant has made a
notable policy shift—initially preferring a tripling of the
incarceration rate, but shifting to a status quo policy after
receiving feedback. Such policy shifts suggest that people
have implicit beliefs about plausible ranges for a quantity
(cf. Ranney et al.’s, 2001, “non-surprise intervals”), and
evidence contradicting such beliefs yield surprise, leading
them to change their beliefs and desires regarding the focal
issue. We assess a numerical policy (e.g., a wish to halve––
or triple––a quantity) by eliciting one’s preference (e.g.,
“What would you prefer the number to be?”) and dividing it
by what one believes the value to be. (See Garcia de Osuna,
Ranney, & Nelson, 2004, for more discussion of the

qualitative and quantitative natures of such surprisetriggered shifts, regarding the topic of abortion).
A host of experiments based on the Numerically-Driven
Inferencing paradigm (NDI; Ranney et al., 2001) have now
shown marked policy shifts resulting from a single number
(including Garcia de Osuna et al., 2004; Lurie & Ranney,
2005; Munnich et al., 2003; Ranney et al., 2001), and
therefore contrast with findings discussed by Chinn and
Brewer (1993), among others, which indicated that
conceptual changes are difficult to effect. Going beyond the
existence of policy shifts, this paper addresses how durable
policy shifts are: Do those who shift policies immediately
after receiving feedback maintain the new policies over
time? It could be that we feel obliged to express shock when
we hear surprising numbers, but we might later return to our
usual ways of thinking. Were this the case, then what appear
to be policy shifts may be relatively transient experimental
effects. On the other hand, to the extent that policy shifts
persist, they provide evidence of stable, substantive, belief
revision resulting from the receipt of a single, surprising,
feedback number.

Theoretical Framework
NDI builds on work in many fields, including estimation,
attitude, conceptual change, mental models, and judgment
and decision-making (although NDI deals with base rates
directly—not through Bayesian analyses). For instance, NDI
builds on studies regarding the numerical concepts a person
has, as indicated by the estimates one produces. Estimates
have been found to draw on a variety of sources, including
category information (e.g., Huttenlocher, Hedges, &
Prohaska, 1988), relevant “seed” numbers (e.g., Brown &
Siegler, 2001), and underlying magnitude representations
(e.g., Dehaene & Marques, 2002). However, NDI goes
beyond the numerical-concepts literature to consider how
such notions of quantities relate to preferences and attitudes
on a variety of issues. Specifically, our group examines how
understandings of relevant numerical information (e.g., the
incarceration rate) affect public policy opinions (e.g., what
would one prefer the incarceration rate to be, and why?).
We suppose that qualitative attitudes have some—albeit not
necessarily direct—relationships with relevant quantities,
and we aim to explore the nature of those connections. By
focusing on people’s conceptions of quantities, NDI can
shed light on how such concepts interact with people’s
initial attitudes, and the extent to which learning true values
shapes subsequent attitudes.
Even when considering the same issue, one can arrive at
strikingly different estimates and policies, depending on the
issue’s framing (cf. Schwarz, 1999). When Munnich et al.
(2003) asked for the number of abortions per million live
births, the median response was 33.5 times too low. (Indeed,
Ranney et al., 2001, with a larger sample, found it to be 67
times too low.) If their estimates were so far off, how were
participants’ preferences impacted? Rather than discount the
feedback, they showed an overall policy shift—a 64% more
reductive policy than they had initially indicated. In
1554

contrast, when participants estimated the number of
abortions per million fertile women, the median estimate
was much more accurate—half the actual number––so for
this item variant, rather than shift policies, people more
often just rescaled their preferences to adjust to their new
understanding of the number. In other words, when a
quantity (e.g., an abortion rate) is framed in different ways,
accuracy in estimating the quantity is affected, and this
strongly influences people’s preferences after they learn the
true number.
More broadly, NDI has ties to work in scientific
conceptual change, including the Theory of Explanatory
Coherence (TEC; e.g., Ranney & Thagard, 1988; Thagard,
1989). TEC describes change as spawned by incoherence
and inter-idea conflicts, such that people try to revise their
beliefs in order to increase global coherence. For example,
Ranney, Schank, Mosmann, and Montoya (1993; based on a
misconception noted by Keysar, 1990) found that most
participants initially believed that Berlin lay on the
East/West German border, but revised their beliefs as they
incrementally received information that could be used to
disconfirm the “on-the-border” hypotheses. (E.g., they were
told/reminded of the Berlin airlift, the Western Allies’
agreement to halt their troops far west of Berlin, Berlin’s
location within united Germany, and the northern and
southern ends of the border.) With each successive piece of
evidence, participants moved toward a more accurate view
of Berlin’s location relative to the border, suggesting that
they modified their belief networks to maintain coherence in
the face of the new information. In this vein, and relating to
studies on metacognitions about one’s estimates (e.g., Soll
& Klayman, 2004, on overconfidence), Munnich, Ranney,
and Appel (2004) found that a curriculum that fosters
counterarguments to one’s own initial estimates can lead to
improved estimations of novel quantities.

Numeracy and Policy: Elicitation and Hypotheses
According to TEC, accepted evidence that is critical and
germane carries considerable weight in our belief systems.
Within NDI, we seek to understand when and how a special
kind of proposition that meets these criteria—numerical
evidence—can catalyze knowledge-transformations. To
address NDI, Ranney and colleagues have developed
various methods, including EPIC (Estimate-PreferIncorporate-Change; see the top four cells of Table 1): (1)
Participants estimate a quantity that is relevant to an issue;
for instance, we asked our (California) students for the
number of U.S. citizens registered to vote per 1000 18-24
year olds. (2) Participants indicate what they prefer the
quantity to be. (3) Participants later receive correct base rate
feedback to incorporate (507 of every thousand 18-24 year
olds are registered). Finally, (4) participants indicate again
what they prefer the quantity to be––telling us whether their
preferences changed after learning the actual number. We
have found that, to the extent that feedback is surprising, it
generally leads to nontrivial belief revision (e.g., Lurie &
Ranney, 2005). However, previous studies of EPIC-induced

changes have focused on rather short periods of time (e.g.,
under two hours in Ranney et al., 2001), so an obvious
extension is to note what happens with numerical
conceptions and policies over longer periods.
Numerical Recall First we consider how well
participants recall numbers they receive as feedback after
some delay. Had students not received any feedback, we
would expect their subsequent estimates to be randomly
distributed around their original estimates; this would also
be the case if they fully forgot the feedback they received.
On the other hand, if they recall numbers that show
distributional movement (relative to initial estimates) in the
direction of the feedback they received, the result would
show some memory of the feedback. This leads to the
Improved Item Numeracy Hypothesis: After receiving
feedback, participants may recall numbers that differ from
their initial estimates, and show movement in the direction
of the feedback.
Policy Shift Persistence To capture the contingency of
preference on one’s numerical beliefs at a given time, we
represent policy as a ratio between one’s numerical
preference and what one believes the base rate to be at that
time (e.g., Munnich et al., 2003; Ranney et al., 2001).
Specific policy formulas are summarized as follows:
Initial Policy = Initial Preference / Estimate
Feedback-Present Policy =
Preference at Time of Feedback / Actual Number
Delayed Policy = Preference at Recall / Recalled Number
In order to determine whether one’s policy shifted, we
compute policy ratios. Such a ratio is the degree to which a
policy changed between two points (e.g., between the start
and feedback; between feedback and recall; or overall):
A Policy Ratio = A Later Policy / An Earlier Policy
Note that proportionally rescaling one’s preference yields a
policy ratio of one; for instance, consistently preferring
halving a value entails a policy ratio of 0.5/0.5=1. Policy
shifts are thus signaled by policy ratios that are significantly
greater or less than one (e.g., preferring no change initially,
then later preferring a doubling: 2/1=2).
In the present work we sought to elicit policy shifts like
those observed in earlier studies, and then observe whether
they persisted over time. As with the recall of the numbers
themselves, if people were never given feedback any
subsequent policies they indicated would be expected to
cluster randomly around their original policies. This result
would also be expected if participants reverted to their
initial policies some time following the receipt of feedback,
either because (a) they forgot the feedback that had
prompted them to adopt new policies in the first place––and
it no longer had an effect, or (b) as they had time to digest
the feedback, they no longer believed that the base rate
warranted a policy shift. In both such cases, although people
may indicate policy shifts at the time of feedback, they

1555

would be the products of a momentary surprise, and would
not constitute lasting revisions of policy beliefs.
In contrast to these scenarios, if delayed policies move
away from the set of original policies, and toward the
policies formed at the time of feedback, it would suggest
that policy shifts persist beyond the point of feedback. This
leads to our second hypothesis, the Persistent Policy Shift
Hypothesis: Policy shifts that occur during the EPIC
procedure are long-lasting (i.e., endure one or more weeks),
as evidenced by the movement of delayed policies toward
the policies people formed when feedback was present,
relative to the set of initial policies. To the extent that policy
shifts persist beyond the point of feedback, it indicates that
feedback produced a relatively permanent change in
people’s belief networks, such that future policy-making
will be affected by the shift that took place when feedback
was given.
Table 1. EPIC-RP procedure steps for one item.
Estimate
Out of 1,000 U.S. Citizens between the ages of 18 and 24,
estimate the number of people who were registered to
vote in the presidential election in the year 2000.
____________ out of every 1,000 U.S. citizens were
registered to vote in the 2000 presidential election.
Indicate Preference
Imagine you had the power to change this amount. Give
your preference for the number of registered voters
between the ages of 18 and 24.
___________ out of every 1,000 U.S. citizens would
have been registered to vote in the 2000 presidential
election.
Incorporate feedback
According to the U.S. Census Bureau,
507
out of
every 1,000 U.S. citizens between the ages of 18 and 24
were registered to vote in the 2000 presidential election.
Change?
(Identical to Preference above)
Retention interval: 8 days/12 weeks
Recall Feedback
Out of 1,000 U.S. Citizens between the ages of 18 and
24, try your best to remember the number of people who
were registered to vote in the presidential election in the
year 2000.
____________ out of every 1,000 U.S. citizens were
registered to vote in the 2000 presidential election.
Change?
(Identical to Preference above)

Method
This study’s participants were 95 eighth-grade Algebra I
students from three consecutive class periods at a San
Francisco Bay Area middle school. All students received

four “common” items (Voter Registration, Immigration,
Incarceration, Athlete’s Salary), and four of 12 other items
that were each given to one-third of the students.
Two items in the EPIC format were presented each day
over a four-day period. (See Table 1 for format, and Table 2
for a complete list of items.) For each item, students first
estimated a quantity. Next, they indicated their preferences
for the estimated quantity. Participants then received
feedback (the true value) to incorporate, and had the
opportunity to revise their preferences in light of feedback.
Beginning eight days after the first EPIC items were
presented, an “RP” extension of EPIC was administered––in
which students were asked to recall the numbers they
received on the first day and again to indicate their
preferences. The following (tenth) day, participants were
asked to recall, and give preferences for, the numbers they
had received on the second EPIC day. Eleven weeks later,
participants were asked to recall the feedback for, and give
preferences for, the remaining four items (over two days).
Thus, four EPIC-RP item sequences were completed after
eight days’ delay, and four more after 84 days.

Results
Improved Item Numeracy Hypothesis
We first considered whether recalled numbers moved in the
direction of the feedback numbers that participants received
(indicating that feedback influenced people’s recall).
Overall, participants’ delayed recall showed a tendency
towards the feedback values, relative to their initial
estimates: After eight days, 201 of the 271 (74%) applicable
responses moved towards the feedback value; after 12
weeks, 148 out of 218 (68%) did so. We tallied the
proportions of students for each question whose recall value
moved in the direction of the feedback (including those who
overshot it) and found that, after both eight days and 12
weeks, majorities of students on all eight questions recalled
a number that moved in the direction of the feedback
(Binomial p<.01). Thus, we observed a reliable pattern of
movement in the direction of the feedback value among a
majority of participants––and over both time delays,
supporting the Improved Item Numeracy Hypothesis. Table
2 summarizes estimates, true values (feedback), and recallvalues by question, but we urge caution in interpreting its
medians.1
1
That is, another, inferior, way of testing for movement in the
direction of feedback is to consider whether the medians move in
the direction of the true value. For the numbers recalled eight days
after feedback, median recall values diverged from estimates in the
direction of the true value, for seven out of eight questions
(Binomial p<.05). For numbers recalled 12 weeks after feedback,
though, median-based analyses are not sufficiently sensitive––and
even misleading––as median recall values diverged from estimates
in the direction of the true value for only three out of the five items
that showed medial movement (of the eight items; ns). However,
closer examination of the patterns of recall by individual
participants reveals that it was quite common for, say, two people
to give estimates that straddled the feedback value; if each moved
toward the feedback value at the recall stage, but one moved more

1556

Persistent Policy Shift Hypothesis
Having examined participants’ recall after eight days and 12
weeks, we determined whether feedback-driven policy shifts
endured. If the feedback-present policies did not persist over
a delay, we would expect the delayed policies to be
indistinguishable from the initial policies (i.e., people would
have returned to their original policies). In contrast, policy
shifts should be seen as persistent if the delayed policies
move toward feedback-present policies, relative to students’
initial policies. Overall, participants’ delayed policies
showed movement towards feedback-present values: After
eight days, 183 of the 271 (68%) of the applicable responses
moved towards the feedback-present value; after 12 weeks,
126 out of 218 (58%) did so. Correspondingly, the
proportions of students whose delayed policies moved in the
direction of their feedback-present policies show that the
majority demonstrated this pattern for all eight questions
after eight days (Binomial p<.01), and for seven out of eight
questions (Binomial p<.05) after 12 weeks. Paralleling item
numeracy findings, we saw reliable movement in the
direction of the feedback-present policy among a majority
of participants over both delays, which supports the
Persistent Policy Shift Hypothesis. Table 2 summarizes
initial, feedback-present, and delayed policies, by question,
but we again urge caution in interpreting its medians.2

Discussion
Preferences are central to human cognition, and many
propositions inform our social preferences (e.g., Ranney &
Schank, 1998). In particular, numerical policies offer
cognitive scientists compact, useful, sources of evidence
regarding individuals’ conceptual changes. Moreover, voters
and candidates may form preferences that conflict with what
they would otherwise prefer if they ignored base rates.

than the other, their median recall might actually diverge from the
feedback value, relative to the median estimate! Since an analysis
of medians potentially indicates divergence from feedback
numbers for cases like this—in which both participants actually
approached the feedback—we consider the analyses reported in the
main text to be of greater value.
2
Similarly to our analysis of delayed recall, we considered what
happened with median delayed policies For the policies elicited
eight days after feedback, median delayed policies diverged from
initial policies, moving in the direction of the feedback-present
policies, for seven out of eight questions (Binomial p<.05). For
policies elicited 12 weeks after feedback, though, median delayed
policies moved in the direction of the feedback-present policies for
only five out of seven items for which the median policy changed
(of the eight items; ns). As with assessing the prior hypothesis,
considering median policies obscures underlying patterns by
offsetting effects of participants who actually gave delayed policies
that moved asymmetrically in the direction of the feedback-present
policies. In concert with the item numeracy results, we, therefore,
consider the analyses reported in the main text to be the most
informative.

Table 2. Summary of medians1,2 for estimates, true values, recall values, and corresponding policies; 100% = status quo policy.
Question

US Voter Registration

Estimate

600

Initial
True
Feedback-Pres.
Policy
Policy
Value
Recall and Policies 8 days after feedback
137%
507
177%

Recall
Value

Delayed
Policy

500

167%

per 1000 Young Adults

US Legal Immigration3

460

125%

3

19999%

7

931%

418

222%

275

364%

300

300%

8 Hrs
$19K
$20K
30
899

125%
35%
50%
33%
111%

6.9 Hrs.
$18K
$19,560
25.5
980

130%
54%
77%
39%
101%

6.9 Hrs.
$18.6K
$19,500
25
800

133%
51%
71%
30%
104%

$1 Mil.
300

85%
67%

per 1000 Residents

College Degrees
per 1000 Adults

US Sleep per Night
Public University Cost
Toyota Camry Price
US One-Way Commute
Households with TV(s)
per 1000 US Households

US Male Athlete Salary
US Incarceration

$1 Mil.
450

Recall and Policies 12 weeks after feedback
73%
$2.5 Mil.
81%
80%
7
100%

per 1000 Residents

Female Teachers

600

100%

833

60%

600

95%

25 lbs.

35%

4.5 lbs.

67%

16 lbs.

30%

$2750
647

49%
125%

$5785
510

39%
181%

$2750
750

28%
130%

1,075

85%

1,183

85%

900

69%

135

56%

150

37%

140

47%

per 1000 Teachers

Garbage Production
per day per US resident

Inflation: 1962 vs. 2002
US Computers
per 1000 Households

US Cars
per 1000 Drivers

Non-diet Soda Calories

NDI theory proposes that estimates and numerical
preferences are outputs of our belief systems—the tips of a
“reasoning iceberg” (Ranney et al., 2001). Underlying the
estimates and preferences, one’s understanding of an issue
may be thought of as a network of ideas connected by
personal experiences, media, religion, etc. When asked to
estimate, say, the incarceration rate, few can simply recall it.
Instead one usually activates various propositions about
crime rates and law enforcement that shape the estimate.
Likewise, numerical policy for a given item/topic is,
metaphorically, an output from an extensive belief network
that lies below the surface of overt response. For example,
one might believe one’s incarceration estimate to be
acceptable and simply reiterate it as one’s preference (a
status quo policy). However, if later surprised by the true
incarceration rate, one’s sense of reality is challenged, and
one might decide that the prior reasoning was incorrect or
incomplete. In this conception, the iceberg’s hidden “bulk”–
–the belief network from which estimates and numerical
preferences emerge––may be transformed by the feedback’s
impact. To extend the metaphor, imagine an object hitting
an iceberg, causing much of the ice to fall off: The new
contours thus created are analogous to the post-feedback

numerical concepts and policies that result when one
encounters surprising numbers. In like fashion, NDI can
offer rich findings to cognitive scientists interested in the
dynamics of belief networks.
The present study demonstrated that numerical feedback
was memorable, and that it had lasting effects on policies.
As might be expected, effects were perhaps more prominent
after eight days than after 12 weeks. However, even at 12
weeks, students recalled whether they had initially over- or
underestimated, as indicated by movement in the correct
direction over both delays. Similarly, even after 12 weeks,
students’ policies moved in the direction of the policies they
formed while looking at the feedback numbers. (Space
prohibits a detailed discussion here, but our results also
showed correlations between feedback recall and policyshift maintenance, and that, while one may be slightly more
likely to retain the feedback than one’s new policy, a change
in one’s policy may be more likely to remind one of the
feedback than vice versa.)
Skeptics would be correct to point out that few
participants maintained the exact policy they formed at the
time of feedback, and that few recalled the exact feedback
numbers. Does this diminish the importance of the present

3
Extremely high feedback-present policies suggest that students either misinterpreted this question or had a grossly distorted impression of
the U.S. immigration rate. Analyses were carried out with and without this item, but there was no difference in significance.

1557

findings? We think not, for the following reasons: First, it is
important to note that these eighth-graders were exposed to
the true value for each item for less than five minutes, and
the fact that they showed effects of this brief exposure 12
weeks later would delight most parents and teachers.
Second, in the parallel case of Ranney et al. (1993), it is
notable that many students reached a veridical
understanding of the location of Berlin only as the result of
the cumulative effect of several facts they were given. If we
were to give multiple pieces of numerical feedback in
follow-up studies, we expect that each piece of information
would increase the odds of a broader restructuring of
people’s belief networks. Incorporation of each new datum
might be likened to a minor impact for the metaphorical
iceberg, leading to a slight change in its mass distribution;
although the effect of any single event might be minor, a
succession of such events may cause a dramatic shift,
yielding new features or exposing previously hidden ones.
Prior to the present work, a variety of experiments from
our laboratory had shown that a single number can lead to
striking shifts in numerical policy preferences. This stood in
contrast to work suggesting that conceptual shifts were
relatively rare (see Chinn & Brewer, 1993, among others).
Until now, though, it was unclear how long such new
orientations would last—that is, whether they represented
belief revisions or fleeting adjustments that would fade
shortly after the experiment. The present findings of
persistent numerical concepts and policy shifts indicate that
a transformative belief revision can be sparked by a single
number.

Acknowledgements
We thank Jake Disston and his students, Dan Appel, Luke
Rinne, Christine Diehl, Sujata Ganpule, Janek Nelson, Patti
Schank, Michelle Million, Jed Stamas, Daniel Wolf-Root,
Kelvin Chan, Sasha Raskin and rest of the UCB Reasoning
Group for their helpful comments. This work was funded by
a UCB faculty research grant and an AERA/IES
Postdoctoral Fellowship.

References
Brown, N. & Siegler, R. (2001). Seeds aren’t anchors.
Memory & Cognition, 49, 405-412.
Chinn, C. & Brewer, W. (1993). The role of anomalous data
in knowledge acquisition: A theoretical framework and
implications for science
instruction. Review of
Educational Research, 63, 1-49.
Dehaene, S. & Marques, J. (2002). Cognitive euroscience:
Scalar variability in price estimation and the cognitive
consequences of switching to the euro. The Quarterly
Journal of Experimental Psychology, 55A(3), 705–731.
Garcia de Osuna, J., Ranney, M., & Nelson, J. (2004).
Qualitative & quantitative effects of surprise:
(Mis)estimates,
rationales,
&
feedback-Induced
preference changes while considering abortion.
Proceedings of the Twenty-sixth Annual Conference of the

1558

Cognitive Science Society (pp. 422-427). Mahwah, NJ:
Erlbaum.
Huttenlocher, J., Hedges, L., & Prohaska, V. (1988).
Hierarchical organization in ordered domains: Estimating
the dates of events. Psychological Review, 95, 471-488.
Keysar, B. (1990). East meets west at the Berlin wall:
Mental maps and the changing world order. Unpublished
data.
Lurie, N., & Ranney, M. (2005). The effects of estimates
and base rates on preferences and preference change:
How thinking about what is can influence what one wants.
Manuscript submitted for publication.
Munnich, E., Ranney, M., & Appel, D. (2004).
Numerically-Driven Inferencing in Instruction: The
Relatively Broad Transfer of Estimation Skills.
Proceedings of the Twenty-sixth Annual Conference of the
Cognitive Science Society (pp. 987-992). Mahwah, NJ:
Erlbaum.
Munnich, E.., Ranney, M., Nelson, J., Garcia de Osuna, J.,
and Brazil, N. (2003). Policy shift through NumericallyDriven Inferencing: An EPIC experiment about when
base rates matter. Proceedings of the Twenty-fifth Annual
Conference of the Cognitive Science Society. (pp. 834839). Mahwah, NJ: Erlbaum.
Ranney, M., Cheng, F., Nelson, J., and Garcia de Osuna, J.
(2001). Numerically driven inferencing: A new paradigm
for examining judgments, decisions, and policies
involving base rates. Paper presented at the Annual
Meeting of the Society for Judgment & Decision Making
Ranney, M., & Schank, P. (1998). Toward an integration of
the social and the scientific: Observing, modeling, and
promoting the explanatory coherence of reasoning. In S.
Read & L. Miller (Eds.), Connectionist models of social
reasoning and social behavior (pp. 245-274). Mahwah,
NJ: Erlbaum.
Ranney, M., Schank, P., Mosmann, A., & Montoya, G.
(1993). Dynamic explanatory coherence with competing
beliefs: Locally coherent reasoning and a proposed
treatment. In T.-W. Chan (Ed.), Proceedings of the
International Conference on Computers in Education:
Applications of Intelligent Computer Technologies (pp.
101-106).
Ranney, M., & Thagard, P. (1988). Explanatory coherence
and belief revision in naive physics. Proceedings of the
Tenth Annual Conference of the Cognitive Science Society
(pp. 426-432). Hillsdale, NJ: Erlbaum.
Schwarz, N. (1999). How the questions shape the answers.
American Psychologist, 54, 93-105.
Soll, J. & Klayman, J. (2004). Overconfidence in Interval
Estimates. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 30(2), 299-314.
Thagard, P. (1989). Explanatory coherence. Behavioral and
Brain Sciences, 12, 435-502.

