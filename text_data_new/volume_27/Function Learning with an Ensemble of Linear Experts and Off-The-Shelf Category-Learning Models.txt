UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Function Learning with an Ensemble of Linear Experts and Off-The-Shelf Category-Learning
Models

Permalink
https://escholarship.org/uc/item/6b5992vr

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 27(27)

Authors
Harris, Harlan D.
Hasson, Uri
Johnson-Laird, P.N.
et al.

Publication Date
2005-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Function Learning with an Ensemble of Linear Experts and
Off-The-Shelf Category-Learning Models
Harlan D. Harris (harlan.harris@uconn.edu)
University of Connecticut at Storrs
Department of Psychology; 406 Babbidge Road, Unit 1020
Storrs, CT 06269 USA

John Paul Minda (jpminda@uwo.edu)
University of Western Ontario
Department of Psychology
London, ON N6A 5C2 Canada
In experimental investigations of function learning,
several properties of the human capacity for function
learning have been discovered. For example, functions
that are linear (in an appropriate psychological space)
are easier to learn than functions that have curvature,
functions that increase are easier to learn than functions
that decrease, and extrapolation is less accurate than
interpolation (Busemeyer, Byun, Delosh, and McDaniel
1997).
Several different categories of models have been used
to explore function learning. Briefly, rule-based models
perform mathematical regression given the stimuli (Koh
and Meyer 1991), exemplar models use interpolation and
extrapolation techniques to generalize over stored examples (Busemeyer, Byun, Delosh, and McDaniel 1997; DeLosh, Busemeyer, and McDaniel 1997; Guigon 2004),
and gating models learn a piecewise-linear approximation to the function using simple experts and a gating
module (Kalish, Lewandowsky, and Kruschke 2004).
Experimental results have generally not been consistent with the predictions of rule-based models, and they
have generally been left behind. Exemplar models, such
as ALM (Busemeyer et al. 1997) and EXAM (DeLosh
et al. 1997), have been more promising, but cannot account for multi-modal patterns of extrapolation results
seen when multiple functions are learned simultaneously
(Lewandowsky et al. 2002). The POLE (Population
Of Linear Experts) model of function learning (Kalish,
Lewandowsky, and Kruschke 2004) is an attempt to address this. POLE is a complex model which uses a large
number of fixed linear experts, controlled by a gating
network. The gating network learns which experts are
most accurate for particular input domains, then gates
the experts in a probabilistic manner. POLE can replicate the multi-modal patterns, but has significant flaws
(summarized in the discussion) that limit the extent to
which its results support its laudable framework.
The work presented here is an effort to improve on
some of the basic assumptions of POLE, by using wellunderstood computational models of category learning
as major components of the model. These models account for a wide variety of categorization phenomena,
and their use as components of this new work allows it
to be better tied to research regarding attention allocation, exemplar and cluster formation, and other important aspects of concept and skill acquisition.
The remainder of this paper describes two new,

Abstract
The relationship between function learning and other
types of concept acquisition is far from well understood.
Some models of function learning have used approaches
that are very different from current models of categorization, while more recent function learning models have
used exemplar representations, following the categorization literature. This paper describes two new models
of function learning that combine well-studied ‚Äúoff-theshelf‚Äù approaches to category learning (ALCOVE and
SUSTAIN) with recent work in knowledge partitioning.
These models are shown to perform basic function learning tasks, to partition knowledge of functions, and to be
capable of addressing some individual differences in attention and generalization.

Introduction
Although most research in concept learning focuses on
learning of discrete categories, people also learn functions of continuous variables. Cognitive tasks such as
estimating how long you can stay in the sun before
you burn, or how much a used car might be worth, require prediction of a quantitative value, given a combination of qualitative and quantitative cues. Laboratory tasks in the literature include prediction of the rate
of spread of wildfires, given windspeed and slope, and
prediction of the amount of food aliens might require,
given size and physical attributes. Formally, function
learning is the task of learning a mapping from a multidimensional domain space to a continuous value. For
the purposes of this paper, we are concerned with the
mapping (C1 , . . . , Cn‚àí1 , Rd ) ‚áí Rr , where the Ci are binary cue features, and Rd and Rr are the domain and
range respectively of the function to be learned1 . This
framework can occur when the function to be learned is
partitioned, or separated into a number of subfunctions,
each of which is learned separately. For example, one
type of animal may require a lot more food as its size
increases, while another type may require only a little
more food. Recent work has shown that both category
and function learning tasks often involve partitioning of
knowledge to particular contexts (Lewandowsky, Kalish,
and Ngang 2002; Lewandowsky and Kirsner 2000).
1
Experimental research into cognitive function learning
has not yet carefully investigated how and when people learn
functions of two or more continuous variables. Extensions of
the models presented here could potentially make interesting
predictions about performance on these tasks.

905

X
ahid
= exp[‚àíc(
Œ±i |hji ‚àí Ii |r )q/r ]
j

Output Selection

(1)

i

Gk =
Expert1

Expert2

Input1

..

Expertk

Gating
Network

X

gkj ahid
j

(2)

j

Each input Ii is compared to the exemplars, hj i,
weighted by each attribute‚Äôs attention value, Œ±i , and
transformed by an exponential function with parameters c, q, andr, giving ahid
j , the activation of each hidden
(exemplar) unit. These activations are then transformed
through a weight matrix (gk j) to get G, the activation of
the k gating nodes (equivalent to aout
K in ALCOVE). G
is then used to compute the ensemble output probability
distribution:

Input2 .. Inputn

Figure 1: AEGLE and SEGLE function learning systems, block diagram. For AEGLE, the gating network
is ALCOVE; for SEGLE, it is SUSTAIN.

exp(œÜGk )
P (O = Ok ) = P
= G0k
(3)
exp(œÜG
)
z
z
O is the overall ensemble output, and Ok is the output
of each of the simple linear experts, computed as:

closely-related algorithms for modeling function learning, based on the concepts underlying POLE and the
mixture-of-experts algorithm from the neural network
literature (Jacobs, Jordan, Nowlan, and Hinton 1991)
but combined with well-understood psychological models of category learning as the gating component. These
models account for a number of the effects observed in
function learning experiments, and suggest new ways to
explore this rather complicated set of behaviors. The
next two sections introduce these new models, followed
by an overview of some basic simulations performed using the models, and some concluding analysis.

Ok = wk I1 ‚àí bk

(4)

where wk and bk are each expert‚Äôs weight and bias.
When the ensemble is learning, a teaching value is
then used to update the model‚Äôs weights. Each expert‚Äôs
error is minimized using a variation on the usual LMS
rule, where the error is the normal sum-squared error.
The weight and bias update rules are modulated by the
gating values (G0k ), so that an expert that made a large
error would be updated only minimally if it was unlikely
to have been selected. Additionally, the use of momentum (m) speeds up learning, and an adjustment to the
bias update rule slows down learning so as not to overwhelm the weight updates when learning rates are large.

AEGLE
‚àÜwk = (‚àÜwk ¬∑ m) + Œ∑w (T ‚àí Ok )G0k I1
The first new model is called AEGLE, for ALCOVEbased Ensemble of Gated Linear Experts. It uses, as
a core component, the ALCOVE (Attention Learning
COVEring map) model of classification (Kruschke 1992).
ALCOVE learns to classify using an exemplar-based representation, with error-driven changes to weights and
attention. AEGLE is thus a model of function learning that uses a well-studied model of classification as its
gating network. Figure 1 shows its overall architecture.

‚àÜbk = (‚àÜbk ¬∑ m) ‚àí Œ∑w (T ‚àí

Ok )G0k

mean(I1 )

(5)
(6)

where Œ∑w is the learning rate, T is the training signal,
and mean(I1 ) is the average value of the inputs to the
experts.
Then, the teaching signal (target vector) for the gating
network is computed as follows:
(|T ‚àí Ok | + )Œ∏
,
(7)
maxz [(|T ‚àí Oz | + )Œ∏ ]
where  is a very small number to prevent division by
zero, and Œ∏ is a parameter. That is, the target value
is near 1 when the expert made only a small prediction
error, relative to the other experts, but near 0 when the
expert made a large prediction error, relative to the other
experts. The updates to weights and attention are the
normal ALCOVE update rules:
Tk0 =

The experts are simple Least-Mean-Square (LMS) linear nodes, receiving only a single real value as input.
The gating network gets all input attributes, and learns
to predict which experts will perform well for each example. Both the experts and the gating network learn
in an error-driven manner.
The input is vector I1 , . . . , In , where I1 is a distinguished real-valued feature in [0, 1], used as the input to
the experts, and I2 , . . . , In are boolean context features,
used only as inputs to the gating network.

‚àÜgkj = Œ∑g (Tk0 ‚àí Gk )ahid
j
XX
‚àÜŒ±i = Œ∑Œ±
[ (Tk0 ‚àí Gk )gkj ]ahid
j c|hji ‚àí Ii |

When a stimulus arrives at the gating network, it is
processed exactly as in ALCOVE:

j

906

k

(8)
(9)

Ckout =

Note that Œ±i is constrained to be non-negative.
The initial values of the expert weights are selected
from a normal distribution. As positive-sloped functions
are easier to learn, that distribution has mean 1 and
standard deviation 2. The biases are initially set to 0.5.
The initial values of the gating network‚Äôs weights are as
follows: Œ±i = 1, gkj = 0. Following ALCOVE, we use
the training examples to set the exemplar nodes, hji .
Table 1 summarizes the parameters for AEGLE.
Summary. AEGLE is a mixture-of-experts learning
model, using the standard ALCOVE classification model
as a gating module, and commonly-used linear LMS
nodes as experts. Like POLE, it does gated piecewiselinear approximation based on an exemplar representation of the stimulus space. Unlike POLE, it uses relatively standard computation and update rules for the
experts and for the gating module.

exp(d Ckout )
P (O = Ok ) = P
= G0k
out )
exp(d
C
z
z

winner = argmaxHjact

(13)

(H act
)Œ≤
out
Hwinner
= P winner
act
Œ≤
j (Hj )

(14)

out
Hnotwinner
=0

(15)

(16)
(17)

These equations are the same as those shown in (Love
et al. 2004), except that ¬µ is computed for scalar rather
than nominal inputs, and then a running average is computed. SUSTAIN‚Äôs rule for updating Œª, the tuning of
cluster receptive fields, does not converge for scalar inputs that get arbitrarily close to the cluster prototype
(Brad Love, personal communication), and this averaging allows convergence.
The teaching signal for the SUSTAIN-based gating
module is the same vector Ti0 as used for ALCOVE in
AEGLE. After computing the teaching signal, the expert
weights are updated (as with AEGLE), then the following steps occur to update the gating network: update
pos
the prototype for the winning cluster, Hwinner
; update
the attention tuning vector, Œª; and update the weights,
wjk . Those steps are notated as follows:

The second new model is called SEGLE, for SUSTAINbased Ensemble of Gated Linear Experts. It uses
the SUSTAIN (Supervised and Unsupervised STratified
Adaptive Incremental Network) model of classification
(Love, Medin, and Gureckis 2004) in essentially the same
framework as AEGLE. SUSTAIN has a similar architecture to ALCOVE, but uses incrementally-created clusters as the internal representation of the input, rather
than exemplars. The allocation of attention also differs,
as noted below. SEGLE thus extends AEGLE by using a newer model of categorization, one that builds a
multiple-prototype model of the stimuli rather than using a large number of arguably implausible exemplars.
The SUSTAIN gating network is initialized with a single cluster prototype, the location of the first training exemplar. The position of a cluster in the instance space is
given by the vector Hjpos . The weights wkj for the first
cluster are initialized to n1 .
When making a prediction, the following steps occur:
update ¬µÃÑj , a vector of the average distances (one per input dimension) of the exemplars to each cluster; compute
Hjact , the activation of each cluster; do winner-take-all
and compute Hjout , the output of each cluster; compute
Ckout , the activation of each gating unit. Then, as with
AEGLE, compute P (O = Oi ) = G0 and select an expert to make a prediction. These steps are expressed
algebraically as follows:
(10)

wkj Hjout

j

SEGLE

pos
¬µij = |Ij ‚àí Hij
|
X
1
¬µij ) + (1 ‚àí Œ≥)¬µÃÑj
¬µÃÑj = Œ≥(
j i
Pn
(Œª )r e‚àíŒªi ¬µj
act
Pn i
Hj = i=1
r
i=1 (Œªi )

X

pos
pos
‚àÜHi,winner
= Œ∑g (Ii ‚àí Hi,winner
)

(18)

‚àÜŒªi = Œ∑g e‚àíŒªi ¬µÃÑij (1 ‚àí Œªi ¬µÃÑij )

(19)

Œ∑g Hjout (Tk

(20)

‚àÜwjk =

‚àí

Ckout )

SUSTAIN has two modes for adding new clusters. Either new clusters can be added when an exemplar is too
dissimilar to existing clusters, or they can be added when
the error on an exemplar is too high. Here, we use the
first method, an unsupervised approach. (The second,
supervised method, is too sensitive to instability in the
act
gating network‚Äôs training signal.) When Hwinner
< œÑ,
a new cluster is added, with center equal to the offending example, and with gating weights set so that it will
initially prefer to use experts that are rarely used:
P
( j wjk )‚àí1
P
P
wnew,k =
(21)
‚àí1
z(
j wjz )
The only significant changes to SUSTAIN for its application to SEGLE are the averaging of ¬µ to allow convergence, the weights for new clusters, and the method
used to generate a training signal. All other details of
processing and learning are identical. See Table 1 for a
summary of SEGLE‚Äôs parameters.
Summary. Like AEGLE, SEGLE is a mixture-ofexperts learning model. It uses a variant of the SUSTAIN classification model as its gating module, and
shares the same LMS experts as AEGLE. Unlike AEGLE and POLE, its gating module uses SUSTAIN‚Äôs
dynamically-created clusters as its internal representation instead of exemplars.

(11)
(12)

Simulations
Four simulations show that AEGLE and SEGLE can account for a number of properties of function learning
seen in experiments.
907

Table 1: Parameters for AEGLE and SEGLE
Param.
Œ∑w
Œ∑g
Œ∑Œ±
c
œÜ

AEGLE
Description
expert learning rate
gating learning rate
attention learning rate
specifity
decision consistency

Value
free
free
free
free
free

Œ∏
r
q

gating target exponent
distance metric
similarity gradient

2
1
1

Param.
Œ∑w
Œ∑w

SEGLE
Description
expert learning rate
gating learning rate

r
d
Œ≤
œÑ
Œ∏
Œ≥

attentional focus
decision consistency
cluster competition
new cluster threshold
gating target exponent
¬µ decay constant

Value
free
free
free
free
free
free
2
0.1

Simulation 1
Following (Kalish et al. 2004), the parameter space
of SEGLE was explored to confirm that it finds the
same functions difficult as people do. Over 20,000
models with parameters selected randomly were taught
seven functions. The free parameters were selected
from the following ranges: r ‚àà [.1, 4], Œ≤ ‚àà [1, 10], d ‚àà
[1, 10], Œ∑g ‚àà [.01, 1], œÑ ‚àà [.1, 1], Œ∑w ‚àà [.01, 1], m ‚àà [0, 1].
5 experts were used in all cases. The seven functions,
all with domain and range in [0, 1], were (a) random,
y = random; (b) positive linear, y = x; (c) negative linear, y = 1 ‚àí x; (d) monotonic increasing, y = x2 ; (e)
monotonic non-decreasing, y = 12 + 8(x ‚àí 21 )3 ; (f) nonmonotonic quadratic, y = 1 ‚àí 4( 12 ‚àí x)2 ; and (g) cyclic,
y = 12 + .2 sin(20x).
After training on 5 blocks of 60 examples each, the
mean-squared error on the training examples were computed, and used to rank the difficulty of each function.
Experimental work has shown a ranking of b < c < d ‚àº
e ‚àº f < g ‚àº a. Over the very wide range of parameters explored, over 21% matched this ordering. All of
the first six of the principles described by (Busemeyer
et al. 1997) were confirmed: 90.6% of the models found
cyclic and random functions most difficult, 94.5% found
positive linear functions easier than negative linear functions, 98.6% found monotonic increasing functions easier than non-monotonic functions, and the linear function was easier than the monotonic increasing function
77.0% of the time. All of these patterns are similar to
those observed in POLE, although we explored a significantly larger area of the parameter space, reducing
overall accuracy.
These results show that over a fairly wide range of
parameters, SEGLE finds similar sorts of functions difficult, and easy, as do humans learning functions in the
lab.

Response

1

Training
Testing

0.5

0
0

0.5
Stimulus

1

Figure 2: Performance of SEGLE on a replication of the
effect seen in Kalish et al. (2004), Exp. 1. Small dark
circles are the training examples, while large dark circles
are SEGLE‚Äôs responses on the final training block. Small
light circles are the predicted ideal responses to the test
stimuli, and the light diamonds are SEGLE‚Äôs responses
to those stimuli.
learned the slope of the line better than did the expert
used for x < 0.5.

Simulation 3
In addition to partitioning based on sub-ranges of the
input attribute used to make the function prediction,
SEGLE can partition based on an external cue. POLE
was not explicitly tested on this sort of function, although it should be able to learn it, so new stimuli were
created to illustrate this ability.
The stimuli consisted of a binary cue, c ‚àà {0, 1}, and a
domain variable that ranged from 0 to 1. The function to
be learned was y = 12 (1+x2 ) if c = 0, and y = 12 (1‚àíx2 ) if
c = 1. 33 examples repeated in 10 blocks were presented
to SEGLE. The parameters, which required almost no
tuning from an initial guess, were as follows: r = 1, Œ≤ =
10, d = 10, Œ∑w = .15, Œ∑g = .8, m = .8, experts = 8, œÑ = .5.
The results from a typical run of the simulation are

Simulation 2
To account for the sort of knowledge partitioning described by (Lewandowsky et al. 2002), POLE was shown
to extrapolate in a discontinuous manner when there
was a gap between qualitatively different segments of the
training examples (Kalish et al. 2004, Exp. 1). SEGLE
also easily shows this effect, as shown in Figure 2. Note
the discontinuity at x = 0.5. The expert used for x > 0.5
908

1.2

0.6
0.4
0.2
0
-0.2
0

0.2

0.4
0.6
Stimulus

0.8

0.25

Figure 3: Performance of SEGLE on a cue-partitioned
function. Lines are the two target functions, and the performance on the last of 10 blocks of training are shown.

CA/FR Ratio 6
5

0.2
4

0.15

3

0.1

2

0.05

1

0
0

1

Training Error
Criterial Attribute
Family Resemblance

1
0.5
1.5
c (Specificity of Exemplar Activation)

2

CA/FR Attention Ratio

Response

0.8

cue=0, target
cue=0, SEGLE
cue=1, target
cue=1, SEGLE

"Error" from Ideal Responses

1

0

Figure 4: Results showing performance of AEGLE on
Minda and Ross (2004) cued function-prediction task.
Lines with symbols and error bars show similarity to
‚Äúideal‚Äù responses, if only CA or only FR information was
used. The CA/FR attention ratio (axis on the right) is
high if most of the attention is on the CA attribute.

shown in Figure 3. On the last block of training, SEGLE
showed close fidelity to the target function, correctly using the cue to partition the experts (with the exception
of one gating error at x = 0.59). Note that performance
on the downward-sloping part of the c = 1 function was
worse than elsewhere, consistent with the general principle that functions with positive slope are easier to learn.

The parameters for AEGLE were roughly tuned to
get good performance on the training task, as follows:
œÜ = 4, Œ∑w = .5, m = .1, Œ∑g = .1, Œ∑Œ± = .9, experts = 2, œÑ =
2. To illustrate individual differences, c, the specificity
of activation of the stored exemplars in the gating network, was varied from 0.2 to 2. 10 replications of the
model (for each value of c) were trained for 10 blocks,
and their responses on the conflict items were compared
to ‚Äúideal‚Äù responses based solely on the CA and FR information. The results are shown in Figure 4, along with
the (low and relatively constant) training error and a
measure of differential attention. With c near 1.1, responses on the conflict items tended to be most similar
to the responses expected if attention were focused on
the criterial attribute. Indeed, the ratio of attention to
the CA attribute to the mean attention to the FR attributes reaches its peak at c = 1.4. With c near 0 or
2, attention is more evenly distributed, and responses to
the conflict items reflect that.

Simulation 4
Minda and Ross recently investigated the interactions
between two simultaneous concept-learning tasks, a categorization task and a function-learning task, sharing the
same stimuli (Minda and Ross 2004). For the present
simulation, we consider just the results from a condition
where only the function learning task was performed.
The stimuli contained both a criterial attribute (CA)
and a family resemblance (FR) structure of 5 attributes
(see Table 1 of Minda and Ross, 2004), plus a scalar attribute. The function target could be predicted given
the scalar attribute and either the CA or FR information. They found significant individual differences in attention and generalization. After learning to a criterion,
subjects saw conflict items where the CA and FR information conflicted. 58% of responses to those conflict
items were consistent with the use of the single criterial
attribute, while 31% of responses were consistent with
the use of the broad family resemblance structure.
This task can be modeled using AEGLE2 , treating the
CA and FR attributes as cues and the scalar attribute
as the domain of the function. That is, AEGLE can
learn to partition its knowledge based on the cues, gating
different functions based on those cues.

These results are consistent with Minda and Ross‚Äô argument that individual differences in generalization on
their task are due to differential weighting of attention
to the CA and FR attributes. Further work is necessary to confirm whether the parameter c, representing
the extent to which exemplars in the ALCOVE gating
network are activated by distant inputs, is a good explanation for those individual differences. It should be
noted that Nosofsky and Zaki (1998) used variations in
this same parameter to explain the differences between
controls and amnesiac patients in recognition and categorization tasks.

2
Unfortunately, the scheme used in SUSTAIN to tune attention is based on maximizing coverage of examples, not
minimizing error. As a result, attention to attributes is not
differentially affected by error, and SEGLE is inadequate for
exploring this data set.

909

Acknowledgments

Discussion

This work was supported by National Institute on Deafness and Other Communication Disorders Grant DC005765 to James S. Magnuson. Thanks to Jim Magnuson
and the reviewers for comments on drafts of this paper,
and to Lewis Bott, Michael Kalish, and Brad Love for
their suggestions regarding this project.

Of the myriad possible models of function learning, AEGLE and SEGLE illustrate two variants on the mixtureof-experts approach pioneered by POLE (Kalish et al.
2004). Like POLE, AEGLE and SEGLE conceptualize
function learning as a process of learning how to select
simple experts. SEGLE finds the learning of different
functions roughly as difficult as do experimental subjects, can partition stimuli based on regions of the function domain, and can partition stimuli based on external
cue variables. Work with AEGLE suggests further approaches for modeling individual differences in learning
with many potential cues.

References
Busemeyer, J. R., E. Byun, E. L. Delosh, and M. A.
McDaniel (1997). Learning functional relations
based on experience with input-output pairs by
humans and artificial neural networks. In K. Lamberts and D. Shanks (Eds.), Knowledge, concepts,
and categories, Chapter 11, pp. 405‚Äì437. Cambridge, MA: MIT Press.
DeLosh, E. L., J. R. Busemeyer, and M. A. McDaniel
(1997). Extrapolation: The sine qua non for abstraction in function learning. Journal of Experimental Psychology: Learning, Memory and Cognition 23 (4), 968‚Äì986.
Guigon, E. (2004). Interpolation and extrapolation in
human behavior and neural networks. Journal of
Cognitive Neuroscience 16 (3), 382‚Äì389.
Jacobs, R. A., M. I. Jordan, S. J. Nowlan, and G. E.
Hinton (1991). Adaptive mixtures of local experts.
Neural Computation 3, 79‚Äì87.
Kalish, M. L., S. Lewandowsky, and J. K. Kruschke
(2004). Population of linear experts: Knowledge
partitioning and function learning. Psychological
Review 111 (4), 1072‚Äì1099.
Koh, K. and D. E. Meyer (1991). Function learning:
Induction of continuous stimulus-response relations. Journal of Experimental Psychology: Learning, Memory & Cognition 17, 811‚Äì836.
Kruschke, J. K. (1992). ALCOVE: An exemplar-based
connectionist model of category learning. Psychological Review 99 (1), 22‚Äì44.
Lewandowsky, S., M. Kalish, and S. K. Ngang (2002).
Simplified learning in complex situations: Knowledge partitioning in function learning. Journal of
Experimental Psychology: General 131 (2), 163‚Äì
193.
Lewandowsky, S. and K. Kirsner (2000). Knowledge
partitioning: Context-dependent use of expertise.
Memory & Cognition 28, 295‚Äì305.
Love, B. C., D. L. Medin, and T. M. Gureckis (2004).
SUSTAIN: A network model of category learning.
Psychological Review 111 (2), 309‚Äì332.
Minda, J. P. and B. H. Ross (2004). Learning categories by making predictions: an investigation
of indirect category learning. Memory and Cognition 32 (8), 1355‚Äì1368.
Nosofsky, R. M. and S. R. Zaki (1998). Dissociations
between categorization and recognition in amnesic
and normal individuals: An exemplar-based interpretation. Psychological Science 9 (4), 247‚Äì255.

Although the general framework used by POLE is
shared by AEGLE and SEGLE, both the experts and the
gating network are radically different, and in many ways,
simpler and more suitable for analysis. Several of the
parameters used in POLE have subtle and non-obvious
effects and interactions. The use of a multiplicative gain
for each expert makes POLE‚Äôs predictions extremely sensitive to the initial conditions and to changes to that
gain. As another example, if not for a threshold at 0, the
three parameters œâ, Œªw , and Œªb would have only two degrees of freedom. These sorts of interactions, combined
with a very novel sort of gating module, make analysis
very difficult. In addition, the first author, despite the
gracious assistance of Michael Kalish (including a portion of the original POLE source code) was unable to
get a reimplementation of POLE to show the behaviors
described in Kalish et al. (2004) without radical changes
from the reported parameters. Although POLE‚Äôs underlying motivations are novel and compelling, our concerns
about its replicability and transparency limit the extent
to which the model can be successfully applied.
It should also be noted that although AEGLE and
SEGLE should be more suitable to analysis than POLE,
they both have significant limitations that will be addressed by future exploration. The simple LMS experts
used in the model, although adequate for the simulations
described here, don‚Äôt learn very quickly or accurately. In
addition, LMS experts would predict that immediate and
accurate learning of a single repeated exemplar could not
occur, while it certainly could. As for the gating modules, ALCOVE, by virtue of being an exemplar model,
requires a large number of training examples to learn all
of the gating weights, and does not efficiently represent
this knowledge in the manner that SUSTAIN‚Äôs clusters
do. Future models in the tradition of SUSTAIN may
improve upon that approach‚Äôs ability to learn attention
weights in an error-driven manner (Brad Love, personal
communication), and these advances will be very useful in extensions to AEGLE and SEGLE. Clearly, the
class of mixture-of-experts models of function learning
allow insight into the sorts of partitioning and exampledriven processes that underly human function learning,
but some details and a truly complete, comprehensive
model remain for future work.
910

