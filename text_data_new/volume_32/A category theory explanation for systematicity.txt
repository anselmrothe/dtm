system generate one without being able to generate the other.
So, this Classical architecture has the systematicity of representation property with respect to this group of four propositions. Tensor products (Smolensky, 1990), or Godel numbers
(van Gelder, 1990) are functionally compositional analogues
to this explanation. Systematicity of inference follows from
having additional processes that are sensitive to the structure
of these representations. For Classical architectures, compositionality of representation also follows, because the semantic content of a complex representation is built up from the
semantic contents of the constituents and their syntactic relationships (Aizawa, 2003a). Aizawa (2003a, 2003b) disputes
whether a Connectionist architecture can also demonstrate
compositionality of representation. Regardless, though, neither Classicism, nor Connectionism can derive theories that
provide a full account of systematicity (Aizawa, 2003b).
A demonstration of systematicity is not an explanation
for it. In particular, although grammar G1 has the systematicity of representation property, the following grammar:
G2: P
→ John loves Patient |
Agent loves Mary
Agent
→ John | Mary
Patient → John | Mary
does not. This architecture cannot generate a representation of the proposition Mary loves John even though it can
generate representations of both John and Mary as agents
and patients, and the John loves Mary proposition. The essential problem for Classical theory—likewise Connectionist
theory—is that syntactic compositionality by itself is not sufficient without some additional assumptions that admit grammars such as G1 that have the systematicity property, but exclude grammars such as G2 that do not. An explanation for
systematicity in these cases turns on the nature of those additional, possibly ad hoc assumptions.

Ad hoc assumptions
Aizawa (2003b) presents an explanatory standard for systematicity and the problem of ad hoc assumptions by analogy with the Ptolemean (geocentric) versus Copernican (heliocentric) explanations for the motions of the planets (see
Phillips, 2007, for a review). The geocentric explanation for
planetary motion places the Earth at the center of the other
planets’ circular orbits. Although this theory can roughly predict planetary position, it fails to predict periods of apparent
retrograde motion for the superior planets (i.e. Mars, Jupiter,
etc.) across the night sky. To accommodate this data, the
geocentric theory was augmented with the assumption that
the other planets revolve around points that revolve around
the Earth. This additional assumption is ad hoc in that it is
unconnected with the rest of the theory and motivated only
by the need to fit the data—the assumption could not be confirmed independently of confirming the theory. The heliocentric explanation, having all planets move around the Sun, eschews this ad hoc assumption. Retrograde motion falls out as
a natural consequence of the positions of the Earth and other
planets relative to the Sun. Tellingly, as more accurate data

became available, the geocentric theory had to be further augmented with epicycles on epicycles to account for planetary
motion; not so for the heliocentric theory.
The problem for Classical and Connectionist theories is
that they cannot explain systematicity without recourse to
their own ad hoc assumptions (Aizawa, 2003b). For Classicism, having a combinatorial syntax and semantics does
not differentiate between grammars such as G1 and G2.
For Connectionism, a common recourse to learning also
does not work, whereby systematicity is acquired by adjusting network parameters (e.g., connection weights) to realize some behaviours—training set—while generalizing to
others—test set. Learning also requires ad hoc assumptions,
because even widely used learning models, such as feedforward (Rumelhart, Hinton, & Williams, 1986) and simple recurrent networks (Elman, 1990), fail to achieve systematicity
(Marcus, 1998; Phillips, 2000) when construed as a degree
of generalization (Hadley, 1994; Niklasson & Gelder, 1994).
Hence, neither Classical nor Connectionist proposals satisfy
the explanatory standard laid out by Aizawa, or Fodor and
Pylyshyn for that matter.
Our category-theory based approach addresses the problem
of ad hoc assumptions because the concept of an adjunction,
which is central to our argument, ensures that the construct
we seek (a) exists, and (b) is unique. That is to say, from
this core assumption and category theory principles, the systematicity property necessarily follows for the particular cognitive domains of interest, because in each case the one and
only collection of cognitive capacities derived from our theory is the systematic collection, without further restriction by
additional (ad hoc) assumptions.

Basic category theory
Category theory is a theory of structure par excellence (see
Awodey, 2006; Mac Lane, 2000, for introductions). It was
developed out of a need to formalize commonalities between
various mathematical structures (Eilenberg & Mac Lane,
1945), and has been used extensively in computer science
for the analysis of computation (see, e.g., Pierce, 1991; Walters, 1991). Yet, applications to cognitive psychology have
been almost non-existent (but, see Halford & Wilson, 1980;
Phillips, Wilson, & Halford, 2009, for two examples). Our
explanation of systematicity with respect to binary relational
propositions is based on the concept of an adjunction. In this
section, we provide definitions of this and other formal concepts that it depends.

Category
A category C consists of a class of objects |C| = (A, B, . . . ); a
set C(A, B) of morphisms (also called arrows, or maps) from
A to B where each morphism f : A → B has A as its domain and B as its codomain, including the identity morphism
1A : A → A for each object A; and a composition operation,
denoted “◦”, of morphisms f : A → B and g : B → C, written
g ◦ f : A → C that satisfy the laws of:

1524

• unity, where f ◦ 1A = f = 1B ◦ f , for all f : A → B; and
• associativity, where h ◦ (g ◦ f ) = (h ◦ g) ◦ f , for all f : A →
B, g : B → C and h : C → D.
The most familiar example of a category is Set, which has
sets for objects and functions for morphisms, where the identity morphism 1A is the identity function and the composition
operation is the usual function composition operator “◦”.
A morphism f : A → B is an isomorphism if there exists a
g : B → A, such that g ◦ f = 1A and f ◦ g = 1B . In this case, A
is said to be isomorphic to B, written A ∼
= B.

Product
A product of two objects A and B in a category C is an object
P together with two morphisms p1 : P → A and p2 : P → B,
such that for any pair of morphisms z1 : Z → A and z2 : Z → B,
there is a unique morphism u : Z → P, such that the following
diagram commutes:
Ä
z1 ÄÄ
Ä
Ä
ÄÄ Ä

Ao

p1

ZÂ ?
?
Â u ???z2
??
Â
²
Â
P p2 / B

Natural transformation

(1)

where a broken arrow indicates that there exists exactly one
morphism making the diagram commute. That is, the compositions along any two paths with the same start object and
the same finish object are the same. So, in this diagram,
z1 = p1 ◦ u and z2 = p2 ◦ u, where p1 and p2 are sometimes
called projection morphisms. A product object P is unique up
to a unique isomorphism. That is, for any other product object P0 with morphisms p01 : P0 → A and p02 : P0 → B there is
one and only one isomorphism between P and P0 that makes
a diagram like this one commute. Hence, P is not unique,
only unique with respect to another product object via isomorphism. In Set, P is (up to isomorphism) the Cartesian
product A × B, p1 : A × B → A, p2 : A × B → B, where p1 and
p2 are the projection maps to A and B, i.e., p1 : (a, b) 7→ a, and
p2 : (a, b) 7→ b, and u is the function hz1 , z2 i : Z → A×B, sending x to tuple (z1 (x), z2 (x)), so that p1 ◦ u = z1 and p2 ◦ u = z2 .
(The 7→ arrow, often read as “maps to”, indicates the action of
a function on a domain element. Thus f (a) = b is equivalent
to f : a 7→ b.) Since u is uniquely determined by z1 and z2 , u
is often written as hz1 , z2 i, and the diagram used in defining a
product then becomes
ZO
ooo Â OOOOO z
z1 ooo
Â hz ,z i OO2O
o
OOO
ooo
Â² 1 2
o
OO'
o
woo o
/B
A×B
A
p1
p2

F( f ) : F(A) → F(B) in D, such that F(1A ) = 1F(A) for each
object A in C; and F(g ◦C f ) = F(g) ◦D F( f ) for all maps
f : A → B and g : B → C for which compositions ◦C and ◦D
are defined in categories C and D, respectively. The object
and arrow components of a functor are sometimes explicitly
distinguished as F0 and F1 , respectively. Otherwise, the functor component is implicitly identified by its argument.
Functor composition and isomorphism are defined analogously to maps (above). That is, the composition of functors
F : C → D and G : D → E is the functor G ◦ F : C → E, sending all objects A in C to objects G ◦ F(A) in E; and maps f :
A → B in C to maps G◦F( f ) : G◦F(A) → G◦F(B), such that
identity and composition are respected. That is, G ◦ F(1A ) =
1G◦F(A) ; and G ◦ F(g ◦C f ) = (G ◦ F(g)) ◦E (G ◦ F( f )). A
functor F : C → D is an isomorphic functor, if and only if
there exists a functor G : D → C such that G ◦ F = 1C and
F ◦G = 1D , where 1C and 1D are the identity functors sending
objects and maps to themselves in the respective categories.
A natural transformation τ : F → G is a structure-preserving
map from domain functor F : C → D to codomain functor
G : C → D that consists of D−maps τA for each object A in C,
such that G( f ) ◦ τA = τB ◦ F( f ), as indicated by the following
commutative diagram in the category D:
F(A)

τA

F( f )

²
F(B)

G( f )
τB

²
/ G(B)

Adjunction
An adjunction consists of a pair of functors F : C → D, G :
D → C and a natural transformation τ : 1C → (G ◦ F), such
that for every C−object X and every C−map f : X → G(Y )
there exists a unique D−map g : F(X) → Y , such that the
following diagram commutes:
τX

/ G(F(X))
X FF
Â
FF
F
Â
f FF
FF Â G(g)
# ²
G(Y )

A functor F : C → D is a structure-preserving map between
categories C and D that associates each object A in C to an
object F(A) in D; and each map f : A → B in C to a map

(3)

A natural transformation is a natural isomorphism, or natural equivalence if and only if each τA is an isomorphism. That
is, for each τA : F(A) → G(A) there exists a τ−1
A : G(A) →
−1
F(A) such that τ−1
◦
τ
=
1
and
τ
◦
τ
=
1G(A) . NatuA
A
F(A)
A
A
ral transformations also compose, and the composition of two
natural transformations is also a natural transformation.

(2)

Functor

/ G(A)

F(X)
Â
Âg
Â²
Y

(4)

where the functors are implicitly identified by (co)domain
categories C (left subdiagram) and D (right subdiagram). The
two functors are called an adjoint pair, (F, G), where F is the
left adjoint of G, and G is the right adjoint of F; and natural
transformation τ is called the unit of the adjunction.

1525

Category theory explanation: Adjoint functors
We develop our adjoint functors explanation of systematicity
in three movements. First, we show that a categorical product provides an account of systematicity of representation and
systematicity of inference. However, a product of two objects
may afford many isomorphic product objects that do not also
account for compositionality of representation. Second, we
show that the product functor provides the principled means
for constructing only those products that also have the compositionality of representation property. However, there may
be more than one product that has the compositionality property, but differs in semantic content by having different syntactic relationships between identical sets of constituents. So,
a principled choice is needed to determine the product. Third,
we show that the diagonal functor, which is left adjoint to
the product functor, provides that principled choice. For concreteness, we refer to the category Set, but our explanation
does not depend on this category.
First, suppose objects A (say, agents) and B (patients) are
sets containing representations of John and Mary, denoted
as {J, M}. Although A and B are the same set in this example they may not be in the general case. Since our argument does not depend on equality, we maintain distinct
names for generality, and for conceptual clarity. A categorical product of these two sets is the Cartesian product of A
and B, which is the set of all pairwise combinations of elements from A and B, together with maps p1 and p2 for retrieving the first and second constituent in each case. That
is, A × B = {(J, J), (J, M), (M, J), (M, M)}, p1 : (a, b) 7→ a, and
p2 : (a, b) 7→ b. By definition, the Cartesian product, A × B,
generates all pairwise combinations of elements from A and
B, therefore the Cartesian product has the systematicity of
representation property. Moreover, by definition, the categorical product, (A × B, p1 , p2 ), affords the retrieval of each constituent from each representation (otherwise it is not a product), therefore the categorical product also has the systematicity of inference property. In this case, Z from the categorical
product definition takes the role of input, so inferring John
as the lover from John loves Mary is just z1 (JM) = p1 ◦ u(JM),
where JM is the input and u is the input-to-product object map,
whose unique existence is guaranteed.
The Cartesian product, however, is not the only product
object that satisfies the definition of a categorical product
of A and B. An alternative product has P = {1, 2, 3, 4} as
the product object, and p01 : 1 7→ J, 2 7→ J, 3 7→ M, 4 7→ M and
p02 : 1 7→ J, 2 7→ M, 3 7→ J, 4 7→ M as the projections. However,
this alternative does not have the compositionality of representation property: the semantic contents of these representations, whatever they may be, are not systematically related to
each other, or the semantic content of John, or Mary. Hence,
categorical products, in themselves, are not sufficient for an
explanation of systematicity.
Second, for any category C that has products (i.e. every pair of objects in C has a product), one can define a
product functor Π : C × C → C, that is from the Cartesian

product of categories, C × C, itself a category, to C, where
Π0 : (A, B) 7→ A × B, Π1 : ( f , g) 7→ f × g, as indicated by the
following diagram:
(A, B) Â

Π0

/ A×B

(5)

f ×g

( f ,g)

²
(C, D) Â

²
/ C×D

Π0

omitting Π1 : ( f , g) 7→ f × g for clarity. In this case, the semantic contents of these elements are systematically related
to each other and their constituents John and Mary. This categorical construction is an instance of Classical compositionality, whereby the constituents ai ∈ A, b j ∈ B are tokened wherever the compositions (ai , b j ) ∈ A × B are tokened. As such,
it has the compositionality of representation property.
Although the product functor explanation accounts for
compositionality of representation, it introduces a new problem: (B × A, p02 , p01 ), where p02 : (b, a) 7→ a and p01 : (b, a) 7→ b
is also a valid product, but the semantic content of (a, b) is
not the same as (b, a). That is because they have different
order relationships between their constituents even though
the corresponding constituents are identical. Thus, a principled choice is required to determine whether, for example, John loves Mary should map to (John, Mary), or (Mary,
John). Otherwise, one can define an architecture that does
not have the systematicity of inference property by employing both products to correctly infer John as the lover in John
loves Mary via (A × B, p1 , p2 ), yet incorrectly infer John as
the lover in Mary loves John via (B × A, p02 , p01 ), where position within the product triple identifies the relevant projection. The assumption that architectures employ only the first
product is ad hoc just like the assumption that Classical architectures employ grammars such as G1, but not G2. So, a
principled choice is needed to determine the product.
Third, and finally, the left adjoint to the product functor is
the diagonal functor ∆ : C → C × C, where ∆0 : A 7→ (A, A),
∆1 : f 7→ ( f , f ) as indicated by the following diagram:
A

Â

∆0

/ (A, A)

f

(6)

(f,f)

² Â
B

∆0

²
/ (B, B)

The (diagonal, product) adjoint pair is indicated by the following commutative diagram:
τC =h1C ,1C i
/ C ×C
C NNN
Â
NNN
NNN
Â s×t
NNN
hs,ti
NN' Â²
M×N

(C,C)
Â
Â (s,t)
Â
²
(M, N)

(7)

(see Pierce, 1991, Example 2.4.6). In this manner, the John
loves Mary family of cognitive capacities is specified by the

1526

commutative diagram
h1Pr ,1Pr i
/ Pr × Pr
Pr OOO
Â
OOO
OOO
Â ag×pt
O
Â
hag,pti OOOO
' ²
S×S

(Pr, Pr)
Â
Â (ag,pt)
Â
²
(S, S)

other propositions. Hence, systematicity is a necessary consequence of this adjoint pair without recourse to additional
(ad hoc) assumptions, and so meets the explanatory standard
set by Aizawa, and Fodor and Pylyshyn.

(8)

Explanatory levels: n-category theory

where ag and pt are the agent and patient maps from the set
of proposition inputs Pr into the set S ⊇ A ∪ B containing all
the possible constituent representations. Given hag, pti as the
morphism used by the architecture to map proposition inputs
to their corresponding internal representations, then as mentioned (Introduction) the definition of an adjunction guarantees that ag × pt is unique with respect to making Diagram 8
commute. That is, ag×pt ◦h1Pr , 1Pr i(JM) = ag×pt(JM, JM) =
(John, Mary) = hag, pti(JM), where JM is the input for proposition John loves Mary. The alternative construction pt × ag is
excluded because pt × ag ◦ h1Pr , 1Pr i(JM) = pt × ag(JM, JM) =
(Mary, John) 6= (John, Mary) = hag, pti(JM). Having excluded pt × ag by the commutativity property of the adjunction, the only two remaining ways to map the other inputs (i.e., hag, pti and ag × pt ◦ h1Pr , 1Pr i) are equal. So,
given that the architecture can represent John loves Mary as
(John, Mary) via hag, pti and infer John as the lover via p1
from the product (A × B, p1 , p2 ), then necessarily it can represent Mary loves John and infer Mary as the lover using the
same maps. That is, p1 ◦ hag, pti(MJ) = p1 (Mary, John) =
Mary, or p1 ◦ ag × pt ◦ h1Pr , 1Pr i(MJ) = p1 ◦ ag × pt(MJ, MJ) =
p1 (Mary, John) = Mary.
This explanation works regardless of whether proposition
John loves Mary is represented as (John, Mary) via hag, pti,
or (Mary, John) via hpt, agi. In the latter case, the adjunction
picks out the construction pt × ag, because it is the one and
only one that makes the following diagram commute:
h1Pr ,1Pr i
/ Pr × Pr
Pr OOO
Â
OOO
OOO
Â pt×ag
O
Â
hpt,agi OOOO
' ²
S×S

(Pr, Pr)
Â
Â (pt,ag)
Â²
(S, S)

(9)

pt × ag ◦ h1Pr , 1Pr i(JM) = pt × ag(JM, JM) = (Mary, John) =
hpt, agi(JM), but ag × pt ◦ h1Pr , 1Pr i(JM) = ag × pt(JM, JM) =
(John, Mary) 6= (Mary, John) = hpt, agi(JM). Given that the
architecture can represent John loves Mary as (Mary, John)
via hpt, agi and infer John as the lover via p02 from the product (B × A, p02 , p01 ), then necessarily it can do so for Mary
loves John using the same maps. That is, p02 ◦ hpt, agi(MJ) =
p02 (John, Mary) = Mary, or p02 ◦ pt × ag ◦ h1Pr , 1Pr i(MJ) =
p02 ◦ pt × ag(MJ, MJ) = p02 (John, Mary) = Mary.
Importantly, the unit of the adjunction, h1Pr , 1Pr i, is not
a free parameter of the explanation; it defines the adjunction. Also, there is no choice in representational format (i.e.
left-right, or right-left constituent order)—the given capacity to represent a proposition fixes the same order for all the

A generalization of category theory, called n-category theory (see Leinster, 2003) is used to formally contrast our category theory explanation against Classical and Connectionist
approaches. Notice that the definitions of functor and natural
transformation are very similar. In fact, they are morphisms
at different levels of analysis. For n-category theory, a category such as Set is a 1-category, with 0-objects (i.e. sets)
for objects and 1-morphisms (i.e. functions) for arrows. A
functor is a morphism between categories. The category of
categories, Cat, has categories for objects and functors for arrows. Thus, a functor is a 2-morphism between 1-objects (i.e.
1-categories) in a 2-category. A natural transformation is a
morphism between functors. The functor category, Fun, has
functors for objects and natural transformations for arrows.
Thus, a natural transformation is a 3-morphism between 2objects (i.e. functors) in a 3-category. (A 0-category is just a
discrete category, where the only arrows are identities, which
are 0-morphisms.) In this way, the order n of the category
provides a formal notion of explanatory level.
Classical or Connectionist compositionality is essentially a
lower levels attempt to account for systematicity. For the examples we used that level is perhaps best described in terms
of a 1-category. Indeed, a context-free grammar defined by a
graph is modeled as the free category on that graph containing sets of terminal and non-terminal symbols for objects and
productions for morphisms (Walters, 1991). By contrast, our
category theory explanation involves higher levels of analysis, specifically functors and natural transformations, which
live in 2-categories and 3-categories, respectively. Of course,
one can also develop higher-order grammars that take as input or return as output other grammars. Similarly, one can
develop higher-order networks that take as input or return as
output other networks. However, the problem is that neither
Classical nor Connectionist compositionality delineates those
(higher-order) grammars or networks that have the systematicity property from those that do not.

Discussion
In addition to explaining systematicity, our category theory
approach has further implications. According to our explanation, systematicity with respect to binary relational propositions requires a category with products. Phillips et al. (2009)
also provided a category theory account of the strikingly similar profiles of development for a suite of reasoning abilities
that included Transitive Inference and Class Inclusion, among
others—all abilities are acquired around the age of five years.
The difference between the failures of younger children and
the successes of older children (relative to age five) across
all these reasoning tasks was explained as their capacity to
compute (co)products. (A coproduct is related to a product

1527

by arrow reversal—see, e.g., Pierce, 1991, for a formal definition.) Therefore, our explanation implies that systematicity is not a property of younger children’s cognition. Some
support for this implication is found on memory tasks that
require binding the background context of memorized items
(Lloyd, Doydum, & Newcombe, 2009), though further work
is needed to test this implication directly.
Our explanation does not depend on Set, it only requires
a category with products. For example, the categories Top
of topological spaces and continuous mappings, and Vec of
vector spaces and linear mappings (see, e.g., Awodey, 2006)
could also be used. These possibilities imply that an explanation of systematicity does not depend on a particular (discrete symbolic, or continuous subsymbolic) representational
format. Thus, a further benefit is that our approach opens the
way for integration of other (sub/symbolic) levels of analysis.
For reasons of space, we have only sketched our category theory approach to systematicity. More detailed explanation and justification are given in Phillips and Wilson
(in prep.), where we also address other examples of systematicity, such as multiple relations, and relational schemas. In
our approach, we have not dealt with domains that are quasisystematic, which appear to be particularly prevalent in language (see Johnson, 2004). For these cases, we would also
need category theory-derived principled restrictions to products. Pullbacks (see Phillips, Wilson, & Halford, 2009, for an
application to cognitive development) are one way to restrict
product objects, in the same arrow-theoretic style.
From a category theory perspective, we now see why
cognitive science lacked a satisfactory explanation for
systematicity—cognitive scientists were working with lowerorder theories in attempting to explain an essentially higherorder property. Category theory offers a re-conceptualization
for cognitive science, analogous to the one that Copernicus
provided for astronomy, where representational states are no
longer the center of the cognitive universe—replaced by the
relationships between the maps that transform them.
Acknowledgment. We thank the reviewers for extensive
comments to help clarify the presentation of this work.

References
Aizawa, K. (2003a). Cognitive architecture: The structure of
cognitive representations. In S. P. Stich & T. A. Warfield
(Eds.), The Blackwell guide to philosophy of mind (pp.
172–189). Cambridge, MA: Blackwell.
Aizawa, K. (2003b). The systematicity arguments. New York:
Kluwer Academic.
Awodey, S. (2006). Category theory. New York, NY: Oxford
University Press.
Eilenberg, S., & Mac Lane, S. (1945). General theory of
natural equivalences. Transactions of the American Mathematical Society, 58, 231–294.
Elman, J. L. (1990). Finding structure in time. Cognitive
Science, 14, 179–211.
Fodor, J. A., & McLaughlin, B. P. (1990). Connectionism and

the problem of systematicity: Why Smolensky’s solution
doesn’t work. Cognition, 35, 183–204.
Fodor, J. A., & Pylyshyn, Z. W. (1988). Connectionism and
cognitive architecture: A critical analysis. Cognition, 28,
3–71.
Hadley, R. F. (1994). Systematicity in connectionist language
learning. Mind and Language, 9(3), 247–272.
Halford, G. S., & Wilson, W. H. (1980). A category theory
approach to cognitive development. Cognitive Psychology,
12, 356–411.
Johnson, K. (2004). On the systematicity of language and
thought. The Journal of Philosophy, 101(3), 111–139.
Leinster, T. (2003). Higher operads, higher categories. Cambridge: UK: Cambridge University Press.
Lloyd, M. E., Doydum, A. O., & Newcombe, N. S. (2009).
Memory binding in early childhood: evidence for a retrieval deficit. Child Development, 80(5), 1321–1328.
Mac Lane, S. (2000). Categories for the working mathematician (2nd ed.). New York, NY: Springer.
Marcus, G. F. (1998). Rethinking eliminative connectionism.
Cognitive Psychology, 37(3), 243–282.
Niklasson, L., & Gelder, T. van. (1994). Systematicity and
connectionist language learning. Mind and Language, 9(3),
288–302.
Phillips, S. (2000). Constituent similarity and systematicity: The limits of first-order connectionism. Connection
Science, 12(1), 1–19.
Phillips, S. (2007). Kenneth Aizawa, The systematicity arguments, Studies in brain and mind. Minds and Machines,
17(3), 357–360.
Phillips, S., & Wilson, W. H. (in prep.). Categorial compositionality: A category theory explanation for the systematicity of human cognition.
Phillips, S., Wilson, W. H., & Halford, G. S. (2009). What do
Transitive Inference and Class Inclusion have in common?
Categorical (co)products and cognitive development. PLoS
Computational Biology, 5(12), e1000599.
Pierce, B. C. (1991). Basic category theory for computer
scientists. Cambridge, UK: MIT Press.
Rumelhart, D. E., Hinton, G. E., & Williams, R. J. (1986).
Learning representations by back-propagation of error. Nature, 323, 533–536.
Smolensky, P. (1987). The constituent structure of connectionist mental states: A reply to Fodor and Pylyshyn.
Southern Journal of Philosophy, 26, 137–161.
Smolensky, P. (1990). Tensor product variable binding and
the representation of symbolic structures in connectionist
systems. Artificial Intelligence, 46(1-2), 159–216.
van Gelder, T. (1990). Compositionality: A connectionist
variation on a classical theme. Cognitive Science, 14, 355–
384.
Walters, R. F. C. (1991). Categories and computer science.
Cambridge, UK: Cambridge University Press.

1528

