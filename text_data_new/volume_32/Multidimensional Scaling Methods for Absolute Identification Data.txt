UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Multidimensional Scaling Methods for Absolute Identification Data

Permalink
https://escholarship.org/uc/item/4vn968rb

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Dodds, Pennie
Donkin, Chris
Brown, Scott
et al.

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Multidimensional Scaling Methods for Absolute Identification Data
Pennie Dodds (Pennie.Dodds@newcastle.edu.au)
School of Psychology, University Drive
Callaghan, NSW, Australia

Chris Donkin (cdonkin@indiana.edu)
Department of Psychological and Brain Sciences, 1101 E. 10th S.
Bloomington, Indiana

Scott Brown (Scott.Brown@newcastle.edu.au)
School of Psychology, University Drive
Callaghan, NSW, Australia

Andrew Heathcote (Andrew.Heathcote@newcastle.edu.au)
School of Psychology, University Drive
Callaghan, NSW, Australia

Abstract
Absolute identification exposes a fundamental limit in human
information processing. Recent studies have shown that this limit
might be extended if participants are given sufficient opportunity
to practice. An alternative explanation is that the stimuli used –
which vary on only one physical dimension – may elicit
psychological representations that vary on two (or more)
dimensions. Participants may learn to take advantage of this
characteristic during practice, thus improving performance. We use
multi-dimensional scaling to examine this question, and conclude
that despite some evidence towards the existence of two
dimensions, a one dimensional account cannot be excluded.
Keywords: absolute identification; unidimensional stimuli;
multidimensional scaling; MDS; learning

A typical Absolute Identification (AI) task uses stimuli
that vary on only one physical dimension, such as loudness,
brightness, or length. These stimuli are first presented to the
participant one at a time, each uniquely labeled (e.g. #1
through to n). The participant is then presented with random
stimuli from the set, without the label, and asked to try and
remember the label given to it previously.
This seemingly simple task exhibits many interesting
benchmark phenomena. The one of most concern for the
current paper is the apparent limitation in performance. The
maximum number of stimuli that people were previously
thought to be able to perfectly identify was only 7±2
(Miller, 1956). Performance was thought to improve slightly
with practice and then reach a low asymptote (Pollack,
1952; Garner 1953).
This finding was particularly surprising given that this
limit appeared to be resistant to practice (Garner, 1953;
Weber, Green & Luce, 1977), and was generally consistent
across a range of modalities (e.g. line length: Lacouture, Li
& Marley, 1998; tone frequency: Pollack, 1952; Hartman,
1954; tone loudness: Garner, 1953; Weber, Green & Luce,
1977). In addition, this limitation appears to be unique to
unidimensional stimuli. For example, people are able to

remember hundreds of faces and names, and dozens of
alphabet shapes. It is generally accepted that this is because
objects such as faces, names, and letters vary on multiple
dimensions. Performance generally increases as the number
of dimensions increase (Eriksen & Hake, 1955). This makes
intuitive sense when one considers the individual
dimensions on a multidimensional object. For example, if
people are able to learn to perfectly identify 7 lengths, and 7
widths, they could potentially learn to identify 49 rectangles
formed by a combination of lengths and widths.
Despite decades of research confirming this limit in
performance for unidimensional stimuli, more recent
research has suggested that we may be able to significantly
increase this limit through practice (Rouder, Morey, Cowan
and Pfaltz, 2004; Dodds, Donkin, Brown & Heathcote,
submitted). For example, given approximately 10 hours of
practice over 10 days, Dodds et al.’s participants learned to
perfectly identify a maximum of 17.5 stimuli (out of a
possible 36), a level significantly beyond the 7±2 limit
suggested by Miller (1956). From 58 participants that took
part in a series of AI tasks, 22 exceeded the upper end of
Miller’s limit range (nine stimuli).

Other Stimulus Dimensions
The results from Dodds et al. (submitted) were not limited
to the identification of lines varying in length. Dodds et al.
also used a wide range of other stimuli, and found similar
learning effects. For example, dots varying in separation,
lines varying in angle and tones varying in pitch all
demonstrated similar results. Participants learned to
perfectly identify a maximum of 12.6 stimuli using dots
varying in separation, 10.4 using lines varying in angle and
17.5 using tones varying in frequency, all exceeding
Miller’s (1956) upper limit of 9 stimuli.
The learning effects from Rouder et al. (2004) and Dodds
et al. (submitted) may be attributed to the type of stimuli
employed. The existence of severe limitations in

2804

performance is unique to unidimensional stimuli, and since
multiple dimensions are commonly associated with
improved performance (Eriksen & Hake, 1955) it may be
argued that the stimuli vary on multiple dimensions. Tones
varying in frequency for example, are generally viewed as
multidimensional. While Dodds et al. employed pure tones,
leaving the stimuli to vary on only one physical dimension
(wavelength), our perception of loudness increases as a
function of increasing frequency. Therefore as frequency
increased, participants would perceive the tones as being of
different loudness, creating a greater number of perceived
dimensions. This is not an uncommon phenomenon, as a
similar effect is found in colour perception. Different
colours are generated by a manipulation which is physically
unidimensional (wavelength change), but the psychological
representation of colour is generally considered to consist of
three dimensions (e.g., MacLeod, 2003). Therefore it may
be possible that the internal psychological representation of
different line lengths used in both Rouder et al. (2004) and
Dodds et al. (submitted) varied on more than one
dimension.
In order to examine this theory using the same stimuli
employed by Dodds et al. (submitted), we use
Multidimensional Scaling (MDS) methods to examine the
structure of similarity ratings generated using these stimuli.
MDS refers to a broadly used range of statistical techniques,
designed to allow the examination of relationships between
objects of interest. Given a matrix of proximity data, MDS
uncovers a spatial arrangement of objects in a manner that
best reconstructs the original proximity data. For example,
given a matrix of data with the distances between n cities,
MDS analysis would present a spatial ‘map’ that would
arrange the cities in the most likely location, given the
distances provided by the data. Because we use subjective
“similarity ratings”, rather than actual measured distances,
we employ non-metric MDS, which does not assume a
linear mapping between similarity ratings and distances.
Typically, MDS is employed after one has already
assumed the number of dimensions on which the stimuli
might vary. In the current experiment however, we use
MDS to determine the number of dimensions that best
describe Dodds et al.’s (submitted) stimuli.

Method
Participants
The 27 participants, recruited from an introductory
psychology course at the University of Newcastle,
Australia, took part in exchange for course credit.

Stimuli
Stimuli were 16 lines varying in length (Figure 1). See
Table 1 for pixel lengths. Lines were 11 pixels in width and
were black, presented on a white background. Stimuli were
log spaced, and were separated by a distance substantially
greater than the Weber fraction for length (2%; Laming,
1986; Teghtsoonian, 1971).

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
Figure 1. Unidimensional stimuli (line lengths) used in the
Experiment. On any single trial, two of these stimuli were
presented consecutively. All possible pairs of stimuli,
including identical stimuli, were presented twice during the
Experiment.

Table 1. Pixel lengths of the 16 lines used as stimuli
Pixel Lengths
15

18

22

27

33

41

50

61

74

90

110

134

164

200

244

298

Procedure
Participants were instructed to rate the similarity of two
stimuli that appeared on a computer monitor, on a scale of 1
to 100. On each trial, a single line would appear on the
screen for 1 sec, followed by another line for 1 sec. The
position of each line was jittered randomly on every
presentation. After the two stimuli had been removed from
the screen, a slider panel appeared at the bottom of the
screen, allowing the participant to move a scrolling bar
along a scale of 1 to 100 (where 1 = dissimilar and 100 =
similar). Every possible pair of stimuli from the set,
including identical pairs were presented twice. This resulted
in 8 blocks of 64 trials, or a total of 512 trials (i.e., where
n=16 stimuli and r=2 replications, number of trials = rn2). A
mandatory 30 sec break was taken between each block.
Each participant was given five practice trials at the
beginning of the experiment, where they were asked to
complete an identical task to the one above, with the
exception that the stimuli were circles varying in diameter.
The purpose of the practice trials was only to familiarize the
participant with the response method. Different stimuli were
used to prevent additional exposure to experimental stimuli.

2805

Results
The main objective of our analysis is to determine
whether the stimuli used by Dodds et al. (submitted) are
represented internally by one or multiple dimensions. Initial
descriptive analysis suggested that the data were consistent
with a one-dimensional explanation: Figure 2 shows the
average similarity ratings across participants, plotted as
function of stimulus magnitude for each stimulus in the
rating pair. Note that identical stimuli are rated as very
similar (along the central diagonal), and rated similarity
decreases monotonically with the rank-distance between the
stimuli (at the left and right corners).

data. Figure 3 graphs the average stress value, across
participants, for MDS fits with dimensions from 1 to 10 (a
scree plot).

Figure 3. Scree plot showing the decrease in stress value as
the number of dimensions increase.

Figure 2. 3D structure of similarity ratings of all 16 stimuli.
Although Figure 2 indicates that the similarity ratings are
consistent with a 1D psychological representation, they
could nevertheless hide very subtle effects in the data, or
large effects for individuals that average out in the group. In
order to test this, we calculated non-metric MDS analyses
for individual data. Each participant’s data were
transformed into a single symmetric dissimilarity matrix by
subtracting the average similarity rating for each pair of
items from 100 and averaging across reversed presentations
(e.g., stimulus pair #1-#7 with stimulus pair #7-#1). This
matrix was submitted for MDS analyses using both 1D and
2D representations for the data.
Deciding which of the 1D and 2D MDS analyses provides
the best account of the data is not trivial. Various ad hoc
methods have been used, including examining a goodness of
fit measure, or examining the spatial arrangement the points
in proximity plots. We applied both methods to our data. In
MDS, goodness of fit between the reconstructed and
observed dissimilarity matrices is typically measured by
sum-squared error, which is called the stress value. Smaller
stress indicates a better fit; however the MDS models are
nested meaning that stress must always decrease as more
dimensions are included. This means that stress must always
be smaller for the 2D than the 1D model. Statistical tests on
the magnitude of decrease in stress are not easily
constructed, because the key properties of non-metric MDS
make it difficult to assume a distributional model for the

Some authors recommend determining the number of
dimensions from a scree plot by finding its “elbow”; a sharp
drop in stress value, followed by a relatively flat
continuation. Such a pattern could suggest that the latter
dimensions fail to provide sufficiently better fit to warrant
adding more dimensions to the model. Unfortunately, this
method fails to provide any insight into the number of
dimensions that best describe the stimuli, as there is no
obvious elbow in the scree plot. This is a common problem
(e.g., Grau & Nelson, 1988; Lee, 2001). In addition, the use
of such methods has been criticized as placing unreasonable
emphasis on a numerical measurement. Such methods to
determine dimensionality are often used to the exclusion of
other, more meaningful aspects of analysis, such as simply
the interpretability of results (Shepard, 1974).
A more appropriate method to determine whether a two
dimensional model provides a sensible description of the
stimuli might be to examine the spatial relationship between
objects in the purported 2D psychological space. This can
be investigated with a “proximity plot”, where each of the
points provided in the similarity matrix are physically
arranged in a manner that best satisfies the distances (or
similarities) provided in the original data. Figure 4 shows
two examples of these proximity plots, for two participants,
from MDS analyses with two dimensions.
The philosophy of using MDS to recover internal
structure relies on the assumption that, if the psychological
representation of the stimuli was truly two dimensional,
these 2D MDS proximity plots should reconstruct the
internal representation. Because of the nature of the models
under consideration (e.g. of categorization and absolute
identification), this internal representation should have some
relatively smooth and systematic shape. On the contrary, if
the internal representation of the stimuli is truly one
dimensional, these 2D MDS proximity plots should

2806

possible; we used 16 stimuli, with maximum and minimum
similarity ratings of 95.91 and 6.88, respectively. Similarity
between stimuli i and j could then be set as:
simmax – (simmax - simmin)*(abs(i-j)/15)

a

b

Figure 4. Two proximity plots of individual fits of a two
dimensional model. Each of these graphs is the resulting
proximity plot from a single participant in the Experiment.
Each point represents a single stimulus in 2D space. Lines
connect adjacent stimuli in the set. The value at the top of
each graph is the stress value, a goodness of fit measure.
illustrate the 1D structure (a straight line) possibly along
with some meaningless noise.
However, these interpretations of the proximity graphs are
only appropriate when examining the results of metric MDS
analyses (using true, quantitative distances). In the current
case, where non-metric MDS analyses must be used,
patterns that may normally suggest a two dimensional
internal representation, might actually arise from data that
are truly one dimensional. This problem stems from the
monotone transformations allowed by non-metric MDS,
between the observed similarity data and the internal
psychological distances (as noted originally by Shepard,
1974). Since non-metric MDS analyses only preserve the
rank order of the similarity ratings, leaving the exact
similarity values to vary in systematic ways that best suit the
data, there is considerable flexibility in the spatial
arrangements that might arise from a single underlying
dimension. Therefore both Figure 4a and Figure 4b could be
construed as evidence favouring a single underlying
dimension. Whilst the two proximity plots demonstrate
distinctly different patterns, both provide evidence to
suggest that our stimuli vary on only a single dimension.
Even though smooth C- or U-shaped proximity plots are
consistent with one dimensional internal representations,
they are also consistent with two dimensional internal
representations – that is, truly C- or U-shaped underlying
structures. We attempt to resolve this ambiguity using a
simulation study comparing MDS outputs from 1D and 2D
fits to truly 1D data, in the presence of noise. These
simulations provide a metric for interpreting the stress
values from our fits to data.

Simulation Study
We investigated this problem of dimensionality with a
simulation study. We generated synthetic data from a
similarity matrix that was truly one dimensional (the rated
distance between each stimulus was a linear function of
their ranked difference in the set). We scaled this generating
similarity matrix to be as similar to the observed data as

From this true similarity matrix, we generated synthetic
data sets that matched the characteristics of the real data.
Noise was added to the matrix using a normal distribution
with standard deviation 12.18, and sampled similarity
values outside [0,100] were truncated. These settings
resulted in synthetic similarity matrices that were nearly
identical to the human data, on average, for the range and
variance of similarities, and also for the variance of
similarity values across participants, conditioned on each
stimulus pair.
We generated 1000 such matrices, and fit each with MDS
using both 1D and 2D settings. The lower panel of Figure 5
shows the difference in stress values between these two fits
for each simulated data set (negative values indicate a better
fit for 2D than 1D).

Figure 5. Difference in stress values for between 2D and 1D
fits of the original data (top panel) and the true 1D data
(bottom panel)
The upper panel of Figure 5 shows the difference between
2D and 1D stress values for the fits to our human data. The
important thing to take from these graphs is that the
decrease in stress generated by moving from a 1D to a 2D
fit is about the same for our human data as it is for our
synthetic data. Since the synthetic data were generated by a
truly 1D process, this means that the stress values calculated
for our human data are entirely consistent with a 1D

2807

account. This provides further support to the evidence
provided by the MDS analysis of our own data – that our
stimuli may vary on only a single dimension.

Discussion
The purpose of the current experiment was test line-length
stimuli commonly used in AI and always assumed to be
unidimensional (e.g., Dodds et al., submitted; Rouder et al.,
2004; Lacouture & Marley, 1995; Lacouture, 1997). Dodds
et al. found that contrary to previous research, their
participants were able to substantially improve their
performance at the task when given significant practice.
Although the stimuli used in their experiment varied on only
one physical dimension, the results were more reminiscent
of experiments using multiple dimensions, where it is more
common to find substantial improvement with practice.
Although the stimuli used in Dodds et al. (submitted)
varied on only one physical dimension, it is possible that
they may vary on multiple psychological dimensions. In
order to examine how many psychological dimensions
underpin these stimuli, we used two methods; 1) using MDS
techniques we examined similarity data taken using these
same stimuli and 2) compared the structure of our data to
simulated one dimensional data. MDS proximity graphs
suggested that the stimuli may vary on a single dimension,
and our simulation study provided further support for this,
showing that these fits could be consistent with a one
dimensional data generating process, when noise is added.
When examining individual proximity graphs taken from
MDS analysis assuming two dimensions, a C (or U) shaped
pattern often emerged, which is commonly assumed to
provide evidence towards a 2D solution (Shepard, 1974).
While this may be appropriate for a metric MDS analysis,
the monotonic transformations unique to non-metric MDS
allow some flexibility in the position of the objects in the
final proximity graph. Despite this difference required in
interpretation of metric vs. non-metric proximity graphs, it
is possible that the two types of proximity graphs generated
by our data (Figure 4) were genuinely representative of one
vs. multiple dimensions, and that the action of specifying
the number of dimensions to examine, forces the model to
fit, sporadically producing evidence for and against a two
dimensional solution. In support of a one dimensional
solution however, our simulated data demonstrate a similar
structure to our original similarity data, suggesting that the
stimuli used in Dodds et al. (submitted) vary on only a
single dimension.
Therefore it appears that the interpretation of MDS output
for the number of underlying dimensions in the data is
difficult. While we were able to gather evidence using a
variety of techniques to suggest that our data were
consistent with a single dimension, MDS could not provide
a definitive answer. Lee (2001) showed that it is possible to
reliably determine dimensionality from MDS analysis, but
only when the determination is between larger numbers of
dimensions. Like us, he found much poorer reliability when
the choice was between lower numbers of dimensions.

Hence, the task of choosing between a low number of
dimensions remains very subjective, and users should take
care not be misled by “overfitting”, where a complex model
imitates data from a simpler underlying data generating
process. Furthermore, in the case of determining
dimensionality, one should take care not to focus solely on
quantitative results such as the stress value, but also take
into consideration the pattern of data in the original
similarity matrix (such as in Figure 2) or even simply the
interpretability of results (Shepard, 1974).
Both the MDS analysis of the similarity data for Dodds et
al.’s (submitted) lines of varying length and our simulation
study were consistent with a 1D psychological
representation. This finding makes it less likely that the
substantial improvement with practice observed by Rouder
et al. (2004) and Dodds et al. (submitted) in absolute
identification of line lengths was due to participants learning
to take advantage of a multi-dimensional psychological
representation. This finding may also extend to the other
stimuli that Dodds et al. employed. Similar learning effects
to that of lines varying in length suggest that modality, or
specifically, the number of dimensions that stimuli vary
within, cannot be the sole cause of the improvement in
performance.
Hence, investigation of alternative
explanations for the improvement they observed seems
warranted.

References
Dodds, P., Donkin, C., Brown, S. D., Heathcote, A. Practice
Effects in absolute identification. Manuscript submitted
for publication
Eriksen, C. W., & Hake, H. W. (1955). Multidimensional
stimulus differences and accuracy of discrimination.
Journal of Experimental Psychology, 50(3), 153-160.
Garner, W. R. (1953). An informational analysis of absolute
judgments of loudness. Journal of Experimental
Psychology, 46(5), 373-380.
Grau, J. W., & Nelson, D. G. K. (1988). The distinction
between integral and separable dimensions: evidence for
the integrality of pitch and loudness. Journal of
Experimental Psychology: General, 117(4), 347-370.
Hartman, E. B. (1954). The influence of practice and pitch
distance between tones on the absolute identification of
pitch. The American Journal of Psychology, 67(1), 1-14.
Lacouture, Y. (1997). Bow, range, and sequential effects in
absolute identification: A response-time analysis.
Psychological Research, 60, 121-133.
Lacouture, Y., & Marley, A. A. J. (1995). A mapping model
of bow effects in absolute identification. Journal of
Mathematical Psychology, 39, 383-395.
Lacouture, Y., Li, S., & Marley, A. A. J. (1998). The roles
of stimulus and response set size in the identification and
categorisation of unidimensional stimuli. Australian
Journal of Psychology, 50(3), 165-174.
Laming, D. (1986). Sensory Analysis. London: Academic
Press.

2808

Lee, M. D. (2001). Determining the dimensionality of
multidimensional scaling representations for cognitive
modeling. Journal of Mathematical Psychology, 45, 149166.
MacLeod, D. I. A. (2003). New dimensions in color
perception. Trends in Cognitive Sciences, 7(3), 97-99.
Miller, G. A. (1956). The magical number seven, plus or
minus two: Some limits in our capacity for processing
information. Psychological Review, 63(2), 81-97
Pollack, I. (1952). The information of elementary auditory
displays. The Journal of the Acoustical Society of
America, 24(6), 745-749.
Rouder, J. N., Morey, R. D., Cowan, N., & Pfaltz, M.
(2004). Learning in a unidimensional absolute
identification task. Psychonomic Bulletin & Review,
11(5), 938-944.
Shepard, R. N. (1974). Representation of structure in
similarity data: Problems and prospects. Psychometrika,
39(4), 373-421.
Teghtsoonian, R. (1971). On the exponents in Stevens' Law
and the constant in Ekman's Law. Psychological Review,
78(1), 71-80.
Weber, D. L., Green, D. M., & Luce, R. D. (1977). Effects
of practice and distribution of auditory signals on absolute
identification. Perception and Psychophysics, 22(3), 223231

2809

