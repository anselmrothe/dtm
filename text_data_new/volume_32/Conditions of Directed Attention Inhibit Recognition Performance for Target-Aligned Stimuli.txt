UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Conditions of Directed Attention Inhibit Recognition Performance for Target-Aligned Stimuli

Permalink
https://escholarship.org/uc/item/15z258w5

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Dewald, Andrew
Sinnett, Scott
Domas, Leonidas

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Conditions of Directed Attention Inhibit Recognition Performance for Target-Aligned Stimuli
Andrew D. Dewald (adewald@hawaii.edu)
Leonidas A. A. Doumas (leonidas@hawaii.edu)
Scott Sinnett (ssinnett@hawaii.edu)
University of Hawaii at Manoa
Department of Psychology
2530 Dole Street, Honolulu, HI 96822
Abstract

were given a word recognition test for the words that had
previously been presented. Behavioral findings suggested
that performance was significantly better (i.e., more words
were correctly recognized) after directly attending to the
words. Furthermore, after attending to the picture stream,
participants were just as likely to incorrectly affirm that a
non-presented foil word had in fact been presented as they
were to correctly identify words that had been originally
presented in the repetition detection task.
While the findings of Rees et al (1999) suggest that
attention plays a critical role in word recognition, one could
make the claim that the words were indeed perceived, but
quickly forgotten because a stabile memory code could not
be formed. However, the authors also compared brain
activations via functional magnetic imaging (fMRI) between
the presented non-words (consonant streams) and words in
the repetition detection task. Importantly, and discrediting
any memory based explanation, while attending to the
picture stream, words and non-words failed to show
different levels of activation in word processing brain areas,
such as the posterior basal temporal region, an important
area associated with word identification (Buchel, Price &
Friston, 1998). Essentially, a string of consonants (e.g.,
BCRTM) was treated the same as a word (e.g., HOUSE)
when attending to the picture stream (Rees et al., 1999).
These results demonstrate that the processing of a written
word requires that attentional resources be directed towards
that word.
Rees and colleagues have also demonstrated a decrease in
visual processing for motion when attentional resources
were depleted (Rees et al., 1997). That is, when attention
was diverted to a difficult task, a reduction in visual motion
perception occurred. In this experiment participants
performed linguistic judgment tasks of varying difficulty
superimposed over a visual motion background while brain
activity was measured with fMRI. The findings suggested
that as the difficulty of the linguistic task increased, brain
activity in an area associated with the processing of motion
(V5; Tootell, 1995) diminished when compared to the easier
task. The authors posited that as task difficulty increases,
attentional resources that could otherwise be used to process
task irrelevant stimuli are recruited for the more difficult
task, resulting in a reduction in perception for task irrelevant
events (Rees et al., 1997; see also Lavie, 1995; 2005 for a
description of attentional load theory).
Despite a multitude of findings suggesting that perception
levels diminish as attentional resources are depleted (see

Watanabe, Náñez & Sasak (2001) demonstrated that the perceptual
learning of task-irrelevant items was enhanced under conditions
when attentional resources were diverted away from the irrelevant
stimuli. However, the current study suggests that when attention is
depleted, recognition for task-irrelevant items is impaired in a
subsequent recognition task. Participants were presented with a
stream of simultaneously presented written words and line
drawings, and required to respond to immediate repetitions in
either the word or picture stream. A surprise recognition test
measured performance for the words. When analyzing word
recognition performance after attention had been directed to the
pictures, words that had previously appeared when attention was
most depleted (i.e., with a picture repetition in the primary task)
were recognized at levels significantly below chance. This novel
finding suggests that information that is actively ignored when
appearing in conjunction with an attended stimulus is subsequently
inhibited in a recognition task.

Introduction
The role of attention in human perception has been
investigated extensively through the better part of
experimental psychology’s history (e.g., Ahissar &
Hochstein, 1993; Broadbent, 1953; Cherry, 1953; James,
1890; Mack & Rock, 1998; Moray, 1954; Seitz &
Watanabe, 2005; Sinnett, Costa & Soto-Faraco, 2006;
Triesman, 1960). A number of findings converge on the
notion that explicit perception requires, at least a certain
degree of attention (Mack & Rock, 1998; Rees, Russell,
Frith, & Driver, 1999). Indeed, this has been demonstrated
even for cognitive processes that have been considered at
one point to proceed in an obligatory or automatic fashion.
For instance, written word recognition, audiovisual
integration in speech perception, and motion detection have
all been empirically supported to require explicit attention in
order for perception to occur (Alsius, Navarra, Campbell &
Soto-Faraco, 2005; Rees, Frith & Lavie, 1997; Rees et al.,
1999).
Despite numerous examples suggesting that visually
presented words are processed automatically (see, e.g.,
Lupker, 1984; Stroop, 1935), Rees et al (1999)
demonstrated that when attentional reservoirs were depleted,
written word perception was interrupted. In their experiment
participants viewed a rapid serial visual presentation
(RSVP) of written items (words or non-words),
superimposed on top of a stream of pictures. The primary
task was to detect immediate repetitions in either the picture
or the word stream. Directly following this task, participants

796

Ahissar & Hochstein, 1993; Lavie, 2005; Mack & Rock,
1998; Rees et al., 1999; Sinnett et al., 2006), Watanabe et al.
(2001; see also Seitz & Watanabe, 2003, 2005)
demonstrated—in direct contrast to the results described
above by Rees et al. (1997)—that the perception of
irrelevant motion can actually be increased under situations
when attentional resources are depleted. Indeed, they
showed that participants’ detection performance for task
irrelevant motion stimuli improved under conditions when
attention was directed to a separate task. Moreover, the
improvement was only seen when the irrelevant motion was
temporally aligned with targets occurring in the attention
demanding task. This is surprising as it demonstrates a
situation where improved perception is observed during
moments when attention is arguably most depleted (i.e.,
when required to detect and respond to a target).
Watanabe et al’s. (2001) participants took part in a series
of experiments in which they were repeatedly exposed to a
background motion signal that was set at either 5% or 10%
coherent motion (see also Seitz & Watanabe, 2003; 2005 for
further examples using the same task). When asked to
determine the direction of coherent motion by choosing one
of eight possible directions, participants performed at
chance levels for the 5% condition, but above chance levels
for the 10% motion condition (suggesting that the motion
was subthreshold in the former, but not the latter,
condition). The same task was also performed when
engaged in a simultaneously presented attention-demanding
task. An RSVP of letters was superimposed over the
background motion, and participants were required to report
the identity of white target letters that occurred in a
sequence of black distractor letters. It is important to note
that when the superimposed white target letter appeared
(i.e., the task-target), the same subthreshold coherent motion
direction was present every single time (i.e., the taskirrelevant target).
Upon completion of this task, participants were again
shown the weak background motion signal and asked to
indicate the direction of the motion by choosing from an
array of eight directions (depicted as arrows). While the 5%
coherent motion condition remained at chance performance
before and after exposure, the 10% coherent motion
condition showed significant improvements in perceptual
performance for the coherent motion, but only for the
specific motion that was synchronized with the presentation
of the white target letter during exposure. Note, this result is
surprising as it shows that an implicitly presented motion
can have a later effect on behavior.
Watanabe and colleagues (2001; 2003; 2005) postulated
that the improved motion perception is due to the temporal
relationship between the task-relevant stimulus (presence of
white letter) and the task-irrelevant stimulus (background
motion). It was hypothesized that if these two stimuli were
presented simultaneously, then the learning associated with
attention being directed to the task-relevant features would
also be applied to the task-irrelevant stimulus, despite
attention being explicitly directed away from the motion

stimulus. These findings are even more surprising when one
considers that significant improvements in performance
only occur when irrelevant stimuli are paired with the most
demanding aspect of a secondary task (i.e., when attentional
reservoirs are depleted, but directed to a temporally aligned
target).
The findings of Watanabe and colleagues (2001; 2003;
2005) seemingly suggest that directed attention is not a
necessary condition for the perceptual learning of irrelevant
targets. While the results are ostensibly robust, their
conclusions stand contrary to the wealth of research that
suggests that these findings would be unlikely to occur;
most research would indicate that perception for irrelevant
stimuli would be diminished under conditions where
attention is utilized in a separate task and not explicitly
directed to the irrelevant stimuli (see for example Rees et
al., 1997).
The present study aimed foremost to investigate the
robustness of Watanabe and colleagues’ claims and expand
their findings to a different type of stimulus; explicitly
presented written words, using a different paradigm.
Accordingly, task-relevant items (visual pictures) were
temporally aligned with task-irrelevant (written words)
items in a RSVP stream to see if this synchronization would
lead to enhanced recognition levels of the task-irrelevant
items. Based on the findings of Watanabe et al. (2001),
enhanced performance would be predicted for taskirrelevant words that appear at the same time as a target
picture when compared with words that do not.

Method
Participants.
Forty participants (n=40) were recruited from the
University of Hawai’i at Manoa in exchange for course
credit. Participants were naïve to the experiment and had
normal or corrected to normal vision.

Materials.
A total of 150 pictures were selected from the Snodgrass
and Vanderwart (1980) picture database. The pictures (on
average 5 to 10 cm’s) were randomly rotated +/-30 degrees
from upright so as to ensure the difficulty of the task in each
version of the experiment (see also Rees et al., 1999). Each
of these pictures was combined with 150 one to two
syllable, high-frequency English words (average length of 5
letters; range 4-6) selected from the MRC psycholinguistic
database (Wilson, 1988). The overall average frequency of
the 150 selected words was 120 per million, ranging
between 28 and 686. The words were displayed in bold,
capitalized letters in Arial font at a size of 24 points. Each
word was superimposed over a picture and the picture-word
stimuli did not exceed 10 cm horizontally or vertically. Care
was taken to ensure that picture-word combinations did not
have any semantic relationship.
Two streams of picture-word stimuli were created. In one
stream, 50 pictures were selected from the database, 25 of
which were pre-selected, duplicated and paired with their

797

match. These repeated pictures acted as targets as each pair
occurred in the visual presentation as an immediate
repetition. The remaining 25 pictures were also duplicated,
but their positioning in the stream of stimuli never allowed
for an immediate repetition. Together this created a block
size of 100 items. A second block of 100 items was created
in which the 25 pictures not immediately repeated in the
first block now served as the pictures that were immediately
repeated. Therefore, across both blocks, each picture was
displayed a total of four times (once as a repeat and then
two other times as non-repeats in the complementary block).
The same principle was used when making streams of items
when the words were repeated (attending to words
condition). To ensure an enhanced level of randomization,
three different groups of 50 words and pictures were created
and randomized in the aforementioned fashion, creating six
different versions of the picture-word superimposed stimuli
for use in the attending to pictures condition as well as the
attending to words condition.
The surprise recognition test administered after the
completion of the repetition detection task, consisted of 100
words from both the previously viewed visual stream (50)
as well as never seen before foil words (50). The foils were
words that were used in a different version of the
experiment as repeated words (fully randomized). The 50
non-foil words presented in the surprise recognition test
were words that were either temporally aligned with the
task-relevant target, (i.e., superimposed over the immediate
repetition of a picture), or were not temporally aligned with
the task-relevant target (i.e., superimposed over nonimmediately repeating pictures). Words synchronized with
task-relevant targets have been given the nomenclature of
target-aligned words and those not aligned with taskrelevant targets have been named non-aligned words (see
Table 1).

The words in the recognition test remained on the screen
until a response was made.

Procedure.
Participants were randomly assigned to one of two
conditions. One group was required to attend to the picture
stream (i.e., ignore the superimposed words) and respond to
immediate picture repetitions, while the other group was
required to respond to immediate repetitions in the word
stream. Participants responded to the repetitions by using
the ‘G’ key on the keyboard.
Each item in the picture-word presentation was presented
for 350 ms with a 150-ms inter-stimulus interval (ISI; blank
screen) between each item for a stimulus onset asynchrony
(SOA) of 500 ms (see Figure 1). Before the first
experimental block, a training block of eight trials was
given and repeated until participants were familiar and
comfortable with the task.
Immediately after the repetition detection task, a surprise
word recognition test was administered to all participants.
Words were displayed individually on the center of the
screen in the same size and font as previously presented in
the repetition detection task, and remained on the screen
until the participant made a response. Participants were
instructed to press the “B” key if they had seen the word
during the repetition detection task or, instead, the “V” key
if they had not seen the word before. Within each group,
half of the participants (n=10) were presented with foils and
target-aligned words, while the other half were presented
with foils and non-aligned words.

Table1: Description of Target-Aligned and Non-Aligned
words.
Word
Type

TargetAligned
NonAligned

Synchronized
Temporal
Pairing with
Task-Target of
Immediately
Repeated
Pictures
Yes

Synchronized
Temporal Pairing
with Non-Task
Target of
Non-Immediately
Repeated Pictures

No

Yes

Figure 1. Rapid Serial Visual Presentation sequence
employed. Each picture–word stimulus was presented for
350 ms and was then replaced by a blank screen for 150 ms
before the next stimulus. Both the word-monitoring task and
the picture-monitoring tasks were performed on the same
streams. Note that in the present example, the word
“HOME” serves as a target-aligned word.

No

Both the repetition detection and word recognition tasks
were randomized and presented on a computer screen one at
a time, in bold, capitalized letters in Arial font at a size of 24
points, just as they were displayed in the previous stream.

798

compared to each other, recognition for non-aligned words
was significantly better than target-aligned words (t(9)=
2.34, p=.044).

Results
Overall surprise recognition performance.
The results of the surprise recognition test were analyzed
in order to compare between conditions (attending pictures
vs. attending words), and also against chance levels.
Overall, recognition performance was significantly better
after attending to the words when compared with after
attending to the pictures (59.4%, SE=1.08 vs. 46.7%,
SE=2.12, t(19)=3.94, p=0.001; see Figure 2). Performance
after attending to the words was significantly better than
chance (t(19)=5.19, p<0.001) while performance after
attending to the picture stream was not significantly better
than chance (t(19)=1.52, p= 0.143).

A.

B.

Figure 2. Overall recognition percentages and standard error
bars for correct identification of words in the surprise word
recognition test after attending to either the word stream
(grey bar) or the picture stream (black bar).

Figure 3. Recognition percentages and standard error bars
for Target-Aligned (grey bar) and Non-Aligned (black bar)
words in the surprise word recognition test after attending to
either the word stream (A) or the picture stream (B).

Target-aligned word recognition.

An analysis was also conducted on the accuracy of the
primary task of immediate target repetition detection.
Overall, subjects were able to accurately detect target
repetitions (75% hit rate vs. 25% miss rate, t(9)= 21.69,
p<.001, see also Sinnett et al. 2006 for similar hit rates using
the same paradigm). In addition, a significant negative
correlation was found between target detection accuracy and
recognition performance for target-aligned words (r (10) = .69, p = .02), further suggesting that target-aligned words
are inhibited in the recognition task.

In order to address the question at hand, that is, if
performance is enhanced for words appearing with a picture
repetition, recognition performance for target-aligned words
was compared with non-aligned words and also against
chance. When attending to words in the repetition task,
subsequent recognition for target-aligned words (words
immediately repeated) was significantly better than chance
performance (59%, t(9)= 2.67, p=.025), while recognition
for non-aligned words (not immediately repeated) was not
statistically different from chance (54%, t(9)= 1.35, p=.210).
There were no significant differences between targetaligned and non-aligned word performance after attending
to the words (t(9)=1.30, p=.224; see Figure 3a). Analysis of
recognition performance after attending to the picture
stream demonstrated that participants were not better than
chance at recognizing non-aligned words (50%, t(9)= 0.08,
p=.931). Interestingly, performance was significantly
different from chance at recognizing target-aligned words
(38%, t(9)= 4.54, p=.001).

Discussion
There are three main findings for the current experiment.
First, we have replicated previous findings on inattentional
blindness showing that word recognition is significantly
better after attending directly to the word stream as opposed
to attending to a distracting stream of pictures (see also
Most, Simmons, Scholl, Jiminez & Chabris, 2001, Rees et
al., 1999; Sinnett et al., 2006). Second, word recognition
failed to be significantly better than chance levels after
attending to the picture stream. That is, participants were
unable to recognize the words if their attention had been
placed elsewhere, suggesting that attention may be a

However, the direction of this significance was the
opposite of what was expected, with performance
significantly worse than chance (see Figure 3b). When

799

necessary component for word recognition (see also Rees et
al., 1999; Sinnett et al., 2006). Lastly, we have shown for
the first time that words that appeared with a picture
repetition (i.e., target-aligned) are recognized at
significantly lower than chance levels after attending to the
picture stream, suggesting, perhaps, an inhibition for
irrelevant information that appears simultaneously with an
attended target. Furthermore, after attending to the words
themselves, subsequent recognition was better than chance
for words that had appeared as a target repetition (i.e.,
target-aligned), while at chance levels for those that had
appeared elsewhere in the stream (i.e., non-target aligned).
Accordingly, this suggests that words that appeared with a
target repetition were either inhibited or facilitated,
depending on whether attention was originally directed to
the pictures or the words in repetition detection task,
respectively.
The finding that there is a possible inhibition of
previously viewed words that appeared with a picture target
stands in direct contrast to the conclusions drawn by
Watanabe and colleagues (2001; 2003; 2005). For their
findings to be replicated here, an enhanced recognition
performance for words synchronized with task-relevant
targets should have occurred. However, while the necessary
temporal synchronization between task-relevant and taskirrelevant stimuli was present, enhanced perception for taskirrelevant stimuli was not observed. In fact, the exact
opposite was seen, in that there was an inhibition of
performance for the recognition of words that were
temporally aligned with the task-relevant target of an
immediate picture detection.
The potential inhibition of the target-aligned words when
attention was diverted to the picture stream is of key interest
to the present findings. While it is apparent that many
investigations have found that when attentional resources
are depleted, unattended and irrelevant stimuli are often not
perceived (Mack & Rock, 1998; Rees et al., 1999; Sinnett et
al., 2006), an inhibition for these stimuli has not been
observed. However, it should be noted that to the best of our
knowledge, this is the first time that a distinction between
irrelevant stimuli appearing with a target, or not, has been
empirically investigated. When doing precisely this in the
present study, an inhibition for words that appeared with
repeated target pictures was observed. One possible
explanation for this would be that due to focused attention
being placed directly on the demanding task of detecting
repetitions, thereby necessitating that the attentional system
actively inhibit irrelevant information in order to facilitate
goal oriented behavior.
Despite significant differences in paradigms, a possible
explanation for the inhibition of target-aligned words after
attending to pictures may be found in the inhibition of return
(IOR) literature (see Klein, 2000 for a review of IOR). If a
target stimulus occurring in the periphery is first cued by a
salient attention grabbing event, then a facilitation is
normally found for the processing of that target if the time
between the cue and the target is relatively short (i.e., < 300

ms; Posner, 1980). However, if there is a longer time period
between the cue and the target (i.e., after attention has been
disengaged from that space), then there is a delay (i.e.,
inhibition) for processing of targets in the previously cued
area. This might be analogous to what was observed in the
present experiment: Information that was attended to is later
inhibited. However, it should be noted that this comparison
is difficult to make as IOR is traditionally seen in visual
search paradigms and measure response latency, while the
present findings result from a non-spatial paradigm
measuring accuracy. Nevertheless, the present findings
could be viewed as an instantiation of a non-spatial,
accuracy based inhibition for ignored stimuli.
As the comparison between visual search and the present
paradigms can be viewed as difficult at best, perhaps a
stronger explanation for the present results can be drawn
from research on negative priming (see Milliken, Joordens,
Merikle, & Seiffert, 1998; Tipper, 1985; Tipper & Driver,
1988). Typically, in negative priming experiments observers
are presented, for instance, with two overlapping streams of
object outlines with each stream printed in a different color
(i.e., green and red). Participants would be required to name
items in one stream (green objects) while ignoring stimuli in
the other stream (red objects). Interestingly, response
latencies are slower for objects that had appeared previously
in the ignored stream (i.e., the to-be- ignored color), than for
objects that participants did not have to ignore previously.
Accordingly, this suggests that while selecting and naming
one picture, the other (simultaneously displayed but not
selected) object seems to be processed as well, at least to the
extent that it influences naming latencies in the following
trial. The theoretical implications of this could quite
obviously be supported by the present findings, as
behavioral responses to the ignored items here were
inhibited in the form of response accuracy.
The significant negative correlation between target
detection accuracy and recognition performance for targetaligned words further illustrates the possibility of negative
priming. That is, while there was a high level of accuracy
for immediate picture repetition detection, performance was
decreased for recognition of target-aligned words
superimposed over the target pictures. Perhaps, as occurs in
the aforementioned negative priming paradigms, the
accurate detection of the primary target is related to
decreased recognition accuracy (rather than a response
latency) for the ignored target-aligned words.
Performance on the surprise word recognition after
attending to the word stream was comparable to that of
previous findings, suggesting that if attention is directed to
words, they are recognized at both better than chance levels
and better than after attending to the picture stream. While
this is not surprising, there is one noteworthy finding:
Overall better than chance performance is driven by targetaligned words (words immediately repeated and serving as
task targets). That is, recognition performance for nonaligned words was not better than chance. Arguably, an
increased amount of attention is allocated to target

800

detection, thereby potentially facilitating memory
consolidation and subsequent performance in the word
recognition task (see Craik & Lockhart, 1972 for a
discussion on levels of processing theory). Accordingly, the
present findings suggest an inhibition for target-aligned
words when attention was directed to the picture stream, but
a trend in the data (59% target-aligned vs. 54% nonaligned) for a facilitation of target-aligned words when
attention was directed to the words themselves.
It is important to take into consideration significant
procedural differences between the present study and the
works by Watanabe and colleagues (2001; 2003; 2005). A
detailed analysis of Watanabe et al’s. (2001) original
paradigm shows that a total of 960 trials, in which 120
consisted of the paired task-relevant and task-irrelevant
stimuli, were presented daily for 20 days (i.e., nearly 100
times the amount here). In addition, the 120 paired taskrelevant/-irrelevant stimuli always had the same direction in
the coherent motion background. This would be equivalent
to presenting only one specific word to appear with picture
repetitions in the present study. Therefore, it might be
possible that perception for irrelevant information paired
with task-relevant information in the Watanabe et al. studies
was an artifact of prolonged exposure in addition to the
temporal synchronization (although this may be negated by
an increased perception for the coherent motion paired with
the task relevant target only). Future research could employ
the paradigm from the present study to investigate
prolonged exposure rates through the utilization of a larger
number of trials and a smaller number of target-aligned
words to see if perception is enhanced, rather than inhibited.

Lavie, N. (1995). Perceptual load as a necessary condition
for selective attention. Journal of Experimental
Psychology: Human Perception and Performance, 21.
Lavie, N. (2005). Distracted and confused?: Selective
attention under load. Trends in Cognitive Sciences, 9.
Lupker, S.J. (1984). Semantic priming without association:
A second look. Journal of Verbal Learning and
Verbal Behavior, 23.
Klein, R.M. (2000). Inhibition of return. Trends in
Cognitive Sciences, 4(4).
Mack, A., & Rock, I. (1998). Inattentional blindness.
Cambridge, MA: MIT Press.
Milliken, B. , Joordens, S. , Merikle, P. & Seiffert, A.E.
(1998). Selective attention: A
reevaluation of the
implication of negative priming. Psychological Review,
105 (2).
Moray, N. (1959). Attention in dichotic listening: Affective
cues and the influence of instructions. Quarterly
Journal of Experimental Psychology, 11, 56-60.
Most, S. B., Simons, D. J., Scholl, B. J., Jimenez, R.,
Clifford, E., & Chabris, C. F. (2001). How not to be
seen: The contribution of similarity and selective ignoring
to sustained inattentional blindness. Psychological
Science, 12.
Posner, M.I., (1980). Orienting of attention. Quarterly
Journal of Experimental Psychology, 32.
Posner, M.I., & Peterson, S.E. (1990). The attention system
of the human brain. Annual Review of Neuroscience,13.
Rees, G., Russell, C., Frith, C. D., & Driver, J. (1999).
Inattentional blindness versus inattentional amnesia
for fixated but ignored words. Science, 286.
Sinnett, S., Costa, A., & Soto-Faraco, S. (2006).
Manipulating inattentional blindness within and across
sensory modalities. Quarterly Journal of Experimental
Psychology, 59(8).
Seitz, A.R. & Watanabe, T. (2003). Psychophysics: Is
subliminal learning really passive? Nature, 422, 36.
Seitz, A.R. & watanabe, T. (2005). A unified model for
perceptual learning. Trends in Cognitive Science, 9 (7).
Snodgrass, J. G., & Vanderwart, M. (1980). A standardized
set of 260 pictures: Norms for name agreement, image
agreement, familiarity, and visual complexity.
Journal of Experimental Psychology: Human Learning
and Memory, 6.
Tootell, B., Silverman, M.S. & R.L. De Valois, R.L.
(1995). Spatial frequency columns in primary
visual cortex. Science, 214(4522).
Tipper, S.P. & Driver, J. (1988). Negative priming between
pictures and words in a selective attention task: Evidence
for semantic processing of ignored stimuli. Memory &
Cognition, 16(1).
Treisman, A. (1960). Contextual cues in selective listening.
Quarterly Journal of Experimental Psychology,12.
Watanabe, T., Náñez,Y., & Sasak, S. (2001). Perceptual
learning without perception. Nature, 413.

References
Alsius, A., Navarra, J., Campbell, R., & Soto-Faraco, S.
(2005). Audiovisual integration of speech falters under
high attention demands. Current Biology, 15(9).
Ahissar, M. and Hochstein, S. (1993). Attentional control of
early perceptual learning. Proceedings of the National
Academy of Science U.S.A, 9.
Craik, F.I.M. & Lockhart, R.S. (1972). Levels of
processing: A framework for memory research. Journal of
Verbal Learning & Verbal Behavior, 11 (6).
DeSchepper, B. & Treisman, A. (1996). Visual memory for
novel shapes: Implicit coding
without attention.
Journal of Experimental Psychology: Learning Memory
and Cognition, 22(1).
Driver, J., & Spence, C. (2004). Crossmodal spatial
attention: Evidence from human performance. In
C. Spence & J. Driver (Eds.), Crossmodal space and
crossmodal attention. Oxford, UK: Oxford University
Press.
Duncan, J., Martens, S., & Ward, R. (1997). Restricted
attentional capacity within but not between
sensory modalities. Nature, 387.

801

