UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Nonverbal Semantic Processing Disrupts Visual Word Recognition in Healthy Adults

Permalink
https://escholarship.org/uc/item/85h8x0j8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Chen, Lang
Rogers, Timothy T.

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Nonverbal Semantic Processing Disrupts Visual Word Recognition in Healthy
Adults
Lang Chen (lchen32@wisc.edu)
Department of Psychology, 1202 W. Johnson Street
Madison, WI 53706 USA

Timothy T. Rogers (ttrogers@wisc.edu)
Department of Psychology, 1202 W. Johnson Street
Madison, WI 53706 USA

Abstract
Two experiments examined the effect of semantic interference
on visual lexical decision (vLD) in normal skilled readers.
Experiment 1 employed a dual-task paradigm to test whether
nonverbal semantic processing disrupts visual word
recognition when the orthographic structure of words and
non-words is controlled. Experiment 2 employed the same
paradigm to test whether participants strategically shifted their
reliance onto orthographic information when orthographic
structure provided a cue to lexicality. The results showed (1)
significant semantic interference in the vLD task in normal
skilled readers when words and non-words were matched for
orthographic well-formedness and (2) no semantic interference
when words and non-words differed reliably in their
orthographic well-formedness. The results are consistent with
the view that accurate lexical decisions depend upon semantic
activation, especially when judgments cannot be made on the
basis of orthographic structure alone.
Keywords: semantics; lexical decision; dual-task; dual-route
models.

Introduction
What is the relationship between semantic and lexical
knowledge in the mind and brain? Neuropsychological
investigations of this question have led to two contradictory
conclusions. One long-standing tradition has emphasized
neuropsychological dissociations to support the argument
that knowledge of word forms and meanings are supported
by functionally independent cognitive systems. For instance,
patient EM performed poorly on semantic tasks such as
picture naming but perfectly when reading or recognizing
even irregular, low-frequency, and orthographically strange
words (Blazely, Coltheart, & Casey, 2005; for similar cases,
also see Cipolotti & Warrington, 1995; Schwarz, Saffran, &
Marin, 1980). For some theorists, such evidence suggests
that successful performance in lexical tasks like reading
aloud or recognizing words does not depend on intact input
from the word-meaning system (Coltheart, 2004).
A different tradition has emphasized that such classical
dissociations are observed in only a tiny fraction of patients
with semantic impairment, and that, in the vast majority of
cases, lexical and semantic impairments go hand-in-hand
(Woollams, Ralph, Plaut, & Patterson, 2007). For instance,
Patterson et al. (2006) examined performance on four

lexical tasks—including reading aloud, lexical decision,
spelling, and past-tense inflection—in fourteen patients with
semantic dementia (SD), a progressive degenerative
syndrome that produces a remarkably pure semantic
impairment. Results revealed that, in all four tasks, all
fourteen patients were seriously impaired at processing
low-frequency items with atypical phonological,
orthographic, or syntactic structure. Similarly Woollams and
colleagues (2007) reported reading performance in a cohort
of 51 patients with semantic impairment and found that only
a vanishingly small proportion—3 out of 51—showed
spared performance comparable to EM’s (and see Graham,
Patterson, & Hodges, 2000; Patterson & Hodges, 1992;
Patterson, Lambon Ralph, Hodges, & McClelland, 2001; for
similar accounts of association between semantic and lexical
impairment). For these theorists, the strong association
between semantic and lexical impairment suggests that, in
most individuals, performance on lexical tasks depends
importantly on intact input from the semantic system (Plaut,
McClelland, Seidenberg, & Patterson, 1996; Seidenberg &
McClelland, 1989).
Differentiating these views on the basis of
neuropsychological evidence has proven challenging
because both views can account for the major findings, that
is, the strong association of lexical and semantic impairment
in the majority of reported cases and the occasional
dissociation in a small minority. For those who believe
semantic and lexical processes are functionally independent,
the strong association arises because the disease process in
these individuals has affected both systems. Patterson et al.
(2006) refer to this as the “Associated but unrelated deficits”
(ABUD) view. Under ABUD, only dissociations provide
useful information about the functional architecture of the
language system, because they straight-forwardly disprove
causal necessity: reading, word recognition, spelling, etc,
cannot of necessity depend upon intact semantic input,
because it is possible for these abilities to be completely
spared in the face of degraded semantic knowledge.
The alternative view—that lexical processes depend
importantly upon semantic input—was dubbed “It’s All
Semantics” (IAS) by Patterson et al. (2006). For proponents
of IAS, the few cases that show strong lexical-semantic

2194

dissociations are the exceptions that prove the rule. Such
cases may deviate somewhat from the more typical pattern
of associated deficits because they are exceptional in other
ways. For instance, they may have had unusually good
lexical skills in their premorbid state, so that, with mild
semantic impairment, they remain capable of performing
within the established norms for their age group, even if
they have declined significantly from their premorbid peak.
From this point of view, the fact that EM was a secretary for
much of her life is potentially important—she presumably
took dictation and as a result may have developed unusually
robust orthographic and phonological representations.
Further complicating the picture is the fact noted by Plaut
(1997) and others that some patterns of apparent
dissociation in the literature may be attributable to poorly
controlled stimulus materials. It is now well established that,
when semantic knowledge degrades, patients can retain
good knowledge of the “surface” structure of different
domains. For instance, even when unable to retrieve the
meanings of words, patients with semantic impairments can
retain knowledge about orthographic structure, that is,
which letter sequences are common and which unusual in
the language. In tests of word-recognition, such patients can
appear completely normal if the target words are all
orthographically well-formed and the distractor words are
all orthographically strange (Rogers, Ralph, Hodges, &
Patterson, 2004). The same patients show serious
impairments, however, if the orthographic structure of
words and non-words is matched—indeed, some patients
judge well-formed non-words to be real words at rates
exceeding chance, showing a strong over-reliance on
orthographic structure in making their decisions.
Taken together, the evidence from neuropsychological
studies is arguably compatible with both ABUD and IAS
and it is not clear that further neuropsychological evidence
can adjudicate the different positions. Because the status of
semantic knowledge cannot be manipulated experimentally
in such studies the causal links between semantic and lexical
processing are difficult to establish.
Experiment 1 of the present study tests the hypothesis that
semantic processing contributes to one kind of lexical
process—word recognition—using a dual-task paradigm.
Healthy participants performed a visual lexical decision task
while simultaneously performing a secondary nonverbal
task (sound judgment) that either did or did not tap semantic
memory. The key question is whether word-recognition is
significantly more disrupted by the semantic than the
non-semantic secondary task. According to ABUD, word
recognition does not depend upon input from semantics, so
there should be no effect of secondary task type as long as
the two tasks are equally demanding. According to IAS,
word recognition does depend upon semantics, so word
recognition should be worse when participants
simultaneously perform the nonverbal semantic task.
Experiment 2 uses the same methods to test the hypothesis

that people show less or even no reliance on input from
semantics when lexicality is confounded with orthographic
structure—that is, when words and non-words differ reliably
in their orthographic well-formedness.

Experiment 1
Method
Participants Fifty-one undergraduate students from
UW-Madison participated in Experiment 1 for course credit
or monetary compensation. All were native English speakers
with normal or corrected-to-normal vision.
Materials and Design Participants were asked to perform
two tasks simultaneously: a visual lexical-decision (vLD)
task and a sound judgment task. The experimental
manipulation concerned whether the sound judgment task
did or did not draw upon semantic knowledge. In the
non-semantic “Tones” condition, participants listened to a
complex tone and judged whether it was ascending in pitch
or not. The task is non-semantic because it does not require
the participant to consult or draw upon stored knowledge
about the sound. In the semantic “Birds” condition,
participants listened to an animal sound and judged whether
it was produced by a bird or not—hence this task required
participants to draw on stored knowledge about the sounds
produced by birds and animals.
The stimuli for the vLD task were adapted from a
previous study (Hauk, et al., 2006) and consisted of 50
orthographically typical words (TW; e.g., “rot”), 50
orthographically strange words (SW; “yacht”), 50
orthographically typical non-words (TNW; “yot”) and 50
orthographically strange non-words (SNW; “racht”). Words
and non-words were matched for the goodness of their
orthographic structure as measured by summed bigram and
trigram frequencies (for details, see Rogers, et al., 2004).
This manipulation ensured that participants could not rely
on the well-formedness of the letter string to decide whether
the item was a word (Blazely, et al., 2005; Plaut, 1997). In
all word items, only 11% of them referred to animal names.
Since little is known about the semantic interference with
non-word stimuli, we will examine the effect of
sound-judgment tasks on word and non-word stimuli
separately.
The sound judgment task included 50 items in each
condition. The tones were complex sounds similar to a dial
tone, half ascending in pitch and half descending, and
varying in initial pitch and rate of change. The animal
sounds included the vocalizations of 25 different birds and
25 non-bird animals. Items from the two conditions were
matched on total duration. A pilot study with 28 participants
who did not engage in Experiment 1 showed that the two
tasks did not differ significantly by items or subjects in

2195

mean accuracy and response time (all ps > 0.10). Thus the
two sound-judgment tasks were closely matched for overall
difficulty.
Procedure The 51 participants were randomly assigned to
either condition, resulting in 25 in Tones and 26 in Birds.
Every participant was tested individually and began with
three short practice sessions. First, participants practiced the
vLD task: on each trial they viewed a letter string on the
computer monitor and pressed a button with their dominant
hand to indicate whether it was a word or not. Next, they
practiced the sound-judgment task alone: participants
listened to a series of sounds presented over headphones and
orally reported their response by saying “Yes” (for
ascending tones in the Tones condition or for birds in the
Birds condition) or “No” (for descending tones / non-birds).
The oral responses were recorded by the experimenter. If
any lexical processing was involved in the oral response, it
should be equivalent across two conditions. In the third
practice phase, participants performed both tasks
simultaneously with a small number of stimuli. In this
practice phase and in the experiment proper, the onsets of
stimuli in vLD and sound tasks were asynchronous so
participants could not get into a “rhythm” of doing one task
then the other. After participants were familiarized with the
dual-task procedure, they continued to the experiment
proper, performing both tasks simultaneously until they had
responded to all 200 items in the vLD task (presented in
random order). In the sound task, sounds were selected
randomly with replacement until participants had finished
the vLD task. The study took about 40 minutes.

The mean accuracy in the sound judgment tasks was
generally high and did not differ significantly between
groups: 0.90 (SD = 0.07) for Tones and 0.93 (SD = 0.03) for
Birds, F(1,49) = 2.329, MSE = 0.003, p = 0.133.
1.0
0.9

Accuracy in Sound Task

1.0

Results

Accuracy in LD

words and non-words in each condition. A one-way ANOVA
revealed that, for word items, accuracy was significantly
lower in the Birds than in the Tones condition both by
subject and by item (Tones, mean = 0.83, SD = 0.08; Birds,
mean = 0.77, SD = 0.10), F1(1,49) = 5.410, MSE = 0.008, p
= 0.024, F2(1,99) = 50.996, MSE = 0.003, p < .001) with no
difference in response time (Tones, mean = 1079.36, SD =
358.67; Birds, mean = 1066.43, SD = 439.40, all ps > 0.10).
For non-words neither accuracy (Tones, mean = 0.86, SD =
0.11; Birds, mean = 0.85, SD = 0.18) nor RT (Tones, mean =
1112.12, SD = 317.14; Birds, mean = 1108.26, SD = 451.54)
differed reliably between conditions, all ps > .05. Thus, the
participants made more errors recognizing words, but not
rejecting non-words, when their semantic system was
occupied with a secondary nonverbal categorization task
compared to an equally-demanding but non-semantic task.
To further test the hypothesis that semantic processing
interferes with vLD, we investigated the correlation in
overall accuracy between the vLD and the sound judgment
task across subjects in each group. If the two tasks do not
share a critical resource, we expect a strong positive
correlation in accuracy: participants who generally cope
well with dual-task situations will perform well on both,
whereas those who generally cope poorly with dual tasks
will perform poorly on both. If, however, the two tasks share
an important resource, this relationship should be altered:
allocation of the resource to one task should boost
performance in one task but should hinder performance of
the other task, attenuating or eliminating the expected
positive correlation between the two tasks.

0.9
0.8
0.7

birds
tones

0.6
0.3

0.8

0.4

0.5
0.6
0.7
0.8
Total accuracy in LD

0.9

1.0

Fig. 2: Correlation between mean accuracy in the vLD task
and sound judgment tasks in Experiment 1.

0.7
0.6

Tones
Birds

0.5
Word

Nonword

Fig. 1: Mean accuracy of the vLD task in Experiment 1.
Figure 1 shows mean accuracy and standard errors for

Figure 2 plots the mean accuracy in vLD and the
sound-judgment task for the two groups. Performance on
vLD and the Tones task was positively correlated (r = 0.700,
p < .001), while this relationship in the Birds condition was
not reliable (r = 0.201, p = .325) and was significantly lower
than that in Tones condition, Z = 2.225, p = 0.026. Thus
some participants traded off accuracy on vLD for an
acceptable level of accuracy on the semantic but not the

2196

non-semantic sound judgment task.

Experiment 2
Experiment 1 found that healthy participants showed worse
performance on the vLD task when their semantic
knowledge was engaged in a concurrent task. Experiment 2
assessed whether this semantic interference is attenuated
when orthographic structure provides a valid cue to
lexicality. We hypothesized that, if words and non-words
differed reliably in their orthographic well-formedness,
participants could rely on this surface cue to guide their
decisions, so that reliance on the semantic system would be
reduced or eliminated.

Method
Participants Sixty undergraduate students who did not
participate in Experiment 1 participated in return for course
credit.
Materials and Designs We used identical materials but with
two important differences in design. First, stimuli were
grouped into two sets in such a way that, within each set,
words and non-words differed systematically in their
orthographic structure. Thus Set 1 (TW-SNW) included
typical words (e.g., rot) and strange non-words (e.g., racht);
while Set 2 (SW-TNW) included strange words (e.g., yacht)
and typical non-words (yot). Participants completed either
Set 1 or Set 2. Second, to maximize our power to detect an
influence of semantic interference on word recognition, the
secondary task condition (Tones vs. Birds) was manipulated
within every subject. Each set was divided into two subsets
closely matched for accuracy and response time (all the ps >
0.05) in a pilot study with 23 participants who did not
participate in Experiment 2. Participants in each group then
completed one subset paired with the Tones task and the
other subset paired with the Birds task. The order of subsets
and their combinations with Tones or Birds condition were
counterbalanced across participants.
Procedure Participants were randomly assigned to one of
the set conditions resulting in 30 participants in each. The
dual-task procedure was identical to that in Experiment 1
except that the participants were exposed to both Tones and
Birds conditions in a block design.

the larger SD in this condition. We will return to this issue
later in this section.
Neither mean accuracy nor RT in the vLD task differed
significantly in the Tones versus Birds conditions—F values
ranged between 0.005 and 2.04, all ps > 0.16 for all
comparisons except response time to reject non-words for
tones versus birds. In this contrast there was a trend toward
an effect, but with somewhat faster response times in the
Birds than the Tones condition (Tones, mean = 1026.45, SD
= 340.14; Birds, mean = 956.34, SD = 364.01), F1(1,29) =
3.424, MSE = 21558.907, p = 0.073, F2(1,49) = 2.400, MSE
= 61468.119, p = 0.128). Thus there is no evidence that
performance of the nonverbal semantic task disrupted word
recognition in this condition.
Could this difference from Experiment 1 somehow be
attributable to the participants who performed poorly at
Tone judgment? To address this question we identified 8
participants with accuracy lower than 0.80 in the Tones task
and excluded them from all analyses to see whether the
results would differ. With these participants excluded, mean
accuracy in Tones condition was 0.91 (SD = 0.07) which
was not significantly difference from the Birds condition
(mean = 0.91, SD = 0.04), F(1,21) = 0.242, MSE = 0.004, p
= 0.628). In the remaining 22 participants we still observed
no reliable effect of sound-judgment task on either accuracy
or response time in the vLD task (all the ps > 0.05). Thus
when words are well-formed and non-words are ill-formed,
there is no evidence that participants rely on semantic
processing to make lexical decisions.
Set 2 (SW-TNW) For participants who completed Set 2,
where words were orthographically ill-formed and
non-words were orthographically typical, there was no
significant difference in the sound judgment accuracy for
Tones versus Birds (Mean accuracy = 0.91, SD = 0.08 for
Tones and 0.93, SD = 0.04 for Birds, F(1,29) = 0.781, MSE
= 0.003, p = 0.384).
Just as in Set 1, the mean accuracy and response time for
the vLD task did not differ significantly in the Tones versus
Birds conditions—all F ratios were between 0.001 and 1.17,
all ps > 0.28. Thus even when words were orthographically
strange and non-words were regular, participants showed no
evidence of worse performance when simultaneously
performing a semantic relative to a non-semantic task.
Experiment 2 thus suggests that, when orthographic
structure can serve as a reliable cue to lexicality, participants
do not substantially rely upon semantic processing to
recognize words.

Results

Discussion
Set 1 (TW-SNW) Unexpectedly, the mean accuracy in the
sound judgment tasks differed reliably for this group (0.86,
SD = 0.10 for Tones and 0.91, SD = 0.04 for Birds), F(1,29)
= 6.447, MSE = 0.006, p = 0.017. Some participants
performed especially badly in the Tones task, as implied by

In a dual-task interference paradigm
nonverbal semantic processing disrupted
in healthy adults (Experiment 1),
orthographic structure did not provide

2197

we found that
word recognition
especially when
a useful cue to

lexicality (Experiment 2). These results are consistent with
the view that word recognition depends upon semantic
processing (Patterson, et al., 2006; Rogers, et al., 2004;
Woollams, et al., 2007), and they also suggest, in
accordance with other work (Plaut, 1997), that such effects
can be attenuated in tasks that confound lexicality with
orthographic structure.
Our results complement patient studies documenting a
strong association between impaired semantic knowledge
and disturbed performance on lexical tasks including word
recognition (Patterson, et al., 2006; Rogers, et al., 2004;
Woollams, et al., 2007). A natural interpretation of this
patient work has been that semantic, orthographic and
phonological representations of words are all represented
within the same interactive system (Dilkina, McClelland, &
Plaut, 2008; Plaut, et al., 1996) so that, when semantic
representations degrade, so too does the stability of unusual
phonological and orthographic forms. This hypothesis has
proven difficult to test through patient studies alone,
however, because it has been difficult to rule out the
alternative hypothesis that lexical and semantic impairments
occur as a consequence of a disease process that jointly
affects two independent systems. The current study provides
a stronger test of the hypothesis because there is no disease
process—instead, the contribution of semantic processing to
word recognition was functionally disrupted by engaging
the semantic system in a secondary task. Moreover, the
secondary task was a nonverbal sound-recognition judgment
that arguably makes no demands upon lexical processes.
Nevertheless, it led to poorer word-recognition when
performed simultaneously with vLD.
Our results challenge the view that there exists “an
orthographic lexicon that is distinct from the semantic
system” (pp1163, Coltheart, 2004). On this view, normal
participants with intact orthographic lexicons should show
equivalent performance in dual-task conditions, regardless
of nature of the secondary task, because accurate
word-recognition can be accomplished solely by
consultation of the orthographic lexicon.
Others have previously argued that the orthographic
structure of targets and distracters might influence the extent
to which accurate lexical decisions depend upon semantic
processing (Plaut, 1997; Seidenberg & McClelland, 1989),
and this hypothesis was corroborated in Experiment 2: using
the same materials and procedure as Experiment 1, the
semantic interference effect was eliminated simply by
blocking stimuli so that orthographic well-formedness
provided a reliable cue to lexicality. If participants could
perform accurately simply by accepting (for Set 1) or
rejecting (for Set 2) all well-formed letter strings, then they
relied less or not at all on semantic input.
It is worth noting that this latter result also poses a puzzle
for the view that there exists an orthographic lexicon that is
independent of semantics. If lexical decisions are “…done at
the level of the orthographic lexicon” (pp701, Blazely, et al.,

2005), it is not clear why one should observe different
patterns of behavior for the exact same set of target words,
depending upon how they are blocked with non-word
distractors. Besides, the results from Experiment 2
eliminated the possibility that the semantic interference
observed in Experiment 1 was due to difference in the extent
of covert word reading across conditions. If so, some might
expect to observe poorer performance on vLD in the Birds
condition as well, since the same paradigm and sound
stimuli were used in Experiment 2. However, this prediction
is not supported by the result, suggesting that the covert
articulation, if any, cannot be the alternative explanation for
the observed semantic inference in Experiment 1.
The present study leaves at least one important question
unanswered: How does one account for individual cases
who, despite serious semantic impairment, can perform
within the normal range on tests of word recognition or
other lexical tasks? Recent computational modeling work
has emphasized that individual differences in linguistic
experience can influence the performance of lexical tasks
and might account for the occasional lexical/semantic
dissociations observed in neuropsychological studies
(Dilkina, et al., 2008). For instance, Zevin and Seidenberg
(2006) showed that variability in the model training regime
can produce individual differences in non-word reading
patterns similar to those observed in skilled readers. Dilkina
et al. (2008) also demonstrated how differences in the
frequency with which a model encounters orthographic
versus visual inputs can produce dissociations between word
reading and object naming in an interactive model of the
lexico-semantic system.
In addition to such differences in experience, our results
suggest that individuals may differ in other important
respects. In Experiment 1, we found that, whereas some
individuals
coped
well
with
the
dual
task
scenario—performing near ceiling on both tasks—others
struggled considerably and, in the “semantic interference”
condition, appeared to trade off the accuracy of one task for
another. Previous work (Herdman & LeFevre, 1992) has
shown that a dual-task paradigm increases resource
demands and affects different aspects of word recognition
process, such as speed and efficiency. Presumably,
participants with superior cognitive control are better able to
manage the resource demands for both tasks and so may
show little semantic interference. Understanding how
individual differences in linguistic experience and in
cognitive control may contribute to differential reliance on
the semantic system in the performance of lexical tasks
remains a goal for future research.
In conclusion, the present study demonstrates that normal
participants’ performance on a visual lexical decision task is
disrupted by a simultaneous sound judgment task that taxes
semantic memory, suggesting that lexical processes draw
upon semantic processes. Moreover, the semantic
interference was affected by the orthographic structure of

2198

the words and non-words, suggesting that reliance on
semantic versus orthographic information in lexical decision
is dynamic.

McClelland, J. L. (2001). Deficits in irregular
past-tense verb morphology associated with
degraded semantic knowledge. Neuropsychologia,
39(7), 709-724.

Acknowledgements
This research was funded by a Vilas Fellowship awarded by
the University of Wisconsin-Madison to the second author.

Patterson, K., Ralph, M. A. L., Jefferies, E., Woollams, A.,
Jones, R., Hodges, J., et al. (2006). "Presemantic"
cognition in semantic dementia: Six deficits in

References

search of an explanation. Journal of Cognitive

Blazely, A. M., Coltheart, M., & Casey, B. J. (2005).
Semantic impairment with and without surface

Neuroscience, 18(2), 169-183.
Plaut, D. C. (1997). Structure and function in the lexical

dyslexia: Implications for models of reading.

system: Insights from distributed models of word

Cognitive Neuropsychology, 22(6), 695 - 717.

reading and lexical decision. Language &

Cipolotti, L., & Warrington, E. K. (1995). Semantic memory
and reading abilities: A case report. Journal of the

Cognitive Processes, 12, 765-806.
Plaut, D. C., McClelland, J. L., Seidenberg, M. S., &

International Neuropsychological Society, 1,

Patterson, K. (1996). Understanding normal and

104-110.

impaired word reading: Computational principles

Coltheart, M. (2004). Are there lexicons? Quarterly Journal

in quasi-regular domains. Psychological Review,

of Experimental Psychology: Section A, 57,
1153-1171.

103(1), 56-115.
Rogers, T. T., Ralph, M. A. L., Hodges, J. R., & Patterson, K.

Dilkina, K., McClelland, J. L., & Plaut, D. C. (2008). A

(2004). Natural selection: The impact of semantic

single-system account of semantic and lexical

impairment on lexical and object decision.

deficits in five semantic dementia patients.

Cognitive Neuropsychology, 21(2-4), 331-352.

Cognitive Neuropsychology, 25(2), 136-164.

Schwarz, M. F., Saffran, E. M., & Marin, O. S. M. (1980).

Graham, N. L., Patterson, K., & Hodges, J. R. (2000). The

Fractionating the reading process in dementia:

impact of semantic memory impairment on spelling:

Evidence for word-specific print-to-sound

Evidence from semantic dementia.

associations. In M. Coltheart, K. Patterson & J. C.

Neuropsychologia, 38(2), 143-163.

Marshall (Eds.), Deep dyslexia. London: Routledge

Hauk, O., Patterson, K., Woollams, A., Watling, L.,
Pulvermüller, F., & Rogers, T. T. (2006). [Q:]

and Kegan Paul.
Seidenberg, M. S., & McClelland, J. L. (1989). A distributed,

When would you prefer a SOSSAGE to a

developmental model of word recognition and

SAUSAGE? [A:] At about 100 msec. ERP

naming. Psychological Review, 96(4), 523-568.

correlates of orthographic typicality and lexicality

Woollams, A. M., Ralph, M. A. L., Plaut, D. C., & Patterson,

in written word recognition. Journal of Cognitive

K. (2007). SD-squared: On the association between

Neuroscience, 18, 818-832.

semantic dementia and surface dyslexia.

Herdman, C. M., & LeFevre, J.-A. (1992). Individual
differences in the efficiency of word recognition.

Psychological Review, 114(2), 316-339.
Zevin, J. D., & Seidenberg, M. S. (2006). Simulating

Journal of Educational Psychology, 84(1), 95-102.

consistency effects and individual differences in

Patterson, K., & Hodges, J. R. (1992). Deterioration of word

nonword naming: A comparison of current models.

meaning: Implications for reading.

Journal of Memory and Language, 54(2), 145-160.

Neuropsychologia, 30(12), 1025-1040.
Patterson, K., Lambon Ralph, M. A., Hodges, J. R., &

2199

