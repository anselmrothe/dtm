UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Tracking Lexical and Syntactic Alignment in Conversation

Permalink
https://escholarship.org/uc/item/42m4n7n0

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 32(32)

Authors
Howes, Christine
Healey, Patrcik G.T.
Purver, Matthew

Publication Date
2010-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Tracking Lexical and Syntactic Alignment in Conversation
Christine Howes, Patrick G. T. Healey and Matthew Purver
{chrizba,ph,mpurver}@dcs.qmul.ac.uk
Queen Mary University of London
Interaction, Media and Communication Group
Mile End Road, London E1 4NS
Abstract
As much empirical work attests, people have a reliable tendency to match their conversational partner’s
body movements, speech style, and patterns of language
use – amongst other things. A specific version of this
tendency, Structural priming, which occurs when prior
exposure to a particular linguistic structure facilitates
one’s subsequent processing of the same structure, has
gained widespread acceptance. Pickering and Garrod
(2004) propose that cross-person structural priming is a
basic mechanism of conversational coordination – part of
an automatic, resource-free alignment mechanism that
is the basis for all successful human interaction. We
present evidence to the contrary from two analyses of a
corpus of ordinary conversation. The first suggests that
the level of structural (syntactic) matching is no different from chance, and the second that the observed
statistical correlation between prime form and target
form may be entirely associated with repetition of lexical
form.
Keywords: structural priming; alignment

Introduction
The apparent tendency for speakers to repeat their own
or others syntactic or structural choices in conversation
– a phenomenon referred to as structural or syntactic
alignment – has been a subject of particular scrutiny
(see Pickering and Ferreira (2008) for an overview).
The evidence for such alignment in dialogue comes
from two main sources: experimental studies of taskoriented dialogue (e.g. (Branigan, Pickering, & Cleland,
2000)), and corpus studies that track frequency of use of
these same constructions in language use outside of the
laboratory setting (e.g. (Gries, 2005)).
In the basic experimental set-up of Branigan and colleagues, there are two participants, one of whom is a
confederate of the experimenter. The participants describe picture cards to each other, the critical items of
which require the use of ditransitive verbs in their descriptions. In English, there are two syntactic structures which can be used; one a double object structure
(“The thief giving the nurse the banana”), and the other
using a preposition (“The thief giving the banana to
the nurse”). The confederate uses a scripted description of the ditransitive prime sentences, thus manipulating which type naive subjects are exposed to. Participants are more likely to use the type of structure
that they have just used or been exposed to. This has
been found to hold across comprehension and production
(Branigan, Pickering, Stewart, & McLean, 2000; Bock,
Dell, Chang, & Onishi, 2007), from main clauses to rel-

ative clauses (Branigan, Pickering, McLean, & Stewart,
2006) and even across languages in bilingual speakers
(Hartsuiker, Pickering, & Veltkamp, 2004). Different
factors found to increase the strength of syntactic alignment include the distance between the prime and the
target, participant role (Branigan, Pickering, McLean,
& Cleland, 2007) and, importantly for the interactive
alignment model (see below), reuse of the same or semantically related lexical items (Branigan, Pickering, &
Cleland, 2000).
In a corpus study using the International Corpus of
English (ICE-GB), Gries (2005) looked at the same syntactic alternation. His data show that there is a tendency
to reuse the form of a ditransitive verb most recently encountered (double object or prepositional), in line with
the experimental results. Similar results have been found
to hold with different constructions such as particle
placement of phrasal verbs (Gries, 2005), future markers
(“will” versus “going to”) and comparatives (“cleverer”
versus “more clever than”) (Szmrecsanyi, 2005).
Pickering and Garrod (2004) argue, in their Interactive Alignment model, that alignment is the basis for
successful communication; “successful dialogue occurs
when interlocutors construct similar situation models to
each other” (Pickering & Garrod, 2006, p206). In order to do this, interlocutors align on situation models;
however, as this alignment is not usually negotiated explicitly, it is hypothesised to arise automatically from
local alignment, via resource-free priming mechanisms.1
Alignment at local levels, including lexical (repetition
of words) and the syntactic alignment discussed above,
“percolates”, leading to alignment at other levels.

From priming to alignment?
There are three problems with using these studies to
support the claim that cross-speaker structural priming
is ubiquitous in conversation. First, automatic priming
predicts an increase in matching of all structures across
turns, but this claim has not been directly tested. For
practical reasons, experimental studies have focussed on
situations in which specific syntactic alternatives can be
used to describe the same situation. Similarly, corpus
studies have tended to track the frequency of use of spe1

Note that the observed effects are alignment effects;
priming mechanisms are their hypothesised cause, leading to
two distinct questions – does such alignment occur; and if it
does, is it caused by priming?

2004

cific constructions across participants and time, rather
than addressing whether or not people tend to match
one-another in general (e.g. Gries (2005)). One exception is Reitter, Moore, and Keller (2006), who examined
general syntactic similarity, but results were unclear.
Reitter et al. (2006), used two corpora, one task-specific
(Map Task) and one more general (Switchboard), and
saw a large difference: while same-person priming was
found in both datasets, cross-person priming was found
only in the task-specific dialogues.2
The second problem is that the data used in these
studies is not adequately representative of ordinary dialogue. As Pickering and Garrod (2004, p187) say:
The interactive alignment model was primarily developed to account for tightly coupled processing
of the sort that occurs in face-to-face spontaneous
dyadic conversation between equals with short contributions. We propose that in such conversation,
interlocutors are most likely to respond to each
other’s contributions in a way that is least affected
by anything apart from the need to align.
However, in the experiments, the confederate is
scripted, and the naive participants were told that if
they didn’t understand they “could say “Please repeat,” but nothing else” (Branigan et al., 2007, p175).
And while corpora can provide more spontaneous data,
Gries (2005)’s corpus is biased towards written and spoken monologue, and a significant proportion of the dialogues it samples involve specialised institutional settings, e.g. legal cross-examinations and broadcast interviews.
The third problem is that these studies have not used
a control condition. As a result the chance level of structural matching is unknown and effects such as conversational genre cannot be discounted (cf. Tannen (2007)).
In order to address two of these issues,3 we conducted
an experiment which tested the degree of match of dative alternation structures in a corpus of naturally occurring dialogue data. We compared this measure to
control conditions for the same genuine conversational
data manipulated to create ‘dialogues’ from turns actually occurring in different conversations (see below).

Experiment 1
Method
The corpus used here is the Diachronic Corpus of
Present-Day Spoken English (DCPSE). This consists of
885,436 words together with a full set of parse trees
that have been hand-checked by linguists. It includes

several distinct genres of dialogue. We consider the
two-person portions of the three largest samples: Faceto-Face Formal (90,000 words), Face-to-Face Informal
(403,000 words) and Telephone Conversations (47,000
words). This gives us 127 dialogues with an average
of 45.24 turns per person (per dialogue), which ought to
provide us with the data most likely to exhibit alignment
phenomena (see above).
Creating control dialogues In order to discount
the potential biasing effect of conversational structure
(e.g. recurrent patterns of turn-taking, topic shifts, openings and closings) on syntactic similarity, a control condition that captures how similar two people’s conversational turns would be by chance is needed. For each
‘real’ dialogue in each genre in the corpus, we therefore create two types of ‘fake’ control dialogue. For the
first, the random-speaker control, one speaker’s turns are
kept and interleaved with the turns of another speaker
from a different dialogue (matching dialogues by genre,
matching by length as closely as possible, and discarding any ‘unmatched’ turns). This ‘fake’ dialogue thus
maintains turn order for each speaker; but consists of
the turns of two speakers who did not, in fact, interact. For the second ‘fake’ dialogue, the random-sentence
control, a new dialogue of the same length is created
by randomly choosing sentences, each time allowing a
new choice of dialogue and speaker (but always matching dialogue genre). This ‘fake’ dialogue thus maintains
neither turn order nor speaker identity (see table 1 for
comparisons).
Table 1: Real and control dialogues comparison
Genuine dialogue:
A: Are you going to go to all of the phonology lectures
B: I think I ought to do that
A: Yes. I think you had. Yeah
B: I mean I don’t know how much I’ll take in
A: I think I’ll go to most of them. But I won’t go to all of
pragmatics the day before
Random-speaker control dialogue:
A: Are you going to go to all of the phonology lectures
C: Well uh ask one of the stallholders down Chapel Street.
They’ll all know
A: Yes. I think you had. Yeah
C: Uhm I was down there the other day and I got some
excellent salmon
A: I think I’ll go to most of them. But I won’t go to all of
pragmatics the day before
Random-sentence control dialogue:
A: Are you going to go to all of the phonology lectures
D: Uhm one of the few. Oh George was impossible
E: Just normal water
F: Yes. What do they call it
G: Oh dear. It does not bode very well

2

In fact, the opposite appeared to hold in the general corpus – participants seemed to avoid repeating each others’
syntactic structure.
3
The first issue we address in additional work; see
e.g. Healey, Howes, and Purver (2010); Healey, Purver, and
Howes (2010).

Creating these control dialogues allows us to compare
the syntactic similarity observed in the real data with
the similarity that would be observed by chance. By
choosing a suitable similarity metric, we can express the

2005

average similarity observed between turns or between
speakers; and examine the difference between the real
and control corpora. Choosing a general syntactic similarity metric (which takes all observed structural rules
into account) would allow us to compare with Reitter et
al. (2006); see e.g. Healey, Purver, and Howes (2010).
In this paper, we only consider the specific ditransitive alternation discussed above, allowing comparison
with Branigan, Pickering, and Cleland (2000) and Gries
(2005).
Metric and predictions Considering only a single
syntactic phenomenon gives us essentially a binary metric: a target sentence scores 1 if it reuses the form of
the most recent prime sentence, and 0 otherwise. More
concretely, each sentence is given a score of 1 only if:
1. it uses one possible form of the phenomenon in question: a double-object or prepositional-object construction; and
2. the most recent prior sentence in the same dialogue
which exhibits the same phenomenon also uses the
same form.
and 0 otherwise. Summing sentence scores and normalising by the number of sentences gives us the score for
each individual in a dialogue. These scores can then be
compared between the real and control corpora.
We test three key predictions:
1. Priming: Sentences in real conversations should display reliably more turn-by-turn structural matching
than would occur by chance.
2. Person: Structural matching should be observed both
between sentences produced by the same participant,
and between those produced by different participants.
3. Genre: Relatively restricted registers should promote
a higher level of cross-speaker structural matching
than less restrictive registers.

Results
Two different analyses were carried out: the first compares real levels of matching against the control dialogues as outlined above, and the second compares the
level of (real) same-person matching against (real) otherperson matching.
In order to test predictions on Priming (1) and Genre
(3) the average turn-by-turn syntactic similarity scores
for each dialogue participant4 in each Genre were analysed in a mixed analysis of variance with Dialogue Type
(Real × Control) as a within subjects factor and Genre
(Face-to-Face Formal × Face-to-Face Informal × Telephone Conversations) as a between subjects factor.
4

Shown as N in tables 2 and 3. As we were only looking
at 2-person dialogues this equates to 127 dialogues overall.

For overall similarity (this measure includes both
same-person and other-person matching), the analysis showed no reliable difference between the Real and
Control (i.e. ‘fake’) dialogues (random-sentence control:
F(1,251) = 1.067, p = 0.30, random-speaker control:
F(1,251) = 0.11, p = 0.92),5 no significant main effect
of Genre (random-sentence control: F(2,251) = 1.279, p =
0.28, random-speaker control: F(2,251) = 1.881, p = 0.16)
and no interaction between Dialogue Type and Genre
(random-sentence control: F(2,251) = 0.213, p = 0.81,
random-speaker control: F(2,251) = 0.809, p = 0.45).
The absolute levels of syntactic matching of the dative
alternation were not reliably different from chance (see
Table 2). There were also no significant results when
comparing only cross-person similarity with its control
condition.
Comparing same-person versus cross-person similarity using a mixed analysis of variance with Speaker
(Same × Other) as a within subjects factor and Genre
as a between subjects factor showed a reliable difference between the Same and Other person (F(1,251) =
4.124, p = 0.043), no significant main effect of Genre
(F(2,251) = 1.058, p = 0.35) and no interaction between
Dialogue Type and Genre (F(2,251) = 0.499, p = 0.61)
(see Table 3). This means that there is reliably more
matching to one’s own prior utterances than to another
person’s.

Discussion
These results seem to show that, at least for the dative
alternation construction, in contrast to hypothesis (1),
sentences in the DCPSE do not show reliably more structural matching than would occur by chance. In regards
to (2), the overall level of same-person matching was
higher than that of other-person matching (in line with
experimental findings that production-production priming is higher than comprehension-production). However
due to the control conditions used, it is not possible to
ascertain whether the same person matching on its own
is reliably higher than chance (though recall that both
other person matching and overall levels of matching
were not). As for hypothesis (3), although it appears
from tables 2 and 3 that there is greater matching in the
more restricted registers as predicted, pairwise comparisons did not show any significant effects. This could be
due to the relatively small values, and limited number
of cases, and further work is necessary to see if this is a
genuine effect.
As the observed power values were in some cases as
low as 0.2, we cannot reject the null hypothesis outright. Power calculations suggest that we require four
times more data in order to be able to do so, and to
this end we are currently conducting analyses on the
5
For completeness we report exact probabilities but
throughout adopt a criterion probability level of < 0.05 for
accepting or rejecting the null hypothesis.

2006

Table 2: Mean Dative Alternation Similarities
N
Real
RandomSimilarity
(s.d.)
Sentence
(s.d.)
Face-to-Face Formal
60
0.017
(0.016)
0.013
(0.016)
Face-to-Face Informal
94
0.013
(0.015)
0.012
(0.014)
Telephone Conversation 100
0.012
(0.025)
0.012
(0.018)
Overall Mean
254
0.014
(0.019)
0.012
(0.016)
Dialogue Type

RandomSpeaker
0.018
0.014
0.011
0.014

Table 3: Mean Dative Alternation Similarities
Dialogue Type
N
Same Person
(s.d.)
Other Person
Face-to-Face Formal
60
0.010
(0.014)
0.007
Face-to-Face Informal
94
0.008
(0.012)
0.005
Telephone Conversation 100
0.007
(0.012)
0.006
Overall Mean
254
0.008
(0.012)
0.006

British National Corpus (BNC), which includes 2884 2person conversations (Healey, Purver, & Howes, 2010).
Another alternative to increase power would be to treat
each occurrence of either form of the dative alternation
as a separate datapoint, as Gries (2005) did, rather than
taking an overall value per person per conversation. Experiment 2 reports such an approach.

Experiment 2
These results suggest that there is little or no priming above chance for the dative alternation in ordinary
dyadic conversation. Prima facie, this is inconsistent
with the evidence from Branigan, Pickering, and Cleland’s experiments and also Gries’ corpus study on the
same constructions.
Other than the power issues discussed above, these
differences could be due to differences in the data used.
Whilst our natural conversational data is obviously different from the task specific experiemntal data, it is also
different to the corpus data used by Gries, in one important respect. Although the DCPSE corpus overlaps
with the ICE-GB corpus used by Gries, the data in the
DCPSE is all spoken, while the ICE-GB contains a mixture of written and spoken data.6 Additionally, our experiment 1 used only dyadic (two-person) dialogues, as
this makes creation of the control corpora more straightforward.7

Method
A further study was therefore carried out, following
Gries’ methodology but using the DCPSE, to attempt to
replicate his positive results. We once again restricted
the analysis to the three largest genres, but this time
6
Note, however, that (Gries, 2005) did not find any significant effect of Medium.
7
Although one might expect that priming would be
stronger in the canonical two-person case – see (Pickering
& Garrod, 2004).

(s.d.)
(0.019)
(0.016)
(0.022)
(0.019)

(s.d.)
(0.010)
(0.007)
(0.019)
(0.014)

Table 4: Comparison of corpus data used

Gries (2005)
This paper

Spoken

Written

600,000
540,000

400,000
N/A

Total prime/
target pairs
3003
1438

included all conversations in those genres (i.e. we did
not restrict this to dyadic conversation as in experiment 1, but still discounted e.g. broadcast interviews,
legal cross-examinations and spontaneous commentaries,
which would also have been included in Gries’ data;
see table 4). Following Gries, prime-target pairs in the
DCPSE were coded for the variables shown in table 5,
using the DCPSE’s ICECUP tool to detect particular
forms based on fuzzy tree fragments (Nelson, Wallis, &
Aarts, 2002).

Results
The general result, as for Gries, is the significant effect
between CPrime and CTarget (χ2(1) = 10.573, p =
0.001), as shown in table 6. We observe priming for both
the ditransitive and prepositional dative forms: observed
target frequencies of each are greater than expected frequencies when following a prime of the same form, and
lower than expected when following a prime of the other
form.
The variables in table 5 were entered into a General
Linear Model (GLM) analysis with CTarget as the dependent variable and CPrime, VFormID, VLemmaID,
SpeakerID as independent variables and Distance as
a covariate. Like Gries (2005), we found a main effect
of CPrime (F(1,1425) = 76.364, p = 0.000) as expected
given the general result above, and indicating that the
form of the prime strongly predicts the constructional
choice of the target, and an interaction effect of CPrime

2007

Variable
CPrime
CTarget
CID
Distance
VFormID

VLemmaID
SpeakerID

of VLemmaID we cannot rule out the possibility that
they are lexically specified, or collocational, rather than
specifically syntactic or structural. To test this possibility, two post-hoc analyses were carried out. When the
prime-target pairs which have an identical lemma are removed from the analysis, there is no longer any effect of
CPrime on CTarget (F(1,1211) = 0.563, p = 0.45), and
there are also no other significant effects. See also table
7 (χ2(1) = 0.454, p = 0.50). Conversely, looking just at
those with an identical lemma we get a large effect of
CPrime on CTarget (F(1,1211) = 171.358, p = 0.000),
as is obvious from table 8 (χ2(1) = 105.6, p = 0.000).
Note that these findings do not, in fact, contradict Gries
(2005), as his major finding was that individual verbs differ in their sensitivity to priming effects, a finding that
is supported by the evidence that the variation in our
data can be accounted for by those cases in which the
lemma is identical between prime and target.

Table 5: Variables
Description
the form of the prime (ditransitive v
prepositional dative)
the form of the target (ditransitive
v prepositional dative)
yes if CPrime and CTarget are
the same form, no otherwise
the number of parsing units between
prime and target
yes if the verb and its form were
identical in prime and target, no
otherwise
yes if the verb lemma was identical
in prime and target, no otherwise
yes if the speaker of prime and target was the same person, no otherwise

× VLemmaID, (F(1,1425) = 28.969, p = 0.000) indicating that when the verb lemma is identical across prime
and target, the effect of priming is stronger. We did not
find an effect of CPrime × SpeakerID, as Gries did,
however, this could be due to the different corpora used,
as written material would inevitably only include cases
where the producer of prime and target are the same
(note also that the effect he found was a marginal one).
Following Gries, a second analysis using CID as a dependent variable was carried out. There was a significant
main effect of CPrime (F(1,1425) = 4.935, p = 0.026),
the direction of which suggests that there is more likely
to be an identical target following a ditransitive prime
than a prime in the form of the prepositional dative.
There was also a significant main effect of VLemmaID
(F(1,1425) = 27.255, p = 0.000), such that the target
is more likely to have the same form as the prime if the
verb lemma used is the same. Like Gries, we did not find
an effect of distance when it was entered into the model
linearly, but when transformed to a logarithmic scale,
it had a significant effect on CID (F(1,1425) = 4.540,
p = 0.033). Adding Genre to the model did not reveal
any additional effects to those outlined above.
Table 6: Observed v expected frequencies
CPrime:
Ditran
Prep
Total

CTarget:
Ditran
527 (497.1)
318 (347.9)
845

CTarget:
Prep
319 (348.9)
274 (244.1)
593

Total
846
592
1438

These results suggest that whilst there are genuine
alignment effects being observed, due to the large effect

Table 7: Observed v expected frequencies of prime-target
pairs where LemmaID = no
CPrime:
Ditran
Prep
Total

CTarget:
Ditran
370 (375.8)
308 (302.2)
678

CTarget:
Prep
304 (298.2)
234 (239.8)
538

Total
674
542
1216

Table 8: Observed v expected frequencies of prime-target
pairs where LemmaID = yes
CPrime:
Ditran
Prep
Total

CTarget:
Ditran
157 (129.4)
10
(37.6)
167

CTarget:
Prep
15 (42.6)
40 (12.4)
55

Total
172
50
222

Conclusions
The results show that, in ordinary dyadic conversation,
there is no unequivocal evidence of syntactic priming
effects for the specific constructions that have been the
focus of previous experimental and corpus work. The
results presented here show that individual people do
tend to repeat the same structure. However, they are
no more likely to converge on the same version of each
structure with their conversational partners than would
be expected by chance. In addition, the overall likelihood
of a match in syntactic structure across turns appears to
be accounted for by the repetition of specific words.
Our results seem to be inconsistent with previous findings, however, as already noted, there may be several reasons for this disparity. Firstly, laboratory based experiments on dialogue are always subject to concerns about

2008

ecological validity and it’s possible that the restricted,
task-oriented, exchanges used in previous studies do not
generalise well to the more open-ended dialogue samples
in the corpus data. Note though, that the present results
do replicate the strong effects of lexical choice on syntactic similarity reported by Branigan, Pickering, and
Cleland (2000). Another point of contrast between the
current study and previous work are the specific characteristics of the corpus we use. Our data only includes
exchanges in ordinary dialogue (and is further restricted
in experiment 1 to dyadic exchanges). We specifically exclude spoken monologue, institutionally specialised contexts such as tutorials and broadcast interviews and onesided interactional activities such as story-telling. Note
however, that in doing so we focus on just those cases
where Pickering and Garrod (2004) predict that priming
should be strongest.
Our data are also compatible with studies on lexical
alignment – reuse of previously encountered words. Despite well documented experimental evidence of lexical
alignment (Brennan & Clark, 1996), there are also questions as to how this scales up to genuine conversation
– a study of relative lexical overlap in conditions allowing or prohibiting verbal feedback (Hadelich, Branigan,
Pickering, & Crocker, 2004) found that in the conditions
which were more akin to genuine dialogue (where verbal
feedback was permitted), there was less relative lexical
overlap.
Additionally, our experiment 2 is in fact an extension
of Gries’ (2005) work, and completely compatible with
it, though it does suggest a shift of focus. While a statistical correlation between prime form and target form is
observable, this may be almost entirely associated with
repetition of lexical form, rather than reuse of syntactic
structure per se.
While there is insufficient data in the DCPSE corpus to definitively prove that structural priming effects
are absent in ordinary conversation, these results indicate that the strength and ubiquity of structural priming
(see e.g. Pickering and Ferreira (2008)) may have been
overstated.

Acknowledgements
The research presented here was carried out as part
of the Dynamics of Conversational Dialogue project,
funded by the UK ESRC (RES-062-23-0962).

References
Bock, K., Dell, G., Chang, F., & Onishi, K. (2007).
Persistent structural priming from language comprehension to language production. Cognition, 104 (3),
437–458.
Branigan, H., Pickering, M., & Cleland, A. (2000). Syntactic co-ordination in dialogue. Cognition, 75 , 13–25.
Branigan, H., Pickering, M., McLean, J., & Cleland, A.

(2007). Syntactic alignment and participant role in
dialogue. Cognition, 104 (2), 163–197.
Branigan, H., Pickering, M., McLean, J., & Stewart, A.
(2006). The role of local and global syntactic structure in language production: Evidence from syntactic
priming. Language and cognitive processes, 21 (7-8),
974–1010.
Branigan, H., Pickering, M., Stewart, A., & McLean, J.
(2000). Syntactic priming in spoken production: Linguistic and temporal interference. Memory and Cognition, 28 (8), 1297–1302.
Brennan, S. E., & Clark, H. H. (1996). Conceptual pacts
and lexical choice in conversation. Journal of Experimental Psychology: Learning, Memory and Cognition,
22 , 482-1493.
Gries, S. (2005). Syntactic Priming: A Corpus-based
Approach. Psycholinguistic Research, 34 (4), 365–399.
Hadelich, K., Branigan, H., Pickering, M., & Crocker, M.
(2004). Alignment in dialogue: Effects of visual versus
verbal-feedback. In Proceedings of the 8th workshop
on the Semantics and Pragmatics of Dialogue.
Hartsuiker, R., Pickering, M., & Veltkamp, E. (2004). Is
syntax separate or shared between languages? Crosslinguistic syntactic priming in Spanish-English bilinguals. Psychological Science, 15 , 409–414.
Healey, P. G. T., Howes, C., & Purver, M. (2010). Does
structural priming occur in ordinary conversation? In
Proceedings of Linguistic Evidence 2010. Tübingen.
Healey, P. G. T., Purver, M., & Howes, C. (2010). Structural divergence in dialogue. In Proceedings of 20th
annual meeting of the Society for Text & Discourse.
Nelson, G., Wallis, S., & Aarts, B. (2002). Exploring
natural language: Working with the British component
of the International Corpus of English. Amsterdam:
John Benjamins.
Pickering, M., & Ferreira, V. (2008). Structural priming:
A critical review. Psychological Bulletin, 134 (3), 427–
459.
Pickering, M., & Garrod, S. (2004). Toward a mechanistic psychology of dialogue. Behavioral and Brain
Sciences, 27 , 169–226.
Pickering, M., & Garrod, S. (2006). Alignment as the
basis for successful communication. Research on Language and Computation, 4 , 203–228.
Reitter, D., Moore, J., & Keller, F. (2006). Priming of
syntactic rules in task-oriented dialogue and spontaneous conversation. In Proceedings of the 28th conference of the Cognitive Science Society.
Szmrecsanyi, B. (2005). Language users as creatures of
habit: A corpus-based analysis of persistence in spoken
English. Corpus Linguistics and Linguistic Theory,
1 (1), 113–150.
Tannen, D. (2007). Talking voices: Repetition, dialogue
and imagery in conversational discourse. Cambridge:
Cambridge University Press. (Second Edition)

2009

