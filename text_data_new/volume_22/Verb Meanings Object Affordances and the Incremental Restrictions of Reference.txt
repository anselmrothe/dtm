UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Verb Meanings, Object Affordances, and the Incremental Restrictions of Reference

Permalink
https://escholarship.org/uc/item/3x16656j

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)

Authors
Kako, Edward
Trueswell, John C.

Publication Date
2000-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Verb Meanings, Object Affordances, and the Incremental Restriction of
Reference
Edward Kako (ekako1@swarthmore.edu)
Department of Psychology, Swarthmore College
500 College Ave.
Swarthmore, PA 19081 USA

John C. Trueswell (trueswel@psych.upenn.edu)
Department of Psychology, University of Pennsylvania
3401 Walnut St.
Philadelphia, PA 19104 USA
Abstract
There has traditionally been significant interest in the role of
verb semantic ristrictions in both psycholinguistic and computational theorizing about language interpretation (e.g.,
McRae, Spivey-Knowlton, & Tanenhaus, 1998; Resnik,
1996; Trueswell, Tanenhaus, & Garnsey, 1994). The bulk of
this research has focused on how such information influences
syntactic choices during parsing. The current paper explores
in detail the time-course of, and mechanisms for, on-going
referential processing. While their eye movements were recorded, subjects acted upon spoken instructions such as "Now
I want you to fold the napkin." The verb was either highly
constraining (e.g., "fold") or weakly constraining ("pick up");
the array contained either just one object with the appropriate
affordances (the target) or two such objects (the target and a
competitor). We provide evidence that listeners are capable of
rapidly constraining the domain of reference of upcoming
constituents to multiple objects with appropriate semantic affordances, which compete for referential consideration.
Moreover, in relation to computational theorizing on this
topic, the eyemovement patterns suggest that a verb's informativeness (i.e., the "tightness" of the semantic space of possible constituents, Resnik, 1996) affects the speed with which
listeners can compute the domain of reference of upcoming
constituents.

Introduction
Psychologists have been interested in the process of language comprehension since the earliest days of generative
grammar (Fodor & Bever, 1965; Miller & Isard, 1963; Slobin, 1966). Most comprehension studies have focused on the
problem of syntactic ambiguity resolution – how listeners or
readers decide among competing structural analyses
(Caplan, Baker, & Dehaut, 1985; Crain & Steedman, 1985;
Ferreira & Clifton, 1986; Frazier & Fodor, 1978; MacDonald, Pearlmutter, & Seidenberg, 1994; Trueswell et al.,
1994, among many others). In the last several years, however, there has been a growing interest in on-line semantic
interpretation – in particular, the extent to which listeners
can use combinatory semantic information to determine the
reference of words and phrases in a rapid, incremental fashion. Much of this work has been conducted in the so-called
visual world paradigm, in which listeners manipulate the

contents of a miniature world as their eyes are tracked by a
head-mounted visor (Sedivy, Tanenhaus, Chambers, & Carlson, 1999; Tanenhaus, Spivey-Knowlton, & Sedivy, 1995).
In this paper we provide evidence, using this paradigm, that
the meanings of verbs become available to listeners rapidly
enough to constrain the domain of reference for the upcoming direct object.
By virtue of what they mean, words often impose restrictions upon the semantics of other words that appear with
them. Many prepositions impose restrictions on the geometric properties of their objects (see especially Landau &
Jackendoff, 1993); through, for instance, requires that its
object have some kind of hole. Verbs are especially picky in
this regard: The subject of a verb must be the sort of thing
that can perform the denoted action, and the direct object
must be the sort of thing that can be sensed, manipulated, or
changed in the relevant way. The verb drink, for instance,
requires a subject capable of drinking, and a direct object
capable of being drunk. Hence while John drank the juice
sounds perfectly natural, both The table drank the juice and
John drank the table register as distinctly odd. Although
semantic restrictions have long played a role in linguistic
theory (e.g., Chomsky, 1965; Jackendoff, 1972) and in the
study of syntactic processing (Boland & Boehm-Jernigan,
1998; McRae et al., 1998; Tabossi, Spivey Knowlton,
McRae, & Tanenhaus, 1994; Trueswell et al., 1994) little
research has been done until recently to examine their potentially important role in on-line referential processing.
Using the visual world paradigm, Chambers, Eberhard,
Carlson, and Filip (1998) have demonstrated rapid access to
the meaning of the preposition inside and its use to restrict
the referential domain of definite noun phrases. Participants
in their experiment sat before an array of objects including a
duck, a rope, a napkin, a can, and a whistle. When they were
instructed to "Put the whistle inside the can," participants
launched eye movements to the can even before the onset of
the noun. The meaning of inside provided enough information for listeners to limit the referential domain of the upcoming noun phrase to the one object with the appropriate
physical properties (or affordances, in the terms of Gibson,
1977). Crucially, such movements were not found when the
preposition was below – which does not constrain the affor-

dances of its object – or when the array contained two additional objects with an interior volume (a bowl and a glass).
While highly suggestive, these results are limited in two
ways. First, Chambers et al. used only one lexical item (inside), and so it is unclear whether semantic restrictions are
rapidly available across a range of lexical items. Second,
prepositions are generally considered to be closed-class
items (Talmy, 1988), which differ from open-class items in a
number of important ways, including frequency and semantic richness (Friederici, 1985; Gordon & Caramazza, 1985;
Neville, Mills, & Lawson, 1992; Van Petten & Kutas,
1991). Perhaps it is the status of inside as closed-class that
makes its semantic restrictions so readily available.
Evidence that bears on both of these concerns comes from
a recent study by Altmann & Kamide (1999), who used a
modified version of the visual world paradigm to explore the
online processing of verbs. In their experiment, participants
sat before a computer screen displaying several pieces of
clip art: for example, a boy, a toy train, a toy car, a birthday
cake, and a balloon. Listeners heard the scene described
with one of two sentences: "The boy will move the cake," or
"The boy will eat the cake." In the first case, multiple objects in the scene satisfied the semantic restrictions of the
verb; in the second case, only the cake did so. Altmann and
Kamide found that eye movements to the target were
launched more rapidly after eat-type verbs (where the verb
picked out only one object in the array) than after move-type
verbs (where the verb picked out multiple objects). Looks to
the target object were always delayed for move-type verbs
until after hearing the definite NP the cake. These results
suggest that semantic restrictions are rapidly available for
open-class verbs as well-as for closed-class prepositions,
and across a range of lexical items.
Like the Chambers et al. (1998) experiment, the Altmann
and Kamide study also has some features that limit what we
can conclude about the on-line use of semantic restrictions.
First, participants in one of their experiments had to indicate
(with a button press) whether the sentence matched the visual scene (in half of all trials, the sentence did not match the
scene). This metalinguistic judgment might have caused
participants to process the incoming sentences in a strategic,
non-natural fashion, perhaps encouraging them to focus
more closely on verb information than they otherwise might
have.1
More importantly, the two experiments reported in
Altmann and Kamide provide conflicting evidence for the
use of semantic restrictions to constrain referential domains.
If listeners rapidly exploit the semantic restrictions of verbs
to constrain the domain of reference, they should spend less
time looking at inedible objects following eat than following
move. Their graph of data from Experiment 1 confirms this
prediction. But their graph of data from Experiment 2 re1

Another version of the experiment eliminated the explicit
metalinguistic component. But in that experiment, the participants
– who did not participate in the prior version – were told that "in
this version of the experiment, we aren't asking you to pay any
particular attention to the sentences." This allusion to the prior
study might have encouraged participants to strategize metalinguistically.

veals the opposite pattern: Participants spent more time fixating non-target objects after eat than after move. Further
complicating interpretation of their results, Altmann and
Kamide include in the category "Other" both non-target objects that meet the restrictions of the verb and non-target
objects that do not meet those restrictions. It is therefore
impossible to judge whether participants excluded incompatible objects from consideration altogether, as would be
predicted by a model in which listeners restrict the referential domain rapidly and incrementally.
In reporting their data, Chambers et al. (1998) separate
looks to other containers from looks to non-containers. Their
data show some signs of early temporary consideration of
the cohort of objects with the appropriate affordances (the
target plus the other two containers). However, the proportion of early looks to each of these objects was only slightly
greater than the proportion of early looks to an unrelated
object. The fragmentation of attention among several objects
in the multiple containers condition may have made it difficult to distinguish looks to the competitors from (presumably random) looks to unrelated objects. The precise timecourse of referential restriction therefore remains uncertain.
In what follows, we report an experiment on the semantic
restrictions of verbs using the visual world paradigm, with
multiple lexical items and a condition with a single competitor. In this study, participants acted out spoken instructions
like "Now I want you to fold the towel." On half of trials,
the array contained just one object with the appropriate affordances (the target). On the other half, it contained both a
target and one competitor (in this case, a napkin). Participants also acted out instructions like "Now I'd like you to
pick up the towel" with precisely the same manipulation of
competitor presence. While some verbs (e.g. fold) imposed
strong semantic restrictions relative to the scene (picking out
just one or two objects), other verbs (e.g. pick up) imposed
only weak restrictions (potentially picking out all four objects).
Two aspects of our experiment should help to illuminate
further both the time course and the causes of rapid referential restriction. First, we separate looks to compatible nontarget objects from looks to incompatible non-target objects.
Second, we include only one competitor in our trials, making it easier to distinguish looks to the competitor from random looks to unrelated (incompatible) objects in the display.

Methods
Participants
Sixteen undergraduates from the University of Pennsylvania
participated in this study. They received either course credit
or $6.00. All were native speakers of English and had uncorrected vision or wore soft contact lenses.

Stimuli
All critical instructions had the form "Now I want you to
verb the noun" (followed in some cases by an additional
phrase, such as "into the box"). We chose eight verbs with
strong semantic restrictions, and four verbs with weak semantic restrictions (meaning that each weak verb was pre-

Procedure
Eye movements were monitored with an ISCAN headmounted eye-tracker. The device had two cameras: One recorded the visual environment from the perspective of the
participant's left eye, and the other recorded a close-up image of the left eye. A computer analyzed the eye image in
real time, superimposing the horizontal and vertical eye position on the scene image; this composite image was recorded to tape using a frame-accurate digital video recorder.
The tracker determined eye position by following the relative positions of the pupil and the corneal surface reflection,
thereby canceling out errors in eye position that might result
from slippage of the visor. Moreover, because the scene and
eye cameras were attached to the visor, tracking accuracy
was not affected by movements of the participant's head.
Participants were asked to carry out the instruction as
quickly as they could. The entire experiment lasted approximately half an hour.

Results
The digital videotape of each participant's scene and eyeposition was analyzed by using the slow motion and freeze
frame viewing on a digital VCR. For each trial, the frame
number corresponding to the onset of the spoken instruction
was noted. Then, the location and onset time of each successive fixation on an object was recorded by inspecting the
video frame images until 1 sec after the offset of the instruc-

tion. Trials were not included in the analysis if the tracking
signal became degraded during the critical portion of the
sentence, which was defined as lasting from the onset of the
verb until 1 sec after the offset of the instruction. Of the 256
trials, 16 (6.25%) were not included in the analyses.
Figure 1 presents the fixation probabilities over time in
33-ms intervals (the sampling rate of the VCR), for the Target (the upper graph) and the Competitor (the lower graph).
The data are plotted relative to the onset of the noun, corresponding to zero milliseconds on the X-axis. The onset of
the verb occurred an average of 485 milliseconds prior to
the noun, and is marked by a vertical bar above the X-axis.
The probabilities do not sum to zero because the plot omits
the probabilities of fixating the cross or the other two objects. The probability of fixating either the cross or the other
two objects did not differ across conditions.
Proportion of Looks to Target

Proportion of Looks to Target

0.80
0.70
0.60

Strong, No (open the box)
Strong, Yes (open the box)
Weak, No (pick up the box)
Weak, Yes (pick up the box)

0.50
open the

0.40

box

0.30
0.20
0.10
0.00
-800

-600

-400

-200

0

200

400

600

800

1000

1200

Time Since Noun Onset (ms)

Proportion of Looks to Competitor
Proportion of Looks to Competitor

sented twice). As outlined in the Introduction, the experiment had a 2 (Restriction Strength: Strong versus Weak) x 2
(Competitor: Present versus Absent) design. Note that when
the verb was Weak, the Competitor acted as such in name
only, as the verb lacked the restrictions necessary to pick out
a subset of the objects in the array.
Each list contained sixteen target trials; eight with Strong
Verbs and eight with Weak Verbs. The design was such that
subjects heard each Strong Verb only once, and manipulated
each target object only once. The target trials in a list were
evenly divided between the four conditions (with four trials
per condition); conditions were rotated across lists, resulting
in four lists. All trials consisted of two instructions: the critical sentence followed by a second instruction, which asked
participants to further manipulate the Target (e.g., "Now I
want you to fold the towel. Now cover the box with it.").
Target trials were accompanied by sixteen filler trials that
used other verbs and involved the manipulation of other
objects. Order of target and filler trials within a list was determined by random assignment, with two constraints: first,
that there be no more than two consecutive target trials using
the same verb type; and second, that critical trials and filler
trials alternated. To control for order of presentation, each
list was presented in one of two orders, one the reverse of
the other.
Prior to each instruction, participants were told to "Look
at the cross" (the central fixation point on the table). Instructions were digitally recorded and played from a laptop computer connected to a pair of external speakers. Post experiment interviews revealed that subjects were unaware of the
manipulation or intent of the experiment.

0.80
0.70
0.60

Strong, No (open the box)
Strong, Yes (open the box)
Weak, No (pick up the box)
Weak, Yes (pick up the box)

0.50
open the

0.40

box

0.30
0.20
0.10
0.00
-800

-600

-400

-200

0

200

400

600

800

1000

1200

Time Since Noun Onset (ms)

Figure 1: Proportion of trials with fixations to target (top)
and competitor (bottom).
In the Strong Verb, Competitor Absent condition, there
were early looks to the Target (the open circles in the upper
graph) and essentially no looks to the Competitor Replacement (the open circles in the lower graph). Early consideration of the Target begins in this condition prior to the onset
of the noun, and rises rapidly during the first 250 msec of
the noun. By contrast, in the Strong Verb, Competitor Present condition (e.g., when the array contained both a towel
and a napkin), looks to the Target (the filled circles in the
upper graph) were reduced, as participants temporarily considered the Competitor (the filled circles in the lower graph).
Interestingly, participants evenly distributed their early inspection of the scene between the objects that had the appropriate affordances (e.g., the two foldable objects).

Instructions containing Weak verbs (e.g., "pick up") exhibited a different pattern of fixations. Fixations on the Target (the triangles in the upper graph) were delayed until after
the onset of the noun. The greatest delay occurred in the
Weak Verb, Competitor Present condition (the filled triangles in the upper graph). This time period was marked by
some temporary consideration of the Competitor (the filled
triangles in the lower graph). This competition presumably
reflects minor confusion arising from perceptual similarity
between the Target and Competitor. For instance, a few "accidental" looks to the towel ought to be expected upon hearing "napkin" in the instruction "Now I'd like you to pick up
the napkin...". Consistent with this explanation, competition
in this condition is small and appears after onset of the noun.

Early Looks to the Target
In order to assess whether early looks to the Target occurred more often in the Strong Verb, Competitor Absent
condition than in the other three conditions, we averaged the
proportion of time spent fixating the Target during a time
slice corresponding to 233 ms after the onset of the verb
until 233 ms after the onset of the noun (see Table 1). Because it takes approximately 200-250 ms for the eyes to respond to phonemic input in word recognition studies using
this paradigm (e.g., Allopenna, Magnuson, & Tanenhaus,
1998), any significant differences during this portion of the
speech are unlikely to be attributable the perception of the
noun (e.g., Allopenna et al., 1998). To test differences, subject and item means were entered into separate Analyses of
Variance (ANOVAs) with three factors: Verb Type (Strong,
Weak); Competitor (Absent, Present) and Presentation
List/Item Group (4 lists in the subject analysis and 4 item
groups in the item analysis).2 These analyses revealed a
reliable effect of Verb Type (F1(1,12)=24.70, p<0.001;
F2(1,12)=15.15, p<0.005) with Strong verbs showing more
early looks to the Target than Weak verbs. There was also a
marginal effect of Competitor Presence (F1(1,12)=3.27,
p<0.1; F2(1,12)=3.91, p<0.1). There was an interaction between Verb Type and Competitor Presence that was significant in the subject analysis and marginally significant in the
item analysis (F1(1,12)=5.65, p<0.05; F2(1,12)=4.32,
p=0.06). Simple effects tests showed that Strong verbs had
an advantage over Weak verbs when the Competitor was
Absent (F1(1,12)=16.28, p<0.005; F2(1,12)=14.30,
p<0.005) but not when it was Present (F1(1,12)=1.64;
F2(1,12)=0.89).3

2
All ANOVAs were conducted on an arcsine transformation of
the data, arcsine ((2*p)-1). This was done to adjust for the fact that
the proportion p is bounded at 0 and 1. ANOVAs conducted on
untransformed data yielded similar statistical patterns.
3
For looks to Target only, there were some uninterpretable interactions with the List factor.

Table 1A: Proportion of Looks to the Target
Time Slice 1: (Verb + 233ms) to (Noun+233ms)
Competitor Present
YES
NO
Strong Verb
0.07
0.17
Weak Verb
0.05
0.04
Time Slice 2: (Noun + 233ms) to (Noun+767ms)
Competitor Present
YES
NO
Strong Verb
0.39
0.56
Weak Verb
0.29
0.44
Table 1B: Proportion of Looks to the Competitor
Time Slice 1: (Verb + 233ms) to (Noun+233ms)
Competitor Present
YES
NO
Strong Verb
0.09
0.01
Weak Verb
0.03
0.01
Time Slice 2: (Noun + 233ms) to (Noun+767ms)
Competitor Present
YES
NO
Strong Verb
0.16
0.00
Weak Verb
0.09
0.03

Early Looks to the Competitor
Similar ANOVAs were conducted on the mean proportion
of early looks to the Competitor during this time slice (see
Table 1). As can be seen in the table, most looks to the
Competitor occurred in the Strong verb condition when the
Competitor was Present. The analysis revealed a reliable
interaction between Competitor presence and Verb Type
(F1(1,12)=7.97, p<0.05; F2(1,12)=18.99, p<0.005), a marginal effect of Competitor Presence (F1(1,12)=3.98, p<0.07;
F2(1,12)=9.79, p<.05) and no effect of Verb Type
(F1(1,12)=3.25; F2(1,12)=3.06). Simple Effects showed an
effect of Verb Type when the Competitor was Present
(F1(1,12)=6.50, p<0.05; F2(1,12)=10.16, p<0.01) but not
when it was Absent (F1(1,12)=2.77; F2(1,12)=2.87).
To assess any preference for looking at the Target over
the Competitor during this time slice, two-tailed t-tests on
subject and item means were done comparing looks to the
Target with looks to the Competitor. To avoid Type I errors,
we corrected for the number of tests by dividing the alpha by
four. As expected, the only reliable difference arose in the
Strong Verb, Competitor Absent condition, where there
were significantly more looks to the Target than to the Competitor Replacement (e.g., a Coke can) (t1(15)= 3.48,
p=0.003; t2(15) = 3.96, p=0.001).

Later Looks to the Target.
We also quantified looks to the Target and Competitor in a
second time slice, corresponding to approximately 500 ms
after the first time slice (i.e., from 233 ms after the onset of
the noun until 767 ms after the onset of the noun; see Table

1). Differences in this region are more likely to be affected
by the perception of the target noun phrase. ANOVAs revealed a main effect of Competitor Presence
(F1(1,12)=10.71, p<0.01; F2(1,12)=11.60, p<0.01), with
more looks to the Target when the Competitor was Absent.
In addition, there was a marginal effect of Verb type
(F1(1,12)=9.15, p<0.05; F2(1,12)=3.91, p<0.08) with more
looks to the Target when the sentence contained a Strong
verb. There was no interaction between these factors (Fs<1).

Later Looks to the Competitor
ANOVAs on the mean proportion of time spent looking at
the Competitor in this region revealed a main effect of Competitor (F1(1,12)=11.48, p<0.01; F2(1,12)= 39.10,
p<0.001), no effect of Verb Type (F1(1,12)=0.38;
F2(1,12)=1.52) and a weak interaction between these factors
that was significant only in the item analysis (F1(1,12)=2.72;
F2(1,12)=6.64, p<0.05).

Discussion
We have presented evidence that the semantic restrictions of
verbs become available rapidly enough during comprehension to permit listeners to make predictions about the likely
reference of the upcoming direct object. Participants looked
more rapidly at the referent of the direct object when the
verb had Strong restrictions than when it had Weak ones.
For instance, they looked more rapidly at the towel when
told to fold it than when told to pick it up. When the scene
included a second foldable object, the use of a Strong restrictions verb resulted in early temporary consideration of
this second object, which competes with the target object.
This pattern replicates the one reported both by Chambers
(1998) and by Altmann and Kamide (1999), with several
improvements: We used multiple lexical items, a task less
likely to induce listener strategies4, and a single competitor.
The last improvement allowed us to show that listeners rapidly eliminated incompatible non-target objects from consideration.
While it seems clear that semantic restrictions are rapidly
available for referential restriction, the precise mechanism of
this restriction remains unclear. There are two explanations
for the source of this restriction. Listeners might launch eye
movements after hearing a strongly constraining verb because they have already assessed the properties of the objects in the display and recognize that only a subset of those
objects is compatible with the verb's restrictions. By con4

It is of course possible that listeners in our task developed
strategies that resulted in them unnaturally focusing on particular
classes of information (see Tanenhaus & Spivey-Knowlton, 1996
for a discussion of this issue). However, if strategies were developed to use verb restrictions, we might expect their effects to
emerge over the course of the experiment. We tested this possibility in two ways. We inspected the first half of the trials in the experiment, and we inspected the first of paired items in the experiment. In both cases, the pattern of eye movements was similar to
the overall pattern, i.e., early looks to the Target in the Strong
Verb Competitor Absent condition, and some early looks to the
Competitor in the Strong Verb Competitor Present condition.

trast, listeners might launch eye movements simply because
a strongly restricting verb is more likely than a weakly restricting in any context to pick out a unique referent (or subset of referents). We will refer to these possibilities as affordance matching and informativeness, respectively. In fact,
the notion of informativeness has been quantified in recent
computational theorizing by (Resnik, 1996), who also provides evidence that verb informativeness has very real psycholinguistic consequences.
These two possibilites make different predictions about
the likelihood of launching an eye movement just after hearing the verb. If listeners actively match affordances, they
should launch eye movements as soon as they determine that
one or more objects in the scene satisfy the restrictions of
the verb. Thus, they should be equally likely to launch eye
movements following a weak verb as following a strong
verb, because in both cases, at least one object in the array
satisfies the restrictions of the verb; in both cases, interrogation of the array can begin immediately. If, on the other
hand, eye movements are triggered by a verb's informativeness, listeners should be more likely to launch eye movements following a strongly constraining verb than following
a weakly constraining one, as informative verbs carry
enough information to identify their direct objects, whereas
weakly informative verbs do not.
To test between these possibilities, we examined the proportion of fixations on any object in two time slices: from
233 ms after the onset of the verb until 233 ms after the onset of the noun, and from 233 ms after the noun to 767 ms
after the noun (the same slices used in the analyses presented
in the Results section). As Table 2 indicates, listeners were
more likely to launch a fixation to any object following a
Strong verb than following a Weak verb. In Time Slice 1,
the effect of verb type was reliable in the subject analysis,
and marginal in the item analysis (F1(1,12)=9.71, p<.01;
F2(1,12)=4.36, p<.06). In Time Slice 2, the effect of verb
type was reliable in both analyses (F1(1,12)=8.28, p<.02;
F2(1,12)=7.96, p<.02).
Table 2: Proportion of looks to any object
Time Slice 1: (Verb + 233ms) to (Noun+233ms)
Competitor Present
YES
NO
Strong Verb
0.22
0.22
Weak Verb
0.16
0.12
Time Slice 2: (Noun + 233ms) to (Noun+767ms)
Competitor Present
YES
NO
Strong Verb
0.60
0.63
Weak Verb
0.46
0.52
While these data are somewhat preliminary, they suggest
that a verb's informativeness, independent of context, contributes to the speed with which listeners can compute the
domain of reference of upcoming constituents. Because a
Strong verb is highly informative about its upcoming direct
object, listeners can begin to interrogate the visual scene for

an object with the appropriate affordances before they have
heard the noun phrase.
Whether early eye movements are driven by informativeness or affordance matching, it is clear that verb meanings
can be accessed rapidly enough to make predictions about
the reference of an upcoming direct object, and to constrain
the set of entities to which the direct object might refer. The
current findings contribute to a growing body of data that
support a view of semantic interpretation as both incremental and predictive. Words not traditionally thought to
carry reference – prepositions (Chambers et al., 1998), adjectives (Sedivy et al., 1999), and verbs (Altmann &
Kamide, 1999, the present study) – can be exploited by listeners to predict the reference of upcoming nouns. Indeed,
the linking of speech to a mental model of the world appears
to be an active, continuous process.

Acknowledgements
We thank Sarah Brown-Schmidt and Jared Novick for their
considerable help in running the experiments, and in coding
and analyzing the data. We also thank the members of the
eyetracking lab group at the Institute for Research in Cognitive Science at Penn for their many helpful suggestions. This
work was supported by NIH National Research Service
Award #HD085070-01 to the first author while a postdoctoral fellow at IRCS; and by NSF grant #SBR-96-16833 and
NIH grant 1-R01-HD37507001, both to the second author.

References
Allopenna, P. D., Magnuson, J. S., & Tanenhaus, M. K. (1998). Tracking the time course of spoken word recognition using eye
movements: Evidence for continuous mapping models. Journal
of Memory and Language, 38, 419-439.
Altmann, G. T. M., & Kamide, Y. (1999). Incremental interpretation at
verbs: Restricting the domain of subsequent reference. Cognition, 73(3), 247-264.
Boland, J. E., & Boehm-Jernigan, H. (1998). Lexical constraints and
prepositional phrase attachment. Journal of Memory and Language, 39(4), 684-719.
Caplan, D., Baker, C., & Dehaut, F. (1985). Syntactic determinants of
sentence comprehension in aphasia. Cognition, 21, 117-175.
Chambers, C. G., Tanenhaus, M. K., Eberhard, K. M., Carlson, G. N., &
Filip, H. (1998). Words and worlds: The construction of context
for definite reference. Proceedings of the Annual Conference of
the Cognitive Science Society, 20.
Chomsky, N. (1965). Aspects of the theory of syntax. Cambridge, MA:
MIT Press.
Crain, S., & Steedman, M. (1985). On not being led up the garden path:
The use of context by the psychological syntax processor. In D.
R. Dowty, L. Karttunen, & A. M. Zwicky (Eds.), Natural language parsing: Psychological, computational, and theoretical
perspectives (pp. 320-358). New York: Cambridge University
Press.
Ferreira, F., & Clifton, C. J. (1986). The independence of syntactic
processing. Journal of Memory and Language, 25, 348-368.
Fodor, J. A., & Bever, T. G. (1965). The psychological reality of
linguistic segments. Journal of Verbal Learning and Verbal
Behavior, 4, 414-420.

Frazier, L., & Fodor, J. D. (1978). The sausage machine: A new twostage model. Cognition, 6, 291-325.
Friederici, A. D. (1985). Levels of processing and vocabulary types:
Evidence from on-line comprehension in normals and agrammatics. Cognition, 21, 133-166.
Gibson, J. J. (1977). The theory of affordances. In R. Shaw & J. Bransford (Eds.), Perceiving, acting, and knowing: Toward an ecological psychology (pp. 67-82). Hillsdale, NJ: Lawrence Erlbaum Associates.
Gordon, B., & Caramazza, A. (1985). Lexical access and frequency sensitivity: Frequency saturation and open/closed class equivalence. Cognition, 21, 95-115.
Jackendoff, R. (1972). Semantic interpretation in generative grammar.
Cambridge, MA: MIT Press.
Landau, B., & Jackendoff, R. (1993). "What" and "where" in spatial
language and spatial cognition. The Behavioral and Brain Sciences, 16, 217-265.
MacDonald, M. C., Pearlmutter, N. J., & Seidenberg, M. S. (1994).
Lexical nature of syntactic ambiguity resolution. Psychological
Review, 101(4), 676-703.
McRae, K., Spivey-Knowlton, M. J., & Tanenhaus, M. K. (1998). Modeling the influence of thematic fit (and other constraints) in online sentence comprehension. Journal of Memory and Language, 38, 283-312.
Miller, G. A., & Isard, S. (1963). Some perceptual consequences of linguistic rules. Journal of Verbal Learning and Verbal Behavior,
2, 217-228.
Neville, H. J., Mills, D. L., & Lawson, D. S. (1992). Fractionating language: Different neural subsystems with different sensitive periods. Cerebral Cortex, 2, 244-258.
Resnik, P. (1996). Selectional constraints: An information-theoretic
model and its computational realization. Cognition, 61, 127159.
Sedivy, J. C., Tanenhaus, M. K., Chambers, C., & Carlson, G. N.
(1999). Achieving incremental semantic interpretation through
contextual representation. Cognition, 71, 109-147.
Slobin, D. I. (1966). Grammatical transformations and sentence comprehension in childhood and adulthood. Journal of Verbal
Learning and Verbal Behavior, 5, 219-227.
Tabossi, P., Spivey Knowlton, M. J., McRae, K., & Tanenhaus, M. K.
(1994). Semantic effects on syntactic ambiguity resolution:
Evidence for a constraint-based resolution process. In U. Carlo
& M. Moscovitch (Eds.), Attention and performance 15: Conscious and nonconscious information processing (pp. 589615). Cambridge, MA: MIT Press.
Talmy, L. (1988). The relation of grammar to cognition. In B. RudzkaOstyn (Ed.), Topics in cognitive linguistics (pp. 165-205).
Philadelphia: John Benjamins Publishing Co.
Tanenhaus, M. K., & Spivey-Knowlton, M. J. (1996). Eye-tracking.
Language and Cognitive Processes, 11(6), 583-588.
Tanenhaus, M. K., Spivey-Knowlton, M. J., & Sedivy, J. C. (1995). Integration of visual and linguistic information in spoken language comprehension. Science, 268, 1632-1634.
Trueswell, J. C., Tanenhaus, M. K., & Garnsey, S. M. (1994). Semantic
influences on parsing: Use of thematic role information in syntactic ambiguity resolution. Journal of Memory and Language,
33, 285-318.
Van Petten, C., & Kutas, M. (1991). Influences of semantic and syntactic context on open- and closed-class words. Memory & Cognition, 19, 95-112.

