UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Contextually Representing Abstract Concepts with Abstract Structures

Permalink
https://escholarship.org/uc/item/4zt536f8

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)

Authors
Wiemer-Hastings, Katja
Graesser, Arthur C.

Publication Date
2000-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Contextually Representing Abstract Concepts with Abstract Structures
Katja Wiemer-Hastings (KWIEMER@LATTE.MEMPHIS.EDU)
Department of Psychology, University of Memphis, CAMPUS BOX 526400
Memphis, TN 38152 USA

Arthur C. Graesser (GRAESSER@MEMPHIS.EDU)
Department of Psychology, University of Memphis, CAMPUS BOX 526400
Memphis, TN 38152 USA

Abstract
This paper proposes that abstract concepts are represented as
contextually derived structures. According to this abstract
structure theory, abstract concepts are related to mostly
temporal and spatial structures that underlie and can be
extracted from concrete situations.
Linguistic context
elements of abstract concepts, such as verbs and prepositions,
express these structures, and can thus aid in the acquisition of
such concepts. The paper presents results from a corpus study
that supports the hypothesis, and discusses implications.

We propose that abstract concepts, such as faith or notion,
are represented as abstract structures, which represent
particular contexts in which they occur. Abstract concepts
are not directly perceivable, but are often used in verbal
descriptions of situations, or in utterances related to a
situation. Such utterances have to unambiguously point out
the entity that is referred to by the abstract noun. We argue
that the relevant abstract structures can be inferred from
their linguistic context, in particular, from verbs and
prepositions used with the abstract nouns.

Concept Constraints and Contextual Similarity
Similar concepts occur in similar linguistic contexts. Miller
and Charles (1991) report that contexts of similar concepts
are more often classified as belonging to the same concept.
For example, the sentences the patient rang for the ____
and the ____ gave the patient an injection both suggest that
the word doctor or nurse would complete the sentence well.
We found that a neural network could be trained to correctly
select one out of seven abstract concepts based on linguistic
context information in 72% of test cases (Wiemer-Hastings,
1998). An approach to learning verbs from context was
described by Wiemer-Hastings, Graesser, and WiemerHastings (1998; see also Hastings, 1994). This work shows
a close link between context of use and concepts.

Acquisition from Contexts
The relationship between concept and context similarity has
implications for language acquisition: Unknown words can
be learned from context. Berwick (1989) discussed a
system that acquired word meaning based on contextual
similarity of the word to the contextual representation of

familiar words. Sternberg and Powell (1983) have shown
experimentally that human participants could infer unknown
word meanings from the context of a short text passage.
So, linguistic context provides useful information for
language acquisition.
In the acquisition of concrete
concepts, this information is a "bonus" added to more
directly useful information that the learner has access to,
that is, information about perceptual or functional
characteristics, as well as uses of the objects in situations. It
is not even clear to what extent the linguistic information
actually adds to this perceptual information. It might
instead just reflect the information contained in the
perceptual context of use, thus being redundant with it.
Linguistic context (in particular, syntactic context) has
been shown to facilitate the acquisition of verbs (e.g.,
Fisher, 1994). Levin (1993) has provided a classification of
semantic verb classes based on syntactic verb frames. Thus,
much critical lexical information can be extracted from the
linguistic context. This is important when the available
information is largely confined to linguistic information.
This is the case for abstract noun concepts, which refer to
complex situations and relationships within these situations.
If linguistic context is informative for verbs, it should be
helpful all the more to acquire abstract concepts, such as
ignorance or strategy. Indeed, Quine (1960) has argued that
abstract concepts must be acquired on the basis of linguistic
information alone. In support of this hypothesis, we found
that abstract concepts can be distinguished pretty reliably
based on semantic and syntactic aspects of their context
(Wiemer-Hastings, 1998). If the hypothesis holds, then it
should also be possible to identify linguistic contexts
elements that are related to abstract concept meanings, thus
that they co-occur with similar frequency with similar
abstract concepts, and do not co-occur with dissimilar
abstract concepts.

Context Dependence
Clearly, the characteristics of entities systematically
constrain contexts in which they can occur. However, this
statement implies that entities are something that is given a
priori, and contexts are selected based on the entities. This
may be true for concrete entities, such as furniture items.
Concrete entities exist independent of aspects of particular

contexts. A chair is still a chair if it occurs in a new context.
Concrete concepts have characteristics that put concrete
constraints on how we interact with them.
Their
characteristics thus determine, to some extent, their use. In
this sense, concrete entities are to some extent independent
of contexts.
With respect to abstract concepts, it seems that the
relationship between context and concept constraints is
reversed: their use is not determined by their characteristics,
but their characteristics are inferred from their use. It seems
that the context is the a priori given in this case, whereas
abstract concepts are used to describe and make sense of
complex situations and processes. Abstract concepts do not
exist independently. They can only "happen" in particular
contexts. An idea, for example, is conceived mentally, and
can be expressed in words. Its consequences can be
observed in context. It has the pragmatic function of
overcoming some obstacle. In a slightly different context,
one may call the concept a suggestion or recollection,
instead of an idea. Similarly, truth is a characteristic
ascribed to a statement that describes a particular state of
affairs correctly (see Barsalou, 1999). If the state of affairs
is different from a statement, the concept truth does not
apply anymore.
This difference in the relation between abstract and
concrete concepts and their contexts also affects language
acquisition. We first acquire words for concrete entities.
Later, we learn that there are abstract concepts, but we need
to infer their characteristics from the contexts in which they
are used. That is, the context is processed before the
abstract concept can be understood. For abstract concepts,
we could accordingly postulate that they are understood to
be similar to the extent that they are used in the same
linguistic contexts.

Operationally Defined Context
Context is a complex notion. In contrast to verbs, there are
no particular syntactic frames associated with abstract
concepts. However, if abstract concepts put constraints on
admissible contexts of use, then some of their contextual
elements should reflect important semantic aspects of the
concepts. Are there any indications as to what context
elements may play a role?

Explaining Contextual Effects with Scripts
Context effects on concept processing (e.g., on the speed in
word recognition) have been shown in many studies. A
series of experiments showed that such effects are mostly
due to global context rather than local context elements
(Hess, Foss, & Carroll, 1995). Sharkey and Mitchell (1986)
suggested that context effects on lexical processing are
mediated by scripts (Schank & Abelson, 1977). Scripts are
schemata of actions, such as seeing a doctor, or eating out in
a restaurant. According to Sharkey and Mitchell, associated
words activate target words not through associations (i.e.,
through strong connections in a semantic network), but by
activating a script that in turn activates the target word.

This hypothesis has received empirical support.
However, it cannot easily be applied to abstract concepts.
Consider, for example, the difficulty in selecting a script for
idea. One would likely assign the concrete concept menu to
the restaurant script, but concepts like idea can occur in a
wide, almost arbitrary, variety of concrete situations such as
represented by scripts. Yet, there are particular aspects of
contexts that must be true for an abstract concept to apply.
In the case of idea, for example, the concept typically
occurs in a context where there is a problem or obstacle of
some kind; an agent who reflects or discusses possible ways
to overcome the obstacle; and a thought or utterance (the
idea) that leads to the problem-solving action. A temporal
sequence with causally related elements emerges from this
scenario. We collectively call such sequences and structures
for other kinds of abstract concepts abstract structures.

Abstract Structures
Abstract structures represent integrated processes, events, or
particular relationships in situations. They are abstract, in
that they apply to situations with different concrete aspects.
They are structures, in that they organize sets of entities in a
situation with respect to the causal, temporal, spatial and
other relations that hold between them. The concept is
similar to schemata or scripts. However, abstract structures
are more abstract than scripts, so we opt to use a different
term here, to avoid the association with concrete situations.
Abstract concepts have a temporal and spatial dimension.
The temporal dimension is critical, because it represents the
ontological class of a concept (i.e., whether the concept is a
point-like event, a process, or a state), and the sequencing of
events within a structure. The representation of many
abstract concepts requires information about their time
course, for example, discussion or sequence. Causal aspects
usually depend on temporal information as well. For
example, concepts like effect, consequence, impact etc.
require some temporally preceding entity or event. In
principle, this suggested representation format is compatible
with a perceptual approach, which integrates perceptual
aspects beyond vision. One such theory has recently been
proposed by Barsalou (1999). He proposes a combination
of situation percepts with introspective information to
represent abstract concepts.
Our approach does not
challenge this view, but approaches the representation from
a linguistic point of view, and focuses on dynamic aspects
of the concepts within context.
This paper describes first results of an investigation of
this abstract-structure hypothesis. If linguistic context
serves as a basis for abstract concept acquisition, then it is
necessary that it reflects critical relationships in the situation
context, and thus directs the learner's attention to the
relevant aspects in this situation to identify the referent of
the abstract noun. In relation to this reasoning, in particular
we test the following prediction: Temporal, spatial and
other aspects of the abstract structure related to an abstract
concept are expressed in, and can be inferred from, its
linguistic context.

Context Elements
According to the abstract structures hypothesis, there
should be linguistic context features that express causal,
temporal, and other information. With this in mind, we
examined the linguistic contexts of abstract concepts
selectively with respect to such elements. What context
elements are likely to reflect spatial, temporal and other
relationships between the agents and entities in a situation?
This paper discusses two elements of context: verbs, and
prepositions. Selecting two groups of lexical items clearly
does not follow the view that it is global context that is
critical with respect to concept representation. However, it
appears worthwhile to examine context elements that can be
easily identified and test these first, instead of attempting to
identify more complex structures in text. The selection of
verbs and prepositions follows directly from our hypothesis
that abstract concepts are represented as contextual
structures.
Both verbs and prepositions express the
relationships pertinent to abstract concepts, according to our
hypothesis.
Verbs describe the way in which agents interact with each
other and with entities, and convey aspects relevant to
abstract concepts, such as events and causality (Basili,
Pazienza, & Velardi, 1996). They express causal (e.g.,
cause, evoke, produce, lead to, etc.), temporal (e.g., follow,
end, begin, etc.) and spatial information (e.g., leave, hide,
bring, remove). Verbs also express other important aspects
of abstract concepts related to agent - object relations, such
as evaluations (e.g., like, want, etc.), verbal expression (e.g.,
announce, explain, suggest, etc.), and others. The central
role of verbs with respect to the processing and
identification of agents and objects has been shown in a lot
of research, even if not specifically for abstract concepts.
Altmann and Kamide (1999), for example, show that verbs
guide our attention to particular aspects of a situation,
because they lead us to expect what particular kinds of
entities will be made reference to subsequently. Whereas
this finding generalizes to entities outside the visual domain
is an open question, but it is a possibility.
Prepositions can explicitly be classified with respect to
the same dimensions (see Table 1). Considering these two
context elements in the linguistic context of abstract
concepts, we examined the question if the verbs and
prepositions that occur in the contexts of particular abstract
concepts express semantic aspects of the abstract concepts.
We predicted that if they do, then similar abstract concepts
should co-occur with similar kinds of verbs and prepositions
with similar frequency.

Corpus Analysis of Abstract Concept Contexts
In order to test what kinds of verbs and prepositions occur
with abstract concepts, one has to consider a representative
number of context samples. For example, one would expect
that very general predicates (such as think about, talk about)
occur with all kinds of concepts, and to provide little basis
for differentiation. In order to get at the systematic
relationships between verb and preposition context and

abstract concepts, we must therefore look at a variety of
contexts and record two aspects: a) patterns of cooccurrence between abstract concepts and verb / preposition
classes, and b) the frequencies of the co-occurrences.
We conducted a corpus analysis to obtain both measures.
Corpus analyses have been used frequently since large
databases of naturally occurring text have become available
electronically. Boguraev and Pustejovsky (1996) express
the power of corpus analyses proposing that "Text corpora
reflect language as it is used and evolves; by studying
regularities of use and patterns of behavior of words, which
only emerge from analysis of very large samples of text and
/ or speech, it is possible to induce (among other things)
lexical properties (...)" (p. 5). The power of co-occurrence
patterns in text for representing semantic aspects of
concepts and texts has been demonstrated by the success of
systems such as Latent Semantic Analysis (LSA; Landauer
& Dumais, 1997) and HAL (e.g., Burgess & Lund, 1997).
However, since LSA uses co-occurrence information among
all elements of text, it does not tell us much about which
elements of context play a role in relation to individual
kinds of concepts.

The Corpus
A sample of thirty abstract nouns was selected randomly,
but so that different ontological classes (e.g., state, process,
event, emotion) were represented. The sample included the
words accident, agreement, approach, aspect, attempt,
effect, decision, discovery, discussion, essence, fear,
freedom, goal, idea, ignorance, impression, indifference,
invention, miracle, notion, plan, pride, principle,
recollection, result, silence, strategy, surprise, truth, and
wisdom. We collected our corpus from NexisLexis, an
online database that contains full texts from newspapers,
magazines and other sources, representing a wide range of
topics. For each abstract noun, 250 sentences were
collected that contained the particular abstract noun. The
sampling was principally random. However, we made sure
that no sentences were repeated, and that a variety of topics
was represented. Altogether, we collected a corpus of 7500
sentences.

Encoding Co-occurrence
For each noun, we looked at every sentence and recorded
the verb and preposition that occurred in direct relation to
the abstract noun. Verbs and prepositions were recorded
with information about whether they preceded or followed
the abstract noun. We additionally counted the frequency
with which each verb and preposition occurred1.
This method yielded a large number of verbs and
prepositions (about 1700). The raw data would have
yielded long context vectors with very low average
frequencies.
Analyses based on such vectors would
1

Verbs and prepositions were not recorded in combination. In
many sentences, only one of the two occurred. Further, the
combinations may lead to an enormously extensive data space that
would be hard to reduce by classification.

presumably be distorted by noise. Therefore, we classified
our recorded verbs and prepositions into semantic classes.
Verbs were classified into the semantic classes constructed
by Levin (1992). Her system contains 37 semantic verb
classes that occurred in our corpus. They include verbs of
occurrence (e.g., happen), possession (give, obtain),
communication (describe, announce), and psychological
verbs (amaze, disturb). We only considered verbs that
could clearly be classified consistent with these classes.
Prepositions were classified into spatial, temporal, causal,
modal, propositional, referential and possessive information,
and further sub-classified within these groups (see Table 1).
Table 1
Classification of prepositions
Preposition class
Spatial location

Spatial motiondirection
Temporal

Temporal

Causal

Modal /
concomative
Propositional
Referential

Subclass
distance
relation to 1 object
relation to 2 objects
related to origin
related to destination
related to path
related to future
related to past
related to presence
expressing time-range
expressing point-intime
related to factor
related to effect
related to means

Examples
near, by, far from
on, in, behind
between, amidst
from, out of
into, towards
through, across
until, prior to
after, since
during, while, at
after (time-range)
on, at
due to, because of
in order to
through, whereby
with
about, on
with regard to

inclusive
exclusive /
adversatives

except, contrary to
of, from

Possessive

Abstract Concept Context Vectors
A noun-context element matrix was constructed that listed
abstract nouns against context element classes (Table 2).
The context elements contained the verb classes 1 to n after
Levin (1992) that had non-zero occurrences in the corpus,
followed by preposition classes 1 to n. The cells in the
matrix contained the co-occurrence frequency in the corpus.
Context elements were represented twice. The first time,
the co-occurrence data only count times that the abstract
noun preceded the particular context element class in
context. The second time counted the times the context
elements were followed by the abstract noun, respectively.
Table 2
Co-occurrence matrix for context elements

Abstract noun 1
...
Abstract noun 30

Verb class 1
5
...
0

...
...
...
...

Preposition class n
0
...
58

Evaluation
Thirty context-vectors were constructed based on the cooccurrence matrix, one for each abstract concept. Each
vector represents how often a particular abstract noun
occurs with different kinds of verbs and prepositions in
context. These vectors were used to evaluate the hypothesis
that linguistic context, in the form of verbs and prepositions,
reflects semantic aspects of abstract concepts. If this
hypothesis is correct, then the contexts of similar abstract
concepts should be similar, resulting in a significant
correlation of the cosines of the context vectors with human
similarity judgments of the corresponding abstract concept
pairs.
We tested what context information is related to abstract
concepts in particular.
Six different vectors were
constructed to represent various aspects of context. We
built vectors to represent only prepositions, only verbs, or
both. For each of these, there were two versions: an
extended, “ordered” version that contained word order
information, and a short, “unordered” version that ignored
word order information. For the ordered version, we
counted co-occurrence separately for context elements
preceding versus following the target noun. For the
unordered vectors, co-occurrence counts within the verb and
preposition classes were collapsed to disregard word order.
This vector version thus represents merely how frequently
which kinds of verbs and prepositions can in general cooccur with the abstract noun.
To test whether the verb and preposition context relates to
abstract concepts, we compared the similarity of the context
vectors to similarity judgments of the corresponding abstract
concept pairs, provided by human raters. The 30 abstract
concepts resulted in 435 vector / abstract concept pairs.
Correlations were computed between two similarity
measures: human similarity judgments of the concept pairs,
averaged across 33 raters, and vector cosines for the context
vector pairs. Both measures range from 0 (maximally
dissimilar) to 1 (maximally similar).

Results
Table 3 shows the correlation coefficients. The cosines of
the full vectors, containing verb and preposition cooccurrences and word order information, were significantly
correlated with the human ratings (r = 0.22, p < 0.01).
Table 3
Correlation coefficients between the vectors and human
similarity judgments

Verbs and prepositions
Verbs only
Prepositions only

Ordered
Vectors
0.22
0.22
0.20

Unordered
Vectors
0.17
0.18
0.13

This correlation is modest, but highly significant. It
indicates that more similar abstract concepts tend to have

similar co-occurrence patterns with verbs and prepositions.
This coefficient is higher than the average human interrater
correlation coefficient, computed for a random sample of
100 coefficients (mean r=0.18, SD=0.16).
To estimate the relative relevance of verbs and
prepositions, we computed the vector cosines separate for
verbs and prepositions.
The cosines for both were
significantly correlated with the human ratings (rprep =
0.20, p < 0.01; rverb = 0.22, p < 0.01). Thus, the cooccurrence patterns of both context elements, verbs and
prepositions, are significantly related to abstract concept
similarity.
Further analyses tested the relevance of word order
information. The question here is whether the correlation is
due to the information which verb and preposition classes
can co-occur with an abstract concept in general, or whether
the word order is critically important.
Word order
information may play an important role in abstract concept
representation. For example, in the phrases "due to the
discussion" versus "the discussion due to (...)" the
prepositions express very different information about
discussion. In the first example, the discussion causes some
effect; in the second example, the discussion itself was
caused by something.
We computed the cosines for the vectors that just
represent co-occurrence with verb or preposition classes
without separating co-occurrence counts according to word
order. The cosines were correlated with the human ratings.
The resulting correlations were significant (p < 0.01), but
the correlations were smaller than the ones obtained before.
The correlation for the verb-only vectors was r=0.18; the
preposition-only vectors yielded a correlation of r= 0.13.
The combined verb and preposition vectors led to a
correlation of r=0.17. Thus, word order does increase the
correlation, especially in the case of prepositions.
We compared our results to correlations of the human
similarity judgments with cosines from LSA for the same
concepts. Since LSA takes into account all words in
context, and for a lot more text, it is a good model to
compare our vector matches to. In particular, if verbs and
prepositions cover the important aspects of context related
to abstract concepts, then the correlations of human ratings
with LSA cosines should be comparable to the ones
obtained in our study. If however the match with LSA
cosines is substantially higher than our correlations, then
verb and preposition context conveys only part of the
relevant context information and other word classes should
be included. We found that the correlation between human
judgments and LSA cosines was significant (rLSA = 0.23, p
< 0.01), but not much higher than the correlations we
obtained for our selective context vectors. This might mean
that the correlation obtained from LSA is mostly due to the
verbs and prepositions in the underlying text corpus. At
least, the verb and preposition co-occurrence patterns can
account for as much of the similarity ratings as LSA.

Correlations of Verb and Preposition Context
In addition to these correlations with human ratings, we
looked at a few correlations among the vector cosines. We
found that the cosines of preposition vectors and verb
vectors were significantly correlated (r=0.13), but only if
the vectors separated co-occurrence counts with respect to
word order. In other words, similar abstract concepts tend
to be preceded and followed by similar types of verbs and
prepositions. This means that contexts with similar patterns
of verb occurrence also resemble each other in the patterns
of prepositions they contain.

The Role of Ontological Information
It was mentioned before that verbs and prepositions convey
ontological information (such as states, processes, events).
To what extent can the human similarity judgments and
context vectors be explained by two concepts being of the
same as opposed to different ontological kinds? To test this,
we created a Boolean variable that was "1" when both
concepts in a pair were of the same ontological status, and
"0" otherwise. We correlated this variable with the human
similarity judgments, and with the context vector cosines.
The ontological status was significantly correlated to the
human ratings, r=0.23, p < 0.01. That is, the ontological
status of two concepts may play a role in how people judge
concept similarity. The ontological status was also related
to the context vector cosines, but only to a selective group.
First, it was correlated to the combined verb and preposition
vectors.
Interestingly, the correlation coefficient was
exactly the same for the vectors containing information
about word order and those not containing this information
(r=0.13, p < 0.01). Furthermore, ontological status was
correlated with the preposition-only vector cosines that did
not contain word order information (r=0.10, p < 0.05).
This interesting result suggests that word order matters
with respect to abstract concepts, but may be irrelevant, or
even provide misleading information, with respect to the
ontological status of the abstract concepts. The information
represented by the preposition-only vectors without word
order information simply reflects the frequency with which
abstract concepts co-occur with the different kinds of
preposition classes (Table 1). It makes sense that statehood,
eventhood, etc. would be reflected in the kinds of verbs and
especially prepositions that co-occur with the concepts. For
example, event concepts may be surrounded by temporal
prepositions such as before and after, whereas process
nouns may be marked by prepositions such as while or
during. Ontological status was also significantly correlated
to the LSA cosines (r=0.12) to a similar extent.

Discussion & Implications
We have proposed that abstract concepts are represented by
abstract structures that contain causal, temporal, spatial and
other information pertinent to the abstract concept.
Assuming that these contextual aspects are reflected by the
verbs and prepositions that co-occur with particular abstract
concepts, we have conducted a corpus study that examined

whether similar abstract concepts co-occur with similar
patterns of verbs and prepositions. We found that the
similarity of context vectors based on these word classes
were significantly correlated with the similarity of the
abstract concepts occurring in these contexts. That is,
similar abstract concepts have similar co-occurrence
patterns with verb and preposition classes. We found that
the correlations of abstract concept similarity was not much
higher with cosines of LSA vectors, indicating that verbs
and prepositions may indeed be the most informative
context elements with respect to abstract concepts. We did
find a pretty substantial correlation between the verb and
preposition vectors, however. This correlation suggests an
alternative interpretation, namely, that different aspects of
context are related to abstract concepts but that they are
interrelated, thus that they do not add any further
information to distinguish abstract concepts.
In future work we plan to examine to what extent a
particular set of verb and prepositions can be used to
identify the abstract structure corresponding to an abstract
concept, and to kinds of abstract concepts (e.g., states versus
events). Another interesting question is how many verb and
preposition classes are most informative in relation to
abstract concepts. Perhaps the correlations could be
improved by choosing more classes with finer distinctions,
or conversely, by reducing the class space even further.
Another interesting question is whether our abstract
structure theory can explains context effects as reported by,
for example, Schwanenflugel and Shoben (1983). Contexts
preceding abstract concepts may instantiate the particular
abstract structure underlying their representation and thus
mediate priming effects. This could be tested by setting up
contexts that differ in the amount of information they
provide with respect to the relevant abstract structure.

Acknowledgments
This work was supported in part by the National Science
Foundation, Learning and Intelligent Systems Unit, under
grant SBR-9720314. We further wish to thank three
anonymous reviewers for their very helpful comments on an
earlier draft of this paper, and for useful suggestions for
follow-up work.

References
Altmann, G.T.M., & Kamide, Y. (1999). Incremental
interpretation at verbs: restricting the domain of
subsequent reference. Cognition, 73, 247-264.
Barsalou, L.W. (1999). Perceptual symbol systems.
Behavioral and Brain Sciences, 22, 577-609.
Basili, R., Pazienza, M.-T., & Velardi, P. (1996). A context
driven conceptual clustering method for verb
classification. In B. Boguraev & J. Pustejovsky (Eds.),
Corpus processing for lexical acquisition (pp. 117-142).
Cambridge, MA: MIT Press.
Berwick, R.C. (1989). Learning word meanings from
examples. In D. Waltz (Ed.), Semantic structures:

Advances in natural language processing (pp. 89-124).
Hillsdale, NJ: Lawrence Erlbaum Associates.
Boguraev, B., & Pustejovsky, J. (1996). Issues in text-based
lexicon acquisition. In B. Boguraev & J. Pustejovsky
(Eds.), Corpus processing for lexical acquisition (pp. 317). Cambridge, MA: MIT Press.
Burgess, C., & Lund, K. (1997). Representing abstract
words and emotional connotation in a high-dimensional
memory space. Proceedings of the Nineteenth Annual
Conference of the Cognitive Science Society (pp. 61-66).
Hillsdale, NJ: Lawrence Erlbaum Associates.
Fisher, C. (1994). Structure and meaning in the verb
lexicon: input for a syntax-aided verb learning procedure.
Language and Cognitive Processes, 9, 473-517.
Hastings, P. (1994). Automatic acquisition of word meaning
from context. Doctoral dissertation, University of
Michigan.
Hess, D.J., Foss, D.J., & Carroll, P. (1995). Effects of global
and local context on lexical processing during language
comprehension. Journal of Experimental Psychology:
General, 124, 62-82.
Keil, F.C. (1979). Semantic and conceptual development.
Cambridge, MA: Cambridge University Press.
Landauer & Dumais (1997). A solution to Plato’s problem:
The latent semantic analysis theory of acquisition,
induction,
and
representation
of
knowledge.
Psychological Review, 104, 211-240.
Levin, B. (1993). English verb classes and alternations.
Chicago: University of Chicago Press.
Miller, G.A., & Charles, W.G. (1991). Contextual correlates
of semantic similarity. Language and Cognitive
Processes, 6, 1-28.
Quine, W.V.O. (1960). Word and object. Cambridge, MA:
MIT Press.
Schank, R.C., & Abelson, R. (1977). Scripts, plans, goals,
and understanding. Hillsdale, NJ: Lawrence Erlbaum
Associates.
Schwanenflugel, P.J., & Shoben, E.J. (1983). Differential
context effects in the comprehension of abstract and
concrete verbal materials. Journal of Experimental
Psychology: Learning, Memory, and Cognition, 9, 82102.
Sharkey, N.E., & Mitchell, D.C. (1985). Word recognition
in a functional context: the use of scripts in reading.
Journal of Memory and Language, 24, 253-270.
Sternberg, R.J., & Powell, J.S. (1983). Comprehending
verbal comprehension. American Psychologist, 38, 878893.
Wiemer-Hastings, K. (1998). Abstract noun classification:
Using a neural network to match word context and word
meaning. Behavior Research Methods, Instruments, &
Computers, 30, 264-271.
Wiemer-Hastings, P., Graesser, A.C., & Wiemer-Hastings,
K. (1998). Inferring the meaning of verbs from context.
Proceedings of the Twentieth Annual Conference of the
Cognitive Science Society (pp. 1142-1147). Mahwah, NJ:
Lawrence Erlbaum Associates.

