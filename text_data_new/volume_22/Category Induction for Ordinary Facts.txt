UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Category Induction for Ordinary Facts

Permalink
https://escholarship.org/uc/item/01r1x16k

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)

Authors
Taraban, Roman
Hayes, Matt

Publication Date
2000-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Category Induction

Category Induction for Ordinary Facts
Roman Taraban (r.taraban@ttu.edu)
Matt Hayes
Department of Psychology
Texas Tech University
Lubbock, TX 79409-2051
Abstract
Typically, research on category learning has examined the acquisition of correct responses for explicitly identified categories. A connectionist model developed by McClelland (1981)
used an interconnected network of factual elements to show
that it was possible for a network to correctly infer connections between knowledge representations that were not explicitly coded into the network. Two experiments were conducted with adults using facts from the McClelland model.
Clustering related facts, presenting the full set of transfer
probes, and providing intermittent feedback during learning,
did not reliably amplify the induction of implicit categories
that was necessary for the transfer of learning tasks. The data
in both experiments revealed a wide range of individual differences suggestive of graded levels of category induction. A
series of simulations using backpropagation with recurrent
connections showed that individual differences could be accounted for by manipulating feedback connections, the number of hidden units, and their connectivity. The discussion
considers the relation of these findings to related research involving correlated features.

The notion of similarity has been very compelling in explanations of category acquisition. Intuitively it makes sense
that we group things together because they are similar to
each other. The details of how similarity should be computed have changed as theories have replaced one another
over time (Taraban, 1993). However, one essential idea has
remained, that category acquisition is driven by the identification or weighting of features that signal membership in
one category or another. What is important to note for purposes of the present paper is that these theories of the relation of features to categorical distinctions have largely considered cases in which the features are all present and immediately available in instances of the object, and the possible classifications are made explicit to the learner (e.g.,
Nosofsky, Gluck, Palmeri, McKinley, & Glauthier, 1994).
Typically, experiments have involved supervised learning,
in which the category labels are part of what a participant
learns. However, category learning is sometimes unsupervised, as when children learn to use linguistic elements that
have an underlying categorical structure in their native language without ever labeling those categories (MacWhinney,
Leinbach, Taraban, & McDonald, 1989), when they learn
unlabeled categories in artificial languages (Billman, 1989;
Brooks, Braine, Catalano, Brody & Sudhalter, 1993; Frigo
& McDonald, 1998), or when they learn to classify events

(Kersten & Billman, 1997). In these cases, properties that
are correlated form the basis for categories. The categories
remain unlabeled and outside of direct instruction, but still
influence individuals’ classifications of novel instances.
Ordinary communication often carries correlated information, but it presents special difficulties because information
is dispersed over time due to the serial and temporal nature
of speech and print. A body of correlated information may
be communicated, but the individual must construct or induce these correlations against temporal constraints. The
question of how categories are formed and processed when
the characteristic or defining features of the category are not
simultaneously available has received very little attention.
One of the few explicit models for the dynamic induction of
categories based on co-occurring properties was proposed
by McClelland (1981; see also McClelland & Rumelhart,
1988), who proposed a mechanism that could form generalizations from stored representations. The model was unique
in that the “probe” or initiating information did not provide
all the relevant cues simultaneously (e.g., large, white, triangle, as in Nosofsky et al., 1994). Instead, categories of
co-occurring properties could be induced from encoded
facts through a process of spreading activation and inhibition along connected pathways in a connectionist network.
The network was capable of filling in missing information
about an individual who was represented in the network
(e.g., a gang member called Lance) due to co-occurring
properties between that individual and other individuals represented in the network. The network could also provide the
most likely features associated with groups (e.g., a gang
called the Jets) based on properties that generally cooccurred with that group. The model is plausible in the sense
that ordinary circumstances often expose us to disparate
facts, and it has important implications in that it suggests we
may still induce useful categorical generalizations based on
co-occurrence patterns within those facts.

Experiments 1 and 2
In Experiments 1 and 2, participants learned facts about individuals. Part of the learning was supervised, consisting of
a name (e.g., Lance) and a category (e.g., education), with
feedback indicating the correct response (high school).
These facts are labeled the base learning items in Table 1.
The responses to base learning items clustered into two im-

Category Induction

plicit categories (i.e., all the individuals sharing the properties Jets, high school, and drug dealer, and all the individuals sharing the properties Sharks, junior high, and car thief).
If participants induced these connections, it was through
unsupervised learning, because those connections were
never directly brought to participants’ attention. Further,
induction of these implicit categories drew heavily on memory, as the correlated properties never appeared together on
a learning trial. Participants’ induction of the implicit categories was tested using two types of transfer questions, base
transfer and novel transfer items. Base transfer items asked
participants about individuals’ properties that were not
among the base learning items. For instance, participants
learned about Lance’s gang and education, but not his occupation. For novel transfer items participants were given a
“hint” about a totally new person (e.g., Moe has a junior
high education) and were asked about the remaining properties (his gang and occupation).
Consonant with connectionist learning principles, performance on the transfer items would depend on weighted
interconnections between elements. Relatedly, the amount of
transfer would not be all-or-none but could occur in varying
degrees. The discovery of individual differences would be
consistent with learning in connectionist models, which occurs incrementally at different learning rates.
Category features that are activated together become associated (Billman, 1989; Kersten & Billman, 1997). As has
already been described, learning trials in Experiments 1 and
2 presented a single property. Experiment 1 examined
whether learning the underlying pattern of connections between properties could be facilitated by presenting related
properties on contiguous trials. In Experiment 2, two additional manipulations were tested in an attempt to amplify
category induction. One involved providing intermittent
feedback during learning. The other involved presenting
transfer probes during learning, without feedback. Both
were meant to encourage participants to think about the connections between the properties they were learning.

Method
Participants The 40 participants in Experiment 1 and the
60 participants in Experiment 2 were recruited from introductory psychology courses at Texas Tech University and
participated for course credit.

Materials The learning and transfer materials were based on
the table of information in McClelland (1981), although
considerably reduced. Each of 16 individuals was described
along three binary-valued dimensions: his gang membership,
his education level, and his occupation. The assignment of
dimension values to individuals was fully reliable in the
following sense. If an individual belonged to the Jets, then
that individual was also a drug dealer with high school education. Likewise, a member of the Sharks always had a
junior high education and made his living as a car thief.
Forty probes and eight hints were constructed from the matrix of information in Table 1. Each probe consisted of two
parts: a name and the category of information about the
named person. Example probes were Art’s gang, Art’s education, Art’s occupation.
Procedure In Experiment 1, participants were randomly
assigned to one of two conditions. In both conditions,
learning trials were presented one at a time in blocks consisting of 18 probes. In the unclustered condition, the 18
base-learning probes were randomized. In the clustered
condition, probes were also presented in random order with
the exception that all probes about a particular person were
presented in sequential trials (e.g., trialn: Lance’s education;
trialn+1: Lance’s gang).
In Experiment 2, participants were randomly assigned to
one of three conditions. The conditions differed in the number of base items that appeared in the learning sets and in the
amount of feedback provided to participants during learning.
The control condition was identical to the unclustered condition in Experiment 1. Participants learned the18 base
learning items shown in Table 1. The intermittent-control
condition was identical to the control condition, except that
feedback consisting of the correct response was provided at
random two thirds of the time. The intermittent-base condition was identical to the intermittent-control condition, except that the six base transfer probes were mixed in randomly in each block of learning trials. Participants never
received feedback on the base transfer items. The final test
was identical in all three conditions.
Participants worked individually at a computer. One or
two meetings were provided for learning the base items to

Table 1: Base Learning, Base Transfer, and Novel Transfer Items
Base Learning and Base Transfer Items
Novel Transfer Items
Name
Gang
Education
Occupation
Name
Gang
Education
Occupation
Art
Jets
high school
drug dealer
Chuck
*
~ high school
*
Lance
Jets
high school
*
Jake
~ Jets
*
*
Greg
*
high school
drug dealer
Zane
*
~ high school
*
Pete
Jets
*
drug dealer
Ed
~ Jets
*
*
Nick
Sharks
junior high
car thief
Moe
*
~ junior high
*
Earl
Sharks
junior high
*
Gene
*
*
~ car thief
Karl
*
junior high
car thief
Vick
~ Sharks
*
*
Bill
Sharks
*
car thief
Ron
~ Sharks
*
*
* Base and novel transfer items are marked with an asterisk. ~ The hints used for novel items are marked with a tilde.

Category Induction

criterion and one meeting was provided for taking the final
test. Learning was self-paced. A learning trial consisted of a
screen displaying a probe about one of the individuals in the
experiment. The participant typed in a response. Feedback
(when provided) indicated whether the response was correct
or incorrect, and the correct response was displayed on the
screen. Participants initiated the next trial by pressing a key
on the keyboard. When participants reached the criterion of
17 or 18 correct, they were dismissed until the next day
when the final test was administered.
Test trials were identical to learning trials in the way
probes were presented and responses were made, except that
participants did not receive feedback. Test trials were presented in two sets. The first set consisted of the presentation
of the full set of 24 base-learning and base-transfer probes in
random order. Immediately after responding to the 24
probes, participants were instructed by the computer that
they would be presented with new items, that for each trial
they would be given a “hint,” and that they should give their
best response. For all trials, participants’ responses and accuracy were automatically recorded by the computer.

curacy; base transfer and novel transfer did not differ from
one another.
The possibility of individual differences in these data warranted a closer examination of individual test outcomes.
Indeed, the rationale for a gamma parameter in the McClelland (1981) model was to allow for individual differences in
induction. The incremental nature of connectionist learning
is also suggestive of individual variation. Participants did
quite well on the base learning items, but differed noticeably
in their performance on the transfer items (See Appendix).
Assuming a binomial distribution (n = 16, p = .50) of individual responses for the novel transfer items, 35% (n = 7) of
the participants in the unclustered condition and 50% (n =
10) in the clustered condition had accuracy rates that were
not likely to be due to chance (accuracy > 75%, p < .03).
For base transfer items, 10% (n = 2) of the participants in
the unclustered condition and 5% (n = 1) in the clustered
condition scored better than chance (binomial: n = 6, p =
.50; accuracy = 100%, p < .02) (These three participants
also scored better than chance on the novel transfer items).

Results for Experiment 2
Results for Experiment 1
Participants took an average of 215 trials to reach criterion
in the unclustered condition and 189 trials in the clustered
condition. Mean accuracy for all the learning trials in the
unclustered condition was 63.6% and in the clustered condition 66.7%. Although these means favored mastering the
base learning items in the clustered condition, an analysis of
variance using number of trials as the dependent variable
failed to show that the effect of condition was significant [F
(1, 38) = 0.58, MSE = 11769, ns], and an analysis using percent correct as a dependent measure failed to show that accuracy rates were significantly different [F (1, 38) = 1.60,
MSE = 59.26, ns].
Table 2: Mean Percent Accuracy for Final Test
Item Type

Experiment 1
Experiment 2
UN
CL
CO IC IB
Base Learning
83
84
85 83 82
Base Transfer
57
50
55 67 52
Novel Transfer
59
67
63 67 55
Note. UN: unclustered; CL: clustered; CO: control; IC: intermittent control; IB: intermittent base
Table 2 summarizes the final test data. Participants’ accuracy was high on base learning trials (84%), lower on novel
transfer trials (63%), and lowest on base transfer trials
(53%). A 2 (Condition: clustered, unclustered) X 3 (Item
Type: base learning, base transfer, novel transfer) analysis of
variance showed a main effect for item type [F (2, 76) =
23.85, MSE = 409.19, p < .001] but not for condition [F (1,
38) = 0.03, MSE = 628.92, ns] nor interaction of the two
factors [F (2, 76) = 1.31, MSE = 409.19, ns]. Tukey HSD
(alpha = .05) tests showed that base learning accuracy differed significantly from base transfer and novel transfer ac-

Participants took an average of 250 trials to reach criterion
in the control condition, 284 trials in the intermittent-control
condition, and 222 trials in the intermittent-base condition.
These differences were not reliable [F (2, 57) = 1.10, MSE =
17756.41, ns]. The mean percent correct was 61.4 in the
control condition, 63.7 in the intermittent-control condition,
and 58.4 in the intermittent-base condition. These differences were significant [F (2, 57) = 4.26, MSE = 33.87, p <
.02]. Tukey HSD tests showed that mean accuracy in the
intermittent-control condition was significantly higher than
in the intermittent-base condition. The control and intermittent control conditions were not significantly different. The
small advantage for the intermittent-control condition was
due in part to the additional blocks of trials these participants needed to reach criterion. These late trials tended to be
error free.
The test data are summarized in Table 2. A 3 (Condition:
control, intermittent-control, intermittent-base) X 3 (Item
Type: base learning, base transfer, novel transfer) analysis of
variance showed a main effect for item type [F (2, 114) =
31.93, MSE = 362.67, p < .001]. Tukey HSD tests showed
that base learning accuracy differed significantly from base
transfer and novel transfer accuracy; base transfer and novel
transfer did not differ from one another. The effect of condition was not significant [F (2, 57) = 1.56, MSE = 834.38,
ns], nor was the Condition X Item Type interaction [F (4,
114) = 0.98, MSE = 362.67, ns].
A closer look at individual performance was again undertaken. For the novel transfer items, 40% (n = 8) of the participants in the control condition, 55% (n = 11) in the intermittent-control condition, and 30% (n = 6) in the intermittent-base condition had accuracy rates that were not likely to
be due to chance (binomial: n = 16, p = .50; accuracy >
75%, p < .03). On base transfer items, 15% (n = 3) of the
participants in the control condition, 20% (n = 4) in the intermittent-control condition, and 5% (n = 1) in the intermit-

Category Induction

tent-base condition scored better than chance (binomial: n =
6, p = .50; accuracy = 100%, p < .02); all but one of these
also scored better than chance on the novel transfer items.
Because the experimental manipulations in Experiments 1
and 2 failed to produce reliable differences, combining the
data was warranted in order to increase statistical power.
Across the 100 participants, mean accuracy on base transfer
items was 56%, and on novel transfer items it was 62%. A
one-sample t-test showed that base transfer performance was
significantly greater than chance (50%) [t (99) = 2.55, p <
.02]. A paired t-test showed that performance on novel
transfer items was significantly higher than on base transfer
items [t (99) = -2.06, p < .05]. Overall, participants did
better on novel transfer items. Performance for both types of
transfer items exceeded chance.

Discussion
A knowledge base was organized around individuals, like
Art and Lance, about whom participants learned properties
(e.g., Lance’s gang is Jets; Lance’s education is high
school). In order to transfer knowledge of these facts to new
instances, participants had to use the learned facts to induce
the categorical relations between them. There is no specific
way in which this had to be done. A person might notice
that Jets and high school always co-occur without noting the
link with drug dealer. A person might induce some other
connections or the complete set of connections. An examination of individual performances (see Appendix) suggests
large discrepancies in induction. Some participants appeared to perform at chance on the transfer trials, others
scored perfectly, and yet others were in between. These data
suggest that individuals can evoke the appropriate categories
even if these were not explicitly taught. As the McClelland
(1981) model suggests, it is not necessary to develop explicit connections in order to exploit the existing connections in useful ways. The data also support the supposition
that the level of induction is graded. This is consistent with
connectionist models, which do not encode rules or If-Then
productions, but which develop interconnections and internal representations (on a hidden layer) incrementally, or
alternatively, which control the spread of activation and inhibition parametrically within a storage and retrieval mechanism like McClelland’s (1981).

Connectionist Simulations
In a preliminary set of simulations, the base learning items in
Table 1 were interconnected as described in McClelland
(1981) and McClelland and Rumelhart (1988). There were
no direct connections for base transfer items (e.g., a link
from Lance to drug dealer). For novel transfer items, the
“hint” (e.g., Jets) was activated. The model was tested at
three settings of gamma, a parameter that controls the level
of inhibition between units in the same pool of units in the
network, and thereby changes the level of generalization
(McClelland, 1981). With gamma set to .1000, .1249, or
.1500, the mean probability of a correct response to base
learning items was .98. Probabilities for base transfer items
were .97, .67, .50, respectively. For all three gamma values

the probability of a correct response to novel transfer items
was .98.1 The first two findings are consistent with the findings in Experiments 1 and 2, that is, a range of individual
differences on base transfer items when performance was
high on base learning items. The third outcome of the
simulation, uniformly high performance on novel transfer
items, did not fit the data, which showed a wide range of
individual differences on these items. It is generally impossible to salvage the McClelland (1981) model. When given a
hint like Jets, the network needs to find only one member
with that feature and will generalize from that member. The
highest levels of inhibition leave at least one member to
generalize from. Another shortcoming of the McClelland
model for present purposes is that it uses fixed weights and
thus does not account for individual differences based on
learning.
The binomial analyses of individual performance presented earlier suggested that there were three major patterns
of behavior (See the Appendix for representative data). The
most predominant pattern, characteristic of 54% of the 100
participants, was above chance performance on the base
learning items and chance performance on base transfer and
novel transfer items, which will be labeled the HLL pattern.
The next most predominant pattern, representing 29% of the
participants, was above chance performance on the base
learning, chance performance on the base transfer items, and
above chance performance on novel transfer items (the HLH
pattern). Ten percent of the participants achieved above
chance performance on all items (the HHH pattern). Only
one participant had a HHL pattern. Three participants had
LLH patterns and three had LLL patterns. The connectionist
solution presented next required the simultaneous manipulation of multiple connectionist factors, including network
architecture, hidden unit resources, connectivity, and internal feedback. The model replicated all the patterns above
except the LLL and the LLH patterns. Adding a decay factor
would be necessary to account for human participants who
reached the criterion on the day prior to the test but who
scored at chance (L - -) on base learning items on the day of
the test.
The model is depicted in Figure 1. The inputs, corresponding to probes, activated exemplars (local representations). Each input (e.g., Art) was linked to a single exemplar
unit (e.g., Art). All other units between pools were fully interconnected. The output units had recurrent connections
back to a hidden layer of units (distributed representation).
The hidden layer also received connections from the exemplar units. A learning trial occurred in two

1

All connections in the network were set to 1. Default values
were used for the parameters alpha, decay, and estr. The remaining parameters were set to max = 1.10, min = .01, rest = .01 for
ease of interpreting the output. The probabilities were based on an
application of the Luce (1959) choice rule to the activations from
the relevant pool of units; e.g., P(Jets) = activation (Jets) / activation (Jets) + activation (Sharks).

Category Induction

Table 3: Mean Probabilities (X100) for the Connectionist Simulations

Item Type
Base Learning
Base Transfer
Novel Transfer

1

2

90
51
50

92
53
55

Feedback Connections Only
Number of Hidden Units
3
4
5
6
7
8
9
91
44
78

91
49
88

91
48
82

91
49
81

91
52
52

91
52
48

91
51
51

passes. During the first pass, the output units were activated
by the inputs via the exemplar and hidden units. During the
second pass, activation was passed back to the hidden units
via the recurrent connections and only these units fed activation forward to the output units. Error on each pass was
calculated and weight adjustment took place through the
application of the backpropagation learning rule (Rumelhart,
Hinton, & Williams, 1986) at the end of each epoch of
training. An epoch of training consisted of one exposure to
each base learning item.
For base learning and base transfer test trials, a name
(e.g., Art) and category (e.g., occupation) were presented on
the input layer, and the probability of a correct response was
computed using the Luce (1959) choice rule for the relevant
activations (see footnote 1). For novel transfer items, the
“hint” (e.g., gang, Jet) was activated on the output layer,
which functioned as the “teacher,” and fed back to the hidden units; the probe category (e.g., occupation) was activated on the input layer. Activation was fed forward to the
output layer and probabilities were computed as described
above. On test trials, there was a single pass through the
network and no weight adjustments.
Activation and weight adjustment roughly corresponded
to a trial in the human experiments. An explicit probe
evoked an output, feedback was provided and all the weights
were adjusted in order to improve performance on the base
learning items. During the second pass, there was an implicit recirculation of the outputs through the hidden layer
(cf., McClelland, McNaughton, & O’Reilly, 1995, for a discussion of consolidation in memory) and related weight adjustment. The first pass in learning corresponded to elements
that could be observed in the experimental manipulation
(e.g., probes, response, feedback). The second pass corresponded to unobservable processes for which some justification will be provided in the course of describing the
simulation manipulations and results.
Each simulation outcome presented in Table 3 is the mean
of 10 independent simulations. All the parameters in the
simulations were fixed, except whether or not the exemplar
units were connected to the hidden units, and the number of
hidden units, which varied from one to ten. The learning rate
for all trials was .01, momentum was .90, and each simulation consisted of 4000 epochs of training. Eleven input units
were used to code base learning trials. One input was allocated to each of eight gang member names and one to each
category of information (i.e., gang, education, occupation).
Thus, the input layer mimicked a participant who was asked
Art’s gang, for instance. Each of these input units connected to a single exemplar unit. These internal exemplar
representations were necessary to guarantee high learning of
the base learning items across all manipulations of the hid-

10

Feedback and Exemplar Connections
Number of Hidden Units
1
2
3
4
5
6
7
8
9

10

91
51
49

90
53
51

97
91
52

94
73
54

96
88
89

97
92
95

97
92
93

97
89
94

97
94
51

97
93
50

97
91
55

den units. The exemplar units connected fully to all the output units. The output units coded the same elements as the
input layer and, additionally, the responses to the probes
(e.g., Jets, drug dealer). These feedforward connections
from input to exemplar units to output units were all that was
required to learn base learning items.
Output Units

Hidden Units
Exemplar Units

Inputs
Figure 1: The Simulation Model
Feedback connections from all the output units were fully
connected to the hidden units. A practical benefit of the
feedback connections is that they allowed the “hint” that was
used for the novel transfer trials to originate from the
“teacher” (output) units, where the responses were coded.
Feedback connections like these, or an equivalent, were necessary to cross reference the probes and responses in the
experimental manipulation. These feedback connections
were primarily responsible for the gradations of performance, up to 88% correct, on novel transfer items depending
on the number of hidden units (see Table 3). By varying the
number of hidden units, base learning items were high
(90%-92%) and base transfer items were near chance (48%53%). In half of the simulations, the exemplar units also
connected to the hidden units. These additional connections, along with the feedback connections from output
units, allowed for gradations of performance on base transfer (53%-94%) and novel transfer items (50%-95%), depending on the number of hidden units. Near perfect performance on all three types of items occurred with four hidden units: base learning (97%), base transfer (92%), and
novel transfer (95%).
The simulations were not intended to account for all the
individual differences in the human data, but rather to uncover network organizations that produced variations comparable to those observed in the human performance. Doing
well on base transfer items requires connections between the
exemplar units and the hidden units. One account of participants’ better performance on novel versus base transfer
items is that connections from exemplar units to hidden units
were formed less readily than feedback (recurrent) connec-

Category Induction

tions. The pattern in Table 3 for the transfer trials also suggests that too few or too many hidden units is not ideal.
This suggests that the hidden units control the dimensionality of the solution (cf., Hinton, 1992). The dimensionality of
the solution determines how much induction takes place (cf.,
Landauer & Dumais, 1997).

General Discussion
The experiments and simulations presented here were inspired by McClelland’s (1981) connectionist model that was
able to infer connections between stored “facts,” even
though the network was not explicitly trained to make those
connections. Correctly making these inferences depends on
uncovering the correlational structure between the facts.
Further research is necessary to confirm that differences in
the conditions of learning and retrieval are crucial to explaining the strong individual differences found in the human performance here and elsewhere. Two bodies of research currently suggest somewhat different conclusions on
these points. Billman (1989) and Kersten and Billman
(1997) contrasted learning and generalization for stimuli
with many correlated features to those with only few correlated features and found that participants readily generalized
from the former but not the latter. The features of the facts
in Experiments 1 and 2 were also highly correlated, but participants did not readily form generalizations from them.
The crucial difference, which remains to be tested more
fully, is that Billman and Kersten explicitly displayed the
correlations as part of their learning phase, whereas the connections in our experiments were implicit across learning
trials. For instance, Jets and drug dealer are perfectly correlated, but participants never viewed those two features
together. The present manipulations are more comparable
to the “control” language in the artificial language experiments of Brooks et al. (1993). Their control language also
had a rich correlational structure comparable to the ways in
which noun gender in languages like Russian affects morphological and inflectional differences. In spite of the underlying correlations, participants found the control language difficult to learn, we surmise, because the correlational structure was implicit across trials as in the present
study. However, the generally low performance for the
control language presumably included a range of individual
differences, as presented here, meaning that some individuals discover the correlational structure in spite of its dispersion over trials. Therefore, we believe that the present research begins to bridge several lines of existing research,
that it uncovers the broad individual differences in performance, and offers a preliminary connectionist explanation for
those differences. The counterpart to the “experimental”
language in Brooks et al. and “high systematicity” in Billman needs to be tested for the current stimuli and integrated
into the present connectionist architecture.

Appendix
Each triple, separated by semicolons, is mean percent accuracy for each participant, for base learning, base transfer,
and novel transfer items, respectively.

Experiment 1, Unclustered 100, 83 ,69; 100, 100, 94; 94,
67, 94; 94, 50, 88; 94, 33, 50; 89, 50, 25; 89, 100, 100; 89,
50, 31; 89, 83, 44; 89, 67, 44; 89, 50, 25; 83, 33, 100; 83,
50, 69; 78, 17, 25; 78, 67, 25; 72, 33, 76; 72, 67, 25; 72, 50,
47; 61, 33, 88; 50, 50, 63 Clustered 100, 100, 100; 94, 67,
31; 94, 67, 38; 94, 33, 41; 94, 33, 18; 89, 33, 56; 89, 50, 18;
89, 33, 44; 89, 67, 94; 89, 67, 100; 83, 50, 94; 83, 17, 44;
78, 17, 100; 78, 67, 50; 78, 67, 100; 78, 50, 81; 78, 50, 100;
72, 50, 94; 72, 33, 50; 67, 50, 88.

References
Billman, D. (1989). Systems of correlations in rule and category
learning: Use of structured input in learning syntactic categories.
Language and Cognitive Processes, 4, 127-155.
Brooks, P., Braine, M., Catalano, L., & Brody, R. (1993). Acquisition of gender-like noun subclasses in an artificial language:
The contribution of phonological markers to learning. Journal
of Memory and Language, 32, 76-95.
Frigo, L., & McDonald, J. (1998). Properties of phonological
markers that affect the acquisition of gender-like subclasses.
Journal of Memory and Language, 39, 218-245.
Hinton, G. (1992). How neural networks learn from experience.
Scientific American, 145-151.
Kersten, A., & Billman, D. (1997). Event category learning. Journal of Experimental Psychology: Learning, Memory, and Cognition, 23, 638-658.
Landauer, T., & Dumais, S. (1997). A solution to Plato’s problem:
The latent semantic analysis theory of acquisition, induction,
and representation of knowledge. Psychological Review, 104,
211-240.
Luce, R. (1959). Individual choice behavior. New York: Wiley.
MacWhinney, B., Leinbach, J., Taraban, R., & McDonald, J.
(1989). Language learning: Cues or rules. Journal of Memory
and Language, 28, 255-277.
McClelland, J. L. (1981). Retrieving general and specific information from stored knowledge of specifics. Proceedings of the
Third Annual Meeting of the Cognitive Science Society, 170172.
McClelland, J. L., McNaughton, B., & O’Reilly, R. (1995). Why
there are complementary learning systems in the hippocampus
and neocortex: Insights from the successes and failures of
connectionist models of learning and memory. Psychological
Review, 102, 419-457.
McClelland, J. L., & Rumelhart, D. (1988). Explorations in parallel distributed processing. Cambridge, MA: MIT Press.
Nosofsky, R., Gluck, M., Palmeri, T., McKinley, S., & Glauthier,
P. (1994). Comparing models of rule-based classification learning: A replication and extension of Shepard, Hovland, and Jenkins (1961). Memory & Cognition, 22, 352-369.
Rumelhart, D., Hinton, G., & Williams, R. (1986). Learning internal representations by error propagation. In D. Rumelhart, J.
McClelland, & the PDP Research Group, Parallel distributed
processing: Explorations in the microstructure of cognition.
Cambridge, MA: MIT Press.
Taraban, R. (1993). Introduction: A coupling of disciplines in
categorization research. In G. Nakamura, R. Taraban, and D.
Medin (Eds.), The psychology of learning and motivation, Vol.
29: Categorization by humans and machines. San Diego, CA:
Academic Press.

