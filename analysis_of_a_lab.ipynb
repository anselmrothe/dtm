{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from IPython.core.debugger import set_trace\n",
    "import difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "alldata_new = pickle.load(open('output/dtm_processed_output.p', 'rb'))\n",
    "alldata_new.keys()\n",
    "doc_year=alldata_new['docs_per_year']\n",
    "doc_ids =[0]+list(np.cumsum(doc_year))\n",
    "\n",
    "term_topic = alldata_new['term_topic']# term_topic is n_years*n_topics*n_terms\n",
    "terms = alldata_new['terms']\n",
    "term_frequency = alldata_new['term_frequency'][1:] # weirdly the first entry is empty\n",
    "doc_topicyrs = alldata_new['doc_topic']\n",
    "\n",
    "doc_topic = []\n",
    "doc_length=[]\n",
    "for year in range(len(term_topic)):    \n",
    "    doc_topic.append(alldata_new['doc_topic'][doc_ids[year]:doc_ids[year+1]])# doc_topic is nyear*n_docs given year*n_topics\n",
    "    doc_length.append(alldata_new['doc_length'][doc_ids[year]:doc_ids[year+1]]) #doc_length is nyear*n_docs given year\"\"\"    \n",
    "# rename topics by the hand-picked names\n",
    "topic_labels = pickle.load(open('topicnames.p','rb'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stringdiff(a,b):\n",
    "    return sum ( a[i] != b[i] for i in range(len(a)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def finddoc(alldocs,title):\n",
    "    for doc in alldocs:\n",
    "        \"\"\"print(doc)         \n",
    "        matchratio = difflib.SequenceMatcher(None,title,doc).ratio()\n",
    "        print(matchratio)\n",
    "        if matchratio >.9:\n",
    "            print(doc+'\\n'+title)\n",
    "            idx = alldocs.index(doc)\n",
    "            return([year,idx])\"\"\"\n",
    "        if len(doc)==len(title):\n",
    "            if stringdiff(doc,title)<3:\n",
    "                #print(doc+'\\n'+title)\n",
    "                idx = alldocs.index(doc)\n",
    "                return([year,idx])\n",
    "    return([])\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getlist(titles):\n",
    "    titles = [k.lower() for k in titles]\n",
    "    doclist=[]\n",
    "    titlelist=[]\n",
    "    for t in titles:\n",
    "        didfind=False\n",
    "        for year in range(18):\n",
    "            docdir = 'text_data/volume_{}/'.format(22+year)\n",
    "            alldocs = glob.glob(docdir+'*.txt')\n",
    "            alldocs = [k.lower()[20:-4] for k in alldocs]\n",
    "            find=finddoc(alldocs,t)\n",
    "            if find:\n",
    "                doclist.append(find)\n",
    "                titlelist.append(t)\n",
    "                didfind=True\n",
    "                break\n",
    "\n",
    "        if didfind==False:\n",
    "            print('\\ncannot find: '+t)\n",
    "    return([doclist,titlelist])\n",
    "# given a list of paper, what are their main topics? for analyzing like a lab or an author\n",
    "def maintopics(doclist,*topic_labels):\n",
    "    ntopics=20\n",
    "    doc_topfreq=np.empty((len(doclist),ntopics))\n",
    "    for k in range(len(doclist)):\n",
    "        if len(doclist[0])==1:\n",
    "            doc_topfreq[k]=alldata_new['doc_topic'][doclist[k]]\n",
    "        elif len(doclist[0])==2: # year then index\n",
    "            doc_topfreq[k]=doc_topic[doclist[k][0]][doclist[k][1]]\n",
    "            \n",
    "    doc_topfreq = np.mean(doc_topfreq,axis=0)\n",
    "    print(doc_topfreq)\n",
    "    maintopid = np.argsort(-doc_topfreq) \n",
    "    doc_topfreq=doc_topfreq[maintopid]\n",
    "    if topic_labels:\n",
    "        maintopics=[topic_labels[0][idx] for idx in maintopid]\n",
    "    return (maintopics,doc_topfreq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cannot find: computationally reproducible experiments\n",
      "\n",
      "cannot find: online experiments using jspsych, psiturk, and amazon mechanical turk\n",
      "[  3.52360824e-05   3.52360824e-05   2.83207576e-02   3.52360826e-05\n",
      "   9.24625903e-03   3.52360824e-05   3.52360823e-05   3.52360825e-05\n",
      "   3.52360827e-05   1.74083251e-02   2.69273092e-03   3.52368036e-05\n",
      "   3.52360823e-05   3.52360822e-05   3.52360825e-05   3.89713131e-01\n",
      "   3.52360823e-05   5.52125491e-01   3.52360827e-05   3.52360824e-05]\n",
      "> \u001b[0;32m<ipython-input-9-c71673ab08b7>\u001b[0m(36)\u001b[0;36mmaintopics\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mdoc_topfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc_topfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaintopid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mtopic_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mmaintopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaintopid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaintopics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_topfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "label='alex'\n",
    "titles=['Computationally reproducible experiments','The Attentional Learning Trap and How to Avoid it','Online Experiments using jsPsych, psiTurk, and Amazon Mechanical Turk']\n",
    "[doclist,titlelist]=getlist(titles)        \n",
    "(mtops,meantpfreq)=maintopics(doclist,topic_labels)\n",
    "with open('result/lab_topic/'+label+'.txt','w') as f:\n",
    "    for k in range(len(mtops)):\n",
    "        f.write(mtops[k]+', freq={}'.format(meantpfreq[k])+'\\n')\n",
    "    f.write('\\n papers included:\\n')\n",
    "    for title in titlelist:\n",
    "        f.write(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.12893817e-05   8.85112609e-03   3.12891121e-05   1.51686260e-02\n",
      "   1.23247133e-02   7.62020917e-02   3.12891121e-05   3.12891121e-05\n",
      "   3.55792874e-01   3.12891119e-05   1.72890294e-01   6.94449590e-02\n",
      "   3.12891121e-05   5.06132765e-02   2.38367859e-01   3.12891120e-05\n",
      "   3.12891119e-05   3.12891121e-05   3.12891121e-05   3.12891121e-05]\n",
      "> \u001b[0;32m<ipython-input-9-c71673ab08b7>\u001b[0m(36)\u001b[0;36mmaintopics\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     34 \u001b[0;31m    \u001b[0mdoc_topfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoc_topfreq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmaintopid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     35 \u001b[0;31m    \u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 36 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mtopic_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     37 \u001b[0;31m        \u001b[0mmaintopics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtopic_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaintopid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     38 \u001b[0;31m    \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaintopics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdoc_topfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n"
     ]
    }
   ],
   "source": [
    "label='anselm'\n",
    "titles=['Asking and evaluating natural language questions']\n",
    "[doclist,titlelist]=getlist(titles)        \n",
    "(mtops,meantpfreq)=maintopics(doclist,topic_labels)\n",
    "with open('result/lab_topic/'+label+'.txt','w') as f:\n",
    "    for k in range(len(mtops)):\n",
    "        f.write(mtops[k]+', freq={}'.format(meantpfreq[k])+'\\n')\n",
    "    f.write('\\n papers included:\\n')\n",
    "    for title in titlelist:\n",
    "        f.write(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cannot find: information selection in categorization with stimulus uncertainty\n",
      "\n",
      "cannot find: the distorting effects of deciding to stop sampling\n",
      "\n",
      "cannot find: active control of study leads to improved recognition memory in children\n",
      "\n",
      "cannot find: workshop: online experiments using jspsych, psiturk, and amazon mechanical turk\n"
     ]
    }
   ],
   "source": [
    "# find the paper index for given titles\n",
    "label='gureckis'\n",
    "titles = ['Information selection in categorization with stimulus uncertainty','Beliefs about sparsity affect casual experimentation',\n",
    "         'Asking and evaluating natural language questions','The distorting effects of deciding to stop sampling',\n",
    "         'Desirable difficulties in the development of active inquiry skills',\n",
    "         'Active control of study leads to improved recognition memory in children',\n",
    "          'Deep Neural Networks Predict Category Typicality Ratings for Images',\n",
    "         'the Attentional Learning Trap and How to Avoid it',\n",
    "         'Are Biases When Making Causal Interventions Related to Biases in Belief Updating',\n",
    "         'Decisions to intervene on causal systems are adaptively selected',\n",
    "         'The value of approaching bad things',\n",
    "         'A preference for the unpredictable over the informative during self-directed learning',\n",
    "         'Workshop: Online Experiments using jsPsych, psiTurk, and Amazon Mechanical Turk']            \n",
    "[doclist,titlelist]=getlist(titles)        \n",
    "(mtops,meantpfreq)=maintopics(doclist,topic_labels)\n",
    "with open('result/lab_topic/'+label+'.txt','w') as f:\n",
    "    for k in range(len(mtops)):\n",
    "        f.write(mtops[k]+', freq={}'.format(meantpfreq[k])+'\\n')\n",
    "    f.write('\\n papers included:\\n')\n",
    "    for title in titlelist:\n",
    "        f.write(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sequential learning', 'Face and emotion perception', 'Reasoning', 'Text processing and creativity', 'Mathematical cognition', 'Decision making', 'Language: syntax', 'Causal reasoning', 'Knowledge structure', 'Developmental psychology', 'Spatial cognition and embodied cognition', 'Memory', 'Categorization', 'Language: semantics', 'Educational psychology', 'Network models for cognition and Neuroscience', 'non-verbal communication', 'Probabilistic modeling', 'Consciousness and identity', 'Visual attention']\n"
     ]
    }
   ],
   "source": [
    "print(topic_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,\n",
       "        nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan,  nan])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meantpfreq"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
