UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Effects of Competing Speech on Sentence-Word Priming: Semantic, Perceptual, and
Attentional Factors

Permalink
https://escholarship.org/uc/item/36f0t93c

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)

Authors
Moll, Katherine
Cardillo, Eileen
Utman, Jennifer

Publication Date
2001-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Effects of Competing Speech on Sentence-Word Priming:
Semantic, Perceptual, and Attentional Factors
Katherine Moll (Katherine.Moll@keble.ox.ac.uk)
Keble College, University of Oxford
Oxford OX1 3PG United Kingdom

Eileen Cardillo (Eileen.Cardillo@st-johns.ox.ac.uk)
Department of Experimental Psychology, University of Oxford
South Parks Road, Oxford OX1 3UD United Kingdom

Jennifer Aydelott Utman (Jennifer.Utman@psy.ox.ac.uk)
Department of Experimental Psychology, University of Oxford
South Parks Road, Oxford OX1 3UD United Kingdom

Abstract
This study examined the effects of a competing signal on
sentence-word priming using an auditory lexical decision
paradigm. Previous studies have suggested that the
facilitatory component of the sentential priming effect is
particularly sensitive to acoustic distortions that reduce
the perceptibility of the sentence context, whereas the
inhibitory component is more sensitive to increased
attentional demand. Three competing signal conditions
were compared: forward speech presented to a different
ear, backward speech presented to a different ear, and
forward speech presented to the same ear. The results
demonstrate that the competing signal has different
effects on priming depending upon the semantic content
of the signal and its perceptual isolability from the
sentence context.

Introduction
The influence of sentence meaning on lexical
processing has been studied extenstively in sentenceword priming studies, which have demonstrated that
sentence context has both facilitatory and inhibitory
effects on responses to single words (e.g., Stanovich &
West, 1983; Meyer & Schvaneveldt, 1976; Simpson,
Peterson, Casteel, & Burgess, 1989; Duffy, Morris, &
Henderson, 1989). In other words, reaction times for
words preceded by a highly congruent sentence context
are faster than those preceded by a neutral context,
whereas responses to words presented in an incongruent
are slowed relative to a neutral context. Further,
facilitatory and inhibitory effects tend to emerge under
different experimental conditions in both sentence-word
and word-word priming studies.
Specifically,
facilitation effects emerge at brief stimulus onset
asynchronies (SOAs), and are generally insensitive to
expectancy and processing strategies (Neely, 1991;
Utman & Bates, 1998a,b), to the extent that facilitation
is observed even when a prime stimulus is presented

briefly and then masked, such that subjects are not
consciously aware of the identity of the prime (Neely,
1991). In contrast, inhibitory effects are more
pronounced at longer SOAs, and are sensitive to factors
that affect expectancy, such as the proportion of
related/unrelated test trials in the stimulus set (Neely,
1991), and tend to be reduced in populations with
limited attentional capacity (e.g., Faust, Balota,
Duchek, Gernsbacher, & Smith, 1997). Based on this
evidence, researchers have argued that facilitation
occurs rapidly and requires little in the way of
attentional and/or processing resources, whereas
inhibition occurs later in the time course of lexical
access, and may reflect more controlled or strategic
processing (Faust & Gernsbacher, 1996; Gernsbacher,
1997; Neely, 1991; Utman & Bates, 1998a,b).
Recent studies have revealed that the facilitatory and
inhibitory components of the sentence-word priming
effect respond differently to acoustic distortion of the
semantic context. Specifically, facilitatory effects are
particularly sensitive to distortions that reduce the
intelligibility of the acoustic signal, whereas inhibitory
effects are more sensitive to distortions that reduce
processing time and/or increase attentional demand
(Utman & Bates, 1998 a,b; Utman, Dick, Prat, & Mills,
1999). For example, low-pass filtering of the sentence
context significantly reduces facilitation of congruent
targets (Utman & Bates, 1998a,b).
In contrast,
temporal compression of the context significantly
reduces inhibition of incongruent targets, but has no
effect on facilitation (Utman & Bates, 1998a,b). These
findings suggest that facilitation effects are more
dependent on bottom-up information from the acoustic
signal, whereas inhibition effects are more dependent
on attentional resources.
In the present study, we sought to investigate how
competing speech influences the facilitatory and
inhibitory components of the sentence-word priming

effect. The separate influences of perceptual and
attentional factors on facilitation and inhibition have
particular implications for competing speech. It is
generally recognised that competing speech places an
increased demand on processing resources, as the
listener must selectively attend to one signal while
suppressing another. For example, Downs & Crum
(1978) found that competing speech significantly
increased effort required for auditory learning, although
actual performance was not affected. They concluded
that competing speech increased attentional load,
thereby decreasing resources for speech processing.
More recently, Connolly, Phillips, Stewart, & Brake,
(1992) found that hearing competing speakers resulted
in a decreased ability to process semantic features of the
target speech, indicating that the increased attentional
demand of competing speech directly affects semantic
processing.
Competing speech may also be relatively more
demanding than a competing signal with no semantic
content, because the speech signal will activate
linguistic representations that are in conflict with the
attended signal. Unattended speech has been found to
be processed at a semantic level by Moray (1959) as
well as Bentin, Kutas, & Hillyard (1995). Further,
Garstecki & Mulac (1974) found that subjects had more
difficulty on an auditory discrimination task when
competing speech was played forwards than when it
was played backwards, although subjects described the
backwards speech as sounding like language. The
interference effect was attributed to the semantic
content of the forward speech. In addition, Harris,
Benedict, & Leek (1990) observed that performance on
a language-based task was more severely disrupted by
more intelligible competing speech, and that
performance was worst with only one competing
speaker, as it is easier to extract semantic information
from the competing signal of a single voice than
several.
In addition to placing increased demands on
attentional resources, competing speech may also affect
the perceptibility of the attended signal by masking the
spectral frequencies of the signal, thereby interfering
with the bottom-up encoding of phonetic contrasts.
This effect may be particularly pronounced when the
two competing signals come from a similar spatial
location, making the target signal more difficult to
isolate.
These possibilities were explored in a sentence-word
priming study, in which the sentence context was
presented in isolation or in the presence of a competing
signal. Lexical decision responses to target words were
compared when the targets were presented in
congruent, neutral, and incongruent sentence contexts.
Given the framework described above, it was possible
to predict the effect of different forms of auditory

competition on lexical decision following biasing
sentence contexts.
When the context was easily isolable from the
competing signal, we expected that the primary effect
of competing speech would be to increase attentional
demand, leaving the perceptibility of the context
relatively unaffected. As a result, we predicted that
strategic or attentional inhibitory processes would be
severely compromised, while facilitation would remain
intact. This hypothesis was tested by presenting the
semantic context and the competing speech signal to
different ears. In this case, we predicted no significant
change in reaction times to contextually congruent
targets, but a significant decrease in inhibition for
contextually incongruent words.
We expected this release from inhibition to be more
pronounced for a competing signal with semantic
content, as a meaningful signal should place relatively
greater demands on available resources for semantic
processing. To confirm this prediction, we compared
the effect of competing speech with that of a similar
competing signal with no semantic content, i.e.
backward speech. Since backward speech does not
appear to greatly tax attentional resources despite its
speech-like properties, we predicted no significant
difference in reaction times between targets preceded
by sentence contexts presented in isolation and targets
preceded by sentence contexts accompanied by
competing backward speech in a different ear.
We also considered the effect of competing speech
when presented in the same auditory channel as the
sentence contexts, by presenting forward speech in the
same ear as the semantic context. In this case, we
expected that the competing signal would have a
masking effect, disrupting the peripheral encoding of
the speech input, as well as making it more difficult to
attend only to the appropriate sentence. Consequently,
we predicted that both facilitatory and inhibitory effects
of sentence context would be affected.

Method
Participants
Thirty-six undergraduates (15 male and 21 female) at
Oxford University participated in the experiment. All
participants were right-handed, native British English
speakers. None reported any hearing impairments.

Stimuli
The stimuli consisted of 30 target words, 30 nonwords,
a neutral sentence, and 60 highly constraining sentence
contexts (30 to be paired with targets and 30 with
nonwords).

The targets were one-syllable words containing 3-5
phonemes (mean = 3.27, SD = 0.64) with a mean
Kucera-Francis print frequency of 139 (SD = 99)
(Kucera and Francis, 1967), a mean London-Lund
spoken frequency of 14 (SD = 81) (Brown, 1984), and a
mean concreteness rating of 546 (SD = 81) as specified
in the MRC Psycholinguistic Database (Coltheart,
1981). To avoid possible morphological and morphophonological constraints of determiners (a/an, the),
mass nouns (e.g., blood, dust) were excluded, and all
targets were consonant-initial. The nonword distracter
targets consisted of phonologically permissible onesyllable nonsense items, which did not differ
significantly from the targets in terms of number of
phonemes (mean = 3.33, SD = 0.61).
The sentence contexts matched with the word targets
were approximately ten syllables in duration (mean =
9.47, SD = 2.66), containing a maximum of six content
words (mean = 3.37, SD = 1.07), and a maximum of
three words related to the congruent target (mean =
1.13, SD = 0.51). There was no significant difference in
length or number of content words between sentences
paired with word targets and sentences paired with
nonword distractors.
In the congruent condition, word targets were
matched with the appropriate sentence context (e.g., He
wanted to come in, but she refused to open the... DOOR). In the incongruent condition, word targets
were matched with a sentence context appropriate to
another target in the stimulus set (e.g., He wanted to
come in, but she refused to open the... - HORSE). Pilot
analyses revealed that word targets had a mean cloze
probability of 100% (SD = 0%) when presented in the
correct context. Therefore, if a target was presented in
an incongruent context its cloze probability was 0%. A
neutral sentence context, providing no semantic cues
with regard to the target (The next item is...), was
created to serve as a neutral baseline.
Each participant received one of six randomised lists,
each containing 60 trials. Across lists, each target
appeared in each condition (congruent alone, congruent
+ competing signal, neutral alone, neutral + competing
signal, incongruent alone, and incongruent + competing
signal), with no target or biasing context appearing
more than once per list. In each of the three semantic
context conditions, half of the sentences were presented
without a competing signal (presented alone in only one
ear), or with a competing signal (presented in one ear
with the competing signal presented in the same ear or
the other ear). Thus, semantic bias (congruent, neutral,
or incongruent) and competing signal (present or
absent) served as within-subjects variables (each
participant received all six conditions). This pattern
also applied to the thirty nonwords and their sentence
contexts in each list.

The stimuli were produced by native speakers of
British English. To distinguish each target clearly from
the preceding context, the words and nonwords were
produced by a male speaker, and the sentences were
produced by a female speaker. The stimuli were
recorded onto digital audio tape in an Industrial
Acoustics 403-A audiometric chamber with a Tascam
DA-P1 Digital Audio Tape recorder and a Sennheiser
ME65/K6 supercardioid microphone and pre-amp at
gain levels between -6 and -12 db. The recorded
stimuli were then digitised via digital-to-digital
sampling onto a Macintosh G4 computer via a
Digidesign audio card using ProTools LE software at a
sampling rate of 44.1 kHz with a 16-bit quantization.
The waveform of each sentence, target, and nonword
was then edited and saved in its own mono-audio file.
All the stimulus files were converted into 16-bit 22.05
kHz stereo files in SoundEdit16 and saved in System 7
format.

Competing Speech Conditions
A passage from the book Profit Patterns (Slywotzky,
1999) was also recorded and edited on the same
equipment and under the same conditions (including
gain levels) but using a different female speaker. This
recording was then used for both the forward and
backward competing speech conditions.
In the forward competing speech condition (different
ear), copies of all the stereo sentence files were made
and segments of competing speech of the same duration
as the sentence context were excised at random and
inserted on the blank track in the stereo sound file.
In the backward competing speech condition
(different ear), the same competing speech was used as
in the forward speech condition, played backward. This
was achieved using the backwards function in
SoundEdit16. This condition was intended to produce
auditory interference with the same frequency spectrum
as speech but without semantic content.
In the forward competing speech condition (same
ear), the sentence contexts were mixed with the forward
speech and presented through a single channel. All the
original stereo files containing forward competing
speech were converted into new stereo files in which
the two tracks had been mixed together using the mix
function in SoundEdit16.
Type of competing signal (forward/different ear,
backward/different ear, and forward/same ear) served as
a between-subjects variable (each participant was
assigned to one of the three conditions).

Procedure
The test trials were presented auditorily with an interstimulus interval of 1500 ms on a Macintosh G4
computer using SuperLab software. The stimuli were

presented through Sennheiser HD 25-1 headphones via
a Sirocco VideoLogics amplifier in a sound-protected
testing room. Reaction times (RTs) and accuracy were
recorded in SuperLab from a Cedrus RB-610 response
box. Subjects were instructed to respond as quickly and
accurately as possible after hearing the target word, and
to press a green button if they heard a real English word
or a red button if they heard a nonword. Whether the
participant heard the context sentence in the left or right
ear was counterbalanced across both lists and male and
female subjects.

250

Congruent (Facilitation)
Incongruent (Inhibition)

Priming (ms)

150
50
-50

of context ear with competing signal, type of signal, or
semantic bias, and no four-way interaction, in either the
accuracy or RT analyses.
Thus, there was no
significant right ear advantage for semantic context, and
no significant difference between the pattern of
performance obtained across conditions when the
semantic context was presented to the right ear and the
pattern when the semantic context was presented to the
left ear.
A significant interaction of competing signal x
semantic bias x type of signal emerged (Subject F(2,30)
= 4.69, p < .05) emerged, although this effect failed to
generalise across items. The accuracy analyses revealed
no significant three-way interaction, nor was the pattern
of results indicative of speed-accuracy trade-offs when
compared with the RT data.
To provide a clearer picture of the patterns of
performance produced by the three types of competing
signal, separate ANOVAs were conducted on the RT
data for each competing signal condition.

-150

Forward Speech (Different Ear)

-250

Figure 1 shows the average priming effect produced by
biasing contexts presented in the presence or absence of
a competing signal in the forward speech condition
(different ear). The magnitude of the priming effect
was analysed in two-way subject and item ANOVAs
with semantic bias and competing signal as withinsubjects variables. There was a significant main effect
of semantic bias (Subject F(1,11) = 45.17, p < .001;
Item F(1,29) = 11.28, p < .01), but no significant main
effect of competing signal. A significant semantic bias
x competing signal interaction emerged for RTs
(Subject F(1,11) = 10.31, p < .01; Item F(1,29) = 4.54,
p < .05). Planned contrasts conducted within a general
linear model revealed that inhibition was significantly
reduced when the context was presented along with
competing forward speech in a different ear, relative to
when the context was presented in isolation (Subject
F(1,11) = 20.35, p < .001; Item F(1,29) = 5.41, p < .05).
However, this manipulation did not significantly affect
facilitation.

-350
-450
No Competing
Speech

Forward
Speech
(Different Ear)

Figure 1. Effect of forward competing speech (different
ear). Error bars indicate standard error.

Results
To minimise the effect of outliers in the RT data, the
median RT for correct responses was calculated for
each subject in each condition for use in the statistical
analyses (Wilcox, 1992; Ulrich & Miller, 1994). The
magnitude of the priming effect was obtained for both
RTs and accuracy by subtracting average median values
in the biasing conditions from average median values in
the neutral baseline condition for each subject. Fourway subject and item analyses of variance (ANOVAs)
comparing the magnitude of the priming effect across
conditions were conducted for accuracy (percent
correct) and RTs (milliseconds), with competing signal
(present vs. absent) and semantic bias (congruent vs.
incongruent) as within-subjects variables and type of
signal (forward/different ear vs. backward/different ear
vs. backward/same ear) and context ear (left vs. right)
as between-subjects variables. There was no main
effect of context ear in either the accuracy or RT
analyses. Further, there was no significant interaction

Backward Speech (Different Ear)
Figure 2 shows the average priming effect produced by
biasing contexts presented in the presence or absence of
a competing signal in the backward speech condition
(different ear). The magnitude of the priming effect was
analysed in two-way subject and item ANOVAs for RT
and accuracy with semantic bias and competing signal
as within-subjects variables. There was a significant
main effect of semantic bias (Subject F(1,11) = 48.77, p
< .001; Item F(1,29) = 63.62, p < .001), but no
significant main effect of competing signal. The
interaction of semantic bias and competing signal did

not approach significance in either the subject or item
analysis.
Further, planned contrasts revealed no
significant effect of this competing signal on facilitation
or inhibition.

Forward Speech (Same Ear)
Figure 3 shows the average priming effect produced
by biasing contexts presented in the presence or
absence of a competing signal in the forward speech
condition (same ear). The magnitude of the priming
effect was analysed in two-way subject and item
ANOVAs with semantic bias and competing signal as
within-subjects variables. There was a significant main
effect of semantic bias (Subject F(1,11) = 21.92, p <
.001; Item F(1,29) = 16.02, p < .001), but no significant
main effect of competing signal. A significant semantic
bias x competing signal interaction emerged (Subject
F(1,11) = 14.24, p < .01; Item F(1,29) = 4.76, p < .05).
Planned contrasts revealed that facilitation was
significantly reduced when the context was presented
along with competing forward speech in the same ear
(Subject F(1,11) = 22.40, p < .001; Item F(1,29) =
13.58, p<.001). However, this manipulation did not
significantly affect inhibition.

250

Congruent (Facilitation)
Incongruent (Inhibition)

Priming (ms)

150

Specifically, competing speech presented in a different
ear from the target signal significantly reduced the
inhibitory effect of context on incongruent targets,
without affecting the facilitatory effect of context on
congruent targets.
Thus, as predicted, increased
attentional demand disrupted only the inhibitory
component of the priming effect. However, when
backward speech was presented to a different ear, there
was no significant effect on facilitatory or inhibitory
priming. This finding suggests that it is the semantic
content of the competing signal, rather than the signal
itself, that increases attentional demand. When forward
speech was presented to the same ear, however, the
facilitatory effect of context was significantly reduced,
whereas the inhibitory effect was unaffected. Thus,
when the target signal cannot be isolated from the
competing speech, the masking effect of the competing
signal disrupts the perceptibility of the target signal,
resulting in reduced facilitation.
These results are compatible with previous claims
that the facilitatory component of the priming effect
reflects the early and automatic processing of lexicalsemantic information, whereas the inhibitory
component reflects later, more controlled or strategic
processes (Faust & Gernsbacher, 1996; Gernsbacher,
1997; Neely, 1991; Utman & Bates, 1998a,b). Future
research will examine the implications of these results
for language comprehension populations with limited
perceptual and attentional capacity, including hearingimpaired and elderly individuals.

50
250

-150

150

-250

50

-350
-450

Priming (ms)

-50

Congruent (Facilitation)
Incongruent (Inhibition)

-50

-150

No Competing
Speech

Backward
Speech
(Different Ear)

-250
-350
-450

Figure 2. Effect of backward competing speech
(different ear). Error bars indicate standard error.

Discussion
These results demonstrate that competing speech
modulates the effect of sentence context on the
processing of spoken words. Further, the pattern of
these effects depends crucially upon the semantic
content of the competing signal and the perceptual
separability of the competing and target signals.

No Competing
Speech

Forward
Speech
(Same Ear)

Figure 3. Effect of forward competing speech (same
ear). Error bars indicate standard error.

References
Bentin, S., Kutas, M., & Hillyard, S.A. (1995).
Semantic processing and memory for attended and
unattended words in dichotic listening: behavioural
and electrophysiological evidence. Journal of
Experimental Psychology: Human Perception and
Performance, 21(1), 54-67.
Brown, G.D.A. (1984). A frequency count of 190,000
words in ther London-Lund Corpus of English
Conversation. Behavioural Research Methods
Instrumentation and Computaters, 16 (6), 502-532.
Coltheart, M. (1981). The MRC Psycholinguistic
Database. Quarterly Journal of Experimental
Psychology, 33A, 497-505.
Connolly, J.F., Phillips, N.A., Stewart, S.H., & Brake,
W.G. (1992). Event-related potential sensitivity to
acoustic and semantic properties of terminal words in
sentences. Brain and Language, 43(1), 1-18.
Downs, D.W., & Crum, M.A. (1978). Processing
demands during auditory learning under degraded
listening condition. Journal of Speech and Hearing
Research, 21(4), 702-714.
Duffy, S.A., Henderson, J.M., & Morris, R.K. (1989).
Semantic facilitation of lexical access during
sentence processing. Journal of Experimental
Psychology: Learning, Memory, and Cognition,
15(5), 791-801.
Faust, M. E., Balota, D. A., Duchek, J. M.,
Gernsbacher, M. A., & Smith, S. (1997) Inhibitory
control during sentence comprehension in individuals
with dementia of the Alzheimer type. Brain and
Language, 57(2), 225-253.
Faust, M.E., & Gernsbacher, M.A. (1996). Cerebral
mechanisms for suppression of inappropriate
information during sentence comprehension. Brain
and Language, 53(2), 234-259.
Gernsbacher, M.A. (1997). Group differences in
suppression skill. Aging, Neuropsychology, &
Cognition, 4 (3), 175-184.
Garstecki, D.C., & Mulac, A. (1974). Effects of test
material and competing message on speech
discrimination. Journal of Auditory Research, 14(3),
171-177.
Gilhooly, K.J. & Logie, R.H. (1980). Age of
acquisition, imagery, concreteness, familiarity and
ambiguity measures for 1944 words. Behaviour
Research Methods and Instrumentation, 12, 395-427.
Harris, A.E., Benedict, R.H., & Leek, M.R. (1990).
Consideration of pigeon-holing and filtering as
dysfunctional attention strategies in schizophrenia.
British Journal of Clinical Psychology, 29(1), 23-35.
Kucera & Francis, W.N. (1967). Computational
Analysis of Present-Day American English.
Providence: Brown University Press.
Marslen-Wilson, W. (1989). Access and intergration:
Projecting sound onto meaning. In W. MarslenWilson, (Ed.) Lexical representation and process.
Cambridge, MA: MIT Press.

Marslen-Wilson, W. (1993). Issues of process and
representation in lexical access. In G.T.M. Altmann
& R. Shillcock (Eds.), Cognitive models of speech
processing: The second Sperlonga Meeting. Hove,
UK: Lawrence Erlbaum.
Meyer, D.E., & Schvaneveldt, R.W. (1976). Meaning,
memory structure, and mental processes. Science,
192(4234), 27-33.
Moray, N. (1959). Attention in dichotic listening:
Affective cues and the influence of instructions.
Quarterly Journal of Experimental Psychology, 11,
56-60.
Pavio, A., Yuille, J.C. and Madigan, S.A. (1968).
Concreteness, imagery and meaningfulness values for
925 words. Journal of Experimental Psychology
Monograph Supplement, 76 (3, part 2).
Poldrack, R.A., Protopapas, A., Nagarajan, S., Tallal,
P., Merzenich, M., Temple, E., & Gabrieli, J.D.E.
(1998). Auditory processing of temporally
compressed speech: an fMRI study. Presented at the
Cognitive Neuroscience Society, Fifth Annual
Meeting, San Francisco, CA.
Simpson, G.B., Peterson, R.R., Casteel, M.A., &
Burgess, C. (1989). Lexical and sentence context
effects in word recognition. Journal of Experimental
Psychology: Learning, Memory, and Cognition,
15(1), 88-97.
Slywotzky, A. (1999). Profit Patterns. Chichester: John
Wiley and Sons.
Stanovich, K.E., & West, R.F. (1983). On priming by a
sentence context. Journal of Experimental
Psychology: General, 112(1), 1-36.
Ulrich, R., & Miller, J. (1994) Effects of truncation on
reaction time analysis. Journal of Experimental
Psychology: General, 123, (1):34-80.
Utman, J. A. & Bates, E. (1998a) Effects of acoustic
degradation and semantic context on lexical access:
Implications for aphasic deficits. Brain & Language,
65 (1), 216-218.
Utman, J. A. & Bates, E. (1998b). Effects of acoustic
distortion and semantic context on lexical access
(Tech. Rep. No. 9803). La Jolla: University of
California, San Diego, Center for Research in
Language.
Utman, J. A., Dick, F., Prat, C., & Mills, D. (1999)
Effects of acoustic distortion and semantic context on
event-related potentials to spoken words. Abstract,
Cognitive Neuroscience Society, Sixth Annual
Meeting, Washington, DC.
Wilcox, R. R. (1992) Comparing the medians of
dependent groups. British Journal of Mathematical &
Statistical Psychology, 45, (1):151-162.
Wood, N., & Cowan, N. (1995). The cocktail party
phenomenon revisited: How frequent are attention
shifts to one’s name in an irrelevant auditory channel?
Journal of Experimental Psychology: Learning,
Memory, and Cognition, 21(1), 255-260.

