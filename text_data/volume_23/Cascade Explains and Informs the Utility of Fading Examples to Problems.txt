UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cascade Explains and Informs the Utility of Fading Examples to Problems
Permalink
https://escholarship.org/uc/item/24x461z8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Jones, Randolph M.
Fleischman, Eric S.
Publication Date
2001-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

   Cascade Explains and Informs the Utility of Fading Examples to Problems
                                       Randolph M. Jones (rjones@colby.edu)
                                       Eric S. Fleischman (esfleisc@colby.edu)
                                              Computer Science, Colby College
                                                 5847 Mayflower Hill Drive
                                              Waterville, ME 04901-8858 USA
                          Abstract                              students first read some domain material, then study
                                                                some completely worked out example problems, and
  Recent research demonstrates that people learn to solve       finally solve problems that have not been worked out.
  problems more effectively when presented with a series        Various studies explore why it is beneficial for students
  of faded examples and problems, than when presented
                                                                to study completely worked out examples (e.g., Chi et
  with completely worked out examples and completely
  unsolved problems alone. We propose an explanation
                                                                al., 1989; Pirolli & Anderson, 1985; Renkl, 1997,
  for this effect, based on the Cascade model. Cascade          VanLehn, 1996). The technique of fading examples
  was originally built to model the self-explanation effect,    constitutes a particular variation on such a course of
  but it also accounts for other aspects of human learning      study. When fading, the teacher first presents a
  and problem solving strategies.            A relatively       completely worked example and then follows this with
  straightforward application of Cascade, without               a series of nearly completely worked examples. Each
  alteration, also explains why fading might be beneficial.     subsequent problem removes an explanatory step,
  This explanation provides further support for Cascade as      forcing the students to solve that portion of the problem
  an accurate model of human learning and problem
                                                                themselves. This gives more guidance than a regular
  solving, and it also augments the results on fading with
  specific insight into how, and when, example fading
                                                                problem, because the student still has the guidance of
  should be effective.                                          the rest of the worked out example, but it gives less
                                                                guidance than a completely worked example.
                       Introduction                                Renkl et al. (2000) demonstrated that different
                                                                particular methods of presentation can yield different
There are a variety of research results characterizing          levels of learning. Specifically, they showed that fading
factors that facilitate the human ability to learn how to       sometimes improves learning over other orders of
solve problems.          Among recent results, Renkl,           presentation. In their initial study, they presented
Atkinson, and Maier (2000) report that people learn             subjects with a completely worked example, followed
more effectively when presented with a set of “faded”           by an example that omits the last step in the solution.
examples and study problems than they do when                   This was then followed by an example that omits the
presented with study examples alone (followed by                second to last and last steps and finally one presentation
completely unworked problems). Given this result, our           of a completely unworked problem. They compared this
interest is in identifying the cognitive mechanisms that        situation to one in which students first studied a
explain why the effect exists. Additionally, if we              completely worked example, and then solved a
understand the underlying mechanisms, they may                  completely unworked problem. The results of this
provide extra insight into precisely how to create              study confirmed that the group of subjects exposed to
effective sets of study examples and problems. We               faded examples learned more effectively than the other
have identified a potential set of explanatory                  group, even though both groups had similar pre-test
mechanisms, which are precisely the mechanisms that             performances.       A more thorough, but similar,
define Cascade, an existing model of human learning in          experiment produced comparable results.
problem solving (VanLehn, Jones, & Chi, 1991;                      Renkl et al.’s study provides us with valuable
VanLehn & Jones, 1993a). The Cascade model                      information about potential ways to design study
suggests which study and learning mechanisms                    curricula. However, the research also leaves a few
contribute to the fading effect, and provides a tool for        unanswered questions. Among these are why fading
pinpointing precisely which types of faded examples             works as well as it does. In addition, it would be useful
will be most effective.                                         to know exactly what forms of fading will be effective.
                                                                Is it always the case that examples should be faded
                    Fading Examples                             from back to front? Or are there more formal methods
A common curriculum for teaching students to solve              we can use to design faded examples? Such questions
problems in a particular domain involves having the             can, and should, be answered in part by further

experimentation. However, we believe that an existing      knowledge gaps and otherwise unproductive dead-ends
computer model of human learning in problem solving        in the attempted problem solution.
can also shed light on some of the answers. At worst,         Experiments with Cascade have focused mostly on
the model can help guide future experimentation. At        problems involving Newtonian physics, due to the fact
best, the model makes specific predictions and             that the system’s creators had access to physics problem
recommendations about how to fade examples.                protocol data from Chi et al. The experiments show
                                                           that Cascade’s interacting learning mechanisms account
                The Cascade Model                          for the basic self-explanation effect, and are able to
                                                           explain a variety of problem-solving and learning
Before presenting Cascade’s account of example             strategies on an aggregate and an individual basis
fading, we will first provide an overview of Cascade’s     (Jones & VanLehn, 1992; VanLehn et al., 1991;
cognitive mechanisms, and how they contribute to           VanLehn & Jones, 1993c).
explaining other experimental results on human                Because it plays into Cascade’s account of example
problem solving and learning. Cascade was originally       fading, it is worth describing part of the experimental
developed to explain the cognitive mechanisms              methodology used in the previous Cascade work. The
involved in the self-explanation effect (Chi et al., 1989; basic method for running experiments with Cascade
Fergusson-Hessler & de Jong, 1990; Pirolli &               involves three steps:
Bielaczyc, 1989). Simplifying a bit, the effect shows         1. Configure the system’s initial knowledge base,
that people learn more effectively by studying examples            to reflect the hypothetical initial knowledge state
when they are careful to explain to themselves as many             of a human subject.
steps of the example as they can. Students who do not         2. Force Cascade to explain exactly those pieces of
carefully explain worked out example steps do not                  a series of examples that correspond to observed
perform as well on subsequent problems.                            self-explanations in the subject’s protocol (by
   Cascade explains this effect as the interaction                 running it in “explain” mode only on those
between two basic learning mechanisms (VanLehn et                  example pieces).
al., 1991; VanLehn & Jones, 1993b). The basic                 3. Run Cascade on a series of problems, recording
prediction of Cascade is somewhat intuitive: A student             answers, errors, and learning events, to compare
learns effectively when the student is able to identify            with similar events in the encoded subject
and patch a specific gap in their knowledge. In                    protocol.
Cascade, such knowledge acquisition can occur both            This methodology makes explicit that Cascade does
while studying worked out examples and while solving       not model all the cognitive process in learning from
problems. When studying an example, Cascade must           examples and problem solving. For example, although
self-explain each worked step. When the system finds a     Cascade can explain the results of self-explanation
step it cannot explain, this signifies a knowledge gap.    episodes, it currently has no way to predict which
Because the example specifies what the answer is,          pieces of an example a student will choose to self-
Cascade can (given appropriate domain-general              explain. However, for the cognitive processes that
background knowledge) compensate for the gap by            Cascade models, it does a good job of matching
constructing an explanation for the answer. When           detailed protocol data (Jones & VanLehn, 1992). Thus,
Cascade successfully creates such an explanation, it       we will use the same basic formula to test Cascade’s
learns a new piece of knowledge that it has some faith     account of example fading.
will work in future problems.
   When solving problems, Cascade may also learn by
exposing and patching knowledge gaps. However,
                                                                 A Potential Explanation for Fading
during problem solving, the process is less constrained    Given the background details of how Cascade studies
because the system does not know the correct answer        examples and learns to solve problems, we can now
ahead of time. If the system is missing knowledge,         sketch the theory behind how Cascade ought to be able
there are potentially a number of ways Cascade could       to explain the fading effect reported by Renkl et al. It
go wrong in attempting to solve a problem. Thus, it is     should be clear that, if the Cascade model is accurate,
highly likely that the system may expose and attempt to    fading of examples can lead to improved learning only
patch a “false” knowledge gap. However, when the           if it provides the students with more opportunities to
system explains examples, it also stores search-control    patch their knowledge successfully.
knowledge, essentially remembering the subgoal                However, it is certainly a valid question whether this
structure of each example. Experiments with Cascade        is really an accurate characterization of the source of
show that this search-control knowledge can be enough      the benefit of example fading. According to Cascade, if
to guide the system into real knowledge gaps during        a student completely self-explains an example, the
problem solving. It can then successfully patch those      student would successfully encounter and patch every
gaps (VanLehn et al., 1991). Without the search-           potential knowledge gap relevant to that example.
control knowledge provided by self-explaining
                                                           Thus, there would be absolutely no benefit to first self-
examples, Cascade cannot distinguish between real

explaining the example and then combining self-                a string and sitting on an inclined plane. The example
explanation with regular problem solving on a similar          will include some lines that, implicitly or explicitly,
subsequent example. The only way example fading                involve the inclination of the normal force exerted by
could be effective (according to the Cascade model) is         the inclined plane on the block. It is not uncommon for
if it leads the student to patch a knowledge gap that it       a first-year college student never to have heard of
would not patch through example studying alone.                normal force, much less to know its inclination. If the
   As we mentioned above, Cascade can be configured            student self-explains the entire example, they will come
to emulate the self-explanation behavior of any                across these portions, reach an impasse, and be forced
individual subject (Jones & VanLehn, 1992), or to              to create some new understanding concerning normal
emulate aggregate self-explanation effects (VanLehn et         force. If the student does not bother to self-explain the
al., 1991). However, it does not explain how or why a          important parts of the example, they will happily go off
subject chooses to self-explain any particular piece of        and solve inclined plane problems without involving
an example. Although an idealized version of Cascade           normal force at all (such episodes appear in Chi et al.’s
can self-explain a worked example in its entirety, there       protocol data). Consider taking the same example, but
was not a single subject in Chi et al.’s study who was so      replacing one part of the work with the problem
thorough in their self-explanation behavior.                   statement, “What is the inclination of the normal
   Thus, the evidence and model suggest that                   force?” This certainly draws the student’s attention to
completely worked examples are never (or at least              normal force, and it explicitly requires the student to
seldom) as beneficial to students as they could be,            understand the concept, if the student is going to be
because students never (or at least seldom) completely         able to finish the problem. In contrast, a student can
self-explain the examples. This in turn may cause the          very easily read a completely worked example without
students to miss opportunities to learn from the               bothering to learn about normal force at all.
examples. However, when a student is given a faded
example, there should be some confidence that the                             Experimental Design
student will focus their attention at least on the part of     We ran Cascade on Newtonian physics problems,
the example that they are requested to solve. Thus, a          because we already had a thorough task analysis and
faded example is similar to a completely worked-out            knowledge representation for the physics domain.
example with a special highlight that says “make sure             The basic approach involves first using Cascade as a
you self-explain at least this portion of the example”.        knowledge analysis tool. We ran the system on all the
   Our hypothesis is that there are no additional              examples and problems given to Chi et al.’s subjects,
mechanisms required by Cascade to account for the              determining which examples and problems provided the
example-fading effect.         Rather, using Cascade’s         first opportunity to learn a variety of pieces of
existing mechanisms, we hypothesize that example               knowledge. In addition, we used the model to
fading forces the student to pay thorough attention to         determine which problems required the application of
particular portions of the example. Because this forcing       particular pieces of knowledge. This exercise allowed
is highly focused, the student has a good chance of            us to create a dependency chart for a number of
successfully exposing and patching a knowledge gap (if         different knowledge chunks. The chart basically tells
the faded piece of the example relies on such missing          us “if you force Cascade to learn this chunk from this
knowledge).                                                    example, then it ought to be able to solve this piece of
   When Cascade is forced to self-explain an individual        this problem.” Or in some more interesting cases, if
“faded” portion of an example, we predict that Cascade         you force Cascade to learn a particular chunk from an
will acquire new knowledge if that portion of the              example, it provides the scaffolding for the student to
example exposes a knowledge gap. In such a case,               learn another chunk in a subsequent problem.
Cascade will exhibit improved learning over normal                Given this knowledge analysis, it allows us to create
example studying if Cascade was not originally forced          experimental runs that simulate effective example
                                                               fading. The analysis tells us exactly where in each
to self-explain the same example portion. Due to the
                                                               example each knowledge chunk can be learned. Thus,
fact that we do not have such protocol data from Renkl
                                                               we can focus the system, telling it to explain exactly
et al., there is currently no empirical way to tell if this is that portion of the example that will lead to the
an accurate characterization of when Renkl et al.’s            acquisition of the desired knowledge chunk. This
subjects learned. However, it does provide a testable          corresponds to creating a focused “faded example”,
prediction. Before that experiment is run, however, we         where we allow Cascade not to self-explain most of the
should first test the Cascade model to make sure our           example, but force it to self-explain exactly the correct
predictions about its behavior during example fading           piece. We can then run Cascade on the same example,
are accurate.                                                  but with an additional faded portion, so the system can
   As an example, a first-year college physics text will       learn a second chunk from the same example. As a
often contain an example with a block suspended from           control, we can force Cascade to self-explain example

pieces that do not cause any learning, and demonstrate    to self-explain this portion of this example, it generates
that this has no beneficial effect on future problem      incorrect answers on any future problems that involve
solving. An additional control has Cascade “study” the    normal force. In fact, it usually generates the same
examples without self-explaining the lines, in which      incorrect answers as students who also fail to self-
case no useful learning occurs.                           explain that portion of that example (Jones & VanLehn,
                                                          1992). A portion of the dependency table that covers
                        Results                           this chunk appears in Table 1.
   As predicted, the experiments with Cascade were               Table 1: Dependency chart for the normal-
able to demonstrate improved learning with simulated             force chunk.
fading of examples over normal processing of
examples. The knowledge analysis showed where                       Chunk              normal-force
Cascade required, or did not require, particular pieces             Learning           Example ixa, line 2
of knowledge to solve a problem. In some cases, the                 opportunities      Example ixb, line 2
system could solve problems even without any example
studying. In other cases, the model was unable to solve             Used in            i1a, i1b, i2a, i2b,
                                                                    problems           i3a, i3b, q5
problems due to a particular lack of knowledge, even if
the system had “studied” an appropriate example
without actually self-explaining the key portion of the      In one experiment, we forced Cascade to learn about
example. With simulated fading, the system was forced     normal force by fading the normal-force portion of the
to self-explain the appropriate portions of the examples, example. Even if Cascade did not self-explain any
and then could solve more problems. Even more, the        other part of that example, it learned the normal-force
knowledge analysis was able to tell us exactly which      chunk because we forced its attention there.
pieces of certain examples should be faded in order to       In each of our experiments, we deleted one of the 12
allow the system to solve each particular problem.        target rules from Cascade initial knowledge. We then
                                                          compared Cascade’s behavior without any self-
                                                          explanation to Cascade’s behavior when it is forced to
                                                          self-explain only the portion of the examples that leads
                                                          it to learn the deleted chunk. The results show that
                                                          Cascade cannot solve all of the inclined-plane problems
                                                          without acquiring all 12 of the target pieces of
        10 kg                                             knowledge. It cannot solve any of the problems
                                                          without learning at least some of the 12 chunks
                                                          (although each of the problems only makes use of a
                                                          subset of the 12 chunks). More importantly, the results
                                                          tell us exactly which example portions will lead to
                                                          success on which problems.
                                                             In some cases, Cascade is also able to learn new
                                                          knowledge chunks during problem solving. In fact, it
                                                          cannot solve some of the problems without also
          30o                                             patching some knowledge gaps during the solution of
                                                          that problem. The experiments also show that this
        Figure 1: A typical inclined-plane problem.       learning is not always successful unless Cascade has
        What is the tension in the string?                first acquired all the knowledge it needs from the
                                                          examples. Again, perhaps most informative is that the
                                                          experiments tell us which pieces of the examples are
   The experiments we report here concentrated on a       most beneficial to fade. For example, Cascade cannot
thorough analysis of one particular sequence of           solve any problems correctly without first being forced
examples and problems in the Chi et al. study. These      to learn about normal force (as discussed above). But if
examples and problems were all variations of inclined-    Cascade is not forced (during example studying) to
plane problems (see Figure 1). Given Cascade’s initial    learn about the inclination of an inclined block’s
knowledge base, complete self-explanation of two          acceleration, it is able to learn that particular piece of
inclined-plane examples and one “weights and pulleys”     knowledge (or at least compensate for it and get the
example provides the opportunity to expose and patch      right answer) during problem solving. It can only do
12 knowledge gaps.                                        this, however, if it has learned about the existence of
   These opportunities appear in specific portions of the normal force from one of the examples (or from prior
explanation traces for the examples. For example,         experience).
Cascade can only learn about normal force from self-         In general, the experimental results confirm our
explaining the normal-force vector in the free-body       contention that graded fading of examples can map to
diagram of the inclined-plane example. If Cascade fails

improvement in Cascade, if we correspond fading with     Future experiments on fading should include detailed
the forced self-explanation of portions of each example. protocol analysis, and should look for evidence of
These results demonstrate the basic dependencies we      impasses and learning events in the faded portions of
predicted.      Thus, without any alteration to the      the examples. Such data will confirm or disprove
underlying Cascade model, it is able to provide an       Cascade’s account of fading.
explanation for the benefit of faded examples. The key      It would be prudent to note that the account of fading
assumption is that example fading serves primarily as a  presented here does not need to be the exclusive source
focus of attention, forcing the subject to study closely of improved learning. As we mentioned in describing
productive portions of each example. In the closing      Cascade, the system relies on an interaction between a
section, we discuss some implications of this            domain knowledge acquisition learning mechanism and
assumption, as well as the possibility of further
                                                         a search-control knowledge learning mechanism. The
experiments that would identify more complex
                                                         experiment and explanation reported here relies almost
interactions between fading and learning.
                                                         exclusively on the knowledge acquisition mechanism.
                                                         However, our knowledge of Cascade suggests that it
                     Conclusions                         would likely also predict at least some benefit to
We feel this work provides two basic contributions.      example fading from the learning of search control
First, it offers additional evidence that Cascade is an  knowledge.
accurate model of (at least some of) the cognitive          Even if a faded portion of an example does not force
mechanisms involved in studying examples and             an impasse and learning event, if it forces some amount
learning to solve problems. In some ways, this may       of problem solving, Cascade predicts that a student
only be of interest to the designers of Cascade.         would acquire search control knowledge for the goals
However, more generally, it allows us to have more       and subgoals addressed in the faded portion of the
faith in using Cascade as a tool both to study human     example. As with Cascade’s model of the self-
behavior, and perhaps as an aid for curriculum           explanation effect, such search-control knowledge
development. In this work, we were able to use           could benefit later learning, even if no knowledge
Cascade not only as a cognitive model, but also as a     chunks are learned during the solution of the faded
knowledge analysis tool. It allowed us to perform a      example. However, we have not yet run an experiment
focused dependency analysis that would certainly be      along those lines. For now, we will leave that form of
beneficial to an instructor creating examples and        learning from a faded example to speculation, to be
problems.                                                confirmed or rejected later.         It would be most
   However, we should note that much of the hard work    interesting to conduct such computational experiments
that made this analysis possible was performed years     in concert with similar detailed protocol studies of
ago. We have the benefit of the detailed cognitive       human subjects. The main point is that Cascade
analysis of college physics that went into the original  predicts the primary benefit of a faded example is that it
design of Cascade. To apply Cascade to any new           forces the student to process parts of the example that
domains would require a similar intensive effort.        they might otherwise ignore. Once a portion of the
However, Cascade at least provides a framework and       example is processed, all the cognitive mechanisms that
set of assumptions for creating such knowledge           Cascade posits can be brought to bear on learning.
representations.      Furthermore, it provides clear
principles for where, and how, examples and problems                     Acknowledgements
will cause a student to learn target knowledge chunks,
as well as which target knowledge chunks contribute to   This work would not have been possible without the
the solution of target test problems.                    original development of the Cascade system. That, in
   The second contribution is that we have enhanced our  turn, would not have been possible without the efforts
knowledge of how, and why, example fading proves         of Kurt VanLehn and Michelene T. H. Chi.
beneficial in some circumstances. The Cascade model
suggests that arbitrary fading of examples is not likely                        References
to be fruitful, in general. Rather, fading should be     Chi, M. T. H., Bassok, M., Lewis, M. W., Reimann, P.,
focused towards the pieces of examples that will enable     & Glaser, R. (1989).         Self-explanations: How
learning of a teacher’s target knowledge chunks.            students study and use examples in learning to solve
    Again, this conclusion depends on a key assumption      problems. Cognitive Science, 13, 145−182.
that is integral to Cascade’s candidacy as an accurate   Ferguson-Hessler, M. G. M., & de Jong, T. (1990).
cognitive model. If Cascade is accurate, it must be the     Studying physics texts: Differences in study
case that faded examples cause effective learning by        processes between good and poor solvers. Cognition
forcing the student to encounter and overcome an            and Instruction, 7, 41−54.
impasse. This is a prediction that can easily be tested.

Jones, R. M., & VanLehn, K. (1992). A fine-grained
  model of skill acquisition: Fitting Cascade to
  individual subjects. Proceedings of the Fourteenth
  Annual Conference of the Cognitive Science Society
  (pp. 873−878). Hillsdale, NJ: Lawrence Erlbaum.
Pirolli, P., & Anderson, J. R. (1985). The role of
  learning from examples in the acquisition of
  recursive programming skills. Canadian Journal of
  Psychology, 39, 240−272.
Pirolli, P., & Bielaczyc, K. (1989). Empirical analyses
  of self-explanation and transfer in learning to
  program. In G. M. Olson & E. E. Smith (Eds.),
  Proceedings of the Eleventh Annual Conference of
  the Cognitive Science Society (pp. 450−457).
  Hillsdale, NJ: Lawrence Erlbaum.
Renkl, A. (1997). Learning from worked-out examples:
  A study on individual differences. Cognitive Science,
  21, 1-29.
Renkl, A., Atkinson, R. K., & Maier, U. H. (2000).
  From studying examples to solving problems: Fading
  worked-out solution steps helps learning. In L. R.
  Gleitman & A. K. Joshi (Eds.), Proceedings of the
  Twenty-Second Annual Conference of the Cognitive
  Science Society (pp. 393−398).        Mahwah, NJ:
  Lawrence Erlbaum.
VanLehn, K. (1996). Cognitive skill acquisition.
  Annual Review of Psychology, 47, 513−539.
VanLehn, K., & Jones, R. M. (1993a). Learning by
  explaining examples to oneself: A computational
  model. In S. Chipman & A. L. Meyrowitz (Eds.),
  Foundations of knowledge acquisition: Cognitive
  models of complex learning. Boston: Kluwer
  Academic.
VanLehn, K., & Jones, R. M. (1993b). Integration of
  explanation-based learning of correctness and
  analogical search control. In S. Minton (Ed.),
  Machine learning methods for planning. Los Altos,
  CA: Morgan Kaufmann.
VanLehn, K., & Jones, R. M. (1993c). Better learners
  use analogical problem solving sparingly. Machine
  Learning: Proceedings of the Tenth International
  Conference (pp. 338−345). San Mateo, CA: Morgan
  Kaufmann.
VanLehn, K., Jones, R. M., & Chi, M. T. H. (1991). A
  model of the self-explanation effect. Journal of the
  Learning Sciences, 2, 1−59.

