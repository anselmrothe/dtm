UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Selection Procedures for Module Discovery: Exploring Evolutionary Algorithms for
cognitive Science
Permalink
https://escholarship.org/uc/item/0mm7567w
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Wiles, Janet
Schulz, Ruth
Bolland, Scott
et al.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                              Selection Procedures for Module Discovery:
                  Exploring Evolutionary Algorithms for Cognitive Science
                                           Janet Wiles (j.wiles@csee.uq.edu.au)
                                            Ruth Schulz (ruth@csee.uq.edu.au)
                                          Scott Bolland (scottb@csee.uq.edu.au)
                                       Bradley Tonkes (btonkes@csee.uq.edu.au)
                                    Jennifer Hallinan (J.Hallinan@imb.uq.edu.au)
                                The University of Queensland, Brisbane QLD 4072 Australia
                           Abstract                            algorithms need to be taken into account to select an
                                                               appropriate design.
  Evolutionary algorithms are playing an increasingly            This study is part of a wider program of research
  important role as search methods in cognitive science        whose goal is to enhance the effective use of
  domains. In this study, methodological issues in the use
                                                               evolutionary computation techniques in cognitive
  of evolutionary algorithms were investigated via
  simulations in which procedures were systematically          science domains. This program involves assessing the
  varied to modify the selection pressures on populations      performance of popular evolutionary algorithms on
  of evolving agents.          Traditional roulette wheel,     tasks of interest to cognitive scientists.
  tournament, and variations of these selection algorithms       Current areas in cognitive science that are utilizing
  were compared on the “needle-in-a-haystack” problem          EC methods include the direct modeling of evolutionary
  developed by Hinton and Nowlan in their 1987 study of        processes, such as the role of learning in evolution,
  the Baldwin effect. The task is an important one for         learning as a local search technique in a genetic
  cognitive science, as it demonstrates the power of           algorithm, the evolution of modularity, the evolution of
  learning as a local search technique in smoothing a
                                                               cooperation, and the evolution and learnability of
  fitness landscape that lacks gradient information. One
  aspect that has continued to foster interest in the problem  language (e.g., see the biennial “Evolution of
  is the observation of residual learning ability in           Language” conferences, or the Evolutionary
  simulated populations even after long periods of time.       Computation “Special Issue on EC and Cognitive
    Effective evolutionary algorithms balance their search     Science”, Wiles & Hallinan, 2001).
  effort between broad exploration of the search space and       Other domains use evolutionary algorithms for
  in-depth exploitation of promising solutions already         optimization, for example, testing theories of infant
  found. Issues discussed include the differential effects of  development; modeling populations of individuals
  rank and proportional selection, the tradeoff between        engaged in cognitive tasks; testing outcomes following
  migration of populations towards good solutions and
                                                               damage in neural network models; and exploring the
  maintenance of diversity, and the development of
  measures that illustrate how each selection algorithm        range of behaviors in a dynamic model of an artificial
  affects the search process over generations. We show         language learning task.
  that both roulette wheel and tournament algorithms can         In all of the cognitive science domains mentioned,
  be modified to appropriately balance search between          evolutionary algorithms have been tested on specific
  exploration and exploitation, and effectively eliminate      problems, but little work has been done at a
  residual learning in this problem.                           methodological level to characterize the nature of the
                                                               tasks per se, and the way in which they interact with the
   Introduction: EC and Cognitive Science                      evolutionary algorithms chosen. Many factors affect
Evolutionary computation (EC) is increasingly used in          the performance of evolutionary algorithms, including
cognitive science, both for evolving cognitive models          the choice of fitness function, representation of the
and for modeling evolutionary processes.                       genome, population size, selection technique, and
  Many algorithms use evolutionary search in one form          genetic operators.
or another. No single search algorithm will be optimal
for all tasks (a thesis colloquially known as “no free         Learning and EC
lunch”, Wolpert & Macready, 1996). In any simulation           For this study, the area of interest is the interaction of
study, characteristics of the task need to be taken into       learning and evolution known as the Baldwin effect,
account in the selection of algorithms. However, to            first formalized as a computational problem by Hinton
many cognitive science researchers it is not clear which       and Nowlan (1987). Hinton and Nowlan’s simulation of
aspects of tasks are important in the design of a search       the Baldwin effect provided insight into how learning
process, and what properties of evolutionary search            can guide evolution within a Darwinian, rather than a
                                                               Lamarkian evolutionary framework.

  In Hinton and Nowlan’s model, each individual            since learning can occur in very few guesses. Several
consisted of a bit string representing a simple neural     researchers have studied the phenomena of the residual
network with twenty connections, which must be set         question marks in the haystack problem and identified a
correctly via either learning or evolution. A network      variety of factors, including selection pressure and drift
that achieves the correct settings has a fitness dependant as significant factors in the results (Belew, 1989,
upon the time required to achieve the correct settings,    Harvey, 1993).
while all incorrect networks have equal, minimal             In a previous study, we analyzed multiple simulations
fitness. This task has a single fitness peak, which is     of the haystack problem to identify the characteristics
surrounded by a perfectly flat fitness landscape, making   of two classic selection algorithms (one fitness
it a classic needle-in-a-haystack problem (henceforth      proportional and the other rank based) with respect to
referred to as the haystack problem). The task is          exploitation and exploration of the fitness landscape
analogous to finding the components of a module in         (Wiles et al., in press). These simulations demonstrated
which no partial credit is given for partial solutions.    that fitness proportional selection finds good solutions
Issues of modular design were popularized by Dawkins       and the average fitness of a population rises quickly,
in the Blind Watchmaker (Dawkins, 1986), and are           but at high fitness levels the population drifts gradually
particularly relevant to understanding the evolution of    to homogeneity (all the alleles in one position on the
complex cognitive systems.                                 chromosome are identical for all individuals in a
  The haystack task requires exhaustive search if          population). Residual learning is frequently a result of
genetic operators alone are used (crossover and            an interaction between a pseudo-founder effect
mutation). However, if each agent modeled in the           (dominance by one early successful solution) and drift
search population is allowed to perform some local         to homogeneity at one or more of the genes. Selection
searching, then the task can be solved by a much           by rank has the opposite effect, with populations
smaller population.                                        drifting initially, until a critical mass find good
  Hinton and Nowlan used a population size set to          solutions (or until an allele becomes homogeneous in
approximately the square root of the size of the search    0s, resulting in an unsuccessful trial). Of the successful
space, with each agent able to search on average a         trials, at high fitness levels, populations converge to
portion of the search space also equal to the square root  homogeneity based on fitness, rather than drift. By
of the size of the space. The choice of population size    comparing fitness level and number of homogeneous
and local search space balanced the need for a             genes to generation number, the relative effects of drift
population to have sufficient diversity to cover the       and selection pressure can be monitored during
space, and sufficient flexibility to find the “needle”     evolution.
(maximum fitness) in almost every trial.                     The analyses in our previous study provide tools to
  Computationally, each individual is implemented as a     understand how selection pressures are working during
string of twenty “genes”, each of which may be either      trials. The two techniques produce very different
1, 0, or ? (question mark). The ? represents a learnable   characteristic performance. Fitness proportional
gene. The individual learns by guessing 0 or 1 with a      selection has initially fast fitness increases followed by
probability of 0.5. The target pattern is a string of      slow convergence, whereas rank-based selection has
twenty 1s. The number of guesses required to achieve       initially slow and erratic fitness increases followed by
this target is recorded and used to calculate the          fast convergence.
individual’s fitness. The next generation is created by      For the haystack problem, neither of these selection
repeatedly selecting two parents, to produce pairs of      methods can be considered optimal in balancing the
new individuals. Parents are probabilistically selected    exploration of possible solutions with the exploitation
proportional to the individual’s fitness relative to the   of good solutions. Fitness proportional selection has
total population fitness.                                  too strong an exploitation of early successful solutions,
  Hinton and Nowlan (1987) demonstrated that under         leading to a pseudo-founder effect, and insufficient
these conditions, the ability to learn, represented by ?s, pressure to optimize when most of the population have
was replaced by appropriate instincts, represented by      good solutions. In contrast, rank-based selection has
1s. The number of 1s rose from an initial 25% of alleles   insufficient exploitation of its good early solutions,
in the population to 50-80% after 50 generations, with     allowing drift to reduce the diversity of alleles available
the remainder of the alleles ?s. Non-target alleles,       before fitness pressures shape the search space.
represented by 0s, disappeared from the population.
  An interesting feature of Hinton and Nowlan’s            Method
simulation is the persistence of learnable genes in the    In this study, we report three sets of simulations. The
population once it has stabilized. Hinton and Nowlan       first set replicates our previous work on the classic
suggested that there is very little selective pressure in  fitness proportional (roulette wheel) and stochastic
favor of genetically specifying the last few connections,

rank-based (tournament) methods and is reproduced          1024 instead of 1000. All trials were run until the
here for comparison.                                       population converged (homogeneous in all genes).
   The second set of simulations was designed to             For each selection method, 100 trials were performed.
investigate other selection algorithms on the haystack     We report the proportion of trials that successfully
task, and also to test whether the analysis would be       eliminated all zeros from the population, the average
useful for their evaluation. For this set, we designed two number of residual question marks at the end of each
additional algorithms to combine the search                trial, and the average number of generations to
characteristics of fitness proportional and rank-based     homogeneity (see Table 1). The average fitness
selection. The first operator was designed to exhibit fast pressures in the early and late stages of trials were
fitness rises and fast convergence, and the second to      calculated as the average number of generations until
exhibit slow fitness rises and slow convergence.           the fitness rose to 50% of the maximum (Stage 1) and
   The third set of simulations directly addressed the     from the midpoint to final convergence (Stage 2). By
problems inherent in fitness proportional and rank-        defining these values, the relative selection pressures
based selection using modifications suggested in the       early and late in a run can be compared. The average
literature. To modify fitness proportional selection, the  fitness of the population when the first gene in each
expected number of offspring for any one individual        trial became homogeneous was also calculated (see
was scaled in proportion to its deviation from the mean    Table 1, column 4). This measure shows the potential
fitnesses of other individuals, which balances the         exploration available to the algorithm.
selection pressure over a trial. To modify rank-based
selection, the two fittest individuals (replacing the      Set 1: Original algorithms
offspring of one pair of parents) were copied to the next  Traditional roulette wheel (fitness proportional)
generation, thus preserving good solutions once found.     selection: The fitness of an individual is determined
In the next section, the algorithms are described, and     using equation (1) given above, and the selection
then the results summarized and presented together for     procedure for two parents is as described for Hinton and
ease of comparison.                                        Nowlan’s simulations.
                                                             Tournament (rank based) selection: In this algorithm
Simulation details for the haystack problem                two candidates are selected at random from the parent
   Hinton and Nowlan (1987) modelled the Baldwin           population, and the individual with the higher fitness
Effect using a simple genetic algorithm, with no           becomes a parent. The probability of being selected as a
mutation and a crossover value of 1.0; each pair of        parent for the next generation therefore depends on the
parents undergoes crossover once during each               relative rank of an individual within the population,
reproduction event. The next generation is created by      rather than its proportional fitness. Under tournament
repeatedly selecting two parents for each pair of new      selection, the reduced fitness differential later in
individuals. The probability of selecting an individual    evolution does not change the ranking of individuals
as a parent is proportional to its fitness divided by the  and selection pressure is maintained as long as there are
total population fitness. The fitness, f, of an individual different fitnesses within the population.
is calculated using the recorded number of guesses, g,
taken to find the target:                                  Set 2: Modified algorithms
                        ( L − 1)(G − g )                   Roulette with ranking: In order to produce a selection
               f = 1+                                 (1)
                                                           strategy that should both begin and end rapidly, ranking
                               G
where G is the maximum number of guesses allowed           was added to roulette wheel selection. This algorithm
and L is the length of the chromosome. In Hinton and       has also been called stochastic tournament (attributed to
Nowlan’s model, G = 1000, L = 20, and the population       Wetzel by Goldberg, 1989). Continued pressure after
size, N = 1000.                                            the initial fast start means that selection will force the
   We implemented Hinton and Nowlan’s model, and as        population to converge, rather than simply drifting to
in our previous work, selection of each parent was         homogeneity.
implemented using a fitness proportional algorithm.          To select each parent, two candidates are chosen
After selecting two parents, a crossover point was         using roulette wheel selection. The fittest of these two
chosen at random, and two new individuals were then        individuals becomes one parent, as in tournament
created. Parameters were set similar to Hinton and         selection. A second parent is selected in the same way.
Nowlan (1987), with initial proportions of 1, 0 and ?      The fitness-proportional selection of candidates enables
alleles set to 0.25, 0.25 and 0.50 respectively. A minor   very successful individuals to have many offspring, in a
change from their parameters was setting both              similar manner to roulette wheel selection. The addition
population size and maximum number of guesses to           of a tournament between two candidates ensures that as
                                                           fitness differentials decrease later in trials, the selection

pressures continue. The strategy is identical in all other     deviation of the fitness maintains a constant selection
ways to the others that have been used previously.             pressure in the population throughout a trial.
  Probabilistic tournament: The second variation is a            Elite tournament: The slow initial period of all trials
strategy that is designed to start slowly and end slowly.      during tournament selection is a known problem. Even
For this strategy, tournament selection was modified to        when a good solution is found, recombination of
include the proportional elements of roulette wheel            parents results in disruption of the solution and drift
strategy.                                                      (rather than selection) can lead to homogeneity in one
  For each parent, two candidates are chosen randomly          or more of the genes. Many researchers use elitism to
from the parent population. The one that will become a         preserve good solutions (first introduced in the 1970s
parent is chosen using proportional selection based on         by de Jong, according to Mitchell, 1996). In this
the fitness of these two individuals. That is, the one         strategy, one or more individuals with the highest
that is fitter will be more likely to be chosen than the       fitnesses are copied to the next generation unchanged.
less fit individual, but both still have a chance of being     In our implementation, elite tournament is identical to
a parent. The selection of candidates with equal               tournament selection, except that the individuals with
probability means that each individual, even the fittest       the two highest fitnesses are copied to the next
one, can expect on average to contribute genes to a            generation.
maximum of four offspring. The second parent is
chosen in the same way, and reproduction continues as          Results and Discussion
in the other selection strategies.                             The results from all three sets of simulations have been
                                                               collated in Table 1, which shows the performance of
Set 3: Optimized algorithms                                    each selection technique, the average number of
  Sigma Scaled Roulette: Amongst the known problems            residual question marks, and the number of generations
with roulette wheel selection is the variable selection        to convergence (i.e., all genes become homogeneous)
pressure between early and late stages in a trial and the      over 100 trials. Figures 1-3 show the selection pressures
premature convergence of populations with inadequate           during early and late stages over 10 trials. Stage 1 is the
exploration of the search space (Mitchell, 1996). A            average number of generations taken to reach a fitness
variety of modifications of roulette wheel selection           value of 10 (i.e., 50% of the maximum fitness), the
have been proposed. One such mechanism is to balance           point at which fitness increases most rapidly in this
the selection pressures evenly throughout a trial. Sigma       task. Low values (few generations) indicate high initial
scaled roulette is a renormalized version of roulette          selection pressure and high values indicate low
wheel. We use the description given by Mitchell (1986,         selection pressure. Stage 2 is the average number of
who credits an early unpublished manuscript of Forrest         generations from this level of fitness to convergence of
from 1985). The expected number of offspring, E, is            the population and indicates the selection pressure after
calculated from the mean and standard deviation of the         the initial increase in fitness. The mean population
fitnesses of the population:                                   fitness when the first allele becomes homogeneous
               f (i ) − m                                      generally indicates how good the solution will be. If an
    E = 1+                    ifσ ≠ 0                          allele is homogeneous before the population is very fit,
                  2σ                                           the solution tends to be poor.
      =1                      ifσ = 0                            The simulations in Set 1 (roulette wheel and
where f(i) is the fitness of individual i, m is the mean       tournament) provide a benchmark for the later studies.
fitness of the population and σ is the standard deviation.     Performance in these simulations was consistent with
This means that an individual with a fitness equal to the      our previous results (Wiles et al. in press). Using
mean will gain a slice of the roulette wheel proportional      roulette wheel selection, all trials eliminated zeros from
to one unit. An individual with fitness one standard           the population, and at convergence, individuals had an
deviation above the mean will (on average) gain a slice        average of 1.4 residual question marks (stdev. 0.9). The
proportional to 1.5 units, and one with fitness one            change in selection pressure is revealed by the average
standard deviation below will gain a slice proportional        number of generations spent in Stage 1 (10) versus
to 0.5 units. If the expected value for an individual is       Stage 2 (1437). See Table 1 for the means and standard
less than 0.1, then the slice is set to 0.1. The total size of deviations of all results.
the wheel is the sum of the slices of all individuals in         Using tournament selection, 85/100 trials eliminated
the population. The expected number of offspring is            all zeros. In the successful trials, individuals retained an
proportional to the size of the slice, with corrections for    average of 1.2 residual question marks, with a much
the very small slices. For each pair of parents selected,      higher variance (stdev. 2.2). The average time spent in
two offspring are produced. Using the standard                 Stages 1 and 2 is reversed in this case, with 185
                                                               generations in Stage 1 and 23 generations in Stage 2.

The interaction between Stages 1 and 2 for roulette
                                                                                                                        Set 3: Optimized Algorithms
wheel and tournament selection is clear in Figure 1.
                                                                                        Number of Generations
                                                                                                                10000
                    Set 1: Original Algorithm s                                                                  1000
                                                                                                                  100
      10000                                                                                                        10
       1000                                                                                                         1
                                                                                                                               Stage 1             Stage 2
        100
         10                                                                                                             Sigma Scaled Roulette   Elite Tournament
          1
                             S tage 1                      S tage 2               Figure 3. Time to convergence in Set 3, the optimized
                                                                                  algorithms. Both sigma scaled roulette and elite tournament
                                  R ouletteWheel             T ournament          eliminate virtually all residual question marks and are much
                                                           F                      faster than the algorithms in Sets 1 and 2 (cf. Figs 1 and 2).
igure 1. Time to convergence in Set 1, the original roulette
wheel and tournament selection algorithms. Note that the y-                         The average time spent in Stage 1 and Stage 2 was
axis is logarithmic. The algorithms show clear differences in                     also much more balanced (16 and 42 generations
behaviour, with roulette wheel faster in Stage 1, and                             respectively in sigma scaled roulette and 56 and 19
tournament faster in Stage 2.
                                                                                  generations respectively in elite tournament, see Figure
                     Set 2: Modified Algorithm s                                  3).
                                                                                    Premature convergence is a known problem for these
        10000
                                                                                  evolutionary algorithms. Tracking progress towards
         1000
                                                                                  homogeneity can therefore provide valuable
          100
                                                                                  information. The average fitness at which the first gene
                                                                                  becomes homogeneous provides a quantifiable measure
           10
                                                                                  of diversity at a significant point in a simulation. This
              1
                              S tage 1                      S tage 2
                                                                                  fitness value was recorded for each selection regime
                                                                                  (see Table 1, column 5). Higher values (maximum is
                  R oulette with R anking          P r obabilistic T our nament   20) indicate that higher levels of diversity are
                                                                                  maintained in the population. For problems in which
Figure 2. Time to convergence in Set 2, the modified                              hitchhiking genes (sub-optimal genes that are carried by
algorithms. The Stages 1 and 2 components from Set 1 (see                         pseudo-founders in a population) are liable to cause
Fig 1), have been recombined as intended, to produce one
                                                                                  problems such as in the haystack problem, this measure
algorithm in which both Stages 1 and 2 are fast (roulette with
ranking), and the other algorithm in which both Stages 1 and                      is a good indicator of potential problems with
2 are slow (probabilistic tournament). Note that neither of                       premature convergence. The tournament-based
these algorithms eliminate residual question marks.                               algorithms that have trials that do not eliminate all zeros
                                                                                  show the lowest values with average population
  In Set 2, the number of successful trials and residual                          fitnesses at the first homogeneous alleles of 9.1 and 6.0
question marks are similar to those from Set 1, but the                           for Sets 1 and 2 respectively. Values for the
time spent in Stages 1 and 2 differed markedly, as                                corresponding roulette wheel-based algorithms are
expected. Roulette wheel with ranking was fast in both                            higher (16.7 and 13.6 respectively), but are not optimal.
stages (averages 7.6 and 33 generations respectively),                            The best algorithms, those in Set 3 have the highest
and stochastic tournament was slow in both stages                                 values (19.3 for sigma-scaled roulette and 19.9 for elite
(average 249 and 1624 generations respectively, see                               tournament) indicating that none of the trials suffered
Figure 2).                                                                        from premature convergence.
  In Set 3, the original roulette and tournament selection                          The combination of relatively balanced fitness
procedures were modified to address their major known                             pressures in Stages 1 and 2, short times to convergence,
weaknesses,       and     both     showed    considerable                         and high fitness before diversity is reduced indicate that
improvement in optimization performance (as                                       both selection algorithms in Set 3 are well-adapted to
evidenced by the number of residual question marks).                              the haystack task.
All trials eliminated zeros from the population, the time
to convergence was short and very few residual                                    Conclusions
question marks remained (an average of 0.02 in sigma                              One specific conclusion from these experiments is that
scaled roulette and 0.06 in elite tournament).                                    residual learning is not an inherent aspect of the
                                                                                  Baldwin effect. Rather, it is a consequence of the way

  the fitness landscape is searched, and the application of         NY: Norton.
  selection pressures at different stages.                  The   Goldberg, D.E. (1989), Genetic algorithms in search,
  methodological studies presented in this paper are one            optimization, and machine learning, Addison-Wesley,
  way to explore such issues. Further work is needed to             Reading, MA.
  tie these results to biologically-plausible learning            Harvey, I. (1993). The puzzle of the persistent question
  scenarios, but that is beyond the scope of this study.            marks: A case study of genetic drift. Computer Science
    At a more general level, the simulations show that the          Research Paper Serial No. CSRP 278, The University
  haystack task is one for which tailoring of the algorithm         of Sussex. (Also published in S. Forrest, (Ed.)
  makes a qualitative difference to the behaviors                   Proceedings of the Fifth Int. Conf. on Genetic
  observed. Specific issues addressed in this study                 Algorithms, Morgan Kaufmann, 1993.)
  concern the characteristics of the algorithms and the           Hinton, G. E. & Nowlan, S. J. (1987). How learning can
  nature of the landscape.                                          guide evolution. Complex Systems 1: 495 –502.
    The simulations of the original algorithms illustrate         Maynard Smith, J., (1998). Evolutionary Genetics, second
  properties such as premature convergence in roulette              edition. Oxford University Press: NY.
  wheel and the dangers of early homogeneity in one or            Mitchell, M. (1996). An Introduction to Genetic
  more genes due to drift in tournament selection. With             Algorithms. MIT Press: Cambridge, MA.
  appropriate modifications, the optimized algorithms             Wiles, J. and Hallinan, J.S. (eds) IEEE Trans. on
  achieve a balance between exploration and exploitation,           Evolutionary Computation Special Issue on EC and
  resulting in convergence to good solutions. Residual              Cognitive Science. 5 (2), 2001.
  learning can be almost eliminated, and performance on           Wiles, J., Schulz, R., Hallinan, J., Bolland, S., and
  the haystack problem can be near optimal.                         Tonkes, B., Probing the Persistent Question Marks, to
    These results illustrate the need for a characterization        appear in the Proceedings of GECCO, 2001.
  of task types in cognitive science, and a characterization      Wolpert, D.H. and Macready, W.G. (1997), No Free
  of evolutionary algorithms and their performance on               Lunch Theorems for Optimization. IEEE Trans
  these tasks. Such a classification would facilitate the           Evolutionary Computation, April 1997, pp. 67-82.
  tailoring of algorithms to particular problems, and has
  the potential to significantly reduce artifacts due to
  implementation details.
                   Acknowledgements
  This project was supported by a CSEE summer grant to
  RS, and an APA to SB.
                         References
Baldwin, J. M. (1896). A new factor in evolution.
  American Naturalist 30: 441 – 451. Reproduced in
  (eds.) Belew, R.K. & Mitchell, M.,. Adaptive
  Individuals in Evolving Populations, Proceedings
  Volume XXVI, Santa Fe Institute Studies in the Sciences
  of Complexity. Addison-Wesley, Reading, MA.
Belew, R. K. (1990). Evolution, learning and culture:
  Computational metaphors for adaptive search. Complex
  Systems 4 (1), 11-49.
Dawkins, R. (1986). The Blind Watchmaker: Why the
  evidence of evolution reveals a universe without design,
                                               Table 1. Summary of Numerical Results
                                All Trials                                    Successful Populations
                                                          Residual                Generations to            Av fitness at 1st
 Selection Strategy        Proportion of trials       homogeneous ?s               homogeneity            homogeneous allele
                            that eliminated 0s    [Mean (SD) of 20 trials]         [Mean (SD)]          [Mean (SD) of 10 trials]
 Roulette Wheel                     100                1.44    (0.91)          1448.16 (734.66)             16.70    (1.68)
 Tournament                          85                1.24    (2.22)           208.67 (142.60)              9.13   (8.81)
 Roulette with Ranking              100                1.27    (1.25)            41.45     (9.58)           13.62    (3.08)
 Probabilistic Tournamt              80                2.08    (1.79)          1873.66 (1035.19)             6.01   (8.19)
 Sigma Scaled Roulette              100                0.02    (0.14)            57.93      (5.41)          19.34    (0.53)
 Elite Tournament                   100                0.06    (0.34)            75.01     (20.12)          19.90   (0.08)

