UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Simulating the Evolution of Modular Neural Systems
Permalink
https://escholarship.org/uc/item/0jb7v7q9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Author
Bullinaria, John A.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                     Simulating the Evolution of Modular Neural Systems
                                      John A. Bullinaria (j.bullinaria@physics.org)
                                   School of Computer Science, The University of Birmingham
                                             Edgbaston, Birmingham, B15 2TT, UK
                             Abstract                           how modularity can arise in connectionist systems and
                                                                hence have the potential for exhibiting double
   The human brain is undoubtedly modular, and there are        dissociation.
   numerous reasons why it might have evolved to be that
                                                                    Of particular interest to us here is the discovery that
   way. Rueckl, Cave & Kosslyn (1989) have shown how a
                                                                visual perception involves two distinct cortical pathways
   clear advantage in having a modular architecture can exist
   in neural network models of a simplified version of the
                                                                (Mishkin, Ungerleider & Macko, 1983) – one running
   “what” and “where” vision tasks. In this paper I present a   ventrally for identifying objects (“what”), and another
   series of simulations of the evolution of such neural        running dorsally for determining their spatial locations
   systems that show how the advantage c a n cause              (“where”). Some time ago, Rueckl, Cave & Kosslyn
   modularity to evolve. However, a careful analysis            (1989) considered the interesting question of why “what“
   indicates that drawing reliable conclusions from such an     and “where” should be processed by separate visual
   approach is far from straightforward.                        systems in this way. By performing explicit simulation
                                                                and analysis of a series of simplified neural network
                        Introduction                            models they were able to show that modular networks
                                                                were able to generate more efficient internal represent-
Intuitively, given the obvious potential for disruptive         ations than fully distributed networks, and that they
interference, it seems quite reasonable that two                learned more easily how to perform the two tasks. The
independent tasks will be more efficiently carried out          implication is that any process of evolution by natural
separately by two dedicated modules, rather than together       selection would result in a modular architecture and
by a homogeneous (fully distributed) system. Certainly          hence answer the question of why modularity has arisen.
there is considerable neuropsychological evidence that              Now, eleven years later, the power of modern
human brains do operate in such a modular manner (e.g.          computer technology has finally reached a level whereby
Shallice, 1988). In particular, the inference from double       the relevant explicit evolutionary simulations are now
dissociation to modularity is one of the corner stones of       feasible. Already Di Ferdinando, Calabretta & Parisi
cognitive neuropsychology, and over recent years double         (2001) have established that modularity can evolve. In
dissociation between many tasks have been established,          this paper, I present the results of further simulations and
with the implication of associated modularity.                  conclude that, whilst modularity may arise, the situation
    Some early neural network models seemed to indicate         is not quite as straight-forward as the original comput-
that fully distributed systems could also result in double      ational investigation of Rueckl et al. (1989) suggested.
dissociation (e.g. Wood, 1978) and hence cast some
doubt on the inference of modularity. Since then, the                         Learning Multiple Tasks
potential for double dissociation in connectionist systems
with and without modularity has been well studied (e.g.         Nowadays, the basic structure of simple feed-forward
Plaut, 1995; Bullinaria & Chater, 1995; Bullinaria, 1999),      neural network models is well known. We typically use
and the early connectionist double dissociations have           a three layer network of simplified neurons. The input
been seen to be merely the result of small scale artefacts.     layer activations represent the system’s input (e.g. a
Several later studies (e.g. Devlin, Gonnerman, Andersen         simplified retinal image). These activations are passed
& Seidenberg, 1998; Bullinaria, 1999) have shown how            via weighted connections to the hidden layer where each
weak double dissociation can arise as a result of resource      unit sums its inputs and passes the result through some
artifacts (e.g. Shallice, 1988, p232) in fully distributed      form of squashing function (e.g. a sigmoid) to produce its
systems, but it seems that strong double dissociation does      own activation level. Finally, these activations are
require some form of modularity, though not necessarily         passed by a second layer of weighted connections to the
in the strong (hard-wired, innate and informationally           output layer where they are again summed and squashed
encapsulated) sense of Fodor (1983). Plaut (1995), for          to produce the output activations (e.g. representations of
example, has shown that double dissociation can result          “what“ and “where”). The connection weights are
from damage to different parts of a single neural network,      typically learnt by some form of gradient descent training
and Shallice (1988, p249) lists a number of systems that        algorithm whereby the weights are iteratively adjusted so
could result in double dissociation without modularity in       that the network produces increasingly accurate outputs
the conventional sense. In this paper, I am not so much         for each input in a set of training data.
interested in showing how double dissociation can arise             In this context, the question of modularity relates to
in connectionist systems without modularity, but rather,        the connectivity between the network’s hidden and

                                       9 "what"                    9 "where"                  Output Layer
                                Nhid1                 Nhid12                 Nhid2            Hidden layer
                                                     5 × 5 retina                             Input Layer
                Figure 1: Architecture of the basic neural network model for the “what“ and “where” tasks.
output layers. During training, a hidden unit that is being       simplified systems, we have been able to observe the
used to process information for two or more output units          genetic assimilation of learnt characteristics without
is likely to receive conflicting weight update                    Lamarckian inheritance, see how appropriate innate
contributions for the weights feeding into it, with a             values for network parameters and learning rates can
consequent degradation of performance relative to a               evolve, understand how individual differences across
network that has a separate set of hidden units for each          evolved populations are constrained, and so on (e.g.
output unit (Plaut & Hinton, 1987). However, such an              Bullinaria, 2001). In the remainder of this paper I shall
extreme version of modularity with a set of hidden units          consider the evolution of modularity in neural network
(or module) for each output unit is likely to be rather           models of the “what” and “where” tasks previously
inefficient in terms of computational resources, and an           studied by Rueckl et al. (1989). The lessons we learn
efficient learning algorithm should be able to deal               here will be applicable to the learning and evolution of
appropriately with the conflicting weight update signals          modularity more generally.
anyway. Nevertheless, splitting the hidden units up into
disjoint sets corresponding to distinct output tasks, may                  The “What” and “Where” Model
be an efficient option. Indeed, it is hard to imagine how
it could be optimal to expect a single set of hidden units        To avoid the need to repeat the extensive analyses of the
to form more than one distinct internal representation.           learnt internal representations carried out by Rueckl et al.
    It is well known that, when one trains a neural               (1989), I shall study exactly the same simplified neural
network using standard gradient descent type learning             network model that they used, and explore whether the
algorithms, the processing at the hidden layer tends to           advantages of modularity they observed are sufficient to
become fully distributed – in other words, there is no            drive the evolution of modularity. I shall also follow
spontaneous emergence of modularity (e.g. Plaut, 1995;            Rueckl et al. (1989) and Jacobs et al. (1991) in
Bullinaria, 1997). However, the human brain is some-              emphasizing that the tasks we are simulating are vast
what more sophisticated than a simple feed-forward                over-simplifications of what real biological visual
network learning by gradient descent, and Jacobs, Jordan          systems have to cope with. It makes sense to use them,
& Barto (1991) have shown explicitly how it is possible           however, despite their obvious unrealistic features, since
to set up gated mixtures of expert networks that can learn        they allow us to illustrate the relevant factors with
to process two tasks in a modular fashion. Such systems           simulations we can perform on current computational
appear to have advantages in terms of learning speed,             hardware in a reasonable amount of time.
minimizing cross-talk (i.e. spatial interference),                    The task consists of mapping a simplified retinal
minimizing forgetting (i.e. temporal interference), and           image (a 5 × 5 binary matrix) to a simplified
generalization. In a further computational study, Jacobs          representation of “what” (a 9 bit binary vector with one
& Jordan (1992) have shown how a simple bias towards              bit ‘on’) and a simplified representation of “where”
short range neural connectivity can also lead to the              (another 9 bit binary vector with one bit ‘on’). I use the
learning of modular architectures.                                same 9 input patterns and 9 positions as in the previous
    In this paper, I am more interested in the evolution of       studies, giving the same 81 retinal inputs for training on.
modularity than the learning of modularity. The old               Each of the 9 patterns consist of a different set of 5 cells
Nature-Nurture debate has come a long way in recent               ‘on’ within a 3 × 3 sub-retina array, and the 9 positions
years (e.g. Elman et al., 1996), but it is still important to     correspond to the possible centers of a 3 × 3 array within
understand which characteristics are innate and which             the full 5 × 5 array.
need to be learnt during ones lifetime. Moreover, as                  Figure 1 shows the basic network that was originally
computer technology becomes more powerful, we are                 investigated by Rueckl et al. (1989). We have 25 input
able to explore these issues by increasingly realistic            units, 18 output units and 81 training examples. The
simulations. Old ideas about the interaction of learning          arrowed lines represent full connectivity, and Nhid1,
and evolution (e.g. Baldwin, 1896) can now be confirmed           Nhid12, Nhid2 specify how many hidden units in each
explicitly (e.g. Hinton & Nowlan, 1987). In suitably              block. Rueckl et al. (1989) studied in detail the fully

distributed network (Nhid1 = Nhid2 = 0) and the purely       dominant genes, learning and procreation costs, different
modular network (Nhid12 = 0). Our characterization will      inheritance and mutation details, different survival and
allow us to explore the full continuum between these         procreation criteria, more restrictive mate selection
extremes. If the maximum number of hidden units Nhid         regimes, protection for young offspring, different
= Nhid1 + Nhid12 + Nhid2 is fixed, then we need define       learning algorithms and fitness functions, and so on, but
only two innate architecture parameters Con1 = Nhid1 +       for the purposes of this paper, the simplified approach
Nhid12 and Con2 = Nhid2 + Nhid12 corresponding to the        outlined above seems adequate. A similar regime has
number of hidden units connecting to each output block.      already been employed successfully elsewhere
                                                             (Bullinaria, 2001) to study the Baldwin effect in the
                 Simulating Evolution                        evolution of adaptable control systems.
                                                                 The simulated genotypes naturally include all the
To simulate an evolutionary process for the models           innate parameters needed to specify the network details,
discussed above, we take a whole population of               namely the architecture, the learning algorithm, the
individual instantiations of each model and allow them to    learning rates, the initial connection weights, and so on.
learn, procreate and die in a manner approximating these     In real biological evolution, all these parameters will be
processes in real (living) systems. The genotype of each     free to evolve. In simulations that are designed to
individual will depend on the genotypes of its two           explore particular issues, it makes sense to fix some of
parents, and contain all the appropriate innate parameters.  these parameters to avoid the complication of un-
Then, throughout its life, the individual will learn from    foreseen interactions (and also to speed up the
its environment how best to adjust its weights to perform    simulations). In my earlier study of genetic assimilation
most effectively. Each individual will eventually die,       and the Baldwin effect (Bullinaria, 2001), for example, it
perhaps after producing a number of children.                made sense to keep the architecture fixed and to allow the
    In more realistic situations, the ability of an          initial innate connection weights and learning rates to
individual to survive or reproduce will rely on a number     evolve. Here it is more appropriate to have each
of factors which can depend in a complicated manner on       individual start with random initial connection weights
that individual’s performance over a range of related        and allow the architecture to evolve. Then, since the
tasks (food gathering, fighting, running, and so on). For    optimal learning rates will vary with the architecture, we
the purposes of our simplified model, however, we shall      must allow these to evolve along with the architecture.
consider it to be a sufficiently good approximation to           It is clearly important to fix the evolutionary
assume a simple relation between our single task fitness     parameters appropriately according to the details of the
function and the survival or procreation fitness. Whilst     problem and the speed and coarseness of the simulations.
any monotonic relation should result in similar              For example, if all individuals learn the task perfectly by
evolutionary trends, we often find that, in simplified       the end of their first year, and we only test their
simulations, the details can have a big effect on what       performance once per year, then the advantage of those
evolves and what gets lost in the noise.                     that learn in two months over those that take ten is lost
    I shall follow a more natural approach to procreation,   and our simulated evolution will not be very realistic.
mutation and survival than many evolutionary                 Since the networks were allowed to evolve their own
simulations have done in the past (e.g. in Belew &           learning rates, this had to be controlled by restricting the
Mitchell, 1996). Rather than training each member of the     number of training data presentations per year to 10 for
whole population for a fixed time and then picking the       each individual. Choosing a fixed population size of 200
fittest to breed and form the next generation, the           was a trade-off between maintaining genetic diversity
populations will contain competing learning individuals      and running the simulations reasonably quickly. The
of all ages, each with the potential for dying or            death rates were set in order to produce reasonable age
procreation at each stage. During each simulated year,       distributions. This meant about 5 deaths per year due to
each individual will learn from their own experience with    competition, and another 5 individuals over the age of 30
the environment (i.e. set of training/testing data) and have dying each year due to old age. The mutation parameters
their fitness determined. A biased random subset of the      were chosen to speed the evolution as much as possible
least fit individuals, together with a flat random subset of by maintaining genetic diversity without introducing too
the oldest individuals, will then die. These are replaced    much noise into the process. These parameter choices
by children, each having one parent chosen randomly          led to coarser simulations than one would like, but
from the fittest members of the population, who              otherwise the simulations would still be running.
randomly chooses a mate from the rest of the whole
population. Each child inherits characteristics from both             Experiment 1 – The Basic Model
parents such that each innate free parameter is chosen at
random somewhere between the values of its parents,          I began by simulating the evolution of the system as
with sufficient noise (or mutation) that there is a          stated above. For comparison purposes, this involved
reasonable possibility of the parameter falling outside the  fixing the learning algorithm to be that used by Rueckl et
range spanned by the parents.               Ultimately, the  al. (1989), namely online gradient descent with
simulations might benefit from more realistic encodings      momentum on the Sum Squared Error cost function E
of the parameters, concepts such as recessive and            (Hinton, 1989). As before, the target outputs were taken

        18                                                            10
                                                                                                                    etaIH
                                                     Nhid1
                                                                                                                    etaHO
        12
                                                                 Parameter
       Units                                                                 1
                                                                                                                    etaOB
                                                                                                                    etaHB
          6
                                                     Nhid2
                                                                                              alpha
                                                    Nhid12
          0                                                              .1
               0               800   Year   1600         2400                     0         800       Year   1600      2400
   Figure 2: Evolution of the model in Figure 1 with Sum-Squared Error cost function and Log Cost fitness function.
       18                                                               10
                                                    Nhid12
                                                                                                                    etaIH
       12                                                                     1
                                                                  Parameter
       Units
                                                                                                                    etaHO
                                                                                                                    etaOB
          6                                                                  .1
                                                                                              alpha                 etaHB
                                                     Nhid1
                                                     Nhid2
          0                                                            .01
               0               800   Year   1600         2400                     0         800       Year   1600      2400
       Figure 3: Evolution of the model in Figure 1 with Cross Entropy cost function and Log Error Count fitness.
to be 0.1 and 0.9, rather than 0 and 1, and appropriate          than expecting the mutations to carry the system from a
outputs beyond these targets were deemed errorless.              state in which there is little learning at all. Thus, in all
Experience indicates that the networks learn better if they      the following experiments, the initial population learning
have different learning rates for each of the different          rates were chosen randomly from the range [0.0. 2.0] and
connection layers, and each of the different bias sets. So,      the momentum parameters randomly from the range
to ensure that the architecture comparisons were fair in         [0.0, 1.0]. Following Rueckl et al. (1989), the initial
the sense that they were all learning at their full potential,   weights were chosen randomly within the range [0.0,0.3].
each network had five learning parameters: the learning              Figure 2 shows how the innate parameters evolved
rate ηIH for the input to hidden layer, ηHB for the hidden       when there were 18 hidden units in total (which is how
layer biases, ηHO for the hidden to output layer, and ηOB        many Rueckl et al., 1989, used). We see that the learning
for the output biases, and the momentum parameter α.             parameters soon settle down and, after a non-modular
These appear in the standard weight update equation              start, the population quickly evolves to take on a modular
                                                                 architecture with Nhid12 near zero. This is exactly what
                              ∂E
                   ∆wij (n) = −η L+ α∆wij (n − 1) .              we would expect from the Rueckl et al. (1989) study,
                             ∂wij                                right down the to optimal values for Nhid1 and Nhid2.
Each genotype thus contained two parameters to control
the network architecture, and five to control its learning                            Experiment 2 – Different Costs
rates. The Sum Squared Error cost distribution turns out
to be rather skewed across the population, so the                The results of Experiment 1 make the evolution of
individual evolutionary fitnesses were defined to be             modularity look almost inevitable. However, it would be
–log(Cost).                                                      misleading not to report on the countless simulations in
    I have found in my earlier studies (Bullinaria, 2001)        which modularity did not evolve, and which could
that the evolution can depend on the initial conditions,         equally well correspond to human evolution, with the
i.e. on the distribution of the innate parameters across the     implication that modularity in the human brain must
initial population, and that the population settles into a       originate in some other manner. Figure 3 shows what
near optimal state more quickly and reliably if it starts        can happen with one particularly reasonable alternative
with a wide distribution of initial learning rates, rather       choice for the gradient descent cost function and

                     4                                                                             4
                     3                                                                             3
   Log Error Count                                                               Log Error Count
                     2                                                                             2
                     1                                                                             1
                     0                                                                             0
                         0               12                    24          36                          0               12                  24             36
                                                     Age                                                                        Age
 Figure 4: Comparison of evolved populations with Sum Squared Error (left) and Cross Entropy (right) cost functions.
                     18                                                                            18
                     16                                                                            16
                     14                                                                            14
                     12                                                                            12
           Nhid12                                                                  Nhid12
                     10                                                                            10
                         8                                                                             8
                         6                                                                             6
                         4                                                                             4
                         2                                                                             2
                         0                                                                             0
                             −15   −10        −5         0       5   10   15                               −15   −10    −5         0       5    10   15
                                                   Nhid2 − Nhid1                                                             Nhid2 − Nhid1
                             Figure 5: Mean learning times with Sum Squared Error (left) and Cross Entropy (right) cost functions.
evolutionary fitness function, namely the standard Cross-                       barely enough hidden units to solve the task at hand, it
Entropy cost function (Hinton, 1989), and fitness defined                       behaves differently to when it has plenty of spare
by counting the total number of output units with errors                        resources (e.g. Bullinaria & Chater, 1995; Bullinaria,
above some small fixed value (0.2 say). This results in                         1997). Since 18 hidden units is near minimal for our
the evolution of a completely non-modular architecture.                         task, all of the above simulations were repeated with 36
A systematic study reveals that changing the fitness                            hidden units. This had little effect on the Cross Entropy
between –Cost, –log(Cost), 1/Cost, –ErrorCount, and                             simulations, but the results were rather variable with Sum
–log(1+ErrorCount) and has little effect on the results.                        Squared Error costs. Sometimes modularity evolved,
However, the choice of cost function is crucial. Figure 4                       sometimes it didn’t, and often mixed populations arose.
compares the learning in the evolved populations for the                        Apparently minor variations in the implementational
Sum Squared Error and Cross Entropy cost functions                              details, or even just different random number seeds,
with –log(1+ErrorCount) fitness. The non-modular                                could change the results completely.
Cross-Entropy population shows a clear superiority.                                 Figure 6 shows the mean learning times here for
    Although we should not rely on the mean learning                            comparison with those for the smaller networks in Figure
rates to predict what will evolve (since the standard                           5. We see the Cross-Entropy plot has the same non-
deviations, the worst and best cases, and so on, are also                       modular optimum as before, but the Sum-Squared Error
important), the plots in Figure 5 of the mean learning                          case is now much noisier, with further, roughly
times as a function of the architecture do show quite                           equivalent, minima appearing in the non-modular regime.
clearly where the different optimal configurations (shown                       This is presumably why the evolutionary simulation
darkest) are situated.                                                          results were so variable.
                         Experiment 3 – Larger Networks                                                                Conclusions
A final worry was that our simulations were suffering                           I have shown how it is possible to simulate the evolution
from small scale artefacts. Often when a network has                            of modularity in simple neural network models.

          35                                                                 35
          30                                                                 30
          25                                                                 25
 Nhid12                                                             Nhid12
          20                                                                 20
          15                                                                 15
          10                                                                 10
          5                                                                  5
          0                                                                  0
               −30   −20   −10      0      10   20     30                         −30   −20   −10      0      10   20   30
                              Nhid2 − Nhid1                                                      Nhid2 − Nhid1
           Figure 6: Large network learning times with Sum Squared Error (left) and Cross Entropy (right) cost functions.
However, drawing conclusions from them about the                      Seidenberg, M.S. (1998). Category-Specific Semantic
modularity in human brains is not so straightforward. If              Deficits in Focal and Widespread Brain Damage: A
the results (i.e. modularity versus non-modularity)                   Computational Account. Journal of Cognitive
depend so crucially on such non-biologically plausible                Neuroscience, 10, 77-94.
details as the learning algorithm, then it is clearly going        Di Ferdinando, A., Calabretta, R, & Parisi, D. (2001).
to be rather difficult to extrapolate from them to                    Evolving Modular Architectures for Neural Networks. In
                                                                      R.F. French & J.P. Sougne (Eds), Connectionist Models
biological systems. On one hand, we might expect that
                                                                      of Learning, Development and Evolution. Springer.
the human brain has evolved particularly efficient                 Elman, J.L., Bates, E.A., Johnson, M.H., Karmiloff-Smith,
learning algorithms, in which case we could argue that                A., Parisi, D. & Plunkett, K. (1996). Rethinking
the more efficient non-modular cross-entropy populations              Innateness: A Connectionist Perspective on
are the more realistic. On the other hand, real tasks are             Development. Cambridge, MA: MIT Press.
considerably harder than those used in our simulations,            Fodor, J.A. (1983). The Modularity of the Mind. Cambridge,
and so the modular populations might be deemed a more                 MA: MIT Press.
reliable representation of the actual relation between the         Hinton, G.E. (1989). Connectionist Learning Procedures.
human learning algorithm power and task complexity.                   Artificial Intelligence, 40, 185-234.
The general simulation approach I have presented                   Hinton, G.E. & Nowlan, S.J. (1987). How Learning Can
appears promising, but future simulations in this area will           Guide Evolution. Complex Systems, 1, 495-502.
clearly have to be much more realistic if we are to draw           Jacobs, R.A. & Jordan, M.I. (1992). Computational
reliable conclusions from them.                                       Consequences of a Bias Toward Short Connections.
                                                                      Journal of Cognitive Neuroscience, 4, 323-336.
                                                                   Jacobs, R.A., Jordan, M.I. & Barto, A.G. (1991). Task
                           References                                 Decomposition Through Competition in Modular
                                                                      Connectionist Architecture: The What and Where Vision
Baldwin, J.M. (1896). A New Factor in Evolution. The                  Tasks. Cognitive Science, 15, 219-250.
   American Naturalist, 30, 441-451.                               Mishkin, M., Ungerleider, L.G. & Macko, K.A. (1983).
Belew, R.K. & Mitchell, M. (Eds) (1996). A d a p t i v e              Object Vision and Spatial Vision: Two Cortical
   Individuals in Evolving Populations. Reading, MA:                  Pathways. Trends in Neurosciences, 6, 414-417.
   Addison-Wesley.                                                 Plaut, D.C. (1995). Double Dissociation Without
Bullinaria, J.A. (1997). Analysing the Internal                       Modularity: Evidence from Connectionist Neuro-
   Representations of Trained Neural Networks. In A.                  psychology. Journal of Clinical and Experimental
   Browne (Ed.), Neural Network Analysis, Architectures               Neuropsychology, 17, 291-321.
   and Applications, 3-26. Bristol: IOP Publishing.                Plaut, D.C. & Hinton, G.E. (1987). Learning Sets of Filters
Bullinaria, J.A. (1999). Connectionist Dissociations,                 Using Back-Propagation. Computer Speech and
   Confounding Factors and Modularity. In D. Heinke,                  Language, 2, 35-61.
   G.W. Humphreys & A. Olsen (Eds), Connectionist                  Rueckl, J.G., Cave, K.R. & Kosslyn, S.M. (1989). Why are
   Models in Cognitive Neuroscience, 52-63. Springer.                 “What” and “Where” Processed by Separate Cortical
Bullinaria, J.A. (2001). Exploring the Baldwin Effect in              Visual Systems? A Computational Investigation.
   Evolving Adaptable Control Systems. In: R.F. French &              Journal of Cognitive Neuroscience, 1, 171-186.
   J.P. Sougne (Eds), Connectionist Models of Learning,            Shallice, T. (1988). From Neuropsychology to Mental
   Development and Evolution. Springer.                               Structure. Cambridge: Cambridge University Press.
Bullinaria, J.A. & Chater N. (1995). Connectionist Model-          Wood, C.C. (1978). Variations on a Theme of Lashley:
   ling: Implications for Cognitive Neuropsychology.                  Lesion Experiments on the Neural Model of Anderson,
   Language and Cognitive Processes, 10, 227-264.                     Silverstein, Ritz & Jones. Psychological Review, 85,
Devlin, J.T., Gonnerman, L.M., Andersen, E.S. &                       582-591.

