UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Real Wordl Constraints on the Mental Lexicon: Assimilation, the Speech Lexicon and the
Information Structure of Spanish Words
Permalink
https://escholarship.org/uc/item/2rs7g5vr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Tamariz, Monica
Shillcock, Richard C.
Publication Date
2001-01-01
Peer reviewed
  eScholarship.org                             Powered by the California Digital Library
                                                                 University of California

   Real World Constraints on the Mental Lexicon: Assimilation, the Speech
                Lexicon and the Information Structure of Spanish Words
                                     Monica Tamariz (monica@ling.ed.ac.uk)
                                   Department of Linguistics, AFB, 40 George Square
                                                 Edinburgh EH8 9LL, UK
                                   Richard C. Shillcock (rcs@cogsci.ed.ac.uk)
                                  Department of Cognitive Science, 2 Buccleuch Place
                                                Edinburgh EH8 9LW, UK
                           Abstract                             (Butterworth, 1983): every word-form, including
                                                                inflected and derived forms, is explicitly listed in the
   This paper focuses on the optimum use of                     mental lexicon.
   representational space by words in speech and in the            Shillcock, Hicks, Cairns, Chater and Levy (1995)
   mental lexicon. In order to do this we draw the concept      suggest the general principle of the presentation of
   of entropy from information theory and use it to plot the
   information contour of words. We compare different
                                                                information in the brain that information should be
   representations of Spanish speech: a citation vs. a fast-    spread as evenly as possible over time or over the
   speech transcription of a speech corpus and a dictionary     representational space. Therefore, if the entropy of the
   lexicon vs. a speech lexicon. We also compare the            mental lexicon is to be maximized so that the storage
   information profiles yielded by the speech corpus vs. that   over a limited space is most efficient, then all the
   of the speech lexicon in order to contrast the               phonemes will tend to occur as evenly as possible in
   representation of words over two representational spaces:    each segment position of the word. The phonology of
   time and storage space in the brain. Finally we discuss      each individual word, because it will have an effect on
   the implications for the mental lexicon and interpret the
                                                                the entropy of the system, affects whether it is likely to
   analyses we present as evidence for a version of
   Butterworth‚Äôs (1983) Full Listing Hypothesis.                become part of the mental lexicon.
                                                                   Shillcock et al. stated that ‚Äúthe optimum contour
                       Introduction                             across the phonological information in a spoken word is
                                                                flat; fast-speech processes cause the information
In this paper we focus on the optimum use of                    contour to become more level‚Äù. We generalize this
representational space by words over time (the                  notion and propose the Levelling Effect of Realistic
sequence of sounds in speech) and over space (the               Representations (LERR): processes that make the
storage site of the mental lexicon in the brain). We draw       representation of words more accurate will flatten the
the concept of entropy from information theory and              information profiles.
propose that it can be used to study the information               In order to test this, we will use Spanish word
structure of the set of words uttered in speech and of          systems to calculate the slope and overall level of
those stored in the mental lexicon in the face of the           entropy of a citation (idealized pronunciation of the
constraints of communication and of storage,                    word in isolation) transcription and of a fast-speech
respectively, in a potentially noisy medium.                    (more realistic) transcription and of a dictionary lexicon
   We have two representational spaces for words: time          and the speech lexicon. Our prediction is that the
and storage space. Further, we will consider the                second system in each comparison should yield flatter
phonology and morphology of word systems. Our data              information contours. We also compare a representation
sets are phonetic representations of words, and recent          of words over time and another one over storage space -
research demonstrates that information on the                   a speech corpus and the speech lexicon.
probabilistic distribution of phonemes in words is used
in language processing (see Frisch, Large & Pisoni,                                     Entropy
2000 for review). Morphology is involved in this
research because we will be comparing groups of words           We will use the concept of entropy in the context of
with different inflectional and derivational features. We       information theory (Shannon, 1948), also employed in
will initially assume the Full Listing Hypothesis               speech recognition studies (e.g. Yannakoudakis &
                                                                Hutton, 1992). Entropy H is defined for a finite scheme

(i.e., a set of events such that one and only one must                                                                                                  (-m)=0.0256. The flatness of the slope refers literally to
occur in each instance, together with the probability of                                                                                                how horizontal the trendline is.
them occurring) as a reasonable measure of the
uncertainty or the information that each instance                                                                                                                                 Transcriptions
carries. E.g. the finite scheme formed by the possible                                                                                                  We have restricted ourselves to phonemic
outcomes when throwing a dice has maximum entropy:                                                                                                      representations of word and will not report data
each side of the dice has 1/6 probability of occurring                                                                                                  concerning the distributions of phonemic features. We
and it is very difficult to predict what the outcome will                                                                                               have used citation transcription rules (the idealised
be. A loaded dice, on the other hand, has an unequal                                                                                                    pronunciation of the isolated word) and fast-speech
probability distribution, and the outcome is less                                                                                                       rules (an attempt to represent normal speech more
uncertain. In this research, the possible events are the                                                                                                realistically). Both citation and fast-speech rules were
phonemes and allophones, and for each word only one                                                                                                     applied uniformly to the whole data sets. For the
of them can occur at each segment position.                                                                                                             citation transcription we used 29 phonemes including 5
   For probabilities (p1, p2, p3...pn):                                                                                                                 stressed vowels; for the fast-speech transcription we
     H = - Œ£ (pi ¬∑ log pi)                                                                                                                              used 50 phonemes and allophones:
   The relative entropy Hrel is the measured entropy                                                                                                       Citation transcription: Vowels: /a/, /e/, /i/, /o/, /u/, /√°/,
divided by the maximum entropy Hmax, which is the                                                                                                       /√©/, /√≠/, /√≥/, /√∫/. Consonants: /p/, /b/, /t/, /d/, /k/, /g/, /m/,
entropy when the probabilities of each event occurring                                                                                                  /n/, / /, / /, /r/, /f/, / /, /s/, / /, / /, /l/, / /, / /.
                                                                                                                                                              
                                                                                                                                                                                                            
are equal and the uncertainty is maximized. Using Hrel                                                                                                     Fast-speech transcription: The above plus semivowel
allows us to compare entropies from systems with a
                                                                                                                                                        /i/, /u/, voiced approximants / /, / /, / /, voiceless
different number of events (in this case, a system with
                                                                                                                                                        approximants / /, / /, / /, labiodental /m/, dental /n/ and
30 phonemes with another one with 50).
                                                                                                                                                                                       
                                                                                                                                                        /l/, palatalised /n/ and /l/, velarized /n/, /z/, dental voiced
     Hmax = log n
                                                                                                                                                        /s/, dental /s/, fricative / /, voiced / / and a silenced
     Hrel = H / Hmax
                                                                                                                                                                                                            
   Redundancy R is a measure of the constraints on the                                                                                                  consonant / . The transcription was made following
                                                                                                                                                                         
choices. When redundancy is high, the system is highly                                                                                                  the rules for consonant interactions, such as feature
organized, and more predictable, i.e. some choices are                                                                                                  assimilation, set out by Rios Mestre (1999, chapter 5).
more likely than others, as in the case of the loaded                                                                                                   Diphthongs were treated as two separate segments, as is
dice.                                                                                                                                                   usual in Spanish. Rules to mark stressed vowels were
     R = 1 - Hrel                                                                                                                                       applied to all but monosyllabic words without an
   In order to obtain the information profiles of words                                                                                                 orthographic accent. For the corpus, the whole text was
(see Figure 1), the entropy was calculated separately for                                                                                               used, including repetitions and false starts of words.
each segment position in a set of left-justified words of                                                                                               After deleting all the tags, the corpus was divided into
equal length, i.e., for the first phoneme in the words, the                                                                                             chunks separated by pauses (change of speaker, comma,
second phoneme etc.                                                                                                                                     full stop, or pause marked in the transcription). The
                                                                                                                                                        resulting text was transcribed automatically word by
                                                                                                                                
                                                                                                                                                        word (orthographic forms being replaced by phonetic
                                            +
                                                                                                                                          (     ) * +
                                                                                                                                                        forms) and then word boundary effects were introduced
                                                                                                                                                        within the chunks, following the same rules as for the
                                                                               !       "             "     #   $   %     &     '   "
                                       )
                      "
                                     (
                                                                                                                                                        intra-word transcription.
                    "
                  "
                                         ,
                                                                                                                                                                                          Data
                "
                          
                                    %
                                                                                                                                                        We used these three sets of data:
              "
                        
                                  $
                                                                                                                                                           The speech corpus: a 707,000 word Spanish speech
                                              +
                                                #       .
                                                                  *
                                                                                            $                         %
                                                                                                                                                ,
                                                                                                                                                        corpus, including repetitions and unfinished words.
                                                   / 0   1 /                                    
                                                                                                                                                        This corpus was developed by Marcos Mar√≠n of the
                                                                                                                                                        Universidad Autonoma de Madrid in 1992 and contains
                                                                                                                                                        transcribed speech from a wide range of registers and
 Figure 1: Information profile of 7-segment words from                                                                                                  fields, from everyday conversation to academic talks
       the citation transcription of the speech corpus.                                                                                                 and political speeches.
                                                                                                                                                           The dictionary lexicon: a 28,000 word Spanish word
   The information profile of the word was measured as                                                                                                  lexicon (the Spanish headword list of the Harrap
the linear trendline of these individual segment                                                                                                        Compact Spanish Dictionary, excluding abbreviations).
entropies. The slope (m) (multiplied by (-1)) of these
                                                                                                                                                        This list does not include inflections, but approximately
trendlines and the mean relative entropy for each word
length are shown in the figures below. E.g. In Figure 1,                                                                                                40% of the words are derived words (we take the
                                                                                                                                                        infinitive of verbs and the simple form of the noun as

the basic forms). This word system could represent a          corpus transcribed with citation rules and with fast-
mental lexicon where that only word stems are listed          speech rules.
and where inflected words are assembled during speech           As predicted by the LERR principle, Figure 2
production.                                                   confirms that this is also the case for Spanish. The
   The speech lexicon: the 42,000 word types found in         information profile is consistently flatter for the more
the corpus. Some 80% of these types were derived and          realistic fast-speech transcriptions in all word lengths.
inflected words. We take this word system to be the           Note that in the figure, a higher value of (‚Äìm) indicates
most realistic representation of the mental lexicon,
assuming Butterworth (1983)‚Äôs Full Listing Hypothesis,
where all the wordforms are individually represented in                            0.07
                                                                                                        Citation
the mental lexicon.                                                                0.06
                                                                                                        Fast-speech
   The dictionary lexicon and the speech lexicon share
only ~30% of the words. The remaining ~70% of the                                  0.05
                                                                      slope (-m)
words in the dictionary lexicon are mostly low                                     0.04
frequency words which do not appear in our sample of
speech. The new ~70% in the speech lexicon are verbal                              0.03
inflections (~35%), plurals and feminine inflections                               0.02
(~25%), some derived words absent from the dictionary
lexicon (~4%), unfinished or mispronounced words                                   0.01
(~4%) and proper nouns (~2%).                                                        0
   From these data, we used 4, 5, 6 and 7-segment                                         4    5        6          7
transcriptions. Words were separated by length in order                                       w ord length
to see a clearer picture of the information profiles,
especially as far as the word-ending contribution is          a steeper profile.
concerned. Considering that the information profiles of
Spanish words follows the same pattern as those of               Figure 2: Slopes of the information profiles of the
English words as seen in Shillcock et al. (1995), we can      citation and the fast-speech transcriptions applied to the
extend research in English to Spanish words. In                          corpus, over the four word lengths.
English, word recognition typically occurs before the
end of the word is uttered (Marslen-Wilson & Tyler,
1980), and information about word-length is typically
available once the nucleus is being processed                                                           Citation
(Grosjean, 1985). It is, therefore, legitimate to assume                                                Fast-speech
that recognition processes are restricting their activities                         0.8
to the subset of words in the lexicon that match the
word being uttered both in terms of initial segments and                           0.75
approximate overall length. The particular word lengths
                                                                      mean Hrel
were chosen because the structure of shorter words is
                                                                                    0.7
simpler, and the effects are less likely to be obscured by
greater variation in the internal structure of each word-
length group. These word lengths are equidistant from                              0.65
the modes of the word-length distribution of the three
data sets (lexicon: mode = 8, speech lexicon: mode = 7                              0.6
and speech corpus: modes = 2, 4 ‚Äì the mode of the                                         4    5       6           7
normal distribution is 4, but the proportion of 2-                                            w ord length
segment words is even higher, accounting for 32% of
all tokens). The sum of these four word lengths
accounts for 41% of the dictionary lexicon, 45% of the        Figure 3: Mean relative entropy of the citation and fast-
speech lexicon and 37% of the speech corpus.                     speech transcriptions over the four word lengths.
         The effect of the transcription                         Figure 3 shows how the overall entropy is lower for
                                                              the fast-speech transcription: when we introduce the
Shillcock et al. (1995) showed that fast-speech               allophones and the assimilation rules, the system
processes cause the information contour to become             becomes more redundant and thus, more predictable.
more level for English, German, Welsh, Irish and
Portuguese. Here we compare the slope of the
information profiles of 4-7 segment words from the

                        The Speech Lexicon                   possible. The results from both the slopes and the
                                                             entropy levels support the Full Listing Hypothesis that
Some current models of lexical access propose two            all wordforms, particularly inflected forms, are listed in
parallel word recognition routes, a whole-word route         the mental lexicon ‚Äì the system that includes all
and a morpheme-based one (e.g. Wurm (1997) for               wordforms (the speech lexicon) could be stored more
English; Col√©, Segui & Taft (1997) for French; Laine,        efficiently over a limited representational space.
Vainio & Hyona (1999) for Finnish). Following this
hypothesis, the full forms of words need to be stored in
the mental lexicon (cf. Butterworth, 1983). It is                                                                           Dict. Lex
relevant, then, to study the behaviour of the set of all
                                                                                                                            Speech Lex
word types, including derived and inflected words, that                                     0.8
appear in speech: the speech lexicon.
   We have seen that fast-speech transcriptions yield
                                                                  mean rel. entropy
                                                                                      0.75
flatter information contours than citation transcriptions,
so we will use the fast-speech transcriptions of the
speech lexicon, the lexicon and the corpus.                                                 0.7
   Comparing the slopes of the information profiles of
the speech lexicon on the one hand and the dictionary                                 0.65
lexicon and the corpus on the other hand will help
characterize the active mental lexicon.
                                                                                            0.6
Speech lexicon vs. dictionary lexicon                                                                     4        5        6       7
                                                                                                                  w ord length
The speech lexicon contains inflected and derived
forms, and does not contain the more obscure words
that can be found in the dictionary. The LERR principle          Figure 5: Mean relative entropy of the dictionary
that data that are closer to real speech should produce         lexicon and the speech lexicon over the four word
flatter information contours is confirmed in Figure 4,                               lengths.
where we see that the values of the slope of the
information profile of the speech lexicon are lower than     Speech lexicon vs. corpus
those of the dictionary lexicon.                             The fact that entropy and redundancy statistics obtained
                                                             from a lexicon are different from those obtained from a
                                                             corpus has been noted by Yannakoudakis and
                                                             Angelidakis (1988). Here we are comparing the word
                     0.07                  Dict. Lex
                                                             tokens with the word types in a speech corpus. Figures
                     0.06                  Speech Lex        6 and 7 show that the speech lexicon has consistently
                                                             flatter slopes and higher entropy levels than the corpus.
                     0.05
        slope (-m)
                     0.04
                     0.03                                                                                                  Corpus
                                                                                                   0.07
                     0.02                                                                                                  Speech Lex
                                                                                                   0.06
                     0.01
                                                                                                   0.05
                                                                                      slope (-m)
                       0
                                                                                                   0.04
                            4     5      6       7
                                w ord length                                                       0.03
                                                                                                   0.02
   Figure 4: Slopes of the information profiles of the                                             0.01
dictionary lexicon and the speech lexicon over the four
                     word lengths.                                                                   0
                                                                                                              4      5      6           7
   Figure 5 shows that the overall entropy level is higher                                                          word length
for the speech lexicon. This means that the speech
lexicon is less redundant than the dictionary lexicon.
The representational space is now a limited amount of           Figure 6: Slopes of the information profiles of the
memory storage space in the brain, and for maximal             corpus and the speech lexicon across the four word
efficiency redundancy has to be reduced as much as                                   lengths.

   We are comparing two representational spaces:              and the 70% of words in the dictionary lexicon not
words in the brain are constrained by a limited space         present in the speech lexicon are mainly low-frequency
and words uttered over time are constrained by the            words. The flatter profile of the speech lexicon is due to
efficiency of communication. We saw in the last section       the fact that the inflected words (which are derived
that the flat slopes and high entropy levels of the speech    from one third of the dictionary lexicon words) yield a
lexicon information profiles are best suited to enhance       flatter profile than the low-frequency dominated group.
storage efficiency. Slopes in the corpus are relatively       This suggests that inflected words are included in the
flat, but still steeper than those of the speech lexicon.     mental lexicon, and so it supports the Full Listing
This may reflect the fact that there are other factors        Hypothesis.
affecting the information contour of words in speech,            Additionally, the overall level of entropy and
such the need to encode cues to lexical segmentation
                                                              redundancy gives us an insight into the degree of
(signals that indicate where words begin and end).
                                                              complexity of a system. Highly organized systems will
These other factors may be interacting with the
optimization of communication.                                show low entropy and high redundancy. Fast-speech
                                                              rules make the system more redundant than the citation
                                                              rules. This higher predictability helps to deal with the
                                                              loss of information produced by noise and thus enhance
                                             Corpus           communication. The speech lexicon is less redundant
                                             Speech Lex       than the dictionary lexicon. Here again, the higher
                          0.8
                                                              entropy must be attributable to the fact that the
                                                              phonemes in inflected forms are more evenly
     mean rel. entropy
                         0.75                                 distributed over the phonological space than the more
                                                              obscure words present in the dictionary lexicon.
                          0.7
                                                                 The comparison between the corpus and the speech
                                                              lexicon shows the features of the representation that has
                                                              evolved to enhance communication and storage,
                         0.65                                 respectively. Both systems are ‚Äúrealistic‚Äù, and indeed
                                                              both show relatively flat information contours, but more
                          0.6                                 so the speech lexicon, suggesting that communication
                                4      5        6     7       has other constraints that interact with this measure,
                                      w ord length            such as word-boundary recognition. This is true
                                                              particularly for shorter words. The fact that the corpus
                                                              is markedly more redundant than the speech lexicon is
 Figure 7: Mean relative entropy of the corpus and the
                                                              only to be expected, since it reflects the added
     speech lexicon across the four word lengths.
                                                              complexity of different word-frequencies.
                                                                 In conclusion, we have shown that it is possible to
  The corpus presents lower entropy levels than the
                                                              use psychological theories of the mental lexicon and
speech lexicon. Speech over time is not constrained by
                                                              spoken word recognition to make testable predictions
space limitations, but rather by the need to
                                                              concerning distributional information in large samples
communicate efficiently. The higher redundancy means
                                                              of language, and, conversely, that data from
that this system reduces the uncertainty and is indeed
                                                              information distribution may potentially falsify
better for communication.
                                                              particular aspects of those psychological theories. Our
                                                              current conclusions from the analyses of Spanish favour
                                    Discussion                versions of Butterworth's original Full Listing
The present study points in the direction of the LERR         Hypothesis, in which all the wordforms encountered in
principle that the more realistic data - the fast-speech      speech are individually stored.
transcription and the speech lexicon - produce flatter
information profiles.                                                         Acknowledgments
   The flatter profile of the fast-speech transcription can
                                                              This research has benefited from the support of EPSRC
be partly explained in terms of the Markedness
                                                              studentship award nr. 00304518.
Ordering Principle (Shillcock et al., 1995) that when
consonant      interactions     introduce     phonological
ambiguity, the ambiguity introduced is always in the
                                                                                   References
direction of a less frequent phoneme. As for the              Butterworth, B. (1983). Lexical representation. In B.
comparison between lexicons, let us remember that the           Butterworth (Ed.), Development, writing and other
70% of words in the speech lexicon that do not appear           language processes, Vol. 2, London: Academic Press.
in the dictionary lexicon are mostly inflected words,

Col√©, P., Segui, J., & Taft, M. (1997, Words and
  morphemes as units for lexical access, Journal of
  memory and language, 37 (3), 312-330.
Frisch, S. A., Large, N. R. & Pisoni, D. B. (2000).
  Perception of wordlikeness: Effects of segment
  probability and length on the processing of nonwords,
  Journal of Memory and Language, 42 (3), 481-496.
Grosjean, F. (1985). The recognition of words after
  their acoustic offset: Evidence and implications.
  Perception and Psychophysics, 38, 299-310.
Laine M., Vainio, S., & Hyona, J. (1999). Lexical
  access routes to nouns in a morphologically rich
  language, Journal of memory and language, 40 (1),
  109-135.
Marcos Marin, F. (1992). Corpus oral de referencia del
  espa√±ol, Madrid: UAM.
Marslen-Wilson, W. D., & Tyler, L. K. (1980). The
  temporal structure of spoken language understanding,
  Cognition, 8, 1-71.
R√≠os Mestre, A. (1999). La transcripci√≥n fon√©tica
  autom√°tica del diccionario electr√≥nico de formas
  simples flexivas del espa√±ol: estudio fonol√≥gico en el
  l√©xico, Estudios de Ling√º√≠stica Espa√±ola, 4.
Shannon, C. E. (1948). A mathematical theory of
  communication, Bell System Technology Journal, 27
  (July), 379-423 and (October), 623-656.
Shillcock, R.C., Hicks, J., Cairns, P., Chater, N., &
  Levy, J. P. (1995). Phonological reduction,
  assimilation, intra-word information structure, and
  the evolution of the lexicon of English: Why fast
  speech isn‚Äôt confusing. Proceedings of the
  Seventeenth Annual Conference of the Cognitive
  Science Society (pp. 233-238), Hillsdale, NJ:
  Lawrence Erlbaum Associates.
Yannakoudakis, E. J. & Hutton, P. J. (1992). An
  assessment of N-phoneme statistics in phoneme
  guessing algorithms which aim to incorporate
  phonotactic constraints, Speech communcation, 11,
  581-602.
Yannakoudakis, E. J. & Angelidakis, G. (1988). An
  insight into the entropy and redundancy of the
  English dictionary, IEEE Transactions on Pattern
  Analysis and Machine Intelligence, 10 (6), 960-970.
Wurm L. H. (1997). Auditory processing of prefixed
  English     words     is    both    continuous    and
  decompositional, Journal of memory and language,
  37 (3), 438-461.

