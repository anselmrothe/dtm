UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Using Distributional Measures to Model Typicality in Categorization
Permalink
https://escholarship.org/uc/item/0kq3h2sm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Connell, Louise
Ramscar, Michael
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                               Powered by the California Digital Library
                                                                  University of California

         Using Distributional Measures to Model Typicality in Categorization
                                          Louise Connell (louise.connell@ucd.ie)
                                  Department of Computer Science, University College Dublin,
                                                      Belfield, Dublin 4, Ireland
                                      Michael Ramscar (michael@cogsci.ed.ac.uk)
                                     School of Cognitive Science, University of Edinburgh,
                                       2 Buccleuch Place, Edinburgh, EH8 9LW, Scotland.
                             Abstract                                   In much of this work, it is assumed that linguistic
                                                                     behavior (such as naming features associated with a
   Typicality effects are ordinarily tied to concepts and            concept, c.f. Rosch, 1973) is determined by, and
   conceptualization. The underlying assumption in much              reflective of, underlying concepts that are grounded in
   of categorization research is that effects such as
                                                                     perceptual experience of objects and artifacts
   typicality are reflective of stored conceptual structure.
   This paper questions this assumption by simulating
                                                                     themselves. Here, we wish to consider the idea that
   typicality effects by the use of a co-occurrence model of         language itself is part of the environment that
   language, Latent Semantic Analysis (LSA). Despite                 determines conceptual behavior. A growing body of
   being a statistical tool based on simple word co-                 research indicates that distributional information may
   occurrence, LSA successfully simulates subject data               play a powerful role in many aspects of human
   relating to typicality effects and the effects of context on      cognition. In particular, it has been proposed that
   categories. Moreover, it does so without any explicit             people can exploit statistical regularities in language to
   coding of categories or semantic features. The model is           accomplish a range of conceptual and perceptual
   then used to successfully predict participants’
                                                                     learning tasks. Saffran, Aslin & Newport (1996; see
   judgements of typicality in context. In the light of the
   findings reported here, we question the traditional
                                                                     also Saffran, Newport, & Aslin; 1996) have
   interpretation of typicality data: are these data reflective      demonstrated that infants and adults are sensitive to
   of underlying structure in people’s concepts, or are they         simple conditional probability statistics, suggesting one
   reflective of the distributional properties of the linguistic     way in which the ability to segment the speech stream
   environments in which they find themselves.                       into words may be realized. Redington, Chater & Finch
                                                                     (1998) suggest that distributional information may
                                                                     contribute to the acquisition of syntactic knowledge by
                        Introduction                                 children. MacDonald & Ramscar (this volume) have
The world contains a myriad of objects and events that               shown how information derived from a 100 million
an intelligent observer could seemingly infinitely                   word corpus can be used to manipulate subjects’
partition and generalise from. So how it is that humans              contextual experience with marginally familiar and
can adopt a particular partitioning in the mass of data              nonce words, demonstrating that similarity judgements
that confronts them? How do they pick out regularities               involving these words are affected by the distributional
in the stuff of experience and index them using words?               properties of the contexts in which they were read.
What are these regularities? And how do humans                          The objective of this paper is to examine the extent to
recognise, communicate, learn and reason with them?                  which co-occurrence techniques can model human
These questions are central to cognitive science, and                categorization data: What is the relationship between
traditionally, their close linkage has tempted researchers           typicality judgements and distributional information?
to seek a unified answer to them: categorization – the               Indeed, are the responses people provide in typicality
act of grouping things in the world – has been                       experiments more reflective of the distributional
commonly linked to the representation of concepts1,                  properties of the linguistic environments in which they
with many researchers assuming that a theory of one                  find themselves than they are of the underlying
provides for the other (Armstrong, Gleitman &                        structure of people's concepts?
Gleitman, 1983; Keil, 1987; Lakoff, 1987).
                                                                                       Typicality Effects
1                                                                    The first empirical evidence of typicality effects was
   In the experiments reported, we follow the common
assumption (Medin & Smith, 1984; Komatsu, 1992) that                 provided by Rosch (1973), who found participants
categories are classes, concepts are their mental                    judged some category members as more (proto)typical
representations and that an instance is a specific example of a      than others. Rosch (1973) gave subjects a category
category member.                                                     name such as fruit with a list of members such as apple,

fig, olive, plum, pineapple, strawberry, etc. and asked     (although describing these underlying structures has
subjects to rate on a 7-point scale how good an example     proven elusive, see Komatsu, 1992; Ramscar & Hahn,
each member was of its category. The results showed a       in submission). However, distributional theories suggest
clear trend of category gradedness – apples are             that information about substitutability and word
consistently judged a typical fruit, while olives are       similarity can instead be gleaned from the structure of
atypical. Further evidence underlines the pervasiveness     the linguistic environment. Such information is readily
of typicality (or “goodness of example”) and its ability    – and objectively - obtainable for the purposes of model
to predict a variety of results. Typicality was found to    building and hypothesis testing.
predict reaction times in sentence verification tasks
(Rosch, 1973; McCloskey & Glucksberg, 1979) and                   Experiment 1 – Canonical Typicality
order of item output when subjects are asked to name        The purpose of this experiment is to examine whether
members of a category (Barsalou & Sewell, 1985).            data from typicality studies (Rosch, 1973; Armstrong,
   Roth & Shoben (1983) showed that the context a           Gleitman & Gleitman, 1983; Malt & Smith, 1984) can
concept appears in affects the typicality of its instances. be modeled using a distributional measure. Specifically,
A typical bird in the context-free sense may be a robin,    it was predicted that subject typicality scores from
but if it appears in the context “The bird walked across    previous studies would correlate with a distributional
the barnyard”, then chicken would instead be typical.       measure (LSA; Landauer & Dumais, 1997) when
Subject reaction times to sentence verification tasks are   comparing similarity scores for category members
faster for the contextually appropriate item (chicken)      against their superordinate category name.
than the normally typical, but contextually
inappropriate item (robin). Roth and Shoben found that      Materials
measures of typicality determined in isolation no longer
                                                            Each set of typicality data was divided up according to
play a predictive role once context has been introduced.
                                                            the taxonomy used in the original study: Set A was
Typicality, Substitutability and LSA                        taken from Rosch (1973), B from Armstrong, Gleitman
                                                            & Gleitman (1983), and C from Malt & Smith (1984).
According to Rosch (1978): “The meaning of words is            Within these three data sets, 18 sets of typicality
intimately tied to their use in sentences. Prototypicality  ratings existed, across 12 separate categories due to
ratings for members of superordinate categories predict     overlap between categories used in Sets A, B and C.
the extent to which the member term is substitutable for
the superordinate word in sentences.”                       Procedure
   This notion of contextual substitutability has a
                                                            For each category in each data set, all items were
parallel in distributional approaches to word meanings
                                                            compared in LSA to the superordinate category name
(e.g. Landauer & Dumais, 1997; Burgess & Lund,
                                                            and the similarity scores noted. All scores were
1997). In a distributional model of word meaning such
                                                            calculated in LSA using a corpus whose texts are
as Latent Semantic Analysis (LSA), the corpus analysis
                                                            thought to be representative of reading materials
calculates a contextual distribution for each lexeme
                                                            experienced by students up to first year in college3.
encountered by counting the frequency with which it
                                                               The LSA scores were then scaled from the given [-1,
co-occurs2 with every other word in the corpus. The
                                                            +1] range to fit the standard 7-point typicality scale
contextual distribution of a word can then be
                                                            used in the subject studies, where a score of 1
summarized by a vector – or point in high-dimensional
                                                            represents the most typical rating. Malt & Smith used
space – that shows the frequency with which it is
                                                            the 7-point scale in reverse order (where 7 represented
associated with the other lexemes in the corpora. In this
                                                            most typical) so these scores were inverted. LSA score
way, two words that tend to occur in similar linguistic
                                                            scaling was done by aligning the highest of the LSA
contexts – i.e. are distributionally similar – will be
                                                            scores for each category with the most typical rank on
positioned closer together in semantic space than two
                                                            the 7-point scale4; i.e. the highest LSA score for a
words which do not share as much distributional
                                                            category would be matched to 1, and the other scores
information. By using the proximity of points in
                                                            falling proportionately towards 7.
semantic space as a measure of their contextual
substitutability, LSA offers a tidy metric of
distributional similarity.
   Rosch (1973; 1978) held that such substitutability       3
arises as a result of similarities between the underlying     Using General Reading up to 1st Year College semantic
                                                            space, with term-to-term comparison and maximum factors.
structures of the concepts representing the words           4
                                                              The exact formula used is as follows: Where X is the LSA
                                                            score one wishes to scale and M is the maximum LSA score
2
  How words are used together within a particular context,  for this category set:
such as a paragraph or moving-window.                       Scaled LSA score = M – (M – 1) / (M * X).

Results                                                       correlation coefficients may be lower, they are more
Spearman’s rank correlation (rho) was used to compare         significant. Thus, it seems reasonable to consider as
scaled LSA and subject scores. The global rank                marginally significant those results where p<0.10, given
correlation between the subject ratings and LSA scores        the constraints of the data.
across Sets A, B and C (193 items) was rho=0.515 (2-
tailed p<0.001). Many of the categories that failed to        Discussion
produce greatly significant correlations correlated           In this experiment, LSA similarity scores correlated
significantly with the removal of one member, due to it       significantly with subject typicality ratings. Without
having an extremely high or low LSA score (usually            any hand-coding of category membership or salient
because of its low frequency of occurrence in the             features, LSA’s semantic space successfully modeled
corpus). See Table 1 for full LSA results. Also, Set A /      gradients of typicality within categories. Significant
Set B correlations for their 4 shared categories of sport,    global correlation existed between LSA-to-subject
fruit, vehicle and vegetable were rho=1.0 (p<0.01),           typicality ratings at rho=0.515 (p<0.001). Items that
rho=0.943 (p<0.05), rho=0.886 (p<0.05) and rho=0.886          subjects judged typical correlated with those that LSA
(p<0.05) respectively.                                        scored highly in similarity with the category name. The
                                                              same correlation is true of items that subjects judged to
   Table 1: Rank correlation coefficients rho (with levels of be highly atypical members of their category – these
        significance p) between LSA and subject scores        received low similarity scores in LSA. The more
                                                              closely the ranking of LSA scores mirrored that of the
Set    Category      Initial category    Adjusted category    subjects’, the higher the correlation, and the closer the
A      sport         1.000 (p<0.01)                           level of significance dropped to zero.
       fruit         0.886 (p<0.05)                              Regarding the categories themselves, there were
       vehicle       0.829 (p<0.10)      1.000 (p<0.05)       cases where LSA modeled a category’s typicality
       crime         0.814 (p<0.10)      0.975 (p< (0.10)     gradient successfully in one data set but not in another.
       bird          0.714 (p<0.10)      0.900 (p<0.10)       An example of this is the category fruit, which was
       science       0.414 (-)           0.675 (p<0.10)       modeled with rank correlation of rho=0.886 (p<0.05) in
       vegetable     0.371 (-)                                Set A and 0.748 (p<0.05) in Set B (adjusted), but failed
B      sport         0.811 (p<0.01)                           to correlate significantly at all in Set C.
                                                                 Only one of the 5 category types in Set B came from
       vehicle       0.788 (p<0.01)
                                                              what Armstrong, Gleitman & Gleitman (1983) term as
       vegetable     0.580 (p<0.10)      0.745 (p<0.05)
                                                              “well-defined” categories – the category female.
       fruit         0.539 (p<0.10)      0.748 (p<0.05)
                                                              Despite Armstrong, Gleitman and Gleitman’s
       female        0.346 (-)           0.558 (p<0.10)       designation of this category as well-defined, it seems
C      trees         0.705 (p<0.01)                           reasonable to regard typicality in female as one would
       clothing      0.521 (p<0.05)      0.676 (p<0.05)       any other category examined in this experiment – a
       furniture     0.466 (p<0.05)      0.609 (p<0.01)       measure of contextual substitutability. In this case, the
       bird          0.375 (-)           0.640 (p<0.05)       contextual substitutability shown by LSA similarity
       fruit         0.157 (-)                                scores failed to convincingly model the typicality scores
       flowers       -0.499 (-)                               for female, only reaching correlation of 0.558 (p<0.10)
    Values (-) represent insignificant correlation of p>0.10  when the category was adjusted. We propose the
                                                              reason for this is that typicality ratings for a category
   It must be noted that the same rank correlation            such as female are subject to social conditioning in a
coefficient results in differing levels of significance       way other categories such as fruit or sport are not. For
within Table 1. This is due to different sizes in             example, the item that LSA scored highest against
categories’ data sets (from 5 to 20), where the same          female was housewife, which was next followed by
score could be significant for one size set and not           chairwoman. Although this simply reflects the general
another; e.g. perfect rank correlation of 1.000 is            contextual substitutability of the words across all of
significant to p<0.01 with N=10, but only to p<0.05           LSA’s corpora, it also reflects a ranking that may not be
when N=5. This high sensitivity to the degrees of             found within a social group. It would be inconsistent
freedom from small-sized data sets is why one outlying        for a group of subjects to rate housewife as the most
item was capable of skewing the rank correlation. With        typical female (a stereotyped sexist attitude), while
small data sets such as these, the power of the tests         rating chairwoman (a stereotyped politically correct
being used is restricted and they are overly sensitive to     attitude) closely behind. Thus LSA may have failed to
individual data points. Larger category data sets are to      convincingly model this category’s typicality gradient
be found in Sets B and C, where although the rank             because it reflects an average of social attitudes across

its corpora, and not just those of one particular group –   of 1500 near neighbors of the context sentence6. This
1980’s Philadelphia undergraduates.                         list corresponds to the 1500 points in LSA’s high-
   One of the most interesting findings is that in 3 out of dimensional space that are closest to the context
4 cases of shared categories between Set A and Set B,       sentence, and would receive the highest similarity
LSA provided as good a fit to Set A typicality ratings as   scores.
Set B did. When the item skis was removed from Set             Second, inappropriate items were found by compiling
A’s vehicle category, LSA’s correlation bettered that of    a large list of category members and selecting the 5-6 of
Set B (with the sole exception of the category              those that had the lowest (preferably negative) LSA
vegetable). This serves to make an important point and      similarity score against the context sentence.
put the data in Table 1 into perspective: it suggests that     These materials were split into two sections. Each
the difference between subject groups in Rosch’s            section consisted of 7 context sets, now with 5 items,
(1973) and Armstrong, Gleitman & Gleitman’s (1983)          selected so that there were at least 2 of both appropriate
experiments is comparable to the difference between         and inappropriate items in the set and so that each
LSA and human subjects. In other words, a co-               category member appeared only once per section.
occurrence model like LSA is as successful at matching      Subjects received one section apiece, with presentation
the typicality gradients of a subject group as another      of section 1 or 2 alternated between subjects. All 35
subject group would be.                                     items within each section were presented in random
                                                            order, resampled for each subject.
     Experiment 2 – Contextual Typicality
   The first experiment indicates that a co-occurrence      Participants
model such as LSA can be used to model typicality           19 native speakers of English took part in this
judgements in canonical (context-free) categories.          experiment. All were volunteers who participated by
However, categorization is also subject to linguistic       completing an electronic questionnaire.
context, whose capacity to skew typicality has been
demonstrated by Roth & Shoben (1983).                       Procedure
   Having examined canonical typicality in Experiment       LSA Procedure The scores were calculated in LSA by
1, the purpose of Experiment 2 was to test if LSA could     comparing the context sentence to each item in the list,
be used to predict subject responses for typicality in      using the same corpus as for Experiment 17.
context. The hypothesis was that LSA could predict             The LSA scores were then scaled from the given [-1,
human judgements of exemplar appropriateness                +1] range to fit the standard 7-point typicality scale
(typicality) for given context sentences. LSA similarity    used in the subject studies. Due to the presence of very
scores for each context sentence5 and respective            low negative LSA scores, this was done by aligning the
category members were used to form significantly            extremes of the LSA scores for each category with the
different clusters of appropriate (high scores / high       opposite extremes of the 7-point scale; i.e. the highest
similarity) and inappropriate (low scores / low             LSA score for a category would be matched to 1, the
similarity) items. It was predicted that subject ratings    lowest score to 7, and the intermediate scores falling
of typicality in context for these items would fall into    proportionately in between8.
the same clusters, and that these clusters would also be
significantly different.                                    Human Procedure Participants read instructions that
                                                            explained typicality and the 7-point scale as per Rosch
Materials                                                   (1973) and Armstrong, Gleitman & Gleitman (1983).
Materials consisted of 7 context sets, each of which        They were then given this example of a context
consisted of a context sentence and 10 possible             sentence (not used in experiment) “The girl played the
members of the category. 3 of the context sentences         GUITAR while the others sang around the campfire”,
were taken from Roth & Shoben (1983), the other 4
created for this experiment. Category members were
                                                            6
chosen in two ways, to form the appropriate and               The sentence was processed as a pseudodoc using maximum
inappropriate clusters for the context.                     factors in the same semantic space as used in Experiment 1,
   First, appropriate items were found by randomly          from which all words in the corpus with a frequency of less
                                                            than or equal to 5 had been removed.
selecting 4-5 high-level category members (e.g. cow not     7
                                                              Using document-to-term comparison and maximum factors.
calf for category animal) that appeared in the LSA list     8
                                                              The exact formula used is as follows: Where X is the LSA
                                                            score one wishes to scale, M is the maximum LSA score for
                                                            this category set and L is the midpoint of the LSA score range
                                                            for this category set:
5
   The LSA score for a sentence is computed by taking a     Scaled LSA score = 4 – [(L – X) * 3] / (L * M).
weighted average of the vectors for each word.              (4 = midpoint of 7-pt scale; 3 = scale end [7] – midpoint [4]).

and told to consider the appropriateness of the                 contentious item, each of these three adjusted subject
capitalized word in the context given.                          sets achieved significance of p<0.025 (see Table 2).
   Participants were asked not to spend more than 10
seconds deciding on what score to give, and were told           Discussion
that it would not be possible to go back and change an          The results support the basic hypothesis that, in the
answer (the questionnaire was set up to prevent                 majority of cases, distributional information (in this
participants from doing this).                                  case modeled in LSA) can predict whether members of
                                                                a category will be appropriate or inappropriate in a
Results                                                         given context. In other words, it can predict human
Subjects agreed with LSA’s predictions of typicality for        judgements of typicality in context as well as in
62 of the total 70 items – 10/10 items in 3 context sets,       canonical categories (as demonstrated in Experiment 1).
9/10 items in 3 further context sets, and 5/10 in the           For example, LSA predicted in the context set for
remaining context set.            Significant difference in     animal (“Fran pleaded with her father...”) that the item
clusters, not rank correlation, is the important factor         elephant would be placed in the inappropriate cluster,
here, because even subject data with low correlation to         even though it is entirely possible to ride on an
the LSA score may fall into the two specified clusters          elephant.9
(and thus provide support for the main prediction).                In 3 of the 7 context sets, subject typicality scores
                                                                agreed with LSA predicted clusters for 10/10 items and
     Table 2: Wilcoxon’s W and significance of difference       separated the clusters to a difference significance of
           between clusters for each context sentence.          p<0.01. These sets involved natural kinds as the
                                                                category for which typicality was taken (animal, bird).
Context Sentence                    LSA           Subjects
                                                                In a further 3 context sets, subjects agreed with LSA’s
Stacy volunteered to milk the       10 (p<0.01)   10 (p<0.01)   clustering for 9/10 items and separated the clusters to a
animal whenever she visited                                     significant difference of p<0.05 when these 9 items
the farm *                                                      were considered. For these sets, two categories were of
Fran pleaded with her father        15 (p<0.01)   15 (p<0.01)   natural kinds (bird, fruit) and one was an abstract
to let her ride the animal *                                    artifact kind (sport). Finally, the context set for which
The bird swooped down on            10 (p<0.01)   10 (p<0.01)
the helpless mouse and carried                                  only 5/10 items were agreed to be in the predicted
it off                                                          clusters was also for an artifact kind (beverage). This
Jane liked to listen to the         15 (p<0.01)   18 (p<0.1)    suggests that distributional information (or at least,
bird singing in the garden                         10 (p<0.05)  LSA) may perform better in predicting the contextual
                                                   adjusted     typicality of natural kinds than artifact kinds. This is
Jimmy loved everything sweet 15 (p<0.01)          18 (p<0.1)    perhaps as a result of the vectors for artifact kinds
and liked to eat a fruit with his                  10 (p<0.05)
                                                                containing a greater degree of contextual variation and
lunch every day                                    adjusted
Sophie was a natural athlete        15 (p<0.01)   19.5 (p<0.1)  thus scoring more unpredictably against the context
and she enjoyed spending                           10.5(p<0.05) sentence.      Such a theory is compatible with
every day at sport training                        adjusted     psychological data showing that artifact kinds are
During the mid morning break 15 (p<0.01)          25 (p<0.7)**  processed differently because they may be found in a
the two secretaries gossiped                                    variety of functional and relational roles, and/or are
as they drank the beverage *                                    often polysemous (e.g. Wisniewski & Gentner, 1991).
         * Sentences taken from Roth & Shoben (1983)
        ** Not significant but included for completeness
                                                                                 General Discussion
   For all 7 context sets, Mann-Whitney (Wilcoxon               The success of a distributional measure (LSA) in these
Summed Ranks, 2-tailed) tests showed the LSA scores             modeling experiments suggests interesting possibilities
fell into two significantly different clusters. When            for a theory of categorization based in context, that
testing subject scores for difference between the               incorporates information from the structure of language
predicted clusters, results varied from three context sets      as well as from the structure of the world.
showing significant differences at p<0.01 (those at             Distributional models of language use a representation
10/10 agreement), to one set failing to achieve any             that is learned from the language alone, assuming that
significant difference at p=0.69 (5/10 agreement). Data         the way words co-occur with one another gives rise to
for clustering in both LSA and subject scores are given
in Table 2. Three of the context sets that only produced        9
                                                                   Although we anticipated a problem with participants’
clusters which were significantly different to p<0.10           judgements here, the prediction was consistent with the data,
were those where subjects agreed with LSA-predicted             where elephant received a typicality score of 4.1 and resided
clusters for 9/10 items. With the removal of this lone          in the inappropriate cluster. Is this respect, LSA predictions
                                                                were sometimes unexpectedly appropriate.

clues about their semantic meaning. Gleitman (1990)        Keil, F.C. (1987). Conceptual Development and
has discussed a similar approach with regards to first       Category Structure. In U. Neisser (Ed.), Concepts and
language acquisition, where this type of representation      Conceptual Development: Ecological and intellectual
can be easily learned from an individual’s response to       Factors in Categorization. Cambridge:Cambridge
their linguistic environment, thus lending a                 University Press.
psychologically plausible base to such a theory.           Komatsu, L., (1992). Recent views of conceptual
   In this respect, the results of these simulations raise   structure. Psychological Bulletin, 112, 500-526.
interesting questions with regard to people’s mental       Lakoff, G., (1987). Women, Fire and Dangerous
representations of the meanings of words: Do people          Things. University of Chicago Press.
use distributional information to construct their          Landauer, T. K. & Dumais, S. T., (1997). A solution to
                                                             Plato’s problem: The latent semantic analysis theory
representation of word meanings? Or are distributional
                                                             of acquisition, induction and representation of
properties of words (which models such as LSA
                                                             knowledge. Psychological Review, 104, 211-240.
extract) merely an epiphenomenonon; a reflection of the    Malt, B. & Smith, E. (1984). Correlated properties in
fact that underlying concepts share certain semantic         natural categories. Journal of Verbal Learning and
features? By the latter account, the distributional          Verbal Behavior, 23, 250-269.
properties associated with words would arise because       McCloskey, M., & Glucksberg, S. (1979). Decision
the concepts underlying the words possess certain            processes in verifying category membership
features, and it is sensitivity to similarities between      statements: Implications for models of semantic
these concepts that subjects actually manifest.              memory. Cognitive Psychology, 11, 1-37.
However, MacDonald & Ramscar (in submission) have          MacDonald, S & Ramscar, M. J. A. (this volume)
shown that manipulating the distributional properties of     Testing the distributional hypothesis: the influence of
the contexts in which nonce words are read can               context on judgements of semantic similarity. This
significantly influence similarity judgements between        volume.
existing words and nonces. This indicates that not all     Medin, D. & Smith, E. (1984). Concepts and concept
distributional responses can be explained in terms of        formation. Annual Review of Psychology, 35, 113-
existing conceptual structure – nonce words won’t have       138.
an existing conceptual structure. Equally, it seems        Redington, M., Chater, N. & Finch, S. (1998).
highly unlikely that the structure of the linguistic         Distributional information: a powerful cue for
environment is entirely unreflective of the structure that   acquiring syntactic categories. Cognitive Science, 22,
people extract from their interactions with the world.       425-469.
   What the results presented here (and other              Ramscar, M. J. A. & Hahn, U. (in submission). What
distributional research) seem to indicate is that any        family resemblances are not: Categorisation and the
                                                             concept of ‘concept’. Manuscript in submission
proper characterization of conceptual thought will have
                                                           Rosch, E. (1973). On the internal structure of perceptual
to consider more than just the information that comes
                                                             and semantic categories. In T. E. Moore (Ed.)
from physical experience and the physical environment.       Cognitive Development and the Acquisition of
One must also consider experience of language, and the       Language. New York: Academic Press.
structure of the linguistic environments in which          Rosch, E., (1978). Principles of Categorization. In E.
speakers find themselves.                                    Rosch and B. B. Lloyd (Eds.), Cognition and
                                                             categorization. Hillsdale, N.J.: Erlbaum.
                 Acknowledgments                           Roth, E. M. & Shoben, E. J., (1983). The effect of
We thank Dermot Lynott and Dan Yarlett for many              context on the structure of categories. Cognitive
insightful comments on the work reported in this paper.      Psychology, 15, 346-378.
                                                           Saffran, J. R., Aslin, R. N. & Newport, E. L. (1996).
                                                             Statistical learning by 8-month-old infants. Science,
                       References                            274, 1926-1928.
Armstrong, S. L., Gleitman, L. R. & Gleitman, H.,          Saffran, J. R., Newport, E. L. & Aslin, R. N. (1996).
   (1983). What some concepts might not be. Cognition,       Word segmentation: The role of distributional cues.
   13, 263-308.                                              Journal of Memory and Language, 35, 606-621
Barsalou, L. W. and D. R. Sewell (1985). Contrasting       Wisniewski, E. J., & Gentner, D. (1991). On the
   the representations of scripts and categories. Journal    combinatorial semantics of noun pairs: Minor and
   of Memory and Language, 24, 646-665.                      major adjustments to meaning. In G. B. Simpson
Burgess, C. & Lund, K., (1997). Modelling parsing            (Ed.),     Understanding     word     and     sentence.
   constraints with high-dimensional context space.          Amsterdam: Elsevier.
   Language and Cognitive Processes, 12, 1-34.
Gleitman, L. (1990). The structural sources of verb
   meanings. Language Acquisition, 1, 3-55.

