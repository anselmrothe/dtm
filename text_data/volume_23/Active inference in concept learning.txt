UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Active inference in concept learning
Permalink
https://escholarship.org/uc/item/90m7n1xf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Nelson, Jonathan D.
Tenenbaum, Joshua B.
Movellan, Javier R.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                    Active inference in concept learning
                                  Jonathan D. Nelson (jnelson@cogsci.ucsd.edu)*
                                 Joshua B. Tenenbaum (jbt@psych.stanford.edu)^
                                 Javier R. Movellan (movellan@cogsci.ucsd.edu)*
                                           *Cognitive Science Department, UCSD
                                                  La Jolla, CA 92093-0515
                                       ^Psychology Department, Stanford University
                                                     Stanford, CA 94305
                          Abstract                              tasks (Fedorov, 1972; MacKay, 1992; Oaksford &
                                                                Chater, 1994).
  People are active experimenters, constantly seeking new
  information relevant to their goals. A reasonable                A Bayesian concept learning model
  approach to active information gathering is to ask
  questions and conduct experiments that minimize the              In the approach presented here, we evaluate questions
  expected state of uncertainty, or maximize the expected       in terms of their information value.            Formally,
  information gain, given current beliefs (Fedorov, 1972;       information is defined with respect to a probability
  MacKay, 1992; Oaksford & Chater, 1994). In this paper         model. Here we use a Bayesian framework in the sense
  we present results on an exploratory experiment               that we model internal beliefs as probability
  designed to study people’s active information gathering       distributions. In order to quantify the information value
  behavior on a concept learning task. The results of the       (in bits) of a person’s questions, we first need a model
  experiment suggest subjects’ behavior may be explained
                                                                of her beliefs, and the way those beliefs are updated as
  well from the point of view of Bayesian information
  maximization.                                                 new information is obtained. Tenenbaum (1999, 2000)
                                                                provides such a model of people’s beliefs, for a number
                      Introduction                              concept learning task. While Tenenbaum (1999, 2000);
                                                                and the first and last authors of the present paper, in a
  In scientific inquiry and in everyday life, people seek       pilot study, found that his model described subjects’
out information relevant to perceptual and cognitive            beliefs well, there were some deviations between model
tasks. Whether performing experiments to uncover                predictions and subjects’ beliefs. The concept learning
causal relationships, saccading to informative areas of         model used in the present study, which we describe
visual scenes, or turning towards a surprising sound,           below, is based on Tenenbaum’s original model, but
people actively seek out information relative to their          extended in ways that reduce previously observed
goals.                                                          deviations between model predictions and study
  Consider a person learning a foreign language, who            participants’ beliefs.
notices a particular word, “tikos,” used to refer to a             We formalize the concept learning situation
baby moose, a baby penguin, and a baby cheetah.                 described by the number concept model using standard
Based on those examples, she may attempt to discover            probabilistic notation: random variables are represented
what tikos really means. Logically, there are an infinite       with capital letters, and specific values taken by those
number of possibilities. For instance, tikos could mean         variables are represented with small letters. The random
baby animals, or simply animals, or even baby animals           variable C represents the correct hidden concept on a
and antique telephones. Yet a few examples are often            given trial. This concept is not directly observable by
enough for human learners to form strong intuitions             study participants; rather, they infer it on the basis of
about what meanings are most likely.                            example numbers that are consistent with the true
  Suppose the learner could point to a baby duck, an            concept. Notation of the form “C=c” is shorthand for
adult duck, or an antique telephone, to inquire whether         the event that the random variable C takes the specific
that object is “tikos.” What question would she ask?            value c, e.g. that the correct concept (or “hypothesis”) is
Why do we think that pointing to the telephone is not a         prime numbers. We represent the examples given to
good idea, even though from a logical point of view, a          the subjects by the random vector X. The subject’s
phone could very well be tikos? In this paper we                beliefs about which concepts are probable prior to the
present a normative theoretical framework, to try to            presentation of any examples is represented by the
predict the questions people ask in concept learning            probability function P(C=c). The subject’s updated
                                                                belief about a concept’s probability, after she sees the

examples X=x, is represented by P(C=c|X=x). For
                                                                           P( X = x | H = h ) =
                                                                                                     1
example, if c is the concept even numbers and x the                                                   m
                                                                                                        ,
numbers “2, 6, 4”, then P(C=c|X=x) represents the                                                   h
subject’s posterior probability that the correct concept  if all m examples are in the concept h, and zero
is even numbers, given that 2, 6, and 4 are positive      otherwise.
examples of that concept. Study participants are not         This generating assumption reflects the human
explicitly given the true hidden concept; rather, they    intuition that although a given set of example numbers
infer it from examples of numbers that are consistent     is typically compatible with more than one concept, it
with the true concept.                                    may be more representative of some concepts than
   The number concept model includes both arithmetic      others. For instance, although the example numbers 60,
and interval concepts. Interval concepts are sets of      80, 10, and 30 are compatible with both multiples of 10
consecutive integers between n and m, where               and multiples of 5, that set of numbers is a better
1 ≤ n ≤ 100 , and n ≤ m ≤ 100 , such as numbers           example of the concept multiples of 10 than it is of the
between 5 and 8, and numbers between 10 and 35.           concept multiples of 5, because it is much more likely
Thus, there are 5050 interval concepts. Arithmetic        to be observed as a random sample from the more
concepts include odd numbers, even numbers, square        specific hypothesis multiples of 10.
numbers, cube numbers, prime numbers, multiples of n         The generative model described above can be used to
( 3 ≤ n ≤ 12 ), powers of n ( 2 ≤ n ≤ 10 ), and numbers   compute the probability that a new element y belongs to
ending in n ( 1 ≤ n ≤ 9 ). There are 33 arithmetic        the hidden concept C given the examples in x:
concepts.
                                                                       P( y ∈ C | X = x) =
   Inferences are made with respect to the following
model of how examples are generated: A concept is                        å P ( X = x | H = h ) P ( H = h)
first chosen at random according to a prior probability                h: y∈h
distribution. The prior probability distribution of the                 å P ( X = x | H = h) P ( H = h)
model is designed to reflect the human intuition that a                 h
concept like multiples of 10 is more plausible than a        An ideal concept learning model would assign some
concept like multiples of 10 except 30. A portion of      prior probability to every possible concept, according to
total prior probability is divided evenly into the        each concept’s plausibility to human learners. The
arithmetic concepts, with the exception of even           main difference between the concept learning model
numbers and odd numbers. To reflect the higher            used in the current paper, and the model introduced in
salience of the concepts even numbers and odd             Tenenbaum (1999, 2000), is our inclusion of a large
numbers, each of those concepts is given five times the   number of random “exception” concepts, which are
prior probability of the other arithmetic concepts.       formed by replicating and slightly changing, or
Among the interval concepts, prior probability is         “mutating,” concepts from the basic model. Here, we
apportioned according to the Erlang distribution          include 50,830 exception hypotheses -- on average, 10
                                                          exception concepts for each concept in the basic model.
                                     −h
                                h
                  P(H = h ) ∝
                                                          To form an exception concept (or “hypothesis”), a
                                     σ
                                 2 e                      concept is first picked from the basic model, according
                               σ
                                                          to the prior probability of concepts in the basic model.
according to the concept’s size |h|. (The concept         We include a parameter µ for the average number of
numbers between 15 and 30 is size 16.) Sigma gives        changes to the original concept, and divide these
the optimal interval length.        In the simulations    changes equally, on average, into additions of new
described in this paper we set σ to 15, although in       numbers and exclusions of existing numbers. The
principle, σ is a free parameter to fit to the data.      probability of each existing number being excluded
Interval concepts of a given length, such as numbers                              µ
between 25 and 35, and numbers between 89 and 99,         from a concept is           , and the probability of each
receive the same prior probability, irrespective of their                        2 h
endpoints.                                                currently excluded number (between 1 and 100) being
   Once a concept is chosen, examples are randomly
                                                                                          µ
and independently generated, with equal probability,
                                                                                      (         )
                                                          added to the concept is                 .
from the set of numbers in that concept. Thus, the                                  2 100 − h
likelihood of a particular vector of m examples X=x,         Each exception hypothesis receives a constant share
given the concept h,                                      of the total proportion of prior probability assigned to
                                                          the exception hypotheses. In the simulation of the
                                                          model reported in this paper, 60% of prior probability

was assigned to the exception hypotheses, and µ was                 approximate here by using the expanded number
set to 6. It takes approximately 30 minutes to simulate             concept learning model. An information-maximizing
the set of trials in the study, for any setting of model            strategy prescribes asking the question with the highest
parameters, and we are just beginning to explore the                expected information gain, e.g., the question that
parameter space. Early exploration suggests that a wide             minimizes the expected entropy, over all concepts.
range of parameters in the extended number concept                     Another strategy of interest is confirmatory sampling,
model can improve on the basic model’s                              which consists of asking questions whose answers are
correspondence to human beliefs.                                    most likely to confirm current beliefs. In other domains
                                                                    it has been proposed that people have a bias to use
   Information-maximizing sampling                                  confirmatory strategies, regardless of their information
                                                                    value (Klayman & Ha, 1987; Popper, 1959; Wason,
     In the experiment reported in this paper, we allowed
                                                                    1960).
subjects to actively ask questions about number
concepts, instead of making inferences solely on the
basis of the examples given to them. For example, on                          The active sampling concept game
one trial the subject was given the number 16 as an                    Twenty-nine undergraduate students, recruited from
example of the hidden underlying concept, and then                  Cognitive Science Department classes at the University
was allowed to test another number, to find out whether             of California, San Diego, participated in the
it was also consistent with the true, hidden concept.               experiment.          Subjects gave informed consent, and
   In our formalism, the binary random variable Yn                  received either partial course credit for required study
represents whether the number n is a member of the                  participation, or extra course credit, for their
correct concept. For example, Y8=1 represents the event             participation. The experiment began with the following
that 8 is an element of the correct, hidden concept, and            instructions:
Y8=0 the event that 8 is not in that concept. Asking “is                  Often it is possible to have a good idea about the state
the number n an element of the concept?” is equivalent                 of the world, without completely knowing it. People
                                                                       often learn from examples, and this study explores how
to finding the value taken by the random variable Yn, in
                                                                       people do so. In this experiment, you will be given
our formalism.                                                         examples of a hidden number rule. These examples will
   We evaluate how good a question is in terms of the                  be randomly chosen from the numbers between 1 and
information about the correct concept expected for that                100 that follow the rule. The true rule will remain
question, given the example vector X=x. The expected                   hidden, however. Then you will be able to test an
information gain for the question “Is the number n an                  additional number, to see if it follows that same hidden
element of the concept?” is calculated with respect to                 rule. Finally, you will be asked to give your best
the learner’s beliefs, as approximated with the extended               estimation of what the true hidden rule is, and the
number concept model described above. Formally,                        chances that you are right. For instance, if the true
                                                                       hidden rule were “multiples of 11,” you might see the
expected information gain is given by the following
                                                                       examples 22 and 66. If you thought the rule were
formula:                                                               “multiples of 11,” but also possibly “even numbers,” you
                                                                       could test a number of your choice, between 1-100, to
   I ( C , Yn | X = x ) = H ( C | X = x ) − H ( C | Y n , X = x ) ,    see if it also follows the rule.
where the uncertainty (entropy) about the hidden                       On each trial subjects first saw a set of examples
concept C given the example numbers in x,                           from the correct concept. For instance, if the concept
                                                                    were even numbers, subjects might see the numbers “2,
                          H (C | X = x ) =                          6, 4” as examples. Subjects were then given the
        − å P (C = c | X = x) log2 P (C = c | X = x ) ,             opportunity to test a number of their choice. Subjects
           c                                                        were given feedback on whether the number they tested
and the expected remaining uncertainty about the                    was an element of the correct concept.
hidden concept C, given the example numbers in x and                   We wrote a computer program to simulate the
the answer to the question Yn:                                      expanded number concept model, and to compute the
                                     1
                                                                    information value of each possible question, given each
            H (C | Yn , X = x ) = − å P (Yn = v | X = x )           set of examples. By considering beliefs and questions
                                   v =0                             together, we may evaluate the information value of
  å P (C = c | Yn = v , X = x ) log 2 P (C = c | Yn = v , X = x )   participants’ questions, as well as that of information-
  c                                                                 maximizing and confirmatory sampling strategies. We
   We consider only binary questions, of the form “is n             define the confirmatory strategy as testing the number
consistent with the concept?” so the maximum                        (excluding the examples) that has the highest posterior
information value of any question in our experiment is              probability, as given by the extended number concept
one bit. Note how information value of questions is
relative to subjects’ internal beliefs, which we

model, of being consistent with the correct hidden              numbers to test are non-example powers of two, 4 or
concept.                                                        32. Most (16/29) subjects tested these numbers.
                                                                                                 0.4                                             0.7
                           Results
                                                                                             0.35                                                0.6
  We discuss two types of trials, grouped according to
                                                                   P(subject tests number)                                                             Information in test (bits)
                                                                                                 0.3
the posterior beliefs of the extended number concept                                                                                             0.5
model, after all the example numbers have been seen.                                         0.25
                                                                                                                                                 0.4
These results should be considered preliminary, as 29                                            0.2
data points on each trial are not sufficient for estimation                                                                                      0.3
                                                                                             0.15
of statistically reliable sampling distributions over the
                                                                                                                                                 0.2
range of possible queries from 1 to 100.                                                         0.1
                                                                                             0.05                                                0.1
  Arithmetic trials
                                                                                                  0                                       0
   On some trials, the model is dominated by arithmetic                                                     10 20 30 40 50 60 70 80 90 100
concepts, and exception hypotheses based on arithmetic
concepts. On each of these trials, good agreement                                 Figure 2. Information value of questions
between a number’s information value and subjects’                                (line), and subjects’ questions (circles),
propensity to sample that number was observed. The                                given the examples 81, 25, 4, and 36.
information value of the confirmatory strategy was near
to that of the information-maximizing strategy on these            Finally, we may consider the trial with the examples
trials.                                                         60, 80, 10, and 30, in which the hypothesis multiples of
   Consider the trial with the examples 81, 25, 4, and          10 receives the highest posterior probability; multiples
36, in which the concept with the highest posterior             of 5 also receive moderate probability (Figure 4). On
probability is square numbers. Generalization behavior          this trial, non-example multiples of 10, such as 20, and
of the model, and beliefs of subjects, are shown in             odd multiples of five, have the highest information
Figure 1. Note that the model and subjects alike assign         value.      Multiples of 10 were tested by 21 of 29
certain, or near certain, probability to each of the            subjects; an additional 5 subjects tested odd multiples
example numbers, but less than certain probability to           of five
the other square numbers. Relative to the model’s                                            1
beliefs, the most informative numbers to test are non-
example square numbers, such as 9, 16, 49, 64, or 100              0.75
(Figure 2). In fact, 20 of 29 subjects tested one of these
numbers. Other subjects’ samples do not show a clear                        0.5
pattern, except for testing the number 10 (5 of 29
subjects), which is unpredicted.                                   0.25
      1
                                                                                             0
   0.75                                                                                                10    20   30   40   50   60   70   80   90   100
    0.5                                                                           Figure 3. Generalization probabilities given
                                                                                  the examples 60, 80, 10, and 30.
   0.25
                                                                    The difference between the first two arithmetic
      0
                                                                trials, and the trial with the examples 60, 80, 10, and 30
            10   20   30    40   50   60   70   80   90   100
                                                                appears to be that a clear alternate hypothesis --
                                                                multiples of five -- receives moderate posterior
     Figure 1. Generalization probabilities, given              probability in the multiples of 10 trial, but not on the
     the examples 81, 25, 4, and 36. Model                      other trials.
     probabilities are given by the line. Subjects’
     probabilities, for the 30 probe numbers
     subjects rated, are given with circles.
  Good agreement between subjects’ samples and rated
information value is also observed on the trial with the
examples 16, 8, 2, and 64. The most informative

                             0.25                                 0.6                                                          1
                                                                  0.5                                0.75
   P(subject tests number)
                              0.2
                                                                        Information in test (bits)
                                                                  0.4                                         0.5
                             0.15
                                                                  0.3                                0.25
                              0.1
                                                                  0.2                                                          0
                             0.05                                                                                                        10    20   30   40   50   60   70   80   90   100
                                                                  0.1
                               0                                  0                                                 Figure 5. Generalization probabilities, given
                                    10 20 30 40 50 60 70 80 90 100                                                  the examples 16, 23, 19, and 20.
                  Figure 4. Information value of questions,
                  and subjects’ questions, given the examples
                                                                                                                               0.12                                                1
                  60, 80, 10, and 30.
                                                                                                                                                                                   0.9
                                                                                                                                   0.1
                                                                                                     P(subject tests number)
                                                                                                                                                                                   0.8
                                                                                                                                                                                         Information in test (bits)
                                                                                                                                                                                   0.7
  Interval trials                                                                                                              0.08
                                                                                                                                                                                   0.6
   On these trials, several examples of numbers of
                                                                                                                               0.06                                                0.5
similar magnitude, such as 16, 23, 19, and 20, are given
                                                                                                                                                                                   0.4
(these numbers are points where model probabilities are                                                                        0.04
                                                                                                                                                                                   0.3
1.00, Figure 5, and Figure 7). The model is certain that
                                                                                                                                                                                   0.2
the example numbers themselves are consistent with the                                                                         0.02
true concept. The model is fairly sure that non-example                                                                                                                            0.1
numbers within the range spanned by the examples, like                                                                              0                                       0
17, 18, 21, and 22, are consistent with the true concept.                                                                                     10 20 30 40 50 60 70 80 90 100
Finally, the model assigns decreasing probability to
numbers as they move away from the range of observed                                                                Figure 6. Information value of questions,
examples (Figure 5).                                                                                                and subjects’ questions, given the examples
   It should be noted that there is some variability from                                                           16, 23, 19, and 20.
one run of the model to the next. The general pattern of
results, however, holds from run to run. In particular,
(1) numbers slightly outside of the range of the                                                                               1
observed examples are most informative, (2)
information value of numbers decreases with increasing                                               0.75
distance from the observed examples, and (3) there is
                                                                                                              0.5
moderate information value in non-example numbers
within the range of observed examples.
                                                                                                     0.25
   Most subjects tested numbers outside of, but near the
observed examples (Figure 6). About one-third of                                                                               0
subjects tested (non-example) numbers within the                                                                                         10    20   30   40   50   60   70   80   90   100
range spanned by the examples. On the other interval
trials -- with example numbers 60, 51, 57, and 55; and
                                                                                                                    Figure 7. Generalization probabilities, given
81, 98, 96, 93 (illustrated in Figure 7 and Figure 8)--
                                                                                                                    the examples 81, 98, 96, and 93.
similar patterns emerged.

                             0.18                                 1.2                                                 Acknowledgments
                             0.16                                                                      Thanks to Gedeon Deák, Jeff Elman, Iris Ginzburg,
                                                                  1
   P(subject tests number)                                              Information in test (bits)
                             0.14                                                                    Craig McKenzie, Terry Sejnowski, and three
                             0.12                                 0.8
                                                                                                     anonymous reviewers for their ideas; and Kent Wu,
                                                                                                     Dan Bauer and Jonathan Weh for their help in this
                              0.1
                                                                  0.6                                research. J. Nelson was partially supported by a Pew
                             0.08                                                                    graduate fellowship during this research.
                             0.06                                 0.4
                             0.04                                                                                          References
                                                                  0.2
                             0.02                                                                    Anderson, J. R. (1990). The adaptive character of
                               0                                  0                                    thought. New Jersey: Erlbaum.
                                    10 20 30 40 50 60 70 80 90 100                                   Fedorov, V. V. (1972). Theory of optimal experiments.
                                                                                                       New York: Academic Press.
                  Figure 8. Information value of questions,                                          Ginzburg, I.; Sejnowski, T. J. (1996). Dynamics of rule
                  and subjects’ questions, given the examples                                          induction by making queries: transition between
                  81, 98, 96, and 93.                                                                  strategies.    Proceedings of the 18th Annual
                                                                                                       Conference of the Cognitive Science Society, 121-
                                                                                                       125.
                                                                                                     Klayman, J.; Ha, Y.            (1987).   Confirmation,
                                          Discussion                                                   disconfirmation, and information in hypothesis
  This paper presents work in progress to analyze                                                      testing. Psychological Review, 94, 211-228.
active inference in concept learning from the point of                                               MacKay, D. J. C. (1992). Information-based objective
view of the rational, probabilistic approach to cognition                                              functions for active data selection.           Neural
(Anderson, 1990). In the rational study of information-                                                Computation, 4, 590-604.
gathering behavior, the current research adds to existing                                            Oaksford, M.; Chater, N. (1994). A rational analysis of
analyses of Wason’s (1966, 1968) selection task                                                        the selection task as optimal data selection.
(Oaksford & Chater, 1994, 1998), and Wason’s (1960)                                                    Psychological Review, 101, 608-631.
2-4-6 task (Ginzburg & Sejnowski, 1996).                                                             Oaksford, M.; Chater, N. (1998). Rationality in an
  We found that a normatively inspired criterion of                                                    uncertain world: Essays on the cognitive science of
optimal sampling -- maximizing average information                                                     human reasoning. UK: Erlbaum
gain -- predicts human behavior well on a relatively                                                 Popper, K. R. (1959). The logic of scientific discovery.
unconstrained task. This result is strengthened by the                                                 London: Hutchinson.
fact that the extended number concept model we                                                       Tenenbaum, J. B. (1999). A Bayesian Framework for
employed, as a proxy for subjects beliefs, was not                                                     Concept Learning. Ph.D. Thesis, MIT
originally developed with the goal of serving as a                                                   Tenenbaum, J. B. (2000). Rules and similarity in
                                                                                                       concept learning. In Advances in Neural Information
model for sampling. Nor were our extensions to it ad
                                                                                                       Processing Systems, 12, Solla, S. A., Leen, T. K.,
hoc. To the contrary, our extended model now has a
                                                                                                       Mueller, K.-R. (eds.), 59-65.
better fit to data from earlier studies.                                                             Wason, P. C. (1960). On the failure to eliminate
  If rational theories of cognition are to explain thought                                             hypotheses in a conceptual task. Quarterly Journal of
and behavior in natural environments, then optimal                                                     Experimental Psychology. 12, 129-140.
sampling agents should also exhibit the systematic                                                   Wason, PC (1966). Reasoning. In Foss, B (ed.), New
“biases” traditionally associated with human behavior.                                                 Horizons in Psychology, pp. 135-151.
Indeed, we found that on many trials, a confirmatory                                                 Wason, PC (1968). Reasoning about a rule. Quarterly
sampling strategy approximates the information-                                                        Journal of Experimental Psychology, 20, 273-281.
maximizing strategy.
  A final point is that whereas information gain,
calculated with respect to the extended number concept
model, predicts study participants’ questions fairly well,
information gain with respect to the original number
concept model does not do so. This illustrates that
particular queries are not informative or uninformative
on their own, but only in relation to a particular
probability model. To understand people’s questions,
or build artificial sampling systems that come closer to
meeting human competence, developing appropriate
probability models is critical.

