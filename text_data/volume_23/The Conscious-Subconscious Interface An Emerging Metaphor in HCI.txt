UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Conscious-Subconscious Interface: An Emerging Metaphor in HCI

Permalink
https://escholarship.org/uc/item/9z45z3x4

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)

Authors
Pyke, Aryn A.
West, Robert L.

Publication Date
2001-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Conscious-Subconscious Interface: An Emerging Metaphor in HCI
Aryn A. Pyke (apyke@ccs.carleton.ca)
Department of Cognitive Science, Carleton University
Ottawa, K1S 5B6 Canada

Robert L. West (robert_west@carleton.ca)
Department of Psychology, Carleton University
Ottawa, K1S 5B6 Canada

Abstract
Although there already exist traditional metaphors
influencing human-computer interaction (HCI) such as
the human-human interaction metaphor, some
applications emerging in areas from intelligent agents to
wearable and context-aware computing have prompted
the authors to identify a new metaphor implicitly
emerging in HCI. This will be referred to as the
conscious-subconscious (C-S) metaphor. The explicit
elucidation of this C-S metaphor poises HCI to speak to
and leverage research in philosophy and cognitive
science pertaining to consciousness and cognition.

Introduction
Although the characterization of consciousness and
cognition, per se, are not the primary objectives of the
applied field of human-computer interaction (HCI),
the authors contend that emerging endeavours in HCI
are poising it to speak, perhaps more directly than in
the past, to such issues.
To address novel challenges as HCI applications
have expanded and diverged, the field has developed a
growing toolbox of metaphors to inform and interpret
interface design. Two such, traditionally prevalent,
metaphors for human-computer interaction are the
human-tool interaction metaphor and human-human
interaction metaphor (see Marchionini (1995) for a
general overview). However, some of the applications
in relatively new areas such as wearable, contextaware computing, and intelligent/autonomous agents
seem to be promoting the implicit development of a
new metaphor which will be referred to as the
conscious-subconscious (C-S) metaphor.
In HCI, it is natural to partition computer activity
into two classes: interface processes and underlying
computational processes which are predominantly
opaque to the interface/user. Just as much of the
computation that goes on in a computer is not evident
in any way through, or even to, the interface, so too,
much of the computation that transpires in the mind is

opaque; even to the individual’s own introspection.
This is evident in such activities as throwing a
baseball, during which there are no conscious
calculations of trajectories.
From this perspective, humans can be modelled as
cognitively modular with a conscious process running
concurrently with one or more subconscious processes.
In some cases our conscious mind is completely
unaware of the underlying computation, in other cases
it is privy to the product or result of the computation,
and sometimes it seems actively involved in the
process. In light of it’s intermittent and incomplete
exposure to inner information, the conscious mind can
be viewed in this regard as a form of interface itself.
The following example provides an illustration of
how the C-S metaphor can be applied in HCI. The
next generation of search engine interfaces will be
information retrieval agents (e.g. Lieberman, 1995;
Rhodes & Starner, 1996; Stenmark, 1997) which are
able to proactively, that is, without an explicit query,
search out and bring to the user’s attention
(consciousness) web documents that might be relevant
in the current task context. For example, it might fetch
pages on Hamlet while an individual is writing a paper
on Hamlet in MS Word.
In a similar spirit,
subconscious memory processes proactively pop
memories into mind (consciousness) that are relevant
to the current context, such as when you enter a video
store and spontaneously remember that your friend
recommended that you should see The Matrix. In the
sense that such interface agents perform tasks of a
similar nature to those performed by human
subconscious mechanisms, and exchange information
with the conscious facet of the user in a similar
manner, such agents could be regarded acting as
supplementary or prosthetic subconscious systems.
The explicit elucidation of this C-S metaphor is
significant in that, more directly than previous
metaphors, it poises HCI to speak to and leverage
research in philosophy and cognitive science

pertaining to consciousness and cognition.
A distinctive contribution of HCI in this regard, is
that by virtue of it’s agenda, it is geared toward actual
operationalizations
of
the
concepts
and
implementations of the processes. Such efforts yield
impetus and insight towards identifying and
characterising: a) information availability and internal
interfacing aspects of conscious experience; and b)
the underlying processes necessary to support such
experience. It is beyond the scope of this paper to
delve into the details of these characterizations beyond
a few examples. It is hoped that the identification and
systemisation of the metaphor will catalyse
interdisciplinary impetus toward an integrated
theoretical interpretation and framework.

Human-Computer Interaction: Catering
to Consciousness
The flip side of the relevance of HCI to the
characterization of consciousness, is the relevance of
consciousness to the characterization of HCI.
Although in cognitive models of computation,
consciousness is often regarded as an aside or
epiphenomenon (e.g. Jackendoff, 1987), the user’s
conscious experience often holds centre stage in the
field of human-computer interaction. Familiar
conscious experiences during computer use, such as
effort, confusion, frustration and impatience are all
relevant to the evaluation of an HCI design, and these
are the types of experiences that HCI efforts endeavour
to minimise.
This focus on phenomenology first is actually shared
by an explicit methodological approach to the
characterization of consciousness. It is one advocated
by William James (1910) who advised that the
researcher “begin with the most concrete facts, those
with which he has a daily acquaintance in his own
inner life”.

The C-S Metaphor
Humans, as social animals, are equipped with
substantial experience in interacting with each other.
Designers can cater to this experience by following a
human-human interaction metaphor, and attempt to
make interacting with a computer resemble, in some
sense, interacting with another individual. In terms of
design, the practical implication was that making a
better computer (interface) was synonymous with
making it appear more human. This pursuit is
evidenced in research involved with developing natural
language interfaces, endowing computer interfaces
with personality trait cues, facial expressions and
imbuing them with emotions (e.g. Minsky, 1999;

Picard, 1997). As users, we tend to meet the design
effort
halfway
with
our
inclination
to
anthropomorphize.
However, some emerging applications in HCI
require a phenomenological framework that does not
fit well with the human-human, or other traditional
interface metaphors. There is a trend for computers to
become wearable and equipped with their own sensory
systems, (e.g. Rhodes, 1997). They can thus be
programmed to be context-aware in terms of both the
task and physical environment (Dey & Abowd, 1999,
is a good survey).
Applications are also being
programmed to absorb, and make inferences from, the
behavioural patterns of their users. For example, web
browsers can keep track of the URL’s visited and
proactively complete the URL string the user is
currently typing by matching it to a habitual one.
Extrapolating from the “short hand” ease of interaction
enjoyed between close friends due to shared
experiences, imagine the potential fluency of
interaction with a context-aware, habit-aware,
wearable device which could potentially accompany an
individual at all times and share all “experiences”. In
this sense the interaction has the potential not only to
be more intimate than ever before in HCI, but also in
some respects more seamless than interpersonal
interaction, and thus of a different, more continuous
and customized character than human-human
interaction paradigms could properly inform.
Although such a scenario may not be informed by
interpersonal interaction paradigms, such an
integrated, customized interface has aspects in
common with the cognitive intra-actions that occur
between the conscious and subconscious processes
within an individual. Compare the experience of
information retrieval from a computer search engine
interface, or even by querying another person, with the
spontaneous retrieval afforded by internal memory.
Memories often pop into mind (consciousness) just as
they are needed (Rhodes, 2000), before an explicit
query need even be formulated. From the perspective
of conscious experience, such retrieval is accomplished
by an apparently context-aware unconscious process
operating concurrently, autonomously and proactively.
In the human-human interaction metaphor for HCI,
the human user is, in principle, regarded somewhat
holistically. The computer (interface) is designed to
simulate human interface characteristics (e.g. speech
recognition, and speech output) by effectively acting as
another human with “whom” the user can interact (in
the spirit of the Turning Test). In contrast, in the C-S
interface metaphor, the computer could be thought to
be interacting in a more integrated way, simulating a
service style akin to that of the user’s own subconscious

processing. Several such subconscious systems could
be simultaneously active.
As with internal
subconscious processes, it is not unreasonable to
suppose that several could run simultaneously and have
some form of intermittent ‘interactions’ projecting on,
or guided from, the explicit stream of conscious
experience. Although this is a fairly pre-theoretic
model, it is at least consistent with two of the most
familiar themes in cognitive science and the
philosophy of mind: the modularity of mental processes
(e.g. Fodor, 1983) and the introspective opacity of
some processes and premises (e.g. Davidson, 1987).
The next section describes intelligent/autonomous
interface agents (e.g. Lieberman, 1997) whose
characteristics can be applied to C-S metaphor
applications.

Intelligent Agents: Aspects of Autonomy
and Implicit Interaction
Intelligent/autonomous
interface
agents
(e.g.
Liberman, 1997) are software processes/programs that
can operate in parallel with the user and autonomously
impact the interface. They are best described by
example (as provided in the next section), but a brief
prefacing discussion is appropriate to emphasise their
key characteristics in the current context.
They are able in principle to operate without explicit
initiation by the user, and/or continually and
concurrently with other explicitly interactive activities
of the user. By way of contrast, in strictly turn-taking
conversational interfaces, such as the familiar
traditional search engine interfaces, the user and the
interface take turns (inter)acting, and are dormant
while awaiting the response of the other. An agent’s
ability to act proactively sometimes includes the
potential to initiate explicit interaction with the user.
For example the agent may explicitly inform the user
of a something it has detected in the course of it’s
independent (though often context-aware) activities.
Conversational interfaces are characterized by
communication which tends to be fully explicit in both
directions. For intelligent interface agents, there can
be explicit and implicit aspects of interaction and
information gathering. Though the user may or may
not be aware of the agent’s activities at any given
moment, an agent can be programmed to attend to the
user’s activities, and base it’s activity on such
implicitly gleaned information, rather then requiring
explicit instruction.
Interface agents can have a broad range of
capabilities and characteristics. As such, they are not
at all tightly or necessarily coupled to the C-S
metaphor.
An agent could perform autonomous

activity but also employ a conversational interaction
style, and fit under the auspices of the human-human
interface metaphor. The relevance of such agents here
lies in the fact their nature permits them to be tailored,
if desired, towards applications which do fit with the
C-S metaphor. For example, they can run concurrently
and invisibly in the background, implicitly ingest
information, adapt to the individual, interject with
task-relevant information or initiate interruptions.

Analogies between Autonomous Interface
Agents and Internal Subconscious Processes
The proposal of a C-S interface metaphor for HCI has
been justified by the commonalties noted between the
attributes of some such interface agents and those of
subconscious processes. The parallels are best
exemplified in agents which actually perform similar
specific functions to those provided by our own
subconscious system. Examples of such agents which
are likely familiar to the reader include: (1) the
information retrieval agents already alluded to; (2)
automatic “typo” correction ‘agents’ as in MS Word;
and (3) automatic string completion ‘agents’ such as
provided in browsers for automatic URL string
completion.
(1) The C-S interface metaphor is particularly well
suited for information retrieval (IR) applications. For
the most part, these electronic IR endeavours have been
guided by paradigms from the library sciences.
However, a very efficient, personally customised,
information retrieval system - our own memory system
- provides a nearer and dearer paradigm.
It is a
testament to the appropriateness of the C-S metaphor
that when we forget something, we often assert that
“it’ll come to us”, implying the involvement of an
agent/process other than our(conscious)selves.
There are several other phenomena in memory
which speak to the conscious/unconscious interaction
issue. Most of our memories are subconscious most of
the time. Otherwise we would be constantly actively
engaged in experiencing all our previous memories
(simultaneously)! It is a common experience to have
an old memory resurface (not consciously bidden)
when returning to an old haunt. It is also common not
to be able to remember something, such as the location
of one’s car keys, despite the fact that one consciously
wants to. Such experiences serve to remind us that we
do not remember by conscious will alone, but rather
through a collaboration (interaction) of the conscious
and subconscious mediated by context.
Letizia (Lieberman, 1995) is an example of an
autonomous interface agent for web search (also
Rhodes, 2000; Stenmark, 1997). Letizia operates in

parallel with the user’s browsing activity and is always
active, sifting the web space that is “nearby” (linked to)
the user’s current page of focus. Letizia implicitly
gleans the user’s current web location by monitoring
the user’s explicit interaction with the browser, and
conducts empirical observation of the user’s past and
present browsing behaviour to infer aspects of interest.
The user profile can be saved, so knowledge persists
and accumulates across sessions. This information is
used to make relevancy judgements without (prior to)
explicit presentation of information to the user. Based
on this implicitly acquired information, Letizia
proactively displays pages in a separate right frame of
the browser that it judges might be of interest. Note
that Letizia’s search is context driven, such that
whenever the user switches pages, Leteiza’s context is
refocused on the new page. In terms of the user’s
conscious participation in the interaction, the user is
free to ignore or pursue the suggestions shown subtly
in a window at the edge of the screen.
(2) Word processing applications such as MS-Word
can now be set to automatically correct spelling
mistakes as the user types1. The operation is subtle
and unobtrusive, and in composing this document, this
author has remained largely unaware of this corrective
activity (though not due to a lack of ‘typos’).
In a similar vein, human musicians have been
observed to automatically internally correct ‘musical
typos’ when playing off sheet music without even being
consciously aware of it (Jackendoff, 1987). In both
cases, there is a concurrent automatic process that is
functioning like a proactive proof-reader.
(3) Automatic string completion ‘agents’ exemplify
other HCI activities that could be interpreted as serving
as supplementary subconscious processes. Browsers
now can be set to automatically/proactively attempt to
complete the URL as the user types. Similarly, in the
UNIX command-line interface shell “bash”, users can
type the first few letters of a filename or command and
press tab to invoke the completion process (a beep will
sound if there more than one possible match requiring
the user to be more explicit). In the UNIX case the
user has to explicitly invoke the completion process by
pressing tab. In some respects, these examples could
be interpreted according to the human-human interface
metaphor. Conversing individuals often preemptively
complete each other’s sentences, and this could be
considered an appropriate analogy for automatic string
completion.
However there are significant reasons
why a C-S metaphor could be ultimately considered
more appropriate. In principle, even in conversation, it
is the speaker herself, not the other individual, who
1

For example, automatically changing adn to and.

best knows what the correct completion will be. Thus,
an intra-individual (subconscious) metaphor rather
than an inter-individual metaphor is appropriate for
achieving optimal performance.
Furthermore, in
practise, ultimately wearable computers will be privy to
context and user history information on a scale that
will make them more ‘acquainted’ with the user, in
their head so to speak, than any human-human
acquaintance protocol could be properly equipped to
model.

Implications for the Characterization of
Consciousness and Cognition
A perspective on consciousness which revolves around
the human conscious/subconscious (C-S) interface has
been taken. The authors have proposed that a C-S
metaphor is an emerging (though perhaps implicit)
metaphor guiding HCI design. In the course of the
discussion it was demonstrated that the operation of
several existing autonomous interface agents, such as
the type providing automatic URL string completion,
can be readily interpreted according to this metaphor.
However, the actual development of the existing
applications was largely on a piecemeal basis and
involved implicit or pre-theoretic application of the
metaphor.
To the authors knowledge, the C-S
metaphor has not been labelled as such nor applied in a
systematic manner. It lays the foundation for observing
that the different disciplines of philosophy and HCI
have converged to concentrate on some of the same
issues, and thus are poised to mutually
inform/influence each other.
There are two types of challenges inherent in
implementations according to the C-S metaphor. First,
it is necessary to determine and describe the exact
nature of the conscious experience the interface is
supposed to engender. This might include such factors
as the degrees of implicit and explicit exchange, timing
issues and information availability,
format and
salience. Then it is required to characterize and
operationalize underlying computational processes to
afford the desired interaction and information
exchange. These two challenges are discussed in the
following two sections.

Characterizing the Conscious Experience
In the human-human metaphor, much of the
interaction is typically conversational and of a very
explicit nature. That is, it involves direct, deliberate
“communication” with the computer. The user has a
conscious experience of ongoing active involvement in
the interaction. This includes not only awareness of
the information exchanged itself but also

(phenomenology of) intentional initiation and
interpretation of exchanges.
In contrast, for
applications in the C-S style, the trend is towards less
(experience of) explicit effort, and greater emphasis on
fine tuning on the phenomenological aspects of the
information availability.
The HCI endeavour of making interacting with a
computer more like interaction with one’s
subconscious processes provides pressure to make the
phenomenology of such interactions more explicit.
That is, what are the various types and features of
phenomenological
projections
of
unconscious
computation processes?
Phenomenology is often exemplified by reference to
qualia of sensory experiences such as pain.
Considerations regarding the
phenomenology of
interacting with our subconscious process or computers
promote the characterization of a different
family/modality of phenomenal experiences. These are
the less sensory-centric, conscious correlates of
computation and internal communication.
For
example, there is something it is like to consciously,
with effort, conduct some reasoning, or to generate and
receive explicit communication.
Some such characterizations, especially in terms of
memory, have already preceded the HCI efforts. For
example, meta-memory models (Kihlstrom, 1987), the
feeling of knowing2 (Hart, 1965), and tip of the tongue
experiences (e.g. James and Burke, 2000).
Endeavours in HCI according to the C-S metaphor may
catalyse
more
full
characterizations
and/or
operationalizations of such phenomenology.
For example, with regards to information agents,
there are several relevant aspects of memory
phenomenology at the level being imitated by the
agent. It is necessary that the information become
accessible to conscious reasoning and declaration,
which falls under the auspices of Block’s (1995) access
consciousness. Another characteristic is that the time
course of it’s arrival with respect to changing context
be such that it ideally arrives when it is relevant and
before the user has a conscious sense of missing or
wishing for it. This is a motivating premise of Rhodes’
(2000) Just-In-Time information retrieval system.
Also it is intended to be rendered accessible in such a
way that it enters discretely onto the Cartesian stage
without upstaging the focus of the current train of
thought. The user is free to disregard or ignore the
information. Lieberman (1997) points out the
2

The feeling of knowing refers to a scenario in which,
although the individual is experiencing difficulty retrieving a
memory, they nonetheless feel that it is in there (their
subconscious) somewhere.

significance of this spontaneous subtle suggestion
system in Letizia which avoids having the user make
the “context switch” required by conversational
interfaces from browsing the space of web pages to
explicitly interacting with the search agent.
In some respects interaction with C-S style interface
agents cannot possibly be experienced exactly like
interaction with internal processes. The information
from the interface agent starts out on the screen and is
subject to absorption via our sensory system. But what
is noteworthy is that some of the convenient and
customised character is achieved nonetheless. When
viewing memory phenomenology at this level, what
seems to matter is that the right data be brought to
mind at the right time regardless of whether it was a
subconscious or sensory delivery channel.
While such input modality issues might not be
brought to the fore in operationalizing the semantic
access of declarative memory, such issues might
become relevant in postulated cases of agents acting as
artificial sensory systems. Consideration of attributes
and implications of such artificial sensory agents might
shed light on some important phenomenal issues and
delineations.
It provides a good connection point
between HCI inspired insights and existing theoretical
frameworks about consciousness such as the one
proposed by Block (1995).

Characterizing the Underlying Computation
Determining the character and components of the
desired conscious experience, which was discussed in
the pervious section, might be far less than half the
battle. When it comes to cognition, the portion which
projects onto conscious is just the tip of the iceberg.
Having established what the desired experience is like,
the question becomes: how to make it like that? In
order to serve as the subconscious does, it becomes
necessary to operationalize the attributes and
information resources of the underlying process, at
least at a functional level. HCI has faithfully followed
this trail far from it’s initial focus on the conscious
experience.
Along the way, it (though perhaps
inadvertently) produced computational models that act
as unconscious computational processes.
The details are beyond the scope of this paper, but
the crux of the matter amounts to characterizing the
catch-all notion of context. A preliminary framework
within HCI for such a characterization is provided by
Dey and Abowd (1999).
When it comes to memory,
we are unaware of what contextual cues our
subconscious process might be using to prompt recall.
In HCI mediated memory, the nature of the contextual
cues in the computational process need not be identical

to the ones leveraged by our subconscious, provided
that from a functional perspective they are sufficiently
correlated. For example, content stored on a computer
can be tagged with time of day and date. Unconscious
processes may involve some form of temporal tagging
of memories, but not in the same format.

Conclusions
The authors have identified the emergence of an
implicit C-S metaphor in HCI, which seems more
appropriate to interpret and inform certain contextaware and autonomous agent applications than the
traditional human-human interface metaphor. The C-S
metaphor was inspired by the observation that, from
the perspective of the conscious human experience,
autonomous interface agents (e.g. Lieberman, 1997)
often have attributes in common with subconscious
processes. Most notably they exhibit autonomy, and
the capacity for implicit interaction. Despite the
existence of various applications that fit the bill, to the
authors’ knowledge the C-S metaphor has not been
systematically identified and exploited. Remembrance
Agents (Rhodes & Starner, 1996; Rhodes, 1997) were
the closest encountered approximation in this regard.
In the application of the human-human metaphor to
HCI, fairly operationalized models already existed on
the nature of human-human interaction itself. This is
not so much the case for human C-S interactions. This
situation provides an opportunity for HCI and cognitive
science to mutually inform and give impetus to each
other on the C-S interface issue.
Probing the C-S metaphor fosters greater
appreciation and awareness of the contribution and role
of non-conscious processes in cognition. Newton’s
quote in homage to his predecessors can be aptly
adapted to salute the support structure provided by
actual and simulated subconscious processes.
If I have seen farther, it is because I have stood on
the shoulders of giants.
-- Sir Isaac Newton

References
Block, N. (1995). On a confusion about a function of
consciousness.
From Behavioural and Brain
Sciences, 18, 227-247.
Dey, A. K. & Abowd, G.D. (1999). Towards a better
understanding of context and context-awareness.
GVU Technical Report GIT-GVU-99-22, College of
Computing, Georgia Institute of Technology.
Fodor, J. (1983). Modularity of Mind. Cambridge:
MA, MIT Press.

Hart, J. (1965). Memory and the feeling-of-knowing
experience. Journal of Educational Psychology, 58,
193-197.
James, W. (1910). The Stream of Consciousness. In
Psychology, Chap. XI. New York: Henry Holt and
Co.
James, L. E. & Burke, D. M. (2000). Tip of the
tongue, phonological priming and aging. Journal of
Experimental Psychology: Learning, Memory and
Cognition, 26(6), 1378-1391.
Jackendoff,
R.
(1987).
Consciousness
and
Computation. Cambridge, MA: MIT Press.
Kihlstrom, J. F. (1987). The Cognitive Unconscious,
Science, 237, 1445-1452.
Lieberman, H. (1997). Autonomous Interface Agents.
Proceedings of the ACM conference on computers
and human interface, [CHI-97], New York, NY:
ACM Press.
Lieberman, H. (1995). Letizia: An Agent that assists
web browsing. International Joint Conference on
Artificial Intelligence, August 1995. Montreal: QE.
Minsky, M. (1999). ‘The emotion machine’ from pain
to suffering. Proceedings of the ACM Conference
on Creativity and Cognition, New York, NY: ACM
Press.
Marchionini, G. (1995). Information seeking in
electronic environments.
Cambridge, England:
Cambridge University Press.
Nelson, T. O. & Narens, L. (1990). Metamemory: a
theoretical framework and new findings. The
Psychology of Learning and Motivation, 26, 125141.
Picard, R. W. (1997). Affective Computing. Cambridge
MA: the MIT Press.
Rhodes, B. & Starner, T. (1996). The Remembrance
Agent. AAAI Symposium on Acquisition, Learning
and Demonstrations, Menlo Park, CA: AAAI Press.
Rhodes, B. (1997). The wearable remembrance agent:
a system for augmented memory.
Personal
Technologies Journal Special Issue on Wearable
Computing, 1, 123-128.
Rhodes, B. (2000). Just-In-Time information retrieval.
Doctoral Thesis, MIT, Cambridge, MA.
Stenmark, D. (1997). To search is great, to find is
greater: a study of visualization tools for the web.
Unpublished Manuscript. Retrieved October 12,
2000,
from
the
World
Wide
Web:
http://w3.informatik.gu.se/~dixi/publics.htm

