UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Synfire Chains and Catastrophic Inference
Permalink
https://escholarship.org/uc/item/3pd9s1fk
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Sougne, Jacques P.
French, Robert M.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                           Synfire Chains and Catastrophic Interference
                  Jacques P. Sougn and Robert M. French {J.Sougne, rfrench}@ulg.ac.be
                                      Department of Psychology, University of Li ge
                                                     4000 Li ge, Belgium
                          Abstract                               forgetting patterns of humans, as demonstrated by
                                                                 Barnes & Underwood. This leads to the prediction that
  The brain must be capable of achieving extraordinarily         real neural synfire chains will be forgotten gradually,
  precise sub-millisecond timing with imprecise neural           rather than catastrophically.
  hardware. We discuss how this might be possible using
  synfire chains (Abeles, 1991) and present a synfire chain
  learning algorithm for a sparsely-distributed network of                           Synfire Chains
  spiking neurons (Sougn , 1999). Surprisingly, we show          Empirical data demonstrate the existence of very
  that this learning is not subject to catastrophic              precise temporal behavior in neuron firings. For
  interference, a problem that plagues many standard             example, researchers have recorded spike timing of
  connectionist networks. We show that the forgetting of
  synfire chains in this type of network closely resembles
                                                                 different cortical cells in monkeys (Abeles, 1991, Prut
  the classic forgetting pattern described by Barnes &           & al, 1998) and have observed the following stimulus-
  Underwood (1959).                                              dependent pattern: when an initial neuron, A, fired, a
                                                                 second neuron, B, would fire 151ms later, followed by
                                                                 a third neuron, C, that would fire 289ms later with a
                      Introduction                               precision across trials of 1 ms! Intervals of this
A professional pitcher can send a baseball hurtling              duration require dozens of transmission delays from
towards a batter at speeds approaching 100 miles an              neuron A to neuron C. One of the major hypotheses
hour. In a mere 2 milliseconds the ball moves three              about how this phenomenon could occur involves so-
inches, more than the width of a baseball bat. Given the         called synfire chains. Abeles (1991). The other
long chain of neurons that must fire sequentially with           hypothesis is based on an increase in a population rate,
incredible precision in order for the bat to connect with        which builds excitation in a downstream population,
the ball, how could anyone ever hit a baseball?                  which, in turn, increases its firing rate, etc. (see Shadlen
Consider gymnastics. The landing of a skilled gymnast            & Newsome, 1994). According to Abeles hypothesis,
dismounting from the high bar with a triple somersault           since cortical synapses are relatively weak, many inputs
is completely determined by the millisecond-precise              to cells must arrive at the same time for them to fire.
instant he releases the bar. How is it possible to achieve       Consequently, each step in the synfire chain requires a
the extraordinary timing accuracy necessary to                   significant pool of neurons whose simultaneous firing
consistently hit this beautiful landing correctly?               raises the potential of the next pool of neurons to allow
  The problem is to find a way to make imprecise                 them to fire. Recent experiments (Prut & al, 1998)
neurons act in an extremely precise manner. Nature has           indicate that these precise temporal firing sequences
clearly found a way to circumvent the imprecision of             correlate more to behavior than to rate modulation and
individual neuron firings. The solution seems to rely on         do not seem to be a byproduct of rate modulation. This
the presence of large populations of interacting                 would seem to buttress the synfire chain hypothesis.
neurons. In this paper we will discuss a mechanism for              Previous work on synfire chain learning has focused
achieving precise timing, synfire chains (Abeles, 1991),         on how they can develop from a chaotic net with an
that has received considerable empirical support. We             unsupervised Hebbian learning rule (Bienenstock,
will consider how the brain might learn these synfire            1995; Hertz & Pr gel-Bennet, 1996). These studies
chains and will present a neurobiologically plausibly            involved an external stimulus which makes a large pool
computer simulation of synfire chain learning (see               of neurons fire simultaneously at a particular instant.
Sougn , 2001). Most importantly, we will show that the           Subsequently, a sequence of successive large pools of
problem of catastrophic interference, a problem that             simultaneous neuron firings occurs, produced by the
plagues many types of neural networks (see French,               random connection weights of the network. A given
1999, for a review), does not seem to be a problem for           neuron will only fire if a large enough number of its
synfire chains implemented in a sparsely-distributed             presynaptic neurons provoke an increase of
network of spiking neurons. We simulate the classic              postsynaptic potential simultaneously. Connections are
forgetting experiment of Barnes & Underwood (1959)               modified by a Hebbian learning rule. After learning,
on a network designed to learn synfire chains and show           when the previously learned stimulus is presented
that forgetting of information encoded in these                  again, the same chain fire, thereby constituting a synfire
simulated synfire chains very closely resembles the              chain. These studies show that these chains are stable,

noise tolerant and that one network can store many                                                 simultaneously sensitive to, but not radically disrupted
different chains. Formal analysis showed that there is a                                           by, new input.
relation between network size and the length of                                                       A number of ways have been proposed to avoid the
learnable synfire chains (Bienenstock, 1995), and that                                             problem of catastrophic interference in connectionist
the recall speed should be faster than the training speed                                          networks. In the connectionist network that is our brain,
of the sequence (Sterratt, 1999).                                                                  McClelland, McNaughton & O Reilly (1995) proposed
   In previous modeling work (Sougn , 2001), it has                                                that the dual memory system consisting of our
been shown how a synfire chain can develop, thereby                                                hippocampus and neocortex evolved, at least in part, in
linking two pools of neuron firings caused by two                                                  order to overcome the problem of catastrophic
sequential external stimuli. After learning, the first                                             interference (see also French, 1997).
external stimulus will reactivate the stored synfire                                                  In what follows, however, we hope to show that,
chain. It was also shown that synfire chain learning                                               rather unexpectedly, there is no catastrophic
depends on the size of the network, the presence of long                                           interference in the implemented network of old
term depression (LTD) and the sparseness of                                                        information from newly learned precise firing
connections. It turns out, surprisingly, that these synfire                                        sequence. We will begin by considering a now classic
chains are not subject to catastrophic interference.                                               experiment on human forgetting by Barnes &
                                                                                                   Underwood (1959). We will then show that when this
                       Catastrophic Interference                                                   experiment is simulated for synfire chains in a sparsely
                                                                                                   distributed network of spiking neurons, the forgetting
Gradual forgetting is one of the fundamental facts of                                              curves observed during new learning are largely the
cognition, which means that plausible models of human                                              same as those observed in Barnes & Underwood.
cognition must exhibit progressive forgetting of old
information as new information is acquired. Only rarely
does new learning in natural cognitive systems                                                            Forgetting Caused by New Learning
completely (or catastrophically ) interfere with                                                   Barnes & Underwood (1959) conducted a series of
previously learned information (see, for example,                                                  experiments that measured the extent of retroactive
French & Ferrara, 1999). However, it turns out that for                                            interference in human learning. We will consider two of
a very large class of commonly used connectionist                                                  their experiments in this paper. In the first, subjects first
models      those with a single set of shared (or partially                                        learned a set of paired associates (A-B) consisting of a
shared) multiplicative weights (and most notably,                                                  nonsense syllable and an adjective (e.g. dax paired with
standard feedforward backpropagation networks)                                                     regal, etc.) and then were asked to learn a new set of
learning new information can quite easily completely                                               paired associates (A-C) consisting of the same nonsense
destroy all traces of previously learned information                                               syllables associated with a new set of adjectives (e.g.
(McCloskey & Cohen, 1989; Ratcliff, 1990). In fact,                                                dax paired with dirty, etc.). (This was called the A-B/A-
the very features that give these connectionist models of                                          C paradigm.) The forgetting curve for the A-B associate
memory their much-touted abilities to generalize, to                                               pairs produced by interference from the learning of the
function in the presence of degraded input, etc., are the                                          new A-C pairs was relatively gradual (Figure 1a).
root cause of catastrophic forgetting (See French, 1999,                                              In a second experiment, participants first learned a
for a review of research on catastrophic interference).                                            list of paired associates A-B, as above. Then they were
  Catastrophic interference is a radical manifestation of                                          asked to learn a series of paired associate where the
a more general problem for connectionist models of                                                 second word was very semantically close to the original
memory        in fact, for any model of memory , the                                               I word in the A-B pairs. They called this paradigm the
so-called stability-plasticity problem (Grossberg,                                                 A-B/A-B′ paradigm. See Figure 1b for the results of
1982). The problem is how to design a system that is                                               this second experiment.
 a             1                                                   b 1                                                           c 1
             0.9                                                             0.9                                                           0.9
             0.8                                                             0.8                                                           0.8
             0.7                                                             0.7                                                           0.7
p. Correct                                                      p. Correct                                                    p. Correct
             0.6                                                             0.6                                                           0.6
             0.5                                                             0.5                                                           0.5
             0.4                                                             0.4                                                           0.4
             0.3                                     A-B List
                                                                             0.3                                  A-B List
                                                                                                                                           0.3                                                                    A-B List
             0.2                                                             0.2                                                           0.2
             0.1                                     A-C List                0.1                                  A-B’ List                0.1                                                                    A-C List
              0                                                               0                                                              0
                   1    5         10                       20                      1    5         10                     20
                                                                                                                                                                  11-15   16-20   21-25   26-30   31-35   36-40   41-45   46-50
                                                                                                                                                 0
                                                                                                                                                     1-5   6-10
                       Learning Trials on A-C List                                     Learning Trials on A-B’ List
                                                                                                                                                              Learning Trials on A-C List
             Figure 1, a: Gradual forgetting of previously learned information in Barnes & Underwood’s (1959) A-B/A-C.
             b: Results of the same experiment when the C list closely resembles the original B list (A-B/A-B′ paradigm).
             c: McCloskey & Cohen’s (1989) results showing the network’s catastrophic forgetting A-B/A-C paradigm.

   When connectionist networks began to become               and dendritic delays of real neurons.
widely used as models of human memory, McCloskey                 A signal, whether excitatory or inhibitory, will be
& Cohen (1989) used the Barnes & Underwood A-B/A-            affected by a leakage factor. When the signal has
C paradigm to test forgetting in these networks. It came     reached its maximum, at each following step of 1 ms,
as a considerable surprise to most researchers in the        the signal will be divided by 2. Delays and leakage
field that, at least under certain circumstances,            factors define the Post Synaptic Potential function
McCloskey & Cohen were able to show that forgetting           ε ij ( x ) :
in a standard backpropagation network was anything                                              1
                                                                                 ε ij ( x ) = x H ( x )                     (1)
but gradual. In one set of experiments, for example, a                                         2
standard backpropagation network thoroughly learned a                                                          1if x ≥ 0 
set of one s addition facts (i.e., the 17 sums 1+1                              where: H ( x ) =                         
through 9+1 and 1+2 through 1+9). Then the network                                                            0 if x < 0 
learned the 17 two s addition facts (i.e., 2+1 through       and x is the difference between the time t , the time of
2+9 and 1+2 through 9+2). Recall performance on the          the presynaptic node firing, and the noisy delay on the
originally learned one s facts plummeted as soon as the      connection: x = t - tj(f) - d.
network began learning the new two s addition facts.             When a node potential V i reaches a threshold θ , it
Within 1-5 two s learning trials, the number of correct      emits a spike. Thereafter, the potential is reset to its
responses on the one s facts had dropped from 100% to        resting value. After emitting a spike, a node enters a
20%. In five more learning trials, the one s knowledge       refractory period. This corresponds to the membrane
was at 1%, by 15 trials, no correct answers from the         resistance of real neurons which increases after a spike.
previous one s problems could be produced by the             In INFERNET, the refractory state of node i depends
network. The network had catastrophically forgotten          only on the last spike of the node i: ti(f) . A value
its one s sums. (See Figure 1c).                             dependent on the refractory state is subtracted from the
                                                             node state value Vi. This value is denoted by ηi (u ) ,
                                                             where u is the difference between the current time t and
          Networks of Spiking Neurons                        the time of the last spike of node i: u = t — ti (f) , and
In a network of spiking neurons (Maass & Bishop,             where a and b are constants
                                                             ηi (u) = 1 + e (
1999), nodes can be in two different states: they can fire                       − u a − b) 
(on), or they can be at rest (off). A node fires at a                                         ϑ (u ) θ                     (2)
                                                                                            
precise moment and transmits activation to other
                                                                                       + ∞ ,  if u < 1 
connected nodes with some time course. When a node           where: ϑ (u) =                                 
activation or potential Vi(t ) reaches a threshold, it emits                         1, otherwise
a spike. After firing, the potential is reset to some            Variables affecting the potential of a node have now
resting value Vr. Inputs increase the node potential, but    been defined. Equation (3) express how Vi(t ) i s
some part of the node potential is lost at each time step.   calculated at each time step.
Spiking neuron models, and in particular, INFERNET,                                                      
the network discussed here, use a quite realistic post           ( t )                                  
                                                              Vi = ∑                 ∑      wij ε ij ( x ) − ηi (u)
                                                                                            ˆ
                                                                         j ∈Γ ( f )                                       (3)
synaptic potential (PSP) function.                                          i t
                                                                                  j ∈F j                  
   INFERNET is not a fully connected network; its
structure is organized by clusters of nodes which                Node i fires when its potential Vi(t) reaches the
constitute subnets. Each subnet is fully connected.          threshold Θ . This potential is affected by connection
From each node of a subnet there is a connection to          weights ŵij coming from each presynaptic node j. The
every other node within that subnet. Some subnet nodes       set of presynaptic connections to node i is given by
                                                              Γi = { j j is presynaptic to i} . F j is the set of all firing
have connections to external subnet nodes. This not
only reduces the computational demands of the
program, but also better corresponds to the actual           times of presynaptic nodes j : tj(f). Noisy connection
organization of the brain.                                   weights linking j node to i node are ŵij .
   Two variables affect each connection: weight and
delay. Each weight corresponds to the synaptic strength                                              Learning
between a presynaptic and postsynaptic cell. The
weight between a presynaptic node j and a postsynaptic       Long term potentiation (LTP) and depression (LTD) are
node i is designated by wij. Noise is added to this value    the basic mechanisms of long-lasting modifications of
and the resulting noisy connection is denoted by ŵij .      synaptic efficiency. Hebb (1949) postulated that when
                                                             presynaptic activity coincides with postsynaptic
The delay d of a connection determines when the effect       activity, the connection between both neurons is
of the presynaptic node firing will be maximum on the        strengthened. According to recent experiments, the
postsynaptic node. There is also a noise factor on the       modification of synaptic efficiency depends on precise
delay. This delay corresponds to the axonal, synaptic        timing of afferent signals (neurotransmitters binding to

receptors) and the postsynaptic neuron spike. LTP                                   This requires a large fan out of connections at all levels
seems to require that postsynaptic action potential be                              between the probe nodes and the target nodes.
simultaneous or subsequent to postsynaptic currents                                    The refractory state indicates when a particular node
(Markram et al., 1997; Zhang et al., 1998). In short, when                          fired. We also know the delay of signal propagation
the signal from the presynaptic neuron firing arrives                               from a presynaptic node to a postsynaptic node. From
before, or during the spike of postsynaptic neuron, the                             these two values we can, therefore, detect which
synapse is strengthened (LTP). When the signal from                                 synapse can contribute to a node firing at the right
the presynaptic neuron arrives after the spike of                                   moment. In Figure 3, one can detect which nodes
postsynaptic neuron, the synapse is depressed (LTD).                                contribute to the firing of node g                       i.e., e and f, whose
   In the present model, the plasticity of a synapse wij is                         signals arrive at g virtually simultaneously. If f fired 9
a function of three parameters: the firing time of the                              ms before g , and e fired 11 ms. before g , their
presynaptic neuron: tj(f), the transmission delay between                           respective connections will be strengthened. Similarly,
this firing and its effect on the postsynaptic neuron (dij),                        one can also determine which nodes contributed to the
and the firing time of postsynaptic neuron ti(f). Learning                          firing of f (i.e., d and d′), if d fired 7 ms before f, their
in INFERNET consists of modifying the weights of                                    connection will be strengthened (to a somewhat lesser
connections between nodes wij by a value ˘ wij (weights                             extent because we are farther down the chain). This
are all short integers from -32767 to 32767, which                                  chaining rule acts as if a signal was going backwards
explains why the weight change values run from —                               1024 from the target node to the probe nodes, losing a bit of
to 1024). The Hebbian learning function used is shown                               its strength at each step. In order to reduce
in Figure 2. This function follows empirical studies                                combinatorial explosion, only the n best contributing
(Markram et al., 1997; Zhang et al., 1998). Similar                                 nodes are selected for the next level in this chaining
functions have been used in various simulations by                                  rule. Connections between nodes will be modified
others (Levy & Horn, 1999; Munro & Hernandez, 1999).                                according to equation (4):
                    1000                                                                    time
                      800
                                                                                                                 g Node firing at time 49
                      600                                                                                                     9ms
                      400
                                                    Φ(tj (f) + dij - ti(f))                               11ms
                                                                                                    5ms                            f
                      200                                                                                                                           level 4
              ∆wij      0
                                                                                                          e                    7ms
                                                                                                              5ms
                     -200
                                                                                                                         d         d’               level 3
                     -400
                     -600                                                                               8ms     8ms
                                                                                                                     8ms     9ms       9ms
                     -800
                                                                                                                 c                                  level 2
                   -1000                                                                                                         c’      c’’
                          -15 -10 -5           0           5          10    15                                     11ms
                                                                                                                          9ms
                                    tj(f) + dij - ti (f)                                                    10ms              10ms
                                                                                                               b                                    level 1
  Figure 2: INFERNET’s Hebbian learning function:                                                                          b
                                                                                                      15ms 15ms            ’
  when the signal from the presynaptic neuron arrives                                                               14ms
  before or during the spike of the postsynaptic neuron,
                                                                                                          a    a Nodes firing at time 0
  the synapse is strengthened (LTP); when the signal                                                           ’
  arrives after this spike, the synapse is depressed (LTD).
                                                                                      Figure 3: The chaining rule problem: Learning a path
   The learning algorithm attempts to reproduce the                                   of neural firings that makes node g fire exactly 49
temporal relation between two successive inputs. This                                 ms after nodes a and a′.
is particularly difficult because two successive inputs
can be separated by several tenths of a second and a                                           (                       )
                                                                                     ∆wij = Φ t (j f ) + dij − ti( f ) − λ                                   (4)
single connection cannot alone be responsible for such
                                                                                                                     (                   )
long delays. A long chain of successive pools of node                                             −level if Φ t ( f ) + dij − t ( f ) is negative 
firings is therefore required. This problem is illustrated                          where λ =                         j             i                  
in Figure 3. The problem is linking nodes a and a′ that                                             level otherwise                                   
fire at time 0 with node g firing at time 49. In the
                                                                                       This rule is based on the history of node firing and
learning phase, only nodes a and a′ and g, 49 ms later,
                                                                                    has neurobiological justification. For example,
are externally stimulated. The system has to find a
                                                                                    Markram, et al. (1998) show that the state of a synapse is
chain of node-firings that makes the target node g fire at
                                                                                    indicative of its past activity. Moreover, empirical
time 49 when the probe nodes a and a′ fire at time 0.
                                                                                    studies (Engert & Bonhoeffer, 1997) show that LTP also
The levels shown in Figure 3 are defined by the pools
                                                                                    propagates from the originating synapse to neighboring
of firing nodes that separate the nodes firing in response
                                                                                    synapses, lending further plausibility to the present
to the input probe and the nodes responding to the
                                                                                    chaining rule. In addition, each connection has a small
target. Note that when simultaneous input from enough
                                                                                    decay factor (of —       10 by epoch).
afferent neurons does not occur, the node will not fire.
                                                                                       The learning algorithm is triggered only when
There is therefore a phenomenon of selection of only
                                                                                    external input is presented. We can imagine that
those nodes that have fired due to simultaneous inputs.

external input provides a strong signal that triggers the                 of correct node firings, i.e. the number of B and C
chaining rule. Note that Hebbian learning does not                        node-firings within a –2ms window divided by the total
seem to be dependent on this kind of signal and affects                   number of nodes in B and C words. It is clear that,
probably all synapses downstream from an action                           unlike the catastrophic interference observed in
potential. Here, it is the target input that is the signal to             standard backpropagation networks (see Figure 1c), this
launch the chaining rule. The objective is to link the                    sparsely-distributed network of spiking neurons can
probe nodes firing to the target nodes firing and to                      learn the second set of associations without
avoid reinforcing other irrelevant firings.                               catastrophically forgetting the previously learned list.
                                                                          These results are strikingly similar to those of Barnes &
                                    Simulation 1                          Underwood (Figure 1a).
In general, motor forgetting occurs more slowly than
cognitive forgetting (Globerson, Nahumi, Ellis, 1998).                                                      Simulation 2
By testing the present synfire chain algorithm for                        All of the model parameters for this simulation were
cognitive forgetting,, we reasoned that if catastrophic                   identical to those of the preceding simulation, with the
interference disappeared for this paradigm, the same                      exception that wordlist C was replaced by a wordlist B′.
algorithm would eliminate it for precise motor learning.                  All words in the B′ List were very similar to the
   The following simulation is based on the original                      corresponding words in the B list. Of the 6 nodes used
AB-AC paradigm used in Barnes & Underwood (1959).                         by the representation of each B′ word, 4 of them were
As in the original experiment, we created a list of non-                  shared by the corresponding word in the B List.
words (A) and two associated lists of words (B and                                                  1
C). Each B and C word was coded over 6 nodes (out of                                              0.9
800 possible nodes) and each non-word A was coded                                                 0.8
                                                                                                  0.7
over 16 nodes. Although the selection of nodes was
                                                                                     p. Correct
                                                                                                  0.6
made randomly, we ensured that there was very little                                              0.5
                                                                                                  0.4
overlap among the items in the A-list and among the                                               0.3
items in the B-list. All lists consisted of eight items.                                          0.2                             A-B List
                                                                                                  0.1                             A-B’ List
   Each temporal firing sequence consisted of 16 nodes                                              0
firing at time 0, corresponding to a presentation of a                                                  0    10     20      30     40         50
                                                                                                            Learning Trials on A-B’ List
non-word from list A in the Barnes & Underwood
experiments. Six nodes fired at time 60, triggered by                       Figure 5: INFERNET performing AB-AB′ learning.
the associated word from the B wordlist.
   Once the network had learned to associate the items                      The results, based on 20 runs of the program, are
in list A with those in list B, the network then had to                   shown in Figure 5. Again, this simulation closely
associate the node-firings associated with the items in                   reproduced the experimental results of Barnes &
the A-list with those of the C-list. As in Barnes &                       Underwood s second experiment (see Figure 1b). The
Underwood, we kept the similarity very low between                        results indicate the second associations are learned
the corresponding words in the B and C lists. This                        more quickly and the first associations are almost not
meant that very few nodes overlapped in the encoding                      forgotten, as for humans.
of the corresponding words from the two lists. As the
network learned the new set of associations, we tracked                                                     Conclusions
how fast new learning was taking place (i.e., how close
the output of the network was to the desired word in                      Human learning involves relating two signals separated
List C) and, at the same, time, how far the output was                    in time, or linking a signal, an action and a subsequent
from the originally learned word in List B.                               effect. On occasion, the precise timing of these signals
                                                                          is of critical importance. A millisecond inaccuracy can
                            1
                          0.9                                             mean that the spear thrown by the hunter will miss its
                          0.8                                             target, that the gymnast will miss her landing, etc.
                          0.7
                                                                          Events may often be separated in time, but nonetheless,
             p. Correct
                          0.6
                          0.5                                             humans can link them, if necessary, with extraordinary
                          0.4
                          0.3                                             accuracy, thereby allowing them to correctly perform a
                                                          A-B List
                          0.2
                                                          A-C List
                                                                          particular action at precisely the right moment. We
                          0.1
                            0                                             have explored one major hypotheses concerning how
                                0    10     20      30     40
                                    Learning Trials on A-C List
                                                                     50   the brain might achieve this namely, synfire chains.
                                                                             Clearly people are not born with encodings of this
  Figure 4: INFERNET performing AB-AC learning.                           timing information. Hunters learn to throw projectiles
                                                                          accurately, gymnasts learn to land correctly. Precise
  The results, based on 20 runs of the program, are                       temporal firing sequences must be learnable and permit
shown in Figure 4. The Y axis indicates the proportion                    the linking of two events with extreme precision.

   A learning algorithm based on a Hebbian learning         Hebb, D. O. (1949). The Organization of Behavior.
rule has been presented in this paper. We have briefly        New York: Wiley.
explored the ability of a sparsely-distributed network of   Hertz, J.A., & Pr gel-Bennet, A. (1996). Learning
spiking neurons, INFERNET, to learn synfire chains            synfire chains by self organazation. Network:
and, most importantly, we studied forgetting in this          Computation in Neural Systems, 7, 357-363.
network of these chains. Unlike many current                Levy, N., & Horn, D. (1999). Distributed synchrony in
connectionist networks, we found that the forgetting of       a Hebbian cell assembly of spiking neurons. In
synfire chains is not subject to catastrophic interference,   Advances in Neural Information Processing Systems
but rather, closely resembles the gradual forgetting          11, Cambridge Ma, MIT Press.
curves exhibited in Barnes & Underwood s (1959)             Maass, W., & Bishop, C. M. (1999). Pulsed Neural
paper on human forgetting. This is due to the                 Networks. Cambridge, Ma, MIT Press.
sparseness of the number of paths (compared to the          Markram, H., Gupta, A., Uziel, A., Wang, Y., &
very large number of possible paths) from probe to            Tsodyks, M. (1998). Information processing with
target created by the learning algorithm. We hope to          frequency-dependent synaptic connections.
have demonstrated the importance of synfire chains for        Neurobiology of Learning and Memory, 70, 101-112.
human cognition and to have shown an implementation         Markram, H., L bke, J., Frotscher, M., & Sakmann, B.
in a network of spiking neurons. Finally, and crucially,      (1997). Regulation of Synaptic Efficacy by
our simulations indicate that synfire chains, so              coincidence of Postsynaptic Aps and EPSPs. Science,
necessary for precision actions in the real world, may        275, 213-215.
not be affected by catastrophic forgetting.                 McClelland, J., McNaughton, B., & O’Reilly, R.
                                                              (1995). Why there are complementary learning
                 Acknowledgements                             systems in the hippocampus and neocortex: Insights
                                                              from the successes and failures of connectionist
This research was supported by the Belgian PAI Grant          models of learning and memory. Psychological
p4/19 and the E.C. grant HPRN-CT-1999-00065.                  Review, 102, 419-457.
                                                            McCloskey, M., & Cohen, N. (1989). Catastrophic
                      References                              interference in connectionist networks: The
Abeles, M. (1991). Corticonics: Neural circuits of the        sequential learning problem. In G. H. Bower (ed.)
   cerebral cortex. New-York: Cambridge University            The Psychology of Learning and Motivation: Vol. 24,
   Press.                                                     pp. 109-164, NY: Academic Press
Barnes, J., & Underwood, B. (1959). Fate of first-          Munro, P., & Hernandez, G. (1999). LTD facilitates
   learned associations in transfer theory. Journal of        learning in a noisy environment. In Advances in
   Experimental Psychology, 58, 97-105.                       Neural Information Processing Systems 11,
Bienenstock, E. (1995). A model of neocortex.                 Cambridge Ma, MIT Press.
   Network: Computation in Neural Systems, 6, 179-          Prut, Y., Vaadia, E., Bergman, H., Haalman, I., Slovin,
   224.                                                       H., & Abeles, M. (1998). Spatiotemporal structure of
Engert, F., & Bonhoeffer, T. (1997). Synapse                  cortical activity: Properties and behavioral relevance.
   specificity of long-term potentiation breaks own at        Journal of Neurophysiology, 79, 2857-2874.
   short distances. Nature, 388, 279-284.                   Ratcliff, R. (1990). Connectionist models of recognition
French, R. M. (1997). Pseudo-recurrent connectionist          memory: Constraints imposed by learning and
   networks: An approach to the sensitivity-stability         forgetting functions. Psych. Review, 97, 285-308.
   dilemma. Connection Science, 9, 353-379.                 Shadlen, M. N., & Newsome, W. T. (1994). Noise,
French, R. M. (1999). Catastrophic forgetting in              neural codes and cortical organization. Current
   connectionist networks. Trends in Cognitive                Opinion in Neurobiology, 4, 569-579.
   Sciences, 3, 128-135.                                    Sougn , J. P. (1999). INFERNET: A neurocomputational
French, R. M., & Ferrara, A. (1999). Modeling time            model of binding and inference. Doctoral dissertation,
   perception in rats: Evidence for catastrophic              Universit de Li ge.
   interference in animal learning. In Proceedings of the   Sougn , J. P. (2001). A learning algorithm for synfire
   21 st Annual Conference of the Cognitive Science           chains. In R. M. French, & J. P. Sougn (Eds.)
   Conference. NJ:LEA, 173-178.                               Connectionist Models of Learning, Development and
Globerson, S., Nahumi, A., & Ellis, S. (1998). Rate of        Evolution. pp. 23-32 London: Springer Verlag.
   forgetting for motor and cognitive tasks.                Sterratt, D. C. (1999). Is biological temporal learning
   International Journal of Cognitive Ergonomics, 2,          rule compatible with learning synfire chains?
   181-191.                                                   Proceedings of the Ninth International Conference
Grossberg, S. (1982). Studies of Mind and Brain:              on Artificial Neural Networks.
   Neural Principles of Learning, Perception,               Zhang, L. I., Tao, H. W., Holt, C. E., Harris, W., &
   Development, Cognition, and Motor Control. Boston:         Poo, M. (1998). A critical window for cooperation
   Reidel.                                                    and competition among developing retinotectal
                                                              synapses. Nature, 395, 37-44.

