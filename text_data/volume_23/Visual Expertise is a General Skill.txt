UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual Expertise is a General Skill
Permalink
https://escholarship.org/uc/item/4fr95447
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Sugimoto, Maki
Cottrell, Garrison W.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                      Visual Expertise is a General Skill
                 Maki Sugimoto (mxs@hnc.com)                   Garrison W. Cottrell (gary@cs.ucsd.edu)
                           HNC Software, Inc.                     UCSD Computer Science and Engineering
                      5935 Cornerstone Court West                               9500 Gilman Dr.
                   San Diego, CA 92121-3728 USA                         La Jolla, CA 92093-0114 USA
                            Abstract                           evidence for the plausibility of the domain-general view
                                                               of the FFA.
   The fusiform face area (FFA) in the ventral temporal lobe      In the following sections, we will describe the evi-
   has been shown through fMRI studies to selectively re-
   spond with high activation to face stimuli, and has been    dence for and against the FFA’s face specificity, and our
   identified as a face specific processing area. Studies of   refinement of the domain-general hypothesis. The exper-
   brain-lesioned subjects with face recognition or object     imental methods are then described in detail followed by
   recognition deficits also have often been cited as evidence the results. We conclude by summarizing our findings
   for face specific processing. Recent studies, however,
   have shown evidence that the FFA also responds with         and suggesting future research.
   high activation to a wide variety of non-face objects if
   the level of discrimination and the level of expertise are  Evidence for the Face Specificity of the FFA
   controlled. Based on these recent results, we hypothe-      Studies of brain-lesioned subjects provide the strongest
   sized that the features of faces that the FFA respond to    evidence for localized face specific processing. Pa-
   can be useful for discriminating other classes of visu-
   ally homogeneous stimuli with some tuning through ex-       tients with associative prosopagnosia reportedly have
   perience. To test our hypothesis, we trained two groups     deficits in individual face identification, but are normal
   of feed-forward neural networks on visual classification    in face detection and object recognition (Farah, Levin-
   tasks. The first group was pretrained on basic level clas-  son & Klein, 1995). On the other hand, patients with
   sification of four stimulus classes, including faces. The
   second group was pretrained on subordinate level clas-      visual object agnosia are normal in identifying individ-
   sification on one of the stimulus classes and basic level   ual faces but have deficits in recognizing non-face ob-
   classification on the other three. In two experiments that  jects (Moscovitch, Winocur & Behrmann, 1997). The
   used different criteria to stop pretraining, we show that   two groups of patients serve as evidence for a double dis-
   networks that fully acquire the skill of subordinate level  sociation of visual processing of faces and other objects.
   classification consistently show an advantage in learning
   the new task.                                                  Through fMRI studies of normal brains, the FFA
                                                               has been identified as the area being most selec-
                                                               tive to faces (Kanwisher, McDermott & Chun, 1997).
                        Introduction                           Prosopagnosia patients usually have a lesion in an area
The functional role of the so-called fusiform face area        encompassing the FFA (De Renzi et al., 1994), providing
(FFA) located in the ventral temporal lobe is controver-       consistent evidence for the face specificity of the FFA.
sial. The FFA has been shown in fMRI studies to respond
with high activation to face stimuli but not to other visual   Evidence against the Face Specificity of the FFA
object stimuli, and has thus been identified as a face spe-    Gauthier and colleagues argued that the FFA showed
cific processing area (Kanwisher, 2000). Studies of pa-        high activity in response to various classes of visual stim-
tients with face recognition or object recognition deficits    uli when the levels of discrimination and expertise were
also have often been cited as evidence for face specific       properly controlled (Gauthier et al., 1999a). One study
processing. Recent studies by Gauthier and colleagues          showed significantly high activity of the FFA for car and
have questioned whether the FFA is really a face-specific      bird experts when stimuli from their respective expert
area (Gauthier, Behrmann & Tarr, 1999a). They have             class were presented (Gauthier et al., 2000). Another
proposed an alternative theory that the FFA engages in         study that utilized 3-D artificially rendered models called
expert level classification of visually similar stimuli from   “Greebles” (Gauthier & Tarr, 1997), showed the FFA in-
a wide variety of categories not limited to faces.             creasing its activation in response to the rendered mod-
   The current study is an attempt to shed light on the de-    els as the subjects were trained to classify them at a fine
bate through simulations of computational models. We           level (Gauthier et al., 1999b). For the latter study, the
constructed our hypothesis based on the recent view that       use of the Greebles allowed the authors to develop hu-
the FFA is a domain-general processing area, special-          man subject experts of non-face objects while fully con-
izing in visual expertise of fine level discrimination of      trolling the subjects’ experience with the stimuli.
homogeneous stimuli. Our experimental results show                These results showing high activity of the FFA for
strong support for the hypothesis, thus providing further      non-face objects including completely novel objects,

 serve as strong evidence against the face specific view
 of the FFA.
 Our Approach with Computational Models
 Why does the FFA engage in expert classification of non-
 face objects? We hypothesized that the features of faces
 that the FFA responds to can be useful for discriminat-
 ing any class of visually homogeneous stimuli with some
 tuning through experience. If our hypothesis is correct,
 possession of expertise with faces should facilitate the    Figure 1: Example of face and common object images
 expert level learning of other classes. In this paper, we
                                                             (Dailey & Cottrell, 1999)
 consider individuating members of a homogeneous class
 (subordinate classification) to be an expert level task.
    To test our hypothesis, we trained two groups of neu-
 ral networks with hidden layers to perform a subordinate
 level Greeble classification task. Prior to training on the
 Greebles, we pretrained the networks on one of the fol-
 lowing two tasks:
                                                             Figure 2: Example of Greeble images;The left two are
1. Basic level classification of faces and objects           images of the same Greeble
2. Subordinate level classification of one of the classes
    and basic level classification of the rest               Preprocessing
                                                             To preprocess the images, we followed the procedures
 Developing the first visual expertise for non-face objects
                                                             introduced by Dailey and Cottrell (1999), applying Ga-
 is one of the conditions that cannot be ethically achieved
                                                             bor based wavelet filters and using principal component
 in human experiments. Our computational model at-
                                                             analysis (PCA) for dimensionality reduction.
 tempts to overcome this limitation by pretraining neural
                                                                2-D Gabor wavelet filters, which are relatively robust
 networks on subordinate classification of non-face ob-
                                                             to variations in background, translation, distortion and
 jects. If the advantage can be observed for all groups of
                                                             size (Lades et al., 1993), have been used previously for
 networks with various pretraining tasks, we would con-
                                                             face recognition tasks with neural networks. Each im-
 clude that the features that are discriminative of homo-
                                                             age was represented by the magnitude of the responses
 geneous visual stimuli in general are robust features that
                                                             of 40 filters tuned to 8 orientations and 5 spatial frequen-
 translate well to any other class of stimuli.
                                                             cies, measured at 64 points subsampled in an 8x8 grid,
                                                             resulting in a vector of 2560 elements (Buhman, Lange
                Experimental Methods                         & von der Malsburg, 1990; Dailey & Cottrell, 1999).
 As described briefly in the previous section, we trained       PCA was done separately on each spatial frequency,
 neural networks on subordinate level classification with    extracting 8 components for each of the 5 scales to form
 various pretraining tasks. In this section, we will de-     40-dimensional input vectors. Each element of the in-
 scribe further details on the input database, the prepro-   put vectors were normalized across all face/object im-
 cessing procedure, network configurations and the simu-     ages by z-scoring, i.e., a linear transformation to mean 0
 lation procedures.                                          and standard deviation 1. The Greeble patterns were not
                                                             represented in the principal components to prevent any
 Image Database                                              knowledge of the Greebles contaminating the model.
 The images were 64x64 8-bit grayscale images consist-
 ing of five basic classes: human faces, books, cans, cups,  Network Configuration
 and Greebles. Each class included 5 different images of     Standard feed forward neural networks with a 40-unit
 12 individuals, resulting in a total of 60 images for each  hidden layer were used for all the experiments. The hid-
 class. Example images are shown in Figure 1 and 2. The      den layer units used the logistic sigmoid function while
 non-Greeble images are described elsewhere (Dailey &        the output units were linear. The learning rate and mo-
 Cottrell, 1999). For the Greebles, the 12 individuals were  mentum were .005 and .5, respectively. These parame-
 selected exclusively from one of the five families. Five    ters were tuned so that the networks reliably learned the
 images were obtained for each individual by performing      most difficult task, which was the subordinate level clas-
 random operations of shifting up to 1 pixel vertically and  sification on faces and Greebles with basic level classifi-
 horizontally, and rotating up to 3 degrees clockwise or     cation on the common objects.
 counterclockwise in the image plane. A region from the
 background of the common object images was randomly         Training Set Variations
 extracted and applied to the background of the Greeble      Each network was trained on a subset of the whole data
 images.                                                     set as follows. For the classes on which subordinate level

 classification were performed, one image for each indi-      The first criterion controls the networks’ familiarity with
 vidual was randomly selected to test generalization. An-     the input data with respect to their given tasks. This cri-
 other image was removed to be used as the holdout set        terion is partly motivated by Gauthier et al.’s definition
 (for early stopping) from the rest of the images, resulting  of experts that takes into account not only the classifica-
 in a reduced training set of 3 images per individual.        tion accuracy but also the response time which reflects
    For the classes on which basic level classification were  the subjects’ degree of certainty. Response time is often
 performed, images of one randomly selected individual        modeled in neural networks by the RMSE on a pattern.
 were reserved for testing. Images of a different individ-    The second criterion controls the number of opportuni-
 ual were used as the holdout set, resulting in a reduced     ties the networks can learn from the input. Employing
 training set of images of 10 individuals.                    this criterion corresponds to the idea of controlling the
    With the arrangements mentioned above, 3 images of        subjects’ experience with their tasks, which is often dif-
 12 individuals were available for use as the training set    ficult to control in human subject experiments.
 for the subordinate level classification task and 5 images      For the Greeble phase, the networks were trained to a
 of 10 individuals were available for the basic level task.   fixed RMSE threshold for both experiments.
 In order to control the number of images presented to           Provided that the networks adequately learned the pre-
 the networks during the training, the training set was re-   training task in the pretraining phase, any difference in
 stricted to 3 images from 10 individuals for both levels     the learning process of the new task (in the second phase)
 of classification, for a total of 30 images for each class.  between the Non-experts and the Experts must be due to
    In the experiments reported below, we do not use the      the differences in the pretraining task. For the first exper-
 holdout and test sets, as we use RMSE thresholds and         iment, we set the pretraining RMSE threshold to 0.0806.
 amount of training as conditions for stopping training       This threshold value was determined through prelimi-
 phases. The holdout and test sets are used in prelimi-       nary experiments by estimating the training set RMSE
 nary experiments to find appropriate values of the RMSE      for the face expert task to be learned without overfitting.
 thresholds.                                                  For the second experiment, the epoch limits ranged over
                                                              5  2n with n 2 0 1 :: 10 to fully analyze the effect of the
 Task Variations                                              pretraining task differences. We set the RMSE threshold
 Training of the neural networks was done in two phases.      for the second (Greeble) phase to 0.158. This was de-
 In the first phase, the pretraining phase, the networks      termined from similar preliminary experiments based on
 were trained using only the face/common object data on       the estimated optimal RMSE on the most difficult task,
 one of the following two tasks:                              subordinate level classification on faces and Greebles.
1. Basic level classification on all 4 input categories       Evaluation
2. Subordinate level classification on 1 category and ba-     For the two experiments, we compared the number of
    sic level on the rest.                                    epochs required to learn the new task for the Non-experts
                                                              and the Experts. For experiment 1, we trained 20 net-
 The networks that were assigned the first task had 4 out-    works with different initial random weights for all 5 pre-
 puts, corresponding to book, can, cup, and face. We will     training tasks, for a total of 100 networks. For experi-
 refer to these networks as “Non-experts”.                    ment 2, we trained 10 networks with different initial ran-
    The networks that were assigned the second task had       dom weights for all 5 pretraining tasks for 5120 epochs.
 13 outputs; 3 for the basic level categories and 10 for the  We stored the intermediate weights of each network at 10
 individuals in the subordinate level. For example, if a      different intervals ranging over 5 to 2560 epochs, train-
 network was assigned a subordinate level classification      ing a total of 550 networks in the second phase.
 task for cans and basic level for the rest, the output units
 corresponded to book, cup, face, can 1, can 2, can 3, etc.                              Results
 We will refer to these networks as “Experts”.
    In the second phase, the pretrained networks were         Experiment 1: Fixed RMSE Criterion
 trained on a subordinate level classification task of in-    Pretraining
 dividuating Greebles in addition to the pretrained task.     Figure 3 shows the number of training epochs for the two
 Greebles were included in the input data set and 10 out-     phases averaged across the 20 networks for each pre-
 put units corresponding to each Greeble were added.          training condition. The Non-experts required a much
 Thus, the networks performed either a 14-way or a 23-        shorter training period than all the expert networks for
 way classification depending on their pretrained task.       the pretraining phase, reflecting the ease of basic level
    We ran two sets of experiments using different criteria   classification. For the second phase, the Non-experts
 to determine when to stop pretraining:                       were significantly slower than all the Experts in learn-
 Experiment 1 The networks were trained until the             ing the new task (p  0:001, pairwise comparison be-
    training set RMSE dropped below a fixed threshold.        tween Non-experts and the face, can, cup, book experts
                                                              with t 38 = 7:03 5:74 14:69 10:76, respectively). The
 Experiment 2 The networks were trained for a fixed           difference between the can experts and the face experts
    number of epochs.                                         was insignificant (t 38 = 1:20 p  0:2), the face experts

                                                                                                                        1e-00
                           400
                                                                                                                        1e-01                                           Pretraining
                                                                                                                                                                        expert task
        Number of Epochs
                           300
                                                                                                                                                                               None
                                                                                                RMSE
                                                                         Pretraining                                                                                           Face
                                                                         New Task                                       1e-02                                                  Can
                           200                                                                                                                                                 Cup
                                                                                                                                                                               Book
                           100                                                                                          1e-03
                             0                                                                                          1e-04
                                 None   Face     Can       Cup    Book                                                          10          100              1000
                                        Pretraining Expert Task                                                                           # pretraining epochs
Figure 3: Number of epochs to reach the RMSE thresh-                                      Figure 4: Learning curve for the pretraining phase
old. Error bars denote standard error.
                                                                                                                        600
Table 1: Training set accuracy for just the Greebles. Fig-
ures in parentheses denote standard error.                                                                              500
    Expert task Greebles training set accuracy(%)
                                                                                                #after new task added
                                                                                                                                                                                 None
    Non-expert                71.2 (2.00)                                                                               400                                                      Face
                                                                                                                                                                                 Can
        Face                  93.5 (1.17)                                                                                                                                        Cup
                                                                                                                                                                                 Book
        Can                   95.2 (1.04)                                                                               300
        Cup                   89.8 (2.00)
        Book                  88.8 (1.46)                                                                               200
                                                                                                                                     10        100               1000
                                                                                                                                          # pretraining epochs
were slower than the book experts (t 38 = 3:08 p 
0:005), and the book experts were slower than the cup                                  Figure 5: Number of epochs to learn the new task. Error
experts (t 38 = 3:22 p  0:005).                                                    bars denote standard error.
   Table 1 shows that despite the overall RMSE having
been controlled, the Non-experts were still non-experts at
Greebles after training on them. Further training on the
Non-experts would have widened the gap between train-                                  the second phase are fully determined by the learnabil-
ing times on the Greebles for Experts and Non-experts                                  ity of the newly added task. If the pretraining stopped
even more. On the other hand, for the Experts, there was                               prematurely, however, the networks must improve their
a positive correlation between the training set accuracy                               performance on the prior task as well as the newly added
and the number of training epochs, suggesting the differ-                              task to achieve the second phase RMSE threshold. All
ences in training epochs between the Experts would have                                of the networks that were pretrained for at least 1280
narrowed if the training set accuracy on the newly added                               epochs achieved a pretraining RMSE that was an order of
task had been controlled. Being an expert on some task                                 magnitude lower than the second phase RMSE threshold.
prior to learning another expert task was clearly advanta-                             Therefore, the advantage that Experts with this amount
geous.                                                                                 of pretraining gained must be due solely to their perfor-
                                                                                       mance in learning the new task.
Experiment 2: Fixed Exposure Pretraining                                               Analysis: Network Plasticity We hypothesized that
                                                                                       the advantage of learning a fine-level discrimination task
Not surprisingly, the Non-experts maintained lower
                                                                                       would be due to greater plasticity in the hidden units.
RMSE than all the Experts during the pretraining phase
                                                                                       That is, we expected the activations of the hidden units to
(Figure 4). Among the four groups of expert networks,
                                                                                       end up in the linear range of the squashing function in or-
the face experts had the most difficult pretraining task,
                                                                                       der to make the fine discriminations. This is also a good
followed by the can experts, book experts, and finally
                                                                                       place to be for back propagation learning, as the higher
cup experts.
                                                                                       the slope of the activation function, the faster learning oc-
   For the secondary task training, there was a crossover                              curs. We therefore analyzed how the features extracted at
in effects at 1280 epochs: Fewer epochs meant the non-                                 the hidden layer were tuned by measuring the plasticity
Experts had an advantage; more meant Experts had an                                    (average slope) of the pretrained networks. Our findings
advantage (Figure 5). If the networks were pretrained                                  surprised us.
long enough, the improvement on the error for the pre-
trained portion of the task became negligible compared                                   We defined a network’s plasticity as the value of the
to the error due to the newly added task. In this case, we                             derivative of the activation function at the activation level
can safely argue that the epochs of training required in                               averaged across all hidden layer units and all patterns in

                                                                                               Pretrained categories               Newly added category
a given set of input patterns:                                              0.24
                           1     1
                           N s∑    ∑ g0 xsi 
                                                                            0.22
                  PS =
                              2S n i2I
                                                                                                                                                          None
                                                               plasticity
                                                                                                                                                          Face
                                                                             0.2                                                                          Can
                                                                                                                                                          Cup
                                                                                                                                                          Book
where gx is the activation function, S a set of patterns,                 0.18
N the number of patterns in S, I the set of hidden layer
units, n the number of hidden layer units, and xsi the ac-                  0.16
tivation of unit i in response to pattern s. In the online                         10        100               1000    10        100               1000
backpropagation learning rule, g0 x scales the weight
                                                                                        # pretraining epochs                # pretraining epochs
changes of the hidden layer units with respect to the er-                          Figure 6: Plasticity of the pretrained networks
rors computed for the output layer. The plasticity of neu-
ral networks is usually taken to be predictive of the abil-
ity to learn new tasks (Ellis & Lambon Ralph, 2000).
                                                                            retained their plasticity better than all Experts. As we
   As the activation function, all the hidden layer units in                saw in the previous section, however, it was the Experts
our neural networks used the logistic sigmoid function:                     that eventually showed an advantage in learning the new
                                   1                                        task. All Experts learned the new task faster as they
                              1 + exp,x
                    gx =                                                  rapidly lost plasticity over pretraining time. Normally,
                                                                            we would expect the Experts to be generally poorer in
                                                                            learning new tasks due to their low plasticity. These
where x is the weighted sum of the inputs, or the inner
                                                                            results imply that the advantage the Experts gained in
product of the input vector ~z and the weight vector ~w:
                                                                            learning the Greebles task cannot be explained as part of
                           x  ~z  ~w:                                     a general capability of learning new tasks. Instead, it is
                                                                            more appropriate to interpret this to mean that the hidden
The first derivative of gx can be written as                              unit features were well-matched to the new task.
                                                                               The lower plasticity of the Experts for the pretrained
                     exp,x                                                data implies that the Experts had to finely tune their fea-
       g0 x =
                          ,x2
                  1 + exp
                                     = gx1    , gx:                   tures to fit their respective expert category, while the
                                                                            Non-experts did not require fine tuning of the features
For x 2 ∞ ,∞, gx ranges over 0 1 and g0 x over                    to achieve the lower errors. The eventual advantage of
0 0:25. g0 x is a bell-shaped function with a global                   the Experts can then be explained in terms of the fea-
maximum at g0 0 = 0:25. By our definition of plastic-                     tures tuned for the expert tasks matching the Greebles
ity, the networks that produce intermediate responses at                    data set as well. Given the strong trend regardless of the
the hidden layer level would have higher plasticity than                    domain of expertise, we claim that the features useful for
networks with bimodal responses. Networks with higher                       one subordinate classification task are general expert fea-
plasticity are generally more likely to learn new tasks                     tures that are good for discriminating individuals of other
faster since the hidden layer units would change their                      classes as well. Although other uncontrolled factors such
weights more rapidly in response to the errors propagated                   as the length of the weight vectors can influence the plas-
from the newly added output units.                                          ticity of a network, they seem unlikely to explain our ex-
   Network plasticity can also be considered as a mea-                      perimental results.
surement of mismatch between the hidden layer weights                       Experiment 2 Summary For longer pretraining
and the input patterns. If the input patterns and the                       epochs, the Non-experts took longer than any of the Ex-
weights were orthogonal, x would be near 0, resulting                       perts to reach the final RMSE after the new task was
in maximal plasticity. If, however, the weights tuned for                   added. While we would expect the Experts to have
some task matched the input patterns of a new stimulus                      higher plasticity given their advantage in learning the
class, jxj would have a larger value resulting in lower                     new task, it was the Non-experts that retained higher
plasticity. The issue is whether these features will be ad-                 plasticity. A comparison between Experts within each
vantageous for learning the new stimulus class. When a                      task also showed that the networks with longer pretrain-
network with a low plasticity (high match) measured on                      ing and lower plasticity learned the new task faster. The
novel patterns learns faster on those patterns than a net-                  results regarding network plasticity led us to interpret
work with higher plasticity, this suggests that the highly                  plasticity as a measurement of mismatch specific to a
matched features are efficacious for classifying the new                    given set of patterns, rather than a predictor of the abil-
stimuli.                                                                    ity to learn arbitrary new tasks. Given these results, we
   Figure 6 shows the plasticity of the pretrained net-                     claim that the underlying cause for the advantage gained
works in response to the training set used for the pretrain-                by the Experts is the generality of the hidden layer fea-
ing and to the set of new patterns which would be added                     tures, fitting well with the subordinate classification task
into the training set for the second phase. For both the                    of other classes. This is remarkable in that overtraining
pretrained patterns and the unseen patterns, Non-experts                    on a prior task facilitates learning the new one.

                       Conclusion                              Dailey, M. N. and Cottrell, G. W. (1999). Organization
Based on the recent studies that showed FFA’s engage-                of face and object recognition in modular neural
ment in visual expertise of homogeneous stimuli is not               network models. Neural Networks, 12(7–8):1053–
limited to faces, we hypothesized that the features useful           1074.
for discriminating individual faces are useful for the ex-     De Renzi, E., Perani, D., Carlesimo, G., Silveri, M., and
pert learning of other classes. Both of our experiments              Fazio, F. (1994 ). Prosopagnosia can be associated
yielded results in favor of our hypothesis. Furthermore,             with damage confined to the right hemisphere — An
while faces had a tendency to show the greatest advan-               MRI and PET study and a review of the literature.
tage, the results were replicated with networks whose ex-            Psychologia, 32(8):893–902.
pertise was with other stimulus classes, including cups,
cans and books.                                                Ellis, A. and Lambon Ralph, M. (2000). Age of acquisi-
   The results of the two experiments showed that the                tion effects in adult lexical processing reflect loss of
possession of a fully developed expertise for faces or               plasticity in maturing systems: Insights from con-
non-face objects is advantageous in learning the subordi-            nectionist networks. Journal of Experimental Psy-
nate level classification of Greebles. Contrary to our ex-           chology: Learning, Memory & Cognition, 26(5).
pectation that expert networks would show greater plas-
ticity, analyses of network plasticity for Experiment 2        Farah, M. J., Levinson, K. L., and Klein, K. L. (1995).
showed that plasticity decreased for the expert networks             Face perception and within-category discrimination
over time, and it was lower than for non-Expert net-                 in prosopagnosia. Neuropsychologia, 33(6):661–
works. Indeed, the lower the plasticity, the less time it            674.
took to learn the new task. By reinterpreting low plastic-
                                                               Gauthier, I., Behrmann, M., and Tarr, M. J. (1999a). Can
ity to mean ”high match,” we take these results to mean
                                                                     face recognition really be dissociated from object
that the features being learned not only match the Gree-
                                                                     recognition? Journal of Cognitive Neuroscience,
ble stimuli well, but also are the right features for fine
                                                                     11:349–370.
discrimination of Greebles. Since the choice of Gree-
bles for the second experiment was arbitrary, this sug-        Gauthier, I., Skudlarski, P., Gore, J. C., and Anderson,
gests that learning to discriminate one homogeneous vi-              A. W. (2000). Expertise for cars and birds recruits
sual class leads to faster learning in discriminating a new          brain areas involved in face recognition. Nature
one. Therefore, we conclude that visual expertise is a               Neuroscience, 3(2):191–197.
general skill that translates well across a wide variety of
object categories.                                             Gauthier, I. and Tarr, M. (1997). Becoming a “greeble”
                                                                     expert: Exploring mechanisms for face recognition.
Future Work                                                          Vision Research, 37(12):1673–1682.
Firm believers in the face specificity of the FFA might        Gauthier, I., Tarr, M. J., Anderson, A. W., Skudlarski,
insist that it must be shown that individual neurons in              P., and Gore, J. C. (1999b). Activation of the mid-
the FFA can simultaneously code features for multiple                dle fusiform “face area” increases with expertise in
classes of objects in order their theory to be rejected              recognizing novel objects. Nature Neuroscience,
(Kanwisher, 2000). Even with the advances in brain                   2(6):568–573.
imaging technology, monitoring each neuron in the FFA
is infeasible. Simulations with computational models,          Kanwisher, N. (2000). Domain specificity in face per-
however, allow us to monitor the behavior of every single            ception. Nature Neuroscience, 3(8):759–762.
unit in the network.
   Naturally, then, one possible extension of the current      Kanwisher, N., McDermott, J., and Chun, M. M. (1997).
research is to investigate in detail what the hidden layer           The fusiform face area: A module in human extras-
units in the expert networks are encoding. Although our              triate cortex specialized for face perception. Journal
experimental results seem to suggest there are features              of Neuroscience, 17:4302–4311.
that are useful for visual expertise of any object classes, it
                                                               Lades, M., Vorbrüggen, J. C., Buhmann, J., Lange, J.,
is unclear exactly what those features are. Visualization
                                                                     von der Malsburg, C., Würtz, R. P., and Konen, W.
of these expert features would help understand how we
                                                                     (1993). Distortion invariant object recognition in
develop visual expertise.
                                                                     the dynamic link architecture. IEEE Transactions
                                                                     on Computers, 42(3):300–311.
                       References
Buhmann, J., Lades, M., and von der Malsburg, C.               Moscovitch, M., Winocur, G., and Behrmann, M. (1997).
      (1990). Size and distortion invariant object recog-            What is special about face recognition? Nineteen
      nition by hierarchical graph matching. In Proceed-             experiments on a person with visual object agnosia
      ings of the IJCNN International Joint Conference               and dyslexia but normal face recognition. Journal
      on Neural Networks, volume 2, pages 411–416,                   of Cognitive Neuroscience, 9(5):555–604.
      New York. IEEE.

