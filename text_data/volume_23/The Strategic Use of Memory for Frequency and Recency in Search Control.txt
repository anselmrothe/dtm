UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Strategic Use of Memory for Frequency and Recency in Search Control
Permalink
https://escholarship.org/uc/item/8ph031vj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Howes, Andrew
Payne, Stephen J.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                        The Strategic Use of Memory for
                                Frequency and Recency in Search Control
                                         Andrew Howes (HowesA@cardiff.ac.uk)
                         School of Psychology, Cardiff University, Cardiff, CF10 3YG, Wales, UK
                                        Stephen J. Payne (PayneS@cardiff.ac.uk)
                         School of Psychology, Cardiff University, Cardiff, CF10 3YG, Wales, UK
                            Abstract                               One might expect that these are issues of such
                                                                fundamental importance that they must have been
   A requirement of an information processing account of        solved or at least addressed by the two substantial
   human problem solving is that it includes a mechanism        architectural accounts of cognition (ACT-R, Anderson,
   by which people remember which goals and operators           1998; Soar, Newell, 1990), but in fact it is an issue that
   have been evaluated and which still need to be evaluated.    is glossed in both.            In Soar, the architecture
   One might expect that these are issues of such               automatically ensures that operators that have already
   fundamental importance that they must have been solved       been applied to a particular state in pursuit of a
   or at least addressed by the two architectural accounts of
                                                                particular goal (on the goal stack) on a particular trial
   cognition (Soar and ACT-R), but in fact it is an issue that
   is glossed in both. We identify two problems: (1) Soar
                                                                will not be reselected. In ACT-R the goal stack has
   and ACT-R guarantee information about goals, and (2)         privileged status. Items posted on the stack are not
   ACT-R combines measures of frequency and recency             subject to the constraints of memory, i.e. they do not
   into a single representation of activation. In this paper we have decaying activation and cannot therefore be
   report a model of how people search simple binary trees.     forgotten (Altman and Trafton, 1999).
   The model demonstrates the cognitive plausibility of a          Another resource for supporting decisions about
   search algorithm that is supported by a memory system        which operator to apply is memory for previous
   that delivers independent estimates of frequency and         attempts at a goal (either successful or failed). If a goal
   recency.                                                     has been achieved prior to the current attempt then
                                                                memories that indicate that an operator is familiar may
                         Introduction                           be taken as evidence that it is more likely to lead to the
   A requirement of an information processing account           goal than an unfamiliar operator (Payne, Richardson,
of human problem solving is that it includes a                  Howes, 2000). However, an issue for the problem
mechanism by which people remember which goals and              solver is how to determine the source of the familiarity.
operators have been evaluated and which still need to           If the source is the current trial then the operator should
be evaluated. Whether the task is the Tower of Hanoii,          be rejected, if it is a previous trial then perhaps it should
a waterjugs problem, a world-wide web search problem            be selected.
or a spatial navigation task, a person engaged in search           Payne, Richardson, Howes (2000) investigated the
examines the consequences of applying an operator to a          role of familiarity (Jacoby, 1991) in controlling
state by trying it out and perceiving to which state it,        interactive search. They tested the hypothesis (Aasman
and subsequent operators, lead. At some point in the            & Akyurek, 1992; Howes, 1994) that people help
future, the person may, through backup, or because of           control search merely by recognising the actions that
loops, find themselves in a visited state. Recognition          have been tried before and found that the familiarity of
that the state has already been visited and/or that the         items could affect decisions about which item to select.
operator has already been applied to this state, will in        Moreover familiarity was used strategically. When
the long-term help prune the search space and thereby           participants had information indicating that familiarity
constrain the effort spent on attaining the goal. This          would be more likely to indicate that an operator would
constraint has been used in a number of models of               lead to the goal, they were more likely to use familiarity
human problem solving (Atwood & Polson, 1976;                   to guide selection.
Jeffries, Polson., Razran, & Atwood, 1977; Anderson,               Again, one might expect that this issue would have
1993; Howes, 1994). Atwood & Polson's model of                  been addressed in architectural theories of cognition.
human performance on the waterjugs problem, built up            However, while Soar’s chunking mechanism is flexible,
a representation of the 'familiarity' of states that was        the issue of whether it can provide a mechanism for
factored into the operator selection process. The more          representing the episodic familiarity of an operator has
familiar an operator then the less likely it was to be          only recently started to be explored (Altmann and John,
selected.                                                       1999). The situation for ACT-R is more complex.

                               40
                               35
                               30
      Mean number of actions
                                                                                                  participants(high)
                               25
                                                                                                  participants(low)
                               20
                               15
                               10
                                5
                                0
                                    1         2         3         4        5            6        7            8        9      10
                                                                               Trial
                                        Figure 1: Mean number of actions taken by high and low systematicity participants
   In ACT-R, each chunk stored in declarative memory                                   makes strategic use of frequency and recency
has an activation that is used to determine probability of                             information and demonstrates the cognitive plausibility
retrieval. This activation is made up of a base-level                                  of a search algorithm that is supported by a memory
activation and an associative activation. Anderson and                                 system that delivers independent estimates of frequency
Lebiere (1998; page 70) state: “... the activation of a                                and recency.
chunk is a sum of the base-level activation, reflecting
its general usefulness in the past, and an associative                                                             Task
activation, reflecting its relevance to the current                                       In a series of studies to be reported elsewhere we
context,” and, “The base-level activation of a chunk                                   observed participants searching simple binary word-
represents how recently and frequently it is accessed.”                                mazes. Each maze was a binary tree structure with a
   Importantly however, the frequency and recency                                      depth of 5 nodes. At each choice point participants
components of base-level activation are not                                            were presented with three buttons on a computer
independently inspectable by the production rules and it                               display. Two buttons at the top and bottom of the right
is not therefore possible to write ACT-R production                                    of the screen were labelled with different words
rules that make strategic use of frequency and recency                                 (perhaps ‘gun’ and ‘pistol’) and the other button, on the
information stored as components of chunk activations.                                 left of the screen, was labelled ‘back’. Selection of one
It seems unlikely therefore that it is possible to write                               of the two buttons on the right changed the current state
productions that, for example, prefer the most frequent                                to a state nearer to the leaves of the tree and selection of
operators at the expense of the most recent.                                           ‘back’ moved the state to a node nearer the root of the
   A commonly used solution to this in ACT-R models                                    tree. Participants were asked to search for a leaf node
has been to use flags on declarative memory structures.                                with a given label (a random word).
A flag is added to operators that have been applied on
this trial and then all flags are wiped at the end of the                              Observations:
trial (Anderson's model of navigation 1993; Lebiere,
personal communication) leaving no episodic evidence                                        •   All participants were able to complete these
that they had ever been there. While, this is an extra-                                         search tasks.
architectural mechanism that, unsurprisingly, is not                                        •   Three strategies were used:
claimed as part of the theory, its use undermines the                                           o Random search with a forward bias.
claim that models constructed in ACT-R are subject to a                                           Participants selected either the top or the
principled set of memory constraints.                                                             bottom button on the right of node X,
   In this paper we report a computational level model                                            searched the subtree and then on returning to
of how people search simple binary trees. The model                                               X selected the other button.

          o Systematic search. Participants always
            selected the top button on the first visit to        •    F = frequency( I ) - returns an estimate of the
            node X, searched the subtree, and then on                 frequency F of item I.
            return to X selected the bottom button.              •    X = most_recent( P ) - Instantiates pattern P
          o Memory-based search. On trials after the                  to its most recent occurrence.                (e.g.
            first participants generally attempted to                 most_recent( op ) would bind X to the most
            remember the correct path.                                recently tried operator). Only one value can be
      •   On trials after the first, participants flexibly            returned for a particular P.
          interleaved search based on memory for                 •    F = freq_before( I, E ) - returns the frequency
          previous trials with, when memory for                       F of I before the most recent occurence of
          previous trials failed, either systematic or                event E. (e.g. to give the frequency of an item I
          random search.                                              before the selection of the current goal.)
      •   None of the participants perseverated, i.e. they       •    F = freq_after( I, E ) - returns the frequency F
          did not repeatedly search the same incorrect                of I after event E.
          subtree more than a handful of times.
      •   With practice (about 4 trials) all participants      In order to simulate a lack of reliability in the
          were able to follow the correct path with         information returned by these functions, frequency and
          relatively few errors (Figure 1).                 recency      information      decayed     from     memory
      •   Those participants who used a systematic          stochastically. Also, false positives were randomly
          strategy were significantly more efficient than   generated in answer to queries about whether operators
          those who did not. On the first trial the         had been applied on this trial.            In the Payne,
          variation in the performance of the systematic    Richardson, and Howes (2000) experiment, false
          participants was less than the variation in the   positives occurred when participants were forced to
          performance of the random participants.           make a decision about whether or not they had applied
          (Unfortunately, the statistically significant     an operator before. In fact, participants may have only
          difference in efficiency between the use of the   seen the operator and not applied it.        The functions
          two strategies is not reflected in Figure 1. This that determined the rate of decay and false positives are
          is because some participants using the random     not important for our current purposes.
          strategy can, luckily, find the goal with            The purpose of introducing the errors was not to
          relatively few actions.)                          capture some quantitative aspect of the data but instead
                                                            to ensure that the search algorithm was robust given the
                           Model                            return of incorrect information from memory. Most
   The first model that we built relied on a single         importantly the algorithm should not perseverate
activation-based measure that combined both frequency       implausibly even when degraded information is
and recency information. This model could perform the       returned from memory.
first trial of a task by avoiding operators with high          The heuristics work by adding to a preference value
activation (those inferred to have been selected recently   for each operator proposed. There are three sets of
or frequently). However, on subsequent trials, a            heuristics: those that switch algorithm (or strategy);
strategy of preferring operators with a higher activation   those that control systematic search; and those that
(i.e. the ones used most recently on the previous trial or  control frequency-based search.
the ones used most frequently over trials) proved to be        Given goal G, operator Op and a preference constant
fragile. Activation may be high either because an           V, the rules for each algorithm are described below.
operator was selected many times incorrectly or             The rules depend on memory encodings of the
because it was selected more recently (i.e. closer to the   frequencies and recencies of associations, in general
achievement of the goal). Worse, if an error is made        between G and Op, but for clarity. a short-hand has
because an algorithm prefers highly active operators,       been used to describe the rule conditions, which does
then the algorithm may perseverate ad infinitum on          not refer to the association per se, but instead just to Op.
incorrect selections.                                       Each rule proposes an addition (plus) or a subtraction
   The model that we focus on in this paper, is an          (minus) to the current value of the preference for Op.
extension of a proposal by Payne, Richardson, Howes         The rules are described in a pseudo-code where
(2000). It relies on the separate and strategic use of      variables are represented with capitals. The symbol ‘=’
information about the frequency and recency of              indicates a test of equality. If the test has a variable on
operator usage. The model is not based on assumptions       either side and the variable is not already bound then
about the structure of memory, rather it is based on        the test will result in binding. The variables TOP and
assumptions about what information memory can               BOTTOM are respectively bound to the top and bottom
deliver. The heuristics that define the search algorithm    forward menu selections.
rely on the following functions for acquiring                  Rules 1 to 5 describe the memory-based algorithm.
information from memory:                                    This algorithm is used if the model has a memory

indicating that the goal has been achieved before.        7. IF     most_recent( algorithm ) = A, A = random,
Rules 6 and 7 describe the random algorithm. Rules 8                back( Op ) = true,
to 10 describe the systematic algorithm. (A particular              freq_after( TOP, A ) > 0,
instantiation of the model uses either the random or the            freq_after( BOTTOM, A ) > 0,
systematic rules but not both.) Finally, rule 11 switches   THEN P becomes plus( V ).
to the memory algorithm and rule 12 restarts a search in
the case of apparent exhaustion (this is described        8. IF     most_recent( algorithm ) = systematic,
further below).                                                     forward( Op ) = true, top( Op ) = true,
   There is only space to describe some of these rules              most_recent( op ) = R, not( back( R ) = true ),
here. We will focus on those for the systematic             THEN P becomes plus( V ).
algorithm. Rule 8 says, if the most recent algorithm is
systematic and the operator (Op) being evaluated is a     9. IF     most_recent( algorithm ) = A, A = systematic,
forward operator at the top of the screen, and the most             forward( Op ) = true, bottom( Op ) = true,
recent of the previously applied operators (R) was not a            most_recent( operator ) = R,
‘back’ operator THEN add V to the preference for Op.                back( R ) = true,
Rule 9 is similar to rule 8 but adds a preference for the           freq_after( Op, A ) = 0,
forward operator at the bottom of the screen if the         THEN P becomes plus( V ).
previous operator was a backup, Lastly, rule 10 prefers
the back operator when the bottom operator has been       10. IF    most_recent( algorithm ) = A, A = systematic,
tried on this trial and the most recent previous operator           back( Op ) = true,
was also a back.                                                    most_recent( operator ) = R,
                                                                    back( R ) = true,
1. IF     most_recent(algorithm) = A,                               freq_after( BOTTOM, A ) > 0,
          A = use_memory,                                   THEN P becomes plus( V ).
          forward(Op) = true,
          freq_after(Op,A) = 0,                             11. IF most_recent( algorithm ) = A, A = none,
          freq_before( achieved(G), A ) = FG,                       freq_before( achieved(G), A ) > 0,
          freq_before( Op, A ) = FO                                 Op = algorithm( use_memory ),
THEN P becomes plus( 1 / (1 + abs( FO – FG ) * V ) )        THEN P becomes plus( 3*V ).
2. IF     most_recent( algorithm ) = use_memory,          12. IF    current_node = root ,
          forward( Op ) = true,                                     most_recent( algorithm ) = A ,
          freq_before( fail( Op ), now ) = FN                       Op = algorithm( A ),
  THEN P becomes minus( FN * V ).                                   freq_after( TOP, A ) > 0,
                                                                    freq_after( BOTTOM, A ) > 0,
  3. IF most_recent( algorithm ) = A,                       THEN P becomes plus( 3*V ).
          A = use_memory,
          forward( Op ) = true,
          freq_after( Op, A ) = 0,                           The last algorithm switching rule (rule 12) plays a
          freq_before( Op, achieved(G) ) = OF,            crucial role. Occasionally the problem solver will return
  THEN P becomes plus( OF * V ).                          to the root node without having found the goal. This
                                                          will happen if the search was incomplete (i.e. some
4. IF     most_recent( algorithm )=A, A= use_memory,      subtree remained unsearched) due to inadequate
          forward( Op ) = true,                           information from memory (a false positive). In this
          freq_after( Op, A ) = 0,                        situation rule 12 restarts the search. In the model this is
  THEN P becomes plus( V ).                               operationalised as the operator for the current algorithm
                                                          is reapplied. The time at which the most recent
5. IF     most_recent( algorithm )=A, A= use_memory,      algorithm operator was applied is used by the other
          back( Op ) = true,                              rules to judge whether memories for operator
          freq_after( TOP, A ) > 0,                       applications were part of the current trial or previous
          freq_after( BOTTOM, A ) > 0,                    trials.
THEN P becomes plus( V ).
                                                                                    Results
6. IF     most_recent( algorithm ) = A, A = random,          For particular rates of memory decay and false
          forward( Op ) = true,                           positives, the model was run 40 times on each of the 4
          freq_after( Op, A ) = 0,                        tasks performed by participants. The resulting mean
THEN P becomes plus( V ).                                 performance for three decay rates is shown in Figure 2.

                                    45
                                    40
                                    35
                                                                                                      systematic(0.5)
                                                                                                      random(0.5)
                                    30
           Mean number of actions
                                                                                                      systematic(1)
                                                                                                      random(1)
                                    25                                                                systematic(3)
                                                                                                      random(3)
                                    20
                                    15
                                    10
                                    5
                                    0
                                          1         2         3        4         5            6       7               8   9      10
                                                                                     Trial
                                         Figure 2: Mean number of actions taken by model given increasingly unreliable information from
                                                                                   memory
   The participants’ mean performance is within the                                          whether key events occurred on the current trial or
bounds of the best and worst model performance                                               previous trials. The analysis of the model’s behaviour
illustrated in Figure 2. We have not attempted to fit the                                    under a range of memory decay and false positive
model precisely, rather in accordance with Roberts and                                       conditions reveals that it produces behaviour broadly
Pashler (2000) we explored the range of its behaviour.                                       similar to human performance on a simple search task.
   Importantly, the model did not perseverate.                                               Notably, unlike previous activation-based models built
Regardless of errors made during search, it always                                           by the authors, the model does not perseverate when
recovered and eventually found the goal. Also, as the                                        receiving degraded information from memory. In
decay rate increased the model was still able to learn                                       addition, the mean performance of the model over ten
the task. A large number of errors in the first trial did                                    trials consists of a practice curve similar to that of the
not on average incapacitate the learning over                                                participants.
subsequent trials.                                                                              However, further investigation revealed that, after the
   The gradual improvement in practice after the first                                       first trial, the model produced a much greater variation
trial was a result of a search algorithm (rules 1 to 5) that                                 in behaviour than the participants in the experiment.
is guided by a combination for memory for previous                                           This issue is a matter for further investigation, and may
trials and the current trial. If memory for previous trials                                  well imply the need for some superordinate learning
proved inadequate then memory for the current trial, as                                      mechanism (perhaps rehearsal or impasse-driven
distinguished by relative recency, ensured a reasonably                                      learning).
efficient search.                                                                               A superordinate learning mechanism might involve
   Also, in accordance with the participants behaviour,                                      the deliberate encodings of what the correct option is.
the systematic algorithm produced more efficient and                                         This is an approach that was explored in Howes (1994),
less varied searches on trial 1.                                                             and while it deserves further attention, there are two
                                                                                             problems. The first is that there is a dislocation in time
                      Discussion                                                             between when the items are experienced and when a
  The model reported here demonstrates that aspects of                                       participant achieves the goal. In previous models the
the way in which people search and learn paths through                                       feedback of information about correctness produced
external problem spaces can be captured with heuristic                                       recency effects in which lower levels of the tree were
rules that make strategic use of independent estimates                                       learnt first (Howes, 1994). These effects were not
of the frequency and recency of previously selected                                          observed in our experiments. The second is that
operators. Without access to this information it is                                          deliberate learning only pushes the problem back one
impossible to write heuristics that distinguish an                                           level. If people deliberately learn what is correct then
operator with high frequency from one that has high                                          when situations change or mistakes are made, they also
recency, and it is therefore a problem to determine                                          have to deliberately learn that a different option is

correct. Subsequent competition between different                                  References
representations of correctness would then have to be       Aasman, J. & Akyurek, A. (1992). Flattening goal
resolved, perhaps using exactly the kind of mechanism        hierarchies. In J.A.Michon & A.Akyurek (eds.) Soar:
that we have proposed. Progress will require modelling       A Cognitive Architecture in Perspective , 199 -217.
the range of individual trial data rather than just mean     Kluwer.
data.                                                      Altmann, E.M. & John, B.E. (1999). Episodic indexing:
   Another possibility that we are investigating is that     A model of memory for attention events. Cognitive
the long-term learning is based on recency and not           Science, 23(2),117-156.
frequency. Once the goal has been achieved, then the       Altmann, E. M. & Trafton, J. G. (1999). Memory for
operator that led to the goal will be the most recently      goals: An architectural perspective. Proceedings of
selected operator at any choice. Memory for recency          the twenty first annual conference of th e Cognitive
could therefore be used to guide learning. However,          Science Society (pp. 19-24). Hillsdale, NJ: Erlbaum.
under normal assumptions about decay, a recency-based      Anderson, J. R. (1993). Rules of the mind. Hillsdale,
model predicts that choice points at different distances     NJ: Erlbaum.
from the goal would be learnt at different rates. Our      Anderson, J. R. & Lebiere, C. (1998). The Atomic
data (not described above) does not support this             Components of Thought. NJ: Erlbaum.
prediction.                                                Atwood, M. E. & Polson, P. G. (1976). A process
   In principle, it may be possible to construct             model for water jug problems. Cognitive Psychology,
algorithms in ACT-R designed to ensure that during           8, 191-216.
search sufficient episodic information is stored in        Delaney, P. F., Reder, L. M., Staszewski, J. J., & Ritter,
declarative chunks to enable the kinds of computations       F. E. (1998). The strategy-specific nature of
that are posited in the model report here (e.g. Altmann      improvement: The power law applies by strategy
and Trafton, 1999). However, regardless of the success       within task. Psychological Science, 9, 1-7.
of this approach, there will remain an issue about how     Howes, A. (1994). A model of the acquisition of menu
people obtain information about frequency, and               knowledge by exploration.          In B. Adelson, S.
recency. While the concept of activation is well             Dumais, J. Olson (Eds.) Proceedings of Human
established in psychology, an architecture in which          Factors in Computing Systems CHI'94 (pp. 445-451),
chunks are stored with independent measures of               Boston, MA.: ACM Press.
frequency and recency may lead to more parsimonious        Jacoby, L. L. (1991). A process dissociation
accounts of problem solving behaviour.                       framework: Separating automatic from intentional
   There are a number of models of the cognitive             uses of memory. Journal of Memory and Language,
activity that give rise to practice effects, amongst them    30, 513-541.
Logan's (1988) instance model and Rosenbloom and           Jeffries, R. P., Polson, P. G., Razran, L. & Atwood, M.
Newell’s (1981) chunking model. More recent work has         (1977). A process model for missionaries-cannibals
emphasised the strategy specific nature of the practice      and other river-crossing problems.            Cognitive
curves (Delaney, Reder, Staszewski & Ritter, 1998).          Psychology, 9, 412-440.
The model reported here is similar to Logan's in that the  Logan, G. D. (1988). Toward an instance theory of
practice curve emerges as a result of encodings made         automatization. Psychological Review, 95, 492-527.
from experience with the external environment:             Newell, A. (1990). Unified Theories of Cognition.
however, maze-like tasks are more complex than simple        Cambridge, MA: Harvard University Press.
letter arithmetic tasks and it is for this reason that our Newell, A., & Rosenbloom, P. S. (1981). Mechanisms
model requires the combination of frequency and              of skill acquisition and the power law of practice. In
recency dependent control mechanisms that we have            J. R. Anderson (Ed.), Cognitive skills and their
described.                                                   acquisition. Hillsdale, New Jersey: Erlbaum.
   In the introduction we claimed that ACT-R’s             Payne, S. J., Richardson, J. & Howes, A. (2000).
representation of undifferentiated activations was not       Strategic use of familiarity in display-based problem
sufficient to directly support algorithms that capture the   solving.      Journal of Experimental Psychology-
behaviour of people engaged in typical search tasks. In
                                                             Learning Memory and Cognition, 2, 1685-1701.
contrast, the model that we have reported illustrates the
                                                           Richardson, J., Howes, A., & Payne, S.J. (1998) A
cognitive plausibility of a mechanism that makes
strategic use of separate sources of operator recency and    cognitive model of the use of familiarity in the
frequency during search.                                     acquisition of interactive search skill. In M.A.
                                                             Gernsbacher & S. J. Derry (Eds.), Proceedings of the
                    Acknowledgement                          20th Annual Conference of the Cognitive Science
                                                             Society (p. 1258). Mahwah, NJ: Erlbaum.
   Juliet Richardson contributed a great deal to the       Roberts, S., Pashler, H. (2000). How persuasive is a
development of the ideas presented in this paper.            good fit? A comment on theory testing.
                                                             Psychological Review, 107, 358-367.

