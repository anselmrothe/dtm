UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Knowledge-Resonance (KRES) Model of Category Learning
Permalink
https://escholarship.org/uc/item/6rk3d9zh
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Rehder, Bob
Murphy, Gregory L.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            A Knowledge-Resonance (KRES) Model of Category Learning
                                              Bob Rehder (bob.rehder@nyu.edu )
                               Department of Psychology, New York University, 6 Washington Place
                                                      New York, NY 10003 USA
                                   Gregory L. Murphy (gmurphy@s.psych.uiuc.edu )
                                   Beckman Institute, University of Illinois, 405 N. Mathews Ave
                                                        Urbana, IL 61801 USA
                             Abstract                                1988; Kruschke, 1992), and these models have generally
                                                                     used feedforward networks (i.e., activation flows only from
   In this article we present a connectionist model of category      inputs to outputs) and learning rules based on error signals
   learning that takes into account the prior knowledge that         that traverse the network from outputs to inputs (e.g., back-
   people bring to many new learning situations. This model,
   which we call the Knowledge-Resonance Model or KRES,
                                                                     propagation). KRES departs from these previous models in
   employs a recurrent network with bidirectional connec-            two regards. First, rather than feedforward networks, KRES
   tions which are updated according to a contrastive-Hebbian        uses recurrent networks in which activation is allowed to
   learning rule. When prior knowledge is incorporated into a        flow not only from inputs to outputs but also from outputs
   KRES network, the KRES activation dynamics and learning           to inputs and back again. Recurrent networks respond to
   procedure accounts for a range of empirical results regard-       inputs by each unit iteratively adjusting its activation in
   ing the effects prior knowledge on category learning, in-         light of all other units until the network “settles,” that is,
   cluding the accelerated learning that occurs in the presence      until change in units’ activation levels ceases. This settling
   of knowledge, the reinterpretation of features in light error     process can be understood as an interpretation of the input in
   correcting feedback, and the unlearning of prior knowledge        light of the knowledge encoded in the network. As applied to
   which is inappropriate for a particular category.
                                                                     the categorization problems considered here, a KRES net-
A traditional assumption in category learning research is that       work accepts inputs that represent an object’s features, and
learning is based on those category members people observe           interprets (i.e., classifies) that object by settling into a state
and is relatively independent of the prior knowledge that they       in which the object’s correct category label is active.
already possess. According to this data-driven or empirical             Second, rather than backpropagation, KRES employs con-
learning view of category learning, people associate observed        trastive Hebbian learning (CHL) as a learning rule (Movel-
exemplars and the features they display (or a summary repre-         lan, 1989; O’Reilly, 1996). Backpropagation has been criti-
sentation of those features such as a prototype or a rule) to        cized for being neurally implausible because it assumes non-
the name or label of the category. In this account there is          local information regarding the error generated from correc-
neither need nor room for the influence of the learner’s prior       tive feedback in order for connection weights to be updated.
knowledge of how those features are related to each other or         In contrast, CHL transmits error by using the same connec-
other concepts on the learning process. In contrast, the last        tions that propagate activation. During an initial minus
several years has seen a series of empirical studies that dem-       phase, a network is allowed to settle in light of an input
onstrate the dramatic influence that a learner’s prior knowl-        pattern. In the ensuing plus phase, the network is provided
edge often has on the learning process in interpreting and           with what serves as error-corrective feedback by being pre-
relating a category’s features to one another and other con-         sented with the output pattern that should have been com-
cepts. Indeed, knowledge effects have been demonstrated in           puted during the minus phase and allowed to resettle in light
every area of conceptual processing in which they have been          of that (correct) output pattern. Connection weights are then
investigated (see Murphy, 1993, for a review).                       updated as a function of the difference between the activation
   The goal of this article is to introduce a theory of category     of units in the two phases.
learning that accounts for the effects of prior knowledge on            In the following sections we first describe KRES and then
the learning of new categories. This theory, which we refer          present three simulations of human category learning data.
to as the Knowledge-Resonance Model, or KRES, is a                   We will show how KRES’s successes can be attributed to
connectionist network that specifies prior knowledge in the          its recurrent network that allows category features to be in-
form of existing concepts and relations between concepts.            terpreted in light of prior knowledge, and the CHL learning
We will show that when knowledge is incorporated into a              algorithm that allows (re)learning of all connections in a
KRES network, KRES’s activation and learning procedures              network, including those that represent prior knowledge.
account for a number of empirical results regarding the ef-
fects of prior knowledge on category learning.                       The Knowledge-Resonance Model (KRES)
   Other connectionist models have been proposed to account          An example of a KRES model is presented in Figure 1. In
for the learning of new categories (e.g., Gluck & Bower,             Figure 1, circles depict units that represent concepts that are

                                                                                                          X
                                           A1       B1       C1         D1        E1
                               A0        B0        C0        D0       E0                                  Y
                                                                                   1:1
                                                                                                      Category
                                                                                                         Label
                                                   Feature Units                                         Units
                                                     Figure 1. A sample KRES model.
either category labels (X and Y) or features (A0, A 1, B0, B1,      nected by the connection’s weight, and then summing over
C 0 , C 1 , etc.). To simplify the depiction of connections         those units in the usual manner,
among units, units are organized into layers specified by                           net-inputi = ∑j acti * weightij .
rectangles. Solid lines between layers represent connections           KRES primarily represents prior knowledge in the form
among units. Solid lines terminated with black circles are          of prior relations between features. For example, in Figure 1
excitatory connections, whereas those terminated with hol-          it is assumed that features A0, B0, and C0 are related by prior
low circles are inhibitory connection. Dashed lines represent       knowledge, as are features A 1, B1, and C 1 . These relations
new, to-be-learned connections. Two connected layers are            are rendered as excitatory connections between the features.
fully connected (i.e., every unit is connected to every other       In KRES prior knowledge can also be represented in the
unit), unless annotated with “1:1” (i.e. “one-to-one”) in           form of preexisting concepts (i.e., units) and excitatory con-
which case a unit in a layer is connected to only one unit in       nections that link those preexisting concepts to the feature
the other layer. Finally, double dashed lines represent             units (see Simulation 3 below).
sources of external inputs. As described below, both the
feature units and the category label units receive external         Classification via Constraint Satisfaction
input, although at different phases of the learning process.
   We now describe the basic elements of KRES, which in-            Before a KRES model is presented with input that represents
clude its representation assumptions, activation dynamics           an object’s features, the activation of each unit is initialized
(i.e., constraint satisfaction), and learning via CHL.              to a value determined solely by its bias. The external input
                                                                    of a feature unit is then set to 1 if the feature is present in
Representational Assumptions                                        the input, -1 if it is absent, and 0 if its presence or absence
                                                                    is unknown. The external input of all other units is set to 0.
At any time a unit has a level of activation in the range 0 to      The model then undergoes a multi-cycle constraint satisfac-
1 that represents the activation of the concept. A unit i’s         tion processes which involves updating the activation of
activation acti is a sigmoid function of its total input,           each unit in each cycle in light of its external input, its bias,
               acti = 1 / [1+ exp (–total-inputi)]                  and its current network input. (In each cycle, the serial order
and its total input comes from three sources,                       of updating units is determined by randomly sampling units
      total-inputi = net-inputi + external-inputi + biasi.          without replacement.) After each cycle the harmony of the
                                                                    network is computed, given by,
Network input represents the input received from other
units. External input represents the presence of (evidence for)                harmony = ∑i ∑j acti * actj * weightij .          (1)
the concept in the external environment. Finally, a unit’s          Constraint satisfaction continues until the network settles,
bias can be interpreted as a measure of the prior probability       as indicated by a change in harmony from one cycle to the
that the concept is present in the environment.                     next of less than 0.00001.
   In many applications, two or more features might be                 The activation of units X and Y that result from this set-
treated as mutually exclusive values on a single dimension.         tling process represent the evidence that the current input
In Figure 1 the stimulus space is assumed to consist of five        should be classified as an X or Y, respectively. These activa-
binary valued dimensions, with A0 and A1 representing the           tion values can be mapped into a categorization decision in
values on dimension A, B0 and B1 the values on dimension            the standard way, that is, according to Luce’s choice axiom,
B, etc. To represent that these feature pairs are mutually                 choice-probability (X, Y) = actX / (actX + actY) .
exclusive they are linked by inhibitory connections. The
category labels X and Y are also assumed to be mutually             Contrastive Hebbian Learning (CHL)
exclusive and are linked by an inhibitory connection.               As described earlier, the settling of a network that results
   Connections between units are symmetric, that is,                from presenting just the feature units with input is referred
weightij = weightji. A unit’s network input is computed by          to as the minus-phase. In the plus-phase, error-correcting
multiplying the activation of each unit to which it is con-         feedback is provided to the network by setting the external

inputs of the correct and incorrect category label units to 1
and –1, respectively, and allowing the network to resettle in                                 1     Empirical Data          KRES            1.0
light of these additional inputs. We refer to the activation
                                                                        Response Time (sec)
                                                                                                                                            0.9
                                                                                                                                                  Choice Probability
values of unit i that obtain after the minus and plus phases
                                                                                              2                                             0.8
as acti– and acti+, respectively. After the plus phase the con-
nection weights are updated according to the rule,                                                                                          0.7
                                                                                              3
        ∆weightij = lrate * (acti+ * actj+ – acti– * actj–) (2)                                                                             0.6
where lrate is a learning rate parameter.                                                     4                                             0.5
                                                                                                                        Theme               0.4
Network Training
                                                                                              5                         No Theme            0.3
Before training a KRES network, all connections weights
are set to their initial values. In the following simulations,                                                                              0.2
all to-be-learned connections are initialized to a random value                                   Frequent Infrequent Frequent Infrequent
in the range [-0.1, 0.1], and the biases of all units are initial-
                                                                                                     Feature Type        Feature Type
ized to 0. As in the behavioral experiments we simulate,
training consists of repeatedly presenting a set of training                                  Figure 2. Results from Murphy & Allopenna (1994).
patterns in blocks with the order of the patterns randomized
                                                                     categories were linked with excitatory connections. The
within block. Training continues until the error for a block
                                                                     weight on these excitatory connections was initialized to
falls below an error criterion of 0.10. The error for a block is
                                                                     0.4, the inhibitory connections were initialized to –2.0, and
computed by summing the errors associated with each train-
                                                                     the learning rate was set to 0.10.
ing pattern in the block and dividing by the number of pat-
                                                                        The results indicated that KRES reproduces the learning
terns. The error associated with a training pattern is the sum
                                                                     advantage found in the Theme condition: The error criterion
of the squared differences between the activation levels of the
                                                                     was reached in fewer blocks as compared to the No Theme
category label units and their correct values (0 or 1).
                                                                     condition (2.0 vs. 4.0). This advantage can be attributed to
                                                                     KRES’s use of recurrent networks: The mutual excitation of
     KRES Simulation of Empirical Data                               knowledge-relevant features in the Theme condition resulted
We present KRES simulations of three empirical data sets             in higher activation values for those units, which in turn led
that illustrate the effect of prior knowledge on category            to the faster growth of the connection weights between the
learning. The KRES model was rerun ten times with a dif-             features and category label units (according to the CHL
ferent set of random weights, and the results reported below         learning rule Eq. 2). Once some learning of those connec-
are averaged over those ten runs.                                    tions has occurred, the higher activation of the features also
                                                                     leads to greater activation of the category labels themselves.
Simulation 1: Murphy and Allopenna (1994)                               Murphy and Allopenna also varied the frequency with
In the literature on category learning with prior knowledge,         which the six knowledge-relevant features appeared during
perhaps the most pervasive effect is that learning is dramati-       training, and then tested how subjects classified those fea-
cally accelerated when the prior knowledge is consistent with        tures during an ensuing test phase. The left side of Figure 2
the empirical structure of training exemplars. For example,          indicates that, as expected, RTs for these single-feature clas-
Murphy and Allopenna (1994, Experiment 2), presented                 sification trials were shorter for frequent versus infrequent
examples of two categories the features of which either could        features in the No Theme condition. In contrast, in the
(Theme Condition) or could not (No Theme Condition) be               Theme condition RTs were insensitive to features’ empirical
related to one another. In the Theme condition one category          frequency. This pattern of results was also reflected in sub-
had six typical features that could be related because they          jects’ categorization accuracy. (Note Figure 2’s RT scale has
could be construed as features of arctic vehicles ("drives on        been inverted to facilitate comparison with KRES’s choice
glaciers," "made in Norway," "heavily insulated,” etc.)              probabilities presented below.)
whereas the other category had six typical features that could          To determine whether KRES would also exhibit these ef-
be construed as features of jungle vehicles ("drives in jun-         fects, after training the model was presented with single fea-
gles," "made in Africa," "lightly insulated,” etc.). In the No       tures. That is, the unit representing that feature was given an
Theme condition, the typical features of the categories could        external input of 1, the unit representing the other feature on
not be related to one another. Exemplars also possessed three        the same dimension was given an input of –1, and all other
knowledge-irrelevant features which were not predictive of           units were given an input of 0. The right side of Figure 2
category membership. Murphy and Allopenna found that                 indicates that KRES’s choice probabilities reproduce the
participants reached a learning criterion in fewer blocks in         pattern of results for the single-feature tests. In KRES, in-
the Theme (2.5) versus the No Theme condition (4.1), a               frequently presented knowledge-relevant features are classified
result the authors attribute to the knowledge relating the           nearly as accurately as frequently presented ones because
features in the Theme condition.                                     during training those features were activated by inter-feature
  This experiment was simulated by a KRES model like the             excitatory connections even on trials in which they were not
one shown in Figure 1 with 18 features representing the two          presented, and hence were associated with the category label
values on 9 binary dimensions. In the Theme but not the No           nearly as strongly as knowledge-relevant features that were
Theme condition the six related features in each of the two          frequently presented.

Simulation 2: Kaplan and Murphy (2000)                                                                                                                     1.0
                                                                                         0.7       Empirical Data                     KRES
Simulation 1 provides evidence in favor of KRES’s use of                                                                                                   0.9
                                                                   Response Time (sec)
recurrent networks to accelerate learning by amplifying the                              0.9
                                                                                                                                                                 Choice Probability
activation of features interconnected by prior knowledge.                                1.1                                                               0.8
However, another distinctive characteristic of KRES is that
the category label units are also recurrently connected to the                           1.3                                                               0.7
features. In this section we provide evidence that activation                            1.5
                                                                                                                                                           0.6
also flows backwards from category label units.
                                                                                         1.7
   Using a modified version of the materials used in Murphy                                                                                                0.5
                                                                                         1.9                                Intact Theme
and Allopenna (1994), Kaplan and Murphy (2000, Experi-
                                                                                                                            No Theme
ment 4) provided an especially dramatic demonstration of the                             2.1                                                               0.4
effect of prior knowledge. In that study, participants were
presented with training examples that contained only one of                                    Characteristic Idiosyncratic Characteristic Idiosyncratic
the knowledge-relevant features and up to six knowledge-                                             Feature Type                 Feature Type
irrelevant features that were predictive of category member-
ship. That is, the single knowledge-relevant feature in each               Figure 3. Results from Kaplan & Murphy (2000). In
exemplar had prior associations only to features in other              the Intact Theme condition Idiosyncratic features are
category exemplars. Under these conditions, one might have             knowledge-relevant and Characteristic features are
predicted that participants would be unlikely to notice the            knowledge-irrelevant.
relations among the features in different exemplars, espe-
cially given that those features were each embedded in an         tures would be expected to overshadow the learning of
exemplar with many knowledge-irrelevant features. In fact,        knowledge-irrelevant features (Gluck & Bower, 1988)–that
participants in this Intact Theme condition reached a learning    is, these features should be worse with knowledge than
criterion in fewer blocks (2.7) than did those in a No Theme      without as a result of them competing with the stronger
condition (5.0) in which the categories had the same empiri-      knowledge-relevant features. In contrast, Figure 3 indicates
cal structure but no relations among features.                    that KRES is able to account for the better learning (or in
   We simulated this experiment with a KRES model with            some experiments, equal learning) of the knowledge-
22 features on 11 binary dimensions. In the Intact Theme          irrelevant features in the Intact Theme condition. This result
condition the features within the two sets of six knowledge-      can be attributed to the use of recurrent connections to the
relevant features were inter-related with excitatory connec-      category label units. After some excitatory connections be-
tions, as in Simulation 1. The weight on these excitatory         tween the knowledge-irrelevant features and category labels
connections was initialized to 0.35, the inhibitory connec-       have been formed, the knowledge-relevant and -irrelevant
tions were set to –2.0, and the learning rate was set to 0.10.    features began to activate each other through the category
   KRES reproduced the learning advantage found in the In-        node. This greater activation of the knowledge-irrelevant
tact Theme condition (3.0 blocks) as compared to the No           features leads to accelerated learning of their connection
Theme condition (5.4). This advantage obtained because            weights to the category labels. That is, KRES’s use of re-
even though each training pattern in the Intact Theme condi-      current networks compensates for the effects of cue competi-
tion contained only one knowledge-relevant feature, that          tion found in the usual feedforward network.
feature tended to activate the knowledge-relevant features to
which it was connected, and hence the connections between         Simulation 3: Wisniewski and Medin (1994)
each knowledge-relevant feature and its correct category label    In a final simulation we demonstrate the efficacy of contras-
were strengthened on every trial to at least some degree.         tive-Hebbian learning to update weights on connections not
   After each training block, Kaplan and Murphy also pre-         involving the category label units. In particular, we examine
sented test blocks in which participants classified each of the   KRES’s ability to update connections representing prior
22 features. The left side of Figure 3 indicates that as ex-      knowledge that is inappropriate in the current context.
pected after the final block of training participants in the No      Wisniewski and Medin (1994, Experiment 2) present em-
Theme condition were faster at classifying those features that    pirical results that call into question the assumption of stan-
appeared in several training exemplars (Characteristic fea-       dard theories of category learning that features can be identi-
tures) than those that appeared in just one (Idiosyncratic fea-   fied prior to learning. Participants were shown two catego-
tures). In contrast, in the Intact Theme condition participants   ries of line drawings of persons that were described as drawn
were faster at classifying the Idiosyncratic features, because    by creative and non-creative children or by farm and city
they were also knowledge-relevant. Unexpectedly, Intact           kids. Wisniewski and Medin chose to use line drawings to
Theme participants were also faster at classifying the Char-      illustrate that what constitutes a feature in a stimulus de-
acteristic features (i.e., the knowledge-irrelevant features)     pends on the prior expectations that one has about its possi-
even though those features were not related via prior knowl-      ble category membership. For example, they found that par-
edge, and even though Intact Theme participants had experi-       ticipants would assume the presence of abstract features
enced fewer training blocks on average (2.7 vs. 5.0).             about a category depending on the category’s label (e.g.,
   This latter result is a challenge for many standard            creative children’s drawings depict unusual amounts of detail
connectionist accounts of learning, because in such accounts      and characters performing actions) and examine the drawings
the better learning associated with knowledge-relevant fea-       for concrete evidence of those abstract features in order to

                                               running in                     city
                                               playground                  locations
                                                                                                      drawing by
                                                                                                         city kid
                                                   city                       city
                     Drawing A
                                                 uniform                    clothing
                      Features                                  1:1                         1:1
                                                        dancing                      farm
                                                                                  locations
                                                                                                      drawing by
                                                                                                        farm kid
                                                         farm                        farm
                     Drawing C                          uniform                    clothing
                      Features
                     Primitive                    Feature                    Category              Category Label
                      Features                Interpretations             Expectations                  Units
                                             Figure 4. KRES model for Simulation 3.
determine its category membership. They also found that the         knowledge incorporated into this KRES model is able to
feedback participants received about category membership led        decide on a classification of both drawings. Upon presenta-
them to change their original interpretation of certain fea-        tion of Drawing A, its two interpretations, climbing-in-a-
tures of the line drawings. For example, after first interpret-     playground or dancing are activated, and climbing-in-a-
ing a character’s clothing as a farm “uniform” (and categoriz-      playground in turn activates the city location expectation,
ing the picture as drawn by a farm kid), some participants          which in turn activates the category label for city kids’ draw-
reinterpreted the clothing as a city uniform after receiving        ings. The drawing is correctly classified as having been
feedback that the picture was drawn by a city kid.                  drawn by a city kid. Moreover, as the network continues to
   To demonstrate these effects with KRES, we imagined a            settle, activation is sent back from the category label to the
simplified version of the materials of Wisniewski and               climbing-in-a-playground unit. As a result, the climbing-in-
Medin’s in which there were only two drawings. One draw-            a-playground interpretation of Drawing A is more active
ing (Drawing A), was of a character performing an action            than the dancing interpretation when the network settles.
interpretable either as climbing in a playground or dancing.        That is, the top-down knowledge provided to the network
In the other (Drawing C), a character’s clothing could be           results in the resolution of an ambiguous feature (i.e., the
seen as a farm uniform or a city uniform. These alternative         action is interpreted as climbing in a playground rather than
interpretations are represented in the left side of the KRES        dancing). Wisniewski and Medin found that the same draw-
model of Figure 4. Whereas we assume the two interpreta-            ing would be interpreted as depicting dancing instead when
tions of Drawing A are equally likely, we assume that a city        participants were required to classify the drawings as having
uniform is the more likely interpretation of Drawing C (as          been done by creative or noncreative children.
depicted by the heavier line connecting the features of Draw-          Similarly, upon presentation of Drawing C, its two inter-
ing C and their city uniform interpretation). The alternative       pretations are activated, but because the city uniform inter-
interpretations are connected with inhibitory connections           pretation receives more input as a result of its larger connec-
representing that only one interpretation is correct.               tion weight, it quickly dominates the farm uniform interpre-
   The model of Figure 4 was presented with the problem of          tation. As a result, the category label for city kids’ drawings
learning to classify Drawing A as done by a city kid, and           becomes active (via the city clothing expectation). That is,
Drawing C by a farm kid. We represented the expectations or         the drawing is incorrectly classified as having been drawn by
hypotheses that Wisniewski and Medin found that learners            a city kid. However, error feedback results in the model
form in the presence of meaningful category labels such as          changing its interpretation of Drawing C. During the
farm or city kids as units connected via excitatory connec-         model’s plus phase, the farm kids’ category label is more
tions to the category labels, as shown in the right side of         active than the city kids’ label as a result of the external
Figure 4. In Figure 4, city and farm kids are expected to be        inputs those units receive. The activation emanating from
in locations and wear clothing appropriate to cities and            the farm kids’ label leads to the activation of the farm cloth-
farms. These expectations are in turn related by excitatory         ing expectation and then the farm uniform feature interpreta-
connections to the picture interpretations that instantiate         tion, which ends up dominating the city uniform unit.
them: climbing in a playground instantiates a city location,           This result indicates that KRES can reinterpret features in
and city and farm uniforms instantiate city and farm cloth-         light of error feedback. The more important question, how-
ing, respectively. In Figure 4, all inhibitory connections          ever, is whether KRES can learn this new interpretation so
were set to –3.0 and all excitatory connections were set to         that Picture C (or a similar picture) will be correctly classi-
0.25, except for those between Drawing C’s features and             fied in the future. The left side of Figure 5 shows the
their city uniform interpretation, which were set to 0.30.          changes to the connection weights brought about by the
   Before a single training trial is conducted, the prior           CHL learning rule with a learning rate of 0.3 as a function

                                                                                                                            prior concepts send activation to the category label units,
                                                                                  Choice Probability (Farm kid, City kid)
                              Weights From             Classification                                                       and that learning consists of learning the connections to the
                                                                            0.9
                    0.4
                               Features of             of Drawing C                                                         category labels. Although we believe that existing categories
                                                                            0.8
Connection Weight
                               Drawing C                                                                                    often aid the learning of new categories (e.g., our knowledge
                                                                            0.7                                             of VCRs helps us understand DVD players), the Baywatch
                                                                            0.6                                             approach is limited to the learning of new categories that are
                    0.3
                                                                            0.5                                             essentially refinements of existing concepts. In contrast,
                                                                                                                            KRES only assumes the presence of relations between fea-
                                                                            0.4
                                                                                                                            tures to account for the data in Simulations 1 and 2, and
                    0.2                                                     0.3                                             hence is able to learn truly new concepts, not just refine-
                                         To Farm                            0.2                                             ments of existing ones.
                                         Uniform
                                         To City                            0.1                                                There remains much to be discovered about the properties
                    0.1                  Uniform                                                                            of recurrent networks and contrastive Hebbian learning with
                                                                                                                            regard to the learning of categories. However, we believe
                          0     1    2   3    4    0    1    2   3      4                                                   that recurrent networks are likely to be critical to any at-
                          # of Training Blocks # of Training Blocks                                                         tempt at accounting for the effects of prior knowledge on
                                                                                                                            category learning. For example, standard feedforward net-
                              Figure 5. Results from Simulation 3.                                                          works seem intrinsically unable to account for (a) the accel-
of number of blocks of training on the two drawings. Figure                                                                 erated learning produced by prior knowledge without presup-
5 indicates that the connection weights associated with the                                                                 posing prior knowledge of the to-be-learned category, (b) the
interpretation of Drawing C as a city uniform rapidly de-                                                                   effects of top-down knowledge on resolving ambiguous fea-
crease from their starting value of 0.30, while the weights                                                                 tures, and (c) the reinterpretation of ambiguous features in
associated with Drawing C’s interpretation as a farm uni-                                                                   light of feedback regarding category membership.
form increase from their starting value of 0.25. As a result,
after just one training block KRES’s classification of Draw-                                                                                 Acknowledgements
ing C switches from being done by a city kid to a farm kid                                                                  This work was supported by NSF Grant SBR 97-20304.
(as indicated by the choice probabilities shown in the right
side of Figure 5). That is, KRES uses the error feedback it                                                                                        References
receives to learn a new interpretation of Drawing C.
                                                                                                                            Gluck, M. A., & Bower, G. H. (1988). From conditioning
                                                                                                                              to category learning: An adaptive network model. Journal
                                    General Discussion                                                                        of Experimental Psychology: General, 117, 227-247.
We have presented a new model of category learning that                                                                     Heit, E., & Bott, L. (2000). Knowledge selection in cate-
attempts to account for the influence of prior knowledge that                                                                 gory learning. In D. L. Medin (Ed.), The psychology of
learners often bring to the task of learning a new category.                                                                  learning and motivation. (pp. 163-199). Academic Press.
KRES utilizes a recurrent network in which knowledge is                                                                     Kaplan, A. S., & Murphy, G. L. (2000). Category learning
encoded in the form of connections among units. We have                                                                       with minimal prior knowledge. Journal of Experimental
shown the changes brought about by this recurrently-                                                                          Psychology: Learning, Memory, and Cognition, 26, 829-
connected knowledge to the interpretations and reinterpreta-                                                                  846.
tions of a category’s features provides a reasonable account                                                                Kruschke, J. K. (1992). ALCOVE: An exemplar-based
of three data sets exhibiting the effects of prior knowledge                                                                  connectionist model of category learning. Psychological
on category learning. In Simulation 1 we demonstrated how                                                                     Review, 99, 22-44.
KRES’s recurrent network provides a pattern of activation                                                                   Movellan, J. R. (1989). Contrastive Hebbian learning in the
among features that accounts for the finding that knowledge                                                                   continuous Hopfield model. In D. S. Touretzky, G. E.
accelerates the learning of connections to category labels. In                                                                Hinton, & T. J. Sejnowski (Eds.), Proceedings of the
Simulation 2 we demonstrated that the presence of knowl-                                                                      1989 Connectionist Models Summer School .
edge does not inhibit the learning of knowledge-irrelevant                                                                  Murphy, G. L. (1993). Theories and concept formation. In I.
features, a striking result in light of well-known learning                                                                   V. Mechelen, J. Hampton, R. Michalski, & P. Theuns
phenomena such as cue competition. In Simulation 3 top-                                                                       (Eds.), Categories and concepts: Theoretical views and in-
down flow of activation was instrumental in KRES’s suc-                                                                       ductive data analysis. (pp. 173-200). Academic Press.
cess in resolving the ambiguity surrounding the interpreta-                                                                 Murphy, G. L., & Allopenna, P. D. (1994). The locus of
tion of a perceptual features. Moreover, the CHL learning                                                                     knowledge effects in concept learning. Journal of Experi-
rule allowed the knowledge responsible for one interpretation                                                                 mental Psychology: Learning, Memory, and Cognition,
of an ambiguous feature to be unlearned and a new interpre-                                                                   20, 904-919.
tation learned when the network was provided with feedback                                                                  O'Reilly, R. C. (1996). Biologically plausible error-driven
regarding the stimulus’s correct category.                                                                                    learning using local activation differences: The generalized
   KRES departs from previous connectionist models that at-                                                                   recirculation algorithm. Neural Computation, 8, 895-938.
tempt to account for the effects prior knowledge with feed-                                                                 Wisniewski, E. J., & Medin, D. L. (1994). On the interac-
forward networks. For example, Heit & Bott (2000) have                                                                        tion of theory and data in concept learning. Cognitive Sci-
proposed a model, Baywatch, that assumes that features send                                                                   ence, 18, 221-282.
activation to prior concepts, that both the features and the

