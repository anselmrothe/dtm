UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Grammatical Constructions
Permalink
https://escholarship.org/uc/item/6df9d2fr
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Chang, Nancy C.
Maia, Tiago V.
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                    Learning Grammatical Constructions
                                       Nancy C. Chang (nchang@icsi.berkeley.edu)
                                             International Computer Science Institute
                                    1947 Center Street, Suite 600, Berkeley, CA 94704 USA
                                           Tiago V. Maia (tmaia@cse.buffalo.edu)
                                              State University of New York at Buffalo
                                           226 Bell Hall, Buffalo, NY 14260-2000 USA
                            Abstract                                   The remainder of the paper casts the learning prob-
                                                                    lem in terms of two interacting processes, construction
   We describe a computational model of the acquisition of          hypothesis and construction reorganization, and presents
   early grammatical constructions that exploits two essen-         an algorithm based on Bayesian model merging (Stolcke,
   tial features of the human grammar learner: significant
   prior conceptual and lexical knowledge, and sensitivity          1994) that attempts to induce the set of constructions that
   to the statistical properties of the input data. Such prin-      best fits previously seen data and generalizes to new data.
   ciples are shown to be useful and necessary for learn-           We conclude by discussing some of the broader implica-
   ing the structured mappings between form and meaning             tions of the model for language learning and use.
   needed to represent phrasal and clausal constructions. We
   describe an algorithm based on Bayesian model merg-
   ing that can induce a set of grammatical constructions                  Conceptual and lexical prerequisites
   based on simpler previously learned constructions (in the
   base case, lexical constructions) in combination with new        Children learning their earliest word combinations bring
   utterance-situation pairs. The resulting model shows how         considerable prior knowledge to the task. Our model of
   cognitive and computational considerations can intersect         grammar learning makes several assumptions intended
   to produce a course of learning consistent with data from        to capture this knowledge, falling into two broad cat-
   studies of child language acquisition.
                                                                    egories: representational requirements for ontological
                                                                    knowledge; and the ability to acquire lexical mappings.
                        Introduction                                   Infants inhabit a dynamic world of continuous per-
                                                                    cepts, and how they process and represent these fluid
This paper describes a model of grammar learning in
                                                                    sensations remains poorly understood. By the time they
which linguistic representations are grounded both in the
                                                                    are learning grammar, however, they have amassed a
conceptual world of the learner and in the statistical prop-
                                                                    substantial repertoire of concepts corresponding to peo-
erties of the input. Precocity on both fronts has previ-
                                                                    ple, objects, settings and actions (Bloom, 1973; Bloom,
ously been exploited in models of lexical acquisition; we
                                                                    2000). They are also competent event participants who
focus here on the shift from single words to word combi-
                                                                    have acquired richly structured knowledge about how
nations and investigate the extent to which larger phrasal
                                                                    different entites can interact (Tomasello, 1992; Slobin,
and clausal constructions can be learned using principles
                                                                    1985), as well as sophisticated pragmatic skills that al-
similar to those employed in word learning. Our model
                                                                    low them to determine referential intent (Bloom, 2000).
makes strong assumptions about prior knowledge – both
ontological and linguistic – on the part of the learner,               Few computational models of word learning have ad-
taking as both inspiration and constraint the course of             dressed the general problem of how such sensorimotor
development observed in crosslinguistic studies of child            and social-cultural savvy is acquired. Several models,
language acquisition.                                               however, have tackled the simpler problem of how la-
   After describing our assumptions, we address the rep-            bels (either speech or text) become statistically associ-
resentational complexities associated with larger gram-             ated with concepts in restricted semantic domains, such
matical constructions. In the framework of Construc-                as spatial relations (Regier, 1996), objects and attributes
tion Grammar (Goldberg, 1995), these constructions can,             (Roy and Pentland, 1998), and actions (Bailey et al.,
like single-word constructions, be viewed as mappings               1997; Siskind, 2000). Such models assume either explic-
between the two domains of form and meaning, where                  itly or implicitly that lexical items can be represented as
form typically refers to the speech or text stream and              maps (i.e., bidirectional associations) between represen-
meaning refers to a rich conceptual ontology. In partic-            tations of form and meaning that are acquired on the basis
ular, they also involve relations among multiple entities           of input associations.1 Most of these also produce word
in both form (e.g., multiple words and/or phonological              senses whose meanings exhibit category and similarity
units) and meaning (multiple participants in a scene), as               1 Typically, supervised or unsupervised training is used to
well as mappings across relations in these two domains.             induce word categories from sensorimotor input, which is de-
We introduce a simple formalism capable of representing             scribed using continuous or discrete features; models vary in
such relational constraints.                                        the degree of inductive bias present in the input feature space.

effects like those known to be pervasive in human cogni-       from the meaning of its parts; the syntactic pattern it-
tion (Lakoff, 1987): concepts cluster into categories with     self may also contribute a particular conceptual fram-
prototype structure and graded category membership.            ing. For example, the Caused-Motion construction
   For our current spotlight on the acquisition of gram-       underlying Pat sneezed the napkin off the table imposes
matical structures, we will make a similar set of simpli-      a causative reading on the typically non-causative verb
fying assumptions. We do not attempt to model the com-         sneeze, and the need for an agentive recipient in the Di-
plex reasoning and inference processes needed to infer         transitive construction renders Harry kicked the door
the appropriate intended meaning of an utterance in con-       the ball somewhat anomalous.
text; rather, we take as input a representation of the in-        On this account, syntactic patterns are inextricably
ferred meaning in a given situational context. We also as-     linked with meaning, and grammaticality judgments are
sume that lexical maps like those produced by the word-        rightly influenced by semantic and pragmatic factors.
learning models described above are available as input to      The interpretation and acceptability of an utterance thus
the grammar-learning process.                                  depends not only on well-formedness conditions but also
   For present purposes, the precise variant of word           on the structure of the language user’s conceptual ontol-
learning is not at issue, as long as several representa-       ogy and on the situational and discourse context.
tional requirements are met. Lexical maps should facil-           The main representational complexity introduced with
itate the identification of similar concepts and provide       these multiword constructions is the possibility of struc-
some basis for generalization. They must also be able to       ture in the form pole. As mentioned above, although
capture the kinds of event-based knowledge mentioned           individual lexical items can evoke complex frames with
above: the meanings of many early words and construc-          multiple participant roles (e.g., bye-bye, baseball), the
tions involve multiple entities interacting within the con-    actual mapping between the form and meaning pole
text of some unified event (Bloom, 1973) or basic scene        is necessarily straightforward. With multiple form
(Slobin, 1985). Fortunately, these representational de-        units available, however, additional structures arise, both
mands have long been recognized in the context of adult        within the form pole itself and, more significantly, in the
constructions, and semantic descriptions based on frames       relational correlations between the form and meaning
relating various participant roles have been developed by,     poles.2 That is, a multiword construction may involve
e.g., the Berkeley FrameNet project (Baker et al., 1998).      a more complex, structured map between its form and
Frame-based representations can capture the relational         meaning poles, with maps between form and meaning
structure of many concepts, including not only early sen-      relations whose arguments are also mapped.
sorimotor knowledge but also aspects of the surrounding           In addition to the sound patterns of individual words,
social and cultural context.                                   the form pole includes intonational contours, morpholog-
   It will be convenient to represent frames in terms          ical inflections and word order. As with single words, the
of individual role bindings: Throw.thrower:Human and           meaning pole encompasses the much larger set of frame-
Throw.throwee:Object together bind a Throw frame with a        based conceptual knowledge. The constructional map-
Human thrower acting on an Object throwee. Note that al-       ping between the two domains typically consists of a set
though this representation highlights relational structure     of form relations (such as word order) corresponding to
and obscures lower-level features of the underlying con-       a set of meaning relations (such as role-filler bindings).
cepts, both aspects of conceptual knowledge will be cru-
cial to our approach to language learning.
                                                                                                                                      meaning
                                                                               form   THROW- TRANSITIVE
   In the current model, ontological knowledge is rep-                                                constructional
resented with an inheritance hierarchy in which frames         FORM
                                                                                      t1                   t2                    t3
                                                                                                                                                          MEANING
are represented as feature structures (i.e., attribute-value
                                                                                            meaning
                                                                      I       form    I                                                                      Speaker
matrices) and role bindings are handled by unification.
                                                                                                                                                             Throw
Our initial set of constructions contains a number of lex-
                                                                                                                       meaning
                                                                                           form
                                                                                                                                                             thrower
                                                                 throw                                THROW
ical form-meaning maps, where for simplicity we further                                                                                                      throwee
constrain these to be mappings from orthographic forms
                                                                                                                                                meaning
                                                                the ball                                        form    THE- BALL                            Ball
to feature-structure meanings, as in Bailey (1997).
   We now turn to the representationally more complex
case of grammatical constructions, before addressing           Figure 1: A constructional analysis of the sentence, I
how such constructions are learned.                            throw the ball, with form elements at left, meaning ele-
          Grammatical Constructions                            ments at right and some constituent constructions linking
                                                               the two domains in the center.
We base our representations of grammatical knowledge
on ideas from Construction Grammar (Goldberg, 1995)            As an example, Figure 1 gives an iconic representation of
and Cognitive Grammar (Langacker, 1987). In these ap-          some of the possible constructions involved in an analy-
proaches, larger phrasal and clausal units are, like lexical       2 See Gasser and Colunga (2000) for arguments that the abil-
constructions, pairings of form and meaning. A key ob-         ity to represent relational correlations underlies infants’ reputed
servation in the Construction Grammar tradition is that        aptitude for statistically driven learning of concrete and abstract
the meaning of a sentence may not be strictly predictable      patterns.

sis of I throw the ball. The lexical constructions for I,                         Learning Constructions
throw and the-ball3 all have simple poles of both
                                                                  We can now specify our construction learning task:
form and meaning. But besides the individual words and            Given an initial set of constructions C and a sequence
concepts involved in the utterance, we have several word          of new training examples, find the best set of construc-
order relationships (not explicitly shown in the diagram)         tions C 0 to fit the seen data and generalize to new data. In
that can be detected in the form domain, and bindings             accord with our discussion of conceptual prerequisites, a
between the roles associated with Throw and other se-             training example is taken to consist of an utterance paired
mantic entities (as denoted by the double-headed arrows           with a representation of a situation, where the former is
within the meaning domain). Finally, the larger clausal           a sequence of familiar and novel forms, and the latter a
construction (in this case, a verb-specific one) has con-         set of frame-based conceptual entities and role bindings
stituent constructions, each of which is filled by a differ-      representing the corresponding scene.
ent lexical construction.4 Crucially, the clausal construc-
                                                                     Previous work on Bayesian model merging (Stolcke,
tion serves to associate the specified form relations with
                                                                  1994; Bailey et al., 1997) provides a suitable starting
the specified meaning relations, where the arguments of
                                                                  point. In that framework, training data is first incor-
these relations are already linked by existing (lexical)
                                                                  porated, with each example stored as an independent
maps. For example, the fact that the I construction’s form
                                                                  model. Similar models are then merged (and thereby
pole comes before the throw construction’s form pole
                                                                  generalized); the resulting drop in likelihood is balanced
means that the meaning pole of I (i.e., the speaker in the
                                                                  against an increase in the prior. Merging continues until
situation) fills the thrower role in the Throw frame.
                                                                  the posterior probability of the model given the data de-
   A more formal representation of the Throw-                     creases. In the case of probabilistic grammars (Stolcke
Transitive construction is given in Figure 2. For cur-            and Omohundro, 1994), structural priors favor grammars
rent purposes, it is sufficient to note that this represen-       with shorter descriptions, and likelihood is based on the
tation captures the constituent constructions, as well as         probability of generating the data using the grammar.
constraints on its formal, semantic and constructional el-           We apply a similar strategy to our current task by cast-
ements. Each constituent has an alias used locally to             ing it as a search through the space of possible grammars
refer to it, and subscripts f and m are used to denote            (or sets of constructions), where the grammars are evalu-
the constituent’s form and meaning poles, respectively.           ated using Bayesian criteria. The operations on the set of
A designation constraint (in Langacker’s (1987) sense)            constructions (merging and composition, described be-
specifies a meaning type for the overall construction.            low as reorganization processes) extend previous oper-
                                                                  ations to handle relational structures. Similarly, the eval-
                                                                  uation criteria need not change significantly for the con-
          construction Throw-Transitive
             constituents:                                        struction learning case: structural priors favor grammars
                construct t1 of meaning type Human                with fewer, more general constructions that compactly
                construct t2 of type Throw                        encode seen data; this measure combats the inevitable
                construct t3 of meaning type Object               corresponding drop in the likelihood of generating the
             formal constraints:                                  seen data using the grammar. Again, the learning algo-
                t1 f before t2 f
                t2 f before t3 f                                  rithm attempts to maximize the posterior probability of
                                                                  the set of constructions given the data.5
                              !
             semantic constraints:
                t2m .thrower
                t2m .throwee  !  t1m
                                   t3m
                                                                     The main complication requiring a departure from pre-
                                                                  vious work is the need to hypothesize structured maps
          designates t2m
                                                                  between form and meaning like those described in the
                                                                  previous section. Essentially, incorporating new data in-
Figure 2:       Formal representation of the Throw-
                                                                  volves both the analysis of an utterance according to
Transitive        construction, with separate blocks listing      known constructions and the hypothesis of a new con-
constituent constructions, formal constraints (e.g., word         struction to account for any new mappings present in
order) and semantic constraints (role bindings).                  the data. These processes, described below, are based
                                                                  on the assumption that the learner expects correlations
   Although this brief discussion necessarily fails to do         between what is heard (the utterance) and what is per-
justice to Construction Grammar and related work, we              ceived (the situation).6 Some of these correlations have
hope that it nevertheless conveys the essential represen-         already been encoded and thus accounted for by previ-
tational demands on the structures to be learned.
                                                                      5 Model merging conducts a best-first search through the hy-
                                                                  pothesis space based on available merges. It is thus is not guar-
    3 The definite determiner the explicitly depends on a repre-  anteed to find the best model, which would require searching
sentation of the situational and discourse context that supports  through an exponential number of possible grammars.
reference resolution. For simplicity, we will ignore the internal     6 The task as defined here casts the learner as primarily com-
structure of “the ball” and treat it as an unstructured unit.     prehending (and not producing) grammatical utterances. The
    4 This example, like the rest of those in the paper, is based current model does not address production-based means of hy-
on utterances from the CHILDES corpus (MacWhinney, 1991)          pothesizing and reinforcing constructions, which would be in-
of child-language interaction.                                    cluded in a more complete model.

ously learned constructions; the tendency to try to ac-          Next, the constraints specified by these constructions
count for the remaining ones leads to the formation of           must be matched against the input utterance and situa-
new constructions. In other words, what is learned de-           tion. The form constraints for all the lexical construc-
pends directly on what remains to be explained. The              tions are trivially satisfied, and in this case each also hap-
identification of the mappings between an utterance and          pens to map to a meaning element present in S.7 Check-
a situation that are predicted by known constructions can        ing the form and meaning constraints of the throw-
be seen as a precursor to language comprehension, in
                                                                 ball construction is also trivial: all relations of inter-
which the same mappings actively evoke meanings not
present in the situation. Both require the learner to have       est are directly available in the input utterance and situa-
an analysis procedure that determines which construc-            tion.8
tions are potentially relevant, given the utterance, and,
                                                                    Analyze utterance. Given utterance U in situation S and
by checking their constraints in context, finds the best-           current constructions C , produce best-fitting analysis A:
fitting subset of those.
    Once the predictable mappings have been explained               1. Extract the set Fknown of familiar form units from U , and
away, the learner must have a procedure for determin-                    use them to cue the set Ccued of constructions.
ing which new mappings may best account for new data.               2. Find the best-fit analysis A =                  
                                                                                                             CA FA MA , where
                                                                        CA is the best-fitting subset of Ccued for utterance U in
The mappings we target here are, as described in the pre-                situation S, FA is the set of form units and relations in U
vious section, relational. It is important to note that a                used in CA , and MA is the set of meaning elements and
relational mapping must hold across arguments that are                   bindings in S accounted for by CA .
themselves constructionally correlated. That is, map-                    A has associated cost CostA providing a quantitative
pings between arguments must be in place before higher-                  measure of how well A accounts for U in S.
order mappings can be acquired. Thus the primary can-               3. Reward constructions in CA ; penalize cued but unused
didates for relational mappings will be relations over el-               constructions, i.e., those in Ccued n CA .
ements whose form-meaning mapping has already been
established. This requirement may also be viewed as                               Figure 3: Construction analysis.
narrowing the search space to those relations that are
                                                                     In the eventual best-fitting analysis A, the con-
deemed relevant to the current situation, as indicated by
their connection to already recognized forms and their           structions used are CA =fyou,throw,ball,throw-
                                                                 ballg, which cover the forms and form relations
mapped meanings.
                                                                 in FA = fyou,throw,ball,before(throw,ball)g and
    Details of these procedures are best illustrated by ex-
ample. Consider the utterance U1 = “you throw a ball”            map the meanings and meaning relations in MA =
spoken to a child throwing a ball. The situation S con-
                                                                 fSelf,Throw,Ball,Throw.throwee:Ballg. (Remaining unused
sists of entities Se and relations Sr ; the latter includes role in this analysis is the form a.)
                                                                     We proceed with our example by applying the proce-
bindings between pairs of entities, as well as attributes
                                                                 dure shown in Figure 4 to hypothesize a new construc-
of individual entities. In this case, Se includes the child,
the thrown ball and the throwing action, as well as po-          tion. All form relations and meaning bindings, respec-
                                                                 tively, that are relevant to the form and meaning entities
tentially many other entities, such as other objects in the
                                                                 involved in the analysis are extracted as, respectively,
immediate context or the parent making the statement:
Se = fSelf,Ball,Block,Throw,Mother,. . . g. Relational bind-     Frel = fbefore(you,throw), before(throw,ball),
                                                                 before(you,ball)g and Mrel = fThrow.thrower:Self,
ings include those encoded by the Throw frame, as well
                                                                 Throw.throwee:Ballg; the remainder of these not used
as other properties and relations: Sr = fThrow.thrower:Self,
                                                                 in the analysis are Frem = fbefore(you,throw),
Throw.throwee:Ball, Ball.Color:Yellow, . . . g.
                                                                 before(you,ball)g and Mrem = fThrow.thrower:Selfg.
    In the following sections we describe what the learner
                                                                 The potential construction Cpot derived by replacing
might do upon encountering this example, given an
                                                                 terms with constructional references is made up of form
existing set of constructions C that has lexical en-
                                                                 pole fbefore(you f ,throw f ),before(you f ,ball f )g
tries for ball,throw,block,you,she, etc., as well
                                                                 and meaning pole fThrowm .thrower:youm g. The final
as a two-word throw-ball construction associating
the before(throw,ball) word-order constraint with the                 7 We assume the you construction is a context-dependent
binding of Ball to the throwee role of the Throw frame.          construction that in this situation maps to the child (Self).
                                                                      8 The analysis algorithm can be viewed as a version of pars-
                                                                 ing allowing both form and meaning constraints. More sophis-
Construction analysis and hypothesis                             ticated techniques are needed for the many complications that
                                                                 arise in adult language – category constraints on roles may ap-
Given this information, the analysis algorithm in Fig-           ply only weakly, or may be overridden by the use of metaphor
ure 3 first extracts the set Fknown = fyou,throw,ballg,          or context. For the cases relevant here, however, we assume
which serves to cue constructions whose form pole in-            that constraints are simple and few enough that exhaustive
                                                                 search should suffice, so we omit the details about how cueing
cludes or may be instantiated by any of these units. In          constructions, checking constraints and finding the best-fitting
this case, Ccued = fyou,throw,ball,throw-ballg.                  analysis proceed.

construction CU1 is obtained by retaining only those               Reorganize constructions. Reorganize          C to consolidate
relations in Cpot that hold over correlated arguments:             similar and co-occurring constructions:
(fbefore(you f ,throw f )g, fthrowm .thrower:youm g)              1. Find potential construction pairs to consolidate.
                                                                        Merge constructions involving correlated relational
                                                                          mappings over one or more pairs of similar con-
   Hypothesize construction. Given analysis A of utterance                stituents, basing similarity judgments and type gen-
   U in situation S, hypothesize new construction CU linking              eralizations on the conceptual ontology.
   correlated but unused form and meaning relations:                    Compose frequently co-occurring constructions with
                                                                          compatible constraints.
  1. Find the set Frel of form relations in U that hold between
      the forms in the analysis FA , and the set Mrel of mean-    2. Evaluate how possible merge/compose operations af-
      ing relations in S that hold between the mapped mean-            fect the posterior probability of C on seen data, perform-
      ing elements in MA .                                             ing operations on a greedy, best-first basis.
                          =
  2. Find the set Frem Frel n FA of relevant form relations
                                                    =
      that remain unused in A, and the set Mrem Mrel n MA                    Figure 5: Construction reorganization.
      of relevant meaning relations that remain unmapped in
      A. Create a potential construction Cpot = (Frem ,Mrem ),
      replacing terms with references to constructions in CA    straints with appropriate correlations are found, resulting
      where possible.                                           in the hypothesis of the construction CU2 :
  3. Create a new construction CU consisting of pairs of
      form-meaning relations from Cpot whose arguments are       (fbefore(she f ,throw f )g, fthrowm .thrower:shem g)
      constructionally related.
  4. Reanalyze utterance using C fCU g, producing a new
                                                                CU1 and CU2 bear some obvious similarities: both con-
      analysis A0 with cost CostA . Incorporate CU into C if
                                    0
                                                                structions involve the same form relations and meaning
     CostA , CostA  MinImprovement ; else put CU in pool
                     0                                          bindings, which hold of the same constituent construc-
      of potential constructions.                               tion throw. Moreover, the other constituent is filled in
  5. If U contains any unknown form units or relations, add
           
       U  S to the pool of unexplained data.                   the two cases by she and you. As emphasized in our
                                                                discussion of conceptual representations, a key require-
              Figure 4: Construction hypothesis.                ment is that the meaning poles of these two constructions
                                                                reflect their high degree of similarity.9 The overall simi-
   At this point, the utility of CU1 can be evaluated by re-    larity between the two constructions can lead to a merge
analyzing U1 to ensure a minimum reduction of the anal-         of the constructional constituents, resulting in the merged
ysis cost. As noted in Step 4 of Figure 4, a construction       construction:
not meeting this criterion is held back from incorpora-
tion into C . It is possible, however, that further examples         (fbefore(h f ,throw f )g,fthrowm .thrower:hm g)
will render it useful, so it is maintained as a candidate       where h is a variable over a construction constrained to
construction. Similarly, Step 5 is concerned with main-         have a Human meaning pole (where Human is a gener-
taining a pool of examples involving unexplained form           alization over the two merged constituents). A similar
elements, such as the unfamiliar article a in this example.     process, given appropriate data, could produce the gen-
Further examples involving similar units may together           eralized mapping:
lead to the correct generalization, through the reorgani-
                                                                     (fbefore(throw f ,o f )g,fthrowm .throwee:om g)
zation process to which we now turn.
                                                                where o is constrained to have an Object meaning pole.10
Reorganizing constructions                                         Besides merging based on similarity, constructions
The analysis-hypothesis process just described provides         may also be composed based on co-occurrence. For ex-
the basis for incorporating new examples into the set of        ample, the generalized Human -throw and throw-
constructions. A separate process that takes place in par-      Object constructions just described are likely to occur
allel is the data-driven, bottom-up reorganization of the       in many analyses in which they share the throw con-
set of constructions based on similarities among and co-        stituent. Since they have compatible constraints in both
occurrences of multiple constructions. Figure 5 gives a         form and meaning (in the latter case even based on the
high-level description of this process; we refrain from         same conceptual Throw frame), repeated co-occurrence
delving into too much detail here, since these processes        eventually leads to the formation of a larger construction
are closely related to those described for other general-       that includes all three constituents:
ization problems (Stolcke, 1994; Bailey et al., 1997).              9 The precise manner by which this is indicated is not at is-
   Continuing our example, let us assume that the utter-        sue. For instance, a type hierarchy could measure the distance
ance U2 = “she’s throwing a frisbee” is later encountered       between the two concepts, while a feature-based representation
                                                                might look for common featural descriptions.
in conjunction with an appropriate scene, with similar re-         10 Although not further discussed here, examples with unex-
sults: in this case, both the unfamiliar inflections and the    plained forms (such as the a in U1 and U2 ) may also undergo
article are ignored; the meanings are mapped; and con-          merging, leading to the emergence of common meanings.

      (fbefore(h f ,throw f ),before(throw f ,o f )g,       Baker, C. F., Fillmore, C. J., and Lowe, J. B. (1998).
       fthrowm .thrower:hm ,throwm .throwee:om g)                The Berkeley FrameNet P roject. In Proceedings of
                                                                 COLING-ACL, Montreal, Canada.
Note that both generalization operations we describe are,
like the hypothesis procedure, merely means of finding      Bloom, L. (1973). One word at a time: the use of single
potential constructions, and are subject to the evaluation       word utterances before syntax. Mouton & Co., The
criteria mentioned earlier.                                      Hague.
                       Discussion                           Bloom, P. (2000). How Children Learn the Meanings of
                                                                 Words. MIT Press, Cambridge, MA.
We have described a model of the acquisition of gram-
matical constructions that attempts to capture insights     Gasser, M. and Colunga, E. (2000). Babies, variables,
from child language using the formal tools of machine            and relational correlations. In Proceedings of the
learning. Methods previously applied to word learning            Cognitive Science Society Conference, volume 22,
are extended to handle grammatical constructions, which          pages 182–187.
are claimed to require new representational and algorith-
mic machinery.                                              Goldberg, A. E. (1995). Constructions: A Construction
   The model is compatible to the extent possible with           Grammar Approach to Argument Structure. Univer-
evidence from child language acquisition. In particu-            sity of Chicago Press.
lar, the tight integration proposed between comprehen-      Lakoff, G. (1987). Women, Fire, and Dangerous Things:
sion and learning is consistent with usage-based theories        What Categories Reveal about the Mind. University
of language acquisition: new constructions are hypothe-          of Chicago Press.
sized to capture form-meaning correlations not covered
by known constructions, in a manner akin to some of         Langacker, R. W. (1987). Foundations of Cognitive
Slobin’s (1985) Operating Principles for mapping. The            Grammar, Vol. 1. Stanford University Press.
data-driven progression from lexically specific to more
                                                            MacWhinney, B. (1991). The CHILDES project: Tools
abstract constructions is also consistent with Tomasello’s
                                                                 for analyzing talk. Erlbaum, Hillsdale, NJ.
(1992) observation that the earliest verb-argument con-
structions are lexically specific and give way only later   Regier, T. (1996). The Human Semantic Potential. MIT
to more general argument structure constructions.                Press, Cambridge, MA.
   More broadly, since the algorithm produces construc-
tions based on any utterance-situation pair and existing    Roy, D. and Pentland, A. (1998). Learning audio-
set of constructions represented as described above, it          visually grounded words from natural input. In
can apply equally well for more advanced stages of lan-          Proc. AAAI workshop, Grounding Word Meaning.
guage development, when the learner has more sophis-        Siskind, J. M. (2000). Visual event classification via
ticated meaning representations and more complex con-            force dynamics. In Proc. AAAI-2000, pages 149–
structions. The potential continuity between early lan-          155.
guage acquisition and lifelong constructional reorgani-
zation offers hope for the modeling of adaptive language    Slobin, D. I. (1985). Crosslinguistic evidence for the
understanding systems, human and otherwise.                      language-making capacity. In Slobin, D. I., editor,
                                                                 The Crosslinguistic Study of Language Acquisition,
                  Acknowledgments                                volume 2, chapter 15. Erlbaum, NJ.
We are grateful for the input and influence of Jerry Feld-  Stolcke, A. (1994). Bayesian Learning of Probabilistic
man and the NTL group at ICSI, as well as comments               Language Models. PhD thesis, Computer Science
from the reviewers; opinions and errors remain ours              Division, University of California at Berkeley.
alone. This work was supported in part by an IBM Re-
search Fellowship granted to the first author, and a Praxis Stolcke, A. and Omohundro, S. (1994). Inducing prob-
XXI Fellowship from the Portuguese “Fundação para a            abilistic grammars by Bayesian model merging. In
Ciência e a Tecnologia” to the second author.                   Carrasco, R. C. and Oncina, J., editors, Grammat-
                                                                 ical Inference and Applications, pages 106–118.
                       References                                Springer-Verlag.
Bailey, D. R., Feldman, J. A., Narayanan, S., and Lakoff,   Tomasello, M. (1992). First verbs: A case study of early
      G. (1997). Modeling embodied lexical develop-              grammatical development. Cambridge University
      ment. In Proceedings of the 19th Cognitive Science         Press, Cambridge, UK.
      Society Conference.

