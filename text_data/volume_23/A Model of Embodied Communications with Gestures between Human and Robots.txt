UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Model of Embodied Communications with Gestures between Human and Robots
Permalink
https://escholarship.org/uc/item/7mv2v0ft
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Ono, Tetsuo
Imai, Michita
Ishiguro, Hiroshi
Publication Date
2001-01-01
Peer reviewed
  eScholarship.org                             Powered by the California Digital Library
                                                                University of California

                     A Model of Embodied Communications with Gestures
                                          between Humans and Robots
                                              Tetsuo Ono (tono@mic.atr.co.jp)
                            ATR Media Integration & Communications Research Laboratories
                                2-2 Hikaridai, Seikacho, Sorakugun, Kyoto, 619-0288 Japan
                                           Michita Imai (michita@mic.atr.co.jp)
                            ATR Media Integration & Communications Research Laboratories
                                 Hiroshi Ishiguro (ishiguro@sys.wakayama-u.ac.jp)
                                    Faculty of Systems Engineering, Wakayama University
                           Abstract                                In order to investigate the mechanism of the mutu-
                                                                ally entrained gestures described above, we conduct ex-
   In this paper, we propose a model of embodied commu-         periments on human-robot communications as well as
   nications focusing on body movements. Moreover, we           human-human communications. The reason why we use
   explore the validity of the model through psychologi-        a robot is that we can unrestrictedly design experiments
   cal experiments on human-human and human-robot com-
   munications involving giving/receiving route directions.     by using a programmable robot’s gestures. Moreover, an
   The proposed model emphasizes that, in order to achieve      investigation of human-robot communications can con-
   smooth communications, it is important for a relationship    tribute to research on the methodology of robot design
   to emerge from a mutually entrained gesture and for a        and the interaction between humans and artifacts.
   joint viewpoint to be obtained by this relationship. The        The purpose of this paper is to propose a model of
   experiments investigated the correlations between body
   movements and utterance understanding in order to con-       embodied communications that can give an explanation
   firm the importance of the two points described above.       for the mechanism of communications described above
   We use robots so that we can control parameters in ex-       and, moreover, provide evidence for the validity of the
   periments and discuss the issues related to the interaction  model through psychological experiments. The main
   between humans and artifacts. Results supported the va-
   lidity of the proposed model: in the case of human-human     characteristic of our model is to focus on the relation-
   communications, subjects could communicate smoothly          ship emerging from a mutually entrained gesture and the
   when the relationship emerged from the mutually en-          joint viewpoint obtained by the relationship. The exper-
   trained gesture and the joint viewpoint was obtained; in     iments concretely investigate the correlations between
   the case of human-robot communications, subjects could       body movements and utterance understanding in human-
   understand the robot’s utterances under the same condi-
   tions but not when the robot’s gestures were restricted.     human and human-robot communications involving giv-
                                                                ing/receiving route directions. In such a task, it is hard
                                                                for a person and a stranger to communicate with each
                        Introduction                            other if they do not share the same viewpoint. Here, in
                                                                order to obtain a joint viewpoint, both sides need to con-
Why do people use gestures when communicating? A                struct a relationship emerging from mutually entrained
common scene on a street involving giving/receiving             body movements. We investigate the process of commu-
route directions is some person and a stranger making           nications in the experiments by using our implemented
gestures together as if dancing synchronously and rhyth-        robot.
mically (see Figure 2). These gestures appear not only
when the person describes turns at visible locations, but                  Embodied Communications
also at invisible ones. Moreover, it has been shown that
people are unable to achieve smooth communications if           Previous Research on Gestures
they are restricted from using spontaneous gestures (Ono        Research on gestures conducted to investigate the mech-
et al., 2001). Consequently, gestures play an important         anism of communications emerged around 1980. In
role in human-human communications.                             this field, McNeil was the first to carry out cutting-
   In this paper, however, we do not discuss emblem ges-        edge research. He pointed out that gestures are syn-
tures such as the OK sign; these gestures have arbitrar-        chronized with speech in communications, and thus both
ily defined meanings and figures in social conventions.         are closely connected in the cognitive system (McNeil,
The target of our research is mutually entrained gestures,      1987). McNeil’s research provided findings leading to
where a speaker and a hearer spontaneously and syn-             the development of research on the functions of gestures.
chronously move their bodies according to the entrain-             However, previous research has mainly analyzed the
ment resulting from mutual actions and utterances. We           speaker’s gestures in communications. In other words,
focus on such gestures because smooth communications            many researchers have analytically investigated the cor-
between humans can be expected when these gestures              relations between speech and the speaker’s body move-
are used, as illustrated by the above example involving         ments. Consequently, their aim has been to explain an
giving/receiving route directions.                              internal mechanism of an individual speaker. However,

these research works have not looked into the dynamical          In our proposed model, the characteristic of commu-
mutual interaction between a speaker and a hearer.            nications discussed above is expressed as follows:
   In contrast, we focus on the dynamical mutual interac-
tion in human-human and human-robot communications                                      / U)
                                                                                      (0,       I                      (1)
involving giving/receiving route directions. Especially,
the reason why we come to adopt this route directions is                           O(iR j )                            (2)
that spontaneous gestures such as pointing easily appear                           E(torso, arms, eyes)   iR j         (3)
in this context. Kita (2000) analyzed a speaker’s gestures
for this task but did not deal with the dynamical mutual      Here, 0/ indicates the situation where there is nothing to
interaction between them. In this research, we are able to    point out, iR j is the relationship between persons i and j,
give evidence for a hypothesis in detail because we can       and O is a function for obtaining the viewpoint from the
control the parameters in experiments by using a robot.       relationship. Moreover, torso and arms are expressions
                                                              for entrained movements of the torso and arms, while
Model of Embodied Communications                              eyes expresses the eye contact in communications. E is a
                                                              function of the relationship emerging from the entrained
In this paper, we propose a model of embodied commu-          movements.
nications focusing on entrained body movements. Our              These formulae express the process of communica-
model is basically described by the following formula:        tions involving giving/receiving route directions as fol-
                                                              lows. People cannot adopt an absolute coordinate sys-
                         (S , U )    I                        tem when they do not have a landmark or object to point
                                                              out. Consequently, it is hard for them to achieve utter-
                                                              ance understanding because of the difficulty of obtaining
Here,       is a viewpoint for understanding an utterance     a joint viewpoint (Formula 1). To overcome this prob-
in a situation, S is the situation around a speaker and       lem, they try to construct a relationship to obtain the
a hearer, U is an utterance from the speaker, and I is        joint viewpoint (Formula 2). This relationship emerges
information obtained by having understood utterance U .       from mutual entrained body movements (Formula 3).
   For example, let us suppose that in a situation S in-      Smooth communications can be achieved through these
volving giving/receiving route directions, a person A ut-     processes because the joint viewpoint makes both the
ters “Go right” to a stranger B while both are facing         speaker’s utterance and the hearer’s understanding eas-
each other. Let us further suppose that B understands         ier.
from his/her viewpoint of A that the utterance means the         In our model, we formalize the process of commu-
“right” of A. In this case, the relation among the view-      nications described above. We carry out psychological
point, situation, utterance, and information is expressed     experiments to explore the validity of the model in the
as A (S , UA )        IB . However, B may instead under-      following two chapters.
stand from his/her viewpoint of himself/herself that the
utterance means the “right” of him/her. In this case, the            Human-Human Communications
relation is expressed as B (S , UA ) IB .
                                                              Experiments
   The above ambiguity can be effectively solved by us-
ing an absolute coordinate system. For example, a person      Experiments on human-human communications were
can clearly direct a stranger to a destination when both      conducted by the following method.
sides can use a visible landmark or object, or when both      Outline of experiments We focused on the interac-
sides can construct a similar cognitive map (this assumes     tion between a subject and a person involving giv-
the stranger has previously visited the area). In this case,  ing/receiving route directions as an informant just hap-
the viewpoint       is determined definitely.                 pened to be passing by. Here, we investigated the appear-
   However, a person cannot use an absolute coordinate        ance of their gestures, gestural arrangements, utterances,
system when landmarks and turns to the destination are        and the level of utterance understanding.
invisible, or when a stranger has not visited the area be-
fore. In this case, it is difficult to maintain a joint view- Subjects Ten undergraduate and graduate students
                                                              (male and female). The subjects had not previously
point      in communications because the stranger is un-
                                                              visited the experimental environment, and thus did not
able to imagine the route map of the person; the person’s
                                                              know the route to any destination at all.
memory access also becomes overloaded.
   As described in the Introduction, people seem to solve     Environment Figure 1 shows an outline of the experi-
the problem of deciding a viewpoint by mutually en-           mental setup. These experiments were done in the hall-
trained body movements. In other words, people first          ways of a laboratory. Point A denotes the place where
construct a relationship that emerges from a mutually en-     the route directions were given, and B and C denote the
trained gesture. This relationship allows people to obtain    goals, i.e., a cafeteria and an information desk, respec-
a joint viewpoint. Finally, they can communicate with         tively. Point T1 denotes a turn in the route from A to
each other smoothly because of the utterance understand-      B, and Points T2-T4 denote turns from A to C. Only the
ing achieved as a result of this joint viewpoint.             corner of T1 is visible from A.

                    T1
                            B Cafeteria                         Table 1: Results of entrained actions of arms and eyes in
                                                                human-human interaction.
                               Types of gestural arrangement                        Arm           Elbow       Eye contact
                                                                                synchronized     extended        (total)
                                                                   Cafeteria        6/ 10          6/ 6    12 times/ 123 sec
                                                                  Information       8/ 10          8/ 8    25 times/ 216 sec
                                Aligned    Absolute    Relative
         Informant
                    A
            Subject
                                                 Information
                            T2               C      desk
                             T3          T4
Figure 1: Experimental setup: arrangement of subject,
informant, destinations, and turns.
Procedure The subjects received the following in-
structions from the experimenter (position A): “Ask a           Figure 2: Photo of mutually entrained gesture in human-
passerby the way to the cafeteria and the information           human communications in the route direction.
desk and go to each place by yourself.” The behav-
iors and utterances of the subjects and the persons were
recorded with a camera and a microphone.                        those who made synchronized gestures moved their ex-
                                                                tended arm right and left. Moreover, in all cases, they
Evaluation The results of the experiments were eval-            made eye contact. In particular, in the more complicated
uated from the record of the subjects’ and the persons’         route to C, eye contact was made with high frequency.
behaviors, i.e., gestural arrangements, arm and elbow              Furthermore, the time needed to communicate was
movements, and eye contact. In addition, we evaluated           17.2 seconds in the case of destination B but 32.2 sec-
the time needed to communicate and the accuracy of the          onds in the case of destination C. That is, the more com-
communicated information.                                       plicated route direction statistically needed much more
   We classified the gestural expressions and arrange-          time (t(18) = 2.122, p <. 05). However, there was not
ments into three categories, i.e., aligned, absolute, and       much difference in the kinds of expressions used in the
relative gestures, following the literature (Kita, 2000)        utterances between the two destinations. Eventually, all
(see the upper right-hand side of Figure 1). To illustrate,     of the subjects could arrive at the two destinations. In
let us assume that, at position A in Figure 1, an infor-        other words, information was accurately communicated
mant directs a subject to destination B by telling him/her      from the person to the subjects.
to turn right at corner T1. In aligned gesture, an infor-          A summary of the experimental results is as follows.
mant makes gestures to indicate his/her right aligning          First, the persons acting as informants made spontaneous
his/her torso orientation with that of the subject. In ab-      gestures not only when they described turns at visible lo-
solute gesture, an informant makes gestures to indicate         cations but also at invisible ones. The subjects involun-
the subject’s right while facing the subject. In relative       tarily made entrained and synchronized gestures to the
gesture, an informant makes gestures to indicate his/her        persons.
right while facing the subject.                                    We can assume the following relation between the ex-
                                                                perimental results and our proposed model. The subjects
Results                                                         had not previously visited the experimental environment.
First, the gestural expressions and arrangements that the       Therefore, it was hard for the subjects to understand the
subjects and the persons took were aligned gesture in           persons’ utterances because of the difficulty of obtaining
nine out of ten cases and relative gesture in the remain-       a joint viewpoint (Formula 1). To overcome this prob-
ing one case. These results were the same for both des-         lem, they tried to construct a relationship to obtain the
tinations. Next, Table 1 shows the analyzed results of          joint viewpoint (Formula 2). This relationship emerged
synchronized gestures between the subjects and the per-         from mutually entrained body movements (Formula 3).
sons. Synchronized arm gestures were observed in six               In the next chapter, we describe experiments on
out of ten cases in the route directions to destination B       human-robot communications in order to investigate
and eight out of ten cases to destination C. Here, synchro-     these mechanisms in detail. We can unrestrictedly design
nized arm gestures mean that the subject synchronously          the experiments by using a programmable robot’s ges-
makes similar movements to the person’s spontaneous             tures. Moreover, the investigation of human-robot com-
arm movements (see Figure 2). In this experiment, all           munications can contribute to research on robot design
of the persons made arm movements. In addition, all of          and the interaction between humans and artifacts.

                                                                                                       X
          Human-Robot Communications
 Experiments
 Experiments on human-robot communications were con-                                            Z
 ducted by the following method.                                                                                Y
 Outline of experiments We focused on the interaction                                                    Q S
 between a subject and a robot as an informant involving
 giving/receiving route directions. Here, we investigated                                                      R
 the appearance of the subject’s gesture and the level of
 utterance understanding while changing the robot’s ges-
 ture.                                                                                                       P
 Subjects Thirty undergraduate and graduate students           Figure 3: Outline of robot called “Robovie” (left), and
 (male and female). The subjects were randomly divided         robot’s head and arm motion mechanisms (right).
 into six groups. The subjects had not previously visited
 this experimental environment, as in the human-human
 experiments.                                                  Conditions We prepared the following six conditions
 Robot Our robot system can make gestures by using             from C-1 to C-6, which differed in terms of the robot’s
 the upper part of its body in the same way as a human         body movements (see Figure 5). The content of the ut-
 (see Figure 3). The robot has two arms, two eyes, a mo-       terance was the same under every condition.
 bile platform, and various actuators and sensors. With
 this equipment, the robot can generate almost all of the      C-1 (No gesture): The robot did not move.
 behaviors needed for communications with humans.
                                                               C-2 (Absolute gesture): The robot raised its left arm
 Environment Figure 4 shows an outline of the experi-             leftward when telling the subject that he/she should
 mental setup. These experiments were done in the hall-           go right, while it raised its right arm rightward when
 ways and lobby of a laboratory. Points S and R denote            telling the subject that he/she should go left.
 the initial positions of the subject and robot, respectively.
 Point A denotes the place where the route directions were     C-3 (Absolute gesture with gaze): In addition to C-2,
 given, and B denotes the goal, i.e., the lobby. Points T1-       the robot turned its eyes to the subject while making
 T4 denote turns in the route from A to B, directed by the        the utterance.
 robot. Only the corner of T1 is visible from A.
                                                               C-4 (Only aligned torso): The robot rotated so that it
 Procedure      The experiments consisted of the following        aligned its torso with the subject.
 six phases.
                                                               C-5 (Aligned gesture): In addition to C-4, the robot
1. The subjects received the following instructions from          raised an arm forward telling the subject when he/she
    the experimenter (position S): “Ask the robot the way         should go forward, rightward when the subject should
    to a lobby and go there by yourself.” The question to         go rightward, and leftward when the subject should go
    the robot was specified as follows: “Tell me the way          leftward.
    to the lobby.”
                                                               C-6 (Aligned gesture with gaze): In addition to C-5,
2. The subjects moved from S to A, and the robot from R           the robot turned its eyes to the subject while making
    to A.                                                         the utterance.
3. At position A, the subjects asked the question, and the     Evaluations The results of the experiments were eval-
    robot answered. The robot could make its utterance         uated from the record of the subjects’ behaviors and the
    with synthesized speech sounds. The content of the         answers of the questionnaire. In the questionnaire, the
    utterance was “Go forward, turn right, turn left, turn     subjects were asked whether they understood the robot’s
    right, turn left, and then you’ll be at the destination.”  utterance and to give a psychological evaluation of the
    The robot could make gestures while uttering this. In      robot on a seven-point scale for six items: Familiar-
    these experiments, we prepared six conditions under        ity, Sincerity, Reliability, Intelligence, Extroversion, and
    which the robot’s gesture was changed.                     Kindness.
4. The subjects tried to go to the lobby after receiving the
    robot’s directions.                                        Predictions
                                                               In the experiments, we gave evidence for the following
5. The experiments finished whether the subjects arrived       three predictions derived from the proposed model. The
    at the lobby or gave up after losing their way. The        more the robot’s gestures increase systematically rather
    subjects psychologically evaluated the robot through a     than randomly, i.e., the more the conditions shift in order
    questionnaire after the experiments finished.              from C-1 to C-6,

            Stairs     Lobby
                  B
                      T4
             Elevator
                       T3         T2
                                          R         S
                                  T1            A
                                        Robot     Subject
Figure 4: Experimental setup: arrangement of subject,
robot, destination, and turns.
                                                           Figure 6: Results of subjects’ body movements in
                             A
                                                           human-robot interaction.
                     Robot           Subject
                  C-1         C-2             C-3
                   C-4        C-5             C-6
                                                           Figure 7: Photos of a subject under Condition C-1 (left)
                                                           and two subjects under C-6 (center and right).
Figure 5: Outline of experimental conditions under
changing robot gestures.
                                                           up to the elbow level (Elbow). In the analysis, a signif-
                                                           icant difference was found between the ratio of appear-
Prediction 1: the more the subjects’ gestures will in-     ances of the subjects’ body movements and the condi-
   crease by entrainment and synchronization with the      tions (χ2 = 25.210, p <. 01). In other words, the more
   robot’s, and consequently, a relationship will emerge   the conditions shifted from 1 to 6 (i.e., the more the
   from the mutual gestures.                               robot’s gestures increased systematically), the more the
                                                           subjects’ gestures increased in sync. Moreover, the aver-
Prediction 2: the easier the joint viewpoint will be ob-   age scores for the numbers of times the subjects turned
   tained by the relationship.                             their eyes to the robot were higher when the robot turned
                                                           to meet the eyes of the subjects (C-3 and C6).
Prediction 3: the easier the subjects will understand the
   utterance of the robot and arrive at the destination by    We show appearances of the experiments in Figure 7.
   using the obtained viewpoint.                           First, the left-hand side of Figure 7 shows the appear-
                                                           ance of a subject not making any body movement and
Here, Predictions 1, 2, and 3 correspond to Formulae (3),  not turning his eyes to the robot at all (C-1). In contrast,
(2), and (1) in the model of embodied communications,      the center of Figure 7 shows the appearance of a sub-
respectively.                                              ject making an entrained body movement and turning his
                                                           eyes to the robot (C-6). The right-hand side of Figure
Results                                                    7 also shows the appearance of a subject making an en-
We give evidence for the three predictions in the order of trained body movement and turning her eyes in the same
Predictions 1, 3, and 2 to make the point of our argument  direction as the robot (C-6).
clearer.                                                      As a result of the observations described above, we
Verification of Prediction 1 From the observation re-      could confirm that relationships emerged between the
sults on the subjects’ behaviors, we analyzed the sub-     subjects and the robot from mutually entrained gestures.
jects’ gestures. First, the gestural arrangements that     Consequently, Prediction 1 was supported.
the subjects took were as we had expected (see Figure      Verification of Prediction 3 We recorded the time the
5). Next, Figure 6 shows the ratio of appearances of       subjects spent moving from A to B in Figure 4. Table 2
the subjects’ body movements under each condition. In      shows the average time and the number of subjects not
this analysis, we classified the subjects into three cate- arriving at B under each condition. Regarding the av-
gories: subjects who did not practice body movements       erage time, no significant difference was found between
at all (Nothing), subjects who only moved their hands      the conditions. However, the average time in C-6 was the
(Hand), and subjects who moved and raised their hands      shortest.

Table 2: Average time until subjects’ arrival at destina-
tion, and number of subjects not arriving at destination.
                        C-1  C-2  C-3   C-4   C-5   C-6
    Time to destination 69.5 71.3 67.7  70.2  66.8  65.4
    Number of subjects   1    2    2     0     0     0
       not arriving
   A noteworthy point is that a considerable number of
subjects did not arrive at the goal in C-1, C-2, and C-3.
The results of the questionnaire clearly showed that the
subjects who did not arrive were unable to correctly un-
derstand the robot’s utterance. One of the comments of-
ten heard was that they could not understand whether the
robot’s utterance including “left” and “right” meant the   Figure 8: Results of subjects’ psychological evaluations
robot’s or the subjects’. In other words, the reason why   to a robot.
the subjects did not understand the utterance was that
they could not obtain a joint viewpoint with the robot.
   Consequently, the subjects who did manage to obtain     iments roughly supported our research direction. How-
a joint viewpoint could understand the robot’s utterance   ever, we could not investigate the details of the model
and arrive at the goal, whereas the subjects who did not   because we were unable to manipulate the parameters in
were unable to understand and arrive at the goal. There-   the experiments. Therefore, we carried out similar ex-
fore, Prediction 3 was supported.                          periments using our implemented robot system. From
                                                           the results of these experiments, we could give evidence
Verification of Prediction 2 First, we discuss obtain-     for the validity of the model more appropriately.
ing a joint viewpoint from the aspect of body arrange-        The contributions of our research should be viewed
ment. Under the verification of Prediction 3, it was clear from two perspectives. First, our model of embodied
that all of the subjects could obtain a joint viewpoint    communications suggests a new direction in research on
when the robot aligned its body arrangement with the       communications. The target of previous research had
subject’s to the destination (C-4, C-5, and C-6). In con-  mainly been the mechanism of verbal communications
trast, approximately one-third of the subjects could not   based on informatics approaches, e.g., Shannon’s model.
obtain a joint viewpoint when the robot did not align its  After that, McNeil’s school pointed out that gestures are
body arrangement (C-1, C-2, and C-3). Consequently, it     synchronized with speech. However, they have not yet
is hard for subjects to obtain a joint viewpoint when no   modeled a whole conception of interactive communi-
relationship emerges from the use of body arrangement.     cations that includes the function of embodiment. Our
   Next, we discuss obtaining a joint viewpoint from the   model gives a clue toward better understanding of such
aspect of mutually entrained gestures such as synchro-     communications.
nized arm movements and eye contact. As discussed in          Moreover, the results of this research can be applied
the verification of Prediction 1, from the results of the  to interactive technologies between humans and artifacts.
observed data, the more the robot’s gestures increased     In other words, artifacts that can draw out human phys-
systematically, the more the subjects’ gestures did so.    ical movements can make humans feel familiar with
Moreover, from the results of the questionnaire, the more  them. These cognitive engineering technologies enable
the conditions shifted from C-1 to C-6, the higher the av- us to develop an interface system and a robot system in
erage scores became (see Figure 8). In other words, the    the work’s next generation.
more the conditions shifted, the smoother the communi-
cations became. Based on this consideration, the rela-                            References
tionship that emerged from the entrained gesture made it   Kita, S. (2000). Interplay of gaze, hand, torso orientation
easier to obtain the joint viewpoint.                         and language in pointing. In Pointing: Where lan-
   As a result of the above observations, Prediction 2 was    guage, culture, and cognition meet. Cambridge Uni-
supported. Consequently, the validity of our proposed         versity Press, Cambridge.
model was given evidence by the three supported predic-
tions.                                                     McNeill, D. (1987). Psycholinguistics: A new approach.
                                                              Harper & Row.
              Discussion and Conclusions                   Ono, T., Imai, M., Ishiguro, H., & Nakatsu, R.
In this paper, we proposed a model of embodied com-           (2001). Embodied communication emergent from
munications focusing on body movements. Moreover,             mutual physical expression between humans and
we explored the validity of the model through experi-         robots. Transactions of Information Processing So-
ments on human-human communications involving giv-            ciety of Japan, (submitted).
ing/receiving route directions. The results of the exper-

