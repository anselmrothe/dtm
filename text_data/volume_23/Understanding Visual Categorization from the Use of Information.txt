UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Understanding Visual Categorization from the Use of Information
Permalink
https://escholarship.org/uc/item/0jm7n0tj
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Authors
Bonnar, Lizann
Schyns, Philippe G.
Gosselin, Frederic
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                      Understanding Visual Categorization from the Use of Information
                                      Lizann Bonnar (LIZANN@PSY.GLA.AC.UK)
                                Philippe G. Schyns (PHILIPPE@PSY.GLA.AC.UK)
                                  Frédéric Gosselin (GOSSELIF@PSY.GLA.AC.UK)
                            Department of Psychology, University of Glasgow, 58 Hillhead Street,
                                                    Glasgow, Scotland, G12 8QB
                            Abstract                                (Biederman & Gerhardstein, 1995; Jolicoeur, 1990;
                                                                    Tarr & Bülthoff, 1995).
   We propose an approach that allows a rigorous                       To address these complex issues, recognition
   understanding of the visual categorization and                   researchers should be equipped with methodologies of a
   recognition process without asking direct questions about
                                                                    commensurate power; methodologies that can assign
   unobservable memory representations. Our approach
   builds on the selective use of information and a new             the credit of behavioral performance (e.g., viewpoint-
   method (Gosselin & Schyns, 2000, Bubbles) to depict              dependence, configural effects, color, speed of
   and measure what this information is. We examine three           categorization, point of entry, expertise and so forth) to
   face recognition tasks (identity, gender, expressive or          specific properties of the representations of visual
   not) and establish the information responsible for               events in memory. However, the relationship between
   recognition performance. We compare the human use of             behavior and representations is tenuous, making
   information to ideal observers confronted to similar             representational issues the most difficult to approach
   tasks. We finally derive a gradient of probability for the       experimentally.
   allocation of attention to the different regions of the face.
                                                                       In this paper, we propose an alternative approach that
                                                                    allows a rigorous understanding of the recognition
                      Introduction                                  process, without directly asking questions about
In recent years, most face, object and scene recognition            unobservable memory representations. Our analysis
researchers have gathered around a common agenda: to                builds on the selective use of diagnostic information, an
understand the structure of representations in memory.              important but neglected stage of the recognition
A number of fundamental issues have been articulated,               process. To recognize an object, people selectively use
and researchers typically ask questions such as: “Are               information from its projection on the retina. This
face, object and scene representations viewpoint-                   information is not available to conscious experience,
dependent? “ (Hill, Schyns & Akamatsu, 1997; Perrett,               but the visual system knows what it is, and how to
Oram & Ashbridge, 1998; Troje & Bülthoff, 1996; Tarr                extract it from the visual array.          Our approach
& Pinker, 1989; Bülthoff & Edelman, 1992; Simons &                  interrogates the visual system to determine and to
Wang, 1998, among many others);                      “Are these     depict the information the system uses to recognize
representations holistic (e.g, view-based, Poggio &                 stimuli.
Edelman, 1990; Tarr & Pinker, 1991; Ullman, 1998), or                  The aim of this paper is twofold. At an empirical
made of smaller components? (e.g,, geons, Biederman,                level, we will use Gosselin and Schyns (2000) Bubbles
1987; Biederman & Cooper, 1991)”; “Are internal                     technique to visualize the information used in three face
representations complete (e.g., Cutzu & Edelman,                    categorization tasks (identity, gender and expressive or
1996), or sparse? (Archambault, O’Donnell & Schyns,                 not). Faces are a good stimulus for our demonstrations:
1999; Rensink, O’Regan & Clark, 1997), “two- or                     their compactness enables a tight control of presentation
three-dimensional?” (Liu, Knill & Kersten, 1995),                   which limits the spatial extent of useful cues; the
“colored or not?” (Biederman & Ju, 1988; Oliva &                    familiarity of their categorizations simplifies the
Schyns, 2000; Tanaka & Presnell, 1999), “Are they                   experimental procedure which does not require prior
hierarchically organized in memory?” (Jolicoeur, Gluck              learning of multiple categories--most people are
& Kosslyn, 1984; Rosch, Mervis, Gray, Johnson &                     “natural” face experts (Bruce, 1994). However, the
Boyes-Braem, 1976), “Is there a fixed entry point into              principles developed with faces also apply to the more
the hierarchy?” (Gosselin & Schyns, in press; Tanaka &              general cases of objects and scenes.
Taylor, 1991)          “Does expertise modify memory                   At a more theoretical level, we will reveal the
representations?” (Biederman & Shiffrar, 1987; Tanaka               information used in recognition tasks without asking
& Gauthier, 1998; Schyns & Rodet, 1997) and the entry               questions (or even making assumptions) about memory
point to recognition?” (Tanaka & Taylor, 1991); “What               representations.     This is nonetheless a powerful
is the format of memory representations, and does it                approach because the information used encompasses all
change uniformly across the levels of a hierarchy?”                 the visual features that mediate the recognition task at

hand. These features therefore reflect the information     frequencies of one octave each). Figure 1 illustrates the
required from memory to recognize the stimulus; their      stimulus generation process.
extraction from the visual array specifies the job of low-    To compute each stimulus, we first decomposed an
level vision. Shortly put, the features involved in a      original face into 6 bands of spatial frequencies of one
recognition task bridge between memory and the visual      octave each—at 2.81, 5.62, 11.25, 22.5, 45 and 90
array. Now, show me the features!                          cycles per face, from coarse to fine, respectively
                                                           (computations were made with the Matlab Pyramid
                   Experiment                              Toolbox, Simoncelli, 1997). The coarsest band served
This experiment was cast as a standard face                as a constant background, as a prior study revealed that
categorization and recognition experiment.           In a  it does not contain face identification information.
between-subjects design, a different subject group            The face represented at each band was then partly
resolved one of three possible categorizations (identity,  revealed by a mid-grey mask punctured by a number of
gender, expressive or not) on the same set of ten faces    randomly located Gaussian windows (henceforth called
(5 males, 5 females), each displaying two possible         “bubbles”). The size of the Gaussian differed for each
expressions (neutral vs. happy).           Prior to the    frequency band, to normalize to 3 the number of cycles
experiment, all subjects learned the identity of the ten   per face that any bubble could reveal (standard
faces, in order to normalize exposure to the stimuli.      deviations of bubbles were 2.15, 1.08, .54, .27, and .13
  To determine the specific use of face information in     cycles/deg of visual angle, from coarse to fine scales).
each task, we applied Gosselin and Schyns’ (2000)          Since the size of the bubbles decreases from coarse to
Bubbles technique. Bubbles samples an input space to       fine scales, we multiplied the number of bubbles at each
present as stimuli sparse versions of the faces. Subjects  scale to normalize the average area of the face revealed
categorize the sparse stimuli and Bubbles keeps track of   at each scale.
the samples of information that lead to correct and           To generate an experimental stimulus, we simply
incorrect categorization responses.           From this    added the information revealed at each scale. The total
information, we can derive the usage of each region of     subspace revealed by the bubbles (and therefore the
the input space for the categorization task at hand (see   number of bubbles per scale) was adjusted to maintain
Figure 1).       In a nutshell, Bubbles performs an        categorization of the sparse faces at a 75% correct
exhaustive search in a specified image generation space    criterion.
(here, the image plane x spatial scales), using human
recognition responses to determine the diagnostic
information.
                        Methods
Participants.
                                                              a .
Participants were forty-five paid University of Glasgow
students, with normal, or corrected to normal vision.
Each participant was randomly assigned to one of three
possible experimental groups (IDENTITY; male vs.
female, GENDER; expressive or not, EXNEX) with the            b .
constraint that the number of participants be equal in
each group.
Stimuli.
All experiments reported in this paper ran on a               c .
Macintosh G4 using a program written with the
Psychophysics Toolbox for Matlab (Brainard, 1997;
Pelli, 1997). Stimuli were computed from the greyscale
faces of Schyns and Oliva (1999) (5 males, 5 females          d .
each of whom displayed two different expressions,
neutral and happy, with normalized hairstyle, global
orientation and lighting).
  To search for diagnostic information, we used
Gosselin and Schyns’ (2000) Bubbles technique applied
to an image generation space composed of three
dimensions (the standard X and Y axes of the image
plane, plus a third Z axis representing 6 bands of spatial    e .

Figure 1 illustrates the application of Bubbles to the 3D space       From CorrectPlane(scale) and TotalPlane(scale), we
composed of a 2D face in Experiment 2. Pictures in (b)             can compute for each subject the diagnositicity of each
represent five different scales of (a); (c) illustrate the bubbles region of the input space with ProportionPlane(scale) =
applied to each scale; (d) are the revealed information of (b)     CorrectPlane(scale)/TotalPlane(scale). For each scale,
by the bubbles of (c). Note that on this trial there is no
revealed information at the fifth scale. By integrating the
                                                                   the ProportionPlane(scale) is the ratio of the number of
pictures in (d) we obtain (e), a stimulus subjects actually saw.   times a specific region of the input space has led to a
                                                                   successful categorization over the number of times this
Procedure                                                          region has been presented. Across subjects, the
Prior to experimentation, all participants learned to              averaged ProportionPlane(scale) weighs the importance
criterion (perfect identification of all faces twice in a          of the regions of each scale for the categorization task
row) the gender, expression and the name attached to               at hand (Gosselin & Schyns, 2000). If all regions had
each face from printed pictures with corresponding                 equal diagnosticity, ProportionPlane(scale) would be
name at the bottom. Each participant was then                      uniformly grey. That is, the probability that any
randomly assigned to one of the three different                    randomly chosen bubble of information led to a correct
categorization tasks. In IDENTITY, participants had to             categorization of the input would be equal to the
determine the identity of each face stimulus. In the               performance criterion—here, .75.             By the same
GENDER task, participants were instructed to decide                reasoning, whiter regions are significantly above the
whether the stimulus was male or female. In EXNEX,                 performance criterion, and therefore more diagnostic of
participants had to judge whether the face was                     these tasks.
expressive or not. Thus, each group performed different               To compute the significance of diagnostic regions, a
categorizations on the same stimulus set.                          confidence interval is built around the mean of the
   In a trial, one sparse face computed as just described          ProportionPlane(scale), for each proportion (p < .01).
appeared on the screen. To respond, participants                   To depict the complex interaction between
pressed labelled computer-keyboard keys. No feedback               categorization tasks, spatial scales and use of
was provided. The experiment comprised two sessions                information, we can visualize the effective stimulus of
of 500 trials (25 presentations of the 20 faces), but we           each task (see Figure 2). The effective stimulus is a
only used the data of the last 500 trials, when subjects           concrete image of the information the visual system
were really familiar with the faces and experimental               uses in each task. It is obtained by multiplying the face
procedure. A chinrest was used to maintain subjects at             information in Figure 2 with the diagnostic masks.
a constant viewing distance (of 100 cm). Stimuli
subtended 5.72 x 5.72 deg of visual angle on the screen.
                                                                                                        .   7
                            Results
On average, a total of 33, 20 and 15 bubbles were
needed for subjects to reach the 75% performance
criterion in the identity, gender and expressive or not
task, respectively. Remember that these bubbles resided                                                   0
                                                                                                              1   2    3    4
at different scales of the same stimulus, and were
randomly distributed within each scale. Thus, Bubbles
performs a random search of the input space that is                                                    .    7
exhaustive after many trials.
   Following        Gosselin        and     Schyns’        (2000)
methodology, we used subjects responses to determine
which stimulus information was, and was not
diagnostic. The correct categorization of one sparse                                                    0
                                                                                                              1   2    3    4
stimulus indicates that the information revealed in the
bubbles was sufficient for its categorization. When this
happened, we added the mask of bubbles to a
                                                                                                        .   7
CorrectPlane,          for       each       scale—henceforth,
CorrectPlane(scale), for scale = 1 to 5. We also added
these masks to a TotalPlane(scale), for each scale.
Across trials, TotalPlane(scale) represents the addition
of all masks leading to a correct categorization and a                                                   0
miscategorization.                                                                                            1   2    3    4

Figure 2. (a) The larger face depicts the effective face           Turning to the relative use of scales within each task,
stimulus for the identity task. The smaller pictures illustrate there is a clear advantage for the third scale in identity,
the diagnostic information used to resolve the identity task at corresponding to face information comprised between
each independent scale from fine to coarse, respectively. The   11.25 and 22.5 cycles per face. This is consistent with
coarsest scale is not depicted as it contains no meaningful
information. The bar chart provides a quantitative illustration
                                                                the face recognition literature where the best scale for
of the proportion of the face area used to resolve the task at  face recognition is between 8 and 32 cycles per face,
each scale. Figures (b) and (c) follow the same format as       depending on authors (see Morrison & Schyns, in press,
figure (a) illustrating the potent face for the gender task and for a review). Note, however, that our analysis is more
expressive or not task respectively, the diagnostic information refined because not only can we specify what the best
for each task at each scale and a quantitative account of the   scale is, but also where this information is located in the
use of information is illustrated in the bar charts.            image plane. In contrast, the best scale for expressive
                                                                or not (here, the discrimination between neutral and
                          Discussion                            happy) is information comprised between 5.62 and
Use of scale information between categorization tasks.          11.25 cycles per face (the fourth scale). This is in line
Figure 2 presents a comparison of the relative use of           with Jenkins et al. (1997) and Bayer, Scwartz & Pelli,
scale information across tasks. From top to bottom, the         (1998) who also found that the detection of the happy
large face pictures depict the information used in              expression was most resilient to changes in viewing
identity, gender and expressive or not. The figure              distances (i.e., with information corresponding to
reveals that the use of diagnostic information differs          coarser scales). For gender, scales 3 and 4 were most
across categorization tasks, and scales. For example,           used, and across task, there appears to be a bias for face
whereas the mouth is well-defined at all scales in the          information comprised between 5.62 and 22.5 cycles
identity and expressive tasks it is neglected at the finest     per face (the coarser scales) when information was
scales in the gender task. In a related vein, the eyes are      available from the entire scale spectrum. At this stage,
both represented at all scales in identity, but only one of     it is worth pointing out that the self-calibration property
them is well represented in gender, and both are                of Gosselin and Schyns’ (2000) technique ensures that
neglected in expressive. The chin is well defined in            if subjects required only information from the finest
identity, but not in expressive and gender. Compared to         scale to resolve the tasks, they would not reach the
the mouth and the eyes, the nose is less well defined in        performance criterion of 75% and the average number
all tasks.                                                      of bubbles would increase at each scale, until they
   To quantify the use of spatial scales across tasks, we       displayed enough information at the finest scale to
computed the diagnostic areas revealed at each scale            reach criterion. In other words, the reported biases for
over the total area covered by the face in the image            the coarser scales do not arise from the technique,
plane. The histograms in Figure 2 plot the use of               which is unbiased, but from the biases of observers who
diagnostic information across spatial scales--1 means           use information in categorization tasks.
finest, and 4 coarsest scale. The small face pictures              Ideal Observers. In Bubbles, the observer determines
corresponding to each scale illustrate what this face           the informative subset of a randomly, and sparsely
information is. The pictures reveal that the use of fine        sampled search space.          To highlight this unique
scale information (labelled 1 in the histograms, and            property, we here contrast human and ideal observers
depicted in the leftmost small picture) is most                 (Tjan, Braje, Legge & Kersten, 1987). The ideal
differentiated across the three tasks. In identity, it          observer will provide a benchmark of the information
depicts the eyes, the mouth and the chin, whereas in            available in the stimulus set to resolve each task. We
gender it is only used for the left side eye, and the           have biased the ideal to capture all the regions of the
mouth in expressive. In contrast to the finest scale, the       image that have highest local variance between the
coarsest scale (i.e., the fourth scale) is much less            considered categories (identity, male vs. female, and
differentiated, revealing only a holistic representation of     neutral vs. expressive). This ideal considers the stimuli
the face features. This forms a skeleton that is                as images (not as faces composed of eyes, a nose and a
progressively distinguished and fleshed out with                mouth, as humans do). The ideal might not necessarily
increasing spatial resolution (see the progression of face      be sensitive to the regions that humans find most useful
information from coarse to fine in the small pictures of        (the diagnostic regions), but to the information that is
Figure 2, from right to left.) The asymmetry in                 mostly available in the data set for the task at hand. We
extracting diagnostic information to resolve the gender         constructed a different ideal observer for the tasks of
task is consistent with studies showing that there is a         identity, gender, and expressive or not and submitted
right-hemisphere bias (the left-side of the image) in           them to Bubbles, using the same parameters as those of
processing various facial attributes, including gender          our experiment with humans. Here, however, the
(Burt & Perrett, 1997).                                         number of bubbles remained constant (equal to the
                                                                average required in each task), and we added to the face

stimuli a varying percentage of white noise to maintain         consistently demonstrated that the eyes and the mouth
categorization performance at 75% correct. In a                 were mostly scanned in face identification tasks.
Winner-Take-All algorithm, the ideal matched the
information revealed in the bubbles with the same
bubbles applied to the 32 memorized face pictures. The
identity, gender or expressive or not categorization
response of the ideal was the best matched picture. We
then computed the ProportionPlane(scale) and
DiagnosticPlane(scale), as explained earlier, to derive
the effective face of each categorization task (see Figure      Figure 4. The 2D attentional maps for each categorization
3). A comparison between the human and the ideal                task, identity, gender and expressive or not, respectively.
effective faces reveal only a partial correlation of use of
information. This indicates that the highest variations                           Concluding Remarks
of information in the image were not necessarily used              Our goal was to address the problem of recognition
by humans, who instead focused on the diagnostic face           without directly asking questions about internal
information. It further stresses that Bubbles is a human,       representations. Our analysis established how three
partially efficient, not a formal, optimally efficient,         face categorization tasks selectively used information
feature extraction algorithm (Gosselin & Schyns, 2000).         from a three-dimensional input space (the two-
                                                                dimensional image plane x spatial scales). From this
                                                                selective use, we derived a gradient of probability of
                                                                locating diagnostic information in the image plane. A
                                                                rational categorizer should selectively allocate its
                                                                attention to the regions of the image that maximize this
                                                                probability thus minimizing the uncertainty of locating
                                                                diagnostic information, see Figure 4.
Figure 3. The effective face stimulus of the Ideal Observer for
each categorization task, identity, gender and expressive or                       Acknowledgements
not, respectively.                                              This research        was    supported     by     ESRC      grant
                                                                R000223179.
   Deriving a two-dimensional map of attention. So far,
we have examined the use of information across the
different spatial scales of a face. We can now derive a                              References
precise measure of the diagnosticity of each image              Archambault, A., O’Donnell, C., & Schyns, P.G.
locations for the different face categorizations.                   (1999). Blind to object changes: When learning
Remember that the DiagnosticPlane(scale) represent a                one object at different levels of categorization
with value of 1 the presence of diagnostic information              modifies its perception. Psychological Science, 10,
at all image locations. To measure the gradient of                  249-255.
probability of finding diagnostic information at any            Bayer, H.M., Schwartz, O., & Pelli, D. (1998).
image location, we simply multiply the normalized                   Recognizing facial expressions efficiently. IOVS,
probability of using a scale with the DiagnosticPlane of            39, S172.
this     scale,     and      add      together      all    the  Biederman, I. (1987). Recognition-by-components: A
DiagnosticPlane(scale). When diagnostic information                 theory       of     human       image       understanding.
was present (vs. absent) at all scales for this image               Psychological Review, 94, 115-147.
location, it has a probability of 1 (vs. 0). Figure 4           Biederman, I., Shiffrar, M.M. (1987). Sexing day-old
renders with a grey scale the gradient of probability               chicks: a case study and expert systems analysis of a
(white = 1, black = 0) of finding diagnostic information            difficult perceptual leaning task.             Journal of
at any location of the image in identity, gender, and               Experimental Psychology: Learning, Memory &
expressive or not. If the attention is alloctated (or eye           Cognition, 13, 640-645.
movements are guided) to the most relevant image                Biederman, I., & Cooper, E.E. (1991). Priming
locations in a task, the maps of Figure 4 have a                    contour-deleted images: Evidence for intermediate
predictive value. For example, Figure 2 reveals that the            representations in visual object recognition.
regions of the eyes and the mouth are diagnostic across             Cognitive Psychology, 23, 393-419.
the entire scale spectrum, and so these locations have          Biederman, I., & Ju, G. (1988). Surface versus edge-
highest probability in Figure 4. From the seminal work              based determinants of visual recognition. Cognitive
of Yarbus (1965), studies in eye movements have                     Psychology, 20, 38-64.

Biederman, I. & Gerhardstein, P.C.                 (1995). Perrett, D.I., Oram, M.W., & Ashbridge, E. (1998).
    Viewpoint-dependent mechanisms in visual object           Evidence accumulation in cell populations
    recognition:     a critical analysis.     Journal of      responsive to faces: an account of generalisation of
    Experimental Psychology: Human Perception and             recognition     without     mental    transformation.
    Performance, 21, 1506-1514.                               Cognition, 67, 111-145.
Brainard, D. H. (1997). The Psychophysics Toolbox.         Poggio, T., & Edelman, S. (1990). A network that
    Spatial Vision, 10, 433-436.                              learns to recognize three-dimensional objects.
Bruce, V. (1994). What the human face tells the               Nature, 343, 263-266.
    human mind: Some challenges for the robot-human        Rensink, R.A., O’Regan, J.K., & Clark, J.J. (1997). To
    interface. Advanced Robotics, 8, 341-355.                 see or not to see: the need for attention to perceive
Bülthoff, H.H., & Edelman, S. (1992). Psychophysical          changes in scenes. Psychological Science, 8, 368-
    support for a two-dimensional view theory of object       373.
    recognition. Proceedings of the National Academy       Rosch, E., Mervis, C. B., Gray, W., Johnson, D. &
    of Science USA, 89, 60-64.                                Boyes-Braem, P. (1976). Basic objects in natural
Burt, D.M. & Perrett, D.I.          (1997).     Perceptual    categories. Cognitive Psychology, 8, 382-439.
    asymmetries in judgements of facial attractiveness,    Schyns, P.G., & Rodet, L. (1997). Categorization
    age,      gender,     speech      and      expression.    creates functional features. Journal of Experimental
    Neuropsychologia, 35, 685-693.                            Psychology: Learning, Memory & Cognition, 23,
Cutzu, F., & Edelman, S.              (1996).     Faithful    681-696.
    representations of similarities among three-           Simoncelli, E.P. (1999).       Image and Multi-scale
    dimensional shapes in human vision. Proceedings           Pyramid Tools [Computer software]. NewYork:
    of the National Academy of Science, 93, 12046-            Author.
    12050.                                                 Simons, D., & Wang, R.F. (1998). Perceiving real-
Gosselin, F. & Schyns, P.G. (2000). Bubbles: A new            world viewpoint changes. Psychological Science.
    technique to reveal the use of visual information in      9, 315-320.
    recognition tasks. Submitted for publication.          Tanaka, J., & Gauthier, I. (1997). Expertise in object
Gosselin, F & Schyns, P.G. (in press). Why do we              and face recognition. In R.L. Goldstone, D.L.
    SLIP to the basic-level? Computational constraints        Medin, & P.G. Schyns (Eds.), Perceptual Learning.
    and their implementation. Psychological Review.           San Diego: Academic Press.
Hill, H., Schyns, P.G., & Akamatsu, S. (1997).             Tanaka, J.W., & Presnell, L.M. (1999). Color
    Information and viewpoint dependence in face              diagnosticity in object recognition. Perception &
    recognition. Cognition. 62, 201-222.                      Psychophysics, 61, 1140-1153.
Jenkins, J., Craven, B., Bruce, V., & Akamatsu, S.         Tanaka, J., & Taylor, M.E. (1991). Object categories
    (1997). Methods for detecting social signals from         and expertise: Is the basic level in the eye of the
    the face. Technical Report of IECE, HIP96-39. The         beholder? Cognitive Psychology, 15, 121-149.
    Institute    of    Electronics,    Information    and  Tarr, M.J., & Bülthoff, H.H. (1995). Is human object
    Communication Engineers, Japan.                           recognition better described by geon structural
Jolicoeur, P. (1990). Identification of disoriented           descriptions or by multiple views? Journal of
    objects:     A dual-systems theory.        Mind and       Experimental Psychology: Human Perception and
    Language, 5, 387-410.                                     Performance, 21, 1494-1505.
Jolicoeur, P., Gluck, M., & Kosslyn, S.M. (1984).          Tarr, M.J., & Pinker, S. (1989). Mental rotation and
    Pictures and names:         Making the connexion.         orientation-dependence in shape recognition.
    Cognitive Psychology, 19, 31-53.                          Cognitive Psychology, 21, 233-282.
Liu, Z., Knill, D.C., & Kersten, D. (1995). Object         Tarr, M.J., & Pinker, S. (1991). Orientation-dependent
    classification for human and ideal observers. Vision      mechanisms in shape recognition: Further issues.
    Research, 35, 549-568.                                    Psychological Science, 2, 207-209.
Morrisson, D. & Schyns, P.G. (in press). Usage of          Troje, N. & Bülthoff, H.H. (1996) Face recognition
    spatial scales for the categorization of faces, object    under varying pose: The role of texture and shape.
    and scenes. Psychological Bulletin and Review.            Vision Research, 36, 1761-1771.
Oliva, A. & Schyns, P.G. (2000). Colored diagnostic        Ullman, S.       (1998).     Three-dimensional object
    blobs mediate scene recognition.             Cognitive    recognition based on the combination of views.
    Psychology, 41, 176-210.                                  Cognition, 67, 21-44.
Pelli, D.G. (1997). The VideoToolbox software for          Yarbus, A.L. (1965). Role of eye movements in the
    visual psychophysics: Transforming numbers into           visual process. Nauka: Moscow, USSR.
    movies. Spatial Vision, 10, 437-442.

