UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
"Two" Many Optimalities
Permalink
https://escholarship.org/uc/item/7t1123md
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 23(23)
Author
Vilarroya, Oscar
Publication Date
2001-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                               “Two” Many Optimalities
                                            Òscar Vilarroya (24678ovo@comb.es)
                                               Centre de Recerca en Ciència Cognitiva
                                        Gran de Gràcia, 127, 2-1; 08012 Barcelona, Spain
                           Abstract                                    4. Establish the fitness value of the trait in the pop-
                                                                            ulation.1
   In evolutionary biology a trait is said to be optimal if it
   maximizes the fitness of the organism, that is, if the trait
   allows the organism to survive and reproduce better than             This sort of story could be the general strategy for
   any other competing trait. In engineering, a design is said      any discipline which required teleonomic explanations.
   to be optimal if it complies with its functional require-        However, cognitive science has certain particularities
   ments as best as possible. Cognitive science is both a bio-      that change this methodology. In explaining the cogni-
   logical and engineering discipline and hence it uses both
   notions of optimality. Unfortunately, the lack of a clear        tive mechanisms of biological organisms, the cognitive
   methodological stance on this issue has made it common           scientist may attempt to identify the adaptive problem
   for researchers to conflate these two kinds of optimality.       that the brain is supposed to solve. In reality, however,
   In this paper I argue that a strict distinction must be kept     this turns out to be quite difficult, because the trait—that
   in order to avoid inaccurate assumptions.                        is, the specialized device within the brain that is respon-
                                                                    sible for solving the adaptive problem—is not as self-
                Cognitive Explanations                              evident as, say, an eye, a liver or a wing. Specialized cog-
                                                                    nitive mechanisms lie within the circuitry of the brain in
Contemporary biological explanations are teleonomic
                                                                    such a way that makes them not as obvious as one would
explanations. Teleonomic explanations are those expla-
                                                                    like (Barkow, Cosmides & Tooby, 1992).
nations that treat biological traits as adaptations. Adap-
tations are innovations that make a difference between                  In order to overcome this problem, cognitive scientists
alternative biological designs embodied in different indi-          usually invert the first and second steps of the algorithm
viduals. Such designs are “chosen” from among alterna-              above:
tive designs on the basis of how well they perform in a
given environment.                                                                     (B) Cognitive Explanation
   The phenotype of an organism is therefore understood                1. Identify the adaptive problem that the organism
as a collection of functionalities that were added and                      is supposed to solve.
maintained (i.e., copied over generations) in the design
features of a given species because these functionalities              2. Presuppose the trait that is likely to be under se-
had the consequence of solving problems that promoted,                      lection.
in some way or other, survival and reproduction (Mil-                  3. Show:
likan, 1984). A complete teleonomic explanation would                  (a) that the trait is specialized for solving the adap-
then consist of a step-by-step process in which the scien-                    tive problem;
tist must:                                                             (b) that it is unlikely to have arisen by chance alone;
                                                                              and
                (A) Teleonomic Explanation
                                                                       (c) that it is not better explained as the by-product
  1. Identify the trait that is likely to be under selec-                     of mechanisms designed to solve some alterna-
      tion.                                                                   tive adaptive problem.
  2. Identify the adaptive problem that the trait is sup-              4. Establish the fitness value of the trait in the pop-
      posed to solve.                                                       ulation.
  3. Show:
   (a) that the trait is specialized for solving the adap-          Inverting the two first steps of algorithm (A) cannot be
        tive problem;                                               without consequences. The most obvious is the fact
   (b) that it is unlikely to have arisen by chance alone;          that identifying the function of a trait, such as a wing
        and                                                              1 In other words, the theorist must establish that the distribu-
   (c) that it is not better explained as the by-product            tion of the trait in the population contributes to the evolutionary
        of mechanisms designed to solve some alterna-               notion of fitness, which for present purposes means simply the
        tive adaptive problem.                                      capacity to survive and reproduce.

or an eye, is much easier when the trait has been iden-      if a system draws upon the correct information, then the
tified rather than presupposing the trait when we only       explanation of system is correct regardless of the detailed
know its function. In the first case we can simply ob-       algorithm that the system uses.
serve the trait at work or determine if it is rarely used,      Be this as it may, the computational characterization
etc., or perhaps we might test it under all imaginable cir-  of a problem determines the specifications by which the
cumstances just to see what it does. Cognitive scientists    reverse-engineering must proceed. These specifications
face a much more difficult enterprise, however, since we     are taken at face value and are considered sufficient to es-
have to “imagine” the design features of the trait. This is  tablish the design features of the mechanism. Cummins
where the reverse-engineering strategy comes in.             (1983) further argues that such characterizations should
                                                             proceed by decomposing them into a set of simpler ca-
        Optimality in Reverse-Engineering                    pacities that are to be explained by subsumption. The
Dennett (1995) is perhaps one of the most adamant about      overall capacity is thus explained in terms of the con-
defending the reverse engineering strategy in cognitive      tributing capacities of parts of the system, and the func-
science. This strategy can be defined as the interpre-       tion of a given item is its contribution to the overall ca-
tation of an already existing intelligent artifact or sys-   pacity. Such design theories of functions define the func-
tem through an analysis of the design considerations that    tion of a mechanism or process in terms of the roles they
must have governed its creation. Logically, this overide-    might play, that is, in terms of their contribution to some
alizes the design problem, because it presupposes that       capacity of the system to which the process or mecha-
the trait is optimally executed by the cognitive machin-     nism belongs. In short, design theories relativize func-
ery. Thus, reverse-engineering takes cognitive systems to    tions to capacities of containing systems.
be systems that are designed to solve the problem identi-
fied by the theorist; otherwise, the analysis could not get         Optimality in Evolutionary Biology
off the ground. As Dennett observes, if cognitive scien-     The previous sense of optimality must be distinguished
tists cannot assume that there is a good rationale for the   from the notion of optimality that is used in evolution-
features they observe in cognizers, they cannot even be-     ary biology. To begin with, the biological notion of an
gin their task. Optimality must be the default assumption    optimum does not imply an optimal design, as it does
in cognitive explanations.                                   in engineering. Rather, it refers to a solution to a given
    A standard way of advancing the reverse-engineering      adaptive problem that maximizes the fitness of the organ-
strategy is to resort to Cummins’ notion (1983) of func-     ism in the adaptive situation.
tional analysis. Basically, a functional analysis amounts       A biological optimum can be said to be the point at
to:                                                          which the difference between costs and benefits of en-
                                                             vironmental and genetic variables (e.g., amount of food,
   1. System S performs F                                    energy requirements, distribution of the trait, alternative
   2. F can be broken down into f1 , f2 , f3 . . . fn        phenotypes, etc.) is maximized (see Figure 1). Thus,
   3. S implements f1 , f2 , f3 . . . fn                     the role of a trait as an adaptation must be established by
                                                             considering the manner in which such a trait contributes
The first step is therefore to establish F, that is, what    to the optimum. This makes the notion of optimality in
the system does. The usual way in which one charac-          biology and engineering orthogonal to one another:
terizes F is to call upon the computational theory pro-
posed by Marr (1982). In this framework, the theorist           Biological optimality: Natural selection favors the
must provide an abstract formulation of the information-           trait that maximizes the organism’s fitness.
processing task that defines a given cognitive ability.         Reverse-engineering optimality: A mechanism is
Peacocke (1986), for example, describes such formula-              designed to comply with its function.
tions as characterizations of the information state that the
system draws upon.                                              The fact of the matter is that a trait need not be op-
    Now, the notion of “information drawn upon” can be       timally designed to be adaptive: what is optimal is the
spelled out as follows:                                      fitness value of the trait, not its design characteristics.
                                                             Evolutionary solutions must, on this view, only be “se-
    A state draws upon some information whenever             lectively efficient,” that is, they need only to comply with
    such state carries the information which is causally     adaptive requirements. It follows, then, that the notion of
    influential in the operation of the algorithm or         optimal design should be detached from the notion of fit-
    mechanism. (Peacocke, 1989, p.102).                      ness value.
                                                                That natural selection is only susceptible to the fitness-
Given this definition, explanations based on Peacocke’s      value maximizations is anything but surprising: evo-
notion can be seen as a fully causal. For instance,          lution by natural selection only requires that biologi-
facts about the meaning, syntactic structure, and phonetic   cal systems be minimally effective (stay alive and leave
form of linguistic expressions are causally explained by     offspring) with respect to their of adaptive problems.
facts about the information drawn upon by algorithms or      Hence, rather than actively designing and building organ-
mechanisms in the language-user (ibid., p.113). Thus,        isms that are well-adapted to the world, nature eliminates

                                              BENEFIT
                                                                      Fitness optimum
                              Benefit                                 (B-C maximum)
                                  or
                                 cost
                                                                               COST
                                                            Adaptive solution
                            Figure 1: The optimum for a given adaptive solution is the point
                                       in which the benefit/cost relationship is maximized.
those that are too ill-suited for survival and reproduc-        in an engineering sense, to solve specific adaptive prob-
tion. In other words, biological systems are simply not         lems.
designed by engineers. Design and evolution are differ-            It is of course possible for engineering and biological
ent precisely because they have different strategies open       characterizations to coincide for a given trait and a given
to them. An engineer may build a system out of an anal-         organism. Nonetheless, counterexamples abound (e.g.,
ysis of the problem, and thus may go from the problem to        Ullman, 1996; Steels, 1994; Dehaene, 1997; Cooper
the solution. This is not a possibility for biological sys-     & Munger, 1993;). Consider the well-known example
tems: biological systems are blind to the solution until        of the sight-strike-feed mechanism of the frog (Gilman,
they have stumbled upon it.                                     1996). Frogs catch flies by way of a strike with their
   The bottom line, then, is that we should explain how         tongue. It is assumed that mediating between the envi-
cognitive systems are selected for and maintained by tak-       ronmental presence of a fly and the motor response of the
ing into account not only the adaptive problem itself, but      tongue strike there is some sort of mechanism that regis-
also their resources and the environment in which they          ters the fly’s presence in the vicinity of the frog. That is,
are evolving.                                                   the presence of the fly causes the relevant mechanism to
                                                                go into state S, and its being in state S causes the tongue
         Conflating the Two Optimalities                        to strike.
The previous discussion makes it advisable to maintain             This story goes on to assume that the information
the engineering and the biological optimalities separate.       drawn upon by state S is that of “fly”, “fly, there,” or
However, some cognitive scientists (e.g., Barkow, Cos-          “edible bug, there,” since this information can be de-
mides & Tooby, 1992) seem to conflate both notions.             rived from that the fact that the function of the frog’s
According to these theorists, what must guide the de-           sight-strike-feed mechanism mechanism is to detect the
sign specifications of cognitive mechanisms is a com-           presence of flies. Yet, an analysis of the frog’s cogni-
putational characterization (Marr, 1982) of the adaptive        tive system indicates that the best account of the system’s
problems that these mechanisms were meant to solve.             function is in fact detecting “little ambient black things.”
These specifications are considered sufficient to establish     Specifically, the function of the mechanism is to mediate
the design features of the mechanism:                           between little ambient black things and the frog’s tongue
                                                                strike.
   In effect, knowledge of the adaptive problems hu-               This means that the frog’s mechanism is functioning
   mans faced, described in explicitly computational            optimally even when the frog strikes at a little ambient
   terms, can function as a kind of Rosetta Stone:              black thing that is not a fly but a BB-gun pellet that hap-
   It allows the bewildering array of contents effects          pens to be in the vicinity. To be sure, from a reverse-
   that cognitive psychologists routinely encounter—            engineering point of view, the system is not optimally
   and usually disregard—to be translated into mean-            designed to catch flies. However, from a biological point
   ingful statements about the structure of the mind.           of view, it might be the optimal system. The reason is
   (Cosmides & Tooby, 1992, p.221)                              quite simple. The cost of “fly-detecting” mechanism may
                                                                outweigh the cost of eating, say, lead pellets. The guar-
In other words, these theorists take the brain to be the seat   antee that a frog with such an less-than-perfect mech-
of specialized mechanisms that are optimally designed,          anism could have survived and reproduced is provided

by the contingent fact that, during natural selection, a      If, on the other hand, we employ an evolutionary strat-
sufficient number of little ambient black things in the       egy, then we will have to develop a model of adapta-
frog’s environment were flies (or edible bugs). The com-      tion (see, for example, Parker & Maynard Smith, 1990).
bination of the benefits (which should include adequate       Such a model will have to consider competing alterna-
feeding) with the costs (which should include design-         tives that exist in an adaptive scenario. For instance, we
building costs) shows that a better design need not mean      can assume that we should evaluate the performance of
better fitness, which is what would be predicted if only      a system that predicts object motion according to kine-
design were considered. Accordingly, in some situations       matic variables, and another according to dynamic vari-
a better design can actually mean a drop in fitness.          ables. This comparison should establish the performance
    It might be objected that the fact that frogs also flick  of each system, not in isolation but as a part of the whole
their tongues out at little black things that happen not to   organism-environment interaction. Once this is done we
be flies is an empirical discovery and, hence, either sense   will be able to consider the costs of either system, in
of optimality could have been wrong about what frogs          terms of design and computation.
would do when confronted with BB-gun pellets. For ex-            It is very conceivable that this model might yield
ample, an evolutionary biologist might predict that natu-     an outcome that is very different from the reverse-
ral selection would favor the trait if the trait were specif- engineering analysis. It could, for example, provide the
ically tailored to fly catching, since this would maximize    hypothesis that the kinematic system is the most adaptive
fitness. Yet this prediction would have been wrong. A         solution because it satisfies the task of predicting object
reverse-engineering perspective, by contrast, might well      trajectories in a way that outweighs the cost of a much
have made the correct prediction: striking at little black    more complex, yet more optimally designed, computa-
things that are not flies might be seen as an acceptable      tional system that computes dynamic variables. Among
amount of noise, and not necessarily an unoptimally de-       other things, the errors induced by a kinematic system
signed fly-catching mechanism. Such being the case, the       may not be unacceptably gross and may be easily com-
problem, it might be argued, does not really have any-        pensated by the continuous activation of the perceptual
thing to do with the two different notions of optimality,     system. This would be congruent with empirical research
but rather with the claims one is making about a partic-      such as Cooper and Munger (1993).
ular trait and what sort of evidence should be used in           The point, then, is this: if we had relied the reverse-
evaluating those claims.                                      engineering strategy we would not have reached the cor-
    It seems to me that such an objection would miss the      rect analysis. This is not because we would have as-
point of the argument, which is to uncover two differ-        sumed an incorrect claim but because we simply would
ent methodological strategies, and not competence in hy-      have employed the wrong optimality strategy.
pothesis formation. I will illustrate the problem with an-       Having said this, it is no doubt true that the distinc-
other example. Peacocke (1993) has argued that the use        tion between the engineering and biological optimalities
of particular kinds of physical principles is constitutive    might not be an easy matter, at least not at first blush.
of the capacity of normal mature subjects to reason about     On the one hand, the functionality of the system (e.g.,
and predict object motions. Such a constitutive basis is      detecting flies) is amenable to both reverse-engineering
held to underlie the remarkable precision of our percep-      and ecological analyses; on the other, it is not always
tual systems in extracting and using the motion of objects    clear how to establish the parameters of the fitness-
in space. Examples of this capacity include our ability to    maximization process that constrains adaptive cognitive
anticipate the trajectories of objects in order to intercept, traits. The latter might not be impossible to establish in
follow, or avoid them.                                        cognitive science (Vilarroya, 2001). The former requires
    As is well known, two general types of information        changes in algorithm (B).
are used in classical physics to describe the behavior of
moving objects. On the one hand, kinematic informa-                    Cognitive Explanation Revisited
tion describes the pure motion of bodies without regard       In my opinion the explanatory strategy of cognitive sci-
to mass (i.e., the position, velocity and acceleration of     ence cannot be simply an inversion of the first steps of the
an object). On the other, dynamics describes the forces       teleonomic explanation. It is not enough to identify the
causing movement or acting on objects with mass. Ac-          adaptive problem and then infer the mechanism. Rather,
cording to Peacocke (ibid.), in order to qualify as being     we need to complement the assumption about a trait’s de-
able to reason about objects, we must attribute to humans     sign with a characterization of how the adaptation might
the capacity to reason according to dynamic principles.       have appeared over evolutionary time. Fortunately, we
This would correspond to what I have described as the         have the elements to proceed to the different steps neces-
task characterization, which is a normative description:      sary to complete a cognitive explanation. In order to do
it is what the system must do in order for its behavior to    that, we should divide the first step of algorithm (B) into
be selectively efficient (e.g., avoid falling stones).        two substeps, namely:
    If we employ a reverse-engineering strategy, the task
characterization of reasoning and predicting object mo-                      (B ) Cognitive Explanation
tions (qua dynamic computation) will be all that we need
to analyze the system that accounts for such a capacity.        1. Characterize:

   (a) the adaptive problem that the organism is sup-        the trade-off between the costs as well as the benefits
        posed to solve; and                                  of available solutions. This will (or should) eventually
   (b) the fitness-maximization process.                     yield a description of the functional account of the cog-
  2. Presuppose the trait that is likely to be under se-     nitive system, if the analyst takes into account: (a) the
      lection.                                               nature of the adaptive problem itself, (b) the analysis of
                                                             the system’s resources, (c) the environment and interac-
  3. Show:                                                   tion with competitors, as well as (d) the way in which all
   (a) that the trait is specialized for solving the adap-   these elements interact.
        tive problem;                                           How can we apply this characterization in the case of
   (b) that it is unlikely to have arisen by chance alone;   the frog? I believe that there is a way to account for
        and                                                  the paradox that the cognitive system of the frog accords
   (c) that it is not better explained as the by-product     with a characterization of the adaptive problem, even
        of mechanisms designed to solve some alterna-        though it is not the characterization of the mechanisms
        tive adaptive problem.                               that accounts for the adaptive capacity. For one thing,
  4. Establish the fitness value of the trait in the pop-    we already have an account of the adaptive problem that
      ulation.                                               the system has to solve: identify flies. This is a normative
                                                             description; it is what the system must do in order for its
   The explanation should proceed as follows. The first      behavior to be selectively efficient. For another, we have
sub-step should yield the informational-theoretic char-      the functional requirements that the fitness-maximization
acterization (Marr, 1982) of the functional requirements     process imposes: identify “little ambient black things.”
needed to satisfy the adaptive problem. Specifically, we     The evolutionary rationale behind this solution is con-
need to indicate the requirement imposed by the adaptive     sistent with the assumption that the extra computational
problem that the system should satisfy in an idealized sit-  cost of taking only flies into account (over and above
uation.                                                      other small dark ambient things) arguably outweighs the
   Once this characterization has been established, then     small increase in accuracy that would be gained from do-
the theorist must proceed to characterize the fitness-       ing so.
maximization process (including the adaptive require-           In sum, a system may seem to accord with a certain
ments that are to be satisfied by the organism in such       functionality (e.g., identifying flies) that is, in actual-
a process). Then, the theorist should verify whether the     ity, different from the description of the structure of the
computational characterization of the adaptive problem       cognitive system (e.g., identifying “little ambient black
is compatible with the optimum established in the fitness-   things”). Accordingly, such a system may in fact take ad-
maximization process. If both draw upon the same infor-      vantage of mechanisms that are not specifically designed
mation, then the characterization of the adaptive prob-      to deal the problem at hand. This does not mean that
lem can be used in conjunction with reverse-engineering      the solution is somehow deficient. The fact that the fly-
methodology. This should yield the assumed design            catching mechanism of the frog is not sensitive only to
specifications for the trait. If, on the other hand, the the flies does not mean that it cannot identify flies. It can
adaptive problem’s computational characterization is not     and it does.
compatible with the fitness-maximization optimum, then
the functional requirements of the fitness-maximization                             Conclusion
process should guide the design assumptions. As the
case of the frog has shown, the fitness-maximization ac-     Cognitive science uses two distinct notions of optimality:
count allowed the assumption that the trait should be de-    engineering optimality and biological optimality. In en-
signed to detect “little ambient black things,” rather the   gineering, optimality refers to design ideals whereas, in
one offered by the adaptive problem which would have         biology, optimality refers to fitness maximization. While
been “fly-there.”                                            conflation of the two concepts is understandable, neglect-
   The characterization of the fitness-maximization pro-     ing the distinction entails incurring risk of arriving at
cess in cognitive science is, unfortunately, not a straight- a mistaken conclusion. Fitness value and designs are
forward operation, as I have shown elsewhere (Vilar-         therefore best analyzed separately.
roya, in press). It is actually a complex process because,
among other things, there is an essentially open-ended                          Acknowledgments
set of factors that influence just where the cost-benefit    I would like to thank the following friends and colleagues
curve reaches its maximum. What allows an individ-           for their help and advice: Antoni Gomila, David Casacu-
ual, or a group of individuals, to survive and leave off-    berta, Joseph Hilferty, Joan Carles Soliva, Javier Valen-
spring depends precisely on their biological constitution    zuela, Maria Verdaguer, and Agustı́n Vicente.
and the exact characteristics of the surrounding environ-
ment with which they interact.
   Nonetheless, the elements in this characterization are
                                                                                    References
objective. Therefore one can hope to make them ex-           Barkow, J., Cosmides, L. & Tooby, J., (Eds.) (1992).
plicit, and thus provide an adaptive characterization of        The Adapted Mind: Evolutionary Psychology and the

  Generation of Culture. New York: Oxford University
  Press.
Cooper, L.A. & Munger, M.P. (1993). Extrapolating and
  Remembering Positions along Cognitive Trajectories:
  Uses and Limitations of Analogies to Physical Motion.
  In Eilan, N., R. McCarthy & Brewer, B. (Eds.), Spatial
  Representation. Oxford: Basil Blackwell.
Cosmides, L. & Tooby, J. (1992). Cognitive Adapta-
  tions for Social Exchange. In Barkow, J., L. Cosmides,
  & Tooby, J. (Eds.), The Adapted Mind: Evolutionary
  Psychology and the Generation of Culture. New York:
  Oxford University Press.
Cummins, R. (1983). The Nature of Psychological Ex-
  planation. Cambridge: MIT Press.
Dehaene, S. (1997). The Number Sense: How the Mind
  Creates Mathematics. New York: Oxford University
  Press.
Dennett, D.C. (1995). Cognitive Science as Reverse
  Engineering: Several Meanings of “Top Down” and
  ”Bottom Up.” In Prawitz, D., Skyrms, B. & Wester-
  stahl, D. (Eds.), Proceedings of the 9th International
  Congress of Logic, Methodology and Philosophy of
  Science. Dordecht: North Holland.
Franks, B. (1995). On Explanation in the Cognitive Sci-
  ences: Competence, Idealization, and the Failure of
  the Classical Cascade. British Journal of Philosophy
  of Science 46, 475-502.
Gilman, D. (1996). Optimization and Simplicity: Com-
  putational Vision and Biological Explanation. Syn-
  these, 107, 293-323.
Marr, D. (1982). Vision. Cambridge, MA: MIT Press.
Millikan, R. (1984). Language, Thought and Other Bio-
  logical Categories. Cambridge, MA: MIT Press.
Parker, GA, & Maynard Smith. (1990). Optimality the-
  ory in evolutionary biology. Nature 348, 27-33.
Peacocke, C. (1986). Explanation in Computational Psy-
  chology: Language, Perception and Level 1.5. Mind
  and Language 1, 101-123.
Peacocke, C. (1989). When is a Grammar Psycholog-
  ically Real? In Alexander, G. (Ed.), Reflections on
  Chomsky. Oxford: Basil Blackwell.
Peacocke, C. (1993). Intuitive Mechanics, Psychological
  Reality and the Idea of a Material Object. In Eilan, N.,
  McCarthy, R. & Brewer, B. (Eds.), Spatial Represen-
  tation. Oxford: Basil Blackwell.
Steels, L. (1994). The Artificial Life Roots of Artificial
  Intelligence. Artificial Life, 1, 75-110.
Ullman, S. (1996). High-Level Vision. Cambridge, MA:
  MIT Press.
Vilarroya, Ò. (2001). From Functional “Mess” to
  Bounded Functionality. Minds and Machines 11, in
  press.

