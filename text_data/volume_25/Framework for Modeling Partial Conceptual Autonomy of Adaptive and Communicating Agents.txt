UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Framework for Modeling Partial Conceptual Autonomy of Adaptive and Communicating
Agents
Permalink
https://escholarship.org/uc/item/0n42c0mc
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Honkela, Timo
Knuuttila, Tarja
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                       Framework for Modeling
                                Partial Conceptual Autonomy of
                           Adaptive and Communicating Agents
                                   Timo Honkela (timo.honkela@hut.fi)
                                 Laboratory of Computer and Information Science
                                          Helsinki University of Technology
                                                    Espoo, Finland
                              Tarja Knuuttila (tarja.knuuttila@helsinki.fi)
                          Center for Activity Theory and Developmental Work Research
                                                 University of Helsinki
                                                   Helsinki, Finland
                        Abstract                              such a case. The basic properties of natural lan-
                                                              guages and their interpretation include ambiguity,
   We consider the idea of conceptual autonomy of             contextuality, open-endedness, vagueness, and sub-
   natural and artificial agents. We claim that agents        jectivity.
   that have explicit, propositional representations are         Ambiguity, for instance, is a “virtue” when the
   limited in their conceptual autonomy. We dis-
   cuss how partial conceptual autonomy is obtained           communication media is used in an open and chang-
   through an self-organization process. The input for        ing environment in which having a distinct and
   the agents consists of perceptions on the context,         before-hand determined symbol, or combination of
   expressions communicated by other agents as well           symbols would be difficult, or practically impossi-
   as recognized identities of the other agents.
                                                              ble. To ensure successful communication, the send-
                                                              ing and the receiving agent must have similar enough
                                                              framework of interpretation, and the message or the
         Agents and communication                             situation (“context”) must contain enough informa-
Agents communicate by sending and receiving mes-              tion to activate proper framework of the receiver.
sages. In the primitive case, all the agents have a
common model of their environment, and the mes-               Cognitive capabilities of agents
sages are signals that have fixed and common in-              The basic cognitive functions of agents consist of
terpretations. In the advanced level of multi-agent           their input and output functions, memory and pro-
co-operation each agent has its own model of the              cessing mechanisms. The agents can perceive their
environment. Thus, each agent has a “subjective”              environment and have a model or representation of
interpretation for the relation between the messages          it. This representation may be
and its environment. The differences in the mod-
els motivate development of methods for providing             • static or dynamical,
learning abilities. Each agent might then learn to            • given from outside or autonomously learned,
interpret messages from other agents. In this paper
a general scheme for multi-agent communication is             • common with the other agent or individual which
first presented providing views on the applicational             makes learning capabilities necessary, and
and methodological alternatives.
                                                              • symbolic, non-symbolic or hybrid (Wermter &
   The basic elements of a generalized model of
                                                                 Sun, 2000)
multi-agent communication are: the environment of
the agents, the language used in the communica-                  Steels (1995), among others, presents division into
tion, and the input-output functions, and the mem-            explicit and implicit representation. He states that
ory and processing mechanisms of the agents.                  in the traditional AI models usually use explicit rep-
   The agents can perceive their environment, they            resentation. Implicit one is defined to emerge once
are part of it, and possibly they can change it. The          the agent behaves appropriately in a specific situa-
environment may be computerized representation,               tion with respect to the task, and to the other agents
constructed, or natural. The borderlines of these             without having any explicit model. The robots
domains may, of course, be vague. Especially a nat-           of Brooks are perhaps the best-known example of
ural environment is changing, and consists of various         agents based on such representations (Brooks 1991).
continuous phenomena.                                         According to Brooks the robots should react directly
   In its simplest form, communication may be based           to the stimulus based on their behavioral models.
on a fixed set of distinct signals. Here we consider             Brazdil and Muggleton (1991) show how to use
the possibility of applying a natural, or near-to-            symbolic inductive inference as a means to learn
natural language as communication media. The gen-             to relate terms in a multiple agent communication.
eral properties of natural languages necessitate some         They have shown how to overcome language differ-
capabilities that autonomous agent need to have in            ences between agents automatically in a situation
                                                         569

where the agents do not have the same predicate            tual autonomy will be discussed later in this paper
vocabulary. The system consists of a number of sep-        in more detail.
arate agents that can communicate. Each agent has
certain perceptive, communicative and reasoning ca-                     Communication and
pabilities, being able to (1) perceive a portion of the                    Context Sharing
given, possibly simulated world, (2) accept facts and
rules from another agent, (3) formulate queries and        The model of communicating agents consists of three
supply them to another agent, (4) respond to queries       modalities:
formulated by another agent, (5) interpret answers
                                                           • expressions used in communication (shortened as
provided by another agent, (6) induce rules on the
                                                              “E”),
basis of facts, and (7) integrate knowledge. Such
symbolic model of the environment is closely related       • contexts (“C”), and
to the model-theoretic approaches in defining the se-
mantics of formal languages. The problem lies in the       • agents’ identifications (“A”).
fact that the meaning of an expression (queries, re-
sponses) in a natural domain is fuzzy and changing,           An agent can process any channel of input alone if
biased by the particular context.                          the other two are missing, or it can associate two of
   It is also important to mention that the notion of      the pairs (the “A” channel is only present when the
autonomy can be considered critically as, e.g., Al-        “E” is in use), or even all the three input domains.
terman (1997) does. He points out that the aspects
of collaboration and distributed cognition have to be      Alternatives of abstract situations
taken into account. These considerations are central       Next we’ll consider the most relevant input combi-
also in this paper. In particular, the domain of con-      nations one by one using a distinction into separate
ceptual autonomy will be studied in more detail and        learning and communication phases. Such separa-
the concept of partial autonomy will be adopted.           tion is not strictly necessary but it simplifies the
   Kirsh (2001) expresses that in ecological systems       description of the model. In the learning phase the
each component of the system has a causal influ-           main input combinations are:
ence on the other. In the biological world organ-
isms interact with their environment and with other        • C as input: formation of the representation of the
organisms, who, of course, also tend to be part of            context domain
each other’s environment, the whole system of com-
ponents being interdependent and interlocked. The          • C+E as input: associating contexts patterns with
result is a highly complex system displaying attrac-          the expressions
tors, instabilities and cycles typical of dynamical sys-
                                                           • C+E+A as input: associating context-symbol as-
tems. (Kirsh, 2001)
                                                              sociations with the agent identifications, or more
Subjectivity and vocabulary problem                           accurately, associating all the three input “chan-
                                                              nels”.
In the field of information retrieval, Furnas et
al. (1987) have found that in spontaneous word                Also the secondary input combinations may be
choice for objects in five domains, two people fa-         listed for completeness.
vored the same term with less than 20% probability.
Bates (1986) has shown that different indexers, well       • E as input.
trained in an indexing scheme, might assign index
terms for a given document differently. It has also        • A as input.
been observed that an indexer might use different
terms for the same document at different times.            • E+A as input.
   Moore & Carling (1988) state: “Languages are in
some respect like maps. If each of us sees the world          In the communication phase the following input-
from our particular perspective, then an individual’s      output combinations are the most relevant.
language is, in a sense, like a map of their world.        • C as input, E as output: the agent names the
Trying to understand another person is like trying            “object” it has been “shown”.
to read a map, their map, a map of the world from
their perspective.”                                        • E as input, best-matching instance of a list with
   As an example related to the vocabulary problem,           C as output: the agent points out from a list an
two persons may have different conceptual or termi-           “object” that best matches the expression.
nological “density” of the topic under consideration.
A layman, for instance, is likely to describe a phe-       • C+A as input: E as output: the agent names the
nomenon in general terms whereas an expert uses               “object” taking into account the receiving agent
more specific terms. This aspect of partial concep-           of the message.
                                                       570

• E+A as input, best-matching instance of a list         they share the conception of the color name ’sienna’
   with C as output: the agent points out from a         by comparing whether they agree upon the nouns
   list an “object” that best matches the expression     that this adjective can readily qualify. Similarly, the
   taking into account the agent that expressed itself.  agents may compare the conceptually neighboring
                                                         color terms within some, implicit similarity metrics
• E+C as input, E as output: the agent evaluates         scheme. For instance, one agent might state that
   whether it would use the same expression as the       the color ’light coral’ is between the colors ’salmon’
   description of the “object”.                          and ’rosy brown’. MacWhinney (1989) mentions
• E+C as input, A as output: the agent specifies         that the prototype theory fails to place sufficient
   which agent is the likely utterer of the expression   emphasis on these kinds of relations between con-
   in the particular case.                               cepts. MacWhinney also points out that prototype
                                                         theory has not covered the issue of how concepts de-
Example: color naming                                    velop over time in language acquisition and language
A practical example can be given related to the do-      change, and, moreover, it does not provide a the-
main of colors. Naming the colors in particular has      ory of representation. MacWhinney has presented a
certain invariant features as well as a potentially      model of emergence in language based on the SOM
large number of borderline cases in which two sub-       (MacWhinney, 1997). Gärdenfors (2000) has pre-
jects often name the same color differently. The         sented a detailed account on the motivation for the
alternatives considered above give rise to following     use of the SOM in modeling conceptual spaces. This
cases: two subjects are comparing their expressions      topic will be discussed in more detail in the following
on some color that the both can perceive. Strictly       section.
speaking, the different visual points of view should
be taken into account which was one essential fac-       From color naming to societies of agents
tor in the Talking Heads project (Steels & Kaplan,
2002). If two subjects state same expression the sit-    An additional aspect of modeling is obtained if the
uation is unproblematic. If they use different ex-       agent takes into account in its internal interpreta-
pressions the following options are possible: on can     tion the utterer of the color expression. Namely,
agree that the expression used by the other subject      if one agent uses a particular color term in an un-
is a viable alternative, e.g., a piece of furniture is   usual manner, the other agent can learn this specific
considered sky blue by the other and plainly blue by     relation and use this naming convention while com-
the other but they agree that both expressions can       municating with each other. In general, this phe-
be used. As another options, they may disagree on        nomenon is called meaning negotiation. The phe-
the applicability of each other’s expressions. An ad-    nomenon can be considered as something happening
ditional level of increased realism and complexity to    between two communicating individual agents. In
the model can be obtained by considering the fuzzi-      addition, the consideration is important while com-
ness of the color naming process. The borderlines        paring the naming conventions between two more or
of three-dimensional domains of color features for       less isolated agent communities.
each color name are not crisp. Similarly, the degree
of agreement or disagreement on the use of a color                      Agent Learning and
term can be considered in the framework of fuzzy set
theory (Zadeh, 1965). Another point of view can be                     Self-Organizing Maps
obtained by taking into account the distinction into
active and passive vocabulary. One agent names one       One novel approach to aim at modeling the learn-
color with a certain term but is ready to accept al-     ing, interpretation and use of natural language has
ternative expressions denoting the same color (e.g.      been to develop systems that simulate the learning
’dark salmon’ versus ’rosy brown’).                      process. In the area of machine learning methods
   The previous discussion handled a situation in        for generalization, i.e. inductive inference have been
which both subjects experienced the same (or ap-         implemented. However, many of such models are
proximately the same) color perception and were          based on symbolic representation of rules that makes
comparing their associated color terms. However,         it difficult to create means for symbol grounding into
if the perceptual input is missing for one or both of    continuous and changing perceptual domains.
the agents, there is no direct source of evidence to        The self-organizing map (SOM) (Kohonen, 1982,
check the agreement on naming. Thus, if one agent        1995) is a information processing model which is
expresses a color name the other agent interprets this   often considered as an artificial neural network
name within its own scheme. However, there may be        model, especially of the experimentally found or-
other, indirect evidence on (dis)agreement. Namely,      dered “maps” in the cortex. There exists quite a lot
the color names can be expressed in the context of       of neurophysiological evidence to support the idea
symbol-level context, i.e., for instance, with associ-   that the self-organizing map captures some of the
ated nouns. The two subjects can check whether           fundamental processing principles of the brain.
                                                     571

 Knowledge Representation Aspects                             codebook vectors mi (t).
 The self-organizing map can be viewed as a model         2. The best-matching unit on the map, i.e., the unit
 of unsupervised machine learning and also, impor-            where the parameter vector is most similar to the
 tantly in this context, as an adaptive knowledge rep-        input vector in some metric, called the winner, is
 resentation scheme. The traditional knowledge rep-           identified.
 resentation formalisms (semantic networks, frame
 systems, predicate logic, to provide some examples)      3. The codebook vectors of the winner and a number
 are static and the reference relations of the elements       of its neighboring units in the array are changed
 are determined by a human. Those formalisms are              incrementally according to the learning principle
 based on the tacit assumption that the relationship          specified below. (Kohonen, 1995)
 between natural language and world is one-to-one:
 the world consists of objects and the relationships          The basic idea in the self-organizing map is that,
 between the objects, and these objects and relation-      for each input sample vector x(t), the parameters
 ships have straightforward correspondence to the el-      of the winner and units in its neighborhood are
 ements of language. Moreover the representations          changed closer to x(t). For different x(t) these
 are ”programmed”, not learned through experience.         changes may be contradictory, but the net outcome
    The self-organizing map is described in the follow-    in the process is that ordered values for the mi (t) are
 ing using agent terminology (slightly adapted from        finally obtained over the array. If the number of in-
 (Lagus et al., 1996). Consider a collection or sys-       put vectors is not large compared with the number of
 tem of agents which must learn to carry out very          codebook vectors (map units), the set of input vec-
 different tasks. Let us assume that the system may        tors must be presented many times reiteratively. As
 assign different tasks to different agents of the col-    mentioned above, the codebook vectors may initially
 lection that are able to learn from what they do.         have random values, but they can also be selected in
 Each new task is given to the agent that can best         an ordered way. Adaptation of the codebook vectors
 complete the task. Since the agents learn, and since      in the learning process takes place according to the
 they receive tasks that they can do well, they be-        following equation:
 come even more competent in those tasks. This is a
 model of specialization by competitive learning. If          mi (t + 1) = mi (t) + α(t)[x(t) − mi (t)]
 the agents are interconnected in such a way that also
 the neighbors of the agent carrying out a task are al-       for each i ∈ Nc (t), where t is the discrete-time
 lowed to learn some of the task, the system slowly        index of the variables, the factor α(t) ∈ [0, 1] is a
 becomes ordered so that agents near each other have       scalar that defines the relative size of the learning
 similar abilities, and the abilities change slowly and    step, and Nc (t) specifies the neighborhood around
 smoothly over the whole system. This is the general       the winner in the map array. At the beginning of
 principle of the self-organizing map.                     the learning process the radius of the neighborhood
                                                           is fairly large, but it shrinks during learning. This
 Self-organizing map algorithm
                                                           ensures that the global order is obtained already at
 In the following, the self-organizing map algorithm       the beginning, whereas towards the end, as the ra-
 is described in some more detail based on (Kohonen,       dius gets smaller, the local corrections of the code-
 1995). Assume that some sample data sets have to          book vectors in the map will be more specific. The
 be mapped onto a two-dimensional array, a sample          factor α(t) decreases during learning.
 set is described by a real vector x(t) ∈ Rn where
 t is the index of the sample, or the discrete-time               Partial Conceptual Autonomy
 coordinate. In setting up the Self-Organizing Map,
 we first assign to each unit in the array a parame-                 through Self-Organization
 ter vector mi (t) ∈ Rn called the codebook vector,        Consider that an agent is to denote an interval of a
 which has the same number of elements as the in-          single continuous parameter using a limited number
 put vector x(t). The initial values of the parameters     of symbols. These symbols are then used in the com-
 (components of mi (t)) can be selected at random.         munication between the agents. In a trivial case two
 The process described below changes these parame-         agents would have same denotations for the sym-
 ters.                                                     bols, i.e. the limits of the intervals corresponding to
    The “image” of an input item on the map is             each symbol would be identical. If the “experience”
 defined to be in the location, the mi (t) of which        of the agents is acquired from differing sources, the
 matches best with x(t) in some metric. The self-          conceptualization may very well differ.
 organizing algorithm that creates the ordered map-           One may then ask how to deal with this kind of
 ping can be described as a repetition of the following    discrepancies. The following section describes self-
 basic tasks:                                              organizing maps and a model of their use in this task.
                                                           The key idea is to provide the means for each agent
1. An input vector x(t) is compared with all the           to associate continuous-valued parameter spaces to
                                                      572

sets of symbols, and furthermore, to “be aware” of         ing agents. Based on the framework various prac-
the differences in this association and to learn those     tical applications can be build. The use of the self-
differences explicitly. These kinds of abilities are es-   organizing map algorithm was considered as one op-
pecially required by highly autonomous agents that         tion for modeling the internal conceptual and adap-
need to communicate using an open set of symbols           tive processes was presented.
or constructs in the agent language.                          The conceptual spaces of partially autonomous
   The self-organizing map is especially suitable for      agents were earlier discussed in the context of color
the central processing element of autonomous agents        names. Different situations related to “subjective”
because of the following reasons:                          variance of naming the colors were studied. The is-
                                                           sue of the cultural and societal levels of conceptual
• The self-organizing map algorithm modifies its in-       spaces of agents is of great importance when practi-
   ternal presentation, i.e., the codebook vectors ac-     cal political and societal phenomena are considered.
   cording the external input which enables the adap-      Instead of names of colors the differences in the con-
   tation of the agents.                                   ceptual spaces can be related to expressions such as
• The self-organizing map is able process natural          ’democracy’, ’freedom’, ’equality’, and ’terror’, etc.
   language input to, e.g., form “semantic maps”           Whether the scientific community dealing with the
   (Ritter & Kohonen, 1989) Natural language in-           study of societies of agents and conceptual spaces
   terpretation using self-organizing map has further      will ever be able to contribute to solving such prob-
   been examined by Miikkulainen (1993), Scholtes          lems in the future remains to be seen.
   (1993) and Honkela (1991, 1995, 1997).             In
   (Honkela 1995), the input data consisted of a set                             References
   of English translations fairy tales collected by the    Alterman, R. (1997). Rethinking Autonomy. Tech-
   Grimm brothers. Word trigrams were used as                 nical Report CS-97-195, Computer Science De-
   input vectors taking the encoded representations           partment, Brandeis University. (Appeared also in
   of three subsequent words from the preprocessed            Minds and Machines, 10:1 15-30, 2000)
   text. Summarizing the results of the statistical        Bates, M. J. (1986). Subject access in online catalog:
   analysis conducted by the map algorithm all verbs          a design model. Journal of the American Society
   were to be found in the top section whereas the            of Information Science, 37(6):357-376.
   nouns are located in the opposite site. Among the
   nouns inanimate and animate nouns formed areas          Brazdil, P. & Muggleton, S. (1991). Learning to re-
   of their own. Similar results can be obtained using        late terms in a multiple agent environment. Pro-
   other clustering algorithms.                               ceedings of Machine Learning - EWSL-91, pp.
                                                              424-439, Berlin, Springer-Verlag.
• Symbols and continuous variables may be com-
                                                           Brooks, R. (1991). Intelligence without reason. Pro-
   bined in the input, and they are associated by
                                                              ceedings of IJCAI-91, International Joint Confer-
   self-organizing map (Honkela, 1991). Continuous
                                                              ence on Artificial Intelligence, pp. 569–595.
   variables may be quantized, and a symbolic inter-
   pretation can be given for each section in the pos-     Furnas, G. W., Landauer, T. K., Gomez, L. M., &
   sibly very high-dimensional space of perceptional          Dumais, S. T. (1987). The vocabulary problem in
   variables (Honkela, 2000).                                 human-system communication. Communications
                                                              of the ACM, 30(11):964-971.
• Because the self-organizing map is based on unsu-
   pervised learning, processing external input with-      Gärdenfors, P. (2000). Conceptual Spaces. MIT
   out any prior classifications is possible (Kohonen,        Press.
   1995). The autonomous agent may form an indi-           Honkela, T. (1991). Interpreting imprecise ex-
   vidual model of the environment and of the rela-           pressions: Experiments with Kohonen’s self-
   tion between the expressions of the language and           organizing maps and associative memory. T. Ko-
   the environment.                                           honen, K. Mäkisara, O. Simula, and J. Kangas,
                                                              (eds.), Artificial Neural Networks, North-Holland,
• The interpretation of the messages need to be               pp. I–897–902.
   identical among the agents. self-organizing map
   enables creating a model of the relation between        Honkela, T. (1993). Neural nets that discuss: A
   the environment and the expressions of the lan-            general model of communication based on self-
   guage used by the other agents. In addition,               organizing maps. Stan Gielen and Bert Kappen,
   generalizations of this relations can be formed            editors, Proceedings of International Conference
   (Honkela, 1993).                                           on Artificial Neural Networks (ICANN-93), Am-
                                                              sterdam, pp. 408–411, London, Springer-Verlag.
                     Discussion                            Honkela, T. (1995). Contextual Relations of Words
We have presented a framework for considering                 in Grimm Tales Analyzed by Self-Organizing
the level of conceptual autonomy of communicat-               Map. Proceedings of International Conference
                                                       573

  on Artificial Neural Networks, ICANN-95, F.             formal and computational models, pp. 53-73,
  Fogelman-Soulié and P. Gallinari (eds.), EC2 et        Cambridge University Press. Cambridge.
  Cie, Paris, pp. 3-7.                                  Wermter, S. & Sun, R. (eds.) (2000). Hybrid Neu-
Honkela, T. (1997). Learning to Understand - Gen-         ral Systems. Lecture Notes in Computer Science,
  eral Aspects of Using Self-Organizing Maps in           Springer.
  Natural Language Processing. Computing Antici-        Zadeh, L. (1965). Fuzzy sets, Inf. Control, 8, pp.
  patory Systems, D. Dubois (ed.), American Insti-        338-353.
  tute of Physics, Woodbury, New York, pp. 563-
  576.
Honkela, T. (2000). Self-Organizing Maps in Sym-
  bol Processing. Hybrid Neural Systems, Stefan
  Wermter, Ron Sun (eds.), Springer, Heidelberg,
  2000, pp. 348-362.
Kirsh, D., The Context of Work. Human Computer
  Interaction, 2001.
Kohonen, T. (1982). Self-organizing formation of
  topologically correct feature maps. Biological Cy-
  bernetics, 43(1):59-69.
Kohonen, T. (1995).           Self-Organizing Maps.
  Springer, Berlin, Heidelberg.
Lagus, K., Honkela, T., Kaski, S., and Kohonen, T.
  (1996). Self-organizing maps of document collec-
  tions: A new approach to interactive exploration.
  Simoudis, E., Han, J., and Fayyad, U., (eds.),
  Proceedings of the Second International Confer-
  ence on Knowledge Discovery and Data Mining,
  pp. 238-243. AAAI Press, Menlo Park, Califor-
  nia.
MacWhinney, (1989). chapter Competition and
  Lexical Categorization. Linguistic categorization,
  Benjamins, New York.
MacWhinney, (1997). chapter Lexical Connection-
  ism. Cognitive approaches to language learning,
  MIT Press.
Miikkulainen, R. (1993). Subsymbolic Natural Lan-
  guage Processing: An Integrated Model of Scripts,
  Lexicon, and Memory. MIT Press, Cambridge,
  MA.
Moore & Carling (1988). The Limitations of Lan-
  guage. Macmillan Press, Houndmills.
Ritter, H. & Kohonen, T. (1989). Self-organizing
  semantic maps. Biological Cybernetics, 61(4):241-
  254.
Scholtes, J. (1993). Neural Networks in Natural Lan-
  guage Processing and Information Retrieval. PhD
  thesis, Universiteit van Amsterdam, Amsterdam,
  Netherlands.
Steels, L. (1995). Intelligence - dynamics and repre-
  sentations. L. Steels, (ed.), The Biology and Tech-
  nology of Intelligent Autonomous Agents, Berlin,
  Springer-Verlag.
Steels, L. and Kaplan, F. (2002). Bootstrapping
  grounded word semantics. Briscoe, T., editor,
  Linguistic evolution through language acquisition:
                                                    574

