UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Counterfactual Reasoning: How to Organize a Possible World

Permalink
https://escholarship.org/uc/item/69q17482

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)

Authors
Revlin, Russel
Calvillo, Dustin P.
Mautone, Patricia

Publication Date
2003-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Counterfactual Reasoning: How to Organize a Possible World
Russell Revlin (revlin@psych.ucsb.edu)
Dustin P. Calvillo (calvillo@psych.ucsb.edu)
Patricia Mautone (mautone@psych.ucsb.edu)
Department of Psychology, University of California, Santa Barbara
Santa Barbara, CA 93106-9660 USA

Abstract

Belief Revision Paradigm
Counterfactual reasoning appears to be a universal
phenomenon of human inference from childhood to
adulthood, yet, the prevailing explanations seem able to
capture only a limited aspect of the process and are in need of
an overarching framework. We propose that David Lewis’
possible worlds analysis offers a first approximation to such a
framework and gives a psychologically plausible account of
counterfactuals. It identifies the unique properties of our
ability to reason from false assumptions—whether talking
about pretense or revising our beliefs. Three experiments are
offered to suggest the plausibility of this account.

Counterfactual Reasoning
Counterfactual or hypothetical reasoning is ubiquitous in
human interaction. It ranges from children’s pretense (Scott,
Baron-Cohen, & Leslie, 1999), everyday regret for the past,
planning for the future (Roese & Olson, 1995), revising our
knowledge base (e.g., Elio & Pelletier, 1997), to testing
hypotheses (Farris & Revlin, 1989).
Theories or
descriptions of how this type of reasoning is actually
accomplished are as varied as the situations they describe.
Models of pretense rely on broadly specified processes, such
as activation of “possible world box”, input from “belief
box”, etc. (e.g., Nichols & Stich, 2000).
Social
psychologists describe tendencies to uphill vs. downhill
reasoning when considering how events could have been
different (e.g., Kahneman & Miller, 1986; Kahneman &
Tversky, 1982). Models of belief revision range from
minimizing the number of discarded propositions (e.g.,Elio
& Pelletier, 1997) to preferences for certain types of
sentences (e.g.; Revlis, Lipkin, & Hayes, 1971). Models of
reasoning emphasize semantic and inference procedures
(e.g., Walsh & Byrne, 2002) or modal logic categories (e.g.,
Revlin, Cate, & Rouss, 2001). A proposal for the process of
counterfactual reasoning that has only slightly been
represented in research paradigms is one offered from
philosophical writings by David Lewis (1973, 1986) in his
proposal of Possible Worlds. Our purpose here is to explore
the consequences of Lewis’ possible worlds treatment for
counterfactual judgments in a belief-revision paradigm. We
begin by describing the paradigm and why it might be
useful as well as some basic findings. Then we turn to a
description of Lewis’ possible worlds and how it might be
useful in understanding the findings of at least the beliefrevision paradigm.

994

When we conjecture about some hypothesis, whose truth is
in doubt or when we consider the consequences of some
conjecture for what we already know or believe, we are
doing counterfactual or hypothetical reasoning (Revlis &
Hayes, 1972). A formal definition would be reasoning from
false assumptions (Chisholm, 1946; Rescher, 1964). Let us
suppose that you have discovered a new creature--it lays
eggs and can live under water for prolonged periods of time
and has no external mammary teats. On the face of this
evidence you believe the animal is a reptile and treat it that
way. However, someone proposes that you should assume,
for the sake of argument, that it is a mammal”. To evaluate
this conjecture, you might assemble some pertinent facts
from your belief portfolio and add the new “fact” to it1:
(1) (a) All mammals have live births
(b) This creature lays eggs
(c) This creature is a reptile (not a mammal)
(d) Assume: this creature is a mammal
There are two inconsistencies here. First the assumption
directly contradicts statement (c), which must now be
labeled “false”. Second, the assumption, when joined with
statement (a), contradicts statement (b) [If all mammals have
live births and this creature is a mammal, then this creature
must not lay eggs]. Later we will refer to this as the
Generalist Path. Alternately, if we join the assumption
with statement (b), the two jointly contradict statement (a)
[This mammal lays eggs so not all mammals have live
births]. This will be referred to as the Particularist Path.
Given that these assembled “facts” are the pertinent ones to
be considered, how shall we resolve the inconsistency
introduced by this assumption, which contradicts our beliefs
(at least it contradicts the belief that this creature is a
reptile)? This is not a toy problem. The characteristics of the
creature in question in (1) are among those of the platypus
whose inclusion in the category of mammals was
1

Technically, the suppositions described here are
beliefcontravening in that they contradict an accepted assertion, but do
not necessarily deny a long held statement of fact. The
paradigmatic problems are called belief-contravening problems by
Rescher (1964).

controversial and required at least 80 years of debate during
the 19th century (Eco, 2000).
The logical problem with counterfactuals is that anything
is allowed to follow from a false assumption (i.e., from a
false antecedent of a conditional) (e.g., Chisholm, 1946).
How do we constrain the consequences of counterfactuals
so that they do not promiscuously overwhelm our
knowledge base? There must be a natural way to solve these
inconsistencies because counterfactual reasoning is
universal and is even understood by people whose language
does not have the syntactic markers that are cues to
counterfactual in English (Au, 1983). If we did not have a
natural way of constraining the inferences, such reasoning
would be useless. Our goal then is to identify the tools that
people naturally use to revise their beliefs in the face of an
assumption that defies those beliefs.
Interest in counterfactuals by philosophers, futurists, and
computer scientists is decades old (see Elio & Pelletier,
1997 for a partial summary), but only a few of these projects
addressed the question of how people actually interpret and
act-upon counterfactuals (e.g., Rescher, 1964; Revlis, 1974;
Simon & Rescher, 1966). In the past few years three quite
different proposals have surfaced, each of which capture
some aspect of how we treat counterfactuals. A logical
analysis has been proposed by Byrne and her colleagues
(e.g., Byrne & *, 1999; Byrne & Walsh, 2002; Thompson &
Byrne, 2002), where counterfactuals are treated as a type of
conditional reasoning. Her data suggest that people apply
the same inference procedures to draw conclusions from
counterfactuals conditionals as they do from indicative
conditionals, except that the former are said to engender a
richer representation in that they include more possible
states of affairs (i.e., models). A different view of
counterfactuals is represented by Dieussaert (e.g.,
Dieussaert, Schaeken, De Neys, & d’Ydewalle, 2000;
Dieussaert, Schaeken, & d’Ydewalle, 2002). She
reformulates counterfactuals as an example of beliefrevision that fits within the broader context of defeasible
reasoning (see also Elio & Pelletier, 1997). The third view is
one that we advocate (e.g., Revlis & Hayes, 1972; Revlin,
Cate, & Rouss, 2001). It sees counterfactual reasoning as a
departure from standard conditional inference.
Counterfactuals are not mere conditionals. The purpose of
considering a counterfactual assumption is to challenge
prevailing facts and beliefs. We propose that counterfactuals
are usefully described by modal logic (Rescher, 1964) and
that the vehicle for evaluating counterfactuals is to construct
possible worlds (Lewis, 1986).

Experiment 1
Method and Procedure
To illustrate the natural resolution of counterfactuals, and
that it does not readily follow rules of standard deduction,
we gave 24 problems similar to (1) above to 28 university
undergraduates (average age, 19) and to 18 elderly residents
of a retirement community (average age, 70). Half of the

995

problems had affirmatively expressed statements (e.g., All
whales are mammals) and half had negative statements
(e.g., No whales are reptiles). Participants were shown a
sample problem that required no special knowledge of
classes (e.g., All trees on the town square are elms, suppose
that this pine is a tree on the town square) and they
considered the two primary paths to creating consistency on
this problem.

Results and Discussion
The percentage of people that selected the general solution
(illustrated above) is presented in Table 1, which shows that
for problems similar to (1) (called “combining”), most
people prefer to retain the general statement and discard the
specific fact significantly more often than chance. We note
that elderly participants retain the generalities less often
than do the university undergraduates [F(1,44)=7.1, p=.01].
Overall, reasoners did not distinguish between affirmatives
and negatively expressed statements.
This preference for resolving inconsistencies by retaining
scientific generalizations may be the reason that it required
nearly a century to include the platypus and other
monotremes into the class of mammal and therefore adjust
the characteristics of that class.
Table 1: Percentage selecting the generalist path.

University Students
Older Adults

Combining (1)
91.4
79.7

Rending (2)
21.4
18.3

Experiment 2
It might be conjectured that the people are simply choosing
to retain the statements that they most believe. So that,
people choose the generalist path because the generality is
already known to be true across time and space (i.e., a
scientific law), whereas the specific fact might be based on a
single observation. Alternately, the reasoner solving such a
problem has no particular belief in the fact—it’s new to the
belief system. We tested for this possibility in Experiment 2.

Method and Procedure
The same set of statements of Experiment 1can be rearranged as in (2) where the counterfactual assumption (d)
removes a member from a class (rather than adds a new
member to a class). We call these types of problems
Rending counterfactuals:
(2) (a) All mammals have live births
(b) This creature has live births
(c) This creature is a mammal
(d) Assume: this creature lays eggs (not live births)
The choices are basically the same for the reasoner under
the counterfactual assumption in (1) and (2); that this,

creature, which is already a member of the class mammal,
does not have one of its definitional properties (circa 19th
century). These types of problems were shown to 25
undergraduate and 17 elderly participants from the same
sample as included in Experiment 1. If believability is the
mode of reasoning, then we should see the same pattern
with Rending counterfactuals as we do for Combining ones.

presented here, we provide the salient facts for the reasoners
to consider, but left on their own, they are free to fill the
universe of discourse in anyway they wish (see also
Thompson & Byrne, 2002). Take the following whimsical
example as an illustration that there can be alternative
possible worlds considered:
A man asked the speaker: “How many home runs would
Hank Aaron score in a season with today’s watered-down
pitching?”

Results and Discussion
These preferences are also presented in Table 1, which
shows that Rending counterfactuals are not treated the same
as Combining counterfactuals. Both groups of participants
rejected the generality reliably more often than chance
(p<.001). Although the overall percentage of elderly
participants selecting the generalist path is less than for the
students, the pattern is the same. The important thing to
notice is that a commitment to the pre-conjectural truth of a
statement seems to have little to do with how people resolve
inconsistencies as a result of accepting a counterfactual
assumption. This has been supported by the findings in
other studies, where none of the statements has a belief
value and yet the reasoners use the same strategy in solving
the problems that they use in (1) above (Politzer & Carles,
2001; Redding-Stewart & Revlin, 1978; Revlis, 1974;
Revlis & Hayes, 1972).
How Shall We Account For Counterfactuals? Lewis
described at least six principles involved in the use of
possible worlds that would both constrain and clarify
contrary-to-fact conditionals (Lewis, 1986). We advocate
the consideration of three of these principles (re-numbered
here). Principle 1 is that when considering a supposition,
you select a possible world in which that statement is true in
order to appreciate the consequences of it. The usefulness of
this principle is not restricted to philosophy, it is also
effective for understanding pretense behavior in children.
Consider the process model of Nichols and Stich (2000):
pretense behavior is initiated by the introduction into
consciousness of a proposition that requires a possible
world. This proposition in the “possible world box”
connects with the child’s belief system and activates
necessary facts to allow the proposition to function and
which inhibits antagonistic propositions. In the case where
the child puts a banana to her ear and starts to speak to it as
if it were a telephone (e.g., Leslie, 1987), many possible
“speaking on the phone” scripts may be activated, but eating
the banana, qua phone has to be inhibited or the pretense is
over (O’Brien, Dias, Roazzi, & Braine, 1998). You can’t
have two possible worlds functioning with equal priority.
Which of the limitless possible worlds should be selected?
The answer is dependent on the individual reasoner and can
account for the diversity of conclusions drawn to
counterfactuals. In response, Principle 2 states that when
you entertain a counterfactual assumption, you select the
closest possible world—not just any world. We are free,
however, to select the attributes on which the comparison of
the worlds is made (i.e., the facts at hand). In the research

996

“40 or 50”, was the reply.
“How can you say that?” the man argued. “Aaron hit 755
home run and was the greatest home run hitter who ever
lived.”
“You’ve got to remember,” said the speaker, “the man is 69
years old.”2

The findings of Experiments 1 and 2 show that reasoners
across a substantial age span exhibit a consistent pattern for
combining counterfactuals: they prefer to organize the belief
space top-down, retaining the most law-like statements and
rejecting others that are inconsistent with the union of the
general statement and the assumption. This is in keeping
with Lewis’ Principle 3, the Principle of Modality: in the
present world and in all possible worlds, the same modal
logic holds. Modal logic specifies that statements may be
characterized in term of degrees of necessity ranging from
necessary truths (e.g., scientific laws and definitions: all
whales are mammals) down to accidental generalizations
(e.g., all the coins in my pocket are made of silver)
(Goodman, 1955). Modal logic also specifies rules of
inference that may be used to derive which conclusions are
necessarily true and which are possibly true.
We propose that under the counterfactual assumption, the
reasoner entertains a possible world workspace where the
facts are organized by modal logic (Rescher, 1964), which
offers a metric to resolve inconsistencies. Rescher (1964),
whose treatment of counterfactuals pre-dated Lewis,
described how the logic of modals could be used to organize
any hypothetical domain (read that possible world
workspace). For example, a sensible principle would be to
arrange statements in terms of degrees of necessity. The
counterfactual supposition should be joined with all
operative laws. Those beliefs or statements that would be
inconsistent with the union of these necessary modals would
be eliminated (e.g., if previously believed to be true, their
truth value would be changed to false). We believe that this
application of modal logic is what we witness when students
are asked to accept an assumption that combines two classes
that previously are not connected.

2

Not to put too fine a point on it, but the example illustrates that
the possible world can be today with Aaron batting as he is
currently constituted. Or the world could be today, but with Aaron
as he was 40 years ago.

The decisions that occur when the assumption disconnects
(i.e., rends) two classes that previously had a superset-subset
relation are more equivocal. These are the Rending
counterfactuals described in (2). Both Rescher and Lewis
would argue that modal logic must apply here as well.
Retrospective reports of students indicate that the
supposition for these problems are perceived as a direct
“attack” on the general proposition and make it seem less of
a law and more of an empirical generalization. In this case,
its modal status is reduced and it is, for some of the
reasoners, not an organizing principle operative in the
possible world. Hence, fewer people take the generalist path
on these problems.
Of all the constraints on the use of possible worlds
advocated by Lewis, Principle 1 is the most critical to our
treatment of counterfactuals. It proclaims that counterfactual
reasoning begins with the selection of a possible world in
which the assumption is true. If the reasoner does not
employ possible world logic, then we have no expectation
of the path through these problems. Reasoners might opt to
select the generalist or particularist path roughly equally on
these problems, as observed by Byrne and Walsh (2002), or
the particularist path that was reported by Elio and Pelletier
(1997).
What would happen if Principle 1 is irrelevant to
counterfactual reasoning and the pre-existing state of affairs
did not have an effect on the resolution path chosen by
people? If Principle 1 is not operative, then the resolution
procedures may be the ones that are consistent with
procedures applied to drawing inferences from indicative
conditionals, as described by mental models theory.
Therefore, we would agree that if Principle 1 is irrelevant,
then the entire enterprise of employing possible world
formalism will not contribute much to our understanding of
counterfactuals.
In Experiments 1 and 2, reasoners are instructed to first
certify that the beliefs (i.e., the facts in question) form a
consistent set. This latter procedures lends some coherence
to the set of statements that may correspond to the “current
world”. Reasoners then have to consider the implications of
the counterfactual. We believe that in our paradigm there is
a clear division between the old belief system and the new,
which heightens the requirement to consider a second,
possible world. If this sensitivity to the pre-existing state of
affairs is not present, then possible worlds logic would not
need to be applied and reasoners would be free to use
believability or conditional reasoning procedures to resolve
inconsistencies.

Experiment 3
Method and Procedure
This experiment contrasts the two paradigms just described
by examining the reasoning patterns of students sampled
from the same introductory psychology cohort. There were
four groups of participants. Two groups (n=60) constituted
the Inference Condition. They either solved problems

997

similar to (1) or (2) above except that they were not
instructed to certify “pre-assumption” consistency nor did
they see a statement that directly contradicted the
assumption (e.g., statements 1c or 2b). In this way the
counterfactual assumption was just one of a set of
statements, and was unique only in the sense that the letter
“T” appeared next to it indicating that the reasoners should
treat it as true.
Two other groups (n=50) consisted of participants from
the same course. They solved (1) or (2) type problems. They
first were to assure themselves that the first three sentences
were consistent, and then they were to consider the impact
of the counterfactual (which they had to assume was
true).This was a replication of previous findings.

Results and Discussion
The students in the Inference condition, overwhelming
preferred to reconcile inconsistencies by retaining the most
general statement. The percentages are shown in Table 2.
They indicate that reasoners in this condition do not
distinguish between combining and rending counterfactuals
and simply select the general statement as their starting
point and reject the particular statement.
In contrast, the students who were presented with two
distinct conditionals (called the Two World conditions in
Table 2) showed an elevated preference for reasoning with
the generality when they were confronted with Combining
counterfactuals, but were not reliably above chance in the
preferences with Rending counterfactuals. This is just what
is anticipated by the possible worlds/modal logic analysis..
Table 2: Percent selecting the generalist path
Paradigm
Inference condition
Two world condition

Combining (1)
77.1
85.7

Rending (2)
80.1
61.0

General Discussion
Three principles offered by Lewis are manifested in the data
of students reconciling inconsistencies that are introduced
by counterfactual conditionals. Principle 1 says that people
will take the supposition and will automatically activate a
possible world. Principle 2 states that this world will include
the relevant facts at hand so that the two worlds will be as
similar as possible. Finally, Principle 3 claims that the
possible world will be organized along the lines of modal
logic, where statements can be arranged in terms of degrees
of necessity. It is a top-down world that dictates which
statements will be retained and which will be rejected. The
findings of the studies presented here fit nicely with the
pattern predicted from the three principles.3 Experiment 3
3

Principle 2 is not assessed here. It allows for differing
interpretations of what constitutes the facts at hand by different
reasoners.

shows that reasoners are doing something special over and
above predicate calculus (or reading-off a mental model)
when they consider the counterfactual assumption.
Experiments 1 and 2 illustrate that there is a distinct path
that reasoners select and this is in line with the predictions
of a modal logic assessment of counterfactual reasoning.
Stated differently, if the reasoner treats the assumption and
in conflict with a prior state of affairs, then it will be treated
as a counterfactual. If the assumption is viewed as merely
one of a set of statements that needs to be made consistent,
then the reasoning process will be sensitive to believability
or to standard logical procedures.
These principles are not restricted to the paradigms
described here. For example, the notion of possible worlds
plays a role in treatments of pretense in children. Some
acknowledgment of this is seen in the theory proposed by
Nichols and Stich (2001) and others (e.g., Lillard, 2001).
One of the many forms of counterfactual reasoning occurs
in situations of regret or what might be called upward
reasoning (e.g., German, 1999), in which counterfactuals
are employed to simulate an undesirable past and to see how
it could have been made better.4 Kahneman and Tversky
(1982) in initiating this line of research identify two aspects
of the reasoning that bears on the present proposal. First, in
support of Principle 2, they note that the reasoners differ on
which events they would change as a function of their
perspective or point-of-view manipulated in the scenarios.
However, Kahneman and Tversky appear to contradict
Principle 3: they identify what they consider to be the
dominant reasoning strategy, downhill reasoning, which is
the tendency to avoid changing the least probable event. On
the face of it, this strategy violates Principle 3 because a
modal analysis of conditions should seek to retain the most
necessary events at the expense of the contingent ones.
Kahneman and Tversky (1982) found that when people try
to imagine how a traffic accident scenario could have been
“better”, only a minority of them alters the accident itself (a
low probable event). This is sensible, however, if the
reasoners view the traffic accident as part of the supposition
to which they are committed and which, therefore, cannot,
on the face of it, be defined away. Rather than violating
Principle 3, they are acknowledging the demarcation
between the present world and the possible.
Decoupling
The Possible Worlds perspective is evaluated here for its
ability to give some coherence to counterfactual reasoning.
But it is not merely useful. The concept of possible worlds
or something of its genre is absolutely necessary to account
for the natural use of counterfactuals. This is because when
we imagine a future situation or re-imagine an old one, or
create a hypothesis to be tested, the propositions that we
consider must not contaminate our database of personal
knowledge because such information “may be false,
4

We note that simulated conditions in that paradigm are not
strictly, pre-experimental beliefs held by the reasoners. They too
are belief-contravening.

998

misleading or harmful”. They must be decoupled from what
we know (Cosmides & Tooby, 2000). We must have a
mechanism that labels propositions as belief, conjecture,
hearsay, etc. lest we add the statements themselves or the
inferences that we derive from them to our knowledge base.
A formalism that can accomplish this separation and keep
track of our inferences and their dependencies is to compute
such inferences in a, possible world workspace, which can
be as real as the “real” one, but separate.

References
Au T. K-F (1983). Chinese and English counterfactuals. The
Sapir-Whorf hypothesis revisited. Cognition, 15, 155187.
Byrne, R. M. J. & Tasso, A. (1999). Deductive reasoning
with factual, possible, and counterfactual conditionals.
Memory & Cognition, 27, 726-740.
Byrne, R. M. J. & Walsh, C. R. (2002). Contradictions and
counterfactuals: Generating belief revisions in conditional
inference. In W. D. Gray & C. D. Schunn (Eds.),
Proceedings of the 24th Annual Conference of the
Cognitive Science Society. Mahwah, N.J.: Erlbaum. Pp.
160-165.
Chisholm, R. M. (1946). The contrary-to-fact conditional.
Mind, 55, 389-307.
Cosmides, L. & Tooby, J. (2000). Consider the source: The
evolution of adaptations for decoupling and
metarepresentation. In D. Sperber (Ed.),
Metarepresentation. New York: Oxford University Press.
Dieussaert, K., Schaeken, W., De Neys, W., & d’Ydewalle,
G. (2000). Initial belief strategies as a predictor of belief
revision. Current Psychology of Cognition, 19, 277-288.
Dieussaert, K., Schaeken, W., & d’Ydewalle, G.(2002). The
quality of test context and contra-evidence as a
moderating factor in the belief revision process. In W.
th
Gray & C. Schunn (Eds.), Proceedings of the 24 Annual
Conference of the Cognitive Science Society (pp. 280285). Mahwah, NJ: Lawrence Erlbaum Associates.
Eco, U. (2000). Kant and the platypus: Essays on language
and cognition. A. McEwen trans.). New York: Harcourt
Brace.
Elio, R., & Pelletier, F.J. (1997). Belief change as
propositional update. Cognitive Science, 21(4), 419-460.
Farris, H., & Revlin, R. (1989). The discovery process: A
counterfactual strategy. Social Studies of Science, 19, 513.
German, T. P. (1999). Children’s causal reasoning:
Counterfactual thinking occurs for ‘negative’ outcomes
only. Developmental Science, 2, 442-447.
Goodman, N. (1955). Fact, fiction, and forecast.
Cambridge, MA: Harvard University Press.
Kahneman, D. & Miller, D. T. (1986). Norm theory:
Comparing reality to its alternatives. Psychological
Review, 93, 136-153.
Kahneman, D. & Tversky, A. (1982). The simulation
heuristic. In D. Kahneman, P. Slovic, & A. Tversky
(Eds.), Judgment under uncertainty: Heuristics and
biases. New York: Cambridge University Press. (pp. 201208).

Leslie, A. (1987). Pretense and representation: The origins
of “theory of mind”. Psychological Review, 94, 412-426.
Lewis, D. K. (1973). Counterfactuals. Cambridge, MA:
Harvard University Press.
Lewis, D. (1986). On the plurality of worlds. New York:
Blackwell.
Lillard, L. (2001). Pretend play as twin earth: A socialcognitive analysis. Developmental Review, 21, 495-531.
Nichols, S. & Stich, S. (2000). A cognitive theory of
pretense. Cognition, 74, 115-147.
O’Brien, D. P., Dias, M. G., Roazzi, A., & Braine, M. D. S.
(1998). Conditional reasoning: The logic of supposition
and children’s understanding of pretense. In M.D. S.
Braine & D. P. O’Brien (Eds.), Mental Logic. Mahwah,
NJ: Lawrence Erlbaum Associates.
Politzer, G., & Carles, L. (2001) Belief revision and
uncertain reasoning. Thinking and Reasoning, 7, 217-234.
Redding-Stewart, D. & Revlin, R. (1978). Hypothetical
inference and category structure. Bulletin of the
Psychonomic Society, 12, 465-467.
Rescher, N. (1964). Hypothetical reasoning. Amsterdam:
North-Holland Publishing.
Revlin, R., Cate, C., & Rouss, T. (2001). Reasoning
Counterfactually: Combining and Rending. Memory &
Cognition, 29, 1196-1208.
Revlis, R. (1974). Prevarication: Reasoning from false
assumptions. Memory & Cognition, 2, 87-95.
Revlis, R., Lipkin, S. G., & Hayes, J.R. (1971). The
importance of universal quantifiers in a hypothetical
reasoning task. Journal of Verbal Learning and Verbal
Behavior, 10, 86-91.
Revlis, R. & Hayes, J. r. (1972). The primacy of generalities
in hypothetical reasoning. Cognitive Psychology, 3, 268290.
Roese, N. & Olson, J. (1995). Counterfactual thinking. In
N.J. Roese & J.M. Olson (Eds.), What might have been:
The social psychology of counterfactual thinking.
Hillsdale, NJ: Erlbaum.
Scott, F. J., Baron-Cohen, S., & Leslie, A. (1999). 'If pigs
could fly': a test of counterfactual reasoning and pretence
in children with autism British Journal of Developmental
Psychology, 17, 349-362.
Simon, H. A. & Rescher, N. (1966). Cause and
counterfactual. Philosophy of Science, 33, 323-340.
Thompson, V. A. & Byrne, M. J. (2002). Reasoning
counterfactually: Making inferences about things that
didn’t happen. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 28, 1154-1170.

999

