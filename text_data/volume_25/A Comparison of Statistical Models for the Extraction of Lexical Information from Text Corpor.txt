UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Comparison of Statistical Models for the Extraction of Lexical Information from Text Corpor
Permalink
https://escholarship.org/uc/item/8hc2g9cd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Author
Dennis, Simon
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                      University of California

  A Comparison of Statistical Models for the Extraction of Lexical Information from
                                                        Text Corpora
                                       Simon Dennis (Simon.Dennis@colorado.edu)
                                      Institute of Cognitive Science, University of Colorado
                                                      Boulder, Co 80301 USA
                            Abstract                                In this paper, the Syntagmatic Paradigmatic model (SP;
                                                                    Dennis, submitted, Dennis & Harrington 2002) is compared
  The Syntagmatic Paradigmatic model (SP; Dennis &                  against the Pooled Adjacent Context model (PAC;
  Harrington 2001, Dennis submitted) and the Pooled Adjacent        Redington, Chater & Finch 1998). Both models rely on the
  Context model (PAC; Redington, Chater & Finch 1998) are
                                                                    immediately surrounding words to act as a form of context.
  compared on their ability to extract syntactic, semantic and
  associative information from a corpus of text. On a measure       In the SP model, each context is used as a cue to retrieve
  of syntactic class (and subclass) information based on the        words that appear in similar contexts within the corpus.
  WordNet lexical database (Miller 1990), the models                Words that commonly fill similar contexts are said to have
  performed similarly with a small advantage for the PAC            high substitution probabilities and are deemed to be similar.
  model. On a measure of semantic structure based on the            By contrast, the PAC model pools the immediate contexts of
  similarities produced by Latent Semantic Analysis (LSA;           a given word into a single vector. The vector corresponding
  Landauer & Dumais 1997), the models performed                     to a target word is then compared against the vectors for
  equivalently with a small advantage for the SP model. On a        other words to determine similarity. So, for the SP model
  measure of associative information based on the free
                                                                    contexts are kept separate and similarities are pooled,
  association norms of Nelson, McEvoy & Schreiber (1999),
  the SP model shows a substantive advantage over the PAC           whereas for the PAC model contexts are pooled and then
  model producing more than twice as many associates.               similarities calculated.
                        Introduction                                In the following sections, we first describe the SP and PAC
                                                                    models in more detail and provide some examples of the
In recent years a number of statistical algorithms for              words that each model considers similar. Then, we contrast
extracting lexical information from text corpora have been          quantitatively their abilities to capture syntactic, semantic
proposed (Dennis submitted; Landauer & Dumais 1997,                 and associative information.
Lund & Burgess 1996, Griffiths & Steyvers 2002,
Redington, Chater & Finch 1998). Work in this area aims
                                                                          The Syntagmatic Paradigmatic Model
to identify what can be extracted from word distribution
alone, without recourse to perceptual grounding, innate             The Syntagmatic Paradigmatic model (SP, Dennis
constraint or other sources such as sublexical information.         submitted, Dennis & Harrington 2002) is a memory-based
The purpose of this research is not to argue that other forms       theory of verbal cognition. It proposes that sentence
of information do not play a role in lexical acquisition, but       processing involves the retrieval of sentence fragments from
rather to try to characterize what a language learner could be      memory and the alignment of these fragments with the
extracting from word occurrence information. Typically,             sentence to be interpreted. Retrieval and alignment are
this has been found to be a great deal more than might              achieved using a Bayesian version of String Edit Theory
originally have been thought.                                       (SET; Sankoff & Kruskal 1983).
Methods such as the Syntagmatic Paradigmatic model (SP;             In order to employ SET, a matrix of edit operation
Dennis submitted, Dennis & Harrington 2001) and the                 probabilities is induced using a version of the Expectation
Pooled Adjacent Context model (Redington, Chater & Finch            Maximization algorithm. These edit operation probabilities
1998) group words in a way that is indicative of syntactic          can be thought of as the lexical memory of the system, and
class information, while models such as Latent Semantic             the substitution probabilities (i.e. the probability that one
Analysis (LSA, Landauer & Dumais 1997) and the topics               word can substitute for another) can be thought of as lexical
model (Griffiths & Steyvers 2002) seem to extract structure         similarities. However, the EM procedure involves taking
that might be described as semantic. Still other models such        each sentence fragment from a corpus and comparing it
as Hyperspace Analog to Language (HAL, Lund & Burgess               against every other sentence fragment. Unfortunately, such a
1996) appear to capture a combination of syntactic and              procedure is computationally expensive for large corpora
semantic information. Work has begun on the task of                 where there may be tens of millions of fragments to be
systematically comparing these models (Griffiths &                  compared against each other.
Steyvers 2003), but much remains to be done to characterize
the type of information each of these algorithms acquire.           By making a few assumptions, however, it possible to
                                                                    construct a fast approximation to the generic procedure. The
                                                                    key to improving the time complexity of the algorithm is to
                                                               330

divide the sentence fragments into equivalence classes such     has three words in common with the retrieval cue and so
that each fragment need only be compared against those          each has a matching strength of 3. As there are three
from the same equivalence class rather than the entire          fragments of equal strength the retrieval probability of each
corpus. To do this we define a fragment as a sequence of        fragment is 0.33, and so the substitution probability as
words bounded by very high frequency words (and the end         calculated from this fragment between “picture” and “copy”
of sentences boundaries) and assign fragments with the          is 0.33. The second instance of the word “picture” appears
same HF word patterns to the same equivalence class. For        in the context of the fragment “ONTO THE picture [E]”.
instance, the sentence "THE book showed A picture OF            Retrieval using this fragment results in a substitution
THE author carrying A copy OF THE manuscript." would            probability of 0.5, so that the average retrieval probability is
be divided into the following fragments:                        0.415.
    1.   [S] THE book showed A                                  The algorithm was run over the TASA corpus1 using the
    2.   A picture OF THE                                       200 most frequent words as fragment boundaries. The
    3.   OF THE author carrying A                               corpus contains 1.2 million words, in 38000 documents and
    4.   A copy OF THE                                          750000 sentences. Substitution probabilities were collected
    5.   OF THE manuscript [E]                                  for the 4000 most frequent words (note, however, that the
                                                                200 most frequent can never enter into substitutions and so
where the very high frequency words (and end of sentence        in fact the substitution matrix is restricted to the 3800
markers) are marked in capital letters. Note that the second    subsequent words). Tables 1 and 2 show several examples
and fourth fragments would be assigned to the same              of target words and the corresponding substitution
equivalence class as they contain the same pattern of HF        candidates with the highest probabilities.
words. As a consequence, it would be deduced that "picture"
and "copy" may substitute for one another. Equivalence                    The Pooled Adjacent Context Model
classes are restricted to contain fragments of the same         The PAC model (Redington, Chater & Finch 1998)
length. So, "A picture OF THE" and "A small picture OF          constructs a representation of a word by accumulating
THE" would belong to different equivalence classes.             frequency counts of the words that appeared in the two
                                                                positions immediately before and immediately after the
To calculate substitution probabilities each fragment within    target word. The four position vectors created in this way
an equivalence class was matched against each other             are then concatenated to form the representation of the word
fragment in that class. The matching strength was the count     (see Figure 2).
of the number of words in position that the fragments had in
common. This matching strength was then normalized              Example Windows of Text
against the total matching strength for all of the fragments
within the equivalence class. These retrieval probabilities     found          A                      picture          of                   the
were then averaged across the instances of each target word     found          A                      picture          in                   her
(appearing in different fragments).                             a              pretty                 picture          of                   her
                           Match    P(Retrieval)                found          a                      copy             of                   a
A picture OF THE                                                found          A                      copy             below                the
A copy OF THE              3        0.33                        destroyed      The                    copy             of                   the
A description OF THE       3        0.33
A side OF THE              3        0.33                        Corresponding Pooled Vectors
ONTO THE picture [E]                                            picture      2       0          1    1       2    0    2     1      0        1     2      0
ONTO THE copy [E]    3              0.5                         copy         2       1          0    0       2    1    2     0      1        2     0      1
ONTO THE table [E]   3              0.5                                                         a            a
                                                                                                                 the                        the
                                                                                                                                                          a
                                                                                    destroyed
                                                                                                                                    below
                                                                                                                                                   her
                                                                            found                   pretty
                                                                                                                       of    in
P(<picture, copy>) = (0.5+0.33)/2 = 0.415
Figure 1: Illustration of SP model calculation.
                                                                                 Pos -2                  Pos -1             Pos 1                 Pos 2
Figure 1 provides an illustration of how the SP model might
                                                                Figure 2: Illustration of PAC model calculation
calculate the similarity of the word “picture” and the word
“copy”. The first instance of the word “picture” appears in
the fragment “A picture OF THE”. In this same equivalence
                                                                1
class are the fragments “A copy OF THE”, “A description          We thank the late Stephen Ivens and Touchstone Applied
OF THE” and “A side OF THE”. Each of these fragments            Science Associates (TASA) of Brewster, New York for
                                                                providing this valuable resource.
                                                          331

Similarities between words are determined using                                Examples of Similar Words
Spearman’s rank correlation, a form of correlation that takes
into account the ranks of the values of vector components        Tables 1 and 2 present a number of examples drawn from
(i.e. word by position combinations). The use of the rank        the similarty matrices of both the SP model and the PAC
correlation in this case ensures that the similarities are not   model to demonstrate the different sorts of information that
dominated by variability in a small number of very high          are extracted by each algorithm. Each row shows a word
frequency words.                                                 and the ten words with the highest similarities in order of
                                                                 similarity. The examples in Table 1 show the sensitivity of
Redington et. al. (1998) restricted the words for which they     the models to syntactic categories, while the examples in
took frequency counts to the 150 most frequent in their          Table 2 show their sensitivity to semantic and associative
corpus. In order to maintain comparability with the SP           information.
model simulations, the frequency counts of the 200 most
frequent words were included, and the similarity matrix          Both models show evidence of distinguishing singular and
constructed includes the next 3800 most frequent words. In       plural nouns, past and present tense verbs, adjectives,
addition, we calculated word representations across the          contractions and even self pronouns. In addition, there is
same TASA corpus used in the SP model simulations and            also evidence that both models are capturing semantic
did not accumulate counts across sentence boundaries             information. For instance, the most similar words to
Tables 1 and 2 show several examples of the highest              “Australia” include many countries which would not appear
similarity sets.                                                 as associates of Australia, but are nonetheless semantically
                                                                 related. Likewise the most similar words for “nine” contain
           Table 1: Similarity Examples: Syntactic               many numbers that are clearly semantically related. Finally,
                                                                 strong associates (as measured by free association) are often
Word                      Ten Most Similar Words                 present in the word sets of both models. For instance, the
                    SP Model                PAC Model            pairs hot-cold, west-east, below-above and afternoon-
Band         group, kind, piece,      statement, degree,         evening appear in both models. In the next three sections,
             amount, lot, set,        bridge, hat, clock,        we will provide a quantitative assessment of how well each
             variety, series, type,   tribe, scene, bottle,      of the models captures – syntactic, semantic and associative
             line                     club, discussion           information.
Bands        amounts, groups,         bars, columns, vapor,
             cells, pieces, patterns, bases, ions, pairs,                     The Syntactic Structure Test
             natural, kinds, waves, behaviors, bottles,
                                                                 As a quantitative test of the ability of the models to capture
             hundreds, society        seas, nuclei
                                                                 syntactic structure, syntactic categories from the WordNet
Agree        want, believe, deal,     depend, forget,
                                                                 database (Miller 1990) were used to determine how often
             play, try, talk, begin,  realize, listen,
                                                                 pairs that are deemed to be similar by each model shared a
             feel, learn, live        survive, seek,
                                                                 syntactic category.
                                      recognize, operate,
                                      discover, worry
                                                                 WordNet classifies each word as either a noun, a verb, an
Agreed       wanted, tried,           explained, answered,
                                                                 adjective, a satellite adjective or an adverb. Words from
             decided, believed,       recognized,
                                                                 closed classes are not included and some words are assigned
             learned, continued,      supported, owned,
                                                                 to more than one category. For each cue word, the most
             seemed, started,         ordered, crossed,
                                                                 similar word, the five most similar words and the ten most
             refused, turned          fought, removed,
                                                                 similar words according to each of the models were
                                      suggested
                                                                 extracted.
Below        above, behind,           above, beyond,
             across, among,           formed, shown,
                                                                 Figure 3 shows the percentage of the time that these
             against, near, along,    higher, east,
                                                                 extracted words shared a syntactic category with the cue
             inside, toward, within provided, watching,
                                                                 word according to WordNet. Both models are performing at
                                      paid, beginning
                                                                 over 90% and as the confidence intervals suggest there is no
didn't       Don't, couldn't,         don't, couldn't,
                                                                 significant difference between them. There is a small and
             doesn't, am,             cannot, shall,
                                                                 insignificant trend for the percentage to decrease as the size
             wouldn't, wasn't,        decided, fell, walked,
                                                                 of the set increases.
             can't, felt, hadn't,     sat, says, wasn't
             shall
                                                                 Care must be taken in estimating chance performance to
Myself       himself, yourself,       yourself, herself,
                                                                 incorporate the degree of polysemy of the similar words. To
             themselves, herself,     anyone, sand, wrong,
                                                                 ensure an appropriate baseline the target words of the
             possible, meeting,       walking, meat,
                                                                 substitution matrix were permuted and the analysis was
             going, someone,          exactly, grass, ready
                                                                 repeated. Figure 3 also shows these chance baselines. Note
             memory, want
                                                                 that because each model selects a different subset of most
                                                             332

similar words the chance baseline can vary between the two
models. The SP model chose similar words that were                                   100.0%
slightly more polysemous and so the chance baseline is
                                                                                     90.0%
marginally higher. However, again there is no significant
difference between the models at any set size.                                       80.0%
Table 2: Similarity Examples: Associative and Semantic                               70.0%
                                                                                     60.0%                                 SP Model
Word                    Ten Most Similar Words
                                                                        Percentage
                                                                                                                           PA C Model
                   SP Model                PAC Model                                 50.0%
Australia   China, India, Europe, Philadelphia, Brazil,                                                                    SP Chance
            power, Canada,           Florida, Kansas,                                40.0%                                 PA C Chance
            California, England,     Cuba, vapor, senate,
                                                                                     30.0%
            America, Africa,         males, Pennsylvania,
            Mexico                   Athens                                          20.0%
Afternoo    morning, night, year, minute, corner,
n           evening, summer,         month, effort,                                  10.0%
            room, winter, week,      evening, hill,                                   0.0%
            early, late              conversation, chair,                                       1         5         10
                                     image, appearance
April       November, June,          June, August, dawn,                                      Num be r of Sim ilar Words
            July, march, October, Sally, Saturday,
            January, pages,          Harry, noon, Anne,              Figure 3: Percentage commonality of syntactic class for the
            August, September,       Adam, Florida                   most similar, five most similar and ten most similar words
            December                                                 from the SP and PAC models. The bars represent 95%
Diagram     picture, map,            graph, membrane,                confidence intervals calculated using 1000 bootstrap
            drawing, chart, book, illustration,                      samples (nonparametric).
            pictures, bank,          peninsula, valve,
            section, page, maps      plateau, cord, coil,
                                     ledger, creek                                   100.0%
Hand        head, eyes, side,        car, head, paper, job,
                                                                                     90.0%
            hands, mind, face,       name, room, line,
            arms, father, arm,       side, child, hands                              80.0%
            mouth
Hot         cold, warm, big, fast, heavy, cold, warm,                                70.0%
            hard, late, strong,      dry, low, dark, deep,                                                                 SP Model
                                                                                     60.0%
            fresh, deep, early       bad, simple, blue
                                                                        Percentage
                                                                                                                           PA C Model
Nine        six, four, several,      twelve, fifteen, fifty,                         50.0%
            five, seven, eight, ten, twenty, lunch,                                                                        SP Chance
            least, twelve, twenty    younger, rough,                                 40.0%                                 PA C Chance
                                     thirty, dinner, aunt                            30.0%
Neutrons    protons, electrons,      chapters, membrane,
            waves, others, atoms, legislature, equator,                              20.0%
            animals, services,       arctic, coil, valve,
            plants, metal, rays      Mediterranean,                                  10.0%
                                     ledger, plateau                                  0.0%
River       Sea, ocean,              tree, road, village,                                       1         5         10
            mountains, road,         book, door,
            door, city, surface,     community, street,                                       Num be r of Sim ilar Words
            floor, room, ground      area, program, gas
West        north, south, east,      east, Europe, France,           Figure 4: Percentage commonality of WordNet class for the
            ground, door, next,      church, tree, town,             most similar, five most similar and ten most similar words
            river, western, sun,     sea, China, table,              from the SP and PAC models. The bars represent 95%
            morning                  river                           confidence intervals calculated using 1000 bootstrap
                                                                     samples (nonparametric).
                                                               333

In addition to syntactic categories, WordNet also reports a      associations (e.g. run-walk) were thought to occur as a
more fine grained classification particularly for nouns and      consequence of experiencing words in similar sentential
verbs. This classification contains 45 categories and is         contexts.
therefore a more stringent test of the models. Figure 4 shows
both the SP and PAC results when items are required to
share a WordNet category. Again the models give quite                                  0.2
similar performance, although PAC has a tendency to
produce somewhat lower baseline estimates.                                            0.18
To summarize, the analysis suggests that both the SP model                            0.16
and the PAC model are capable of extracting a significant
proportion of the syntactic structure, at least for high                              0.14
frequency words. In general, there seems to be little
                                                                    Mean LSA Cosine
difference between the models with the PAC model                                      0.12                                SP Model
showing a small advantage.                                                                                                PA C Model
                                                                                       0.1
                                                                                                                          SP Chance
           The Semantic Structure Test                                                0.08                                PA C Chance
To test the ability to capture semantic structure the most
similar words produced by each model were compared for                                0.06
similarity based on their correspondence with the similarity
cosines provided by Latent Semantic Analysis (LSA,                                    0.04
Landauer & Dumais 1997). While data has been collected
on human similarity judgments (Romney, Brewer, &                                      0.02
Batchelder 1993) and has been used to compare models
                                                                                        0
(Steyvers, Shiffrin & Nelson in progress), the available
                                                                                               1         5         10
database is small in comparison to the WordNet collection
or the free association norms that will be used in the next                                  Num be r of Sim ilar Words
section. By contrast, LSA has been tested on a variety of
tasks requiring semantic processing and provides a
                                                                 Figure 5: Mean LSA cosines for the most similar, five most
similarity between any two words – allowing for a
                                                                 similar and ten most similar words for the SP and PAC
comparison that is more comparable with the syntactic and
                                                                 models. The bars represent 95% confidence intervals.
associative tests provided in this paper. While it would be
preferable to have a human dataset (rather than comparing
                                                                 A systematic shift from the production of syntagmatic
against another model) current methods for collecting
                                                                 associates to paradigmatic associates was observed both as a
semantic judgments (e.g. the triads method, c.f. Romney et.
                                                                 consequence of development (Brown & Berko 1960, Ervin
al. 1993) are too intensive to be applied on a large scale.
                                                                 1961) and as a function of training with nonsense syllables
                                                                 (McNeill 1966).
Figure 5 shows the mean LSA cosines for the most similar,
five most similar and ten most similar words produced by
                                                                 The SP model takes inspiration directly from these early
the SP and PAC models, respectively. Both models are
                                                                 models, but both the SP model and the PAC model can be
performing well above chance and the analysis shows a
                                                                 considered as computational instantiations of these early
significant but small advantage for the SP model. However,
                                                                 ideas – particularly of the extraction of paradigmatic
the SP model also shows an elevated mean cosine on the
                                                                 associates. It is of interest then, to determine to what extent
permuted sets of words of a similar amount (i.e. the words
                                                                 they are capable of capturing free association norms.
chosen by the SP model tend to be more similar to all other
words), so there is little distinction between the models on
                                                                 Of the 3800 words for which statistics were calculated for
this measure.
                                                                 each of the models, 1934 appeared in the Nelson, McEvoy
                                                                 and Schreiber (1999) free association norms. Figure 6 shows
          The Associative Structure Test                         the count of the number of associates of these words that
The final test compared the ability of each of the models to     appeared as the most similar, in the five most similar and in
capture associative structure. Many early theories of            the ten most words according to each of the models. The
association formation (Brown & Berko 1960, Ervin 1961,           majority of the associates did not appear in the high
Ervin-Tripp 1970, McNeill 1966) proposed that associative        frequency selection and so these counts are only useful as a
links were formed by two basic mechanisms. Syntagmatic           comparison of the two models. However, the results indicate
associations (e.g. run-fast) were thought to be acquired as a    that both models are performing well above chance and that
consequence of words appearing in succession in the              the SP model has a substantive advantage over the PAC
experience of the subject. By contrast, paradigmatic
                                                           334

model, producing over twice as many associates within the                         grant EIA-0121201 and US Department of Education grant
10 most similar words.                                                            R305G020027. I would like to thank Walter Kintsch, Tom
                                                                                  Landauer and Jose Quesada for their helpful comments and
                                                                                  suggestions. In addition, I would like to thank Jose Quesada
                          1800                                                    for his assistance with the semantic structure analysis.
                          1600                                                                           References
                          1400                                                    Brown, R. & Berko, J. (1960). Word association and the
                                                                                    acquisition of grammar. Child Development, 31, 1-14.
   Number of Associates
                          1200                                                    Dennis, S. (submitted). A memory-based theory of verbal
                                                              SP Model
                                                                                    cognition.
                          1000                                PA C Model          Dennis, S. & Harrington, M. (2001). The Syntagmatic
                           800                                SP Chance             Paradigmatic Model: An distributed instance-based model
                                                              PA C Chance
                                                                                    of sentence processing. The Second Workshop on Natural
                           600                                                      Language Processing and Neural Networks, 30
                                                                                    November, Tokyo.
                           400                                                    Ervin, S. M. (1961). Changes with age in the verbal
                                                                                    determinants of word association. American Journal of
                           200
                                                                                    Psychology, 74, 361-372.
                             0                                                    Ervin-Tripp, S. M. (1970). Substitution, context, and
                                    1        5        10                            association. In L. Postman and G. Keppel (Ed.), Norms of
                                                                                    word association. New York: Academic Press, pp. 383-
                                 Num be r of Sim ilar Words                         467.
                                                                                  Griffiths, T.L., & Steyvers, M. (2002) A probabilistic
                                                                                    approach to semantic representation. Proceedings of the
Figure 6: The number of associates among the most similar,
                                                                                    24th Annual Conference of the Cognitive Science Society.
five most similar and ten most similar words of the SP and
                                                                                  Griffiths, T.L., & Steyvers, M. (2003) Prediction and
PAC models. The bars represent 95% confidence intervals
                                                                                    semantic association. Advances in Neural Information
calculated from 1000 bootstrap samples (nonparametric).
                                                                                    Processing Systems 15.
                                                                                  Landauer, T. K., & Dumais, S. T. (1997). A solution to
                                          Conclusion                                Plato’s problem: The Latent Semantic Analysis theory of
The SP model and the PAC model share many basic                                     acquisition, induction and representation of knowledge.
assumptions. They both assume that lexical information can                          Psychological Review, 105, 221-240.
be induced directly from text corpora and the performance                         Lund, K., & Burgess, C. (1996). Producing high-
of both models on measures of syntactic structure, semantic                         dimensional semantic spaces from lexical co-occurrence.
structure and associative structure lends additional support                        Behavior Research Methods, Instrumentation, and
to this conjecture (Landauer & Dumais 1997, Lund &                                  Computers, 28, 203-208.
Burgess 1996, Redington, Chater & Finch 1998).                                    McNeill, D. (1966) A study of word association. Journal of
                                                                                    Verbal Learning and Verbal Behavior, 2, 250-262.
Furthermore, both models assume that lexical similarity is                        Miller, G. A., ed. (1990). WordNet: An On-Line Lexical
determined to a large degree by the similarity of immediate                         Database. International Journal of Lexicography 3(4).
sentential context (c.f. Lund & Burgess 1996). The models                         Nelson, D. L., McEvoy, C. L., & Schreiber, T. A. (1999).
differ, however, in how they accumulate contextual                                  University of South Florida word association, rhyme, and
information. In the SP model, each context in which a word                          word fragment norms. http://www.usf.edu/FreeAssociation
appears is considered as a retrieval cue. Each instance of a                      Redington, M., Chater, N. & Finch, S. (1998). Distributional
word in the corpus invokes an independent memory                                    information: A powerful cue for acquiring syntactic
retrieval operation and the probability of substitution is                          categories. Cognitive Science, 22, 425-469.
pooled across these retrievals. In the PAC model, the                             Romney, A. K., Brewer, D. D., & Batchelder, W. H. (1993).
contexts in which a word appears are first pooled to provide                        Predicting     clustering   from     semantic    structure.
a single vector representing the word. Similarity is then                           Psychological Science, 4, 28-34.
calculated by comparing these context vectors. The results                        Sankoff, D. & Kruskal, J. B., eds (1983).Time warps, string
suggest that while this difference has little impact on the                         edits and macromolecules: the theory and practice of
abilities of the models to account for syntactic and semantic                       sequence comparison. Addison Wesley.
structure, it has a large impact on the models’ ability to                        Steyvers, M., Shiffrin, R.M., & Nelson, D.L. (in progress).
extract associative structure.                                                      Semantic spaces based on free association that predict
                                                                                    memory performance.
                                        Acknowledgments
This research was supported by Australian Research
Council grant A00106012, US National Science Foundation
                                                                            335

