UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Mechanism-Based Framework for Predicting Routine Procedural Errors
Permalink
https://escholarship.org/uc/item/3m67891q
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Author
Byrne, Michael D.
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         A Mechanism-Based Framework for Predicting Routine Procedural Errors
                                             Michael D. Byrne (byrne@acm.org)
                                                        Department of Psychology
                                                         Rice University, MS-25
                                                          Houston, TX 77005
                               Abstract                                suffer shortcomings of one kind or another. For example,
                                                                       Reason (1990) defines human error as “the failure of a
   Routine procedural errors are facts of everyday life but            physical or mental action to achieve an intended outcome “
   have received little empirical study and have eluded                (p. 9). The fundamental problem is that the same human
   prediction. Leading frameworks for thinking about such              cognitive-perceptual-motor system that produces “errors” is
   errors have not been successful in generating predictions,          also the one which produces “correct” behaviors. Thus, it is
   either. This paper describes the desiderata for error
                                                                       difficult to posit an error definition based solely on either
   prediction, and notes that the MHP was a step in the right
   direction. Because it generally meets the criteria, ACT-R is        overt behaviors or internal psychological states; Reason’s
   proposed as a simulation framework for making                       definition is hampered by reliance on the notion of
   predictions about routine procedural errors, and some of            “intended outcome.” If an operator forms an “incorrect”
   the critical mechanisms explored.                                   subgoal in performing a complex task, but performs that
                                                                       subgoal correctly, is that an error? The answer is unclear and
                          Introduction                                 is not solved by the classic slip/mistake dichotomy
                                                                       (described below) because intentions are formed at multiple
Even in the execution of known routine procedures, people              levels.
make non-random errors. Everyone has had this experience,                  Instead, it is the joint internal and external context of
whether it is leaving one’s bank card in an ATM or failing             task performance that defines a particular action as an
to attach a promised file to an email message. While many              “error.” Thus, an error could be a failure to produce
such errors have little or no real cost, many such errors have         behaviors which meet a particular task demand (e.g. the
dire consequences, including loss of human life (Casey,                correct sequence of actions is performed, but so slowly the
1993). Clearly, an understanding of the cognitive and                  biological sample dies), or failure to meet some requirement
perceptual mechanisms underlying such error, and therefore             imposed by the tool or artifact used in the task (e.g. not
knowledge about how to potentially defeat them, would be               selecting letter paper when printing an A4-formatted
valuable. However, this problem has spawned surprisingly               document), or even by the state of the task environment
little research. Senders and Moray (1991, p. 2) identify               (e.g. lowering the flaps to reduce speed when airspeed is too
probably the major explanation: “one reason for this is that           high). Thus, one way to define an error in the context of a
error is frequently considered only as result or measure of            routine cognitive skill is any action which causes the actor
some other variable, and not a phenomenon in its own                   to fail to meet the performance requirements (either
right.” Empirical work on systematic errors in the execution           internal or external) of their task. Most (but, critically, not
of routine procedures is dominated by anecdotal accounts               all) performance requirements of many tasks are defined
(e.g., Casey, 1993) but controlled experiments on this                 external to the agent performing the task. This will become
subject are quite rare.                                                important in later discussions of error mechanisms.
   Before going into more detail, it is important to delineate
scope. First, the current effort is not concerned with all
forms of human error, but only routine procedural error.                                    Extant Taxonomies
This is a more restrictive definition, and for the purposes of         The dominant theoretical paradigm in this area is certainly
this discussion, will be taken to mean errors which occur              the one proposed by Reason (1990), which is more a
during the execution of a routine cognitive skill, as defined          taxonomy than a theory. Reason classifies errors into two
by, for example, Card, Moran, and Newell (1983) and John               types: “mistakes,” which are the result of forming an
and Kieras (1996). That is, the person involved in the                 incorrect intention to act, and “slips,” which are failures to
activity has the correct knowledge and needs to execute that           correctly execute an intention. These are tied to
knowledge. While there are certainly a wide array of other             Rasmussen’s (1987) skill-rule-knowledge (SRK) hierarchy
error types, some of which even have useful functions                  of skill execution.
(Ohlsson, 1996), this restricted domain of inquiry is both                At the lowest levels of skill acquisition, behavior is
rich and significant. For example, this describes many of              controlled by essentially declarative knowledge that must be
the errors made by extensively-trained and highly-motivated            interpreted on-line by the cognitive system, which is taxing.
people in safety-critical situations, such as commercial               Further along the skill curve, behavioral control is
pilots and medical professionals.                                      dominated by explicit rules, hence behavior is said to be
   A second issue is the definition of error itself. A wide            rule-based. Finally, behavior at the skill level is governed
variety of definitions have been proposed, but many of them            by stored patterns of preprogrammed instructions,
                                                                   204

corresponding roughly to Shiffrin and Schneider’s (1977)          more toward error classification than error prediction.
notion of automaticity. In the account of errors derived from        If the goal is prediction of errors, there are two
this framework, mistakes are usually errors at the knowledge      fundamental problems with taxonomic efforts. First, from
level; that is, the person making the error has incorrect         the standpoint of causal mechanisms, they group unlike
knowledge about how to perform the task. While this is            things together and like things apart. For example, there a
certainly the explanation for many errors, it does not appear     variety of cognitive mechanisms which can produce errors in
to apply to many interesting forms of systematic procedural       executing an action sequence, some of which can produce
error in which the person does know the correct set of steps.     errors at other stages of action. Thus, “execution errors” will
Reason generally attributes errors at the skill or rule levels    be heterogeneous, while mechanisms that might produce
of performance to various kinds of failures of attention:         errors in other stages will be categorized as being different
inattention, overattention, informational overload, and the       from those execution errors which share their cause. This
like. This has enormous face validity and has been useful in      defeats the purpose of a taxonomy. Second, and more
understanding errors in a variety of contexts. However, from      critically, these taxonomies, because they are not based on
the perspective of trying to predict errors, this account         mechanisms, cannot generally be predictive.
simply shifts the locus of the problem to another area of            In defense of extant taxonomies, they clearly have had
research, attention, which presently lacks a predictive           value in non-predictive real-world fault diagnosis and
performance theory.                                               system design, and have successfully guided various error
   Another prominent figure in the study of errors is Norman      interventions—this is not intended as a criticism of the
(e.g. Norman, 1988). Norman’s well-known “seven stages            taxonomies for the purposes for which they were developed.
of action” framework is depicted in Figure 1. In this             For the purpose of prediction, however, other methods will
framework, each goal to be achieved must be translated into       be required.
an intention to act upon the world, then that intention
converted into a sequence of actions, and so on. Once the                         Criteria for a Framework
action has been taken, it is necessary to assess the outcome,     If the goal is an obvious one, to reduce or prevent routine
which requires perceiving the state of the world, then            procedural errors, a method which predicts which errors will
interpreting that intention, etc.                                 be made, preferably with a frequency estimate attached,
                                                                  would certainly be helpful. No extant framework or model
                               Goal                               supports such prediction in general (though there have been
                                                                  specific tasks and errors for which this has been approached,
                                                                  for example see Byrne & Bovair, 1997; Gray, 2000). In
                                                                  fact, in the general case, there is not even a good empirical
      Intention to                              Evaluation of     method for such an inquiry. One might try, for a particular
           act                                 interpretations    task, to recruit or observe human operators to get error
                                                                  frequency counts. However, this will not necessarily yield
                                                                  useful predictive data unless the number of subjects that can
                                                                  be recruited and run is quite large. Especially in domains
     Sequence of                                 Interpreting     where the operators are highly-trained and in great demand
         actions                                  perception      (again, pilots and medical professionals are excellent
                                                                  examples), collecting even a small sample can be
                                                                  prohibitively expensive. A second difficulty faced by such
                                                                  an empirical enquiry is the determination of causality. Even
      Execution of                                Perceivng       when an error is observed under controlled conditions, the
       sequence                                   world state     root cause of the error is not always clear, and thus
                                                                  strategies for remediation are not apparent.
                                                                     One possible solution to this problem would be to
                            The World
                                                                  develop a model based on human operators that could
                                                                  perform the relevant task repeatedly under a variety of
                                                                  conditions and faster than real time. This would allow for
           Figure 1. Norman’s “seven stages of action”            the collection of large amounts of data and thus more stable
                                                                  frequency counts and, critically, this could be done on an a
   It is possible to base an error taxonomy on this               priori basis. Note also that this idea—essentially, Monte
framework by asking the question “at what stage did the           Carlo simulation—requires some stochasticity in either the
error occur?” Norman’s framework is in some ways more             operator model, the task environment, or both. Otherwise,
comprehensive than the Reason scheme because it gives a           every simulation run would yield the same outcome, which
larger role to the perception of the outcomes of action.          would hardly be useful.
However, Norman’s framework is also neither mechanism-               How could we arrive at such a system? There are probably
based nor predictive. However, Zhang, et al. (2002) describe      multiple possible approaches, but it is clear that to be
a taxonomy based on an extended version of this framework         successful in safety-critical applications with demanding
that does make some attempts to be predictive. This is            time constraints, such an approach requires a sophisticated
clearly a step in the right direction but the effort is geared    model of the operator at a fine grain size of behavior. It has
                                                               205

to include end-to-end processing from perceptual to               Audition Modules) of ACT-R 5.0 are depicted in Figure 2.
cognitive to motor, and it has to have a variety of               Like the MHP, ACT-R contains multiple active processing
mechanisms in it which are capable of producing errors even       units, which include the perceptual-motor modules and the
when the operator model is supplied with the “correct”            production system pattern matcher. Also like the MHP,
knowledge.                                                        each one of these units is essentially serial but all the units
   The Model Human Processor (MHP) of Card, Moran, and            operate in parallel with one another. As is usual for
Newell (1983) might serve as a starting point for such an         production systems, it contains two memories, a declarative
endeavor. The MHP was a synthesis of the cognitive                memory and a procedural memory (though the Vision and
psychology and human performance of the time, cast                Audition Modules each contain their own temporary stores
somewhat in the form of a “modal” theory of cognitive             as well). Communication between system components is
architecture. The system consists of a number of memories         managed through a representation of the current system
and “stores” as well as cognitive, perceptual, and motor          state, which resides in a set of special memory elements
processors. The processors are themselves serial but work in      referred to as “buffers.”
parallel with one another. Each of the MHP stores had
certain information-processing parameters and the processors
were guided by several principles of operation.
   For example, the MHP working memory has limited
capacity and degrades as a function of both decay and
interference. The MHP’s long-term memory is cue-based,
affected by frequency, recency, and similarity. The
principles guiding the cognitive processor included
standards such as search through a problem space and
constrained adaptation supported by ubiquitous learning. In
very general terms, the MHP was not especially contentious
at least in part because it tended to be more inclusive than
exclusive. Also, one of its great strengths was also its fatal
weakness in terms of error prediction: the MHP was not
implemented as a running system, so commitments were
never made to the exact form taken by most of the proposed
mechanisms.
   The lack of commitments to specific details skirted many
of the kinds of arguments about representation and process
that occupy much of the cognitive science literature today;
however, in some circles (primarily within the HCI
community) this became a guiding conceptualization. But,
of course, it does not meet the goal of allowing prediction
by simulation.                                                     Figure 2. Major components of ACT-R 5.0. Boxes represent
   What is needed is an instantiation of the MHP that does                      memories, ovals active processes.
address the range of cognition, perception, and motor
activity and that is also executable. This would allow for           Unlike the MHP, however, the workings of the various
repetitive simulation to ultimately obtain frequency counts.      processes and memories have been specified in detail (see
In addition, if a trace of the system could be kept, it may be    Anderson, Bothell, Byrne, & Lebiere, 2002 for a more
possible to record the causal mechanism which produced            complete description; see Anderson, 1990, for the “rational”
each error. This may lead to insight into what might be           justification for many of these mechanisms) and the system
possible in terms of remediation.                                 is runnable, producing as its output a timestamped sequence
                                                                  of behaviors, both overt (e.g. keystrokes) and covert (e.g.
             A Candidate System: ACT-R                            retrieval from declarative memory). In order to produce this
A system that appears to meet the desiderata laid out thus        output, ACT-R requires two inputs: knowledge and an
far is ACT-R 5.0 (Anderson, Bothell, Byrne, & Lebiere,            environment with which to interact. The knowledge consists
2002; this version subsumes all previous versions of ACT-         of declarative memory elements (termed “chunks”) and
R, including ACT-R/PM). It is important to be clear that          production rules, as well as some parameters which affect
this is not a suggestion that ACT-R is the only possible or       how that knowledge will be used (more on this shortly).
ultimately best such system, but it currently does satisfy        ACT-R also requires a runnable environment which
many of the aforementioned conditions. And though ACT-            responds to its actions and produces stimuli.
R is quite comprehensive, this is not necessarily an                 So, ACT-R meets the “runnable” criterion. The next
endorsement of either the completeness or correctness of          question is whether or not ACT-R is capable of producing
ACT-R’s mechanisms. Rather, this is a claim that ACT-R            errors in the execution of routine procedures. And if so, how
is a tenable platform for exploring the idea of predictive        might that lead to an improved taxonomy or remediation
human error simulation for routine procedural errors.             strategies?
   The major components (except for the Speech and
                                                               206

   The answer to the first question appears to be “yes.”           simple procedure, say, driving home from the office. There
ACT-R contains a number of mechanisms that can produce             are two possible routes, with known probabilities and costs,
errors despite the presence of “correct” knowledge.                which leads the model to consistently choose route A.
Furthermore, in places where it does not appear that ACT-R         However, on a particular trip home, unbeknownst to the
has appropriate error-producing mechanisms, modifications          model, there is utility construction along route A. Because
that would produce them appear to be straightforward. Thus,        of the model’s preferences based on P and C, it will choose
while it most certainly is not a complete or necessarily           route A. This can be an error if the construction yields a
correct theory everywhere, it might serve as a starting point      delay long enough that the performance requirements (e.g.,
for systematic explorations into routine procedural errors.        get to day care by 6:30 pm) are not met. Thus, the system
To make the case more clear and concrete, two mechanisms           can err despite the presence of the correct knowledge. Note
will be elaborated in some depth.                                  that the situation described above pushes on the definition
                                                                   of “correct;” in the changed environment, it might be
Procedural Memory Mechanisms                                       reasonable to say that the model’s knowledge is no longer
In ACT-R, the basic unit of procedural memory is the               correct. However, this is a fine line, since the model does
production rule (or simply production). This is a condition-       have the correct knowledge about how to navigate route A.
action pair, IF a particular pattern is present in the buffers,    Ultimately, this semantic question is probably not that
THEN take one or more actions. These actions include               important in predicting errors; we’d like to know where
modifications of the contents of a buffer (e.g. a change in        human errors are likely to occur, and humans are likely to
the state of the current goal) and requests of the other           have similar imperfections in the tuning of their knowledge
subsystems (e.g. retrieve a declarative memory, initiate           when the world changes.
some perceptual-motor action). It seems apparent that if the          Another important point here is that while ACT-R has
correct productions are in place, then the correct action          default values it will supply for P, G, and C, these can be
sequence should be output.                                         taken with a grain of salt. With Monte Carlo techniques, it
   However, this is not always the case. It can be (and often      is be possible to simply repeatedly sample the space of
is) the case that more than one production will match on a         reasonable values and from that derive a distribution of
given cycle. Since the production system is serial—that is,        predicted error frequencies. Obviously, the better the values
only one production at a time can fire—there needs to be a         selected, the better the model output will be, but supplying
way to arbitrate when multiple productions match. In ACT-          even a good approximate range should yield useful outputs.
R, this is done with a simply utility calculation. Each
production has a utility (U) associated with it, and the           Declarative Memory Mechanisms
matching production with the highest utility is the one            ACT-R’s other memory system is an even richer potential
selected.                                                          source of error. To understand why, some detail regarding
   The utility is computed with the formula PG–C, where P          how it works will be necessary. First, ACT-R’s declarative
represents the estimated probability that the firing of that       memory system is engaged when a production requests the
production will lead to success in pursuing the current goal       retrieval of a chunk matching a particular pattern. If the
and C the estimated cost (in terms of time) until that             system is able to retrieve such a chunk, then the retrieved
success if the production is allowed to fire. G represents the     chunk is placed in one of ACT-R’s buffers so it can be
value of the current goal. Importantly, this computation is        accessed directly by productions.The time that it takes is a
noisy. This means that the production with the highest             function of the retrieved chunk’s activation, with more
utility will not always be chosen. In fact, the system             active chunks taking less time to be retrieved. Chunk
delivers what is sometimes referred to as “soft max”               activation plays other key roles as well. First, because there
behavior; the probability of a production being selected is        is a system-wide threshold for chunk activation, it
higher when its utility is higher, and thus the one with the       determines whether a chunk can be retrieved at all. Second,
highest utility is the one mostly likely to be selected. But it    when multiple chunks match the pattern specified by the
will not always be. Thus, when in a situation where there          retrieval, the chunk with the highest activation is the one
are multiple viable alternatives, ACT-R will choose                actually retrieved. Thus, chunk activation is a critical
stochastically from among them. This can lead to the               quantity. The activation of chunk i is given by the
selection of strategies or actions which are not as well-          following equation:
matched as they might be. This, in turn, can lead to failure                  Ai = Bi + Â W j S ji +e
to meet task requirements, even when the actions taken are                                                                  [1]
by some definition “correct.”                                         where epsilon represents stochastic noise added to all
   The second issue is with the PG–C quantities themselves.        chunk activations at each retrieval request. Like with
P and C for each production can be set by the modeler or           production utilities, this leads to soft max behavior; the
learned by the system over time; they are intended to           †  chunk with the highest pre-noise activation is the one most
represent the true probabilities and costs in the history of       likely to have the highest post-noise activation, but this is
the agent being modeled. G is generally left fixed. However,       not guaranteed. The other terms require explanation as well.
this leads to a potentially interesting situation: what            The summation is across each chunk which is an element of
happens when the environment changes? This might be best           the current goal (termed a “source;” note that goals in ACT-
illustrated with a somewhat simplified example.                    R are also chunks), where Wj is the total source activation
   Suppose the model has two strategies for executing a            W (usually W is set to 1) divided by the number of such
                                                                207

  chunks. Sji is the strength of association between the source        needs to meet the task requirements successfully. Moreover,
  chunk j and the target chunk i. In essence, this is the              this effect is stochastic and depends on the values of some
  summed strength of the chunk’s relationship to the current           system-wide and memory-specific parameters. Again, a
  context, scaled to account for the amount of such context.           space of reasonable values could be sampled repeatedly to
     The other equation of importance is the one determining           generate error frequency predictions.
  base-level activation of a chunk, Bi in equation 1:
                                                                       Timing, Combinations, and Cascades
                       (
             Bi = ln Â t -d j  )                             [2]
                                                                       Space constraints prohibit an exhaustive discussion of other
                                                                       potentially error-generating mechanisms in ACT-R, but
     where the summation is across each previous access j of           such mechanisms, or the potential for them, certainly exist
  the chunk, t represents the time since that access, and d is         in the other ACT-R subsystems such as the visual system.
  system-wide constant (usually 0.5). Thus, the base-level             For example, the visual system has limited bandwidth (only
  activation of a chunk is a function of both frequency and            one set of eyes) meaning, among other things, difficult
† recency of access, with more accesses leading to higher              visual searches can be time-consuming.
  activation, and more recent accesses weighing more heavily             In fact, timing is another crucial error source. Many tasks
  than older accesses.                                                 in dynamic environments (e.g., again, aviation and
     Taken together, what this means is that despite the               medicine) have stringent timing requirements, and
  presence of the “correct” chunk in declarative memory, it            performance that is simply too slow may also be considered
  may not be accessible when requested. Furthermore, an                erroneous. Timing plays a critical role internally in ACT-R
  “incorrect” chunk may be retrieved in its place. The fact that       as well. Since the various systems act asynchronously, this
  such an event can occur is certainly promising for the               raise the possibility of the right thing being done at the
  prospective error modeler, but it is more interesting to             wrong time, especially, too late. For example, some visual
  consider the conditions that are most likely to lead to such         search takes longer than expected, after which time the
  failures.                                                            critical piece of state information is no longer accessible
     First, note that chunks’ base-level activations decay over        because it has decayed. This points out another important
  time. This can be overcome with additional accesses (e.g.,           aspect of the system’s behavior: it is often potentially the
  rehearsal), but of course additional access takes time and,          case that no single mechanism is “responsible” for a
  since the declarative memory system can only retrieve one            particular error, but rather that multiple mechanisms were
  chunk at a time, this prevents it from being used for other          involved. This suggests that one of the reasons that
  parts of task performance. This makes the obvious                    taxonomies of errors may be so difficult to successfully
  prediction that dynamic pieces of task information (e.g.             construct, is that the lines of demarcation are not clear at a
  partial products, state information) will be forgotten if not        mechanistic level.
  accessed enough; more importantly, it specifies the                    Furthermore, when searching for the cause of a particular
  likelihood of forgetting under various conditions.                   error, in some sense the cause may not always be proximal.
     Additionally, for most chunks, they require more than             ACT-R’s behavior is both non-linear (see equation 2 for an
  just base-level activation to be above threshold, they require       example) and stochastic, and thus chaotic in the
  the activation spread from the current context (the slots of         mathematical sense. That is, a small perturbation in the
  the current goal). Retrievals can fail if there is a shortage of     activation of a chunk at time t may produce a much larger
  this activation as well. What conditions lead to this? The           shift in behavior at time t + n. Anyone who has run
  two components in the equation tell us. First, there is the          multiple people through an experiment where the same
  strength of the sources (Wj). As the goal chunk gets bigger          conditions are presented multiple times can appreciate the
  and bigger in an attempt to store more state or context,             face validity of such a system as a model of human
  spreading activation gets more diffuse, making all retrievals        behavior. And again, this points to the necessity of Monte
  both slower and more likely to fail. This is essentially a           Carlo simulations.
  workload effect; the greater the workload of the system, the
  more likely it is that a retrieval will fail, possibly leading to                              Discussion
  an error.                                                            The central point here is not that ACT-R is the ultimate
     Second, there are the effects of the strength of association,     solution to predicting human error, rather, that it is a
  which is essentially an index of the specificity of the cues.        candidate system that at least potentially meets the
  Cues that are too general are less effective. For example,           requirements for making such predictions, at least in the
  adding a red indicator light to cue the pilot that something         case of routine procedural errors. The availability of such a
  is in an error condition, even if the pilot sees the indicator,      system is a relatively recent innovation; now is the time to
  is unlikely to help if many things are associate with a red          take seriously the idea of simulation modeling for human
  indicator light. Again, this is hardly a novel idea or               error prediction.
  prediction. But again, ACT-R makes specific predictions                Obviously, the amount of effort and resources required to
  about the effects of such manipulations, and also makes              do such modeling is not trivial. The knowledge engineering
  predictions about how all three factors discussed trade off          required to model people with even moderate real-world
  with one another.                                                    expertise in executing complex but routine (for them)
     Thus, even a model with the “correct” set of productions          procedures is significant, and running large Monte Carlo
  can fail if it cannot access the declarative information it
                                                                    208

simulations is also resource-intensive. However, as noted,        Byrne, M. D., & Kirlik, A. (2003). Integrated Modeling of
even traditional empirical methods in such domains can be           Cognition and the Information Environment: A Closed-
quite expensive to administer and often provide quite               Loop, ACT-R Approach to Modeling Approach and
limited results. For safety-critical applications where             Landing with and without Synthetic Vision System
millions of dollars and/or human lives are at stake, the costs      (SVS) Technology. Technical Report AHFD-03-4/NASA-
of such simulation-based prediction may well pay off.               03-3, Institute of Aviation. University of Illinois at
  This is something of a departure from how such errors             Urbana-Champaign.
have been approached in the past. Systematic exploration of       Card, S. K., Moran, T. P., & Newell, A. (1983). The
human error has traditionally been the domain of human              psychology of human-computer interaction. Hillsdale, NJ:
factors researchers, while this simulation-based approach           Lawrence Erlbaum Associates.
requires a great deal of expertise in computational cognitive     Casey, S. (1993). Set phasers on stun. Santa Barbara, CA:
modeling, an area more familiar to the cognitive scientist.         Aegean Publishing.
Fortunately, these communities overlap and my hope is that        Freed, M. and Remington, R. (1998) A conceptual
people from both groups will be drawn to this kind of               framework for predicting errors in complex human-
approach.                                                           machine environments. In Proceedings of the Twentieth
  For that to happen, the approach will have to demonstrate         Annual Conference of the Cognitive Science Society (pp.
some empirical success. Such efforts are have been initiated        356–361). Mahwah, NJ: Erlbaum.
(Schoppek, Boehm-Davis, Diez, Hansberger, & Holt, 2000;           Gray, W. D. (2000). The nature and processing of errors in
see also Byrne & Kirlik, 2002, 2003) and look promising.            interactive behavior. Cognitive Science, 24(2), 205-248.
Hopefully other candidate systems (such as APEX, Freed &          John, B. E., & Kieras, D. E. (1996). The GOMS family of
Remington, 1998) can be identified and put into use this            user interface analysis techniques: Comparison and
way to provide a broader gauge of the ultimate tractability         contrast. ACM Transactions on Computer-Human
of this approach.                                                   Interaction, 3, 320-351.
                                                                  Norman, D. (1988). The design of everyday things. New
                   Acknowledgements                                 York: Doubleday.
                                                                  Ohlsson, S. (1996). Learning from performance errors.
I would like to acknowledge the support of the Office of
                                                                    Psychological Review, 103, 241–262.
Naval Research under grant number N00014-03-1-0094 and
                                                                  Rasmussen, J. (1987). The definition of human error and a
the National Aeronautics and Space Administration, grant
                                                                    taxonomy for technical system design. In K. D. J.
number NDD2-1321. The views and conclusions contained
                                                                    Rasmussen, & J. Leplat (Ed.), New technology and
herein are those of the author and should not be interpreted
                                                                    human error (pp. 53–62). Chichester: John Wiley &
as necessarily representing the official policies or
                                                                    Sons.
endorsements, either expressed or implied, of ONR, NASA,
                                                                  Reason, J. T. (1990). Human error. New York: Cambridge
the U.S. Government, or any other organization.
                                                                    University Press.
  I would also like to thank Alex Kirlik and Wayne Gray
                                                                  Schoppek, W., Boehm-Davis, D. A., Diez, M., Hansberger,
for numerous helpful discussions and Stellan Ohlsson for
                                                                    J. T., & Holt, R. W. (2000, August). Letting ACT-R fly-
helpful comments on an earlier draft.
                                                                    A model of the interaction between trained airline pilots
                                                                    and the flight management system. Paper presented at the
                        References                                  7th Annual ACT-R Workshop, Carnegie Mellon
Anderson, J. R. (1990). The adaptive character of thought.          University, Pittsburgh, PA
  Hillsdale, NJ, USA: Lawrence Erlbaum Associates, Inc.           Shiffrin, R. M., & Schneider, W. (1977). Controlled and
Anderson, J. R., Bothell, D., Byrne, M. D., & Lebiere, C.           automatic human information processing II: Perceptual
  (2002). An integrated theory of the mind. Manuscript              learning, automatic attending and a general theory.
  submitted for publication and available at                        Psychological Review, 84, 127–190.
  http://actr.psy.cmu.edu/papers/403/IntegratedTheory.pdf.        Zhang, J., Patel, V. L., Johnson, T. R., & Shortliffe, E. H.
Byrne, M. D., & Bovair, S. (1997). A working memory                 (2002). Toward an action based taxonomy of human error
  model of a common procedural error. Cognitive Science,            in medicine. In W. D. Gray & C. D. Schunn (Eds.),
  21, 31–61.                                                        Proceedings of the Twenty-Fourth Annual Conference of
Byrne, M. D., & Kirlik, A. (2002). Integrated Modeling of           the Cognitive Science Society (pp. 970–975). Mahwah,
  Cognition and the Information Environment: Closed-                NJ: Erlbaum.
  Loop, ACT-R Modeling of Aviation Taxi Errors and
  Performance. Technical Report AHFD-02-19/NASA-02-
  10, Institute of Aviation, University of Illinois at Urbana-
  Champaign.
                                                               209

