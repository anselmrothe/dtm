UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Thinking Graphically: Extracting Local and Global Information
Permalink
https://escholarship.org/uc/item/4544r6tm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Ratwani, Raj M.
Trafton, J. Gregory
Boehm-Davis, Deborah A.
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

                  Thinking Graphically: Extracting Local and Global Information
             Raj M. Ratwani                                 J. Gregory Trafton                     Deborah A. Boehm-Davis
          (rratwani@gmu.edu)                           (trafton@itd.nrl.navy.mil)                     (dbdavis@gmu.edu)
       George Mason University                                NRL Code 5513                         George Mason University
            Fairfax, VA 22030                             Washington DC, 20375                          Fairfax, VA 22030
                               Abstract                                 graph. Empirical data suggest that global questions take
                                                                        longer and are more difficult to answer than local questions
   This study investigates how information is extracted from a          (Guthrie, Weber, & Kimmerly, 1993; Lohse, 1993). Specifi-
   graph when different types of questions are asked. Although          cally, Lohse (1993) found that the more difficult the ques-
   the process for extracting local information from simple
                                                                        tion was, the longer it took to answer the question. Further,
   graphs is understood quite well, the processes used to extract
   global information from more complex graphs are not as               Guthrie et al. (1993) found that local questions elicited more
   clear. In a series of two studies using verbal protocols and eye     explicit category-related extractions (i.e., reading off the
   tracking, we compared responses to local and global                  axes on a bar-graph) and explicit read off information than
   questions.      We replicated previous research on local             did global questions while global questions elicited more
   questions, and show that people extract global information           general (global) abstractions.
   using a different set of cognitive processes.                                  The processes that might underlie these differences
                                                                        between local and global extractions have not been elabo-
                           Introduction                                 rated. Although Lohse (1993) showed that the most impor-
Several frameworks (Bertin, 1983; Kosslyn, 1989; Lohse,                 tant determinant to reaction time was the number of cogni-
1993; Pinker, 1990) and modifications to those frameworks               tive operations needed to answer a specific question, he did
(Peebles & Cheng, 2002; Carpenter & Shah, 1998; Trafton                 not define global questions as needing a different set of
& Trickett, 2001) have been proposed to explain how infor-              cognitive operations. Other current models (Kosslyn, 1989;
mation is extracted from graphs. These frameworks provide               Pinker, 1990) do not differentiate between different types of
a broad set of cognitive operations that can be applied in              questions. Thus, although they may be able to account for
different situations. Pinker (1990), for example, suggests a            the results, they offer no predictions about the processes that
general task analysis that allows a "conceptual question" to            people use to extract global information from graphs.
be posed, a set of cognitive operations to be applied (e.g.,                      Our research goal was to show that there are
relating information to long term memory via "graph sche-               qualitative differences between the way people answer
mas"), and a "conceptual message" to be extracted from the              global and local questions and that different questions acti-
graph.                                                                  vate different cognitive operations.
           The focus of most of these models, theories, and
experiments has been on the extraction of “local” informa-                                      Experiment 1
tion from simple and moderately complex graphs. For ex-                 The first experiment was designed to examine whether the
ample, Pinker (1990) asked people to determine the answer               type of question asked influences the cognitive processes
to questions such as "What is the price of graphium in                  used by individuals to answer those questions in the context
1983?” Consequently, these kinds of local information ex-               of complex graphs. Thus, we chose to use graphs that were
tractions (also called read-offs) are quite well understood. In         more complex than the graphs that have been used to date in
fact, local extractions can be described by a reasonably con-           this type of research. Our work uses choropleth graphs,
sistent set of steps that occur in a reasonably consistent or-          which use different colors, shades of gray, or patterns to
der.                                                                    represent different quantities.
           First, participants read a question to determine
what information they are being asked to extract from the                                          Method
graph (e.g., What is the price of tin in 2001?). Parts of the
                                                                        Participants
question may be read multiple times (Peebles & Cheng,
2002). Next, the participant searches for the specific infor-           The participants were ten George Mason University under-
mation on the graph, shifting from the axes to the main part            graduate psychology students who received course credit for
of the graph and back again (Lohse, 1993; Kosslyn, 1989;                their participation.
Pinker, 1990; Carpenter & Shah, 1998). Once the informa-
tion is found, multiple saccades occur between the main part            Materials
of the graph and the legend in order to keep the information            Four sets of choropleth graphs were created. Each set con-
in memory (Carpenter & Shah, 1998; Trafton, Marshall,                   sisted of three to ten conceptually related graphs. For exam-
Mintz, & Trickett, 2002). Finally, the question itself is an-           ple, one set of three graphs showed the population for the
swered.                                                                 years 1990, 1995, and 2000. Two sets of graphs were com-
           Less is known about what happens when people                 plex, containing 53 counties (see Figure 1 for an example).
are asked to extract global or trend information from a
                                                                    958

The remaining two sets of graphs were less complex; each            tion then received either a global question or a multi-search
graph in those sets showed nine counties.                           question for that specific graph. This process continued for
                                                                    each of the graphs in the set. At the end of the set, all
                                                                    participants were asked to answer five to ten questions
                                                                    about those graphs. These questions were inference ques-
                                                                    tions and were the same for both conditions.
                                                                              Each graph was presented on a single sheet of pa-
                                                                    per. Participants were instructed to answer every question
                                                                    at their own pace. Participants were permitted to look back
                                                                    at any of the graphs needed. Each participant provided a
                                                                    talk-aloud protocol (Ericsson & Simon, 1994) as they ex-
                                                                    amined the graphs and answered the questions. The partici-
                                                                    pants’ verbal protocols and the graphs they were examining
                                                                    were videotaped.
                                                                    Coding Scheme
                                                                    Transcriptions of the verbal protocols were coded prior to
                                                                    data analysis. The first step was to segment the protocols
                                                                    into individual utterances. Utterances were defined as a sin-
Figure 1. Graphs used in Experiments 1 and 2.                       gle thought and utterances that were not germane to the task
                                                                    at hand were coded as “off task” and eliminated from fur-
          Four types of questions were generated for each set       ther analysis. Each remaining utterance was then coded as
of maps: describe questions (which asked for a general de-          being an aggregate read-off (extracting conceptual infor-
scription of what the graph represented); global questions          mation from the graph), a specific read-off (extracting indi-
(which required general trends or descriptions to be identi-        vidual information from the graph), explicit search (looking
fied); local questions (which required straightforward single       for a specific object or county), or reasoning (constructing a
extractions from the graph); and multi-search questions             “story” of what is happening in the graph or making infer-
(which asked for information that could only be obtained by         ences about the data). A second independent coder coded
searching the graph in multiple locations and had features of       25% of the protocol data. Inter-rater reliability was calcu-
both local and global questions). Examples of each type of          lated using Cohen’s Kappa, kappa = .923, (p<.001), with
question are illustrated in Table 1.                                inter-rater agreement at 94.2%. Table 2 shows examples of
                                                                    each type of utterance.
         Code                           Example
  Describe Question     Describe what is going on in this                     Code                          Example
                        graph.                                        Aggregate Read-off    There is more blue on the graph, and
  Global Question       What is the general trend of population                             less orange.
                        growth in this graph?                         Specific Read-off     The population of Victorville county is
  Local Question        What is the population of Victorville                               20,451 to 35,622
                        county?                                       Search                Victorville, Victorville, Victorville, I
  Multiple-Search       Which counties have the greatest                                    don’t see Victorville.
  Question              populations?                                  Reasoning             Since the outside seems to be the
                                                                                            country area the center will grow.
Table 1. Examples of each question type.                            Table 2. Examples of each utterance type.
Design
Participants were randomly assigned either to the local or                           Results and Discussion
global condition. Participants in both the global and local         Our two manipulations in Experiment 1 were question type
conditions were asked both global and local questions.              (describe, local, global, multi-search) and condition (global,
Participants in the global condition answered global                local). There were no significant differences between the
questions first while the local condition answered local            global and local conditions in how they answered different
questions first.                                                    types of questions (all p > .05); thus, we collapsed across
                                                                    condition for all analyses. Table 3 shows the percentage of
Procedure                                                           each type of utterance for the entire experiment.
In this experiment, all participants first saw a graph and then     Utterance Type          Overall Frequency         Percentage
received an orientation question to allow them to become            Aggregate Read Off      899                       47.39
familiar with it. This orientation question asked the partici-      Specific Read Off       637                       33.58
pant to “describe what was going on in the graph.” Partici-         Search                  145                       7.644
pants in the local condition then received a local question         Reasoning               216                       11.39
for that specific graph, and participants in the global condi-      Table 3: Frequency and Percentage of Different Utterances.
                                                                959

         Our main goal was to show differences between                                We found that there was an overall difference in
types of questions and how participants answered these                       the pattern of transition probabilities as a function of ques-
types of questions. Because search and reasoning accounted                   tion type, χ2(15) = 217.3, p < .001. Pairwise analyses with a
for a relatively small proportion of utterances, we focused                  Bonferroni adjustment showed that the describe questions
on the number and type of extractions (specific read-off and                 are not significantly different from global questions, and
aggregate read-off). To analyze these data, we normalized                    local questions are not significantly different from multi-
the raw frequencies by dividing the number of each extrac-                   search questions, but all other comparisons were significant.
tion type by the number of questions that were asked.                                 Thus, describe and global questions were answered
                                                                             in much the same way, and local and multi-search questions
               4                                                             were answered in a similar way, but the manner in which
                                         Aggregate   Specific                global/describe questions and local/multi-search were an-
               3
                                                                             swered was very different. Because the global and describe
 Extractions
               2                                                             questions are so similar, we will illustrate the process differ-
               1                                                             ences using only the global questions. Similarly, because
               0                                                             local and multi-search questions were so similar, we will
                   Describe   Global      Local         Multi-Search
                                                                             only discuss the process used to answer local questions.
           -1
                                Question Type                                     Search           3%            Reasoning
Figure 2. Average extractions per question
                                                                             7%              7%
          As Figure 2 suggests, participants extracted more
                                                                                                     Question
aggregate information than specific information when an-                                   44%
swering describe questions, F(1,9)=27.1, MSE=.408, p <
.001 and when answering global questions, F(1,9) = 61.3,
MSE = .617, p < .001. Thus, when participants were de-                          Specific              36%         Aggregate
scribing the general trends of the graph or answering a                         Read-off                          Read-off
global question, they extracted much more aggregate infor-
                                                                             Figure 3. Local question transition diagram.
mation from the graph than specific information.
          In contrast, participants answering local questions                                                    Reasoning
extracted far more specific information from the graphs than                    Search        5%
aggregate information, F(1,9) = 133.7, MSE=.164, p < .001.
Participants answered multi-search questions using roughly                                   Question
equivalent amounts of specific and aggregate information                                                                     3%
(F(1,4)=5.2, MSE=.216, p = .08), although there was a                                  4%                            48%
trend suggesting that they extracted a bit more specific in-
formation than aggregate information. As Figure 1 suggests,                                        22%
                                                                                Specific                          Aggregate
the interaction between question type and extraction type is                    Read-off                          Read-off
highly significant, F(1,9) = 153.8, MSE=.382, p < .001.                                              3%
          Clearly, participants extracted differential types of
data for different question types. Not surprisingly, for de-                 Figure 4. Global question transition diagram.
scribe and global questions, participants extracted primarily
aggregate information (i.e., the biggest counties are right                           As Figures 3 and 4 suggest, participants answering
next to each other), while for local and multi-search ques-                  local questions spent much of their time making specific
tions they extracted primarily local information.                            read-offs and searching. In contrast, when participants an-
          Did they extract this information in different or-                 swered global questions, they spent most of their time
ders? To examine this issue, we calculated transition prob-                  making aggregate read-offs and reasoning.
abilities and created transition diagrams for each question                           These data clearly show that there are large
type. To do this, we looked at the sequence of utterances in                 differences in the type and order of cognitive operations
the verbal protocols. We then coded each pair of utterances                  used: local questions elicit primarily search and specific
(1-2; 2-3) by the type of utterance each pair represented                    read-offs while global questions elicit primarily reasoning
(e.g., search followed by search, S-S, or search followed by                 and aggregate read-offs. At one level this is not a surprising
specific read-off, S-SR). The total proportion of each type of               result: global questions elicit global extractions and local
transition was then calculated and diagrams constructed to                   questions elicit local extractions. However, it does show
illustrate those transition probabilities. The diagrams them-                that current graph comprehension models and theories need
selves include only those links that occurred more than 3%                   to be updated to show sensitivity to the type of question
of the time for that question type.                                          asked as they do not predict these sorts of differences.
                                                                       960

                       Experiment 2                             Design
In the first experiment, we clearly showed that there were      The design was the same as Experiment 1, with 10 partici-
high-level differences in the utterances that participants      pants in the global condition and 10 participants in the local
gave as they answered different types of questions. We also     condition.
showed that the patterns of use of these utterance types
differed as they answered different types of questions. This    Procedure
raises the question of how people might be visually             The procedure was very similar to that used in Experiment
examining the maps. These differences should surely             1; however, the use of the computer and eye tracker did ne-
translate into different ways of visually examining the maps.   cessitate some changes. The participants were seated at a
          The protocols from experiment one, theories of        comfortable distance from the monitor and used a chin rest.
visual search, and previous work on graph comprehension         Participants first were calibrated on the eye tracker. Par-
suggest that when answering local questions, participants       ticipants were then shown each map and the question(s)
should visually search for the target, probably by systemati-   relevant for that map. The interface allowed participants to
cally examining areas that catch the attention, then con-       progress from map to map with a button-click and to look at
tinuing on to other areas (McCarley, Wang, Kramer, Irwin,       maps they had previously viewed.
& Peterson, in press; Wolff, 1996). After finding the target,
participants will probably saccade back and forth to the        Coding Scheme
legend (Carpenter & Shah, 1998; Trafton et al., 2002) to        In these analyses, we examined a representative subset of
read off the information, then answer the question.             the questions (two global questions and three local ques-
          Global questions will presumably show a different     tions). Frequencies and transition diagrams were created by
pattern of eye movements, but how those differences will be     counting the number of gazes (via saccades) to different
shown is not clear. Participants could systematically search    areas of the graph. The areas of the graph that were coded
county by county to understand differences at that level.       were: the legend, the title of the graph, and the main part of
Alternatively, participants could focus more on larger scale    the graph itself.
areas across the map. In this case, participants would spend              If a participant gazed at the main part of the graph,
far more effort on counties that are next to different colors   it was coded in two additional ways: location of county and
(“edge” counties) to understand the size and shape of the       whether or not they read. For the location coding, if other
different centroid areas (Lewandowsky, Herrmann, Behrens,       counties of the same color surrounded the gazed-at county,
Li, Pickle, & Jobe, 1993). Given the large qualitative and      it was coded as an “inner” county. If the county was on an
quantitative differences we found between global and local      edge between one or more different colored counties, it was
questions in Experiment 1, we believe that participants will    coded as an “edge.” If the county was on the outside border
visually examine maps by focusing on more counties that         of the map, it was coded as a “border.” For the read coding,
border another color and spend proportionally less effort       if the participant read the name of the county, it was coded
focusing on the legend. This experiment was designed to         as “read.” If the participant looked at a county but did not
use eye movement data to test these hypotheses.                 read the county’s name, it was coded as “not read.” Figure 5
                                                                shows an annotated example of each different coding type.
                           Method
Participants
Twenty-one George Mason University undergraduate psy-
chology students served as participants for course credit.                                                     a.Edge, non-read
One participant could not be calibrated on the eye tracker;
his data were removed from all analyses.
                                                                 b. Edge, read
                                                                                                               c.Inner,    non-
Materials                                                                                                      read
The same sets of graphs used in the first experiment were
used in the second experiment. For the second experiment,
the materials (graphs and questions) were displayed on a
                                                                                                               d. Border, read
computer screen. Graphs were shown in the center of the
screen; questions (global, local or multiple search) were
displayed at the bottom of the screen. To reduce the amount
of time students took answering the questions, describe
questions were eliminated from this study. Eye track data       Figure 5. Sample eye-movements with examples of each gaze
were collected using an LC Technologies Eyegaze System          type.
eye tracker operating at 60Hz (16.7 samples/second).
                                                            961

                 Results and Discussion
          Experiment 2 was designed to expand on the proc-
ess differences found in Experiment 1. Specifically, we
wanted to examine if participants’ eye movements differed
across global and local questions, and, if so, how they dif-
fered. In general, because global questions are more com-
plex (Guthrie et al., 1993; Lohse, 1993) and elicited many
more gazes and utterances, we perform our statistics on
percentages, though we also present raw frequencies.
          For local questions, we expected to find an initial
search for the county names with more reading than non-
reading, finding of the target, and several back and forth
saccades between the legend and the target. For global
questions, we expected to find participants gazing more fre-
quently at edge counties, and cycling back and forth be-
tween edges. We also expected to find proportionally fewer        Figure 6. Sample eye-movements from a participant answering
                                                                  a global question.
legend gazes overall when answering a global question than
                                                                            Comparing the number of edge gazes to the other
when answering a local question.
                                                                  gaze types also shows an interesting pattern: people in both
                   Local           Global
                                                                  conditions examined edge counties more often than other
  Edge          3.8 (39%)       17.4 (56%)
                                                                  county types (Bonferonni adjusted χ2 significant, p < .008).
  Inner         1.3 (13%)       9.8 (26%)
                                                                  When answering a global question, this makes sense. How-
  Border        1.7 (17%)        1.0 (3%)
                                                                  ever, when answering local questions, participants showed
  Legend        3.1 (31%)        4.1 (15%)                        the same pattern. This could be due to participants having
   Read         5.8 (85%)       12.2 (46%)                        their eyes drawn to differential colors. It also could be that
  Non-Read 1.0 (15%)            14.1 (54%)                        participants are searching for county names from edge to
Table 4. Kinds of counties examined, whether or not they read     edge, using the same processes used when answering global
the county names, and number of times the legend was              questions. To investigate these possibilities, we created
examined (averaged by question).                                  transition graphs (see Figures 7 and 8).
          In general, this is exactly what we found (see Table                                             Inner
4). Participants read county names more often than not in               Target        13%
the local condition, but reading behavior did not differ in the
global condition, χ2(1) = 32.0, p < .0001, (Bonferonni ad-                             Edge            14%
justed χ2 significant at p < .001 for local questions, p > .10                                                    7%
                                                                      6%
for global questions).
          We also found that when participants answered lo-                      4%                      36%
cal and global questions, they differed in the number and
type of counties they examined, χ2(3) = 22.7, p < .0001.               Legend            6%              Border
The main source of this difference between question types
seems to be that when participants answered local questions       Figure 7. Global transition graph from Experiment 2.
they focused more on the legend and less on the edge coun-
ties, while global questions elicited more edge gazes and                Target          13%               Inner
fewer legend gazes, χ2(1) = 7.8, p < .01.
          Figures 1 and 6 show examples of participants an-         8%        3%                         3%
swering a local question and a global question, respectively.                               Edge
Notice that Figure 6 shows a participant focusing primarily
on edge counties, tracing the boundaries of the color di-                     18%                                8%
                                                                                                         6%
vider. In contrast, Figure 1 shows the participant searching                                     7%
for the target, finding it (obscured in the figure by the eye-
track), and then sacadding down to the legend to read off the          Legend                            Border
value.
                                                                  Figure 8. Local transition graph from Experiment 2.
                                                                            As Figures 7 and 8 suggest, answering global and
                                                                  local questions engage different types and orders of eye
                                                                  movements. Importantly, when answering local questions,
                                                                  looking from edge to edge occurs less frequently than when
                                                              962

answering a global question, χ2(1) = 10.8, p < .05. Thus,         graph and the legend, this does not seem to be true in all
consistent with our earlier analysis, when participants           cases.
answer a global question, they look from edge to edge to                     Finally, how people go about visually inspecting a
understand the size and shape of the centroid. When an-           graph is much more complex than what we have described
swering a local question, participants search, find the target,   here. It seems that people use several heuristics to search
and then examine the legend.                                      and a completely different set of heuristics to explore. This
          One part of our earlier analysis did not, however,      search/explore methodology is not accounted for in any
hold up. Previous research has shown that when partici-           theories of graph comprehension, and it is not immediately
pants need to extract information from a legend, they sac-        obvious how to easily integrate this information into such
cade back and forth between the main graph and the legend         theories.
(Carpenter & Shah, 1998; Trafton et al., 2002). In this
study, we found that when participants answered local                                    Acknowledgements
questions, they found the target and immediately went to the      This research was supported in part by grant 55-7850-00 to
legend (see Figure 1). However, after a single examination        the second author from ONR and by George Mason Univer-
of the legend, they answered the question. This result is         sity. We thank Mike Schoelles for designing the interface of
somewhat odd because it seems to contradict a robust,             the eye tracker and Brandon Beltz for IRR coding.
replicable effect. We believe that there are two main
possibilities for this finding. First, it could be that because                                 References
participants saw these graphs over and over again, they
                                                                  Bertin, J. (1983). Semiology of graphs. Madison, WI: University of
became more familiar with the legend and essentially
                                                                     Wisconsin Press.
memorized them, needing only a reminder gaze at the
                                                                  Carpenter, P. A., & Shah, P. (1998). A model of the perceptual and
legend. Alternatively, our legend was rather bigger than
                                                                     conceptual processes in graph comprehension. Journal of
that used in previous studies, and that may have affected the        Experimental Psychology: Applied, 4 (2), 75{100.
overall gaze performance in some way.                             Ericsson, K. A., & Simon, H. A. (1993). Protocol analysis: Verbal
                                                                     reports as data (Revised edition). Cambridge, MA: MIT Press.
                    General Discussion                            Guthrie, J., Weber, S., & Kimmerly, N. (1993). Searching documents:
Choropleth graphs were used in these experiments because             Cognitive processes and deficits in understanding graphs, tables,
of their complexity. This complex graph type allows us to            and illustrations. Contemporary Educational Psychology, 18 186-
generalize to complex representations such as                        221.
meteorological graphs and scientific visualizations.              Kosslyn, S. M. (1989). Understanding charts and graphs. Applied
Experiment 1 showed that there were major process differ-            Cognitive Psychology, 3, 185-226.
ences in how people answer local and global questions.            Lewandowsly, S., Herrmann, D.J., Behrens, J.T., Li, S-C, Pickle, L.,
First, local questions elicited the standard search Æ find Æ         Jobe, J.B., (1993). Perception of clusters in statistical maps. Applied
                                                                     Cognitive Psychology,7, 533-551.
answer behavior that has been found in previous studies.
                                                                  Lohse, G. L. (1993). A cognitive model for understanding graphical
However, contrary to other graph comprehension theories,
                                                                     perception. Human Computer Interaction, 8, 353-388.
we showed that the cognitive steps that are followed to an-
                                                                  McCarley, J. S. , Wang, R. F., Kramer, A. F., Irwin, D. E., & Peterson,
swer a global question are quite different. In general, global       M. S. (in press) How Much Memory Does Oculomotor Search
questions were answered by a series of aggregate read-offs.          Have? Psychological Science.
          Experiment 2 expanded on this finding by showing        Peebles, D., & Cheng, P. C.-H. (2002). Extending task analytic models
big differences in how people visually inspected graphs              of graph-based reasoning: A cognitive model of problem solving
when asked local and global questions. Local questions               with Cartesian graphs in ACT-R/PM. Cognitive Systems Research,
showed a search (read) Æ find Æ legend Æ answer                      3, 77-86.
behavior, while global questions showed a trace-edges             Pinker, S. (1990). A theory of graph comprehension. In R. Freedle
(don’t read) Æ answer behavior. We believe that this edge-           (Ed.), Artificial intelligence and the future of testing, (pp. 73-126).
tracing behavior allows participants to understand the               Hillsdale, NJ:
general shape of large map features, which in turn allows         Trafton, J. G., Marshall, S., Mintz, F., & Trickett, S. B. (2002).
them to describe what is occurring in the graph at a high            Extracting explicit and implict information from complex
level without becoming overly concerned with individual              visualizations. In H. Narayanan (Ed.), Diagramatic Representation
data elements.                                                       and Inference (pp. 206-220). Berlin: Springer-Verlag.
          What are the implications for current theories of       Trafton, J. G., & Trickett, S. B. (2001). A new model of graph and
graph comprehension? One obvious implication is that they            visualization usage, The proceedings of the twenty third annual
should not assume that different questions use the same              conference of the cognitive science society . Mahwah, NJ: Erlbaum.
mental operations. Using different operations to account for      Wolfe J.M. (1996). Extending guided search: Why guided search
different question types should allow better theories and            needs a preattentive “item map.” In: A.F. Kramer, M.G.H. Coles, &
models to be built. Second, even though several current              G.D. Logan (Eds), Converging operations in the study of visual
                                                                     attention. (pp. 247-270) Washington, DC: American Psychological
models suggest sacadding back and forth between the main
                                                                     Association.
                                                              963

