UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Interventions do not solely benefit causal learning: Being told what to do results in worse
learning than doing it yourself
Permalink
https://escholarship.org/uc/item/1m386515
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Sobel, David M.
Kushnir, Tamar
Publication Date
2003-01-01
Peer reviewed
  eScholarship.org                                   Powered by the California Digital Library
                                                                      University of California

  Interventions do not solely benefit causal learning: Being told what to do results in
                                        worse learning than doing it yourself
                                         David M. Sobel (David_Sobel_1@brown.edu)
                          Department of Cognitive and Linguistic Sciences, Box 1978, Brown University
                                                       Providence, RI, 02912 USA
                                      Tamar Kushnir (Tkushnir@socrates.berkeley.edu)
                                  Department of Psychology, Tolman Hall, University of California
                                                        Berkeley, CA 94720 USA
                             Abstract                                   update those probabilities based on the observed data
                                                                        through an application of Bayes’ rule. The resulting
  Previous research has demonstrated that causal learning is            posterior probabilities on the hypotheses represent how
  facilitated by observing interventions on a causal system (e.g.,      likely each is the causal structure that generated the
  Lagnado & Sloman, 2002). Does the origin of these
                                                                        observed data.
  interventions influence learning? Sobel (2003) demonstrated
  that causal learning was facilitated when learners observed the            These algorithms make different predictions about the
  results of their own interventions as opposed the results of          role of interventions in causal learning. Constraint-based
  another’s interventions, even though the data learners                algorithms treat interventions as special conditional
  observed were identical. Learners in the former condition             probabilities, which enable learners to distinguish between
  were able to test various causal hypotheses, while learners in        otherwise equivalent causal graphs (Pearl, 2000).
  the latter condition were less able to do so. The present             Constraint-based algorithms ignore the source of the
  experiment followed up on these findings by comparing                 interventions: only knowledge of conditional independence
  causal learning based on observing the results of a learner’s         and dependence is critical for learning.
  own interventions with causal learning based on observing
                                                                             In contrast, Bayesian algorithms require that learners
  data from a set of interventions a learner is forced to make.
  Although learners observed the same interventions and                 have particular hypotheses in mind, and given the observed
  subsequent data, learning was better when participants                data, update the probability that each hypothesis reflects the
  observed the results of their own interventions. These                actual causal structure. If a learner observes interventions
  findings are discussed in relation to various computational           that are relevant to those hypotheses, learning will be
  models of causal learning.                                            facilitated. However, if a learner observes interventions that
                                                                        are not relevant to those hypotheses, then those data will be
                         Introduction                                   less beneficial, even if those data contain the critical
     Causal knowledge is important for everyday interaction             conditional independence and dependence information
in the world. A recent pursuit in cognitive science has been            necessary to discern a unique causal structure.
to describe how human beings learn and represent causal                      An (albeit simple) example might help. Suppose you
knowledge.        Researchers in computer science have                  wake up one morning with the flu, and have two symptoms:
examined causal graphical models as a way of representing               coughing and dry-mouth. Many different causal models
causal structure. Recently, psychologists have adopted this             follow from these observations. For example, the flu could
formalism as a way of representing causal relations in a                cause the dry-mouth, which in turn could cause coughing.
variety of domains (Gopnik, Glymour, Sobel, Schulz,                     Alternatively, the flu could independently cause coughing
Kushnir, & Danks, in press; Lagnado & Sloman, 2002;                     and dry-mouth: coughing and dry-mouth could be unrelated,
Rehder & Hastie, 2001; Tenenbaum & Griffiths, 2002).                    but dependent given that you have the flu. Figure 1 depicts
     One issue in this discussion is whether a particular               these two potential causal models.
algorithm or class of algorithms best instantiates human
causal learning. Glymour (2001) proposes that constraint-                                 Dry-
                                                                                                           Flu
                                                                                          mouth
based models offer the best account of human causal
learning (see also Gopnik et al., in press). These models                      Flu                                    Coughing
posit rules for learning causal structure based on observing
                                                                                                          Dry-
patterns of dependence and independence among a set of                                  Coughing
                                                                                                          mouth
events. In contrast, Tenenbaum and colleagues (Tenenbaum
& Griffiths, 2002; Steyvers et al., in press) propose that
human causal structure learning is better instantiated by                           Figure 1: Two potential causal models
Bayesian algorithms. Using these algorithms, learners
assign probabilities to a constrained set of hypotheses. They
                                                                   1100

     An intervention could distinguish between these two              The second assumption of this project is that when
hypotheses: drinking a glass of water would eliminate the        learners are able to generate their own interventions, they
dry-mouth, but have no effect on the flu. Learners would         choose interventions that enable them to test their
observe the probability of coughing given the presence of        hypotheses. Steyvers et al. (in press) provided a critical
the flu, but the absence of dry-mouth. If coughing persisted,    piece of evidence for this assumption.             They asked
then the left-hand model of Figure 1 would be the more           participants to learn a causal structure from observing data.
likely causal structure. If coughing were eliminated, then       After participants generated a set of structures that reflected
the right-hand model in Figure 1 would be more likely.           this learning, Steyvers et al. (in press) allowed learners to
     However, this “drink water” intervention is only            observe the results of one intervention on that structure.
effective at discriminating among certain causal models,         Learners did not choose their intervention randomly. The
such as the two shown in Figure 1. For example, another          majority of learners chose the intervention that provided
hypothesis is that dry-mouth and flu both cause coughing,        them with the information necessary to distinguish among
and are independent from each other (perhaps because you         the models they chose previously. Steyvers et al. (in press)
are also dehydrated). The “drink water” intervention does        presented a Bayesian model with an “active learning”
not discriminate between this common effect model and the        component (e.g., Murphy, 2001), which provided the best
common cause model depicted on the left side of Figure 1.        model of these data.
Given that you have the flu, both models predict that                 However, neither of these experiments directly tested a
coughing would persist if dry-mouth were eliminated.             situation that compared learning from observing the results
     What this example illustrates is that a learner’s initial   of one’s own interventions with the results of another’s
hypotheses matter. This is not a novel idea in cognitive         interventions. Sobel (2003) presented participants with a
science: many researchers propose that adult learners have a     novel causal learning task: participants were told that “Dr.
variety of hypothesis-testing strategies, which may lead         Science” had wired up a set of colored lights and sensors.
them to proper or improper conclusions (see e.g., Klayman        The sensors were color sensitive and made the light they
& Ha, 1987; Wason, 1968). Is this the case in the domain of      were connected to activate. Thus, if a red sensor was
causal learning? If learners use constraint-based algorithms     connected to a white light, then the white light would
to build a causal model from observed data, then the source      activate whenever the red light activated. Since this
of those data should not matter. However, if learners are        happened at the speed of light, learners just saw the white
actively testing hypotheses, then the source of interventions    and red lights activating together. Depending on the
might make a difference in causal learning.                      experiment, the sensors could have deterministic or
     This hypothesis relies on two assumptions about causal      probabilistic relationships. Participants were asked to learn
learning. The first assumption is that learners benefit from     the causal structure among four colored lights (i.e., whether
interventions over simply observing data. Schulz (2001)          each light had sensors on it, and if so, of which color). One
investigated whether adults and children could make causal       group of learners was allowed to intervene on those lights
inferences based on interventions. In one experiment, she        themselves. Another group observed another person make
presented participants with two creatures (A and B) that         the same interventions (with the same results). Over several
moved together simultaneously, and told them that one was        experiments, although learners in both groups observed
the “boss”, and made the other creature move. From this          identical interventions and data, learning was superior when
information alone, the directionality of the causal relation     participants observed the results of their own interventions.
between the two events was indeterminate: neither temporal            The goal of this investigation is to examine two
priority nor contingency information allowed the                 concerns with Sobel’s (2003) experiments.              In these
participants to determine the nature of the causal relation      experiments, learners actively manipulated the learning
between the two creatures. Participants were then shown          environment; observers, in contrast, did not. The first
that there was an intervention (i.e., a button), designed for    concern is that it is possible that learners in the intervention
one of the creatures (B), which made it move. The button         condition were simply paying more attention than learners
was pressed and only creature B moved. After observing           in the observation of intervention condition. Sobel (2003,
this intervention, both adults and 4-year-olds consistently      Experiment 4) attempted to control for this by presenting
claimed that the other creature (A) was the boss.                learners with the ability to select cases in which they
     This valid conclusion follows from one of Pearl’s           observed a particular light activating. In this condition,
(2000) algorithms for learning causal structure through          learners actively manipulated the learning environment, but
interventions. Learners have observed a critical conditional     had no information about interventions (and hence, little
independence: p(A | B) > p(A | do(B)) = 0. Thus, these data      information about conditional independence and
are consistent with the predictions of constraint-based          dependence). Learning was quite poor in this situation.
model. However, Schulz’s (2001) experiments are also                  However, a better manipulation would be to allow
consistent with a Bayesian model. The cover story of the         learners to manipulate a learning environment, but disable
experiment specified that one of two hypotheses were             them from testing their own hypotheses. To do this, we
correct; the intervention produced data that distinguished       created a fixed intervention condition. In this condition, the
between them.                                                    learning environment was identical to an intervention
                                                            1101

condition, but learners were forced to make a particular set     Materials: Participants were tested on a Dell Dimension
of interventions. This way, learners generated interventions,    8100 desktop computer with a 19” monitor.
but those interventions were based on another learner.
     This allows us to examine a second concern with             Procedure: Following Sobel (2003, Experiment 5), all
Sobel’s (2003) experiments, based on literature in               participants were seated at the computer and given the
educational psychology. Several researchers suggest that         following instructions:
kinesthetic learning – the ability to act on the environment                “In Dr. Science's laboratory, he has created a
as opposed to simply observing – may benefit learners even            number of games. Each game has four lights, colored
in non-kinesthetic domains, such as language (e.g.,                   red, white, blue, and yellow. Each light also has zero,
Furuhata, 1999). Such a benefit may also translate to the             one, or many sensors. Some sensors are sensitive to red
                                                                      light, others to blue light, others to white light, and
domain of causal structure learning. The results of the fixed         others to yellow light and will activate the light that it is
intervention condition allows us to examine whether                   connected to. For example, if the red light is connected
observing the results of interventions generated by a learner,        to a yellow sensor, then whenever the yellow light
independent of their own hypotheses impairs causal                    activates, the red light will also activate. But, because
structure learning compared with learners who observe the             this happens at the speed of light, all you will see is the
results of their own interventions.                                   red and yellow lights activating together. It is also
                                                                      possible that a light has no sensors attached to it, and
                        Experiment                                    therefore is not activated by any other light. Dr. Science
                                                                      is pretty absentminded, so he is not careful about how he
     In this experiment, we presented learners with four              wires the lights together. Sometimes the sensors do not
causal structure learning problems using the same paradigm            always work perfectly, so they won't always turn the
as Sobel (2003). Participants were introduced to Dr.                  lights they are connected to on.
Science, and told that he had wired together colored lights                 For each game, you have to figure out how the
and sensors. Participants were asked to learn the causal              lights and sensors are wired up. To help you, Dr.
structure among four colored lights (i.e., whether each light         Science is going to let you turn on each of the lights. So,
                                                                      you will see a set of buttons that turn on each light.
had sensors on it, and if so, of which colors). Participants
                                                                            In addition, Dr. Science has given you a black
were either allowed to intervene on the data freely                   bucket. You can put the bucket over any one of the
(Intervention Condition), or were instructed to make                  lights (and the sensors it is connected to). Putting the
specific interventions (Fixed Condition). In the fixed                bucket over the light covers both it and its sensors. If the
condition, these interventions and the subsequent data were           bucket is over the light, then the light will not activate
yoked to a learner in the intervention condition. Thus,               because the other lights cannot reach its sensors.”
learners observed identical data across the two conditions.
     Participants in the intervention condition were allowed          Participants were divided into two groups. In the
to turn on lights, as well as temporarily remove any one         intervention group, participants were told that they would be
light from the causal structure (by placing a bucket over it,    able to turn on any of the four lights as well as place the
which covers it and its sensors). Sobel (2003, Experiment        bucket over any of the lights as many times as they wanted.
5) found that this additional type of intervention greatly       These participants were shown a computer screen with nine
benefited learning. In particular, this enabled learners to      buttons. Four of the buttons activated the four different
observe conditional independence relations as well as            colored lights. If one of these buttons was pressed, then that
conditional dependence relations – the exact data necessary      light appeared on the screen for 0.5s. In addition, any effect
to learn a causal structure given a constraint-based             of that light (and likewise any of its effects) also appeared at
algorithm. As long as the conditional independence               the same time on the screen. The probability that any effect
relations are present, these algorithms would predict no         occurred given that its cause occurred was 0.8. Thus,
difference between these two conditions. However, if             turning on a light did not always cause its effects, which
hypothesis testing is important to learners, then when they      learners can attribute to Dr. Science carelessness in how the
observe the results of their own interventions, they do so       lights and sensors were wired together.
based on their own causal hypotheses. Learners in the fixed           The other five buttons moved the bucket – either over
intervention condition, in contrast, observe interventions       one of the four lights or off all of the lights. Pressing one of
and data based on another’s hypotheses, which might not          these buttons would result in the bucket moving to the
match there own, and which might cause impaired learning.        appropriate place. The bucket appeared on the screen as a
                                                                 black box.
Method                                                                Participants in this condition were told to intervene as
                                                                 much as they wanted in order to learn how the lights and
Participants: Forty-eight undergraduates were recruited          sensors were wired together. However, they were required
from an urban area university. Approximately equal               to turn on the four lights a minimum of 25 times. Their
numbers of men and women participated in the experiment.         interventions and the subsequent data were recorded. When
Participants were paid $7 for their participation.               they indicated they were finished, they were asked the test
                                                                 questions described below.
                                                            1102

      Participants in the fixed intervention condition were        occurred was 0.8. Importantly, lights never occurred
shown the same nine buttons. However, Dr. Science gave             spontaneously: the probability of an effect given the absence
them instructions to press particular buttons in a particular      of a cause was zero. The models were presented in one of
order. Participants were not allowed to intervene on their         four quasi-random orders. In both conditions, participants
own accord, but could only generated interventions that            were allowed to take notes.
turned the lights on and moved the bucket based on what                 After participants indicated that they thought they knew
Dr. Science told them. These instructions appeared on the          how the lights and sensors were wired together (in the
screen one at a time. If participants pressed an incorrect         intervention condition) or were shown the same intervention
button, then they received an error message.                       sequence (in the fixed intervention condition), participants
      Importantly, each sequence of interventions given to a       were asked two sets of questions. First, participants were
participant in the fixed intervention condition was yoked to       asked a set of causal structure questions – whether each
a participant in the intervention condition. Thus, the first       light had a sensor of each other color attached to it (e.g., was
participant in fixed intervention condition was told to make       there a blue sensor on the red light?). Participants first
identical interventions (and observed identical results) as the    answered the yes/no question, then rated their level of
first participant in the intervention condition.                   confidence in their answer on a scale of 0-100, with zero
      Before learning the four models, participants in both        being a total guess, and 100 being fully confident. There
conditions were given a training session with the bucket.          were twelve of these questions (one for each possible
They were shown three lights (colored green, purple, and           combination), asked in a random order.
gray), and three buttons that each activated one of the lights.         Participants were also asked a set of conditional
They were told that Dr. Science had wired these lights and         probability questions, in which they were asked to rate the
sensors perfectly. They were first told to press the button        likelihood of a particular light activating given that they had
that activated the gray light, and were shown that only the        turned on another light. These questions were phrased as
gray light activated. They were told that from this they           follows: “suppose you turned on the X light and the bucket
could conclude that there was not a gray sensor on the other       wasn’t on any of the lights, what is the probability that the
two lights. One could conclude this since if there had been        Y light (among possible others) would activate”.
a sensor on either of those lights, those lights would have        Participants were asked the twelve exhaustive pair-wise
activated.                                                         combinations, plus four questions that asked about the
      Then they were told to activate the green light and          conditional probability of that light activating by itself (e.g.,
observed that green and gray activated together. From this,        what is the probability that only the X light comes on if you
they were told to conclude that there was a green sensor on        turn on the X light). The order of these question sets was
the gray light. Then, they were then told to activate the          counterbalanced across participants.
purple light, and shown that all three lights activated. From
this, they were told that they could conclude that there was a
purple sensor on the green light. However, whether there                       A           B           C          D
was a purple sensor on the gray light was uncertain, since
they already knew that there was a green sensor on the gray
light and that the green light activated.
      They were then told that using the bucket could help.                    A          B            C          D
In particular, if the purple light was activated with the
bucket on the green light, then they could observe whether
the purple light activated the gray light in the absence of the        A                                         B
green light. Participants were told to make this intervention
and shown that under this circumstance only the purple light                     C           D         A                   D
activated.      Thus, participants observed the relevant
conditional independence between purple and gray given the             B                                         C
absence of green. The probability that the gray light
activated given the purple light and not the green light was
zero. There must not be a purple sensor on the gray light.         Figure 2: The four causal structures that participants were
Thus, there was only a purple sensor on the green light and        asked to recover. The colors were randomly assigned for
a green sensor on the gray light.                                  each participant
      After this training, participants were asked to learn four
different causal models, a chain, a chain with a link from the          Results
root light to the leaf light (A->D), a common effect and
chain and a diamond model. These are shown in Figure 2.                 For each model, participants received a score of one for
The color of the lights was randomly determined for each           each causal structure question they answered correctly, and
model. The causal connections were always probabilistic.           a score of zero for each question they answered incorrectly.
Thus, if a cause occurred, the probability that its effect         These scores were summed to reflect an overall accuracy
                                                              1103

score for each model (maximum: 12). These scores are            and the expected conditional probability for the sixteen
shown in Table 1. Preliminary analyses revealed no order        questions. These scores are shown in Table 2. A similar
effects: neither the question order nor the order the models    4 (model) x 2 (condition) mixed Analysis of Variance was
were presented in influenced responses.                         performed on these scores. A main effect of model was
     A 4 (model) x 2 (condition) mixed Analysis of              found: overall, deviance on the conditional probability
Variance was performed on participants’ accuracy scores.        questions differed among the four models: F(3, 138) = 7.22,
Model was a within-subject factor; condition was a              p < .001. A main effect of condition was not found. No
between-subject factor. This analysis revealed a main effect    significant interactions were found. Simple effect analysis
of condition: overall, learners were more accurate in the       revealed that the deviance score on the chain with A->D
intervention condition than the fixed intervention condition:   model was greater than any of the other three models: t(47)
F(1, 46) = 8.74, p < .01. A main effect of model was not        = 3.06, 2.96, and 3.49, in contrast with the chain, common
found. No significant interactions were found. Simple           effect and chain, and diamond models respectively, all p-
effect analysis revealed that this difference was consistent    values < .005.
for each of the four models: t(46) = 2.07, 2.01, 3.24, and           Did learners’ error on the conditional probability
2.20 for the chain, chain with A->D link, common effect         questions reflect their ability to recognize causal structure?
and chain, and diamond models respectively, all p-values <      If learners are building accurate causal models, then
.05.                                                            responses to the conditional probability questions should be
                                                                predictive of accuracy on the causal structure questions. To
 Table 1: Accuracy scores on causal structure questions for     examine this, four hierarchical regressions were performed;
    each model and condition (Maximum = 12). Standard           accuracy on the causal structure questions for each model
               deviation shown in parentheses                   was the dependent variable. First, condition was factored
                                                                into the model. Next, deviance scores on the other three
      Model          Intervention    Fixed                      models were factored in. This was done to control for
                     Condition       Intervention               participants’ individual differences in the deviance scores.
                                     Condition                  Finally, the deviance score for the model in question was
      Chain              10.88             9.88                 factored in. This score contributed to the variance in the
                         (1.44)           (1.87)                accuracy on the causal structure questions for the chain and
      Chain with         11.08             9.96                 the common effect and chain models: ∆r2 = .110 and .048
      A->D link          (1.10)           (2.51)                respectively, F(1, 42) = 7.22 and 3.99, both p-values < .05.
      Common             11.33             9.79
      Effect and         (1.47)           (1.82)                                            Discussion
      Chain
      Diamond            10.96             9.88                      Learners who were able to observe the results of their
                         (1.08)           (2.15)                own interventions were better at recovering the causal
                                                                structure among a set of events than learners who observed
                                                                the results of interventions they were forced to make. This
     Table 2: Deviance scores on conditional probability        result parallels Sobel (2003), who found that observing the
       questions for each model across the conditions.          results of another’s interventions resulted in worse causal
           Standard deviation shown in parentheses              learning than observing the results of one’s own
                                                                interventions. In both Sobel’s (2003) observation of
      Model          Intervention    Fixed                      intervention condition and the present fixed intervention
                     Condition       Intervention               condition, learners were unable to test their own causal
                                     Condition                  hypotheses. Even though learners might have observed
      Chain              12.66            14.44                 critical information about conditional independence and
                        (10.37)          (10.59)                dependence, learning in these circumstances was impaired
      Chain with         17.23            25.23                 compared with observing the results of one’s own
      A->D link         (11.67)          (16.19)                interventions. In fact, subsequent analysis revealed that all
      Common             12.80            15.35                 the participants in the intervention condition generated data
      Effect and        (10.47)          (11.68)                that presented them with the specific conditional
      Chain                                                     independence and dependence information necessary to
      Diamond            13.18            13.38                 learn each causal structure via constraint-based algorithms.
                         (8.48)           (9.06)                Thus, all learners were given the relevant conditional
                                                                independence and dependence information necessary to
     For each model, a deviance score was computed on           learn the causal structure. However, learning was facilitated
participants’ answers to the conditional probability            when the learner controlled when they were given that
questions. This was done by averaging the absolute value of     information.
the difference between the judged conditional probability
                                                           1104

     This experiment was motivated by two concerns with                              Acknowledgments
the procedure used by Sobel (2003). First, learners who
                                                                 We wish to thank Emily Blumenthal, Kathryn Noe, and
observe the results of their own interventions might have
                                                                 Sara Yerry for their assistance in data collection, and Amy
simply been more involved with the task of learning than
                                                                 Hoff, David Lagnado, Sean Stromsten, and Josh Tenenbaum
learners who observe another’s interventions because of
                                                                 for insightful discussion and comments.
their ability to act on the system. Further, the benefit of
observing the results of one’s own interventions might by
due to learners relying on kinesthetic learning skills. These                            References
two possibilities are inconsistent with the present data.        Furuhata, H. (1999). Traditional, natural and TPR
     These data seem inconsistent with the hypothesis that         approaches to ESL: A study of Japanese students.
constraint-based algorithms of causal structure learning best      Language, Culture, and Curriculum, 12, 128-142.
account for human learning. However, it is possible that         Glymour, C. (2001). The mind’s arrows: Bayes nets and
constraint-based methods could be modified to account for          graphical causal models in psychology. Cambridge, MA:
these data. We suggest that Bayesian accounts of causal            MIT Press.
structure learning are at least more qualitatively consistent    Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E.,
with these data than other approaches to causal structure          Kushnir, T., & Danks, D. (in press). Theory formation
learning. This is clearly a topic for future research.             and causal learning in children: Causal maps and Bayes
     One question that must be addressed is whether learners       nets. Psychological Review.
explicitly engage in hypothesis testing, or are relying on       Klayman, J., & Ha, Y. W. (1987). Confirmation,
processes that are more implicit. Several researchers (e.g.,       disconfirmation, and information in hypothesis testing.
Kuhn, 1989) have argued that children and in some cases,           Psychological Review, 94, 211-228.
even adults lack the ability to design experiments that          Kuhn, D. (1989). Children and adults as intuitive scientists.
explicitly test causal hypotheses. Such deficits in scientific     Psychological Review, 96, 674-689.
reasoning indicate that adults and children might lack the       Lagnado, D. A., & Sloman, S. (2002). Learning causal
metacognitive skills necessary to design unconfounded              structure. Proceedings of the 24th annual meeting of the
experiments or interventions that discriminate among causal        Cognitive Science Society.
hypotheses.                                                      Murphy, K. P. (2001). Active learning of causal Bayes net
     Steyvers et al. (in press), however, demonstrated that        structure. Technical Report: Department of Computer
adult learners would usually make a single intervention that       Science, University of California, Berkeley.
offered them the most information to discern among various       Pearl, J. (2000). Causality. New York: Oxford University
causal structures consistent with the data already observed.       Press.
They proposed that there might be a difference between           Rehder, B., & Hastie, R. (2001). Causal knowledge and
implicit causal knowledge, which is used in this kind of           categories: The effects of causal beliefs on categorization,
learning situation, and explicit causal knowledge, which           induction, and similarity. Journal of Experimental
was tested by researchers investigating scientific reasoning.      Psychology: General, 130, 323-360.
For instance, participants in both the present experiment and    Schulz, L. E. (2001). “Do-calculus”: Adults and
in Steyvers et al.’s (in press) experiments were not asked to      preschoolers infer causal structure from patterns of
justify their responses, nor were they asked to reflect on the     outcomes following interventions. Paper presented at the
strategies they used to garner their knowledge. Learning           2001 meeting of the Cognitive Development Society,
through a Bayesian algorithm does not require explicit             Virginia Beach, VA.
verbal representations of those hypotheses (see also Gopnik      Sobel, D. M. (2003). Watch it, do it, or watch it done: The
et al., in press).                                                 relation between observation, intervention, and
     To conclude, researchers in causal learning have been         observation of intervention in causal structure learning.
seeking a way to instantiate algorithms for learning causal        Manuscript submitted for publication, Brown University.
structure.     We believe that causal learning is better         Steyvers, M., Tenenbaum, J. B., Wagenmakers, E. J., &
instantiated by the causal graphical model framework,              Blum, B. (in press). Inferring causal networks from
particularly because of its ability to account for data from       observations and interventions. Cognitive Science.
interventions (see Gopnik et al., in press). The present         Tenenbaum, J, & Griffiths, T. L. (2002). Theory-based
experiment represents an ongoing effort to investigate             causal inference. Proceedings of the 2002 Neural
algorithms within that framework (see also Sobel, 2003).           Information Processing Systems Conference.
This line of research is more consistent with the qualitative    Wason, P. C. (1968). Reasoning about a rule. Quarterly
predictions of Bayesian algorithms. Future work, however,          Journal of Experimental Psychology, 20, 273-281.
must specify exactly what the nature of these algorithms is
and how they might be represented in the brain.
                                                            1105

