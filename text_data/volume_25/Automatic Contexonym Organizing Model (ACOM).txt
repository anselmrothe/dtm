UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic Contexonym Organizing Model (ACOM)
Permalink
https://escholarship.org/uc/item/3t98k5fc
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Ji, Hyungsuk
Ploux, Sabine
Publication Date
2003-01-01
Peer reviewed
  eScholarship.org                             Powered by the California Digital Library
                                                                University of California

              Automatic Contexonym Organizing Model (ACOM)
                                       Hyungsuk Ji (jihs@isc.cnrs.fr)
                                    Institut National Polytechnique de Grenoble
                                           Institut des Sciences Cognitives
                                      Sabine Ploux (ploux@isc.cnrs.fr)
                                      UMR 5015 CNRS – University of Lyon I
                                           Institut des Sciences Cognitives
                                                  67, boulevard Pinel
                                             69675 BRON cedex, France
                        Abstract                             speakers would choose stagger and possibly reel for
   Normal language user’s word-association intuition
                                                             the second task without hesitation. On the contrary,
   (e.g. drunken – stagger) raises questions about the       non-English speakers or machines would have con-
   mental lexicon organization and its application for       siderable difficulty in performing such a task even
   natural language processing tasks. We present an          with all available references 1 . This absence of ap-
   automatic contextually related words (contexonym)         propriate reference for contextually related words –
   organizing model (ACOM) that reflects this intu-
   ition, giving one of the possible answers to this         far from justifying the useless of their generalization
   question. Trained on large corpora, the model (1)         – may imply that our understanding on the mental
   selects contexonyms for a given word and (2) clas-        lexicon remains still immature.
   sifies these groups of related words on a geometric          Indeed, Edmonds and Hirst expressed the need
   representation. Some near-synonyms discussed in           for such references that can be used in their compu-
   Near-Synonymy and Lexical Choice (Edmonds and
   Hirst, 2002) were chosen to test the model. The re-       tational linguistic model in discussing fine-grained
   sults showed that our model provides valuable con-        word senses(Edmonds and Hirst, 2002): stupid-
   texonyms that reflect different usage and nuance of       ity, blameworthiness, pejorative attitude and higher
   each word. Furthermore, the test on polysemous            concreteness for blunder vs. error; writing-related
   words showed that the model can classify contex-
   onyms by grouping the different senses of a target        mistake slip; memory-related mistake lapse; larger
   word. The model can can be used as both theoret-          and animal-or-hunt-related forest vs. smaller wood
   ical lexicon-related research and practical natural       (Gove, 1984, Room, 1985 as cited in (Edmonds and
   language processing (NLP) research as well as an          Hirst, 2002)). While they rightly pointed out the
   interactive reference.                                    importance of the fine-grained differences of near-
                                                             synonyms, the problem on how to develop an auto-
                    Introduction                             matic process without the aid of lexicographer-like
For any given word, we can generate many others              experts was not addressed.
related to it. Hearing the word snow for example,               Concerning this rather practical problem, auto-
we think of words like winter, ski, cold, white, etc.        matic generation of a decision list for the target word
Similarly, if we encounter words learn, teacher and          – though it was focused on word sense disambigua-
school followed by the word pupil, we would inter-           tion – was proposed (Yarowsky, 1995). After itera-
pret pupil as ‘student’ rather than ‘opening of the          tive processes, decision lists like car, union, equip-
eye’. Of course this is not always true: for someone,        ment, assembly, nuclear, job, etc. were obtained for
snow might evoke a completely different set of words         (industrial) plant. Though different in nature, la-
from the above depending on her/his individual ex-           tent semantic analysis (LSA) also generated series
perience; the previous interpretation of pupil are no        of words related to the target word.
longer valid for a sentence like “In school, the teacher        Yet, in both approaches, automatic classification
was examining the pupil of a fainted student.”.              is missing: identifying seed words step in Yarowsky’s
   This discrepant feature makes us think over the           model needs human intervention and LSA, applied
nature of word-association intuition. Clearly it             several spheres such as automatic text evaluation
depends much on individual linguistic and extra-             (Landauer et al., 1998), metaphor problem (Kintsch,
linguistic experience. But is it so arbitrary, com-          2003), lacks this automatic classification (Laham’s
pared to synonymy or antonymy, to generalize?                categorization (Laham, 1997), using encyclopedia as
   Consider if an English speaker is asked to (1) give       a source text, is closer to matching task than general
synonyms for an English verb that describes an un-           automatic classification).
stable walk or (2) give verbs that describe a drunken            1
man’s unstable walk. Does the second task require                  For example, WordNet suggests careen, keel, lurch,
                                                             reel, stagger and swag as synonyms for an unstable walk
much longer time than the first? Are the words an-           but no specific indication for the usage in such a situa-
swered in the second task less homogeneous com-              tion; the query drunken+unstable+walk in search engines
pared to those in the first one? In fact most English        would fail also.
                                                        622

   A fully automatic sense discriminating method           texonym of ci (1 ≤ i ≤ k) and is true between ci s).
based on a second-order has been proposed (Schütze,       Second, unlike synonyms or antonyms, contexonyms
1998). This approach shares with LSA their indirect        are often mixed grammar categories. We hypothe-
nature: unlike a direct method such as Yarowsky’s,         size that if the more adequate a training corpus is,
they take into account the relations of the whole          the more relevant and more robust the contexonyms
words rather than to focus on the target word and          obtained from it will be. By an adequate corpus,
its neighbors.                                             we mean a sufficiently large and (1) well balanced
   Although such an indirect approach proved to be         corpus or (2) specific one depending on the research
effective for certain tasks such as document classifi-     focus.
cation, it loses in fact precious advantages of a direct      The procedure for constructing an automatic
approach. For example, it does not produce explicit        contexonym-organizing model is briefly presented
related words to a target words which are impor-           below.
tant output to be used in theoretical or practical
research. These cue words make it possible to also                                        Model
have a more sophisticated human mimic agent (un-           STEP 1
derstanding atypical sentence, puns, etc).
                                                           For a given corpus, co-occurrences of all words in
   As for a direct approach, since it focuses on the
                                                           a defined passage (a sentence in this study) are
target word, it fails to consider complex effects that
                                                           counted and stored. Each headword Win (1 ≤ i ≤ N ,
other words could make. That is, although the
                                                           where N is the total number of the headwords in the
neighbors of the target word are globally checked,
                                                           database) has the whole types that co-occurred with
the neighbors of the words other than the target
                                                           it in a sentence; and each child cj is arranged in de-
word are not seriously taken into account. In con-
                                                           scending order of co-occurrence with Win :
sequence, this approach fails to classify properly the
obtained words set.                                                              Win : c1 , c2 , . . . , cn .
   We present here a model that can automatically
discriminate words’ senses like indirect approaches,       STEP 2
but without losing rich features of a direct approach.     For the target word, word-association table is con-
Furthermore, the model proposes dynamic and con-           structed using four factors.
tinual representation of a target word which reflects
human language users’ intuition.                           STEP 2-1 The first α portion (where α(0 < α ≤
   The model uses the minimal senses of words              1)) of the words (i.e. children that frequently co-
(cliques) that was first proposed by Ploux et al. to       occur with Win ) is selected and Win becomes:
represent words’ different semantic values (Ploux,
                                                                                Win : c1 , c2 , . . . , ck .,
1997; Ploux and Victorri, 1998). In their study,
cliques were obtained from non-sense-classified syn-       where k = nα and n is the original number of chil-
onym database, and they were used to organize and          dren of Win .
represent words’ senses. An evolved model based
on a mapping method was used to represent a two-           STEP 2-2 Similarly, the factor β(0 < β ≤ 1)
languages synonym representation (Ploux and Ji,            serves to cut off rarely co-occurring children of the
2003). This is in a sense a response to the problem        child cj :
of arbitrary organization in conventional dictionar-             cm
                                                                  j : g1 , g2 , . . . , gl    (1 ≤ j ≤ k,      l = mβ).
ies as pointed out by Dolan (inability to represent
semantic distance between defined senses and hence            In this way, the following word-association table
the failure of organizing the senses properly(Dolan,       is obtained.
1994)) among others (Fellbaum, 1998; Budanitsky
and Hirst, 2001; Pustejovsky and Boguraev, 1994).
   The main difference between the present model                  Table 1: Candadate contexonym table.
and the previous one is that the present model does              Headword                Selected             Rejected
not need any kind of hand-coded references. More-
over, different sets of related words and cliques can                 Win            c1 , c2 , . . . , ck  ck+1 , . . . , cn
be obtained according to chosen criteria. This will                   cm
                                                                       1             g1 , g2 , . . . , gl  gl+1 , . . . , gm
be explained later.                                                   ...
                                                                      cpk           h1 , h2 , . . . , hq   hq+1 , . . . , hp
                    Contexonym
We define contexonym as relevant contextually re-
lated words for a target word. Contexonym is               STEP 2-3 The factor γ(0 < γ ≤ 1, γ ≤ β) has the
not symmetric or transitive contrary to synonym or         same role as β except that γ is smaller. This gives
antonym (that is, when a target word W has con-            another word-association table (Table 2) which will
texonyms c1 , c2 , ..., ck , W is not necessarily a con-   be used later to obtain cliques.
                                                       623

                       Figure 1: Representation of match in a semantic space (α = β = γ = 0.10).
   The gray pixel indicates clique and the black one shows the central mass of the cliques that belong to a
    contexonym. The clustering was carried out using the central mass of the cliques. This output is the
                               projection on the principal plane of a multi-dimensional space.
                                                                          only one clique. Table 2 can be used to calculate
              Table 2: Second contexonym table.                           these cliques. Composed of several sets of words,
                                                                          cliques are considered in our model as ‘minimal unit
      Headword              Selected               Rejected
                                                                          of a contexonym’ that represent finer meanings than
             Win         c1 , c2 , . . . , ck   ck+1 , . . . , cn         the word itself.
              cm
               1        g1 , g2 , . . . , gl0 . . . , gl , . . . , gm
             ...                                                          STEP 4
              cpk       h1 , h2 , . . . , hq0 . . . , hq , . . . , hp     A correspondence factor analysis (proposed by
                                                                          Benzécri (Benzécri, 1992)) was used to represent
                                                                          correlations between cliques. The output is repre-
STEP 2-4 The factor δ is on/off Boolean. If                               sented as a geometric semantic space that has as
the headword Win is not found among cj children                           many axes as the total number of contexonyms cho-
(g1 , . . . , gl ) in Table 1, cj itself in Win and the cj                sen, in such a way that each axis could represent the
row (which contains cj ’s children) are removed from                      corresponding word. Since every clique has its own
both tables whenever δ is on. This filtering step gives                   coordinate, clique distances are proportional to their
the following final contexonym set (Cin ) for Win :                       relatedness. The distance χ2 between two cliques, yi
                                                                          and yj , is calculated in order to represent the cliques
         Cin = {ci : 1 ≤ i ≤ k, ci 6∈ D}            (k = nα),             in a multi-dimensional space:
                                                                                                   Xn     µ           ¶2
where D is the set of cj words removed by filtering.                                 2                 x.. xik    xjk
                                                                                    χ (yi , yj ) =             −         ,
                                                                                                       x.k xi.    xj.
STEP 3                                                                                             k=1
Cliques are calculated from these two tables. A                                              Pn     Pp                  Pp
clique is a mathematical term in graph theory mean-                          where x.. = i=1 j=1 xji and x.i = k=1 xki ,
                                                                                 Pn
ing a maximum, complete subgraph. If w1 has w2                            xi. =      k=1 xik ; n is the total number of contex-
and w3 as its member and vice versa for w2 and                            onyms and p is that of cliques; xji is equal to 1 if
w3 , then w1 , w2 and w3 form a clique. Otherwise,                        the ith contexonym belongs to the j th clique, and
if say w3 has only w1 as its member, they fail to                         equal to 0 otherwise.
form a clique. If w1 , w2 , w3 , and w4 form another                         When (1) a clique (yi or yj ) has many contexonym
clique, it absorb the clique w1 , w2 , w3 , resulting in                  members or (2) many contexonyms belong to cliques
                                                                      624

Word       α     β      γ Contexonyms
blunder    0.07 0.15 0.05 [commit, committed, mistake] [stupid]
           0.35 0.50 0.35 {blunder, mistake, corrected, unpardonable, commit, committed, grievous, fatal,
                          frightful, mistakes, repair} {stupidity, gross, stupid} {joke, unlucky}
           0.50 0.50 0.50 {stupidity, commits, gross, stupid, blunders, corrected, detected, mistake, blunder,
                          repair} {indiscretion, unpardonable, committing, commit, mistakes, grievous, com-
                          mitted, fatal} {calamity, frightful} {awkward, joke, unlucky} [howells]
error      0.07 0.15 0.05 {argument, opinions, belief, faith, contrary, knowledge, source, greater, taught, eas-
                          ily, imagine, liberty, due, divine, former, understanding, experience, regard, merely,
                          appears, authority} {error, admit, opinion, convinced, correct} {discovered, ideas,
                          political, principle, causes, doctrine, degree, mere, religion, science, fundamental,
                          modern, discover, method} {false, judgment, evil, virtue, conduct, ignorance, judge,
                          lead, wise, fallen, makes, avoid, fall} {prove, wrong, errors, liable} {vulgar, sin, ways,
                          commit, trial, fault, guilty, committed, lies} {grave, mistaken, , corrected, mistake,
                          supposing} {serious, fatal} [clerical] [pointed] [text]
lapse      0.07 0.15 0.05 [{lapse, changes, slow} {centuries, ages, century} {geological, strata}] [memory]
           0.10 0.25 0.10 {strata, geological, organic, centuries, ages, century, lapse, slow, changes, species,
                          rate, period, progress} {forgotten, memory} {minutes, interval, weeks, absence,
                          months} {moments, recall}
slip       0.07 0.15 0.05 {foot, narrow, slip, fingers, hole, corner, quietly, coat, watch} {advantage, allowed,
                          chance, letting, opportunity, reach, easily, easy, managed, try, lest, fall, caused, es-
                          cape} {written, handed, wrote, tongue, pocket, paper, inside, lines} {fast, noose,
                          rope, boat, knot, neck}
mistake    0.05 0.10 0.05 {discovered, wrong, error, instead, fatal, committed, supposing, mistake, serious}
                          {impossible, correct, makes} {thinking, meaning, perceived} {possibility}
           0.07 0.15 0.05 [{instead, mistake, opinion, mere, possibility, seeing, imagine, likely, unless, partic-
                          ular, supposed, discovered, easily, makes, easy, convinced, impossible} {slight, due,
                          greatest, regard, greater, result, correct, false, giving, caused, committed, serious}
                          {supposing, surely, error, marriage, possibly, mistaken, wrong, anybody, perceived,
                          thinking} {intended, trying, meaning, explain, meant} {fatal, sad, fallen, terrible}]
                          [sorry]
enjoined   0.10 0.25 0.10 {secrecy, silence, multitude, commanded, enjoined} {priests, penance, perform}
                          {instructions, obedience} [strictly]
           0.50 0.50 0.50 {strictly, instructions, obedience, code, priestly, piety, enjoined, silence} {prohibited,
                          positively, expressly, forbidden, obey, priests, penance, punishment, penalty, com-
                          manded, commands, executed, execute, perform, governors, whatsoever} {prudence,
                          advised, abstain, multitude} {injunction, observance, strict, despatch, injunctions,
                          caution, secrecy, strictest} {commended, earnestly, solemnly} [directors]
prescribed 0.07 0.15 0.05 {prescribed, regulations, rules, terms} {assembly, authority, duties, oath, thereof,
                          provided, conditions, according, required, constitution, laws} {section} {mode, treat-
                          ment} {patient, physician, medicine, medicines} {remedies, remedy} [limits]
ordered    0.05 0.05 0.05 {officer, officers, orders, royal, report, prisoner, prisoners, duke, ships, charge, em-
                          peror, appointed, governor, majesty, carry, ship, palace, send, arrived, horses, ac-
                          cordingly, follow, placed, immediately, ordered} {lieutenant, command, guard, com-
                          manded, join, camp, army, troops, move, division, regiment, soldiers, battle, enemy,
                          advance, attack, brigade, cavalry, march, colonel, corps} {informed, board, finding,
                          council, remain, receive, post, refused} {thrown, carriage, twelve, proceed, instantly,
                          drive, paid} {clothes, servant, clock, servants} {bell, prepared, bottle, breakfast, din-
                          ner} {coffee, wine, supper, tea}
forest     0.03 0.04 0.03 {(wind, woods, green, fields, forest, covered, trees, depths, snow, blue, sky) (nar-
                          row, village, hill, stream, broad, below, wide) (mountains, hills, mountain, plain,
                          valley, distance, mile) (field, grass, wood, beasts, dense, beneath, tree) (east, vast,
                          shore, west, lake, north, distant, plains) (oak, grew, leaves, birds, flowers, forth, tall,
                          branches, thick, pine, summer, golden, spring) (path, edge, foot)} {deer, hunting}
                          {knight, castle, rode}
woods      0.03 0.04 0.03 {snow, pine, sky, mountain, hills, meadows, forest, trees, woods} {leaves, flowers, bird,
                          birds, green, tree, grass, fields, wood, winter, blue, gray, yellow, spring, thick, golden,
                          summer} {rivers, streams, lake, valley, distant, rocks, forests, places, mountains,
                          waters} {mile, shore, hill, edge, stream} {path, walk, walking}
drunken    0.07 0.15 0.05 {wine, drunk, sober, drink, drinking, sleep, singing, drunken, laughter, song} {fool,
                          mad} {dirty, streets} [brute] [reeled, staggered] [reeling, staggering] [sailor]
           0.10 0.25 0.10 [{drunken, mad, bar, fallen, drink, fit, asleep, sleep, devil, lot, fool, worse, dog, legs,
                          dirty, trying} {sailor, dancing, singing, sailors, songs, crying, laughter, dance, soldiers,
                          shouts, cries, streets} {eaten, liquor, sober, feast, drank, swearing, drunk, drinking,
                          wine, soldier, song} {brutal, creature, brute, coarse} {crowd, fury, mob, riot}] [reeled,
                          reeling, staggered, staggering] [stagger]
               Table 3: Output of test on Edmonds and Hirst’s examples and drunken.
                                                    625

yi and yj , they should be less representative. This      with Room’s observation(1985, as cited in (Edmonds
was considered in the first and second terms of the       and Hirst, 2002)).
equation, respectively, by a distance-reducing effect.
                                                                                 Discussion
STEP 5
                                                          In this paper, we presented a model that automati-
Cliques are projected onto a two dimensional space.       cally produces and organizes contexonyms for a tar-
The center of mass of the cliques which belong to         get word. The test results show that the model is
a contexonym corresponds to this contexonym. Ei-          able to classify contexonyms as well as to reflect
ther cliques or this contexonyms is grouped to form       words’ minute usage and nuance. In addition, what
a few clusters using hierarchical clustering method.      the model reflects can be extended to broader knowl-
As will be discussed later, this cluster should be        edge representation such as historical one (e.g. Egypt
considered as rough boundary rather than absolute         2
                                                            ) or situational one (e.g. (actor, concert, curtain,
class. The advantage of the geometric representa-         opera, performance, play, spectators, ticket for the-
tion is that it represents continuous minute change       ater).
of the relatedness between contexonyms.                      The model also shows automatic evolving features.
   Figure 1 shows the result obtained for the word        For example, after trained on the French newspaper
match after the model was trained on an English           Le Monde, the model generated, for vache (cow),
corpus with 240 million words. In this figure, four       the contexonyms folle (mad), ESB(BSE), embargo,
major senses are successfully distinguished. Note         Spongiforme, Creutzfeldt, Jakob, etc, reflecting re-
that, any kind of the electronic dictionary or ency-      cent mad cow issue in Europe 3 .
clopedia was used to train the model.                        This automatic feature of the model has some
                                                          advantages over a manual coding approach. First,
                   Experiments                            some usages of a word apt to miss to compile are
                                                          easily captured by our method. Scientific usage of
Test on Edmonds and Hirst’s Examples                      error discussed above is one of such examples.
The model was trained on an English corpus main-             Second, rapidly changing issues, which are too
tained by Project Gutenberg, which includes liter-        wide to be coded manually, can be updated by au-
atures, essays, and other writings. Any kind of           tomatic approach. The most widely used machine
electronic dictionaries or encyclopedia was excluded      translator like Systran, Babel Fish, and FreeTrans-
from the train corpus because they are already hand-      lation interpreted the word match as a wooden lighter
coded references and our main goal is to construct        and wrongly translated the word into the French
automatically relevant sets of contexonyms from           word allumette in the sentence that includes signifi-
non-knowledge structured texts. The total number          cant cue words such as final, Sampras, wins, champi-
of tokens in the training corpus counts more than         ons, and Agassi 4 . Trained on Le Monde, the model
240 million.                                              generate relevant cue words 5 , suggesting sports-
   The near-synonyms which were carefully investi-            2
gated by Edmonds and Hirst were tested.                         egypt (α = β = γ = 0.05) { cities, nations, rome,
                                                          greek, roman, kings, ancient, kingdom, africa, cyprus,
   As shown in Table 3, while blunder has the con-        palestine, cambyses, syria } { abraham, israel, sons,
texonyms stupid and stupidity, there are no such          egyptians, priests, temple, sacred, thence, jews, wor-
contexonyms for error, suggesting that the former         ship, babylon, jerusalem, alexander, gods, caesar, greeks,
has ‘stupidity’ as a connotation. Contexonyms like        egyptian, temples, bonaparte, egypt, ptolemy, alexan-
                                                          dria, cleopatra } { china, india, arabia, persia, countries,
calamity, frightful, fatal, grievous; awkwark; indis-     asia, europe, civilization, italy, conquered, empire, greece
cretion, unpardonable characterize the target word        } { brethren, jacob, exodus, joseph, pharaoh, israelites,
blunder by its ‘strength’, ‘blameworthiness’, ‘pejora-    moses } { slave, cairo, upper, expedition, throne, pyra-
tivity’, which distinguish the word from error. On        mids, desert, nile } { al, sultan }
                                                              3
the other hand, contexonyms like discovered, ideas,             vache (α = β = γ = 0.02) { bovine, alimenta-
                                                          tion, mesures, farines, agriculture, animaux, animales,
political, principle, causes, doctrine, religion, sci-    animale, bovins, contamination, britanniques, sang, esb,
ence, fundamental, modern, discover and method of         maladie, alimentaire, agricole, bretagne, folle, vache } {
error suggest that this word is used in scientific and    embargo, interdiction, boeuf, viande } { transmission,
political contexts.                                       agent, humaine, pathie, spongiforme, creutzfeldt, jakob
                                                          } { afssa, aliments, experts, sanitaire } { lait }
   The contexonyms of lapse like forgotten, mem-              4
                                                                The final was Hewitt’s first and Sampras’ 17th, but
ory, minutes, and weeks also reflect the word’s us-       the less experienced 20-year-old Australian was much
age. Among other senses of the word slip, written,        more energetic. After consecutive wins against former
handed, wrote, lines, and tongue suggest its usage in     champions Pat Rafter, Andre Agassi and Marat Safin,
speech(or writing)-related mistakes.                      Sampras appeared to have nothing left for his second
                                                          match in barely 24 hours.
   The contexonyms of woods like houses, path, walk,          5
                                                                Agassi+Sampras (α = β = γ = 0.05) { terre, mon-
and walking contrast with those of forest like deer,      dial, tennis, agassi, andre, roland, patrick, australie,
beasts, hunting, castle, and knight. This is consistent   demi } { rafter, chelem, wimbledon, australien, open,
                                                      626

related contexts. The pre-calculation-free feature          Yarowsky, D. (1995). Unsupervised word sense
(unlike LSA or Schütze’s model) of the model makes           disambiguation rivaling supervised methods. In
it easier to evolve by simply adding newly created            Proceedings of the 33rd Annual Meeting of the ACL,
                                                              pages 189–196. Cambridge, MA.
database to an existing one.
   The model presented here can be used as
a reference for lexicographers or foreign lan-
guage learners.         On-line users could test all
types of words (more than 200,000) in the
corpus (http://dico.isc.cnrs.fr/dico/context/search)
and may obtain visual representation like Figure 1.
Besides this practical usage, the model could be used
for a theoretical research on the mental lexicon by
inspiring possible mechanism or by simulating theo-
retical results.
References
Benzécri, J.-P. (1992). Correspondence Analysis
   Handbook. Marcel Dekker, New York.
Budanitsky, A. and Hirst, G. (2001). Semantic distance
   in wordnet: An experimental, application-oriented
   evaluation of five measures. In Workshop on
   WordNet and Other Lexical Resources, Second
   meeting of the North American Chapter of the ACL,
   Pittsburgh, PA.
Dolan, W. B. (1994). Word sense ambiguation:
   clustering related senses. In Proceedings of
   COLING94, pages 712–716.
Edmonds, P. and Hirst, G. (2002). Near-synonymy and
   lexical choice. Computational Linguistics,
   28(2):105–144.
Fellbaum, C. D. (1998). WordNet: An Electronic
   Lexical Database. MIT Press, New York.
Kintsch, W. (2003). Metaphor comprehension: A
   computational theory. Psychonomic Bulletin &
   Review. In press.
Laham, D. (1997). Latent semantic analysis approaches
   to categorization. In Shafto, M. G. and Langley, P.,
   editors, Proceedings of the 19th annual meeting of the
   Cognitive Science Society, page 979, Mawhwah, NJ.
   Erlbaum.
Landauer, T. K., Foltz, P. W., and Laham, D. (1998).
   An introduction to latent semantic analysis.
   Discourse Processes, 25:259–284.
Ploux, S. (1997). Modélisation et traitement
   informatique de la synonymie. Linguisticæ
   Investigationes, XXI(1):1–28.
Ploux, S. and Ji, H. (2003). A model for matching
   semantic maps between languages (French / English,
   English / French). Computational Linguistics,
   29(2):155–178.
Ploux, S. and Victorri, B. (1998). Construction
   d’espaces sémantiques à l’aide de dictionnaires
   informatisés des synonymes. TAL, 39(1):161–182.
Pustejovsky, J. and Boguraev, B. (1994). Lexical
   knowledge representation and natural language
   processing. Artificial Intelligence, 63:193–223.
Schütze, H. (1998). Automatic word sense
   discrimination. Computational Linguistics,
   24(1):97–123.
battu, joueur, vainqueur, finale, tournoi, no, sampras,
garros, internationaux, pete } { martin, arnaud, michael
} { gustavo, kuerten } { tenant }
                                                        627

