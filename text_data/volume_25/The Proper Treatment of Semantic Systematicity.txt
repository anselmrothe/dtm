UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Proper Treatment of Semantic Systematicity
Permalink
https://escholarship.org/uc/item/93n753f8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Author
Hadley, Robert F.
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                          The Proper Treatment of Semantic Systematicity
                                           Robert F. Hadley (hadley@cs.sfu.ca)
                                School of Computing Science and Cognitive Science Program
                                                      Simon Fraser University
                                                      Burnaby, B.C., V5A 1S6
                            Abstract                                crafted to ensure that its eventual vector representation
                                                                    would fall exactly in the centre of the vector space that
   Connectionist-minded philosophers, including Clark and           kindred, non-novel terms occupied. These two defects
   van Gelder, have espoused the merits of viewing hidden-          (as I viewed them) contributed very substantially to the
   layer, context-sensitive representations as possessing           network’s “success” at generalization.
   semantic content, where this content is partially revealed          In recent work, Bodén and Niklasson (2000) present
   via the representations' position in vector space. In recent     experiments and arguments designed to show that
   work, Bodén and Niklasson have incorporated a variant            connectionist networks can not only satisfy SS, but also
   of this view within their conception of semantic
                                                                    a kind of strong semantic systematicity, at least when
   systematicity. Moreover, Bodén and Niklasson contend
   that they have produced experimental results which not
                                                                    the concept of `semantic representation' is construed in
   only satisfy a kind of context-based, semantic                   a fashion which they believe is fair to connectionism.
   systematicity, but which, to the degree that reality             Indeed, they forthrightly claim that “In the experimental
   permits, effectively deals with challenges posed by              section we shall show how the proposed architecture is
   Fodor and Pylyshyn (1988), and Hadley (1994a). This              an extension of the work of Niklasson and van Gelder,
   paper examines the claims of Bodén and Niklasson. It is          intended to remove Hadley’s reservation” (p. 129).
   argued that their case fatally involves a fallacy of             They also state that “... we contend that the
   equivocation. In addition, it is argued that their ultimate      connectionist metaphor is not only leveling with Fodor
   construal of context sensitive semantics employs lax,            and Pylyshyn’s (1988) challenge but also with Hadley’s
   incorrect standards.                                             (1994a, b) revised challenge of semantic systematicity”
                                                                    (p. 139) and further, “The connectionist system we
                        Introduction                                present in the following will be able to assign relevant
The expressions ‘Strong Systematicity’ (SS) and                     semantic content to novel tokens appearing in test
‘Strong Semantic Systematicity’ (SSS) were introduced               sentences     which      could    demonstrate      strong
and formally defined in Hadley (1994a) and Hadley                   systematicity.” (Bodén and Niklasson, 2000, p. 113).
(1994b), respectively. These definitions were intended                 In what follows, I will argue that B&N have not
not only to clarify the nature of attempts (recent at that          produced, in their present (2000) work, any convincing
time) to satisfy Fodor’s and Pylyshyn’s (1998) well                 example of a network’s displaying SS, much less a kind
known systematicity challenge, but to highlight the                 of SSS. As they acknowledge, only one of their
remaining distance between what those attempts had                  experiments is even intended to avoid my 1994
accomplished and what Fodor and Pylyshyn were                       criticism. I contend that this one crucial experiment is
demanding. Detailed explanations of SS and SSS are                  fatally flawed, because B&N fail to show that their
provided in section 2, but for the present the following            network ever successfully processes a ‘novel test
(oversimplified) characterizations should suffice. A                sentence’. Rather, B&N fall prey to the fallacy of
connectionist network (or human agent) exhibits SS                  equivocation and employ the expression ‘novel test
provided it learns to generalize a significant fraction of          sentence’ in an unusual, and implausible fashion.
its vocabulary to novel syntactic positions within both             Moreover, I argue that they adopt mistakenly lax
simple and complex sentences. In contrast, an agent or              standards for what constitutes a correct semantic
network satisfies SSS provided it not only exhibits SS,             representation. Significantly, my examination of this
but can assign correct meaning representations to any of            latter issue has relevance beyond B&N’s work. For,
the novel test sentences which could be used to                     B&N’s remarks on semantics echo similar comments
establish the presence of SS in that agent.                         and confusions found in a worrisome range of
   Now, Niklasson and van Gelder (1994) presented                   connectionist publications and conference discussions.
connectionist experiments which, in their view,
satisfied at least the conditions required by SS. My                          Learning-Based Definitions of
(1994b) reply to their article described their results as a                             Systematicity
“borderline case” of SS, and I pointed out several                  In Hadley (1994a), a hierarchy of degrees of learning-
difficulties with their work. These difficulties included:          based systematicity was introduced. For purposes of the
(a) only a single novel term was ever employed, and (b)             discussion which follows, it will be helpful to have in
the encoding of this novel term had been carefully                  mind a brief paraphrase of a portion of this hierarchy.
                                                                492

• Weak Systematicity. An agent is at most weakly            reasons, I wish to emphasize certain crucial aspects of
systematic if, after training, it can process “test”        my definitions of SS and SSS. In particular, both SS
sentences (or symbol sequences) containing novel            and SSS require (i) that previously known words be
combinations of words (symbols), but cannot process         used in novel positions within (post-training) test
sentences containing familiar words in positions which      sentences; (ii) a significant fraction of the vocabulary of
are novel to those words.                                   the training corpus must be presented in these novel
• An agent is strongly systematic (SS) if and only if       positions; (iii) the ‘novel positions’ in question must
“it can correctly process a variety of novel simple         appear in both simple sentences and embedded clauses.
sentences and novel embedded sentences containing              Of all experiments described in their (2000) paper,
previously learned words in positions where they do not     not one satisfies points (i) and (ii) above. In addition, as
appear in the training corpus (i.e., the word within the    will emerge, their crucial (coup de grace) experiment
novel sentence does not appear in that same syntactic       entirely ignores condition (iii). In light of these points
position within any simple or embedded sentence in the      alone, the passages I have quoted from B&N seem at
training corpus) ... Also, ... training corpora which are   least misleading.
used to induce strong systematicity must not present the       Presently, we shall consider the view of “semantic
entire training vocabulary in all the legal syntactic       content” that B&N put forward, as they set the stage for
positions, but should refrain from doing so for a           the experiment they believe to have attained a kind of
significant fraction of that vocabulary.” (Hadley,          SSS. Before examining details, however, I would ask
1994a, pp. 250-251).                                        the reader to note that nothing in my definition of SSS
   The forms of systematicity just listed do not require    assumes a classically based semantic theory. My
that an agent be capable of semantically interpreting the   definition only requires that the agent “assigns
sentences in question. However, F&P’s examples of           appropriate meanings to all words occurring in novel
systematicity included cases where an agent assigns         test sentences which (would or could) demonstrate the
meaning to the sentences involved (e.g., whoever            strong systematicity of the network”. I have left it an
understands ‘John loves Mary’ can also understand           open question how appropriate meanings are
‘Mary loves John’). For this reason, a more demanding       represented.
criterion (given below) of systematicity was offered in        It is important to bear in mind, however, that both
(Hadley, 1994b).                                            my definition of SSS and Fodor and Pylyshyn’s original
• Strong Semantic Systematicity (SSS) “A system             characterization of systematicity were introduced in the
possesses semantic systematicity if it is strongly          context of examples of sentences found in natural
systematic and it assigns appropriate meanings to all       language. In both cases, the terms `semantics' and
words occurring in novel test sentences which (would        `meaning' were used as they are commonly understood
or could) demonstrate the strong systematicity of the       by philosophers and linguists. In particular, the
network” (Hadley, 1994b).                                   semantics (or meaning) of a declarative sentence in
   Now, it must be noted that B&N do not claim to           natural language was assumed to be intrinsically
satisfy the precise details of my definition of SSS. At     connected to the ability of such a sentence to describe
one point they say,                                         or express external situations (or states of affairs) which
   “The results presented herein do not achieve exactly     could render a given sentence true.
what semantic systematicity requires. Instead, we have         Since this is so, within the definition of SSS, the
shown that by redefining some central concepts in folk      phrase “assign appropriate meanings to all words
psychology in terms of connectionist primitives a           occurring in novel test sentences ...” must be
similar kind of context-based systematicity can be          understood against a background of standards of
achieved. In the following, we shall still use Hadley’s     correctness. Any purported demonstration that SSS has
levels (weak, quasi and strong) of systematicity to         been attained (or even nearly attained) by a network
qualify what has been achieved. ”                           must present convincing evidence that the “novel test
   Nevertheless, in the passages quoted earlier,            sentence” has been assigned a semantic representation
especially when they say “The connectionist system we       that is semantically coherent and correct.
present in the following will be able to assign relevant
semantic content to novel tokens appearing in test               Bodén and Niklasson’s Treatment of
sentences     which     could       demonstrate    strong                   “Semantic Content”
systematicity”, they strongly imply that they have very
nearly satisfied the requirements for SSS, their caveat     B&N are much concerned that “semantic content” be
being that they employ a conception of ‘semantic            understood in a (theory-laden) fashion that, in their
content’ which they believe to be most suitable to          view, does justice to the underlying assumptions of
connectionist research. Moreover, B&N state, in effect,     non-classically-oriented connectionism. For this reason,
that they will and have produced an experimental result     they stress the need to realize that semantics, properly
which lays to rest my published 1994 qualms about           understood, deals with context-sensitive, distributed
Niklasson’s and van Gelder’s 1994 work. For these           representations.       Nevertheless,        their     initial
                                                            characterization of semantic content is certainly
                                                        493

compatible with the notion that the semantics of a            the semantic content of such sentences, because the
sentence concerns the relation between the sentence and       sentences are utterly meaningless -- they refer to
a possible state of affairs which could render the            nothing. Consequently, the positions such activation
sentence true. They say, for example, “... the focus in       patterns occupy in vector space cannot be contributing
semantic systematicity is on the meaning or content of        to the semantic content of those sentences.
representational tokens (i.e., what they refer to in the         It is relevant to note, moreover, that even if sentences
represented world).” The view that semantic content           in the input corpus are selected from a natural human
concerns the ability of tokens in a sentence to refer to      language, and so presumably possess meaning, any
items in a represented world harmonizes nicely with the       network architecture and training regime that generates
philosophical-linguistic conception of semantics              hidden layer (HL) activation patterns merely on the
described in the preceding section. Indeed, it is only        basis of the contextual constraints within the training
because some of the tokens in a sentence refer (or            corpus would be generating HL patterns of precisely
potentially refer) to a represented world that a              the same kind as are generated for the utterly
declarative sentence can have truth conditions.               meaningless sentences described above. That is, the HL
   Thus far, I have no quarrel with B&N’s view of             activation patterns in each case would merely comprise
semantic content. It is essential to realize, however, that   statistical information about co-occurrence patterns
the ability of tokens to refer to objects in a represented    among symbol tokens. Information of this type cannot
world places strong constraints on the degree of context      constitute semantic information, because this type of
sensitivity of the meaning of words in sentence. The          information is identical in structure both when the input
word ‘rabbits’ denotes exactly the same class of objects      corpus contains only meaningless sentences, and when
in each of the following sentences: “Ferraris are faster      it contains sentences known to have meaning.
than rabbits”, “Rabbits are faster than turtles”. As Fodor       We have now seen that factors (i) and (ii) are not
and Pylyshyn (1988) correctly remind us, it is only           sufficient to endow an internal representation with
because of this consistency in reference (or meaning)         semantic content. Therefore, if B&N’s “working
that any conclusion logically follows from those two          semantic theory” is to be credible, much depends on the
sentences. B&N effectively acknowledge this point,            plausibility of the supplemental factor (iii), which
when they cite Clark (1993) (see their p. 116), but they      concerns the associations formed by internal
do not further discuss the conflict between their             representations. Now, the contention that HL
emphasis on context sensitivity and the constraints just      activations acquire semantic content, in part, from their
described. This is unfortunate because the view of            associations with other data (via the intervening
semantic content that they proceed to present largely         weights) offers promise of providing at least the
abandons the essential idea that semantic content             foundations of an acceptable semantic theory. However,
pertains to the ability of “tokens” and sentences to refer    as philosophers of language are well aware, the
to aspects of an externally represented world. As their       associative correlations must be of the right kind if they
paper unfolds, B&N reveal that, in their view, the            are to provide the basis for an adequate account of
semantic content of an internal representation is             semantic reference (or denotation). In particular, it must
determined by three factors, namely, (i) the word order       be the case that the associative correlations be rich (or
(syntactic) constraints imposed by the input training         complex) enough to explain how the ``inner
data, (ii) the position that a representation’s activation    representations'', produced by the understanding of
pattern occupies in vector space, and (iii) the various       declarative sentences, could express a complete state of
associations that the representation acquires during          affairs (or a situation) in the external world. In order for
training.                                                     this to be possible, the inner representations themselves
   Now, it is crucial to realize that factors (i) and (ii)    must possess sufficient complexity to permit them to be
could not be a sufficient source of semantic content for      mapped onto external states of affairs. (This is so even
words or sentences. This follows from the following           if the mapping is performed solely by complex weight
fact. It is possible (and indeed this sometimes occurs) to    vectors within the agent’s brain).
create training corpora on the basis of artificial               Unfortunately, B&N never address the issue of the
grammars and vocabularies which have no prior                 kind or complexity of associations that must be formed
semantic content whatsoever. The sentences within             if their HL representations are to acquire semantic
these corpora incorporate word-order (syntactic)              content. They do not, for example, require that this
constraints imposed by the artificial grammar in              “associated data” satisfy any standards of “richness” or
question, and these constraints may be quite elaborate.       correctness as one would expect to see when the HL
Nevertheless, the sentences within the corpora simply         patterns are purported to be representations of the
do not possess any descriptive (or referential, or            meaning of natural language sentences. Indeed (as we
semantic) relationship to an external world, state of         shall soon see), B&N place no constraints whatsoever
affairs, or situation. In such a case, internal distributed   on the nature of the data that, during training, becomes
activation patterns (which develop on hidden layers of a      associated with HL activation patterns.
network trained on the corpus) cannot be representing
                                                          494

       B&N’s Systematicity Experiments                       non-novel terms occurring in the identical syntactic
                                                             position, but these distributed encodings are partially
In the “Experiments” section of their paper, B&N
                                                             shaped by error feedback derived from every task that
describe two types of experiments which they believe to
                                                             the “novel” terms are ever involved in. (B&N
exhibit at least strong systematicity. In what follows, I
                                                             repeatedly describe the influence of this error feedback,
refer to these as the “Type 1 -- Default-Based
                                                             though they find no fault with it.)
Experiments” and the “Type 2 -- Crucial Experiment”.
                                                                Because the latter experiments not only involve the
Experiments of both types employ distributed
                                                             result-biasing technique of pre-assigning class-based
representations generated by RAAM networks.
                                                             representations to putatively novel terms, but involve
   Let us suppose that a given RAAM has input and
                                                             the task-oriented biasing just described, I submit that
output layers that each contain two separate regions of
                                                             B&N have failed to make a credible case for strong
“bits”. Within the leftmost region, one may present a
                                                             systematicity in their Type 1 experiments.
binary encoding of a given term, say, ‘cat’. Within the
rightmost region, one may present a binary encoding of
a general category that ‘cat’ belongs to, say, ‘noun’.
                                                             Type 2 -- The Crucial Experiment
During training of the RAAM, the hidden layer receives       As noted earlier, B&N are aware that the experiments
information from both the left and right input regions,      discussed above do not meet the published reservations
and over time develops a condensed distributed               of (Hadley, 1994b). However, they present one final
encoding which blends information from the two input         experiment which they believe adequately answers
regions. In this way, a distributed encoding for `cat' can   those reservations. While B&N stress that this crucial
be created which contains considerable information           experiment does not satisfy the precise requirements of
about the category or class of that term, ‘noun’. As we      SSS (as I define it), they do insist that it satisfies a kind
shall see, B&N employ this kind of “class-based              of strong semantic systematicity. Also, as previously
encoding” of terms in their systematicity experiments.       remarked, they contend that the only reason this
                                                             experiment does not satisfy my SSS, is that they have
Type 1 -- Default-Based Experiments                          redefined a number of terms of “folk psychology”, and
                                                             in doing so have adopted a conception of “semantic
B&N acknowledge that their Type 1 experiments do not
                                                             content” which they believe now provides
avoid a criticism which I voiced in my 1994 reply to the
                                                             connectionists with a level playing field.
claims of Niklasson and van Gelder (1994). (See
                                                                I have claimed that B&N’s conception of semantics
Hadley, 1994b, for full details.) As noted earlier, my
                                                             suffers from serious difficulties. In what follows, we
1994 critique described several problems with
                                                             shall see how these difficulties arise in their crucial
Niklasson’s approach to encoding and training, but the
                                                             experiment. Quite apart from concerns about
criticism that B&N currently acknowledge concerns the
                                                             “semantics”, however, their interpretation of this
RAAM-generated distributed encoding assigned to the
                                                             experiment involves a fatal equivocation involving the
single (putatively) novel term that Niklasson employed.
                                                             expression, “novel test sentence”. To see this, we must
I had, in 1994, complained that Niklasson had biased
                                                             review the general outline of their design.
his network’s results by assigning to the solitary
                                                                As in the Type 1 (Default-Based experiments), the
“novel” term (call it NT) a distributed encoding which
                                                             Type 2 (Crucial) experiment employs two RAAM
shared many featural values with all non-novel terms
                                                             networks and a simple, two layer, transformation
appearing within precisely the same syntactic position
                                                             network. The first RAAM net is used to create class-
as NT occupied in the test sentences.
                                                             based distributed representations for the atomic terms.
   As noted, B&N recognize that their Type 1
                                                             (E.g., the term ‘ernie’ is given the class-based encoding,
experiments are open to the objection just explained.
                                                             ‘bird’). A total of three terms (‘ernie’, ‘bo’, and ‘jack’)
However, in my view, the current (Type 1 -- default-
                                                             ever receive class-based encodings during the
based) experiments are open to a more severe version
                                                             experiment. During the first of two training phases,
of this criticism, for the following reason. The current
                                                             class-based encodings are created for ‘ernie’ and ‘bo’
experiments involves default reasoning with terms,
                                                             on the first RAAM’s hidden layer and are extracted for
such as ‘sparrow’, ‘penguin’, ‘tweety’ and ‘ernie’
                                                             later use in the second RAAM. The third of the atomic
which are assigned to classes, such as ‘bird’. All such
                                                             names, (‘jack’) does not receive a class encoding until a
terms are assigned distributed encodings by a RAAM
                                                             second training phase is performed.
network, whose encoding processes are influenced by
                                                                The second RAAM, described by B&N as an
error     feedback      from     another    task-oriented
                                                             “assertion encoder”, is used to create encodings for four
(transformation) network. RAAM generated encodings
                                                             very simple “sentences”, namely,
for terms such as ‘tweety’ and ‘sparrow’ include
                                                             R(ernie fly) [which we may read as “ernie flies”],
information about the ‘class’ that these terms pertain to,
                                                             R(ernie not-fly), R(bo fly), R(bo not-fly)
e.g., ‘bird’. During the encoding process, B&N have
                                                                It is relevant to note that, although ‘bo’ has the class-
ensured that distributed encodings of the two “novel”
                                                             based encoding of ‘fish’, the assertion encoder RAAM
terms they employ not only share a substantial amount
(about 50%) of class-based featural information with
                                                         495

is never trained to generate assertions to the effect that     to produce an output of ‘1’ is R(ernie fly), and ‘ernie’
Bo swims or that Ernie (which is a bird) does not swim.        has the class-based content, ‘bird’.
   RAAM generated encodings for two of the four                   What is surprising (to my mind), is that B&N believe
sentences shown above are used in the initial training of      that the results just described entail that this last
the last of the three networks, the transformation             experiment displays an important kind of strong
network. In particular, the transformation network is          semantic systematicity. Indeed, the results just cited are
initially trained to output ‘1’ (or ‘true’) when the input     their sole justification for the following claim: “The
is R(ernie fly) and to output ‘0’ (or ‘false’) when the        connectionist system we present in the following will
input is R(bo fly). During a later training phase, this        be able to assign relevant semantic content to novel
same network is trained to output `1' for the assertion        tokens appearing in test sentences which could
R(jack fly).                                                   demonstrate strong systematicity.” (Bodén and
   Now, because ‘jack’ does not receive a class-based          Niklasson, 2000, p. 113). The textual context and
encoding during the initial training phase of the first        precise wording of this quote make it clear that B&N
RAAM, B&N regard it as a novel token. Moreover, the            have my SS in mind when they say ‘strong
distributed encoding assigned to R(jack fly) was created       systematicity’. Moreover, their discussion of this last
by simply presenting ‘jack’ and ‘fly’ to the two input         experiment makes it entirely clear that they regard the
regions of the second RAAM and extracting the                  sentence R(jack fly) as the test sentence which is
contents of that RAAM’s hidden layer. This RAAM                assigned “relevant semantic content”, and they regard
received no training on that input during the initial          ‘jack’ as the novel term. (For brevity, I shall refer to
training phase.                                                ‘R(jack fly)’ as sentence ‘S’).
   Once this second RAAM has created a distributed                Now, as the reader will recall, not only my
encoding for R(jack fly), B&N present this encoding as         definitions of SSS, and SS, but even the definition of
input to the third network (transformation net). At this       ‘weak systematicity’ requires that a trained network be
stage, the transformation network produces no useful           tested upon a “novel test sentence”. Moreover, in their
response to R(jack fly). Since no class encoding has           original characterization of systematicity, F&P are
been assigned to ‘jack’, this is perfectly understandable.     clearly claiming that humans who have the capacity to
A human would likewise be unable to produce any                understand a sentence such as “Mary sees the kitten”
helpful response to R(jack fly) at this stage, since the       will automatically have the capacity to understand
human would have no idea whether `jack' is supposed            systematically related sentences that they have never
to be a bird, a fish, or even mud.                             encountered before. The employment of novel test
   However, B&N next proceed to train the                      sentences is therefore an essential component of any
transformation network, for 1000 epochs, on the                counterexample to F&P. Yet, at the (post-training)
assertion encoding for R(jack fly). Backpropagation is         stage where B&N are able to claim some form of
employed, and the target output during this second             success for their network, it would be bizarre to regard
training phase is ‘1’. During this new training phase,         S as a novel test sentence. For, at this final stage, their
error feedback not only alters the behaviour of the            network has been subjected to considerable training
transformation network on R(jack fly), but is conveyed         upon S (1000 epochs).
back to the hidden layer of the second RAAM, and                  Now, it is beyond dispute that as ‘novel token’ and
thence back to the hidden layer of the first RAAM. The         ‘novel test data’ are commonly used by connectionists,
input-to-hidden-layer weights of both these RAAMs are          ‘jack’ and S are, at the relevant stage, not novel test
modified, during the 1000 epochs just mentioned, using         data. Moreover, it is difficult to believe that B&N are
this error feedback.                                           unaware of this common usage. Any charitable reading
   As we would expect, this second training phase              of B&N must, therefore, assume that B&N are using
eventually succeeds in associating R(jack fly), within         those phrases in some new and surprising sense. Given
the transformation network, with an output value of ‘1’.       this, I can only conclude that B&N have committed a
That network is now able to produce ‘1’ for just two           serious instance of the fallacy of equivocation.
input sentences. Note also that this trained association          In any case, B&N imply, more than once, that this
(i.e., producing an output of ‘1’) is the sum total of         crucial experiment deals satisfactorily with my criticism
“associative content” ever given to the sentence, R(jack       (Hadley, 1994b) concerning the pre-assignment of
fly) or to R(ernie fly). Under these circumstances, and        class-based encodings employed in Niklasson’s and van
given that error feedback is used during this second           Gelder's 1994 experiments. Yet, that criticism was set
training phase to shape the input-to-hidden-layer links        in the context of my definitions of systematicity, which
of the initial class-based RAAM encoder, it is not             assumed the normal understanding of novel test data.
surprising that this RAAM develops for `jack' the class-       Any experiment directed at meeting those qualms must
based encoding of ‘bird’. Nor is it surprising that the        employ this same understanding if equivocation and
hidden layer encoding eventually assigned to ‘jack’ lies       fallacy are to be avoided. The same holds true of my
very close, in vector space, to the hidden layer encoding      SSS challenge and of F&P’s original (1998) challenge.
of ‘ernie’. After all, the only other assertion ever trained   What then are we to make of B&N’s summary remark
                                                           496

that “... we contend that the connectionist metaphor is       transformation network. Could this last association,
not only leveling with Fodor and Pylyshyn’s (1988)            then, provide adequate semantic content, albeit
challenge but with Hadley’s (1994a, b) revised                indirectly, for the input token `jack'? Clearly, the
challenge of semantic systematicity”? B&N’s crucial           answer is no. For, any number of other sentences, such
experiment does not even satisfy the novelty                  as `Bo swims', and `Ernie does not swim', could be
requirements of my “weak systematicity”. Admittedly,          trained to produce `1' in the output layer of the
B&N have taken care to state that they “do not achieve        transformation network. It is obvious that these
exactly what semantic systematicity requires”.                differing sentences have rather different meanings. The
However, the quotations given above and hitherto              plain truth is that the potential for all the distributed
demonstrate that B&N have at various points claimed,          encodings of these sentences to generate `1' as output --
implied, and suggested that they have dealt with not          reflects a task that is too trivial to demonstrate that each
only my challenges, but that of F&P.                          of these encodings already possesses an internal
   Apart from the foregoing issue of novelty, there           structure that would permit correct and coherent
remains B&N's clear claim that their network `will be         associations with referential content to be acquired.
able to assign relevant semantic content to novel tokens      For this reason, it is implausible that `Jack' acquires
appearing in test sentences which could demonstrate           correct semantic content via the associations developed
strong systematicity'. We have seen that B&N take             for `Jack flies' within the transformation network.
`jack' to be the novel token, but what of their contention
that `jack' has, in the end, been assigned `relevant                                   Summary
semantic content'? B&N's belief is that, upon                 In the foregoing, we have seen that B&N employ a
completion of both training phases, both `jack' and           seriously implausible conception of “novel test data”
`ernie' have been assigned virtually identical semantic       and, in their experiments, unacceptably weak standards
content -- the content being the class `bird'. The case       for semantic content. Moreover, their crucial
they offer for this belief is that, following all training,   experiment employs just a single, purportedly novel
the HL vectors for `ernie' and `jack' occupy nearly the       term and sentence. Likewise, they have ignored issues
same region of vector space. B&N describe this spatial        pertaining to embedded clauses. Given all this, it
region as the `bird' region, though their justification for   appears farfetched for B&N to claim that they have
this ascription is dubious. For, at the crucial time of       “leveled with” the challenges raised both by F&P and
testing, there is no reason to believe that `ernie' is any    Hadley (1994a, b). It is, indeed, difficult to discern
longer associated with a correct encoding of `bird'.          what relevance B&N’s results have to those challenges.
This is because, in order to achieve the results they         This is not to say that those results have no value, but
desired, during the final training phase, B&N forced the      the onus now rests upon B&N to explain the relevance
input encoding for `bird' to mutate during each of 1000       of their experiments to systematicity issues, as
epochs. At the end of these 1000 epochs, the `bird’           ‘systematicity’ is commonly understood.
input representation differs substantially from the initial
encoding of `bird’. Although the initial encoding might
be regarded as a correct representation of the concept of                             References
a bird, there is no reason to think that the mutated          Bodén, M. and Niklasson, L. (2000), Semantic
encoding is in any way correct. In any case, as                  Systematicity and Context in Connectionist
explained earlier, the mere fact that the HL vector of a         Networks, Connection Science, 12, pp. 111-142.
(purportedly) novel term or sentence lies close in vector     Clark, A. (1993), Associative Engines, Cambridge, MA:
space to another vector in no way establishes that the           MIT Press.
`novel HL vector' represents a correct or coherent            Fodor, J.A., & Pylyshyn, Z.W. (1988), Connectionism
meaning, as opposed to a garbled and degraded version            and Cognitive Architecture: A Critical Analysis,
of the remaining vector. Moreover, we have seen that             Cognition, 28, pp. 3-71.
the mere fact that such vectors occupy positions in           Hadley, R.F. (1994a), Systematicity in Connectionist
vector space does not ensure that these vectors                  Language Learning, Mind and Language, 9, pp. 247-
represent any meaning. We are only entitled to assume            272.
that the vectors represent meanings when they possess         Hadley, R.F. (1994b), Systematicity Revisited, Mind
appropriate, and sufficiently elaborate associations             and Language, 9, pp. 431-444.
within the cognitive agent. Let us consider therefore         Niklasson, L.F. and van Gelder, T. (1994), On Being
whether other possible associations are developed for            Systematically Connectionist, Mind and Language, 9,
the HL vector of `jack' within B&N's networks.                   pp. 288-302.
   Recall that the HL encoding of `jack' is used as an        Phillips, S. (1994), Strong Systematicity within
input component in generating a distributed                      Connectionism: the Tensor-Recurrent Network,
representation for the complete sentence `Jack flies'.           Proceedings of the Sixteenth Annual Conference of
This latter representation, in turn, eventually becomes          the Cognitive Science Society, Hillsdale, NJ:
associated with an output value of `1' within the final          Lawrence Erlbaum Associates, pp. 723-727.
                                                          497

