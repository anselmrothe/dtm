UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Latent Problem Solving Analysis as an explanation of expertise effects in a complex,
dynamic task
Permalink
https://escholarship.org/uc/item/31w39621
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Queseda, Jose
Kintsch, Walter
Gomez, Emilio
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                 University of California

 Latent Problem Solving Analysis as an explanation of expertise effects in a complex,
                                                           dynamic task
                     José Quesada, Walter Kintsch ([quesadaj, wkintsch]@psych.colorado.edu)
                                   Institute of Cognitive Science, University of Colorado, Boulder
                                                     Boulder, CO 80309-0344 USA
                                                Emilio Gomez (egomez@ugr.es)
                                   Department of Experimental Psychology, University of Granada
                                                Campus Cartuja, S/N, Granada, Spain
                            Abstract                                 and has been used extensively in contemporary cognitive
                                                                     science. LPSA needs a corpus of experience, and does not
  Latent Problem Solving Analysis (LPSA) is a theory of              propose mechanisms to act when there is no experience. We
  knowledge representation in complex problem solving that           need to assume that there are two modes of reasoning, one
  argues that problem spaces can be represented as                   for situations in which we know very little and another for
  multidimensional spaces and expertise is the construction of       those situations where we already have a knowledge base.
  those spaces from immense amounts of experience. The               We will review current approaches to expertise and how
  model was applied using a dataset from a longitudinal              LPSA relates to them, and present data on how LPSA
  experiment on control of thermodynamic systems. When the
                                                                     models prediction in the complex thermodynamic task
  system is trained with expert-level amounts of experience (3
  years), it can predict the end of a trial using the first three
                                                                     DURESS (Vicente, 1991).
  quarters with an accuracy of .9. If the system is prepared to
  mimic a novice (6 months) the prediction accuracy falls to .2.                          Expertise Theories
  If the system is trained with 3 years of practice in an
  environment with no constraints, performance is similar to the     The most popular expertise theories are Long Term
  novice baseline.                                                   Working Memory (LTWM), Elementary Perceiver and
                                                                     Memorizer (EPAM), and Constraint Attunement Hypothesis
                        Introduction                                 (CAH). We will briefly describe them in the next sections.
In this paper, we introduce a computational theory of
representation in experienced problem solving that we call           Long Term Working Memory (LTWM). The LTWM
Latent Problem Solving Analysis (LPSA). It is specially              theory claims that working memory has two different
suited to model performance in complex, dynamic tasks                components: a short-term working memory (STWM), which
such as control of dynamic systems. Complex tasks have               is available under any condition, but of very limited
always been thought to involve high level processes, such as         capacity, and a long-term memory (LTWM), that is
mental models and reasoning. We would like to show in the            available only on the domain where one is an expert, but
next sections that, although the conscious, effortful                provides unlimited capacity. STWM accounts for working
reasoning path is certainly available, people can also use a         memory in unfamiliar activities but does not appear to
similarity-based way of action that can give good results in         provide sufficient storage capacity for working memory in
certain situations. LPSA proposes that what people do in             skilled complex activities. LTWM is acquired in particular
some situations that have previously been considered                 domains to meet specific demands imposed by a given
problem solving can be considered memory retrieval and               activity on storage and retrieval. LTWM is task specific.
pattern matching.                                                    Intense practice in a domain creates retrieval structures:
                                                                     associations between the current context and some parts of
LPSA is a spatial theory of representation, inheriting the
                                                                     LTM that can be retrieved almost immediately without
assumptions and concepts of Shepard (1987). That is, the
                                                                     effort. That is, the retrieval is fast and automatic without
proximal stimulus is supposed to be represented as a point
in a multidimensional space, where all other past                    requiring voluntary resources as in intentional memory
experiences can be represented as well. The space is created         search: the results ‘pop out’ in memory. The contents of
to capture the similarities between objects. Thus, two               working memory act as the center of a focus that activates
objects that are similar tend to occupy close areas in the           other contexts from LTM that are related to them thanks to
mental space.                                                        the retrieval structures.
LPSA is inspired by Latent Semantic Analysis (LSA), a                The concept of retrieval structures is inherited from the
theory of representation that explains how semantics can be          Skilled Memory Theory (Chase & Ericsson, 1981). A
learned from large amounts of experience. LSA has been               retrieval structure is defined as an abstract, hierarchical
applied to understand language comprehension phenomena,              knowledge structure used to organize cues used in the
                                                                  940

encoding and retrieval of information. LTWM theory                creates the representations (classification networks) starting
proposes that LTWM is generated dynamically by the cues           from empirical information of similar proportions to what
that are present in short term memory. During text                humans accumulate in their experience with the tasks. For
comprehension, for example, where the average human               example, to mimic DD’s (a digit memory expert) behavior,
adult is an expert, retrieval structures retrieve propositions    Richman et al. trained the system with exactly the same
from LTM and merge them with the ones derived from text.          information the expert had used to reach his expertise level.
                                                                  However, there are no models of continuous, dynamic
The evidence for the existence of LTWM comes from two             processes like the one we present in this paper. The main
fronts (1) proactive and retroactive interference, and (2)        difference is in the representations proposed. LPSA uses a
interruption and resumption of performance. If the                comparatively simple spatial model, whereas EPAM uses
                                                                  discrimination nets, which are elaborated structured
representations formed during text comprehension are
                                                                  representations. The symbolic approach of the
stored in short-term memory, interruption should hinder
                                                                  discrimination net makes it difficult to apply it to represent
performance, measured as memory for the text (free and            domains where variables change continuously, whereas
cued recall) and comprehension measures. However,                 LPSA does not show this problem.
classical experiments (e.g., Glanzer, Dorfman, & Kaplan,
1981) find no detriment in performance at all. The only           Constraint Attunement Hypothesis (CAH). The LTWM
difference between interrupted and non-interrupted                and EPAM theories of expertise are process theories, that is,
conditions was longer reading times. LTWM permits rapid           they try to specify the psychological mechanisms that
and reliable reinstantiation of a context after interruption      explain the observable effects. That is, they are theories of
without a decrease in performance.                                ‘how’. An alternative view would be to create a product
                                                                  (i.e., input-output) theory of expertise, where the question to
LTWM has been applied to several domains such as                  answer is ‘what’ conditions are needed to observe expertise
memory for dinner orders, digit recall, chess, and text           effects. This is the role of the Constrain Attunement
comprehension, but to date there is no explicit explanations      Hypothesis (CAH) theory by Vicente and Wang (1998).
of complex, dynamic tasks. The most promising                     Contrary to what process theories maintain, CAH does not
computational implementations of LTWM retrieval                   commit to a particular psychological mechanism to explain
structures have used LSA (see Kintsch, 1998; Kintsch,             the phenomenon of expertise. As a product theory, it aims to
Patel, & Ericsson, 1999).                                         address three related issues: ‘(1) How should one represent
                                                                  the constrains that the environment (i.e., the problem
EPAM and the chunking theories. EPAM (e.g., Richman,              domain) places on expertise? (2) Under what conditions will
Staszewski, & Simon, 1995) has three main components: an          there be an expertise advantage? (3) What factors determine
STM, a LTM, and a discrimination net, which allows nodes          how large the advantage can be?’ (Vicente & Wang, 1998,
in LTM to be accessed. Short term memory includes                 p. 35).
specialized auditory and visual subcomponents, whereas
                                                                  The CAH theory proposes an important distinction between
long term memory is divided into declarative and procedural       intrinsic and contrived tasks. Intrinsic tasks are those that
systems. EPAM is the natural evolution of the chunking            are definitive features of the domain of expertise, for
theory (Chase & Simon, 1973). In EPAM, chunks are                 example, blindfolded chess, memorizing dinner orders, and
extended into templates. Templates are a large chunk, which       memorizing digits. A contrived task is one that is not part of
contains slots (which are variables) that can be filled with      the domain of expertise, but designed to fulfill some
concrete values for the current situation that the expert         experimental purposes. For example, chess players just play
experiences or recreates. The slots might have default values     chess, and remembering chess configurations is not part of
that can reflect the statistically most frequent item that        the task. This distinction is important because (1) in the
appear in the situation described by the template. Slots are      expertise literature, contrived tasks abound and (2) for some
fundamental concepts in EPAM. Within EPAM there are               theories such as LTWM the proposed retrieval structures are
two types of slotted structures: schemas with all slots           obtained through a deliberate effort and then will be only
(generic retrieval structures) and schemas with only a few        relevant on the explanation of intrinsic tasks, that is, tasks
slots and mostly fixed values, called templates.                  that are needed to be an expert in the domain, such as
                                                                  memory enhancement in the waiter case. Vicente and Wang
The concept of template is intimately bound to the nature of      consider that most of the tasks used in the literature that
the discrimination net that is assumed as the representational    studies memory expertise are contrived, not intrinsic, and in
format in EPAM. Slots are created as a function of the            this sense LTWM and other process theories cannot explain
number of tests below a node in the discrimination net (e.g.,     them.
Gobet, 1998). Like the chunking theory, the template theory       CAH is an ecological theory of expertise in memory recall,
proposes that expertise is due to ‘(a) a lager database of        inheriting some of the basic ideas from Gibson’s (1979)
chunks indexed by a discrimination net. (b) a large               ecological theories of perception. In CAH, the experimenter
knowledge base, encoded as production and schemas; and            is after a definition of the goal-relevant constraints in a
(c) a coupling of the (perceptual) chunks in the index to the     domain. For example, the concept of affordance (what can
knowledge base’ (Gobet, 1998, p. 127). Like LPSA, EPAM            be done in a particular environment) is reused indirectly and
                                                               941

extrapolated to the domain of memory recall and expertise.          Eriksson and Kintsch (1995; 2000) predicate that they are
However, affordances are defined to describe properties of          not needed, whereas Gobet (1998; 2000) cannot conceive
objects, events, and places, and what Vicente and Wang              EPAM without them. (2) LTWM proposes a gradual speed-
(1998) propose is a description of the whole domain of              up of encoding in LTWM, but EPAM proposes that there
expertise, so they fall short. Vicente and Wang (1998)              are fixed times for storage, and they are estimated. These
proposal needs a mechanism to identify and describe                 two points are not addressed directly in LPSA and will not
relations between the high numbers of components that               be commented further. Where LPSA does have a
make up a domain of expertise instead of the components             contribution to make is on the definition of retrieval
themselves. The solution proposed to study goal-oriented            structures, which has been criticized as vague in LTWM,
constrains in the environment is the Abstraction Hierarchy          and on the effects of amount of practice on expertise. The
(AH). The AH is a hierarchical description of the constrains        CAH assertions about the amount of structure of the
of the problem domain, but a particular kind of hierarchy.          environment are explained as well under a computational
Possible hierarchical descriptions to describe environments         framework in LPSA.
are part-whole relations, is-a relations, ‘obeys’ relations, and
mean-ends relations. The definitive characteristic of the AH        LTWM claims that the magnitude of expertise effects is
is that it describes the environment as mean-ends relations,        related to the level of attained skill and to the amount of
connecting objects within and between levels. Thus, the AH          relevant prior experience. CAH argues that this claim is
is explicitly goal oriented.                                        incomplete. Expertise effects in memory recall are also
                                                                    determined by the amount of structure in the domain (and
The AH provides a different language for each level of              by active attunement to that structure).: CAH ‘predict[s] …
analysis, providing the faculty of abstracting in an out (as in     a memory expertise advantage in cases in which experts are
zooming) from the deeper significance of the system goals           attuned to the goal-relevant constraints in the material to be
to the lowest physical levels of description (what physical         recalled and that the more constraints available, the greater
changes need to be made in order to implement those goals).         the expertise advantage can be’ (Vicente & Wang, 1998, p.
                                                                    33). A theory that could explain both these assertions
The descriptions produced by experimenters using the AH             (amount of experience and structure of the environment)
approach are a-posteriori, and there is no guarantee that two       would be welcomed. LPSA is sensitive both to ‘relevant
experimenters would come up with the same AH when                   previous practice’ and to ‘amount of structure in the
trying to describe the exact same task. AHs have been               domain’, as we will show in the next sections.
proposed for complex, dynamic tasks such as DURESS by
Vicente. However, our proposal with LPSA is to create a             The LPSA proposal for an expertise theory
similarity-based set of operations that define the                  One of our interests is to show that the abstraction
representation of the environment in such a way that the            hierarchy, the main innovation and contribution in Vicente
similarity measures can be derived automatically for any            and Wang theory (Vicente, 2000 ; Vicente & Wang, 1998)
task. That is, the definition of similarity is bound to             falls short in meeting the requirements for a theory of the
experience in the particular environment, so the input for the      environment in its actual form. A good theory that attempts
theory will be the exact same information that humans use           to model the environment should be consistent and effective
when they solve the tasks for the same period of time in            in different domains. The units and operators proposed
which the human was exposed to the environment.                     should be the same for different environments, even though
                                                                    the basic structures can be very different. We agree with
Comparing the theories                                              Vicente that it is important that a single theory can model
Comparing these theories has proven to be a difficult task.         different environments without changes in its basic
Even though some part from the same concepts (for                   assumptions. However, when CAH is used for modeling
example, EPAM and LTWM share the concept of retrieval               different environments “the details of such models usually
structures), and in some cases the same phenomena have              differ tremendously from one domain to the next because
been targeted (for example, chess memory), the theories are         the relevant cues and their ecological validities can change
not well compared in the literature. The reviews that do            dramatically (…)” (Vicente & Wang, 1998, p. 603)
compare them normally attribute the advantage to the theory
that the author of the review proposed (e.g., Gobet, 1998)          LSA is based on the idea of portraying environments as
and that normally originated a retaliation in related articles      complex networks of coocurrences, that, given a big enough
where the authors of the alternative theories try to amend          scale, can be mapped onto a multidimensional space of
the criticisms.                                                     much lower dimensionality. Thus, it provides the means for
                                                                    modeling different domains in a comparable manner. At the
In the case of CAH vs. the process theories (LTWM and               moment of this writing, LSA has been applied to a variety
EPAM) the comparisons are even more difficult because the           of domains including the followings: understanding of
phenomena of interest are different for the different theories.     source code (Maletic & Marcus, 2000a), text comprehension
                                                                    (e.g., Kintsch, 1998; Kintsch, 2001), categorization (Laham,
The ongoing discussion maintained by Gobet (2000) and               1997), metaphor understanding (Kintsch, 2000) and
Ericsson and Kintsch (2000) seems to be concentrated in             vocabulary acquisition and semantic priming (Landauer &
two main points: (1) the necessity for slotted schemas.             Dumais, 1997). LPSA has been applied to model human
                                                                 942

similarity judgments in problem solving tasks (Quesada,            very high and their relations can be intricate, the analysis are
Kintsch, & Gomez, 2002), practice effects (Gonzalez &              usually beyond the scope of most statistical methods
Quesada, submitted), and expert evaluations of landing             normally employed in experimental psychology, particularly
technique (Quesada, Kintsch, & Gomez, submitted).                  when system states are not in interval scale. As a result, the
                                                                   richness of these log files is underused. However, a clear
A complex, dynamic task: DURESS II. Manipulating                   analogy can be drawn between this particular problem and
previous knowledge by eliminating it has been a dominant           representational theories of semantics such as LSA: like
in cognitive science, due in part to the need for random           words, states and actions appear in particular contexts but
assignment of participants to groups that is an exigency of        not in others. Some states and actions are interchangeable,
the experimental method. An alternative and very popular           being ‘functional synonyms’. Given the right algorithms and
take is the expert-novice approach (e.g., Chase & Simon,           sufficient amounts of logged trials, a problem space can be
1973), that is, to manipulate previous knowledge by pre -          derived in a similar way as semantic spaces are. The
selecting participants, forgetting about random assignment         underlying idea is that the aggregate of all the action
of participants to groups. In a wide and diverse range of          contexts in which a given state does and does not appear
contexts, from academic disciplines through to games and           provides a set of mutual constraints that largely determines
sports, comparisons of the performance of novices and              the similarity of meaning of states and sets of states to each
experts have established consistent relations between              other.
knowledge, task performance and level of expertise.
However, not many researchers have the possibility of
manipulating the environment for the time necessary to
make a person an expert in a domain. Most of the studies in
expertise and skill acquisition have to content themselves
with analyzing diaries and interviews (i.e., Ericsson,
Krampe, & Tesch-Römer, 1993) to estimate a posteriori the
amount of deliberate practice that their participants invested.
Important exceptions to the problem posited above are
single-subject designs such as Richman, Staszewski and
Simon (1995), but it is only possible in very simple
environments like digit recall tasks. In that case, the
experimenter controls the environment (i.e. the sequence of
digits that the memonist is to learn) completely and can
manipulate it. The basic idea in this research paradigm is to
move complexity to the lab, and manipulate previous
knowledge by giving exactly the same amount of practice,
enough to show expertise levels of skill, to all participants.
To simulate expertise environments in labs, we need tasks
more complex than the standard ones: more representative,
with a long learning curve, and interesting enough to keep         Figure 1: Prediction method employed to estimate the next
the motivation for a long period of time. An example of this       states in the task in LPSA. Each rectangle represents a trial
kind of tasks is DURESS (DUal REServoir System).                   in DURESS II. (a) The nearest neighbors of the predicting
DURESS is a thermal-hydraulic process control simulation           part are retrieved; (b) a composite using the ends of these
that was designed to be representative of Industrial process       neighbors serves to predict the target trial’s final states.
control systems. It consists of two redundant feedwater
streams that can be configured to supply either, both or           The AH proposed for DURESS (e.g., Vicente & Wang,
neither of the two reservoirs. The goals of the game is to         1998) contains four levels: (1) Functional, that describes the
keep each of the reservoir temperatures (T1 and T2) at a           purposes: keep the temperature and demand flow rate for
prescribed level (e.g., 40 C and 20 C, respectively), and to       each reservoir, (2) Abstract, that describes the system as a
satisfy the current mass (water) output demand (5 liters per       function of the laws of conservation of mass and energy, (3)
second and 7 liters per second, respectively). Thanks to the       generalized, that uses rates of heat and flow transfer, and (4)
seminar work of Vicente and collaborators (Christoffersen,         physical, that describes the physical position and settings of
Hunter, & Vicente, 1996, 1997, 1998), the equivalent of            the components (valves, pumps, and heaters).
three years of experience with the system DURESS II is
available and we used it in our LPSA simulations.                  A different LPSA corpus was created for each level of the
                                                                   Abstraction Hierarchy. After performing the SVD, the first
Method. Complex experimental tasks normally keep a log             100 dimensions were used. Since the goal values are
                                                                   different at each level, the pertinent variables were
file containing all the actions and states that every
                                                                   normalized to goal values in order to make trials more
participant has experienced. Since the number of variables is
                                                                943

comparable for Functional purpose and Abstract function                                                          Expert (3 years)
levels. All levels were normalized with respect to scale.                                                       10 nearest neighbors
                                                                                                                10 random trials
                                                                                            1
To test the ‘amount of experience hypothesis’, two different                              0.9
corpora, one with 3 years of practice (expert), and another                               0.8
                                                                                          0.7
with only 6 months (novice), were created, and the quality
                                                                         Average cosine
                                                                                          0.6
of their prediction of future states compared. To test the                                0.5
‘amount of domain structure hypothesis’, an additional                                    0.4
corpus of 3 years of practice was created, but this time in an                            0.3
environment where the laws of conservation of mass and                                    0.2
                                                                                          0.1
energy do not exist: the states where randomly assigned to                                  0
the trials, resulting in a corpus with practically no                                            Functional      Abstract          Generalized   Physical
constraints. This corpus was compared to the 3-years-expert
with a constrained environment.                                      Figure 2: Average cosine between the fourth quarter of a
                                                                     target trial and the fourth quarter of the 10 nearest
Prediction. Prediction plays a very important role in                Neighbors when the three first quarters are used to retrieve
humans’ interaction with the environment. Some scientists            the neighbors. The model has been trained with three years
argue that many features of cognitive the cognitive system           of experience.
(such as representation, memory, and categorization) can be                                                    Novice (6 months)
conceptualized as tools that help to predict the next states of                                                   10 nearest neighbors
                                                                                                                  10 random trials
an organism’s environment (e.g., Anderson, 1990). The                                       1
methodology that we used was to test how good of a                                        0.9
                                                                                          0.8
prediction can be generated using the nearest neighbors of a
                                                                                          0.7
target slice of performance. For example, in a trial of
                                                                         Average cosine
                                                                                          0.6
DURESS, how much of the end can be predicted using the                                    0.5
information from the beginning? To do this, we needed to                                  0.4
define a cutting point that divided the predicting and                                    0.3
                                                                                          0.2
predicted parts. The cutting point we defined is the point
                                                                                          0.1
that leaves ¾ of the trial behind. Such a case is depicted in                               0
Figure 1a. Trials in DURESS are represented as rectangles.                                -0.1   Functional      Abstract          Generalized   Physical
The shaded area is the part of the trial that is used to predict
the remaining part (signaled with a question mark). In               Figure 3: Average cosine between the fourth quarter of a
LPSA, any passage is a vector, as well as any sub-passage;           target trial and the fourth quarter of the 10 nearest
that is, the shaded (predicting) part and the question mark          Neighbors when the three first quarters are used to retrieve
(predicted) part are both a vector in LSA. Using the                 the neighbors. The model has been trained with six months
predicting vector, we retrieve the nearest N neighbors,              of experience.
depicted as rectangles as well in Figure 1a. In this figure,                                        3 years in environment with no constraints
N=6, that is 6 nearest neighbors are evoked by the first ¾ of                                                   10 nearest neighbors
                                                                                                                10 random trials
the trial. Then, the last quarter of each retrieved neighbor is                             1
used to create a composite that predicts the end of the target                            0.9
                                                                                          0.8
trial (Figure 1b). The contribution to the composite is                                   0.7
                                                                         Average cosine
weighted by the cosine between the neighbor and the                                       0.6
predicting part of the target.                                                            0.5
                                                                                          0.4
Results                                                                                   0.3
                                                                                          0.2
The results presented here were calculated using 10                                       0.1
neighbors (striped bars), and the same calculations                                         0
performed with 10 random neighbors are used as a control                                         Functional      Abstract          generalized   physical
group (solid bars). A sample of 100 random trials was
                                                                     Figure 4: Average cosine between the fourth quarter of a
selected as target trials, and the results averaged. The
                                                                     target trial and the fourth quarter of the 10 nearest
predicting accuracy of this method in the 3-years of
                                                                     Neighbors when the three first quarters are used to retrieve
practice, structured environment’ can be observed in Figure
                                                                     the neighbors. Three year of experience in a DURESS
2: the average prediction is .87, which means that our
                                                                     simulation with no constraints (random states).
simulated expert can predict the next states of its
environment very well indeed. Figure 3 shows that, for the
novice simulation, the average prediction is much worse,                                                       Conclusions
which is in line with the ‘amount of experience’ hypothesis.         LTWM argues that the magnitude of expertise effects is
Figure 4 describes the prediction rate (that does not                related to the level of attained skill and to the amount of
outperform the random control) for the ‘3 years expert in the        relevant prior experience. CAH claims that expertise effects
unconstrained domain’.                                               in memory recall are also determined by the amount of
                                                                   944

structure in the domain (and by active attunement to that            Process. Computational and Mathematical Organization
structure). LPSA can explain both arguments under the                Theory.
same framework, and proposes a computational model on              Kintsch, W. (1998). comprehension: a paradigm for
how the constrains of the environment are internalized and           cognition: Cambridge university press.
represented. LPSA also extends the area of application of          Kintsch, W. (2000). Metaphor comprehension: A
computational expertise theories to complex, dynamic tasks           computational theory. Psychonomic Bulletin and Review,
such as DURESS. In doing so, LPSA is a new approach to               7, 257-266.
the expertise and knowledge representation discussions.            Kintsch, W. (2001). Predication. Cognitive Science, 25,
                                                                     173-202.
                                                                   Kintsch, W., Patel, V., & Ericsson, K. A. (1999). the role of
                    Acknowledgments                                  long-term working memory in text comprehension.
                                                                     Psychologia, 42, 186-198.
This research was partially supported by Grant EIA –
                                                                   Laham, D. (1997). Latent Semantic Analysis approaches to
0121201 from the National Science Foundation. We are
                                                                     categorization. In M. G. Shafto & P. Langley (Eds.),
extremely thankful to Kim Vicente and John Hajdukiewicz
                                                                     Proceedings of the 19th annual meeting of the Cognitive
for sharing experimental data that were extraordinarily
                                                                     Science Society (pp. 979). Mahwah, NJ:: Erlbaum.
relevant and useful for testing the theory. We also thank
                                                                   Landauer, T. K., & Dumais, S. T. (1997). A solution to
Tom Landauer, Simon Dennis, and Bill Oliver for
                                                                     Plato's problem: The Latent Semantic Analysis theory of
interesting theoretical discussions.
                                                                     the     acquisition, induction, and representation of
                                                                     knowledge. Psychological Review, 104, 211-240.
References
                                                                   Maletic, J. I., & Marcus, A. (2000a). Using Latent Semantic
                                                                     Analysis to Identify Similarities in Source Code to
Anderson, J. R. (1990). The adaptive character of thought.
                                                                     Support Program Understanding, 12th IEEE International
   Hillsdale, New Jersey: Lawrence Erlbaum associates.
                                                                     Conference on Tools with Artificial Intelligence
Chase, W. G., & Ericsson, K. A. (1981). Skilled memory. In
                                                                     (ICTAI00). Vancouver, British Columbia.
   J. R. Anderson (Ed.), Cognitive skills and its acquisition
                                                                   Quesada, J. F., Kintsch, W., & Gomez, E. (2002). A theory
   (pp. 141-189). Hillsdale NJ: Erlbaum.
                                                                     of Complex Problem Solving using Latent Semantic
Chase, W. G., & Simon, H. A. (1973). The mind's eye in
                                                                     Analysis. In W. D. Gray & C. D. Schunn (Eds.), 24th
   chess. In W. G. Chase (Ed.), Visual information
                                                                     Annual Conference of the Cognitive Science Society (pp.
   processing. New York: Academic Press.
                                                                     750-755). Fairfax, VA.: Lawrence Erlbaum Associates,
Christoffersen, K., Hunter, C. N., & Vicente, K. J. (1996). A
                                                                     Mahwah, NJ.
   longitudinal study of the effects of ecological interface
                                                                   Quesada, J. F., Kintsch, W., & Gomez, E. (submitted).
   design on skill acquisition. Human Factors, 38, 523-541.
                                                                     Automatic Landing Technique Assessment using Latent
Christoffersen, K., Hunter, C. N., & Vicente, K. J. (1997). A
                                                                     Problem Solving Analysis, 25th Annual Conference of the
   longitudinal study of the effects of ecological interface
                                                                     Cognitive Science Society.
   design on fault management performance. International
                                                                   Richman, H., Staszewski, J., & Simon, H. A. (1995).
   Journal of Cognitive Ergonomics, 1, 1-24.
                                                                     simulation of expert memory using EPAM IV.
Christoffersen, K., Hunter, C. N., & Vicente, K. J. (1998).
                                                                     Psychological Review, 102(2), 305-330.
   longitudinal study of the impact of ecological interface
                                                                   Shepard, R. N. (1987). Toward a universal law of
   design on deep knowledge. International Journal of
                                                                     generalization for psychological science. Science, 237,
   human-Computer Studies, 48.
                                                                     1317-1323.
Ericsson, K. A., & Kintsch, W. (1995). long-term working
                                                                   Vicente, K. J. (1991). Supporting Knowledge-Based
   memory. Psychological Review, 102(2), 211-245.
                                                                     Behavior       Through      Ecological Interface Design.
Ericsson, K. A., & Kintsch, W. (2000). Shortcomings of
                                                                     University of Illinois at Urbana-Champaign.
   generic retrieval structures with slots of the type that
                                                                   Vicente, K. J. (2000). Revisiting the constraint attunement
   Gobet (1993) proposed and modeled. British Journal of
                                                                     hypothesis: reply to Ericsson, Patel and Kintsch (2000)
   Psychology, 91, 571-588.
                                                                     and Simon and Gobet (2000). Psychological Review,
Ericsson, K. A., Krampe, R. T., & Tesch-Römer. (1993).
                                                                     107(3), 601-608.
   The role of deliberate practice in the acquisition of expert
                                                                   Vicente, K. J., & Wang, J. H. (1998). An ecological theory
   performance. Psychological review, 100(3), 363-406.
                                                                     of expertise effects in memory recall. Psychological
Gibson, J. J. (1979). The Ecological Approach to Visual
                                                                     Review, 105, 33-57.
   Perception. Boston: Houghton Mifflin.
Glanzer, M., Dorfman, D., & Kaplan, B. (1981). Short-Term
   Storage in the Processing of Text. Journal of Verbal
   Learning and Verbal Behavior, 20(6), 656-670.
Gobet, F. (1998). Expert memory: a comparison of four
   theories. Cognition, 66(2), 115-152.
Gobet, F. (2000). Some shortcomings of long-term working
   memory. British Journal of Psychology, 91, 551-570.
Gonzalez, C., & Quesada, J. F. (submitted). Learning in a
   Dynamic Decision Making Task: The Recognition
                                                                945

