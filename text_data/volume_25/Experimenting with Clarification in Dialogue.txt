UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Experimenting with Clarification in Dialogue
Permalink
https://escholarship.org/uc/item/74m8w8z4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Healey, Patrick G.T.
Purver, Matthew
King, James
et al.
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    Experimenting with Clarification in Dialogue
                               Patrick G.T. Healey1 (ph@dcs.qmul.ac.uk),
                           Matthew Purver2 (matthew.purver@kcl.ac.uk),
                                   James King1 (jking@dcs.qmul.ac.uk),
                        Jonathan Ginzburg2 (jonathan.ginzburg@kcl.ac.uk),
                                     Greg J. Mills1 (gj@dcs.qmul.ac.uk)
                     1
                       Department of Computer Science; Queen Mary, University of London,
                                                     London E1 4NS.
                            2
                              Department of Computer Science; Kings College London
                                                  London WC2R 2LS.
                        Abstract                              and level of grounding (first vs. second mention) on
                                                              interpretation. Further potential applications of the
   A new technique for integrating experimental ma-           approach are discussed in the context of the experi-
   nipulations into text-based, synchronous dialogue
   is introduced. This method supports fine-grained,          mental results.
   systematic transformation of conversational turns
   and the introduction of ‘artificial’ probe turns and       Manipulating Chat Interactions
   turn sequences. It can be used to introduce ma-            The experimental technique presented in this paper
   nipulations that are sensitive to aspects of the local     draws on two general developments. Firstly, the
   linguistic and conversational context for any task
   or dialogue type. The use of this technique is il-         increasing use of text-based forms of synchronous
   lustrated by an experimental investigation of the          conversational interaction, for example: chat rooms
   effect of word category and level of grounding on          (MUD’s, MOO’s etc.) and instant messaging. Sec-
   the interpretation of reprise clarifications. The re-      ondly, advances in natural language processing tech-
   sults show that these factors affect both the type
   and likelihood of response to reprise fragment clar-       nology which make some forms of parsing and trans-
   ifications.                                                formation fast enough to be performed on a time
                                                              scale consistent with exchanges of turns in syn-
                                                              chronous text chat.
                    Introduction                                 The basic paradigm involves pairs of subjects,
Empirical analyses of dialogue phenomena have been            seated in different rooms, communicating using a
limited by a lack of techniques that provide adequate         synchronous text chat tool (see figure 1 for an exam-
experimental control. The most detailed analyses of           ple). However, instead of passing turns directly to
dialogue have focused on descriptive analyses of cor-         the appropriate chat clients, each turn is routed via
pora of natural conversations (e.g. Schegloff, 1987).         a server. The server is used to systematically modify
Corpus studies are limited in that they provide only          turns in a variety of ways determined by the goals of
retrospective, correlational data that make it diffi-         the experiment. For example, simple forms of mis-
cult to resolve conflicting interpretations of the phe-       communication can be introduced into an interac-
nomena. Experimental techniques have been lim-                tion by transforming the order of characters in some
ited to the manipulation of relatively coarse-grained         of the input words or by substituting words with
parameters of interaction such as task type, level            plausible non-words. Importantly, the server con-
of participation, or communicative modality (for              trols which modifications are transmitted to which
overviews see Pickering and Garrod, 2003; Clark,              participant. So, if participant A types the word “ta-
1992).                                                        ble” the sever can echo back A: table to partici-
   Development and testing of hypotheses about de-            pant A and a transformed version, say, “blate” to
tailed mechanisms and procedures that sustain di-             participant B who sees A: blate. The ability to set
alogue co-ordination has consequently been limited            up controlled asymmetries of this kind between the
by the indirect nature of the available evidence. Psy-        participants in a interaction creates a powerful range
cholinguistic techniques do not provide general, sys-         of experimental possibilities. Here, we describe an
tematic and fine-grained ways to integrate experi-            application of this technique to the investigation of
mental manipulations into unfolding interactions.             reprise clarification requests (CR’s).
   This paper introduces a new technique for carry-
ing out experiments on text-based dialogue which              Request for Clarification
addresses these limitations. The rationale for the            Requests for clarification are critical for maintain-
approach is set out together with some of its prac-           ing mutual-understanding in dialogue and have re-
tical limitations. An experiment is reported which            ceived attention from both the formal semantic (e.g.
uses this approach to investigate the interpretation          Ginzburg and Cooper, 2001, 2003) and conversation
of clarification requests in dialogue: in particular,         analytic traditions (e.g. Schegloff, 1987). Clarifi-
the influence of word type (content vs. function)             cation requests (CRs) can take a variety of forms.
                                                          539

Some CRs explicitly identify the clarification re-         particular readings. Intuitively, at least two factors
quired, e.g., “What did you say?” or “What do              would be expected to affect the type of reading as-
you mean?”. Others are more elliptical and involve         signed to a RF; word category and level of ground-
repetition of only parts of the problem utterance.         ing. The linguistic category of the reprised word
The most elliptical forms of CR are reprise frag-          should influence expectations about what is being
ments (RFs) which occur where part of the problem          clarified. For example, reprise of a content word
utterance, possibly a single word, is repeated with-       (e.g. noun or verb) should be more likely to signal
out modification as in Excerpts 11 and 22 (taken           a ‘constituent’ problem than a reprise of a function
from the British National Corpus (BNC) (Burnard,           word (e.g. preposition or determiner). Dialogue par-
2000)).                                                    ticipants would normally assume that the meaning
                                                           of function words is well known in a particular lin-
  Lara:         There’s only two people in the class.      guistic community and that, as a result, a reprise of
  Matthew:      Two people?                                a function word is more likely to signal clausal or
  Unknown:      For cookery, yeah.                         lexical problems. The interpretation of a RF should
                                                           also depend on whether a reprised fragment is al-
      Excerpt 1: Example Reprise Fragment CR               ready considered to have been grounded by the par-
                                                           ticipants in a conversation. For example, a reprise
                                                           of a proper noun would be more likely to be read as
  Laura:     Can I have some toast please?                 signalling a constituent problem if it occurs on the
  Jan:       Some?                                         first mention than on second mention. All things
                                                           being equal, the content of a constituent is already
  Laura:     Toast.
                                                           considered to be established by the time a second
      Excerpt 2: Example Reprise Fragment CR               mention occurs.
   RFs account for approximately 30% of CRs in                    Reprise Fragment Experiment
natural conversation (Purver et al., 2002) and are         A chat-tool experiment was designed to test the fol-
interesting partly because of their ambiguity. Al-         lowing hypotheses:
though they can efficiently localise where a prob-
lem occurs they do not explicitly signal what prob-       1. RFs for function words will normally receive
lem the recipient has encountered. Purver, et al.             clausal readings, whereas both clausal and con-
(2002) distinguish between three main readings of             stituent readings will be available for content
RFs: Clausal, Constituent, and Lexical. A clausal             words.
reading treats a CR as asking about the content of
the conversational move that prompted the CR. It          2. RFs for content words will receive more con-
can be roughly paraphrased as “Is it X about which            stituent readings on first mention than on second
you are asking/asserting Y?”. The constituent read-           mention.
ing queries the content of a constituent of the prob-
lem turn and can be paraphrased as “What/Who is           3. No difference is predicted for RFs for function
X?” or “What/who do you mean by X?”. The lexical              words on first vs. second mention.
reading is similar to the clausal reading except that
it is an aspect of the surface form, not the content                               Method
of the conversational move, that is is queried. This
corresponds to “Did you utter X?”.                         Two tasks were used to elicit dialogue, a balloon
   Purver et al. (2002) carried out an analysis of         debate and a story-telling task. In the balloon de-
the BNC corpus of conversations to investigate the         bate subjects are presented with a fictional scenario
relationship between the different forms of CR and         in which a balloon is losing altitude and about to
the readings they are given. Their findings indicate       crash. The only way for any of three passengers to
that, in contrast to other forms of reprise clarifica-     survive is for one of them to jump to a certain death.
tion, RFs can receive each of the possible readings.       The three passengers are; Dr. Nick Riviera, a cancer
However, the corpus data show a strong preference          scientist, Mrs. Susie Derkins, a pregnant primary
for a Clausal reading (87% of cases) over the other        school teacher, and Mr. Tom Derkins, the balloon
forms.                                                     pilot and Susie’s husband. Subjects are asked to de-
   As noted above, although corpus studies of this         cide who should jump. The advantages of this task
kind provide valuable information about the distri-        are that it is effective at generating debates between
bution of different CR forms and readings, they do         subjects and involves repeated references to partic-
not provide tests of the conditions which prompt           ular individuals.
                                                              The second dialogue task, from Bavelas et al.
    1
      BNC file KPP, sentences 352–354                      (1992), is the story-telling task. In this case sub-
    2
      BNC file KD7, sentences 392–394                      jects are asked to relate a ‘near-miss’ story about
                                                      540

some experience in which something bad almost hap-         NLP Component The NLP component consists
pened but in the end everything was okay. The ad-          of a Perl text-processing module which communi-
vantage of this task is the topic of the exchange is       cates with various external NLP modules as re-
unrestricted, in effect a random factor, and the in-       quired: part-of-speech tagging can be performed us-
teraction relates to real events.                          ing LTPOS (Mikheev, 1997), word rarity/frequency
                                                           tagging using a custom tagger based on the BNC
Subjects                                                   (Kilgarriff, 1997), and synonym generation using
                                                           WordNet (Fellbaum, 1998).
Twenty-eight subjects were recruited, 20 male and             Experimental parameters are specified as a set of
8 female, average age 19 years, from computer sci-         rules which are applied to each word in turn. Pre-
ence and IT undergraduate students. They were re-          conditions for the application of the rule can be
cruited in pairs to ensure that the members of a           specified in terms of part-of-speech, word frequency
pair were familiar with one another and only sub-          and the word itself, together with contextual fac-
jects who had experience with some form of text            tors such as the time since the last artificial turn
chat such as chat rooms, IRC, ICQ or other mes-            was generated, and a probability threshold to pre-
saging systems were used. Each subject was paid            vent behaviour appearing too regular. The effect
at a rate of £7.50 per hour for participating in the       of the rule can be to transform the word in ques-
experiment.                                                tion (by substitution with another word, a synonym
                                                           or a randomly generated non-word, or by letter or-
Materials                                                  der scrambling) or to trigger an artificially generated
A custom experimental chat tool, written in Java           turn sequence (currently a reprise fragment, followed
and Perl, was used for the experiment. The user in-        by an acknowledgement, although other turn types
terface is similar to instant messaging applications:      are possible).
a lower window is used to enter text, and the con-            The current experimental setup consists of rules
versation is displayed in the main upper window as         which generate pairs of RFs and subsequent ack-
it emerges (see Figure 1). The chat clients were run       owledgements3 , for proper nouns, common nouns,
on two Fujitsu LCD tablet computers with text in-          verbs, determiners and prepositions, with probabil-
put via standard external keyboards, with the server       ities determined during a pilot experiment to give
running on a standard PC in a separate room.               reasonable numbers of RFs per subject. No use is
                                                           made of word rarity or synonyms.
                                                              The turn sequences are carried out by (a) pre-
User Interface The Chattool client user interface          senting the artificially-generated RF to the relevant
is written in Java. The application window is split        client only; (b) waiting for a response from that
into two panes: a lower pane for text entry and an         client, preventing the other client from getting too
upper pane in which the conversation is displayed.         far ahead by locking the interface if necessary; (c)
   A status display between the two panes shows            presenting an acknowledgement to that response;
whether the other participant is active (typing) at        and (d) presenting any text typed by the other client
any time. This can be manipulated during the gen-          during the sequence.
eration of artificial turns to make it appear as if they   Procedure
are generated by the other participant. The client
also has the ability to display an error message and       Subjects were informed that the experiment was
prevent text entry: this can be used to delay one par-     investigating the effects of a network-based chat
ticipant while the other is engaged in an artificially-    tool on the way people interact with one another.
generated turn sequence.                                   They were infomed that their interaction would be
                                                           logged, anonymously, and kept for subsequent anal-
                                                           ysis. Subjects were advised that they could request
Server Each turn is submitted to a server (also            the log to be deleted after completion of the inter-
written in Java) on a separate machine when a ‘Send’       action and that they were free to leave at any time.
button or the ‘Return’ key is pressed. This server         They were then given a brief demonstration of the
passes the text to a NLP component for process-            operation of the chat tool.
ing and possible transformation, and then displays            To prevent concurrent verbal or gestural interac-
the original version to the originator client, and the     tion subjects were seated in separate rooms. Each
processed (or artificially generated) version to the       pair performed both dialogue tasks and were given
other client. The server records all turns, together       written instructions in each case. The balloon task
with each key press from both clients, for later anal-     was carried out once and the story-telling task twice;
ysis. This data is also used to dynamically control        one story for each participant. To control for order
the speed and capitalisation of artificially generated         3
                                                                 Acknowledgements are randomly chosen amongst:
turns, to be as realistic a simulation of the relevant     “ah”, “oh”, “oh ok”, “right”, “oh right”, “uh huh”, “i
subject as possible.                                       see”, “sure”.
                                                       541

                                        Figure 1: Chattool Client Interface
                   Table 1: Story Telling Task Excerpt, Noun Clarification, Subjects 1 & 2
    Subject A’s View                                              Subject B’s View
    B: Obviously the relatives were                               B: Obviously the relatives were
         coming around like they do to                               coming around like they do to
         see me                                                      see me
                                                    Probe →       A: relatives?
                                                    Block            B: Yeah just unts and uncles
                                                    Ack →         A: ah
    A: yeah                                                       A: yeah
effects presentation of the two tasks was counter-         system-generated CR was checked and, where ap-
balanced across pairs. A 10-minute time limit was          propriate, corrected. Because pairs completed both
imposed on both tasks. At the end of the experi-           tasks together CRs classified as ‘first mentions’ were
ment subjects were fully debriefed and the interven-       checked to ensure that they hadn’t already occured
tion using ‘artificial’ clarifications was explained to    in a previous dialogue.
them. This resulted in a within-subjects design with
two factors; category of reprise fragment and level of                             Results
grounding (first vs. second mention).
                                                           In addition to the Clausal, Constituent and Lexi-
   After the experiment, the logs were manually cor-       cal readings introduced above, Purver et al. (2002)
rected for the part-of-speech category of the RF and       identify three other possible interpretations of
for the first/second mention clarification. Part-of-       reprise fragment clarifications: ‘Gap’, ‘Correction’
speech required correction as the tagger produced          and ‘Non-clarificational’. Gaps occur where the frag-
incorrect word categories in approximately 30% of          ment reprised is not the one about which clarifica-
cases. In some instances this was due to typing            tion is actually being requested, but the one imme-
errors or text-specific conventions, such as “k” for       diately preceding it. For example, in Excerpt 2, the
“okay”, that were not recognised. Detection and            reprised word is “some” but the clarification is of the
classification of proper nouns was also sensitive to       following word – “toast”. Corrections occur where
capitalisation. Subjects were not consistent or con-       the fragment is offered as a correction and can be
ventional in their capitalisation of words and this        paraphrased as “Did you mean to say X?”. ‘Non-
caused some misclassifications. In addition a small        clarificational’ refers to situations in which the frag-
proportion of erroneous tags were found. Each              ment is treated as something other than a CR. In the
                                                      542

                       Table 2: Balloon Task Excerpt, Verb Clarification, Subjects 3 & 4
    Subject A’s View                                              Subject B’s View
    A: so we agree                                                A: so we agree
    B: agree?                                        ← Probe
    A: yeah to chuck out Susie derkins               Block
    B: uh huh                                        ← Ack
    B: yes                                                        B: yes
present corpus, gap, lexical and non-clarificational          The influence of grounding on reading type was
readings were low frequency events (4, 1 and 8 in-         assessed firstly by comparing the relative frequency
stances respectively) and no instances of correction       of Constituent, Clausal and Other readings on first
readings were noted. These figures are compara-            and second mention. This was reliably different (χ2(2)
ble with Purver et al.’s (ibid.) observations for the      = 6.28, p = 0.04) indicating that level of grounding
BNC. For statistical analysis these three catergories      affects the reading assigned. A focussed compari-
together with explicit requests for clarification of the   son of Constituent and Clausal readings on first and
CR were were grouped as ‘Other’.                           second mention shows no reliable difference (χ2(1) =
   Across the corpus as a whole a total of 215 system-     0.0, p = 0.92). Together these findings indicate that,
generated RFs were produced. In 50% of cases the           across all word categories, Constituent and Clausal
system-generated clarification received no response        readings are more likely for CR’s of a first mention
from the target participant. This is discussed below.      than a second mention and, conversely, Other read-
                                                           ings are less likely for CR’s to a first mention than
Table 3: Frequency of Reading Types By RF Cate-            a second mention.
gory and Mention                                              The effect of grounding on the relative frequency
                                                           with which a CR received a response was also tested.
                           Response Category               This showed an effect of mention (χ2(1) = 3.87, p =
      Category        None Con       Cla Other             0.05); 56% of reprise clarifications of first mentions
      Cont (1st)        29     14    23        4           received a response whereas only 43% of second men-
      Cont (2nd)        43      7    16        9           tion clarifications did.
      Func (1st)         6      0     0        6
      Func (2nd)        20      1     0        9                                Discussion
                                                           The experimental results indicate that people’s in-
   The distribution of reading types according to          terpretation of reprise fragment CR’s is influenced
word categrory was tested firstly by comparing the         both by the category of the reprise fragment and its
frequency of Clausal, Constituent, and Other read-         level of grounding.
ings for content words and function words. This               One concern that arises with these results is
proved to be reliably different (χ2(2) = 35.3, p =         whether they represent an artifact of differences be-
                                                           tween text and utterances as media or whether they
0.00).4 As Table 3 shows, RFs of Function words
                                                           bear on more basic aspects of the use of CR’s in in-
were almost exclusively given Other readings i.e.,
                                                           teraction. In contrast to utterances, text-chat turns
either they were explicitly queried indicating they
                                                           have no intonation, they take longer to produce, are
could not be interpreted, or they were interpreted
                                                           normally produced in overlap, and persist for longer.
as Gap, Lexical or Non-clarificational. By contrast
                                                           Turns can also get out of sequence since users may
Content word reprises were interpreted as Clausal
                                                           still be responding to a prior turn when a new turn
CRs 53% of the time, as Constituent CRs 29% of
                                                           arrives. In some cases we observed that the response
the time and as Other 18% of the time.
                                                           to a clarification was displaced to the end of the turn
   Content word and Function word clarifications
                                                           in progress or to a subsequent turn.
were also compared for the the frequency with which
they received a response. This showed no reliable             One respect in which this feeds into the present
difference (χ2(1) = 1.95, p = 0.16) indicating that        study is that persistence makes a Lexical reading of
                                                           a CR less plausible since participants can still see
although the interpretations given to Content and          what word was used in a previous turn. In the BNC
Function CR’s are different they are equally likely        corpus Lexical readings of reprise fragment CR’s ac-
to receive some kind of response.                          count for 3% of the sample analysed by Purver et. al.
   4
     A criterion level of p < 0.05 was adopted for all     (2002). In the present experimental corpus we found
statistical tests.                                         only one instance of a lexical reading (0.004%). Me-
                                                       543

dia differences may also contribute to differences in      possible use of this technique. Amongst other things
the distribution of clausal and constituent readings.      potential manipulations include; distance, in turns
In the BNC reprise fragments content words receive         or time, between target and probe, substitution of
Clausal readings in 81% of cases, and constituent          synonyms, hyponyms and hypernyms, introduction
readings in 6% of cases. In the experimental corpus        of artifical turns, blocking of certain forms of re-
they receive Clausal readings in 53% of cases and          sponse. The important potential it carries, in com-
Constituent readings in 29% of cases.                      parison with existing techniques, is in the direct test-
   However, the finding that almost 50% of the ex-         ing of claims about the fine-grained mechanisms of
perimental CRs are ignored does not seem to be             dialogue co-ordination.
attributable to differences between text-based and
verbal interaction. Reprise fragments are also of-                        Acknowledgments
ten ignored in verbal exchanges. For the sample of         This work was supported by the EPSRC under the
reprise fragments analysed by Purver et. al (2002)         project “ROSSINI: Role of Surface Structural Infor-
only 56% receive a clear answer. For 5% of those that      mation in Dialogue” (GR/R04942/01).
do not receive a clear answer the transcription of the
next turn is not clear enough to determine whether                              References
a response occurred or not. For the remainder no re-       Bavelas, J., Chovil, N., Lawrie, D., and Wade, L.
sponse is recorded in the transcript. In some of these       (1992). Interactive gestures. Discourse Processes,
cases there will have been a non-verbal response and         15:469–489.
these are not transcribed in the BNC. However, not
all CR’s could be resolved in this way. On balance         Burnard, L. (2000). Reference Guide for the British
it seems that even in face-to-face interaction a sig-        National Corpus (World Edition). Oxford Univer-
nificant proportion of reprise fragment CR’s receive         sity Computing Services.
no direct response.                                        Clark, H. H. (1992). Arenas of Language Use. Uni-
   Perhaps more importantly, the experimental re-            versity of Chicago Press & CSLI.
sults show a reliable difference in the frequency of       Fellbaum, C., editor (1998). WordNet: An Elec-
responses to CR’s for first and second mentions of           tronic Lexical Database. MIT Press.
a word. This indicates that the CR’s are not just          Ginzburg, J. and Cooper, R. (2001). Resolving el-
being missed, the recipients of the CR’s sometimes           lipsis in clarification. In Proceedings of the 39th
choose not to address them. In addition, there is            Meeting of the ACL, pages 236–243. Association
a reliable difference in the profile of reading types        for Computational Linguistics.
for CR’s on first and second mention with a shift          Ginzburg, J. and Cooper, R. (2003). Clarification,
away from clausal and constituent readings toward            ellipsis, and the nature of contextual updates. Lin-
Other readings. CR’s for second mentions are thus            guistics and Philosophy, forthcoming.
more likely to be either ignored, explicitly queried or    Kilgarriff, A. (1997). Putting frequencies in the dic-
treated as doing something other than just clarifying        tionary. International Journal of Lexicography,
the reprised fragment.                                       10(2):135–155.
   It appears that participant’s responses to reprise
fragment CR’s reflect a trade-off between the ef-          Mikheev, A. (1997). Automatic rule induction for
fort required to diagnose a problem and the risk             unknown word guessing. Computational Linguis-
to mutual-understanding of carrying on without ad-           tics, 23(3):405–423.
dressing it.                                               Pickering, M. and Garrod, S. (2003). Toward a
   This work demonstrates the viability of investi-          mechanistic psychology of dialogue. Behavioral
gating dialogue co-ordination through the manip-             and Brain Sciences, forthcoming.
ulation of chat-tool based interactions. This tech-        Purver, M., Ginzburg, J., and Healey, P. (2002). On
nique supports task independent, systematic and              the means for clarification in dialogue. In Smith,
fine grained experimental interventions in interac-          R. and van Kuppevelt, J., editors, Current and
tion. It was successful in producing plausible clarifi-      New Directions in Discourse & Dialogue. Kluwer
cation sequences and although some artificial clarifi-       Academic Publishers.
cations were difficult to interpret this is also true of   Schegloff, E. (1987). Some sources of misunderstand-
genuine CR’s from other participants. When ques-             ing in talk-in-interaction. Linguistics, 25:201–218.
tioned during debriefing, no participants reported
any suspicions about the experimental manipula-
tion. The main practical difficulties encountered in
the present study related to txt conventions such as
novel spellings, abbreviations, and use of ‘smileys’
and typing errors and inconsistency in spelling and
capitalisation.
   The experiment presented here exploits only one
                                                       544

