UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Why/AutoTutor: A Test of Learning Gains from a Physics Tutor with Natural Language Dialog

Permalink
https://escholarship.org/uc/item/6mj3q2v1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)

Authors
Graesser, A.C.
Jackson, G.T.
Matthews, E.C.
et al.

Publication Date
2003-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Why/AutoTutor: A Test of Learning Gains from a Physics Tutor with Natural
Language Dialog
Graesser, A.C.1 , Jackson, G.T. 1 ., Mathews, E.C.1 , Mitchell, H.H. 1 , Olney, A.1 , Ventura, M.1 , Chipman, P.1 ,
Franceschetti, D.1 , Hu, X.1 , Louwerse, M.M.1 , Person, N.K.2 , and the Tutoring Research Group1
(a-graesser, gtjacksn, emathews , hmitchll, aolney, mventura, pchipman, dfrncsch, xhu, mlouwers) @memphis.edu
1
Institute for Intelligent Systems
University of Memphis
Memphis, TN 38152

(person@rhodes.edu)
2

Rhodes College
2000 N Parkway
Memphis, TN 38112
Abstract
Why/AutoTutor is a tutoring system that helps students
construct answers to qualitative physics problems by holding a
conversation in natural language. Why/AutoTutor provides
feedback to the student on what the student types in (positive,
neutral, negative feedback), pumps the student for more
information, prompts the student to fill in missing words,
gives hints, fills in missing information with assertions,
identifies and corrects bad answers and misconceptions,
answers students’ questions, and summarizes answers. In
essence, constructivist learning is implemented in a mixedinitiative dialog. Why/AutoTutor delivers its dialog moves
with an animated conversational agent whereas students type in
their answers via keyboard. We conducted an experiment that
compared Why/AutoTutor with two control conditions (Read
textbook, nothing) in assessments of learning gains. The
tutoring system performed significantly better than the two
control conditions on a test similar to the Force Concept
Inventory.

AutoTutor and Why/AutoTutor
Why/AutoTutor is the most recent tutoring system in the
AutoTutor series developed by the Tutoring Research Group
at the University of Memphis.
Why/AutoTutor was
specifically designed to help college students learn
Newtonian qualitative physics (Graesser, VanLehn, Rose,
Jordan, & Harter, 2001), whereas the previous AutoTutor
systems were on topics of introductory computer literacy
(Graesser, Person, Harter, & TRG, 2001; Graesser, P.
Wiemer-Hastings, K. Wiemer-Hastings, & Kreuz, 1999)
and military tactical reasoning (Ryder, Graesser,
McNamara, Karnavat, & Pop, 2002).
The design of AutoTutor was inspired by three bodies of
theoretical, empirical, and applied research. These include
explanation-based constructivist theories of learning
(Aleven & Koedinger, 2002; Chi, deLeeuw, Chiu,
LaVancher, 1994; VanLehn, Jones, & Chi, 1992), intelligent
tutoring systems that adaptively respond to student
knowledge (Anderson, Corbett, Koedinger, & Pelletier,
1995; VanLehn, Lynch, et al.,2002), and empirical research
that has documented the collaborative constructive activities
that routinely occur during human tutoring (Chi, Siler,
Jeong, Yamauchi, & Hausmann, 2001; Fox, 1993; Graesser,

474

Person, & Magliano, 1995; Moore, 1995; Shah, Evens,
Michael, & Rovick, 2002). The process of actively
constructing explanations and elaborations of the learning
material allegedly produces better learning than merely
presenting information to students. This is where human
tutors excel in scaffolding learning, because they guide the
students in productive constructive processes and
simultaneously respond to the student’s information needs.
Surprisingly, the dialog moves of most human tutors are
not particularly sophisticated from the standpoint of today’s
pedagogical theories and those theories implemented in
intelligent tutoring systems (Graesser et al., 1995). Human
tutors normally coach the student in filling in missing pieces
of information in an expected answer and they fix bugs and
misconceptions that are manifested by the student during the
tutorial dialog. Human tutors rarely implement bona fide
Socratic tutoring strategies, modeling-scaffolding-fading,
and other intelligent pedagogical techniques (Collins,
Brown, & Newman, 1989). The argument has been made
that it is the conversational properties of human tutorial
dialog, not sophisticated tutoring tactics, that explain why
normal human tutors facilitate learning (Graesser et al.,
1995). More sophisticated pedagogical techniques will no
doubt increase learning even further. Why/AutoTutor was
designed to simulate the dialog moves of normal human
tutors who coach students in constructing explanations.
Why/AutoTutor helps students learn by presenting
challenging problems (or questions) from a curriculum
script and then engaging in mixed initiative dialog that
guides the student in constructing an answer. An example
question is “Suppose a boy is in a free-falling elevator and
he holds his keys motionless right in front of his face and
then lets go. What will happen to the keys? Explain why.”
Another example question is “When a car without headrests
on the seats is struck from behind, the passengers often
suffer neck injuries. Why do passengers get neck injuries in
this situation?” Such questions are designed to require
about a paragraph of information (3-7 sentences) to answer.
However, initial answers to these questions are typically
only 1 or 2 sentences in length, even though students have
more knowledge that is relevant to an answer. This is where
tutorial dialog may be particularly helpful. AutoTutor
engages the student in a mixed initiative dialog that assists

in the evolution of an improved answer and that draws out
more of what the students know. AutoTutor provides
feedback to the student on what the student types in
(positive, neutral, negative feedback), pumps the student for
more information (“What else?”), prompts the student to fill
in missing words, gives hints, fills in missing information
with assertions, identifies and corrects erroneous ideas and
misconceptions, answers the student’s questions, and
summarizes answers. A full answer to the question is
eventually constructed during this dialog.
The following dialog excerpt from a tutoring ses sion on
conceptual physics illustrates some of AutoTutor’s dialog
features.
AutoTutor (SEED QUESTION):
When a car without
headrests on the seats is struck from behind, the
passengers often suffer neck injuries. Why do
passengers get neck injuries in this situation?
Student: The
passenger
experiences
a
backward
acceleration, while the car moves forward.
AutoTutor (PUMP): And can you add to that?
Student: This is because the passenger experiences a force
opposite in direction to the force on the car.
AutoTutor (POSITIVE FEEDBACK): Um, yes, correct!
AutoTutor (HINT): When the neck provides a large force,
what within the neck would get damaged?
Student: the spine
AutoTutor (NEUTRAL NEGATIVE FEEDBACK): umm
AutoTutor (PROMPT): I think you can get this. Damage
within the neck will occur in the ligaments and the
. . . . . ? [spoken with rising intonation and
accompanied with a prompting hand gesture]
Student: muscles
AutoTutor (POSITIVE FEEDBACK): Brilliant!
AutoTutor (PROMPT RESPONSE): ligaments and the
muscles.
AutoTutor (DIALOG ADVANCER): Let’s keep going.
AutoTutor (HINT): Additionally, when there is no headrest
present in the car, what accelerates the head of the
passenger?
Student: the impact from behind
AutoTutor (PROMPT): I am sure you can get this. The
head of the passenger will be accelerated by the
passenger's . . . . .? [spoken with rising intonation
and accompanied with a prompting hand gesture]
Student: car
AutoTutor (NEGATIVE FEEDBACK): Wrong!
AutoTutor (PROMPT RESPONSE): by the passenger's
neck.
[moving ahead 22 turns in the dialog]
AutoTutor (QUESTION PROMPT): Do you perhaps have
any general conceptual physics questions?
Student: no
AutoTutor (FINAL ANSWER PROMPT): How would you
answer my first question, having gone over what
we've just talked about?
Student: The passengers get neck injuries because the neck
needs to exert a large force on the head equal to the

475

force on the body. When struck, the body will
continue to move in the direction of motion of the
car, while the car exerts a force on the passenger's
body in the opposite direction. The force of the
neck on the head must equal the force of the head
on the neck, and the force on the neck's smaller
mass often results in torn muscles and ligaments.
AutoTutor (POSITIVE FEEDBACK): Great!
AutoTutor (SUMMARY): To recap, when a car is struck
from behind, the force of impact will cause the car
to experience a large forward acceleration. The car
seat is attached to the car and will also have the
same large acceleration. When the car is hit from
behind, the seat will exert the same acceleration to
the torso of the body. In order for the head to go
along with the torso, it will need to be accelerated
at the same rate as the torso. Since the head has no
acceleration being applied to it by a headrest, the
neck gets stretched damaging its muscles and
ligaments in an attempt to produce the required
large acceleration.
Figure 1 shows the interface of Why/AutoTutor. The
major question is selected and presented in the top-right
window. This major question (e.g., involving a boy
dropping keys in a falling elevator) remains at the top of the
web page until it is finished being answered by a multi-turn
dialog between the learner and Why/AutoTutor. The
students use the bottom-right window to type in their
contributions for each turn, with the content of both tutor
and student turns being reflected in the bottom-left window.
The animated conversational agent resides in the upper-left
area. The agent uses either an AT&T or a Microsoft Agent
speech engine to speak the content of AutoTutor’s turns
during the process of answering the presented question.
The computational architectures of Why/AutoTutor and
earlier versions of AutoTutor have been discussed
extensively in previous publications (Graesser, Person et al.,
2001; Graesser, VanLehn, et al., 2001; Graesser, WiemerHastings et al., 2001), so this paper will provide only a brief
sketch of the components. Why/AutoTutor was written in
Java and resides on a Pentium-based server platform to be
delivered across the web. The software residing on the
server has a set of permanent databases that do not get
updated throughout the course of tutoring. These include (a)
the curriculum script repository consisting of questions,
answers, and associated dialog moves, (b) lexicons,
syntactic parsers, and other computational linguistics
modules, (c) a question answering facility, (d) a corpus of
documents, including a text book on conceptual physics,
and (e) latent semantic analysis (LSA) vectors for words,
curriculum content, and the document corpus.
Why/AutoTutor uses LSA as the backbone for
representing world knowledge about conceptual physics, or
any other subject matter that is tutored (Graesser, P.
Wiemer-Hastings, K. Wiemer-Hastings, Harter, Person, &
TRG, 2000; Olde, Franceschetti, Karnavat, Graesser, &
TRG, 2002).

Figure 1: Interface of Why/AutoTutor
LSA is a high-dimensional, statistical technique that, among
other things, measures the conceptual similarity of any two
pieces of text, such as a word, sentence, paragraph, or
lengthier document (Foltz, Gilliam, & Kendall, 2000;
Kintsch, 1998; Landauer, Foltz, & Laham, 1998).
Why/AutoTutor uses LSA to perform conceptual pattern
matching operations when we compare student
contributions to expected good answers and to anticipated
misconceptions. An expectation is considered covered if
the student’s contributions end up matching the expectation
by some LSA threshold of overlap.
Similarly, a
misconception is considered present if the student’s input
matches the misconception by some LSA threshold.
In addition to the static data modules mentioned above,
Why/AutoTutor has a set of processing modules and
dynamic storage units that maintain qualitative content and
quantitative parameters.
These storage registers are
frequently updated as the tutoring process proceeds. For
example, Why/AutoTutor keeps track of student ability (as
evaluated by LSA from student Assertions), student
initiative (such as the incidence of student questions),
student verbosity (number of words per turn), and the
progress in having a question answered by virtue of the
dialog history.
The dialog management module of
AutoTutor flexibly adapts to the student by virtue of these
parameters, so it is extremely unlikely that two
conversations with AutoTutor are ever the same.

476

The dialog management module is an augmented finite
state network. The nodes in the network refer to knowledge
goal states (e.g., expectation E is under focus and AutoTutor
wants to get the student to articulate it) or dialog states (e.g.,
the student just expressed an assertion as the first turn in
answering the question). The arcs refer to categories of
tutor dialog moves (e.g., feedback, pumps, prompts, hints,
summaries, etc.) or discourse markers that link dialog
moves (okay, moving on, furthermore). A particular arc is
traversed when particular conditions are met (e.g., it is the
student’s first turn and the student’s assertion is correct).
Arc traversal is sometimes contingent on outputs of
computational algorithms and procedures that are sensitive
to the dynamic evolution of the dialog. These algorithms
and procedures operate on the snapshot of parameters, data
content, knowledge goal states, student knowledge, dialog
states, LSA measures, and so on, that reflect the current
conversation constraints and achievements. For example,
there are algorithms that select dialog move categories that
attempt to get the student to fill in missing information in
expectation E. There are several alternative algorithms to
achieve this goal. Consider one of the early algorithms we
adopted. If the student has almost finished articulating
expectation E, but lacks a critical noun or verb, then a
prompt category would be selected because the function of
prompts is to extract single words from students. The
particular prompt selected from the curriculum script would
be tailored to extracting the particular missing word through
another module that fills dialog move categories with

content. If the student is classified as high ability and has
failed to articulate most of the words in expectation E, then
a hint category might be selected. Fuzzy production rules
make these selections.
An alternative algorithm to fleshing out expectation E
uses two cycles of hint-prompt-assertion.
That is ,
AutoTutor’s selection of dialog movers over successive
turns follows an ordering: first hint, then prompt, then
assert, then hint, then prompt, then assert. AutoTutor exists
the two cycles as soon as the student articulates expectation
E to satisfaction (i.e., the LSA threshold is met).
Other processing modules in AutoTutor execute various
important functions: speech act classification, linguistic
information extraction, evaluation of student assertions,
selection of the next expectation to cover, and speech
production with the animated conversational agent. It is
beyond the scope of this paper to describe these modules.

Previous Empirical Studies of Tutorial
Learning
One-to-one tutoring is a powerful method of promoting
knowledge construction, as has been shown through
available empirical studies (Bloom, 1984; Cohen, Kulik, &
Kulik, 1982; Corbett, 2001). The vast majority of the tutors
in these studies of human tutoring have had moderate
domain knowledge and little or no training in pedagogy or
tutoring; the tutors were peer tutors, cross-age tutors, or
paraprofessionals, but very rarely accomplished tutors. The
unaccomplished human tutors enhanced learning with an
effect size of .4 standard deviation units (called sigmas),
which translates to approximately an improvement of half a
letter grade (Cohen et al., 1982). The accomplished human
tutors produced effect sizes of 2 sigmas according to Bloom
(1984), although the magnitude of this effect should be
questioned due the relative small number of studies that
have looked at accomplished tutors.
In the arena of computer tutors, intelligent tutoring
systems with sophisticated pedagogical tactics but no
natural language dialog produce effect sizes of
approximately 1 sigma (Corbett, 2001; VanLehn et al.,
2002).
Previous versions of AutoTutor have produced
gains of .4 to 1.5 sigma (a mean of .7), depending on the
learning measure, the comparison condition, the subject
matter, and version of AutoTutor (Graesser, Moreno, et al.,
2003; Person et al., 2001; VanLehn & Graesser, 2002).
This places previous versions of AutoTutor somewhere
between an unaccomplished human tutor and an intelligent
tutoring system. It might be noted, however, that one recent
evaluation of physics tutoring (VanLehn & Graesser, 2002)
remarkably reported that the learning gains produced by
accomplished human tutors via computer mediate
conversation were equivalent to the gains produced in two
computer
tutors
with
natural
language
dialog
(Why/AutoTutor and Why/Atlas, a system developed at the
University of Pittsburgh). The effectiveness of different
tutoring systems clearly requires additional research.

477

Present Study of Why/AutoTutor
We conducted an experiment that assessed learning gains of
Why/AutoTutor, compared with two comparison conditions.
Those assigned to the AutoTutor Condition learned
conceptual physics by participating in a tutorial dialog with
Why/AutoTutor for approximately 3-4 hours. Those in the
Read-textbook condition read textbook chapters on the
same Newtonian physics topics covered by Why/AutoTutor,
for a comparable amount of study time; the textbook was
Hewitt’s Conceptual Physics (1998). There was also a nomaterial Control condition in which the subjects did not
receive any material on conceptual physics. The participants
were 67 college students enrolled in a college physics
course at Ole Miss, Rhodes College, and the University of
Memphis. The participants were randomly assigned to the
three conditions, except that twice as many subjects were to
be assigned to the AutoTutor condition as in the two
comparison conditions. Learning gains were assessed by
administering a pretest and a posttest that consisted of
multiple choice questions. The questions were extracted
from or were similar to those in the Force Concept
Inventory (Hestenes, Wells, & Swackhamer, 1992).
Another method of assessing learning was the quality of
their answers to an additional sample of qualitative physics
questions, but these data are not reported in the present
study.
The experiment included two sessions, approximately 2-3
hours each, one week apart. The first session consisted of a
pretest followed by a learning phase, while the second
session began with the learning phase and ended with a
posttest.
Two different test versions (A, B) were
counterbalanced across conditions as pre and post tests.
Each test has a multiple choice part and a conceptual
physics essay part. There were 40 multiple choice items
pulled from the Force Concept Inventory (FCI) in each
version, A and B. There were 4 conceptual physics
questions in each of the two versions of the test.
During the learning phases, participants received either
Why/AutoTutor (N=32), Read-textbook (N=16), or Control
(N=19). The learning phase of Why/AutoTutor covered 10
conceptual physics questions, such as the example in Figure
1. Each problem took approximately 20 minutes to answer,
as the student and AutoTutor collaborative answered the
questions. The participants in the Read-textbook condition
read the textbook for an approximately equivalent amount
of time, as estimated by the tutoring sessions reported in
VanLehn and Graesser (2002). VanLehn and Graesser
(2002) cover additional details about the tests, learning
materials, and methodology.
We computed the proportion of multiple choice questions
that were answered correctly on the pretest and posttest.
Table 1 presents the means and standard deviations (SD) of
the pretests and posttests in the three conditions. The right
column in table includes adjusted posttest scores that
statistically control for the pretest score; standard errors are
in parentheses.

An ANOVA was conducted on the scores, using a 3x2
factorial design, with condition as a between-subject
variable and test phase (pre versus post) as a repeated
measures variable. There was a statistically significant
condition by test phase interaction, F(2,64) = 12.28, p < .01,
MSerror = .005. The pattern of means clearly showed more
learning gains from pretest to posttest in the Why/AutoTutor
condition than the other two conditions. An ANCOVA was
statistically significant when we analyzed the posttest
scores, using the pretest scores as a covariate, F(2,63)=
14.81, p < .01. The adjusted posttest scores showed the
following ordering among means: Why/AutoTutor > Readtextbook = Control. The effect size (sigma) of the learning
gains of Why/AutoTutor was .75 when its pretest served as
a control, .61 when the posttest Control mean served as the
control, and 1.22 when the posttest Read-textbook mean
served as the control. These effect sizes are comparable to
the intelligent tutoring of systems on physics reported by
VanLehn et al. (2002).
Table 1: Proportion Correct on Pretests and Posttests
Condition

AutoTutor
Readtextbook
Control

Pretest
Mean
(SD)

Posttest
Mean
(SD)

0.597
(.170)
0.566
(.126)
0.633
(.172)

0.725
(.153)
0.586
(.114)
0.632
(.153)

Adjusted
Posttest
(Std.
Error)
0.727
(.016)
0.610
(.022)
0.608
(.020)

Table 2: Learning Gains Proportions

AutoTutor
Readtextbook
Nothing

Simple
Learning
Gains (SD)
0.128 (.111)
0.020 (.068)

Normalized Gain
Score (SD)

-0.001 (.100)

-0.109 (.337)

These results of the present study on qualitative physics
follow previous trends in AutoTutor research that have
continually shown it to be an effective learning tool
(Graesser, Moreno, et al., 2003; Person et al., 2001).
Why/AutoTutor consistently outperformed its comparison
conditions in three alternative comparisons that were
considered (pretest for Why/AutoTutor, Read-textbook
control, and a no learning material Control). These results
are compatible with the claim that there is something about
tutorial dialog in natural language that promotes learning in
these constructivist learning environments.
We are currently exploring what it is, more precisely, that
accounts for the learning gains (VanLehn & Graesser,
2002). Is it the dialog facility, the responsive feedback, the
student’s active construction of information, the
construction of explanations, or some other factor that is
responsible for learning gains? Perhaps the same amount of
learning might occur if we have them simply study the
explanation and answer for each question. Now that we
know that learning does occur, we can dissect the potential
causes of learning in subsequent research.

Acknowledgments

Two alternative measures of learning gains were
computed to show differences between conditions. First,
the simple learning gains were computed as Posttest-Pretest.
A one-way ANOVA performed on the simple learning gains
showed significant differences among conditions,
F(2,64)=12.28, p < .01, MSerror = .010. As shown in Table
2, and confirmed in follow up planned comparisons, there
was the following ordering of means: Why/AutoTutor >
Read-textbook = Control.
Second, we computed the
normalized gain score, a standard that often has been used to
report learning gain proportions: [(Posttest-Pretest) / (1Pretest)]. An ANOVA performed on the normalized gain
scores showed the same significant effect, F(2,64)=13.17, p
< .01, MSerror = .008, and ordering of means.

Condition

Conclusions

0.303 (.279)
0.033 (.168)

478

The Tutoring Research Group (TRG) is an interdisciplinary
research team comprised of approximately 35 researchers
from psychology, computer science, physics, and education
(visit http://www.autotutor.org). This research conducted by
the authors and the TRG was supported by the National
Science Foundation (REC 0106965), and the DoD
Multidisciplinary University Research Initiative (MURI)
administered by ONR under grant N00014-00-1-0600. Any
opinions, findings, and conclusions or recommendations
expressed in this material are those of the authors and do not
necessarily reflect the views of ONR or NSF. Kurt
VanLehn, Pam Jordan, Carolyn Rose, Stephanie, Siler, and
others at the University of Pittsburgh prepared the materials
for the physics tests.

References
Aleven V. & Koedinger, K. R. (2002). An effective
metacognitive strategy: Learning by doing and
explaining with a computer-based Cognitive Tutor.
Cognitive Science, 26, 147-179.
Anderson, J.R., Corbett, A.T., Koenger, K.R., & Pelletier,
R. (1995). Cognitive tutors: Lessons learned. The
Journal of the Learning Sciences, 4, 167-207.
Bloom, B. S. (1984). The 2-sigma problem: The search for
methods of group instruction as effective as one-to-one
tutoring. Educational Researcher, 13(6), 4-16.
Chi, M.T.H., de Leeuw, N., Chiu, M. & LaVancher, C.
(1994) Eliciting self-explanation imp roves
understanding. Cognitive Science, 18, 439-477.
Chi, M. T. H., Siler, S., Jeong, H., Yamauchi, T., &
Hausmann, R. G. (2001). Learning from human tutoring.
Cognitive Science, 25, 471-533.

Cohen, P. A., Kulik, J. A., & Kulik, C. C. (1982).
Educational outcomes of tutoring: A meta-analysis of
findings. American Educational Research Journal, 19,
237-248.
Collins, A., Brown, J. S., & Newman, S. E. (1989).
Cognitive apprenticeship: Teaching the craft of reading,
writing, and mathematics. In L. B. Resnick (Ed.),
Knowing, learning, and instruction: Essays in honor of
Robert Glaser (pp. 453-494). Hillsdale, NJ: Erlbaum.
Corbett, A.T. (2001). Cognitive computer tutors: Solving
the two-sigma problem. User Modeling: Proceedings of
the Eighth International Conference (p. 137-147).
Foltz, P.W., Gilliam, S., & Kendall, S. (2000). Supporting
content-based feedback in on-line writing evaluation
with LSA. Interactive Learning Environments, 8, 111127.
Forbus, K. (1984). Qualitative process theory. Artificial
Intelligence, 24, 85-168.
Fox, B. (1993).
The human tutorial dialog project.
Hillsdale, NJ: Erlbaum.
Graesser, A.C., Moreno, K., Marineau, J., Adcock, A.,
Olney, A., & Person, N. (2003). AutoTutor improves
deep learning of computer literacy: Is it the dialog or the
talking head? Proceedings of Artificial Intelligence in
Education
Graesser, A.C., Person, N., Harter, D., & TRG (2001).
Teaching tactics and dialog in AutoTutor. International
Journal of Artificial Intelligence in Education, 12, 257279.
Graesser, A. C., Person, N. K., & Magliano, J. P. (1995).
Collaborative dialogue patterns in naturalistic one-to-one
tutoring. Applied Cognitive Psychology, 9, 1-28.
Graesser, A.C., VanLehn, K., Rose, C., Jordan, P., and
Harter, D. (2001). Intelligent tutoring systems with
conversational dialogue. AI Magazine, 22, 39-51.
Graesser, A.C., Wiemer-Hastings, K., Wiemer-Hastings, P.,
Kreuz, R., & the TRG (1999). Auto Tutor: A
simulation of a human tutor. Journal of Cognitive
Systems Research, 1, 35-51.
Graesser, A.C., Wiemer-Hastings, P., Wiemer-Hastings, K.,
Harter, D., Person, N., and the TRG (2000). Using
latent semantic analysis to evaluate the contributions of
students in AutoTutor. Interactive Learning
Environments, 8, 129-148
Hestenes, D., Wells, M., & Swackhamer, G. (1992). Force
Concept Inventory. The Physics Teacher 30. 141-158.
Hewitt, P.G. (1998). Conceptual physics (8th edition).
Reading, MA: Addison-Wesley.
Kintsch, W. (1998). Comprehension: A paradigm for
cognition. Cambridge, MA: Camb ridge University
Press.
Landauer, T.K., Foltz, P.W., Laham, D. (1998). An
introduction to latent semantic analysis. Discourse
Processes, 25, 259-284.
Moore, J.D. (1995). Participating in explanatory dialogues.
Cambridge, MA: MIT Press.

479

Olde, B. A., Franceschetti, D.R., Karnavat, Graesser, A. C.
& the Tutoring Research Group (Aug., 2002). The right
stuff: Do you need to sanitize your corpus when using
latent semantic analysis? Proceedings of the 24th
Annual Conference of the Cognitive Science Society (pp.
708-713). Mahwah, NJ: Erlbaum.
Person, N. K., Graesser, A. C., Bautista, L., Mathews, E. C.,
& the Tutoring Research Group (2001). Evaluating
student learning gains in two versions of AutoTutor. In
J. D. Moore, C. L. Redfield, & W. L. Johnson (Eds.)
Artificial intelligence in education: AI-ED in the wired
and wireless future (pp. 286-293). Amsterdam, IOS
Press.
Person, N.K., Graesser, A.C., Kreuz, R.J., Pomeroy, V., &
TRG (2001). Simulating human tutor dialog moves in
AutoTutor. International Journal of Artificial
Intelligence in Education. 12, 23-39.
Ryder, J.M., Graesser, A.C., McNamara, J., Karnavat, A., &
Pop, E. (2002). A dialog based intelligent tutoring
system for practicing command reasoning skills. Paper
presented at I/ITSEC.
Shah, F., Evens, M., Michael, J., & Rovick, A. (2002).
Classifying student initiatives and tutor responses in
human keyboard-to-keyboard tutoring sessions.
Discourse Processes, 33, 23-52.
VanLehn, K. & Graesser, A. C. (2002). Why2 Report:
Evaluation of Why/Atlas, Why/AutoTutor, and
accomplished human tutors on learning gains for
qualitative physics problems and explanations.
Unpublished report prepared by the University of
Pittsburgh CIRCLE group and the University of
Memphis Tutoring Research Group.
VanLehn, K., Jones, R. M. & Chi, M. T. H. (1992). A
model of the self- explanation effect. Journal of the
Learning Sciences, 2(1), pp. 1-60.
VanLehn, K., Lynch, C., Taylor, L.,Weinstein, A., Shelby,
R., Schulze, K., Treacy, D., & Wintersgill, M. (2002).
Minimally invasive tutoring of complex physics problem
solving. In S. A. Cerri, G. Gouarderes, & F. Paraguacu
(Eds.), Intelligent Tutoring Systems 2002 (pp. 367-376).
Berlin, Germany: Springer.

