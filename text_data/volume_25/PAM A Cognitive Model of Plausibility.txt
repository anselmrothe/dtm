UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
PAM: A Cognitive Model of Plausibility
Permalink
https://escholarship.org/uc/item/4jt2p1jn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Connell, Louise
Keane, Mark T.
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                        PAM: A Cognitive Model of Plausibility
                                                Louise Connell (louise.connell@ucd.ie)
                                                 Mark T. Keane (mark.keane@ucd.ie)
                                      Department of Computer Science, University College Dublin,
                                                           Belfield, Dublin 4, Ireland
                              Abstract                                    specified model of uncertainty assessment which he terms
                                                                          plausibility, but this work is not intended to be a cognitive
   Plausibility has been implicated as playing a critical role in         model of human plausibility judgements.
   many cognitive phenomena from comprehension to problem                    These varied approaches provide pieces of the plausibility
   solving. Yet, plausibility is usually treated as an
                                                                          puzzle, informing our own cognitive model of plausibility
   operationalised variable (i.e., a plausibility rating) rather than
   being explained or studied in itself. This paper reports on a
                                                                          (see also Connell and Keane, 2002, 2003a, 2003b). We
   new model of plausibility that is aimed at modeling several            argue that human plausibility is based upon both concept-
   direct studies of plausibility. This model, the Plausibility           coherence (i.e., the conceptual relatedness of the described
   Analysis Model (PAM), used distributional knowledge about              situation) and word-coherence (i.e., the distributional
   word co-occurrence (word-coherence) and commonsense                    information of the words used). In this paper, we review the
   knowledge of conceptual structure and relatedness (concept-            evidence for this theory and describe its computational
   coherence) to determine the degree of plausibility of some             implementation the Plausibility Analysis Model (PAM).
   target description. A detailed simulation of several plausibility
   findings is reported, which shows a close correspondence               Plausibility and Concept-Coherence
   between the model and human judgments.
                                                                          Notwithstanding the lack of specificity in definitions of
                          Introduction                                    plausibility, there is a shared view running through the
                                                                          literature that plausibility has something to do with the
Plausibility is an ineluctable phenomenon of everyday life,               coherence of concepts as established by prior knowledge.
whether it is used to assess the quality of a movie plot or to            For example, if we were asked to assess the plausibility of
consider a child’s excuse for a broken dish. It is perhaps                the scenario --The bottle fell off the shelf and smashed -- we
this very ubiquity that has led to it being ignored in                    might make the bridging inferences that the bottle falling
cognitive science. Typically, in the psychological literature,            caused it to smash on the floor. We may then judge this
plausibility is merely operationalised (as ratings on a scale),           situation to be quite plausible because our prior experience
rather than explained. This literature has shown plausibility             suggests that fragile things often break when they fall on
to play a vital role in diverse phenomena; such as discourse              hard surfaces. In short, the smashing scenario has good
comprehension (Speer & Clifton, 1998), conceptual                         concept-coherence. In contrast, if we were asked to judge
combination (Costello & Keane, 2000), reasoning (Collins                  the plausibility of the scenario --The bottle fell off the shelf
& Michalski, 1989; Smith, Shafir, & Osherson, 1993) and                   and melted-- we may judge it to be less plausible because
arithmetic problem solving (Lemaire & Fayol, 1995). In                    there is little in our prior experience to suggest that fragile
this way, the empirical literature leaves us with a sense that            things melt when they fall onto a surface. In short, the
plausibility is important but without a good indication of                melting scenario lacks concept-coherence. Intuitively, these
what it is. Theoretically, the literature really only contains            examples suggest that the way the concepts cohere in a
broad, statements suggesting that “something is plausible if              scenario contributes to its perceived plausibility.
it is conceptually supported by prior knowledge” (Collins &                  Connell and Keane (2002, 2003a) have provided
Michalski, 1989; Johnson-Laird, 1983). In short, plausibility             empirical support for this intuition in studies of people's
is in need of a thorough computational and empirical                      plausibility judgements of scenarios with differential
treatment.                                                                concept coherence (i.e., scenarios that invite different
   Recently, several proposals have emerged that might well               bridging inferences). Many studies have shown that people
provide a computational basis for plausibility. Costello &                simultaneously and independently monitor causal
Keane (2000) have modeled plausibility in conceptual                      and temporal continuity when reading, making
combination, illustrating what "conceptually supported by                 bridging inferences when necessary, to build up a coherent
prior knowledge" might mean. Lapata, McDonald & Keller                    model of a described scenario (Zwaan et al., 1995).
(1999) have suggested that plausibility might be modeled by               Connell and Keane found that causal inferences (causal
the surface, distributional properties of words themselves,               pairs, like the smashing scenario) were judged more
though some argue that this view overlooks conceptual                     plausible than those that failed to invite obvious
structure (Zwaan, Magliano & Graesser, 1995; French &                     causal inferences (unrelated pairs, like the melting
Labiouse, 2002). Finally, Halpern (2001) has a well-                      scenario), when other factors are being held
                                                                      264

                                               Figure 1: Illustration of distributional overlap
constant1. Furthermore, causal pairs were also found to be              sentences appear more plausible by virtue of the particular
more plausible than sentence pairs that invited simple                  words used.
attributal inferences, which in turn were judged to be more                Distributional knowledge of a language can be gleaned
plausible than inferences of temporal succession (see                   from statistical analyses of how each word is distributed in
Table 1). In addition to inference type affecting how people            relation to others in some corpora of texts. In these analyses,
rate the plausibility of situations, Connell and Keane                  a given word's relationship to every other word is
(2003b) have also shown that inference type affects the time            represented by a contextual distribution. The contextual
needed to make a plausibility judgement. People took                    distribution of a word is formed by moving through the
significantly longer to make a binary (yes/no) decision of              corpus and counting the frequency with which it appears
plausibility for causal sentence pairs than attributal sentence         with other words in its surrounding context. Thus, every
pairs. These studies provide specific concrete evidence that            word may be summarised as a vector – or point in high-
plausibility is influenced by the conceptual coherence of a             dimensional space – showing the frequency with which is it
situation, as shaped by the type of inferences involved.                associated with other lexemes in the corpus. Similarly, a
                                                                        sentence may be represented as single point in distributional
 Table 1: Example of inference types with mean plausibility             space by merging its word points; for example, the Latent
 scores for all materials in Experiment 1, Connell and Keane            Semantic Analysis (LSA) model (Landauer & Dumais,
                             (2003a)                                    1997) uses the weighted sum of constituent word vectors to
                                                                        denote tracts of text. In this way, two sentences containing
  Inference      Sentence Pair                      Mean Score          words that occur in similar linguistic contexts (i.e., that are
  Type                                                                  distributionally similar) will be positioned closer together in
  Causal         The breeze hit the candle.              7.8            this space than two sentences containing words that do not
                 The candle flickered.                                  share as much distributional information.
  Attributal     The breeze hit the candle.              5.5               When a sentence is read, a neighbourhood of activation
                 The candle was pretty.                                 spreads out around its point in distributional space. The
  Temporal       The breeze hit the candle.              4.2            activated neighbourhood of a point is made up of words that
                 The candle shone.                                      are distributionally similar, such as those that the sentence
  Unrelated      The breeze hit the candle.              2.0            in question may prime. If two sentences lie close to each
                 The candle drowned.                                    other in distributional space, their neighbourhoods will have
Note: All inference types were reliably different from one another.
                                                                        an overlap. For example, the sentence pairs:
                                                                        (i)       The pack saw the fox. The hounds snarled.
Plausibility and Word-Coherence
                                                                        (ii)      The pack saw the fox. The hounds growled.
Apart from the long-argued-for concept-coherence effect on              have essentially the same meaning, but have different
plausibility, more recently some have argued for a word-                distributional overlaps. The differences in the distributional
coherence effect (Lapata et al., 2001). This view suggests              properties of snarled versus growled means that the
plausibility judgements are sensitive to the distributional             sentences of pair (i) are further apart and thus have a smaller
patterns of the specific words used to describe a situation.            overlap of distributional information than the sentences of
In other words, the distinctive relationships between words,            pair (ii) (see Figure 1). However, the entire distributional
as encoded in distributional knowledge, make certain                    overlap does not contribute to the understanding of the
                                                                        sentences; only some of the overlapping information is
1
  Factors controlled were word frequency (using counts from the         relevant to the meaning of the sentence pair as a whole. For
British National Corpus), word-coherence (using scores from             example, the overlap of pair (ii) may contain words like
Latent Semantic Analysis, discussed below), and word                    leaped, bounded, beast, chasing, howling, lair, etc., but
appropriateness (of noun/verb and noun/adjective use).                  many of these words (like leaped, bounded, beast) do not
                                                                   265

                                             Figure 2: The Plausibility Analysis Model
play key semantic roles in scenarios about hounds hunting         Comprehension Phase
foxes. These words are irrelevant to the meaning of the           When a sentence is first read it is parsed and each word
sentence pair and must be suppressed – i.e., the information
                                                                  helps to activate a certain neighbourhood of distributional
is superfluous to the task and so its activation must be
                                                                  knowledge. This activated neighbourhood affects the ease
dampened (Gernsbacher & Faust, 1991; Gernsbacher &
Robertson, 1995). The words in the overlap (e.g., chasing,        with which any following sentence is read. Connell and
howling, lair) that are relevant to the meaning of the            Keane (2003b) have shown that even when word frequency
sentence pair will remain activated. In short, sentences with     and appropriateness are controlled for, people are slower to
a small distributional overlap generally have less                read and judge the plausibility of a sentence that has a large
information to suppress than sentences with a large               distributional overlap with its predecessor than a sentence
distributional overlap. This means that pair (i) has greater      that has little or no overlap. PAM models this effect by the
word-coherence than pair (ii) because it has a smaller            use of a model of linguistic distributional knowledge, Latent
overlap, and less of the activated distributional information     Semantic Analysis (LSA: Landauer & Dumais, 1997)2.
has to be suppressed.                                                 PAM uses LSA to calculate the 50 nearest neighbouring
  Connell and Keane (2003b) have shown that word-                 words for each sentence in the pair3, and counts the number
coherence measured in this way, has an effect on                  of common terms between the neighbourhoods (i.e., the
plausibility. They found that the greater the word-coherence      sentence overlap). This number represents the amount of
of sentence-pairs, the faster people are to read them and to      distributional information shared by the two sentences.
judge their plausibility. So, word-coherence has an effect on     PAM then uses LSA to calculate the 50 nearest neighbours
plausibility, albeit weaker than that of concept-coherence.       of the sentence pair as a whole, and removes these terms
                                                                  from the sentence overlap. What is left is the information
              Plausibility Analysis Model                         that must be suppressed, and is shown as the shaded area in
Given this recent evidence, the challenge for a cognitive         Figure 1. This suppressed information is used by PAM as a
model of plausibility is to capture the combined effects of       downward-scaling variable in estimating the plausibility
concept- and word-coherence. In the remainder of this             rating. In general, the larger the distributional overlap of
paper, we describe just such a model, the Plausibility            two sentences, the greater the amount of suppressible
Analysis Model (PAM). PAM takes sentence inputs and               information and the lower the plausibility rating will be.
outputs a plausibility rating for the scenario described in the       However, distributional information on its own does not
sentences. PAM judges plausibility using a combination of         provide adequate knowledge to judge a sentence pair’s
commonsense reasoning (for concept-coherence) and                 plausibility. Regardless of their degree of distributional
distributional analysis (for word-coherence). At present,
PAM specifically deals with the sentences from Connell and        2
                                                                    It is important to note here that we do not regard LSA as a model
Keane's studies though it can easily be extended, with            of meaning (c.f. Glenberg & Robertson, 2000), but rather as a
further knowledge, to other inputs.                               model of a particular form of linguistic knowledge that reflects the
  PAM has two phases, as shown in Figure 2. The                   distributional relationships between words.
                                                                  3
Comprehension phase models the word-coherence effect by              The LSA analyses were done in the ‘General Reading up to 1st
using distributional analysis, and the Assessment phase           Year College’ semantic space, with pseudodoc comparison at
models the concept-coherence effect by reasoning out a            maximum factors. In order to exclude misspellings and other very
scenario and rating its plausibility.                             low frequency words, and to maximize the sensitivity of PAM, any
                                                                  words with a corpus frequency of less than 10 were excluded.
                                                              266

overlap, the sentences must be conceptually analyzed to
judge whether the events described are plausible or not.
This is the task of the Assessment phase.
                                        1 −
                                                 1     2
                                              L + 1 
           plausibility = 10 ×  1 −                   
                                       P − H + 1 
                                  
                                                      
        Figure 3: PAM’s formula for plausibility ratings
Assessment Phase
PAM analyses the sentence pair by breaking it down into
propositional form and checking if its selection restrictions
are confirmed by its knowledge-base. To start, the concept-
coherence of the first sentence in the pair is examined. For
example, the sentence [The pack saw the fox] is transformed
into propositional form as see(pack, fox) and the
selection restrictions for its arguments are checked. The first
argument requires that something be an animal in order to
see – a pack contains dogs, and dog is an animal, so that
                                                                        Figure 4: Graph of PAM’s plausibility rating function
requirement is met. The second argument requires that
something that must be a non-abstract entity in order to be
seen – a fox is an animal, and animals are non-abstract            asymptotic function of Figure 3. In short, a high number of
entities, so that requirement is met. The way in which each        paths (P) means higher plausibility, because there are more
requirement is met is listed, and if all selection restrictions    possible ways that the sentence can be verified. A high
are fulfilled PAM returns this list as a path of verification.     mean path length (L) means lower plausibility, because
If a path is found, it means that the first sentence has been      elaborate requirements must be met to verify the sentence.
conceptually verified, and so PAM can move onto                    Finally, a high proportion of hypothetical paths (H) means
examining the second sentence.                                     lower plausibility, because it is assuming the existence of
   The sentence [The hounds growled] is the second                 entities that may not be there.
sentence of the pair. Again, PAM breaks it down into                  Figure 4 shows the boundaries of plausibility score that
propositional form as growl(hounds) and searches for               PAM generates for an increasing number of paths. The
different ways to verify its selection restrictions, noting the    dotted line represents the inner (lower) score boundary,
path taken each time. For example, growl(hounds)                   which is the worst-case situation where the mean path
may be verified via several different paths, such as the           length approaches infinity and every path is hypothetical.
hounds growling because hounds are generally aggressive,           The solid line represents the outer (upper) score boundary,
or because they are predators who have just encountered            where the mean path length is one and no path is
their prey (the fox of the first sentence), or because they are    hypothetical. For example, a set of four (non-hypothetical)
fighting amongst themselves, etc. It is likely that there are      paths with a mean length of three will have a rating of 7.2
many paths in the knowledge base that could be followed in         out of 10, while a set of three paths (again with a mean
order to verify this sentence, and PAM will note them all.         length of three) will have a rating of 6.6 out of 10. If one of
The final part of the Assessment phase involves using this         those three paths were a hypothetical path, then the score
set of paths to calculate a plausibility rating. To do this,       would drop to 6.3 out of 10.
PAM uses three different variables taken from the set of              When the path rating has been calculated, PAM then
paths (the exact formula used can be seen in Figure 3):            applies the scaling variable supplied by distributional
1. Total Number of Paths P (the number of different ways           knowledge in the Comprehension phase to represent the
     the sentence can be verified in the knowledge base)           carry-over effect that the effort of suppression has on
2. Mean Path Length L (the average count of how many               plausibility ratings. The scaling is of a lesser magnitude
     different requirements must be met per path)                  than that of the other variables in the model, but will still
3. Proportion of “Hypothetical” Paths H (proportion of all         have a perceptible effect. In this way, PAM models the
     paths that can only be followed by meeting a                  small difference in plausibility ratings found between
     requirement for something that is not explicitly              versions of sentence pairs that vary in their distributional
     mentioned – e.g. [The bottle fell off the shelf. The bottle   overlap but are conceptually identical.
     melted.] is considered a plausible path if we allow that
     the bottle may have fallen into a hypothetical furnace)                           Model Evaluation
The rating returned is between 0 (not plausible) and 10             PAM’s performance in plausibility ratings was compared to
(completely plausible), and is calculated according to the          human data. Using the sentence pair materials from Connell
                                                               267

                                                                 was very plausible).           The second experiment, that
                                                                 manipulated both concept- and word-coherence, presented
                                                                 two sentence pairs per page in the booklet, where one pair
                                                                 was the variant with the large distributional overlap and the
                                                                 other pair was the variant with the small distributional
                                                                 overlap. Again, participants were asked to judge the
                                                                 plausibility of both sentence pairs and rate them on two
                                                                 separate 10-point scales. For the purposes of this simulation,
                                                                 the mean plausibility rating of each sentence pair was used.
                                                                 The procedure for PAM was to enter each natural language
                                                                 sentence pair and note the output from the Assessment
                                                                 phase, which took the form of a rating of plausibility (0-10).
                                                                 Results & Discussion PAM returned plausibility ratings
                                                                 that were highly correlated with the human data from
                                                                 Connell and Keane (2003a), R=0.788, p<0.0001, N=60. A
                                                                 regression analysis confirmed that PAM’s output could be
                                                                 used to predict human performance in plausibility ratings,
                                                                 R2=0.621, p<0.0001. Figure 5 shows a scatterplot of the
                                                                 relationship between model output and participant means.
  Figure 5: PAM’s output against human plausibility ratings         PAM performed well for all four concept-coherence
                                                                 variants (causal, attributal, temporal and unrelated). Table 2
and Keane (2003a), the simulation produced plausibility          shows the means per inference type for Connell and Keane’s
ratings that were then compared to the human judgments.          data against PAM’s.
The test items used were a different subset of Connell and          We also altered PAM’s output to disregard the effect of
Keane’s materials than those used as PAM’s training items.       word-coherence in the Assessment phase, and compared this
  It is important to note here that although the simulations     to the human data. While we still found a significant
were performed with materials from Connell and Keane’s           correlation (R=0.779, p<0.0001), it was less than that found
papers, PAM was designed to be generalisable to any other        earlier and a regression analysis showed that PAM’s
input simply by extending the commonsense knowledge              performance had worsened by 1.4% without the word-
base. We will address this issue further in the general          coherence effect, R2=0.607, p<0.0001. This confirms that
discussion. Additionally, PAM’s knowledge base was built         word-coherence does indeed have a pertinent effect on
in a “blind” fashion. That is, the knowledge was simply          PAM’s plausibility ratings.
represented in local definitions of requirements, without
checking possible path lengths that might emerge or without        Table 2: Mean Plausibility ratings per inference type from
modifying the knowledge base to fit the data.                         PAM and Experiment 1, Connell and Keane (2003a)
Simulation                                                         Inference Type        Human Rating         PAM Rating
Materials Connell and Keane’s (2003a) materials were               Causal                       7.8                7.9
from two experiments, from which 60 sentence pairs were            Attributal                   5.5                5.7
                                                                   Temporal                     4.2                5.0
drawn as test items for the simulation. Of these, there were
                                                                   Unrelated                    2.0                0.9
a number of different variants of each sentence pair. For
example, some sentence pairs had variants manipulating
concept-coherence (e.g., causal inference [The bottle fell off                      General Discussion
the shelf. The bottle smashed.] versus unrelated inference       There are a number of novel achievements reported in this
[The bottle fell off the shelf. The bottle melted.]) while       paper. The Plausibility Analysis Model (PAM) is the first
others     manipulated      word-coherence     (e.g.,    large   computational model that specifically and accurately
distributional overlap [The pack saw the fox. The hounds         addresses human plausibility judgements. It does this by
growled.] versus small distributional overlap [The pack saw      using a number of innovative techniques to capture the
the fox. The hounds snarled.]).                                  complex influences that empirical work has shown to bear
                                                                 upon plausibility, namely the use of both commonsense
Procedure The procedures in the two psychological                knowledge and distributional knowledge.
experiments were slightly different. The first experiment,          PAM uses a commonsense knowledge base to assess
which manipulated just concept-coherence, presented each         concept-coherence. This assessment is based upon an
sentence pair on its own page in a booklet. Participants were    analysis of the requirements that must be met for a
then asked to judge the plausibility of the sentence pair and    proposition to be true. Many of these requirements are based
rate it on a 10-point scale (where 0 was implausible and 10      upon what is intuitively regarded as common sense. For
                                                             268

example, for an entity X to melt, one of the requirements is         Twenty-Fourth Annual Conference of the Cognitive
that X is currently solid. For X to be solid, there is a further     Science Society (p. 998). Hillsdale, NJ: Erlbaum.
requirement that X is non-abstract, and so on. In general,         Connell, L., & Keane, M. T. (2003a). What Plausibly
this precludes the use of figurative language in the sentence        Affects Plausibility? Concept-Coherence & Distributional
pairs that PAM takes as input, but it would be possible to           Word-Coherence As Factors Influencing Plausibility
build up such a requirements set for future versions.                Judgements. Manuscript in submission.
  In addition to concept-coherence, PAM also assesses              Connell, L., & Keane, M. T. (2003b). The effect of
word-coherence by using linguistic distributional                    distributional information on plausibility decision times.
knowledge. It does this through the use of Latent Semantic           Manuscript in preparation.
Analysis (LSA). However, rather than the conventional use          Costello, F., & Keane, M.T. (2000). Efficient Creativity:
                                                                     Constraints on conceptual combination. Cognitive
of LSA scores that represent the distance between points in
                                                                     Science, 24, 299-349.
a high-dimensional space (c.f. Kintsch, 2001; Landauer &
                                                                   French, R., & Labiouse, C. (2002). Four problems with
Dumais, 1997), we have taken the alternative approach of             extracting human semantics from large text corpora.
neighbourhood activation. By treating words and sentences            Proceedings of the Twenty-Fourth Annual Conference of
as activating only a certain area of distributional knowledge,       the Cognitive Science Society (pp. 316-321). Hillsdale,
we believe our implementation of a high-dimensional                  NJ; Erlbaum.
distributional space to have greater cognitive plausibility.       Gernsbacher, M. A., & Faust, M. (1991). The role of
  There is an interaction between commonsense knowledge              suppression in sentence comprehension. In G.B. Simpson
and distributional knowledge as shown in the empirical               (Ed.), Understanding word and sentence. Amsterdam:
work of Connell and Keane (2002; 2003a; 2003b). For a                North Holland.
considered plausibility rating, PAM models the interaction         Gernsbacher, M. A., & Robertson, R. R. W. (1995).
as sequential: the conceptual soundness of the situation is          Reading skill and suppression revisited. Psychological
fully explored and afterwards a lingering effect of                  Science, 6, 165-169.
distributional knowledge is applied. While the simulations         Glenberg, A. M., & Robertson, D. A. (2000). Symbol
were run with all available human data, it is our intention to       grounding and meaning: A comparison of high-
use PAM to create more sentence pairs and examine how its            dimensional and embodied theories of meaning. Journal
output predicts additional human plausibility ratings. It is         of Memory and Language, 43(3), 379-401.
also our intention to extend PAM to deal with other                Halpern, J. Y. (2001). Plausibility Measures: A General
discourse inputs, which will require only that the                   Approach for Representing Uncertainty. Proceedings of
commonsense knowledge base be extended accordingly.                  the Seventeenth International Joint Conference on
The     distributional    knowledge       accessed     in    the     Artificial Intelligence, (pp. 1474-1483). San Mateo, CA:
Comprehension phase need not be altered, as LSA already              Morgan Kaufmann.
deals with the full English language.                              Johnson-Laird, P.N. (1983). Mental Models. Cambridge:
                                                                     Cambridge University Press.
  PAM is the computational implementation of the
                                                                   Kintsch, W., (2001). Predication. Cognitive Science, 25,
plausibility theory put forward by Connell and Keane
                                                                     173-202.
(2003a; 2003b), and as such is the first model specifically of     Landauer, T. K. & Dumais, S. T., (1997). A solution to
human plausibility judgements.             Although still in         Plato's problem: The latent semantic analysis theory of
development, the simulations reported here demonstrate the           acquisition, induction and representation of knowledge.
importance and accuracy of PAM’s modeling techniques.                Psychological Review, 104, 211-240.
When people judge the plausibility of a scenario, they are         Lapata, M., McDonald, S., & Keller, F. (1999).
influenced both by the concept-coherence of the situation in         Determinants of adjective-noun plausibility. Proceedings
hand and by the word-coherence of the description they               of the 9th Conference of the European Chapter of the
have read or listened to. Any future models of human                 Association for Computational Linguistics, (pp. 30-36).
plausibility judgements must therefore take account of both          San Mateo, CA: Morgan Kaufmann.
these factors, and implement conceptual and distributional         Lemaire, P. & Fayol, M. (1995). When plausibility
knowledge, and the interactions between them.                        judgments supersede fact retrieval: The example of the
                                                                     odd-even rule effect in simple arithmetic. Memory and
                    Acknowledgments                                  Cognition, 23, 34-48.
                                                                   Smith, E. E., Shafir, E., & Osherson, D. (1993). Similarity,
This work was funded in part by grant from the Irish                 plausibility, and judgments of probability. Cognition, 49,
Research Council for Science, Engineering and Technology.            67-96.
                                                                   Speer, S. R., & Clifton, C. (1998). Plausibility and argument
                         References                                  structure in sentence comprehension. Memory and
Collins, A., & Michalski, R. (1989). The logic of plausible          Cognition, 26(5), 965-978.
  reasoning: A core theory. Cognitive Science, 13, 1-49.           Zwaan, R.A., Magliano, J.P., & Graesser, A.C. (1995).
Connell, L., & Keane, M. T. (2002). The roots of                     Dimensions of situation-model construction in narrative
  plausibility: The role of coherence and distributional             comprehension. Journal of Experimental Psychology:
  knowledge in plausibility judgements. Proceedings of the           Learning, Memory, and Cognition, 21, 386-397.
                                                               269

