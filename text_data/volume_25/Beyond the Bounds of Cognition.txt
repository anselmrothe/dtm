UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Beyond the Bounds of Cognition

Permalink
https://escholarship.org/uc/item/37s2095c

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)

Authors
Susi, Tarja
Lindblom, Jessica
Ziemke, Tom

Publication Date
2003-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Beyond the Bounds of Cognition
Tarja Susi (tarja@ida.his.se)
Department of Computer Science, University of Skövde, Box 408
541 28 Skövde, Sweden

Jessica Lindblom (jessica@ida.his.se)
Department of Computer Science, University of Skövde, Box 408
541 28 Skövde, Sweden

Tom Ziemke (tom@ida.his.se)
Department of Computer Science, University of Skövde, Box 408
541 28 Skövde, Sweden

Abstract
One of the questions that frequently come up in
discussions of situated, embodied and distributed
cognition is where to draw the boundary between
cognisers and their environment. Adams and Aizawa
(2001) have recently formulated a critique of what they
consider a “radical view of tool use”, i.e., the view of
tools as part of the cognitive system. We analyse their
critique and show that much of what they consider
‘radical’ turns out to be compatible with what they
consider ‘common sense’. Hence, we argue that much of
the debate boils down to a disagreement over different
uses of the term ‘cognitive’, whereas there is growing
agreement about the central role that agent-environment
interaction in general, and tool use in particular, play in
cognitive processes. We therefore suggest to drop the
‘bounds of cognition’ debate, and conclude by raising
what we consider more important questions in the study
of cognitive tool use.

Introduction
The question exactly where to draw the boundary
between a cognitive system and its environment is as
old as the study of mind itself. Polanyi (1964) and
Bateson (1972) illustrated the question with the now
classical example of a blind man using a stick, and
asked what the bounds of the blind man’s system are.
More specifically, does it or does it not include the
stick? Another classical example, that of the knot in the
handkerchief, comes from Vygotsky (1978), who
argued that the knot serves as a reminder that changes
the psychological structure of the memory process, and
it extends the operation of memory “beyond the
biological dimensions of the human nervous system”
(ibid., p. 39). Vygotsky emphasised in particular the
role of cultural artefacts in both evolutionary and
individual development, elaborating that in “[t]he use of
notched sticks and knots, the beginnings of writing and
simple memory aids all demonstrate that even at early

1134

stages of historical development humans went beyond
the limits of the psychological functions given to them
by nature and proceeded to a new culturally-elaborated
organization of their behavior” (ibid. p. 39).
The question of the bounds of cognition received
somewhat less attention during the first decades of
cognitive science, which predominantly equated
cognition with internal computational processes
implemented by the brain and paid relatively little
attention to the interaction of agents and environment.
The question is currently going through a certain
revival triggered by increasing interest in theories of
situated cognition (e.g., Clancey, 1997; Suchman,
1987), embodied cognition (e.g., Clark, 1997; Varela,
Thompson & Rosch, 1991) or distributed cognition
(e.g., Hutchins, 1995), all of which emphasise the close
coupling between agent and environment and its central
role in cognitive processes.
This shift in what is considered the appropriate unit
of analysis in the study of cognition has noticeably also
led to a corresponding shift in the use of the term
‘cognitive’. While the term traditionally has been used
mostly for internal processing, in the 1990s it started to
appear in expressions like “cognitive tools” or
“cognitive
artifacts”
(Norman,
1991,
1993).
Furthermore, several authors have started to
characterise the whole of humans and the technical
tools they use, e.g., a pilot interacting with the
instruments in her cockpit, or even a group of humans
interacting with each other and the instruments on the
bridge of a ship, as one ‘cognitive system’ (Hutchins,
1995) or as a “joint cognitive system” (Hollnagel, in
press).
Others consider this a “radical view of tool use”
(Adams & Aizawa, 2001), which blurs the distinction
between cognitive agents and the non-cognitive tools
they use (cf., for instance, Nardi, 1996; Neuman &
Bekerman, 2000). Perhaps most notable among these
critics are Adams and Aizawa (2001) who formulated a

manipulation so as to reduce the complex problem to a
sequence of simpler, pattern-completing steps that we
already command. On this model, then, it is the
combination of our biological computational profile with
the fundamentally different properties of a structured,
symbolic, external resource that is a key source of our
peculiar brand of cognitive success. The external
environment, actively structured by us, becomes a source
of cognition –enhancing ‘wideware’– external items
(devices, media, notations) that scaffold and complement
(but usually do not replicate) biological modes of
computation and processing, creating extended cognitive
systems whose computational profiles are quite different
from those of the isolated brain” (Clark, 1999, p. 349,
original emphasis).

detailed critique of several theories they consider guilty
of going too far in blurring that distinction (Clark &
Chalmers, 1998; Dennett, 1996; Donald, 1991;
Hutchins, 1995). They defend a ‘common sense’ view,
which they refer to as ‘intracranialism’, considering
cognition as “restricted to the confines of our brains”
(Adams & Aizawa, 2001, p. 44).
We will here argue that Adams and Aizawa, as well
as other critics arguing along similar lines, might be
tilting at windmills, since most of the views that they
describe as ‘radical’ are in fact highly compatible with
what they consider as ‘common sense’.

The Bounds of Cognition
It is commonly agreed that humans use calculators, road
signs, notes, calendars, computers, pen and paper, and
even other people as external resources and as a way
around the limitations of their own cognitive capacities.
In other words, as Clark (1997, p. 68) formulated it, we
“call on external resources to perform specific
computational tasks”1 and thus depend on cultural
artefacts to “augment and enhance biological cognition”
(Clark, 1999, p. 350).
Consider, for example, the use of Scrabble tiles
(Clark, 1997; Clark & Chalmers, 1998; Kirsh, 1997;
Kirsh & Maglio, 1994). As described by Clark (1997),
the tiles are physically ordered and re-ordered during
play, thereby prompting our own on-line neural
resources. We manipulate the tiles externally and
thereby create a variety of fragmentary inputs (new
letter strings) capable of prompting the recall of whole
words from the pattern-completing resource. It seems
that our own biological resources do not easily provide
for this kind of manipulations, which might therefore be
considered as a set of operational capacities that emerge
from the interaction between brain and world. That
means, through the flexible use of environmental
resources we enhance or augment our own cognitive
abilities – we use such resources as scaffolds. The
Scrabble tiles, for instance, scaffold our thinking, and,
thus in a very real sense it can be said that “the rearrangement of tiles on the tray is not part of action; it
is part of thought” (Clark & Chalmers, 1998).
Consider a second example, provided by Clark
(1999):
“Most of us, armed with pen and paper, can … solve
multiplication problems that would baffle our unaided
brains. In so doing we create external symbols
(numerical inscriptions) and use external storage and

The general point of both these examples, that
cognitive processes can be complemented, augmented
and transformed by environmental scaffolds, in
particular the use of tools, is relatively uncontroversial.
Adams and Aizawa’s critique, however, is directed at
the idea of the environment as a “source of cognition”
and the characterisation of agent and environment as an
“extended cognitive system”. According to them,
“common sense has it that our cognitive faculties,
restricted to the confines of our brains, can be aided in
any manner of ways, by cleverly designed noncognitive tools” (Adams & Aizawa, 2001, p. 44,
emphases added). That means, they agree that the
coupling of internal cognitive processes with the
environment can augment those processes, but they
maintain that coupling “of some process with a broader
environment … [does not] extend that process into the
broader environment” (ibid, p. 56). However, despite a
certain disagreement over the use of the term
‘cognitive’, Adams and Aizawa’s position is highly
compatible with, for example, that of Norman (1991,
1993). Norman used the term ‘cognitive tools’ for tools
that enhance human cognitive abilities, and never
intended it to refer to tools literally having any of the
cognitive processes or abilities that humans are
endowed with. Considering processes as extending into
the broader environment is not necessarily the same as
saying that the environment, or some part of it, actually
comes to have human-like cognitive processes or
capacities itself.
However, Clark and Chalmers (1998) who referred to
their view of the extended mind as an “active
externalism” 2 , argued that this is not just a matter of
terminology, but much more a matter of methodology:
“… in seeing cognition as extended one is not merely
making a terminological decision; it makes a significant
difference to the methodology of scientific investigation.
In effect, explanatory methods that might once have been
thought appropriate only for the analysis of ‘inner’
processes are now being adapted for the study of the

1

Adams and Aizawa, as well as several of the authors they
criticise, refer to cognitive and brain processes as
‘computational’. This is, of course, not uncontroversial (cf.,
e.g., Clark, 1997), but the reader should not get distracted by
this; the discussion in this paper is relatively independent of
whether ‘computation’ is the appropriate term in all cases.

1135

2

To be distinguished from the ‘passive’ externalism of, e.g.,
Putnam (1975) and Burge (1979).

outer, and there is promise that our understanding will
become richer for it” (Clark & Chalmers, 1998).

Concrete examples of extending the application of
traditional cognitive scientific methods and terminology
from ‘inner’ to ‘outer’ processes can be found in
Hutchins’ (1995) work on distributed cognition.
Hutchins is concerned with cognition at a ‘higher’ level,
such as team performance in ship navigation, i.e. interindividual rather than intra-individual cognition.
Analysing ship navigation, Hutchins (1995) showed
how multiple embodied biological brains combine with
tools (sextants, alidades, etc.), and media (maps, charts,
etc.) during performance. The artefacts allow the human
users “to do the tasks that need to be done while doing
the kinds of things people are good at: recognizing
patterns, modeling simple dynamics of the world, and
manipulating objects in the environment” (ibid., p.
155).
In this type of analysis, Hutchins, as he pointed out
himself, deliberately applied “the principal metaphor of
cognitive science – cognition as computation – to the
operation of this system” (ibid., p. 49). Adams and
Aizawa (2001), however, argue that in doing so
Hutchins “threatens to depart from common sense,
toward Dennett’s radical transcranial cognition” (ibid,
p. 45), because “[i]f cognition is simply computation
over representational states, and if one’s tools, such as
paper and pencil, form or contain representations, then
one has a case for the radical view that, in at least some
cases of tool use, cognition extends beyond the
boundary of the brain” (ibid, p. 46). In Adams and
Aizawa’s view,
“… the kinds of computational processes we find
operating over external representations, such as marks on
a piece of paper … will turn out to differ from the kinds
of computational processes that we find operating over
representations in brains. Compare the intracranial
computation of the product of 347 and 957 from the
computation of this product with pencil and paper. We
may assume that there are computational processes at
work in both cases, but that these computational
processes are different. In particular, the internal
processes are cognitive computational processes, where
only some of the computational processes in the
transcranial cases are cognitive. In particular, it will be
only the internal portions of the transcranial computation
that turn out to be cognitive” (Adams & Aizawa, 2001, p.
59).

They further argue that it is ”obvious” that brain
processes are ”causally distinct” from the processes
involved in tool use, such as ”moving beads up and
down on rods in an abacus, or pressing buttons on an
electronic calculator” (Adams & Aizawa, 2001, p. 44).
A similar critique was formulated by Nardi (1996)
who argued that the conceptual framework of
distributed cognition
“… views people and things as conceptually equivalent;
people and artifacts are ‘agents’ in a system. This is

1136

similar to traditional cognitive science, except that the
scope of the system has been widened to include a
collaborating set of artifacts and people rather than the
narrow ‘man-machine’ dyad of cognitive science …
Treating each node in a system as an ‘agent’ … leads to
a problematic view of cognition. We find in distributed
cognition the somewhat illogical notion that artifacts are
cognizing entities. Flor and Hutchins (1991) speak of
‘the propagation of knowledge between different
individuals and artifacts’. But an artefact cannot know
anything; it serves as a medium of knowledge for a
human” (Nardi, 1996, pp. 86-87).

It should be noted that while Adams and Aizawa as
well as Nardi might very well be right about the
differences between human and machine ‘computation’
or ‘information processing’, their criticisms are
nevertheless misguided in the sense that none of the
criticised authors actually denied those differences. As
the reader might have noticed in the above quotes,
Clark (1999), for example, also referred to biological
computation and external resources as “fundamentally
different”. Furthermore, he made it clear that he views
the environment as a “source of cognition”, but only in
the sense that it complements, rather than replicates,
biological computation and processing. Similarly,
Hutchins (1995) explicitly pointed out that he uses the
notion “cognition as computation” as a “metaphor” in
the description of distributed cognitive systems, and he
never denied the differences between intra-individual
and inter-individual cognitive processes. Hence, much
of what Adams and Aizawa (2001) characterise as a
“radical view of tool use” turns out to be less radical
than it might seem at first.
The same applies to Adams and Aizawa’s critique of
Donald (1991), whose view they consider “in many
respects ... the same as Dennett’s and Clark and
Chalmers’” (p. 45). Donald’s theory is concerned with
‘exograms’, or external representations, and the way
they have impacted, in the course of evolution, the
architecture of human cognition, allowing to off-load
biological memory. Donald claims that “[t]he exis tence
of exograms eventually changed the role of biological
memory in several ways”. While the first two
evolutionary transitions increased the load on biological
memory, “the final step in this tremendous cognitive
expansion might have reduced the load on some aspects
of biological memory, by gradually shifting many
storage tasks onto the newly developed ESS [external
symbol storage]” (Donald, 1991, p. 320, original
emphasis).
According to Adams and Aizawa (2001), Donald
implicitly refers to psychological laws of human
memory and those will not generally hold for external
memory storage. However, in Donald’s (1991)
description the biological and the external are two quite
different things: while engrams refer to single entries in
the biological memory system, exograms refer to single

entries in the ESS, and are considered external memory
records of ideas. Even though both engrams and
exograms are described in similar terms, exograms do
not become biological, not even ‘implicitly’. In fact,
Donald notes that systems of exogram storage are much
more flexible than engrams and thus a symbolic
information environment frees us from wholly
depending on biological memory. He therefore
concludes that a “cognitive system containing exograms
will have very different memory properties from a
purely biological system” (Donald, 1991, p. 315).
Obviously, this is much in line with Clark’s (1999)
aforementioned argument that extended cognitive
systems of biological brains and external resources
perform very differently than the ‘naked brain’ on its
own. However, neither Donald nor Clark argue that
hooking the biological system to external resources
transforms the external into biologically cognitive
entities, but in fact both are careful to point out the
fundamental differences.
Bateson (1972), in the example of the blind man
using a stick, argued that questions concerning whether
a mental system is bounded by skin or skull, whether
artefacts should be included or not, and so on, are in
fact “nonsense questions”. Polanyi (1964) argued that
“The way we use a hammer or a blind man uses his stick,
shows in fact that in both cases we shift outwards the
points at which we make contact with the things that we
observe as objects outside ourselves. While we rely on a
tool or a probe, these are not handled as external objects
… We pour ourselves out into them and assimilate them
as parts of our own existence.” (Polanyi, 1964, p. 59)

Similarly, Bateson described the blind man’s stick as
“a pathway along which transforms of difference are
being transmitted”, and “the way to delineate the
system is to draw the limiting line in such a way that
you do not cut any of these pathways in ways which
leave things inexplicable” (p. 465). Subsequently, the
boundaries of cognition, as well as the appropriate units
of analysis in the study of cognition, depend on what
we want to explain. Human activities, for the most part,
cannot be studied without considering things like the
artefacts we use. Neither can artefacts be studied in
isolation since in itself a tool is ‘nothing’ (Ingold,
2000). Hence it is only natural for cognitive scientists
interested in situated, embodied and distributed
cognition to choose as their units of analysis cognitive
agents in situ, i.e. embedded in their environments.
Whether or not such units of analysis should be referred
to as extended cognitive systems, and whether or not
the tools involved should be referred to as cognitive
artefacts, is only a secondary question. What is
important in the notion of ‘cognitive’ artefacts or
systems is the recognition of a close coupling between
the individual’s internal cognitive processes and the
outer world.

1137

Beyond the Bounds
The close coupling between the individual and the outer
world is realised through two major cultural mediators
in human cognition, namely tools and language
(Preston, 1998; Vygotsky, 1978). However, the role of
artefacts and tools have mainly been left unattended
while language, for instance, has received far more
attention (Preston, 1998; Wynn, 1991)3 . In language
research there is “a sophisticated body of theory on how
utterances are constructed. Nothing comparable exists
for tool behaviour … [t]here is almost no concern with
how tools are made and used and there are no welldeveloped theories of how sequences of tool-use are
constructed” (Wynn, 1993, p. 392). Others have also
pointed out that development and tool use is largely an
overlooked issue in cognitive development (e.g.,
Gauvain, 2001; Smitsman, 1997). However, artefacts
and tools have a similar role in cognitive processes as
that of language, “in particular they constitute the other
major form of cognitive mediation between individual
and world” (Preston, 1998, p. 514). Yet, we do not fully
understand the relation between cognition and artefacts,
and there are several unanswered questions. For
instance, how should we understand the concepts
‘artefact’ and ‘tool’? While both terms can be grappled
with intuitively (or folk-psychologically), there do not
seem to be any coherent definitions of them. A related
question, as pointed out by Preston (1998), concerns
what objects and behaviours should count as tools and
tool use, respectively.
For further development of theories concerning
artefacts and cognition we should attend, for instance,
research on tool making and tool use that has been
conducted in the field of primatology (e.g., Boesch &
Boesch 1993; McGrew, 1992; Taylor Parker, Mitchell
& Lyn Miles, 1999). According to Tomasello (2000),
human cognition is a particular form of primate
cognition, since many structures of human cognition are
identical with non-human primate cognition. Tomasello
(2000) therefore argues that the study of non-human
cognition can provide important information to
cognitive scientists . Research in ape-language has, for
instance, led to insights concerning the nature of
language that might have been overlooked had we only
focused on language in human children (e.g., SavageRumbaugh et al., 1998). Likewise, we might miss out
aspects of tool use unless we take into consideration
findings in the field of primate tool use. The other way
around, primatologists have attended findings in
cognitive science, e.g., by taking distributed cognition
as a framework for analysis of social interactions
3

In the field of AI, for example, there are thousands of papers
on AI models of language, but hardly any studies of AI
systems’ tool use (i.e. the use of tools by AI systems, rather
than the use of AI systems as tools).

among non-human primates (Forster, 2002; Johnson,
2001; Strum, Forster & Hutchins, 1997). Such crossfertilisation of areas (like cognitive science and
primatology) might be advantageous for both fields.
When it comes to artefacts in the context of human
activities, a lot of studies have focused on the individual
level and it is commonly recognised that
“… the inclusion of a tool in the process of behavior …
abolishes and makes unnecessary several natural
processes, whose work is accomplished by the tool; and
alters the course and individual features (the intensity,
duration, sequence, etc.) of all the mental processes that
enter into the composition of the instrumental act,
replacing some functions with others (i.e., it re-creates
and reorganizes the whole structure of behavior just as a
technical tool re-creates the whole structure of labor
operations)” (Vygotsky, 1981, pp. 139-140, in Cole &
Wertsch, 1996).

However, we need to consider the role of artefacts
beyond the level of the individual - the question is, what
kind of replacements do artefacts cause at a multiindividual level? We know that artefacts provide, e.g.,
an external means for organising cooperative behaviour
(Hutchins, 1995; Susi & Ziemke, 2001), but how do
artefacts effect cognition in shared activities?
Distributed cognition clearly has taken a step towards
explaining cognition at the multi-individual level.
However, further work is needed in order to understand
the role of artefacts in ‘higher’ level cognition.

Conclusions
Should the bounds of cognition be drawn so as to
include the artefacts we use? From the classical
information processing view of cognition the answer is
clearly ‘no’: cognition takes place solely within the
boundaries of the brain. From a situated view of
cognition, however, quite a different picture emerges:
cognition is not purely what goes on inside the brain.
Rather, cognition emerges from the interaction between
brain, body and the environment (Clark, 1997), and in
order to understand cognition, the units of analysis in
cognitive studies need to be extended to include
external resources brought into our activities. In
addition, we need to take notice of findings in other
fields of research, such as primatology, to a greater
extent than presently done. As shown in this paper, the
inclusion of artefacts as part of ext ended cognitive
systems does not necessarily lead to illogical or absurd
assumptions of artefacts coming to have human
cognitive processes or abilities, as some have argued. It
could therefore be concluded that debating where to
draw the bounds of cognition to some extent simply is
‘much ado about nothing’. Where the boundary is
drawn is not the main issue – more importantly, we
need to attend the role of artefacts themselves in
cognition.

1138

References
Adams, F. & Aizawa, K. (2001) The Bounds of
Cognition. Philosophical Psychology, 14 (1), 43-64.
Bateson, G. (1972) Steps to an Ecology of Mind.
Northwale, New Jersey: Jason Aronson Inc.
Boesch, Ch. & Boesch, H. (1993) Diversity of Tool Use
and Tool-making in Wild Chimpanzees. In: A.
Berthelet & J. Chavaillon (Eds.) The Use of Tools by
Human and Non-human Primates. Oxford: Clarendon
Press.
Burge, T. (1979) Individualism and the Mental.
Midwest Studies in Philosophy, 4, 73-122.
Clancey, W. J. (1997) Situated Cognition: On Human
Knowledge and Computer Representations. New
York: Cambridge University Press.
Clark, A. (1997) Being There: Putting Brain, Body, and
World Together Again. Cambridge, Mass.: MIT
Press.
Clark, A. (1999) An Embodied Cognitive Science?
Trends in Cognitive Science, 3 (9), 345-351.
Clark, A. & Chalmers, D. (1998) The Extended Mind.
Analysis, 56, 10-23.
Cole, M. & Wertsch, J. (1996) Beyond the Individualsocial Antinomy in Discussions of Piaget and
Vygotsky. Human Development, 39 (5), 250-256.
Dennett, D. (1996) Kinds of Minds. New York, NY:
Basic Books.
Donald, M. (1991) Origins of the Modern Mind: Three
Stages in the Evolution of Culture and Cognition.
Cambridge, Mass.: Harvard University Press.
Flor, N. V. & Hutchins, E. (1991) Analyzing
Distributed Cognition in Software Teams: A Case
Study of Team Programming During Perfective
Software Maintenance. In: Empirical Studies of
Programmers: Fourth Workshop (pp. 36-64).
Forster, D. (2002) Consort Turnovers as Distributed
Cognition in Olive Baboons: A Systems Approach to
Mind. In: M. Bekoff, C. Allen & G. M. Burghardt
(Eds.) The Cognitive Animal: Empirical and
Theoretical Perspectives on Animal Cognition.
Cambridge, Mass.: MIT Press.
Gauvain, M. (2001) Cultural tools, social interaction
and the development of thinking. Human
Development, 44, 126-143.
Hendriks-Jansen, H. (1996) Catching Ourselves in the
Act: Situated Activity, Interactive Emergence,
Evolution, and Human Thought. Cambridge, Mass.:
The MIT Press.
Hirose, N. (2002) An Ecological Approach to
Embodiment and Cognition. Cognitive Systems
Research, 3, 289 – 299.
Hollnagel, E. (in press) Cognition as Control: A
Pragmatic Approach to the Modelling of Joint
Cognitive Systems. IEEE Transactions on Systems,
Man, and Cybernetics, to appear.
Hutchins, E. (1995) Cognition in the Wild. Cambridge,
MA: MIT Press.

Ingold, T. (2000) The Perception of the Environment:
Essays in Livelihood, Dwelling and Skill. London:
Routledge.
Johnson, C. M. (2001) Distributed Primate Cognition:
A Review. Animal Cognition,3 (4), 167-183.
Kirsh, D. (1995) The Intelligent Use of Space. Artificial
Intelligence, 73, 31-8.
Kirsh, D. (1996) Adapting the Environment Instead of
Oneself. Adaptive Behavior, 4 (3/4), 415-452.
Kirsh, D. & Maglio, P. (1994) On Distinguishing
Epistemic from Pragmatic Action. Cognitive Science,
18 (4), 513-549.
McGrew, W.C. (1992) Chimpanzee Material Culture:
Implications for Human Evolution. Cambridge:
University Press.
Nardi, B. (1996) Context and Consciousness: Activity
Theory and Human-Computer Interaction. London:
MIT Press.
Neuman, Y. & Bekerman, Z. (2000) Where a Blind
Man Ends: Five Comments on Context, Artifacts and
the Boundaries of the Mind. Systems Research and
Behavioral Science, 17, 315 – 319.
Norman, D. (1991) Cognitive Artifacts. In: J.M. Carroll
(Ed.) Designing Interaction: Psychology at the
Human-Computer Interface (pp. 17-38). Cambridge:
Cambridge University Press.
Norman, D. (1993) Things That Make us Smart:
Defending Human Attributes in the Age of the
Machine. Cambridge, Mass.: Perseus Publishing.
Polanyi, M. (1964) Personal knowledge: Towards a
post-critical philosophy. New York: Harper
Torchbooks.
Preston, B. (1998) Cognition and Tool Use. Mind &
Language, 13 (4), 513 – 547.
Putnam, H. (1975) The Meaning of ‘Meaning’. In: K.
Gunderson (Ed.) Language, Mind, and Knowledge.
Minneapolis : University of Minnesota Press.
Smitsman, A.W. (1997) The Development of Tool Use:
Changing Boundaries Between Organism and
Environment. In: C. Dent-Read & P. ZukowGoldring
(Eds.)
Evolving
Explanations
of
Development. Washington: American Psychological
Association.
Strum, S. C., Forster, D. & Hutchins, E. (1997) Why
Machiavellian Intelligence may not be Machiavellian.
In: A. Whiten & R. Byrne (Eds.) Machiavellian
Intelligence II: Extensions and Evaluations (pp. 5085). Cambridge: Cambridge University Press.
Suchman, L. A. (1987) Plans and Situated Actions: The
Problem of Human-Machine Communication. New
York: Cambridge University Press.
Susi, T. & Ziemke, T. (2001) Social Cognition,
Artefacts, and Stigmergy: A Comparative Analysis of
Theoretical Frameworks for the Understanding of
Artefact-mediated Collaborative Activity. Cognitive
Systems Research, 2 (4), 273-290.
Taylor Parker, S., Mitchell, R.W. & Lyn Miles, H.
(1999) The Mentalities of Gorillas and Orangutans:

1139

Comparative Perspectives. Cambridge: Cambridge
University Press.
Tomasello, M. (1999) The Cultural Origin of Human
Cognition. Cambridge, MA: Harvard University
Press.
Tomasello, M. (2000) Primate Cognition: Introduction
to the Issue. Cognitive Science, 24 (3), 351-361.
Varela, F. J., Thompson, E. and Rosch, E. (1991) The
Embodied Mind: Cognitive Science and Human
Experience. Cambridge, MA: MIT Press.
Vygotsky, L.S. (1977) The Development of Higher
Psychological Functions. Soviet Psychology, 16, 6073.
Vygotsky, L.S. (1978) Mind in Society: The
Development of Higher Psychological Processes.
Cambridge, Mass.: Harvard University Press.
Wynn, T. (1993) Layers of Thinking in Tool Behavior.
In: K.R. Gibson & T. Ingold (Eds.) Tools, Language
and Cognition in Human Evolution. Cambridge:
Cambridge University Press.

