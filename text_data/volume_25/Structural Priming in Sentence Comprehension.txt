UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Structural Priming in Sentence Comprehension

Permalink
https://escholarship.org/uc/item/1z4557g1

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)

Authors
Harrington, Michael
Dennis, Simon

Publication Date
2003-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Structural Priming in Sentence Comprehension
Michael Harrington (m.harrington@uq.edu.au)
Linguistics Program, School of English, University of Queensland
Brisbane, Queensland 4072, AUSTRALIA

Simon Dennis (Simon.Dennis@colorado.edu)
Institute of Cognitive Science, University of Colorado
Boulder, Co 80301 USA
of the trace stored when processing the prime in a particular
context facilitates subsequent processing in similar contexts.
Pickering and others (Pickering & Branigan, 1999) have
argued against a data-driven approach to structural priming
on the grounds that the prime and target sentences can be
very different and in particular need not have substantial
lexical overlap. In this paper we present and test the
Syntagmatic-Paradigmatic Model (Dennis, submitted), a
distributed instance-based model of processing that captures
structural priming effects without recourse to abstract
structural information.

Abstract
Structural priming in sentence production has long been
observed, but the nature of the information that mediates
priming and the conditions under which it occurs remain open
questions. This study presents a data driven account of
structural priming that addresses both issues in sentence
comprehension. Evidence from an on-line English reading
task by first and second language readers showed priming for
the latter, suggesting that priming may occur where there are
insufficient sentence traces in memory to support sentence
interpretation. The empirical results are simulated using the
Syntagmatic Paradigmatic (SP) model, a distributed, instancebased account of sentence comprehension.

Introduction
Structural priming is the tendency to unconsciously
generalize recently spoken or heard syntactic structures to
subsequent sentences (Bock & Loebell, 1990; Pickering &
Branigan, 1999). Priming arises even in cases where the
following sentence shares neither lexical nor thematic
content with the previous one e.g. The 747 was landing by
the airport’s control tower will prime The man is being
stung by the bee, despite the by phrase in the first sentence
being an adjunct prepositional phrase and the by phrase in
the second heading a passive (Bock & Loebell, 1990).
Structural priming is generally assumed to involve the
persistent activation of structural information previously
employed in processing. However, significant questions
remain concerning the nature of this information and the
conditions under which it is used. The consensus view is
that priming is mediated by information regarding surface
form configurations (Bock & Loebell, 1990; Pickering,
Branigan, Cleland & Stewart, 2000; Chang, Dell, Bock, &
Griffin, 2000). Pickering and colleagues maintain that
priming results from lasting activation of verb
subcategorization information (Pickering & Branigan, 1998;
Pickering, et al., 2000). This information is represented as a
distinct level of lexical representation that is independent of
specific lexico-syntactic processes like thematic relations
and tense (see Chang, et al., 2000 for a similar approach
using alternative formalisms).
In this paper we consider a more parsimonious alternative;
namely, that structural priming occurs because the prime
and target structures occur within the same context. The part

510

Another important question concerns the conditions that
give rise to structural priming. Pickering & Branigan (1999)
have suggested limited resource availability as a
determinant of priming, with priming more likely when
resources are limited. The distributed instance-based model
proposed here makes similar predictions. An individual with
fewer linguistic resources may be more likely to make use
of available primed structures in subsequent production.
Alternatively, experienced individuals may have stored
more instances of sentences of the appropriate structural
form prior to the priming trial. These previous instances
may serve to reduce the impact of the prime sentence as a
consequence of the retrieval based processing assumed in
the model.
In this study we examine both representation and condition
issues by examining structural priming in an on-line reading
task that compares reading performance by first and second
language readers of English. If priming is sensitive to
resource availability then second language (L2) individuals
reading in the target L2 should show more priming than first
language (L1) individuals on the same comprehension task.
The empirical results will then be simulated using the
Syntagmatic-Paradigmatic Model in order to test the
assumptions of the data-driven approach to structural
priming. Although recent work argues for a unitary system
underlying comprehension and production, theory and
research has focused on production (Pickering et al., 2000;
Potter & Lombardi, 1998). The present study also extends
our understanding of priming in comprehension.

Overview of the Syntagmatic Paradigmatic
Model
The Syntagmatic Paradigmatic Model (SP; Dennis
submitted) is a distributed, instance-based model of verbal
cognition. depicts the SP model as it would appear when
exposed to the following mini corpus:
1.
2.
3.
4.
5.
6.
7.
8.

Note that as suggested above the set containing Mary, Ellen,
and Jody can be thought of as a representation of the
“lovee” role and the set containing John, Bert and Steve as
the “lover” role, so the trace is an extraction of the relational
information contained in the sentence. That is, the relational
trace captures a form of deep structure.

John loves Mary
Bert loves Ellen
Steve loves Jody
Who does Bert love ? Ellen
Who does Steve love? Jody
When the loud music started John left
When the race started Dave left
When the lecture started Michael left

Lexical LTM
John : Bert,Steve, Dave, Michael
Mary : Ellen, Jody
Bert : John, Steve
Ellen : Mary, Jody
Steve : John, Bert
Jody : Mary, Ellen
Loud : race, lecture
Race : loud, music, lecture

The SP model consists of three long-term memory systems,
lexical, sequential and relational, each of which is defined in
terms of syntagmatic and paradigmatic associations.
Syntagmatic associations are thought to exist between
words that often occur together, as in “run” and “fast¨. By
contrast, paradigmatic associations exist between words that
may not appear together but can appear in similar sentential
contexts, such as “run” and “walk” (Ervin-Tripp 1970).
Lexical memory consists of a trace for each word comprised
of the paradigmatic associates of that word across the
corpus. In the example, the lexical trace for John is {Bert,
Steve, Dave, Michael} because each of these words
substitutes for “John” in a sentential context. For “Bert” and
“Steve” the paradigmatic associations derive from the
simple active constructions in sentences two and three,
while for “Dave” and “Michael” the associations derive
from the more complicated clause initial constructions in
sentences seven and eight. In the lexical trace, however,
these associations are accumulated regardless of their origin.
Sequential memory consists of a trace for each sentence
comprised of the syntagmatic associations embodied by that
sentence. In the example, the sequential trace for the
sentence “John loves Mary” is the string of words, “John”,
“loves”, and “Mary”, in order.
Relational memory consists of a trace for each sentence. It is
comprised of the paradigmatic associations embodied by
that sentence. In the example, the relational trace for “John
loves Mary” would be {John: Bert, Steve; Mary: Ellen,
Jody}. Note that although the lexical and relational traces
both contain paradigmatic associations, the lexical trace is
accumulated over the entire corpus for an individual word
(e.g. in this corpus John is bound to the distributed pattern
containing Bert, Steve, Dave and Michael), while the
relational trace is a binding of the paradigmatic associations
of each of the words in a given sentence, so that within the
relational trace for “John loves Mary”, John is bound only
to Bert and Steve (not Dave or Michael).

511

Working Memory

Who [Who

]

Sequential LTM

does [ does

]

John [ Bert Steve

]

love [love

]

?

[?

]

John loves Mary
Bert loves Ellen
Steve loves Jody
Who does Bert love? Ellen
Who does Steve love? Jody
When the loud music started John left
When the race started Dave left
When the lecture started Michael left

#

[ Ellen Jody

]
Relational LTM
John : Bert, Steve
Mary : Ellen, Jody
Bert : John, Steve
Ellen : Mary, Jody
race: loud, music, lecture
Dave: John, Michael

Figure 1: The SP Model architecture.
In the SP model, sentence processing is characterized as the
retrieval of associative constraints from long-term memory
followed by the resolution of these constraints in working
memory. Creating an interpretation of a sentence/utterance
involves the following steps:
Sequential Retrieval: The current sequence of input words is
used to probe sequential memory for traces containing
similar sequences of words. In the example, traces four and
five; “Who does Bert love? Ellen” and “Who does Steve
love? Jody”; are the closest matches to the target sentence
“Who does John love? #” and are assigned high
probabilities:
0.499 who does bert love ? ellen
0.499 who does steve love ? jody
0.001 john loves mary …
In this simple example, the retrieved traces contain many of
the same words in the same order and consequently are the
best retrieval candidates. In general, however, lexical traces

are used to establish structural similarity even in the absence
of lexical overlap.
Sequential Resolution: The retrieved sequences are then
aligned with the target sentence to determine the appropriate
set of paradigmatic associates for each word. At this stage,
sentential context will affect the trace words that are aligned
with each of the input words:
who: who (0.997) /does: does (0.997) /john: steve (0.478)/
bert (0.478) / love: love (0.998) /?: ? (0.998) /#: jody (0.460)
/ellen (0.460)
The “#” symbol indicates an empty slot. Ultimately, it will
contain the answer to the question. The numbers in brackets
are probabilities associated with the words immediately
preceding them. Space precludes a description of how these
probabilities are calculated but a full exposition is available
in Dennis (submitted). Note that the slot adjacent to the “#”
symbol contains the pattern {Jody, Ellen}. This pattern
represents the role that the answer to the question must fill
(i.e. the answer is the lovee).
Relational Retrieval: The bindings of input words to the
corresponding sets of paradigmatic associates (the relational
representation of the target sentence) are then used to probe
relational long-term memory. In this case, trace one is
favoured as it involves the same role filler bindings as the
target sentence. That is, it contains a binding of John onto
the {Steve, Bert} pattern and it also contains the {Jody,
Ellen} pattern.
0.687
0.089
0.089

john: bert (0.298) steve (0.298)
mary: ellen (0.307) jody (0.307)
bert: steve (0.319) john (0.226)
ellen: jody (0.320) mary (0.235)
steve: bert (0.319) john (0.226)
jody: ellen (0.320) mary (0.235) …

Despite the fact that “John loves Mary” has a different
surface form than “Who does John love ? #” it contains
similar relational information and consequently has a high
retrieval probability.
Relational
Resolution:
Finally,
the
paradigmatic
associations in the retrieved relational traces are used to
update working memory:
who: who (0.997) / does: does (0.997) / john: john (0.500)/
steve (0.488) bert (0.488) /love: love (0.998)/ loves (0.153) /
?: ? (0.998) /#: mary (0.558) ellen (0.523) jody (0.523)
In the relational trace for “John loves Mary”, “Mary” is
bound to the {Ellen, Jody} pattern. Consequently, there is a
strong probability that “Mary” should align with the “#”
symbol which as a consequence of sequential retrieval is
also aligned with the {Ellen, Jody} pattern. Note that the
model has now answered the question - it was Mary who
was loved by John.
To summarize, the model hypothesizes four basic steps.
Firstly, the series of words in the target sentence is used to

512

retrieve traces that are similar from sequential long term
memory. Then, the retrieved sequential traces are aligned
with the input sentence to create a relational interpretation
of the sentence based on the word order. This interpretation
is then used to retrieve similar traces from relational long
term memory. Finally, working memory is updated to
reflect the paradigmatic constraints retrieved in the previous
step.
In a number of circumstances, it is necessary for the model
to be able to distinguish between traces that were stored in
the current context from those that are part of the
background memory of the system. Rather than propose a
separate memory system to store the recent traces, the SP
model assumes that these traces are more available because
they contain a representation of the current context. Rather
than try to provide explicit context processing mechanisms,
the model simply uses a symbol (CC, C1, C2, …) to
represent the appropriate context and otherwise treats these
symbols as if they were words. When a given retrieval probe
shares context with traces in memory the same context
symbol is used in each. In this paper, the contextual
mechanism will be used to capture the fact that the prime
and the target appear on the same trial and hence share
context. This treatment of context is somewhat arbitrary, but
is used here in lieu of a more comprehensive mechanism.

The Study
The study compares performance by English L1 and English
L2 readers on a self-paced, reading task. Subjects read
sentence pairs that were either matched or mismatched for
syntactic structure, but that always differed in lexical
content. Faster reading times in the critical region of the
second sentence in the congruent Matched pair (same
structures, different lexis) over the incongruent Mismatched
pair (different structures, different lexis) would represent
evidence for structural priming in comprehension. Evidence
is sought for priming for the Matched versus Mismatched
pairs across groups, and for greater priming evident in L2
participants. The findings are then simulated in the
Syntagmatic-Paradigmatic model.

Method
Participants Forty-two native English speakers (henceforth
L1) and 24 fluent speakers/readers of English as a second
language (L2) participated in the experiment. Both groups
were recruited from an introductory Linguistics course at an
Australian university and participated for course credit. The
L2 speakers were matriculated students at the university,
having a minimum of 6.5 on the IELTS test (550 TOEFL)
and most had been in the country for at least five months at
the time of the test. They were from different L1s.
Materials The stimuli set contained two kinds of syntactic
structures, questions involving Object Extraction (OE) and
Subject Extraction (SE) (Juffs & Harrington, 1995). Each
sentence was presented in either a Match condition, in
which both sentences were the same structure, or
Mismatched condition were one of each structure was

presented. Examples of the match and mismatch condition
are presented below.

participants, t = 5.59, p < .001 and for the L2 participants, t
= 8.09, p < .001.

Subject extraction sentences
Prime: Who did Ann believe likes Mary at the club?
Match: Who did Joe THINK saw Irene in the class?
Mismatch: Who did Joe THINK Irene saw in the class?

The key comparison is between reading times on the second
sentences as a function of the type of preceding sentence.
Reading time (in milliseconds) is the difference between the
first verb and the words in the following critical region. In
the moving window technique reading time per word tends
to increase as the reader moves from left to right. The
smaller the difference between the critical region and the
first verb, the greater the facilitation, or priming. Three
region values were calculated: Region 1 (First critical word
– 1st verb); Region 2 (average of first and second critical
words – 1st verb); and Region 3 (average of first, second and
third critical words – 1st verb). The averages are used
because the moving window is a fairly noisy procedure in
which the locus of processing effects is difficult to identify
precisely. Table 1 presents reading time differences between
first verb and the three region values.

Object extraction sentences
Prime: Who did Ann believe Mary likes at the club?
Match: Who did Joe THINK Irene saw at the club?
Mismatch: Who did Joe THINK saw Irene at the club?
The critical comparison is between the reading times in the
underlined regions in the Match and MisMatch sentences.
The region immediately following the first verb, where the
reader either encounters a proper noun (in the OE structure)
or another verb (in the SE structure) represents a point
where on-line processing decisions must be made, and
where structural priming may be evident. The 16 pairs
consisted of 32 sentences made up of different first verbs
and a following proper noun (OE) or 2nd verb (SE) that were
matched for frequency. The 32 sentences were randomly
assigned across structure and matching conditions for each
subject. The need to match for frequency meant that
particular verbs always appeared with a specific following
proper noun (in the OE sentences) or second verb (in the SE
sentences). Each subject saw 16 subject and 16 object
extraction sentences. Half the target sentences were
presented first and half presented second. Likewise, half the
pairs matched for syntactic structure and half did not. Each
subject saw the 16 test sentence pairs and 24 filler pairs in a
randomly ordered, 40-item set. The filler pairs consisted of
grammatical structures that differed from the test items.
Procedure Participants were tested in groups of 10-18 in a
computer lab. The sentences were presented on computer
using the standard self-paced moving window technique in
which a sentence was read by hitting a key to progress to
each subsequent word. After the first sentence was read it
disappeared from the screen and the second sentence read
using the same procedure. In order to focus attention on
global comprehension, subjects were then asked to give a
rating of relatedness for the pair. Each subject did five
practice sets of sentence structures, which were different
from those used in the experiment.

Results
For the L1 participants: L1 First sentence, M = 411 msec,
SD= 139 msec; L1 Second Sentence, M = 373 msec, SD=
110 msec, L1 Overall M = 392 msec, SD= 101 msec. For
the L2 participants: L2 First Sentence, M = 573 msec, SD=
233 msec; L2 Second Sentence, M = 459 msec, SD= 145
msec, L2 Overall M = 522 msec, SD= 156 msec. In general
the L1 participants read the sentences faster than their L2
counterparts. The 130 msec advantage in Overall M reading
time for the L1s was significant, t = 13.56, p < .001. In
addition, the second sentence was read significantly faster
across structure and match conditions for the L1

513

Table 1.
Reading time differences between first verb and the three
region values by Language (L1 versus L2), Structure
(Object Extraction versus Subject Extraction), and
Condition (Match versus Mismatch).
* Difference in milliseconds
Structure x Match 1st region
M SD
L1 OE Match
13
49
L1 OE Mismatch 22
46
L1 SE Match
24
52
L1 SE Mismatch
11
49
L2 OE Match
33
130
L2 OE Mismatch 69
283
L2 SE Match
16
117
L2 SE Mismatch
58
151

2nd region
M
SD
16
49
31
39
32
49
21
53
47
138
73
177
48
142
80
165

3rd region
M
SD
32
55
44
43
39
44
38
54
70
148
89
175
79
139
90
155

The key contrast is between the Match and Mismatch cells
in the respective structures and language. Lower difference
times in the Match cells are evidence for priming. For the
L1 subjects this pattern is evident in the OE sentences for all
three Regions, but the opposite pattern holds for the SE
sentences, though the differences are small in both cases.
For the L2 subjects the predicted pattern is evident for both
structures. Differences for the L2 subjects range from 42
msec between Matched and Mismatched SE sentences in
Region 1 to an 11 msec difference the same sentences in
Region 3.
The mean results by language and region were analyzed in a
two-way ANOVA with Structure (OE vs SE) and Condition
(Match vs. Mismatch) as within-subject factors. Because of
the difference in sample sizes (N = 42 L1 versus N = 24 L2),
language was not included as a between subjects variable in
the statistical analysis. Due to space limits only results that
were significant or approaching significance will be
presented. For the L1 subjects, there were no significant
main effects in either the Subject or the Item analyses. The
L1 subjects were not sensitive to differences in Structure or

Condition.
This was not the case for the L2 subjects.
Although there was no main effect evident for Structure, the
effects for Condition were significant or approaching
significance across all three regions. There was no
interaction of Structure and Condition in any of the regions.
In Region 1 there was a main effect for Matching on the
subject analysis F1 (1,23) = 7.07, p < .05, MSE = 5015, but
not for the Item Analysis F2 1,31)= .67, n. sg. MSE = 6012.
In Region 2 there was a reliable difference for both subject
and item analyses F1 (1,23)= 5.54, p < .05, MSE = 4281, F2
(1,31)= 7.19, p < .05 MSE = 5995. Both subject and item
analyses approached significance in Region 3: F1 (1,23)=
3.40, p = .078, MSE = 3216, F2 (1,31)= 3.34, p = .077,
MSE = 7113. There was a large amount of variability in the
L2 data, as is evident in the standard deviation values in the
Table 1 and the MSE values in the ANOVA. This
variability may come from the somewhat heterogenous
nature of the L2 sample. The L2 subjects represent a number
of L1s and, although in full-time academic study in an
Australian university, they may still differ in English
proficiency. Although the first verbs were randomly
assigned across structure and matching conditions, the need
to match for frequency meant that particular verbs always
appeared with a specific following proper noun (in the OE
sentences) or second verb (in the SE sentences). A finergrained analysis is needed to examine these specific
combinations.
In summary, the L1 subjects showed no significant
differences in reading times across Structure or more
importantly Condition. In contrast the L2 subjects did show
a reliable effect for Condition, with reading times on the
Matched sentences significantly faster than those on the
Mismatched sentences. In the next section we use the
Syntagmatic-Paradigmatic model to model these findings.

Modeling Structural Priming
The empirical findings can be interpreted as a consequence
of the retrieval based processing assumed in the model. An
individual with fewer linguistic resources may be more
likely to make use of available primed structures in
subsequent
production.
Alternatively,
experienced
individuals may have stored more instances of sentences of
the appropriate structural form prior to the priming trial.
These previous instances then serve to reduce the impact of
the prime sentence. To model these effects, the SP model
was exposed to the following corpus:
1.
2.
3.
4.
5.
6.
7.
8.

Joe saw Ellen .
Bill hurt Sarah .
Bert helped Kirsten .
What do you believe ?
What do you know ?
What do you feel ?
C1 Who did Ellen believe saw Bert ?
C2 Who did Sarah know Joe hurt ?

Traces one to six were added to allow the induction of
background knowledge on the substitution probabilities of

514

words. As a consequence of lexical training the model
learns the following substitution sets:
Joe, Bill and Bert
saw, hurt and helped
Ellen, Sarah and Kirsten
believe, know, feel
Note that lexical learning occurred only over the first six
traces and was conducted on the change probabilities only.
Traces seven and eight represent two different prime
situations. In context C1, the model has been given the
subject extraction prime “Who did Ellen believe saw Bert?”.
In context, C2 the model has been given object extraction
prime “Who did Sarah know Joe hurt?” Now can investigate
the response of the model as a consequence of presenting
the target subject extraction sentence “Who did Kirsten feel
helped Bill?” either in the congruent context C1 (see Figure
2A) or in the conflict context C2 (see Figure 2B).
A) Congruent Context for L2
c1: c1 (1.00) / who: who (1.00) / did: did (1.00)/ kirsten:
ellen (1.00) / feel: believe (1.00)/ helped: saw (1.00) /
bill: bert (1.00) / ?: ? (1.00)
B) Conflict Context for L2
c2: c2 (1.00) / who: who (1.00) / did: did (1.00)/Kirsten:
Sarah (1.00) feel: know (1.00) / helped: hurt (.48) Joe (.02) /
bill: Joe (.49)/ ?: ? (1.00)
Figure 2: Working memory following syntactic resolution
of the subject extraction sentence “Who did Kirsten feel
helped Bill?” in either the congruent (A) or conflict (B)
contexts.
Note that in the positions post the critical verb (i.e. the
helped and Bill positions) the substitution probabilities are
much lower in the conflict case than in the congruent case.
These lower substitution probabilities correspond to longer
reading times in the equivalent conditions and are also seen
when the object extraction version of the sentence is
presented (i.e. “Who did Kirsten feel Bill helped?”). To
understand why the SP model is producing these results it is
instructive to look at the traces that are returned during
sequential retrieval in each case. When the subject
extraction sentence is used as a probe in context C1, trace
seven “C1 Who did Ellen believe saw Bert?” is retrieved.
As this matches the structure of the probe there is no
ambiguity in the alignment. However, when the same probe
is used in context C2 it is trace eight that is retrieved.
Against trace eight there are two dominant alignments:
C1 Who
C2 Who
and
C1 Who
C2 Who

did Kirsten feel helped Bill -- ?
did Sarah
know
-Joe hurt ?
did Kirsten feel - helped Bill
did Sarah
know Joe hurt
--

?
?

These two possible alignments share probability mass and
hence create ambiguity in the critical region.
To simulate the L1 subjects, additional traces were added to
capture in a purely qualitative fashion their additional
language experience:
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

Joe saw Ellen .
Bill hurt Sarah .
Bert helped Kirsten.
Simon loves Alison.
Paul knew Nina.
What do you believe?
What do you know?
What do you feel?
What do you say?
What do you think?
CC Who did Nina say loves Simon?
CC Who did Alison think Paul knew?
C1 Who did Ellen believe saw Bert?
C2 Who did Sarah know Joe hurt?

Conclusions
Structural priming in comprehension was evident only for
the L2 participants, a finding consistent with a contextually
dependent retrieval explanation for why priming might
occur. The simulations showed that the distributed instancebased model of sentence processing presented here provides
a promising tool for modeling these effects. The findings
here also yield insight into structural priming in
comprehension, an area that has received comparatively
little attention in priming research.

Acknowledgments
This research was supported by Australian Research
Council grant A00106012, US National Science Foundation
grant EIA-0121201 and US Department of Education grant
R305G020027.

References

Four additional traces (4, 5, 9 & 10) have been added to
simulate additional general language experience necessary
for lexical training and two additional traces (11 & 12) have
been added to simulate past experience with the subject and
object extraction sentences specifically. Note that these
additional SE and OE questions have a neutral context
representation (CC). Figure 3 shows the response of the
model when presented with the subject extraction sentence
“Who did Kirsten feel helped Bill” in context C1 the
congruent context (see Figure 3A) and in context C2 the
conflict context (see Figure 3B).
A) Congruent Case for L1
c1: c1 (.65) cc (.35) / who: who (1.00) / did: did (1.00) /
Kirsten: Ellen (.65) Nina (.30) Alison (.05) / feel: believe
(.65) say (.30) think (.05) / helped: saw (.65) loves (.30)
Paul (.04) / Bill: Bert (.65) Simon (.30) knew (.04) / ?: ?
(1.00)
B) Conflict Case for L1
c2: cc (.80) c2 (.20) / who: who (1.00) / did: did (1.00) /
Kirsten: Nina (.69) Sarah (.20) Alison (.11) / feel: say (.69)
know (.20) think (.11) / helped: loves (.69) Paul (.10) hurt
(.10) / Bill: Simon (.69) knew (.10) Joe (.10) / ?: ? (1.00)
Figure 3: Working memory following syntactic resolution
of the subject extraction sentence “Who did Kirsten feel
helped Bill?” in either the congruent (A) or conflict (B)
contexts.
While there is still some priming in the L1 Conflict
simulation, it much reduced because now the background
traces representing the correct structure are retrieved and
participate in syntactic resolution.

515

Bock, J. K. & Loebell, H. (1990). Syntactic persistence in
language production. Cognition, 35, 1-39.
Chalnick, A., & Billman, D. (1988). Unsupervised learning
of correlational structure. Proceedings of the Tenth
Annual Conference of the Cognitive Science Society (pp.
510-516). Hillsdale, NJ: Lawrence Erlbaum Associates.
Chang, F., Dell, G., Bock, J. K. & Griffin, Z. M. (2000).
Structural priming as implicit learning: a comparison of
models
of
sentence
production.
Journal
of
Psycholinguistic Research, 29, 217-229.
Dennis, S. (submitted). A memory-based theory of verbal
cognition.
Feigenbaum, E. A. (1963). The simulation of verbal
learning behavior. In E. A. Feigenbaum & J. Feldman
(Eds.), Computers and thought. New York: McGraw-Hill.
Juffs, A., & Harrington, M. (1995). Parsing effects in L2
sentence processing: Subject and Object asymmetries in
WH-extraction. Studies in Second Language Acquisition,
17, 483-512
Hill, J. A. C. (1983). A computational model of language
acquisition in the two-year old. Cognition and Brain
Theory, 6, 287-317.
Lewis, C. (1978). Production system models of practice
effects. Doctoral dissertation, Department of Psychology,
University of Michigan, Ann Arbor.
Pickering, M. J., Branigan, H. P., Cleland, A. A. & Stewart,
A. J. (2000). Activation of syntactic information during
language production. Journal of Psycholinguistic
Research, 29, 205-216.
Pickering, M. J. &, Branigan, H. P. (1998). The
representation of verbs: Evidence from syntactic priming
in language production. Journal of Memory and
Language, 39, 633-651.
Pickering, M. J. &, Branigan, H. P. (1999). Syntactic
priming in language production. Trends in Cognitive
Sciences 3, 4, 136-141.
Shrager, J., & Langley, P. (Eds.) (1990). Computational
models of scientific discovery and theory formation.
San Mateo, CA: Morgan Kaufmann.

