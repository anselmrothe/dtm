UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Split Model to Deal with Semantic Anomalies in the Task of Word Prediction
Permalink
https://escholarship.org/uc/item/78s949t9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Author
Hsiao, Janet Hui-wen
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

          A Split Model to Deal with Semantic Anomalies in the Task of Word
                                                          Prediction
                                    Janet Hui-wen Hsiao (h.hsiao@sms.ed.ac.uk)
                                      Division of Informatics, University of Edinburgh
                                        2 Buccleuch Place, Edinburgh, EH8 9LW, UK
                           Abstract                               should be an edible noun. The task here is to deal with a
                                                                  subset of such sentences.
   On the task of predicting the range of possible next              Ideally, the connectionist network is expected to
   words in a sentence, many networks (e.g. Elman, 1990)          make syntactic predictions, instead of semantic
   that have been proposed are capable of displaying a
                                                                  predictions, for grammatically correct but semantically
   certain degree of systematicity, but fail in recognizing
   grammatically correct but semantically anomalous               anomalous sentences. If we train the network to
   sentences. Based on an expansion of Hadley’s model             generalize the input words more and recognize fewer
   (Hadley et al, 2001), I present a competitive network,         subcategories, it may not have the capacity to discover
   which employs two sub-networks that discern coarse-            all the semantic constraints. On the other hand, if we
   grained and fine-grained categories respectively, by           train the network to recognize more subcategories, it
   being trained via different parameter settings. Hence, one     will lose the information about general categories to
   of the sub-networks will have a greater capacity for           make syntactic predictions. Therefore, to train the
   recognizing the syntactic structure of the preceding           network with suitable parameters, which will enable the
   words, while the other will have a greater capacity for
                                                                  network to handle both situations well, is a challenging
   recognizing the semantic structure. This corresponds to
   the recent suggestion about specialization of the two          task.
   hemispheres in the human brain (Beeman, 1998). Also, a            Based on an expansion of Hadley’s work (2001), a
   mechanism to switch attention between the predictions          more challenging training corpus is created according to
   from the two sub-networks is employed in order to make         a set of semantic constraints. It is believed that humans
   the global network more closely approximate human              require both semantic and syntactic information to deal
   behavior. The results show that the network is able to         with semantic anomalies. So that when we encounter a
   deal with grammatically correct but semantically               semantically anomalous sentence such as “boys eat
   anomalous sentences.                                           rocks”, we can still recognize it as a grammatical
                                                                  sentence. Hence, a mechanism to learn information
                       Introduction                               from both general categories (e.g., noun) and
Since 1990, several cognitive scientists have                     subcategories (e.g., human noun) is required in the
concentrated on the capacity of connectionist networks            network design. A way to achieve this is to use two
to display systematicity in the task of predicting the            sub-networks which respectively learn information
range of possible next words in a sentence (e.g. Elman,           about categories and subcategories, by using different
1990, 1998; Christiansen and Chater, 1994; Hadley,                training parameter settings. It is assumed that a network
1994a, 1994b, 2001; Marcus, 1998; Phillips, 2000) 1 .             can recognize a grammatical sentence if a period is
Some also proposed networks which are able to                     predicted at the right place and if it can make
discover hierarchical semantic categories and predict             predictions according to correct English grammar. A
according to the semantic constraints they have                   failure to make substantial semantic predictions
acquired from contexts (e.g. Elman, 1990). However,               suggests that current input contains a novel semantic
the issue of the networks’ response to semantically               pattern that the network does not habitually encounter
anomalous sentences was barely addressed. By                      during training, i.e., a semantically anomalous sentence.
definition, semantic constraints are the semantic                 Moreover, during testing, a mechanism to coordinate
patterns we habitually encounter, and a semantically              the information exchange between the two sub-
anomalous sentence is a sentence containing semantic              networks is used in the hope that it will help the
patterns that violate the semantic nature of these                network make predictions close to human behavior.
semantic constraints. An example of semantically
anomalous sentences is “boys eat rocks”, which violates                             System Overview
the semantic constraint that the word following “eat”             The task of the network proposed here is to learn to
                                                                  predict semantic features of the next word, given a prior
                                                                  sequence of words. Words are taken from a pool of
1
  Or rather, we could say that the task of the network is to      sentences generated according to a simple syntax
“anticipate” the range of possible next words in a sentence.      displayed in Figure 1.
                                                              581

                                                             Hebbian-competitive networks (Hadley et al, 2001) are
S -> NP V NP .                                               put together side by side, sharing the same input layer,
NP -> N | N RC | N PP                                        and train them independently. Different parameter
N -> NOUN-HUM | NOUN-ANIM | NOUN-INANIM |                    settings are used in the two sub-networks to make the
NOUN-FOOD                                                    left sub-network recognize general categories (e.g. the
V -> VERB-EAT | VERB-PERC | VERB-TRAN |                      correct usage of English grammar) and the right sub-
VERB-STREN | VERB-HIT                                        network recognize sub-categories (e.g. human or
RC -> that V NP                                              inanimate nouns). This also corresponds with the recent
RC -> that N V                                               suggestion that the two hemispheres in the human brain
PP -> PREP NP                                                activate different breadth of semantic fields2 (Beeman,
                                                             1998).
 Figure 1: The grammar for generating training and test
                         sentences.                             Vocabulary        Presentation layer Vocabulary
   In our corpora, the vocabulary contains 16 nouns, 16         buffers                                  buffers
verbs, and 2 prepositions. All words have been
previously assigned semantic feature vectors with 60                      Gating nodes
                                                                Left-buffer                              Right-buffer
features taking binary values. A unit in the encoding of
a word is set to one if the word exhibits the feature, and                        Competitive cluster
zero otherwise. Among the 60 features, 23 features are
assigned to nouns, 21 are to verbs, and the remaining 16      Output
features are reserved for the words (1) “that”, (2) “with”,   layers
(3) “from”, and (4) the period “.”, which do not have           HL2
straightforward semantic information. These 16 features
are divided equally and assigned to the four words              HL1       A    B       C        A      B      C
above. They might be viewed as syntactic                                Input layer
representations (Hadley et al, 2001), since these four
words serve as function words, which are semantically                      Figure 3: Network architecture.
light and used to signal structure. The creation of
semantic features here is admittedly somewhat arbitrary.     Training Phase The training corpus contains 10,000
However, it has conveyed the general approach adopted        sentences. Half of the sentences in the training corpus
here. That is, if semantic features do exist in the human    are simple sentences with the form NOUN VERB
language acquisition mechanism, the proposed network         NOUN. 25% of the sentences contain a single
is able to provide a possible computational model for        prepositional phrase. The rest sentences contain one or
dealing with semantic anomalies.                             two relative clauses. During the training phase, 50,000
   The sentences in the training corpus are generated        sentences were randomly selected from the training
according to a set of semantic constraints: all the simple   corpus and presented to the network. The two sub-
sentences and all clauses of complex sentences must          networks are trained with the same algorithm and
fall into one of the semantic structures defined in the      winner selection rules as used in Hadley’s networks
semantic constraints. See Figure 2 for some examples.        (see Hadley et al, 2001), except that the links from HL2
                                                             to the output layer are trained via a reverse competitive
NOUN-HUM VERB-EAT NOUN-FOOD                                  learning algorithm, described below. In short, area A
NOUN-HUM VERB-EAT NOUN-FOOD with NOUN-                       has a post-training role of categorizing the input feature
HUMAN                                                        vectors into semantic groups. Area B and C store the
NOUN-HUM VERB-PERCEPT NOUN-INANIM                            previous successive contents of area A. The role of HL2
NOUN-HUM VERB-TRAN NOUN-HUM                                  is to be a higher order pattern recognizer to categorize
…                                                            the ternary patterns that appear in the three areas of
                                                             HL1. The output layer receives activation from HL2
       Figure 2: Examples of semantic constraints            and is trained to make semantic predictions of the next
                                                             word.
   Figure 3 shows the network architecture. The arrows
                                                                Also, the sum of the weights on all the links from
in the figure represent entire sets of links between two
                                                             each node in HL2 to the output layer is set to one, so
layers. Dotted arrows indicate trainable links. The
training of the network involves only the portion inside     2
the dotted square, referred to as the training network.        Taken from Beeman’s explanation, “the subset of semantic
The training network consists of four layers: an input       information activated in response to an input word is termed
                                                             the semantic field, a projective field comprising the set of
layer, a first hidden layer (HL1), a second hidden layer
                                                             internal representational units (semantic features) that are
(HL2), and an output layer. In short, two of Hadley’s        activated by an external input (a word)”.
                                                         582

that the total activation predicted in the output layer will  0.02, and a smaller constant c, 0.6, in the area A of the
also sum to one. Before training, the weights are             right sub-network, to make it form groups of sub-
distributed evenly on the outgoing links from each node       categories. (See Hadley et al, 2001 for the influence of
in HL2. The weight modification equation is:                  adopting different values for the parameters.)
                       cik
           ∆ω ij = g       − gwij                             Test Phase During testing, the two sub-networks take
                       nk                                     the same input, go through the same process as training,
   where i is the index of the output layer; j is the         except that no weight modification occurs, and input
current active node in HL2; nk is the number of active        words are presented only in the input layer. Sentences
nodes in the output layer; cik is equal to one if node i in   involving an anomalous combination of the agent, the
the output layer is active and 0 otherwise; g is the          action, or the patient, are created to examine the
learning rate. Notice that the modification equation          capacity of the network to deal with semantic anomalies.
resembles the one in the original competitive learning        An example of sentences with an anomalous
algorithm (von der Malsburg, 1973). It is actually a          combination of the agent and the action is “rocks eat
reverse competitive learning algorithm since the input        cookies”. Sentences such as “boys eat tables” involve
layer and the competitive cluster have been put upside        an anomalous combination of the action and the
down with respect to the original algorithm.                  patient.3
   The basic idea of this algorithm is that it takes a small     During the test phase, another mechanism to
amount of weight, decided by the learning rate, from all      orchestrate the interaction between the predictions from
links connected to inactive nodes in the output layer,        both sub-networks is placed on top of the original
and then redistributes the weight to the links connected      network (see Figure 1). Besides the training network,
to active nodes (see Figure 4). With this method, we          the test network also contains vocabulary buffers to
can strengthen the links between two active nodes and         store the semantic vectors of each word in the
weaken those between an active and an inactive node,          network’s vocabulary, a left-buffer to store a copy of
while keeping the sum of weights from any given node          the left output layer, a right-buffer to store a copy of the
in HL2 to the output layer to be equal to one. This           right output layer, a presentation layer to store the final
method actually preserves the basic idea of Hebbian           semantic predictions, and a competitive cluster of two
learning (Hebb, 1949). One of the advantages of using         gating nodes to gate the activation from the output
this algorithm over the simple Hebbian increment              layers to the presentation layer. The two sub-networks
model is that the sum of activation presented in the          will make predictions respectively and compete with
output layer will be restricted to one, instead of being      each other to present a result to the presentation layer
incremented without a limit. The assumption of this           through the competitive gating-node cluster.
design is that prior to training, every semantic feature
will be equally weakly predicted. If a node in HL2              Presentation layer
never wins during training, the weights on the links          Vocabulary buffer                    Vocabulary buffer
from this node to the output layer will never be changed.
Thus, every semantic feature in the output layer will
still have been equally weakly predicted.
                                                                Left-buffer                              Right-buffer
   Output                         Output
   Layer                          Layer                                       Competitive gating node
                                                                                        cluster
   HL2                            HL2                                   Left output layer     Right output layer
               Stage 1                        Stage 2
                                                                 Figure 5: The detailed structure on the top of the two
       Figure 4: Weight modification in the reverse                                  output layers.
              competitive learning algorithm.                    In the left sub-network, links from the left output
   The two sub-networks in the proposed network are           layer to the left-buffer, and from the left-buffer to the
trained independently with different parameter settings,      vocabulary buffer are all one-to-one copy links and
i.e. the learning rate and the constant c in the winner
selection rule (see Hadley et al, 2001). They then            3
                                                                Notice that a semantic anomaly, specifically defined in the
develop different weight configurations. A larger             models proposed here, is any sentence that violates the
learning rate, 0.5, and a larger constant c, 1.0, are used    semantic constraints used for generating the training corpus.
in the area A of the left sub-network, to make it form        For experimental purposes, the semantic constraints contain
groups of general categories, and a smaller learning rate,    some simplifying assumptions that admittedly are not always
                                                              in compliance with English semantics.
                                                          583

have weights of +1. On the other hand, links from the         whose predicted vector has greater coherence with the
left-buffer to the left gating node, and from the left        network’s vocabulary will be the one that has greater
gating node to the links between the right output layer       activation in total in its output layer buffer.
and the presentation layer, are fully connected. The             Recall that prior to training, every outgoing link from
same applies to the links in the right sub-network. The       a node in HL2 to the output layer is given an equal
vocabulary buffers, the left-buffer, the right-buffer, and    fractional weight. This equal fractional weight, if not
the presentation layer all have the same size as the          incremented during training, will later not be able to
output layers. Each node in the presentation layer is         generate activation above the reinforcement threshold
connected to the corresponding nodes in the output            and hence will not be reinforced. In other words, if any
layers of the two sub-networks, forming a ternary             node that has never been selected as a winning node
structure (see Figure 5). The left and right gating nodes     during training is later selected as the winner in HL2,
receive activation from the left-buffer and the right-        none of the features in the subsequently predicted
buffer, respectively. Each outgoing link of a gating          semantic vector will be reinforced. So, if the predictions
node serves as a modifier link to inhibit the activation      from the other sub-network have gained some
in the output layer of the opposite sub-network from          reinforcement, they will be eventually activated in the
going up to presentation layer.                               presentation layer.
   When predictions from both sub-networks are                   The competitive gating-node cluster manages
activated in the lowest output layers, the two sub-           predictions that will eventually be activated in the
networks will compete with each other according to            presentation layer between the two sub-networks. In the
their coherence with the network’s vocabulary.                initial state, the two gating nodes have the same high-
Coherence is a measure of similarity between the              level activation and inhibit the predictions from being
predicted vector and the various semantic vectors in the      activated in the presentation layer. Since the two sub-
network’s vocabulary. The more the predicted vector           networks have been trained with different parameter
resembles the preassigned semantic features of a certain      settings, the predictions in the output layers are also
word in the network’s vocabulary, the greater the             different. After the coherence reinforcement process is
degree of coherence it has. In other words, if the            performed, the two gating nodes will also receive
predicted vector covers a broad range of semantic             different activation values. Hence, the gating node that
features, and it is hard to tell which word the vector is     initially received less activation will cease its inhibition,
predicting, then that predicted vector will have less         and the predictions in the other output layer will be
coherence. The activation level of the predicted vectors      activated in the presentation layer. Notice that during
in the two output layers are boosted according to their       the coherence reinforcement process, only the
degree of coherence. The one with greater coherence           activation in the left-buffer and the right-buffer is
will be activated in the presentation layer. This process     reinforced. The original activation values in the output
is called coherence reinforcement process, and is             layers are still intact. Therefore, it is the original
explained in detail below.                                    activation in the output layer of the winning network
   After predictions are activated in the output layers,      that is spread up to the presentation layer.
the content of the left output layer is copied into the          The predictions are evaluated by calculating the
left-buffer, and the content of the right output layer is     cosine value of the angle between the predicted
copied into the right-buffer. Each word in the network’s      semantic vector and the semantic vector of each word in
vocabulary will be presented in the vocabulary buffer in      the vocabulary. The greater the cosine value is, the
turn. For each pair of nodes between the left-buffer and      closer the two vectors are, or in other words, the more
the vocabulary buffer, if either member of the pair has a     strongly the given word is predicted.
value below a predetermined reinforcement threshold, a
boost of activation will not occur. However, if both of                        Experimental Results
them have values above the threshold, a boost of              In the predictions of the right sub-network following an
activation, which is proportional to the square of the        anomalous combination of agent, action, or patient in a
activation value of the node in the left-buffer, will be      sentence, all features have equally weak activation as
added to the node in the left-buffer. Each word in the        their initial state. This suggests that a novel semantic-
vocabulary will be activated in the vocabulary buffer in      syntactic pattern that has never been seen during
turn and go through the same process 4 . The same             training is formed in HL1. Consequently, a node that
applies to the right-buffer in the right sub-network.         has never won during training is selected as the winner
After reinforcement is complete, the sub-network              in HL2, and the links from the winner to the output
                                                              layer have never been trained. The equally weak
4
  If there is indeed a process in the brain similar to the    activation on each feature reveals the network’s
coherence reinforcement process proposed here, this process   inability to make semantic predictions for the given
would be expected to occur in parallel.
                                                          584

input sentence. On the other hand, the left sub-network     in HL2 is then selected in each sub-network.
is still able to make predictions. Figure 6 shows           Theoretically, these patterns should have been seen
predictions from the left sub-network following an          during training, so a period will be predicted by both
anomalous sentence. It has the same distribution of         sub-networks. Thus, for normal sentences, both
predictions as the predictions for normal sentences with    networks should give good predictions.
a pattern “Noun Verb Noun”. The same predictions can          Output Layer
also be found in the presentation layer. This indicates
that the left sub-network wins the competition after the
                                                               HL2
coherence reinforcement process.
                                                               HL1
                                                                                            Noun-     Verb     Noun
                                                               Noun     Verb      Noun      Inanim    -Eat     -Hum
                                                               Input Layer             Rocks
                                                              Figure 8: The predictions when the current sentence is
                                                             the semantically anomalous sentence, “boys eat rocks”.
                                                               When the current input is the word “rocks” in a
                                                            semantically anomalous but grammatically correct
                                                            sentence, such as “boys eat rocks”, (see Figure 8), the
                                                            left sub-network still recognizes “rocks” as a Noun, but
                                                            the right sub-network recognizes it as a Noun-Inanim.
                                                            Thus, in the right sub-network, an entirely new triadic
                                                            pattern is formed in HL1, and a new winner will
    Figure 6: The predictions following a sequence of
                                                            consequently be picked in HL2. Since this winner has
 words “boys eat rocks” for the left sub-network and the    never won during training, the weights on the links
                     presentation layer.
                                                            from the winner in HL2 to the output layer have never
   Output Layer                                             been adjusted. Hence, the right sub-network only
                                                            generates an equal fractional prediction for every
 HL2                                                        feature. These unsubstantial predictions indicate a
                                                            semantic anomaly. On the other hand, the left sub-
                                                            network still predicts a period, indicating its capacity
 HL1
                               Noun      Verb               for recognizing a grammatical sentence.
 Noun       Verb     Noun                         Noun-
                               -Food     -Eat                  As revealed in Figure 7 and 8, when encountering a
                                                  Hum
                                                            semantically anomalous sentence, the network fails to
  Input                    Cookies                          make semantic predictions, but still recognizes that it is
                                                            a grammatical sentence and makes predictions
     Figure 7: The predictions when the current input       accordingly. This suggests that some mechanism
    sentence is a normal sentence “boys eat cookies”.       similar to this network might be found within a larger
                                                            language acquisition system to explain how humans
   For example, when the current input sentence is a        deal with semantically anomalies.
normal sentence, such as “boys eat cookies”, (see
Figure 7), and the current input word is “cookies”, the                 Discussion and Conclusion
category information of the first two words, “boys” and
“eat”, have been respectively stored in area C and B of     I have presented a connectionist network which is able
HL1. The left sub-network recognizes “boys” as a Noun,      to deal with semantic anomalies. More specifically, for
and “eat” as a Verb, while the right sub-network            semantically anomalous but grammatically correct
recognizes “boys” as a Noun-Human and “Eat” as a            sentences, it fails to predict according to the anomalous
Verb-Eat. When the word “cookies” comes into the            semantic pattern, but it is able to predict according to
input layer, the left sub-network will recognize            their syntactic structures instead. It is the employment
“cookies” as a Noun, since it is trained to recognize       of two identical sub-networks, which are trained via
general categories. On the other hand, the right sub-       different parameter settings during training to recognize
network will recognize “cookies” as a Noun-Food,            different fineness of grains of categorization, that
since it is trained to recognize sub-categories. A winner   provides the network with the capacity for dealing with
                                                            semantic anomalies. This also corresponds with the
                                                        585

anatomical and psychological evidence that both              acquisition, such as language deficits in aphasia or
hemispheres are necessary for full sentence                  dyslexia.
comprehension (Beeman, 1998).                                  The proposed model here is not claimed to provide a
   Also, the network employs a coherence                     general language acquisition mechanism. The lack of
reinforcement mechanism on top of the two sub-               biological evidence also means that we cannot be
networks to enable an information switch between them.       certain of a true computational model for human
In a separate examination, it has been found that with       language acquisition processes in the brain. However,
this mechanism, for normal sentences, most predictions       with the employment of both syntactic and semantic
from the global network are closer to what is actually       information, or rather, information about both fine-
presented in the test corpus, than those from any of the     grained     and      coarse-grained    syntactic-semantic
sub-networks alone. Thus, the network has provided a         categories, the proposed network has successfully
possible computational model to simulate human               provided a possible framework to deal with a subset of
behavior on predicting the range of possible next words      semantic anomalies within a connectionist network and
in either a normal sentence or a semantically anomalous      raised the issue of the interaction between syntactic and
sentence.                                                    semantic information.
   It is believed that making predictions for the next
word in a sentence not only requires syntactic                                Acknowledgments
information, but also semantic information. Most             Special thanks to Dr. Robert F. Hadley for his idea of
previous works on the issue of systematicity have            using two sub-networks to acquire different information
focused on the syntactic category that the network           in this learning task, and valuable help throughout this
predicts (Christiansen and Chater, 1994; Elman, 1998).       research.
The authors usually trained the networks, with certain
parameter settings, to be sensitive to only the syntactic
structures of input patterns. However, it is probable that
                                                                                    References
humans switch back and forth between semantic and            Beeman, M. (1998). Coarse semantic coding and
syntactic information to make good predictions. For            discourse     comprehension.       Right    hemisphere
example, we require semantic information for “eat” to          Language Comprehension: Perspective from
predict a food noun after it. On the other hand, we            cognitive neuroscience. Mahwah, NJ, UAS:
require syntactic information to predict the appearance        Lawrence Erlbaum Associates.
of function words such as prepositions. The proposed         Christiansen, M.H. & Chater, N. (1994). Generalization
                                                               and connectionist language learning. Mind and
network here is intended to draw attention to the issue
                                                               Language, 9, 273-287.
of the interaction between syntactic and semantic
                                                             Elman, J.L. (1990). Finding structure in time. Cognitive
information, and possibly between the two hemispheres,         Science, 14, 179-211.
in cognitive modeling. Taking a suggestion from              Elman, J.L. (1998). Generalization, simple recurrent
Hadley, the two sub-networks have been successfully            networks, and the emergence of structure.
trained to be sensitive to different semantic-syntactic        Proceedings of the Twentieth Annual Conference of
structures, by adjusting the parameters in the winner          the Cognitive Science Society. Mahwah, NJ:
selection rule. Also, the coherence reinforcement              Lawrence Erlbaum Associates.
process successfully switches the attention between the      Hadley, R.F. (1994a). Systematicity in Connectionist
two sub-networks. Hence, the network can more closely          Language Learning, Mind and Language, 9(3).
simulate human behavior, especially when encountering        Hadley, R.F. (1994b). Systematicity Revisited, Mind
semantically anomalies.                                        and Language, 9, 431-444.
   We can further compare the network’s behavior with        Hadley, R.F., Rotaru-Varga, A., Arnold, D.V., Cardei,
that of human subjects through psychological                   V.C. (2001). Syntactic Systematicity Arising from
experiments. However, the human brain is like a “black         Semantic Predictions in a Hebbian-Competitive
box” － it is difficult to understand how cognitive             Network, Connection Science, 13, 73-94.
processes happen in the brain directly. The main source      Hebb, D.O. (1949). The organization of behavior. New
for cognitive psychologists to understand human                York: Wiley.
cognition is to explore the brain indirectly through the     Marcus,      G.     (1998).     Rethinking    eliminative
                                                               connectionism. Cognitive Psychology, 37.
understanding of deficient cognition. The same applies
                                                             Phillips, S. (2000). Constituent similarity and
to verifications of computational models, since any
                                                               systematicity: The limits of first-order connectionism.
computational model of human cognitive processes is            Connection Science, 12(1), 45-63.
useless if it cannot address psychological phenomena.        von der Malsburg, C. (1973). Self-Organization of
Thus, to further verify and challenge the proposed             Orientation Sensitive Cell in Stirate Cortex,
network, we can examine whether it can address                 Kybernetik, 14, pp. 85-100.
phenomena or explain causes of deficits in language
                                                         586

