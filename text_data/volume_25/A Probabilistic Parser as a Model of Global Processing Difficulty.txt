UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Probabilistic Parser as a Model of Global Processing Difficulty
Permalink
https://escholarship.org/uc/item/1sr8c8rz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Author
Keller, Frank
Publication Date
2003-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

           A Probabilistic Parser as a Model of Global Processing Difficulty
                                            Frank Keller (keller@inf.ed.ac.uk)
                                        School of Informatics, University of Edinburgh
                                         2 Buccleuch Place, Edinburgh EH8 9LW, UK
                           Abstract                                about the differential behavior of verb final and verb ini-
   We present a model of global processing difficulty in           tial sentences and provides evidence for the importance
   human parsing. This model is based on a probabilistic           of lexical information in sentence processing.
   context-free grammar and is trained on a realistic cor-
   pus sample. It achieves broad coverage and good pars-                               Experimental Data
   ing accuracy on unseen text, and its predictions are sig-
   nificantly correlated with experimental data on word or-        Keller (2000a, 2000b) presents experimental results on
   der preferences in German. The model makes predictions          word order variation in subordinate clauses in German.
   about the differential behavior of verb final and verb ini-     These data form the basis for our modeling studies, and
   tial sentences and provides evidence for the importance         will be summarized in the following section.
   of lexical information in sentence processing.
                                                                   Experiment 1
                                                                   Keller’s (2000a) experiment included transitive verbs
                       Introduction                                such as kaufen ‘buy’ which take an animate subject and
The human sentence processor is constantly confronted              an inanimate object. Four different word order patterns
with ambiguous input, i.e., with linguistic material that          were investigated: SOV, OSV, VSO, VOS (we use ‘S’
is compatible with more than one syntactic analysis.               for subject, ‘O’ for object, and ‘V’ for verb). The object
The question of how such ambiguities are resolved has              and the subject were realized as either a full NP or as a
generated considerable debate in the psycholinguistic              pronoun. The target word order was presented as a subor-
literature, and a variety of approaches have been pro-             dinate clause embedded by verbs like glauben ‘believe’.
posed to address this question (see Crocker, 1999 for an           (1) illustrates the SOV order with two full NPs.
overview).
   One of these approaches is the Tuning Hypothesis                (1) Maria glaubt, dass der          Vater den       Wagen kauft.
                                                                        Maria believes that the[nom] father the[acc] car     buys
(Mitchell, Cuetos, Corley, & Brysbaert, 1996), which                    ‘Maria believes that the father is buying the car.’
states that the sentence processor extracts frequency in-
formation from its environment. In the case of ambigu-             In the syntactic literature on German (e.g., Müller, 1999)
ity, the processor adopts the most frequent structure. This        SOV is generally regarded as the basic word order for
predicts that more frequent structures are easier to pro-          subordinate clauses. Verb initial orders are regarded as
cess than less frequent ones, as the processor is more             ungrammatical, while scrambling (the permutation of
likely to have encountered them before, and can choose             subject and object) is regarded as marked, i.e., of reduced
the correct analysis. A number of experimental studies             grammaticality, but it not outright ungrammatical.
confirm this prediction for PP attachment and relative                Keller (2000a) used magnitude estimation (ME; Bard,
clause attachment (e.g., Brysbaert & Mitchell, 1996).              Robertson, & Sorace, 1996) to test these theoretical
   The aim of the present paper is to generalize the Tun-          claims. He elicited acceptability judgments for 16 word
ing Hypothesis from local processing difficulty (as it oc-         orders, each of which as represented by eight lexicaliza-
curs with attachment ambiguities) to global processing             tions, yielding a total set of 128 sentences. Twenty native
difficulty. By this we mean processing difficulty that per-        speakers of German were used as subjects. Under the as-
sists even when the whole sentence has been read in                sumption that ME judgments provide an index of global
by the parser, and a unique reading should be available.           processing difficulty, Keller’s (2000a) results support the
Standard examples include center embedding construc-               following generalizations:
tions and constructions that induce ‘strong’ garden paths,
i.e., garden paths from which the parser fails to recover.         (2) a. Verb initial orders are harder to process than verb final
The Tuning Hypothesis predicts a link with frequency                        orders.
                                                                        b. Object initial orders are harder to process than subject
for these cases: if the globally correct analysis of a sen-                 initial orders.
tence is infrequent, then this sentence will lead to strong             c. Orders in which non-pronouns precede pronouns are
processing difficulty.                                                      harder to process than orders in which pronouns pre-
   In this paper, we test prediction with respect to word                   cede non-pronouns.
order variation in German, a phenomenon for which
global processing difficulty can be observed. The paper            There is a range of experimental results that were ob-
is structured as follows. We first give an overview of             tained using different paradigms that confirm these pro-
the two experimental data sets that our modeling stud-             cessing preferences. This includes eye-movement and
ies are based on. Then the relationship between fre-               self-paced reading data (Bader & Meng, 1999; Scheep-
quency and processing difficult is discussed and a pars-           ers, 1997), and a range of other comprehension and pro-
ing model based on probabilistic context-free grammars             duction paradigms (Pechmann, Uszkoreit, Engelkamp, &
is proposed. We train and test the model on a standard             Zerbst, 1994).
corpus and demonstrate that it achieves broad coverage
and good parsing accuracy on an unseen test set. Then the          Experiment 2
model is evaluated by correlating its predictions with the         Keller (2000b, Experiment 6) extends these results to di-
two experimental data sets. The model makes predictions            transitive verbs such as vorstellen ‘introduce’ that can
                                                               646

take three animate arguments. Six word order patterns                                                 S
were tested: SIOV, SOIV, ISOV, IOSV, OSIV, OISV, ei-
ther with three full NPs or with two full NPs and one
pronominalized NP (‘O’ denotes the direct object, ‘I’ the
indirect object). Again, the word order was presented as               KOUS              NP-SB             NP-OA       VVFIN-HD
a subordinate clause. (3) gives an example for the order
SIOV with three full NPs.                                               dass          ART       NN      ART       NN       kauft
(3) Ich weiß, dass der          Manager dem        Projektleiter                       der     Vater     den    Wagen
     I know that the[nom] manager the[dat] project leader
     den       Mitarbeiter vorstellt.                                             Figure 1: Example of a Negra tree
     the[acc] staff member introduces
     ‘I know that the manager is introducing the staff member
     to the project leader.’                                              Verb                       Total   IO order OI order
                                                                          geben ‘give’               560        16        0
ME judgments were elicited for 24 orders; each order                      vorstellen ‘present’        38         0        3
was presented in eight lexicalizations, yielding an overall               zur Verfügung stellen      24         0        3
set of 192 stimuli. Twenty-five native speakers were used                 ‘make available’
as subjects. The results support claims (2b) and (2c), and
yield the additional finding in (4) (verb initial orders were        Table 1: Word order frequencies for full NPs in Negra
not included, hence the result in (2a) could not be tested).         reported by Kurz (2000)
(4) Orders in which the direct object precedes the indirect ob-
     ject are harder to process than orders in which the indirect
     object precedes the direct object.
                                                                     We extract all instances of a given structure from the cor-
We will use the data sets from Experiments 1 and 2 to                pus and then correlate the resulting frequencies with a
test a model of global processing difficulty. The under-             measure of processing difficulty.
lying assumption is that the ME score of a sentence can
serve as a measure of processing difficulty: the harder a               This naive approach, however, is not feasible due to
sentence is to process, the more unacceptable it is in an            data sparseness: many of the word orders tested in Ex-
ME judgment task. Evidence for this assumption is pro-               periments 1 and 2 are rare in the corpus, which makes
vided by Bard, Frenck-Mestre, Kelly, Killborn, and So-               it difficult to obtain reliable frequency counts for these
race’s (1999) study which shows that ME data are corre-              structures. As an example consider the frequency data
lated with data from self-paced reading and eye-tracking             that Kurz (2000) extracted from Negra. Kurz (2000) in-
experiments.                                                         vestigated the word order patterns of certain ditransi-
                                                                     tive verbs, such as geben ‘give’ vorstellen ‘present’, and
                                                                     zur Verfügung stellen ‘make available’. All instances of
      Frequency and Processing Difficulty                            these verbs were extracted from Negra and then classi-
The aim of the present study is to test the Tuning Hy-               fied with respect to the order of their objects. The result-
pothesis, i.e., the claim that there is a correlation between        ing frequencies are given in Table 1. The column headed
the frequency of a structure in the linguistic environment           Total lists the overall frequency of a given verb in the cor-
and global processing difficulty, as measured by magni-              pus; the IO column contains the number of cases where
tude estimation studies. Before we can test this claim,              the indirect object (dative NP) precedes the direct object
we have to find a way of approximating the linguistic                (accusative NP), the OI column lists the counts for the
environment of a speaker, i.e., we need a sample of the              inverse order. The frequencies in these two columns only
linguistic input that the speaker is exposed to. Such sam-           take into account cases in which both objects are realized
ples are readily available for a number of languages in the          as full NPs; Kurz (2000) does not report data on pronom-
form of corpora, large computerized collections of text              inalized word orders.
or speech. In the remainder of the paper, we will assume
that the frequency distributions in the linguistic environ-             In principle, we could now correlate the frequencies in
ment can be approximated by frequency distributions in               Table 1 with the results of Experiment 2, in which it was
a corpus.                                                            found that OI orders are harder to process than IO orders
                                                                     (see (4)). However, as the corpus counts are too sparse
   For German, a suitable corpus is available in the form            for such a comparison: three out of six counts are zero,
of Negra (Skut, Krenn, Brants, & Uszkoreit, 1997), a                 and also the other three orders are very rare. This means
350,000 word corpus of newspaper text. Negra is an-                  that no reliable claims can be derived from these counts.
notated with (a) part of speech labels (e.g., KOUS for
complementizer, ART for article, NN for count noun,                     This example indicates that data sparseness makes it
and VVFIN for finite verb); (b) syntactic information in             impossible to directly correlate corpus frequency and
the form of syntactic trees and phrase structure labels              processing difficulty, at least for the particular syntactic
(e.g., NP for noun phrase, S for sentence); (c) grammat-             construction we are interested in here, and for the cor-
ical function labels (e.g., HD for head, SB for subject,             pus we are using. In cognitive terms, this means that it
OA for accusative object). Figure 1 shows a Negra-style              is implausible to assume that the human parser directly
structure for the sentence in (1) (subordinate clause only;          keeps track of structural frequencies in its environment
a subset of the Negra function labels is displayed).                 to determine word order preferences; it simply does not
   A corpus annotated with syntactic structure affords a             encounter the relevant structures often enough to derive
straightforward way of testing the Tuning Hypothesis:                reliable statistics.
                                                                 647

                S     →       KOUS NP NP VVFIN                    .9                                   S[kauft]
                S     →       KOUS NP VVFIN                       .1
             NP       →       ART NN                             1.0
         VVFIN        →       kauft                              1.0
          KOUS        →       dass                               1.0
            ART       →       der                                 .8          KOUS            NP[Vater]      NP[Wagen]         VVFIN
            ART       →       den                                 .2
             NN       →       Vater                               .6           dass         ART      NN     ART      NN         kauft
             NN       →       Wagen                               .4
                                                                                             der    Vater    den   Wagen
                Figure 2: Example of a PCFG
                                                                            Figure 4: Example of tree generated by a lexicalized
                                                                            PCFG
                                   S.9
                                                                            dressed by incorporating grammatical function informa-
                                                                            tion into the grammar. For example, the noun phrase la-
  KOUS1.0              NP1.0                 NP1.0             VVFIN1.0
                                                                            bel NP can be split up into the labels NP-SB, NP-OA,
     dass         ART.8 NN.6           ART.2 NN.4                 kauft     and NP-DA for subjects, direct objects, and indirect ob-
                                                                            jects, respectively. Grammatical functions are marked up
                    der Vater            den Wagen                          in the Negra corpus, as illustrated in Figure 1. We can
       P(t) = .9 · 1.0 · 1.0 · 1.0 · 1.0 · .8 · .6 · .2 · .4 = .03456       use this information to replace a PCFG rule such as S →
                                                                            KOUS NP NP VVFIN with a set of rules incorporat-
      Figure 3: Example of tree generated by a PCFG                         ing grammatical function labels, e.g., S → KOUS NP-
                                                                            SB NP-OA VVFIN-HD, and S → KOUS NP-OA NP-
                                                                            SB VVFIN-HD. The resulting grammar is more adequate
     Probabilistic Context-Free Grammars                                    for modeling processing differences that arise from dif-
                                                                            ferences in the order of subjects and objects (as they were
In the last section, we argued that data sparseness makes                   demonstrated by Experiments 1 and 2).
it implausible that the human parser directly records                          An alternative way of improving the adequacy of a
structural frequencies. We will therefore pursue an al-                     PCFG is adding lexical information. This approach has
ternative hypothesis: that the parser keeps track of the                    been pursued extensively in the computational linguis-
frequencies of grammar rules.                                               tics literature (e.g., Carroll & Rooth, 1998) and has been
   More specifically, we will assume that global pro-                       shown to dramatically improve parsing performance.
cessing difficulty can be modeled using a probabilistic                     Lexicalization means that the set of category labels is
context-free grammar (PCFG). Models of syntactic dis-                       extended by incorporating information about the head of
ambiguation (i.e., of local processing difficulty) based on                 the categories. For example, the category NP is split up
PCFGs have been proposed by a variety of authors and                        into NP[Vater] and NP[Wagen] for noun phrases headed
have been shown to account for experimental findings                        by the lexical items Vater ‘father’ and Wagen ‘car’, re-
on human disambiguation preferences (Jurafsky, 1996;                        spectively. This is illustrated in Figure 4, which contains
Crocker & Brants, 2000; Hale, 2001). We will extend this                    the lexicalized version of the tree in Figure 3. As with
approach to global processing difficulty as measured by                     grammatical functions, this leads to an extension of the
magnitude estimation studies.                                               set of rules, yielding rules such as S[kauft] → KOUS
   A PCFG consists of a set of context-free rules, where                    NP[Vater] NP[Wagen] VVFIN.
each rule LHS → RHS is annotated with a probability                            Lexicalization can be seen as a way of approximat-
P(RHS|LHS). This probability represents the likelihood                      ing linguistic information that is not explicit in the cor-
of expanding the category LHS to the categories RHS. In                     pus (and in the grammar). An example is morphologi-
order to obtain a mathematically sound model, the prob-                     cal information: the label NP[Vater] implicitly contains
abilities for all rules with the same lefthand side have to                 the information that the NP is nominative, third person,
sum to one. The probability of a parse tree T is defined                    and singular, i.e., the morphological features of Vater
as the product of the probabilities of all rules applied in                 ‘father’. Lexicalization is also a way of incorporating
generating T . We will assume that this probability is cor-                 co-occurrence information into the grammar. The rule
related with processing difficulty, i.e., that improbable                   S[kauft] → KOUS NP[Vater] NP[Wagen] VVFIN con-
structures are harder to process than probable ones.                        tains the information that the verb kauft ‘buys’ co-occurs
   An example for a PCFG is given in Figure 2. This                         with the nouns Vater ‘father’ and Wagen ‘car’, thus
grammar contains all the rules required to generate (1).                    capturing the semantic relationship between these three
Figure 3 displays the parse tree for this sentence, anno-                   words. There is evidence in the psycholinguistic litera-
tated with rule probabilities. The overall probability of                   ture showing that the human parser makes use of mor-
the parse is also listed; it is computed as the product of                  phological information (e.g., Trueswell, 1996) and se-
all the rule probabilities.                                                 mantic plausibility (e.g., Garnsey, Pearlmutter, Myers, &
   A simple PCFG such as the one in Figure 2 has a num-                     Lotocky, 1997).
ber of obvious limitations; the linguistics distinctions it
makes are not fine-grained enough. For instance, all noun
phrases are assigned the category NP, even though the                                    Modeling Broad Coverage
relative order of subjects, direct objects, and indirect ob-                We developed three models of global processing diffi-
jects was shown to trigger differences in processing be-                    culty, as outlined in the previous section: (a) a baseline
havior in Experiments 1 and 2. This problem can be ad-                      model using a standard PCFG, the (b) a lexicalized model
                                                                        648

using a lexicalized PCFG, and (c) a functional model                                            LR     LP      F-score
based on a PCFG that includes grammatical function la-                          Baseline        72.5  71.3      71.9
                                                                                Lexicalized     67.2  60.9      63.9
bels. In all three cases both the grammar rules and the                         Functional      71.9  70.0      70.9
probabilities were derived from the Negra corpus.
                                                                    Table 2: Testing the coverage of the models using labeled
Method                                                              bracketing scores
Negra was split into three subsets: the first 90% of the               Failed parses:      constant              removed
corpus were used as training set, the remainder was di-                                 r     p      N       r       p     N
vided into a 5% test set and a 5% development set (for                 Baseline       .393  .000 128       .489    .000 109
parameter tuning). Sentences with more than 40 words                   Lexicalized .512     .000 128       .636    .000 109
were removed (to increase parsing efficiency).                         Functional .137      .123 128       .374    .002    68
   The baseline model was realized using the proba-
bilistic left-corner parser Lopar (Schmid, 2000), run-                      Table 3: Modeling results for Experiment 1
ning in unlexicalized mode. A grammar and a lexicon
were read off the Negra training set, after empty cate-
gories and function labels had been removed from the                     Modeling Global Processing Difficulty
corpus. The lexicalized model was also realized using               Recall that the aim of this study is to test the hypoth-
Lopar, which in lexicalized mode implements Carroll                 esis that there is a correlation between the frequency
and Rooth’s (1998) model. Lexicalization requires that              of a structure in the linguistic environment and global
each rule in a grammar has one of the categories on its             processing difficulty. We have argued that structural fre-
righthand side annotated as the head. For the categories            quency cannot be measured directly due to data sparse-
S, VP, AP, and AVP, the head is marked in Negra. For the            ness. Instead, we hypothesized that the probability of a
other categories, we used rules to heuristically determine          structure, as computed by a PCFG, is a predictor of pro-
the head. The functional model was implemented by in-               cessing difficulty. In this section, this hypothesis will be
ducing a new grammar from the training set: the function            tested against the data sets from Experiments 1 and 2.
labels SB, OA, and DA were kept, but all other function
labels were removed. The model was again implemented                Experiment 1
by running Lopar in unlexicalized mode.
   The parameters for all three models were estimated               We tested each of the models (baseline, lexicalized, and
using maximum likelihood estimation. This means that                functional) against the experimental data as follows. The
P(LHS → RHS), the probability of rule LHS → RHS,                    sentences used as experimental materials was parsed by
                                                                    the model, and the probability of the most probable parse
is estimated as P(LHS → RHS) = f (LHS → RHS)/N,                     was computed. This probability was normalized by sen-
where f (LHS → RHS) is the number of times the rule                 tence length (measured as the number of words in the
occurs in the training data, and N is the overall number            sentence). This is necessary as a PCFG assigns lower
of rules in the training data. Various smoothing schemes            probabilities to longer sentences (all other factors being
are implemented in Lopar to address data sparseness, see            equal), as longer sentences involve more rule applica-
Schmid (2000) for details.                                          tions.
                                                                       To compare the models, we conducted a set of corre-
Results                                                             lation analyses: we correlated the log of the probability
                                                                    predicted by the model for each sentence with the log of
All models were evaluated by running them on the test               the mean magnitude estimation score for this sentence.
corpus, which had remained unseen during model devel-               The parser failed on some sentences, i.e., it did not find a
opment. As is standard in the computational linguistics             parse. There are two ways of dealing with this problem:
literature, we measured labeled bracketing: to score a hit,         (a) setting the probability of a failed parse to a small,
the parser has to predict both the bracket (the beginning           constant probability, and (b) removing the failed parses
or end of a phrase) and the category label correctly. We            from the data. Table 3 lists the correlation coefficients for
report labeled recall (LR), i.e., the number of correct la-         all three models and for both ways of dealing with failed
beled brackets found by the parser divided by the total             parses.
number of labeled brackets in the test corpus, and labeled             The results show that the baseline and lexicalized
precision (LP), i.e., the number of correct labeled brack-          models obtain significant correlations with the ME data.
ets found by the parser divided by the total number of              The functional model only achieves a correlation once
labeled brackets found by the parser. We also list the F-           the failed parses are removed; however, there are a lot
score, which is defined as F = 2 · LP · LR/(LP + LR).               of failed parses here (only 78 data points remain), so
   The results are given in Table 2. The baseline model             this result has to be interpreted with caution. We per-
achieves an F-score of 71.9%, while the functional model            formed a t-test to compare the correlation coefficients
performs slightly worse with an F-score of 70.9%. The               achieved by the baseline model and the lexicalized model
lexicalized model performs worse than the baseline with             (failed parses removed). The correlation of the lexical-
                                                                    ized model was significantly higher (t(109) = 2.454,
an F-score of 63.9%.1                                               p < .05). The fact that the lexicalized model outperforms
                                                                    the unlexicalized baseline model points to the important
    1 For a detailed analysis of why standard lexicalized parsing   role that morphological and semantic information (plau-
models perform do not perform well for German, see Dubey            sibility) plays for global processing difficulty. Such in-
and Keller (2003).                                                  formation is approximated in the lexicalized model, but
                                                                649

                                                                                                           Failed parses:                                       constant                   removed
                                     -8                                                                                  r                                         p     N            r        p   N
    normalized probability (logs)
                                                                                                           Baseline    .154                                      .033 192           .167     .022 190
                                                                                                           Lexicalized .208                                      .004 192           .230     .001 190
                                    -10                                                                    Functional .441                                       .000 192           .019     .910  39
                                    -12
                                                                                                                                             Table 5: Modeling results for Experiment 2
                                    -14                             verb final sentences                                                      -7
                                                                                                             normalized probability (logs)
                                                                    verb initial sentences
                                    -16                                                                                                       -8
                                          -0.4   -0.2     0      0.2      0.4      0.6       0.8
                                             mean magnitude estimation score (logs)
Figure 5: Correlation for the lexicalized model (failed                                                                                       -9
parses removed) for Experiment 1
                                                                                                                                             -10
  Failed parses:                                    constant                    removed
                                              r        p       N          r        p          N
                                                        verb final                                                                           -11
                                                                                                                                                   -0.6     -0.4     -0.2       0        0.2       0.4
  Baseline    .219                                   .082      64       .057       .690       52                                                          mean magnitude estimation score (logs)
  Lexicalized .233                                   .064      64       .067       .637       52
  Functional .155                                    .220      64       .296       .094       33         Figure 6: Correlation for the lexicalized model (failed
                                                       verb initial
  Baseline    .109                                   .392      64       .070       .605       57
                                                                                                         parses removed) for Experiment 2
  Lexicalized .123                                   .333      64       .089       .510       57
  Functional .044                                    .733      64       .011       .951       35
                                                                                                         Experiment 2
Table 4: Modeling results for Experiment 1, separation                                                   The modeling results for the data from Experiment 1
of verb final and verb initial items                                                                     showed that our models are able to distinguish between
                                                                                                         verb final and verb initial orders. However, the results
                                                                                                         also indicated that the models failed to reliably predict
not in the baseline model.                                                                               processing difficulty if the two word orders are consid-
   An inspection of the data shows the following inter-                                                  ered separately. In the following, we will further inves-
esting pattern. The models generate plausible analyses                                                   tigate the behavior of the models for verb final orders
for verb final sentences and assign them high probabili-                                                 based on the data from Experiment 2 (which only dealt
ties. No plausible analyses are found for verb initial sen-                                              with verb final sentences). Experiment 2 also provides
tences, and they are assigned low probabilities. This find-                                              a larger amount of data, viz., 192 items (compared to
ing makes an interesting prediction with respect to pro-                                                 the 64 verb final items from Experiment 1). Furthermore,
cessing difficulty as recorded by the ME judgments task:                                                 Experiment 2 provides a test of the generality of the mod-
verb initial orders are predicted to receive low ME scores                                               eling results, as it included ditransitive verbs, giving rise
(recall that they are generally considered ungrammati-                                                   to additional word orders not included in Experiment 1.
cal in the theoretical literature), while verb final orders                                                 We used the same modeling procedure as for the data
should be assigned high ME scores. This prediction is                                                    from Experiment 1. The results for all three models and
borne out, as illustrated in Figure 5, which plots sentence                                              for the two ways of treating failed parses (set to a con-
probabilities against ME scores for the lexicalized model                                                stant or remove) are listed in Table 5. We observe signif-
(with failed parses removed). We observe a clear sepa-                                                   icant correlations for the baseline model and the lexical-
ration of verb final and verb initial sentences. (The plots                                              ized model for both ways of treating failed parses. Note
for the other two models show a similar pattern.)                                                        that the lexicalized model again achieves higher corre-
   The distinction between verb final and verb initial or-                                               lation coefficients than the baseline model. However, a
ders is captured successfully by our model. However,                                                     t-test shows that this difference is not significant.
this raises the question if the model is able to predict                                                    For the functional model, we find a high correlation
processing difficulty also if only verb final or verb ini-                                               if failed parses are set to a constant; however, this cor-
tial orders are tested. We investigated this by performing                                               relation disappears if the failed parses are removed from
separate correlation analyses for the two subsets of the                                                 the data set, leaving only 39 items. In other words, the
data. The results are given in Table 4. For the verb final                                               functional model fails to assign a parse in most of the
sentences, we failed to find any significant correlations                                                cases; this is probably due to data sparseness: there are
between probabilities and ME scores. The only excep-                                                     not enough instances of ditransitive verbs in the corpus
tions were the baseline and the lexicalized models (failed                                               to acquire realistic probabilities for the functional model.
parses set to a constant). Here a marginal correlation is                                                   Figure 6 plots the magnitude estimation scores of Ex-
obtained. (The correlation for the functional model with                                                 periment 2 against the probabilities predicted by the lex-
failed parses removed was also marginal, but included                                                    icalized model (failed parses removed). The graph shows
only 33 data points.) For verb initial sentences, the cor-                                               that this time all sentences behave in the same way; there
relation coefficients were even lower and non-significant                                                is no split into two sentence types (such as the verb fi-
across the board.                                                                                        nal/verb initial split in the model of Experiment 1).
                                                                                                   650

                       Conclusions                                  linguistic anomaly. (Unpubl. ms., Human Communication
In this paper, we tested the Tuning Hypothesis by apply-            Research Centre, University of Edinburgh)
                                                                 Bard, E. G., Robertson, D., & Sorace, A. (1996). Magnitude
ing it to global processing difficulty as measured by mag-          estimation of linguistic acceptability. Language, 72(1), 32–
nitude estimation. Two experimental data sets were used,            68.
both dealing with word order variation in German. We             Brysbaert, M., & Mitchell, D. C. (1996). Modifier attachment
argued that data sparseness makes it implausible that the           in sentence parsing: Evidence from Dutch. Quaterly Journal
human parser directly records structural frequencies; in-           of Experimental Psychology, 49A(3), 664–695.
stead, we assumed that it keeps track of rule frequencies.       Carroll, G., & Rooth, M. (1998). Valence induction with a
We implemented this hypothesis in a series of models                head-lexicalized PCFG. In Proceedings of the Conference
based on probabilistic context free grammars. Sentence              on Empirical Methods in Natural Language Processing (pp.
probabilities predicted by these models were shown to               36–45). Granada.
                                                                 Crocker, M. (1999). Mechanisms for sentence processing. In
be significantly correlated with the ME scores obtained             S. Garrod & M. Pickering (Eds.), Language processing. Psy-
experimentally. We also showed that our models make                 chology Press, London.
predictions with respect to the differential processing of       Crocker, M. W., & Brants, T. (2000). Wide-coverage prob-
verb final and verb initial sentences. These predictions            abilistic sentence processing. Journal of Psycholinguistic
were borne out in the ME data.                                      Research, 29(6), 647–669.
   Three different probabilistic models were tested, each        Dubey, A., & Keller, F. (2003). Probabilistic parsing for Ger-
incorporating different types of linguistic information.            man using sister-head dependencies. In Proceedings of the
The baseline model was based on a standard PCFG; it                 41st Annual Meeting of the Association for Computational
achieved a significant correlation with ME data for both            Linguistics. Sapporo.
experiments. However, a model that incorporates lexical          Garnsey, S. M., Pearlmutter, N. J., Myers, E. M., & Lotocky,
                                                                    M. A. (1997). The contributions of verb bias and plausibility
information into the category labels achieved a better fit          to the comprehension of temporarily ambiguous sentences.
with the experimental data than the baseline model. This            Journal of Memory and Language, 37(1), 58–93.
indicates that the information that is approximated by           Hale, J. (2001). A probabilistic earley parser as a psycholin-
the lexical model, viz., morphological information and              guistic model. In Proceedings of the 2nd Conference of the
semantic plausibility, plays a role in determining global           North American Chapter of the Association for Computa-
processing difficulty. We also investigated the behavior            tional Linguistics. Pittsburgh, PA.
of a functional model, in which the categories of the            Jurafsky, D. (1996). A probabilistic model of lexical and syn-
grammar incorporate grammatical function labels (sub-               tactic access and disambiguation. Cognitive Science, 20,
ject, object, etc.). However, this model did not outper-            137–194.
                                                                 Keller, F. (2000a). Evaluating competition-based models of
form the baseline model. This could be due to sparse                word order. In L. R. Gleitman & A. K. Joshi (Eds.), Pro-
data: there are not enough corpus examples available to             ceedings of the 22nd Annual Conference of the Cognitive
reliably estimate the parameters of the functional model.           Science Society (pp. 747–752). Mahwah, NJ: Lawrence Erl-
   Many models in the psycholinguistic literature are de-           baum Associates.
signed to account for ‘pathological’ behavior of the pro-        Keller, F. (2000b). Gradience in grammar: Experimental and
cessor, i.e., for cases of processing breakdown (such as            computational aspects of degrees of grammaticality. Unpub-
garden paths). They are unable to explain why the hu-               lished doctoral dissertation, University of Edinburgh.
man parser is generally very efficient and accurate on           Kurz, D. (2000). A statistical account on word order variation
naturally occurring text, as pointed out by Crocker and             in German. In A. Abeillé, T. Brants, & H. Uszkoreit (Eds.),
                                                                    Proceedings of the COLING Workshop on Linguistically In-
Brants (2000). The models we presented here, however,               terpreted Corpora. Luxembourg.
are broad coverage models. This means they are able              Mitchell, D. C., Cuetos, F., Corley, M. M. B., & Brysbaert, M.
to parse naturally occurring, previously unseen text and            (1996). Exposure-based models of human parsing: Evidence
achieve good parsing performance (precision and recall).            for the use of coarse-grained (non-lexical) statistical records.
They therefore capture this important characteristic of             Journal of Psycholinguistic Research, 24(6), 469–488.
the human parser.                                                Müller, G. (1999). Optimality, markedness, and word order in
   Finally, our approach also presents a methodological             German. Linguistics, 37(5), 777–818.
innovation. Previous work on probabilistic models of hu-         Pechmann, T., Uszkoreit, H., Engelkamp, J., & Zerbst, D.
man parsing (Jurafsky, 1996; Crocker & Brants, 2000;                (1994). Word order in the German middle field: Linguis-
Hale, 2001) only contained a simple, qualitative form of            tic theory and psycholinguistic evidence (CLAUS Report
                                                                    No. 43). Department of Computational Linguistics, Saar-
evaluation. Typically, the model is applied on a small set          land University.
of examples to check if it predicts the correct processing       Scheepers, C. (1997). Menschliche Satzverarbeitung: Syn-
pattern for these sentences. The present paper presented a          taktische und thematische Aspekte der Wortstellung im
more rigorous form of evaluation: we used two large data            Deutschen. Unpublished doctoral dissertation, University of
sets (128 and 192 sentences, respectively) and performed            Freiburg.
a quantitative evaluation by correlating model probabil-         Schmid, H. (2000). LoPar: Design and implementation. (Un-
ities and ME scores. Model fit was measured using cor-              publ. ms., Institute for Computational Linguistics, Univer-
relation coefficients, making it possible to compare the            sity of Stuttgart)
performance of different models on the same data.                Skut, W., Krenn, B., Brants, T., & Uszkoreit, H. (1997). An an-
                                                                    notation scheme for free word order languages. In Proceed-
                                                                    ings of the 5th Conference on Applied Natural Language
                        References                                  Processing. Washington, DC.
Bader, M., & Meng, M. (1999). Subject-object ambiguities         Trueswell, J. C. (1996). The role of lexical frequency in syntac-
   in German embedded clauses: An across-the-board compar-          tic ambiguity resolution. Journal of Memory and Language,
   ison. Journal of Psycholinguistic Research, 28(2), 121–143.      35(4), 566–585.
Bard, E. G., Frenck-Mestre, C., Kelly, L., Killborn, K., & So-
   race, A. (1999). Judgement and perception of gradable
                                                             651

