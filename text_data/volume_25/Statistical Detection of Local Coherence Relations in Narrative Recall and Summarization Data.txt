UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Statistical Detection of Local Coherence Relations in Narrative Recall and Summarization
Data
Permalink
https://escholarship.org/uc/item/3fj3181j
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)
Authors
Jaynes, Cynthia M.
Golden, Richard M.
Publication Date
2003-01-01
Peer reviewed
  eScholarship.org                                  Powered by the California Digital Library
                                                                      University of California

                              Statistical Detection of Local Coherence Relations
                                  in Narrative Recall and Summarization Data
                                            Cynthia M. Jaynes (jaynes@utdallas.edu)1
                                                School of Human Development, GR4.1
                                               University of Texas at Dallas, Box 830688
                                                      Richardson, TX 75083-0688
                                            Richard M. Golden (golden@utdallas.edu)1
                                                School of Human Development, GR4.1
                                               University of Texas at Dallas, Box 830688
                                                      Richardson, TX 75083-0688
                              Abstract                                presents an extension of work previously presented in
                                                                      Golden (1998) and applies the extended statistical modeling
   A new categorical time-series analysis method (which has a         methodology to the analysis of some recall and
   connectionist model interpretation) called KDC (Knowledge          summarization data which we have collected for the
   Digraph Contribution) analysis was used to investigate
                                                                      purposes of exploring differences and similarities between
   differences in recall and summarization production data as a
   function of reproductive and semantic coherence relations.         recall and summarization protocol data.
   The results provided support for the hypothesis that
   reproductive memory contributions play a dominant role in                        The Behavioral Experiment
   characterizing differences between recall and summarization.
   Moreover, the methodology and results described here               Participants
   illustrate the usage and application of KDC analysis.
                                                                      Participants for this experiment were 24 undergraduate
         Text Coherence and Comprehension                             psychology students at University of Texas at Dallas who
                                                                      received research credit for participation. All participants
   Semantic coherence relations, which indicate how                   were fluent English speaking students. Participants were
specific clauses in a text are semantically related, play a           randomly assigned to six conditions. Four participants were
major role in theories of human text comprehension (e.g.,             in each condition. The six conditions were comprised of
Kintsch, 1998), automatic text summarization (e.g., Mani,             different presentation orders of the three instruction
2001; Mani and Maybury, 1991), and text linguistics (e.g.,            conditions, recall, detailed summary and concise summary.
Longacre, 1979; Mann and Thompson, 1988) . In addition,
considerable research in the field of experimental                                 Table 1: The Czar and his Daughters
psychology has established that the organization of                                 [Reprinted from Rumelhart, 1977].
propositional information in the text (i.e., “textbase
coherence relations”) influences memory for text (e.g.,                 “There was once a Czar who had three lovely
Britton et al., 1980; Einstein et al., 1984; Golden, 1998;              daughters. One day, the three daughters went walking
Hasher & Griffin, 1978; Kintsch & van Dijk, 1978; Kintsch,              in the woods. They were enjoying themselves so much
1998). Moreover, it has been established that semantic                  that they forgot the time and stayed too long. A dragon
coherence relations among ideas referenced within a text                kidnapped the three daughters. As they were being
may be revealed through recall and summarization                        dragged off they called for help. Three heroes heard the
production data (e.g., Golden, 1998; Goldman &                          cries and set off to rescue the daughters. The heroes
Varnhagen, 1986; Mandler & DeForest, 1979; Rumelhart,                   came and fought the dragon. They defeated the dragon
1977; Stein & Glenn, 1979; Trabasso & Magliano, 1996).                  and rescued the maidens. The heroes returned the
These observations suggest that it would be advantageous to             daughters safely to their palace. When the Czar heard
develop a statistical methodology for the detection of local            of the rescue he rewarded the heroes handsomely.”
semantic coherence relations in human production data.
Such a statistical methodology could be used not only for             Materials
testing theories of human text comprehension but also for
obtaining useful information for the purposes of informing            Two simple narrative texts, “The Dog and his Shadow” and
the design of automatic summarization systems and refining            “The Czar and his Daughters”, taken from Rumelhart (1977)
theories of text linguistics. Towards this end, this paper            were used as practice and experimental stimuli for the study
                                                                      respectively. The experimental text consisted of nine
1
  The order of the authors is arbitrary.
                                                                616

sentences and 16 complex propositions. The practice text           node 18 refers to the final mental state of the participant
was of similar length and complexity. The experimental text        which arises when the participant’s response is completed.
is provided in Table 1.
                                                                   Reproductive Memory Knowledge Digraph
Procedure                                                          The reproductive memory knowledge digraph is the
Text Presentation. A HyperCard program presented the               component of the situation model which refers to the
practice text “The Dog and his Shadow” followed by the             original sequence of ideas which were presented to the
experimental text “The Czar and His Daughters” one                 reader. A formal representation of this knowledge digraph is
sentence at a time using a self-paced reading task.                specified by the arcs in Figure 1 which depict the order in
Participants were instructed to read the instructions              which the complex propositions in Table 2 are presented in
carefully and told they would be asked questions about the         the original text. The reproductive memory knowledge
stories at a later time period in the experiment. To view each     digraph is intended to instantiate the behavioral hypothesis
                                                                   that production order is influenced by the original ordering
sentence, participants used an arrow in the corner of the
                                                                   of propositions in the text.
screen. When the arrow was clicked, the present sentence
disappeared and the next sentence appeared. After the               Table 2: Complex Propositions Used in Simulation Study
experimental text was presented, participants participated in              (C=Czar, P=Princesses, D=Dragon, H=Heros)
an intervening distractor task which took several minutes to
complete.                                                             Node     Complex Proposition
Production Task. In the production task, participants were            Id #
asked to summarize, give a detailed summary, and recall the           1        SETTING(INTRODUCE,C)
story. The order of the instruction tasks were counter                2        SETTING(POSSESS(C,P)
balanced across participants. Participants in the “concise            3        METHOD(GO(P,WOODS))
summary” condition were instructed to construct a story               4        CONSEQUENCE(POSSESS(P,JOY))
summary consisting of no more than three sentences.                   5        CONSEQUENCE(REMAIN(P,IN-WOODS)
Participants in the “detailed summary” condition were                 6        METHOD(CAPTURE(D,P))
instructed to construct a story summary consisting of at least        7        METHOD(TRANSFER(D,P))
three sentences. Participants in the “recall” condition were          8        CONSEQUENCE(SCREAM(P))
instructed to recall the story by explicitly recalling the exact      9        EVENT(HEAR(H,P))
wording of each sentence and recalling the sentences                  10       METHOD(GO,H)
according to their original order of presentation. Participants       11       SETTING(INTRODUCE,H)
typed their responses for both the practice text and the              12       METHOD(KILL(H,D))
experimental text into the HyperCard program.                         13       METHOD(RESCUE(H,P))
                                                                      14       METHOD(TRANSFER(H,P))
Coding of Protocol Data                                               15       EVENT(HEAR(C,NEWS))
                                                                      16       OUTCOME(REWARD(C,H))
The recall and summarization protocol data for each                   17       INITIAL-CONTEXT
individual participant in the study was then coded as an              18       FINAL-CONTEXT
ordered sequence of complex propositions with the aid of
the AUTOCODER computer program (Durbin, Earwood,                   Semantic Coherence Knowledge Digraph Based
and Golden, 2000). This computer program may be                    Upon Rumelhart’s (1977) Story Grammar
downloaded for research purposes only by visiting the web
site: www.utdallas.edu/~golden/autocoder.                          The semantic coherence knowledge digraph is intended to
                                                                   model the predictions of Rumelhart’s (1977) theory for
                                                                   predicting the order in which experimental participants will
                Proposed Situation Model                           generate sequences of propositions when they were asked to
The proposed situation model is assumed to consist of two          summarize the experimental text. According to Rumelhart’s
components: (1) a “reproductive memory” representation of          semantic analysis of the experimental text, episodes in the
the order in which the ideas in the text were presented, and       story are hierarchically organized with the “lower-level”
(2) a “semantic local coherence” representation. These two         episodes describing the achievement of the subgoals for the
semantic representations are formally expressed as directed        “higher-level” episodes. Rumelhart’s (1977) model makes
graphs or “knowledge digraphs” which depict relations
                                                                   predictions about the levels of summarization for this story.
among a set of complex propositions. The complex
                                                                   Rumelhart’s (1977) predictions regarding Level 0, Level 1
propositions used in the proposed situation model are listed
in Table 2. They were derived from Rumelhart’s (1977)              and Level 2 summaries for “The Czar and his Daughters”
analysis of the “Czar and the Daughters” text. The                 are summarized in Figure 2. A concise summary from
proposition node number 17 refers to the initial mental state      Rumelhart’s model would be modeled by the arcs in Figure
of the participant which arises from a request for the             2 as the path: 17, 6, 13, 16, 18 While more detailed
participant to recall or summarize the text. The proposition       summaries would be modeled by other paths through the
                                                                   network presented in Figure 2 (e.g., 17, 6, 8, 13, 16, 18).
                                                               617

                                                                  participants. By reworking the mathematics such that the
                       17             9                           sample size is based upon the number of propositions
                                                                  mentioned following the method of Golden (in press), the
                                                                  statistical power of the KDC theory is dramatically
                                      10                          improved.
                       1
                                                                                         17
                       2              11
                                                                                                        4
                       3              12
                                                                                          6
                       4              13
                                                                                                        8
                       5              14
                                                                                         13
                       6              15
                                                                                                      15
                       7
                                      16
                                                                                         16
                       8
                                      18
                                                                                         18
Figure 1: Reproductive Memory Knowledge Digraph. Each             Figure 2: Rumelhart Summarization Knowledge Digraph.
arc indicates the order in which a proposition in Table 1         Each arc indicates the order in which a proposition in Table
follows another in the original text.                             1 is expected to follow another in a story summary based
                                                                  upon a story grammar causal network analysis.
   Knowledge Digraph Contribution Analysis
                                                                  Statistical Model
Overview
                                                                  Formally, let xi(t) indicate the tth proposition mentioned by
Knowledge Digraph Contribution (KDC) analysis is a
                                                                  the ith participant in the experiment within a particular
special type of categorical time-series analysis which is
                                                                  experimental condition where the notation xi(t) denotes a d-
specifically intended to identify evidence for different types
                                                                  dimensional vector. If xi(t) refers to the kth proposition in
of knowledge digraphs through the analysis of ordered
                                                                  the proposition dictionary, then xi(t) is the kth column of a
sequences of propositions in production data. More
                                                                  d-dimensional identity matrix. In such a situation, the vector
specificially, KDC theory is based upon a specialized type
                                                                  x(t) defined as the kth column of a d-dimensional identity
of multinomial logistic regression time-series analysis
                                                                  matrix would denote that the tth proposition mentioned by a
where individual beta weights in the model correspond to
                                                                  particular participant within a particular experimental
the influence of different knowledge digraphs. . The KDC
                                                                  condition was the kth proposition in a dictionary of d
software used here may be downloaded (for research
                                                                  propositions. Let p(x(t)=uk) denote the probability that the
purposes        only)       from        the     web       site:
                                                                  the tth proposition mentioned by the participant will be the
www.utdallas.edu/~golden/kdc. Earlier versions
                                                                  kth proposition in the proposition dictionary. Let R be a
of KDC theory (e.g., Golden, 1994, 1995, 1998) based the
                                                                  matrix which specifies the reproductive memory knowledge
sample size on the number of participants in the experiment
                                                                  digraph in Figure 1 such that the ijth element of R is equal
instead of the number of propositions mentioned by the
                                                              618

to one if the jth node in Figure 1 is connected to the ith node    Connectionist Model Interpretation
by an arc and a zero otherwise. Similarly, let C be a matrix       Finally, note that as shown in Golden (1998), the
which specifies the causal knowledge semantic coherence            probabilistic model in KDC theory has a dual interpretation
relation digraph in Figure 2 such that the the ith element of
                                                                   as a particular type of highly structured connectionist
C is equal to one if the jth node in Figure 2 is connected to
                                                                   network. Figure 3 shows a portion of the connectionist
the ith node by an arc and a zero otherwise. Let βR and βC
be the “contribution weights” indicating the respective            network interpretation of Equations (1) and (2). The
influences of the d-dimensional square knowledge digraph           activation levels of the input units are denoted by x14, x15,
matrices R and C. Then the specific KDC statistical model          and x16 and only x14 is activated indicating that proposition
used here is specified by:                                         14 was most recently mentioned by the model. The next
                                                                   layer of connection strengths which connect the input units
              p(x(t)=uk) = exp((uk)Thk)/∑m (uk)Thm           (1)   to the hidden units are specified by the knowledge digraphs
                                                                   in Figure 1 and Figure 2. Only two parameters βR and βC are
for m = 1, …, d and where:                                         estimated in order to obtain the complete mapping from
                                                                   input units to hidden units. The activation levels of the
                    hm= [ βR R + βCC ] x(t-1).               (2)   hidden units are specified by Equation (2) in the text. The
                                                                   output layer of connection strengths is a forward lateral
Figure 3: Connectionist Interpretation of KDC Model.               inhibition mapping which is constant and implements the
Only 3 of the 18 proposition nodes (propositions 14,15, and        “softmax” nonlinearity described by Bridle (1990). The
16 in Table 1) are shown. In this example, the model has           output activations are probabilities which are always
just mentioned proposition 14 in Table 1 and the                   positive and sum to one and are specified by Equation (1) in
probabilities that the model will generate propositions 14,        the text.
15, and 16 (denoted as p(14), p(15), and p(16)) are                   Computing maximum likelihood estimates using KDC
computed and returned as the output unit activations of the        theory is formally equivalent to having the connectionist
network.                                                           network learn to recall or summarize texts using human
                                                                   production data as training data. Production data can be
The two free parameters in the model are the contribution          generated from the connectionist network by sampling from
weights βR and βC which indicate the respective predictive         the KDC probability model.
influence of knowledge digraphs R and C. Using the large
sample methods of Golden (in press; also see White, 1994)          Parametric Bootstrapping
maximum likelihood estimates of the contribution weights              In order to check the validity of the large sample
can be estimated in conjunction with their standard errors.        approximations, three such connectionist networks were
In addition, statistical tests can be constructed for providing    constructed for each of the three experimental conditions.
insights regarding how the beta weights change as a                Then, each of these three networks was used to generate
function of the instruction condition in the experiment.           three simulated response data sets where each data set
                                                                   consisted of the responses from 24 simulated subjects. The
                                                                   generation algorithm consisted of simply sampling from the
     p(14)                p(15)            p(16)                   KDC probability model described by Equations (1) and (2)
                                                                   to generate three additional “simulated” data sets. Then for
                                                                   each simulated response data set the contribution weights
                                                                   were estimated. Since there were three              parameter
                                                                   estimations for each of the three experimental conditions
                                                                   involving both the reproductive memory and semantic
                                                                   coherence contribution weights, 18 additional contribution
                                                                   weights were estimated. These additional 18 contribution
                                                                   weights will be referred to as “bootstrap contribution weight
                                                                   estimates”. If the large sample approximations are correct,
                                                                   then the standard errors estimated by the theory should
                                                                   approximately contain the bootstrap contribution weights
                                                                   estimated/learned from the simulated data.
                                                                                             Results
            βR
                                        βR + βC                    Qualitative Overview
                                                                   The results of applying KDC theory to the data in this study
                                                                   are reported in Figure 4. As can be seen from Figure 4, the
                                                                   influence of the Reproductive Memory Knowledge Digraph
                                                                   Contribution Weight βR has the greatest influence when
                                                                   participants are asked to recall a text, a moderate influence
       x14                  x15               x16
                                                               619

for the detailed summary condition, and the least influence      of beta weights between the detailed summary and recall
in the concise summary condition. In contrast, the influence     instruction conditions, W(2) = 4.7, p = 0.10 (please see
of the Semantic Coherence Knowledge Digraph                      Figure 4). Post-hoc analyses showed this marginally
Contribution Weight βC has the greatest influence in the         significant difference appeared to arise from a smaller
concise summary condition and shows a tendency to                reproductive memory contribution βR weight (Z=2.1, p =
decrease in the detailed summary condition and decrease          0.03) in the detailed summary relative to the recall
further in the recall condition.                                 instruction conditions. Although the semantic coherence βC
                                                                 weight was larger in the detailed summary instruction
Statistical Test Results                                         relative to the recall condition as shown in Figure 4, this
Within-Group KDC Statistical Tests As previously noted           difference was not statistically significant (Z=0.04, p =
in Figure 4, the βR and βC contribution weights were             0.97).
estimated using each of the three data sets yielding six beta       A third KDC between-group planned comparison test
weight estimates. KDC theory was then used to estimate the       showed no significant change in the pattern of beta weights
standard errors for each of the six beta weights. These          between the detailed summary and concise summary
standard errors are plotted as confidence intervals in Figure    instruction conditions, W(2) = 2.1, p = 0.35 (despite the
2 as well. All six beta weight coefficients were significantly
                                                                 clear trends in the data depicted in Figure 4).
positive (p < 0.0001) indicating a statistically significant
contribution of all knowledge digraphs.
                                                                 Reliability of the Asymptotic Statistical Inferences
                                                                    The reliability of the estimated variance-covariance
                                                                 matrix of the parameter estimates is indirectly checked by
                                                                 seeing if the bootstrap contribution weights lie
                                                                 approximately within the estimated confidence intervals.
                                                                 Inspection of Figure 4 shows the bootstrap contribution
                                                                 weights (identified by the small circles and small triangles)
                                                                 tended to lie within the estimated confidence intervals with
                                                                 the sole exception of one bootstrap reproductive memory
                                                                 contribution weight estimate in the concise summary
                                                                 condition. These observations supports the appropriateness
                                                                 of the large sample approximations used in this paper.
                                                                           General Discussion and Summary
                                                                    Qualitative trends obtained from the KDC data analysis
                                                                 showed that semantic knowledge components of the
                                                                 situation model are more dominant than reproductive
                                                                 memory situation model components for summarization
Figure 4: Reproductive Memory and Causal Knowledge               data. Moreover, the reverse pattern tends to hold for recall
Digraphs. Reproductive memory knowledge digraph is               protocol data. KDC statistical analyses indicated that the
                                                                 semantic knowledge components of the situation model
depicted by the solid arcs. Rumelhart’s semantic local
                                                                 provide influence production data in a similar way in both
coherence causal knowledge digraph is depicted by the
                                                                 recall and summarization. On the other hand, the
dashed arcs. Smaller circles and triangles denote bootstrap      reproductive memory knowledge digraph had a greater
contribution weight estimates (see text for details).            influence in the recall condition relative to the
                                                                 summarization conditions. Simulation studies supported the
Between Group KDC Statistical Tests As shown in Figure           reliability of the large sample statistical inferences which
4, a between-group planned comparison KDC statistical test       only revealed a reliable difference in the pattern of beta
revealed the βR and βC contribution weights estimated in         weights between the concise-instruction and recall-
the concise instruction condition differed reliably from the     instruction experimental conditions.
contribution weights estimated in the recall instruction            Because of the clear trends in the data shown in Figure 4,
condition, W(2) = 10.3, p = 0.006. Post-hoc analyses             a likely interpretation of the obtained results is that the lack
showed this reliable difference appeared to arise from a         of reliable differences between the detailed summary
smaller reproductive memory contribution βR weight               instruction condition and the other recall and concise
(Z=3.1, p = 0.002) in the concise relative to the recall         summary instruction conditions is simply due to a lack of
instruction conditions. Although the βC weight was larger        statistical power associated with the KDC analysis. An
in the concise instruction relative to the recall condition as   alternative interpretation is that the lack of reliable
shown in Figure 2, this difference was not statistically         differences might simply not be present indicating that
significant (Z=1.0, p = 0.3).                                    differences in recall and summarization performance arise
                                                                 primarily due to reproductive memory processes.
   A second KDC between-group planned comparison test
showed only a marginally significant change in the pattern
                                                             620

   In summary, a new categorical time-series analysis             Experimental Psychology: Learning Memory and
method called KDC analysis was applied to the analysis of         Cognition, 4, 318-330.
previously unpublished recall and summarization protocol        Kintsch, W. (1998). Comprehension: A paradigm for
data. In addition to providing some new insights into the         cognition. New York: Cambridge University Press.
relationship between recall and summarization data, the         Mandler, J. M. & DeForest, M. (1979). Is there more than
methodology and results described in this paper provided an       one way to recall a story? Child Development, 50, 886-
example of the usage of KDC analysis within the context of        889.
a practical cognitive modeling problem and illustrated how      Mani, I. (2001). Automatic summarization. Philadelphia:
the large sample approximations could be checked using a          John Benjamins Publishing Company.
connectionist model for parametric bootstrapping simulated      Mani, I. and Maybury, M. T. (1999). Advances in automatic
data generation.                                                  text summarization. Cambridge: MIT Press.
                                                                Mann, W. C. and Thompson, S. A. (1987). Rhetorical
                   Acknowledgments                                structure theory: Towards a functional theory of text
                                                                  organization. Text, 8, 243-281.
This research was supported in part by the Information
                                                                Kintsch, W. and van Dijk (1978). Toward a model of text
Technology Research (ITR) Initiative through the Research
                                                                  comprehension and production. Psychological Review,
on Learning and Education Program Award 0113369 to
                                                                  85, 363-394.
Richard M. Golden.
                                                                Rumelhart, D. E. (1977). Understanding and summarizing
                                                                  brief stories. In D. LaBerge & S. J. Samuels (Eds.), Basic
                        References                                processes in reading: Perception and comprehension (pp.
Bridle, J. S. (1990). Probabilistic interpretation of             265-303). Hillsdale, NJ: Erlbaum.
  feedforward classification network outputs, with              Stein, N. L., & Glenn, C. G. (1979). An analysis of story
  relationships to statistical pattern recognition. In Neuro-     comprehension in elementary school children. In R. O.
  computing: Algorithms, Architectures, and Applications          Freedle (Ed.), New directions in discourse processing:
  (F. Fougelman-Soulie and J. Herault, eds.), pp. 227-236.        Vol. 2. Advances in discourse processes (pp. 53-120).
  New York: Springer-Verlag.                                      Norwood, New Jersey: Ablex.
Britton, B., Meyer, B., Hodge, M., & Glynn, S. (1980).          Trabasso, T. & Magliano, J. P. (1996). Conscious
  Effects of the organization of text on memory: Texts of         understanding      during    comprehension.    Discourse
  retrieval and response criterion hypotheses. Journal of         Processes, 21, 255-287.
  Experimental Psychology: Human Learning and Memory,           White, H. (1994). Estimation, inference,and specification
  6, 620-629.                                                     analysis. New York: Cambridge University Press.
Durbin, M. A., Earwood, J., & Golden, R. M. (2000).
  Hidden Markov models for coding story recall data. In
  Proceedings of the 22nd Annual Cognitive Science Society
  Conference. Mahwah, New Jersey.
Einstein, G., McDaniel, M., Bowers, C., & Stevens, D.
  (1984). Memory for prose: The influence of relational and
  proposition-specific processing. Journal of Experimental
  Psychology: Learning Memory and Cognition, 10, 133-
  143.
Golden, R. M. (1994). Analysis of categorical time-series
  text recall data using a connectionist model. Journal of
  Biological Systems, 2, 283-305.
Golden, R. M. (1995). Making correct statistical inferences
  using a wrong probability model. Journal of
  Mathematical Psychology, 38, 3-20.
Golden, R. M. (1998). Knowledge digraph contribution
  analysis of protocol data. Discourse Processes, 25, 179-
  210.
Golden, R. M. (in press). Discrepancy risk model selection
  test theory for comparing possibly misspecified or
  nonnested models. To appear in Psychometrika.
Goldman, S & Varnhagen, C. (1986). Memory for
  embedded and sequential story structures. Journal of
  Memory and Language, 25, 401-418.
Graesser, A. C., Robertson, S. P., & Anderson, P. A. (1981).
  Incorporating inferences in narrative representations: A
  study of how and why. Cognitive Psychology, 13, 1-26.
Hasher, L. & Griffin, M. (1978). Reconstructive and
  reproductive processes in memory. Journal of
                                                            621

