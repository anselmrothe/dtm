UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Additive or Multiplicative Perceptual Noise? Two Equivalent Forms of the ANCHOR Model

Permalink
https://escholarship.org/uc/item/1d14r27g

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 25(25)

Author
Petrov, Alexander A.

Publication Date
2003-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Additive or Multiplicative Perceptual Noise?
Two Equivalent Forms of the ANCHOR Model
Alexander A. Petrov (apetrov@uci.edu)
Department of Cognitive Sciences
University of California, Irvine, CA 92697 USA

Abstract
ANCHOR is an integrated memory-based scaling
model that accounts for a wide range of phenomena
in category rating and absolute identification. The
model uses anchors stored in memory that serve as
prototypes for each response category. The stimuli are represented by magnitudes. Two alternative formulations of the magnitude variability are
considered: additive noise, which leads to logarithmic scales, and multiplicative noise, which leads to
power scales. Both formulations are consistent with
Weber’s and Stevens’s laws. Four variants of the
ANCHOR framework systematically explore these
alternative formulations. The performance of the
models is evaluated against experimental data. The
results show that the form of the perceptual equation is not critical for the operation of the model.
Thus, the power vs. logarithmic controversy does
not affect ANCHOR’s central claim that human
scaling performance is memory-based.

Introduction
Ever since the seminal work of Thurstone (1927) subjective continua occupy a prominent place in psychological theory. This notion captures in a convenient
and general way two complementary aspects of the
perceptual system: its systematicity and variability.
A stimulus of physical intensity S gives rise to an internal magnitude M . Due to perceptual uncertainty,
M is a random variable with non-zero variance. Its
location is systematically related to the intensity S.
This paper elaborates some of these ideas within
the framework of the ANCHOR model (Petrov &
Anderson 2000; Petrov, 2001). The presentation
rests entirely on absolute-identification data, although the model applies equally well to other scaling tasks (Petrov & Anderson, 2000, submitted).
The absolute identification task is of considerable interest because it reveals some intriguing limitations
of the cognitive system (Miller, 1956). Moreover, it
makes direct contact with both psychophysical scaling (notably category rating) and memory (notably
paired-associate learning). These are exactly the two
domains that ANCHOR sets out to integrate.
The most influential model of absolute identification postulates N − 1 criteria that partition the
subjective continuum into N regions (Torgerson,

922

1958). When a stimulus is presented for identification, its internal magnitude falls within one of
these regions and is labeled with the corresponding response. The overall accuracy is limited by uncertainties within the perceptual system (“perceptual noise”) and/or in the criterion locations. When
augmented with mechanisms for dynamic criterion
setting this framework can account for various sequential effects (Treisman & Williams, 1984).
A criterion bisects the magnitude continuum and
is very natural for binary decisions. When the
number of responses increases, however, the criterion framework becomes progressively unwieldy
and an alternative framework seems more appealing. Instead of emphasizing the boundaries between
adjacent regions, it centers on the prototypes—or
anchors—of each response category.
The anchors are magnitude-response associations
that reside in memory and internalize the stimulusresponse mapping required by all scaling tasks. Using the magnitude of the target stimulus as a cue, the
memory system selects a single anchor that, perhaps
after a minor correction, determines the response.
The selection mechanism is sensitive to factors such
as similarity, recency, and strength.
The anchor-based scheme offers considerable advantages (Petrov & Anderson, submitted). It is very
straightforward and consistent with the introspective protocols of human observers. The growing field
of memory psychophysics (Algom, 1992) provides
abundant evidence that magnitude-response associations can be committed to memory and maintained
over extended periods. There are also well documented sequential (e.g., Luce, Nosofsky, Green, &
Smith, 1982; Lockhead & King, 1983) and context
effects (e.g., Parducci & Wedell, 1986) that clearly
indicate that some kind of internal state persists
across trials, blocks, and even days and influences
subsequent processing. Memory seems the most natural candidate to perform this function. Finally,
the anchor hypothesis meshes seamlessly with the
huge corpus of memory-related theory and data and
in particular the ACT-R architecture (Anderson &
Lebiere, 1998). ANCHOR thereby establishes connections between psychophysical scaling and a whole
array of ACT-R applications.

S→

perceptual
subsystem

→M →

central
subsystem

→R

Figure 1: The stimulus S maps to an internal magnitude M which in turn maps to the response R.
The link between the two theories is the construct
of internal magnitude (Figure 1). It is assumed that
some sensory processes, collectively referred to as
perceptual subsystem, construct a magnitude M that
encodes the intensity of the stimulus S. This magnitude is then processed within the central subsystem
to determine the overt response R. Each subsystem can maintain an internal state that evolves in
time and differs from trial to trial. The processing,
therefore, is far more complex than the simple sequence suggested by the diagram. The response R
depends not only on the immediate stimulus S but
also, at least in principle, on all previous stimuli and
responses. This gives rise to various sequential, context, transfer, and other dynamic effects.
The defining claim of the ANCHOR theory is that
the bulk of the processing within the central subsystem is memory-based. This claim is supported by
experimental evidence and by detailed simulations
with the model (Petrov & Anderson, 2000; Petrov,
2001; Petrov & Anderson, submitted). It seems warranted, therefore, to adopt the ANCHOR characterization of the central subsystem and consider its implications for the perceptual one. This is the task
we set for ourselves in this article.
The next section presents ANCHOR first in general terms and then with specific equations. Building
on this foundation, subsequent sections discuss two
alternative forms of the perceptual equation. Then
an identification experiment is reported and the alternative versions of the model are fitted to the data.

Main Principles of ANCHOR
Internal Magnitude Continuum. Each stimulus induces a subjective magnitude M . It is this internalized quantity that can be committed to memory and compared against other magnitudes.
Content-Addressable Memory. The second
principle postulates content-addressable memory involving these magnitudes. In particular, it is possible to establish associations between a magnitude
and the label of a response category. These anchors
substantiate the mapping between magnitudes (and
hence the stimuli represented by them) and responses. When a new target magnitude is produced
by the perceptual subsystem, the memory fills in the
corresponding response label. This completion process is stochastic and depends on two factors: (a)
the location of the target magnitude with respect to
the various anchors in memory and (b) the frequency

923

and recency of use of each response category. The
latter factor is captured by the base-level activations
(or biases) of the anchors. These activations play a
very important role in the theory and make direct
contact with many memory-related phenomena.
Explicit Correction Strategies. Because the
memory system is noisy and prone to biases, it is
not guaranteed to provide on each trial the anchor
that best matches the target magnitude. The verbal
protocols of human observers suggest that they are
aware of the unreliability of their “first guesses” and
adopt explicit correction strategies. Consequently,
the third ANCHOR principle provides for such explicit corrections. Phenomenologically, an introspective report of a trial might go like this, “I see the
stimulus. . . It looks like a 7 . . . No, it’s too short for
a 7 ; I’ll give it a 6.” Such increments and decrements have far-reaching implications and are vital
for the stability of the overall system, especially in
the absence of feedback.
Obligatory Learning. So, the stimulus has been
encoded, matched against anchors, and a response
has been produced. Is this the end of the trial? No,
according to the fourth ANCHOR principle. Two
learning mechanisms update the internal state of the
model: the base-level activations and locations of the
anchors. All changes are incremental and give rise
to various dynamic effects.

The Perceptual Subsystem
ANCHOR uses a simplified generic formulation of
the perceptual subsystem that still takes into account the fundamental empirical constraints imposed by Weber’s and Stevens’s laws. The whole
subsystem is modeled by a single equation describing the distribution of magnitudes as a function of
the stimulus intensity S. It abstracts away factors
such as attention, habituation, Gestalt, etc. They
can be included in the future without disrupting the
rest of the theory.
Weber’s Law. One empirical constraint that cannot be neglected by any credible scaling system is
that the difference threshold ∆S tends to be proportional to S over much of the dynamic range of
the stimulus attribute. Thus the ratio of the two—
the Weber fraction—is approximately constant for a
given perceptual modality:
∆S/S = k = const

(1)

Stevens’s Law. The other major empirical regularity comes from a vast array of magnitude estimation and category rating studies (Stevens, 1957,
1975). For intensive (or prothetic) continua the average rating R varies approximately as a power function of the stimulus intensity S:
R = aS n

(2)

Both Weber’s and Stevens’s laws are subject to
qualifications and various alternative formulations
have been proposed (e.g., Ekman, 1959; Norwich &
Wong, 1997). Most of them deal with deviations
near the low absolute threshold and can be put aside
for our present purposes.
Additive Noise Equation. The standard interpretation of Weber’s law is that the subjective magnitude M is proportional to the logarithm of the
stimulus. Assuming equal variance (Fechner’s postulate), this explains the progressively poorer discriminability at higher intensity levels. Equation 3
formalizes these ideas. In it, a is an arbitrary conversion factor and εp is a Gaussian deviate with
mean zero and variance scaled by the free parameter σp = const. This perceptual noise makes the
magnitude M a random variable too.
M = a (log S + σp εp )

(3)

Multiplicative Noise Equation. It is possible,
however, that the standard deviation of each magnitude distribution grows in proportion to its mean
(Ekman’s law, 1959). The spacing among the means
can thus be less compressive than the logarithm in
Eq. 3 and still produce poorer discriminability at
higher intensities. In fact, it has been shown mathematically that when the centers of the magnitude
distributions vary as a power function of the stimuli, Ekman’s law implies Weber’s law and vice versa
(Norwich & Wong, 1997; Petrov & Anderson, submitted). This leads to Equation 4, in which n is the
exponent from Stevens’s power law (Eq. 2) and kp
is a dimensionless coefficient of proportionality. The
noise εp has zero mean and unit variance as in Eq. 3.
M = aS n (1 + kp εp )

(4)

In summary, we have two alternative equations,
one with additive and the other with multiplicative
perceptual noise, that are equally consistent with
the two foremost empirical regularities in the psychophysical literature.
Faced with this underdetermined situation the
theoretician has a choice. We have no strong commitments on this issue, although all ANCHOR simulations reported so far (Petrov, 2001; Petrov & Anderson, 2000, submitted) use Equation 4. Our goal
in the present paper is to investigate whether this
particular choice limits the applicability of our earlier results. To that end, we compare the behavior of the model under additive and multiplicative
noise, everything else being equal. Before embarking on this project, however, a brief description of
the other ANCHOR mechanisms is in order.

The Central Subsystem
The model maintains an anchor for each response
category. The location Li of each anchor i represents

924

the current estimate of the prototypical member of
the corresponding category. When a target magnitude M is presented for identification, it acts as a
memory cue and the anchors compete to “match”
this target. Due to memory fluctuations, the processing on each trial depends on anchor magnitudes
Ai , which are noisy versions of the locations Li .
For consistency, the memory noise in the model has
the same form as its perceptual counterpart. Thus,
Equation 5 and 3 form a pair, and similarly Equations 4 and 6. The standard deviation of the additive memory noise is a σm and the coefficient of the
multiplicative noise is km . Again, εm is Gaussian.
Ai = Li + a σm εm

(5)

Ai = Li (1 + km εm )

(6)

A selection mechanism determines, stochastically,
a single anchor on each trial. The outcome of the
competition is described by two equations in the
model. Equation 7 produces goodness scores Gi and
the “softmax” Equation 8 converts them into selection probabilities Pi :
Gi = − |M − Ai | + HBi

(7)

exp(Gi /T )
Pi = P
j exp(Gj /T )

(8)

Each goodness score Gi is a sum of two terms:
similarity − |M − Ai | and history HBi . The first
is simply the negation of the mismatch between the
target magnitude M and the anchor magnitude Ai .
The second term reflects the base-level activation Bi
of the anchor, weighted by a parameter H. It does
not depend on the target at all. The “temperature”
parameter T controls the degree of non-determinism
in the selection process.
The memory system is noisy and prone to biases.
Therefore it is not guaranteed to provide the anchor
that best matches the target. The correction mechanism attempts to compensate for that. It compares
the target magnitude M and the anchor magnitude
A to determine the discrepancy D = M − A. If the
latter is less than some cutoff value c, the response
associated with the anchor is chosen as the final response on the trial. Otherwise the anchor response is
corrected by ±1 or occasionally even ±2 depending
on the algebraic difference D. The respective cutoffs
are ±c and ±3c. The final response R is the sum of
the anchor label and the correction, clipped between
the lowest and highest valid category if needed.
The cutoff parameter c is chosen so that the corrections are conservative—substantial discrepancy
D is required to trigger any changes. The memoryrelated effects introduced during the anchor selection
process thus persist, albeit attenuated, and produce
sequential and context effects in the responses.
At the end of the trial, feedback indicating the correct response is typically provided in absolute identification experiments. In category rating without

feedback, the model uses its own response as the best
available estimate. Either way, exactly one anchor is
considered “used” on that trial and its location L is
updated according to Equation 9, which is a form of
competitive learning. The new location is pulled towards the target magnitude M , thereby improving
the chances that the same anchor will match this
target in the future. This tends to promote consistency but has other consequences as well, notably
context effects (Petrov & Anderson, submitted).
L(t+1) = (1 − α)L(t) + αM (t)

(9)

In the long run, the location of each anchor becomes a running average (exponentially discounted
by the learning rate α) of the magnitudes of all stimuli classified under the associated response category.
Therefore the anchors represent true prototypes.
In contrast to the competitive learning mechanism, the base-level learning Equation 10 updates
the availability of every anchor on each trial. The
formula is not transparent and can be discussed only
briefly here. It is an approximate and parameter-free
version of the base-level learning equation in ACT-R
(Anderson & Lebiere, 1998, p. 124). The availability B of a given anchor reflects the frequency and
recency of its use. The formula disregards the detailed history and retains only three critical pieces of
information: the lag since the most recent use tlast ,
the total time since the creation of the anchor tlif e ,
and the overall number of uses n.
·
¸
2(n − 1)
√
B = log t−0.5
+
(10)
√
last
tlif e − tlast
Qualitatively, Equation 10 captures three important aspects of memory dynamics: sharp transient
boost immediately after use, gradual buildup of
strength with frequent use, and gradual decay in the
absence of use.

Identification Experiment
To evaluate the performance of the ANCHOR model
under the alternative noise formulations, we use the
data set from an absolute identification experiment
reported in full detail in (Petrov & Anderson, submitted). Only a small subset of the data is sufficient
for our present purposes and is described below.
Method. The stimuli were pairs of dots presented
at randomized locations on a monitor. The independent variable was the distance between the dots.
Only 9 stimulus lengths were involved: 275, 325,
375, . . . , 675 pixels (275 pix ≈ 88 mm ≈ 8.4 deg.
visual angle; 675 pix ≈ 216 mm ≈ 20 d.v.a). The
imaginary segment formed by the dots was always
horizontal. 24 naı̈ve observers were instructed that
there were 9 stimuli and 9 responses and that their
task was to identify “the distance between the dots”

925

by pressing a key from 1 to 9. Each observer completed 450 trials with feedback. The stimulus presentation frequencies were non-stationary in order
to induce context and transfer effects (see Petrov &
Anderson, submitted, for details). The presentation
schedule was counterbalanced so that each stimulus
appeared exactly 50 times.
Results. The experiment yielded a wealth of data
and replicated all classical absolute-identification
phenomena falling within its scope. These included:
limited information capacity (Miller, 1956), various
sequential effects, repetition effect, edge effect, and
practice effect. An unexpected assimilative context
effect was also found (Petrov & Anderson, submit.).
The linear correlation coefficient between stimuli
and responses is extremely high (r > 0.92 for all
observers). This suggests a linear relationship and
can be interpreted as a power law with n = 1 (Eq. 2).
This replicates the robust finding that the exponent
for line length is very close to 1.0 (Stevens, 1975).
Three empirical profiles are singled out as our current modeling targets. They are plotted with “–×–”
symbols in Figure 2. The top panel shows the overall probability of correct identification for each of the
nine stimuli. An edge effect is clearly visible.
The elevated accuracy near the edges could stem
from the simple fact that there are fewer possibilities
for mistake there. The inter-stimulus discriminability d0i,i+1 is a better measure of the identification
performance (Luce et al., 1982). It is calculated
from the S × R probability matrix for each of the
8 inter-stimulus boundaries. Whenever Si+1 is presented, all responses ≥ i + 1 are considered “hits”
and those ≤ i “misses.” On the other side of the
boundary, on trials with Si the responses ≥ i + 1 are
“false alarms” and ≤ i “correct rejections.” The discriminability d0 is then computed in the usual way,
separately for each participant. The middle panel in
Figure 2 plots the group average.
The asymmetry in the d0 profile suggests that
short distances are more discriminable than long
ones. This finding is directly related to Weber’s law
(Eq. 1) and hence to the issues of main interest here.
Each stimulus elicits a whole distribution of responses. The third panel in Figure 2 plots the standard deviations of these distributions. The profile
seems to increase but not by much: all values vary
between σ2 = 0.63 and σ8 = 0.81 (save the flanks,
which are contaminated by edge effects).
Let us assume temporarily, as Stevens (1957) once
did, that the overt responses R are direct reports of
the internal magnitudes M . Then the additive noise
Equation 3 would predict a flat deviation profile for
all stimuli. The multiplicative Equation 4 with n =
1, on the other hand, predicts proportionality.
On the surface, the empirical profile looks like
a compromise between these two extremes. Such
conclusion, however, is unwarranted because the re-

Probability correct

0.9
0.7
0.6

Inter−stimulus d’

Profile
Accuracy
Discriminability
Variability

0.5
1

Standard deviation

Table 1: Root mean squared errors of the fits of the
models described in the text to the empirical profiles.

E
P
Mlin
Mlog

0.8

3

5

7

Plin
.10
.21
.10

Plog
.10
.21
.09

Mlin
.06
.17
.03

Mlog
.07
.25
.04

9

2.0
1.5
1.0
1

3

5

7

9

1

3

5
Stimulus

7

9

1.0
0.8
0.6
0.4

Figure 2: Empirical profiles (E) and model fits for
the perceptual mechanism alone (P ) and the full
model with linear (Mlin ) and logarithmic (Mlog )
magnitude scales. Overall accuracy (top), discriminability d0 for each inter-stimulus boundary (middle), and standard deviation of responses (bottom).
sponses are only indirectly related to the internal
magnitudes. Moreover, the task involves feedback.
The deviation data must be interpreted in a framework that takes the M → R transition in Figure 1
into account. Thus we turn to the ANCHOR model.

Model Fits and Simulations
We experiment with four variants of the model—
denoted Plin , Plog , Mlin , and Mlog below. The
two “perception only” variants P bypass most central mechanisms in order to highlight the perceptual
subsystem. The M variants engage all mechanisms.
In particular, Mlin is synonymous with the standard
ANCHOR model (Petrov & Anderson, submitted).
The multiplicative noise Equation 4 defines a linear magnitude scale when n = 1. This is the basis
of model Plin . The conversion factor a is arbitrarily set to alin = 0.001 so that stimulus S5 , which
is 475 pixels long, produces magnitudes centered on
M = 0.475. The coefficient kp is the only free parameter of this model. The nine anchors are opti-

926

mally placed (at the images of the stimuli) and the
response is always based on the anchor that best
matches the target. This is equivalent to a Thurstonian system with fixed criteria (Torgerson, 1958).
Model Plog is based on the additive noise Equation 3 and hence a logarithmic magnitude scale. In
an effort to make the simulations as comparable as
possible, the conversion factor a in this case is set
to alog = 0.0771. Thus the image of S5 is again
M = 0.475. The anchors are placed at the logarithmic images of the stimuli. Everything else is as in
Plin . The standard deviation σp is a free parameter.
Model Mlin upgrades Plin with all central mechanisms. The memory noise is multiplicative (Eq. 6).
This amounts to the standard ANCHOR model
and provides default values for many parameters
(Petrov & Anderson, submitted). It is convenient
to formulate them in category-size units δ. The distance between any two adjacent categories on the
linear scale is δlin = 0.050. The default history parameter is H = 0.100 = 2δ (Eq. 7); temperature
T = 0.050 = δ (Eq. 8); rate α = 0.3 (Eq. 9). Three
free parameters remain: kp , km , and the cutoff c.
Finally, model Mlog explores an additive-noise
version of ANCHOR. Equations 3 and 5 replace
4 and 6, respectively. Everything else remains the
same. The new category-size unit is estimated as the
geometric mean of the eight intervals on the scale.
For alog = 0.0771 this yields δlog = 0.0084. The default parameters can now be converted: H = 2δ =
0.0167, T = δ = 0.0084, α = 0.3. Model Mlog thus
has three free parameters: σp , σm , and c.
Each model is fitted to the empirical d0 profile
via least mean squares. The optimal parameters are
as follows. Plin : kp = 0.076. Plog : σp = 0.076.
Mlin : kp = 0.031, km = 0.046, c = 0.75 δlin . Mlog :
σp = 0.041, σm = 0.050, c = 0.50 δlog .
Next, we generate predictions from the models
and compare them against the three empirical profiles (Fig. 2). The predictions for models Plin and
Plog can be calculated directly from the corresponding perceptual equation. For the full models we must
resort to simulations. Both models are run 10 times
on each of the 24 stimulus sequences shown to the
human observers. The responses are then analyzed
in exactly the same way as the empirical data.
Figure 2 plots the simulated profiles and Table 1
reports the associated root mean squared errors.

The two “perception only” variants are nearly
equivalent. In fact, their profiles are so close to each
other that are plotted together in Figure 2. This is
consistent with their mathematically proven equivalence with respect to Weber’s law and suggests that
the equivalence extends to the absolute identification task as well. (The proofs are for the 2AFC
task.) Remarkably, the response variability profiles
(bottom panel) of Plin and Plog are very similar too,
with only minor discrepancies at the edges. Thus,
even though the noise on the magnitude continua are
qualitatively different in the two models, the variability of the overt responses is the same. This is
explained by the compensatory spacing of the anchors. The predicted profile, however, is too steep
in comparison with the experimental data.
The full models Mlin and Mlog are superior to
their simpler counterparts. In general, the central
subsystem tends to redistribute resources among the
anchors, thereby reducing the steepness and asymmetry of all three profiles. This improves the fits
as the empirical profiles tend to be quite level (barring the edge effects). The only feature that all four
models fail to reproduce is the upward turn at the
right edge of the d0 profile (the bow effect). Model
Mlin is the least discrepant from the experimental
data in this region, which explains its reduced error
(rmse = 0.17) relative to the other models.
Finally, we come to the comparison of greatest interest: Mlin versus Mlog . The quantitative fits in
Table 1 show that the standard ANCHOR model
(≡ Mlin ) performs slightly better. The additivenoise variant, however, does not lag far behind and
its profiles are qualitatively very similar. Moreover,
Mlog competes with a handicap as all default parameters have been fine-tuned within the multiplicative framework. Also, the correction mechanism assumes uniform category sizes (on the magnitude continuum) in accordance with the assumptions of the
linear model. Under the logarithmic reformulation,
this tends to generate corrections that are too aggressive for the shortest stimuli and too conservative for the longest ones. It seems likely that model
Mlog , which already achieves very good fit, can be
fine-tuned to the extent to which Mlin is. In light
of all these considerations the final outcome of the
competition appears to be a tie.

Conclusions
Our results show that the distinction between additive and multiplicative noise does not significantly
affect the ability of the ANCHOR model to account
for the data from the identification experiment.
Consequently, the controversy between logarithmic
and power-based sensory scales that has dominated
the psychophysical literature since Stevens’s original
paper (1957) cannot detract from ANCHOR’s primary goal—to explore the hypothesis that the transition between magnitudes and responses is memory-

927

based. The present paper contributes to this goal
by showing that the particular form of the perceptual equation is not critical for the operation of the
model. This suggests that the successful accounts
provided by the memory hypothesis for over a dozen
sequential, context, and other dynamic effects are
not dependent on this issue either.

References
Algom, D. (1992). Memory psychophysics: An
examination of its perceptual and cognitive
prospects. In D. Algom (Ed.), Psychophysical approaches to cognition. Amsterdam: Elsevier.
Anderson, J. R., & Lebiere, C. (1998). The atomic
components of thought. Hillsdale, NJ: LEA.
Ekman, G. (1959). Weber’s law and related functions. The Journal of Psychology, 47, 343–352.
Lockhead, G., & King, M. (1983). A memory model
of sequential effects in scaling tasks. Journal of
Experimental Psychology: HPP, 9, 461–473.
Luce, R. D., Nosofsky, R., Green, D. M., & Smith, A.
(1982). The bow and sequential effects in absolute
identification. Perc. & Psychophysics, 20, 49–54.
Miller, G. (1956). The magical number seven, plus
or minus two: Some limits on our capacity for processing information. Psychological Rev, 63, 81–97.
Norwich, K., & Wong, W. (1997). Unification of
psychophysical phenomena: The complete form of
Fechner’s law. Perc. & Psychophys., 59, 929–940.
Parducci, A., & Wedell, D. (1986). Category effects
with rating scales: Number of categories, number
of stimuli, and method of presentation. Journal
of Experimental Psychology: HPP, 12, 496–516.
Petrov, A. (2001). Fitting the ANCHOR model
to individual data: A case study in Bayesian
Methodology. Proceedings of the Fourth Intern.
Conf. on Cognitive Modeling. Hillsdale, NJ: LEA.
Petrov, A., & Anderson, J. R. (2000). ANCHOR: A
memory-based model of category rating. Proceedings of the 22 Annual Conf. of the Cognitive Science Society (pp. 369–374). Hillsdale, NJ: LEA.
Petrov, A., & Anderson, J. (submitted). ANCHOR:
An integrated memory-based scaling model.
Stevens, S. (1957). On the psychophysical law. Psychological Review, 64, 153–181.
Stevens, S. (1975). Psychophysics: Introduction to
its perceptual, neural and social prospects. Wiley.
Thurstone, L. L. (1927). A law of comparative judgment. Psychological Review, 34, 273–286.
Torgerson, W. S. (1958). Theory and methods of
scaling. New York, Wiley.
Treisman, M., & Williams, T. (1984). A theory of
criterion setting with an application to sequential
dependencies. Psychological Review, 91, 68–111.

