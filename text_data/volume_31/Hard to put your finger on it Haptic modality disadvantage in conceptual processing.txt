UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Hard to put your finger on it: Haptic modality disadvantage in conceptual processing
Permalink
https://escholarship.org/uc/item/3390k2jx
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Connell, Louise
Lynott, Dermot
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

                                            Hard to Put Your Finger on it:
                       Haptic Modality Disadvantage in Conceptual Processing
                                     Louise Connell (louise.connell@manchester.ac.uk)
                                     Dermot Lynott (dermot.lynott@manchester.ac.uk)
                                    School of Psychological Sciences, University of Manchester
                                               Oxford Road, Manchester M13 9PL, UK
                             Abstract                               and inhibit how we perceive an entity in the real world
                                                                    should also influence how we conceive of that entity during
  Recent neuroimaging research has shown that perceptual and        language comprehension. Several studies demonstrate
  conceptual processing share a common, modality-specific           instances where this is indeed the case (Goldstone &
  neural substrate, while work on modality switching costs          Barsalou, 1998; Pecher, Zeelenberg & Barsalou, 2003). For
  shows that they appear to share some of the same attentional      example, Spence, Nicholls and Driver (2001; see also
  mechanisms. In two experiments, we employed a modality            Turatto, Galfano, Bridgeman & Umiltà, 2004) asked people
  detection task that displayed modality-specific object
                                                                    to indicate the left/right location of a series of perceptual
  properties (e.g., shrill, warm, crimson) for extremely short
  display times and asked participants to judge whether each
                                                                    stimuli, and found that switching modalities from one trial
  property corresponded to a particular target modality             to the next (e.g., from a visual light flash to an auditory
  (auditory, gustatory, haptic, olfactory, or visual). Results      tone) incurred a processing cost. Pecher et al. (2003)
  show that perceptual and conceptual processing share a haptic     investigated whether this switching cost effect extended to
  disadvantage: people need more time to detect expected            conceptual processing by asking people to verify a series of
  information regarding the sense of touch than any other           object properties from different modalities, presented as text
  modality. These findings support the assertions of embodied       onscreen. They found that people were slower to verify a
  views that the conceptual system uses the perceptual system       property in a given modality (e.g., auditory leaves:rustling)
  for the purposes of representation and are discussed with         after verifying a property in a different modality (e.g., visual
  reference to differences in endogenous attentional control.       apple:shiny) than after verifying a property in the same
                                                                    modality (e.g., auditory blender:loud), and that this effect
                         Introduction                               was not due to associative priming. Pecher et al. (see also
It has become increasingly clear of late that cognition             van Dantzig, Pecher, Zeelenberg & Barsalou, 2008)
cannot be successfully studied by marginalising the roles of        concluded that these switching costs during language
body, world and action. Embodied cognition research                 comprehension, like those found by Spence et al. during
represents a recent trend to cease viewing conceptualisation        perceptual tasks, resulted from the re-allocation of attention
and mental representation in terms of abstract information          from one modality-specific brain system to another.
processing, but rather as perceptual and motor simulation.             Modality-specific perceptual simulation has also been
  While early, influential work in cognitive psychology             implicated in the processing of single words. In both
advocated symbolic knowledge structures (Collins &                  behavioural and cognitive neuroscience research, while fine-
Quillian, 1969; Newell & Simon, 1972; Tulving, 1972),               grained sensory distinctions have been long been noted,
recent years have witnessed a multidisciplinary convergence         more recent work has highlighted the continuity between
of opinion from cognitive psychology (Barsalou, 1999;               conceptual and perceptual knowledge with respect to the
Glenberg, 1997), linguistics (Gibbs, 2003; MacWhinney,              different sensory modalities. For example, Gonzáles and
1999) and artificial intelligence (Anderson, 2003; Chrisley,        colleagues (2006) found that passively reading scent-related
2003) that cognition is situated in, rather than independent        words (e.g., cinnamon) increased activation in the primary
from, its environment. Embodied theories of cognition hold          olfactory areas of the piriform cortex (similar to
that conceptual thought is grounded in the same neural              Pulvermüller's 2005 finding of motor cortex activation for
systems that govern sensation, perception and action                action words). Regarding visual processing, Simmons et al.
(Glenberg & Kaschak, 2002; Johnson-Laird, 1983; Pecher              (2007) showed that verifying colour properties in text (e.g.,
& Zwaan, 2005) and one of the most influential views is             that a banana is yellow) led to activation in the same region
Barsalou’s (1999, 2008) Perceptual Symbol Systems                   of the left fusiform gyrus in the visual cortex as a perceptual
account. According to this theory, concepts are essentially         task that involved judging colour sequences. Similarly,
partial recordings of the neural activation that arises during      Newman, Klatzky, Lederman and Just (2005) examined
perceptual and motor experiences.             These recordings      visual and haptic modalities by asking participants to
(known as perceptual symbols) can later be re-enacted as a          compare various objects and found differential activation in
perceptual simulation of that concept.                              the inferior extrastriate and intraparietal sulcus depending
  One of the most important elements of the embodied                on whether visual features (e.g., which is bigger? pear OR
view, separating it from other theories of mental                   egg) or haptic features (e.g., which is harder? potato OR
representation, is the dependence of conception on                  mushroom) formed the basis for comparison. Further
perception. In other words, the same factors that facilitate        comparisons by Goldberg, Perfetti and Schneider (2006)
                                                                762

found that verification of colour, sound, touch and taste            detection of emotionally affective words at near-subliminal
properties activated cortical regions respectively associated        thresholds (Dijksterhuis & Aarts, 2003). Participants will be
with encoding visual, auditory, haptic and gustatory                 presented with unimodal object properties (i.e., perceived
experiences. In sum, such studies illustrate that perceptual         through one sense alone, such as shiny, echoing) for
experience and conceptual knowledge share a common                   extremely short display times and asked to judge whether
neural substrate.                                                    the property corresponds to a target modality (e.g., visual).
                                                                     By measuring accuracy rates for a range of increasing
The Current Study                                                    display times above the subliminal threshold, we can
If the conceptual system uses perceptual simulations for the         examine whether the perceptual haptic disadvantage also
purposes of representation, then it follows that one should          emerges during conceptual processing.
expect perceptual phenomena to emerge in conceptual
processing.       One such phenomenon is the haptic                                         Experiment 1
disadvantage in perceptual processing, relative to vision and        In this modality detection task, participants will first see
audition. When people are asked to respond to the arrival of         blocks for each modality (auditory, gustatory, haptic,
a perceptual stimulus, they are generally slower to detect           olfactory, visual) for an extremely short display time at the
haptic stimuli (e.g., finger vibration) than visual (e.g., light     threshold of subliminal perception (17ms), then the blocks
flash) or auditory (e.g., noise burst) stimuli, even when they       will be repeated for increasing display times (33ms, 50ms,
are told which modality to expect (Spence et al., 2001;              67ms, 100ms). We expect accuracy rates to improve from
Turatto et al., 2004). In other words, asking people to focus        near-chance performance over successive repetitions, both
their attention on the sense of sight, hearing or touch allows       because of practice effects and because longer display times
information from the relevant modality to be processed               increase the probability of successful detection, but we
faster than that from other modalities, but expected haptic          expect performance differences between modalities. In
stimuli take longer to process than expected visual or               particular, we predict faster detection of visual and auditory
auditory stimuli.                                                    properties (more accurate detection at earlier display times)
   So why should haptic processing be disadvantaged?                 than haptic properties (i.e., the haptic disadvantage). Since
There are obvious physiological differences in processing            the sense of taste presumably requires as much of an
stimuli from different perceptual modalities, with                   internal body representation as the sense of touch, Spence et
differential latencies for transduction in the skin, retina, and     al.'s (2001) notion of attentional perspective suggests that
cochlea and for transmission of their respective signals to          gustatory accuracy should be similar to haptic accuracy.
the somatosensory, visual and auditory cortices. However,            Likewise, since taste is not particularly useful in detecting
since the retina is actually the slowest of the three in             an approaching danger, Turatto et al.'s (2004) idea of
converting a stimulus to an electrical signal and delivering it      attentional adaptation for threat detection would suggest that
to the brain, these physiological differences alone cannot           the gustatory modality should have similar accuracy to
explain the haptic disadvantage in stimulus perception.              haptic.
Rather, the haptic modality appears to be disadvantaged
when it comes to the resolution of the raw sensory signal            Method
into a recognisable percept. Researchers have speculated on          Participants Forty-five native speakers of English, with no
a number of reasons why this might be the case. The haptic           reported reading or sensory deficits, participated in the
modality may be special in requiring an internal, body-              experiment for course credit or a fee of £5. Participants
focused representation, in contrast to the visual or auditory        were recruited via university email lists and notice boards
modalities requiring a representation of the external world,         and through the university’s research volunteering website.
and hence may require a different attentional perspective            Three participants’ data were removed prior to analyses; two
(Martin, 1995; Spence et al., 2001). For example, if                 due to pressing incorrect buttons during the experiment and
something is being felt by touch, it is (by definition) located      one due to a consistently high error rate (>80%).
on the body's surface, and there may be costs involved in
shifting attentional perspective to something that is seen or        Materials A set of 200 words were taken from Lynott &
heard some distance away. Alternatively, there may be an             Connell's (2009) modality exclusivity norms: 100 test items
adaptive advantage in coupling attention longer to visual            and 100 fillers. These norms comprise 423 adjectives, each
and auditory modalities than to haptic (Turatto et al., 2004).       describing an object property, with mean ratings (0-5) of
In this account, approaching threats could be efficiently            how strongly that property is experienced through each of
detected by keeping attention focused on sight or sound, but         five perceptual modalities (auditory, gustatory, haptic,
waiting to detect a potential threat by touch is unlikely to         olfactory, visual) plus a number of other useful statistics.
have evolved as a useful attentional mechanism.                      For this experiment, test items were selected to be unimodal,
   The current study aims to investigate if the haptic               and consisted of 20 words from each modality, where each
disadvantage in perceptual processing also emerges during            word had the highest score in the target modality (minimum
conceptual processing. In two experiments, we use a                  strength rating of 3) and all other modalities were at least
modality detection task to examine conceptual processing of          one full point lower on the the ratings scale (see Table 1 for
modality-specific words. The modality detection task is a            examples). Only 17 and 15 words met this criterion for the
variant of that used to examine the positive/negative                haptic and olfactory modalities, respectively, and so
                                                                 763

morphological variants of existing words were included                  Design A two-factor repeated measures design employed the
(e.g., odorous, malodorous) to ensure balanced blocks of 20             factors of modality (auditory, gustatory, haptic, olfactory,
items per modality; data relating to these variants were                visual) and display duration (17ms, 33ms, 50ms, 67ms,
removed prior to analysis. There were no differences                    100ms). As per Dijksterhuis and Aarts (2003), the
between modalities in British National Corpus (BNC) word                proportion of correctly detected words per participant per
frequency, orthographic length, or target modality strength             condition are subjected to analyses of variance. Effect sizes
ratings of test words (all Bonferroni comparison ps>.18). In            are reported as generalized eta-squared ( 2G), which allows
addition, we used the English Lexicon Project database                  direct comparison of within- and between-participants
(Balota et al., 2007) to examine further lexical                        designs (Olejnik & Algina, 2003).
characteristics of the test words. Seventeen of our test
words were not featured in the eLexicon database                                        100
(distributed across modalities), but tests on those words
present showed that there were no differences between
modalities in the lexical decision time or accuracy of each                              90
word, nor in the number of orthographic, phonological or
phonographic neighbours of each word (all Bonferroni
comparison ps>.2).                                                                       80                                         82.4
                                                                                                                      80.5
   Twenty filler items were selected per modality so that
each filler word had a low strength rating (less than 2) on                                                 75.8
                                                                         Accuracy (%)
the target modality. This meant that all fillers had                                     70                                 Auditory
                                                                                                   69.7
significantly lower strength on the target modality than the                                                                Gustatory
corresponding test words (all Bonferroni comparison                                                                         Haptic
ps<.001). However, there were no differences between test                                60                                 Olfactory
and filler words in BNC frequency or orthographic length                                                                    Visual
(all Bonferroni ps>.25).
                                                                                         5053.3
     Table 1: Sample words for each modality used in
                 Experiments 1 and 2.
                                                                                         40
 Auditory     Gustatory    Haptic     Olfactory    Visual                                     17   33       50         67           100
 bleeping     bitter       chilly     aromatic     crimson                                         Display Duration (ms)
 echoing      bland        itchy      fragrant     dazzling
 loud         palatable    silky      musky        flickering              Figure 1: Percentage of correctly-detected words per
 shrill       salty        ticklish   perfumed     pale                  modality and duration in Experiment 1 (yes/no task). Error
 squeaking    tangy        warm       stinky       shiny                     bars represent 95% confidence intervals for within-
                                                                        participant designs (Loftus & Masson, 1994), calculated per
Procedure Participants were instructed that they would be                 display duration, and for clarity are only shown for the
asked to judge whether or not words appearing onscreen                                        haptic modality.
could be experienced through a particular sense (heard,
tasted, felt through touch, smelled or seen). They were told            Results & Discussion
that words would appear onscreen one at a time and be                   Responses to test words less than 200 ms or more than three
covered very quickly by a row of Xs, and that they should               standard deviations away from a participant's mean per
press “Yes” (the comma key) if the word could be perceived              display duration were removed as outliers (3.7% of data).
through that sense or “No” (the full stop key) if it could not.         The percentage of correctly detected test words per modality
Stimuli were arranged into blocks of test and filler words for          per display time is shown in Figure 1, where 50% represents
each modality; since all test items pertained to the given              performance at chance level.
modality and all fillers did not, there was an equal ratio of              There was an overall main effect of modality [F(4, 164) =
yes:no responses within each block. At the start of each                14.00, p < .0001, 2G = .06]. Planned contrasts between
block, participants were told which sense they would be                 haptic and other modalities showed a distinct haptic
making judgements about.            When participants had               disadvantage: people were indeed worse at detecting haptic
completed all five modality blocks with a display duration              words than any other modality (all ps < .001). As expected,
of 17s, the same five blocks were repeated at 33ms, 50ms,               there was also a main effect of display duration [F(4, 164) =
67ms, and 100ms. Items were presented randomly within                   89.25, p < .0001,  2G = .26], with people becoming more
each block, with each trial beginning with a central fixation           accurate with each increasing duration up to 67ms (all
(250ms), followed by a word (displayed for different                    ps<.001), and performance levelling out between 67ms and
durations depending on the block), followed by a mask (a                100ms (p = .599). The interaction between factors was not
row of Xs) until the participant responded. Response times              significant [F<1,  2G = .01].
(RTs) were measured from mask onset to keypress.                           In order to examine when the haptic disadvantage first
                                                                        appears, and whether relative performance changes when
                                                                        more time is given to process the word, we examined each
                                                                  764

display duration separately. At 17ms, modalities differed in            Method
performance [F(4, 164) = 3.21, p = .014,  2G = .03]: in                Identical to Experiment 1, with the following exceptions:
planned contrasts, accuracy for haptic words was
significantly worse than for all other modalities (all ps < .           Participants Forty-six new participants took part. Data
03). The same pattern emerged for 33ms [F(4, 164) = 5.88,               from two participants were excluded prior to analysis due to
p < .001,  2G = .07; all contrast ps < .02], 50ms [F(4, 164) =         equipment malfunction during testing.
8.51, p < .001,  2G = .09; all contrast ps < .004], and 67ms
[F(4, 164) = 8.16, p = .001,  2G = .09; all contrast ps < .            Procedure Following calibration of the unidirectional
004]. By 100ms, where accuracy had begun to plateau out,                microphone (worn as part of a headset), participants were
performance still varied by modality [F(4, 164) = 4.25, p               instructed to say “yes” as clearly as possible if the word
= .004,  2G = .05]; people continued to be significantly less          could be perceived through the target sense or remain silent
accurate in detecting haptic words than auditory or gustatory           if it could not (constituting a “no” response). RTs were
words (ps < .002), and marginally less accurate than                    measured from the mask onset to the registration of a voice
olfactory (p = .072) and visual (p = .104) words.                       response. If no response was made within 1500ms, it was
   When accuracy at the 17ms display duration was                       considered a “no” response and the next trial was presented.
compared to chance (50%) in one-sample t-tests,
performance was significantly better for auditory [t(41) =
3.70, p = .001], gustatory [t(41) = 3.86, p < .001], olfactory                         100
[t(41) = 4.12, p < .001], and visual [t(41) = 4.22, p < .001]
modalities, but not for haptic [t(41) = 1.00, p = .321]. At                             90
33ms, accuracy for haptic words reached a level above
chance [t(41) = 5.51 p < .001]. Since performance                                       80
consistently improved with longer display durations, we do                                                                             76.8
                                                                                                                      75.1
not report further above-chance statistics.                                             70                  73.1
   In summary, results show a distinct haptic disadvantage in
                                                                        Accuracy (%)
conceptual processing. More time is needed for the                                      60
                                                                                                                           Auditory
successful processing of haptic information than any other
                                                                                                  55.7                     Gustatory
modality. Even when a word is displayed for only 17ms,                                  50                                 Haptic
and people are not necessarily conscious of having read it,                                                                Olfactory
they can successfully detect auditory, gustatory, olfactory                             40                                 Visual
and visual modalities at a rate above chance. Haptic words,
on the other hand, need to be displayed for longer (33ms)                               30
before they can be reliably detected.             This haptic                            29.5
disadvantage, ranging between 4 and 15 percentage points,
                                                                                        20
remains consistent across increasingly longer display times
up to 100ms, where performance begins to plateau out and                                     17    33        50           67           100
the differences between modalities become less pronounced.                                        Display Duration (ms)
Since accuracy for both gustatory and olfactory modalities
closely followed that for auditory and visual, and remained                 Figure 2: Percentage of correctly-detected words
significantly better than haptic accuracy throughout, neither           per modality and duration in Experiment 2 (go/no-go task).
the attentional perspective nor threat detection explanations                           Error bars are as Figure 1.
for the haptic disadvantage can adequately explain the
results. We return to this issue in the General Discussion.             Results & Discussion
                                                                        Responses due to disfluencies (e.g., lip pops, coughs) were
                      Experiment 2                                      excluded from analysis. Responses to test words less than
Since the task in Experiment 1 required pressing “yes” and              200 ms or more than three standard deviations away from a
“no” buttons in response to stimuli, participants would have            participant's mean per display duration were removed as
experienced haptic feedback from their fingers on every                 outliers (1.7% of data). Figure 2 shows the percentage of
trial. It could be argued that this feedback, and the                   correctly detected test words per modality per display time.
expectation of such feedback, could have swamped the                      As in Experiment 1, the main effect of modality [F(4,
haptic simulators and interfered with the simultaneous                  172) = 16.54, p < .0001,  2G = .03] resulted from a haptic
processing of haptic words (similar to e.g., Kaschak et al.,            disadvantage: people were less accurate in detecting haptic
2005, for visual motion processing), potentially contributing           words than words from the other modalities (all planned
to the haptic disadvantage. In this experiment, we employ a             contrast ps < .001). Accuracy improved as display duration
verbal go/no-go task where participants respond with a                  increased [F(4, 172) = 12.74, p < .0001,  2G = .35], with
voice trigger rather than a button press. If the haptic                 significant improvements up to 50ms (planned contrast ps
disadvantage effect is more than a mere artifact of the                 < .001) and no significant change between 50-67ms (p = .
button-pressing task, then we should see it replicated in the           519) or 67-100ms (p = .266). The interaction of modality
current experiment.                                                     and display duration was marginal [F(16, 688) = 1.62, p = .
                                                                        058,  2G = .01].
                                                                  765

   Further investigation of the timeline of the haptic               neural substrate, while work on modality switching costs
disadvantage also replicated Experiment 1. At 17ms,                  shows that they appear to share the same attentional
accuracy differed across modalities [F(4, 172) = 2.99, p = .         mechanisms.        Our results further demonstrate that
020 ,  2G = .02], with planned contrasts showing lower              perceptual and conceptual processing share a haptic
accuracy for haptic words than any other modality (all ps            disadvantage: people need more time to detect expected
< .03). Haptic performance remained consistently worse               information regarding the sense of touch because of
than other modality words at 33ms [F(4, 172) = 12.94, p              modality-specific differences in attentional control.
< .001,  2G = .08; all contrast ps < .01], and 50ms [F(4, 172)         Two attentional mechanisms are at play in our modality
= 6.59, p < .001,  2G = .03; all contrast ps < .001]. At 67ms       detection task: endogenous control (where participants
[F(4, 172) = 4.92, p = .001, 2G = .03], where overall               consciously focus attention on the target modality) and
performance had begun to plateau, haptic accuracy was                exogenous control (where the modality involved in
similar to that of olfactory words (p = .23), but still worse        processing a word automatically and obligatorily grabs
than the remaining modalities (all ps < .03). By 100ms,              attention). In any given block, therefore, endogenous and
haptic responses were again less accurate than all other             exogenous control are in competition: endogenous control
modalities [F(4, 172) = 6.35, p < .001,  2G = .03; all contrast     attempts to focus continuously on the target modality while
ps < .02].                                                           exogenous control flickers between the target modality (test
   Comparison to chance performance showed that people               items) and other modalities (filler items). We propose that
were generally more conservative in the current go/no-go             the haptic disadvantage described in this paper arises from
task than in the previous experiment's yes/no task, which            difficulties in haptic endogenous control: people find it
was not unexpected given that uncertain participants tend to         more difficult to sustain attentional focus on the haptic
withhold their responses in go/no-go tasks (thus registering         modality than on any other which leaves haptic blocks more
an incorrect “no” to target items), whereas, in a yes/no task,       prone to exogenous disruption and hence leads to lower
they must press one of the two available buttons (thus               accuracy in detection of haptic stimuli.
carrying a 50% chance of being correct). At 17ms, people                Endogenous control of attention towards a particular
detected words at below-chance accuracy for all modalities:          perceptual modality creates anticipatory activation in the
auditory [t(43) = -2.79, p = .008], gustatory [t(43) = -2.85, p      relevant area of the cortex (Foxe, Simpson, Ahlfors &
= .007], haptic [t(43) = -5.12, p < .001], olfactory [t(43) =        Saron, 2005). However, attentional control may vary in
-2.59, p = .013], and visual [t(43) = -3.16, p = .003]. By           strength. Strong endogenous control means that conscious
33ms, performance had risen above chance for auditory                attention is anchored effectively in a specific modality and
[t(43) = 6.49, p < .001], gustatory [t(43) = 8.37, p < .001],        that stimuli from other modalities, while grabbing
olfactory [t(43) = 5.87, p < .001] and visual [t(43) = 4.07,         exogenous control during their processing, cannot hold onto
p < .001] words, but not haptic [t(43) = 1.37, p = .178],            attention and endogenous focus quickly returns to the target
which took until 50ms to achieve above-chance accuracy               modality in preparation for the next stimulus. Weak
[t(43) = 6.76, p < .001].                                            endogenous control, on the other hand, means that
   In short, the replication of the haptic disadvantage effect       conscious attention is not well-anchored and that stimuli
using a voice-trigger task confirms that the results of              from other modalities, when they wrest exogenous control
Experiment 1 were not due to the fact that participants              away during their processing, are able to disrupt endogenous
registered responses by pressing buttons, but rather are due         focus enough that attention may not be on the target
to differences in the conceptual processing of modality-             modality when the next stimulus appears. We propose that
specific words.                                                      the haptic modality suffers from weaker endogenous control
                                                                     of attention than the other perceptual modalities, which
                    General Discussion                               means more time is needed to detect words successfully, and
In this paper, we have demonstrated that a phenomenon                thus the haptic modality lags behind in accuracy rates across
observed during perception – the haptic disadvantage – also          display times.
emerges during conceptual processing. Results showed that               So how did this haptic disadvantage in endogenous
the processing of modality-specific information is rapid and         attentional come into being? Spence et al.'s (2001)
automatic, with above-chance performance after just 17ms             speculation that haptic processing is special because it
exposure in Experiment 1 and 33ms in Experiment 2.                   requires an internal attentional perspective is not borne out
Haptic information, however, is the hardest to process.              by the results. Taste is detected inside the mouth, and hence
Even with extra time to process the word, people are less            also requires body-focused attention, but gustatory
accurate at detecting properties that pertain to the sense of        information was processed as quickly as visual and auditory
touch than to hearing, taste, smell or vision, and this effect       information. Turatto et al.'s (2004) suggestion of the
emerged even though the strength on the given modality and           attentional system having evolved to stay coupled longer to
the lexical decision times for each word were equal across           visual and auditory modalities than haptic due to an adaptive
modalities. These findings support the assertions of                 advantage in threat detection was also not supported: taste is
embodied theories that the conceptual system utilises the            of little use in detecting approaching danger but did not
perceptual system for the purposes of representation.                share the haptic disadvantage. However, threat detection is
   Neuroimaging research has shown that perceptual and               not the only reason that adaptive advantages may have
conceptual processing share a common, modality-specific              emerged for certain modalities, and we would speculate that
                                                                     Turatto et al.'s account may be partially correct. Being able
                                                                 766

to sustain attentional focus on a particular sensory modality        regions. Journal of Neuroscience, 26, 4917-4921.
(i.e., endogenous control) is also useful in hunting, where        Goldstone, R., & Barsalou, L.W. (1998). Reuniting
efficacious looking, listening and even smelling for traces of       perception and conception. Cognition, 65, 231-262.
prey could afford an adaptive advantage.            Similarly,     González, J., Barros-Loscertales, A., Pulvermüller, F.,
contaminant detection (visual, olfactory and gustatory               Meseguer, V., Sanjuán, A., Belloch, V., & Ávila, C.
information) and mate selection (visual and olfactory                (2006). Reading cinnamon activates olfactory brain
information) will be most successful if attention can be             regions. Neuroimage, 32, 906-912.
deliberately and consciously turned towards these cues. In         Johnson-Laird, P. N. (1983). Mental models. Cambridge,
other words, the attentional system may have evolved to              MA: Harvard University Press.
stay coupled at length to visual, auditory, olfactory and          Loftus, G. R., & Masson, M. E. J. (1994). Using confidence
gustatory modalities because of their usefulness in detecting        intervals in within-subject designs. Psychonomic Bulletin
stimuli that affect the ability to survive and reproduce,            & Review, 1, 476-490.
whereas sustained attentional focus on the haptic modality         Lynott, D. & Connell, L. (2009). Modality exclusivity
brought no such adaptive advantage. If such attentional              norms for 423 object properties. Behavior Research
mechanisms evolved as part of our perceptual systems, and            Methods, 41, 558-564.
these same attentional and perceptual systems are utilised         MacWhinney, B. (1999). The emergence of language from
during conceptual processing and language comprehension,             embodiment. In B. MacWhinney (Ed.), The emergence of
then it should come as no surprise that modality-specific            language. Mahwah, NJ: Lawrence Erlbaum.
differences, such as the haptic disadvantage, emerge with          Martin, M. G. F. (1995). Bodily awareness: A sense of
linguistic as well as sensory stimuli.                               ownership. In J. L. Bermudez, A. Marcel, & N. Eilan
                                                                     (Eds.), The body and the self. Cambridge, MA:MIT Press.
                      Acknowledgments                              Newell, A. & Simon, H. A. (1972). Human Problem
                                                                     Solving. Englewood Cliffs, NJ: Prentice-Hall.
This work was funded by grant RES-000-22-2407 from the
                                                                   Newman, S. D., Klatzky, R. L., Lederman, S. J., Just, M. A.
UK Economic and Social Research Council to the first
                                                                     (2005). Imagining material versus geometric properties
author.
                                                                     of objects: An fMRI study. Cognitive Brain Research, 23,
                                                                     235-246.
                          References                               Olejnik, S., & Algina, J. (2003). Generalized eta and omega
Anderson, M. L. (2003). Embodied Cognition: A field                  squared statistics: Measures of effect size for some
   guide. Artificial Intelligence, 149, 91-130.                      common research designs. Psychological Methods, 8,
Balota, D. A., Yap, M. J., Cortese, M.J., Hutchison, K. A.,          434-447.
   Kessler, B., Loftis, B., Neely, J. H., Nelson, D. L.,           Pecher, D., Zeelenberg, R., & Barsalou, L.W. (2003).
   Simpson, G. B., & Treiman, R. (2007). The English                 Verifying properties from different modalities for
   Lexicon Project. Behavior Research Methods, 39, 445-              concepts produces switching costs. Psychological
   459.                                                              Science, 14, 119-124.
Barsalou, L. W. (1999). Perceptual symbol systems.                 Pecher, D., & Zwaan, R. A. (2005). Introduction to
   Behavioral and Brain Sciences 22, 577–660.                        grounding cognition. In D. Pecher & R. A. Zwaan (Eds.),
Barsalou, L. W. (2008). Grounded cognition. Annual                   Grounding cognition: the role of perception and action in
   Review of Psychology, 59, 617–645.                                memory, language, and thinking. Cambridge: CUP.
Chrisley, R. (2003). Embodied artificial intelligence.             Pulvermuller, F. (2005) Brain mechanisms linking language
   Artificial Intelligence, 149, 131-150.                            and action. Nature Reviews Neuroscience, 6, 576-582.
Collins, A. M., & Quillian, M. R. (1969). Retrieval time           Simmons, W.K., Ramjee, V., Beauchamp, M.S., McRae, K.,
   from semantic memory. Journal of Verbal Learning and              Martin, A., & Barsalou, L.W. (2007). A common neural
   Verbal Behaviour, 8, 240-248.                                     substrate for perceiving and knowing about color.
Dijksterhuis, A., & Aarts, H. (2003). On wildebeests and             Neuropsychologia, 45, 2802-2810.
   humans: The preferential detection of negative stimuli.         Spence, C., Nicholls, M. E. R., & Driver, J. (2000). The cost
   Psychological Science, 14, 14–18.                                 of expecting events in the wrong sensory modality.
Foxe, J. J., Simpson, G. V., Ahlfors, S. P., & Saron, C. D.          Perception & Psychophysics, 63, 330-336.
   (2005). Biasing the brain’s attentional set: I. Cue driven      Tulving, E. (1972). Episodic and semantic memory. In E.
   deployments of intersensory selective attention.                  Tulving & W. Donaldson (Eds.), Organization and
   Experimental Brain Research, 166, 370–392.                        memory. New York: Academic Press.
Gibbs, R. W. (2003). Embodied experience and linguistic            Turatto, M., Galfano, G., Bridgeman, B., & Umiltà, C.
   meaning. Brain and Language, 84, 1-15.                            (2004). Space-independent modality-driven attentional
Glenberg, A. M. (1997). What memory is for. Behavioral               capture in auditory, tactile and visual systems.
   and Brain Sciences, 20, 1–55.                                     Experimental Brain Research, 155, 301-310.
Glenberg, A. M., & Kaschak, M. P. (2002). Grounding                van Dantzig, S., Pecher, D., Zeelenberg, R., & Barsalou,
   language in action. Psychonomic Bulletin & Review, 9,             L.W. (2008). Perceptual processing affects conceptual
   558–565.                                                          processing. Cognitive Science, 32, 579-5.
Goldberg, R. F., Perfetti, C. A., & Schneider, W. (2006).
   Perceptual knowledge retrieval activates sensory brain
                                                               767

