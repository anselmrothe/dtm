UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Universal vocal signals of emotion
Permalink
https://escholarship.org/uc/item/7hm963kz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Eisner, Frank
Ekman, Paul
Sauter, Disa
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                       Universal vocal signals of emotion
                                                Disa A Sauter (disa.sauter@mpi.nl)
                          Department of Psychology, University College London, Gower Street, London
                                                    WC1E 6BT, United Kingdom.
                 Comparative Cognitive Anthropology, Max Planck Institute of Psycholinguistics, PO Box 310,
                                                  6500 AH Nijmegen, The Netherlands
                                                   Frank Eisner (f.eisner@mpi.nl)
                       Institute of Cognitive Neuroscience, University College London, 17 Queen Square,
                                                    WC1N 3AR, United Kingdom
                                       Max Planck Institute of Psycholinguistics, PO Box 310,
                                                  6500 AH Nijmegen, The Netherlands
                                                              Paul Ekman
                              Human Interaction Laboratory, University of California San Francisco,
                                       401 Parnassus Avenue, San Francisco CA 94143 USA
                                              Sophie K Scott (sophie.scott@ucl.ac.uk)
                       Institute of Cognitive Neuroscience, University College London, 17 Queen Square,
                                                    WC1N 3AR, United Kingdom
                              Abstract                               convey their thoughts, feelings, and intentions to those around
    Emotional signals allow for the sharing of important             them (Hauser, Chomsky & Fitch, 2002). But although there
  information with conspecifics, for example to warn them of         are some commonalities between different communicative
  danger. Humans use a range of different cues to communicate        systems, speakers of different languages cannot understand
  to others how they feel, including facial, vocal, and gestural     each other. Or rather, they cannot understand either other’s
  signals. Although much is known about facial expressions of        words and sentences. Other aspects of communicative
  emotion, less research has focused on affect in the voice. We
  compare British listeners to individuals from remote Namibian      systems do not rely on common lexical codes and may be
  villages who have had no exposure to Western culture, and          shared across linguistic and cultural borders. One candidate of
  examine recognition of non-verbal emotional vocalizations,         communicative systems for constituting a psychological
  such as screams and laughs. We show that a number of               universal is emotional signals.
  emotions can be universally recognized from non-verbal vocal         Humans use a range of signals to communicate emotions,
  signals. In addition we demonstrate the specificity of this
  pattern, with a set of additional emotions only recognized         including vocalizations, facial expressions, and postural cues.
  within, but not across these cultural groups. Our findings         Auditory signals allows for affective communication when the
  indicate that a small set of primarily negative emotions have      recipient cannot see the sender, for example, across a distance
  evolved signals across several modalities, while most positive     or at night. In addition, young infants are sensitive to vocal
  emotions are communicated with culture-specific signals.           cues from the very beginning of life, when their visual system
                                                                     is still relatively immature (Mehler, Bertoncini & Barrier,
     Keywords: emotion; voice; happiness; affective signals.         1978).
                                                                       Vocal signals of emotions can occur overlaid on speech in
                                                                     the form of affective prosody (Scherer, Banse & Wallbott,
                          Background                                 2001). However, humans also make use of a range of non-
Some human traits are shared by all human beings, despite            verbal vocalizations to communicate how they feel, such as
differences in language, culture and ecology. These                  screams and laughs. In this study we investigate whether these
psychological universals tell us what features of the human          kinds of non-verbal emotional vocalizations communicate the
mind are part of our shared biological heritage and which are        same affective states regardless of the listener’s culture.
products of culture and language. Because all humans share           Currently, the only available cross-cultural data comes from
the vast majority of their genetic makeup with all other             studies of emotional prosody in speech (e.g., Scherer et al.,
humans, there is great similarity in the physical features that      2001). This work has indicated that listeners can infer some
are typical for our species, while minor characteristics vary        affective states from emotionally inflected speech across
between individuals. Similarly to physical features, many            cultural boundaries. However, emotional information overlaid
aspects of the human psychology are shared. For example, all         on speech (or nonsense-speech) is restricted by the segmental
human societies have complex systems of communication to             and supra-segmental structure of speech. In contrast, non-
                                                                 2251

verbal vocalizations are relatively “pure” expressions of         use with a pre-literate population, as it requires no ability to
emotions. Furthermore, no study to date has investigated          read – unlike the forced-choice format that is common in
emotion recognition from the voice in a population that has       emotion perception studies. Furthermore, the current task is
had no contact with other cultural groups, through media or       particularly well suited to cross-cultural research, as it does
personal contact.                                                 not rely on the translation of precise emotion terms. The
  We examined the universality of vocal signals of emotions       original task included three response alternatives on each trial,
using the two-culture approach, in which participants from        with all three stimuli presented simultaneously. However, as
two populations that are maximally different in terms of          sounds necessarily extend over time, the response alternatives
language and culture are compared (Norenzayan & Heine,            in the current task had to be presented sequentially. Thus,
2005). The claim of universality is strengthened to the extent    participants were required to remember the other response
that the same phenomenon is found in both groups. This            alternative(s) whilst listening to the current response option.
approach has previously been used in work demonstrating the       In order to avoid overloading the participants’ working
universality of emotional facial expressions of the emotions      memory, the number of response alternatives in the current
happiness, anger, fear, sadness, disgust, and surprise (Ekman,    study was reduced to two.
Sorenson & Friesen, 1969), a result that has now been                The Western participants were tested in the presence of an
extensively replicated using different sets of facial signals     experimenter; the Himba participants were tested in the
(Elfenbein & Ambady, 2002).                                       presence of two experimenters and one translator. For each
  In order to investigate whether emotional vocalizations         emotion, the participant was told a short emotion story
universally communicate affective states, we compared             describing a scenario that would elicit that emotion. After
British English speakers with the Himba, a semi-nomadic,          each story, the participant was asked how the person was
pastoral people living in the Kaokoland region in Northern        feeling to ensure that they had understood the story. If
Namibia. The Himba live completely traditional lives, with        necessary, participants could hear the story again. The
no electricity, water, formal education, or any contact with      emotion stories used with the Himba participants were
Western culture or people.                                        developed together with a local person with extensive
                                                                  knowledge of the culture of the Himba people, who also acted
                           Methods                                as a translator during testing. The emotion stories used with
                                                                  the Western participants were matched as closely as possible
                                                                  to the Himba stories, but adapted to be easily understood by
Stimuli                                                           Western participants. The stories were played from
The stimuli were taken from a previously validated set of non-    recordings, spoken in a neutral tone of voice by a male native
verbal vocalisations of negative and positive emotions            speaker each language (the Himba local language Otji-Herero
(Sauter, Calder, Eisner & Scott, 2009; Sauter & Scott, 2007).     and English). Once they had understood the story, the
The stimulus set was comprised of ten tokens of each of nine      participant was played two sounds. The stimuli were produced
emotions: achievement, amusement, anger, disgust, fear,           by the experimenter pressing two computer mice in turn, each
sensual pleasure, relief, sadness, and surprise, based on         playing one of the sounds. The participant was asked which
demonstrations that all of these categories can be reliably       one was the kind of sound that the person in the story would
recognized from non-verbal vocalizations by Western               make. They were allowed to hear the stimuli as many times as
listeners. The sounds were produced by two male and two           they need to make a decision. Participants indicated their
female native English speakers and the stimulus set was           choice on each trial by pointing to the computer mouse that
matched for peak amplitude. Further information about the         had produced the sound appropriate for the story, and the
stimuli is available in Sauter et al. (2009).                     experimenter inputted their response into the computer.
                                                                  Throughout testing, the experimenters and the translator were
Participants                                                      naïve to which response was correct and which stimulus the
                                                                  participant was hearing. Speaker gender was constant within
The Western sample consisted of 25 native British English
                                                                  any trial, with participants hearing two male and female trials
speakers (10 male, 15 female; mean age 28.7 years). Twenty-
                                                                  for each emotion. Thus, all participants completed four trials
nine participants (13 male, 16 female) from Himba
                                                                  for each of the nine emotions, resulting in a total of 36 trials.
settlements in Northern Namibia comprised the non-Western
                                                                  The target stimulus was of the same emotion as the story, and
sample. The Himba do not have a system for measuring age,
                                                                  the distractor was varied in terms of both valence and
but no children or very old adults were included in the study.
                                                                  difficulty, such that for any emotion participants heard four
                                                                  types of distracters: maximally and minimally easy of the
 Design and Procedure
                                                                  same valence, and maximally and minimally easy of the
In this study, we used an adapted version of a task used in       opposite valence, based on confusion data from a previous
previous cross-cultural research on recognition of emotional      study (Sauter et al., 2009). Which mouse was correct on any
facial expressions (Ekman et al., 1969). In the original task, a  trial, as well as the order of stories, stimulus gender, distractor
participant heard a story about a person feeling in a particular  type, and whether target was first or second, was randomized
way and was then asked to choose which of three emotional         for each participant.
facial expressions fit with the story. This task is suitable for
                                                              2252

                                                    Results                                  shown to be reliably identified by several groups of Western
                                                                                             listeners (Sauter & Scott, 2007). This pattern demonstrates
  As expected, listeners from the British sample matched the
                                                                                             that there are universally recognizable vocal signals for
sounds to the story at a level that significantly exceeded
                                                                                             communicating the Basic Emotions, but that this does not
chance (χ2 = 271.82, df = 1, p < 0.0001), and they performed
                                                                                             extend to all affective states, including ones that can be
better than would be expected by chance for each of the
                                                                                             identified by listeners from closely related cultures.
emotion categories (χ2 = 96.04 (achievement), 88.36
(amusement), 81.00 (anger), 96.04 (disgust), 96.04 (fear),                                                            Discussion
51.84 (sensual pleasure), 67.24 (relief), 81.00 (sadness), and
70.56 (surprise), all df = 1, all p < 0.001, Bonferroni                                      Our results show that emotional vocal cues communicate
corrected; See Figure 1). This replicates previous findings that                             affective states across cultural boundaries. The Basic
have demonstrated good recognition of a range of emotions                                    Emotions anger, fear, disgust, happiness, sadness, and
from non-verbal vocal cues both within (Sauter et al., 2009)                                 surprise, were reliably identified from vocalizations (See
and between (Sauter & Scott, 2007) Western cultures.                                         Figure 1). This indicates that some affective states are
  The Himba listeners also matched the sounds to the stories                                 communicated with vocal signals that are broadly consistent
at a level that was significantly higher than would be expected                              across human societies, and do not require that the producer
by chance (χ2 = 271.82, df =1, p < 0.0001). For individual                                   and listener share language or culture. This is consistent
emotions however, they performed at better-than-chance                                       with research in the domain of visual affective signals.
levels only for a sub-set of the emotions (χ2 = 49.79                                        Facial expressions of the Basic Emotions are recognized
(amusement), 8.83 (anger), 27.03 (disgust), 18.24 (fear), 9.96                               across a wide range of cultures and correspond to consistent
(sadness), and 25.14 (surprise), all df = 1, all p < 0.05,                                   constellations of facial muscle movements (Ekman, 1999).
Bonferroni corrected; See Figure 1).                                                         These facial configurations produce alterations in sensory
                                                                                             processing suggesting that they likely evolved to aid in the
                            100                                                              preparation for action to particularly important types of
                                  *     **    **    **      **    *     *     **    **
                                                                                             situations (Susskind et al., 2008). Furthermore, despite the
                                                                                             considerable variation in human facial musculature, the
                            80                                                               facial muscles that are essential to produce the Basic
                                                                                             Emotions are constant across individuals, suggesting that
    Correct responses (%)
                            60
                                                                                             specific facial muscle structures have likely been selected to
                                                                                             allow individuals to produce universally recognizable
                                                                                             emotional expressions (Waller, Cray & Burrows). The
                            40                                                               consistency of emotional signals across cultures supports
                                                                                             the notion of universal affect programs, that is, evolved
                            20
                                                                                             systems that regulate the communication of emotions, which
                                                                                             take the form of universal signals (Ekman, 1992). These
                                                                               Western
                                                                               Himba
                                                                                             signals are rooted in ancestral primate communicative
                             0                                                               displays. In particular, facial expressions produced by
                                  ach   amu   ang   dis     fea   ple   rel   sad   sur
                                                          Emotion                            human and chimpanzees have substantial similarities (Parr,
                                                                                             Waller & Heintz, 2008). Although a number of primate
Figure 1: Recognition performance (%) for Western (dark
                                                                                             species produce affective vocalizations (Seyfarth & Cheney,
bars; n = 25) and Himba participants (light bars; n = 29) for
                                                                                             2003), the extent to which these parallel human vocal
each emotion category. Stars indicate significantly better
                                                                                             signals is as yet unknown. The data from the current study
than chance performance (50%) for a group for a particular
emotion category.                                                                            suggests that vocal signals of emotion are, like facial
                                                                                             expressions, biologically driven communicative displays,
  The emotions that were reliably identified by this non-                                    that may be shared with non-human primates.
Western sample comprise the set of emotions commonly                                            In humans, the basic emotional systems are modulated by
referred to as the Basic Emotions (Ekman, 1992). These                                       cultural norms which dictate which affective signals should
emotions are thought to constitute evolved functions that are                                be emphasized, masked, or hidden (Matsumoto, Yoo,
shared between all human beings, both in terms of                                            Hirayama & Petrova, 2005). In addition, culture introduces
phenomenology and communicative signals. Notably, these                                      subtle adjustments of the universal programs, producing
emotions have also been shown to have universally                                            differences in the appearance of emotional expression across
recognizable facial expressions (Ekman et al., 1969; Elfenbein                               cultures (Elfenbein & Ambady, 2002). These cultural
& Ambady, 2002). In contrast, vocalizations of several other                                 variations, acquired through social learning, result in the
emotions (achievement/triumph, relief, and sensual pleasure)                                 finding that emotional signals tend to be recognized most
were not recognized by the Himba participants, although non-                                 accurately when the producer and perceiver are from the
verbal vocalizations of these emotions have previously been                                  same culture. The current study could provide a preliminary
                                                                                          2253

demonstration of this pattern in the context of non-verbal         expressions of emotions (Ekman et al., 1969), This supports
vocalizations of emotion. It suggests that these signals are       theories proposing that these emotions are psychological
also modulated by culture-specific variation in a similar way      universals and constitute a set of basic, evolved functions,
to emotion facial expressions and affective speech prosody.        that are shared by all humans. In addition we demonstrate
Which cultural aspects are most important for modulating           that several positive emotions are recognized within, but not
these different types of affective communication will be a         across cultural groups, which may suggest that affiliative
question for future studies.                                       social signals are shared only with in-group members.
  Some affective states are communicated using signals that
are not shared across cultures, but specific to a particular                            Acknowledgments
group or region. In our study, vocalizations intended to           This research was funded by a grant from the University of
communicate a number of positive emotions were not                 London Central Research fund to D. A. S., a contribution to
reliably identified by the Himba listeners. Why might this         travel costs from the University College London
be? One possibility is that this is due to the function of         Department of Psychology, and a Wellcome Trust
positive emotions. It is well known that the communication         fellowship to S. K. S. The authors would like to thank David
of positive affect facilitates social cohesion with group          Matsumoto for useful discussions.
members (Shiota, Campos, Keltner & Hertenstein, 2004).
Such affiliative behaviors may be restricted to in-group                                     References
members with whom social connections are built and                 Boster, J. S. (2005). Emotion categories across languages.
maintained. However, it may not be desirable to share such               In H. Cohen & C. Lefebvre (Eds.), Handbook of
signals with individuals who are not members of one’s own                Categorization in Cognitive Science. Amsterdam:
cultural group. An exception may be self-enhancing                       Elsevier.
displays of positive affect. Recent research has shown that        Ekman, P. (1992). An Argument for Basic Emotions.
postural expressions of pride are universally recognized                Cognition and Emotion, 6, 169–200.
(Tracy & Robbins, 2008). However, pride signals high               Ekman, P. (1999). Facial expressions. In T. Dalgleish & T.
social status in the sender rather than group affiliation,              Power, (Eds.), The Handbook of Cognition and
differentiating it from many other positive emotions.                   Emotion. Sussex, UK: John Wiley & Sons.
  In the current study, one type of positive vocalization was      Ekman, P., Sorenson, E. R., & Friesen, W. V. (1969). Pan-
reliably recognized by both groups of participants: Listeners           cultural elements in facial displays of emotion. Science,
agreed, regardless of culture, that sounds of laughter                  164, 86–88.
communicated amusement, exemplified as the feeling of              Elfenbein, H. A., & Ambady, N. (2002). On the universality
being tickled. Tickling triggers laugh-like vocalizations in            and cultural specificity of emotion recognition: A meta-
non-human primates (Vettin & Todt, 2005) as well as other               analysis. Psychological Bulletin, 128, 203–235.
mammals (Knutson, Burgdorf & Panksepp, 2002),                      Hauser, M. D., Chomsky, N., & Fitch, W. T. (2002). The
suggesting that it is a social behavior with deep evolutionary          faculty of language: what is it, who has it, and how did
roots. Laughter is thought to have originated as a part of              it evolve? Science, 298, 1569–1579.
playful communication between young infants and mothers,           Kimball Romney, A., Moore, C. C. & Rusch., C. D. (1997).
                                                                        Proceedings of the National Academy of Sciences of the
and also occurs most commonly in both children and non-
                                                                        USA, 94, 5489-5494.
human primates in response to physical play (Provine,
                                                                   Knutson, B., Burgdorf, J., & Panksepp, J. (2002). Ultrasonic
2000). Our results support the idea that the sound of
                                                                        vocalizations as indices of affective states in rats.
laughter is universally associated with being tickled, as               Psychological Bulletin, 128, 961–977.
participants from both groups of listeners selected the            Matsumoto, D., Yoo, S. H., Hirayama, S., & Petrova, G.
amused sounds to go with the ticking scenario. Indeed,                  (2005). Development and validation of a measure of
given the well-established coherence between expressive                 display rule knowledge: the display rule assessment
and experiential systems of emotions (Rosenberg & Ekman,                inventory. Emotion, 5, 23–40.
1995), our data suggest that laughter universally reflects the     Mehler, J., Bertoncini, J., & Barriere, M. (1978). Infant
feeling of enjoyment of physical play. Future work should               recognition of mother’s voice. Perception, 7, 491–497.
address whether this universality extends to conceptual            Norenzayan, A., & Heine, S. J. (2005). Psychological
representations in semantic systems as well, which has been             Universals: What are they and how can we know?
explored in the context of primarily negative emotions                  Psychological Bulletin, 131, 763–784.
(Boster, 2005; Kimball Romney, Moore & Rusch, 1997).               Parr, L. A., Waller, B. M., & Heintz, M. (2008). Facial
  In this study we show that a number of emotions are                   expression categorization by chimpanzees using
universally recognized from vocal signals, which are                    standardized stimuli. Emotion, 8, 216–231.
perceived as communicating specific affective states. The          Provine, R. R. (2000). Laughter: A Scientific Investigation.
emotions found be recognized from vocal signals                          London, UK: Faber and Faber.
correspond to those universally inferred from facial               Rosenberg, E. L., & Ekman, P. (1994). Coherence between
                                                               2254

    expressive and experiential systems in emotion.             Shiota, M. N., Campos, B., Keltner, D., & Hertenstein, M. J.
    Cognition and Emotion, 8, 201–229.                            (2004). Positive emotion and the regulation of inter-
Sauter, D. A., Calder, A. J., Eisner, F., & Scott, S. K.          personal relationships. In P. Philippot & R. S. Feldman
    (2009). Perceptual cues in non-verbal vocal expressions       (Eds.), The regulation of emotion. Mahwah, NJ: Erlbaum.
    of emotion. Manuscript under review.                        Susskind, J. M., Lee, D. H., Cusi, A., Feiman, R., Grabski,
Sauter, D. A. & Scott, S. K. (2007). More than one kind of          W., and Anderson, A. K. (2008). Expressing fear
    happiness: Can we recognize vocal expressions of                enhances sensory acquisition. Nature Neuroscience, 11,
    different positive states? Motivation and Emotion, 31,          843–850.
    192-199.                                                    Tracy, J. L., & Robins, R. W. (2008). The nonverbal
Scherer, K. R., Banse, R., & Wallbott, H. G. (2001).                 expression of pride: Evidence for cross-cultural
    Emotion inferences from vocal expression correlate               recognition. Journal of Personality and Social
    across languages and cultures. Journal of Cross                  Psychology, 94, 516-530.
    Cultural Psychology, 32, 76–92.                             Vettin, J., & Todt, D. (2005). Human laughter, social play,
Seyfarth, R. M. and Cheney, D. L. (2003). Meaning and               and play vocalizations of non-human primates: An
    emotion in animal vocalizations. Annals of the New              evolutionary approach. Behaviour, 142, 217–240.
    York Academy of Science, 1000, 32–55.                       Waller, B. M., Cray, J. J., & Burrows, A. M. (2008).
                                                                    Selection for universal facial emotion. Emotion, 8, 435–
                                                                    439.
                                                            2255

