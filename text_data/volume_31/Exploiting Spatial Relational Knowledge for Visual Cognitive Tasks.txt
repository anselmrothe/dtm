UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Exploiting Spatial Relational Knowledge for Visual Cognitive Tasks
Permalink
https://escholarship.org/uc/item/4n05x8q2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Eggart, Julian
Einecke, Nils
Riad, Medhat
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                               Powered by the California Digital Library
                                                                  University of California

              Exploiting Spatial Relational Knowledge for Visual Cognitive Tasks
                                             Medhat M. Riad (medhat.riad@phil.uu.nl)
                                                     Utrecht University, Heidelberglaan 6
                                                      3584 CS Utrecht, The Netherlands
                                   Florian Röhrbein (roehrbei@informatik.uni-bremen.de)
                                               University of Bremen, Enrique-Schmidt-Str. 5
                                                            28359 Bremen, Germany
                                               Nils Einecke (nils.einecke@honda-ri.de)
                                             Julian Eggert (julian.eggert@honda-ri.de)
                                     HONDA Research Institute Europe GmbH, Carl-Legien-Str. 30
                                                    63071 Offenbach am Main, Germany
                              Abstract                                    object complexity (boundary points). However, these tech-
   Reasoning about objects in a visual scene can be substantially         niques do not scale very well with number of images and if
   improved if we have a representation that includes both in-            any regularities are seen then they are more representative of
   formation about the object properties and information about            artistic preferences of photographers than actual object prop-
   the relations that hold between them. For this, we have built
   a semantic-relational network that makes use of textual com-           erties in real-world scenes (e.g. photographs of airplanes will
   monsense knowledge of both sorts and allows for inference              usually be centered on the plane when obviously an airplane
   within a Bayesian framework (Röhrbein, Eggert, & Körner,             is seldom in the center of the visual field in everyday scenes).
   2007). In order to enrich this graphical representation, we tar-
   get at adding complementary information gained, for example,           For this reason, it is our belief that analyzing object-object
   from sets of labeled images. We are especially interested in re-       relations in images rather than object-scene relations would
   lational knowledge, a demand that rules out most existing im-          reduce the effect of photography bias and, as shown in the
   age databases since they usually contain only one labeled ob-
   ject per image. LabelMe proved as a promising alternative and          results, could detect some regularities in spatial relations be-
   we started our efforts by analyzing the statistical dependencies       tween these objects.
   between all objects in fully-labeled images of that database. In          The following section will give a brief introduction to the
   the contribution here, we report these results and discuss how
   the gained information can be used to build contexts as a first        LabelMe database that we use in our analysis followed by an
   important step in reaching the final goal of learning a relational     overview of region connection calculus, of which we used a
   knowledge representation in an autonomous way.                         modified version to describe relations between objects in im-
   Keywords: inter-object relations; spatial context; labeled im-         ages. In the results section, we report on some of the interest-
   ages
                                                                          ing results we found on different levels of detail. Following
                          Introduction                                    this, we dedicate the final section to discussing the results and
Visual scenes contain a wealth of information which would be              how to interpret them as well as present the problems faced
very useful for technical systems. The complexity of visual               and how these problems affected the results. There is also
information and the processing and storage costs involved in              a subsection discussing related work and the reported results
acquiring any form of this information that is directly usable,           and the discussion section ends by briefly talking about future
makes the use of visual information very challenging. This is             plans and incorporating this information into our semantic-
further complicated by the problem of deciding what kind of               relational network.
information is useful and what is simply superfluous. How-
ever, a lot of research has been carried out over the years
                                                                                                      Method
to obtain useful information from visual scenes whether it                Annotated images
be high-level, global context information (Fei-Fei & Perona,              One of the main requirements for this research is to have a
2005), object recognition (Wersing & Körner, 2003), or low-              large database of images with multiple annotated objects per
level image processing for feature detection (Lowe, 2004). In             image. Even though there are several publicly available an-
this paper, we report on preliminary results of statistical anal-         notated image data-sets, most of them either have too few
ysis on images at an intermediate-level where object informa-             images for our purpose or contain only one object per image.
tion is assumed to be readily available showing that there are            Such single-object images are very useful as training data for
some statistical regularities in visual scenes at a level below           object recognition but are useless for trying to uncover regu-
that of global cues (like texture or gist models) and above that          larities in larger, complex, multi-object scenes. For this pur-
of local analysis (such as edge detection or single objects).             pose, we use LabelMe (Russel, Torralba, Murphy, & Free-
   Working at object-level means that annotated images must               man, 2008) which is an on-line, publicly accessible database
be available. Some of the common analysis techniques in-                  which depends on Internet users to upload and annotate im-
clude object positions, percentage area covered by object, and            ages.
                                                                      1535

   The LabelMe database consists of many images along with
corresponding XML files containing the label names and
polygon points representing each labeled object in the image.
A single image may contain any number of labeled polygons
(see Figure 1 for an example). Internet users can view current
labels and add new ones. Labels of objects are typed in using
the keyboard and there are no restrictions on what any label
can be.
   Undoubtedly, the use of such an “uncontrolled” data-set
introduces some problems. One very pronounced problem is
that there could be many variations of the same object class
(e.g. trashcan, bin, trash bin, waste basket, etc...). In the
reported results, all the different “synonyms” of an object
class are treated as if they are independent classes without
any attempt to normalize or consolidate the user-submitted            Figure 1: A fully-annotated LabelMe image with associated
labels. Another related problem is that of viewing-angle la-          labels. In this example, manhole is a proper part of road-
bels. Many users provide some hints in the labels as to what          Region and disconnected from bicycleSide which itself par-
the viewing angle of the object is, and even though there are         tially overlaps one of the car occluded objects (see next sec-
some attempts by the annotators to have a standard for pro-           tion). Repeated labels have been removed for brevity. (Image
viding such information, it is largely un-managed resulting in        adapted from LabelMe (Russel et al., 2008))
labels like car front, car side view, and car az240deg specify-
ing the azimuth in degrees. Such labels are going to be very
useful at a later stage when view-dependent statistics are re-        jects; externally connected (EC) represents separate objects
quired but again, at this stage, each different label is treated      that are touching at an edge; the equal (EQ) relation means
as an independent object class. There are also spelling mis-          both objects are exactly equal in size and in the same position;
takes (e.g. wnidow) and garbage labels found in the data but          partially overlapping (PO) means part of one object intersects
these do not appear often enough to pass as legitimate object         with the other; tangential proper part (TPP) and tangential
classes according to our filtering criteria discussed next.           proper part inverse (TPPi) represent the cases where one ob-
   LabelMe is a very large database, and many of its images           ject is completely contained within the other and is touch-
have few or no annotated objects. One way to deal with this           ing at some edge; and non-tangential proper part (NTPP)
problem is to only use fully-annotated images. An image is            and non-tangential proper part inverse (NTPPi) also repre-
considered to be fully-annotated if at least 90 percent of its        sent cases of one object contained within the other with the
area is assigned to at least one annotation. Of course this           difference that no edges are touching. From these basic re-
is an arbitrary choice but it provides a large enough data-set        lations, different combinations can be built, resulting in new
while removing most images that do not have enough labeled            relations.
objects. The resulting data-set of 4,955 images had an aver-             In our analysis, we choose a subset of RCC8 which rep-
age of 16.7 objects per image ranging from 1 object to 266.           resents the combinations we found to be most likely in a
To increase the reliability of the results, any object class that     two-dimensional projection of the three-dimensional physi-
had less than 10 instances in the database, or only existed in        cal world. The EC category is incorporated with the DC cat-
one image was excluded from the analysis, in the latter case,         egory by introducing a distance variable where a distance of
regardless of how many instances were found.                          zero represents EC and a distance greater than zero repre-
                                                                      sents DC. We call this new relation, non-overlapping (NO).
Region Connection Calculus                                            TPP and NTPP are combined into a proper part category (PP)
In order to be able to extract useful relations between objects       which simply means that one object is completely contained
in images we need a standard way of describing the possi-             within the other. Similarly, TPPi and NTPPi are combined
ble spatial arrangements between them. One way to do this             into proper part inverse (PPi). The PO category is used as
would be to have directional relations like left-of, above, be-       is with no changes while EQ is dropped all together since it
hind, etc, but this introduces the problem of granularity and         would be highly improbable for two objects to be in exactly
fuzziness so a much simpler and unambiguous representation            the same position with exactly the same size in an image and
was needed.                                                           still be recognizable as to receive two separate labels.
   Region connection calculus (RCC) is a qualitative spatial             Interestingly, Galleguillos, Rabinovich and Belongie
representation to abstractly describe regions and their rela-         (Galleguillos, Rabinovich, & Belongie, 2008) came up with
tions to each other (Randell, Cui, & Cohn, 1992). One ver-            similar spatial categories using a vector quantization ap-
sion of RCC, called RCC8, consists of 8 basic relations that          proach. For the representation of spatial relationships they
are possible between two regions in two-dimensional space.            use INSIDE, AROUND, ABOVE and BELOW. The main
The disconnected (DC) relation represents two separate ob-            difference to our RCC-derived categories lies in neglecting
                                                                  1536

horizontal relations, which is due to the image databases they
                                                                         Table 1: All object pairs where the probability of appearance
are using (see Discussion section).
                                                                         of the second object given the first object is present is 1
   For deciding which category an object pair falls into, poly-
gon intersection areas are used. An intersection area of zero              Object 1             Object 2    Object 1           Object 2
means an NO relation; PP or PPi is the result when the area                taxi                 road        tray               wall
of the intersection is equal to the area of one of the polygons            washbasin            wall        socket             wall
but not the other, and a PO relation is the result when the in-            windshield (occ)     window      dishwasher         wall
tersection area is less than both polygon areas. For distance              van rear             road        cars side (occ)    road
measurement, we use a minimum gap algorithm on the con-                    wheel rim            wheel       telephone          wall
vex hulls of the corresponding object polygons and for angle               dishwasher           sink        ceiling            wall
measurement, we calculate the angle between the centroids                  light switch         wall        cushion            wall
of the polygons.                                                           dishwasher           faucet      bed crop           wall
                                                                           cupboard             wall        toilet paper       wall
                             Results
                                                                           bed                  wall        outlet             wall
In the following few subsections, results from different levels            electrical outlet    wall        one way sign       window
of abstraction are shown.                                                  wheel (occ)          window      cabinet            wall
Object Co-occurrence                                                       ceiling light        wall        motorcyclist       road
                                                                           toilet               wall        rug                wall
Using only fully-labeled images as described earlier, there                alarm clock          wall        end table          wall
was a total of 1,622 object classes which gives a total of                 papers               wall        porch              window
1,314,631 possible tuples. Out of these, only 3207 tuples
were found to exist in the same image, which is less than
0.25 percent.
                                                                         Table 2: All pairs of the proper part (PP) category with prob-
Conditional Probabilities                                                ability greater than 0.5
In an attempt to see how the presence of an object predicts
the presence of another, we calculate the conditional proba-               Object 1           Object 2        Object 1    Object 2
bilities of object 1 being found in an image given that object 2           bed                pillow          field       shrub
is known to be there and vice-versa. It is not possible to list all        building region    window          house       sign
these probabilities here so Table 1 shows all instances where              buildings          windows         road        manhole
this probability is one. In the table, the presence of “Object             car az30deg        wheel rim       road        manhole cover
1” in an image predicts with a probability of one, that “Ob-               ceiling            ceiling light   wall        alarm clock
ject 2” is found somewhere in the same image. For example,
the data predicts that if taxi or van rear is seen, then there is
always a road. It has to be kept in mind that this does not
make any predictions about how the objects are related spa-              objects as well as the distribution of the angle between them
tially or conceptually, it is merely a co-existence correlation          (Figures 2(a) and 2(b) respectively). For PO, Figure 2(c)
which explains why seemingly counter-intuitive pairs such as             shows the distribution of the ratio between the area of the
one way sign and window are so strongly correlated.                      overlapping regions and the area of the first object while Fig-
                                                                         ure 2(d) shows the angles between the partially overlapping
Spatial Relations                                                        objects. For PP (Figures 2(e) and 2(f)), the distributions show
Out of the 3,207 found co-occurring pairs, there are 144 pairs           the angles between the objects and how much of the larger
that have a probability less than 0.5 to be in the NO category.          object is covered by the smaller one (represented as a ratio).
Only 10 pairs are found to belong to category PP with a prob-            Distributions for PPi are the same as those for PP with the
ability greater than 0.5 (Table 2). The PPi category contains            difference that angle distributions are mirrored along the hor-
the same 10 pairs with a probability greater than 0.5 with the           izontal direction.
difference that “Object 1” and “Object 2” are switched. For
the PO category, 103 pairs with probability greater than 0.5                                       Discussion
are found.                                                               Some research suggests that many cognitive abilities, includ-
                                                                         ing abstract thought, make use of spatial relations or schemas
Distributions
                                                                         in contexts that do not necessarily involve physical spatial
For each of the categories, distributions of selected variables          properties (Gattis, 2001). An example would be people think-
over the individual instances are presented here. For the NO             ing about horizontal directions when thinking about siblings
category, distributions are shown for the distance1 between              or the upwards direction when thinking about respect. It
    1 Several image sizes have been used therefore the distance mea-     is therefore our belief that spatial relations are important in
surements also include an implicit depth attribute.                      knowledge representations since they are not only confined
                                                                     1537

                      (a) Distribution of distances (in pixels) for         (b) Percentage distribution of angles (in
                      the NO category                                       degrees) for the NO category
                      (c) Distribution of area ratio (overlap area/         (d) Percentage distribution of angles (in
                      area of object 1) for PO category                     degrees) for the PO category
                      (e) Distribution of area ratio (area of ob-           (f) Percentage distribution of angles (in
                      ject 2/ area of object 1) for PP category             degrees) for the PP category
                      Figure 2: Various distributions between object pairs of the different relation categories
to relations between physical objects thus providing ground-            everyday scenes. It is also predicted by the results that the
ing for other, more abstract concepts.                                  majority of co-occuring objects in a scene will be nonover-
                                                                        lapping. Even though we believe that this prediction is overly
   In the physical context, it could at first seem that natu-           exaggerated due to reasons discussed later, it seems that it is
ral scenes are combinatorially infinite in terms of object re-          also a viable characteristic of natural scenes since most ob-
lations, however, previous research (Torralba, Oliva, Castel-           jects will, in fact, have some distance between them except in
hano, & Henderson, 2006) shows regularities in distributions            highly crowded scenes.
for object instances of the same class. The results presented
here, show that there are also regularities between object in-             There are also some regularities seen regarding the rela-
stances of different classes which limits the possible combi-           tive positions and distances for the different relation cate-
nations, or at least, highlights the most probable ones. The            gories. The distributions in Figure 2 seem to suggest that
results also show that more than 99.75% of all object pairs             non-overlapping, co-occurring object pairs tend to be close
tested, never co-occur in the same scene, suggesting that it is         together and positioned horizontally from each other. Par-
not very likely that any of these pairs would occur in normal,          tially overlapping pairs show a very small overlap ratio to the
                                                                    1538

area of the first object and are more evenly positioned with a        suggest that, 75% of cars do not have license plates which is
preference towards the vertical direction. For the proper part        obviously false. Such false predictions are made due to a
pairs, it seems that the majority of smaller objects are much         combination of several factors, one of which is the aforemen-
smaller than the bigger ones. It might also be worth noting           tioned viewing angle. In this case, it could be said that out of
that the angle distributions for NO and PO are almost sym-            all the times a car is seen, it is only seen at an angle which al-
metrical in both the vertical and horizontal directions while         lows the license plate to also be seen, about 25% of the time.
the PP and PPi angle distributions are only symmetrical along         This makes sense if we assume that most of the time, cars are
the vertical. Even though it might not be straight forward to         seen from the side. However, in other cases, viewing angle
interpret what these regularities mean, it seems that these reg-      does not properly account for the discrepancy between the
ularities do exist and can be helpful for visual tasks.               results and real world statistics. One of the most pronounced
   Looking at results from other research, it has been shown          examples of this is that of comparing building occluded with
that multi-class object detection using contextual information        window (see Table 3). In this example, we see a very high
between objects and object parts has shown an improvement             percentage of NO instances, with a relatively small percent-
in performance over systems which do not use such contex-             age of PP instances where a window is completely inclosed
tual information (Fink & Perona, 2004). However, this work            within a building. One of the factors which brings about such
has only been applied to face recognition tasks and it is not         inaccurate results is the inconsistency in the labeling. Some
clear how this would generalize to other tasks. Also, the focus       buildings will have every single window with a separate la-
of this work is on the interactions between part and whole de-        bel, some buildings will have all of its windows labelled with
tection of one object rather than on the inter-object relations       a single all-inclusive label. Others still, will have only one
which our work focuses on.                                            or two labelled windows and sometimes none, and this obvi-
   There is also work on improving image segmentation by              ously skews the results. Another very important issue is that
finding associations between image segments and a list of             of the category abstraction level of a label. In this case, the
word tokens the image is annotated with (Carbonetto, Fre-             label “window” is found in the dataset to represent instances
itas, Freitas, & Barnard, 2004). The way this works is by             of car windows, building windows, indoor windows, and this
formulating a probabilistic mapping between continuous im-            contributes to a certain extent to the NO category overtaking
age feature vectors and the supplied word tokens, which can           the others. A more illustrative example might be that of the
lead to smoothed image segmentation, especially in situations         object leg which could represent a dog’s leg, a person’s leg,
where the scene was previously over-segmented. In contrast,           or a chair leg.
we make use of already labeled multi-object images and di-               Some of the other problems we found include polygon in-
rectly analyze the spatial relations which hold between these         accuracy and edge overlap issues. In polygon inaccuracy, la-
objects within an image, giving inter-object relations rather         belers often need to estimate borders and there can always be
than segment-word mappings.                                           a small overlap between separate objects or parts of a sup-
   A very recent paper by Galleguillos, Rabinovich and Be-            posedly PP object lying outside of its enclosing object. In
longie (Galleguillos et al., 2008) is most similar to our work        edge overlap situations, where one object completely hides
reported here, since they make use of co-occurrence statistics        the edge of another object, labelers tend to trace the visible
as well as spatial relations to improve their object recognition      border between the two objects rather than approximate the
system. They claim to be the first who make use of explicit           actual edge, giving inaccurate results. For example, in im-
spatial context between objects, but the generality of the re-        ages with buildings that have cars parked in front of them, it
sults they obtain is severely limited by the databases (MSRC          is very common to see labelers trace around the cars instead
and PASCAL2007) they are using: MSRC comprises only                   of guess where the building would meet the ground.
23 different categories while PASCAL2007 contains 20 cat-
egories. Even more severe, the images contain on average                 There is also one particular problem that has proven to be
of only 3 (MSRC) or even 2 (PASCAL2007) objects. A fur-               not so trivial to deal with; and that is the problem of “false-
ther drawback with respect to accuracy is that both do not use        positives”. Many pair instance comparisons result in an NO
polygons, but region masks or simple bounding boxes2 .                relation when in fact one of the instance pairs has a PO or
                                                                      a PP relation with another instance in the same image. For
Problematic Cases                                                     example, if we go back to our car/license plate example, hav-
                                                                      ing multiple instances of cars and license plates in an image
In our results, it is generally the case that many more in-
                                                                      is problematic, even if the labeling is accurate and complete.
stances of any given object pair fall into the NO category than
                                                                      If we assume there are n cars and n license plates in the image
we expected. For example, looking at car and license plate
                                                                      and every instance of car has exactly one PP relation with a
(see Table 3), we see that a license plate is only a proper part
                                                                      license plate, we can see that there are n2 − n NO relations
of a car about 25 percent of the time and non-overlapping
                                                                      and only n PP relations. And the problem gets worse with
with it the rest of the time with no partial overlaps. This might
                                                                      more instances since increasing the number to n + 1 cars and
    2 For a detailed comparison of the different labeled image        license plates, gives a much higher increase in NO to n2 + n
databases see (Russel et al., 2008).                                  compared to the increase in PP which only becomes n + 1.
                                                                  1539

                                                                   penser or bed to differentiate between offices and bedrooms).
Table 3: Some inaccurate examples (Object names are fol-
                                                                   It seems plausible that the idea of a hierarchy of relations
lowed by number of instances found)
                                                                   could prove to be very useful. Another way to improve the
                 Example 1            Example 2                    results would be to capitalize on orientation-dependent regu-
     Object 1    car (101)            building (occ) (127)         larities that have already been found where it might be useful
     Object 2    license plate (111)  window (603)                 to use image analysis at an early stage to determine the pose
     Tuples      151                  833                          of objects as it is very likely that pose-related regularities can
     NO          114 (≈ 75%)          709 (≈ 85%)                  be found (e.g. chair facing desk, mug handle facing outside).
     PO          0 (0%)               3 (≈ 0%)                     On a slightly different front, performing the analysis on se-
     PP          37 (≈ 25%)           121(≈ 15%)                   quences of images seems to be a very interesting idea, where
     PPi         0 (0%)               0 (0%)                       the aim would be to discover regularities in the way spatial re-
                                                                   lations change over time and how these regularities might be
                                                                   different between different objects, adding an extra temporal
                                                                   dimension to the semantic-relational network.
   In an attempt to solve this problem we separate the NO cat-
egory into two sub-categories, NO-1 and NO-2, where NO-1                                      References
represents pairs where the first object does not overlap any       Carbonetto, P., Freitas, N. de, Freitas, O. D., & Barnard, K.
instance of the second object in the same image and NO-               (2004). A statistical model for general contextual object
2 represents pairs where the first object does not overlap a          recognition. In ECCV (pp. 350–362).
given instance of the second object while it does overlap at       Fei-Fei, L., & Perona, P. (2005). A bayesian hierarchical
least one other instance. This distinction between “verified”         model for learning natural scene categories. In Proceedings
NO pairs and “suspicious” ones gives the ability to have some         of IEEE computer society conference on computer vision
idea of how strong the overall NO relation between the object         and pattern recognition CVPR’05 (Vol. 2, pp. 524–531).
classes is while not making any assumptions based on our           Fellbaum, C. (1998). Wordnet: An electornic lexical
knowledge of the objects in question. For the license plate ex-       database. Bradford Books.
ample this gives 81 instances in the NO-1 category (≈ 54%)         Fink, M., & Perona, P.(2004). Mutual boosting for contextual
which is still quite high, but it must be noted that license          inference. In NIPS. MIT Press.
plate can also be part of van or car back so some process-         Galleguillos, C., Rabinovich, A., & Belongie, S. (2008). Ob-
ing of the synonyms of object names could give much bet-              ject categorization using co-occurrence, location and ap-
ter results (e.g. using WordNet (Fellbaum, 1998)). It is still        pearance. In IEEE conference on computer vision and pat-
not very clear what NO-2 indicates since in some situations it        tern recognition, CVPR-2008 (pp. 1–8).
would contain legitimate non-overlapping object pairs, and in      Gattis, M. (Ed.). (2001). Spatial schemas and abstract
other situations it would include the false-positives we wish         thought. Cambridge, MA: MIT Press.
to eliminate. We found no trivial, generic way to differenti-      Lowe, D. G. (2004). Distinctive image features from scale-
ate between the two situations without having some previous           invariant keypoints. International Journal of Computer Vi-
knowledge about the objects in question.                              sion, 60, 91–110.
                                                                   Randell, D., Cui, Z., & Cohn, A.(1992). A spatial logic based
Future Directions
                                                                      on regions and connection. In Proceedings of KR’92 (pp.
One of the reasons for performing this analysis is to extend          165–176). San Mateo, California.
a semantic-relational network with information about spatial       Röhrbein, F., Eggert, J., & Körner, E. (2007). A cortex in-
relations between objects. It is relatively straightforward at        spired neural-symbolic network for knowledge represen-
this stage to use the results we have to store Bayesian spa-          tation. In Proceedings of IJCAI’07 workshop on neural-
tial relations in the network. A future step would be to see          symbolic learning and reasoning. CEUR Workshop Pro-
how combining this setup with other techniques like saliency          ceedings.
maps or feature detection algorithms would improve the per-        Russel, B. C., Torralba, A., Murphy, K. P., & Freeman, W. T.
formance in tasks such as object recognition or guided vi-            (2008, MAY). Labelme: a database and web-based tool
sual search. However, it must be noted that the results pre-          for image annotation. International Journal of Computer
sented here are only for pairs of objects, and given the prob-        Vision, 77(1-3), 157–173.
lems faced, there is still more work needed to improve the         Torralba, A., Oliva, A., Castelhano, M. S., & Henderson,
results (as discussed earlier). Another way the results could         J. M. (2006). Contextual guidance of eye movements and
be made more reliable is by extending the idea to analyze             attention in real-world scenes: the role of global features in
triples or quadruples of objects. By moving towards incorpo-          object search. Psychological Review, 113(4), 766–786.
rating more and more objects in the analysis, any regularities     Wersing, H., & Körner, E. (2003). Learning optimized fea-
found would eventually form a context (for example chair,             tures for hierarchical models of invariant recognition. Neu-
desk, wall and window can form a “working area” context               ral Computation, 15(7), 1559–1588.
which can be combined with other objects like water dis-
                                                               1540

