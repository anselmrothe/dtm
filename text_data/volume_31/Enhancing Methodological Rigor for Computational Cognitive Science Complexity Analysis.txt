UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Enhancing Methodological Rigor for Computational Cognitive Science: Complexity Analysis
Permalink
https://escholarship.org/uc/item/5h24h0vp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Beal, Jacob
Roberts, Jennifer
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

          Enhancing Methodological Rigor for Computational Cognitive Science:
                                                     Complexity Analysis
                                                 Jacob Beal (jakebeal@bbn.com)
                                                 BBN Technologies, 10 Moulton Street
                                                      Cambridge, MA 02138 USA
                                              Jennifer Roberts (jenmarie@mit.edu)
                                                      MIT CSAIL, 32 Vassar Street
                                                      Cambridge, MA 02139 USA
                             Abstract                                use examples from two recent pieces of work: Xu and Tenen-
                                                                     baum’s work applying Bayesian inference to word learning
   Complexity analysis provides a measure of how well the com-
   putations being performed by a cognitive model are supported      (Xu & Tenenbaum, 2007) and Forbus and Hinrich’s work on
   by the constraints of biological computing. We argue that         the construction of a large-scale analogical reasoner (K. D.
   research in computational cognitive science will be greatly       Forbus & Hinrichs, 2006). We have chosen these two pieces
   aided by treating computational complexity as a primary is-
   sue on the same order of importance as significance analysis      of solid, well-formulated computational work to illustrate
   in experimental work. In this paper, we give a brief review       how complexity analysis can enhance qualitatively different
   of computational complexity and its application in computer       types of computational research.
   science. We then show how it can be applied to incorporate
   biological constraints abstractly into computational cognitive
   science research, even in the presence of massive uncertainty        A brief review of computational complexity
   about the underlying neuroscience. To ground this discussion
   of complexity, examples are drawn from two recent pieces of       Let us start with a brief review of computational complex-
   work: Xu and Tenenbaum’s work applying Bayesian inference         ity, which should be familiar to anyone with a computer sci-
   to word learning (Xu & Tenenbaum, 2007) and Forbus and            ence background. When computer scientists speak of “com-
   Hinrich’s work on the construction of a large-scale analogical
   reasoner (K. D. Forbus & Hinrichs, 2006).                         putational complexity,” what they are generally referring to
                                                                     is asymptotic computational complexity—how the resources
   Keywords: Methodology; Asymptotic Complexity; Complex-
   ity Analysis; Biological Limitations                              consumed by a model grow as its scale increases. This re-
                                                                     source consumption can stem from costs incurred by the data
                           Motivation                                structure used to represent the model (e.g. the number of
                                                                     nodes and edges in a Bayesian network) or by the algorithms
Cognitive scientists often produce computational models that
                                                                     that implement the model’s operations (e.g. performing infer-
simulate the operation of cognitive processes. The discussion
                                                                     ence in a Bayesian network) or by the algorithms necessary
of a model, however, commonly neglects its computational
                                                                     for modifying the model (e.g. changing a conditional proba-
complexity. Cognitive science thus abandons one of the most
                                                                     bility table in a Bayesian network).
fundamental tools computer science provides for the analy-
                                                                        If we use the positive number n to describe the scale of a
sis of models. This impairs our ability to clearly compare
                                                                     model, then the model has upper bound asymptotic complex-
competing models and thereby encourages the development
                                                                     ity O( f (n)) if and only if there are constants n0 and k such
of both models that work on particular problems but cannot
                                                                     that whenever n > n0 , the resource cost of the model is less
extend to broader problems and models that are likely to be
                                                                     than k f (n). For example, a Bayesian network with n nodes
rendered obsolete by small changes in our understanding of
                                                                     can have up to ∑ni=1 (i − 1) dependencies, so it takes O(n2 )
the biology of the brain.
                                                                     space to represent its graphical structure. A node in the net-
   Complexity analysis helps address such problems by pro-
                                                                     work with p parents has a conditional probability table with
viding a measure of how well the computations being per-
                                                                     2 p entries, requiring O(2 p ) space. If the greatest number of
formed by a model are supported by the constraints of bio-
                                                                     parents of any node in the network is P, then the cost of stor-
logical computing. We argue that research in the field will be
                                                                     ing the entire network—nodes, dependencies, and conditional
greatly aided by treating computational complexity as a pri-
                                                                     probability tables—is O(n2P ).
mary issue on the same order of importance as significance
                                                                        Although people most frequently use the “Big O” bound,
analysis in experimental work, rather than an optional prop-
                                                                     other complexity bounds are important as well, such as the
erty that is useful when it can be established.
                                                                     Ω asymptotic lower bound and the Θ asymptotic tight bound.
   In this paper, we give a brief review of computational com-
                                                                     People most often analyze costs for time and space, and while
plexity and its application in computer science. We then show
                                                                     they are usually focus on the worst case cost, we may also be
how it can be applied to incorporate biological constraints ab-
                                                                     interested in the expected cost or the amortized cost.1
stractly into computational cognitive science research, even
in the presence of massive uncertainty about the underlying              1 Amortized cost shows how an expensive operation can be “paid
neuroscience. To ground this discussion of complexity, we            for” by improved performance on many other operations. For exam-
                                                                  99

   When possible, complexity bounds are established through               scale of the phenomena being modelled (vocabulary, for in-
formal analysis. For many models, however, this is either                 stance, debatably contains anywhere from 10,000 to 1 mil-
not practical or yields bounds that are too loose. This need              lion known words, depending on the definition of “word” and
not stop us, any more than it has stopped digital electron-               “know”), we can expect several orders of magnitude uncer-
ics, where metastability theorems show formally that a digi-              tainty in our estimates. Even so, we can readily judge the
tal circuit might never converge, and yet every execution of              plausibility of a model.
a modern processor does so in approximately one nanosec-                     For example, taking the highly conservative estimate of
ond. In these circumstances, one can often characterize the               10,000 words in an adult vocabulary, a model of language
scaling of a model through careful experiment, establishing               understanding that used O(w) = k · 104 space would be beau-
an operating range in which the behavior of the model is well             tifully cheap and one that cost O(w2 ) = k · 108 space would
understood and making projections outside of this range in                be reasonable. But O(w3 ) = k · 1012 is starting to devote an
areas where no unmeasured phenomena are expected to in-                   awful lot of space to words, and O(w4 ) = k · 1016 is unreason-
trude. For example, graph search is O(bd ) for branching fac-             able unless one can pack many bits per synapse or ensure that
tor b and depth d to the goal, but if heuristic search through            the constant will be much less than one. Higher complexities,
a highly porous planar graph like a road network were deter-              like O(w10 ) or O(2w ), are simply ridiculous.
mined empirically to be, say, O(d) for several cities, then it               Figure 1 shows some other examples of reasonable com-
would be reasonable to predict that it would hold for nation-             plexity bounds implied by the relationship between available
wide road networks, because the character of the network is               biological resources and a modeling domain. Even though
not particularly different at the larger scale.                           the particular numbers are highly debatable, the uncertainty
                                                                          makes little difference to the complexity bounds. For exam-
   Why care about computational complexity?                               ple, consider how vocabulary complexity bounds would be
                                                                          affected if our model of the human brain shifts so that glial
In cognitive science, we study of the nature of intelligence,
                                                                          cells are designated as important computational elements and
but even the most ambitious of today’s computational models
                                                                          their number is estimated at 50 times the number of neurons.
only address a small fraction of the whole. Therefore, ev-
                                                                          This raises the number of computational elements from 1011
ery computational model must aim to advance us toward the
                                                                          to 1013 —a hundred-fold increase that at first appears mas-
Holy Grail of the subject, a “broad model” of intelligence that
                                                                          sive. But the cube root of 100 is less than 5, and so while
addresses the entirety of a mind.
                                                                          this change makes it somewhat easier to argue for the plau-
   How a model maps onto that goal may vary—some aim
                                                                          sibility of a model that requires O(w3 ) space, it by no means
to be used as elements of a broad model (e.g. feature maps
                                                                          assures it. It does even less for O(w4 ), and nothing at all
for the V1 brain area), some aim to describe abstractions im-
                                                                          for the plausibility of higher complexities. Thus, complexity
plemented somehow by a broad model (e.g. Jackendoff’s se-
                                                                          analysis provides guidance that will likely remain valid even
mantic models), and some, most indirectly, aim to identify
                                                                          through major shifts in our understanding of neuroscience.
computations that must at least be approximated by a broad
                                                                             The mere fact that a model is unreasonably expensive need
model (e.g. Tenenbaum’s program of Bayesian reasoning).
                                                                          not force us to discard it. If the model is attractive for other
   In every case, however, proposing a computational model                reasons, such as elegance or compliance with experiment,
is also proposing a computation that the brain must be able               then we may pursue one of several paths to resolve this diffi-
to perform using its sharply limited computational resources.             culty:
Remember, the entire human brain contains only an estimated
1011 neurons (Williams & Herrup, 1988) and an estimated                   • Can components of the model be replaced by equivalents
1015 synapses (Shepherd, 2004), and, taking the time scale                   with lower complexity? For example, sorting a collection
on which a signal passes along a neuron to be about one mil-                 of n items using bubble sort takes O(n2 ) time using a serial
lisecond, a human lifetime contains only about 1013 “clock                   algorithm. Sorting using heap sort takes only O(n log n)
cycles” of computation.2 While these numbers are vast com-                   time, however, and a parallel implementation of bubble sort
pared to, say, the number of words in a person’s vocabulary,                 requires only O(n) time.
they fall quickly before even moderate complexity.                        • Can we find a tighter complexity bound available for the
   Using these order-of-magnitude estimates, we can make a                   model? Often a model’s experimental performance is bet-
three way comparison between the resources available in a                    ter than the known upper bound, either because the upper
brain, the complexity of a model, and the scale of the phe-                  bound is loose or because the upper bound depends on cir-
nomena being modelled. Combining the uncertainty in our                      cumstances that can be avoided pragmatically. For exam-
knowledge about brain structure, how brains compute, how                     ple, graph-coloring is NP-complete, meaning that one can
a particular model might be implemented by a brain, and the                  easily test whether solutions are correct but searching for
                                                                             a correct solution may require exponential time. However,
ple, the O(n) cost of rebuilding a growing hash table is justified by
the expected n accesses of O(1) cost it enables.                             finding a solution is only difficult right at the boundary of
    2 Each “clock cycle” may, of course, involve quite a bit of com-         colorability; adding a few more colors often makes color-
putation on the massively parallel hardware of a brain.                      ing easy.
                                                                      100

    Measure                       Approximate Budget                 Domain                  Approximate Scale         Complexity
                                                                                                                             n
    Response time to select                                  choosing a door to enter            a few options              √)
                                                                                                                          O(c
    one of a set of n items     102 cycles of computation      recognizing a word          vocabulary of thousands       O( n)
                                                           noticing a small color patch   millions of visual features    O(log n)
                                                           working a physics problem             a few models             O(cn )
    Memory to store a set of
    n items                           1014 synapses       relations in a social network      hundreds of friends          O(n5 )
                                                                 word meanings             vocabulary of thousands        O(n3 )
                                                                    arithmetic                  a few relations           O(cn )
    Time to learn about a set
    of n items                  109 seconds of experience        word meanings             vocabulary of thousands        O(n2 )
                                                            possible body movements          billions of positions        O(n)
Figure 1: Any measurement of a cognitive task is associated with one or more limited computational resources. Given estimates
of the amount of available resources we wish to spend on this model and the scale of the domain, an approximate upper bound
for the reasonable computational complexity of models can be established. The table above shows some examples of such
budget/domain relations, filled in with numbers that are highly debatable and a plausible complexity bound. These particulars
are not the point: the point is that even changing the budget or domain complexity by an order of magnitude or two will have
only a small effect on the plausibility of the complexity bounds.
• Might we instead model a slightly different capability that        & Tenenbaum, 2007), do not suggest a particular implemen-
   allows a lower complexity model? For example, consensus           tation for their Bayesian model and explicitly avoid making
   between two processes is impossible when messages can             claims about how the brain performs computations. Nev-
   be lost. If we change the problem to be consensus with a          ertheless, complexity analysis may be applied to strengthen
   probability ε of failure, and assume messages are lost in-        this work. If a Bayesian model describes human behavior,
   dependently with probability p, however, then this weaker         then the computations carried out in the human brain must
   form of consensus requires only O(log p/ log ε) messages.         either implement the Bayesian model (albeit likely rather
                                                                     abstractly) or implement something that approximates the
• Can the model be merged with other models, so that they            Bayesian model. In the absence of a proposal for approxi-
   share the same resources? A costly model of a particular          mation, however, it is only reasonable that a reader consider
   phenomenon is more palatable if it can be mapped onto             the cost of implementing the model as described.
   an interaction between several more general components.              Considering Xu & Tenenbaum’s problem of word learning,
   For example, the cognitive substrate hypothesis (Cassi-           three basic questions of cost immediately spring to mind:
   matis, 2002) proposes that many cognitive faculties that
   have been sometimes conceived of as independent mod-              • How large is the model in memory?
   ules, such as theory of mind, might be accounted for as
                                                                     • How costly is it to add new evidence to the model?
   combinations of a few more general faculties such as spa-
   tial reasoning and sequence learning.                             • How much does the model grow over a lifetime?
   Thus, considering how any particular model potentially               The model proposed in (Xu & Tenenbaum, 2007) is based
contributes to a broad model of intelligence imposes resource        on tree-structured clustering of a set of a priori similarity
constraints that we can use computational complexity to an-          scores. Although the authors note that “Computing [a simi-
alyze. These constraints are important because even appar-           larity] score could be quite difficult...” we will begin with the
ently simple models may be computationally intractable. A            optimistic assumption that computing the similarity of two
model with unreasonable complexity demands revision be-              objects takes O(1)—constant time. For a set of n labelled
fore it can be accepted, just as a phenomenon with weak              objects, then, it costs O(n2 ) time to find their similarity mea-
statistical significance uncovered by human experiment de-           sures and O(n2 ) time to cluster them into a tree-structured
mands new experiments before it can be judged to exist. Nor          taxonomy of O(n) hypotheses (assuming group-average ag-
does the discussion of computational complexity need to be           glomerative clustering). Any new example can potentially
much longer than discussions of statistical significance—in          change every cluster in the tree, so we assume it is recom-
most papers, a paragraph or two plus appropriate references          puted from scratch every time that a new object is perceived.
would suffice.                                                          Given this tree, the paper describes how the probabilities
   In summary, we argue that a cognitive scientist should no         p(h) can be computed for a cost of O(1) and p(X|h) com-
more accept a computational paper with no complexity anal-           puted for a cost of O(|X|), where X is the set of examples
ysis of its models than an experimental paper with no signifi-       pertaining to a particular word w. Bayes’s rule then allows
cance analysis of its data.                                          the likelihood of a hypothesis about any particular word to be
                                                                     computed for O(|X|n), and with n hypotheses from the tree-
                 Example: word learning                              structured taxonomy, the best can be picked out for O(|X|n2 ).
How do questions about computational complexity apply to                We can now answer the questions above. Since the tree
the two examples we have chosen? Xu & Tenenbaum (Xu                  may need to be recomputed from scratch every time, all n la-
                                                                101

belled objects must be stored. The space for the tree and all         is done by the MAC stage of MAC/FAC retrieval (K. For-
annotating information, however, is still only O(n)—a very            bus, Gentner, & Law, 1995), which takes O(k) operations for
comfortable cost. Again, because everything may be recal-             a knowledge base with k elements. This can be parallelized
culated from scratch, the cost of adjusting the model for a           trivially, resulting in O(log k) time and O(k) circuit complex-
new piece of evidence equals the cost of computing similar-           ity (a form of space complexity). Analogical mapping oper-
ity, building the tree, and picking the best hypothesis for a the     ations are implemented using a greedy version of SME re-
word category being learned: O(|X|n2 ) time. Over a lifetime          quiring time linear in the number of kernel mappings, which
of n examples, then, the time cost is O(|X|n3 ). When n is a          are bounded by a worst case O(n2 ), where n is the number of
few dozen examples, as in the experiments in (Xu & Tenen-             elements in an example. In practice, however, the complex-
baum, 2007), this number is not very big. But if a person             ity appears to often be much lower (K. Forbus, Ferguson, &
encountered around a million labelled examples over their             Gentner, 1994). Mappings are made in the FAC portion of re-
lifetime, then n3 is 1018 and this model begins to look very          trieval, which in practice uses only three (K. Forbus, Usher, &
expensive indeed.                                                     Tomai, 2005), and SEQL (Kuehne, Forbus, & Gentner, 2000),
   Considering that the authors avoided making any claims             where the number of mappings required is unclear, so we op-
about how to perform the computations in their model, the             timistically assume that it too is constant.
authors are probably cognizant of these issues and have                  Next, we look for estimates of the scale of n and k. One
thoughts about how to resolve them. For example, other tree-          of the three domains examined in (K. D. Forbus & Hinrichs,
building algorithms may give much better incremental perfor-          2006), tactical decision games, has cases with a size of ap-
mance. An explicit discussion of the computational complex-           proximately n = 1000 propositions (case size in the other two
ity issues, however, improves the work by helping the reader          domains is not stated). The expected size of the knowledge
to fairly assess the cognitively plausibility of their model, by      base is not specified in this paper, but Forbus and colleagues
clearly indicating open problems implied by complexity is-            are architecting it to support knowledge bases with k = 109 el-
sues, and by clearly showing when complexity issues might             ements (K. D. Forbus, 2009), which gives us a good ballpark
preclude the reader from extending the model beyond the par-          estimate of their guess at how large human-scale knowledge
ticular experiments reported.                                         might be.
            Example: analogical reasoning                                With these established complexities and estimates of scale,
                                                                      we can now consider the relationship of the Companion ar-
The analogical reasoning architecture described in (K. D. For-        chitecture to analogical reasoning in human minds. We need
bus & Hinrichs, 2006) relates even less directly to the hu-           only assume that human minds are also doing large-scale ana-
man brain, as it only seeks to cope with a problem that hu-           logical reasoning, and that the algorithms’ costs are more due
man minds must cope with as well. Nevertheless, relating the          to the computational nature of analogy than to peculiarities of
complexity of the computational model back to questions of            design—a reasonable conjecture after two decades of prag-
cognitive plausibility can raise important questions for inves-       matic honing.
tigation.
                                                                         Consider the 109 scale of the knowledge base. At this scale,
   In the Companion architecture (which has actually been
                                                                      logarithmic time is quite reasonable, so long as the constants
constructed) a user interacts with a cluster of machines all
                                                                      are not bad. For circuit complexity: 109 elements is much
doing analogical retrieval on a knowledge base that contains
                                                                      smaller than 1011 neurons. Most of the operations are mul-
models of the domain, tasks, dialog, users, and itself. Brush-
                                                                      tiplications or additions, which might even be supported by
ing aside a number of other details, let us consider two ba-
                                                                      synapses—and 1015 is much larger still. Consider, however,
sic activities of the architecture: searching the knowledge
                                                                      that biological hardware is often fairly noisy. The amount of
base for promising examples and manipulating small num-
                                                                      noise can be reduced by increasing the amount of hardware
bers of examples with algorithms based on SME analogical
                                                                      per operation, but the cost may rise sharply as allowable error
mapping (Falkenhainer, Forbus, & Gentner, 1989). We now
                                                                      decreases. Considering cognitive plausibility thus motivates
consider the following three questions:
                                                                      a new question about retrieval: how sensitive are the results
• What are the complexities of searching the knowledge base           of MAC/FAC to noise in the MAC stage? If the sensitivity is
   and analogical mapping?                                            high enough, then that casts doubt on the plausibility of large-
                                                                      scale knowledge bases and may lead to investigation of less
• What is the expected scale of the examples and the knowl-           sensitive retrieval methods (which may have other interesting
   edge base?                                                         cognitive properties) or of how large-scale analogy might be
                                                                      supported with smaller knowledge bases.
• What can we learn from comparing these complexities and
   domain scales with available biological resources?                    Time is the limiting factor for analogical matching. With
                                                                      n in the range of 103 , matching might cost on the order of
   Although the paper does not directly address computa-              106 serial time steps—many minutes of neuron-speed “clock
tional complexity, we can mostly answer the first question            ticks”—but the common case for the greedy algorithm is ex-
by following its references. Searching the knowledge base             pected to be much faster. Empirical surveys can determine
                                                                  102

whether it is reasonable to expect the common case to be fast          We hardly need to mention that cognitive experiments are
enough—O(log
   √             n) would be a nice bound to discover, while       similarly beset with potential interference. Any experiment is
O( n) would be pushing it and O(n) probably too much un-           subject to interference from the cognitive faculties not under
less the constant is much below one. We might also test            consideration, and the complex interactions between faculties
whether something like the greedy algorithm is being used          may produce non-random interference that cannot be aver-
by humans: if it is, then an experimenter should be able to        aged away. The word-learning experiments in (Xu & Tenen-
produce O(n2 + c) scaling in human response time by manip-         baum, 2007), for example, use just one word and 45 pictures
ulating the similarity of elements (and thereby the number of      of objects. How shall we judge that the effects observed are
kernel matches), where c is an “overhead” constant for the         likely to apply to the full human scale of thousands of words
portion of the response time not due to an SME-like algo-          and millions or more perceived objects?
rithm.                                                                 The usual approach to ruling out the effects of interference
   We thus see that using complexity to relate even a purely       is to brainstorm all of the ways that other systems or processes
computational model, such as the Companion architecture, to        might interfere (“the confounds”) and run an exhaustive se-
cognitive plausibility can yield new insights, constraints on      ries of experiments to rule out each potential confound.
the system, and questions for further investigation.                   An alternate, complexity-based approach would be to de-
                                                                   sign a set of experiments that vary the amount of evidence
         Benefits of considering complexity                        provided to the subjects to determine whether their perfor-
Complexity analysis of cognitive models is also likely             mance scales in the manner predicted by the model. In (Xu
to improve the scalability, robustness, composability, and         & Tenenbaum, 2007), they begin down this path, by training
longevity of these models. In computer science, complex-           subjects with either one example or three examples, but this
ity analysis of algorithms helps to mitigate pragmatic diffi-      says nothing about scaling toward the full problem of many
culties in these areas caused by the nature of the field. We       objects and many words. An experiment with variable num-
argue that analogous pragmatic difficulties exist in cognitive     bers of words being learned, however, and showing that the
science, and that complexity analysis of models may have a         judgements scale with the number of words as predicted by
similarly beneficial effect.                                       the Bayesian model, and that that complexity is reasonable
                                                                   for the full scale problem, would be much more compelling.
Scaling In computer science, large-scale algorithms can of-
                                                                   Composability of Models An algorithm may be reused in
ten be tested experimentally only at small scale—consider,
                                                                   many different contexts, on many different sorts of problems.
for example, peer-to-peer file sharing, internet routing, and
                                                                   Complexity analysis shows how behavior in a known context
database mining. Complexity analysis shows how small scale
                                                                   or with a known problem predicts the behavior for novel con-
behavior can be expected to predict large scale behavior.
                                                                   texts and problems.
   Pragmatic constraints often similarly limit the experiments
                                                                       Cognitive models face similar challenges because there are
that can be performed with computational cognitive science
                                                                   no current whole-mind models that constrain the design of
models. For example, in the word-learning experiments in
                                                                   smaller models. This means that the context in which a frag-
(Xu & Tenenbaum, 2007), subjects learn a category from
                                                                   mentary model may operate is unknown, and the scale of the
images of 21 objects. In a lifetime, however, a human en-
                                                                   model might vary significantly based on this context. Con-
counters orders of magnitude more objects and many differ-
                                                                   sider our two example systems, word learning and analogical
ent categories. In (K. D. Forbus & Hinrichs, 2006), the ana-
                                                                   reasoning. In word learning, for example: how many words
logical reasoner is being applied to three domains, at least
                                                                   must be learned? How many examples are provided, and how
one of which contains cases with 103 propositions. In daily
                                                                   much clutter distorts each example? The answers to these
life, however, a human encounters many more domains to
                                                                   questions may vary by several orders of magnitude depend-
think about, and depending on how a domain is formulated,
                                                                   ing on how a “word” is represented (e.g. what counts as a
the number of propositions in a case might be much greater.
                                                                   word sense? must the word be used or simply recognized?)
With knowledge of how the models scale, it is possible to
                                                                   and how the examples are structured (e.g. a constant stream
argue that these experimental results imply something more
                                                                   or occasional episodes? filtered or unfiltered? high-level or
general about word learning or analogical reasoning; with-
                                                                   low-level?). Analogical reasoning is just as uncertain: how
out such knowledge, they only provide information about the
                                                                   many cases are there in a person’s memory? How complex
small scale that has been tested.
                                                                   are they? How often do they need to be retrieved? How fre-
                                                                   quently are analogies made?
Robustness Computers are complex systems where unpre-                  Without complexity analysis, we do not know what will
dictable interactions between components may interfere with        happen to these models when the scale is changed. Unless
experimental measurements. Complexity analysis dampens             a broad model is built on top of a fragmentary model, the
the impact of such interference by measuring the scaling of        fragmentary model probably will not be used within the same
behavior instead of its absolute value.                            context or general constraints that it was originally tested
                                                               103

with. Knowledge of how a model scales, however, allows                                       Contributions
us to predict how it will behave in a new context.                   We have argued that computational cognitive scientists
                                                                     should explicitly analyze the computational complexity of
Longevity of Models Computer systems are highly vari-                their models. To demonstrate this, we have shown how analy-
able in structure and rapidly changing. Complexity analysis          sis of computational complexity can be applied to strengthen
allows results about an algorithm to be portable from sys-           Tenenbaum’s work on Bayesian learning and Forbus’ work
tem to system—even across fundamentally different models             on analogical reasoning.
of computation (e.g. stack machine vs. register machine vs.             We expect that treating computational complexity as a pri-
stream processor), and predicts how hardware changes will            mary issue, with the same importance as significance anal-
affect the feasibility of an algorithm.                              ysis in experimental work, will greatly enhance the ability
   Likewise, experimental evidence is rapidly changing our           of cognitive scientists to communicate and to compare work
models of what sort of computations can be supported by the          across paradigms, and we strongly encourage the community
human brain. When a computational model is tied closely to a         to adopt it as a standard of evaluation for computational re-
particular model of neural computation, it becomes embroiled         search.
in the controversies of neuroscience and is often quickly ren-
dered obsolete. When a model is disconnected entirely from                                Acknowledgements
the notion of biological implementation—as is the case in            The authors thank Ken Forbus for his help and patience
both (Xu & Tenenbaum, 2007) and (K. D. Forbus & Hinrichs,            in sorting out details about analogical reasoning, and Josh
2006)—then it must be constantly defended against charges            Tenenbaum for his feedback. J.M.R thanks the Fannie and
that it may not be realizable in a human brain or may not ac-        John Hertz foundation and both authors thank the National
tually explain what people are doing.                                Science Foundation for their financial support.
   Complexity analysis against an abstract biological hard-
ware model (such as the one presented in (Beal, 2007)), how-                                   References
ever, shows the realizability of a system without tying it to        Beal, J. (2007). Developmental cost for models of intelli-
any particular model of neural computation. Instead, any                gence. In Aaai 2007 workshop on evaluating architectures
model of neural computation, even one not yet dreamed of                for intelligence. AAAI.
when the cognitive model was created, simply adjusts the             Cassimatis, N. (2002). Polyscheme: A cognitive architec-
constant multipliers of the asymptotic complexity.                      ture for integrating multiple representation and inference
                                                                        schemes. Unpublished doctoral dissertation, MIT.
        Pragmatics of discussing complexity                          Falkenhainer, B., Forbus, K. D., & Gentner, D. (1989). The
A presentation of any model in computational cognitive sci-             structure-mapping engine: Algorithm and examples. Arti-
ence thus needs to address the following four questions:                ficial Intelligence, 41(1), 1–63.
                                                                     Forbus, K., Ferguson, R., & Gentner, D. (1994). Incremental
• What resource limitations are pertinent to this model?
                                                                        structure-mapping. In Sixteenth annual conference of the
• What is the order of growth for the model and its operations          cognitive science society.
   with respect to these resources?                                  Forbus, K., Gentner, D., & Law, K. (1995). Mac/fac: A
                                                                        model of similarity-based retrieval. Cognitive Science,
• What is the scale of the model?                                       19(2), 141–205.
• How does the model compare against the current estimated           Forbus, K., Usher, J., & Tomai, E. (2005). Analogical learn-
   resource limits of biological intelligence?                          ing of visual/conceptual relationships in sketches. In Aaai-
                                                                        05.
   This does not mean that publication must wait on precise          Forbus, K. D. (2009). personal communication.
understanding of complicated models. A complexity upper              Forbus, K. D., & Hinrichs, T. R. (2006). Companion cogni-
bound need not be tight, and it is perfectly acceptable to over-        tive systems: A step toward human-level ai. AI Magazine,
estimate the resource consumption of a model—even by a                  27(2).
vast amount! The bounds can always be tightened later.               Kuehne, S., Forbus, K., & Gentner, D. (2000). Seql: Cat-
   The breadth of cognitive science makes it particularly im-           egory learning as incremental abstraction using structure
portant for computational cognitive science papers to answer            mapping. In Cognitive science conference. Cognitive Sci-
all of these questions explicitly and clearly. Many cognitive           ence Society.
scientists are not skilled in computational complexity analy-        Shepherd, G. (2004). The synaptic organization of the brain.
sis, and thus avoiding a clear statement of a model’s compu-            Oxford University Press.
tational complexity and its implications is likely to acciden-       Williams, R. W., & Herrup, K. (1988). The control of neuron
tally mislead one’s colleagues by “sweeping under the rug”              number. Annual Review of Neuroscience, 11, 423–453.
the computational difficulties of the model. Omitting com-           Xu, F., & Tenenbaum, J. (2007). Word learning as bayesian
plexity analysis stifles research by making it seem as though           inference. Psychological Review, 114(2).
open problems have already been solved.
                                                                 104

