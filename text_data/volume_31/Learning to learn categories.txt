UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning to learn categories
Permalink
https://escholarship.org/uc/item/94c48453
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Perfors, Amy
Tenenbaum, Joshua
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                                Learning to learn categories
                                         Amy F. Perfors (amy.perfors@adelaide.edu.au)
                                              School of Psychology, University of Adelaide
                                                       Adelaide, SA 5005 Australia
                                                Joshua B. Tenenbaum (jbt@mit.edu)
                            Department of Brain & Cognitive Science, Massachusetts Institute of Technology
                                                       Cambridge, MA 02139 USA
                              Abstract                                 cantly both between and within categories. This more ab-
                                                                       stract knowledge, or overhypothesis1, supports second-order
   Learning to categorize objects in the world is more than just
   learning the specific facts that characterize individual cate-      generalizations about categories one has never seen: upon
   gories. We can also learn more abstract knowledge about how         seeing a new animal with six legs and a tail, it is reasonable
   categories in a domain tend to be organized – extending even        to conclude that other examples of that animal will also have
   to categories that we’ve never seen examples of. These ab-
   stractions allow us to learn and generalize examples of new         six legs and no tail, but not necessarily the same superficial
   categories much more quickly than if we had to start from           markings. This higher-order overhypothesis is what allows
   scratch with each category encountered. We present a model          the learner to form a reasonable prototype of an entirely new
   for “learning to learn” to categorize in this way, and demon-
   strate that it predicts human behavior in a novel experimental      kind of animal from only one instance, as well as how to gen-
   task. Both human and model performance suggest that higher-         eralize to new instances.
   order and lower-order generalizations can be equally as easy to
   acquire. In addition, although both people and the model show          Children as young as 24 months are able to form ab-
   impaired generalization when categories have to be inferred         stract inferences about how categories are organized, realiz-
   compared to when they don’t, human performance is more              ing that categories corresponding to count nouns tend to have
   strongly affected. We discuss the implications of these find-
   ings. Keywords: overhypotheses; word learning; Bayesian             a common shape, but not a common texture or color (Lan-
   modelling; shape bias                                               dau, Smith, & Jones, 1988; Soja, Carey, & Spelke, 1991),
                                                                       whereas categories corresponding to foods often have a com-
                           Introduction                                mon color but not shape (e.g., Macario, 1991; Booth & Wax-
Learning is often thought of as acquiring knowledge, as if             man, 2002). The advantages of acquiring this overhypothesis,
it simply consists of gathering facts like pebbles scattered           or “shape bias”, is clear: teaching children a few novel cat-
on the ground. Very often, however, effective learning also            egories strongly organized by shape results in early acquisi-
requires learning how to learn: forming abstract inferences            tion of the shape bias as well as faster learning even of other,
about how those pebbles are scattered – how that knowledge             non-taught words (Smith, Jones, Landau, Gershkoff-Stowe,
is organized – and using those inferences to guide one’s fu-           & Samuelson, 2002). This is a noteworthy result because it
ture behavior. Indeed, most learning operates on many lev-             demonstrates that overhypotheses can rapidly be acquired on
els at once. We do gather facts about specific objects and             the basis of little input, but it raises questions about what en-
actions, and we also learn about categories of objects and             ables such rapid acquisition. The work in this paper is mo-
actions. But an even more powerful form of human learn-                tivated by these questions about how knowledge is acquired
ing, evident throughout development, extends to even higher            on higher levels of abstraction, and how that kind of learning
levels of abstraction: learning about kinds of categories and          interacts with lower-level learning about specific items.
making inferences about what categories are like in general.              In a broader sense, acquiring knowledge on a higher, more
This knowledge enables us to learn entirely new categories             abstract level – learning to learn – is important in many con-
quickly and effectively, because it guides the generalizations         texts besides categorization. In the causal domain, people
we can make about even small amounts of input.                         must draw general conclusions about different novel causal
   Consider, for instance, a learner acquiring knowledge               types and their characteristic interactions as well as the causal
about different kinds of animals. He might realize that CATS           roles fulfilled by specific objects (Kemp, Goodman, & Tenen-
have four legs and a tail, SPIDERS have eight legs and no tail,        baum, 2007). Children learning language must simultane-
MONKEYS have two legs and a tail, FISH have no legs and                ously acquire knowledge about specific verbs and which ar-
a tail, and so on. The knowledge supports what we call a               guments they take, as well as higher-order knowledge about
first-order generalization: given a new animal that has eight          entire classes of verbs, some of which may take a certain
legs and no tail, it is more likely to be some kind of spider          kind of argument (e.g., a direct object) and others of which
rather than a cat or a monkey. However, the learner may                cannot. It is this higher-order knowledge that enables people
also have realized something more abstract: that while the             to make intelligent second-order generalizations about verbs
number of legs or the presence of a tail varies a lot between          they have never seen before (Pinker, 1989).
categories, these features tend to be homogenous within cat-
egories. By contrast, surface colorings might vary signifi-                1 This terminology is borrowed from Goodman (1955).
                                                                   136

   For computational theories of learning, the ability to learn
on multiple levels at once poses something of a chicken-and-
egg problem: the learner cannot acquire overhypotheses with-
out having attained some specific item-level knowledge first,
but acquiring specific item-level knowledge would be greatly
facilitated by already having a correct overhypothesis about
how that knowledge might be structured. Often it is simply
presumed that acquiring knowledge on the higher (overhy-
pothesis) level must always follow the acquisition of more
specific knowledge.
   Recently, a computational framework called hierarchical
Bayesian modelling has emerged which can help to explain
how learning on multiple levels might be possible. This
framework has been applied to domains as disparate as causal         Figure 1: Our hierarchical Bayesian model. Each setting of (α, β)
reasoning (Kemp, Goodman, & Tenenbaum, 2007), the ac-                is an overhypothesis: β represents the distribution of features across
                                                                     items within categories, and α represents the variability/uniformity
quisition of abstract syntactic principles (Perfors, Tenen-
                                                                     of features within categories (i.e., the degree to which each category
baum, & Regier, 2006), and learning about feature variability        tends to be coherently organized with respect to a given feature, or
(Kemp, Perfors, & Tenenbaum, 2007). In the hierarchical              not). The model is given data consisting of the features yi corre-
Bayesian framework, inferences about data are made on mul-           sponding to individual items i, depicted here as a sequence of digits
tiple levels: the lower level, corresponding to specific item-       (although representing features as digits implies that order matters;
                                                                     this is not the case for the actual data). Learning categories corre-
based information, and the overhypothesis level, correspond-         sponds to identifying the correct assignment z of items to categories.
ing to abstract inferences about the lower-level knowledge.
   In this paper we present a model of category learning which                                         Model
acquires knowledge about how specific items should be cat-
                                                                     Computational details
egorized as well as higher-order overhypotheses about how
categories in general are organized. It is an extension of           Our hierarchical Bayesian model supports the acquisition of
an earlier model by Kemp, Perfors, and Tenenbaum (2007),             two kinds of knowledge: the ability to put uncatgorized items
which was capable of making inferences at the overhypothe-           into sensible categories on the basis of their featural similar-
sis level but required specific items to be grouped into basic-      ity, and the ability to acquire more abstract knowledge about
level categories as part of the input. Our new model can dis-        the formation of categories in general. An example of the for-
cover how to cluster items at the category level on the basis        mer would be the realization that two entities that share many
of their featural similarity, at the same time that it makes in-     features (e.g., eat bananas, have two legs, have long tails) are
ferences about higher-level parameters (or overhypotheses)           examples of the same category (say, MONKEYS); an example
indicating which features are most important for organizing          of the latter would be the realization that categories in gen-
items into basic-level categories. We show that both first-          eral tend to be coherent with respect to some features (like
and second-order generalizations can emerge in tandem, even          number of legs) and not others. The former ability is realized
when category information is not given; it is not necessary for      in our model by performing Bayesian inference over possible
the lower-level knowledge to be acquired first. We compare           category assignments; the latter by performing inference over
model predictions with human performance on a novel cate-            the hyperparameters governing the overhypotheses.
gorization task with second-order generalization, and demon-            We depict this type of learning graphically in Figure 1 and
strate that human learners follow the same pattern.                  formalize it more precisely as follows. Each item i is associ-
                                                                     ated with a vector of feature counts yi , which are drawn from
   Our model is also capable of performing both supervised
                                                                     category j = zi . Giving the model category information con-
and unsupervised category learning, which enables us to ad-
                                                                     sists of presenting the model with a partition of items into
dress the question of how useful category labels are to an ideal
                                                                     possible categories, represented by a vector z; if the model is
learner that can form generalizations on multiple levels. This
                                                                     not given category information, it tries to find the best possi-
is a topic of some debate in the infant word learning literature
                                                                     ble z.2 The prior distribution on z is induced by the Chinese
(Xu, 2002; Smith, Jones, Yoshida, & Colunga, 2003). We
                                                                     Restaurant Process, which can be defined recursively by ex-
demonstrate that both human and ideal learners benefit from
                                                                     tending a partition over items 1 through k − 1 to a new item
receiving category information, but human learners benefit
                                                                     k:
more; this may suggest that humans differ from the ideal in                                            (
their ability to infer the correct category assignments when no                                             nj
                                                                                                          k−1+γ            nj > 0
category information is given. Both types of learners make              P(zk = c|z1 , . . . , zk−1 ) =       γ
                                                                                                          k−1+γ     k is a new category
stronger generalizations on the basis of highly coherent cat-
egories. We discuss the implications and limitations of these            2 Throughout the paper boldfaced z and y refer to the entire
findings.                                                            dataset – the full set of yi and zi for every item i.
                                                                 137

      Here n j is the number of items previously assigned to cat-             When z is not given, the process of inference alternates be-
  egory j and γ is a hyperparameter which captures the degree                 tween fixing the category assignments z and sampling the
  to which the process favors simpler category assignments (we                space of hyperparameters α, β, λ, and µ, vs. fixing the hyper-
  set γ = 1, consistent with previous work with this model). The              parameters and sampling from category assignments. Learn-
  Chinese Restaurant Process prefers to assign items to cate-                 ing in an HBM thus corresponds to making inferences about
  gories that already have many members, and therefore tends                  category assignments z, as well as the parameters and hy-
  to prefer partitions with fewer categories.                                 perparameters, based on the input data. First- and second-
      At the same time that the model is attempting to identify               order generalization are calculated by computing p(zk = zi |y),
  the best category assignments, it is also performing inference              which is the likelihood of a new item k being in the same cat-
  about the nature of those categories and the overhypotheses                 egory as some item i, given their observed feature vectors
  that govern them. Level 1 knowledge about the features and                  yk , yi , and all the other observed data in y. This can be calcu-
  items associated with a specific category j is represented by               lated5 by integrating over all of the hyperparameters and all
  θ j , which can be understood as the parameters of multinomi-               possible category assignments z:
  als that govern how the features yi of items i in that category                                  Z
  are distributed. This knowledge is acquired with respect to a                 P(zk = zi |y) =             ∑ P(α, β, λ, µ, z|y)δzk =zi dαdβdλdµ
                                                                                                     α,β,λ,µ z
  more abstract both of knowledge, Level 2 knowledge, which
  in this case is knowledge about the distribution of features                   The difference between first and second order generaliza-
  across categories in general. It is represented in our model by             tion is whether item i is already represented in the training set
  two parameters, α and β: roughly speaking, α captures the                   y, or is a new item altogether. All results represent averages
  extent to which each individual category is organized by a                  across 4 runs of the model.
  given feature (or not), and β captures the average distribution
  of features across all categories in the world.3                            Datasets
      Level 2 knowledge depends on knowledge at a higher level,               As the category-learning experiments of Smith et al. (2002)
  Level 3, which is represented in our model by two hyper-                    demonstrated, it is possible for children to acquire an overhy-
  parameters λ and µ. They capture prior knowledge about α                    pothesis about the role of shape in categorization after being
  and β, respectively: the range of values expected about the                 taught only a few novel nouns; however, it is not clear pre-
  uniformity of features within a category(λ), and the range of               cisely what aspects of the input enabled such rapid acquisi-
  values of the expected distribution of features in the world (µ).           tion. Was it the fact that the categories were organized on the
  Our model learns λ and µ in addition to α and β, and assumes                basis of highly coherent features, or because the individual
  that knowledge at the next highest level is given.4 Inferences              items were consistently labelled, effectively providing strong
  about λ, µ, α, and β – in conjunction with inferences about the             evidence about category assignments? Was it because a cer-
  category assignments z – can be made by drawing a sample                    tain number of items or categories is required to effectively
  from P(α, β, λ, µ, z|y), which is given by:                                 form overhypotheses, and the children were at the precise
                                                                              critical point in development? Or perhaps people are biased
  P(α, β, λ, µ, z|y) ∝ P(y|α, β, z)P(α|λ)P(β|µ)P(λ)P(µ)P(z)                   to form overhypotheses about salient features, such as shape,
                                                                              implying that it would be more difficult to acquire overhy-
      Inferences about the category-specific distributions θ j are            potheses about less salient features.
  computed by integrating out α, β, λ, µ, and z:                                 To address these questions we design datasets that vary sys-
             Z                                                                tematically in terms of (a) coherence of category features;
P(θ j |y) =          ∑ P(θ j |α, β, λ, µ, z)P(α, β, λ, µ, z|y)dαdβdλdµ
              α,β,λ,µ z
                                                                              (b) the number of items and categories to be learned; and
                                                                              (c) whether category information is given (the SUPERVISED
                                                                              condition) or must be inferred (the UNSUPERVISED condi-
      Inference is performed by performing a standard numeri-                 tion). How do these factors affect first-order and second-order
  cal stochastic integration technique known as Markov Chain                  generalization? Our goal is to obtain predictions from our
  Monte Carlo (Gilks, Richardson, & Spiegelhalter, 1996).                     model about what an ideal Bayesian learner would do when
       3 One way of thinking about the relationship between θ, α, and         presented with this sort of input, and then to present human
  β is that α captures how close, on average, each individual θ is to β       learners with datasets with precisely the same characteristics.
  (i.e., how close each individual category’s feature distribution is to         In all datasets, items are associated with eight indepen-
  the overall distribution across all categories). Low α would indicate       dent features, four of which have values that are randomly as-
  that each item in a category tends to share a certain feature value,
  but does not say anything about what value that might be: if a cat-         signed (these are denoted fR ), and four of which are coherent
  egory had low α for the shape feature, one would know that it was           with respect to category membership ( fC ). A coherence level
  organized by shape, but not know precisely what shape it was.               of c means that a feature value has a (100 − c)% chance of
       4 We also evaluated performance of a model that assumed that
  knowledge about λ and µ is given (λ = µ = 1, as in Kemp, Per-
                                                                              being random. By systematically varying the factors of inter-
  fors, and Tenenbaum (2007); results were qualitatively similar in all       est, we obtain datasets that correspond to a particular factorial
  cases, but learning at Level 3 as well as Level 2 resulted in a quanti-
  tatively better match to human data.                                            5δ   is the Kronecker delta function, equal to 1 if zk = zi , 0 if not.
                                                                          138

                                                                           tween first-order and second-order generalization in either
                                                                           condition (p > 0.05, n.s., two-tailed). This result may seem
                                                                           counterintuitive, but further reflection suggests that it is sen-
                                                                           sible: second-order generalization occurs on the basis of in-
                                                                           ferences about the overhypothesis, and these inferences ef-
                                                                           fectively have more data bearing on them (all datapoints, not
                                                                           just the specific ones).
                                                                              Generalization is better in the SUPERVISED condition than
                                                                           in the UNSUPERVISED condition (p = 0.0006, two-tailed), al-
                                                                           though the size of the effect is not large: though category in-
                                                                           formation helps somewhat, especially when the features are
                                                                           less coherent, the fairly high performance of the model in the
Figure 2: A schematic depiction of the nature of different datasets        UNSUPERVISED condition suggests that to the extent that the
presented to both humans and our model. Items are associated with          features of a category are coherent enough to support general-
four coherent features ( fC ) and four random ones ( fR ); here we de-
pict each feature as a digit, and its value as the digit value. (a) An
                                                                           ization, they also support categorization, and an ideal learner
example dataset in the SUPERVISED condition with 16 items four of          can take advantage of this. Since there will always be un-
whose fC features are 100% coherent (all items in the category share       certainty about which categories are most appropriate there is
the same feature value). (b) As an illustration, we show an example        some benefit to being given category information, but it is not
dataset whose four fC features are 75% coherent: for each feature          huge. The affect of coherence on generalization in the model
and item, there is 25% probability that its value will differ from the
value shared by most members in the category. (c) The same dataset         is significant7 , which is sensible: if categories are more inco-
as in (b), but in the UNSUPERVISED condition. Here the model must          herent, less generalization is appropriate.
learn both the proper categorization as well as the higher-order in-          To what extent do humans look like our learner? Do people
ference about which features are coherent. (d) A sample first-order        also find first-order and second-order generalization equiv-
generalization task: given an item seen already, which of the test
                                                                           alently easy? Is category information useful? Do they too
items are in the same category, the one sharing features fC or the
one sharing features fR ? (e) Second-order generalization, which is        show differential performance based on how coherent the cat-
the same except that the model is presented with entirely new items        egories are? We address these questions in the next section.
and feature values.
                                                                                                     Experiment
experimental design: 2 (SUPERVISED or UNSUPERVISED) x
                                                                           Our experiment is designed to present participants with the
3 (coherence level of 60%, 80%, or 100%) x 2 (containing
                                                                           exact task and dataset presented to our model, in order to most
8 or 16 items total) x 3 (categories made of 2, 4, or 8 items),
                                                                           closely compare performance between the two.
slightly complicated by the constraint that each category must
                                                                              Items. Because the model was presented with items that
have at least two items. As a result of this constraint, the last
                                                                           each had eight independently-generated features, four ran-
two factors, when crossed, lead to 5 possible category struc-
                                                                           dom ( fR ) and four more coherent ( fC ), we designed items
tures at each coherence level, once in the SUPERVISED and
                                                                           with the same characteristics for the experiment. They con-
once in the UNSUPERVISED condition.
                                                                           sisted of a square with four characters (one in each quadrant)
   We assess model performance by examining first-order and
                                                                           surrounded by circles at the corner, each containing a charac-
second-order generalization. First-order generalization cor-
                                                                           ter of its own. The characters corresponded to the features of
responds to presenting the model with an item that occurs
                                                                           the items in the model datasets, and were designed to ensure
in the dataset and querying whether it is more likely to be
                                                                           that they were salient and discrete, as in the model. Which of
in the same category as an item that shares coherent fea-
                                                                           the four features varied coherently changed from trial to trial
tures fC (a “correct” generalization) or random features fR ?
                                                                           and participant to participant, to eliminate order or saliency
Second-order generalization is identical, except the model is
                                                                           effects of any particular feature or feature combination.
presented with an item and features that have not occurred
before. Figure 2 contains further details.                                    Trial structure. Each trial had several phases. In the
                                                                           first phase, participants were shown a set of novel objects
Results                                                                    on a computer screen and either asked to sort them by mov-
Figure 3 shows the model’s probability of correct generaliza-              ing them around the screen with a mouse and drawing boxes
tion as a function of three factors – whether categories were              around the ones they thought would be in the same category
given for the training data or had to be inferred (SUPERVISED              (in the UNSUPERVISED trials) or were shown the objects al-
versus UNSUPERVISED), whether the generalization was first-                ready sorted with boxes drawn around them (in the SUPER -
order or second-order, and the coherence level of the train-               VISED trials.
ing dataset – averaged across all trials with the same levels                 After the first phase, each participant was asked two gen-
of these factors.6 Interestingly, there is no difference be-               eralization questions, presented in random order. In the first-
    6 We also examined effects of the number of categories and num-        be deferred to a longer report.
ber of items per category, but for space reasons these analyses will           7 One-way ANOVA, p < 0.0001, F = 7.19.
                                                                       139

Figure 3: (a) Model generalization averaged across all datasets based     Figure 4: (a) Subject performance on categorization task by con-
on the nature of the category information given. There is no sig-         dition. Like the model, participants performed equally well for
nificant difference between first- and second-order generalization.       both first- and second-order generalization (SUPERVISED condition,
Although category information aids in generalization, the effect is       p = 0.1176, n.s.; UNSUPERVISED condition, p = 0.7551, n.s., both
small. (b) Coherence affects generalization, especially in the UNSU -     two-tailed). However, they did worse without category information
PERVISED condition.                                                       than with it (p = 0.0001, one-tailed). (b) Subject generalization,
                                                                          like in the model, was affected by coherence (one-way repeated
order generalization questions, they were shown an item cor-              measures (within-subject) ANOVA: UNSUPERVISED condition, p =
                                                                          0.0081, F = 5.16; SUPERVISED condition, p = 0.0446, F = 3.25).
responding to one of the items they had already seen, and
asked which of two other novel items were most likely to                  rectness of category assignments using the adjusted rand in-
belong in the same category as that one. The second-order                 dex adjR (Hubert & Arabie, 1985), a measure of similarity
generalization questions were identical except that the partic-           between two clusterings (in this case, the correct categories
ipants were presented with items and feature values they had              vs. the category assignments made by the participants). Most
not seen before. All of the sorted items were visible to par-             trials (67%) in the UNSUPERVISED condition had high adjR
ticipants throughout the task. To maintain interest in the task,          values (over 0.5), indicating substantial agreement between
after completing both questions participants were told how                the correct categories and the category assignments made;
many of the two they got correct, but not which ones.                     a full 92% were better than chance. Figure 5(a) suggests
   Procedure. Each participant was shown 30 trials, half SU -             that people’s relatively poorer performance in the UNSUPER -
PERVISED and half UNSUPERVISED , in random order. The                     VISED condition is carried by the minority of situations in
factorial design of the experiment corresponded precisely to              which they were unable to find the correct categories, since
the design of the datasets presented to the model.                        when they found the correct ones their generalization perfor-
   Participants. 18 subjects were recruited from a paid par-              mance was quite high. As Figure 5(b) shows, the effect of
ticipant pool largely consisting of undergraduate psychology              coherence disappears when considering only those trials in
students and their acquaintances. The experiment took 1 hour              which people found the correct categories; they look more
to complete and participants were paid $12 for their time.                like the model in the SUPERVISED condition.
Results                                                                                              Discussion
Figure 4(a) demonstrates that, as predicted by the model,                 One interesting finding of our work is that both the model and
first-order and second-order generalization do not signifi-               our participants show that first-order and second-order learn-
cantly differ for human learners. This may be somewhat con-               ing – learning to learn – can occur at the same time as each
trary to intuition, but the fact that this is evident for both hu-        other; it need not be harder to perform second-order general-
man learners as well as the model lends further support to the            ization than it is to perform first-order generalizations. Our
notion that higher-order generalization need not be more dif-             model predicted this result, and we confirmed it empirically
ficult than lower-order. Learning to learn is not only useful,            in human performance as well. The fact that higher-order
but apparently not too difficult either.                                  generalization may at times be easier (or at least equivalently
   Figure 4(b) shows that people’s generalizations depend on              easy) to lower-order generalization has interesting implica-
coherence, although this result is far noisier than shown by              tions for questions of innateness: although we generally infer
the model. We also see that humans, like the model, were                  that higher-order generalizations must be innate if they are
aided by being given category information; however, people’s              observed early in development, this result implies that such
generalizations deteriorated substantially more in the UNSU -             an inference may not always be valid.
PERVISED condition. Why do humans have poorer general-                       Another interesting aspect of this work is the comparison
ization when the categories were not given? One possibility               of model and human performance when given category infor-
is that they simply fail to identify the correct categories, and          mation and when not. For both humans and the model, gen-
in these cases generalize incorrectly. Another possibility is             eralization worsened when not given the category informa-
that they succeed in identifying the correct categories most of           tion, but human performance worsened substantially more.
the time, but are less confident in those categories or less able         This is probably because people had a harder time identifying
to make generalizations on the basis of them.                             the correct categories than the model, perhaps due to capac-
   To decide between these hypotheses, we evaluate the cor-               ity limitations. It may be possible to model such limitation
                                                                      140

                                                                            categories (Love, Medin, & Gureckis, 2004). Although SUS-
                                                                            TAIN and other unsupervised category learning models have
                                                                            not (to our knowledge) been applied to problems of “learning
                                                                            to learn”, they could be. Our framework would still offer dis-
                                                                            tinctive insights stemming from its rational basis and the few
                                                                            free parameters.
                                                                                In the real world, unlike in our experiments or our mod-
                                                                            els, knowledge about which features matter for categorizing
Figure 5: (a) Subject performance on categorization task based on           is usually restricted to just a certain domain of categories.
categorization success. The HIGHEST group succeeded in finding              For instance, children’s strong shape bias applies only to cat-
the correct categories (had adjR scores above 0.5); the MIDDLE              egories of solid artifacts, not to living kinds or non-solid
group had adjR scores above chance, but not substantially; and the          substances. An extension of our model can simultaneously
LOWEST group were below chance performance in sorting items into
                                                                            discover categories and multiple overhypotheses, as well as
categories. Participants who succeeded in finding the correct cate-
gories had high generalization performance, indicating that people’s        which overhypotheses are applicable to which subsets of cat-
relatively poorer performance in the UNSUPERVISED condition was             egories. It incorporates a higher-level nonparametric clus-
probably due to a difficulty in identifying the correct categories. (b)     tering of categories into ‘ontological types’ (Kemp, Perfors,
Among trials in which the correct categories were found (i.e., the          & Tenenbaum, 2007), in addition to clustering objects into
HIGHEST adjR group), overall generalization (collapsed across first-
                                                                            categories; overhypotheses about categories are shared only
and second-order) was uniformly high, regardless of coherence.
                                                                            within these ontological types. Testing the predictions of this
through the use of particle filters, a limited MCMC process,                extended model is an important avenue for future work.
or memory constraints captured by dropping data. In future                      This paper presents a computational framework capturing
work we aim to explore this in more detail.                                 “learning to learn” in categorization and shows that it predicts
   Although hierarchical Bayesian models have been applied                  human performance. The ability to learn on multiple levels at
in many other domains, the essential insight – that learning                once is a fundamental aspect of human cognition, and our
proceeds on multiple levels of inference at once – is rarely                results serve as a step toward understanding that ability.
explicitly incorporated into models of category learning. Our
model can be seen as a version of the hierarchical Dirich-
                                                                                                         Acknowledgments
let Process framework introduced by Griffiths, Canini, San-                 We thank Dan Navarro, Charles Kemp, and Fei Xu for use-
born, and Navarro (2007), but with one crucial difference.                  ful discussions, and Wai Yee Li for her help in running the
Our model infers the higher-level parameters describing over-               experiments. JBT was supported by AFOSR grant FA9550-
hypotheses directly from the data subjects observe, as part                 07-1-0075.
of modeling their learning process8 ; in contrast, Griffiths et
al. (2007) fit these parameters directly to subjects’ behavioral
                                                                                                                References
                                                                            Booth, A., & Waxman, S. (2002). Word learning is ’smart’: Evidence that conceptual
data, without modeling how subjects might infer them. It is                    information affects preschoolers’ extension of novel words. Cognition, 84, B11-B22.
                                                                            Gilks, W., Richardson, S., & Spiegelhalter, D. (1996). Markov chain Monte Carlo in
the inference of higher-level parameters that supports “learn-                 practice. Chapman & Hall.
ing to learn.” In this sense, our model is perhaps most similar             Goodman, N. (1955). Fact, fiction, and forecast. Cambridge, MA: Harvard Univ Press.
                                                                            Griffiths, T., Canini, K., Sanborn, A., & Navarro, D. (2007). Unifying rational models of
to the hierarchical model proposed by Navarro (2006). How-                     categorization via the hierarchical Dirichlet Process. Proceedings of the 29th Annual
                                                                               Conference of the Cognitive Science Society.
ever, like the original overhypothesis model of which this                  Hubert, L., & Arabie, P. (1985). Comparing partitions. Jn of Classification, 193–218.
                                                                            Kemp, C., Goodman, N., & Tenenbaum, J. (2007). Learning causal schemata. Proceed-
work is an extension, Navarro’s model does not learn to cate-                  ings of the 29th Annual Conference of the Cognitive Science Society.
gorize specific items in addition to performing more abstract               Kemp, C., Perfors, A., & Tenenbaum, J. B. (2007). Learning overhypotheses with
                                                                               hierarchical Bayesian models. Developmental Science, 10(3), 307–321.
inferences.                                                                 Kruschke, J. (2008). Models of categorization. In R. Sun (Ed.), The Cambridge Hand-
                                                                               book of Computational Psychology (pp. 267–301). New York: Cambridge University
   More abstractly, the notion that part of category learning                  Press.
consists of making inferences about which features “matter”                 Landau, B., Smith, L., & Jones, S. (1988). The importance of shape in early lexical
                                                                               learning. Cognitive Development, 3, 299–321.
is widespread, but is typically framed as the learning of at-               Love, B., Medin, D., & Gureckis, T. (2004). Sustain: A network model of category
                                                                               learning. Psychological Review, 111(2), 309–332.
tentional weights rather than as an inference about the ab-                 Macario, J. F. (1991). Young children’s use of color in classification: Foods as canoni-
                                                                               cally colored objects. Cognitive Development, 6, 17–46.
stract principles underlying categorization in a domain (see                Navarro, D. (2006). From natural kinds to complex categories. Proceedings of the 28th
Kruschke (2008) for an overview). Most models of catego-                       Annual Conference of the Cognitive Science Society.
                                                                            Perfors, A., Tenenbaum, J., & Regier, T. (2006). Poverty of the stimulus? A rational
rization with learned attentional weights adjust those weights                 approach. 28th Annual Conference of the Cognitive Science Society.
                                                                            Pinker, S. (1989). Learnability and cognition: The acquisition of argument structure.
through a process of supervised learning (Kruschke, 2008),                     Cambridge, MA: MIT Press.
and thus do not explain how people learn what features mat-                 Smith, L., Jones, S., Landau, B., Gershkoff-Stowe, L., & Samuelson, L. (2002). Object
                                                                               name learning provides on-the-job training for attention. Psychological Science,
ter in an unsupervised situation as in our experiment. An un-                  13(1), 13–19.
                                                                            Smith, L., Jones, S., Yoshida, H., & Colunga, E. (2003). Whose DAM account? Atten-
supervised version of SUSTAIN would perhaps be closest                         tional learning explains Booth and Waxman. Cognition, 87, 209–213.
                                                                            Soja, N., Carey, S., & Spelke, E. (1991). Ontological categories guide young children’s
to our models’ ability to simultaneously discover a system of                  inductions of word meaning. Cognition, 38, 179–211.
categories as well as the inductive biases that constrain those             Xu, F. (2002). The role of language in acquiring object kind concepts in infancy.
                                                                               Cognition, 85, 223–250.
    8 In HDP terms, it infers the parameters of the base distribution.
                                                                        141

