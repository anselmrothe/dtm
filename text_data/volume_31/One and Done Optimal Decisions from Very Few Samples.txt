UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
One and Done? Optimal Decisions from Very Few Samples
Permalink
https://escholarship.org/uc/item/1g18m250
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Goodman, Noah
Griffiths, Thomas
Tenenbaum, Joshua
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                    One and Done? Optimal Decisions From Very Few Samples
                      Edward Vul (evul@mit.edu)                                 Noah D. Goodman (ndg@mit.edu)
                 Brain and Cognitive Science, 43 Vassar St                     Brain and Cognitive Science, 43 Vassar St
                         Cambridge, MA 02139 USA                                      Cambridge, MA 02139 USA
         Thomas L. Griffiths (tom griffiths@berkeley.edu)                     Joshua B. Tenenbaum (jbt@mit.edu)
                      Dept. of Psychology, Tolman Hall                         Brain and Cognitive Science, 43 Vassar St
                          Berkeley, CA 94720 USA                                      Cambridge, MA 02139 USA
                             Abstract                                     learned rules to new test items. After exposure to several cat-
                                                                          egory exemplars people classify new test items consistently
   In many situations human behavior approximates that of a               with fully Bayesian inference, on average. This average be-
   Bayesian ideal observer, suggesting that, at some level, cog-
   nition can be described as Bayesian inference. However, a              havior suggests that people consider many possible classifica-
   number of findings have highlighted an intriguing mismatch             tion rules, update their beliefs about each one, and then clas-
   between human behavior and that predicted by Bayesian infer-           sify new items by averaging the classification over all the pos-
   ence: people often appear to make judgments based on a few
   samples from a probability distribution, rather than the full dis-     sible rules. However, this perfectly Bayesian behavior is only
   tribution. Although sample-based approximations are a com-             evident in the average across many observers. In contrast,
   mon implementation of Bayesian inference, the very limited             each individual classifies all test items in a manner consis-
   number of samples used by humans seems to be insufficient
   to approximate the required probability distributions. Here we         tent with only one or a few rules; which rules are considered
   consider this discrepancy in the broader framework of statis-          varies from observer to observer according to the appropri-
   tical decision theory, and ask: if people were making deci-            ate posterior probabilities (Goodman et al., 2008). Thus, it
   sions based on samples, but samples were costly, how many
   samples should people use? We find that under reasonable as-           seems that an individual observer acts based on just one or
   sumptions about how long it takes to produce a sample, locally         a few rules sampled from the posterior distribution, and the
   suboptimal decisions based on few samples are globally op-             fully Bayesian behavior only emerges when averaging many
   timal. These results reconcile a large body of work showing
   sampling, or probability-matching, behavior with the hypoth-           individuals, each with different sampled rules.
   esis that human cognition is well described as Bayesian in-               This sampling behavior is not limited to concept-learning
   ference, and suggest promising future directions for studies of
   resource-constrained cognition.                                        tasks. In many other high-level cognitive tasks, individuals’
                                                                          patterns of response – and sometimes even responses on indi-
   Keywords: Computational modeling; Bayesian models; Pro-
   cess models; Sampling                                                  vidual trials – appear to reflect just a small number of samples
                                                                          from the posterior predictive distribution. When predicting
   Across a wide range of tasks, people seem to act in a man-             how long a cake will bake given that it has been in the oven for
ner consistent with optimal Bayesian models (in perception:               45 minutes (Griffiths & Tenenbaum, 2006), the across-subject
Knill & Richards, 1996; motor action: Maloney, Trommer-                   variance of responses is consistent with individuals guessing
shauser, & Landy, 2007; language: Chater & Manning, 2006;                 based on only two prior observations of cake baking times
decision making: McKenzie, 1994; causal judgments: Grif-                  (Mozer, Pashler, & Homaei, 2008). When making estimates
fiths & Tenenbaum, 2005; and concept learning: Goodman,                   of esoteric quantities in the world, multiple guesses from one
Tenenbaum, Feldman, & Griffiths, 2008). However, despite                  individual have independent error, like samples from a proba-
this similarity between Bayesian ideal observers and human                bility distribution (Vul & Pashler, 2008). In all of these cases
observers, two crucial problems remain unaddressed across                 (and others; e.g., Xu & Tenenbaum, 2007; Anderson, 1991;
these domains. First, human behavior often appears to be                  Sanborn & Griffiths, 2008), people seem to sample instead of
optimal on average, but not within individual people or in-               computing the “fully Bayesian” answer.
dividual trials: What are people doing on individual trails                  Critics of the Bayesian approach (e.g., Mozer et al., 2008)
to produce optimal behavior in the long-run average? Sec-                 have suggested that although many samples may adequately
ond, Bayesian inference is straight-forward when considering              approximate Bayesian inference, behavior based on only a
small laboratory tasks, but intractable for large-scale prob-             few samples is fundamentally inconsistent with the hypoth-
lems like those that people face in the real world: How can               esis that human cognition is Bayesian. Others highlight the
people be carrying out generally intractable Bayesian calcu-              second problem and argue that cognition cannot be Bayesian
lations in real-world tasks? Here we will argue that both of              inference because exact Bayesian calculations are computa-
these problems can be resolved by considering the algorithms              tionally intractable (e.g., Gigerenzer, 2008).
that people may be using to approximate Bayesian inference.                  In this paper we will argue that acting based on a few sam-
   The first problem is highlighted by an intriguing observa-             ples can be easily reconciled with optimal Bayesian infer-
tion from Goodman et al. (2008) about performance in cat-                 ence and may be the method by which people approximate
egorization tasks in which people see positive and negative               otherwise intractable Bayesian calculations. We argue that
exemplars of a category and are then asked to generalize any              (a) sampling behavior can be understood in terms of sensible
                                                                      148

sampling-based approaches to approximating intractable in-              models and are more robust to increasing dimensionality than
ference problems in Bayesian statistics and AI; (b) very few            other approximate methods.
samples from the Bayesian posterior are often sufficient to                Many cognitively plausible sampling algorithms exist and
obtain approximate predictions that are almost as good as pre-          some specific ones have been proposed to account for aspects
dictions computed using the full posterior; and (c) on conser-          of human behavior (Griffiths, Canini, Sanborn, & Navarro,
vative assumptions about how much time it might cost to pro-            2007; Levy, Reali, & Griffiths, 2009; Brown & Steyvers,
duce a sample from the posterior, making predictions based              2008). For our purposes, we need only assume that a per-
on very few samples (even just one), can actually be the glob-          son has the ability to draw samples from the hypothesis space
ally optimal strategy.                                                  according to the posterior probability distribution. Thus, it is
                                                                        reasonable to suppose that people can approximate Bayesian
            Bayesian inference with samples                             inference via a sampling algorithm, and evidence that humans
Bayesian probability theory prescribes a normative method to            make decisions by sampling is not in conflict with the hypoth-
combine information and make inferences about the world.                esis that the computations they are carrying out are Bayesian.
However, the claim that human cognition can be described                   However, recent work suggests that people base their deci-
as Bayesian inference does not imply that people are doing              sions on very few samples (Vul & Pashler, 2008; Goodman
exact Bayesian inference.                                               et al., 2008; Mozer et al., 2008) – so few that any claims of
   Exact Bayesian inference amounts to fully enumerating                convergence to the real probability distribution do not hold.
hypothesis spaces every time beliefs are updated with new               Algorithms using only two samples (Mozer et al., 2008) will
data. In any large-scale application, this is computationally           have properties quite different from full Bayesian integration.
intractable, so inference must be approximate. This is the              This leaves us with the question: How bad are decisions based
case in “Bayesian” artificial intelligence and statistics, and          on few samples?
this must apply even more in human cognition, where the
real-world inferences are vastly more complex and responses
                                                                                  Bayesian and sample-based agents
are time-sensitive. The need for approximating Bayesian in-             To address the quality of decisions based on few samples,
ference leaves two important questions. For artificial intelli-         we will consider performance of optimal (fully Bayesian)
gence and statistics: What kinds of approximation methods               and sample-based agents in the common scenario of choos-
work best to approximate Bayesian inference? For cognitive              ing between two alternatives. Many experimental tasks in
science and psychology: What kinds of approximation meth-               psychology are a variant of this problem: given everything
ods does the human mind use?                                            learned, make a two-alternative forced-choice (2AFC) re-
   In the tradition of rational analysis, or Marr’s computa-            sponse. Moreover, real-world tasks often collapse onto such
tional approach (Marr, 1982), a reasonable strategy to an-              simple 2AFC decisions, for instance: we must decide whether
swering the psychological question begins with good answers             to drive to the airport via the bridge or the tunnel, depend-
to the engineering question. Thus, we will explore the hy-              ing on which route is likely to have least traffic. Although
pothesis that the human mind approximates Bayesian infer-               this decision will be informed by prior experiences that pro-
ence with some version of the algorithmic strategies that have          duced intricate cognitive representations of possible traffic
proven best in AI and statistics, on the grounds of computa-            flow, at one particular junction these complex representations
tional efficiency and accuracy.                                         collapse onto a prediction about a binary variable and deci-
   In artificial intelligence and statistics, one of the most com-      sion: Should we turn left or right?
mon methods for implementing Bayesian inference is with                    Statistical decision theory (Berger, 1985) prescribes how
sample-based approximations. Inference by sampling is a                 information and beliefs about the world and possible rewards
procedure to approximate a probability distribution by repeat-          should be combined to define a probability distribution over
edly simulating a simpler stochastic process which produces             possible payoffs for each available action (Maloney, 2002;
alternatives from a hypothesis space according to their proba-          Kording, 2007; Yuille & Bülthoff, 1996). An agent trying
bility under the distribution in question. The result of any one        to maximize payoffs over many decisions should use these
such simulation is a sample. With sufficiently many samples,            normative rules to determine the expected payoff of each ac-
these calculations based on these approximations approach               tion, and choose the action with the greatest expected payoff2 .
the exact calculations using the analytical probability distri-         Thus, the standard for decisions in statistical decision theory
butions themselves1 . Sampling methods are typically used               is to choose the action (A∗ ) that will maximize expected util-
because they are applicable to a large range of computational           ity under the posterior predictive distribution over possible
                                                                        world states (S) given prior data (D), assuming that action
    1 The Monte Carlo theorem states that the expectation over a        and state uniquely determine the utility obtained:
probability distribution can be approximated from samples:
                                                                                         A∗ = arg max ∑ U(A; S)P(S|D).                 (2)
                                                                                                    A    S
                                 k
                              1
             EP(S) [ f (S)] '   ∑ f (Si ), when Si ∼ P(S).      (1)         2 An agent might have other goals, e.g., maximizing the mini-
                              k i=1
                                                                        mum possible payoff (i.e., extreme risk aversion); however, we will
                                                                        not consider situations in which such goals are likely.
                                                                    149

   If the world state is sufficiently specified, 2AFC decisions        inference? Bernoulli estimated that more than 25,000 sam-
map onto a prediction about which of two actions (A1 and A2 )          ples are required for “moral certainty about the true proba-
will have higher expected utility – for instance: will we spend        bility of a two-alternative event3 (Stigler, 1986). Although
less time in traffic taking the bridge or the tunnel? There-           Bernoulli’s calculations were based on different derivations
fore, choosing among two alternatives amounts to predicting            than those which are now accepted (Stigler, 1986), it is un-
the outcome of a Bernoulli trial: will A1 or A2 have greater           deniable that inference based on a small number of samples
utility? Thus, P(A∗ = A1 ) ≡ p and P(A∗ = A2 ) ≡ (1 − p),              differs from the “fully Bayesian” solution and will contain
and we can simply parameterize these decisions in terms of             greater errors, but how bad are the decisions based on this
the posterior predictive probability p. For simplicity, we will        inference?
consider choosing the higher-utility action a “correct” choice,            In Figure 1 we plot the difference in error rates between
and choosing the lower-utility action an “incorrect” choice.           the sample-based and optimal agents as a function of the un-
The fully Bayesian agent will choose the more likely alterna-          derlying probability (p) and number of samples (k). When p
tive, and will be correct p proportion of the time (we assume          is near 0.5, there is no use in obtaining any samples (since a
p is between 0.5 and 1, given symmetry).                               perfectly informed decision will be as likely to be correct as
   A sample-based agent would sample possible world states,            a random guess). When p is 1 (or close), there is much to be
and make decisions based on those sampled world states (Sn ):          gained from a single sample since that one sample will indi-
                                     k                                 cate the (nearly-deterministically correct) answer; however,
                   A∗ = arg max ∑ U(A; Si )                            subsequent samples are of little use, since the first one will
                                A  i=1                         (3)     provide all the gain there is to be had. Most of the benefit of
                                  Si ∼ P(S|D),                         large numbers of samples occurs in interim probability values
                                                                       (around 0.7 and lower).
so in the case of making predictions between two alterna-
tives one of which may be correct, the sample-based agent
should choose the action corresponding to the most frequent
outcome in the set of sampled world states. Thus, a sample-
based agent drawing k samples will choose a particular out-
come with probability q:
                                       k
                    q = 1 − ΘCDF ( , p, k),                    (4)
                                       2
where ΘCDF is the binomial cumulative density function and
k/2 is rounded down to the nearest integer. This sample-
based agent will be right with probability qp + (1 − q)(1 − p).
                                                                       Figure 2: (a) The maximum and expected increase in error for the
                                                                       sample-based agent compared to the optimal agent as a function of
          Good decisions from few samples                              number of samples (see text). (b) Expected and maximum gain in
                                                                       accuracy from an additional sample as a function of the number of
                                                                       samples already obtained.
                                                                           Since the sample-based agent does not know what the true
                                                                       probability p may be for a particular decision we can consider
                                                                       the scenarios such an agent should expect: the average sce-
                                                                       nario (expectation over p) and the worst case scenario (maxi-
                                                                       mization of the loss over p). These are displayed in Figure 2a
                                                                       assuming a uniform probability distribution over p. The devi-
                                                                       ation from optimal performance decreases to negligible lev-
                                                                       els with very few samples, suggesting that the sample-based
                                                                       agent need not have more than a few samples to approximate
                                                                       ideal performance. We can go further to assess just how much
                                                                       is gained (in terms of decreased error rate) from an additional
                                                                       sample (Figure 2b). Again, the vast majority of accuracy is
                                                                       gained with the first sample, and subsequent samples do very
Figure 1: Increased error rate for the sample-based agent over the
optimal agent as a function of the Bernoulli trial probability and     little to improve performance.
the number of samples drawn for a decision (decisions based on 0           Thus, even though few samples will not provide a very ac-
samples not shown).                                                    curate estimate of p – definitely not sufficient to have “moral
   So, how much worse will such 2AFC decisions be if they                   3 Bernoulli considered moral certainty to be at least 1000:1 odds
                                                                                                          1
are based on a few samples rather than the “fully Bayesian”            that the true ratio will be within 50 of the measured ratio.
                                                                   150

Figure 3: Expected utility per decision, the number of decisions that can be made per unit time, and the expected rate of return (utility per
unit time) as a function of the Bernoulli probability and the number of samples (with an example action/sample cost ratio of 232).
certainty” – they are sufficient to choose an action: We do not           ministic prediction task), substantially less reward should be
need moral certainty to act optimally.                                    expected. Thus, if obtaining a sample takes as long as the
                                                                          action, and we do not get punished for an incorrect answer,
          How many samples for a decision?                                we should draw zero samples per decision and make as many
Lets take seriously the hypothesis that people make infer-                random decisions as we can. More generally, we can param-
ences based on samples. If this is the case, how many sam-                eterize how much a sample “costs” as the ratio between the
ples should people use before making a decision? For in-                  time required to make an action and the time required to ob-
stance, how many possible arrangements of traffic across the              tain one sample (action/sample ratio) – intuitively, a measure
city should we consider before deciding whether to turn left              of how many samples it would take to double the time spent
for the tunnel or right for the bridge? Considering one such              on a decision.
possibility requires concerted thought and effort – it seems                 The expected accuracy for a sample-based agent (previous
obvious that we should not pause at the intersection for sev-             section) gives us the expected utility per decision as a func-
eral hours and enumerate all the possibilities. It also seems             tion of k (the number of samples) and p (the Bernoulli trial
likely that we shouldn’t just turn left or right at random with-          probability; Figure 3a), and the utility function. We consider
out any consideration. So, how many samples should we take:               two utility functions for the 2AFC case: no punishment – cor-
how hard should we think?                                                 rect: gain 1; incorrect lose 0) and symmetric – correct: gain
   Determining an optimal answer to this meta-cognitive                   1; incorrect: lose 1. Given one particular action/sample time
problem requires that we specify how much a sample may                    ratio, we can compute the number of decisions made per unit
“cost”? To be conservative (and for the sake of simplicity),              time (Figure 3b). Multiplying these two functions together
we will assume that a sample can only cost time – it takes                yields the expected utility per unit time (Figure 3c).
some amount of time to conjure up an alternate outcome, pre-                 Since p is unknown to the agent, an ideal k must be cho-
dict its value, and update a decision variable.                           sen by taking the expectation over p. This marginalization
   Thus, if a given sample is free (costs 0 time), then we                (assuming a uniform distribution over p) for many different
should take infinitely many samples, and make the best de-                action/sample time ratios is displayed in Figure 4. It is clear
cision possible every time. If a sample costs 1 unit of time,             that as samples become cheaper, one is best advised to take
and the action time (the time that it would take us to act once           more of them converging to the limit of infinitely many sam-
we have chosen to do so) is also 1 unit of time, then we should           ples when the samples are free (the action/sample time ratio
take zero samples we should guess randomly. To make this                  is infinity).
peculiar result intuitive, lets be concrete: if we have 100 sec-             In Figure 5 we plot the optimal number of samples as a
onds, and the action time is fixed to be 1 second, then we can            function of the action/sample time ratio. Remarkably, for
make 100 random decisions, which will be right 50% of the                 ratios less than 10, one is best advised to make decisions
time, thus giving us an expected reward of $50. If taking a               based on only one sample if the utility function is symmet-
single sample to improve our decision will cost an additional             ric. Moreover, with no punishment for incorrect answers, the
second per decision, then if we take one sample per decision,             action/sample time ratio must be 2 or greater before taking
each decision will take 2 seconds, and we could make at most              any samples (making a guess thats at all educated, rather than
50 of them. It is impossible for the expected reward from this            fully random) becomes a prudent course of action. Thus, un-
strategy to be greater than guessing randomly, since even if              der some assumptions about how much it costs to think, mak-
100% of the decisions are correct, only $50 will be gained.               ing guesses based on very few samples (e.g., one) is the best
Moreover, since 100% accuracy based on one sample is ex-                  course of action: Making many locally suboptimal decisions
tremely unlikely (this could only arise in a completely deter-            quickly is the globally optimal strategy.
                                                                     151

Figure 4: Expected utility per decision, number of decisions per unit time, and expected utility per unit time (rate of return) as a function of
the number of samples and action/sample cost ratios. Action/sample cost ratios are logarithmically spaced between 1 (red) and 1000 (yellow).
In the last graph the solid circles indicate the optimal number of samples at that action/sample cost ratio. (The utility function used for this
figure contained no punishment for an incorrect choice and +1 for a correct choice.)
                                                                         distribution. Moreover, we showed that given reasonable as-
                                                                         sumptions about the time it takes to produce an exact sample,
                                                                         a policy of making decisions based on very few samples (even
                                                                         just one) is globally optimal, maximizing long-run utility.
                                                                            In this paper we considered sample-based decisions about
                                                                         predictions of variables that had not been previously observed
                                                                         – predictions computed through Bayesian inference over la-
                                                                         tent variables and structures in the world. However, a large
                                                                         prior literature on “probability matching” (Herrnstein, 1961;
                                                                         Vulkan, 2000) has studied a very similar phenomenon in a
                                                                         simpler task. In probability matching, subjects predict the
                                                                         outcome of a trial based on the relative frequencies with
                                                                         which that outcome has been observed in the past. Thus, sub-
                                                                         jects have direct evidence of the probability that lever A or
                                                                         lever B should be pulled, but they do not seem to maximize;
                                                                         instead, they “probability match” and choose levers with a
                                                                         frequency proportional to the probability of reward. On our
Figure 5: The optimal number of samples as a function of the ac-         account, this literal “probability matching” behavior amounts
tion/sample time-cost ratio for each of two utility functions (sym-      to making decisions based on one sample, while decisions
metric – correct: +1, incorrect: -1; and no punishment for incorrect     based on more samples would correspond to Luce choice de-
answers – correct: +1, incorrect: 0).
                                                                         cisions with an exponent greater than 1 (Luce, 1959).
                                                                            “Probability matching” to previously observed frequencies
                            Discussion                                   is naturally interpreted as sampling prior events from mem-
                                                                         ory. This interpretation is consistent with recent work sug-
We began with the observation that, on average, people tend              gesting that people make decisions based on samples from
to act consistently with ideal Bayesian inference, integrating           memory. Stewart, Chater, and Brown (2006) suggested that a
information to optimally build models of the world; however,             policy of making decisions through binary preference judg-
locally, they appear to be systematically suboptimal, acting             ments among alternatives sampled from memory can ac-
based on a very limited number of samples. This has been                 count for an assortment of human judgment and decision-
used to argue that people are not “fully Bayesian” (Mozer et             making errors. Similarly, Schneider, Oppenheimer, and Detre
al., 2008). Instead, we have argued that sample-based ap-                (2007) suggest that votes from sampled orientations in multi-
proximations are a powerful method for implementing ap-                  dimensional preference space can account for violations of
proximate Bayesian inference. Although with few samples,                 coherent normative utility judgments. A promising direction
sample-based inferences will deviate from exact Bayesian                 for future research would be to relate models suggesting that
inference, we showed that for two-alternative forced-choice              samples are drawn from cognitive processes such as memory,
tasks, a decision based on a very small set of samples is nearly         to models like those we have described in our paper, in which
as good as an optimal decision based on a full probability               samples are drawn from probability distributions reflecting
                                                                     152

ideal inferences about the world.                                     Berger, J. (1985). Statistical Decision Theory and Bayesian Analy-
   How much might a sample “cost”? A relevant measure of                 sis. New York: Springer.
                                                                      Brown, S., & Steyvers, M. (2008). Detecting and predicting
sample cost in multiple-trial experiments is the ratio between           changes. Cognitive Psychology, 58, 49–67.
the time it takes to make an action and go on to the next trial       Chater, N., & Manning, C. (2006). Probabilistic models of language
and the time required to draw a sample to inform a decision              processing and acquisition. Trends in Cognitive Sciences, 10(7),
                                                                         335–344.
about that action. Ratios near 10 seem quite reasonable: most         Gigerenzer, G. (2008). Rationality for mortals: How people cope
experimental trials last a few seconds, and it can arguably              with uncertainty. Oxford University Press, USA.
cost a few hundred milliseconds to consider a hypothesis. Of          Goodman, N., Tenenbaum, J., Feldman, J., & Griffiths, T. (2008).
                                                                         A rational analysis of rule-based concept learning. Cognitive Sci-
course, this is speculation. However, in general, it seems to            ence, 32(1), 108–154.
us that in most experimental tasks, the benefits gained from a        Griffiths, T., Canini, K., Sanborn, A., & Navarro, D. (2007). Unify-
better decision are relatively small compared to the costs of            ing rational models of categorization via the hierarchical dirichlet
                                                                         process. In Proceedings of the 29th annual conference of the cog-
spending a very long time thinking. So, if thinking amounts              nitive science society (pp. 323–328).
to sampling possible alternatives before making a decision, it        Griffiths, T., & Tenenbaum, J. (2005). Structure and strength in
should not be surprising that people regularly seem to use so            causal induction. Cognitive Psychology, 51, 354 – 384.
                                                                      Griffiths, T., & Tenenbaum, J. (2006). Optimal predictions in every-
few samples.                                                             day cognition. Psychological Science, 17(9), 767–773.
   We should emphasize that we are not arguing that all hu-           Herrnstein, R. (1961). Relative and absolute strength of response as
man actions and decisions are based on very few samples.                 a function of frequency of reinforcement. Journal of the Experi-
                                                                         mental Analysis of Behavior, 4(3), 267.
The evidence for sampling-based decisions arises when peo-            Knill, D., & Richards, W. (1996). Perception as Bayesian inference.
ple make a decision or a choice based on what they think                 Cambridge: Cambridge University Press.
is likely to be true (Which example is in the concept? How            Kording, K. (2007). Decision theory: What should the nervous
                                                                         system do? Science, 318(5850), 606.
long will this event last? How many airports are there in the         Levy, R., Reali, F., & Griffiths, T. (2009). Modeling the effects
US?). In other situations people appear to integrate over the            of memory on human online sentence processing with particle
posterior, or to take many more samples, such as when peo-               filters. In Advances in neural information processing systems
                                                                         (Vol. 21).
ple make graded inductive judgments (How similar is A to              Luce, R. (1959). Individual choice behavior. New York, NY: Wiley.
B? How likely is it that X has property P given that Y does?          Maloney, L. (2002). Statistical decision theory and biological vision.
How likely do you think that F causes G?). It is interesting to          In D. Heyer & R. Mausfield (Eds.), Perception and the physical
                                                                         world (pp. 145–189). New York, NY: Wiley.
consider why there may be a difference between these sorts            Maloney, L., Trommershauser, J., & Landy, M. (2007). Questions
of decisions.                                                            without words: A comparison between decision making under
   Under reasonable two-alternative choice scenarios, people             risk and movement planning under risk. In W. Gray (Ed.), In-
                                                                         tegrated models of cognitive systems (pp. 297–313). New York,
are best advised to make decisions based on few samples (fu-             NY: Oxford University Press.
ture work will extend this to n-AFC and continuous choice             Marr, D. (1982). Vision. Cambridge: MIT Press.
decisions). This captures a very sensible intuition: when we          McKenzie, C. (1994). The accuracy of intuitive judgment strate-
                                                                         gies: Covariation assessment and bayesian inference. Cognitive
are deciding whether to turn left or right at an intersection, we        Psychology, 26, 209–239.
should not enumerate every possible map of the world. We do           Mozer, M., Pashler, H., & Homaei, H. (2008). Optimal predictions
not need “moral certainty” about the probability that left or            in everyday cognition: The wisdom of individuals or crowds?
                                                                         Cognitive Science, 32, 1133-1147.
right will lead to the fastest route to our destination – we just     Sanborn, A., & Griffiths, T. (2008). Markov Chain Monte Carlo with
need to make a decision. We must implicitly weigh the bene-              People. In Advances in neural information processing systems
fits of improving our decision by thinking for a longer period           (Vol. 20). MIT Press.
                                                                      Schneider, A., Oppenheimer, D., & Detre, G. (2007). Application
of time against the cost of spending more time and effort de-            of Voting Geometry to Multialternative Choice. In Proceedings
liberating. Intuition suggests that we do this in the real world:        of the 29th annual conference of the cognitive science society (pp.
we think harder before deciding whether to go north or south             635–640).
                                                                      Shanks, D., Tunney, R., & McCarthy, J. (2002). A re-examination of
on an interstate (where a wrong decision can lead to a detour            probability matching and rational choice. J. Behav. Dec. Making,
of many miles), than when we are looking for a house (where              15, 233–250.
the wrong decision will have minimal cost). Empirical evi-            Stewart, N., Chater, N., & Brown, G. (2006). Decision by sampling.
                                                                         Cognitive Psychology, 53(1), 1–26.
dence confirms this: when the stakes are high, people start           Stigler, S. (1986). The History of Statistics: The Measurement of
maximizing instead of “probability matching” (Shanks, Tun-               Uncertainty Before 1900. Cambridge: Harvard University Press.
ney, & McCarthy, 2002). Nonetheless, it seems that in sim-            Vul, E., & Pashler, H. (2008). Measuring the crowd within: Proba-
                                                                         bilistic representations within individuals. Psychological Science,
ple circumstances, deliberating is rarely the prudent course of          19(7), 645–647.
action – for the most part, making quick, locally suboptimal,         Vulkan, N. (2000). An economist’s perspective on probability
decisions is the globally optimal policy: one and done.                  matching. Journal of Economic Surveys, 14(1), 101–118.
                                                                      Xu, F., & Tenenbaum, J. (2007). Sensitivity to sampling in bayesian
Acknowledgments. This work was supported by ONR MURI (JBT,               word learning. Developmental Science, 10(3), 288–297.
PI: Bavelier); Russell Sage, NDSEG, NSF Dissertation grant (EV).      Yuille, A., & Bülthoff, H. (1996). Bayesian decision theory and
                                                                         psychophysics. In D. Knill & W. RIchards (Eds.), Perception as
                                                                         bayesian inference (pp. 123–161).
                          References
Anderson, J. (1991). The adaptive nature of human categorization.
   Psychological Review, 98(3), 409–429.
                                                                  153

