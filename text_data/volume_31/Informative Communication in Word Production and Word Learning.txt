UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Informative Communication in Word Production and Word Learning
Permalink
https://escholarship.org/uc/item/66s0w3d7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Frank, Michael
Goodman, Noah
Lai, Peter
et al.
Publication Date
2009-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

            Informative Communication in Word Production and Word Learning
                      Michael C. Frank, Noah D. Goodman, Peter Lai, and Joshua B. Tenenbaum
                                              {mcfrank, ndg, peterlai, jbt}@mit.edu
                                               Department of Brain and Cognitive Sciences
                                                  Massachusetts Institute of Technology
                             Abstract                                     Though these proposals differ in their details, they share
                                                                       a basic assumption that communicators are not simply cod-
   Language does not directly code facts about the world. In-
   stead, speakers and listeners rely on shared assumptions to al-     ing and decoding meanings. Instead, listeners are making in-
   low them to communicate more efficiently. Writers like Grice        ferences about speakers’ intentions, taking into account the
   and Sperber & Wilson have proposed that communication is            words they utter and the context of their utterances. This kind
   assumed to be “informative” or “relevant,” but the predictions
   of these accounts are often informal or post-hoc. Here we pro-      of intentional inference framework for language seems much
   pose a formal analogue to these accounts: that communicators        more promising for explaining phenomena like (1-3). But
   choose what they want to say by how informative it would be         although these ideas seem intuitively correct, the difficulty
   about their intended meaning. We derive quantitative predic-
   tions about how this assumption would be used in language           of formalizing notions like “relevance” has largely kept them
   production and learning and test these predictions via two ex-      from making contact with computational theories of language
   periments. This work takes a first step towards formalizing the     use and acquisition.
   pragmatic assumptions necessary for effective communication
   in under-constrained, real-world situations.                           The goal of this paper is to begin to address this issue by
   Keywords: Language acquisition; Bayesian modeling; Com-             proposing a computational framework for intentional infer-
   munication                                                          ence. This framework relies on a shared assumption that com-
                                                                       munications are informative given the context. Although the
                          Introduction                                 basis of our framework is general, making predictions within
How does language work to communicate information from                 it requires a model of the space of possible meanings and
one person to another? Perhaps language is simply a code               how they map to natural language expressions. Thus, in or-
for facts about the world. On this kind of coding view of              der to make a first test of our framework, we study simple
communication, all the information necessary to understand             games that are similar to the “language games” proposed by
an utterance is contained within it. Speakers utter linguistic         Wittgenstein (1953).
expressions equivalent to their intended meanings and listen-             In the language games we study, the shared task of commu-
ers simply decode these expressions to recover their content.          nicators is to identify an object from a set using one or a few
There are a profusion of examples of language use, however,            words. This very restricted task allows us to define the possi-
which can be natural and easy to understand but are not easily         ble meanings that communicators entertain. We then use our
explained by a naive coding model:                                     framework to make predictions about the meaning and use
                                                                       of single words. This move allows us to define an intuitive
(1) The statement “I ate some of the cookies.” (Intended               mapping between words and meanings: that a word stands
   meaning: I ate some and not all of the cookies).                    for the subset of the context it picks out (its extension). Al-
                                                                       though these two simplifications do bring our tasks further
(2) The declaration “No.” (Intended meaning: I can tell you            away from natural language use, they also allow us to derive
   want to pinch him, but don’t do it).                                strong quantitative predictions from our framework.
(3) The contextual introduction of a new word “Can I have                 The outline of the paper is as follows. We first use our
   the glorzit?” (Intended meaning: pass me that thing,                framework to derive predictions for speakers and language
   which happens to be called a “glorzit”).                            learners who assume informative communication in an infer-
                                                                       ential framework. We then test our framework as an account
   Philosophers and linguists interested in this problem have          of two different kinds of tasks. Experiment 1 examines, in
suggested that language relies on shared assumptions about             a simple survey task, whether learners who are inferring the
the nature of the communicative task. Grice (1975) proposed            meaning of a novel word assume that speakers are being in-
that speakers follow (and are assumed by comprehenders to              formative in choosing the word they produce. Experiment 2
follow) a set of maxims, such as “be relevant”, or “make               tests whether, in a more naturalistic production task, speak-
your contribution to the conversation as informative as neces-         ers’ word choice is in fact related to the informativeness of
sary.” Sperber & Wilson (1986) have suggested that there is a          the word they pick.
shared “Principle of Relevance” which underlies communica-
tion. Clark (1996) has argued that communication proceeds                     Modeling Informative Communication
by reference to a shared “common ground.”                              Consider the context in Figure 1, representing the context in
                                                                       a language game. Imagine an English speaker in this game
                                                                       who is told to use a single word to point out the red circle.
                                                                   1228

                                                                        be distributions over propositions, for example (Piantadosi et
                                                                        al., 2008). We use this space of possible meanings for both
                                                                        the intended meaning of the speaker (which will be a delta
                                                                        distribution when the referent is known), and the meanings of
                                                                        words. By using distributional meanings, we are able to use
                                                                        notions of informativeness from information theory in formu-
                                                                        lating the communicative goals of the speaker.
                                                                           Imagine that there is a vocabulary V = {w1 , ..., w p }, and
                                                                        each word has a truth-functional meaning: a Boolean func-
                                                                        tion over objects, indicating whether the word applies to that
                                                                        object. The extension of word w in context C is the set of
                                                                        objects {o ∈ C|w(o) = 1} that the word applies to; denote by
                                                                        |w| the size of a word’s extension. We define the meaning of
                                                                        w in context C to be the distribution:
                                                                                                    (
                                                                                                       1
Figure 1: An example context: one red circle, one blue circle,                                               if w(o) = 1
                                                                                          w̃C (o) = |w|                              (4)
and four blue squares. The arrow shows the object the speaker                                         0       otherwise
intends to talk about.
                                                                        Rational speaker We assume the speaker acts rationally,
Intuitively, she is likely to use the word “red,” since it would        according to Bayesian decision theory: she chooses a speech
not be clear which object she was talking about if she used             act (word choice) in order to (soft-)maximize utility:
the word “circle.” Working from this intuition, a language
learner—who knew that the speaker was pointing out the red                                  P(w|MS ,C) ∝ eαU(w;MS ,C)                (5)
circle (perhaps because of some non-linguistic marker of in-            where MS is her intended meaning and U is a utility function.
tention, like a point or an eye-movement)—could make a very             For us, intended meanings will be delta distributions picking
informed guess about the meaning of the word “red.”                     out her intended referent precisely, but the model will natu-
   The intuition that a speaker would be likely to use the word         rally handle vague intended meanings (which might arise, for
“red” to talk about the red circle seems to come from an as-            instance, from incomplete knowledge). (The decision noise
sumption that, in the language of Grice (1975), speakers are            parameter α measures the speakers deviation from optimal.
choosing their words helpfully, in order to best inform listen-         For all computations in the current paper we set α = 1, which
ers of their intentions. If speakers did not try to communi-            recovers the standard Luce choice rule.) The speaker’s goal
cate informatively, they would not necessarily choose labels            is to choose the word which is informative about MS .
that distinguished their intended referent from other possible             The Kullback-Leibler divergence between two distribu-
objects. In our game, an uninformative speaker (who still re-           tions X and Y , written DKL (X||Y ), is the expected amount
spected the truth conditions of their language) might just as           of information about X that is not contained in Y (Cover &
well have chosen to talk about the shape of the red circle as           Thomas, 2006). We formalize the goal of “informativeness”
its color; correspondingly, a learner who did not assume an             by assuming that the speaker’s utility increases as the KL di-
informative speaker would not be able to infer what the word            vergence between MS and the literal meaning of the chosen
“red” meant.                                                            word decreases:
   In the following sections, we formalize these intuitions
through an inferential model of language within this restricted                       U(w; MS ,C) = −DKL (MS ||w̃C ) + F             (6)
world. We model the speaker as selecting speech acts in or-             where F represents other factors (such as utterance complex-
der to be informative, and derive predictions both for speakers         ity) which affect the speaker’s utility. Assuming for the time
and for learners who assume this about speakers.1                       being that F = 0:
The Informative Communication Framework                                                                    e−αDKL (MS ||w̃C )
We assume that there is a fixed context C, consisting of some                          P(w|MS ,C) =                           0      (7)
                                                                                                        ∑    e−αDKL (MS ||w̃C )
set of objects o1 ...om , and that possible meanings are proba-                                          0
                                                                                                       w ∈V
bility distributions over C—that is, a meaning assigns a prob-
ability over each object in C. In the game described above,                Equation 7 simplifies greatly in simple language games
meanings simply carry information about which object is the             like the one pictured in Figure 1. The speaker’s intended
intended referent, though in a more complex task they might             meaning is a single object oS (the value of MS is 1 for oS ,
                                                                        0 for all other objects). Thus:
    1 One case which we do not treat here is the case of a teacher
who is searching for the best example of a word to show a learner.                                                       MS (o)
This case is discussed in detail in Shafto & Goodman (2008), and
                                                                                     DKL (MS ||w̃C ) =  ∑ MS (o) log
                                                                                                       o∈C                w̃(o)      (8)
we believe the current framework is compatible with their analysis.
                                                                                                     = − log(w̃C (oS ))
                                                                    1229

Substituting Equation 8 into Equation 7 gives:                               speaker of a foreign language indicate one of the objects and
                                                                             say a word in her language. We then asked asked the partici-
                                            w̃C (oS )α                       pants to make judgments about the meaning of that word. In
                    P(w|MS ,C) =                                     (9)
                                          ∑ w̃C0 (oS )α                      order to elicit a continuous, quantitative judgment, we asked
                                         w0 ∈V                               participants to “bet,” splitting $100 between the two possi-
By Equation 4:                                                               ble meanings. This betting measure gives us an estimate of
                                                                             speakers’ subjective probability.
                                                                                We then attempted to predict participants’ mean bets across
                                   (
                                      |w|−α      if w(o) = 1
               P(w|MS ,C) ∝                                         (10)     a range of different contexts. For example, in Figure 1, imag-
                                      0           otherwise
                                                                             ine that the speaker points to the red circle and says “lipfy”
Thus, given the set of simplifying assumptions we have made,                 (a novel word w that you have never heard before). We used
the very abstract goal of “being informative” reduces to a                   Equation 12 to calculate the probability that learners judge
simple formulation: choose words which pick out relatively                   that w means red as opposed to circular:
smaller sections of the context. This recovers the “size princi-
ple” of Tenenbaum & Griffiths (2002) and Xu & Tenenbaum                                                               |red|−1
(2007).2                                                                             P(w = f1 |MS ,C) =
                                                                                                             |red|−1 + |circular|−1
Ostensive word learning We next show how a Bayesian                                                             1
                                                                                                                1      2
learner equipped with the theory of helpful speakers captured                                            =    1   1
                                                                                                                    =
                                                                                                              1 + 2
                                                                                                                       3
in Equation 10 can leverage this knowledge to learn words in
an unknown language. A real language learner often has un-
certainty about both the speaker’s meaning, MS , and the lex-                Thus, our prediction is that learners should bet around $67
icon, L, the mappings between words and meanings (Frank                      that “lipfy” means red.
et al., in press). Although our framework can be extended to                 Materials and Methods
this case, we focus here on a simpler case that is close to os-
tensive learning: the learner knows MS and has only to infer                 Participants Seven hundred participants responded to so-
facts about L. In this case, the learner knows which object the              licitations through MIT-related email lists and were compen-
speaker means to talk about, and can use the assumptions of                  sated via entry in a drawing to win an iPod Shuffle.
informative communication to infer the meaning of the spo-                   Procedure Participants navigated to a webpage on which
ken word (i.e. which feature of the object it refers to). By                 they were given a short backstory about the experiment. They
Bayes’ rule:                                                                 were told to imagine that they were visiting a foreign coun-
                                                                             try and that the display they were shown was a display in a
                P(L|w, MS ,C) ∝ P(w|L, MS ,C)P(L)                   (11)     market. They were told that one of the items (indicated by
                                                                             a square around it) was being described by the merchant so
For simplicity let us assume that the object has two fea-
                                                                             as to teach them a word, and that their task was to guess the
tures f1 and f2 , that there are two words in the language
                                                                             meaning of the word that the merchant used.
w1 and w2 , and that there are only two possible lexicons
                                                                                In each of three trials on the page, six simple objects were
L1 = {w1 = f1 , w2 = f2 } and L2 = {w1 = f2 , w2 = f1 }. Further,
                                                                             shown. The objects in each trial varied randomly on two
assume a uniform prior on vocabularies. Then:
                                                                             binary-valued dimensions picked from a larger set of features
                                       P(w1 |L1 , MS ,C)                     (red/blue, big/small, striped/polka-dot, circular/square) and
  P(L1 |w1 , MS ,C) =                                                        whose other properties were constant on these dimensions.
                         P(w1 |L1 , MS ,C) + P(w1 |L2 , MS ,C)
                                                                    (12)     For example, in Figure 1, size and texture are fixed but ob-
                                | f1 |−1                                     jects varied on color and shape. All trials were constructed
                      =
                         | f1 |−1 + | f2 |−1                                 such that different properties were used for each trial and par-
                                                                             ticipants were not able to make mutual-exclusivity judgments
                           Experiment 1                                      between trials.
In order to make a first test of our framework, we used an                      On each trial, participants were told that the speaker was
experimental paradigm based on the “red circle” example                      talking about one particular object using a novel word (e.g.
above. We created a web survey which asked participants                      “lipfy”) and asked to split a bet of $100 dollars between
to imagine encountering a display like Figure 1 and seeing a                 the two attributes that “lipfy” could refer to (e.g. red or
    2 This principle was originally derived by Shepard (1987) as a           circular). Different novel words were used in each trial.
description of appropriate generalization behavior within psycho-
logical spaces. Our work here can be thought of as an alternate              Results & Model Fits
derivation of the size principle—based on premises about the com-            Results are plotted in Figure 2. Since we had randomized
municative task, rather than about the structure of generalization—
that licenses its application to the kinds of cases that we have treated     the dimensions used in each trial, we averaged across this
here.                                                                        aspect of the data and considered only the distribution of bets
                                                                         1230

                                                                     n u m b er o f o b j ect s with unnamed feature
                                         1                     2                    3                   4                     5               6
      responses
                         30
                                  0.50                      0.70                  0.75                   0.75                 0.80            0.83
                         20
                                                                                                                                                     1
                         10
                          0
                              0          50   100
                                     b et
                                                        0.51                    0.59               0.58                 0.64                 0.74
                                                                                                                                                     2
                                                                                                                                                         num ber of objects with nam ed feature
                                                                               0.51                0.55                 0.61              0. 70
                                                                                                                                                     3
                                                                                                  0.48                 0.56              0.68
                                                                                                                                                     4
                         90
                         80
      m ean hum an bet
                                                          r = .9 3                                                     0.52              0.66
                                                                                                                                                     5
                         70
                         60
                                                                                                                                      0.47
                         50
                                                                                                                                                     6
                                   50          60          70            80           90
                                              m o d el p r ed i c t i o n s
Figure 2: Each subplot shows the histogram of participants’ bets, along with the mean and 95% confidence intervals shown
in red. Confidence intervals are computed via non-parametric bootstrap. Plots are arranged by the number of objects with the
named and unnamed features (e.g., in Figure 1, “red” and “circular”). Plot background colors are proportional to the mean bet.
The inscribed plot (lower-left) shows mean bets plotted by model predictions with 95% confidence intervals. X positions are
jittered slightly to avoid overplotting. Line of best fit is shown in red.
relative to the number of objects with each of the two possible                               perimentally determined means was high (Pearson’s r = .93,
features.                                                                                     Spearman’s rank-order r = .92, p < .0001). Thus, in their
   When there were equal numbers of objects with each fea-                                    inferences about the meanings of novel words, participants’
ture (e.g., two red and two circular objects)—represented by                                  judgements conformed quite precisely to the predictions of
the diagonal in Figure 2—mean bets were very close to $50,                                    our model.
reflecting equal probability. In contrast, in the case shown in
Figure 1, there is only one object in the named category (red)                                                      Experiment 2
but two in the unnamed category (circular). We predicted                                      In our second experiment, we tested the predictions of the
average bets of $67, and participants’ average response was                                   informative communication framework for speakers’ produc-
$70.                                                                                          tive language use. We used a natural-language description
   More generally, the correlation between the values pre-                                    task, rather than probability judgments in a questionnaire. For
dicted by the informative communication model and the ex-                                     our stimulus set we chose a set of photos of “superballs”—
                                                                                           1231

                                                                          “shiny surface; translucent top hemisphere with surfer inside;
                                                                             opaque bottom hemisphere with red green blue yellow
                                                                             stripes”
                                                                          “surfer in half, other half yellow/blue/red stripes”
                                                                          “half transparent, half opaque (colorful), surfer inside clear
                                                                             part”
                                                                          “surfer with horizontal rainbow stripes on bottom half of ball”
                                                                          “clay figurine of man surfing on light blue/gray water glass.
                                                                             reflects light yellow. blue, red claylike bottom”
            Figure 3: Miniature images of the full set of superballs, alongside a ball and descriptions by five participants.
collectible bouncing balls—from an internet photo-sharing              that the informative communication model provided accurate
website. We selected this stimulus set because each ball               predictions about participants’ productions, we calculated for
had been tagged by the album owner with information about              each ball and tag the probability of a participant writing the
its distinguishing features (providing us with some “ground            corresponding “tag-word” (the word corresponding exactly to
truth” about word extensions). Crucially, the tags were as-            the tag) as part of their description of the ball. We then made
signed irrespective of their informativeness relative to this          predictions for the probability of producing a particular tag
particular set of photos: for example, all 304 photos were as-         for each ball using Equation 10. We excluded from our anal-
signed the tag “superball.” The stimulus set is shown along-           ysis tag-words which were not uttered by any participants in
side a sample stimulus in Figure 3.                                    reference to a particular ball and hence may not have been
                                                                       descriptions recognized by participants (e.g., the tag “mor-
Methods                                                                ris,” which referred to the given name of a toy cat pictured in
Participants Forty-four participants from MIT and the sur-             one of the balls).
rounding community took part in this experiment as a web                  Across the whole set of tag-words, we found a small but
survey for which they received payment.                                highly significant effect of informativeness on the probability
Stimuli and Procedure The stimuli were a set of 304 pho-               of a tag-word being produced (r = .19, p < .0001). When we
tos of superballs collected in a Flickr photo album.3 Each             investigated further, we found that the use of basic-level color
participant was asked to click through the entire set of su-           terms was very poorly predicted by the model (r = .02, p =
perballs, one at a time. This process usually took around 5            .63), and that other terms were much better predicted (r = .51,
minutes. Participants next were presented with 50 randomly             p < .0001). Model predictions versus tag-word frequencies
chosen balls, again one at a time. For each ball in this second        words other than color terms are plotted in Figure 4.
set, the participant was instructed to write a short description          Why was the use of particular color words not predicted
“so that someone could pick it out of the full set.”                   by our model? There are likely at least three factors that
                                                                       go into the decision to produce a word in a situation like
Results & Model Fits                                                   Experiment 2: how informative the word is relative to the
Participants’ responses were short descriptions of individual          other possible words, how frequent or easy to produce the
superballs. We collected an average of ten descriptions for            word is (the F term in Equation 6), and how well the
each ball in the set. Responses varied from verbose descrip-           word fits the particular object. In order to make a test
tions to single-word answers; we treated all words in each             of the hypothesis that F was the major factor involved in
description as a “bag of words.” Then, to test the hypothesis          the prediction errors on our model (including its poor per-
                                                                       formance on colors words), we estimated a measure of F
    3 http://www.flickr.com/photos/lenore-m/sets/
                                                                       by using the counts of tag-words from the Google Images
72157600039854497/
                                                                 1232

                                                                                                                        were well fit by our model in the first experiment; in the sec-
                                                                                                                        ond experiment we found that the model predictions were sig-
                                                                                                                        nificantly correlated with speakers’ choice of words.
                                                          stars
                                                     football
                                                  penny         lion
                                                         sunflower
                                                              astronauts   octopus
                                                                              car    penguin    star
                       1.0                                                                                                 While this framework is related to previous game-theoretic
                                                 egg
                                             rose fish
                                           flag        watermelon
                                                   helmet
                                                   usa
                                                          frog                                 turtle                   approaches to pragmatics (Benz et al., 2005), it differs from
                                               zebra
                                                   gold       alien      brine
                                                                            butterfly
                       0.8             smiley
                                                            snake
                                                                flowers
                                                                     skier
                                                                                                                        these approaches in that it does not rely on complex, recursive
                                            spider
                                                coral coin dolphin
                                                                       surfer
                                                                                                        alligator
                                                                                                                        computations but instead on a simple formulation that can be
tag-word probability
                                                japan                             lemon
                                                                    hole                                                computed whenever the space of meanings and mappings to
                                              earth            frogs
                       0.6                       pig
                                                            lizardparachute
                                                                      rocket                                            linguistic expressions is known. With these elements defined,
                                              stripes
                                                    navy
                                                      cat    foot                                 basketball
                                                   skull                                                                our framework can be used to make predictions in any situa-
                                               starfishweb
                                     silver    globewheel                                                               tion in which a space of possible meanings can be defined,
                       0.4                               tiger
                                   glitter eye          morrisfence                                                     ranging from simple non-linguistic communication experi-
                                                planet9lives         train
                               clear
                               half             triangles      eight submarine
                                            elf aquarium
                                                   jet                                                                  ments to complex cases like scalar implicature and anaphora
                                                            rhinoceros
                                               oceans
                       0.2      solid
                                       fuzzy
                                                                     blimp
                                                                   giraffe           skydivers                          resolution. Our hope is that future work will make use of this
                                       clouds
                                transparent  flower
                                                 facetsribs  rubberbands       ladybug
                               opaque striped
                                      print   landscape
                               swirl
                                 translucentembossed   iceberg                                                          framework to address a broad range of questions in language
                                textured lacrosse dinosaur
                               smooth
                                  painted
                                 animal        checkers
                               superball                                                                                use and language learning.
                       0.0
                             0.0                 0.2          0.4            0.6           0.8                 1.0                         Acknowledgments
                                                             model prediction                                           We thank Pat Shafto and Avril Kenney for valuable discus-
                                                                                                                        sion. This work supported by a Jacob Javits Graduate Fel-
                                                                                                                        lowship to the first author and NSF DDRIG #0746251.
Figure 4: Probability of a label being written in participants’
descriptions of a ball, plotted by the predictions of the in-                                                                                   References
formative communication model. Points shown are averaged                                                                Benz, A., Jager, G., & Van Rooij, R. (2005). Game theory
across balls for clearer plotting. Basic level color terms are                                                            and pragmatics. Palgrave Macmillan.
excluded from this analysis. The line of of best fit is plotted                                                         Clark, H. (1996). Using language. Cambridge, UK: Cam-
in red.                                                                                                                   bridge University Press.
                                                                                                                        Cover, T., & Thomas, J. (2006). Elements of information
database (http://images.google.com). Adding this measure to                                                               theory. New York: Wiley-Interscience.
the model predictions only slightly improved the fit to the en-
                                                                                                                        Frank, M. C., Goodman, N. D., & Tenenbaum, J. (in press).
tire dataset (r = .22) and to the non-color words (r = .52). We
                                                                                                                          Modeling cross-situational word learning through infer-
believe that the effects of the third factor—the applicability of
                                                                                                                          ences about speakers’ referential intentions. Psychological
tag-words to the images—is likely responsible for the failure
                                                                                                                          Science.
of the model to predict the use of color words. As in Figure 3,
some color terms applied overall to a particular ball and were                                                          Grice, H.(1975). Logic and conversation. Syntax and Seman-
used by more participants, while others applied to small parts                                                            tics, 3, 41–58.
of the balls and were less widely used.                                                                                 Piantadosi, S., Goodman, N., Ellis, B., & Tenenbaum, J.
                                                                                                                          (2008). A Bayesian model of the acquisition of compo-
                                              General Discussion                                                          sitional semantics. Proceedings of the 30th Annual Con-
A model of language as a code for facts does not account for                                                              ference of the Cognitive Science Society.
the rich interpretations that language users are able to extract                                                        Shafto, P., & Goodman, N. (2008). Teaching games: Sta-
from limited data. Instead, most research on language use in                                                              tistical sampling assumptions for learning in pedagogical
context assumes an intentional inference framework, in which                                                              situations. Proceedings of the 30th Annual Conference of
speakers and listeners share assumptions about the nature of                                                              the Cognitive Science Society.
the communicative task that allow meanings to be inferred                                                               Shepard, R. (1987). Toward a universal law of generalization
even in the presence of ambiguous or limited data.                                                                        for psychological science. Science, 237, 1317–1323.
   Our work here takes a first step towards a formal frame-                                                             Sperber, D., & Wilson, D. (1986). Relevance: Communica-
work for this kind of inferential account. We used tools                                                                  tion and Cognition. Oxford, UK: Blackwell Publishers.
from information theory to give a general framework for                                                                 Tenenbaum, J., & Griffiths, T. (2002). Generalization, simi-
how speakers can communicate informatively and then used                                                                  larity, and Bayesian inference. Behavioral and Brain Sci-
Bayesian inference to derive predictions for both listeners and                                                           ences, 24, 629–640.
learners within simple Wittgenstinean “language games.” We
                                                                                                                        Wittgenstein, L. (1953). Philosophical Investigations. Ox-
then tested these predictions in two experiments: a highly
                                                                                                                          ford, UK: Blackwell Publishers.
constrained word-learning questionnaire and a more natu-
ral production experiment. Learners’ quantitative judgments                                                             Xu, F., & Tenenbaum, J. (2007). Word Learning as Bayesian
                                                                                                                          Inference. Psychological Review, 114, 245.
                                                                                                                     1233

