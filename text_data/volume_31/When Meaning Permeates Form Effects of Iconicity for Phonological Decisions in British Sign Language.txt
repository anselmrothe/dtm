UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
When Meaning Permeates Form: Effects of Iconicity for Phonological Decisions in British Sign
Language

Permalink
https://escholarship.org/uc/item/9d2416jn

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Thompson, Robin
Vigliocco, Gabriella
Vinson, David

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

When Meaning Permeates Form:
Effects of Iconicity for Phonological Decisions in British Sign Language
Robin L. Thompson (robin.thompson@ucl.ac.uk)
David P. Vinson (d.vinson@ucl.ac.uk)
Gabriella Vigliocco (g.vigliocco@ucl.ac.uk)
Deafness, Cognition and Language Research Centre, Department of Cognitive, Perceptual and Brain Sciences
University College London, 26 Bedford Way, London, WC1H 0AP, UK
eating because the phonological form2 can be manipulated
to create a form that bears a strong resemblance to the
meaning (in British Sign Language the hand is brought to
the mouth as if eating, see Figure 1).

Abstract
Signed languages exploit the visual/gestural modality to
create iconic expression across a wide range of basic
conceptual structures in which the phonetic resources of the
language are built up into an analogue of a mental image.
Previously, we demonstrated a processing advantage when
iconic properties of signs were made salient in a
corresponding picture in a picture/sign matching task
(Thompson et al., 2009). The current study investigates the
extent of iconicity effects with a phonological decision task
(does the sign have straight or bent fingers) in which the
meaning of the sign is irrelevant. The results show that
iconicity is a significant predictor of response latencies with
more iconic signs leading to slower responses. We conclude
that meaning is activated automatically for highly iconic
properties of a sign, and this leads to interference in making
form-based decisions. This is supported by the even greater
inhibition observed when iconicity specific to a sign’s
handshape was analyzed (phonological decisions involved
sign handshape). Thus the current study extends previous
work by demonstrating that iconicity effects permeate the
entire language system, arising automatically even when
access to meaning is unnecessary.

Figure 1: The BSL sign EAT
There are few experiments that address the role of
iconicity, likely because, until recently, sign language
research has sought to stress the parallels between signed
and spoken languages (e.g., Bellugi & Klima, 1976; Klima
& Bellugi, 1979). The few early studies there are suggest
that iconicity is irrelevant in language development such
that children's earliest signs are not iconic (Orlansky &
Bonvillian, 1984) and iconic signs are not less prone to
errors (e.g., for iconically motivated agreement signs such
as GIVE which move from source to goal, Meier, 1982).
More recently the findings have been mixed. In support of
earlier work, a case study of anomic patient “Charles”
suggested he was no better at producing iconic signs than
noniconic signs (Marshall, Atkinson, Smulovitch, Thacker
& Woll, 2004; However this study may have simply lacked
power to detect a small effect of iconicity (13/20
performance for iconic signs, 10/20 for noniconic). Further,
Meier, Mauk, Cheek & Moreland (2008), found that errors
in the earliest ASL signs of four deaf infants (in which the
sign form did not match the adult target form) did not tend
to be more iconic than what was produced by the adult
model (e.g., actually licking the hands when producing the
sign ICE-CREAM, normally produced with a fist moving in
front of the mouth). The authors conclude that because
children’s earliest sign errors do not tend to be more iconic,

Keywords: iconicity; sign language; lexical processing;
embodiment.

Introduction
Signed languages conform to the same grammatical
constraints and linguistic principles found in spoken
languages, and are acquired along the same timeline (for
reviews see Emmorey, 2002; Sandler & Lillo-Martin, 2006).
Nonetheless, they make use of iconicity (the transparent
relationship between meaning and form) to a much greater
extent than spoken languages (Taub, 2001). This is likely
because the phonetic resources of a visual/gestural language
can be exploited to a greater degree than oral/aural
languages to build up iconic expressions that are analogues
of mental images. To spell this out, for an English speaker
who is producing the word ‘eat’, there is no direct link
between the phonological representation /it/ and the concept
of ‘eat’. However, for a signer producing the sign EAT1
there is a more direct expression related to the action of

2

Just as in spoken languages, signed languages have a
sublexical level of representation (i.e., a phonology). Signs are
made up of three major parameters: handshape, place of
articulation and movement (see Sandler, and Lillo-Martin,
2006, for an overview.)

1

Signs are customarily represented as English glosses in capital
letters.

165

they are not guided by these closer form-meaning mappings
in acquisition.
Alternatively, normative data on 300 lexical signs in
British Sign Language (BSL) suggests that there is at least
some relationship between age of acquisition (AoA) and
iconicity, with more iconic signs tending to be acquired
earlier in life, while acquisition of less iconic signs is more
distributed across age ranges (Vinson, Cormier, Denmark,
Schembri & Vigliocco, 2008). Further, Vigliocco, Vinson,
Woolfe, Dye, and Woll (2005) found that adult BSL signers
and English speakers differ in their judgments when
grouping signs/words referring to tools, tool-actions and
body-actions according to meaning similarity. While
English speakers in the study tended to group tool actions
along with body actions (showing a preference for
distinguishing actions from objects), BSL signers tended to
group tools and tool-actions together, as predicted on the
basis of shared iconic properties of the signs (i.e., signs
referring to tools [e.g., KNIFE] and tool actions [e.g., CUT]
share “tool-use” iconicity, making them more similar to
each other than body-actions [e.g., HIT]). The authors
account for the difference in terms of the mental images
triggered by the iconic signs. In support of this, when
English speaking non-signers were instructed to develop a
mental image including typical experiences with the thing or
action, they also judged tool-actions to be more similar to
tools, compared to the speakers to whom no imagery
instructions were given.
With growing interest in the relationship between
general cognition and language, along with the everwidening belief that the two are inseparable (e.g., theories of
embodiment; e.g., Barsalou, et al., 2003; see Meteyard &
Vigliocco, 2008 for a review), more transparent mappings
between meaning and form seem a natural outcome even for
spoken languages. While Indo-European languages have
relatively small inventories of onomatopoetic words in
which there is a non-arbitrary relationship between meaning
and sound, some spoken languages such as Japanese and
Korean have a much larger inventory covering not only
onomatopoeia, but also sound-symbolism related to other
sensory experiences, manner, and mental/emotional states
(several thousand entries, including both common and very
rare examples, are found in one Japanese dictionary of
iconic expressions; Kakehi, Tamori & Schourup, 1996).
Recently, Imai, Kita, Nagumo, & Okada (2008), found
that 25 month-old children are sensitive to sound-symbolic
matches in the domain of action verbs and that this sound
symbolism facilitates learning (both English and Japanesespeaking children were able to generalize the meaning of
novel sound-symbolic verbs, and unable to generalize the
meaning of non-sound-symbolic verbs). The authors
conclude that iconic scaffolding through sound symbolism
plays an important role in early verb learning. Interestingly,
the authors additionally suggest that certain aspects of sound
symbolism may be universally and biologically grounded
(based on the finding that both Japanese and English
speaking adults were sensitive to sound-symbolic relations

between novel words and novel actions during the norming
phase of the study). While these studies are crucial to a
better understanding of the role of iconicity in language they
do little to address the potential role of iconicity during
language processing.
For signed languages, the presence of more transparent
links between meaning and form could, in principle, be
beneficial to on-line language processing, both in sign
production and sign comprehension. For example, a stronger
link between semantic properties and iconic phonological
properties in sign production could help signers avoid TOT
states (or tip-of–the-fingers as it has been coined for signed
languages; Thompson, Emmorey, Gollan, 2005). In sign
comprehension, iconic properties of a sign could more
readily activate the corresponding conceptual properties of
the referent, resulting in faster on-line processing.
In support of this, Ormel (2008) found iconicity effects
for deaf children using Sign Language of the Netherlands in
a picture/sign matching task where responses were
significantly faster for highly iconic signs than for less
iconic signs (to answer “yes the picture matches the sign”).
In a similar study using picture/sign matching for adult
users of American Sign Language (ASL), strong
relationships between iconic properties of a sign and
features of a pictured object speeded sign recognition
(Thompson, Vinson & Vigliocco, 2009). Specifically,
participants were asked to indicate by button-press whether
a picture and a sign refer to the same object. Experimental
signs were all iconic. In one condition, the iconic
property/feature of the sign (e.g. BIRD, produced with
thumb and forefinger at the mouth, representing a bird’s
beak) was salient (e.g., a bird pictured from the front, beak
well in view) while in the second condition the iconic
property was not salient (e.g., a picture of a bird flying,
extended wings well in view). As a control, Englishspeaking non-signers were also presented with the same
pictures followed by English words. ASL signers responded
faster when the iconic property of the sign was salient in the
picture than when it was not, while English controls showed
no such difference. In a British Sign Language (BSL)
replication of the ASL study, Vinson, Thompson, Skinner &
Vigliocco (2008) likewise found faster RTs for picture-sign
matching when the iconic property of a sign was made
salient in a picture compared to when it was not.
Additionally, this study manipulated general salience of
iconic properties (based on English semantic feature norms;
McRae, Cree, Seidenberg & McNorgan, 2005) to rule out
the possibility that iconicity effects are modulated by a
property's general salience. For example, the BSL sign for
ELEPHANT shows the shape of an elephant’s trunk, a
feature frequently listed for elephants in the McRae et al.
feature norms and thus highly salient to English speakers,
while the BSL sign LION shows a lion's claws, not
considered a generally salient feature of lions, being only
infrequently listed as a feature for lions. BSL signers
responded faster when the iconic property of a sign was
highlighted in a corresponding picture regardless of general

166

subjects were native signers from Deaf families, three early
signers (exposure to BSL by age 5) and five were late
signers (exposure to BSL after age 5).

salience, thus showing that the effect was not modulated by
a property’s general salience.
These response time studies provide evidence that a
more transparent mapping between meaning and form can
aid language processing. That iconicity is used in areas such
as poetry and word play suggests that signers have an
awareness of the iconic properties of signs and these
properties might therefore be tapped into specifically under
conditions that draw signers’ attention to them. Crucially,
however, these studies aimed to minimize the possibility
that iconicity effects could arise from meta-cognitive
strategies or direct attention to iconicity, by using
experimental methodologies in which participants' attention
is diverted from the iconicity manipulation itself.
Despite these recent findings, however, little is currently
known about the scope of iconicity effects. Given that
iconicity in signed languages is represented in the
phonological form of signs, there may exist stronger links
between phonological and semantic levels of representation.
This is suggested by the Thompson et al. study. However,
one possibility is that iconicity effects are task dependent
(i.e., limited to conditions where semantic representations
and their iconic properties are directly relevant to the task).
This, for example, could have been the case in the
Thompson et al. study, which precisely manipulated the
connection between a real world picture and iconic
properties of a corresponding sign. Alternatively, iconicity
effects may be more automatic and occur during language
processing tasks, including those that do not directly tap into
meaning representations. Thus, for iconic signs regular
mappings between meaning and form might affect
processing at all levels.
In the current study we make use of a phonological
decision task to determine the extent of iconicity effects
during language processing. If iconicity effects are limited
to tasks that require access to meaning, then we predict the
absence of an effect in a phonological decision task which
does not depend upon accessing the meaning of signs.
However, if iconicity effects are more general in nature,
stemming from a tighter coupling between meaning and
form as a result of greater predictability in these mappings,
we should expect processing effects even in a phonological
decision task in which the meaning of signs is irrelevant. It
is only in this case, if iconicity can be shown to have an
effect even when it is irrelevant to the task that we can
confidently argue that it affects language processing in
general.

Figure 2: BSL signs with straight and bent handshapes that
are either iconic or non-iconic.

Materials
Video clips of BSL lexical signs were selected from a set of
300 for which age of acquisition (AoA), iconicity and
familiarity norms have been collected (Vinson et al., 2008).
We aimed to use as many normed items as possible, thus
including items that covered a range of AoA, iconicity and
familiarity ratings (excluding those rated as the least
familiar since these items might not be in the vocabulary of
most participants). Here we decided upon a distinction
between signs that employ "straight" and "bent" handshapes
(see Figure 2). This distinction is determined based upon
whether the finger(s) of any one sign are straight or bent.
Ambiguous signs were excluded from the set (e.g., signs
beginning with one handshape and ending with another),
leaving 162 signs that met all criteria. Video stimuli for the
BSL norming sample were produced by four different
models. To avoid the possibility that participants might use
model identity as a cue to make a particular response, we
selected an additional 24 filler signs (filmed but not normed
by Vinson et al., 2008) so that each model produced an
equal number of straight and bent handshape signs. The
final set included a total of 186 signs, plus twenty additional
signs as practice items.

Method
Subjects

Procedure

Fourteen adult participants (five men, eight women, average
age 47.5, range 25-72) were recruited from Deaf
communities in London, Birmingham and Edinburgh. One
participant responded at chance level and was removed from
the data set, leaving 13 subjects with analyzable data. Of
these 13, twelve were Deaf, while one subject was hearing
from a Deaf family who learned BSL from birth. Five of the

After giving consent to participate, participants were
presented with video-recorded instructions in BSL
(presented by R.S., a native BSL signer). The instructions
focused specifically on the distinction between straight and
bent signs. Examples were provided of signs with
handshapes that are straight or bent (as in BROWN or

167

BELT in Figure 2). Subjects were told that their task was to
make decisions about whether a sign has a straight or bent
handshape as quickly and accurately as possible by pressing
keys. The experiment began with twenty practice items
using a wide range of different handshapes. For these
practice items only, subjects received feedback (correct or
incorrect response) and after the practice, subjects were
given the opportunity to ask questions and then the actual
experiment began.
Stimulus presentation was carried out using DMDX v.
3.2.2.3 (Forster & Forster, 2003) on Windows computers.
The order of presentation of experimental items was
randomized for each participant. Each trial began with a
fixation cross that was displayed for 400 milliseconds,
followed by a BSL sign clip (.AVI format, 720 x 576
pixels). The participant was able to respond as soon as the
clip began to play. Once a response was made, or after a
3000ms timeout, there was a 250ms delay before the
fixation cross for the next trial. Participants were given
frequent opportunities to take breaks if needed.

significant (standardized beta = .034, t=1.321, p=.187). In
the second step (total adjusted R2=.037) familiarity was a
significant predictor (standardized beta = -.134, t=-5.051,
p<.001, rpartial= -.127); more familiar signs were responded
to more quickly. However, AoA was not a significant
predictor (standardized beta = -.011, p>.6). In the last step
(total adjusted R2=.040) iconicity ratings were significant
predictors (standardized beta = .065, t=2.171, p=.030,
rpartial=.054): more iconic signs led to slower responses.
In order to rule out the possibility that the above effect of
iconicity was related to purely visual characteristics of the
sign stimuli rather than having to do with sign language
processing itself, we ran the same BSL phonological
decision experiment on participants with no sign language
experience (n= 15). Non-signers were able to perform the
task since it required no knowledge of sign meanings
(average accuracy = 91%). The same analyses were
conducted as for the signers. Non-signers were significantly
slower for Bent than Straight signs (p=.008), and also
showed differences in recognizing signs produced by the
different sign models. Crucially, they showed no effects of
familiarity (p=.174), AoA (p>.7), or iconicity (p>.9),
suggesting that the iconicity effect reported above is indeed
a product of language experience.
If slower RTs in the phonological decision task are due
to sign iconicity, there might be even greater interference
for iconicity that is specifically expressed in the handshape
of a sign, because the task is specifically about the
handshape (i.e., is it straight or bent). We therefore
considered whether or not iconicity specific to the
handshape of the sign could play an even greater role than
iconicity related to other phonological parameters of a sign
(i.e., movement and place of articulation). To clarify this
point, consider two highly iconic signs in BSL: DEER and
CRY (for DEER see Figure 2, CRY is produced with two
alternating index fingers that move from either eye
downward). While both signs are rated as highly iconic (on
a 7 point scale, DEER has an iconicity rating of 6.0 and
CRY, 6.75), only DEER has an iconic handshape
(representing the antlers of a deer), while the handshape in
CRY is not iconic (the index finger only serves to trace the
path of the tears).
In order to analyze effects specific to handshape
iconicity, we first needed to collect handshape iconicity
norms. Because it proved difficult to distinguish handshape
iconicity from overall iconicity, we used experts in sign
linguistics for the norming task (n=4). These experts are all
linguistically trained, work in the field of sign language
research and have a clear understanding of iconicity in
signed languages (1=M, 3=F, average age 38.4, range 3443).
Overall ratings of handshape iconicity were highly
correlated to overall iconicity ratings (r = .833), primarily
stemming from the fact that noniconic signs receive the
lowest ratings on both scales. We therefore focused only on
iconic signs: those signs that were above average on general
iconicity ratings (rating >4 on a scale of 1-7, n=61),

Results
We first examined accuracy by participants and items.
Signs with accuracy rates below 70% (TEACH, CLOUD,
SICK, KITCHEN, SWALLOW) as well as signs with
handshapes that were not consistently judged as straight or
bent across participants (e.g., a fist with the thumb
extended), leaving 132 experimental signs in the data set
(average 92.0% correct), each with responses by 13
participants. We excluded all error trials and those with RTs
more than three standard deviations from a participant's
average. Average trimmed correct response latencies in this
task were 1345msec (SD=330).
Analysis was primarily intended to test for effects of
iconicity. This was accomplished by the use of sequential
multiple linear regression, with correct trimmed response
latencies as the dependent measure. The first step included
predictors not related to lexical variables. The first variable
was Straight/Bent, whether a sign had a straight or bent
handshape, as assigned to different response buttons. In this
step we also included predictors to distinguish between the
different sign models used in the task, because there were
clear differences in their speed and smoothness of
production which could translate into differences in the
latency of sign recognition independent of the lexical
variables of interest. The residuals from this step were
passed to a second step where lexical variables other than
iconicity (i.e., familiarity and AoA ratings) were entered as
predictors; these variables typically affect lexical decision
latencies and are somewhat correlated to iconicity (Vinson
et al., 2008) and so were factored in first. Finally, residuals
from this step were passed to a final step in which iconicity
ratings from Vinson et al. (2008) were used as a predictor.
The first step (adjusted R2 = .022) revealed differences in
the speed of responses to signs produced by different
models (ranging from 1251ms for the fastest model, to
1369ms for the slowest). The Straight/Bent variable was not

168

conducting multiple linear regressions. As before we first
entered predictors not related to lexical variables (Sign
Model and Straight/Bent handshape; adjusted R2 = .035),
and as in our previous analysis we found significant
differences in the speed of responses to signs produced by
different models, and no significant difference for the
Straight/Bent variable for this reduced set of items
(standardized beta = .015, t=.371, p=.711). In the second
step, familiarity and AoA ratings were used as predictors
(adjusted R2 = .040) familiarity just missed significance
(standardized beta = -.077, t=-1.890, p=.059) likely due to
the reduced set of items in handshape analysis. A significant
effect of AOA was found such that RTs for later-acquired
iconic signs were faster (standardized beta = -.095, t=-2.331,
p=.020). After factoring out these predictors, handshape
iconicity was entered. RTs for iconic signs with higher
handshape iconicity were significantly slower (adjusted Rsquare = .048, standardized beta = .119, t=2.556, p=.011).
As a final step, we entered general iconicity to see if there
was an effect of overall sign iconicity once variance specific
to handshape iconicity was taken into account. In this step,
general iconicity was also a significant predictor of RTs
(standardized beta = -.126, t=-2.488, p=.013). Unlike
handshape iconicity, other aspects of iconicity speeded
phonological decision once effects of handshape iconicity
were factored out.

task requiring access to meaning, a closer form/meaning
mapping led to facilitation due (presumably) to iconic links
aiding in meaning retrieval. In the phonological decision
task, access to meaning was not required. However, some
aspects of meaning appear to have been activated
nonetheless because of closer form/meaning mappings
existing for iconic signs. In this case irrelevant information
about the meaning led to interference because automatic
access to meaning could hinder phonological decisions.
Under this view, we might expect even greater inhibition
when the handshape parameter is iconic because subjects
made a decision involving handshape. Our analyses show
that iconicity specific to the handshape of a sign leads to
greater inhibition. Thus iconicity represented in the
handshape appears to make handshape judgments on other
(phonological) dimensions more difficult. The significant
effect of handshape iconicity suggests that meaning is
accessed (automatically) to a greater degree for highly
iconic signs. This results in inhibition on the phonological
decision task because it detracts from the purely form
related task. Interestingly, once handshape iconicity was
factored out, general iconicity led to faster decisions. That
general iconicity is facilitating responses to some extent
among iconic signs after handshape iconicity is taken into
account, suggests that iconicity has an overall beneficial role
in lexical access that is hindered here due to the nature of
the task.
While there may be mixed results in research areas such
as L1 acquisition, studies looking at on-line processing all
support a role for iconicity in language processing (Grote &
Linz, 2003, Ormel, 2008, Thompson, et al., 2009, Vinson,
Thompson, Skinner & Vigliocco, 2008). That there is a
difference between the acquisition literature and the
processing literature may simply be an indicator of the
sensitivity of the different measures used (i.e., analyses of
child language production may miss underlying knowledge
evident in more automatic RT studies), or the difference
could be due to other factors that come into play during
acquisition (e.g., motor control could affect ability to
produce signs iconic or not, Meier et al., 2008).
According to embodied theories of language, word
meanings are understood via mental simulations of past
perception and action (e.g., Barsalou, et al., 2003). Under
embodiment theory, therefore, there exists a more direct
connection between the real world and meaning than
previously assumed. The validity of this hypothesis has
gained support through a growing number of behavioral
studies showing that word meanings can interact with
perceptual and motor processes (see Meteyard & Vigliocco,
2008 for a review). However, these studies have typically
used paradigms that assess the general impact of the
language system, specifically semantics, on sensory/motor
tasks (and vice versa) and thus have little to say about the
extent to which such effects might penetrate into the
language system.
The current study is a first glimpse at a further connection
linking semantics and phonology in cases where there is an

Discussion
Overall the results demonstrate an effect of iconicity outside
the realm of meaning, and thus reveal a general role for
iconicity in language processing. In the phonological
decision task, signers did not need to access meaning, or
iconic representations. Nonetheless, and despite its lack of
relevance to the task, iconicity affected language processing,
clearly demonstrating that iconicity effects are automatic
and not dependent on tasks requiring access to semantic
representations.
An additional significant effect of familiarity on sign
decisions further suggests that we are tapping into lexical
processing. That there was no effect of AoA could suggest
that subjects were not fully accessing sign meanings, but
only retrieving partial aspects related to iconic properties of
the sign. It is perhaps the case that only iconic aspects of
meaning arise automatically, thus creating an inhibitory
effect, but that in a task involving decisions on phonological
form, other aspects of meaning are not accessed.
Importantly, no effect of iconicity (or other lexical
variables) was found when the same BSL experiment was
run on participants with no sign language experience.
In the previous picture/sign matching study (Thompson
et al., 2009), we observed faster RTs when subjects were
asked to match a sign with a picture that highlighted
properties of that sign. However, closer form/meaning
mappings of iconic signs resulted in an inhibitory effect in
the current phonological decision task. This difference is
likely due to an interaction of the same closer form/meaning
mapping of iconic signs with the experimental task. For the

169

iconic mapping between the two. The findings suggest that
study of signed languages, where iconic links between
phonology and semantics are rampant across a wide range
of basic conceptual structures, may provide a better window
into the nature of embodied cognition. This is because
iconic properties (and the degree of imagery) associated to
any one sign could strengthen the relationship between
meaningful human actions and the comprehension of words
and sentences. Thus the current study crucially extends
previous work in this area by demonstrating that iconicity
effects permeate the entire language system and in particular
can be found beyond what has traditionally been considered
the realm of meaning.

Language. Unpublished doctoral dissertation, University
of California, San Diego.
Meier, R.P., Mauk, C.E., Cheek, A. & Moreland, C.J.
(2008). The form of children's early signs: Iconic or
motoric determinants? Language Learning and
Development, 4:1, 63-98.
Meteyard, L. & Vigliocco, G. (2008). The role of sensory
and motor information in semantic representation: a
review. In P. Calvo & A. Gomila (eds.), Handbook of
Cognitive Science: An Embodied Approach, Ch. 15.
Academic Press, Elsevier: London.
Orlansky, M. & Bonvillian, J.D. (1984). The role of
iconicity in early sign language acquisition. Journal of
Speech and Hearing Disorders, 49, 287–292.
Ormel, E. (2008). Visual Word Recognition in Bilingual
Deaf Children. Unpublished Doctoral Dissertation.
Radbound University: Nijmegan, the Netherlands.
Sandler, W. & Lillo-Martin, D. (2006). Sign language and
linguistic universals. Cambridge MA: Cambridge
University Press.
Taub, S. (2001). Language from the body: Iconicity and
metaphor in American Sign Language. Cambridge MA:
Cambridge University Press.
Thompson, R.L., Emmorey, K., & Gollan, T. (2005). Tipof-the-fingers experiences by ASL signers: Insights into
the organization of a sign-based lexicon. Psychological
Science, 16(11), 856-860.
Thompson, R.L., Vinson, D.P., & Vigliocco, G. (2009). The
link between form and meaning in American Sign
Language: Lexical processing effects. Journal of
Experimental Psychology: Language, Memory, and
Cognition, 35(2), 550-557.
Vigliocco, G., Vinson, D.P., Woolfe, T., Dye, M.W., &
Woll, B. (2005). Words, signs and imagery: when the
language makes the difference. Proceedings of the Royal
Society B, 272, 1859-1863.
Vinson, D.P., Cormier, K., Denmark, T., Schembri, A. &
Vigliocco, G. (2008). The British Sign Language (BSL)
norms for age of acquisition, familiarity and iconicity.
Behavior Research Methods, 40, 1079-87.
Vinson, D.P., Thompson, R.L., Skinner, R. & Vigliocco G
(Sept., 2008), The link between form and meaning in
British Sign Language: Role of iconic properties in
lexical and conceptual processing. Talk given at the 14th
Annual Architectures and Mechanisms for Language
Processing (AMLaP) Conference, Cambridge, UK.

Acknowledgments
This work was supported by the Economic and Social
Research Council of Great Britain (Grant RES-620-286001), Deafness, Cognition and Language Research Centre
(DCAL).

References
Barsalou, L.W., Simmons, W.K., Barbey, A., & Wilson,
C.D. (2003). Grounding conceptual knowledge in
modality-specific systems. Trends in Cognitive Sciences,
7, 84-91.
Bellugi, U. & Klima, E. (1976). Two faces of sign: Iconic
and abstract. In S. Harnad (ed.), The origins and
evolution of language and speech, p. 514-538. New
York: New York Academy of Sciences.
Bergen, B.K. (2004). The psychological reality of
phonaesthemes. Language, 80(2), 290-311.
Forster, K.I & Forster, J.C. (2003). DMDX: A windows
display program with millisecond accuracy. Behavior
Research Methods, Instruments, & Computers, 35, 116124.
Grote, K., & Linz, E. (2003). The influence of sign language
iconicity on semantic conceptualization. In W. G. Muller
& O. Fischer (eds.), From sign to signing, pp. 23–40.
Amsterdam: John Benjamins.
Imai, M. Kita, S., Nagumo, M. & Okada, H. (2008). Sound
symbolism facilitates early verb learning. Cognition,
109(1), 54-65.
Kakehi, H., Tamori, I. & Schourup, L. (1996). Dictionary of
iconic expressions in Japanese. Berlin: Walter de
Gruyter.
Klima, E. & Bellugi, U. 1979. The signs of language.
Cambridge, MA: Harvard University Press.
Marshall J, Atkinson J, Smulovitch E, Thacker A, Woll B.
(2004). Aphasia in a user of British Sign Language:
Dissociation between sign and gesture. Journal of
Cognitive Neuropsychology, 21(5), 537-554.
McRae, K., Cree, G. S., Seidenberg, M. S., & McNorgan, C.
(2005). Semantic feature production norms for a large
set of living and nonliving things. Behavioral Research
Methods, Instruments, and Computers, 37, 547-559.
Meier, R.P. (1982). Icons, analogues, and morphemes: The
acquisition of verb agreement in American Sign

170

