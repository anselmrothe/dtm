UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Active vs Passive Training for Educational Software
Permalink
https://escholarship.org/uc/item/0w86n92t
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Shih, Benjamin
Wylie, Ruth
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

                              Active vs Passive Training for Educational Software
                                                     Ruth Wylie (rwylie@cs.cmu.edu)
                                         Human-Computer Interaction Institute, 5000 Forbes Avenue
                                                            Pittsburgh, PA 15213 USA
                                                      Benjamin Shih (shih@cmu.edu)
                                             Machine Learning Department, 5000 Forbes Avenue
                                                            Pittsburgh, PA 15213 USA
                                Abstract                                         We present results comparing active and passive training
                                                                              for the programming environment: Alice. Developed by
   Computer-based instructional interventions are increasingly
   popular in classroom curricula. For students to benefit from               Carnegie Mellon University, Alice offers users the
   these interventions, it is vital that they are properly trained to use     opportunity to develop programs (called worlds) using a
   the software. We investigate the effects of using active versus            graphical, click-and-drag interface and fully animated,
   passive training techniques to familiarize users with a graphical          three-dimensional characters (Conway, et al., 1999). This
   programming environment, Alice. We examine the impact                      work uses an Alice variant, Storytelling Alice, that includes
   using measures of knowledge, user preferences and motivation.              characters, methods, and entire worlds of props and
   Participants in both training environments gained domain                   backgrounds designed to simplify the building of worlds in
   knowledge and interface familiarity, but passive training                  Alice. The original Storytelling Alice includes an interactive
   participants believed that Alice was easier to use, spent more
                                                                              tutorial (Kelleher & Pausch, 2005) that provides basic
   time using Alice when given the choice, and demonstrated better
   preparation for future learning.                                           training in the use of Alice. We compare that tutorial with a
                                                                              narrated, passive video of an expert user completing the
                                                                              same tasks as those covered in the tutorial. We find that
   Keywords: Passive vs Active Instruction, Computer Science                  while students in both conditions learn domain knowledge
   Education, Multimedia Learning, Motivation
                                                                              equally well, participants in the passive condition show
                                                                              measurable gains over their active condition counterparts on
                           Introduction                                       measures of motivation; preparation for future learning; and
Many curricula incorporate software tutors, simulations, and                  attitudes and opinions of Alice.
computerized testing systems. Without adequate user
training, these technologies are at best inefficient and                                                Instruction
potentially ineffective. Since this can be users’ first
                                                                              For active training, we used the interactive tutorial that is
exposure to the software, it is also important to include both
                                                                              currently included in the version of Storytelling Alice
procedural training to familiarize users with the interface
                                                                              publicly available for download. In addition to serving as an
and motivational elements to encourage users to continue
                                                                              ecological control, the tutorial is a typical example of an
using the system. However, despite the importance and
                                                                              active training environment (Kelleher & Pausch, 2005). The
complexity of this training task, it is presently unknown
                                                                              tutorial's goals are to introduce the interface and to motivate
whether an active approach, like an interactive tutorial, or a
                                                                              potential users to continue using the program. The tutorial
passive approach, like an instructional video, is more
                                                                              uses a technology called stencils (Figure 1). Directions are
effective.
                                                                              displayed on-screen with floating yellow notes while semi-
   Research in attention suggests that interactivity improves
                                                                              transparent blue overlays (stencils) occlude irrelevant
student engagement (Bonwell & Eison, 1991), but evidence
                                                                              interface elements. The stencils direct attention to the
from the worked-examples literature (Clark & Mayer, 2003)
                                                                              important interface elements while limiting user actions to
and cognitive load theory (Sweller, 1988) suggest that well-
                                                                              those same elements. This makes it more difficult for users
designed passive training may lead to greater student
                                                                              to commit errors. However, in the event that a user does
learning. Generally, interactive instruction offers scaffolded
                                                                              make a mistake, they are immediately notified of the error
practice, immediate feedback, and allows the learner to
                                                                              and asked to repeat the step.
control the pace and the experience of using the system;
passive instruction offers fully worked and explained
examples, opportunities to self-evaluate, and prevents the
learner from engaging in poor time management and from
making confidence-destroying errors. Both approaches are
supported directly by theory and indirectly through
empirical evidence, but the choice between them is
ambiguous.
                                                                          715

                                                                    the active training condition where everything is presented
                                                                    visually.
                                                                        Table 1: Differences between instructional conditions
                                                                                              Interactive           Passive
                                                                                               Tutorial            Training
                                                                    Behavior               Doing               Watching
                                                                    Response to errors     Feedback            Error-free
                                                                    Modality               Reading             Listening
                                                                                           Methodology
                                                                    Participants
                                                                    Participants in the study were 35 adults (20 female, 15 male)
 Figure 1: Screen capture of the interactive tutorial. Students
                                                                    who responded to an online posting. The participants' mean
 read directions from the yellow notes and perform the steps
                                                                    age was 26.3 years (sd = 7.5), and on a self-report scale of
 themselves. Stencils (the blue overlays) focus attention and
                                                                    computer programming experience, the mean rating was 1.6
                      reduce student errors.
                                                                    (sd = 0.9) with one representing no computer programming
                                                                    experience and four representing extensive programming
   Our version of passive training was nearly identical to the
                                                                    experience. Participants were paid for their participation.
interactive tutorial. During active training, students read
instructions and then completed the tasks on their own;
                                                                    Experimental Design
during passive training, students watched a video screen
capture of an expert user completing those same steps. In           The overall study was constructed to appear as two separate
the video, there were no stencils and notes. Instead of             but related studies conducted by two separate researchers
reading notes, participants listened as the expert user             (see Figure 2). We will refer to these as Phase 1 and Phase
described her actions. The script for the passive training          2. When participants arrived, the first researcher described
video was created by copying the instructions displayed in          Phase 1 as an investigation of how best to teach Storytelling
the interactive tutorial, so the material covered in both           Alice. Phase 1 included a training session (either active or
training conditions was identical.                                  passive), a computerized assessment embedded in Alice, a
                                                                    paper assessment, and a survey, all administered by the first
Theoretical Predictions                                             researcher. The first researcher then told participants that
                                                                    the first study was finished and introduced them to the
The two forms of training varied on a variety of dimensions
                                                                    second researcher. The second researcher described the goal
(Table 1) with each dimension offering different theoretical
                                                                    of Phase 2 as an investigation of how interface affects
predictions on whether active or passive training would
                                                                    storytelling. While participants were lead to believe that
result in better learning. Active learning theory suggests that
                                                                    Phase 2 was a separate study, it was actually an empirical
students need to actually do the work. Listening is not
                                                                    measure of participant motivation. Phase 2 included several
sufficient; students need to engage with the material in order
                                                                    surveys as well as a general interaction segment. The two
to develop understanding (Bonwell & Eison, 1991). Thus,
                                                                    phases were conducted by separate researchers with separate
according to this line of work, students should learn more
                                                                    consent forms and separate final surveys.
from the interactive training than the passive training.
                                                                      Prior to their arrival, we sent participants a pre-study
Further, the interactive training follows one of the eight
                                                                    survey to determine their computer programming
cognitive tutor design principles and provides immediate
                                                                    experience and their attitudes towards computers and
feedback on student errors. Immediate feedback has been
                                                                    computer science. Upon arrival, the first researcher briefed
shown to make learning more efficient and help students
                                                                    participants on Phase 1, obtained consent, and randomly
diagnose their misunderstandings (Anderson, et al, 1995).
                                                                    assigned participants to either the active or passive training
   However, not all existing work points to the superiority of
                                                                    conditions. After the training, participants completed a
active training. Research on worked examples suggests that
                                                                    domain knowledge assessment embedded in Storytelling
studying worked examples is more efficient than problem
                                                                    Alice. The end product of the assessment was a functional
solving, especially for novices (Clark & Mayer, 2003). A
                                                                    Storytelling Alice program telling the story of The Three
cognitive theory of learning also suggests that passive
                                                                    Little Pigs. The embedded assessment had three segments
training may be better due to the modality effect (Mayer,
                                                                    (Embedded 1, Embedded 2, and Embedded 3) and after each
2001): the modality effect predicts that instruction presented
                                                                    segment, the first researcher opened a new Alice world so
both visually and orally, as in the passive training condition,
                                                                    errors in one segment would not impact other segments.
is better than instruction presented via only one mode, as in
                                                                    Embedded 1 involved adding specific characters to the
                                                                716

                     Figure 2: Presenting the experiment as two separate studies was slightly deceptive, but
                                     allowed us to measure student motivation empirically.
world and then positioning them according to instructions.         programs as often as they liked. After each of the 5-minute
Embedded 2 involved adding Storytelling Alice code to the          initial work periods, participants completed a brief survey
world. The tasks in Embedded 1 and Embedded 2 were                 about their experience with the given program. After the
covered during training. Embedded 3, however, featured             twenty-minute free time, participants completed a final
transfer tasks that were only related to, not identical to,        survey that asked them to compare the stories they made
those included in the training.                                    using Alice and PowerPoint. The survey also included
   After the embedded assessment, participants completed a         several questions assessing participant attitudes towards
paper-based assessment that included: opinions on                  computers and computer science.
Storytelling Alice, opinions on the training, interface
questions, and code interpretation questions. The first                                      Results
researcher then told participants that Phase 1 was over and
introduced the participant to the second researcher. At the        Interface Familiarity
beginning of Phase 2, participants had five minutes to skim        The first goal of Alice training is to familiarize users with
a packet containing all available Storytelling Alice               the interface. In the study, we included interface questions
characters and to brainstorm a story. The second researcher        on both the paper assessment and in the embedded Alice
asked participants to tell the same story in both Storytelling     assessment. The paper assessment included two types of
Alice and Microsoft PowerPoint™, and explained that                interface questions: five questions required participants to
images of the Storytelling Alice characters would be               label a window of the Alice interface, e.g. as the "World
available in PowerPoint. Participants were randomly                Window"; five questions asked participants to describe the
assigned to start with either PowerPoint or Alice. Since           purpose of a window, as shown in Figure 3. In both cases,
participants had recently completed the training in Phase 1,       participants were offered choices a, b, c, d, and e along with
they received no additional instruction. The second                a corresponding image of the interface component. For
researcher did provide all participants with a brief overview      these questions, there was no significant difference between
of PowerPoint, mostly focused on inserting pictures, text,         conditions. On the five labeling questions, active condition
and dialogue boxes. Participants worked with each                  participants averaged 4.35 questions correct; passive
application for five minutes. They then had twenty minutes         condition participants averaged 4.67 questions correct
of free choice: they could spend the whole time with Alice,        (p=0.407, two-sided t-test). On the five function questions,
the whole time with PowerPoint, or switch between the two          active condition participants averaged 3.00 questions
                                                               717

correct; passive condition participants averaged 3.17              to complete seven tasks: use the copy functionality on a line
questions correct (p=0.732, two-sided t-test).                     of code (abbreviated as “copy”), edit a method's text
                                                                   parameter (edit text), change an existing numeric parameter
                                                                   (edit numeric), add two walk methods with parameters (add
                                                                   parameters), create a loop (create loop), set the number of
                                                                   iterations for the loop (edit iterations), and place a set of
                                                                   commands into the loop in a specific order (order). The first
                                                                   four tasks were minor variations on training tasks. For
                                                                   example, during training, students added methods with a
                                                                   text parameter, but never edited one. The last three
                                                                   questions were more challenging and involved loops. The
                                                                   training covered do-together methods which, like loops, are
                                                                   compound constructs that include more than one line of
                                                                   code; unlike loops, do-togethers have no special iteration
                                                                   parameters or ordering requirements. The results are shown
                                                                   in Table 2. Students demonstrated impressive performance
                                                                   across conditions for the edit text, edit numeric, and add
                                                                   parameter tasks. They showed lower, but condition
Figure 3: In the paper assessment, participants were asked to      independent, performance on the copy task, which utilized
 identify the names of the windows of the interface and their      an aspect of the Alice interface that training did not cover in
                           function.                               detail. The most interesting results, however, were in the
                                                                   loop tasks. When asked to add a loop and then edit its
   In the embedded assessment, Embedded 1 asked students           number of iterations, participants in the passive training
to find certain characters in the Alice gallery, place them in     condition performed well (80% correct), but participants in
the world, and then position them according to instructions.       the active training condition were only correct half as often.
This test was largely an assessment of interface knowledge         The differences for both the create loop and edit iteration
and did not require any knowledge of any computer science          tasks are statistically significant (p=0.011 for the loop task;
or programming constructs: participants merely had to find         p=0.032 for the iterations task; Fisher's Exact Test).
and manipulate Alice characters. Out of 8 required steps in        Performance on the ordering task, which has no comparable
the first test, participants in the active training condition      training task, is near floor, but the passive condition
averaged 6.82 steps correct; passive condition participants        marginally outperforms the active condition (p=0.072).
averaged 6.17 questions correct (p=0.547, two-sided t-test).       However it is important to note that the three tasks are
                                                                   strongly correlated and should be treated as only one piece
Domain Knowledge                                                   of evidence. Still, participants in the passive condition
In addition to familiarizing users with the Alice interface,       perform at par with participants in the active condition on
one goal of training is to provide users with basic                the four near transfer tasks and dramatically outperform
programming knowledge. However, this is a secondary                their counterparts on the far transfer task(s).
goal and the training only addresses domain-specific
knowledge indirectly, so we limited our assessment to five               Table 2: Participant performance on transfer tasks
domain-knowledge questions drawn from previous studies                                   (Fisher's Exact Tests)
(Moskal, et al., 2004). For these questions, participants                                      * p < 0.1
were given a sample of Alice code and asked to evaluate                              Edit Edit       Add
what would happen if it were run. There were no significant                  Copy                            Loop* Iterate* Order*
                                                                                     Text Num Params
differences between conditions. In the active condition,
participants averaged 4.06 questions correct; in the passive        Active 0.44 0.88 0.75            0.81    0.38    0.38     0.06
condition, participants averaged 4.39 questions correct             Passive 0.57 0.93 0.93           0.93    0.86     0.79    0.36
(p=0.275, two-sided t-test). Most errors, regardless of             p-value 0.48 0.63 0.19           0.36    0.01     0.02    0.06
condition, were on the last and most difficult question.
Preparation for Future Learning
                                                                   Surveys
After the training, the goal is for users to continue
interacting with Alice for some period of time; thus, one          At the end of the first study, participants completed a survey
metric for successful training is how easy it is for users to      of their opinions about Alice and their opinions about the
acquire new Alice skills after completing the training. To         training they just received. The first five prompts were:
measure this preparation for future learning, Embedded 3           “Alice is confusing”, “Alice is cool”, “Alice is annoying”,
asked students to perform a series of tasks requiring skills       “Alice is easy to learn”, and “Alice is entertaining”.
not covered during training. The assessment asked students         Students were given 7-point Likert scales ranging from
                                                                   "Strongly Disagree" to "Strongly Agree". The results are
                                                               718

shown in Table 3. Only responses to "Alice is easy to learn"        averages very close to 3. There was no statistical difference
showed a significant difference between conditions.                 between conditions.
Participants in the passive condition stated a significantly
(p=0.026, t-test) higher agreement that Alice is easy to            Motivation
learn. Participants averaged a "Disagree" with the negative         An additional goal of Alice training is to motivate users to
statements and an "Agree" with the positive ones. On a              continue using Alice in the future. Our primary measure of
much later survey, participants responded to the prompt: "I         motivation was the free time assessment from Phase 2.
enjoy computer programming". Their responses were close             Students were given a choice between using Alice and using
to "Neither Agree nor Disagree", averaging about 3.6 on the         PowerPoint for a twenty-minute period. Active condition
7-point Likert scale. This suggests that students do not fully      participants spent an average of 68% of their time in Alice;
associate Alice, which they agree is entertaining, with             passive condition participants spent an average of 89% of
computer programming.                                               their time in Alice. The time participants spent in Alice is
                                                                    trending towards significant (p = 0.099, t-test) and suggests
    Table 3: Participant responses to a survey about Alice.         that the training condition does impact perceptions of Alice
          (1=Strongly Disagree, 7 = Strongly Agree)                 and desire to continue using it (Table 5). The motivation
                                                                    measure is empirical evidence that participants in the
                                           Easy to                  passive condition actually chose to spend more time in
           Confusing Cool Annoying                   Entertain.     Alice.
                                           Learn *
 Active       2.12      4.29       2.06      3.88       4.06
                                                                      Table 5: Percent of time spent using Alice and percent of
 Passive      2.00      4.00       1.94      4.56       3.93         students spending more time in Alice during the 20 minute
                                                                                          “free time” period
                                                                                                           % Students Spending
Participants also completed a survey of their opinions on the                   % Time Spent in Alice
                                                                                                           More Time in Alice
training using the same 7-point Likert scale as before. They
                                                                     Active              68%                       70%
received the following prompts: “I was able to write
programs in Alice”, “The instruction was fun to complete”,           Passive             89%                       89%
“I learned a lot from the instruction”, and “I could have
written programs in Alice without any instruction”. The                After each of the initial 5 minute periods, whether with
results are shown in Table 4. The responses are generally           Alice or PowerPoint, participants completed a short survey
ambivalent, with participants neither agreeing nor                  with three questions: “How easy or difficult was using
disagreeing that they can write programs, learned a lot from        Alice/PowerPoint to tell a story?”, “How fun or boring was
the instruction, and that the instruction was fun to complete.      using Alice/PowerPoint to tell a story?”, and “How pleased
Only one of the prompts elicited a marginally different             or displeased are you with your story at this point?” These
(p=0.061, two-sided t-test) response, with students in the          questions used a 7-point Likert scale ranging from “Very
active condition disagreeing more strongly with the                 Fun” to “Very Boring”, with the appropriate substitution of
statement, "I could have written programs in Alice without          terms. At the end of Phase 2, participants completed one
any instruction". This is interesting because, based on the         final survey. They were asked: “Which would you rather
earlier knowledge assessments, we know that participants in         use to tell stories?” and “If we were to share one of your
the passive condition learned the same or more from the             stories online, which would you prefer to share?” These
training than their active condition counterparts. Yet              two questions used a 7-point Likert scale ranging from
passive condition participants showed less agreement that           “Definitely Alice” to “Definitely PowerPoint”. None of the
they needed the instruction at all.                                 responses were statistically different between conditions.
                                                                    Overall, participants strongly preferred Alice on all but one
           Table 4: Participant views on the training               count, their relative contentment with their stories, about
          (1=Strongly Disagree, 7 = Strongly Agree)                 which they were ambivalent.
             Able to Write Learned Could Have Fun to
             Programs        a Lot      Written       Complete                              Conclusions
 Active      3.76            4 .00      2.29          3.53          While we found no differences between active and passive
                                                                    training on measures of interface familiarity, domain
 Passive     4.00            3.94       3.06          3.78
                                                                    knowledge, or near-transfer, we found significant
                                                                    differences on several measures. Participants who received
                                                                    passive training believed that Alice was easier to use, spent
We also offered participants the following two prompts: “I          more time using Alice when given the choice, and
am likely to pursue further study of computer                       demonstrated better preparation for future learning. We also
programming” and “I am likely to continue using Alice”.             found that passive training made participants believe the
Participants slightly disagreed to both prompts, with               training was less critical. Overall, it appears that passive
                                                                719

training offered several advantages over active training, but     (immediate feedback vs worked-examples), and training
without any corresponding disadvantages. This is especially       modality (reading vs listening). It would be invaluable to
significant since active training systems are more difficult      have future studies that separately tested training systems
and time consuming to build.                                      along each of these dimensions.
   There are several theoretical explanations for these
results. Under cognitive load theory, the passive training                          Acknowledgements
condition, having a lighter cognitive load, would engender        Special thanks to Jamie Jirout, Ken Koedinger, David Klahr,
participant beliefs that Alice was easier to learn and that       Tom Lauwers and the rest of the PIER community for their
training was not required. Further, perhaps the lighter           help and feedback on this project. The research reported
cognitive load allowed participants to notice interface           here was supported in part by the Institute of Education
elements during the training that were not explicitly covered     Sciences, U.S. Department of Education, through Grant
in the training. For example, participants in the passive         R305B040063 to Carnegie Mellon University.
training condition may have been more likely to notice the
loop widget, which is physically next to the do-together
widget and thus be more likely to successfully complete the
                                                                                         References
transfer tasks. Finally, the high confidence resulting from       Bonwell, C. & Eison, J. Active Learning: Creating
lower cognitive load could provide motivation to continue           Excitement in the Classroom. ASHE-ERIC Higher
using Alice over PowerPoint.                                        Education Report No. 1. Washington, D.C.: 1991.
   Another possible explanation is novelty. Alice may have        Clark, R. C., & Mayer, R. E. (2003). e-Learning and the
been perceived as easier to learn for the passive training          Science of Instruction : Proven Guidelines for Consumers
condition participants since their first hands-on experience        and Designers of Multimedia Learning. San Francisco:
with Alice was post-training; while active training condition       Jossey-Bass.
participants would have had potential frustrations and errors     Conway, M., et al. (1999) Alice: lessons learned from
during their training. This would also extend to the transfer       building a 3D system for novices. Proceedings, CHI 2000,
tasks. For passive condition participants, their early (post-       486-493.1998, 153-162.
training) experiences with Alice required searching for           Kelleher, C., & Pausch, R. (2005). Stencils-based Tutorials:
interface components because they had no stencils to guide          Design and Evaluation. Proceedings of the SIGCHI
them. This may have granted them a mastery of search not            conference on Human factors in computing systems (pp.
shared by their active condition counterparts, which could          541-550). New York: ACM Press.
yield improved performance on the loop task. This                 Mayer, R.E. (2001). Multimedia learning. London:
experience with self-driven learning may have diminished            Cambridge University Press.
the perceived gap between Alice, with which the                   Moskal, B. Lurie, D. & Cooper, S. (2004) Evaluating the
participants are relatively inexperienced, and PowerPoint,          effectiveness of a new instructional approach. SIGCSE
with which they are familiar.                                       2004: 75-79
   Unfortunately, our distinction between active and passive      Sweller, J. (1988). Cognitive load during problem solving:
training is confounded across several dimensions: user              Effects on learning. Cognitive Science, 12(2), 257-285
behavior (doing vs. watching), system response to errors
                                                              720

