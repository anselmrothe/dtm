UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An LDA Approach to the Neural Correlates of Configural Learning
Permalink
https://escholarship.org/uc/item/9hd4j7m0
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Blaha, Leslie
Busey, Thomas
Townsend, James
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

               An LDA Approach to the Neural Correlates of Configural Learning
         Leslie M. Blaha, Thomas A. Busey & James T. Townsend (lblaha, busey, jtownsen @indiana.edu)
                       Indiana University, Department of Psychological & Brain Sciences, 1101 E. 10th Street
                                                        Bloomington, IN 47405 USA
                              Abstract                                  for the occurrence of unitization already well established
   The purpose of our current study is to employ linear discrimi-       (Goldstone, 2000), Blaha and Townsend (Under Revision)
   nant analysis (LDA; Philiastides & Sajda, 2006) to character-        showed that unitization is characterized by a shift from ex-
   ize the changes in ERPs over the entire course of a perceptual       treme limited to extreme super capacity processing. The su-
   learning task. Configural learning is the perceptual learning
   process by which participants develop configural processing          per capacity at the end of training was predicted by Hebbian-
   strategies or representations characterized by extremely effi-       style feedback learning resulting in facilitatory parallel pro-
   cient parallel information processing (Blaha & Townsend, Un-         cessing. Hence, unitization results in the development of
   der Revision). Participants performed a perceptual unitization
   task in which they learned to categorize novel images. Cor-          configural processing mechanisms for initially novel visual
   rect categorization responses required exhaustive feature iden-      objects.
   tification, which encouraged unitization of images into unified         With our behavioral findings that configural learning re-
   object percepts. Linear discriminator accuracy, measured by
   Az , increased each day of training, showing significant differ-     sults in configural information processing mechanisms, we
   ences in neural signals between categories on and after training     would like to find converging evidence of neural configural
   day 3 or 4 for all participants. Additionally, the LDA training      processing mechanisms developing during configural learn-
   window starting time resulting in discriminator performance
   of 65% accuracy or better shifted from 450–500ms to 300ms            ing. Evidence from studies of both real-life and laboratory-
   after stimulus onset at the completion of training. LDA results      trained experts demonstrated N170 peak amplitude differ-
   are consistent with our earlier report (Blaha & Busey, 2007)         ences for the visual response to objects of expertise. Often
   of peak ERP amplitude differences between categories after
   training at approximately 170ms and 250ms after stimulus on-         these ERPs are similar to the responses to faces. Researchers
   set. Our EEG results are consistent with the hypothesis that         proposed that the neurological response of visual expertise
   perceptual unitization results in configural perceptual process-     engages configural processing strategies to which the N170 is
   ing mechanisms.
                                                                        sensitive (Busey & Vanderkolk, 2005). The N250 ERP com-
   Keywords: Linear Discriminant Analysis; Evoked Response
   Potential; Configural Processing; Perceptual Learning; Capac-        ponent has also demonstrated sensitivity to expertise training
   ity                                                                  and is sometimes referred to as a marker of visual expertise
                                                                        (Scott, Tanaka, Sheinberg, & Curran, 2006). Few studies,
                           Introduction                                 however, have closely examined the development of these
Configural learning is the process by which configural infor-           neural correlates of configural or expert processing.
mation processing mechanisms develop over the course of ex-                We propose that the observed changes in information pro-
tensive perceptual training. From the perspective of informa-           cessing over the course of configural learning should be ac-
tion processing, if an object is treated configurally, or as a          companied by changes in neurological measures of percep-
Gestalt, all the features are processed simultaneously and sta-         tion; in particular, we expect the N170 and N250 peak ampli-
tistically facilitate each others’ processing rates. Through this       tudes to change as configural object representations are de-
facilitation, the decisions made about all features are faster          veloped in our unitization learning task. Indeed, our prelimi-
than features made on any subset of features, indicating a              nary ERP analyses exhibited post-training differences in both
highly efficient use of information. In the formal terminology          the N170 and N250 peak amplitudes for objects processed
of human information processing models, we define config-               with configural mechanisms compared to non-configurally
ural mechanisms as a facilitatory parallel system exhibiting            processed objects (Blaha & Busey, 2007).
super capacity efficiency under an exhaustive stopping rule                However, peak ERP amplitude analyses limit our under-
(Wenger & Townsend, 2001). This system provides a well-                 standing of the configural learning process, because a large
defined model by which to examine mechanisms thought to                 amount of information about both the distribution of EEG re-
underlie both face processing and visual expertise.                     sponses within a single training session and the changes in
   Blaha and Townsend (Under Revision) proposed that the                these distributions across the days of training is lost through
result of configural learning is this facilitatory, parallel con-       the averaging of signals. Our behavioral model of learning,
figural processing model. To characterize the configural                namely the Capacity Coefficient, provides a fine-grained in-
learning process, Blaha and Townsend applied the Capac-                 dex over the response time (RT) distribution for each day of
ity Coefficient measure of work-load efficiency Townsend                configural learning. This enables an examination of process-
and Wenger (2004) to data from a perceptual unitization                 ing efficiency both within a single training session and across
learning task. Unitization is the perceptual learning mech-             the entire configural learning task. An analogous measure of
anism whereby people group or ”chunk together” smaller ob-              the EEG signal is needed to more thoroughly investigate the
ject features into fewer, larger perceptual features over train-        changes in the scalp potentials over the entire course of con-
ing (Goldstone, 1998, 2000). With the boundary conditions               figural learning.
                                                                    2540

   Sajda and colleagues (Parra, Spence, Gerson, & Sajda,
2005; Philiastides & Sajda, 2006) proposed an LDA approach
to EEG analysis that provides a means of investigating the
neural correlates of two-choice discrimination tasks. In a
study of face/car classification Philiastides and Sajda (2006)
identified two training windows for the linear discriminator
resulting in high classification performance. These windows,
centered around 170ms and 300ms after stimulus onset, in-
dicated two time points in the EEG signal that strongly dif-
ferentiated the input image information, providing a sort of
neural discrimination time for each trial.
   Our configural learning task is a categorization task in
which participants must learn to categorize a fixed set of novel
visual objects. The individual object features are grouped to-
gether so that correct Category 1 responses require exhaustive
processing of all features; configural learning mechanisms
develop for the objects belonging to this conjunctive category.
We apply the LDA tools of Sajda and colleagues on each day
of training to locate the time windows and electrode loca-
tions in which the EEG signal differentiates the categories.
As learning proceeds, we predict that the training windows           Figure 1: Example stimuli for both the conjunctive task (top)
differentiating the categories will shift earlier in time, indi-     and single-feature task (bottom). Each Category 2 object
cating faster and perhaps more efficient neural responses con-       contains a single segment different from the segments defin-
current with the emergence of the facilitatory, parallel, super      ing Category 1. Letters, not part of the training stimuli, are
capacity configural processing mechanisms.                           provided here to aid identification of individual squiggle seg-
                                                                     ments.
                           Method
Participants
Four members of the Indiana University, Bloomington, com-            Categorization Tasks
munity (2 male, 2 female), ages 20 to 24, volunteered for this
                                                                     Two different category structures were used for the catego-
study. All were right-handed with normal or corrected-to-
                                                                     rization tasks. Different sets of segments were used in the two
normal vision. Participants were monetarily compensated for
                                                                     tasks, so that the two tasks had no features, or entire objects,
their participation.
                                                                     in common. For the conjunctive task, Category 1 contained
Apparatus                                                            a single object, that is, a single set of five connected features
EEG was sampled at 32 channels at 1000Hz and downsam-                (see Figure 1, upper panel, left-hand side). Five objects be-
pled to 500Hz. It was amplified by a factor of 20,000 (Senso-        longed to Category 2, with each object having a single, unique
rium amps) and band-stop filtered at 58-62Hz. Signal record-         variation of the set of features contained in the Category 1 ob-
ing sites included a nose reference and a forehead ground. All       ject. That is, each Category 2 object had four features identi-
channels had below 5kΩ impedance, and recording was done             cal to those in Category 1 and one feature that differed from
inside a Faraday cage. Data were analyzed using the EEGLab           the Category 1 object. Each variation in Category 2 was made
toolbox (Delorme & Makeig, 2004).                                    with a new feature. Thus, Category 2 introduced five new fea-
   Images were shown on a 21in (53.34cm) Mitsubishi color            tures, with each new feature in a different position along the
monitor model THZ8155KL running at 120Hz. Images were                squiggly line segment. Consequently, no single feature was
approximately 44in (112cm) from the participant. Responses           diagnostic for the entire categorization task. Hence, a cor-
were collected with two buttons on an 8-button button box.           rect decision on Category 1 was a conjunctive categorization
                                                                     decision requiring the participant to exhaustively examine all
Stimuli                                                              features prior to making a response.
Novel visual objects were created by connecting five ‘squig-            The single-feature task only required the participant to find
gle’ line segments into a single ‘squiggly’ line. The five seg-      and identify a single diagnostic feature for correct categoriza-
ments were chosen randomly from sixteen possible segments.           tion. Depicted in Figure 1 (lower panel), the categories for the
Each segment measured 1cm in length, so the entire line mea-         single-feature task each contained a single five-feature item,
sured 5cm in length. The ends of this line segment were con-         completely different from any of the objects in the conjunc-
nected by a semicircle to create a closed object. Sample stim-       tive task. Here, however, the Category 2 object contained a
uli are pictured in Figure 1, with letters assigned here to each     single feature different from the Category 1 object, and the
segment for ease of reader identification.                           remaining four features were identical. For example, if we
                                                                 2541

labeled the five features in the Category 1 object ABCDE and          C(t) = 1 is predicted by an unlimited capacity independent
the single object in Category 2 contained features ABXYE,             parallel (UCIP) model, often referred to as standard paral-
then a correct decision could be made by simply identifying           lel processing. C(t) < 1 indicates limited capacity process-
the fourth feature.                                                   ing, wherein processing of features slowed as more features
                                                                      needed to be processed simultaneously. C(t) > 1 indicates
Procedure                                                             super capacity processing, meaning that additional features
Participants completed 14 experimental sessions, including 7          facilitated faster processing of all features.
training sessions of the conjunctive categorization task and
7 training sessions of the single-feature categorization task.        LDA
Each session consisted of 1200 trials broken into 8 blocks of
150 trials, lasting approximately one hour. Participants could        Following Philiastides and Sajda (2006) and Parra et al.
take breaks between any experimental blocks, with a manda-            (2005), we trained a linear discriminator by using logistic
tory break after completing 4 blocks. Over the 14 training            regression to identify optimal bases for discrimination be-
sessions, participants alternated between the conjunctive and         tween categories. A series of training windows were defined
single-feature tasks. Note that for the single-feature task, par-     for a duration of 10ms starting every 20ms over the 800ms
ticipants were randomly assigned to a critical feature condi-         epoch of EEG recording. A maximally discriminating spatial
tion. EEG recordings were done on every day of conjunctive            weighting vector wτ was estimated for each training window
categorization training and on only the first and last days of        and used to define ‘discriminating components’ y = wTτ X
single-feature categorization training. The remaining training        where X is the NxT data matrix (N sensors, T time points).
days of the single-feature task were only behavioral training
sessions.                                                                We can visualize the locus of the discriminating compo-
   EEG was recorded from 100ms prior to stimulus onset to             nents withe the coupling coefficients a = yXy  T y . Coupling co-
700ms after stimulus onset. Stimuli were centrally presented          efficients are the projection of the discriminating components
for 250ms and were replaced by a blank screen until the ear-          onto the scalp, illustrating the correlation of each electrode
lier of a button-press response or 5000ms. Auditory tone cor-         with y. That is, the coupling coefficients tell us the strength
rective feedback was given on each trial.                             of each electrode’s contribution to the discriminating compo-
   For both categorization tasks, participants were instructed        nents.
to simply decide the category membership of each object and              Linear discriminator performance was measured with
to use the auditory feedback to guide their decisions. They           Az , the nonparametric area under the receiver operating
were not told how to determine category membership, nor               characteristic curve. Note that LDA was applied to the
were they informed of the number of diagnostic features for           conjunctive task only.
any task.
Capacity Analyses
Workload capacity was measured with the Capacity Coeffi-
cient (Townsend & Wenger, 2004), which is defined by:
                                  Σni=1 Ki1 (t)
                     C(t) =
                                     K n (t)
where for j = 1, . . . , n simultaneously operating processing
                    R j
channels K j (t) = 0t Ff j(τ) dτ = log F j (t) is the conditional
                                                
                          (τ)
probability that processing finished at time t given that it fin-
ished at or before time t. F(t) = P(T ≤ t) is the empirical RT
cumulative distribution function (CDF). K(t) is analogous to
an integrated hazard function and can be interpreted as the
amount of work completed in t amount of time. Note that
in this study, n = 5, allowing one channel for each of the 5
features in the novel objects.
   The capacity coefficient is the ratio of the amount of work
completed in t time during the conjunctive processing of all
features to the summed amount of work completed in the
same time t completed on the processing of each feature in-
dividually. We estimate the numerator from the empirical RT
                                                                      Figure 2: C(t) results over all training days for Participant BS.
CDF from the single-feature task. The denominator is esti-
mated from the empirical RT CDF from the conjunctive task.
                                                                  2542

                                              Table 1: Individual Participant Results.
                     Training Day     Conjunctive         C(t)       Peak Az       Peak Az LDA           65% LDA
                                       Mean RT                                   Training Window     Training Window
                           1           366.68ms           Super      0.6149            60ms                 N/A
                           2           533.00ms           Super      0.6356           500ms                 N/A
                           3           818.92ms          Limited     0.7004           540ms                440ms
              AB           4           737.99ms         Unlimited    0.7815           440ms                340ms
                           5           697.13ms          Limited     0.7878           440ms                320ms
                           6           554.87ms           Super      0.7621           440ms                240ms
                           7           481.85ms           Super      0.7712           340ms                300ms
                           1           681.22ms          Limited     0.6140           620ms                 N/A
                           2           544.64ms           Super      0.6416           680ms                 N/A
                           3           595.10ms         Unlimited    0.6360           540ms                 N/A
              BS           4           510.95ms           Super      0.7271           640ms                440ms
                           5           505.68ms           Super      0.7207           540ms                360ms
                           6           477.68ms           Super      0.7620           560ms                300ms
                           7           472.74ms           Super      0.7222           460ms                360ms
                           1           523.75ms          Limited     0.6243           680ms                 N/A
                           2           537.13ms          Limited     0.6331           520ms                 N/A
                           3           547.32ms          Limited     0.6720           540ms                520ms
              DW           4           514.31ms         Unlimited    0.7043           500ms                400ms
                           5           483.38ms         Unlimited    0.7043           520ms                260ms
                           6           430.03ms           Super      0.7408           420ms                260ms
                           7           401.37ms           Super      0.7289           420ms                280ms
                           1           704.58ms          Limited     0.6284           540ms                 N/A
                           2           645.69ms          Limited     0.6658           560ms                540ms
                           3           536.18ms         Unlimited    0.6980           520ms                460ms
              PG           4           492.58ms           Super      0.6735           580ms                460ms
                           5           502.10ms           Super      0.7048           540ms                460ms
                           6           499.91ms           Super      0.7006           480ms                440ms
                           7           450.60ms           Super       0.736           520ms                380ms
                           Results                                    C(t) results. Both participants slowed their responses and
Individual participants’ C(t) and LDA analyses are summa-             reached ceiling accuracy, showing more limited C(t) values
rized in Table 1. All participants exhibited a significant de-        before shifting to super capacity configural processing.
crease in mean RT for both the conjunctive and single-feature
                                                                      LDA
category learning tasks. Accuracy on the single-feature task
was near ceiling for all participants on the first training day,      Linear discriminator performance was at least Az = 0.61 for
indicating immediate mastery of the single-feature task. Ac-          all participants on training days 1 and 2, indicating better-
curacy in the conjunctive task was initially approximately            than-chance discrimination. Peak Az values in Table 1 indi-
70% or better for all participants, improving to near ceiling         cate the optimal performance achieved by the linear discrim-
accuracy by the end of training.                                      inator on each training day. All participants reached a peak
                                                                      Az ≥ 0.74. Maximum discriminator accuracy was reached on
Capacity                                                              training day 6 or 7 for 3 participants, with Participant AB
C(t) results are summarized qualitatively in Table 1 and de-          reaching maximum Az on training day 5. Improvements in
picted for Participant BS in Figure 2. Most participants ex-          Az were strongly correlated with the improvements in overall
hibited limited capacity C(t) < 1 on at least the first two days.     task accuracy for all participants (AB r = 0.9447, p < 0.01;
C(t) then shifted to unlimited and super capacity C(t) > 1 on         BS r = 0.788, p < 0.05; DW r = 0.9394, p < 0.01; PG r =
the third or fourth day of training. All participants exhibited       0.8852, p < 0.01).
super capacity configural mechanisms at the end of training.             As shown in the upper panel of Figure 3, peak discriminat-
   Note that both AB and BS exhibited some early super ca-            ing components form at a late training window over the first
pacity values on training days 1 and/or 2 together with higher        few training days, and over learning the LDA training win-
error rates of 15-30%. This speed-accuracy tradeoff inflates          dow resulting in peak performance shifted earlier in time by
                                                                  2543

Figure 3: Top: Stimulus-locked discriminant component activity optimally differentiating Category 1 from Category 2 trials for
Participant BS. Each line represents the component activity for a single Category 1 trial. The trial average difference component
for Category 1 minus Category 2 is plotted below the component map. Empirical RT CDFs are superimposed on the component
maps. Stimulus onset is at 0ms (solid vertical line). The dashed vertical line indicates the LDA training window onset time
defining the optimally performing discriminator on each day. Bottom: Coupling coefficients of the optimal linear discriminator
projected onto the scalp electrode array.
at least 100ms for each participant. Scalp projections of these     not reach Az = 0.65. For all participants, the linear discrimi-
peak discriminating components, like those shown in Figure 3        nators reach the 0.65 threshold on the day before or the same
(bottom), indicate that sources strongly correlated with cat-       day they began to exhibit reliable unlimited or super capacity
egory discrimination shift to more posterior electrodes over        performance. Initially the threshold LDA training windows
training.                                                           were at 440ms to 540ms after stimulus onset, and these onset
   We note that in general, participants exhibited C(t) im-         times also shift earlier by approximately 100ms or more. For
provements when Az ≈ 0.65. If we consider 0.65 to be a              all participants, day 7 threshold LDA training window onset
threshold of strong linear discrimination, we can track the         times were approximately 250-400ms after stimulus onset.
earliest LDA training window on each training day at which
the Az ≥ 0.65. These times are listed in the last column of Ta-
ble 1. Note that N/A values indicate that the discriminator did
                                                                2544

                          Discussion                                                          References
                                                                     Blaha, L. M., & Busey, T. A. (2007, May). Electrophysio-
Our study is the first, to our knowledge, to employ LDA on             logical substrates of configural learning. In Vision sciences
single-trial EEG data on every day of a category learning ex-          society annual meeting. Sarasota, Florida.
periment. With the LDA we found multiple neural indicators           Blaha, L. M., & Townsend, J. T. (Under Revision). The
of learning, including improvements in discriminator accu-             capacity of configural learning: Perceptual unitization as
racy and changes in both the timing of strong neural discrim-          a mechanism for the development of configural perceptual
ination and the location of discriminating components scalp            representations.
sources.                                                             Busey, T. A., & Vanderkolk, J. R. (2005). Behavioral and
   Capacity Coefficient results replicated our finding that con-       electrophysiological evidence for configural processing fin-
figural learning is characterized by a qualitative shift from          gerprint experts. Vision Research, 45, 431-448.
limited to super capacity (Blaha & Townsend, Under Revi-             Delorme, A., & Makeig, S. (2004). Eeglab: An open source
sion). This confirms that people were not only learning to             toolbox for analysis of single-trial eeg dynamics including
categorize these novel objects, but they developed configu-            independent component analysis. Journal of Neuroscience
ral processing mechanisms for the Category 1 object, as pre-           Methods, 134, 9-21.
dicted.                                                              Goldstone, R. L. (1998). Perceptual learning. Annual Review
                                                                       of Psychology, 49, 585-612.
   LDA results exhibited several parallels to the behavioral
                                                                     Goldstone, R. L. (2000). Unitization during category learn-
findings. Overall accuracy correlated with human perfor-
                                                                       ing. Journal of Experimental Psychology: Human Percep-
mance, showing learning-related improvements over train-
                                                                       tion & Performance, 26, 86-112.
ing. We do note that LDA peak performance was not 100%
                                                                     Parra, L. C., Spence, C. D., Gerson, A. D., & Sajda, P. (2005).
like the behavioral data, indicating that both categories likely
                                                                       Recipes for the linear analysis of eeg. NeuroImage, 28,
share many neural substrates. It may be that more extensive
                                                                       326-341.
training, beyond our 3-week laboratory setting, would lead to
                                                                     Philiastides, M. G., & Sajda, P. (2006). Temporal character-
even more discriminating neural performance.
                                                                       ization of the neural correlates of perceptual decision mak-
   Importantly, we find a key parallel to our C(t) improve-            ing in the human brain. Cerebral Cortex, 16, 509-518.
ments in the time of both the peak and threshold LDA train-          Scott, L. S., Tanaka, J. W., Sheinberg, D. L., & Curran, T.
ing windows. Both measures showed shifts to earlier times              (2006). A reevaluation of the electrophysiological corre-
over training, consistent with improvements in processing ef-          lates of expert object processing. Journal of Cognitive Neu-
ficiency which result from faster RT distributions. Changes            roscience, 18, 1453-1465.
in the threshold LDA training window in particular mirrored          Townsend, J. T., & Wenger, M. J. (2004). A theory of in-
the shift from limited toward unlimited to super capacity per-         teractive parallel processing: New capacity measures and
formance. It could be that the Capacity Coefficient, mea-              predictions for a response time inequality series. Psycho-
suring work-load efficiency, is evidence of a more discrim-            logical Review, 111, 1003-1035.
inable neural signal associated with similar visual images or        Wenger, M. J., & Townsend, J. T. (2001). Computational,
that neural discrimination reflects the efficiency of informa-         geometric, and process perspectives on facial cognition. In
tion processing. More work is needed to find a direct way to           M. J. Wenger & J. T. Townsend (Eds.), (p. 229-284). Mah-
relate these two measures.                                             wah, NJ: Lawrence Erlbaum Associates.
   It is notable that the 0.65 threshold LDA training window
after training occurs in a time frame similar to the N250 ERP
component, which has been associated with the development
of visual expertise indexed by subordinate-level categoriza-
tion (Scott et al., 2006). The threshold discriminating com-
ponents found here may reflect the use of neural mechanisms
of expertise similar to those reflected in the N250 ERP ampli-
tude differences found for this task (Blaha & Busey, 2007),
providing converging evidence for the engagement of config-
ural mechanisms developed by configural learning.
                     Acknowledgments
This research was supported by NIH-NIMH Training Grant
T32 MH019879-11 and NSFGRF to L.M.B., NIH-NIMH
grant 1R03MH060619-01 to T.A.B., and NIH-NIMH grant
R01MH57717 to J.T.T.
                                                                 2545

