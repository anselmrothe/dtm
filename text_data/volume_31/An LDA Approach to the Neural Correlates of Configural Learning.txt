UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An LDA Approach to the Neural Correlates of Configural Learning

Permalink
https://escholarship.org/uc/item/9hd4j7m0

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Blaha, Leslie
Busey, Thomas
Townsend, James

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

An LDA Approach to the Neural Correlates of Configural Learning
Leslie M. Blaha, Thomas A. Busey & James T. Townsend (lblaha, busey, jtownsen @indiana.edu)
Indiana University, Department of Psychological & Brain Sciences, 1101 E. 10th Street
Bloomington, IN 47405 USA
Abstract
The purpose of our current study is to employ linear discriminant analysis (LDA; Philiastides & Sajda, 2006) to characterize the changes in ERPs over the entire course of a perceptual
learning task. Configural learning is the perceptual learning
process by which participants develop configural processing
strategies or representations characterized by extremely efficient parallel information processing (Blaha & Townsend, Under Revision). Participants performed a perceptual unitization
task in which they learned to categorize novel images. Correct categorization responses required exhaustive feature identification, which encouraged unitization of images into unified
object percepts. Linear discriminator accuracy, measured by
Az , increased each day of training, showing significant differences in neural signals between categories on and after training
day 3 or 4 for all participants. Additionally, the LDA training
window starting time resulting in discriminator performance
of 65% accuracy or better shifted from 450–500ms to 300ms
after stimulus onset at the completion of training. LDA results
are consistent with our earlier report (Blaha & Busey, 2007)
of peak ERP amplitude differences between categories after
training at approximately 170ms and 250ms after stimulus onset. Our EEG results are consistent with the hypothesis that
perceptual unitization results in configural perceptual processing mechanisms.
Keywords: Linear Discriminant Analysis; Evoked Response
Potential; Configural Processing; Perceptual Learning; Capacity

Introduction
Configural learning is the process by which configural information processing mechanisms develop over the course of extensive perceptual training. From the perspective of information processing, if an object is treated configurally, or as a
Gestalt, all the features are processed simultaneously and statistically facilitate each others’ processing rates. Through this
facilitation, the decisions made about all features are faster
than features made on any subset of features, indicating a
highly efficient use of information. In the formal terminology
of human information processing models, we define configural mechanisms as a facilitatory parallel system exhibiting
super capacity efficiency under an exhaustive stopping rule
(Wenger & Townsend, 2001). This system provides a welldefined model by which to examine mechanisms thought to
underlie both face processing and visual expertise.
Blaha and Townsend (Under Revision) proposed that the
result of configural learning is this facilitatory, parallel configural processing model. To characterize the configural
learning process, Blaha and Townsend applied the Capacity Coefficient measure of work-load efficiency Townsend
and Wenger (2004) to data from a perceptual unitization
learning task. Unitization is the perceptual learning mechanism whereby people group or ”chunk together” smaller object features into fewer, larger perceptual features over training (Goldstone, 1998, 2000). With the boundary conditions

for the occurrence of unitization already well established
(Goldstone, 2000), Blaha and Townsend (Under Revision)
showed that unitization is characterized by a shift from extreme limited to extreme super capacity processing. The super capacity at the end of training was predicted by Hebbianstyle feedback learning resulting in facilitatory parallel processing. Hence, unitization results in the development of
configural processing mechanisms for initially novel visual
objects.
With our behavioral findings that configural learning results in configural information processing mechanisms, we
would like to find converging evidence of neural configural
processing mechanisms developing during configural learning. Evidence from studies of both real-life and laboratorytrained experts demonstrated N170 peak amplitude differences for the visual response to objects of expertise. Often
these ERPs are similar to the responses to faces. Researchers
proposed that the neurological response of visual expertise
engages configural processing strategies to which the N170 is
sensitive (Busey & Vanderkolk, 2005). The N250 ERP component has also demonstrated sensitivity to expertise training
and is sometimes referred to as a marker of visual expertise
(Scott, Tanaka, Sheinberg, & Curran, 2006). Few studies,
however, have closely examined the development of these
neural correlates of configural or expert processing.
We propose that the observed changes in information processing over the course of configural learning should be accompanied by changes in neurological measures of perception; in particular, we expect the N170 and N250 peak amplitudes to change as configural object representations are developed in our unitization learning task. Indeed, our preliminary ERP analyses exhibited post-training differences in both
the N170 and N250 peak amplitudes for objects processed
with configural mechanisms compared to non-configurally
processed objects (Blaha & Busey, 2007).
However, peak ERP amplitude analyses limit our understanding of the configural learning process, because a large
amount of information about both the distribution of EEG responses within a single training session and the changes in
these distributions across the days of training is lost through
the averaging of signals. Our behavioral model of learning,
namely the Capacity Coefficient, provides a fine-grained index over the response time (RT) distribution for each day of
configural learning. This enables an examination of processing efficiency both within a single training session and across
the entire configural learning task. An analogous measure of
the EEG signal is needed to more thoroughly investigate the
changes in the scalp potentials over the entire course of configural learning.

2540

Sajda and colleagues (Parra, Spence, Gerson, & Sajda,
2005; Philiastides & Sajda, 2006) proposed an LDA approach
to EEG analysis that provides a means of investigating the
neural correlates of two-choice discrimination tasks. In a
study of face/car classification Philiastides and Sajda (2006)
identified two training windows for the linear discriminator
resulting in high classification performance. These windows,
centered around 170ms and 300ms after stimulus onset, indicated two time points in the EEG signal that strongly differentiated the input image information, providing a sort of
neural discrimination time for each trial.
Our configural learning task is a categorization task in
which participants must learn to categorize a fixed set of novel
visual objects. The individual object features are grouped together so that correct Category 1 responses require exhaustive
processing of all features; configural learning mechanisms
develop for the objects belonging to this conjunctive category.
We apply the LDA tools of Sajda and colleagues on each day
of training to locate the time windows and electrode locations in which the EEG signal differentiates the categories.
As learning proceeds, we predict that the training windows
differentiating the categories will shift earlier in time, indicating faster and perhaps more efficient neural responses concurrent with the emergence of the facilitatory, parallel, super
capacity configural processing mechanisms.

Method

Figure 1: Example stimuli for both the conjunctive task (top)
and single-feature task (bottom). Each Category 2 object
contains a single segment different from the segments defining Category 1. Letters, not part of the training stimuli, are
provided here to aid identification of individual squiggle segments.

Participants
Four members of the Indiana University, Bloomington, community (2 male, 2 female), ages 20 to 24, volunteered for this
study. All were right-handed with normal or corrected-tonormal vision. Participants were monetarily compensated for
their participation.

Apparatus
EEG was sampled at 32 channels at 1000Hz and downsampled to 500Hz. It was amplified by a factor of 20,000 (Sensorium amps) and band-stop filtered at 58-62Hz. Signal recording sites included a nose reference and a forehead ground. All
channels had below 5kΩ impedance, and recording was done
inside a Faraday cage. Data were analyzed using the EEGLab
toolbox (Delorme & Makeig, 2004).
Images were shown on a 21in (53.34cm) Mitsubishi color
monitor model THZ8155KL running at 120Hz. Images were
approximately 44in (112cm) from the participant. Responses
were collected with two buttons on an 8-button button box.

Stimuli
Novel visual objects were created by connecting five ‘squiggle’ line segments into a single ‘squiggly’ line. The five segments were chosen randomly from sixteen possible segments.
Each segment measured 1cm in length, so the entire line measured 5cm in length. The ends of this line segment were connected by a semicircle to create a closed object. Sample stimuli are pictured in Figure 1, with letters assigned here to each
segment for ease of reader identification.

Categorization Tasks
Two different category structures were used for the categorization tasks. Different sets of segments were used in the two
tasks, so that the two tasks had no features, or entire objects,
in common. For the conjunctive task, Category 1 contained
a single object, that is, a single set of five connected features
(see Figure 1, upper panel, left-hand side). Five objects belonged to Category 2, with each object having a single, unique
variation of the set of features contained in the Category 1 object. That is, each Category 2 object had four features identical to those in Category 1 and one feature that differed from
the Category 1 object. Each variation in Category 2 was made
with a new feature. Thus, Category 2 introduced five new features, with each new feature in a different position along the
squiggly line segment. Consequently, no single feature was
diagnostic for the entire categorization task. Hence, a correct decision on Category 1 was a conjunctive categorization
decision requiring the participant to exhaustively examine all
features prior to making a response.
The single-feature task only required the participant to find
and identify a single diagnostic feature for correct categorization. Depicted in Figure 1 (lower panel), the categories for the
single-feature task each contained a single five-feature item,
completely different from any of the objects in the conjunctive task. Here, however, the Category 2 object contained a
single feature different from the Category 1 object, and the
remaining four features were identical. For example, if we

2541

C(t) = 1 is predicted by an unlimited capacity independent
parallel (UCIP) model, often referred to as standard parallel processing. C(t) < 1 indicates limited capacity processing, wherein processing of features slowed as more features
needed to be processed simultaneously. C(t) > 1 indicates
super capacity processing, meaning that additional features
facilitated faster processing of all features.

labeled the five features in the Category 1 object ABCDE and
the single object in Category 2 contained features ABXYE,
then a correct decision could be made by simply identifying
the fourth feature.

Procedure
Participants completed 14 experimental sessions, including 7
training sessions of the conjunctive categorization task and
7 training sessions of the single-feature categorization task.
Each session consisted of 1200 trials broken into 8 blocks of
150 trials, lasting approximately one hour. Participants could
take breaks between any experimental blocks, with a mandatory break after completing 4 blocks. Over the 14 training
sessions, participants alternated between the conjunctive and
single-feature tasks. Note that for the single-feature task, participants were randomly assigned to a critical feature condition. EEG recordings were done on every day of conjunctive
categorization training and on only the first and last days of
single-feature categorization training. The remaining training
days of the single-feature task were only behavioral training
sessions.
EEG was recorded from 100ms prior to stimulus onset to
700ms after stimulus onset. Stimuli were centrally presented
for 250ms and were replaced by a blank screen until the earlier of a button-press response or 5000ms. Auditory tone corrective feedback was given on each trial.
For both categorization tasks, participants were instructed
to simply decide the category membership of each object and
to use the auditory feedback to guide their decisions. They
were not told how to determine category membership, nor
were they informed of the number of diagnostic features for
any task.

LDA
Following Philiastides and Sajda (2006) and Parra et al.
(2005), we trained a linear discriminator by using logistic
regression to identify optimal bases for discrimination between categories. A series of training windows were defined
for a duration of 10ms starting every 20ms over the 800ms
epoch of EEG recording. A maximally discriminating spatial
weighting vector wτ was estimated for each training window
and used to define ‘discriminating components’ y = wTτ X
where X is the NxT data matrix (N sensors, T time points).
We can visualize the locus of the discriminating components withe the coupling coefficients a = yXy
T y . Coupling coefficients are the projection of the discriminating components
onto the scalp, illustrating the correlation of each electrode
with y. That is, the coupling coefficients tell us the strength
of each electrode’s contribution to the discriminating components.
Linear discriminator performance was measured with
Az , the nonparametric area under the receiver operating
characteristic curve. Note that LDA was applied to the
conjunctive task only.

Capacity Analyses
Workload capacity was measured with the Capacity Coefficient (Townsend & Wenger, 2004), which is defined by:
C(t) =

Σni=1 Ki1 (t)
K n (t)

where for j = 1, . . . , n simultaneously operating processing

R j
channels K j (t) = 0t Ff j(τ)
dτ = log F j (t) is the conditional
(τ)
probability that processing finished at time t given that it finished at or before time t. F(t) = P(T ≤ t) is the empirical RT
cumulative distribution function (CDF). K(t) is analogous to
an integrated hazard function and can be interpreted as the
amount of work completed in t amount of time. Note that
in this study, n = 5, allowing one channel for each of the 5
features in the novel objects.
The capacity coefficient is the ratio of the amount of work
completed in t time during the conjunctive processing of all
features to the summed amount of work completed in the
same time t completed on the processing of each feature individually. We estimate the numerator from the empirical RT
CDF from the single-feature task. The denominator is estimated from the empirical RT CDF from the conjunctive task.

Figure 2: C(t) results over all training days for Participant BS.

2542

Table 1: Individual Participant Results.
Training Day

AB

BS

DW

PG

1
2
3
4
5
6
7
1
2
3
4
5
6
7
1
2
3
4
5
6
7
1
2
3
4
5
6
7

Conjunctive
Mean RT
366.68ms
533.00ms
818.92ms
737.99ms
697.13ms
554.87ms
481.85ms
681.22ms
544.64ms
595.10ms
510.95ms
505.68ms
477.68ms
472.74ms
523.75ms
537.13ms
547.32ms
514.31ms
483.38ms
430.03ms
401.37ms
704.58ms
645.69ms
536.18ms
492.58ms
502.10ms
499.91ms
450.60ms

C(t)

Peak Az

Super
Super
Limited
Unlimited
Limited
Super
Super
Limited
Super
Unlimited
Super
Super
Super
Super
Limited
Limited
Limited
Unlimited
Unlimited
Super
Super
Limited
Limited
Unlimited
Super
Super
Super
Super

0.6149
0.6356
0.7004
0.7815
0.7878
0.7621
0.7712
0.6140
0.6416
0.6360
0.7271
0.7207
0.7620
0.7222
0.6243
0.6331
0.6720
0.7043
0.7043
0.7408
0.7289
0.6284
0.6658
0.6980
0.6735
0.7048
0.7006
0.736

Results
Individual participants’ C(t) and LDA analyses are summarized in Table 1. All participants exhibited a significant decrease in mean RT for both the conjunctive and single-feature
category learning tasks. Accuracy on the single-feature task
was near ceiling for all participants on the first training day,
indicating immediate mastery of the single-feature task. Accuracy in the conjunctive task was initially approximately
70% or better for all participants, improving to near ceiling
accuracy by the end of training.

Capacity
C(t) results are summarized qualitatively in Table 1 and depicted for Participant BS in Figure 2. Most participants exhibited limited capacity C(t) < 1 on at least the first two days.
C(t) then shifted to unlimited and super capacity C(t) > 1 on
the third or fourth day of training. All participants exhibited
super capacity configural mechanisms at the end of training.
Note that both AB and BS exhibited some early super capacity values on training days 1 and/or 2 together with higher
error rates of 15-30%. This speed-accuracy tradeoff inflates

Peak Az LDA
Training Window
60ms
500ms
540ms
440ms
440ms
440ms
340ms
620ms
680ms
540ms
640ms
540ms
560ms
460ms
680ms
520ms
540ms
500ms
520ms
420ms
420ms
540ms
560ms
520ms
580ms
540ms
480ms
520ms

65% LDA
Training Window
N/A
N/A
440ms
340ms
320ms
240ms
300ms
N/A
N/A
N/A
440ms
360ms
300ms
360ms
N/A
N/A
520ms
400ms
260ms
260ms
280ms
N/A
540ms
460ms
460ms
460ms
440ms
380ms

C(t) results. Both participants slowed their responses and
reached ceiling accuracy, showing more limited C(t) values
before shifting to super capacity configural processing.

LDA
Linear discriminator performance was at least Az = 0.61 for
all participants on training days 1 and 2, indicating betterthan-chance discrimination. Peak Az values in Table 1 indicate the optimal performance achieved by the linear discriminator on each training day. All participants reached a peak
Az ≥ 0.74. Maximum discriminator accuracy was reached on
training day 6 or 7 for 3 participants, with Participant AB
reaching maximum Az on training day 5. Improvements in
Az were strongly correlated with the improvements in overall
task accuracy for all participants (AB r = 0.9447, p < 0.01;
BS r = 0.788, p < 0.05; DW r = 0.9394, p < 0.01; PG r =
0.8852, p < 0.01).
As shown in the upper panel of Figure 3, peak discriminating components form at a late training window over the first
few training days, and over learning the LDA training window resulting in peak performance shifted earlier in time by

2543

Figure 3: Top: Stimulus-locked discriminant component activity optimally differentiating Category 1 from Category 2 trials for
Participant BS. Each line represents the component activity for a single Category 1 trial. The trial average difference component
for Category 1 minus Category 2 is plotted below the component map. Empirical RT CDFs are superimposed on the component
maps. Stimulus onset is at 0ms (solid vertical line). The dashed vertical line indicates the LDA training window onset time
defining the optimally performing discriminator on each day. Bottom: Coupling coefficients of the optimal linear discriminator
projected onto the scalp electrode array.
at least 100ms for each participant. Scalp projections of these
peak discriminating components, like those shown in Figure 3
(bottom), indicate that sources strongly correlated with category discrimination shift to more posterior electrodes over
training.
We note that in general, participants exhibited C(t) improvements when Az ≈ 0.65. If we consider 0.65 to be a
threshold of strong linear discrimination, we can track the
earliest LDA training window on each training day at which
the Az ≥ 0.65. These times are listed in the last column of Table 1. Note that N/A values indicate that the discriminator did

not reach Az = 0.65. For all participants, the linear discriminators reach the 0.65 threshold on the day before or the same
day they began to exhibit reliable unlimited or super capacity
performance. Initially the threshold LDA training windows
were at 440ms to 540ms after stimulus onset, and these onset
times also shift earlier by approximately 100ms or more. For
all participants, day 7 threshold LDA training window onset
times were approximately 250-400ms after stimulus onset.

2544

Discussion

References

Our study is the first, to our knowledge, to employ LDA on
single-trial EEG data on every day of a category learning experiment. With the LDA we found multiple neural indicators
of learning, including improvements in discriminator accuracy and changes in both the timing of strong neural discrimination and the location of discriminating components scalp
sources.
Capacity Coefficient results replicated our finding that configural learning is characterized by a qualitative shift from
limited to super capacity (Blaha & Townsend, Under Revision). This confirms that people were not only learning to
categorize these novel objects, but they developed configural processing mechanisms for the Category 1 object, as predicted.
LDA results exhibited several parallels to the behavioral
findings. Overall accuracy correlated with human performance, showing learning-related improvements over training. We do note that LDA peak performance was not 100%
like the behavioral data, indicating that both categories likely
share many neural substrates. It may be that more extensive
training, beyond our 3-week laboratory setting, would lead to
even more discriminating neural performance.
Importantly, we find a key parallel to our C(t) improvements in the time of both the peak and threshold LDA training windows. Both measures showed shifts to earlier times
over training, consistent with improvements in processing efficiency which result from faster RT distributions. Changes
in the threshold LDA training window in particular mirrored
the shift from limited toward unlimited to super capacity performance. It could be that the Capacity Coefficient, measuring work-load efficiency, is evidence of a more discriminable neural signal associated with similar visual images or
that neural discrimination reflects the efficiency of information processing. More work is needed to find a direct way to
relate these two measures.

Blaha, L. M., & Busey, T. A. (2007, May). Electrophysiological substrates of configural learning. In Vision sciences
society annual meeting. Sarasota, Florida.
Blaha, L. M., & Townsend, J. T. (Under Revision). The
capacity of configural learning: Perceptual unitization as
a mechanism for the development of configural perceptual
representations.
Busey, T. A., & Vanderkolk, J. R. (2005). Behavioral and
electrophysiological evidence for configural processing fingerprint experts. Vision Research, 45, 431-448.
Delorme, A., & Makeig, S. (2004). Eeglab: An open source
toolbox for analysis of single-trial eeg dynamics including
independent component analysis. Journal of Neuroscience
Methods, 134, 9-21.
Goldstone, R. L. (1998). Perceptual learning. Annual Review
of Psychology, 49, 585-612.
Goldstone, R. L. (2000). Unitization during category learning. Journal of Experimental Psychology: Human Perception & Performance, 26, 86-112.
Parra, L. C., Spence, C. D., Gerson, A. D., & Sajda, P. (2005).
Recipes for the linear analysis of eeg. NeuroImage, 28,
326-341.
Philiastides, M. G., & Sajda, P. (2006). Temporal characterization of the neural correlates of perceptual decision making in the human brain. Cerebral Cortex, 16, 509-518.
Scott, L. S., Tanaka, J. W., Sheinberg, D. L., & Curran, T.
(2006). A reevaluation of the electrophysiological correlates of expert object processing. Journal of Cognitive Neuroscience, 18, 1453-1465.
Townsend, J. T., & Wenger, M. J. (2004). A theory of interactive parallel processing: New capacity measures and
predictions for a response time inequality series. Psychological Review, 111, 1003-1035.
Wenger, M. J., & Townsend, J. T. (2001). Computational,
geometric, and process perspectives on facial cognition. In
M. J. Wenger & J. T. Townsend (Eds.), (p. 229-284). Mahwah, NJ: Lawrence Erlbaum Associates.

It is notable that the 0.65 threshold LDA training window
after training occurs in a time frame similar to the N250 ERP
component, which has been associated with the development
of visual expertise indexed by subordinate-level categorization (Scott et al., 2006). The threshold discriminating components found here may reflect the use of neural mechanisms
of expertise similar to those reflected in the N250 ERP amplitude differences found for this task (Blaha & Busey, 2007),
providing converging evidence for the engagement of configural mechanisms developed by configural learning.

Acknowledgments
This research was supported by NIH-NIMH Training Grant
T32 MH019879-11 and NSFGRF to L.M.B., NIH-NIMH
grant 1R03MH060619-01 to T.A.B., and NIH-NIMH grant
R01MH57717 to J.T.T.

2545

