UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Hyperlearning: A Connectionist Model of Psychosis in Schizophrenia
Permalink
https://escholarship.org/uc/item/31d5h9qq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Grasemann, Uli
Hoffman, Ralph
Miikkulainen, Risto
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            Hyperlearning: A Connectionist Model of Psychosis in Schizophrenia
                                         Uli Grasemann                        Risto Miikkulainen
                                  Department of Computer Sciences, The University of Texas at Austin
                                                         {uli, risto}@cs.utexas.edu
                                                               Ralph Hoffman
                                     Department of Psychiatry, Yale University School of Medicine
                                                           ralph.hoffman@yale.edu
                               Abstract                                   clinical research, the brain processes underlying these and
   Abnormal brain processes that underlie schizophrenia are in-           other symptoms of schizophrenia remain incompletely under-
   completely understood. Diagnosis of this disorder relies in            stood (Harrison, 1999). Only recently, theories have begun to
   large part on psychotic symptoms that are observed through             emerge that have the potential to explain how abnormalities
   conversational language. In this paper, two such symptoms,
   delusions (fixed false beliefs) and derailments (inability to fol-     at the brain level might lead to the emergence of symptoms.
   low a coherent discourse plan) are modeled using DISCERN,                 One recent theory, put forth by Kapur (2003), is based
   a connectionist model of human story processing. Simulations           on the view that dopamine (DA) mediates the significance,
   of alternative pathologies thought to underlie schizophrenia are
   applied to DISCERN, and the resulting language abnormalities           or “salience”, of subjective experience (Berridge & Robin-
   are evaluated for symptoms of schizophrenia. “Hyperlearn-              son, 1998). Kapur proposes that in schizophrenia, an over-
   ing”, a simulation of excessive dopamine release, is shown to          abundance of midbrain DA leads to a pathological enhance-
   produce a compelling model for both delusional and derailed
   language. Applied to different locations in the model, hyper-          ment of salience, which in turn causes psychotic symptoms.
   learning led to different symptoms, suggesting how clinical            Delusions, for example, are explained as secondary reactions
   subtypes of schizophrenia could arise from a common under-             to an altered experience of the world — i.e. as an attempt
   lying process.
                                                                          by the brain to make sense of the excessive significance as-
   Keywords: Neural Networks; Schizophrenia; Natural Lan-                 signed to insignificant events. The theory that some symp-
   guage Processing.
                                                                          toms of schizophrenia are caused by excessive salience has
                          Introduction                                    been widely endorsed in the psychiatric literature, and forms
No current laboratory or imaging technique can reliably iden-             the theoretical basis of the present computational study.
tify individuals with schizophrenia. Instead, diagnosis of this              Excessive salience (and thus excessive DA release) was
disorder relies on symptoms observed in clinical interviews               simulated in a neural network model of human story process-
using conversational language. The symptoms of schizophre-                ing using artificially high network learning rates. In contrast
nia are complex and span a wide range of altered behavior                 to other network disturbances, this “hyperlearning” simula-
and perception. The present study focuses on delusions and                tion was shown to produce a compelling model for both delu-
derailment, two psychotic symptoms that play an important                 sional and derailed language.
role in diagnosing patients with schizophrenia.                                                     Approach
   Delusions, a major characteristic of the “paranoid type”               The approach taken in the present study is based on DIS-
of schizophrenia, can take many different forms. In gen-                  CERN (Miikkulainen, 1993; Fidelman, Miikkulainen, &
eral, delusions are are fixed false beliefs that cannot be                Hoffman, 2005; Grasemann, Miikkulainen, & Hoffman,
changed through rational refutation. Delusions in schizo-                 2007), a neural network model of human story processing.
phrenia occur in more than 60% of patients, and often have                Simulations of alternative pathologies thought to underlie
grandiose or paranoid content (Harrow et al., 2004; Apple-                schizophrenia, including “hyperlearning”, a model of exces-
baum, Clark Robbins, & Roth, 1999), i.e. a patient might                  sive salience, were applied to the model. The resulting lan-
believe that he is the lost son of John Lennon, or that he is             guage disturbances in DISCERN were then evaluated for
being monitored by the CIA. In this way, delusions in schizo-             characteristic signs of delusions and derailments in schizo-
phrenia often insert the self or persons close to the patient into        phrenia.
rigid, implausible or bizarre narrative schemata.                            Several computational studies in the past were based on
   Derailment behavior, the second focus of the present study,            similar approaches. Hoffman (1987) and Ruppin, Reggia,
is fluent speech that fails to adhere to an organizing topic or           and Horn (1996), for example, propose models of psychotic
frame of reference (Bleuler, 1911; Andreasen, 1979). When                 symptoms based on attractor networks. Cohen and colleagues
telling a story, for example, a patient may repeatedly skip to            (Cohen & Servan-Schreiber, 1992; Braver, Barch, & Cohen,
other unrelated stories, leaving the listener in a bewildered             1999) focus on modeling behavioral deficits and cognitive
state. Derailments often occur in “disorganized type” schizo-             impairment based on a neural network-based model of the
phrenia, where symptoms are dominated by disorganized lan-                frontal cortex. Spitzer (1997) uses self-organizing maps to
guage and behavior.                                                       simulate aspects of disturbed lexical access in schizophre-
   Establishing the brain processes that lead to delusions and            nia. Finally, Hoffman and colleagues (1997; 2006) investi-
derailment in schizophrenia would greatly advance our un-                 gate mechanisms by which hallucinations can arise in speech
derstanding of this disorder. Yet after almost a century of               perception networks.
                                                                      224

                         Input text    Output text                       [$job Vito Mafia head likes New-York famous gangster]
                                                                         Vito is a gangster.                   [Vito is _ _ gangster]
                                                                         Vito is the head of the Mafia.        [Vito is Mafia _ head]
                                                                         Vito works in New-York.               [Vito works New-York _ _]
             Sentence             Lexicon          Sentence
               Parser                              Generator
                                                                         Vito likes his job.                   [Vito likes _ his job]
                                                                         Vito is a famous gangster.            [Vito is _ famous gangster]
                                                                         [$driving Vito _ scared airport LA recklessly _]
                                                                         Vito wants to go to LA.               [Vito wants LA goes _]
                                                                         Vito enters his car.                  [Vito enters _ his car]
               Story      Memory          Episodic   Story               Vito drives to the airport.           [Vito drives airport _ _]
              Parser      Encoder         Memory   Generator             Vito is scared.                       [Vito is _ _ scared]
                                                                         Vito drives recklessly.               [Vito drives _ _ recklessly]
                                                                         [$pulled-over Vito cop arrests _ murder _ _]
Figure 1: DISCERN is a neural network model of story understand-         Vito is pulled-over by a cop.         [Vito is cop _ pulled-over]
ing and recall. The task of understanding and reproducing a story is     The cop asks Vito for his license. [Cop asks license his Vito]
achieved by a chain of neural network modules, each building on the      Vito gives his license to The cop. [Vito gives cop his license]
results of the previous module and providing input for the next.         The cop checks the license.           [Cop checks _ _ license]
                                                                         The cop arrests Vito for murder.      [Cop arrests murder _ Vito]
                                                                         [$trial Vito _ walks clears free murder good]
   The most important way in which DISCERN differs from                  Vito is accused of murder.            [Vito is murder _ accused]
                                                                         Vito is brought before the court. [Vito is court _ brought]
these previous models is the level of behavior at which symp-            Vito has a good lawyer.               [Vito has _ good lawyer]
toms are observed. Using a model of human story processing               The court clears Vito of murder.      [Court clears murder _ Vito]
                                                                         Vito walks free.                      [Vito walks _ free _]
makes it possible to observe the effects of network distur-
bances at the level of conversational language — the same                Figure 2: An example input story about a gangster getting arrested
                                                                         for a crime committed earlier. The story consists of four scripts: the
level at which the clinical symptoms that define schizophre-             slots of each script are on top, followed by the sentences of the script
nia are diagnosed.                                                       (left) and their static representations used by DISCERN (right). Dur-
   The remainder of this section first gives a brief overview of         ing story understanding, DISCERN translates such stories from in-
                                                                         dividual words to sentence representations, slot-based script repre-
DISCERN, and then discusses the network disturbances used                sentations, and finally episodic memory traces. Story recall reverses
to model possible causes of schizophrenic symptoms.                      this process.
The DISCERN Model                                                           The modules in DISCERN communicate using distributed
DISCERN is a neural network-based model of human story                   representations of word meanings, i.e. fixed-size patterns of
understanding and recall. Stories in DISCERN are sequences               neuron activations, stored in a central lexicon. These repre-
of scripts – stereotypical event sequences that can be adapted           sentations are learned based on how the words are used in the
to match specific situations. A classic example for a script             example stories, using the FGREP algorithm (Miikkulainen,
is visiting a restaurant: The sequence of events (i.e. waiting           1993), a modified version of backpropagation that treats input
to be seated, ordering, etc.) usually stays the same, and can            representations as an additional layer of weights.
be adapted to match a specific restaurant visit by filling in               Words in the input text are first presented to the lexicon,
open slots such as the type of restaurant or the kind of food.           which translates them into word representations. The repre-
Using scripts, specific events (called script instances) can be          sentations are then passed on to the sentence parser one word
understood and remembered by storing only the type of script             at a time. The sentence parser builds a static representation
they follow and the concepts filling the script’s slots.                 of each sentence as it comes in. At the end of each sentence,
   In DISCERN, the task of understanding, recalling, and                 that representation, which consists of a concatenation of word
then paraphrasing a story is achieved by a chain of modules,             representations, is passed on to the story parser. The story
each building on the results of the last module in the chain,            parser in turn transforms a sequence of sentences into a static
and providing input for the next. The modules consist of sim-            representation of a script, simultaneously building a represen-
ple recurrent or feedforward neural networks that are trained            tation of the story’s emotional context. Script representations
with backpropagation and linked together to form the final               are called slot-filler representations, because they consist of a
system, as shown in Figure 1.                                            representation for the name for the script (the words starting
   DISCERN reads and produces natural language. Each                     with $ in Figure 2) and a sequence of concepts filling its slots.
story consists of a sequence of scripts, but is presented to the            At this point, the internal representation of a story consists
system in plain text, one word at a time. While DISCERN                  of its emotional context and a list of slot-filler representa-
understands and recalls the story, it is at different times repre-       tions, one for each script in the story. The memory encoder
sented at the level of words, sentences, scripts, and episodic           turns this representation into a string of episodic memories
memories. Figure 2 shows an example story and the represen-              that can be successively recalled and reproduced by the story
tations used by DISCERN to encode the individual scripts.                generator. This behavior is achieved using Recursive Auto-
Each story in DISCERN is associated with an emotional con-               Associative Memory, or RAAM (Pollack, 1990), a neural net-
text, represented as a pattern of neuron activations that en-            work architecture that forms fixed-size distributed represen-
codes either positive, negative or neutral emotional tone. The           tations of recursive data structures like lists or trees.
emotion of a story plays an important role in story memory                  The representations of script sequences produced by the
and recall, affecting the system’s choice between alternative            memory encoder are later used by the story generator as
continuations of a story.                                                memory cues to address the episodic memory.
                                                                     225

   With the episodic memory in place, the system is now              iments reported below, hyperlearning was therefore used as a
ready to recall the stories that were presented to it earlier.       first approximation to modeling Kapur’s theory.
The story generator module is cued with the first memory in             Hyperlearning was applied separately to DISCERN’s
each story, then called repeatedly, producing a representation       memory encoder network and to its story and sentence gener-
for a sentence each time, until it outputs a special “end of         ators, reflecting the possible impact of increased salience on
story” pattern. In addition to the next sentence, every cycle        episodic memory encoding and recall.
of the story generator produces a cue to the episodic memory            Additionally, a range of other network disturbances were
that determines the next input. A memory cue consists of the         investigated for comparison. First, loss of cortical connectiv-
compressed version of the rest of the current story.                 ity was modeled in DISCERN by removing connections in
   While the story generator produces sentences belonging to         the story generator or memory encoder networks whose ab-
the same script, the memory cue stays the same. Then, at the         solute weights were below a threshold. Following the theory
same time the last sentence of a script is produced, the cue         that symptoms in schizophrenia may be the result of brain
changes, and the input is replaced by a memory of the next           processes that try to compensate for lost connectivity, prun-
script. In this way, the story generator steps through each          ing was investigated both by itself and in combination with
sentence of a story, and recalls each memory encoding it.            additional backpropagation learning.
   Finally the sentence generator, last in the chain, takes the         Noise contamination of working memory, intended to
static sentence representations produced by the story genera-        model impaired processing of context associated with schizo-
tor and turns them back into a sequence of individual words.         phrenia, was simulated by adding increasing levels of noise to
The system then outputs plain text translations of these words       the context layer of the story generator during each cycle.
as provided by the lexicon.                                             Finally, impaired lexical access, thought to underlie lan-
Modeling Impaired Story Processing                                   guage disorganization in schizophrenia, was modeled by
                                                                     adding noise to the word representations in the lexicon.
DISCERN’s architecture is complex and provides a wide
range of opportunities to simulate pathological brain pro-                                    Experiments
cesses and observe their effects. The main focus of this work        The experiments reported below are based on a set of 28
is Kapur’s (2003) theory that psychotic symptoms in schizo-          hand-coded input stories. The stories ranged between three
phrenia are the result of excessive salience.                        and seven scripts long and were divided into two groups: The
   Within Kapur’s framework, excessive salience is assumed           first group described normal experiences in the daily life of
to be caused by increased midbrain DA release. However,              a “Self” character, a person that was overrepresented in the
since the theory does not build on a detailed physiological          corpus to simulate the one experiencing and reproducing the
model, brain processes by which increased salience may in            stories. This part of the corpus included stories with a nega-
turn cause psychotic symptoms remain necessarily abstract:           tive emotional tone, such as the self character driving drunk
Symptoms are simply the result of the brain trying to adapt to       and getting caught by the police, as well as stories about pos-
an altered experience of the world.                                  itive events, like visiting relatives, or the self character being
   The present paper extends Kapur’s theory by adding “hy-           praised by his boss. The second group of stories consisted of
perlearning”, a specific mechanism that could link excessive         stories about a group of gangsters going about their gangster
DA release and psychotic symptoms directly, and may serve            business – committing crimes, killing each other, and occa-
as a possible neural substrate for excessive salience. Hyper-        sionally getting caught. Figure 2 shows an example.
learning simulates excessive DA release in DISCERN by per-              All stories were assembled from 14 different scripts de-
forming additional backpropagation learning with artificially        scribing stereotypical sequences of events such as meeting
increased learning rates.                                            someone for a drink or being pulled over by the police. Over-
   The approach is motivated by two pieces of evidence link-         all, the corpus contained approximately 550 single sentences
ing excessive DA release, psychotic symptoms, and overly             in 120 script instances. The lexicon contained about 170
intense learning in humans. First, excessive midbrain DA re-         words, including 20 names or descriptions of characters in
lease is likely to occur during some stages of schizophrenia         the stories (e.g. “Joe” or “lawyer”).
(Laruelle, 2000), and has been linked to increased learning in-         The first step in the experiments was to develop word rep-
tensity (Gibbs et al., 2007). Second, a tendency to mismatch         resentations to be used in the lexicon. A sentence parser net-
expectancy of observed experience and outcome has been as-           work was trained using the FGREP algorithm to obtain the
sociated with delusions in patients with schizophenia (Corlett       word representations. Each word representation consisted of
et al., 2007); elevated prediction errors of this kind have been     a pattern of 12 neuron activations. After 500 iterations of the
shown to produce a “super-learning” state in human subjects          entire corpus, the word representations had converged to good
(Aitken, Larkin, & Dickinson, 2000).                                 semantic representations of the concepts. Similar word rep-
   A reasonable assumption, then, is that DA imbalance               resentations tended to stand for similar concepts, and usually
causes both excessive salience and overly intense learning.          belonged to the same word category. Names of story char-
Furthermore, hyperlearning in DISCERN may capture impor-             acters, for instance, formed a tight and well-defined cluster:
tant aspects of the impact of excessive salience. In the exper-      with only a single exception, the five words closest to each of
                                                                 226

the ten names were either another name, or the word “man”.          tives. These agency shifts often involved the “self” character
   With the word representations in place, ten complete DIS-        migrating to gangster stories and other violations of global
CERN systems were trained to reproduce all 28 input stories.        context, while the local story structure stayed intact. The fol-
Network sizes and training parameters were determined em-           lowing text is an example from such a story.
pirically. Sentence parsers and generators had 250 hidden           [...]
neurons, story parsers had 225, and story generators had 150.       *I(Tony) was scared.
                                                                    *I(Tony) drove carefully.
Memory encoder networks had 48 hidden neurons.                      *I(Tony) entered City-Hall for bombing.
   All modules were first trained separately until they             *I(Tony) bomb(ed) City-Hall.
achieved a reasonable performance, and then linked in a chain       The *wedding(bombing) was a success.
                                                                    *I(Tony) made a phone-call.
and trained for an additional 10,000 epochs for fine-tuning.        *I(Tony) smoked a cigarette.
The training algorithm was standard backpropagation, so the         [...]
word representations were not changed any further. The
                                                                       Here, the “self” consistently replaces the gangster Tony.
learning rate for each module was recalculated after each it-
                                                                    Apart from this agency shift, the word “wedding” intrudes
eration of the story corpus by multiplying the module’s aver-
                                                                    from another context to replace the word “bombing. Patterns
age output error by a constant factor (0.4). In this way, the
                                                                    like these often recurred many times in the output of a single
learning rate was automatically decreased during the training
                                                                    DISCERN system, creating a compelling simulation of delu-
process to allow for more accurate training.
                                                                    sional narratives.
   After training, the resulting DISCERN systems were able             Agency shifts in this simulation dominated other types of
to reproduce all 28 stories almost perfectly. The average re-       errors. Consistent with language behavior in patients with
call performance (measured as the percentage of sentences           delusions, the syntax of the output language remained intact,
correctly reproduced) ranged from 95% to 97%. Errors usu-           and levels of lexical errors besides agency shifts were low but
ally involved substituting one word for another that was used       non-zero. Derailments following this type of hyperlearning
in a very similar way in the input stories. Two of the ten          were rare, which is consistent with the “delusional type” of
systems switched once from one story to another, but both           schizophrenia, where symptoms do not tend to include promi-
times, the switch was to a closely related story. This type of      nent language disorganization.
“benign” derailment is not uncommon in healthy idividuals              Hyperlearning did, however, produce frequent derailments
(Hoffman, Stopek, & Andreasen, 1986).                               when applied to the memory encoder instead of the story and
   Each of the lesions discussed previously was applied to all      sentence generators. The following output was produced by
ten healthy DISCERN systems. The intensity of each lesion           a DISCERN system after 500 epochs of hyperlearning:
was increased until a realistic reduction of recall performance
                                                                    [...]
was reached (about 50% of heathy performance). Statistics           Vince went to Starbucks.
on recall performance, number and type of lexical errors, and       [Derailing to story 13]
derailment behavior were collected for each lesion.                 I went to Starbucks.
                                                                    *Vince(I) sat at a table.
   The results were then evaluated to determine whether or          I ordered coffee.
not the models produced language disturbances consistent            I drank the coffee.
with schizophrenia. Specifically, a realistic model would           *Vince(I) met *Joe(Mary) at Starbucks.
                                                                    [Derailing to story 15]
be expected to generate grammatically correct language with         Mary was the girlfriend of Joe.
low but non-zero levels of lexical errors, while at the same        [Derailing to story 12]
time showing signs of delusions and/or derailments.                 *Vito(Joe) was the fiancee of *Tony(Mary).
                                                                    I hated Joe.
   Derailments were scored when DISCERN switched from               *Vince(I) distrusted Joe.
one story context to another. Plausible derailment behavior         [...]
should contain frequent jumps between dissimilar stories.              The language in this case seems clearly disorganized, and
   Delusions are harder to quantify than derailments, but           the system becomes unable to follow a coherent story line.
should involve recurring and well-formed new narratives that        This example is particularly interesting because derailments
do not occur in the original story corpus. In patients, delu-       are accompanied by intrusions of characters from the original
sions are associated with “agency shifts”, i.e. migrations of       story context, suggesting that the disorganization occurs at
characters from one story context to another. Often, delu-          a deeper level than just that of distorted memory retrieval.
sional stories involve the self being inserted into implausible     Other examples where word substitutions seemed to serve as
or bizarre narrative schemata.                                      a segway into derailed discourse appear to confirm this view:
Results                                                             [...]
                                                                    I was drunk.
Of all lesions investigated, only hyperlearning lead to plausi-     I drove recklessly.
ble simulations of delusional language. Applied to the story        I was pulled-over by a cop.
and sentence generator networks, hyperlearning robustly pro-        The cop asked *Vince(me) for *his(my) license.
                                                                    [Derailing to story 25]
duced stable patterns of “agency shifts” where characters mi-       Vito was pulled-over by a cop.
grated between stories and produced meaningful new narra-           the cop asked Vito for his license.
                                                                227

                                 200                                                  [...]
                                                               A
                                                                                      *Kate(Stacy) was from New-York.
                                                                                      *Mary(Stacy) *smoked(drove) a *praised(compact).
         Repeated Within Story
                                 150                                                  *Mary(Stacy) liked *baseball(movies).
                                                                    B                 [Derailing to story 22]
                                                                                      Vince talked to Vito about guns.
                                 100                                                  *Tony(Vince) *kissed(liked) guns.
                                                                        C             Vince talked to *Bob(Vito) a long time.
                                                                        D             Vince liked talking to *Tony(Vito).
                                 50                                                   Vince gave a *hand-shake(kiss) good-bye to *man(Vito).
                                                                                      [...]
                                  0
                                       0          50         100          150
                                                                                         The system does derail to another story, but sentences like
                                           Unique Character Substitutions             “Mary smoked a praised” and “Tony kissed guns” make the
Figure 3: The average number of unique vs. repeated character                         output random and non-sensical rather than disorganized.
substitutions resulting from (A) hyperlearning of generator modules,                     Finally, when pruning was applied to the memory encoder
(B) semantic noise, (C) connection pruning, and (D) working mem-                      during training, DISCERN did produce derailments without
ory noise. As the intensities of the network disturbances increase,
all produce more and more character substitutions. However, the                       ungrammatical language or frequent lexical errors. However,
substitutions following hyperlearning are by far the most consistent,                 over 90% of network connections had to be cut in order to ap-
leading to the emergence of stable patterns of “agency shifts” that                   proximate a realistic reduction in recall performance, which
resemble delusional narratives.
                                                                                      makes this kind of pruning an unlikely candidate pathology.
Vito gave his license to the cop.                                                     Furthermore, since pruning does not lead to a model for delu-
the cop checked the license.
the cop arrested Vito for bombing.                                                    sions, two separate processes would have to be assumed un-
[...]                                                                                 necessarily for derailments and delusions.
   In this case, the switch to a gangster story is preceded by                           Additional results, including the full output text of all ten
the intrusion of a gangster character. Note also how DIS-                             DISCERN systems for all lesions investigated, can be found
CERN adjusts the pronoun to match the new subject.                                    at http://nn.cs.utexas.edu/?schizo.
   Not all instances of derailed language were equally consis-
                                                                                                                          Discussion and Future Work
tent with disorganized language in schizophrenia. In particu-
                                                                                      The results demonstrate that hyperlearning provides plausi-
lar, DISCERN tended to oscillate between two stories, which
                                                                                      ble simulations of both delusions and derailment behavior in
occurs only rarely in patients with schizophrenia. Future re-
                                                                                      schizophrenia. The present study therefore supports Kapur’s
finements of the model will address this issue.
                                                                                      (2003) theory of increased salience, and furthermore offers a
   To summarize the results so far: The hyperlearning sim-
                                                                                      computational account of a brain process through which ab-
ulation of aberrant salience led to plausible simulations of
                                                                                      normal salience could lead to psychotic symptoms.
both delusions and derailed language. Different symptoms
                                                                                         Additionally, the model suggests a possible refinement,
emerged depending on the subset of modules to which hy-
                                                                                      namely that different clinical subtypes of schizophrenia may
perlearning was applied, suggesting a possible mechanism
                                                                                      arise depending on the impact of overly intense learning on
by which different clinical subtypes of schizophrenia could
                                                                                      different functional modules. These findings demonstrate
emerge from a common brain process.
                                                                                      how computational models of psychopathology can comple-
   The remainder of this section compares hyperlearning to
                                                                                      ment clinical reearch by creating and fomulating hypotheses
the other lesions applied to the model. First, as mentioned
                                                                                      about the link between mind and brain, between underlying
above, the simulation of delusional language was unique to
                                                                                      brain processes and their behavioral manifestations.
hyperlearning – no other lesion led to patterns of agency shifts
                                                                                         Other possible pathologies underlying derailment and
that were as stable, or tended to insert the “I” character as fre-
                                                                                      delusions in schizophrenia, including working memory im-
quently. Figure 3 compares the consistency of agency shifts
                                                                                      pairment, loss of cortical connectivity, and disturbed lexical
across different lesions, i.e. how many times specific sub-
stitutions of story characters were repeated within the same                                                              10
                                                                                                                                      Working memory noise
                                                                                                                                      Pruning
story. Substitutions following hyperlearning are much more
                                                                                               % Ungrammatical Language
                                                                                                                                      Semantic noise
                                                                                                                          8           Hyperlearning (generators)
likely to be repeated, leading to the consistent “delusional”                                                                         Hyperlearning (memory enc.)
patterns observed.                                                                                                        6
   Derailments, on the other hand, did occur frequently fol-
lowing several lesions, including pruning and working mem-                                                                4
ory noise. However, with lesions that did not include addi-
                                                                                                                          2
tional training, derailments were accompanied by high levels
of ungrammatical language and lexical errors, both of which                                                               0
                                                                                                                           100   90        80      70       60      50   40
are inconsistent with the kind of language seen in schizophre-                                                                                  % Recall
nia (Figure 4). The following text, for example, was produced                         Figure 4: Lesions without additional training lead to high levels of
by a DISCERN system while noise was added to the story                                ungrammatical language as recall performance declines. In contrast,
generator’s working memory:                                                           hyperlearning produces almost no ungrammatical language.
                                                                                228

access, were not supported by simulations. However, DA im-          Cohen, J., & Servan-Schreiber, D. (1992). Context, cortex
balance in schizophrenia is likely a secondary effect of other        and dopamine: A connectionist approach to behaviour and
abnormal processes, and future research may provide insight           biology in schizophrenia. Psychol Rev, 99, 45–77.
into the role of further pathologies involved in schizophrenia.     Corlett, P., Murray, G., Honey, G., Aitken, M., Shanks, D.,
   The present model focuses on delusions and derailments,            Robbins, T., et al. (2007). Disrupted prediction-error sig-
and does not account for other symptoms of schizophrenia.             nal in psychosis: evidence for an associative account of
Specifically, negative symptoms (as opposed to psychotic              delusions. Brain, 130, 2387–400.
symptoms) are not addressed. Negative symptoms include              Fidelman, P., Miikkulainen, R., & Hoffman, R. E. (2005).
reduced language output and flattened emotions. In future             A subsymbolic model of complex story understanding. In
work, emotional intensity will in part determine the intensity        Proc of CogSci’05.
of the learning process, and the possible role of emotional         Gibbs, A. A., Naudts, K. H., Spencer, E. P., & David, A. S.
flattening as a compensatory mechanism will be investigated.          (2007). The role of dopamine in in attentional and mem-
   A further symptom that is not addressed at present are             ory biases for emotional information. Am J Psychiat, 164,
hallucinations, which primarily occur as spoken speech in             1603–9.
schizophrenia. Within the framework of abnormal salience,           Grasemann, U., Miikkulainen, R., & Hoffman, R. E. (2007).
hallucinations are assumed to arise from “the abnormal                A subsymbolic model of language pathology in schizo-
salience of the internal representations of percepts and mem-         phrenia. In Proc of CogSci’07. Nashville, Tennessee, USA.
ories.” (Kapur, 2003). However, a previous computational            Harrison, P. (1999). The neuropathology of schizophrenia a
model suggests that connection loss in speech perception net-         critical review of the data and their interpretation. Brain,
works similar to those in DISCERN can model hallucinated              122, 593–624.
speech (Hoffman & McGlashan, 1997). Future work will at-            Harrow, M., Herbener, E. S., Shanklin, A., Jobe, T. H., Rat-
tempt a unified account of hallucinations in schizophrenia.           tenbury, F., & Kaplan, K. J. (2004). Followup of psychotic
                                                                      outpatients: dimensions of delusions and work functioning
                          Conclusion
                                                                      in schizophrenia. Schizophrenia Bull, 30, 147–61.
A computational model of language disturbance in schizo-            Hoffman, R. (1987). Computer simulations of neural infor-
phrenia was proposed and evaluated. Using DISCERN, a                  mation processing and the schizophrenia-mania dichotomy.
neural network-based model of human story processing, dif-            Arch Gen Psychiat, 44, 178-88.
ferent brain abnormalities thought to underlie schizophrenia        Hoffman, R., & McGlashan, T. (1997). Synaptic elimina-
were simulated and compared with respect to their ability to          tion, neurodevelopment and the mechanism of hallucinated
model symptoms of schizophrenia. “Hyperlearning”, a sim-              ’voices’ in schizophrenia. Am J Psychiat, 154, 1683–9.
ulation of Kapur’s (2003) theory of abnormal salience as the        Hoffman, R., & McGlashan, T. (2006). Using a speech
basis for psychosis in schizophrenia, was shown to provide            perception neural network computer simulation to contrast
a plausible model of delusions and derailment behavior, two           neuroanatomic versus neuromodulatory models of auditory
key symptoms of schizophrenia.                                        hallucinations. Pharmacopsychiat, 39 (suppl 1), 554–64.
                     Acknowledgments                                Hoffman, R., Stopek, S., & Andreasen, N. (1986). A com-
This work was supported by NIMH under grant                           parative study of manic versus schizophrenic speech disor-
R01MH066228 and by NSF under grant IIS-0083776.                       ganization. Arch Gen Psychiat, 43, 831–8.
                                                                    Kapur, S. (2003). Psychosis as a state of aberrant salience: a
                          References                                  framework linking biology, phenomenology, and pharma-
Aitken, M. R., Larkin, M. J., & Dickinson, A. (2000). Super-          cology in schizophrenia. Am J Psychiat, 160(1), 13–23.
   learning of causal judgments. Qt J Exp Psych, 53, 59–81.         Laruelle, M. (2000). The role of endogenous sensitization in
Andreasen, N. C. (1979). Thought, language, and commu-                the pathophysiology of schizophrenia: implications from
   nication disorders. II. diagnostic significance. Arch Gen          recent brain imaging studies. Brain Research - Brain Re-
   Psychiat, 26, 1325–30.                                             search Reviews, 31(2–3), 371–84.
Applebaum, P. S., Clark Robbins, P., & Roth, L. H. (1999).          Miikkulainen, R. (1993). Subsymbolic natural language pro-
   Dimensional approach to delusions: comparison across               cessing: An integrated model of scripts, lexicon, and mem-
   types and diagnoses. Am J Psychiat, 156, 1938–43.                  ory. Cambridge, MA: MIT Press.
Berridge, K., & Robinson, T. (1998). What is the role of            Pollack, J. (1990). Recursive distributed representations. Ar-
   dopamine in reward: hedonic impact, reward learning, or            tif Intell, 46(1), 159–216.
   incentive salience? Brain Res Brain Res Rev, 28, 309–69.         Ruppin, E., Reggia, J., & Horn, D. (1996). Pathogenesis
Bleuler, E. (1911). Dementia praecox oder die Gruppe der              of schizophrenic delusions and hallucinations: A neural
   Schizofrenien. In G. Aschaffenburg (Ed.), Handbuch der             model. Schizophrenia Bull, 22(1), 105–23.
   Psychiatrie. Leipzig: Breithep und Hartel.                       Spitzer, M. (1997). A cognitive neuroscience view of schizo-
Braver, T., Barch, D., & Cohen, J. (1999). Cognition and con-         phrenic thought disorder. Schizophrenia Bull, 23(1), 29–50.
   trol in schizophrenia: A computational model of dopamine
   and prefrontal function. Biol Psychiat, 46(3), 312-28.
                                                                229

