UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Integration of facial information is sub-optimal
Permalink
https://escholarship.org/uc/item/8xd2q0c7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Gold, Jason
Shotts, Megan
Tjan, Bosco
Publication Date
2009-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                              Integration of Facial Information is Sub-Optimal
                                                Jason M. Gold (jgold@indiana.edu)
      Departments of Psychological and Brain Sciences and Cognitive Science, Indiana University, 1101 East 10th Street
                                                       Bloomington, IN 47405 USA
                                                    Bosco S. Tjan (btjan@usc.edu)
                              Department of Psychology, University of Southern California, SGM 501
                                                      Los Angeles, CA 90089 USA
                                               Megan Shotts (mshotts@indiana.edu)
                     Department of Psychological and Brain Sciences, Indiana University, 1101 East 10th Street
                                                       Bloomington, IN 47405 USA
                              Abstract                                  processed independently. As a result, the extra information
                                                                        that is encoded for upright faces allows an observer to
  How efficiently do we combine information across facial
  features when recognizing a face? Previous studies have               identify an upright face more quickly and accurately than an
  suggested that the perception of a face is not simply the result      inverted face. Other experiments (Tanaka & Farah, 1993)
  of an independent analysis of individual facial features, but         have found that observers are more accurate at identifying
  instead involves a coding of the relationships amongst                facial features (e.g., a nose) within the context of a normal
  features. This additional coding of the relationships amongst         face than either in isolation or in the context of a face whose
  features is thought to enhance our ability to recognize a face.       features have been spatially scrambled.
  In our experiments, we tested whether an observer’s ability to          The results of these experiments suggest that observers
  recognize a face is in fact better than what one would expect         benefit from the spatial arrangement of features within a
  from their ability to recognize the individual facial features in     face in a way that would not be predicted by their ability to
  isolation. We tested this by using a psychophysical
                                                                        recognize the individual features in isolation. In our
  summation-at-threshold technique that has been used
  extensively to measure how efficiently observers integrate            experiments, we wished to directly test this idea by
  information across spatial locations and spatial frequencies.         measuring how efficiently observers integrate information
  Surprisingly, we found that observers integrated information          across features in a face identification task. The technique
  across facial features less efficiently than would be predicted       we used is based on a summation-at-threshold method
  by their ability to recognize the individual parts.                   developed previously to measure the efficiency of
                                                                        information integration across spatial and spatial frequency
   Keywords: Face Recognition; Ideal Observer; Information
   Integration.                                                         tuned analyzers (Graham, 1989; Graham, Robson, &
                                                                        Nachmias, 1978; Nandy & Tjan, 2008). In our experiments,
                                                                        we measured observers’ contrast sensitivities (i.e., the
                          Introduction                                  reciprocal of contrast threshold) for identifying facial
The ability to accurately recognize human faces is vitally              features (i.e., left eye, right eye, nose, mouth) either in
important to human social interactions. As such, there has              isolation or all together in combination. Optimal
been a great deal of interest in exploring the psychological            information integration predicts that an observer’s squared
and neurophysiological mechanisms that mediate human                    contrast sensitivity to features when shown in combination
face recognition. Much of this research has focused on                  should be the same as the sum of their squared contrast
determining whether the individual elements in a face (e.g.,            sensitivities to the individual features when shown in
eyes, nose, mouth) are processed independently or if the                isolation (i.e., the ratio of the combined squared contrast
relationships amongst the elements are also encoded in the              sensitivity to the sum of the individual squared contrast
facial representation.                                                  sensitivities should be equal to one). Sub-optimal
  Several lines of evidence are consistent with the idea that           integration predicts this ratio should be less than one, and
the spatial relationships amongst facial features play a                super-optimal integration predicts this ratio should be
crucial role in face identification. Some of this evidence              greater than one (Nandy & Tjan, 2008).
draws upon the “face inversion effect”: the finding that,                 Based on the results of previous experiments with faces,
unlike most other objects, faces tend to be much more                   we would expect to see super-optimal integration, because
difficult to identify when they are inverted than when they             observers are thought to derive an additional benefit from
are upright (Maurer, Grand, & Mondloch, 2002; Valentine,                the use of the relationships amongst features when they are
1988; Yin, 1969). This effect is typically accounted for by             shown together in combination as opposed to when they are
positing that upright faces are processed as single units with          shown in isolation. Contrary to this prediction, we found
the spatial relationships amongst elements encoded in the               that most observers integrated information sub-optimally, in
representation, whereas the elements of inverted faces are
                                                                     1
                                                                    2896

Figure 1: Stimuli used in the face identification experiments. All stimuli were based on the six combined faces shown in row
A. Row B shows the left eye stimuli, row C the right eye stimuli, row D the mouth stimuli and row E the nose stimuli.
a fashion more in line with basing their decision on the           insure that a given feature fell within a given window for
individual feature to which they are most sensitive.               each face (see Figure 1a).
                                                                      The value of each pixel in each image was expressed in
                           Methods                                 terms of contrast, where contrast is defined as (Lpix - Lbg)/
                                                                   Lbg, where Lpix is the luminance of a given pixel and Lbg is
Subjects                                                           the background luminance. The regions of the faces not
                                                                   falling within the Gaussian windows were set to zero
Six subjects (three women and three men, aged 18-37)               contrast (i.e., Lbg).
participated in this study. All subjects except for two authors       Four additional sets of six face images were generated
(MS and JMG) were naive to the purposes of the                     from this first set of images. One set contained only the left
experiment. All had normal or corrected-to-normal visual           eyes of each face (Figure 1b); a second set only the right
acuity. Each naive subject was paid for his or her                 eyes (Figure 1c); a third set only the noses (Figure 1d); and
participation. All subjects had given their informed consent.      a fourth set only the mouths (Figure 1e). In each of the
                                                                   images that contained only a single feature, the regions
Stimuli                                                            where the other features appeared in the original images
Stimuli were modified from a set used in previous                  were set to zero contrast.
experiments on human face recognition (Gold, Bennett, &               White Gaussian contrast noise was added to each pixel of
Sekuler, 1999a, 1999b). Six grayscale faces were used              the image that was shown on each trial (µ = 0; σ = 0.1). A
(three male, three female). Each face was 256 x 256 pixels         unique sample of noise was generated for each pixel on each
in size (2.5° x 2.5°, from a viewing distance of 130 cm), and      trial.
was multiplied by a set of four Gaussian windows (σ = 9
pixels), each centered on a different facial feature (left eye,    Procedure
right eye, nose and mouth). These windows were used to             A one-of-six identification task was used to estimate
isolate the facial features. The locations of the four windows     identification thresholds for each feature condition (left eye,
were the same across all the faces, and they were chosen to        right eye, nose, mouth, combined). The contrast of the
                                                                2
                                                               2897

images was manipulated across trials according to a 1-down                 when identifying the composite that is not used when
1-up staircase in each condition to obtain an observer’s 50%               identifying the individual elements in isolation.
correct identification threshold (chance performance was
~16% correct). The staircases were randomly interleaved                                                    Results
during each experimental session, which meant that the
                                                                           Figure 2a shows contrast sensitivities in each condition for
stimulus types were also randomly mixed within each
                                                                           the ideal observer1 (dashed line) and three human observers2
session. On each trial, the observer saw a noisy stimulus and
                                                                           (solid lines with symbols). Figure 2b shows the
was presented with the set of six noise-free images from
                                                                           corresponding integration index for each observer. Figure 2b
which the noisy image had been chosen (e.g., if a left eye
                                                                           also shows the predictions of the “best-feature” model
had been shown, the six possible left eye images were
                                                                           (where each feature is analyzed independently and the
shown in a selection screen for the observer to choose
                                                                           decision is based on the feature to which the observer is
from).
                                                                           most sensitive3 ), plotted as a dashed line with triangle
   On each trial, a box appeared around the region where the
                                                                           symbols. The best-feature model is intended to provide a
stimulus was going to appear. The observer started the trial
                                                                           lower-bound for performance.
with a mouse click, and the noisy image was shown for
                                                                               There are several interesting things to note about these
~500 ms, after which the image was replaced with a
                                                                           data. First, the pattern of sensitivities across conditions is
selection window. The observer used the mouse to click on
                                                                           similar for all the observers, including the ideal observer.
the image they thought had appeared in the stimulus
                                                                           The fact that the ideal observer shows a similar pattern of
interval. Accuracy feedback was given in the form of a high
                                                                           performance to the human observers is interesting, because
or low beep.
                                                                           it indicates that the variations in human performance across
   Each observer participated in five sessions of 500 trials.
                                                                           conditions can largely be accounted for by the amount of
The first two sessions were not included in the analyses to
                                                                           physically available information in each set of stimuli. In
remove any initial learning effects from the data. A Weibull
                                                                           this case, it shows that performance was worse for mouths
psychometric function was fit to the staircase data (i.e., a fit
                                                                           and noses in isolation largely because there was simply less
to percent correct as a function of stimulus contrast) in each
                                                                           information physically present in those conditions (i.e., the
condition and the 50% correct identification threshold was
                                                                           stimuli were more physically similar to each other).
estimated from each fit. Bootstrap simulations were used to
                                                                               Second, the integration index for two of the human
estimated confidence intervals for the thresholds.
                                                                           observers was significantly less than 1, indicating they were
                                                                           integrating information sub-optimally in the combined
Integration Index
                                                                           condition. In fact, these two observers were closer to the
Following Nandy & Tjan (2008), an integration index Փ was                  predictions of the best-feature model than optimal or super-
defined as follows:                                                        optimal integration. This result is the opposite of what one
                          2
                     CSleft                                                would predict if observers were using the relationships
        Φ=                                                                 amongst features to improve their performance when facial
                            eye + right eye + mouth + nose
                   2            2               2            2
               CSleft eye +CSright eye +CSmouth +CSnose
                                                                           features are shown together rather than in isolation. Such a
                                                                           result is surprising, given that previous experiments on face
                                                                           recognition have suggested observers greatly benefit from
                                                                           using the relationships amongst facial features when
where c is an observer’s contrast threshold and CS, an                     recognizing faces. The one exception was observer VMD,
observer’s sensitivity, is equal to 1/c. Nandy and Tjan                    who integrated information super-optimally. Apparently, this
(2008) have shown that the integration index for a                         observer did in fact derive an additional benefit from
statistically optimal observer in this task will be equal to 1.            viewing the facial features together rather than in isolation.
Sub-optimal integration will yield an index less than 1, and                   It is possible that the sub-optimal integration we found for
super-optimal integration will yield an integration index                  two of the three human observers was somehow related to
greater than 1. Note that only a sub-ideal observer can                    their conditional uncertainty in the experiment (recall that
actually achieve super-optimal integration: an integration                 they did not know which condition would appear on each
index greater than 1 implies additional information is used                trial). For example, the conditional uncertainty may have
1 The ideal decision rule can be derived using Bayes’ rule (Green & Swets, 1966). For our task and stimuli, it is equivalent to choosing the
noise-free signal that produces the highest cross-correlation with the noisy stimulus (Tjan, Braje, Legge, & Kersten, 1995).
2 One additional human observer was excluded due to an inability to perform the task at a level sufficiently above chance.
3 The “best-feature” model is closely related to the model of probability summation for signal detection (Graham, 1989). The integration
index of the best-feature model is computed as the expected value of the maximum of the observer’s squared contrast sensitivities to the
individual face features to that of the sum of the squared contrast sensitivities to all of the face features (Nandy & Tjan, 2008), i.e.
                              2              2             2     2
                  max[CSleft      eye ,CSright eye ,CSmouth ,CSnose ]
 Φbest-feature =          2             2              2       2
                     CSleft eye +CSright eye +CSmouth +CSnose
                                                                       3
                                                                      2898

Figure 2: (A) Squared contrast sensitivities and (B) integration indexes for the ideal observer and three human observers.
Error bars correspond to ± 1 s.e., estimated by bootstrap simulations (Efron & Tibshirani, 1993).
Figure 3: (A) Squared contrast sensitivities and (B) integration indexes for the ideal observer and three human observers. The
conditions in this experiment were presented in blocks of 50 trials rather than randomly permuted as in the first experiment
(Figure 2). Error bars correspond to ± 1 s.e.
induced observers to use an individual feature-oriented            of conditions was randomized across blocks within each
strategy on all trials, including those where the entire set of    session and there were two blocks tested for each condition
features was present (i.e., the combined condition). We            (a total 100 trials per condition within each session, for 5
tested this possibility by running a second set of observers       sessions). Importantly, the observers were told at the
through the same experiment, but with the conditions               beginning of each new block which condition they would be
blocked rather than randomized. Specifically, each session         tested on for the next 50 trials.
contained a series of blocks, where the same condition was           The results of this experiment are shown in Figure 3.
tested within each block for 50 consecutive trials. The order      Figure 3a shows contrast sensitivities in each condition for
                                                                4
                                                               2899

Figure 4: Face images from taken from Figure 1A, but with a constant background image added to each face. The area
surrounding the features (the background image) is an average computed from the six original faces.
the ideal observer and three human observers. Figure 3b                  gained by the use of relational or other second-order coding
shows the corresponding integration index for each observer              strategies.
and the predictions of the best-feature model. Contrary to                  One way to directly address the issue of limited spatial
the idea that conditional uncertainty was responsible for the            attention would be measure ‘classification images’ for each
sub-optimal integration found in the first experiment, these             of the conditions in our experiments (Ahumada, 2002;
data show that observers were generally less efficient at                Murray, Bennett, & Sekuler, 2002). A classification image is
integrating information when the conditions were blocked                 a spatial map that describes the relative weight given to each
rather than randomized. Two observers (JEH, MTA) were                    image location by an observer over the course of an
actually numerically worse than the lower bound set by the               experiment. Classification images are measured by
best-feature model 4.                                                    correlating random pixel noise with an observer’s decisions
                                                                         across trials. The efficiency of an observer’s classification
                           Discussion                                    image can be measured by comparing their classification
                                                                         image with that of an ideal observer (Murray, Bennett, &
   Our experiments were designed to test the prediction that             Sekuler, 2005). Measurement of human and ideal
observers make use of information from facial features                   classification images for individual and combined facial
when recognizing a complete face in a manner that is better              features would allow us to a) directly determine the
than one would predict from their ability to detect the                  efficiency of a human observer’s weighting when the
individual features in isolation. Contrary to this prediction,           features are shown in combination vs. in isolation; and b)
our results are more consistent with the idea that observers             reveal the specific nature of any differences in weighting
analyze each feature independently and base their decision               when the features are shown in combination vs. in isolation.
on the single feature to which they are most sensitive.                     A second less direct way to address the issue of limited
   Previous experiments with much simpler tasks and                      spatial attention would be to carry out our experiment with
stimuli, such as the detection of sinusoidal gratings across             inverted facial features, where the attentional bottleneck
space, have yielded results similar to our own (and have                 would be identical to our original task. If observers rely on
referred to this as “probability summation”) (Graham,                    relational codes when identifying normal faces but not
1989). Pelli, Farell and Moore (2003) have also found that               inverted faces (as previous experiments would suggest), we
observers combine information sub-optimally across letters               would expect integration efficiency to be higher for normal
when recognizing English words. Taken together, these                    than inverted faces..
results suggest that the sub-optimal integration of                         It is worth noting that inefficiencies similar to those we
information across facial features that we observed in our               obtained with faces are also found with respect to the
experiments may reflect a more general inefficiency in                   integration of information across spatial frequencies with
visual spatial information integration. One possible account             simple compound grating detection tasks (Graham, 1989).
for this effect could be that such tasks push against an upper           However, recent experiments by Nandy and Tjan (2008)
limit on the processing capacity of visual spatial attention             have found that observers optimally integrate information
(Driver, 2001). Such a limitation could reduce the amount of             across spatial frequencies when identifying English letters.
information an observer is able to use at any given feature              One obvious difference between spatial frequency
location when they are forced to simultaneously attend to                integration and spatial integration is that stimuli filtered
more than one spatial feature at a time (as in the case of a             with respect to spatial frequency will occupy the same
composite face). If so, it is possible that observers do make            region of space. It would be interesting to see if, like letters,
use of relational properties when recognizing faces, but that            spatial frequency information in faces is integrated in an
the limitations imposed by spatial attention reduce the                  optimal fashion.
processing efficiency of individual features more than is
4 The other observer in this second experiment (JMG) was an author and, unlike all the other observers, was very familiar with original
face stimuli. The integration index for this observer was much higher than the other two observers in the second experiment, albeit still sub-
optimal. This suggests the possibility that information may be integrated less efficiently when recognizing unfamiliar faces, and that
training may serve to increase information integration efficiency.
                                                                      5
                                                                    2900

  One additional factor that may have contributed to the             Murray, R. F., Bennett, P. J., & Sekuler, A. B. (2002).
inefficient processing of composite faces that we observed                     Optimal methods for calculating classification
in our experiments is the relatively unnatural viewing of                      images: weighted sums. J Vis, 2(1), 79-104.
faces through a set of Gaussian windows. That is, viewing            Murray, R. F., Bennett, P. J., & Sekuler, A. B. (2005).
features through a set of Gaussian windows may have                            Classification images predict absolute efficiency. J
disrupted any relational processing that normally takes place                  Vis, 5(2), 139-149.
when recognizing a face. One way to address this issue               Nandy, A. S., & Tjan, B. S. (2008). Efficient integration
would be to place the features within a fixed ‘average’                        across spatial frequencies for letter identification in
background image, as shown in Figure 4. In this figure, the                    foveal and peripheral vision. J Vis, 8(13), 3 1-20.
Gaussian windowed faces from Figure 1A have been added               Pelli, D. G., Farell, B., & Moore, D. C. (2003). The
to an image that was generated by averaging the regions                        remarkable inefficiency of word recognition.
surrounding the Gaussian windows in each of the six                            Nature, 423(6941), 752-756.
original face images. If the sub-optimal integration across          Tanaka, J. W., & Farah, M. J. (1993). Parts and wholes in
features in our experiments was due to a lack of facial                        face recognition. Q J Exp Psychol A, 46(2),
‘context’ around the Gaussian windows, we would expect                         225-245.
the faces shown in Figure 4 to greatly increase integration          Tjan, B. S., Braje, W. L., Legge, G. E., & Kersten, D.
efficiency.                                                                    (1995). Human efficiency for recognizing 3-D
                                                                               objects in luminance noise. Vision Res, 35(21),
                         Conclusions                                           3053-3069.
                                                                     Valentine, T. (1988). Upside-down faces: a review of the
  In this paper, we have reported the results of two                           effect of inversion upon face recognition. Br J
experiments that indicate human observers are inefficient at                   Psychol, 79 ( Pt 4), 471-491.
integrating information across facial features. We have              Yin, R. K. (1969). Looking at upside-down faces. Journal of
suggested several possible accounts for our results,                           Experimental Psychology, 81, 141-145.
including limits on spatial attention and the use of unnatural
face stimuli. We are currently conducting experiments to
test each of these possibilities.
                     Acknowledgments
This research was funded by National Institute of Health
Grants EY019265 to J.M.G., and EY016093, EY017707 to
B.S.T.
                          References
Ahumada, A. J., Jr. (2002). Classification image weights and
          internal noise level estimation. J Vis, 2(1), 121-131.
Driver, J. (2001). A selective review of selective attention
          research from the past century. Br J Psychol, 92(Pt
          1), 53-78.
Efron, B., & Tibshirani, R. (1993). An introduction to the
          bootstrap. New York: Chapman & Hall.
Gold, J., Bennett, P. J., & Sekuler, A. B. (1999a).
          Identification of band-pass filtered letters and faces
          by human and ideal observers. Vision Res, 39(21),
          3537-3560.
Gold, J., Bennett, P. J., & Sekuler, A. B. (1999b). Signal but
          not noise changes with perceptual learning. Nature,
          402(6758), 176-178.
Graham, N. (1989). Visual Pattern Analyzers. New York:
          Oxford University Press.
Graham, N., Robson, J. G., & Nachmias, J. (1978). Grating
          summation in fovea and periphery. Vision Res,
          18(7), 815-825.
Green, D. M., & Swets, J. A. (1966). Signal detection theory
          and psychophysics. New York,: Wiley.
Maurer, D., Grand, R. L., & Mondloch, C. J. (2002). The
          many faces of configural processing. Trends Cogn
          Sci, 6(6), 255-260.
                                                                  6
                                                                 2901

