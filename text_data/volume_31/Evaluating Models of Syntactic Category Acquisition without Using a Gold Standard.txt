UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Evaluating Models of Syntactic Category Acquisition without Using a Gold Standard
Permalink
https://escholarship.org/uc/item/01h2s0gs
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Frank, Stella
Goldwater, Sharon
Keller, Frank
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                 University of California

                           Evaluating Models of Syntactic Category Acquisition
                                               without Using a Gold Standard
                                                Stella Frank (s.c.frank@sms.ed.ac.uk) and
                                             Sharon Goldwater (sgwater@inf.ed.ac.uk) and
                                                     Frank Keller (keller@inf.ed.ac.uk)
                                               School of Informatics, University of Edinburgh
                                                10 Crichton Street, Edinburgh EH8 9AB, UK
                               Abstract                                    applicable to a wide range of different acquisition models
   A number of different measures have been proposed for eval-             (e.g., it should not be limited to probabilistic models).
   uating computational models of human syntactic category ac-                This paper proposes a new evaluation measure which meets
   quisition. They all rely on a gold standard set of manually de-
   termined categories. However, children’s syntactic categories           these criteria: substitutable precision and recall. It relies on a
   change during language development, so evaluating against a             classical idea from linguistics, viz., that words which share
   fixed and final set of adult categories is not appropriate. In this     the same syntactic category occur in similar syntactic envi-
   paper, we propose a new measure, substitutable precision and
   recall, based on the idea that words which occur in similar             ronments. It does not require a gold standard, and therefore is
   syntactic environments share the same category. We use this             suitable for evaluating pre-adult categories. At the same time,
   measure to evaluate three standard category acquisition mod-            it yields results that correlate with gold-standard-based mea-
   els (hierarchical clustering, frequent frames, Bayesian HMM)
   and show that the results correlate well with those obtained            sures. We will show this by applying our new measure, as
   using two gold-standard-based measures.                                 well as existing measures, to three standard models that dis-
                                                                           cover syntactic categories in child-directed speech. This is the
                           Introduction                                    first time these models have been systematically compared;
By the time children reach school age, they have achieved the              previous authors have used their own evaluation measures and
remarkable feat of acquiring most of their native language,                only applied them to their own data sets, thus making a com-
typically without explicit instruction. This includes the ac-              parison across models difficult.
quisition of syntactic categories (noun, verb, adjective, etc.).
A number of computational models of category learning have                     Gold-standard-based Evaluation Measures
been developed, most of which conceptualize the problem as                 In the following section we describe two evaluation measures
one of grouping together words whose syntactic behavior is                 that have been used to evaluate category acquisition models.
similar. Typically, the input for the model is taken from a cor-           Both require gold-standard labeled data, which is problem-
pus of child-directed speech, and clusters are created based               atic from an acquisition standpoint for the reasons previously
on distributional information (Redington et al., 1998; Mintz,              discussed. Hand-labeled data is also scarce, particularly for
2003; Parisien et al., 2008).                                              languages other than English.
   A problem common to all existing models is the evaluation                  Some of the models we investigate categorize word types
of the model clusters. Often researchers have tested the output            (a type being a word such as duck), whereas others categorize
of their models against gold-standard category assignments,                tokens (particular instances of duck). In order to compare both
such as that available in the CHILDES database (MacWhin-                   kinds of models, the measures we describe are used to score
ney, 2000). These gold-standard categories are based on the                tokens, not types.
intuition of human annotators and are representative of adult
morphosyntactic knowledge. Therefore, this type of evalua-                 Matched Accuracy This measure is widely used in the
tion is not ideal for assessing the syntactic categories of chil-          field of Natural Language Processing for unsupervised part-
dren, as these may include linguistically valid distinctions not           of-speech tagging, in which the tokens of a text are automat-
recognized by the gold standard. Conversely, the gold stan-                ically annotated (“tagged”) with cluster numbers. To obtain
dard may make distinctions that children do not have, or only              the matched accuracy MA, the clusters induced by the model
acquire during language development. For example, at the                   are mapped onto the gold-standard categories in order to pro-
age of two, English-learning children have not fully acquired              vide a gold-standard part-of-speech label for each cluster. MA
the verb category (Olguin & Tomasello, 1993), and functional               is then defined as the percentage of word tokens with correct
categories such as determiners are acquired even later (Kemp               category labels. The crucial aspect is the mapping between
et al., 2005).                                                             the clusters and the gold standard categories. In this paper,
   It is therefore highly desirable to develop an evaluation               we use many-to-one accuracy, where each model cluster is
measure that does not make reference to an (adult) gold stan-              matched onto the gold-standard category with which it shares
dard. On the other hand, the measure should give results that              the most tokens. This can result in a situation where multiple
correlate with gold-standard-based measures, indicating that               clusters are mapped onto the same gold standard category.
it is capable of capturing the linguistic distinctions inherent            This means the model is not penalized for creating more fine-
in the gold-standard. Finally, the ideal measure needs to be               grained clusters than the gold standard.
                                                                       2576

Pairwise Precision and Recall These measures are widely                clustered together (Eq. 3).1
used in the cognitive literature on category acquisition
(e.g., Redington et al. 1998; Mintz 2003), and are sometimes                               ∑s∈S ∑c∈C |s ∩ c|(|s ∩ c| − 1)
                                                                                     SP =                                                 (2)
referred to as accuracy and completeness. To compute them,                                        ∑c∈C |c|(|c| − 1)
we consider all possible word pairs. If the words in a pair are                            ∑ ∑ |s ∩ c|(|s ∩ c| − 1)
                                                                                     SR = s∈S c∈C                                         (3)
grouped together by the model correctly (i.e., they are in the                                    ∑s∈S |s|(|s| − 1)
same gold-standard category and in the same model cluster),
                                                                       Because the models we are investigating use context infor-
a true positive (t p) is recorded; if they are not in the same
                                                                       mation that is similar to frames, there may be danger of over-
gold-standard category, a false positive ( f p) is recorded. If
                                                                       fitting the evaluation measure to the models and their training
the two words are not grouped together by the model, but are
                                                                       data. To avoid this, we compute SP and SR using a separate
in the same gold-standard category, then a false negative ( f n)
                                                                       test corpus. The S-clusters used for evaluation are based on
is recorded. Pairwise precision and recall is then defined as:
                                                                       frames found in both the training and the test corpus, but the
                           tp               tp                         words within each S-cluster are from the test corpus only (the
                 PP =             PR =                         (1)     test words must be in the training corpus vocabulary). Un-
                       tp+ f p            tp+ fn
                                                                       der the distributional definition, syntactic categories can be
Note that t p + f p is the total number of pairs within model          interpreted as expectations of substitutability, regardless of
clusters, whereas t p + f n is the total number of pairs within        whether the members of the category have appeared in the
the same category in the gold-standard. PP thus measures               same syntactic context. By using separate, additional data to
the proportion of correct pairs within the model clustering            measure substitutable precision and recall, we evaluate the
(i.e., whether the model clusters together the correct words),         extent to which these learned expectations of substitutability
while PR measures the number of correct pairs as a fraction            generalize to increasing amounts of data.
of all pairs in the gold standard (i.e., whether all correct pairs         If a frame is made up of words with multiple (model) clus-
have been found).                                                      ter memberships, the model may have discovered a valid am-
                                                                       biguity. For example, the frame to — cake is (using gold stan-
                                                                       dard tags) ambiguous between toINF — cakeN (“We are go-
          Substitutable Precision and Recall
                                                                       ing to eat cake today”), which has an S-cluster consisting of
Our goal is to capture the essential nature of syntactic cate-         words such as bake and eat, and toPREP — cakeN (“Put the
gories without using the actual categories themselves. Distri-         juice next to his cake”), with a corresponding S-cluster con-
butional analysis gives us the notion of substitutability (Har-        sisting of words such as his or that. For this reason, we add
ris, 1946; Brown & Fraser, 1964) as the key aspect of syntac-          cluster membership information (as found by the model be-
tic categories. Substitutable categories are made up of words          ing evaluated) to each frame word, as well as to the words in
with identical “privileges of occurrence”, i.e., a syntactic cat-      the S-clusters.
egory consists of words which may be substituted for each                  By using a separate test corpus, we introduce a dependency
other within a sentence without making the sentence ungram-            on the size of the test set. In our experiments, we use a test set
matical. For example, he and she both belong to the same               that is six times the size of the training set (we use the Manch-
category because he is happy and she is happy are both gram-           ester corpus (1.5M words) to train, and the rest of CHILDES
matical.                                                               (9M words) to test). Additionally, we only evaluate on frames
   The measure we propose, substitutable precision and re-             that occur more than once within the test data, since a single
call, evaluates category acquisition models by testing whether         occurrence gives no information about which words should
substitutable words — words which appear in the same                   be clustered together, and a single occurrence of a rare event
contexts — have been clustered together. Because nearly-               also gives little information about which words not to cluster
identical sentences (which would be necessary to strictly              together.
evaluate substitutability) are rare in corpora, we restrict our
notion of context to frames: two words appearing in the cor-
                                                                             Models of Syntactic Category Acquisition
pus with exactly one word in between. From these frames, we            In this section we briefly describe three models2 of syntac-
create substitutable clusters (S-clusters) that consist of the set     tic category acquisition that we will use to test our evaluation
of word types that appear within the same frame. There is a            method. These models were chosen primarily for being rep-
one-to-one correspondence between S-clusters and frames.               resentative of the space of possible models: they differ, for
   Substitutable precision and recall are calculated similarly         example, in their treatment of syntactically ambiguous words
to standard pairwise precision and recall. However, this does          and whether or not they categorize every word in the corpus.
not require a gold standard; instead, the set of clusters C in-             1 Note that we retain the pairwise nature of pairwise precision
duced by the model is compared with the set of S-clusters S.           and recall, which leads to the second term in the products (i.e., the
Substitutable precision SP (Eq. 2) thus measures whether the           number of non-identical pairs in a cluster is |c|(|c| − 1))
                                                                            2 We use the word models loosely; the authors of these systems do
clusters consist of substitutable words, while substitutable re-       not always assume that they are modeling human learning, but may
call SR measures to what extent substitutable words have been          only be examining the possible usefulness of distributional cues.
                                                                   2577

 Frequent Frames                                                         larity between vectors is computed using the Spearman rank
 Our first model is based on the frequent frames (FF) proce-             correlation, and a tree structure is created by iteratively clus-
 dure for discovering syntactic categories described by Mintz            tering together the most similar words (or previously created
 (2003), which has been influential in the language acquisi-             clusters). By “cutting” the tree at different heights, different
 tion community (see, e.g., Gómez & Maye 2005). Mintz’s ap-             numbers of clusters can be produced. The best results of Red-
 proach is inspired by behavioral experiments suggesting that            ington et al. (1998) are with n = 1000, m = 150, and two
 human learning of syntactic categories is strongly aided by             positions on either side of each target word as context. We
 the presence of frequently occurring frames (Mintz, 2002).              use the same parameters here.
 In this case, a frame is defined as any ordered pair of words              An important property of this hierarchical clustering (HC)
 (a, b) that occurs in the corpus with a single intervening word.        model is the fact that the context vector for each word type
 (Note that this differs from our use in the context of evalua-          combines the context counts for all tokens of that word.
 tion, where the categories assigned to the words are also in-           Therefore, every token of a particular word is assigned to the
 cluded in the frame.) The most frequent frames in the corpus            same syntactic category, regardless of the specific context in
 are recorded, and for each one, all words that occur within             which it appears.
 that frame are assigned to the same cluster.                               Although HC does not cluster every word in the corpus,
    Our implementation follows Mintz in initially defining a             its coverage is far more complete than that of FF. Even in
 cluster for each frame whose frequency is at least 0.09% 3 of           a very large corpus, Zipf’s law ensures that the 1000 most
 the total number of frames in the corpus. Pairs of clusters with        frequent words account for most of the corpus. Despite its
 the highest overlap in word types, proportionally to the largest        broad coverage, however, HC only performs well on words
 of the two clusters, are then iteratively merged until the target       with high frequency, unlike children, who can learn words
 number of clusters is reached.                                          (and their usage, i.e. their syntactic categories) on the basis of
    One drawback of FF is that only a very small percentage              very few observations (Woodward et al., 1994). In contrast,
 of tokens are clustered (4%–8% in Mintz’s experiments with              FF may categorize some words that occur only once, provided
 corpora of child-directed speech), and these are almost exclu-          they occur inside frequent frames.
 sively nouns and verbs. The clusters do, however, have very             Bayesian Hidden Markov Model
 high accuracy (i.e., words that are grouped together almost al-
                                                                         Unlike the previous algorithmic approaches, the third ap-
 ways belong to the same gold standard category), and Mintz
                                                                         proach is based on a probabilistic model. We consider the
 points out that a much larger percentage of tokens (48%–
                                                                         Bayesian HMM (BHMM) proposed by Goldwater & Grif-
 61%) belong to the same types as those clustered, suggesting
                                                                         fiths (2007) as our third model because it contrasts with the
 that these tokens could be added to the same clusters. How-
                                                                         previous two on several levels: in addition to being based on
 ever, this does nothing to cluster the large number of word
                                                                         a probabilistic model, it categorizes every word in the corpus,
 types that never appear in a frequent frame. Moreover, it ig-
                                                                         and it can deal with ambiguity, i.e., it may assign different
 nores the problem of syntactic ambiguity: first, because it is
                                                                         tokens of the same word type to different clusters.
 not clear what to do if a word type is initially assigned to
                                                                            As a variant of the standard HMM, this model assumes that
 multiple clusters, and second, because it assumes that all re-
                                                                         the corpus is probabilistically generated as a sequence of clus-
 maining tokens should belong to the same cluster, which may
                                                                         ter labels (tags), each of which in turn generates the observed
 not reflect any true ambiguity.
                                                                         word. The model considers different possible sequences of
 Hierarchical Clustering                                                 tags, searching for a sequence that can explain the observed
                                                                         words well, while also being linguistically plausible. In this
 Researchers in both cognitive science and computational lin-
                                                                         case, plausibility is enforced using Bayesian priors to cap-
 guistics have proposed algorithms for syntactic category in-
                                                                         ture the intuition that the HMM transition and output distri-
 duction based on clustering context vectors (Redington et al.,
                                                                         butions are sparse, i.e., that each tag is followed by relatively
 1998; Clark, 2000; Schütze, 1995). We implemented the algo-
                                                                         few other tags with high probability, and outputs relatively
 rithm described by Redington et al. (1998), which has prob-
                                                                         few words with high probability. In contrast to the other mod-
 ably had the most impact in language acquisition. It treats
                                                                         els, neighboring words affect the BHMM’s decision about a
 the n most frequent word types in the corpus as the target
                                                                         word’s category only indirectly, through their category labels.
 words, and the m most frequent types are used as context
                                                                            Our implementation of the BHMM uses Gibbs sampling to
 words (where m < n). For each target word, a context vector
                                                                         identify a sequence of tags that has high probability under the
~v = v1 . . . vm is created, with vi equal to the number of times
                                                                         model. In this implementation, the only free parameter of the
 the ith context word co-occurs with the target word. Specific
                                                                         model is the number of clusters used. In our experiments, we
 context positions (e.g., one word to the left of the target, two
                                                                         ran the Gibbs sampler for 2000 iterations.
 words to the right) are accounted for by collecting separate
 vectors for each position and concatenating them. The simi-                  Model Implementation and Experiments
     3 We use a slightly lower cutoff than Mintz (who used 0.13%) in     For all our experiments, we used the Manchester corpus
 order to have enough frames to make 80 clusters in the experiments.     (Theakston et al., 2001), which is annotated with syntactic
                                                                     2578

       ADJ    Adjectives, e.g., funny, pink                                           Measures      Spearman’s rho
      ADV     Adverbs, e.g., today, just, normally
      OTH     Miscellaneous, e.g., yes, well, hurray                                  SP, PP              0.638∗
     CONJ     Conjunctions, e.g., and, or                                             SR, PR              0.755∗∗
      DET     Determiners, e.g., a, those, six                                        SP, MA              0.677∗
       INF    Infinitival to
         N    Nouns and Pronouns, e.g., you, duckie
      NEG     Negations, e.g., not                                   Table 2: Spearman’s rho correlations between the rankings
     PART     Participles, e.g., raining, hidden                     given by a pair of evaluation metrics (N = 12), computed us-
     PREP     Prepositions, e.g., on, to, after                      ing the merge condition results; **: p < 0.01; *: p < 0.05; all
        QN    Quantifiers, e.g., many, all, some
         V    Verbs, e.g., swim, do, is                              correlations not included in the table are non-significant.
          Table 1: Collapsed gold-standard categories              Model        K      PP        PR     MA           SP                SR
                                                                   Random       12   0.205      0.324  0.796      0.000065         0.254458
                                                                   Random       53   0.096      0.254  0.720      0.000092         0.173907
categories and is part of the CHILDES database (MacWhin-           BHMM         12   0.570      0.263  0.721      0.000221         0.308508
ney, 2000). The Manchester corpus consists of transcribed          BHMM         53   0.624      0.175  0.747      0.000347         0.109927
recordings of 12 children interacting with adults, and cov-        BHMM         80   0.657      0.128  0.775      0.000330         0.084811
ers an age range of 1 year 8 months to 3 years. Our models         HC           12   0.201      0.864  0.361      0.000046         0.375467
are trained only on child-directed speech (CDS), so we re-         HC           53   0.330      0.654  0.523      0.000117         0.202372
moved all child utterances, as well as any utterances contain-     HC           80   0.484      0.512  0.639      0.000159         0.183736
ing unintelligible words; additionally, we split contractions      FF           12   0.220      0.244  0.448      0.000027         0.217124
(e.g., aren’t) into separate words and added beginning-of-         FF           53   0.219      0.079  0.392      0.000039         0.120499
sentence and end-of-sentence markers (which were included          FF           80   0.224      0.053  0.423      0.000043         0.096760
in the frames used to create S-clusters, but not in the frames
used to train the FF model). This left approximately 1.5M            Table 3: Results for the merge condition. The best score
words and 360,000 child-directed utterances.                         for each evaluation type and number-of-clusters condition is
   The original set of syntactic categories used for the Manch-      highlighted.
ester corpus contains detailed morphosyntactic information,
e.g., playing is annotated part|play-PROG. After stripping out       ery token, the FF model assigns categories to only those word
the morphological information, the category inventory con-           types which appear within frequent frames, and the HC model
tained 53 categories. We also created a collapsed inventory          only categorizes the 1000 most frequent word types. We re-
consisting of 12 categories (see Table 1).                           solve this problem in two ways. In the merge condition, we
   For each of the models described in the previous section,         combine all words that are not clustered by the model into
we varied the number of clusters K over three conditions: 12         one large cluster. In the split condition, we assign each un-
(as in the collapsed category inventory), 53 (as in the original     clustered word to its own cluster. The difference in perfor-
inventory) and 80 (to create more fine-grained clusters). One        mance between these two conditions thus indicates the effect
of the advantages of the substitutable precision-recall mea-         of the unclustered words.
sures is that they do not depend on the gold standard for the           Additionally, it is necessary to assign each token in the
“true” number of clusters; thus there is no penalty for a clus-      text to a category, if the model does not categorize tokens (as
tering that does not have the same number of clusters as the         BHMM does). For HC, each token of a given type is assigned
gold standard.                                                       to the type’s category. In the FF model, a word type can be-
   We also compared each K condition against a random base-          long to multiple categories, making it unclear which cate-
line. For each cluster in the gold standard, we created a clus-      gory a particular token should be assigned to. We assigned
ter with the same number of word types, selected at random           tokens found in frequent frames to the category defined by
from the full vocabulary (the K = 80 and K = 53 conditions           that frame; other instances of ambiguous types were assigned
shared the same random baseline). This results in a random           to a given cluster with probability p(ci |wi ) = ∑ |ci | |c| , that is,
                                                                                                                       c:w∈c
clustering with the same cluster size distribution as the gold       according to the size of the clusters that include the ambigu-
standard, and all tokens of each type in the same cluster.           ous word type.
   Our goal is to show that substitutable precision and recall
yield informative evaluation results without requiring a gold                                     Results
standard. We therefore evaluated each category acquisition           The results are given in Table 3. We first discuss them in light
model not only with substitutable precision and recall, SP and       of our proposed evaluation measures, SP and SR, and then go
SR, but also with the measures introduced earlier: matched           on to compare the performance of the different models.
accuracy MA and pairwise precision PP and recall PR.
   A problem arises, however, when we try to compare the             Comparison of Evaluation Measures
three clustering models: they each categorize a different sub-       Figure 1 shows the similar performance of the two precision-
set of the data. The BHMM model assigns categories to ev-            recall measures. Results for SP and SR are significantly cor-
                                                                 2579

                                                      Pairwise Precision and Recall                                                 Substitutable Precision and Recall
                             0.9                                                                                         0.4
                                                                               Random                                                                       Random
                             0.8                                                BHMM                                    0.35                                 BHMM
                                                                                   HC                                                                           HC
                             0.7                                                   FF                                                                           FF
                                                                                                                         0.3
                             0.6
                                                                                                                        0.25
                  Recall                                                                                       Recall
                             0.5
                             0.4                                                                                         0.2
                             0.3
                                                                                                                        0.15
                             0.2
                             0.1                                                                                         0.1
                                 0                                                                                      0.05
                                      0        0.1      0.2      0.3    0.4          0.5        0.6      0.7                   0     0.0001      0.0002        0.0003     0.0004
                                                                 Precision                                                                      Precision
Figure 1: Pairwise precision and recall on the left, substitutable precision and recall on the right. The size of the points indicates
the number of clusters: small points are for 12 clusters, medium points for 53, large points for 80. HC and FF results are for the
merge condition.
                                     12 clusters              53 clusters                  80 clusters
                    10000                            10000                  10000
                                                                                                                  method and the S-clusters. This demonstrates the importance
                                                                                         GS
                                                                                       BHMM
                                                                                                                  of using separate testing data: the FF models were unable to
                                                                                         HC
                                                                                          FF
                                                                                                                  generalize to new data.
                       1000                           1000                    1000
                                                                                                                  Model Performance
Size of cluster
                                                                                                                  The different model types find very different word cluster-
                           100                         100                     100
                                                                                                                  ings, as Fig. 2 helps to illustrate. HC creates clusters with
                                                                                                                  highly skewed sizes (most extremely so in the 12 cluster con-
                           10                           10                     10                                 dition, in which 969 of the 1000 clustered word types are put
                                                                                                                  into one cluster). The cluster size distribution of FF models
                                                                                                                  is much flatter, indicative of FF’s propensity to create highly
                            1                           1                       1                                 ambiguous clusterings, in which each word type belongs to
                                                                                                                  many clusters. The BHMM clusterings also have higher lev-
Figure 2: Ranked cluster sizes, measured in types: the x-axis                                                     els of lexical ambiguity than the gold standard, resulting in
represents the clusters, which are ordered according to size;                                                     more larger clusters overall, both in terms of types and tokens.
the y-axis gives the size of the clusters on a log scale (GS:                                                     Both BHMM and FF tend towards more ambiguity with more
gold standard; BHMM: Bayesian HMM; HC: hierarchical                                                               clusters. It should be noted as well that the token distributions
clustering, FF: frequent frames). Note the random baseline                                                        are highly similar to the type distributions.
clusters have the same type-size-distribution as GS.                                                                 Keeping these distributions in mind, we can ask how they
                                                                                                                  affect the evaluation metrics. We expect clusterings with
                                                                                                                  peaked distributions (most words in few clusters) to per-
related with PP and PR, respectively (Table 2). SP also cor-                                                      form better on recall-based measures (PR, SR), whereas flat-
relates with MA significantly. This demonstrates that without                                                     ter distributions with high ambiguity may perform better on
using the gold standard, SP and SR can capture similar dis-                                                       precision-based measures (MA, PP, SP). Indeed, we find this
tinctions as PP, PR, and MA.                                                                                      to be the case. BHMM models perform best on PP, MA, and
   The values of SP that we obtain are extremely small. This is                                                   SP, while HC models perform best on PR and SR (Table 3).
due to the fact that, overall, the S-clusters from the frames are                                                 The Random baseline clusterings do surprisingly well, out-
much smaller than the model clusters. Because the S-clusters                                                      performing FF on several measures — even slightly on SP
are gathered from a finite set of data, they do not describe                                                      and SR, for which there should be less advantage for baseline
complete substitutability. In other words, while membership                                                       models linked to the gold-standard. This underlines the im-
in a cluster implies substitutability, non-membership does not                                                    portance of finding clusters with gold-standard-like size dis-
rule out substitutability. However, all models are penalized                                                      tributions.
equally by this lack of complete data.
   It is also interesting to note that the FF models did not do                                                   Effect of Unclustered Words
better when evaluated on SP and SR, compared to PP and PR,                                                        Both the HC and FF do not cluster all word types found in
despite superficial similarities between the model’s clustering                                                   the training data. The HC model clusters only the most fre-
                                                                                                           2580

  Model     K      PP       PR      MA        SP          SR         Finally, we also demonstrated that evaluation results strongly
  HC        12    0.016   0.750    0.380   0.000030    0.193955
  HC        53    0.059   0.405    0.550   0.000061    0.061327      depend on how unclustered words are evaluated.
  HC        80    0.086   0.338    0.666   0.000091    0.046781         In future work, we will explore the external validity of sub-
  FF        12    0.219   0.238    0.486   0.000018    0.095166      stitutable precision and recall. While it is important to show
  FF        53    0.240   0.072    0.440   0.000028    0.023271
  FF        80    0.260   0.046    0.471   0.000035    0.014687      that it correlates with existing evaluation measures, we also
                                                                     need to test it against experimental data (e.g., substitutability
Table 4: Results for the split condition. Scores that have im-       judgments). Additionally, we plan to apply it to longitudinal
proved with respect to the merge condition are in bold.              acquisition corpora to evaluate models which follow the time
                                                                     course of category development.
quent 1000 types, which in our data set make up only 9% of                                     References
types, but account for 95% of the tokens. FF clusters more
                                                                     Brown, R., & Fraser, C. (1964). The acquisition of syntax.
types (70%), but these also make up 95% of tokens, indicat-
                                                                        Monographs of the Society for Research in Child Develop-
ing that some frequent words (i.e., the words in the frames
                                                                        ment, 29(1), 43–79.
themselves) remain unclustered.
   In the split condition, the remaining types are split up          Clark, A. (2000). Inducing syntactic categories by context
into separate clusters, while in the merge condition they are           distribution clustering. In Proceedings of CoNNL (pp. 91–
merged into one large cluster. Splitting up unclustered words           94).
improved MA performance for both HC and FF. This increase            Goldwater, S., & Griffiths, T. (2007). A fully Bayesian ap-
in MA is expected, given that smaller clusters result in higher         proach to unsupervised part-of-speech tagging. In Pro-
accuracy, but the increase was only slight, since relatively few        ceedings of ACL (pp. 744–751).
word tokens were affected. FF models with more clusters also         Gómez, R., & Maye, J. (2005). The developmental trajectory
also saw higher PP performance. This again is to be expected;           of nonadjacent dependency learning. Infancy, 7, 183–206.
more surprising is the fact that HC models did not improve.          Harris, Z. (1946). From morpheme to utterance. Language,
This indicates that much of HC’s performance in the merge               22(3), 161–183.
condition was due to the unclustered-words cluster, which in-        Kemp, N., Lieven, E., & Tomasello, M. (2005). Young chil-
cluded 90% of the word types (and thus many with the same               dren’s knowledge of the “determiner” and “adjective” cat-
gold standard category).                                                egories. Journal of Speech, Language, and Hearing Re-
   SP and SR also decrease in the split condition, in most              search, 48(3), 592–609.
cases by nearly 50%. This also indicates that original per-
                                                                     MacWhinney, B.(2000). The CHILDES project: Tools for an-
formance was greatly boosted by the unclustered-words clus-
                                                                        alyzing talk. Mahwah, NJ: Lawrence Erlbaum Associates.
ter, since as a pairwise measure, SP and SR do not capture
clusters with only one word type, effectively removing the           Mintz, T.(2002). Category induction from distributional cues
unclustered words from this measure.                                    in an artificial language. Memory and Cognition, 30, 678–
                                                                        686.
             Conclusions and Future Work                             Mintz, T. (2003). Frequent frames as a cue for grammatical
This paper dealt with the problem of evaluating computa-                categories in child directed speech. Cognition, 90, 91–117.
tional models of human syntactic category acquisition. We            Olguin, R., & Tomasello, M. (1993). Twenty-five-month-old
started from the observation that children’s syntactic cate-            children do not have a grammatical category of verb. Cog-
gories change during language development, which means                  nitive Development, 8(3), 245–272.
that an evaluation against a fixed gold-standard (typically          Parisien, C., Fazly, A., & Stevenson, S.(2008). An incremen-
based on adult linguistic intuitions) is not adequate. As an            tal Bayesian model for learning syntactic categories. In
alternative, we proposed substitutable precision and recall,            Proceedings of CoNLL (pp. 89–96).
a measure based on the idea that words which share the               Redington, M., Chater, N., & Finch, S. (1998). Distributional
same category occur in similar syntactic environments. We               information: a powerful cue for acquiring syntactic cate-
showed that our new measure significantly correlates with ex-           gories. Cognitive Science, 22, 425–469.
isting, gold-standard measures: substitutable precision corre-
                                                                     Schütze, H. (1995). Distributional part-of-speech tagging. In
lates with pairwise precision and matched accuracy, and sub-
                                                                        Proceedings of EACL (pp. 141–148).
stitutable recall correlates with pairwise recall.
   This paper also presented the first systematic comparison         Theakston, A. L., Lieven, E. V., Pine, J. M., & Rowland, C. F.
of three standard acquisition models from the literature: Red-          (2001). The role of performance limitations in the acqui-
ington et al.’s (1998) hierarchical clustering model, which             sition of verb-argument structure: an alternative account.
performed well on recall-oriented measures, Goldwater &                 Journal of Child Language, 28, 127–152.
Griffiths’s (2007) Bayesian HMM, which performed well                Woodward, A. L., Markman, E. M., & Fitzsimmons, C. M.
on precision-oriented measures, and Mintz’s (2003) frequent             (1994). Rapid word learning in 13- and 18-month-olds.
frame model which showed surprisingly poor performance.                 Developmental Psychology, 30(4), 553-566.
                                                                 2581

