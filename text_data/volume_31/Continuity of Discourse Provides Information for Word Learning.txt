UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Continuity of Discourse Provides Information for Word Learning
Permalink
https://escholarship.org/uc/item/7ks028bq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Fernald, Anne
Frank, Michael
Goodman, Noah
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                Continuity of Discourse Provides Information for Word Learning
                              Michael C. Frank, Noah D. Goodman, and Joshua B. Tenenbaum
                                                     {mcfrank, ndg, jbt}@mit.edu
                                               Department of Brain and Cognitive Sciences
                                                   Massachusetts Institute of Technology
                                                                Anne Fernald
                                                          afernald@stanford.edu
                                                          Department of Psychology
                                                              Stanford University
                               Abstract                                  makes use of the continuity of discourse in conversation. If
                                                                         the second guest’s remark had come an hour or even a minute
   Utterances that are close in time are more likely to share the
   same referent. A word learner who is using information about          after the first remark, the learner would have had much more
   the speaker’s intended referents should be able to take advan-        uncertainty about the topic of conversation.
   tage of this continuity and learn words more efficiently by ag-          Discourse structure has been well-studied in psycholin-
   gregating information across multiple utterances. In the cur-
   rent study we use corpus data to explore the continuity of ref-       guistics (Graesser et al., 1997). Despite this—and despite
   erence in caregivers’ speech to infants. We measure the degree        the potential utility of discourse information in word learn-
   of referential continuity in two corpora and then use regression      ing, as illustrated by the dinner party example—research on
   modeling to test whether reference continuity is informative
   about speakers’ referential intentions. We conclude by devel-         word learning has largely neglected the role of discourse con-
   oping a simple discourse-continuity prior within a Bayesian           tinuity. For example, although a number of recent computa-
   model of word learning. Our results suggest that discourse            tional models use cross-situational information about the co-
   continuity may be a valuable information source in early word
   learning.                                                             occurrence of words and referents for word learning, most
   Keywords: Language acquisition; discourse; word learning;             of these models assume that utterances are sampled indepen-
   Bayesian modeling                                                     dently from one another with respect to time, throwing away
                                                                         important information about the order of utterances (Siskind,
                           Introduction                                  1996; Yu & Ballard, 2007; Frank et al., in press).1
Imagine attending a dinner party where you don’t speak the                  Our goal in the current paper is to investigate the utility
language very well. Most of the time you will likely have                of discourse continuity for word learning. Although a more
trouble understanding what the conversation is about, and if             elaborate model of discourse would contain abstract topics
you don’t understand what is being talked about, you will                like “the quality of the food served in the main course,” here
have a hard time guessing the meanings of new words. There               we consider a very simplified version of talking about the
may be opportunities, however, where you can guess the topic             same topic: talking about the same object (continuity of ref-
of conversation and infer some word meanings. For exam-                  erence), which is common in interactions with infants. Al-
ple, if a guest gestures towards her dinner plate as she makes           though this approach may throw away more abstract informa-
a comment, you can guess that the topic of conversation is               tion about the kind of activity or action that the child and care-
the food and perhaps that one of the words she used means                giver are jointly involved in, it is more likely to be the kind
“trout.”                                                                 of information available to even the youngest word learner.
   The problem of word learning has a similar structure for              For the rest of the paper, we will use the terms “continuity of
children learning their first language. If they are engaged in           reference” and “discourse” interchangeably.
a joint activity or even a moment of joint attention, they can              The plan of the paper is as follows. We first introduce the
use this information to make inferences about the speakers’              corpora we studied. We next discuss a simple model of how
referential intentions and the meanings of words (Tomasello,             to measure about continuity of reference within these corpora
2001). Our recent computational work has elaborated this                 and use a supervised (regression) model to test whether dis-
idea—that inferring the intentions of a speaker can give a so-           course continuity provides information about speakers’ refer-
phisticated word learner leverage in inferring the meanings of           ential intentions. We then end by creating a simple prior dis-
the words the speaker uses (Frank et al., in press).                     tribution over referential intentions which favors continuity
   Going back to our dinner party, a learner who assumes the             of reference and applying it within our model of intentional
guest’s utterance is about the trout is making use of imme-              word learning.
diate contextual information about the speaker’s intentions.                 1 But cf. Roy & Pentland (2002), who used a recurrence filter to
But if a second guest speaks up immediately afterwards, the              take into account temporal information.
learner could guess with some certainty that this remark also
has to do with the trout (or if not, at least the potatoes or the
salad). This kind of aggregation of information across time
                                                                     1418

                                                                     the name of the object or a pronoun referring to that object.
                                                                     For each of the corpora, we coded the referential intention
                                                                     for all of each caregiver’s utterances. For example, in a sen-
                                                                     tence like “look at the doggie,” the referential intention would
                                                                     clearly be to talk about the dog. Likewise, in an utterance like
                                                                     “look at his eyes and ears,” (where the caregiver was point-
                                                                     ing at the dog), the referential intention would also be the
                                                                     dog—though the coder would need to make reference to the
                                                                     videotape to determine the pronoun reference. We did not
                                                                     mark the use of property terms like “red,” super-/subordinate
                                                                     terms like “animal” or “poodle,” or part terms like “eye.” Ex-
                                                                     clamations like “oh” were not judged to be referential, even if
                                                                     they were directed at an object. Objects that were not present
                                                                     were still judged to be part of a referential intention, e.g., “do
                                                                     you like to read books” would be judged to have the intention
        Figure 1: A sample frame from the FM corpus.
                                                                     book even if the child could not see a book or a book was not
                                                                     present in the scene at all.
                   Corpora and coding                                   In addition to coding the referential intention of the
For our initial analysis of discourse continuity, we chose to        speaker, for each utterance we also coded the mid-sized ob-
study corpora of child-caregiver interactions by annotating          jects present in the field of view of the learner at the time of
them with information relevant to discourse. For our anal-           the utterance. A sample frame from the FM corpus is shown
ysis, we chose corpora based on two criteria. First, corpora         in Figure 1. The only object judged to be in the field of view
needed to include video as well as audio so that we could ac-        of the child at the time of the utterance most proximate to this
curately identify both the speaker’s referential intentions (the     frame was the dog. The end product of this coding effort was
objects they were talking about) and the objects present in the      two corpora, one of around 600 utterances and one of almost
physical context. Second, corpora needed to be collected in a        8000 utterances, for which each utterance was annotated with
restricted enough context that it would be feasible to code the      the objects present in the field of view of the learner and the
entire set of plausible referents for a word, so that the set of     referential intention(s) of the speaker.
alternative referents for a word could be considered.
   We selected two corpora which fulfilled these require-                                Predicting reference
ments. The first was a pair of two 10 minute videos from the         The first goal of our study was to investigate and describe fac-
CHILDES Rollins corpus (me03 and di06) (MacWhinney,                  tors involved in determining whether objects are referred to in
2000). These videos recorded mothers interacting with pre-           caregivers’ speech to children. Towards this goal, we first de-
verbal infants by selecting toys from a larger set. The videos       veloped a visualization of reference in child-directed speech;
contained 316 and 303 utterances which made reference to 21          we then attempted to quantify the contributions of physical
and 18 toys, respectively. This corpus was previously used in        presence, discourse continuity, and discourse novelty to ob-
several computational studies of cross-situational word learn-       ject reference.
ing (Yu & Ballard, 2007; Frank et al., in press).
   The second corpus was a larger set of videos of object-           Visualizing continuity of discourse
centered play between mothers and children in their homes,           The first step we took towards understanding the prevalence
collected by Fernald & Morikawa (1993). We refer to this             of discourse continuity in the Rollins and FM corpora was to
as the FM corpus. Although the original study considered             visualize the results of our coding. We introduce what we call
videos of American and Japanese mothers, in the current              a “Gleitman plot”: a visualization of a stretch of discourse
study we only made use of the American data. There were              based on (1) what objects are present and (2) what objects are
24 total videos, ranging from approximately 10 to 30 min-            being talked about.2 Example Gleitman plots for one file in
utes and containing from 82 to 554 utterances (mean = 311)           each of the corpora are shown in Figure 2.
which made reference to 44 total objects. The children in               We can draw two anecdotal conclusions on the basis of
these videos fell into three age groups: 6 months (N=8), 11-         these visualizations. First, within the corpora we studied,
14 months (N=8), and 18-20 months (N=8). Mothers in the              mothers talk primarily about objects that are present in the
videos were given several pairs of toys by the experimenter          field of view of the children. This can be seen by examining
and asked to play with each pair for a 3-5 minute period; thus,      the spread of green within each plot. The largest bout of green
similar to the Rollins corpus, the total set of objects present      is in the lower of the two plots, when the mother is playing
in the videos was severely restricted.                               a hiding game with several of the toys. For a word learner
   We operationalized “referential intention” as an intention            2 Named because Gleitman (1990) was concerned with the rela-
to refer linguistically to an object. We coded an utterance          tionship between what is present in a learner’s experience and what
as referring to an object when the utterance contained either        is being talked about.
                                                                 1419

                                                    Rollins corpus: example 6 month old
 woman
    teeth
      ring
    rattle
       pig
  mouth
   mirror
     man
    lamb
     kitty
   horse
       hat
    hand
       girl
     face
    eyes
    duck
     cow
  bunny
      boy
   bottle
    book
      bird
  bigbird
     bear
    baby
   alison
            0    20      40      60     80      100     120     140        160     180     200      220     240     260    280    300
                                                                   utterance
                                                     FM Corpus: example 12 month old
    truck
       pig
      dog
       car
   brush
      box
    book
      ball
            0       20         40        60         80         100           120        140         160         180      200        220
                                                                   utterance
Figure 2: Example Gleitman plots for videos from the Rollins and FM corpora. Each row represents an object, each column
represents an utterance. A blue mark denotes that the object was present when the utterance was uttered but not mentioned;
a green mark denotes that the object was mentioned but not present; and a red mark denotes that the object was present and
mentioned. The streaks of red indicate bouts of continuous utterances referring to a particular object.
guessing the meaning of a novel word, the best guess will               at time t. Next we defined the probability of discourse con-
likely be that the word refers to an object that is present, al-        tinuity PD (o). This measure captures the probability of an
though though this generalization may not be nearly as useful           object being talked about, given that it was talked about in
when learning verbs rather than nouns (Gleitman, 1990).                 the sentence before:
    Second, we can see clear evidence of discourse continuity
in both files. Rather than being distributed evenly throughout                                        ∑ Rt (o)Rt−1 (o)
                                                                                                        t
the span of time when an object is present, references to an                                PD (o) =                                  (1)
object are “clumpy”: they cluster together in bouts of refer-                                             ∑ Rt (o)
                                                                                                          t
ence to a single object followed by a switch to a different ob-
ject. This can be seen for example in the car / truck portion              We calculated PD (o) for each object for the times when it
of the FM example (utterances 47 - 67), where the mother al-            was present in the physical context. We then took an average
ternates several times between the two objects, talking about           of PD (o) over all objects, weighted by the frequency of each
each object for several sentences before switching.                     object, to produce an average value for each file.
                                                                           We then estimated a baseline value for PD via permutation
Quantifying continuity of discourse                                     analysis. Intuitively, this analysis asks what a “chance” value
In our visualizations of discourse continuity, we observed              for PD would be if utterances were completely independent of
“clumps” of references to a particular object rather than a             one another. We calculated this baseline value for each corpus
more uniform distribution of references over time. To quan-             file by recomputing PD (o) for 100 random permutations of
tify this trend, we first defined a quantitative measure of dis-
course continuity. For an object o, we defined Rt (o) as a delta
function returning whether or not that object was referred to
                                                                 1420

                       10                                                                                    0.4
                                                                         probability of being talked about
                                                          corpus                                                                              lowess smoothing function
                                                          permuted                                                                            exponential fit
                       8                                                                                     0.3
number of caregivers
                       6                                                                                     0.2
                       4                                                                                     0.1
                       2                                                                                     0.0
                                                                                                                   0          50           100          150           200
                       0                                                                                               utterances for which object has been present
                            0.1   0.2   0.3   0.4   0.5   0.6   0.7
                                              PD                         Figure 4: The mean probability of an object being talked
                                                                         about as the number of utterances for which the object was
                                                                         present increases. Data are for the FM corpus.
Figure 3: A histogram of the mean value of PD (probability
of discourse continuity) for each file in the FM corpus (dark               To quantify the effects of discourse novelty on the proba-
gray) and for permuted baseline values (light gray).                     bility of talking about an object, we plotted the mean proba-
                                                                         bility that an object was being talked about (given that it was
the times at which each object was talked about.3 For the                present) by the number of utterances for which the object had
Gleitman plots in Figure 2, this analysis would be represented           been present. We performed this analysis only on the FM
by randomly shuffling all the red and blue squares in each row           corpus, since the Rollins corpus was too sparse to provide
so that the same overall set of squares were red and blue but            accurate estimates. The results are plotted in Figure 4; the
their distribution was different.                                        resulting curve was well-described by an exponential func-
   The results of this analysis for the FM corpus are shown              tion, capturing the generalization that the longer an object is
in Figure 3. As predicted based on our visualizations, PD                present, the less likely it is to be talked about.
differed significantly from the permuted baseline (paired
t(23) = 7.85, p < .0001, Cohen’s d = 1.50). In addition, in              Regression modeling
a simple linear regression, we found no relationship between             In the previous sections we discussed three factors which con-
PD and age (r2 = 0.067, p = .22). For the Rollins files, the             tributed to an object being talked about within the corpora we
mean values of PD were .46 and .61 for the di06 and me03                 studied: whether it was physically present, whether it was be-
files, respectively.                                                     ing talked about in the previous sentence, and whether it was
                                                                         relatively new in the context. In our next analysis we set out
Quantifying discourse novelty
                                                                         to quantify their relative contributions to predicting speakers’
An object’s novelty in the context provides an additional fac-           reference. To do this, we used multi-level logistic regression
tor governing how likely a speaker is to refer to an object. In-         models (Gelman & Hill, 2006). We selected a logistic regres-
tuitively, an object that is newly part of the physical context is       sion since the predicted measure—referring to an object or
more likely to be talked about, and some some empirical evi-             not—was binary, and we used a multi-level model in order to
dence suggests that children may be able to make use of this             estimate and remove variance due to the effects of different
information to learn new words. Akhtar et al. (1996) found               objects and speakers.
that two-year-olds were able to use the fact that an object was             We fit a single regression model for each of the two cor-
new to the experimenter (even though the children themselves             pora. This model predicted whether an object would be talked
had already played with it) to infer that the object was the ex-         about at a particular time and incorporated group-level fixed
perimenter’s intended referent and hence was named by the                effects of (1) presence, whether an object was present in the
novel word the experimenter produced.                                    physical context; (2) discourse continuity, whether an object
    3 Excluding utterances during which an object was not present        was referred to in the previous utterance; and (3) discourse
was important in calculating an accurate baseline; had we permuted       novelty, whether an object was new in the physical context;
all utterances, we would have artificially deflated the baseline by      along with partially-crossed random effects of caregiver and
spreading references to o across the entire file even when o was not
present.                                                                 object. Fixed effects were relatively uncorrelated (pairwise r
                                                                         values less than .34 for all predictors). Random effects served
                                                                      1421

                        Rollins coefficients                                         FM coefficients                           Using discourse continuity for word learning
                   6                                                            6                                          The results of the previous analyses suggested that expecta-
                                                                                                                           tions about discourse may help a learner guess what is being
                   4                                                            4                                          talked about. In our final analysis we explored the possibility
                                                                                                                           of using discourse information in an unsupervised model of
model coefficent                                             model coefficent
                   2                                                            2
                                                                                                                           word learning.
                   0                                                            0
                                                                                                                              We began with the intentional word learning model de-
                   -2                                                           -2                                         scribed in Frank et al. (in press). This model takes as its
                                                                                                                           inputs a set of situations: utterances and the objects that are
                   -4                                                           -4
                                                                                                                           present at the time of the utterance. It assumes first that for
                   -6                                                           -6                                         every situation, the speaker has chosen some subset of the ob-
                                                                                                                           jects in the situation to talk about (possibly an empty subset).
                                  present   previous                                         present   previous
                   -8                                                           -8
                          icept                                                      icept
                                                                                                                           These objects comprise her referential intention. The model
                                                       new                                                        new
                                                                                                                           assumes second that the speaker is likely to utter words that
                                  predictor                                                  predictor
                                                                                                                           are linked to these objects in the lexicon, in addition to some
                                                                                                                           number of other words that do not refer directly to objects
                                                                                                                           in the situation. These two assumptions and the pattern of
Figure 5: Coefficient estimates for mixed logistic regressions                                                             co-occurrences between words and objects in the data jointly
predicting whether an object would be talked about in a par-                                                               define a probability distribution over two latent states: the lex-
ticular utterance. Models are for the Rollins corpus (left) and                                                            icon of the language (the set of mappings between words and
the FM corpus (right). Predictors are (from left to right), the                                                            objects) and the referential intention of the speaker in each
model intercept, whether the object was present, whether the                                                               situation.
object had been talked about in the previous utterance, and                                                                   In the work reported in Frank et al. (in press), solving for
whether this was the first utterance during which the object                                                               the most probable lexicon using Bayesian inference resulted
was physically present.                                                                                                    in learning a more accurate lexicon than purely associative
                                                                                                                           models. But in these simulations, situations were assumed to
to remove systematic variation due to differences in how of-                                                               be sampled independently from one another and no other in-
ten particular caregivers used referential language and how                                                                formation about referential intentions was given to the model.
frequently different objects were referred to.                                                                             Therefore, the model assumed a uniform probability distri-
    The results of this analysis are shown in Figure 5. For both                                                           bution over intentions. Our current work suggests that this
corpora, the models had large negative intercepts, indicating a                                                            uniform prior over intentions may be inappropriate. To make
very low likelihood of talking about any given object a priori.                                                            a preliminary test of whether altering this assumption might
We saw a highly significant positive coefficient on the object                                                             result in more effective learning, we constructed a prior dis-
being present in the physical context for both models (both                                                                tribution which privileged continuity of intention.
ps < .0001), though the difference in coefficient estimates
(4.50 for Rollins versus 2.97 for FM) was likely an artifact                                                               A discourse continuity prior
due to the greater diversity of objects present in the Rollins                                                             Our original model assumed that the speaker’s referential in-
study. In addition, we saw a highly significant positive coef-                                                             tention at time t, It , was chosen uniformly from all the possi-
ficient on the discourse continuity term for both models (both                                                             ble subsets of the objects present at that time (Ot? , the power
ps < .0001); these coefficients are comparable and they are                                                                set of Ot ). To define a prior that takes into account discourse
very similar in magnitude (2.21 for Rollins and 2.80 for FM).                                                              continuity, we create a dependency between It and It−1 . We
Finally, we saw a difference between the two models in the                                                                 assume that when choosing It , the previous intention It−1 can
discourse newness predictor. While this predictor was signif-                                                              be chosen with probability δ, or a new intention can be chosen
icant for the FM corpus (p < .0001), it did not reach signifi-                                                             uniformly from Ot? with probability 1 − δ. (If the objects in
cance for the Rollins corpus (p = 0.94), possibly due to data                                                              Ot−1 were not no longer present in Ot , we assumed a uniform
sparsity.                                                                                                                  choice over the new possible intentions).
    These regression models take a first step towards quantify-                                                               By introducing this temporal dependency, the discourse
ing some intuitions about the utility of discourse continuity.                                                             prior converts the original word learning model into a hidden
For the most part, caregivers talk about what is present. If                                                               Markov model in which the intention is the hidden state. To
something new has come along, they are likely to talk about                                                                score a lexicon during inference, we summed over all possible
it, and if not, they will likely keep talking about what they                                                              sequences of intentions using the forward algorithm (Rabiner,
were talking about a moment ago. While none of these three                                                                 1989).
regularities are hard-and-fast rules, they may allow a learner
to make a good guess about what is being talked about in                                                                   Simulation Data
cases which would otherwise be ambiguous.                                                                                  We made a preliminary test of our discourse continuity prior
                                                                                                                           by creating a small corpus in which the reference of a novel
                                                                                                                        1422

                             situation 1                                  Our aim here has been to identify what we believe to be
                words:    “look at this”!                              an important source of information for word learning. Work
                                                                       on language understanding has long acknowledged the im-
                                                                       portance of discourse information (Graesser et al., 1997). In
               objects:   O1   ! O2 !     O3!                          contrast, researchers studying word learning are only begin-
                                                                       ning to conceptualize this task as language understanding in
                  observed intention
                                                                       the presence of uncertainty about the meanings of words. We
                             situation 2                               hope that our work here inspires future research into connec-
            original model               discourse model               tions between language understanding and language learning.
           “it’s a dax”!                  “it’s a dax”!
                                                                                           Acknowledgments
            .33              .33          .54         .23
                        .33                       .23                  We gratefully acknowledge the work of Maeve Cullinane in
          O1     ! O2 !      O3!        O1     O2 !   O3!              coding the FM corpus. Thanks to Steve Piantadosi and the
                                                                       members of tedlab and cocosci for valuable comments. This
Figure 6: A schematic depiction of the two key situations in           work supported by a Jacob Javits Graduate Fellowship to the
our simulation. In situation 2, the relative probabilities of lex-     first author and NSF DDRIG #0746251.
icons including different links between the novel words and
the objects are shown for the original model and the discourse                                  References
model.                                                                 Akhtar, N., Carpenter, M., & Tomasello, M. (1996). The role
                                                                          of discourse novelty in early word learning. Child Devel-
word was ambiguous, but the speaker’s intention was re-                   opment, 67, 635-645.
vealed in the previous situation (pictured in Figure 6). One           Fernald, A., & Morikawa, H. (1993). Common themes
way of conceptualizing this corpus is as a simple, child-                 and cultural variations in japanese and american mothers’
directed version of the dinner party example with which we                speech to infants. Child Development, 64, 637–56.
began the paper. A first utterance (“Look at this!”), com-             Frank, M. C., Goodman, N. D., & Tenenbaum, J. B.(in press).
bined with some sort of clear intentional cue (e.g., a look or            Using speakers’ referential intentions to model early cross-
a point to the intended object), establishes the discourse ref-           situational word learning. Psychological Science.
erent. Then, the following utterance names the object with a
                                                                       Gelman, A., & Hill, J.(2006). Data analysis using regression
novel word (e.g., “It’s a dax.”). Other situations, not shown,
                                                                          and multilevel/hierarchical models. New York: Cambridge
gave examples of the familiar words (e.g. “look”) in a range
                                                                          University Press.
of other contexts and established that they did not consistently
refer to any single object.                                            Gleitman, L.(1990). The structural sources of verb meanings.
   We ran both the original model and the model with the dis-             Language Acquisition, 1, 3–55.
course prior on this artificial corpus. We found that while            Graesser, A., Millis, K., & Zwaan, R.(1997). Discourse com-
the original model was not able to learn the mapping be-                  prehension. Annual Reviews in Psychology, 48, 163–189.
tween the novel word and the previously-intended object,               MacWhinney, B. (2000). The CHILDES Project: Tools for
the discourse model preferred a lexicon which included this               Analyzing Talk. Third Edition. Mahwah, NJ: Lawrence Erl-
mapping. Thus, including the discourse prior in the model                 baum Associates.
allowed it to make use of the intentional information even             Rabiner, L. (1989). A tutorial on hidden Markov models and
though it did not co-occur precisely with the novel word.                 selected applications in speech recognition. Proceedings
                                                                          of the IEEE, 77, 257–286.
                      General Discussion
                                                                       Roy, D., & Pentland, A. (2002). Learning words from sights
We began by suggesting that a word learner could take ad-                 and sounds: a computational model. Cognitive Science,
vantage of the continuity of discourse to aggregate informa-              26, 113–146.
tion about speakers’ intentions over time and then use better
                                                                       Siskind, J.(1996). A computational study of cross-situational
guesses about intention to learn words more effectively. To
                                                                          techniques for learning word-to-meaning mappings. Cog-
support this claim we analyzed two corpora of mother-child
                                                                          nition, 61, 39–91.
interactions. We found first, that caregivers’ discourse was
extremely continuous across a range of ages and situations,            Tomasello, M. (2001). Perceiving intentions and learning
and second, that for a supervised learner what a speaker had              words in the second year of life. In Language acquisition
just talked about was informative about what she was going                and conceptual development (pp. 132–159). New York:
to talk about. We then added a prior on discourse continuity              Cambridge University Press.
into our unsupervised model of word learning and found that            Yu, C., & Ballard, D. (2007). A unified model of early word
this prior allowed learning in situations that would otherwise            learning: Integrating statistical and social cues. Neurocom-
be ambiguous.                                                             puting, 70, 2149–2165.
                                                                   1423

