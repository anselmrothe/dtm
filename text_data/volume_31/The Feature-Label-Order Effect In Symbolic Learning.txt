UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Feature-Label-Order Effect In Symbolic Learning
Permalink
https://escholarship.org/uc/item/0g57k59z
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Dye, Melody
Kalchbrenner, Nal
Ramscar, Michael
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                   The Feature-Label-Order Effect In Symbolic Learning
                     Michael Ramscar, Daniel Yarlett, Melody Dye, & Nal Kalchbrenner
                                      Department of Psychology, Stanford University,
                                               Jordan Hall, Stanford, CA 94305.
                           Abstract                               when they are over-predicted (Kamin, 1969; Rescorla
                                                                  & Wagner, 1972). As a result, cues compete for
  We present a formal analysis of symbolic learning that          relevance, and the outcome of this competition is
  predicts significant differences in symbolic learning           shaped both by positive evidence about co-occurrences
  depending on the sequencing of semantic features and
                                                                  between cues and predicted events, and negative
  labels. A computational simulation confirms the Feature-
  Label-Ordering (FLO) effect in learning that our analysis
                                                                  evidence about non-occurrences of predicted events.
  predicts. Discrimination learning is facilitated when           This process produces patterns of learning that are very
  semantic features predict labels, but not when labels           different from what would be expected if learning were
  predict semantic features. A behavioral study confirms          shaped by positive evidence alone (a common portrayal
  the predictions of the simulation. Our results and analysis     of Pavlovian conditioning, Rescorla, 1988).
  suggest that the semantic categories people use to
  understand and communicate about the world might only           Symbolic learning
  be learnable when labels are predicted from objects.
                                                                     Language learning involves acquiring information
                        Introduction                              about the relations between labels and their semantic
                                                                  features. Here we define labels as tokens of language,
  The ways in which symbolic knowledge is learned
                                                                  such as the word ‘pan,’ and semantic features as the
and represented in the mind are poorly understood. We
                                                                  properties of the objects and events communicated
present an analysis of symbolic learning—in particular,
                                                                  about in language. In turn, we can distinguish two
word learning—in terms of error-driven learning, and
                                                                  possible forms that symbolic learning about labels and
consider two possible ways in which symbols might be              features can take:
learned: learning to predict a label from the features of
objects and events in the world; or learning to predict              (i) cues are labels and events are semantic features;
those features from a label. This analysis predicts                   (ii) cues are semantic features and events labels.
significant differences in symbolic learning depending               In (i), which we call Label-to-Feature or LF-
on the sequencing of objects and labels, confirmed in             Learning, one learns to predict and expect certain
computational simulations and an empirical study.                 features given a label. In (ii), which we call Feature-to-
Discrimination learning is facilitated when semantic              Label or FL-Learning, one learns to predict and expect
features predict labels, but not when labels predict              labels given a feature or certain set of features. To
semantic features. We call this the Feature-Label-                explain the difference between what is learned in LF-
Ordering (FLO) effect. Our results and analysis suggest           learning versus FL-learning, it is important to note
that the semantic categories people use to understand             some differences between labels, as they are employed
and communicate about the world can only be learned if            in language, and the aspects of the environment they
labels are predicted from objects.                                typically describe.
Learning                                                          The structure of labels and the world
  Formally, learning can be conceived of as a process                Symbolic labels are relatively discrete, and possess
by which probabilistic information is acquired about the          little cue-structure, whereas objects and events in the
relationships between important regularities in the               world are far less discrete, and possess much denser
environment (such as objects or events) and the cues              cue-structure. (By cue-structure we mean the number of
that allow those regularities to be predicted (Rescorla &         potentially discriminable cues that are simultaneously
Wagner, 1972). This process is driven by discrepancies            present.) Consider a situation in which say, a pan is
between what is expected and what is actually observed            encountered in the environment. A pan presents to a
in experience (termed error-driven learning). The                 learner many discriminable features: shape, color, size,
learned value of a given cue produces expectations, and           etc. However, because objects are not discrete (i.e.,
any difference between the value of what is expected              pans share many features with things that are not pans),
and what is observed produces further learning. The               some of these features will cue other labels as well.
predictive value of a cues are strengthened when                     By contrast, consider the label ‘pan.’ A native
relevant events are under-predicted, and weakened                 English speaker can parse this word into a sequence of
                                                              3163

phonemes [ph an], but will be unable to discriminate               evidence), the associative strength between the cue and
many further features. This is not to say that there are           the response will decrease.
no other discriminable features within speech (such as               In one-to-many LF-learning, a single cue will be
emphasis, volume, or pitch contour), but rather to say             predictive of each of the many features encountered in
that the dominant semantic feature is at the level of the          an object or event. Because no other cues are available
phoneme. Other features of speech do not compete with              to compete for associative value, there can be no loss of
phonemes in predicting meaning in the same way that                potential associative value to other cues over the course
color might vie for relevance with shape in predicting             of learning trials. By contrast, in many-to-one FL-
an object label. Further, because phonemes occur in a              learning, because many cues are available to compete
sequence rather than simultaneously, there can be little           for relevance, learning will separate the highly reliable
to no direct competition between them as cues. Thus,               cues from the less reliable cues, favoring cues with a
labels such as ‘pan’ provides little competitive cue-              high degree of positive evidence and disfavoring those
structure: ‘pan’ essentially provides the learner with             with a high degree of negative evidence. FL-learning
only a single cue, i.e. the label ‘pan’ itself.                    and LF-learning thus differ significantly in terms of
   The difference in cue-structure in turn affects the             cue-competition; the dense cue-structure of FL-learning
formal properties of the two forms of learning we                  fosters cue-competition, while the sparse cue-structure
described above. In LF-learning, because labels serve as           of LF-learning inhibits it.
cues and since individual labels have little cue-
structure, learning involves predicting a set of features          Cue-structure and symbolic learning
(the semantic features of objects and events) from a                 To see how these factors affect symbolic learning,
single cue (the label). Thus, LF-learning has a one-to-            consider a simplified environment in which there are
many form: one cue to many features.                               two kinds of objects: wugs and nizes. These objects
      By contrast, in FL-learning, when object or event            have two salient features: their shape and their color.
serve as cues, learning involves predicting a single               Wugs are wug-shaped and can be either blue or red.
response (a label) from a large set of cues (the features          Likewise, nizes are niz-shaped and can be either blue or
of an event or object). Thus FL-learning, has a many-to-           red. Suppose now that one is learning what wugs and
one form: from many semantic features to a label.                  nizes are under FL-learning conditions. Figure 1
                                                                   represents FL-learning in this simplified environment:
Cue-competition in learning                                          At (i), a learner encounters an object with two
   Where many cues are presented simultaneously, they              poentially relevant features, shape-1 and red, and then
can compete for relevance in the prediction of a                   hears the label ‘wug’. The learner acquires information
particular event. If a cue successfully predicts an event          about two equally predictive relations, shape-⇒‘wug’
over time (positive evidence), the associative strength            and red⇒‘wug’. At (ii), the learner two new cues and a
between the cue and the event will increase.                       new label, and forms two new equally weighted
Conversely, when a cue unsuccessfully predicts a given             predictive relations, shape-2⇒‘niz’ and blue⇒‘niz’.
event—i.e., the event does not follow the cue (negative            Then at (iii), the learner encounters two previously seen
                                                                   cues, shape-1 and blue.
Figure 1. Cue competition in Feature-to-Label learning. The top panels depict the temporal sequence of events: an object is
shown and then a word is heard over three trials. The lower panels depict the relationship between the various cues and labels.
                                                             3164

Figure 2. In Label-to-Feature Learning, the absence of cue competition results in a situation where the outcome of learning is
simply a representation of the probability of the features given the label.
   Given what the learner already knows—i.e., shape-
1⇒‘wug’ and blue⇒‘niz’—she expects ‘wug’ and                          The Feature-Label-Order Hypothesis
‘niz,’ but, only ‘wug’ actually occurs. As a result: (1)                 Both FL and LF-learning capture probabilistic
given positive evidence of the occurrence of ‘wug’, the               information predictive relationships in the environment.
associative strength for the relation shape-1⇒‘wug’                   However, there are fundamental differences between
increases; and importantly (2) negative evidence about                the two. In FL-learning, predictive power, not
the non-occurrence of ‘niz’ causes blue⇒‘niz’ to lose                 frequency or simple probability, determines cue values.
associative strength. Crucially, as the associative                   LF-learning is probabilistic in far more simple terms.
strength of blue⇒‘niz’ decreases, its value relative to               Given this, it seems that the sequencing of labels and
shape-2⇒ ‘niz’ changes as well. At (iv), a similar                    features ought to have a marked affect on learning. We
situation occurs. The learner encounters shape-2 and                  call this the Feature-Label-Order hypothesis.
red and expects ‘niz’ and ‘wug’. Only ‘niz’ is heard, so                 We formally tested the FLO hypothesis in
the associative strength of shape-2⇒‘niz’ increases,                  simulations using a prominent error-driven learning
while red⇒‘wug’ loses associative strength.                           model (Rescorla &Wagner, 1972; see also; Allen and
   FL-learning is thus competitive: if a cue loses                    Siegel, 1996). We should note that the analysis of
associative strength, its value can change relative to                symbolic learning described here could be implemented
other cues. Since one cue’s loss can be another’s gain,               in a number of other models (e.g., Pearce & Hall, 1980;
this may shift associative value from one cue to another.             Rumelhart, Hinton & McClelland, 1986; Barlow, 2001)
   Now consider LF-learning in a similar scenario                     and applied to learning other environmental regularities.
(Figure 2). At (i), a learner encounters the label ‘wug’                 The Rescorla-Wagner model formally states how the
and then an object with the two salient features, shape-1             associative values (V) of a set of cues i predicting an
and red. She thus learns about two equally valuable                   event j change as a result of learning in discrete training
predictive relations ‘wug’ ⇒shape-1 and ‘wug’⇒red.                    trials, where n indexes the current trial.
Similarly, at (ii), the learner acquires two further                     Equation (1) is a discrepancy function that describes
equally     valued      relations     ‘niz’⇒shape-2          and      the amount of learning that will occur on a given trial;
                                                                      i.e., the change in associative strength between a set of
‘niz’⇒blue. Now, at (iii), the learner hears ‘wug’ and
                                                                      cues i and some event j:1
expects red and shape-1. However, shape-1 occurs and
blue occurs. This has three consequences: (1) positive                       ΔVijn =α i β j (λj - VTOTAL)                         (1)
evidence induces an increase in the associative strength
                                                                         If there is a discrepancy between λj (the total possible
of ‘wug’⇒shape-1; (2) ‘wug’⇒blue becomes a new
                                                                      associative value of an event) and VTOTAL (the sum of
predictive relation; (3) negative evidence decreases the
                                                                      current cue values), the saliency of the set of cues α and
strength of ‘wug’⇒red. However, since ‘wug’ is the
                                                                      the learning rate of the event β will be multiplied
only cue, this loss of associative strength is not relative
                                                                      against that discrepancy. The resulting amount will then
to any other cues (likewise at iv). LF-learning is thus
                                                                      be added or subtracted from the associative strength of
non-competitive, and simply results in the learning of
                                                                      any cues present on that trial.
the probabilities of events occurring given cues.
                                                                      1
                                                                        Vij is the change in associative strength on a learning trial n.
                                                                      α denotes the saliency of i, and β the learning rate for j.
                                                                3165

    The associative strength between a set of cues i and                It is important to note that in LF-learning, the lack of
an event j will increase in a negatively accelerated                 discrimination produced by learning can lead to
fashion over time, as learning gradually reduces the                 problems of interference in predicting events (or
discrepancy between what is predicted and what is                    responses to them). LF-learning tends to produce
observed. Given an appropriate learning-rate, learning               representations in which a number of competing
asymptotes at a level that minimizes the sum-of-squares              predictions are all highly probable. To illustrate this,
prediction error for a set of observed cues to an event.             we return to our wug / niz example. Imagine a world in
                                                                     which there were fifty times as many blue wugs as blue
                                                                     nizzes in the population, and fifty times as many red
                                                                     nizzes as red wugs. In this scenario, the color red will
                                                                     cue “niz” about 98% of the time and “wug” less than
                                                                     2% of the time, simply based on frequency of
                                                                     occurrence. For a child trying to name a red wug,
                                                                     there’s again a near 100% probability that wug-shaped
                                                                     = wug, but now there’s also a 98% probability that red
                                                                     = niz. There will thus be a large degree of uncertainty
                                                                     regarding the correct answer. We call this response
                                                                     interference. The problem here is that tracking the
Figure 3. The development of cue values in a simulation of           frequencies of successful predictions does not pick out
the LF-learning scenario depicted in Figure 2.                       the cues that best discriminate one prediction from
                                                                     another. Thus, while both FL and LF-learning may
                                                                     produce successful response-discrimination in an ideal
                                                                     world, LF-learning will fail to discriminate events when
                                                                     their frequencies vary; and in the actual world, these
                                                                     frequencies inevitably will.
                                                                                         Non discriminating     Discriminating
                                                                                              features             features
                                                                                         1        2       3 1 2    3      4    5 6
                                                                      Category   75%     1        0       0 1 0    0      0    0 0
                                                                          1      25%     0        1       0 0 1    0      0    0 0
                                                                      Category   75%     0        1       0 0 0    1      0    0 0
                                                                          2      25%     0        0       1 0 0    0      1    0 0
   Figure 4. The development of cue values in a simulation of         Category   75%     0        0       1 0 0    0      0    1 0
                                                                          3      25%     1        0       0 0 0    0      0    0 1
the FL-learning scenario depicted in Figure 1.
                                                                     Figure 5: The abstract representations of the category
 Discrimination and interference                                     structures used to train the Rescorla-Wagner models
   Two computational simulations (in the Rescorla &                  Simulating interference
Wagner, 1972 model, described below)2 formally                          To illustrate the problem of response interference, we
illustrate the differences in the representations of what            simulated category learning in the Rescorla-Wagner
gets learned in LF and FL-learning. As Figure 3 shows,               model using abstract representations of the category
LF-learning simply results in a representation of the                structures in Figure 5. The training set comprised 3
probability of each feature given the label; e.g., the               category labels and 9 exemplar features (3 non-
learned associative value of ‘wug’⇒red is about half of              discriminating features that were shared between
the associative strength of ‘wug’⇒wug-shaped,                        exemplars belonging to different categories, and 6
because ‘wug’ predicts red successfully only 50% of                  discriminating features that were not shared with
the times and wug-shaped successfully 100% of the                    members of another category). The frequency of the
time. In FL-learning (Figure 4), the learned                         sub-categories was manipulated so that each labeled
representations reflect the value of cues: the associative           category drew 75% of its exemplars from one sub-
relationship ‘wug’⇒wug-shaped is very reliable, and is               category and 25% of its exemplars from another
highly valued relative to cues that generate prediction              subcategory. The two sub-categories that made up each
error. In this case the association ‘wug’⇒red is                     labeled category did not share any features, such that
effectively unlearned.                                               learning to correctly classify one of the sub-categories
                                                                     paired with each label would provide no assistance with
                                                                     learning the other sub-category paired with that label.
2
                                                                     Finally, each low frequency sub-category shared its
  The simulations assume either a niz or a wug is encountered        non-discriminating feature with the high frequency
in each trial, that each species and color is equally frequent in    exemplars of a different labeled category. This
the environment, and that color and shape are equally salient.
                                                                 3166

manipulation was designed to create a bias towards the        where P(x) is the likelihood of the network selecting
misclassification of the low-frequency exemplars.             exemplar x, z(·) returns the z-score of its argument
Learning to correctly classify low frequency exemplars        relative to its population, dist(·,·) is the Euclidean
necessarily required learning to weigh the                    distance function, and t is the exemplar pattern
discriminating feature more than the non-discriminating       generated by the network. The P(x) likelihoods were
feature, despite its lower overall input frequency.           normalized using Luce’s Choice Axiom to yield
  Two simulations were configured to created two              normalized probability estimates. These revealed that
networks of feature and label relationships. The first        the LF network performed poorly. At asymptote, it
network learned associative weights from the 9                predicted the correct feature pattern with only p=.35
exemplar features (serving as cues) to the 3 labels           confidence for low frequency exemplars (chance), and
(serving as events; “FL training”), while in the second       p=.75 confidence for high frequency exemplars.
case the network learned from the 3 labels (serving as
cues) to the 9 features (serving as events; LF training).     Testing the FLO Hypothesis
Each category had a high frequency exemplar,                  Consistent with our hypothesis, a notable Feature-
presented on 75% of the training trials for that category,    Label-Order Effect was detectable in the simulations.
and a low frequency exemplar (occurring 25% of the            The following experiment was designed to see whether
time). On each training trial a label and appropriate         human learning would show a similar effect.
exemplar pattern were selected randomly to train each         Participants
of the two networks. Training comprised 5000 trials,             32 Stanford Undergraduates participated for credit.
which allowed learning to reach asymptote. The model
has several parameters that affect learning. For
simplicity, the simulations assumed equally salient cues
and events (α=0.01 for all i; β=0.01 for all j) and equal
maximum associative strengths (= 1.0).
  To test the FL-network, exemplar features were
activated to determine the subsequent activation of the
labels. Propagating these values across the weights
learned by the network then determined the associative
values that had been learned for each label given those
features. Luce’s Choice Axiom (Luce, 1959) was used
to derive choice probabilities for the 3 labels given
these activations, revealing that the FL-trained network      Figure 6. The category structures Experiment 1. (The stimuli
categorized and discriminated well (the probability of        are fribbles created by Michael Tarr’s lab at Brown
                                                              University.) The features that need to be weighted to
correct classification for the low and the high frequency
                                                              successfully distinguish the sub-categories are circled on the
exemplars was p=1).                                           low-frequency “dep” and high-frequency “tob” exemplars.
  LF-network testing involved activating the labels in
order to determine subsequent activation of the features.     Method and Materials
In turn, each label was given an input value of 1, and           Three experimental categories of “fribbles” were
this then produced activation levels in the features,         constructed, each comprising two sub-categories
which were determined by the associative values               clustered around a non-discriminating feature and a set
learned in training. In order to assess the network’s         of discriminating features. The two sub-categories that
performance, the Euclidean distance between the               made up each labeled category did not share features,
predicted activations and the actual feature activations      and so learning to correctly classify one of the sub-
of the appropriate exemplar were calculated. For each         categories paired with each label provided no assistance
label there were two sets of feature activations: those       with learning the other sub-category paired with that
corresponding to the high and low frequency                   label. The sub-categories were again manipulated so
exemplars. To test learning of both exemplar types, a         that 75% of the exemplars of a category belonged to
category and a frequency (either high or low) were            one sub-category, and 25% to another, and each non-
selected, and the difference between the feature              discriminating feature was shared by high frequency
activations predicted by the network and the correct          and low frequency exemplars that belonged to different
values for the category exemplars was computed. These         categories. Thus learning to correctly classify low
differences were then converted to z-scores, and from         frequency exemplars necessarily required learning to
these the probabilities of selecting the correct exemplar     weigh the discriminating feature more than the non-
given the category label were calculated as follows:          discriminating feature. A control category served to
                                                              check that there were no differences in learning
           P(x) = exp(-z(dist(x,t))                    (2)
                                                              between the two groups other than those we
                                                          3167

hypothesized: all its exemplars shared just one, highly
salient feature (all were blue). Because learning this
category involved a binary pairing blue⇒bim, there
was no “predictive structure” to discover. In the
absence of competing exemplars, learning was
predicted to be identical for FL and LF training.
   To enforce LF or FL relationships as our participants
studied “species of aliens” we minimized their ability to
strategize (word learning is rarely a conscious process).
All four categories were trained simultaneously,
exemplars of each category were presented in a non-
predictable sequence, and each exemplar was presented
for only 175ms to inhibit participants’ ability to search
for features. FL training trials comprised 1000ms             Figure 7: Performance of participants training and exemplar type.
presentation of a label (“this is a wug”), followed by a      Note here that SX corresponds to Label-to-Feature (LF) and XS to
blank screen for 150 ms, followed by 175ms exposure           Feature-to-Label (FL).
to the exemplar. LF training trials comprised 175 ms
exemplar, 150 ms blank screen and 1000ms label (“that           To the degree that learning is driven by prediction
was a wug”). A 1000ms blank screen separated all trials       error (and there is considerable evidence that it is) the
(see Figure 10). A training block comprised 20 different      Feature-Label-Ordering effect may be an inevitable
exemplars of each experimental category – 15 high-            feature of learning. We believe it has many implications
frequency exemplars and 5 low-frequency exemplars –           for our understanding of language and cognition.
and 15 control category exemplars. Training comprised
2 identical blocks, with a short rest between the blocks.                         Acknowledgments
   Testing consisted of speeded 4 alternative forced-           This material is based upon work supported by NSF
choice tasks. Half the participants matched an exemplar       Grant Nos. 0547775 and 0624345 to Michael Ramscar
to the 4 category labels, and half matched a label to 4
previously exemplars drawn from each category.                                        References
Participants were instructed to respond as quickly as         Barlow H. (2001). Redundancy reduction revisited,
they could (after 3500ms, a buzzer sounded and no               Network, 12, 241-253
response was recorded). Each sub-category (and the            Kamin L.J. (1969). Predictability, surprise, attention,
control) was tested 8 times, yielding 56 test trials.           and conditioning. In: Campbell B, Church R (eds).
Results and Discussion                                          Punishment and Aversive Behaviour. Appleton-
   The results of the experiment were remarkably                Century-Crofts: New York.
consistent with our predictions; a 2 x 2 ANOVA                Luce, R. D. (1959). Individual Choice Behavior: A
revealed a significant interaction between exemplar-            Theoretical Analysis. New York: Wiley
frequency and training (F(1,94)=20.187, p<0.001;              Pearce J.M. & Hall G. (1980) A model for Pavlovian
Figure 6). The FL-trained participants classified high          learning. Psychological Review, 87:532-552
and low frequency items accurately (FL high p=.98;            Rescorla R.A. and Wagner A.R. (1972). A Theory of
low p=.78), while the LF-trained participants only              Pavlovian      Conditioning:      Variations      in   the
accurately classified high-frequency items (p=.86) and          Effectiveness         of        Reinforcement          and
failed to classify the low frequency exemplars above            Nonreinforcement. In Black & Prokasy (Eds.),
chance levels (p=.36, t(47)=0.536, p>0.5). The control          Classical Conditioning II: Current Research and
category was learned to ceiling in both conditions.             Theory. New York: Appleton-Century-Crofts.
Analyses of confusability (i.e., the rates at which           Rescorla R.A. (1988). Pavlovian Conditioning: It’s Not
exemplars were misclassified to the category with               What You Think It Is, American Psychologist, 43(3),
which they shared non-discriminating features) showed           151-160
the same interaction between frequency and training           Rumelhart, D. E., Hinton, G. E., & McClelland, J. L. A
                                                                framework for Parallel Distributed Processing. in
(F(1,94)=8.335, p<0.005), with higher confusion rates
                                                                Rumelhart, McClelland, & the PDP research group.
after LF training (M=22.6%) than FL (M=6%;
                                                                (1986). Parallel distributed processing. Volume I.
t(16)=5.23, p<0.0001). These differences were not due           Cambridge, MA: MIT Press
to a speed / accuracy trade-off; participants trained FL      Siegel, S.G., & and Allan, L.G. (1996). The widespread
were faster as well as more accurate (LF M=2332ms,              influence      of    the    Rescorla-Wagner         model,
FL M=2181ms; t(190)=1.677, p<0.1).                              Psychonomic Bulletin and Review, 3(3), 314-321
                                                          3168

