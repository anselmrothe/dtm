UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Surprisal-based comparison between a symbolic and a connectionist model of sentence
processing
Permalink
https://escholarship.org/uc/item/02v5m1hf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Author
Frank, Stefan
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

     Surprisal-based comparison between a symbolic and a connectionist model of
                                                      sentence processing
                                              Stefan L. Frank (S.L.Frank@uva.nl)
                                            Institute for Logic, Language and Computation
                                                        University of Amsterdam
                                      Science Park 904, 1098 XH Amsterdam, The Netherlands
                             Abstract                                      It is of particular interest to the current paper that neither
                                                                        of these derivations of surprisal theory depends on the nature
   The ‘unlexicalized surprisal’ of a word in sentence context          of the probability model that is used to estimate the surprisal
   is defined as the negative logarithm of the probability of the
   word’s part-of-speech given the sequence of previous parts-          values. Levy (2008) uses a Probabilistic Context-Free Gram-
   of-speech of the sentence. Unlexicalized surprisal is known          mar (PCFG) whereas Smith and Levy (2008) take a trigram
   to correlate with word reading time. Here, it is shown that          model, but both these choices seem based on practical rather
   this correlation grows stronger when surprisal values are es-
   timated by a more accurate language model, indicating that           than theoretical considerations. In the work presented here,
   readers make use of an objectively accurate probabilistic lan-       surprisal values are estimated by a PCFG and by a Simple
   guage model. Also, surprisals as estimated by a Simple Re-           Recurrent Network (SRN; Elman, 1990).
   current Network (SRN) were found to correlate more strongly
   with reading-time data than surprisals estimated by a Proba-            In spite of the theoretical arguments mentioned above, em-
   bilistic Context-Free Grammar (PCFG). This suggests that the         pirical evidence for surprisal theory is still quite scarce. Hale
   SRN forms a more accurate psycholinguistic model.
                                                                        (2001) and Levy (2008) give examples of how the theory ac-
   Keywords: Surprisal theory; Sentence processing; Reading             counts for particular psycholinguistic phenomena, but they
   time; Probabilistic Context-Free Grammar; Simple Recurrent
   Network.                                                             do not perform any comparison between surprisal values and
                                                                        reading-time data on a scale that allows for investigating
                         Introduction                                   whether there is a statistically significant relation in general.
                                                                           In contrast, Smith and Levy (2008) look at reading-time
The time needed to read a word in sentence context depends              measurements over a collection of British newspaper articles
on many of the word’s properties, ranging from low-level fea-           and show that there is indeed an (approximately) linear rela-
tures such as the word’s frequency, to high-level properties            tion between surprisals and reading times. However, they did
such as its effect on the syntactic and semantic representa-            not investigate whether this effect exceeds that of the words’
tion of the sentence as a whole. Based on earlier work by               ‘forward transitional probabilities’ Pr(wt |wt−1 ), which corre-
Hale (2001), Levy (2008) suggested that many of these as-               late with surprisal.
pects can be combined into a single ‘causal bottleneck’: the
                                                                           Taking these transitional probabilities into account,
word’s surprisal. Formally, the surprisal of word wt occur-
                                                                        Demberg and Keller (2008) did not find a statistically signifi-
ring at position t in a sentence is
                                                                        cant positive effect (and in some cases even a significant neg-
             surprisal(wt ) = − log(Pr(wt |w1...t−1 )),          (1)    ative effect) of surprisal on reading times on English news-
                                                                        paper texts. They did, however, discover a weak but positive
where Pr(wt |w1...t−1 ) is the probability of wt given the sen-         relation between reading times and what they called ‘unlexi-
tence’s previous words w1...t−1 . Informally, a word’s surprisal        calized’ or ‘structural surprisal’, which is the surprisal of the
can be viewed as the extent to which its occurrence came un-            words’ part-of-speech, given the parts-of-speech of the pre-
expected. According to so-called surprisal theory, there is a           vious words in the sentence (i.e., the ws in Equation 1 repre-
positive linear relation between the time needed to read wt             sent parts-of-speech rather than words). Boston, Hale, Patil,
and its surprisal: Less expected words take longer to read.             Kliegl, and Vasishth (2008) replicated this finding using a
   Surprisal theory can be derived from particular assump-              German data set.
tions about sentence processing in at least two different ways.            All in all, there is little evidence that word surprisal ex-
Levy (2008) showed that it follows from the assumptions that            plains reading-time data in general, above what is already
a sentence-so-far is mentally represented as a probability dis-         explained by forward transitional probability. Unlexicalized
tribution over all interpretations of complete sentences, and           surprisal, on the other hand, does seem to correlate positively
that word reading time reflects the extent to which this dis-           with reading times.
tribution needs to be updated. Alternatively, Smith and Levy               Before accepting this conclusion, however, we need to be
(2008) argue that readers attempt to minimize expected pro-             careful not to conflate two different interpretations of the con-
cessing cost. Under certain additional assumptions, it follows          cept ‘surprisal’. First, there is an objective sense of surprisal,
that word reading time is linearly related to word surprisal,           according to which it is a value that can be observed, or at
irrespective of how readers develop their expectations about            least reliably estimated. In this sense, Pr(wt |w1...t−1 ) of Equa-
upcoming words.                                                         tion 1 is estimated using some probability model that is be-
                                                                    1139

lieved to be sufficiently accurate. All the authors mentioned                for observed reading times. The coefficient of correlation be-
above subscribe to such an interpretation when they estimate                 tween surprisals and reading times can therefore be taken as
surprisal by training some well-defined probability model on                 a measure of psycholinguistic model accuracy.
text corpora. Second, there is a subjective sense of surprisal,                 In short, the accuracy of a model that generates surprisal
according to which it is an unobservable psychological vari-                 estimates can be evaluated in two different ways: It is an ac-
able. In this sense, Pr(wt |w1...t−1 ) expresses the extent to               curate language model if the average surprisal estimate is low,
which the reader expects word wt . Since word processing                     and it is an accurate psycholinguistic model if the surprisal es-
depends on the reader’s expectations, it is this subjective in-              timates correlate strongly (and positively) with reading times.
terpretation that matters when surprisal is claimed to affect                Only if, in general, more accurate language models are also
reading.                                                                     more accurate psycholinguistic models, can we conclude that
   It is not at all certain that the reader’s expectations follow            human readers use something like an objectively accurate lan-
those of the probability models used to estimate surprisal val-              guage model for sentence processing.
ues. Yet, current research implicitly assumes that a reader’s
expectations about upcoming words (or parts-of-speech) can                                               Method
be reliably estimated from text corpora. In other words, the                 Two basic models of sentence processing will be investi-
two senses of surprisal are taken to be one and the same.                    gated: a PCFG (a standard symbolic model) and a SRN (the
   The first aim of this paper is to investigate whether this as-            quintessential connectionist model). Both are trained and
sumption is warranted. Indeed, it will be shown that more                    tested on newspaper texts (or, rather, on the part-of-speech
accurate probability models also predict reading times more                  (pos-)tags from these texts). Each model will estimate not
accurately, thereby providing further support for (unlexical-                just one, but a whole range of surprisal values for each pos-
ized) surprisal theory.                                                      tag of the test texts. This means that there is also a range
   Assuming that surprisal theory holds, the paper’s second                  of model accuracies, which allows for investigating the rela-
goal is to use the theory for investigating what type of prob-               tion between langauge model accuracy and psycholinguistic
ability model best describes the human sentence-processing                   model accuracy.
system. The psychological validity of two simple sentence-
processing models (one symbolic, the other connectionist) is                 Text corpora
evaluated by comparing their surprisal estimates to reading-                 Training corpus Both models were trained on the Wall
time data. As it turns out, the connectionist model provides                 Street Journal (WSJ) part of the Penn Treebank, which is the
a more accurate account of the data, suggesting that it forms                same corpus as used by Demberg and Keller (2008). It com-
a better description of human sentence processing than does                  prises 49,208 sentences annotated with their syntactical tree
the symbolic model.                                                          structure. Since only unlexicalized surprisal is investigated
                                                                             here, all words were removed, that is, pos-tags were used as
 Language models and psycholinguistic models                                 lexical items. There are 45 different parts-of-speech, includ-
By definition, a probabilistic language model provides an                    ing punctuation marks, parentheses, etcetera.
estimate of the probability Pr(w1...t ) of any sentence-initial              Test corpus The models were tested on the Dundee corpus
word sequence w1...t . Turning these probabilities into sur-                 (Kennedy & Pynte, 2005), which was also used by Demberg
prisal values is trivial, since                                              and Keller (2008) and Smith and Levy (2008). It consists of
                                                                             2,368 sentences that appeared in The Independent newspaper.
  − log(Pr(wt |w1...t−1 )) = log(Pr(w1...t−1 )) − log(Pr(w1...t )).
                                                                             Pos-tags for these sentence were automatically generated by
                                                                             the pos-tagger developed by Brill (1993). These tags were
   The accuracy of a language model can be measured by hav-
                                                                             checked by hand, and where necessary adapted according to
ing it generate surprisal values for each word in some val-
                                                                             the Penn Treebank pos-tagging guidelines (Santorini, 1991).
idation text. If the model is accurate, it will assign a high
                                                                                The Dundee corpus comes with eye-tracking data from ten
probability (i.e., low surprisal) to the text’s words. Therefore,
                                                                             subjects. Different reading-time measures can be extracted
the average surprisal over all these words can be taken as a
                                                                             from these data. Here, we use only first-pass reading time,
measure for language model accuracy. The lower the average
                                                                             defined as the total fixation time on a word before any fixation
surprisal, the more accurate the language model.1
                                                                             on a later word of the same sentence.
   An accurate language model is not necessarily an accurate
psycholinguistic model. As explained in the Introduction,                    The models
this is because the extent to which words are surprising to
                                                                             Probabilistic Context-Free Grammar A PCFG gives rise
a reader may deviate from the surprisal values as estimated
                                                                             to surprisal values because it assigns a probability to each
by the language model. A language model forms an accu-
                                                                             sentence-initial word string w1...t , which, as mentioned above,
rate psycholinguistic model if its surprisal estimates account
                                                                             can be transformed into surprisals. The probability of w1...t is
    1 Incidentally, the average surprisal is an estimate of the language     the sum of probabilities of all sentences that start with w1...t .
entropy.                                                                     The probability of a sentence is the total probability of all its
                                                                         1140

possible tree structures, and the probability of a tree equals        may be impossible to obtain in practice, this need not to be
the product of probabilities of all the production rules in-          too problematic as long as experiments can be set up in a way
volved in its construction.                                           that dependencies among observations are minimized. The
   Following Demberg and Keller (2008), the PCFG’s rules              current case, however, is fundamentally different: If indepen-
and their probabilities were induced from the WSJ treebank            dence among words in a sentence is assumed, the concept
using an algorithm developed by Roark (2001). Next, Roark’s           of surprisal becomes meaningless because a word’s surprisal
top-down incremental parser was applied to the pos-tag se-            depends on the sentence’s previous words. Hence, a statisti-
quences from the Dundee corpus. At each point of a sentence,          cal analysis of word (or pos-tag) surprisal relies on an inde-
the parser comes up with not just one but many (partial) parse        pendence assumption that is inconsistent with the concept of
trees, each with an associated probability. To reduce com-            surprisal itself.
putational load, many of these trees are discarded. Simply               It is difficult to estimate how serious this problem is in
stated, if the current most likely parse has a probability p,         practice. To make sure that we can rely on the outcome of
then only partial parses with a probability larger than 10−θ p        the analyses, the unit of observation was changed from words
are kept. Parameter θ controls the so-called ‘beam width’.            to sentences. This does not mean that sentences are truly
The larger the beam width, the more parses are taken into ac-         independent from one another. Rather, both the PCFG and
count, so the more accurate (and slower) the parser becomes.          the SRN treat sentences as independent. By taking sentence
   The beam width affects not only the generated parses and           reading times as data points, the independence assumption
their probabilities, but also the estimated surprisal of each         of the statistical analysis becomes consistent with the mod-
sentence’s pos-tags. A range of surprisal estimates can there-        els’ assumption of independence between sentences. Taking
fore be obtained by varying the beam width. Here, θ was               reading times at the sentence rather than word level has the
varied between 1 and 16.                                              additional advantage of doing away with possible spill-over
                                                                      effects (i.e., surprisal effects that show up with some delay)
Simple Recurrent Network SRNs are commonly used for
                                                                      taking place within a sentence.
next-word prediction. In this task, the network is given an
                                                                         The reading time for a sentence (from here on denoted as
input sentence, one word at a time, and has to predict at each
                                                                      RT) is the sum of first-pass reading times for all words in the
point which word will be the next input. Usually, there is
                                                                      sentence, divided by the sentence’s number of characters to
one output unit for each word type, and output activations are
                                                                      compensate for differences in sentence length. Likewise, the
forced to sum to 1 so that they can be interpreted as probabil-
                                                                      surprisal of a sentence is defined as the average surprisal of
ities: After processing the input sequence w1...t−1 , the activa-
                                                                      its pos-tags. If the sentence consists of n pos-tags w1...n :
tion of the output unit representing word wt is the network’s
estimate of Pr(wt |w1...t−1 ). Taking the negative logarithm of                                       1 n
this activation yields the estimated surprisal of wt .                         surprisal(w1...n ) = −   ∑ log(Pr(wt |w1...t−1 ))
                                                                                                      n t=1
                                                                                                                                    (2)
   An SRN was trained to predict each next pos-tag in the pos-
                                                                                                      1
tag sequences from the WSJ corpus (ignoring the tree struc-                                       = − log(Pr(w1...n )).
tures).2 The network had 45 input and output units (one for                                           n
each part-of-speech type) and 100 hidden units. For a fair               Data points (i.e., sentence/subject-combinations) were re-
comparison with the PCFG model, two small adaptations to              moved from the analysis if:
the standard SRN were introduced. First, hidden-unit acti-
                                                                      • The sentence could not be parsed by the PCFG at all levels
vations were reset at the beginning of each sentence. This
                                                                         of θ;
makes sure that each sentence is independent from all others,
as is the case for the PCFG model. Second, the network was            • The subject fixated on fewer than four words (this includes
trained to also estimate a probability for each sentence’s first         all sentences with fewer than four words);
part-of-speech, as does the PCFG.
   To obtain a range of surprisal values, the network was             • There was a track loss, defined as more than three consec-
tested on pos-tag sequences from the Dundee corpus at sev-               utive non-fixated words;
eral moments during training: after every 1,000 training sen-         • After removing data points for the reasons above, log(RT)
tence until sentence number 5,000; from thereon after every              was more than three standard deviations from the mean for
5,000 sentences; and finally after training on all 49,208 WSJ            that subject.
sentences.
                                                                      This left a total of 16,755 data points (between 1,330 and
Statistical notes                                                     1,825 per subject).
Nearly all methods for statistical analysis assume indepen-
dence among observations. Although complete independence                                           Results
    2 Training
                                                                      Language model accuracy
               sequences were presented in random order. Output
units had softmax activation functions and cross-entropy error was    The inaccuracy of the language model is the average sentence
minimized by the standard backpropagation algorithm.                  surprisal (Equation 2), weighted by the number of times the
                                                                  1141

sentence takes part in the analysis. This number varies over
                                                                                                                                                        SRN
sentences, for example because track losses occurred for par-                                                              0.06
                                                                                                        r(surprisal,RT)
ticular sentence-subject combinations.                                                                                                                  PCFG
   Figure 1 shows the range of language model accuracies for
                                                                                                                           0.03
the PCFG and SRN models. As expected, the PCFG model
becomes more accurate as beam width increases. Likewise,
the SRN model becomes more accurate over the course of                                                                       0
training.
                                                                                                                          −0.03
                                       PCFG                                 SRN                                               2.2         2.6              3
                     3                                       3
                                                                                                                                    average surprisal
average surprisal
                    2.6                                    2.6                                   Figure 2: Correlation between surprisal and RT (i.e., accuracy
                                                                                                 of psycholinguistic model) for PCFG and SRN as a function
                                                                                                 of language model inaccuracy. Thin lines indicate 95% con-
                    2.2                                    2.2
                                                                                                 fidence intervals.
                          1     4       8      12   16           0           2.5             5
                                    beam width θ                     # sentences trained x 104
                                                                                                    The fact that the SRN is the more accurate psycholinguis-
                                                                                                 tic model does not mean that the PCFG has no additional
Figure 1: Average surprisal (i.e., inaccuracy of language                                        value: The combination of SRN- and PCFG-based surprisal
model). Left: For PCFG, as a function of beam-width θ.                                           estimates may account for more of the variance in RT than do
Right: For SRN, as a function of the number of sentences                                         the SRN’s estimates by themselves. To investigate whether
trained on.                                                                                      this is the case, three linear mixed-effect regression models
                                                                                                 (see Baayen, Davidson, & Bates, 2008) were fitted. These
Psycholinguistic model accuracy                                                                  three regression models differed only in the surprisal esti-
                                                                                                 mates that were included: Surprisal according to the PCFG
First, RTs were centered by subtracting the average RT for
                                                                                                 (with θ = 16), surprisal according to the SRN (after complete
each subject from that subject’s RTs. This does away with
                                                                                                 training), or both. In addition, the regression included fixed-
individual differences in general reading speed. Next, a single
                                                                                                 effect factors for sentence length (number of characters),
measure for psycholinguistic model accuracy was obtained
                                                                                                 word frequency, forward transitional probability Pr(wt |wt−1 ),
for all subjects by computing the coefficient of correlation
                                                                                                 and backward transitional probability Pr(wt |wt+1 ). Also in-
between these centered RTs and surprisals values.
                                                                                                 cluded were interactions between sentence length and back-
   Figure 2 shows how the accuracy of the language model is
                                                                                                 ward transitional probability, and between word frequency
related to the accuracy of the psycholinguistic model. First,                                    and forward transitional probability.4 All these factors had
as predicted by unlexicalized surprisal theory, there is a sig-
                                                                                                 a significant effect, but no other two-way interactions did.
nificant positive correlation between sentence surprisal and
                                                                                                    Table 1 shows the estimated β-coefficients for the effect of
RT, at least for the more accurate languages models. Second,
                                                                                                 surprisal. When only PCFG-based or only SRN-based sur-
the relation between language model accuracy and psycholin-
                                                                                                 prisal estimates are included, these have a significant positive
guistic model accuracy is nearly monotonous: Lower average                                       effect on RT. More importantly, when both surprisal estimates
surprisal results in a stronger correlation between surprisal
                                                                                                 are included, the effect of PCFG-based surprisal is no longer
and RT. In other words, accurate language models are gen-
                                                                                                 significant. This shows that these surprisal estimates do not
erally also accurate psycholinguistic models. This is in line                                    add useful information to those generated by the SRN.
with the assumption that readers use an objectively accurate
                                                                                                    Another way to analyze the difference between the three
language model.
                                                                                                 regression models is by comparing model fits, as expressed
Comparing PCFG and SRN                                                                           by the Akaike Information Criterion (AIC; Akaike, 1974) in
                                                                                                 Table 1 (note that lower AIC indicates a better fitting model).
As can be seen in Figure 2, the SRN accounts for more of
                                                                                                     4 Word frequencies and transitional probabilities were in fact log-
the variance in RT than does the PCFG, even where the two
models have the same language model accuracy. When com-                                          transformed and averaged over all words of a sentence. The proba-
                                                                                                 bilities were estimated from word and bigram frequencies that were
paring the SRN at the end of training to the best PCFG (i.e.,                                    the average of relative frequencies in the Dundee corpus and in the
with θ = 16), the correlation between SRN-based surprisals                                       written text part of the British National Corpus (BNC). This aver-
and RTs is significantly stronger than the correlation between                                   age of frequencies over two corpora turned out to correlate more
                                                                                                 strongly with word reading times than did frequencies from each
PCFG-based surprisals and RTs (t = 3.52; p < .001).3                                             corpus individually.
                                                                                                    The only random-effect factors were by-subject and by-item in-
                    3 The     correlation between the two sets of surprisal estimates is         tercepts, and a by-subject effect of word frequency. Including other
.85.                                                                                             random effects did not improve model fit significantly.
                                                                                           1142

                                                                                              Discussion
Table 1: Estimated coefficients (with associated p-values) of
surprisal factors, and AIC of regression models.                    Several conclusions can be drawn from the results displayed
                                                                    in Figure 2. First, both PCFG- and SRN-based estimates
       Surprisal                Regression model includes           of unlexicalized surprisal correlate positively with RT (pro-
   estimated by             PCFG        SRN          both           vided beam width is large enough and the SRN is sufficiently
          PCFG              β = 0.45                 β = −.46       trained). These correlations are very weak, but it should be
                             p < .02                 p > .2         kept in mind that many factors that affect reading times are
            SRN                         β = .64      β = 1.02       not captured by surprisals of pos-tags (not to mention the
                                         p < .001 p < .01           presence of unexplainable noise in the data). For example,
                    AIC     104151      104145       104145         reading slows down on words that are infrequent or seman-
                                                                    tically unexpected in the context, but unlexicalized surprisal
                                                                    is not related to such factors (nor to many others). More-
As was expected, such an analysis leads to the same conclu-         over, the RT data were collected over general newspaper texts
sion: The regression model with both SRN- and PCFG-based            rather than experimental stimuli that are carefully constructed
surprisal estimates fits the RT-data better than the PCFG-only      to balance as many factors as possible. For these reasons,
model (χ2 = 7.54; p < .01), whereas there is no significant         we should not expect unlexicalized surprisal to explain much
difference in fit between the full model and the SRN-only           of the variance in RT. The fact that there is any significant,
model (χ2 = 1.44; p > .2).                                          positive relation between unlexicalized surprisal and RT is
                                                                    enough to support the unlexicalized surprisal theory.
Qualitative analysis To find out what causes the higher ac-            Second, it is likely that reading-time delays are actually
curacy of the SRN’s predictions, we first investigated whether      caused by the unexpected occurrence of a part-of-speech,
it results from a slightly better fit to the RT data overall, or    rather than there being some confounding variable responsi-
from a much better fit to a particular group of data points.        ble for this apparent effect. This is because such a confound-
Two ordinary linear regression models were fitted to the cen-       ing variable should also account for the relation between lan-
tered RTs (one including only the SRN-based surprisals, the         guage model accuracy and psycholinguistic model accuracy.
other with only the PCFG-based surprisals) and their residu-        For example, the number of characters in a sentence has a
als were compared. If a particular data point is predicted more     (very weak) negative correlation with both RT5 and surprisal.
accurately by the SRN than by the PCFG, the corresponding           Sentence length might therefore be a confounding variable
residual in the SRN regression model will be closer to zero         that is responsible for the relation between surprisal and RT.
than that residual in the PCFG regression model. Hence, the         However, for the confound to also explain the slopes of the
extent to which data point i is predicted more accurately by        lines in Figure 2, it would need to correlate more strongly
the SRN than by the PCFG can be expressed by                        with surprisal as the language model becomes more accurate.
                                                                    There is no reason to believe that this would be the case for
              δi = |residi (PCFG)| − |residi (SRN)|,                sentence length, and in fact it is not. Also, regression models
                                                                    that include (among others) a sentence-length factor showed
where |residi (MODEL)| is the absolute residual of data point i
                                                                    a significant effect of surprisal on RT (see Table 1), which
in the regression using surprisals estimated by MODEL.
                                                                    means that this effect does not depend on a confound with
   If the difference between SRN and PCFG were due solely           sentence length.
to random noise, the δs would be distributed symmetrically             Third, the SRN seems to be a more accurate psycholinguis-
around 0. In fact, the SRN fits the data better so the mean of      tic model than the PCFG. This was confirmed by the regres-
δ is positive. If this is because of a particular group of data     sion analysis: the SRN explained RT-variance in addition to
points, the corresponding δs would be exceptionally large,          the PCFG, but the reverse was not the case. It was shown that
resulting in a distribution that is skewed to the right. Alter-     this was not because the SRN does better than the PCFG on
natively, if the SRN provides better fit in general, the distri-    particular sentences. Rather, it is a more accurate psycholin-
bution of δ would be shifted rightwards but remain symmet-          guistic model overall.
rical. Therefore, the question whether the SRN’s better fit            Fourth, the monotonous relation between language model
holds only for a subset of the data can be operationalized as:      accuracy and psycholinguistic model accuracy indicates that
Are the δs distributed asymmetrically?                              readers make use of an objectively accurate language model.
   It turns out that they are not: A two-sample Kolmogorov-         This was implicitly assumed in the research by Boston et al.
Smirnov test showed that the distribution is not significantly      (2008), Demberg and Keller (2008), Levy (2008), and Smith
asymmetric (p > .17). Also, a scatter plot of |residi (PCFG )|      and Levy (2008), but has not been empirically validated be-
against |residi (SRN )| did not show a single outlier, which        fore. It is noteworthy that this monotonous relation seems
would have indicated a data point predicted much better by          to hold within model type (SRN or PCFG) but not between
one model than by the other. These findings suggests that the       these types: The PCFG is generally the more accurate lan-
SRN does not just do better in particular cases, but is the more
accurate psycholinguistic model overall.                                5 Be reminded that RT is defined as per character reading time.
                                                                1143

guage model even though the SRN is the more accurate psy-                                   References
cholinguistic model, suggesting that there is some important        Akaike, H. (1974). A new look at the statistical model iden-
qualitative difference between them.                                  tification. IEEE Transactions on Automatic Control, 19,
   This raises the question what might make the SRN a better          716–723.
description of the human sentence-processing system. Al-            Baayen, R. H., Davidson, D. J., & Bates, D. M. (2008).
though PCFGs (and tree-structure models in general) are par-          Mixed-effects modeling with crossed random effects for
ticularly good at dealing with long-term dependencies within          subjects and items. Journal of Memory and Language, 59,
sentences, they do not directly store word sequences. SRNs,           390–412.
on the other hand, do retain information about frequencies          Bannard, C., & Matthews, D. (2008). Stored word sequences
of word sequences, but have difficulties with long-term de-           in language learning: The effect of familiarity on childrens
pendencies. Possibly, people are more like SRNs than like             repetition of four-word combinations. Psychological Sci-
PCFGs in this respect, at least insofar as is relevant for speed      ence, 19, 241–248.
of reading. Indeed, experimental evidence indicates that chil-      Bod, R. (2001). Sentence memory: Storage vs. computa-
dren store frequent multi-word sequences as wholes (Bannard           tion of frequent sentences. Paper presented at CUNY-2001,
& Matthews, 2008) and that adults read frequent word se-              Philadelphia, PA.
quences faster than less frequent ones (Bod, 2001; Tremblay,        Boston, M. F., Hale, J., Patil, U., Kliegl, R., & Vasishth, S.
Derwing, Libben, & Westbury, 2008). The results presented             (2008). Parsing costs as predictors of reading difficulty: An
here suggest that the same may be the case for part-of-speech         evaluation using the Potsdam Sentence Corpus. Journal of
sequences.                                                            Eye Movement Research, 2, 1–12.
                                                                    Brill, E. (1993). A corpus-based approach to language learn-
                          Conclusion                                  ing. Doctoral dissertation, University of Pennsylvania.
The finding that the SRN’s predictions of reading-time data         Chomsky, N. (1957). Syntactic structures. The Hague: Mou-
are more accurate than the PCFG’s is of particular interest           ton.
considering the ongoing debate about the nature of mental           Demberg, V., & Keller, F. (2008). Data from eye-tracking cor-
representations involved in human sentence processing. Ac-            pora as evidence for theories of syntactic processing com-
cording to standard linguistic theories since Chomsky (1957),         plexity. Cognition, 109, 193–210.
the mental representation of sentences involves syntactic tree      Elman, J. L. (1990). Finding structure in time. Cognitive
structures. In contrast, connectionist theories of language           Science, 14, 179–211.
processing take mental representations to be unstructured ac-       Hale, J. (2001). A probabilistic Early parser as a psycholin-
tivation patterns. The fundamental difference between these           guistic model. In Proceedings of the second conference of
two types of model has stood in the way of an objective and           the North American chapter of the Association for Compu-
quantitative comparison of their ability to account for exper-        tational Linguistics (Vol. 2, pp. 159–166). Pittsburgh, PA:
imental data. Yet, such a comparison is precisely what was            Association for Computational Linguistics.
presented here. The result was that the connectionist model         Kennedy, A., & Pynte, J. (2005). Parafoveal-on-foveal effects
outperforms the symbolic model.                                       in normal reading. Vision Research, 45, 153–168.
   No matter how convincing this outcome may seem, it re-           Levy, R. (2008). Expectation-based syntactic comprehen-
mains to be investigated to what extent it generalizes to other       sion. Cognition, 106, 1126–1177.
data sets, other instantiations of SRNs and PCFGs, and other        Roark, B. (2001). Probabilistic top-down parsing and lan-
models. The surprisal-based evaluation method may be par-             guage modeling. Computational Linguistics, 27, 249–276.
ticularly suited to such an investigation, because many (if         Santorini, B. (1991). Part-of-speech tagging guidelines for
not all) probabilistic sentence-processing models can pro-            the Penn Treebank project (Tech. Rep.). Philadelphia, PA:
vide surprisal estimates. Even models that differ widely from         University of Pennsylvania.
one another, such as symbolic and connectionist models, can         Smith, N. J., & Levy, R. (2008). Optimal processing times
thereby be evaluated against one and the same data set. Sur-          in reading: a formal model and empirical investigation. In
prisal can act as a point of convergence for different models of      B. C. Love, K. McRae, & V. M. Sloutsky (Eds.), Proceed-
sentence processing, allowing for a fair comparison between           ings of the 30th Annual Conference of the Cognitive Sci-
them.                                                                 ence Society (pp. 595–600). Austin, TX: Cognitive Science
                                                                      Society.
                     Acknowledgments
                                                                    Tremblay, A., Derwing, B., Libben, G., & Westbury,
I would like to thank Vera Demberg and Victor Kuperman                C.      (2008). Processing advantages of lexical bun-
for answering my many questions; Brian Roark for making               dles: Evidence form self-paced reading experiments, word
his parser available (and answering even more questions);             and sentence recall tasks, and off-line semantic ratings.
and four anonymous reviewers, Rens Bod, Gideon Borensz-               (Manuscript submitted for publication)
tajn, and Victor again for their helpful comments. The re-
search presented here was supported by grant 277-70-006 of
the Netherlands Organization for Scientific Research (NWO).
                                                                1144

