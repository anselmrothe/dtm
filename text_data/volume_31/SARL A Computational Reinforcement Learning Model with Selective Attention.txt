UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
SARL: A Computational Reinforcement Learning Model with Selective Attention
Permalink
https://escholarship.org/uc/item/6bt7m4pq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Grinberg, Maurice
Hristova, Evgenia
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

  SARL: A Computational Reinforcement Learning Model with Selective Attention
              Maurice Grinberg (mgrinberg@nbu.bg), Evgenia Hristova (ehristova@cogs.nbu.bg)
                      Central and East European Center for Cognitive Science, New Bulgarian University,
                                          21 Montevideo Street, 1618 Sofia, Bulgaria
                           Abstract                                 describe and predict eye-movement and behavioural data at
  A model relating eye-movements and decision making is
                                                                    the same time and provide explanations about the relation
  proposed focused on the iterated prisoner’s dilemma game. Its     between them.
  main aim is to model previous experiments with eye-tracking
  recordings which show that participants attend to only a small              The Prisoner’s Dilemma Game
  part of the game payoff information. The model presented
                                                                    The Prisoner’s dilemma (PD) game is one of the most
  generates eye-movements based on two main mechanisms.
  The first takes into account the importance of the information    extensively studied social dilemmas. PD is a two-person
  attended with respect to the decision making process and          game. The payoff table for this game is presented in Figure
  while the second takes into account the variability of the        1. In PD games, the players simultaneously choose their
  information attended. The model is a discrete dynamical           moves – C (cooperate) or D (defect) – without knowing
  system which integrates learned selective attention with move     their opponent’s choice.
  choice. The model is found to reproduce fairly well the              In order to be a Prisoner’s dilemma game, the payoffs
  sensitivity to the payoff structure of the game and the
  attendance to payoffs found in experiments with human
                                                                    should satisfy the inequalities T > R > P > S and 2R > T+S.
  subjects. These results seem to be a promising first step in      Due to the payoff structure of this game a dilemma appears
  explaining the impact of partial and selective information        – there is no obvious best move. On one hand, the D choice
  acquisition in the prisoner’s dilemma.                            is dominant for both players – i.e. each player gets larger
  Keywords: eye-movements models; eye-tracking; selective
                                                                    payoff by choosing D than by choosing C no matter what
  attention; decision making; Prisoner’s Dilemma.                   the other player chooses. On the other hand, the payoff for
                                                                    mutual defection (P) is lower than the payoff S if both
              Goals of the Present Work                             players choose their dominated C strategies (R for each
                                                                    player).
It is the main goal of the current work to present a model in
which decision making is integrated with information                                                   Player II
acquisition in a single integrated mechanism. The model is                                         C               D
tested against experimental data if it is able to account for
                                                                                              C   R, R         S, T
                                                                                   Player I
both behavioral and information acquisition data.
   The model we present in this paper (SARL) is based on a                                    D   T, S         P, P
model proposed and used earlier (Hristova & Grinberg,
2005a) for describing playing in iterated Prisoner’s
Dilemma (PD) games with different payoffs and                          Figure 1: Payoff table for the PD game. In each cell the
cooperation indexes. The new model also uses the expected            comma separated payoffs are the Player I’s and Player II’s
subjective utility framework combined with reinforcement                              payoffs, respectively.
learning; however, it also incorporates selective attention
mechanisms. The name of the model SARL comes from                      As PD game is used as a model for describing social
Selective Attention and Reinforcement Learning. This work           dilemmas and studying the phenomena of cooperation, there
is part of a larger effort of clarifying the cognitive processes    is a great interest in the conditions that could promote or
underlying PD game playing (e.g. Hristova & Grinberg,               hinder cooperation. There are many factors, identified
2005b, 2008; Grinberg et al., 2005). In this series of              experimentally, that influence the cooperation rate in
research not only behavioral data was gathered, but also            playing iterated PD. Among them are framing (or the way
information acquisition data (using eye-tracking recordings         of describing the game to the participants in a experiment),
and computerized process tracing system). The results               players’ goals and motivation, opponent strategy, etc.
obtained in these studies show that players do not use all the      (Colman, 1995; Sally, 1995).
information available and that there is dependence between             One important characteristic which accounts for the
the playing strategy and the information acquisition                relation between payoff structure and cooperation in PD is a
patterns. The experimental results show that under the              quantity called cooperation index (CI) which was
condition of playing different PD, participants sometimes           introduced by Rapoport and Chammah (1965). It is
miss completely the payoff structure of the game which              calculated using the equation: CI = (R–P)/(T–S). CI may
automatically makes any model relying on full information           vary from 0 to 1 (see Figure 2) and it is positively correlated
about the payoffs useless. The model SARL has been                  with the percentage of C choices. An advantage in using
developed to account for such situations and be able to             such an index for predicting cooperation is that the
                                                                   821

probability of a C choice should depend not on the payoffs       information processing tasks using eye-movement
(T, R, P, S) individually but rather on the ratios of their      recordings (Rayner, 1992, 1998).
differences.                                                        The results of all empirical studies stress the essential role
                                                                 of the amount and type of information on the decision
                                                                 making process.
                                                                                      The SARL Model
                                                                 The model we propose here is a modification of the model
                                                                 proposed in Hristova & Grinberg (2005a) and has as goal to
                                                                 incorporate elements of active and selective attention.
                                                                 SARL can be viewed as based on the general framework of
    Figure 2: Examples of PD games with different CI. The        the subjective utility theory (Schoemaker, 1982) but with
     first game has a CI=0.9, the second one has CI=0.1.         dynamic determination of the utilities and of the
                                                                 expectations about the other player move probabilities based
  Information Acquisition in Decision Making                     on an information acquisition mechanism.
Information acquisition studies explore what information is         Models, similar in spirit have been used in different
sought, how long the information is examined, the sequence       contexts by Antonides (1994) and Piunti et al. (2007). The
of acquisition, and the amount of information acquired. The      latter approach is interesting in combining a simple
data made available are essential for studying the decision      subjective expected utility model with affections which
making process as a process taking place in time and based       control the speed of learning in the model. These models
on a specific sequence of information acquisition. The           however lack any selective attention mechanisms.
patterns of information acquisition impose constraints on           In order to benefit from the continuity in the two models,
the possible strategies of information evaluation and            we briefly present the model used in Hristova & Grinberg
decision making. Taking this into account, the importance        (2005a). It can be defined as follows:
of studying information acquisition patterns is emphasized
                                                                   V(C) = wCC Pff(CC) Pop(C) + wCD Pff(CD) Pop(D)          (1)
in numerous research papers (see e.g. Einhorn & Hogarth,
1981; Johnson, Payne, & Bettman, 1988).                            V(D) = wDC Pff(DC) Pop(C) + wDDPff(DD) Pop(D) (2)
   The fact that humans use part of the information and still    where:
behave in a consistent manner, shows the importance of the            • P(C) is the probability of move C for the player
decision making process based on incomplete information –             • V(C) and V(D) are the values of moves C and D;
how and what information is gathered, how and in what                 • Pff(CC), Pff (CD), Pff (DC), and Pff (DD) are the
order it is evaluated and processed to reach a decision. In
                                                                           current payoffs R, S, T and P, respectively;
order to understand these processes, the models of human
judgment and decision making, including game playing                  • Pop(C) is the predicted probability for the opponent
models, should be built on what we know about the real                     to play C.
mind’s capacities and limitations.                                  The quantities wCC , wCD, wDC, and wDD are weights that
   Many studies in judgment and decision making are aimed        stand for the importance of the specific game outcome (CC,
at the development and testing of models that deal with          CD, DC or DD). These weights are computed as running
evaluation and use of information. In many of them it is         averages of the payoffs received in the games with
implicitly assumed that information is already available and     respective outcome and thus depend on previous payoffs:
judgment and choice are considered on the basis of                   [wXY]new = (1-α) [wXY]old + α Pff(XY),                (3)
information which is already given. However, there is            where X and Y stand for C or D, respectively, Pff(XY) is
strong evidence that the information acquisition process is      the received payoff corresponding to a game outcome XY
part of the decision making process and thus can influence it    and 0<α<1.
(e.g., Einhorn & Hogarth, 1981; Lohse & Johnson, 1996).              Pop(C) is also calculated as a running average over the
   Information acquisition studies give us information not       past opponents moves:
only about the way in which reduction of information
occurs (if it is the case), but also on the pattern or temporal      [Pop(C)]new = (1-β) [Pop(C)]old + β Mop,                  (4)
order of acquisition. Such data provide important constraints    where 0< β <1 and Mop is the opponent’s move.
for any decision making model.                                       Because of the way the weights w’s and the probabilities
   Eye-tracking is one of the most popular methods for           Pop(C) are calculated (see eqs. (3) and (4)) they are
studying information acquisition. It is considered that the      responsible for the context sensitivity of the model and are
pattern of eye movements can provide objective and               dynamically updated after each game. In eqs. (1) and (2) ,
quantitative evidence on what is being processed at the          the use of the current-game payoffs ensures that the move
moment. Many studies investigate cognitive processes as          will depend also on the game at hand and on its CI (Hristova
reading, visual search, scene perception and other               & Grinberg, 2005a). This property is not available in typical
                                                                 reinforcement based models used in PD (Erev & Roth,
                                                                822

2001; Camerer et al., 2002; Macy & Flasche, 2002) in             reaching a decision within one and the same game. The
which the probability for a move is based only on the            initial value for the move values – V(X, 0) – is calculated as
previous games.                                                  the average of the respective weights times the
   The parameters for this part of the model are the             corresponding probabilities for the opponent’s move:
averaging parameters (α and β) and the initial cooperation
                                                                     V(X, 0) = wXC Pop(C) + wXD Pop(D)                    (7)
probability P(C).
                                                                 where X can be C or D.
   In SARL eqs. (1) and (2) become iterative and depend on
                                                                     The stopping criterion for this deliberation process is the
the look patterns and thus on the payoffs ‘perceived’ by the
                                                                 reaching of a threshold (see Roe et al., 2001) by the quantity
model. They are generated on the basis of learned
                                                                 (the softmax rule for V(C)):
information about the game. Two are the main factors which
underlie the mechanism of simulated eye-movements. The                                    1
                                                                           V =                                               (8)
first is based on the idea that game outcomes which are                          1+ e  -k(V(C)) - V(D))
wished and important (as measured by the magnitude of the
weights w’s in eqs. (1) and (2)) attract attention to the           and the move is determined according to the rule:
payoffs related to them in a top-down fashion (e.g. the
payoff R is more likely to be attended to the larger the
                                                                                  ⎧C if V ≥ θ
weight wCC is). The second factor is related to the rate of                  M =⎨                                           (9)
change of the information relevant for the decision making                        ⎩D if V < 1 - θ
– in our case the rate of change of the payoffs. This factor is  where the threshold θ can depend on behavioural
regarded to be related to a bottom-up mechanism and is           characteristics such as received payoff, verification of
similar to some extent to the uncertainty minimization           expectations, etc. In the present version θ is taken to be 0.8.
principle proposed in Hayhoe & Ballard (2005). In other          The rule (9) is deterministic but can also be made
words, information related to wishful outcome and                probabilistic. It requires the reaching of one of two
information which is changing fast, tends to attract the         attractors in order to make a move C or D. The speed of
attention of the model and its ‘gaze’. The gaze pattern          reaching the attractors depends on the parameter k in the
generator proceeds in two stages. Firstly, a transition matrix   softmax rule given in eq. (8).
giving the transition probabilities between any two look
zones zi and zj, is calculated using the equation:                            Simulations and Experiments
    T(zi, zj) = atd wxy(zj)+abu ∆wxy(zj) + r(zi, zj)    (5)
                                                                 In this section, SARL predictions are compared to the
where zi and zj are the initial and final look zones for a
                                                                 results of an eye-tracking study with human participants. In
saccade; atd and abu are coefficients standing for the relative
                                                                 the experiment and in the simulations one and the same set
importance of top-down and bottom-up influences,
                                                                 of PD games were used. We compare both information
respectively. The quantity r(zi, zj) can encode spatial
                                                                 acquisition patterns and choices for human participants and
information about the relative position of zi and zj, or can be
                                                                 the model.
related to the learning of looking patterns based on the
received payoff compared to the expected one, or to the          PD games used
level of surprise related to predictions about the opponent’s
move or game outcome. In general it may be non-                  A set of 100 PD different payoff matrices, containing an
symmetric with respect to the two zones reflecting spatial       equal number of games with CI equal to 0.1, 0.3, 0.5, 0.7,
asymmetries related, for instance, to cultural differences.      and 0.9 was used in the experiment. The payoff matrices
For the simulations in this paper it is set to zero. For goal-   were randomly generated with the payoff magnitudes kept
directed behavior, like the one in PD, the top-down              within certain limits. T was between 36 and 97 points (mean
influences are expected to be larger than the bottom-up ones     69), R was between 29 and 95 points (mean 60.7), P was
(Hayhoe & Ballard, 2005). The matrix T(zi, zj) is updated        between 15 and 59 points (mean 32.5), and S was between
after each game.                                                 10 and 20 points (mean 15). The games were presented
   When the game starts based on the updated matrix an           randomly with respect to their CI.
initial zone (payoff) is selected. It corresponds to a game
outcome and with the respective moves of the opponents           Experimental procedure with human participants
(e.g. R corresponds to a CC outcome). Depending on these         Game presentation The game was presented in a formal
moves (X for the player and Y for its opponent) the values       and a neutral formulation to avoid other factors and contexts
of the moves C and D are updated using the equation:             as much as possible. The terms ‘cooperation’ or ‘defection’
                                                                 were not mentioned in the instructions or in the interface to
    V(X, n+1) = (1-ε) V(X, n) + ε wXY Pff(XY)Pop(Y) (6)          further avoid influences other than the payoff matrix. On the
where ε is between 0 and 1; X and Y can be C or D,               interface, the moves were labeled in a neutral manner as ‘1’
depending on the payoff attended.                                and ‘2. ’Subjects were not informed about the existence of
   Eq. (6) replaces eqs. (1) and (2) of the model in Hristova    CI. The game interface is presented in Figure 3. The
& Grinberg (2005a) and is used several times before
                                                                823

participants had to choose their move by mouse clicks on             All participants were paid for their participation. The
one of the button on the left (move ‘1’ or move ‘2).              amount received depended on the points gained in the
   Participants were instructed to try to maximize their          experiment.
payoffs and not to compete with the computer. The payoffs
were presented as points, which were transformed into real
money and paid at the end of the experiment.
   The information about the games played was fully
available. After each game the participants got feedback
about their and the computer’s choices and payoffs in the
current game. Participants could also permanently monitor
the total number of points they have won and its money
equivalent. They had no information about the computer’s
total score. This was made to prevent a possible shift of
participants’ goal – from trying to maximize the number of
points to trying to outperform the computer.
Opponent’s strategy Participants played PD games against
a computer opponent. The computer player used a
probabilistic version of the tit-for-tat strategy: it takes into
account the two previous moves of the player and plays the
same move with probability 0.8. The latter makes the
computer’s strategy harder to be discovered by the                 Figure 3: Game interface and areas of interest (AOIs) used
participant and in the same time allows the participant to          in the experiment. The index ‘s’ and ‘c’ denote ‘subjects’
cooperate if they wish (and be followed by the computer).                         and ‘computer’ respectively.
Eye movements recordings Eye movements were recorded
using the ASL 501 eye-tracker with 60 Hz sampling rate.           Simulations
The light head mounted optics recorded the left eye
                                                                  SARL was run 30 times using the same procedure as in the
movements. The centre of the pupil and the corneal
                                                                  experiment. The same set of PD games was used and the
reflection were tracked to determine the relative position of
                                                                  model played against the same computer opponent. The first
the eye. A magnetic head tracking equipment (Ascension
                                                                  20 games were considered as training games and were
Flock of Birds) was used in order to compensate for the
                                                                  excluded from the analysis.
possible head movements and ensure sufficient precision of
                                                                     The averaging parameters α and β were fixed to 0.5 and
the measurements. Integration of the eye movements and
                                                                  0.4, respectively. The initial cooperation probability P(C)
head movements made it possible to compute point of
                                                                  was set to 0.5 and the initial perceived probability of
regard on the computer screen. Gaze tracker software for
                                                                  opponent playing C (Pop(C)) was also set to 0.5. These
data recording and analysis was used.
                                                                  values are psychologically plausible as in the beginning of
   The eye-tracker was calibrated using a 9-point grid. The
                                                                  the game players probably do not posses clear preferences
accuracy of the gaze position record is about 0.5 degrees
                                                                  between choices or expectations about the play of the
visual angle.
                                                                  opponent. The move threshold θ is set to 0.8.
   The game was presented on a 17” monitor (see Figure 3).
                                                                     The speed of reaching the attractors depends on the
Each box containing payoffs or moves occupied about 1
                                                                  parameter k in the softmax rule given in eq. (8) and is fixed
degree visual angle on the screen. The distance between two
                                                                  to 0.01.
adjacent boxes was at least 1 degree visual angle to ensure
stable distinction between eye-fixations belonging to
respective zones.                                                  Comparison between SARL and Experimental
                                                                                             Data
Participants and procedure 40 participants (17 males, 23          The model predictions and data from the experiment with
females) with normal or corrected to normal vision took part      human subjects are compared on number of measures. First,
in the eye-tracking experiment. All were university students      they are compared on the basis of playing choices, more
with average age of 23 years.                                     specifically, number of cooperative choices. Next, we
   After receiving instructions, participants were asked          compared the eye-movement data from the experiment and
several questions to make sure they have understood the           model predictions about the zone attendances and
game. Each participant played the set of 100 PD games,            transitions between zones.
described above. First 20 games are considered training and
are not included in the subsequent analysis.
                                                                 824

Cooperation                                                        The number of zone attendances for the model and for the
The first analysis compared the number of cooperative           eye-tracking data were compared for each zone using
choices for each experimental condition (model or               independent samples t-test. The tests showed no significant
experiment) and each level of the CI. Repeated measures         differences (all p>0.05) between the model and the
analysis of variance revealed that there is a significant main  experiment for each zone (see Figure 5).
effect of CI on cooperation (F(4, 272) = 11.23, p < 0.001)
and that there is no main effect of experimental condition
(human experiment or model) (F(1, 68) = 0.67, p = 0.41)
and that there is no interaction between the CI and the
experimental condition (F(4, 272) = 0.33, p = 0.85) (see
Figure 4).
                                                                  Figure 5: Comparison of the number of fixations per zone
                                                                        obtained with the model and in the experiment.
                                                                Transitions between different zones
                                                                As a next step in the analysis, the number of transitions
                                                                between zones containing participant’s possible payoffs was
                                                                considered. Transitions are assumed to indicate the
                                                                comparisons made between the payoffs. Averaged data for
                                                                all participants in the eye-tracking study and for the model
                                                                predictions is presented in Figure 6. The players made more
    Figure 4: Comparison of the dependence of the rate of
                                                                transitions between their bigger payoffs (Ts and Rs; and Ts
      cooperation on the CI of the PD game between the
                                                                and Ps); however, in general the number of transitions is
  theoretical and experimental results (error bars represent
                                                                pretty low.
                       standard errors).
Attention to different zones
The eye-tracking data were analyzed using the number of
fixations in each AOI as a measure for attention paid to each
AOI. This measure reflects the relative importance of the
information presented in the AOI (Jacob & Karn, 2003). 8
areas on the screen that are important in studying
information acquisition during PD game playing were
defined (see Figure 3). Each Area of Interest (AOI) contains
the box in which the information is presented and a small
region around it.
   The following AOIs were defined: 4 AOIs containing the
participant’s possible payoffs; 4 AOIs containing the
computer’s possible payoffs. The results showed that
players do not pay equal attention to all available              Figure 6: Comparison of the number of transitions for zones
information. They look at their own payoffs more often than      containing player’s possible payoffs (Ts, Rs, Ps, and Ss) for
the computer’s payoffs (2.71 fixations per game on all 4                     the experimental and the model data.
AOIs with their payoffs and 1.14 fixations per game on all 4
AOIs with their opponent’s payoffs). The low number of                         Discussion and Conclusion
zone attendances per game indicates that players do not
                                                                The paper presented a model based on reinforcement
always attend to all information before making a decision.
                                                                learning and top-down selective attention mechanisms.
They even do not attend their own payoffs in each game
                                                                   The comparison with eye-tracking and behavioural data,
(see Figure 5).
                                                                showed a reasonable agreement with respect to the average
   In the comparisons with the model only the 4 AOIs
                                                                cooperation rates, the dependence of cooperation on CI, and
containing the participant’s possible payoffs are analyzed
                                                                the number of fixations in the payoff looking zones.
referred to as Ts, Rs, Ps, and Ss.
                                                               825

   The number of transitions between the payoff zones,           Hristova, E. & Grinberg, M., (2005a) Investigation of
predicted by the model was larger than the experimental             Context Effects in Iterated Prisoner’s Dilemma Game. In:
value. The latter could be explained by the fact that only          Dey, A., Kokinov, B., Leake, D., Turner, R. (Eds.)
four payoff zones (Ts, Rs, Ps, Ss) were taken into account          Modeling and Using Context. LNCS (LNAI), 3554,
and all of the model transitions are between them leading to        Springer Verlag.
a unrealistically large number of transition. The human          Hristova, E., & Grinberg, M. (2005b). Information
players had access to many more zones when playing the              acquisition in the iterated Prisoner’s dilemma game: an
game and only direct transition between zones were counted          eye-tracking study. Proceedings of the 27th Annual
(with no intermediate fixation). The interface in the               Conference of the Cognitive Science Society. Elbraum,
simulations didn’t account for the opponent’s payoffs and           Hillsdale, NJ.
possible distraction outside the looking zones. Future           Hristova, E., & Grinberg, M. (2008). Disjunction effect in
versions of the simulations should account for these                prisoner's dilemma: Evidences from an eye-tracking
differences.                                                        study. In B. C. Love, K. McRae, & V. M. Sloutsky (Eds.),
   Despite these discrepancies, the results obtained show that      Proceedings of the 30th Annual Conference of the
a reinforcement learning model with selective attention as          Cognitive Science Society. Austin, TX: Cognitive Science
SARL can display a behaviour which is reasonably similar            Society.
to the one displayed by human subjects. The latter seems to      Jacob, R. & Karn, K. (2003). Eye tracking in human
indicate that the model captures important features of              computer interaction and usability research: Ready to
decision making in iterated PD games. It is important to            deliver the promise. In: Hyona, J., Radach, R., & Deubel,
stress that the model presented meets the requirements set in       H. (Eds.), The mind’s eye: cognitive and applied aspects
the beginning: it displays behaviour (decision making) and          of eye movement research. Elsevier Science BV.
information acquisition patterns simultaneously based on an      Johnson, E., Payne, J., & Bettman, J. (1988). Information
integrated decision making mechanism.                               displays and preference revearsals. Organizational
   At the same time, it is evident that more exploration of the     Behavior and Human Decision Processes, 42, 1-21.
dynamical properties of the model with respect to its            Hayhoe M., Ballard, D. (2005). Eye movements in natural
parameters is needed. Application of the model on existing          behavior. Trends in Cognitive Science, 9 (4), 188-193.
data and design of new experiment based on its predictions       Lohse, G. & Johnson, E. (1996). A comparison of two
are also planned for the near future.                               process tracing methods for choice tasks. Organizational
                                                                    Behavior and Human Decision Processes, 68, 28-43.
                   Acknowledgements                              Macy, M., & Flache, A. (2002). Learning dynamics in social
                                                                    dilemmas. PNAS, 99, 7229-7236
We would like to acknowledge the fruitful discussions and        Piunti M., Castelfranchi, C. & Falcone, R. (2007). Surprise
the participation in the experiments and data collection of         as shortcut for Anticipation: clustering Mental States in
Maria Popova, Emilian Lalev, and Vladimir Haltakov.                 Reasoning. In Proceedings of the IJCAI07, Hyberabad,
                                                                    India.
                                                                 Rapoport, A., & Chammah, A. (1965). Prisoner’s dilemma:
                         References                                 a study in conflict and cooperation. Univ. of Michigan
Antonides, G. (1994). Mental accounting in a Sequential             Press.
   Prisoner’s Dilemma game. J. Econ. Psychol.15, 351-374.]       Rayner, K., & Pollatsek, A. (1992). Eye movements and
Camerer, C., Ho, T.-H., & Chong, J. (2002). Sophisticated           scene perception. Canadian Journal of Psychology, 46,
   EWA Learning and Strategic Teaching in Repeated                  342-376.
   Games. J. Econ. Theory 104, 137-88.                           Rayner, K. (1998). Eye movements in reading and
Colman, A. (1995). Game theory and its applications in the          information processing: 20 years of research.
   social and biological sciences. Oxford: Butterworth-             Psychological Bulletin, 124, 372-422.
   Heinemann Ltd.                                                Roe, R. M., Busemeyer, J. R., & Townsend, J. T. (2001).
Einhorn, H., & Hogarth, R. (1981). Behavioral decision              Multi-alternative decision field theory: A dynamic
   theory: Processes of judgment and choice. Annual Review          connectionist model of decision making. Psychological
   in Psychology, 32, 53-88.                                        Review, 108, 370-392.
Erev, I., Roth, A. (2001). Simple reinforcement learning         Sally, D. (1995). Conversation and cooperation in social
   models and reciprocation in the prisoner's dilemma game.         dilemmas. A meta-analysis of experiments from 1958 to
   In: G. Gigerenzer & R. Selten (Eds.), Bounded                    1992. Rationality and Society, 7, 58-92.
   rationality: the adaptive toolbox. Cambridge, Mass. MIT       Schoemaker, P. (1982). The expected utility model: Its
   Press.                                                           variants, purposes, evidence and limitations. Journal of
Grinberg, M., Hristova, E., Popova, M. & Haltakov, V.               Economic Literature, 20, 529-563.
   (2005). Strategies in Playing Iterated Prisoner’s Dilemma
   Game: An Information Acquisition Study. In:
   Proceedings of the International Conference on Cognitive
   Economics. Sofia, NBU Press.
                                                                826

