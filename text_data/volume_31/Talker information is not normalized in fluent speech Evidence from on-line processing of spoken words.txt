UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Talker information is not normalized in fluent speech: Evidence from on-line processing of
spoken words
Permalink
https://escholarship.org/uc/item/03g0x7cv
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Creel, Sarah
Tumlin, Melanie
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

                           Talker information is not normalized in fluent speech:
                              Evidence from on-line processing of spoken words
                                              Sarah C. Creel (creel@cogsci.ucsd.edu)
                                 University of California, San Diego, Department of Cognitive Science
                                                          La Jolla, CA 92093-0515
                                         Melanie A. Tumlin (mtumlin@cogsci.ucsd.edu)
                                 University of California, San Diego, Department of Cognitive Science
                                                          La Jolla, CA 92093-0515
                              Abstract                                   one assumes that humans are intrinsically equipped to detect
   Recent work demonstrates that talker characteristics can be
                                                                         particular speech sounds, listeners still must discern which
   used as predictive cues for spoken word recognition.                  subset of those speech sounds is relevant to word identity in
   However, abstractionist accounts suggest that talker                  her or his own language. Consistent with this, infants are
   information is usually stripped away or “normalized” based            more sensitive than adults to phonemically-irrelevant
   on preceding speech material. A contrasting account is that           variability, including phoneme categories outside their own
   listeners never normalize, instead storing detailed,                  language (Werker & Tees, 1984), and acoustic variability
   acoustically-varied instances of words. These varied instances        among talkers (Houston & Jusczyk, 2000). Over
   then facilitate recognition of words in a vast variety of voices
   and accents. We present data suggesting that such “irrelevant”        development, the learner discovers that his or her spoken
   acoustic characteristics of word forms (talker-varying                language input has certain dimensions (such as F0 variation,
   acoustic attributes) are not normalized, but are instead              phoneme variation, rate variation), and further, that certain
   encoded, when learned in fluent speech context. Experiment 1          dimensions (phoneme variation, but not rate variation) are
   replicates recent demonstrations of talker specificity in word        linked to changes in word meaning. Gradually, then, the
   recognition. Using the same set of words in carrier sentences,        learner would reweight attention toward phonemic variation
   Experiment 2 finds that learners still encode talker
                                                                         and away from other types of variation. On this account,
   information even though in principle they could easily
   normalize away talker-based acoustic variability.                     adult native speakers attend primarily to phonemic
                                                                         information, even in learning new words in their native
   Keywords: talker variability; spoken word recognition; eye            language, as long as they are able to account for
   tracking; normalization; exemplar theory
                                                                         nonphonemic variation coming from another source
                                                                         (properties of the talker).
                          Introduction
                                                                         This approach contrasts with recent findings that talker
One central question in spoken language processing has                   information can be used to disambiguate words prior to their
been how we recognize nonidentical or novel instances of                 phonemic divergence point. Creel, Aslin, and Tanenhaus
known linguistic categories. The problem faced by a listener             (2008) examined the time course of talker effects on word
is that word forms exhibit a large amount of acoustic                    recognition by presenting listeners with known or novel
variability, but only a subset of that acoustic variability              words, where each word was perfectly correlated with a
actually discriminates one word from another. The                        single talker. Creel et al. found that listeners showed less
remaining variability in the speech signal has typically been            competition between different-talker pairs (male maid,
regarded as useless noise. On this account, the presumed                 female maze) than between same-talker pairs (male maid,
goal of the human language processing system is to remove                male maze). More specifically, in an eye tracking paradigm,
irrelevant variation, leaving only that variability which cues           listeners hearing “maid” in a male voice showed fewer looks
word identity. Problematically, there is a different set of              to the maze when it had consistently had a different talker
parameters to filter out depending on the utterance. For                 than when it had the same talker as “maid.” These data
instance, fundamental frequency (F0) and accent                          imply that adult listeners do not ignore talker information in
characteristics can vary from talker to talker, and rate of              learning and recognizing words.
speech can vary even within a talker (Van Lancker,
Kreiman, & Emmorey, 1985; Van Lancker, Kreiman, &                        Note here that talker information is not necessarily a
Wickens, 1985). Nonetheless, adult native speakers of a                  conscious percept that there is a particular talker. By talker
language are good at recognizing novel instances of a                    information, we refer to whatever set of acoustic attributes
familiar word, and seem robust to acoustic variability                   vary between talkers (such as F0, pitch variability, or speech
among talkers.                                                           rate, among other things). Of course, there are other types of
                                                                         acoustic variation that occur in speech as well, such as
Much research has been devoted to how listeners strain out               dialectal (accent) or idiolectal differences. In principle,
or normalize over variability in the speech signal. Even if              listeners should be able to take advantage of any sort of
                                                                     845

acoustic variability (talker-related or otherwise) during word       a sheet during “sheep,” that would suggest that listeners
recognition, as long as that variability is sufficiently             were temporarily entertaining the hypothesis that the word
patterned. We have selected talker variability in particular         they were hearing might be “sheet.” In the current study, we
because it interacts minimally with phonemic information             had participants learn nonsense word labels where certain
(though see Allen, Miller, & DeSteno, 2003; Newman,                  pairs of labels overlapped early, and either shared or did not
Clouse, & Burnham, 2001). (This is much less true for                share a talker.
accent variation, where the accent may alter particular
phonemes to resemble other ones.)                                                           Experiment 1
                                                                     Experiment 1 sought to replicate Creel et al. (2008) with a
The broader claim here is that the acoustic variability
                                                                     different artificial vocabulary than previously used. This
resulting from talker variation (or accent or idiosyncrasies
                                                                     new artificial vocabulary was very low in biphone
of the talker) is intrinsic to representations of word form. On
                                                                     frequency, but still roughly similar to common English
this view, the speech recognition system is not concerned
                                                                     words in the words’ CV[C]C structure. We used this
with straining out talker variability, but instead with storing
                                                                     vocabulary instead of those from either of the two Creel et
detailed information about how a particular word or speech
                                                                     al. experiments for two reasons: the Creel et al. effects with
sound varies as other attributes change (F0, for instance).
                                                                     real words were fairly subtle, and the effects with a highly
There is suggestive evidence that listeners store talker
                                                                     English-atypical artificial lexicon were relatively late. By
variation along with word form information. For instance,
                                                                     using this slightly easier-to-learn vocabulary, we hoped to
listeners seem not to generalize certain phoneme shifts from
                                                                     find strong, rapid talker-specificity effects that could then be
one talker to another (Kraljic & Samuel, 2007), implying
                                                                     compared to a second experiment with the words learned in
that at least some phonemic information may be stored in a
                                                                     a sentential context.
talker-dependent fashion. Further, listeners learning a new
second-language phoneme contrast are more successful at              Method
both perception and production when they hear exemplars
from multiple talkers (Pisoni and colleagues; Logan, Lively             Participants.      Thirty-two       native-English-speaking
& Pisoni, 1990; Lively, Logan & Pisoni, 1993; Lively,                participants received course credit for taking part in this
Pisoni, Yamada, Tokhura & Yamada, 1994; Bradlow,                     experiment.
Pisoni, Akahane-Yamada & Tokhura, 1996). Goldinger                      Stimuli. We created a miniature lexicon of 16 nonsense
(1996) demonstrated that correctly recognizing a                     monosyllabic words (Table 1). The 16 monosyllabic words
previously-heard word as “old” improves as the test talker’s         comprised 8 pairs of words, where each pair matched until
perceptual similarity to the original talker increases.              the final consonant. To lengthen slightly the time period
                                                                     during which each word was ambiguous, and to maximize
However, it is as yet unclear how pervasive these talker-            the availability of fundamental frequency (F0) information,
specificity effects are. It remains possible that, given time to     a correlate of talker identity, both initial and final
identify talker-specific characteristics, adult listeners            consonants were voiced. This meant that F0 information
remove these characteristics from their representations. This        was present from word onset, and that vowels were
is analogous to color perception: in isolation, a gray patch         relatively long. (In English, vowels preceding a syllable-
may appear to have a certain lightness, but given a surround         final voiced consonant are longer than those preceding
of a particular lightness, viewers’ perceptions automatically        voiceless consonants.)
correct for the lightness level of the context. Here, we
wanted to know if listeners correct for talker context in                     Table 1: Word pairs used in Experiments 1 & 2.
learning new words.
                                                                                        boog booj          belm beln
In Experiment 1, we replicated Creel et al.’s (2008) talker-                            darg darj          dalm daln
specificity effect with a vocabulary of novel words. Having                             veeg veej          vorm vorn
established this effect, we proceeded to investigate talker-                            zelm zeln           zerg zerj
specific learning of this vocabulary in sentence context in
Experiment 2. To accomplish this, we utilized an artificial             One male and one female talker each recorded all 16
lexicon paradigm in combination with eye tracking. In this           words, and tokens were selected on the basis of recording
paradigm, listeners learn nonsense words as labels for               quality. Each word diverged from the other word in the pair
unfamiliar objects. After learning, the listeners are asked to       (i.e., the final consonant began) around 362 milliseconds
select one of the objects out of an array on a computer              (ms) on average.
screen (Magnuson, Tanenhaus, Aslin & Dahan, 2003). Their                For each participant, in half of the pairs both words were
eye movements are tracked as the spoken instruction (such            spoken by the same talker (talker-same pairs), and for the
as “Click on the X”) unfolds over time. A high proportion of         other half of the pairs, each word was spoken by a different
looks to an object indicates that listeners are considering          talker (talker-different pairs). Pair type (talker-same, talker-
that object to be a possible alternative—for instance, if            different) and talker (word spoken by male or female) were
listeners hear “sheep” and briefly visually fixate a picture of      counterbalanced across words and participants.
                                                                 846

   Each word was learned as a label for one of 16 black-and-         to consolidate looking time data by participant and
white pictures. These pictures (Figure 1) have been used in a        condition into 50-ms time bins.
number of previous word-learning experiments by Creel and
colleagues. Shapes for similar-sounding word pairs were              Results
selected to be visually dissimilar, so as not to contaminate            Accuracy. Participants took two to six (m=3.3) 128-trial
results with visual similarity effects. There were four              blocks to reach the 90% correct criterion. We performed an
different quasirandom assignments of words to pictures, to           ANOVA with Competitor Type (paired, unpaired), Talker
minimize the possibility of spurious similarity between              Match (same talker, different talkers) and Block (first
words and pictures.                                                  training block, last training block, test) as within-
                                                                     participants factors. Performance is depicted in Figure 2.
                                                                     Accuracy increased over Block (F(2,62) = 345.22, p <
                                                                     .0001). Accuracy was much higher for unpaired
                                                                     phonemically dissimilar (boog, daln) trials than for paired
                                                                     trials (boog, booj; F(1,31) = 143.18, p < .0001). An
                                                                     interaction of Competitor Type and Block showed that the
                                                                     absolute difference in accuracy between phonemically
                                                                     dissimilar and phonemically paired trials decreased across
                                                                     blocks (F(2,62) = 53.73, p < .0001). A marginal interaction
                                                                     of Competitor Type x Talker Match (F(1,31) = 3.91, p =
                                                                     .06) reflected a nonsignificant advantage for different-talker
                                                                     items on paired trials, with a nonsignificant disadvantage for
                                                                     different-talker items among unpaired trials. This is
                                                                     interesting in that it suggests that listeners did not seem to
                                                                     use talker information strategically to gain an advantage in
   Figure 1. Sample learning trial. Labels for the two objects       learning.
                   depicted are paired labels.
   Procedure. Participants were presented with 128-trial
blocks. Trials within a block were randomly ordered. On
each trial, two pictures appeared and a label was spoken.
The location of the pictures on each trial were
counterbalanced to occur equally often at one of four
positions, in the upper left, upper right, lower left, and lower
right of the screen. The participant (initially guessing)
mouse-clicked one picture as the one labeled, and received
feedback in the form of the actually-correct picture
remaining visible, while the incorrect shape disappeared.
After reaching 90% correct on a 128-trial block, participants
proceeded to the test phase, which was identical to training
except that trials were not reinforced. At both training and                Figure 2. Accuracy during training and test phases,
test, on half the trials, the incorrect picture was the paired                Experiment 1. Error bars are standard errors.
label (they heard “boog” and saw a boog and a booj). On the
                                                                        Gaze fixations. The dependent variable was target
other half, the incorrect picture was a particular unpaired
                                                                     advantage: looks to the correct picture minus looks to the
word (they heard “boog” and saw a boog and a daln). This
                                                                     incorrect picture. (In the interests of space, we will not
controlled for effects of common presentation—if
                                                                     discuss analysis of the phonemically dissimilar “unpaired”
participants confuse words more simply because they are
                                                                     trials.) Bearing in mind that signal-driven eye movements
presented with the same pair of objects, then performance
                                                                     take about 200 ms to plan and execute (Hallett, 1986), and
should be equally poor for paired-word trials and unpaired-
                                                                     that the divergence point of paired words was 362 ms (+200
word trials.
                                                                     = 562 ms), we decided to examine target advantage two
   Equipment. During the experiment, participants’ eye
movements were monitored at a 2-ms sampling rate by an               time windows prior to 550 ms: 200-400 ms, and 400-550
Eyelink Remote eyetracker (SR Research, Mississauga,                 ms. We thus conducted an ANOVA with Talker Match
                                                                     (same, different) and Window (200-400ms, 400-550ms) as
ON). Custom Matlab software on a Mac Mini running OS
                                                                     within-participants factors. There was an effect of Window,
10.4 utilized PsychToolbox 3 (Brainard, 1997; Pelli, 1997)
                                                                     with Target Advantage increasing in the later window
and the Eyelink Toolbox (Cornelissen, Peters & Palmer,
                                                                     (F(1,31) = 9.02, p = .005). There was also an effect of
2002) to synchronize and communicate with the eyetracker.
                                                                     Talker Match, with greater target advantage scores for
Data were processed offline using scripts written in Python
                                                                 847

different-talker pairs (F(1,31) = 7.45, p =.01). Finally, a           encode talker information as an integral part of a word’s
Window x Talker Match interaction (F(1,31) = 17.71, p =               sound representation when words were presented more
.0002) indicated that the divergence between same- and                naturalistically in a carrier phrase. Here, listeners would
different-talker trials was not significant in the first time         have opportunity to calculate (and thus remove) talker-
window, but was significant in the second time window (p =            specific attributes from the words.
.0002). In fact, target advantage for same-talker trials did
not exceed 0. This implies that talker-specific information                                  Experiment 2
was used to predict word identity early on different-talker              To assess whether learners still encode acoustically
trials, before the words’ phonemic point of divergence.               specific word representations even when they have
                                                                      sufficient information to account for talker-specific
                                                                      characteristics, we trained participants in Experiment 2 with
                                                                      words presented in sentence contexts (“Click on the X”).
                                                                      This provided sufficient acoustic context to calculate talker-
                                                                      specific attributes, which could potentially be used to
                                                                      normalize upcoming material. At test, the sentence context
                                                                      was removed and words were presented in isolation, as in
                                                                      Experiment 1. If learners encoded normalized forms at
                                                                      training, they should show attenuated or absent effects of
                                                                      talker variability at test. If, instead, they encoded talker
                                                                      information as an integral part of the signal despite the
                                                                      preceding context, then talker variability effects should
                                                                      remain strong.
                                                                      Method
     Figure 3. Gaze fixations to correct pictures (thick lines)          Participants. N=32 participants from the same pool as in
  and incorrect pictures (thin lines) on paired trials, Exp. 1.       Experiment 1 took part.
                                                                         Stimuli. The stimuli used were the same words as in
Discussion                                                            Experiment 1, but were re-recorded in the frame sentence
                                                                      “Click on the X”. The same two talkers from Experiment 1
   Experiment 1 demonstrates both rapid and implicit use of
                                                                      recorded these sentences. The average length of the context
talker information. Talker information is rapid in that it
                                                                      was 511 ms. Data from a control experiment suggested that
facilitates discrimination of words prior to the phonemic
                                                                      listeners were able to distinguish the two talkers within
point of disambiguation, with about a 200 ms lead for
                                                                      about the first 350 ms of the carrier phrase. The average
talker-different pairs over talker-same pairs. Talker
                                                                      divergence point of paired words (from word onset) was 390
information was used implicitly in that it did not seem to
                                                                      ms.
improve accuracy—it merely facilitated processing. This
                                                                         Procedure and equipment. These matched Experiment
null effect of accuracy contrasts with Experiment 2 of Creel
                                                                      1, with the exception that participants were trained on full-
et al. (2008), where talker information did improve
                                                                      sentence versions and tested on isolated words.
listeners’ accuracy levels. The likely reason for this
difference is that the current vocabulary was easier to learn
                                                                      Results
due to its greater resemblance to English words, and that
listeners did not need to exhaust other cues (such as talker-         Accuracy. Participants took between two and five blocks of
varying acoustic attributes) in an attempt to learn the               training (m = 2.9) to achieve 90% correct performance.
vocabulary. More generally, these accuracy and gaze                   Performance (Figure 4) improved over training trials, much
fixation results replicate Creel et al. and support the idea          as in Experiment 1. We again performed an ANOVA with
that listeners necessarily store and utilize talker information       Competitor Type (paired, unpaired), Talker Match (same
during recognition of word-forms, consistent with models of           talker, different talkers) and Block (first training block, last
memory suggesting that listeners’ memories of word forms              training block, test) as within-participants factors. Errors
are highly acoustically accurate (e.g. Goldinger, 1998)               declined over Block (F(2,62) = 302.32, p < .0001). There
rather than filtering for specific pieces of information.             were more errors on paired trials than unpaired trials
   However, a normalization account suggests that this use            (F(1,31) = 242.96, p < .0001). , A Block x Competitor Type
of talker information is a somewhat isolated phenomenon               interaction (F(2,62) = 62.71, p < .0001) suggested that
that occurs only when listeners do not have any other                 paired trial accuracy came closer to unpaired trial accuracy
information at hand. Because words were learned in                    in later blocks. There was an interaction of Talker Match x
isolation, listeners likely had little time to acquire sufficient     Competitor Type (F(1,31) = 8.13, p = .007), suggestive of a
talker information to normalize upcoming input. Thus, in              slight (nonsignificant) advantage for different-talker paired
the next experiment, we test whether listeners continue to            trials but a significant (p = .04) disadvantage for different-
                                                                  848

talker unpaired trials. Thus, there is not a clear pattern of an     talker’s speech. Importantly, it seems that talker information
advantage for different-talker words.                                is stored regardless of whether or not it occurs in context,
                                                                     even in cases where listeners should be able to extract
                                                                     “irrelevant” talker variability.
   Figure 4. Accuracy on training trials and test, Experiment
                2. Error bars are standard errors.
   Gaze fixations. Gaze fixation patterns on unreinforced
test trials (Figure 5) were quite similar to Experiment 1. We
again analyzed two time windows in our ANOVA, 200-400                     Figure 5. Fixations to correct (thick lines) and incorrect
ms and 400-600 ms. The second window was extended to                                (thin lines) pictures, Experiment 2.
600 ms because these words were slightly longer than those
in Experiment 1 (591 ms). There was an effect of Window,                This research suggests not only that listeners can use
with greater target-advantage scores in the later window             nonphonemic variability to recognize words, but that
(F(1,31) = 5.3, p = .03). There was also an effect of Talker         listeners routinely store detailed acoustic information about
Match, with greater target advantages for different-talker           words they hear. Such storage would allow the listener to
trials (F(1,31) = 5.77, p = .02). These factors did not interact     retain a number of types of word form variability that might
(F(1,31)=2.66, p = .11). Compared to Experiment 1, the two           be useful in interpreting language in various contexts. For
Talker Match conditions did not differ in the 200-400 ms             example, the learner could store accent-specific variability
window, but differed in the 400-600 ms window (p = .016).            for various word forms. This is not equivalent to claims that
These results confirm that listeners are storing talker-             the learner adjusts representations of word forms by accent
specific acoustic attributes about these words. This is              (Dahan, Drucker, & Scarborough, 2008). The listener needs
particularly interesting in that listeners do not seem to have       neither to adjust perception or representation, because the
“factored out” talker identity during learning, even though          representations themselves include patterned variability.
they had ample spoken context over which to calculate                   These results have interesting implications with respect to
talker identity prior to word onset.                                 normalization accounts. In essence, normalization is not
                                                                     needed: listeners need not to remove variability from the
Discussion                                                           signal, but to predict the likely acoustic form of upcoming
   In Experiment 2, we trained listeners to recognize talker-        material. Thus, prior results indicating difficulty when talker
specific words in carrier phrases. This gave listeners the           identity changes rapidly (e.g. Magnuson & Nusbaum, 2007;
opportunity to extract talker-specific acoustic variables from       Martin, Mullennix, Pisoni, & Summers, 1989) may reflect
the utterance prior to word onset. If they did this during           errors in prediction rather than the difficulty of repeated
training, we reasoned, then they might not encode talker-            normalizations. That is, if the listener implicitly expects
specific properties along with the word, meaning that they           continuation in the same voice, an unexpected new voice
should not demonstrate talker-specific effects on the words          will mismatch the prediction. Of course, this stands in
alone at test. However, they did demonstrate talker-specific         contrast to data from Strange and colleagues (Jenkins,
effects at test, with talker-different words being                   Strange, & Miranda, 1994) suggesting that vowel
disambiguated sooner than talker-same words. This suggests           recognition is unimpaired when the talker is switched mid-
that listeners did not normalize for talker information with         syllable under a noise mask. Why rapid changes in talker
more spoken context during learning. This strengthens the            cause processing difficulty in some cases and not in others
case that listeners routinely store analog representations of        is a topic for future research. It may be that while processing
new words that do not subtract contextual acoustic variation.        is equally accurate in some cases, processing ease suffers.
                                                                     The current data speak to this issue: while listeners were
                    General Discussion                               equally good at recognizing the words in different-talker
                                                                     and same-talker pairs, they were more rapid at recognizing
   When listening to speech from a particular talker, the
                                                                     the words in different-talker pairs. Future research will
learner stores the acoustic variation that characterizes that
                                                                     address this interesting pattern of data.
                                                                 849

  We have noted that child learners and second-language             Kraljic, T., & Samuel, A. G.            (2007).   Perceptual
(L2) learners may be more sensitive than adult native                 adjustments to multiple speakers. Journal of Memory and
speakers to talker variability. The current results indicate          Language, 56, 1 – 15.
that even native-speaking adults are quite sensitive to talker      Lively, S. E., Logan, J. S., & Pisoni, D. B. (1993). Training
variability. Thus, less expert word learners (children, for           Japanese listeners to identify English /r/ and /l/. II: The
instance) may be even more profoundly affected by talker              role of phonetic environment and talker variability in
variation, as they do not have as much experience with the            learning new perceptual categories. Journal of the
full range of talker variability. In ongoing research, we are         Acoustical Society of America, 94, 1242 –1255.
exploring effects of talker specificity and talker diversity at     Lively, S. E., Pisoni, D. B., Yamada, R. A., Tohkura, Y., &
earlier points in development.                                        Yamada, T. (1994). Training Japanese listeners to
  In sum, listeners encode talker-relevant acoustic variation         identify English /r/ and /l/. III. Long-term retention of
without removing context. Listeners do not store a “relative”         new phonetic categories. Journal of the Acoustical Society
form of a word that removes nonphonemic variability, but              of America, 96, 2076 – 2087.
instead, a collection of acoustically-specific traces. This         Logan, J. S., Lively, S. E., & Pisoni, D. B. (1990).
study extends previous work on talker specificity in word             Training Japanese listeners to identify English /r/ and /l/:
learning to more natural fluent-speech contexts.                      A first report. Journal of the Acoustical Society of
                                                                      America, 89, 874 – 886.
                          References                                Magnuson, J. S., Tanenhaus, M. K., Aslin, R. N., & Dahan,
Allen, J. S., Miller, J. L., & DeSteno, D. (2003). Individual         D. (2003). The time course of spoken word learning and
  talker differences in voice-onset time. Journal of the              recognition: Studies with artificial lexicons. Journal of
  Acoustical Society of America, 119, 544 – 552.                      Experimental Psychology: General, 132, 202 – 227.
Bradlow, A. R., Pisoni, D. B., Akahane-Yamada, R., &                Magnuson, J. S., & Nusbaum, H. (2007). Acoustic
  Tohkura, Y. (1996). Training Japanese listeners to                  differences, listener expectations, and the perceptual
  identify English /r/ and /l/: IV. Some effects of perceptual        accommodation of talker variability. Journal of
  learning on speech perception. Journal of the Acoustical            Experimental Psychology: Human Perception &
  Society of America, 101, 2299 – 2310.                               Performance, 33, 391-409.
Brainard, D. H. (1997). The Psychophysics Toolbox.                  Martin, C. S., Mullennix, J. W., Pisoni, D. B., & Summers,
  Spatial Vision, 10, 433 – 436.                                      W. V. (1989). Effects of talker variability on recall of
Cornelissen, F.W., Peters. E., & Palmer, J. (2002). The               spoken word lists. Journal of Experimental Psychology:
  Eyelink Toolbox: Eye tracking with MATLAB and the                   Learning, Memory, & Cognition, 15, 676-684.
  Psychophysics Toolbox. Behavior Research Methods,                 Newman, R. S., Clouse, S. A., & Burnham, J. L. (2001).
  Instruments & Computers, 34, 613-617.                               The perceptual consequences of within-talker variability
Creel, S. C., Aslin, R. N., & Tanenhaus, M. K. (2008).                in fricative production. Journal of the Acoustical Society
  Heading the voice of experience: The role of talker                 of America, 109, 1181 – 1196.
  variation in lexical access. Cognition, 108, 633 – 664.           Pelli, D. G. (1997). The VideoToolbox software for visual
Dahan, D., Drucker, S. J., & Scarborough, R. A. (2008).               psychophysics: Transforming numbers into movies.
  Talker adaptation in speech perception: Adjusting the               Spatial Vision, 10, 437 – 442.
  signal or the representations? Cognition, 108, 710-718.           Van Lancker, D., Kreiman, J., & Emmorey, K. (1985).
Goldinger, S. D. (1996). Words and voices: Episodic traces           Familiar voice recognition: Patterns and parameters. Part
  in spoken word identification and recognition memory.              I. Recognition of backward voices. Journal of Phonetics,
  Journal of Experimental Psychology: Learning, Memory,              13, 19-38.
  and Cognition, 22, 1166 – 1183.                                   Van Lancker, D., Kreiman, J., & Wickens, T. (1985).
Goldinger, S. D. (1998). Echoes of echoes: An episodic               Familiar voice recognition: Patterns and parameters. Part
  theory of lexical access. Psychological Review, 105, 251-          II: Recognition of rate-altered voices. Journal of
  279.                                                               Phonetics, 13, 39-52.
Hallett, P. E. (1986). Eye movements. In K. R. Boff, L.             Werker, J. F., & Tees, R. C. (1984). Cross-language speech
  Kaufman, & J. P. Thomas (Eds.), Handbook of perception              perception: Evidence for perceptual reorganization during
  and human performance. New York: Wiley.                             the first year of life. Infant Behavior & Development, 7,
Houston, D. M., & Jusczyk, P. W. (2000). The role of                  49 – 63.
  talker-specific information in word segmentation by
  infants. Journal of Experimental Psychology: Human
  Perception and Performance, 26(5), 1570 – 1582.
Jenkins, J. J., Strange, W., & Miranda, S. (1994). Vowel
  identification in mixed-speaker silent-center syllables.
  Journal of the Acoustical Society of America, 95, 1030-
  1043.
                                                                850

