UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modality transfer of acquired structural regularities: A preference for an acoustic route

Permalink
https://escholarship.org/uc/item/7gr2144v

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Forkstam, Christian
Ingvar, Martin
Jansson, Andreas
et al.

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Modality transfer of acquired structural regularities:
A preference for an acoustic route
Christian Forkstam a,b,c (christian.forkstam@mpi.nl)
Andreas Jansson b (andy@kth.se)
Martin Ingvar b (martin.ingvar@ki.se)
Karl Magnus Petersson a,b,c,d (karl-magnus.petersson@mpi.nl)
a Max Planck Institute for Psycholinguistics, Nijmegen, Netherlands; b Cognitive Neurophysiology Research Group,
Stockholm Brain Institute, Karolinska Institute, Stockholm, Sweden; c Donders Institute for Brain, Cognition and Behaviour:
Centre for Cognitive Neuroimaging, Radboud University Nijmegen, Netherlands; d Cognitive Neuroscience Research Group,
Universidade do Algarve, Faro, Portugal
Abstract
In this paper we investigate a modality transfer in syntactic
classification of an implicitly acquired grammatical sequence
structure. Participants either practiced on acoustically
presented syllable sequences or visually presented consonant
letter sequences. During classification, statistical frequencybased and rule-based characteristics of the classification
stimuli were manipulated in an independent manner.
Participants performed reliably above chance on the postacquisition classification task although more so for the group
practicing on syllable sequences. These subjects were also the
only group to keep a significant performance level also in the
transfer condition. The results points to the importance for
keeping in mind the ecological validity of the input signal
when using artificial grammar learning as a laboratory model
for language acquisition.
Keywords: Artificial grammar learning; Implicit learning;
Modality transfer

Introduction
Humans possess adaptive mechanisms capable of implicitly
extracting structural information solely from observation
(Stadler & Frensch, 1998). This extraction typically occurs
by means of learning processes that are implicit to
theindividual. Implicit learning has several characteristics
and are typically compared with and separated from explicit
learning. Implicit learning is commonly supposed to have
(1) no or limited conscious awareness/access to the acquired
knowledge, (2) the acquired knowledge is more complex
than simple associations or exemplar-specific frequencycounts, it is (3) an incidental consequence of information
processing, and it (4) does not rely on declarative memory
(Forkstam & Petersson, 2005; Seger, 1994). Reber (1967)
suggested that humans can learn artificial grammars
implicitly by an abstraction process intrinsic to natural
language acquisition. Recently, there has been renewed
interest in using the artificial grammar learning paradigm to
model aspects of language acquisition (Gomez & Gerken,
1999) and for exploring differences between human and
animal learning relevant to the faculty of language (Hauser
et al., 2002).
Natural language acquisition is a largely spontaneous,
non-supervised, and self-organized process, where the

structural aspects of natural language typically are acquired
at an early age largely without explicit feedback
(Jackendoff, 2002). Similarly, implicit learning at play in
artificial grammar learning is a process whereby a complex,
rule-governed knowledge base is acquired largely
independent of awareness of both the process and product of
acquisition. Other aspects of natural language acquisition,
such as reading and writing, are on the contrary examples of
typically explicitly taught cognitive skills which require a
long period of acquisition. Such a visual/acoustic modality
transfer has the potential to function in the artificial
grammar learning model in the same way as the distinction
over reading/listening in the language function.
In the current study we investigated modality transfer
over the visual/acoustic signal in implicit artificial grammar
learning. In specific we manipulated the order of acquisition
and transfer modality: Participants practiced for 5 days on
either acoustically presented syllable sequences or visually
presented consonant letter sequences after which they
performed a classification test in the same modality,
followed by a between modality transfer test. An implicit
acquisition paradigm without feedback was used in which
the participants were only exposed to positive examples
(i.e., well-formed consonant strings) generated by the Reber
grammar (Figure 1). The classification strings were
balanced for substring familiarity relative the acquisition
string-set, independent of grammatical status. We attempted
to keep the similarity over modality tight by presenting the
stimuli in a sequential fashion, both the acoustically
presented syllables and the visually presented consonant
letter strings. The acquisition sessions were constructed as a
repeated short-term memory tasks extending over 5 days, as
prolonged acquisition over several days has shown still
increasing performance in artificial grammar learning (for
acoustic, see Faísca, Bramão, Forkstam, Reis, & Petersson,
2007; for visual, see Forkstam, Elwér, Ingvar, & Petersson,
2008). The subjects were never informed before or during
the acquisition about the underlying structure in the
acquisition strings. This procedure was used in the attempt
to minimize the influence of explicit knowledge and explicit
strategies during acquisition. First after the last acquisition
session on day 5 were the subjects informed about the
existence of the grammatical structure in the acquisition

1977

input. They were then instructed to perform grammaticality
classifications on new strings similar to the acquisition
strings. Two grammaticality classification tests then
followed, first in the same modality as during acquisition
followed by a transfer test in the transfer modality.
Our choice of visual and acoustic stimuli was made to
keep the different modalities within the scope of familiar
orthographic as well as acoustic stimuli for the Swedish
subjects included in the study, namely the written
consonants ({M,S,V,R,X}) and the spoken syllables ({bå,
fe, lu, pa, ti}). We chose these alphabets not to make the
transfer between the different modality only a matter of
written or spoken representation of the same underlying
linguistic content, but intended instead to force the transfer
not be completely interpreted as a acoustic representation of
the written consonants or vice versa.

Implicit statistical learning and grammar learning
Reber (1967) defined implicit learning as the process by
which an individual comes to respond appropriately to the
statistical structure inherent in the input. Thus, he argued,
the capacity for generalization that the participants show in
grammaticality classification is based on the implicit
acquisition of structural regularities reflected in the input
sample.
However, alternative theoretical frameworks have
questioned the abstract (‘rule’) acquisition interpretation and
instead suggest that grammaticality classification utilizes
exemplar-based (Vokey & Brooks, 1992) or, alternatively,
are based on chunk (n-gram) representations (Perruchet &
Pacteau, 1991). Thus, grammar learning, whether natural or
artificial, is commonly conceptualized either in terms of
structure-based (‘rule’) acquisition mechanisms or statistical
learning mechanisms. Some aspects of natural language
(e.g., syntax) are open to an analysis within the classical
framework of cognitive science, which suggests that
isomorphic models of cognition can be found within the
framework of Church-Turing computability (Davis, Sigal, &
Weyuker, 1994). These language models typically allow for
unlimited concatenation recursion supposedly characteristic
for human performance.
Alternative views on artificial grammar learning, that is
placed somewhere between the two more common
conceptualizations in terms of a rule-based acquisition or a
statistical fragment (surface) based learning mechanism,
relates the acquisition of simple structured representations
as akin to lexical learning which might be supported by
statistical learning mechanisms. These representations are
then activated, by for example an input string, and actively
represented and integrated in working memory during
parsing. The latter process is dependent on general
integrative mechanisms in the left inferior frontal cortex,
and is further dependent during automaticity of this
integration process on the head of the caudate nucleus (for a
review, see Forkstam & Petersson, 2005).
Support for the implicit character of artificial grammar
learning comes for example from lesion studies on amnesic
patients. Knowlton and Squire (1996) investigated amnesic
patients and normal controls on a classical and a transfer

version of the artificial grammar learning task. The patients
and their normal controls performed similarly on both
artificial grammar learning tasks while the amnesic patients
showed no explicit recollection of whole-item or fragment
information (i.e., bi- or tri-gram, or so called Associative
Chunk Strength, ACS). Based on the results from the
transfer version they argued that artificial grammar learning
depends on the implicit acquisition of both abstract and
exemplar-specific information. Knowlton and Squire (1996)
suggested that the latter indicates that distributional
information of local sequential regularities is acquired,
while the former suggests that abstract (i.e., ‘rule-based’)
representations are also acquired.
It has been argued that sensitivity to the level of ACS is a
reflection of a statistical fragment-based learning
mechanism while sensitivity to grammaticality status
independent of ACS is related to a structure-based
acquisition mechanism (Knowlton & Squire, 1996;
Meulemans & Van der Linden, 1997). Consequently, it has
been argued that sensitivity to ACS reflects an explicit
declarative learning mechanism while sensitivity to
grammaticality status independent of ACS reflects an
implicit procedural learning mechanism (cf. e.g., Petersson,
Forkstam, & Ingvar, 2004). It is however well possible to
imagine a parallel grammaticality and substring familiarity
information acquisition that are in both cases implicit in the
sense of independent of conscious awareness during
acquisition as well as retrieval.

Transfer in artificial grammar learning
Few studies on transfer artificial grammar learning report
strong cross-modality transfer effects (for a review, see
Redington & Chater, 1996). Altmann, Dienes & Goode
(1995) and Bigand, Perruchet & Boyer (1998) showed
successful transfer from musical tones to letters sequences,
and Altmann and colleagues (1995) found also successful
transfer from acoustical syllables to graphic symbols as well
as from graphical symbols to written syllables (see also
Tunney & Altmann, 1999, 2001). Conway & Christiansen
have shown that there is an advantage learning an artificial
grammar in the auditory modality as opposed to the visual
(see e.g. 2005; 2006). In the study of Gomez and Gerken
(1999) it was demonstrated that infants can show some
transfer capacity, suggesting abstracting capacities beyond
the acquisition input. Most studies reporting successful
transfer using the artificial grammar learning paradigm have
been working within the visual modality and in specific with
letter sequences (Gomez & Schvaneveldt, 1994; Reber,
1969). Transfer over letter alphabet has also successfully
shown lasting effects of transfer in amnesic patients
(Knowlton & Squire, 1996). Within transfer investigation in
the acoustic modality have also shown successful
performance in 8-month-old infants in the transfer from
linguistic to non-linguistic input (Malmberg, 2004).

The Reber grammar
Formal grammars such as the one used in this study serve as
an intentional definition of languages. These represent the
formal specification of mechanism(s) that generate various

1978

types of structural regularities. They are relevant as a
description tool for the processing regularities which are
ongoing in any cognitive domain which engages processes
operating on structured representations: action planning,
language, perception/generation of musical sound patterns,
etc. (Petersson et al., 2004). A formal grammar represents a
specification of a finite generating/recognizing mechanism
for a particular language (e.g., Davis et al., 1994). The
transition graph representation of the Reber machine
(Figure 1) is a representation of the generating and
recognition mechanism for the Reber language used in this
study.

S
2

V

4

>

M
0

<

S
X

1

R

6

M

V
3

X

>

0

>

5

R

Figure 1: The Reber grammar is an example of a rightlinear phrase structure grammar which can be implemented
in a finite-state architecture, here represented by its
transition graph. Grammatical strings are generated by
traversing the transition graph from state 0 through the
internal states along the indicated direction until reaching an
end state. The grammar will e.g. generate/parse
<MSSVRXSV> as a grammatical string but not the nongrammatical string <MXSVRXVV>.

Methods
Participants
25 right-handed healthy university students fluent in
Swedish volunteered to participate in the study (14 females,
mean age = 26 years, range = 20-36 years). They were all
pre-screened for medication use, history of drug abuse, head
trauma, neurological or psychiatric illness, and family
history of neurological or psychiatric illness. Written
informed consent was obtained according to the Declaration
of Helsinki and the local medical ethics committee approved
the study. Eleven of the participants were included in the
syllable group while 14 participants were included in the
consonant letter group due to technical issues.

Stimulus Material
Grammatical strings with a string length of 5-12 were
generated from the Reber grammar. The frequency
distribution of bi- and trigrams (2 and 3 letter chunks) for
both terminal and whole string positions were calculated for
each string in order to derive the associative chunk strength
(ACS) for each item (cf., Meulemans & Van der Linden,
1997). An acquisition set was selected as well as 3 sets of
grammatical and non-grammatical classification test strings.

The non-grammatical strings were generated by a switch of
letters in two non terminal positions in a grammatical string.
The classification set was further divided into high and low
ACS items relative the acquisition string set. We thus
manipulated two independent stimulus factors with respect
to the 3 classification set, grammaticality (grammatical/nongrammatical) and substring familiarity relative the
acquisition string set (high/low ACS) in a 2x2 factorial
experimental design.

Experimental design
The strings presented in a sequential fashion for both the
acoustically presented syllables and the visually presented
consonant letter strings during acquisition as well as
classification. The sequences presented in the acoustic
modality were generated from a set of normally occuring
syllables in Swedish (i.e., {bå, fe, lu, pa, ti}) while the
visual presented sequences were generated from a consonant
letter alphabet (i.e., {M, S, V, R, X}). The sequences were
presented in a sequential order 300 ms on 300 ms off in both
modalities using the Presentation software (nbs.neurobs.com). Before the first acquisition session, and in the same
modality as during acquisition, did the participants perform
a baseline preference classification where they indicated if
they liked a string or not based on their immediate intuitive
impression (i.e., guessing based on “gut feeling”, see e.g.
Forkstam et al., 2008).
During each acquisition phase for each of the 5 days were
the participants engaged in repeated short-term memory task
without performance feedback. The trials were presented in
a sequential fashion with pairs of either syllable sequences
or consonant letter strings. The subjects had to respond
immediately after presentation indicating whether the
sequences were the same or different. Each trial followed
each other in a self-paced manner to assure that the subject
stayed alert on each trial.
After the last acquisition session on day 5 were the
subjects informed that a complex system of rules had been
used to generate the acquisition strings, but they were not
informed about the rules themselves. They were then
instructed to classify novel strings as grammatical or nongrammatical based on their immediate intuitive impression
(i.e., guessing based on ‘’gut feeling’’). They were told that
these new strings were all generated from the same system
of rules as the acquisition strings. This first grammaticality
classification test was performed in the same modality as
during acquisition and was immediately followed by a
second grammaticality classification performed in the
transfer modality. All 3 classification tests distributed to the
subjects were always novel to the given subject, and
balanced for order over subjects. This means in specific that
the underlying regularity for a given grammatical (or nongrammatical) sequence was never reused in another test
occasion.

Data analysis
Mixed-effect repeated measures ANOVAs were used for the
analysis of the classification performance using the
statistical analysis software R (www.r-project.org). Two

1979

measures were used to analyze the subject response, d-prime
over grammaticality where hit = grammatical string
classified as grammatical, and d-prime over ACS where hit
= high ACS string classified as grammatical. For each
analysis we modeled the main factors classification session
[same/different modality] and group [acoustic/visual] as
fixed-effects, and subjects as random-effect. An overall
significance level of P < 0.05 was used for statistical
inference, and explanatory investigations for significant
effects were restricted to the reduced ANOVA contrasted
over the appropriate factor levels.

90

AGL transfer
Acoustic (Syllables) / Visual (Strings)

Classification Performance

80
70
Baseline

Same

Transfer

Classification test

0

1

2

Syllables2Strings
Strings2Syllables

-1

d-prime over grammaticality

3

Figure 2: Percent correct data for the syllable and
consonant string group. Error bars correspond to the
standard error of the mean.

Baseline

Same

Transfer

Classification test

0.5

Both the group that practiced on syllables and the group that
practiced on consonant letters showed an increase in their
acquisition performance over the 5 days of the experiment
(Day 1 vs. Day 5: F(1, 22) = 11, P < 0.003; Figure 5).
The group that practiced on consonant strings showed
significant correlations between their acquisition
performance on day 2, 3 and 4 with their transfer
performance (d-prime over grammaticality); Spearman’s
correlation coefficient: Day 2-4 > 0.69, P < 0.01). No other
correlation between acquisition and classification
performance was significant in any of the groups.

Syllables2Strings
Strings2Syllables

0.0

Acquisition Performance

1.0

Figure 3: D-prime as a function of grammaticality
status for the syllable and consonant string group. Hit =
grammatical string classified as grammatical.
d-prime over substring familiarity (ACS)

The syllable group showed significant grammaticality
sensitivity in the syllable classification (85% performance
level; F(1, 10) = 137, P < 0.001) and managed to transfer
into the visual modality (62%; F(1, 10) = 19, P = 0.001;
Figure 2 & 3). A static substring familiarity sensitivity (i.e.,
ACS) persisted throughout acquisition from the baseline
preference classification (F(1, 9) = 6.2, P = 0.032) to the last
day grammaticality classification (F(1, 10) = 15, P < 0.003)
but then disappeared in the transfer modality classification
(P > 0.25; Figure 4).
The consonant letter group showed significant
grammaticality sensitivity in the consonant classification
(68% performance level; F(1, 13) = 25, P = 0.001) but failed
to transfer into the acoustic modality (52%; P > 0.19;
Figure 2 & 3). A static substring familiarity sensitivity
(ACS) persisted throughout transfer from the postacquisition classification (F(1, 13) = 60, P < 0.001) to the
acoustic modality transfer classification (F(1, 13) = 23, P <
0.001; Figure 4).
Between group effects persisted for grammaticality
sensitivity where the syllable group performed better on the
post-acquisition test (F(1, 22) = 20, P < 0.001) and also in
the transfer modality (F(1, 22) = 10, P = 0.004), indicating a
persisting transfer effect for the syllable group as opposed to
the random performance of the consonant group (Figure 3).
No difference between group in substring familiarity
sensitivity (ACS) transfer was found (P > 0.08; Figure 4).

60
40

Results

50

Performance (% correct)

Syllables2Strings
Strings2Syllables

Baseline

Same

Transfer

Classification test

Figure 4: D-prime as a function of substring familiarity
(ACS) status for the syllable and consonant string group.
Hit = high ACS string classified as grammatical.

1980

90

AGL Acquisition
Acoustic (Syllables) / Visual (Strings)

85
80
75
70

Performance (% correct)

Syllables2Strings
Strings2Syllables

Day1

Day2

Day3

Day4

Day5

Acquisition days

Figure 5: Acquisition performance data (percent
correct) for the syllable and consonant string group.

Discussion
In the present study we employed the implicit artificial
grammar learning paradigm to investigate the difference in
the lasting effects of a modality transfer in artificial
grammar learning over the acoustic/visual signal. Results
showed that learning was higher overall for sound/syllable
sequences, and that transfer only occurred from syllables to
strings, and not vice-versa. In grammaticality classification,
after 5 days of implicit acquisition, did both subjects who
had practiced on acoustically presented syllables and
subjects which had practiced on visually presented
consonant letter strings classify with high accuracy (Figure
2). However, when tested in cross-modality did only those
participants which had acquired the acoustical syllable
sequences (somewhat equivalent to the listening signal in
the language function) show any transfer performance when
tested on orthographical letter sequences (equivalent to the
reading signal) derived from the same grammar, and not
vice versa. This finding is in line with some other studies
that also have shown an advantage learning an artificial
grammar in the auditory modality as opposed to the visual
(see e.g. Conway & Christiansen, 2005, 2006).
In relation to the substring familiarity manipulation in the
classification material, did both groups show an effect at the
time of the grammaticality classification that was performed
in the same modality. In the transfer modality however, the
group that had practiced on visually presented letter strings
transferred this sensitivity to the acoustic domain, while the
other group, which had practiced on acoustic stimuli, did
not. This might indicate that when the initial input signal is
in the visual domain, the subject is promoted to use
substring information, and that this will then be used as cue
information when going to the transfer modality, while the
opposite route is less affected by such frequency based
transfer. Thus, even though no significant difference in
substring familiarity reliance in the transfer test was found
between groups, a second finding in this study is that even
though learning was higher overall for the sound/syllable
learning than for the visual/consonant string learning,
transfer of substring familiarity only occurred from strings
to syllables, and not vice-versa. A general concern in the

interpretation of these results is the issue of unit size.
Subjects in the auditory modality were always trained on
whole syllables, whereas subjects in the visual modality
were always trained on consonants. If it is the case
individual letters carry with them less information than do
syllables, unit size might be confounded in the experimental
setup. Auditory to visual might then be easier, just as going
from a larger to smaller unit might be easier.
The group that practiced on consonant strings showed a
correlation between the acquisition tests on day 2-4 and the
transfer test. This finding, that only the group working on
sequential input in the visual domain and not the group
working on acoustic sequential input, might just be a
reflection of a difference in working memory load between
the different acquisition tasks. We are more used to
sequence information in the acoustic than in the visual
domain. Furthermore, because the task is being performed
on linguistic stimuli (phonemes presented acoustically and
letters presented visually) it might be natural to recode the
visual sequence into an auditory code (saying or thinking
about the sound of the letter after they see it).
This finding and that only the syllable-to-string group
showed transfer performance greater than chance suggests
an importance of an ecological validity in the input signal in
the use of artificial grammar learning as a laboratory model
for language acquisition. The current results point to that in
certain situation acoustic stimuli might be preferable over
visual stimuli in artificial grammar learning experiments.
The idea of an ecological importance in the input signal is in
line with the thought that humans are evolved and
developed to process auditory/acoustic sequential
information more efficiently than visual/orthographic
sequential information (see e.g., Conway & Christiansen,
2008, for a similar reasoning). This might merely be due to
differences in exposure to different domains (speech vs.
writing), and/or that spoken language is likely an evolved
human cognitive function while writing is a human
invention.
In summary, this paper tries to address important issues
about learning, knowledge representation, and language
acquisition. It gives some directions to what information
that is transferred across the acoustic and visual domain, and
leaves a flavor for future investigations in how this finding
relates to other kinds of skilled behaviour such as aspects of
language learning (speech vs. writing).

Conclusion
Subjects practicing on acoustical syllables as well as
subjects practicing on visual consonant letter strings showed
high performance levels after 5 days of implicit acquisition.
In cross-modality tests did however only participants that
previously were working on syllables show successful
transfer performance, while participants that had been
working on letter sequences did not. We also found
indication of the opposite behaviour for substring familiarity
information. The results points to the relevance of an
ecological validity of the input signal in the artificial
grammar learning model as well as in language learning
paradigms at large.

1981

Acknowledgments
This work was supported by Vetenskapsrådet, Hedlunds
Stiftelse and Stockholm County Council (ALF, FoUU).

References
Altmann, G. T., Dienes, Z., & Goode, A. (1995). Modality
independence of implicitly learned grammatical
knowledge. J Exp Psychol Learn Mem Cogn,
21(4), 899-912.
Bigand, E., Perruchet, P., & Boyer, M. (1998). Implicit
learning of an artificial grammar of musical
timbres. Cahiers de Psychologie Cognitive, 17(3),
577-600.
Conway, C. M., & Christiansen, M. H. (2005). Modalityconstrained statistical learning of tactile, visual,
and auditory sequences. J Exp Psychol Learn Mem
Cogn, 31(1), 24-39.
Conway, C. M., & Christiansen, M. H. (2006). Statistical
learning within and between modalities: pitting
abstract against stimulus-specific representations.
Psychol Sci, 17(10), 905-912.
Conway, C. M., & Christiansen, M. H. (2008). Seeing and
hearing in space and time: Effects of modality and
presentation rate on implicit statistical learning.
European Journal of Cognitive Psychology.
Davis, M. D., Sigal, R., & Weyuker, E. J. (1994).
Computability, Complexity, and Languages:
Fundamentals of Theoretical Computer Science (2
ed.). San Diego, CA: Academic Press.
Faísca, L., Bramão, I., Forkstam, C., Reis, A., & Petersson,
K. M. (2007, 4-8 of July, 2007). Implicit learning
of structured auditory sequences: An advantage for
verbal stimulus. Paper presented at the The Annual
Mid-Year
Meeting
of
the
International
Neuropsychological Society, Bilbao, Spain.
Forkstam, C., Elwér, Å., Ingvar, M., & Petersson, K. M.
(2008). Instruction effects in implicit artificial
grammar
learning:
A
preference
for
grammaticality. Brain Res, 1221, 80-92.
Forkstam, C., & Petersson, K. M. (2005). Towards an
explicit account of implicit learning. Curr Opin
Neurol, 18(4), 435-441.
Gomez, R. L., & Gerken, L. (1999). Artificial grammar
learning by 1-year-olds leads to specific and
abstract knowledge. Cognition, 70, 109-135.
Gomez, R. L., & Schvaneveldt, R. W. (1994). What is
learned from artificial grammars? Transfer tests of
simple association. J Exp Psychol Learn Mem
Cogn, 20(2), 396-410.
Jackendoff, R. (2002). Foundations of language: Brain,
Meaning, Grammar, Evolution. Oxford, UK:
Oxford University Press.
Knowlton, B. J., & Squire, L. R. (1996). Artificial grammar
learning depends on implicit acquisition of both
abstract and exemplar-specific information. J Exp
Psychol Learn Mem Cogn
22, 169-181.

Malmberg, J. M. (2004). Domain specificity in artificial
grammar learning by infants and adults.
Malmberg, Jeanne M : New Mexico State U , US.
Meulemans, T., & Van der Linden, M. (1997). Associative
chunk strength in artificial grammar learning. J Exp
Psychol Learn Mem Cogn, 23, 1007-1028.
Petersson, K. M., Forkstam, C., & Ingvar, M. (2004).
Artificial syntactic violations activate Broca's
region. Cognitive Science, 28, 383-407.
Reber, A. (1967). Implicit learning of artificial grammars.
Journal of Verbal Learning and Verbal Behavior,
6, 855-863.
Reber, A. (1969). Transfer of syntactic structure in synthetic
languages. Journal of Experimental Psychology,
81(1), 115-119.
Redington, M., & Chater, N. (1996). Transfer in artificial
grammar learning: A reevaluation. Journal of
Experimental Psychology: General, 125(2), 123138.
Seger, C. A. (1994). Implicit learning. Psychological
bulletin, 115, 163-196.
Stadler, M. A., & Frensch, P. A. (Eds.). (1998). Handbook
of Implicit Learning. Thousand Oaks, CA: Sage
Publications.
Tunney, R., & Altmann, G. (1999). The transfer effect in
artificial grammar learning: Reappraising the
evidence on the transfer of sequential
dependencies. J Exp Psychol Learn Mem Cogn,
25(5), 1322-1333.
Tunney, R., & Altmann, G. (2001). Two modes of transfer
in artificial grammar learning. J Exp Psychol Learn
Mem Cogn, 27(3), 614-639.

1982

