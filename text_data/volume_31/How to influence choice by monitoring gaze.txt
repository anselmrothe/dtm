UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How to influence choice by monitoring gaze

Permalink
https://escholarship.org/uc/item/6125x42c

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Hoover, Merrit
Richardson, Daniel
Spivey, Michael

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

How to influence choice by monitoring gaze
Daniel C. Richardson (dcr@eyethink.org)

Cognitive, Perceptual and Brain sciences, University College London, Gower Street, London, WC1E 6BT, UK

Michael J. Spivey (spivey@ucmerced.edu)

Department of Cognitive Science, University of California, Merced, P.O. Box 2039, Merced, CA 95344, USA

Merrit A. Hoover (merrit@eyethink.org)

Department of Psychology, University of California, Santa Cruz, 1056 High Street, Santa Cruz, CA 95064 USA
In the moments that lead up to a decision, the cognitive
processes of choice are revealed in movements of the eye
and hand. For example, participants’ mouse cursors will
veer towards a button marked ‘fish’ when categorizing a
whale as mammal (Dale, Kehoe & Spivey 2007); their eyes
will often flit to a picture of a candle in the middle of
processing the spoken word ‘candy’ (Tanenhaus, SpiveyKnowlton, Eberhardt & Sedivy, 1995). In other words, the
probabilistic, incremental nature of cognitive processes are
played out in the timecourse of graded motor responses
(Spivey, 2008). We have developed a gaze contingent
technique that exploits this continuity between cognition
and action and allows us to influence participants’ opinions.
Our participants were asked a series of questions.
Sometimes the answers were clear (Should you brush your
teeth everyday?) but sometimes responses could reasonably
be yes or no (Is murder sometimes justifiable?). In the latter
case of intermediate truth values, previous work has shown
that mouse movements will veer between answers
(McKinstry, Dale & Spivey, 2008), and our pilot work
replicated these findings with eye movements. Participants
would look at yes and no buttons onscreen, settle on one for
around 500ms, and at that point make their decision. In the
current experiments, we exploited this characteristic of eye
movements in order to bias decision making.
A remote eye tracker monitored participants’ gaze as they
looked at yes and no buttons and considered their answer to
a question (do children need more discipline?). In the bias
yes condition, when the eye tracker detected that they had
looked at the yes button for a total of 500ms, the buttons
disappeared and participants were instructed to respond
immediately. On average, statements in the bias yes
condition were given a yes response 10% more often than
statements in the bias no condition (p<.01). Participants
reported no awareness of this gaze contingent manipulation.
In previous work we have shown that eye movements to
the external world are yoked to the internal cognitive
processes that govern memory retrieval (Richardson &
Spivey, 2000; Richardson & Kirkham, 2004; Hoover &
Richardson, 2008), figurative language comprehension
(Richardson & Matlock, 2007), production and
comprehension in conversation (Richardson & Dale, 2005;
Richardson, Dale & Kirkham, 2007) and even how we
respond to potentially offensive remarks (Crosby, Monin &
Richardson, 2008). The current results extend that close
relationship to decision making, and demonstrate that
simply measuring a graded, incremental motor output
allows one to exercise influence over cognitive processing.

References
Spivey, M., Grosjean, M. & Knoblich, G. (2005).
Continuous attraction toward phonological competitors.
Proceedings of the National Academy of Sciences,
102(29), 10393-10398.
Crosby, J. R., Monin, B., & Richardson, D. (2008). Where
do we look during potentially offensive behavior?.
Psychological Science, 19(3), 226-8.
Hoover, M. A., & Richardson, D. C. (2008). When facts go
down the rabbit hole: Contrasting features and objecthood
as indexes to memory. Cognition, 108(2), 533-42.
Richardson, D. C., & Dale, R. (2005). Looking to
understand: The coupling between speakers' and listeners'
eye movements and its relationship to discourse
comprehension. Cognitive Science, 29(6), 1045-1060.
Richardson, D. C., & Kirkham, N. Z. (2004). Multimodal
events and moving locations: Eye movements of adults
and 6-month-olds reveal dynamic spatial indexing.
Journal of Experimental Psychology: General, 133,
46-62.
Richardson, D. C., & Matlock, T. (2007). The integration of
figurative language and static depictions: An eye
movement study of fictive motion. Cognition, 102(1),
129-38.
Richardson, D. C., & Spivey, M. J. (2000). Representation,
space and hollywood squares: Looking at things that
aren’t there anymore. Cognition, 76, 269-295.
Richardson, D. C., Dale, R., & Kirkham, N. Z. (2007). The
art of conversation is coordination: Common ground and
the coupling of eye movements during dialogue.
Psychological Science, 18(5), 407-13.
McKinstry, C., Dale, R., & Spivey, M. J. (2008). Action
dynamics reveal parallel competition in decision making.
Psychological Science, 19(1), 22-4.
Spivey, M. J. (2008). The continuity of mind. New York:
Oxford University Press.
Tanenhaus, M. K., Spivey Knowlton, M. J., Eberhard, K.
M., & Sedivy, J. C. (1995). Integration of visual and
linguistic information in spoken language comprehension.
Science, 268(5217), 1632-1634.
Dale, R., Kehoe, C.E. & Spivey, M.J. (2007). Graded motor
responses in the time course of categorizing atypical
exemplars. Memory and Cognition, 35, 15-28

2244

