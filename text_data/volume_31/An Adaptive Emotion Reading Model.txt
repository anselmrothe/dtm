UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Adaptive Emotion Reading Model
Permalink
https://escholarship.org/uc/item/6bf49133
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Bosse, Tibor
Memon, Zulfiquar A.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                         An Adaptive Emotion Reading Model
                 Tibor Bosse, Zulfiqar A. Memon, Jan Treur ({tbosse, zamemon, treur}@few.vu.nl)
                                   Vrije Universiteit Amsterdam, Department of Artificial Intelligence
                                        De Boelelaan 1081, 1081 HV Amsterdam, the Netherlands
                             Abstract                               causation between emotional state (with gradually more
   This paper focuses on how capabilities to interpret somebody     feeling) and body state (with gradually stronger expression).
   else’s emotions can be modelled in an adaptive manner. First     This cycle is triggered by the stimulus and after an
   a cognitive model to generate emotional states is described.     indefinite number of rounds ends up in equilibrium for both
   This model involves a recursive body loop: a converging          states. In this way a model is obtained in which the process
   positive feedback loop based on reciprocal causation between     of generating an emotional feeling is not only assumed to be
   body states and emotions felt. By this model emotion reading
   can be modelled taking into account the Simulation Theory
                                                                    carried by neurological structures, but equally well by body
   perspective on mindreading as known from the literature,         states, in a reciprocal causation and convergence process.
   which assumes that the own emotions are involved in reading      By Bosse, Memon, and Treur (2008) and Memon and Treur
   somebody else’s emotions. It is shown how the model was          (2008), it was shown that such a recursive body loop model
   extended to an adaptive model within which a direct              for emotions is an appropriate basis to obtain an emotion
   connection between a stimulus and the emotion recognition is     reading model from the Simulation Theory perspective. In
   created, which implies that in principle the observed emotion    the current paper it is shown how the model based on a
   can be recognised just before it is felt.
                                                                    recursive body loop can be extended to obtain an adaptive
   Keywords: Theory of Mind; mindreading; adaptive emotion          model for emotion reading. The adaptation creates a
   reading; emotion generation; modeling; simulation.
                                                                    shortcut connection from the stimulus (observed facial
                                                                    expression) to the imputed emotion, bypassing the own
                         Introduction                               emotional states. Some simulation results are discussed, and
From an evolutionary perspective, mindreading (or having a          some formally specified dynamic properties of adaptive and
Theory of Mind) in humans and some other kinds of                   non-adaptive emotion reading are shown, and it is discussed
animals has developed for a number of aspects, for example,         how they were verified against simulation traces.
intention, attention, emotion, knowing (e.g., Baron-Cohen,
1995; Bogdan, 1997; Dennett, 1987; Goldman, 2006;                                 An Emotion Generation Model
Goldman & Spirada, 2004; Malle, Moses & Baldwin, 2001).
                                                                    The model to generate emotional states for a given stimulus
Two philosophical perspectives on having a Theory of Mind
                                                                    adopts from Damasio (1999) the idea of a ‘body loop’ and
are Simulation Theory and Theory Theory (Goldman,
                                                                    ‘as if body loop’, but extends this by making these loops
2006). In the first perspective it is assumed that mindreading
                                                                    recursive. According to the original idea, emotion
takes place by using the facilities involving the own
                                                                    generation via a body loop roughly proceeds according to
cognitive states that are counterparts of the cognitive states
                                                                    the following causal chain:
attributed to the other person. For example, the state of             sensing a stimulus → sensory representation of stimulus →
feeling pain oneself is used in the process to determine              (preparation for) bodily response → sensing the bodily response →
whether the other person has pain. The second perspective is          sensory representation of the bodily response → feeling the emotion
based on reasoning using knowledge about relationships              As a variation, an ‘as if body loop’ uses a causal relation
between cognitive states and observed behaviour. An                   preparation for bodily response →
example of such a pattern is: ‘I hear that the person says            sensory representation of the bodily response
‘ouch!’. Having pain causes saying ‘ouch!’. Therefore the           as a shortcut in the causal chain. In the model used here an
person has pain’. The current paper addresses emotion               essential addition is that the body loop (or as if body loop)
reading from a Simulation Theory perspective: an approach           is extended to a recursive (as if) body loop by assuming that
is adopted that involves a person’s own emotions in the             the preparation of the bodily response is also affected by the
process of reading the human’s emotions.                            state of feeling the emotion (also called emotional feeling):
   The concept of ‘body loop’ as put forward by Damasio               feeling the emotion → preparation for bodily response
(1999) and formalised by Bosse, Jonker and Treur (2008) is          as an additional causal relation. This idea is supported by
used as a point of departure. This perspective distinguishes        the following quote from Damasio (2003, p. 91-92):
the (bodily) emotional response to a stimulus from feeling
                                                                    ‘In other words, feelings are not a passive perception or a flash in time,
the emotion (sometimes called the emotional feeling), which         especially not in the case of feelings of joy and sorrow. For a while after an
is caused by sensing the own bodily response. Secondly, an          occasion of such feelings begins – for seconds or for minutes – there is a
extension of this idea is adopted by assuming that the body         dynamic engagement of the body, almost certainly in a repeated fashion,
loop is not processed once, but in a recursive manner: a            and a subsequent dynamic variation of the perception. We perceive a series
                                                                    of transitions. We sense an interplay, a give and take.’
converging positive feedback loop based on reciprocal
                                                                  1006

Both the bodily response and the emotional feeling are                            LP8 From sensory representation of body state to emotion
assigned a level or gradation, expressed by a number, which                       If a sensory representation for facial expression f with level v occurs,
is assumed dynamic. The causal cycle is modelled as a                             then emotion e is felt with level v.
positive feedback loop, triggered by the stimulus and                                srs(f, v) →
                                                                                               → emotion(e, v)
converging to a certain level of emotional feeling and body                       LP9 Imputation
state. Here in each round of the cycle the next body state has                    If a certain emotion e is felt, with level ≥ th and a sensory representation for
                                                                                  s occurs, then emotion e will imputed to s. Here, th is a (constant) threshold
a level that is affected by both the level of the stimulus and                    for imputation of emotion. In the simulations shown, th is assumed 0.95.
of the emotional feeling state, and the next level of the                            srs(s) & emotion(e, v) & v≥th →      → imputation(s, e)
emotional feeling is based on the level of the body state. In
the more detailed model described below, the combined                                 In the imputation state, the experienced emotion e is
                                                                                  related to the stimulus s, which triggers the emotion
effect of the levels of the stimulus and the emotional state
                                                                                  generation process. Note that this state makes sense in
on the body state is modelled as a weighted sum (with equal
                                                                                  general, for any type of stimulus s, as usually a person does
weights 0.5 in this case). This implies a pattern of gradual
                                                                                  not only feel an emotion, but also has an awareness of what
generation (and extinction) of an emotion upon a stimulus.
                                                                                  causes an emotion; what by Damasio (1999) is called a state
    In the description of the detailed cognitive model the
                                                                                  of conscious feeling also plays this role. This state that
temporal relation a →       → b denotes that when a state property
                                                                                  relates an emotion felt to any triggering stimulus will play
a occurs, then after a certain time delay (which for each
                                                                                  an important role in the emotion reading process.
relation instance can be specified as any positive real
number), state property b will occur. In this language
(called LEADSTO) both logical and numerical calculations
can be specified, and a dedicated software environment is
available to support specification and simulation; for details
see (Bosse, Jonker, Meij, & Treur, 2007). The specification
(both informally and formally) of the model for emotion
generation based on a recursive body loop is as follows.
LP1 Sensing a stimulus
If stimulus s occurs then a sensor state for s will occur.
   s→ → sensor_state(s)
LP2 Generating a sensory representation of a stimulus
If a sensor state for s occurs, then a sensory representation for s will occur.
   sensor_state(s) →    → srs(s)
                                                                      1
LP3 From sensory representation and emotion to preparation
If a sensory representation for s occurs and emotion e has level v,
then preparation state for facial expression f will occur with level (1+v)/2.
   srs(s) & emotion(e, v) →   → preparation_state(f, (1+v)/2)
If no sensory representation for s occurs and emotion e has level v,
then preparation state for facial expression f will occur with level v/2.
   not srs(s) & emotion(e, v) →    → preparation_state(f, v/2)
LP4 From preparation to body modification
If preparation state for facial expression f occurs with level v,
then the face is modified to express f with level v.
   preparation_state(f, v) →  → effector_state(f, v)
LP5 From body modification to modified body
If the face is modified to express f with level v,
then the face will have expression f with level v.
   effector_state(f, v) → → own_face(f, v)
LP6 Sensing a body state
If facial expression f with level v occurs,
then this facial expression is sensed.
   own_face(f, v) →  → sensor_state(f, v)
LP7 Generating a sensory representation of a body state
If facial expression f of level v is sensed, then a sensory representation for
facial expression f with level v will occur.
   sensor_state(f, v) →   → srs(f, v)
1
  Here, it is assumed that the relative effects of both antecedents are the
   same. However, the formula (1+v)/2 can as well be replaced by the more
   generic formula w1+w2*v with weights w1 and w2. Such an extension                    Figure 1: Example simulation of emotion generation
   also enables the modeller to distinguish different types of emotions (e.g.,
   fear may develop faster than happiness).
                                                                                1007

   Instead of a recursive body loop, a variation of the model              format, and used for simulation. An example simulation
as described can be made to model a ‘recursive as if body                  trace was obtained that for a large part coincides with the
loop’; see (Damasio, 1999) for evidence for a causal                       one shown in Figure 1 (with the other person’s facial
relation between preparation state and sensory                             expression f as the stimulus), with an extension as shown in
representation. This can be incorporated by replacing the                  Figure 2. Here also the time delays within the additional
temporal relations LP4, LP5. LP6, LP7 by the following:                    temporal LEADSTO relations were taken one time unit.
LP4* From preparation to sensory representation of body state
If preparation state for facial expression f occurs with level v, then a                                             s
sensory representation for facial expression f with level v will occur.                               sensor_state(s)
  preparation_state(f, v) → → srs(f, v)                                                                         srs(s)
    Based on the model, a number of simulations have been                                             imputation(s, e)
performed; for an example, see Figure 1 (here the time                       preparation_state(say(your emotion is e))
delays within the temporal LEADSTO relations were taken                         effector_state(say(your emotion is e))
1 time unit). In this figure, where time is on the horizontal                                                    time  0 5   10   15   20    25   30   35
axis, the upper part shows the time periods in which the
binary logical state properties s, sensor_state(s), srs(s),                         Figure 2: Trace extension for emotion reading
imputation(s, e) hold (indicated by the dark lines):
respectively from time point 0, 1, 2 and 9. Below this part                                  Adaptive Emotion Reading
for the other state properties values for the different time               As a next step, the model for emotion reading is extended
periods are shown (by the dark lines). For example, the                    by a facility to learn a direct connection between the
preparation state for f has value 0.5 at time point 3, which is            stimulus (the other face) and the emotion imputation. Such a
increased to 0.75 and further at time points 9 and further.                connection creates an emotion reading process that in
The graphs show how the recursive body loop approximates                   principle bypasses the generation of the own emotion. The
converging states both for emotion and facial expression.                  learning principle to achieve such an adaptation process is
                                                                           inspired by the well-known learning principle at a
                        Emotion Reading                                    neurological level that connected neurons that are frequently
Based on the model for emotion generation presented in the                 activated simultaneously strengthen their connecting
previous section, in this section a model for emotion reading              synapse (e.g., Gleitman, 1999). In an analogous manner,
(for the Simulation Theory perspective) is discussed. Such a               within the model presented here an extra state is included
model for emotion reading should essentially be based on a                 that represents the sensitivity of a direct connection between
model to generate the own emotions. Indeed, the model                      the sensory representation of the stimulus (the other face)
presented in the previous section can be specialised in a                  and the emotion imputation. If this sensitivity is high, the
rather straightforward manner to enable emotion reading.                   imputation will directly follow the sensory representation of
The main step is that the stimulus s that triggers the                     the stimulus, as is expressed by the following temporal
emotional process, which until now was left open, is                       relationship.
instantiated with the body state of another person; to make it             LP12 Imputation shortcut
                                                                           If the imputation sensitivity is high and a sensory representation for s
specific, a facial expression f of another person is                       occurs, then emotion e will imputed to s.
considered: s = othersface(f). Indeed there is strong                      srs(s) & srs_stimulus_imputation_sensitivity(high)
evidence that (already from an age of 1 hour) sensing                                  →→ imputation(s, e)
somebody else’s facial expression leads (within about 300                  The adaptation process itself and the persistence of the
milliseconds) to preparing for and showing the same facial                 sensitivity level is described by the following relationships.
expression (Goldman & Sripada, 2004, pp. 129-130).                         LP13 Imputation sensitivity adaptation
Furthermore, for the sake of illustration, following the                   If the imputation sensitivity is sen1 and a sensory representation for s
emotion imputation, a communication about it is prepared                   occurs and an imputation occurs, then the imputation sensitivity is the value
and performed. This extension is not essential for the                     sen2 next to sen1.
                                                                           srs(s) & imputation(s, e) &
emotion reading capability, but just shows an example of                   srs_stimulus_imputation_sensitivity(sen1) &
behaviour based on emotion reading.                                        next_value(sen1, sen2)
LP10 Communication preparation                                                         →→ srs_stimulus_imputation_sensitivity(sen2)
If emotion e is imputed to s, then a related communication is prepared     LP14 Imputation sensitivity persistence
  imputation(e, s) →→ preparation_state(say(your emotion is e))            If the imputation sensitivity is sen1 and no increase occurs, then it will
                                                                           remain the same.
LP11 Communication                                                         srs_stimulus_imputation_sensitivity(sen1) &
If a communication is prepared, then this communication will be
                                                                           next_value(sen1, sen2) &
performed.
                                                                           not srs_stimulus_imputation_sensitivity(sen2)
  preparation_state(say(your emotion is e))
                                                                                       →→ srs_stimulus_imputation_sensitivity(sen1)
           →→ effector_state(say(your emotion is e))
                                                                           srs_stimulus_imputation_sensitivity(high)
   The model described in the previous section has been                                →→ srs_stimulus_imputation_sensitivity(high)
extended by the above two temporal relations in LEADSTO
                                                                         1008

                  Adaptive Simulation                                Note in the lower part of Figure 3, the values of other
                                                                  state properties gradually increase as the person observes
Based on the model for adaptive emotion reading presented
                                                                  the stimulus, following the recursive feedback loop
in the previous section, a number of simulations have been
                                                                  discussed in Section 3. These values sharply decrease as the
performed; for an example, see Figure 3. In this figure, the
                                                                  person stops observing the stimulus, as described by the
imputation sensitivity state has initial value set to low,
                                                                  temporal relationship LP3 in Section 3. After the adaptation
represented by srs_stimulus_imputation_sensitivity(low) in the
                                                                  phase, and with the imputation sensitivity at high, the person
upper part. The adaptation phase consists of two trials,
                                                                  imputes emotion e to the target stimulus directly after
where as soon as the person imputes emotion e to the target
                                                                  occurrence of the sensory representation of the stimulus, as
stimulus s (which is the observation of the other person’s
                                                                  shown in the third trial in the upper part of Figure 3. Note
face), the imputation sensitivity level goes up, i.e., from low
                                                                  here that even though the person has adapted to impute
to medium to high, in accordance with the temporal
                                                                  emotion e to the target directly after the stimulus, the other
relationship LP13 described above. Note that the sensitivity
                                                                  state property values continue to increase in the third trial as
state keeps its value in the adaptation phase until the person
                                                                  the person receives the stimulus; this is because the
(again) imputes emotion e to target, as described by
                                                                  adaptation phase creates a connection between the sensory
temporal relationship LP14, but retains its final value, i.e.
                                                                  representation of the stimulus and emotion imputation
high, after the adaptation phase of two trials.
                                                                  without eliminating the recursive feedback loop altogether.
                                                                                  Verification of Properties
                                                                  To verify whether the overall behaviour of the model is
                                                                  according to expectations, some hypotheses (in terms of
                                                                  logical dynamic properties) have been identified, formally
                                                                  specified, and verified for simulation traces. These
                                                                  properties express proper emotion reading, and some of
                                                                  them are meant to distinguish emotion reading in a situation
                                                                  before adaptation and after adaptation. In particular, before
                                                                  an accomplished adaptation process, upon occurrence of a
                                                                  stimulus, first the emotion has to be felt before the emotion
                                                                  reading takes place. After an adaptation process, the
                                                                  emotion reading takes place before the emotion is felt and
                                                                  therefore it will take place faster.
                                                                      The modelling approach for temporal expressions is
                                                                  based on the Temporal Trace Language TTL (cf. Bosse,
                                                                  Jonker, Meij, Sharpanskykh & Treur, 2009). This reified
                                                                  temporal predicate logical language supports formal
                                                                  specification and analysis of dynamic properties, covering
                                                                  both qualitative and quantitative aspects. TTL is built on
                                                                  atoms referring to states, time points and traces. A state of a
                                                                  process for (state) ontology Ont is an assignment of truth
                                                                  values to the set of ground atoms in the ontology. The set of
                                                                  all possible states for ontology Ont is denoted by
                                                                  STATES(Ont). To describe sequences of states, a fixed time
                                                                  frame T is assumed which is linearly ordered. A trace γ over
                                                                  state ontology Ont and time frame T is a mapping γ : T →
                                                                  STATES(Ont), i.e., a sequence of states γt (t ∈ T) in
                                                                  STATES(Ont). The set of dynamic properties DYNPROP(Ont)
                                                                  is the set of temporal statements that can be formulated with
                                                                  respect to traces based on the state ontology Ont in the
                                                                  following manner. Given a trace γ over state ontology Ont,
                                                                  the state in γ at time point t is denoted by state(γ, t). These
                                                                  states can be related to state properties via state(γ, t) |= p
                                                                  which denotes that state property p (from sort SPROP(Ont))
                                                                  holds in trace γ at time t. Based on these statements,
                                                                  dynamic properties can be formulated in a sorted first-order
                                                                  predicate logic, using quantifiers over time and traces and
  Figure 3: Simulation results for adaptive emotion reading       the usual first-order logical connectives such as ¬, ∧, ∨, ,
                                                                1009

∀, ∃. A special software environment has been developed                              state(γ, t1) |= othersface(f)
for TTL, featuring a Property Editor for building TTL                                ∃t2:TIME, v:REAL [ t1<t2<t1+D & v>th &
                                                                                     state(γ, t2) |= effector_state(your emotion is e) &
properties and a Checking Tool that enables formal                                   state(γ, t2) |= emotion(e, v) ]
verification of such properties against a set of traces.
      Using the TTL environment, the following Global                              GP3b Emotion reading without own feeling
                                                                                   In trace γ, if at time point t1 a stimulus occurs, then there is a point in time
Properties (GP’s) have been identified, formalised and                             that the emotion is recognised whereas it is not felt (yet).
automatically verified (first an abbreviation is introduced to                     GP3b(t1:TIME, γ:TRACE) ≡
count how often a state holds in a certain time period):                             state(γ, t1) |= othersface(f)
Abbreviations                                                                        ∃t2:TIME, v:REAL [ t1<t2<t1+D & v≤0.1 &
state_holds_times_between(S:SPROP,0,tb,te:TIME,γ:TRACE) ≡                            state(γ, t2) |= effector_state(your emotion is e) &
                                                                                     state(γ, t2) |= emotion(e, v) ]
  ¬ [ ∃t1:TIME tb<t1<te & state(γ, t1) |= S ]
state_holds_times_between(S:SPROP,n+1,tb,te:TIME,γ:TRACE) ≡                             These properties can be used to distinguish the phase
∃t1:TIME tb<t1<te & state(γ, t1) |= S &                                            when the person performs emotion reading with an
   ¬[ ∃t2:TIME tb<t2<t1 & state(γ, t2) |= S ] &                                    experienced emotion from the phase without an experienced
   state_holds_times_between(S, n, t1, te, γ)                                      emotion. Checks pointed out that the second phase is
GP1a Input-Output Correlation Timing                                               entered at time point 126. To conclude, although not proven
In trace γ, if at time point t1 the person perceives a facial expression of        exhaustively, the above checks have pointed out that the
another person, then within time duration D this leads to communication
about the person’s emotional state.
                                                                                   model satisfies a number of relevant expected properties. In
GP1a(t1:TIME, γ:TRACE, D:REAL) ≡                                                   addition, they allow the modeller to fine-tune the precise
   state(γ, t1) |= othersface(f)                                                   temporal aspects of the simulated emotion reading process.
   [ ∃t2:TIME t1<t2<t1+D &
   state(γ, t2) |= effector_state(your emotion is e) ]                                                             Discussion
      This first property checks whether the process of                            A person’s observations of another person’s body, for
responding (verbally) to the stimulus is performed correctly.                      example facial expressions, are used by the person as a basis
As could be expected, this property indeed turned out to                           for emotion recognition. Here, a specific emotion
hold for any t1. In the situation before learning, it holds for                    recognition process can be modelled in the form of a
D=36, and after learning it holds already for D=6.                                 prespecified classification process of facial expressions in
GP1b Input-Output Correlation During Learning                                      terms of a set of possible emotions; see, e.g., (Cohen, Garg
If in trace γ between tb and te the person perceives a facial expression of        & Huang, 2000; Malle, Moses & Baldwin, 2001; Pantic &
another person for n (different) time points, then within time duration D          Rothkrantz, 1997 & 2000). Indeed, a model based on such a
this leads to communication about the person’s emotional state.
GP1b(tb, te:TIME, n:INTEGER, γ:TRACE, D:REAL) ≡
                                                                                   classification procedure is able to perform emotion
   state_holds_times_between(othersface(f), n, tb, te, γ)                          recognition. However, within such an approach the imputed
   [ ∃t:TIME te<t<te+D &                                                           emotions will not have any relationship to a person’s own
   state(γ, t) |= effector_state(your emotion is e) ]                              emotions. The model for emotion reading presented in the
      This property also holds for all time points, and for n=3                    current paper combines the person’s own emotion
and D=6: in all situations that the person perceived the                           generation with the emotion reading process as also claimed
stimulus three times, this resulted in a response within 6                         by the Simulation Theory perspective on mindreading, (e.g.,
time points.                                                                       Goldman, 2006; Goldman & Sripada, 2004). In addition,
                                                                                   adaptive facilities within the model allow the person to learn
GP2 Successful Associative Learning
If in trace γ between tb and te state property S1 and S2 hold together for n
                                                                                   a direct classification without involving the own emotions.
(different) time points, then eventually a relation between these states will           In (Goldman, 2006, pp. 124-132), a number of possible
be learned.                                                                        emotion reading models from the Simulation Theory
GP2(tb, te:TIME, n:INTEGER, γ:TRACE) ≡                                             perspective are sketched and discussed. For his model 1, a
   ∀S1,S2:SPROP                                                                    generate and test process for emotional states was assumed,
   state_holds_times_between(S1∧S2, n, tb, te, γ)
   [ ∃t:TIME ∃w:REAL te<t<te+D &
                                                                                   where on the basis of a hypothesized emotional state an own
   state(γ, t) |= sensitivity_for_relation_between(w, S1,S2) & w>δ ]               facial expression is generated, and this is compared to the
                                                                                   observed facial expression of the other person. In the
      This property holds for n=2 (and for D=1), which
                                                                                   assessment of this model, the hypothesis generation process
confirms that the associative learning is directly successful
                                                                                   for a given observed face was considered as less
after two trials. Note that here δ is a certain sensitivity
                                                                                   satisfactory. Models 2 and 3 discussed by Goldman (2006)
threshold, which can be considered to depend on n. Thus, an                        are based on a notion of ‘reverse simulation’. This means
example instance of sensitivity_for_relation_between(w, S1, S2)
                                                                                   that for the causal relation from emotional state to (the
could be the predicate srs_stimulus_imputation_sensitivity(high).
                                                                                   preparation of) a facial expression which is used to generate
GP3a Emotion reading with own feeling                                              the own facial expressions, also a reverse relation from
In trace γ, if at time point t1 a stimulus occurs, then there is a point in time   prepared own facial expression to emotional state is
that the emotion is recognised whereas it is felt as well.
                                                                                   assumed, which is used for the mind reading process. A
GP3a(t1:TIME, γ:TRACE) ≡
                                                                                 1010

point of discussion concerning these models is that it is        Simulation Theory perspective, whereas the model for the
difficult to fit them to the Simulation Theory perspective:      learning process to obtain this model is. As a final remark, it
whereas the emotional states and facial expression               may be considered that the learnt model (or part of) is
(preparation) states used for mindreading are the same as        innate, and is only further tuned by the learning process.
used for the own emotions and facial expressions, the causal
relations between them used in the two cases are not the                                  References
same. Model 4 is based on a so-called ‘mirroring process’,       Baron-Cohen, S. (1995). Mindblindness. MIT Press
where a correlation between the emotional state of the other     Bogdan, R.J. (1997). Interpreting Minds. MIT Press
person and the corresponding own emotional state is              Bosse, T., Jonker, C.M., Meij, L. van der, Sharpanskykh, A,
assumed, based on a certain causal chain between the two.          and Treur, J. (2009). Specification and Verification of
However, the relation of such a causal chain with the causal       Dynamics in Cognitive Agent Models. Int. Journal of
relations used to generate the own emotional states and            Coop. Information Systems, vol. 18, 2009, pp. 167-193.
facial expressions is not made clear.                            Bosse, T., Jonker, C.M., Meij, L. van der, and Treur, J.
    The approach adopted in the current paper has drawn            (2007). A Language and Environment for Analysis of
some inspiration from the four models sketched (but not            Dynamics by Simulation. International Journal of
formalised) by Goldman (2006), as briefly discussed above.         Artificial Intelligence Tools, vol. 16, 2007, pp. 435-464.
The recursive body loop (or as if body loop) introduced here     Bosse, T., Jonker, C.M., and Treur, J., (2008). Formalisation
addresses the problems of model 1, as it can be viewed as an       of Damasio's Theory of Emotion, Feeling and Core
efficient and converging way of generating and testing             Consciousness. Consciousness and Cognition Journal,
hypotheses for the emotional states. Moreover, it solves the       vol. 17, 2008, pp. 94–113.
problems of models 2 and 3, as the causal chain from facial      Bosse, T., Memon, Z.A., and Treur, J. (2008), Adaptive
expression to emotional state is not a reverse simulation, but     Estimation of Emotion Generation for an Ambient Agent
just the causal chain via the body state which is used for         Model. In: Aarts, E., et al. (eds.), Ambient Intelligence,
generating the own emotional feelings as well. Finally,            Proc. of the 2nd European Conf. on Ambient Intelligence,
compared to model 4, the models put forward here can be            AmI'08. Springer LNCS, vol. 5355, 2008, pp. 141–156.
viewed as an efficient manner to obtain a mirroring process      Cohen, I., Garg, A., and Huang, T.S. (2000). Emotion
between the emotional state of the other person on the own         recognition using multilevel HMM. In: Proc. of the NIPS
emotional state, based on the machinery available for the          Workshop on Affective Computing, Colorado, 2000.
own emotional states.                                            Damasio, A. (1999). The Feeling of What Happens: Body,
    Models for emotion reading by a person can be of two           Emotion and the Making of Consciousness. Harcourt
types: either they make use of the own emotion states of the       Brace & Co., NY, 1999.
person, or they are independent of them. In principle models     Damasio, A. (2003). Looking for Spinoza: Joy, Sorrow, and
according to the Simulation Theory perspective are of the          the Feeling Brain. Harcourt Brace & Co., NY, 2003.
first type, whereas models according to the Theory Theory        Dennett, D.C. (1987). The Intentional Stance. MIT Press.
perspective or based on a specific classification procedure        Cambridge Mass.
can be of the second type. In (Bosse, Memon, & Treur,            Gleitman, H. (1999). Psychology. W.W. Norton &
2008) a non-adaptive cognitive model for emotion reading           Company, New York, 1999.
is described based on a recursive body loop according to the     Goldman, A.I. (2006). Simulating Minds: the Philosophy,
Simulation Theory perspective. Moreover, it is shown how           Psychology and Neuroscience of Mindreading. Oxford
this model can be used by an ambient software agent in             University Press.
order to estimate a person’s emotion level. This software        Goldman, A.I., and Sripada, C.S. (2004). Simulationist
agent is adaptive in the sense that at run-time the parameter      models of face-based emotion recognition. Cognition, vol.
in the emotion reading model can be tuned to the person. By        94, pp. 193–213.
Memon and Treur (2008) it is shown how this non-adaptive         Malle, B.F., Moses, L.J., Baldwin, D.A. (2001). Intentions
model according to the Simulation Theory perspective can           and Intentionality. MIT Press.
be related to a biological (neurological) model. In contrast     Memon, Z.A., and Treur, J. (2008), Cognitive and
to the above models, the current paper addresses a cognitive       Biological Agent Models for Emotion Reading. In: Jain,
model for emotion reading which itself is adaptive. This           L., et al. (eds.), Proceedings of the 8th IEEE/WIC/ACM
adaptivity allows the model to gradually incorporate               Int. Conference on Intelligent Agent Technology, IAT'08.
relations that bypass the own emotion states, and thus at          IEEE Computer Society Press, 2008, pp. 308-313.
run-time provides a model for emotion reading independent        Pantic, M., and Rothkrantz, L.J.M. (1997). Automatic
of the own emotion state. As this learnt pathway bypasses          Recognition of Facial Expressions and Human Emotions.
the own emotion generation process, and its body-related           In: Proceedings of ASCI’97, ASCI, Delft, pp. 196-202.
part, it may be faster. Moreover, as own emotions are not        Pantic, M., and Rothkrantz, L.J.M. (2000), Expert System
involved anymore, it may be argued that the learnt model           for Automatic Analysis of Facial Expressions, Image and
for emotion reading by itself is not a model from the              Vision Computing Journal, vol. 18, pp. 881-905.
                                                               1011

