UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Balancing Long-Term Reinforcement and Short-Term Inhibition
Permalink
https://escholarship.org/uc/item/0zc5j8k7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Best, Bradley
Lebiere, Christian
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

               Balancing Long-Term Reinforcement and Short-Term Inhibition
                                               Christian Lebiere (cl@cmu.edu)
                                     Department of Psychology, Carnegie Mellon University
                                           5000 Forbes Ave, Pittsburgh, PA 15208 USA
                                          Bradley J. Best (bjbest@adcogsys.com)
                                                    Adaptive Cognitive Systems
                                            1709 Alpine Ave, Boulder, CO 80304 USA
                             Abstract                                 2004), include mechanisms that reinforce a piece of
   The ability to imperfectly but robustly enumerate a set of
                                                                      information after it has been accessed, making it even more
   alternatives manifests itself in many human activities.            likely to be accessed in the future. Young (2003) has
   However, many cognitive models have fundamental                    pointed out that the lack of refraction, together with those
   difficulties with this task, which often leads to degenerate       reinforcement mechanisms, can lead to pathological
   behavior. The primary source of this problem is the conflict       behaviors such as out-of-control looping where one piece
   between mechanisms of long-term reinforcement and the              of knowledge becomes so active that it is constantly
   need for short-term inhibition of recent items. Our analysis       retrieved at the expense of others.
   of a pair of pervasive domains of human activity finds that
   the long-term reinforcement process is balanced by a short-           This problem has also occurred in even more serious
   term inhibition. We have implemented this empirical                form in the development of higher-level languages that
   finding in a variation of the knowledge reinforcement              include implicit or explicit retrieval loops for checking
   equation of the ACT-R architecture. This new mechanism             logical conditions often involving universal quantifiers
   not only prevents degenerate behavior in memory retrieval,         (Jones, Crossman, Lebiere, & Best, 2006; Jones, Lebiere,
   but also emerges as a source of the power law distribution         & Crossman, 2007). Nested loops are particularly difficult
   observed in the environment, supporting the proposition that
                                                                      to deal with because they invalidate many of the potential
   the power law distribution arises from the interaction of the
   environment and cognition itself.                                  attempts to deal with the problem. Of course, this kind of
                                                                      processing is cognitively very difficult, and people
   Keywords: Cognitive Architectures, Bayesian Learning,              certainly don't perform it perfectly or completely, but they
   Human Memory, Power Law of Learning.
                                                                      usually manage to accomplish the task to some extent
                                                                      while avoiding the pathological behavior often exhibited
                         Introduction                                 by the cognitive models. While modelers can often
   A key aspect of many cognitive tasks, including                    prevent such behavior by carefully crafting their models to
planning and game playing, involves sequentially                      imbed clever strategies reflecting their meta-knowledge of
examining and evaluating a number of possible options.                the task, such knowledge engineering methods lack
Many everyday tasks also have that characteristic, such as            cognitive plausibility.      They also contribute to the
attempting to name all fifty states of the United States, or          brittleness and lack of portability of cognitive models when
all members of one’s research group.                                  they are transferred to real world situations that lack the
   Such enumeration is seldom exhaustive and                          predictability, static nature, constrained scale, and limited
unstructured. For instance, even (or especially) chess                complexity of laboratory experiments.
grandmasters seldom evaluate more than a few potential                   What is needed is an understanding of the human ability
moves in any given position. Also, people’s ability to                to enumerate a limited set of alternatives. Specifically, we
enumerate large sets of objects also tends to be limited to a         need to analyze the environmental, cognitive and neural
small number of items before repetition sets in, unless they          constraints that allow us to balance the long-term desire to
resort to domain-specific strategies (e.g., relying on                reinforce more commonly accessed items to facilitate
geographical or alphabetical order to name the 50 states).            future retrievals together with the short-term need to avoid
   However, as limited as this enumeration capacity might             iterated retrievals that lead to looping behavior. These
be, it also turns out to be highly pervasive and problematic          constraints, of course, must include those that come from
for many current computational models of cognition. Many              observing human behavior. The constraints then need to
modern cognitive architectures and frameworks, unlike                 be implemented in computational form that integrates with
earlier models such as production systems (e.g.,                      the other architectural mechanisms to provide the proper
McDermott & Forgy, 1978), do not include explicit control             functional characteristics that allow the cognitive models
mechanisms such as refraction, a mechanism that                       to display the same robustness and adaptivity, as is
temporarily prevents the reapplication of a just-performed            commonly exhibited by human experimental participants,
action, such as retrieving a specific piece of information.           without recourse to constant engineering on the part of the
Even more problematic, some of those architectures, e.g.,             modeler.
ACT-R (Anderson & Lebiere, 1998; Anderson et al.,
                                                                 2378

                 Environment Analysis                             As observed, the relation is largely invariant of corpus,
                                                                  with statistically insignificant variations for very short lags
Following the rational analysis approach (Anderson, 1990),
                                                                  (especially 1, which reflects infrequent word repetitions).
we view the environment as the primary shaper of
                                                                  For lags of 10 or more, the curve is roughly linear, i.e. the
cognition. Indeed, it was the analysis of Anderson &
                                                                  odds decrease as a power law of lag as in the original
Schooler (1991) that led to the reinforcement mechanism
                                                                  analysis. However, for short lags, the odds of appearance
in ACT-R that is largely responsible for the degenerate
                                                                  gradually deviate from the power-law, with a precipitous
behavior described above. The primary insight of that
                                                                  decline for immediate word repetitions (i.e. lag=1). This
analysis was that the odds of an item appearing in many
                                                                  deviation can be interpreted as an inhibition of return in the
common contexts such as email correspondence or
                                                                  environment that should be reflected in the appropriate
newspaper headlines increased as a power law of
                                                                  cognitive mechanisms, inasmuch as it is the opposite
frequency and decreased as a power law of recency. The
                                                                  dynamic to the current short-term reinforcement.
latter, in particular, provides a boost in activation after an
item is accessed, leading to a much higher probability of
immediate subsequent retrieval unless that item is
specifically excluded, such as through explicitly marking
conditions on retrievals or tagging by a mechanism such as
a declarative version of visual finsts (Pylyshyn, 1989). It is
fair to ask what we might add to the prior analysis of
Anderson and Schooler. Significantly, that analysis used
domains that were not directly relevant to (or specifically
excluded data related to) the short time scales of interest
here. Therefore, we will follow the same rational analysis
methodology in analyzing domains involving the
consecutive access of large numbers of items, but rather
than exclude items processed at short intervals, we will
focus on them. We have selected two such domains that
are pervasive in human activity and provide large amounts                   Figure 2: Odds of 10 most common words
of regular data for such an analysis: language processing
and arithmetic computations.                                        We performed a more detailed analysis to rule out the
                                                                  possibility that this result was an artifact of grammatical
Language                                                          rules or irregular words. Figure 2 establishes that the
   To be able to draw broad and robust conclusions, we            pattern holds for the ten most common words, albeit with
analyzed a broad array of text corpuses, from a scientific        additional noise resulting from the smaller sample size.
book chapter and proposal (about 30K words each) to               Those words should probably be excluded because their
classic books such as Dickens’ “A Christmas Carol” (about         syntactic roles are usually distinctive enough to result in
100K words) and Joyce’s “Ulysses” (about 300K words)              procedural rather than declarative processing (if they are
and a large section of a reference book, the Encyclopedia         processed at all – articles are often not lexically processed).
Britannica (about 300K words). Figure 1 plots the odds of         An important question is whether this pattern holds for less
a given word appearing a certain number of words after its        common words, and whether the period of inhibition is
previous appearance (a.k.a. lag), averaged over all words         sensitive to word frequency. To answer that question, we
of each text. The plot is on a log-log scale in order to          categorized the words by frequency of appearance.
easily display the expected power-law relations.
        Figure 1: Odds of appearance as a function of lag                  Figure 3: Odds by word frequency in Ulysses
                                                             2379

Figure 3 and 4 present a frequency analysis where words               rely upon our validated cognitive model of the lifetime
were grouped into five quintiles according to their                   learning of arithmetic facts, and in particular its
frequency in the two largest texts. The curves for each               assumptions about the distribution and frequency of
quintile are parallel, capturing the frequency effects (other         arithmetic facts. To avoid being overly dependent upon
than for the first quintile of most common words at long              those assumptions, however, we studied in particular the
lags)1. Both figures, but especially figure 4 (and one                statistical requests generated for one type of fact (counting)
would expect Britannica to be more regular and less                   by another type (addition). This allowed us to reflect both
linguistically idiosyncratic than Ulysses), establish that the        the statistics (in terms of the distribution of addition
inhibition effect is not dependent on word frequency.                 problems) and the structure of the domain in terms of the
Rather, the maximum odds of appearance occur around lag               requests for counting facts generated in solving addition
of 8-10 for all word frequencies. This is an essential piece          problems by backup computation. Figure 5 displays the
of data in constraining the implementation of this                    odds of a counting fact being accessed as a function of the
environmental constraint in an architectural mechanism.               lag since the previous access:
                                                                         Figure 5: Odds of access to counting fact as a function of
                                                                              lag in addition by repeated counting problems
   Figure 4: Odds by word frequency in Britannica
                                                                         All the same patterns evident in Figure 1 are present: an
Arithmetic                                                            initial inhibition for short lags, maximum odds slightly
Just as the original analysis by Anderson and Schooler had            short of a lag of about 8-10, then the typical power law
demonstrated the long-term statistical patterns over a range          decay beyond that. As for the language corpuses, we
of domains, it is essential for us to show that the short-term        decided to break down these aggregate odds into
inhibition trends found in the language corpuses are also             subcategories depending upon the frequencies of the facts
present in other environments. As a second domain, we                 accessed. Figure 6 presents the odds for five quintiles of
have chosen arithmetic facts for a number of reasons: it is a         decreasing frequencies.
regular domain that like language is shaped by both the
everyday world and formal schooling; it is a semi-formal
domain that is relatively well-understood; and it is a
domain that we have studied and modeled ourselves
(Lebiere, 1998). Arithmetic knowledge, for example, is
decomposed in a hierarchy of types, starting with counting
facts and on to addition and multiplication.                Each
subsequent level of the hierarchy is taught sequentially
(i.e., children first learn to count, then add, then
multiply…) and depends upon the previous ones for
reconstructing the current ones (i.e., addition by repeated
counting, multiplication by repeated addition, etc).
Unfortunately, knowledge of the actual statistical
                                                                                Figure 6: Odds of counting facts by quintiles
distributions of access to arithmetic knowledge is not
directly available in the same form as the language
                                                                         Again, the same patterns as in Figure 3 and 4 are present
corpuses. Textbooks provide one source of knowledge, but
                                                                      here as well: the curves for each quintile have the same
this source is relatively incomplete. Instead, we decided to
                                                                      characteristics as the aggregate curves, the maximum odds
                                                                      are reached at the same lags, and the curves are roughly
   1
     This reflects, as discussed previously, the special syntactic    parallel except for one. In the language corpuses, the most
role of the most common words that makes them highly likely to        frequent quintile was the one exhibiting a different pattern
appear regularly and can be ignored for our purposes.
                                                                 2380

  (a more steeply diving tail) because of the difficulty to          inhibition component as well as different ways of
  produce text at long lags without mentioning very common           combining the traditional reinforcement and the new
  words (e.g., articles). In the arithmetic corpus, the curve        inhibition factors. We have found the following form to be
  for the least frequent counting facts is the one exhibiting a      the most suitable in terms of both its functional properties
  different pattern (a flattening tail) because a few rare, large    and its ability to reproduce the data:
  counting facts repeat at significantly longer lags since they                     n            t n−d s 
  only occur in a few, infrequent addition facts. For                   Bi = log ∑ t −d j  − log1+         New BLL Equation
  instance, in the 10x10 addition table, the counting fact                         j=1                 ts 
  stating that 18 follows 17 will only be needed for the most        The “1+” component of the new term is necessary to make
  rare addition fact, 9+9, since the main statistical effect on      sure that it has a strictly inhibitory effect, i.e. the sum is
  fact distribution is that frequency decreases with size.           also greater than 1 meaning that the log is always positive.
                                                            €        One can see that the new inhibitory term added is similar
             Computational Implementation                            to the reinforcement term in being a power-law decaying
  We now turn to implementing those findings in a cognitive          term. However, this term only takes into account the most
  architecture and combine the resulting mechanism with              recent reference. Two new parameters have been added: a
  other, existing mechanisms to determine their interaction.         short-term decay rate ds and a time scaling parameter ts.
  We selected the ACT-R cognitive architecture for this              Figure 7 displays the effect of this new term on the base-
  implementation, although the resulting mechanism should            level activation and the effect of the new parameters. The
  be applicable to other architectures.           As mentioned       first curve (BLL) displays the standard base-level curve,
  previously, ACT-R currently uses a number of techniques            linear in log-log space. The second curve (PL(0.75;10))
  to prevent out-of-control retrieval loops resulting from           displays the new base-level learning with a short-term
  short-term boosts in activation. A full discussion of those        decay rate of 0.75 (compared to the standard decay rate of
  techniques is beyond the scope of this paper, but regardless       0.5) and a time-scaling parameter of 10. The proper effect
  it seemed that the solution to the problem should lay in the       seems to be generated but too weakly. The third curve
  same location as its source, namely in the equation derived        (PL(1.0;10)) shows the effect of increased decay on the
  by Anderson & Schooler (1991) that describes the learning          short-term inhibition, with a probability of retrieval at lag 1
  of the activation value of memory chunks as a function of          roughly equal to that at lag 100, and a peak around lag 10,
  history, specifically:                                             as generally observed in the data of Figure 1. The third
                 n                                                   curve (PL(1.0;5)) shows that decreasing the time scaling
      Bi = log ∑ t −dj         Base-Level Learning Equation          parameter from 10 to 5 effectively moves that peak from
                j=1                                                  around lag 10 to around lag 5. It seems that the parameters
  The summation over all past n references to a chunk i,             of the second curve (short-term decay of 1.0 and time
  implement the power law of practice while the decay of             scaling constant of 10) are about right. The final two
  each reference j as a function of time since reference tj and      curves (PL(3;1.0;10) and PL(2;1.0;10)) show the effect of
  decay rate d implements power law decay. However, as               assuming multiple past references (3 and 2 times as many,
€                                                                    respectively) as the original curve. One can see that the
  our analysis shows, those effects are only valid over longer
  time intervals, as exemplified by the linear trend in the log-     power law of practice is maintained at long lags
  scale graph of odds of appearance as a function of lag since       (significantly above 10) while the difference is
  the last appearance (e.g., see Figure 1 and 5). In the short       significantly reduced at short lags. The peak lag also
  run, within a lag of 5 to 10 appearances, there is a               seems to increase slightly with practice. All of these
  substantial decrease in odds of appearance that could be           effects reproduce the data quite well (see previous figures).
  captured by a short-term inhibition mechanism. This effect
  is precisely what we are looking for to prevent out-of-
  control reinforcement where retrieval leads to a large short-
  term activation boost, which in turn leads to more retrieval,
  and so on until the system ends up completely deadlocked.
  A short-term inhibition component in the base-level
  activation learning equation would actually result in lower
  activation for the next retrieval(s), which would prevent
  the same chunk from being retrieved again and give other
  chunks a chance of being retrieved instead. This is exactly
  the functionality needed to implement many key patterns
  of behavior (e.g. Jones, Lebiere & Crossman, 2007) such
  as the ability of evaluating a set of alternatives.
     We experimented with a number of different possible
  variations of the base-level learning equation, including
  power-law and exponential decay for the short-term                    Figure 7: Inhibition effect of new base-level learning
                                                                2381

This new equation allows for multiple interpretations. The        development of larger, smarter and more complex models
main issue is identifying a neural construct this term can be     capable of unanticipated (reasonable) behavior.
associated with. The most direct interpretation would be to          We therefore put the new base-level learning mechanism
associate it with short-term depotentiation known to inhibit      to a stringent test of robustness. Since the problem is out-
a neuron for a short period of time after its firing. Under       of-control retrieval loops, and the traditional solution is a
that view, the short-term decay rate is simply another            combination of chunk tagging (or finsts) with
instance on a very small time scale of past proposals to          corresponding constraints on retrieval, we focused on a
introduce multiple decay rates in long-term memory                model of free recall (unconstrained by the environment).
corresponding to different time scales (Anderson, Fincham         The model is given a fixed set of chunks and asked to
& Douglass, 1999), albeit here of an inhibitory nature. But       retrieve any chunk without any constraints repeatedly (for
another interpretation would be to associate this short-term      a large number of times). Each chunk starts with the same
inhibition of recently accessed information with its              initial history, and hence the same activation. The current
presence in short-term memory rather than its access in           base-level learning mechanism would immediately lead to
long-term memory. Under that interpretation, what is              a loop in which the same chunk would be retrieved over
preventing the chunk from being retrieved from long-term          and over again while all the other ones would be forgotten.
memory is not that it couldn’t be accessed there, but             With our new base-level mechanism, however, we
instead that it is still active in short-term memory, where       observed that a robust and flexible process of round-robin
access is much quicker and can therefore preempt the              retrieval emerged. Figure 8 displays the frequencies of
process of retrieval from long-term memory. The short-            free recall of each chunk as a function of each chunk’s
term decay rate is therefore the rate of decay in short-term      rank order of retrieval frequency and the total number of
memory, which is usually assumed to be much faster than           recall iterations (varying from 100 to 1000 for 10 chunks).
that of long-term memory (e.g., Ridderinkhof et al., 2004).
                          Behavior
The next question is to determine the effectiveness of this
mechanism in generating appropriate behavior as a part of
the overall architecture. In a simple model of free recall
where a number of chunks compete for retrieval without
any constraint, this new equation has been effective at
preventing out-of-control looping and implementing a
functional, if probabilistic, version of round-robin access.
This capability for declarative retrieval is similar to that
exhibited by a model of procedural selection that learned
production rule utilities to implement a flexible and
probabilistic monitoring loop (Lebiere et al, 2008).
Gradual, seamless transition from declarative to procedural          Figure 8: Frequencies of recall as function of item rank
control is a hallmark of human cognition. An important
benefit of this new form of the base-level learning equation         The results are quite intriguing. The free recall behavior
is to provide the activation calculus in declarative retrieval    is neither the traditional degenerate winner-take-all nor its
with the same sort of inhibition available to procedural          opposite, which would be an even distribution of recall
selection through error-correction feedback in production         frequencies over all chunks. This second extreme, a kind
rule utilities. However, it is relatively easy to show            of perfect round-robin, would be cognitively implausible,
robustness (or at least non-pathological behavior) under          as subjects in free recall experiments do forget some items
careful control conditions as implemented by a                    and retrieve some multiple times. It might also be less than
combination of the task model and its environment. What           perfectly functional, since some items might deserve more
we are looking for is greater robustness that prevents            frequent retrieval as a function of their characteristics such
degenerate behavior even when very little or no control is        as urgency or rate of change (e.g. Lebiere et al, 2008).
exerted upon the model behavior by the control structure          Instead, what emerges is a distribution of frequencies that
provided by the modeler or by the environment itself              slowly grows more uneven as the number of free recall
(including other agents). That is, we want an emergent            iterations gets larger. Stronger items slowly emerge as
robustness that does not originate from the model control         some are gradually forgotten. What is more remarkable is
structure authored by the modeler or that depends on              that the frequency distribution seems to follow the power
triggers present in the environment (e.g. in experimental         law observed in many natural environments, which is at the
design) but instead that results directly from the cognitive      core of the base-level learning equation itself. While this
architecture and its mechanisms. Having this kind of              may seem natural, it was not at all a given since, for
safeguard in the architecture would greatly relieve the           example, the previous base-level learning equation that
burden of the cognitive modelers and allow the                    also reflected those distributions did not give rise to them
                                                             2382

but instead led to degenerate, extreme distributions.             Anderson, J. R., & Lebiere, C. (1998). The Atomic
Instead, finding one possible origin of this phenomenon in          Components of Thought. Mahwah, NJ: Lawrence
the cognitive system itself might provide one important             Erlbaum Associates.
piece of puzzle that has fascinated cognitive scientists for      Anderson, J. R. & Schooler, L. J. (1991). Reflections of the
decades (e.g. Simon, 1955) and is increasingly viewed as            environment in memory. Psychological Science, 2, 396-
resulting from an interaction of the environment and                408.
human cognition itself (e.g., Manin, 2008).                       Anderson, J. R. & Schooler, L. J. (2000). The adaptive
                                                                    nature of memory. In E. Tulving and F. I. M. Craik
                        Conclusion                                  (Eds.) Handbook of memory, 557-570. New York:
   It is important to note the limitations of these results.        Oxford University Press.
First and foremost, full validation of this new mechanism         Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,
requires showing that it can account directly for precise           Lebiere, C., & Qin, Y . (2004). An integrated theory of
behavioral data, which we intend to do by taking existing           the mind. Psychological Review 111, (4). 1036-1060.
models of memory phenomena and removing the                       Huberman, B. A., Pirolli, P., Pitkow, J. E. & Lukose, R. M.
safeguards handcrafted into them by modelers to prevent             (1998). Strong Regularities in World Wide Web
degenerate behaviors, and showing that previous results are         Surfing. Science 280 , 5360, 95-97.
preserved. Also, our rational analysis approach does not          Jones, R.M., Crossman, J. A., Lebiere, C., & Best, B. J.
claim that this inhibition mechanism created these                  (2006). An abstract language for cognitive modeling. In
environmental effects, rather that our cognitive                    Proceedings of the 7th International Conference on
mechanisms have adapted to them. However, while other               Cognitive Modeling. Trieste, Italy
mechanisms (e.g. application of grammatical and                   Jones, R., Lebiere, C. & Crossman, J. A. (2007).
arithmetic rules) might also be responsible for our overall         Comparing Modeling Idioms in ACT-R and Soar. In
cognitive performance in these tasks, the new inhibition            Proceedings of the 8th International Conference on
mechanism definitely facilitates that performance. Finally,         Cognitive Modeling. Ann Arbor, MI.
one can wonder whether those external task characteristics        Lebiere, C. (1998). The dynamics of cognition: An ACT-R
(e.g. grammatical rules against repetition, choice of base          model of cognitive arithmetic. Ph.D. Dissertation. CMU
10 arithmetic) might not have themselves evolved to reflect         Computer Science Dept Technical Report CMU-CS-98-
pre-existing cognitive characteristics. Such a determination        186. Pittsburgh, PA. Available at http://reports-
would require modeling alternative task variants as well as         archive.adm.cs.cmu.edu/
performing the same analysis in more naturalistic domains.        Lebiere, C., Archer, R., Warwick, W., & Schunk, D.
   We have presented data that demonstrate the reduced              (2005) Integrating modeling and simulation into a
short-term likelihood of recent items appearing again in the        general-purpose tool. In Proceedings of the 11th
environment and an extension to the ACT-R architecture              International     Conference     on     Human-Computer
that reflects this likelihood and produces more robust              Interaction. July 22-27, 2005. Las Vegas, NV.
behavior than it did previously. We are currently exploring       Lebiere, C., Archer, R., Best, B., & Schunk, D. (2007).
a number of additional lines of study. Empirically, we aim          Modeling pilot performance with an integrated task
to replicate our findings in other human environments such          network and cognitive architecture approach. In Foyle,
as computer navigation, web environments and spatial                D. & Hooey, B. (Eds.) Human Performance Modeling in
navigation. Neurally, we aim to find correlates of                  Aviation. Mahwah, NJ: Erlbaum.
inhibition    in    mechanisms       such    as    short-term     McDermott, J. & Forgy, C. (1978). Production system
depotentiation. Behaviorally, we want to understand better          conflict resolution strategies. In D. A. Waterman & F.
how this new mechanism interacts with the rest of the               Hayes-Roth (Eds.), Pattern-Directed Inference Systems,
architecture and which other emergent effects it might give         177-199. Academic Press.
rise to, such as the spacing effect. This approach underlies      Manin, D.Y. (2008). Zipf’s law and avoidance of excessive
our belief that applying multiple constraints to architectural      synonymy. Cognitive Science, 32(7), 1075-1098.
mechanisms is the best way to satisfy both scientific goals       Pylyshyn, Z.W. (1989). The role of location indexes in
such understanding human behavior and practical goals               spatial perception: A sketch of the FINST spatial-index
such as developing more robust cognitive models.                    model. Cognition, 32, 65-97.
                                                                  Ridderinkhof, K. R., Ullsperger, M., Crone, E. A., &
                        References                                  Nieuwenhuis, S. (2004). The Role of the Medial Frontal
                                                                    Cortex in Cognitive Control. Science, Vol. 306. no.
Anderson, J. R. (1990). The Adaptive Character of                   5695, pp. 443 – 447.
   Thought. Hillsdale, NJ: Erlbaum.                               Simon, H. A. (1955). On a Class of Skew Distribution
Anderson, J. R., Fincham, J. M. & Douglass, S. (1999).              Functions. Biometrika 42 (3-4): 425–440.
   Practice and retention: A unifying analysis. Journal of        Young, R. M. (2003). Should ACT-R include rule
   Experimental Psychology: Learning, Memory, and                   refraction? In Proceedings of the Tenth Annual ACT-R
   Cognition, 25, 1120-1136.                                        Workshop. Pittsburgh, PA.
                                                             2383

