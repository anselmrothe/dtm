UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A New Theory of Classification and Feature Inference Learning: An Exemplar Fragment
Model
Permalink
https://escholarship.org/uc/item/7rz2v319
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Colner, Robert
Rehder, Bob
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                  A New Theory of Classification and Feature Inference Learning:
                                                An Exemplar Fragment Model
                                               Robert M. Colner (bob.colner@nyu.edu)
                                                  Bob Rehder (bob.rehder@nyu.edu)
                                              Department of Psychology, New York University
                                              6 Washington Place, New York, NY 10003 USA
                               Abstract                                   information such as typical features. In contrast, by focusing
                                                                          on diagnostic information, classification encourages repre-
   In addition to supervised classification learning, people can also     sentations consistent with learning rules and exceptions.
   learn categories by predicting the features of category mem-              In their seminal study, Yamauchi & Markman (1998)
   bers. One account of feature inference learning is that it induces     contrasted classification and inference learning with a
   a prototype representation of categories. Another is that it re-       family resemblance category structure consisting of four
   sults in a set of category-to-feature rules. Because neither
                                                                          items in two categories (labelled ‘A’ and ‘B’ in Table 1).
   model provides an adequate account of existing data, we pro-
   pose instead that inference learning induces an anticipatory
                                                                          Each category member has one exception feature from the
   learning strategy in which learners attend to aspects of training      other category. To keep the classification and inference
   items they think will be needed in the future, and by so doing         tasks as closely matched as possible, inference learners were
   incidentally encode information about the category’s internal          not presented with exception feature trials in which the to-
   structure. The proposal is formalized by an exemplar fragment          be-predicted feature was from the opposite category. For
   model (EFM) that represents partial exemplars, namely, those           example, they were never presented with the category A
   parts that are attended during training. EFM’s attention weights       item 000x and asked to predict (on the basis of A1 in Table
   are approximated by eyetracking data, resulting in fewer free          1) a ‘1’ for the unknown value x on dimension 4. Instead,
   parameters as compared to competing theories.                          they were only given typical feature trials in which they
                                                                          predicted the category’s typical feature (e.g., a ‘0’ for item
When people classify objects, problem solve, describe con-                Ax001). Following learning, all participants completed a
cepts, or infer missing information, they must access con-                transfer test in which each feature was predicted in every
ceptual knowledge. Thus, the question of how people learn                 training item, including both typical and exception features.
and represent concepts has been central to the overall mis-                   Test performance on the typical and exception feature
sion of cognitive psychology.                                             trials in the classification and inference conditions in Yama-
   Researchers have developed sophisticated formal theories               uchi & Markman are presented in Figure 1 (see “YM” con-
that explain many aspects of concept acquisition. These                   ditions) which present the proportion of responses that were
theories are largely based on supervised classification learn-            consistent with the categories’ prototype. (Figure 1 also
ing in which subjects classify items whose category                       includes the results from a number of other studies and fits
membership is unknown and receive immediate feedback.                     of a new model described below.) The critical result was
Recently, to understand the interplay between how categori-               that learners responded with the category’s typical feature
cal knowledge is used and the concept acquired, researchers               more often than did the classification learners. The authors
have begun to investigate a wider range of learning tasks                 concluded that classification learners more often based in-
(Brooks, 1978; Yamauchi & Markman, 1998, 2000a, 2002;                     ferences on the training exemplars whereas inference learn-
Chin-Parker & Ross, 2002; Ross, 2000). For example, class-                ers based theirs on the category prototypes. (Another result
ification learning has been compared with feature inference               was that both groups were more likely to infer an exception
learning in which learners are presented with an item whose               feature on exception feature trials than typical feature trials,
category membership is already identified and asked to infer              a point we return to below.)
one of its unknown features. That is, rather than predicting a
missing category label on the basis of features, feature in-
ference learners predict a missing feature on the basis of the
category label (and perhaps other features).
A Prototype Model of Feature Inference
Differences in how category information is acquired across
classification and inference tasks were initially explained in
terms of exemplars and prototypes. Yamauchi & Markman
(1998) argued that inference learners represent categories as
prototypes because they seem to extract family-resemblance
                                                                      371

   Figure 1. Empirical results and EFM model fits. Note. YM = Yamauchi & Markman. JK = Johansen & Kruschke. SHN = Sweller, Hayes,
   & Newell. RCH = Rehder, Colner, & Hoffman. ARC = Anderson, Ross, & Chin-Parker. CR = Chin-Parker & Ross.
   To further test the claim that inference and classification        count of both the typical and exception conditions.
learners represent categories differently, Yamauchi &                    Related evidence was provided by Sweller, Hayes, &
Markman modified the General Context Model (GCM) to                   Newell (2006) in which subjects were tested in Yamauchi &
account for inference data by treating the category label as          Markman’s classification and inference condition and a sec-
an additional feature. The model provided a good fit to the           ond inference condition in which both typical and exception
test data in the classification condition but not the inference       feature trials were presented. In this condition (SHN/IA
condition (although, see Kruschke et al. 1999). These results         Inference condition, Fig. 1), subjects were less likely to pre-
led Yamauchi & Markman to conclude that inference learn-              dict typical features at test as compared to standard infer-
ers indeed represent prototypes rather than exemplars.                ence learning (SHN/IT Inference) and even classification
                                                                      learning (SHN/Classification) again suggesting that infer-
Evidence Against Prototypes and for Rules                             ence learners were not simply learning the category proto-
There is an alternative interpretation of the feature inference       types (also see Nilsson & Ohlsson, 2005).
task, however. Johansen & Kruschke (2005) proposed that,
rather than prototypes, inference learners in Yamauchi &              Evidence Against Both Prototypes and Rules
Markman (1998) acquired category-to-feature rules instead.            The prototype and set-of-rules models have furthered our
This set-of-rules model is viable because inference learners          understanding of feature inference learning. However, ex-
were never presented with exception-feature trials during             amination of the literature reveals evidence against the set-
training. As a result, they could succeed simply by learning          of-rules model as well as additional evidence against the
associations (rules) relating the categories’ labels with their       prototype model, as we now review.
typical features. Of course, the prototype and set-of-rules              Yamauchi & Markman (1998). As mentioned, inference
model may seem to be equivalent, because they both predict            learners were more likely to respond with an exception fea-
that in many circumstances (e.g., those in Yamauchi &                 ture on exception feature trials than typical feature trials.
Markman) people will infer typical values for missing fea-            This result indicates that they encoded some configural in-
tures. However, rather than invariably encoding the cate-             formation about the categories’ exemplars, that is, the com-
gory’s prototype, the set-of-rules model predicts that which          binations of 1s and 0s that appeared during training. For
rules are learned depends on the exact inferences made dur-           example, inference learners were more likely to predict x =
ing training. For example, Johansen & Kruschke (2005,                 1 for test item A000x than A100x, apparently because
Expt. 2) compared a nonexception condition in which learn-            A000x is so similar to item A1 in Table 1 which has a ‘1’ on
ers were only presented with typical feature trials with an           dimension 4. But such configural information is represented
exception condition in which they were only presented with            by neither a category prototype nor a set of rules that merely
exception feature trials. Whereas at test the nonexception            associates category labels and features.
group inferred typical features, the exception group inferred            Chin-Parker & Ross (2002). Subjects learned categories
exception features (see Fig. 1, “JK” conditions). That is,            that possessed within-category correlations either by classi-
they responded on the basis of the inferences required dur-           fication or inference. The correlations were not necessary
ing training rather than on the categories’ prototypes. More-         for correct classification. They then performed a double
over, only the set-of-rules model provided a reasonable ac-           feature classification test consisting of either intact feature
                                                                  372

pairs (features that appeared together during training) or          virtually never fixated by the end of training. (As in Ander-
broken pairs (features that never appeared together). Infer-        son et al., they were also far more likely to predict typical
ence but not classification learners were more accurate on          features for the sometimes-queried dimensions than for the
intact vs. broken pairs, indicating the sensitivity of the for-     never-queried ones which in turn were above chance, see
mer to the within-category correlation (see Fig. 1, “CR”            Fig. 1, “RCH E3” conditions.) Rehder et al. concluded that
conditions). This finding again suggests that inference learn-      inference learners fixated other feature dimensions during
ing promotes the learning of configural information such as         Expt. 1 training trials not because they were learning the
feature correlations was not explicitly tested during training.     category prototypes but rather because they anticipated be-
As mentioned, neither the prototype nor the set-of-rules            ing queried on those dimensions on future trials, a view they
model represents configural information such as feature             referred to as the anticipatory learning hypothesis. More-
correlations.                                                       over, they argued that the above-chance performance on
   Anderson, Ross, & Chin-Parker (2002). Subjects com-              (and early fixations to) the never-queried dimensions in
pleted a feature inference task in which only two of the four       Expt. 3 arose because inference learners initially thought
feature dimensions were queried during training. On a sub-          they would queried on those dimensions. Indeed, when in-
sequent single-feature classification test, participants were       ference learners were informed at the start of the experiment
more accurate on the two queried dimensions than the two            which dimensions would be queried, fixations to the never-
never-queried ones (see Fig. 1, “ARC” conditions). This             queried dimensions were almost entirely absent (and sub-
result is inconsistent with a prototype model that predicts         jects were at chance on those dimensions) (Rehder et al.
that typical features on all dimensions should be represented       Expt. 4, see “RCH E4” conditions in Fig. 1).
equally well and again emphasizes the importance of which              A logical objection. Finally, we observe that both the
specific features are predicted during training. However, the       prototype and set-of-rules model embody the unrealistic
fact that learners were above chance on the never-queried           assumption that people represent only one possible value
dimensions is inconsistent with the set-of-rules that assumes       per feature dimension. As a result, people but not these
that only rules on queried dimensions are represented and           models can represent the fact that most apples are red but
again emphasizes that inference learners can acquire cate-          some are yellow and green (but none are blue). Indeed,
gory information not explicitly tested during training.             without elaboration, the set-of-rules model is unable to
   Rehder, Colner, & Hoffman (in press). To gather more in-         model the study of Sweller et al. (2006) that required differ-
formation about feature inference learning, Rehder et al. (in       ent responses on the same dimension on different trials.
press, Expt. 1) replicated the Yamauchi & Markman (1998)               Summary. On the basis of these studies, we conclude that
study with an eyetracker. The gathering of eye movement             the prototype and set-of-rules models fail to account for (a)
data as another dependent variable is useful because models         the learning of configural information, (b) the (unsuper-
make different claims regarding the allocation of attention         vised) learning of category information not explicitly tested
during feature inference learning. Besides replicating the          during training, (c) eye fixation data, or (d) the fact that
essential results from Yamauchi & Markman (see Fig. 1,              people know multiple values per dimension.
“RCH E1” conditions), they found that during training the              Instead of supporting the prototype or set-of-rules model,
large majority of inference learners fixated not only the           we argue that these studies together motivate a new account
category label but also most of the other features displayed        of the feature inference task—the anticipatory learning ac-
by the training item, and did so despite the fact that the          count—that postulates that inference learners represent nei-
category label was perfectly predictive of the missing fea-         ther prototypes nor a set of rules but rather allocate attention
ture. This result provides prima facie evidence against the         to those aspects of categories they think will be needed in
set-of-rules model, because the view that feature inference         the future, and by so doing incidentally learn many addi-
involves applying category-to-feature rules suggests that the       tional aspects of a category’s structure (e.g., feature correla-
reasoner will only fixate the antecedent of the rule (the cate-     tions). In other words, the inference task leads participants
gory label). Indeed, Rehder et al. (Expt. 2) found that learn-      to engage in anticipatory learning in which on every trial
ers quickly limited fixations to the antecedent when one-           they learn about the to-be-predicted feature (supervised
dimensional feature-to-category classification rules were           learning) and about features that will need to be predicted
being acquired (also see Rehder & Hoffman, 2005a). Fixat-           on future trials (unsupervised learning). This anticipatory
ing most feature dimensions on most trials appears to sup-          strategy spreads attention over multiple feature dimensions
port the notion that inference learners were trying to acquire      and enables the incidental learning of additional category
the category prototypes.                                            information not explicitly required by the task.
   However, this conclusion was tested by Rehder et al.’s
Expt. 3 that replicated the Anderson et al. (2002) study de-        The Exemplar Fragment Model
scribed earlier in which only two of four of the feature di-        To formalize our proposal regarding how anticipatory learn-
mensions were queried. The prototype model predicts that            ing leads to the incidental acquisition of category informa-
people should continue to fixate features that are never quer-      tion, we now present a new model of category learning, the
ied (so they can learn the typical features on those dimen-         exemplar fragment model (EFM). Unlike the GCM, which
sions) but, contra this prediction, inference learners were         assumes that each presented exemplar is represented com-
more likely to fixate sometimes-queried dimensions than the         pletely, or the set-of-rules model, which only encodes an
never-queried. Indeed, the never-queried dimensions were            association between the category label and the predicted
                                                                373

feature, our model assumes that the dimensions encoded on              be-classified stimuli or because it was ignored during train-
a given trial are those that are attended. Moreover, the               ing and thus poorly encoded. EFM extends the class of ex-
strength of each dimension’s encoding varies as a function             emplar models by decomposing an attention weight wi into
of (a) how much attention it receives and (b) whether it was           one component (EncodingWtm,i) that represents how strongly
the queried dimension (that received feedback). Importantly,           dimension i of stored exemplar m was encoded and a second
because the learner’s attention to (and thus encoding of) the          component (TestWtt,i) that represents the degree to which a
same exemplar can vary from trial to trial, the EFM repre-             dimension is attended in test stimulus t. The value of wi is
sents exemplar tokens (one representation for each subject’s           formed by multiplying EncodingWtm,i and TestWtt,i and then
exposure to that exemplar) rather than types. Finally, EFM             normalizing the result (so that all ws sum to 1).
also assumes that inferences (of a category label or a miss-           wi = (EncodingWtm,i* TestWtt,i) / Σj=1..n EncodingWtm,j* TestWtt,j (6)
ing feature) are affected by which aspects of the current
stimulus are being attended.                                           This definition of wi exhibits the following important prop-
   The representations proposed by EFM have three advan-               erties. First, if dimension i wasn’t encoded when m was
tages. First, they naturally represent the fact that people            presented, then EncodingWtm,i is 0 and so is wi ; thus a
know of more than one value per feature dimension (apples              mismatch between t and m on dimension i has no effect on
are red but occasionally green or yellow). But because the             their similarity. Second, if dimension i of the test stimulus
model encodes the relative number of presentations of each             is not attended, then TestWtt,i = 0, and again a mismatch on
exemplar, EFM, like humans, is more likely to infer typical            dimension i becomes irrelevant.
than atypical values at test.                                             The second change allows the encoding weight of the be-
   The second advantage is that, because EFM encodes at-               ing predicted dimension q to affect the response by replac-
tended features configurally, it allows for the acquisition of         ing Eq. 2 with Eq. 2’,
category information not explicitly required by the inference          TotalSim (t, v) = Σm∈ M,mq=v EncodingWtm,q * Sim (t, m)          (2’)
task. For example, if an interfeature correlation exists be-
tween two dimensions, that correlation is implicitly encoded           In other words, even if t and m are highly similar on all
in the exemplar fragments. Because EFM assumes classifi-               other dimensions, if the queried dimension q of m was never
cation via a multiplicative similarity metric common to ex-            encoded (EncodingWtm,q = 0) then m will have no effect on
emplar models (Medin et al., 1982), it allows sensitivity to           whether a 1 or 0 is predicted for that dimension.
any encoded correlation to be expressed on a subsequent
test. Of course, EFM only encodes those feature configura-             Approximating Encoding Weights
tions that are attended during training.                               EFM’s separation of encoding weights from test weights
   The third advantage is that EFM assumes that predicted              potentially grants it the flexibility needed to account for the
dimensions are encoded more strongly than those that are               feature inference task. However, by itself the usefulness of
only observed. This allows EFM to exhibit sensitivity to the           EFM is limited because of the excessive number of param-
specific inferences that are carried out during training.              eters it introduces (encoding weights for each observed ex-
   We now define EFM in the same terms as the standard                 ample and test weights for each test stimulus). In this article
exemplar model. Below are the equations associated with                we address this concern by approximating these weights
the GCM, generalized so that they predict values on any                from eyetracking data.
queried dimension, not just the category label. Specifically,             Not all studies of feature inference learning used
the probability that a test item t has value 1 rather than 0 on        eyetracking of course. However, the eyetracking results in
the queried dimension q is,                                            Rehder et al. (in press) can be used to model not only the
P(tq = 1|t)       = TotalSim γ (t, 1) /                                behavioral results from that study, they can be extrapolated
                       (TotalSim γ (t, 1) + TotalSim γ (t, 0)) (1)     to a number of other studies. The eyetracking result from the
TotalSim (t, v)   = Σm∈ M,mq=v Sim (t, m)                      (2)     feature inference conditions in Rehder et al. are presented in
Sim (t, m)        = e–cDist(t,m)                               (3)     Table 2. Note that on each inference training trial, there was
                                                                       one queried dimension and four nonqueried dimensions: the
Dist (t, m)       = Πi=1..n di(t, m)                           (4)
                                                                       category label, the sometimes queried dimensions that were
di(t, m)          = wi|ti – m i|                               (5)
                                                                       queried during training but not on the current trial, and the
where M is the set of stored category members, n is the                never queried dimensions that were never queried. (The
number of dimensions (including the category label), di (t,            number of sometimes and never queried dimensions was 3
m) is the distance between t and m on dimension i, c is a              and 0 in Expt. 1, because all dimensions were predicted, and
sensitivity parameter, and γ is a response scaling param-              1 and 2 in Expts. 3 and 4, because only two dimensions
eter. The wi s are attention weights that multiply the mis-            were predicted.) Table 2 presents the proportion of time the
matches between t and m on each dimension and so allow                 average subject spent fixating each type of dimension in
dimensions to have unequal influence on inferences.                    each experiment. Recall that, using eye movement data,
   EFM introduces two changes to this definition of an ex-             EFM can represent each exemplar token observed by each
emplar model. From their inception, so-called “attention               subject. However, because the goal of this article is to ac-
weights” were understood to subsume more than one factor.              count for group level data only, we use eye movement data
A dimension might have a low attention weight either be-               averaged over subjects.
cause a classifier has learned to ignore that dimension in to-
                                                                   374

    As mentioned, a second factor that influences encoding             weights on those two dimension are .5. Note that, because
weights, but not test weights, is the presence of feedback.            of the Chin-Parker & Ross’s category structure, each di-
EFM assumes that on any given trial the dimension that                 mension was a perfect predictor of the category label. Thus,
received feedback will be more strongly encoded than those             in the classification condition we apply previous results
that were only observed. Accordingly, a feedback multiplier            showing that learners will attend exclusively to a single per-
parameter (FM) determines the relative strength of encod-              fectly diagnostic dimension (Rehder & Hoffman, 2005a)
ing for the queried dimension vs. the observed dimensions.             and assume an encoding and test weight of 1 on one dimen-
   The encoding weights for each experiment are derived                sion and 0 on all others.
from the training eye fixations taking into account the feed-              Note that because EncodingWtm,i and TestWtt,i are meas-
back multiplier FM, as specified by Eqs. 7 and 8,                      ured directly from eyetracking data, EFM has no free atten-
EncodingWtm,q = (FM/n) / (FM/n + 1)                          (7)       tion weight parameters, a difference that results in a sharp
                                                                       reduction in its number of parameters relative to standard
EncodingWtm,i = TrainProportionFixationTimem,i / (FM/n + 1) (8)        exemplar models. In the following simulations, we assume
where q is the queried dimension and n is the number of                one c parameter for each study, and γ and FM parameters
dimensions. For example, Table 2 presents the values of                that are common across studies.
EncodingWtm,i when FM = 10 for the three inference condi-
tions in Rehder et al. (in which n = 5). As a result, the quer-        Results
ied dimension q in each stored exemplar m has ten times the            In this article our primary goal is to establish that EFM is
encoding strength of the average nonqueried dimension.                 sufficient to provide a qualitative account of the key feature
   Table 2 also presents the average proportion eye fixations          inference learning results we have reviewed. Accordingly,
observed during test in Rehder et al.; these fixations are             we used an informal model fitting approach in which pa-
used as the values for TestWtt,i.                                      rameters were tuned by hand. This results in values of c of
TestWtt,i = TestProportionFixationTimet,i                    (9)       9.1, 2.6, 7.7, 6.3, 5.5, and 1.1 for Yamauchi & Markman,
                                                                       Johansen & Kruschke, Sweller et al, Anderson et al., Rehder
   We also use eye fixation data from Rehder et al.’s Expt. 1          et al, and Chin-Parker & Ross, respectively; the best fitting
classification condition (not shown in Table 2) to approxi-            values for γ and FM were 1.1 and 10.5. The empirical re-
mate the encoding and test weights in that condition. Be-              sults from each study are presented in Figure 1 alongside the
cause each feature dimension was fixated about equally dur-            EFM fits. As the figure indicates, EFM reproduces most of
ing training, the encoding weights were derived from Eqs. 7            the important results from these studies.
and 8 assuming that TrainProportionFixationTimem,i = .25.                 Yamauchi & Markman. EFM correctly predicts more pro-
The test weights were derived from the proportion fixation             totype consistent responding in the inference condition ver-
times observed during test: .325 on the category label and             sus the classification condition. It also correctly predicts
.225 on each feature dimension.                                        more prototype consistent responding on the typical feature
   Table 3 indicates how, with a few exceptions, the encod-            trials than the exception feature trials.
ing and test weights used to model the conditions in Rehder               Johansen & Kruschke. EFM correctly predicts that sub-
et al. are used to model the other studies. The exceptions are         jects will respond with the typical features in the nonexcep-
as follows. Because Anderson et al. presented single feature           tion condition and with atypical features in the exception
classification tests, the test weight on this single dimension         condition. As for Yamauchi & Markman, it correctly pre-
is 1. Because Chin-Parker & Ross presented double feature              dicts more prototype consistent responding on the typical
classification trials at test, in the inference condition the test     feature trials than the exception feature trials.
                                                                          Sweller, Hayes, & Newell. EFM correctly predicts that the
                                                                       IT inference condition but not the IA inference condition
                                                                       produces more prototype consistent responding as compared
                                                                       to the classification condition. One deficiency is that EFM
                                                                       did not produce the lower rate of prototype consistent re-
                                                                       sponding in the IA condition as compared to the classifica-
                                                                       tion condition.
                                                                          Chin-Parker & Ross. EFM correctly predicts a sensitivity
                                                                       to feature correlations in the inference condition and the
                                                                       absence of this sensitivity in the classification condition.
                                                                   375

   Anderson, Ross, & Chin-Parker. EFM correctly predicts             ting the feedback multiplier (FM) to a relatively high value
more prototype consistent responding on the queried dimen-           (~10). In effect, this validates the central assumption of the
sions than the never-queried ones which in turn are above            set-of-rules model, that associations between the category
chance.                                                              label and the features acquired on the basis of feedback are
   Rehder, Colner, & Hoffman. For Expt. 1 EFM correctly              strongly represented. Therefore, an alternative modeling
produces more prototype consistent responding in the infer-          approach involving combining explicit category-to-feature
ence condition than the classification condition. For Expts. 3       rules with stored exemplars might prove fruitful.
and 4, it correctly predicts more prototype consistent re-
sponding on the queried dimensions than the never-queried            Acknowledgments
ones, which in turn are above chance. One deficiency is that         This material is based upon work supported by the National
it fails to produce the lower performance on the never-              Science Foundation under Grant No. 0545298.
queried dimensions in Expt. 4 as compared to Expt. 3.
                                                                                                  References
                    General Discussion                               Anderson, A. L., Ross, B. H., & Chin-Parker, S. (2002). A further
The EFM was presented as a formal model of the anticipa-                investigation of category learning by inference. Memory & Cog-
tory learning hypothesis. It is distinguished by its ability to         nition, 1, 119-28.
account for both supervised learning of the predicted dimen-         Ashby G., Alfonso-Reese, L., Turken, A., Waldron, E. (1998). A
sion as well as unsupervised learning of dimensions merely              neuropsychological theory of multiple systems in category
observed. On this account, the demands of the task are the              learning. Psychological Review, 105, 442-81.
key determiner of attention. In the feature inference task,          Brooks, L. (1978). Non-analytic concept formation and memory
because multiple features are queried during training, atten-           for instances. In E. Rosch & B. B. Lloyd (eds.), Cognition and
tion is spread among the queried features to learn them in              categorization (pp. 169-211). Hillsdale, NJ: Erlbaum.
anticipation of future trials. This in turn enables the inciden-     Chin-Parker, S., & Ross, B. H. (2002). The effect of category
tal encoding of category information not explicitly tested              learning on sensitivity to within-category correlations. Memory
during training. This approach allowed EFM to exhibit the               & Cognition, 3, 353-62.
key properties we have noted, namely, the encoding of con-           Chin-Parker, S., & Ross, B. H. (2004). Diagnosticity and proto-
figural information, information not explicitly tested during           typicality in category learning: a comparison of inference learn-
training, and multiple values per dimension. To our knowl-              ing and classification learning. JEP:LMC, 1, 216-26.
edge, EFM is unique in providing a qualitative account of            Johansen, M. K., & Kruschke, J. K. (2005). Category representa-
the key results in six studies, and we expect that further de-          tion for classification and feature inference. JEP:LMC, 6, 1433-
velopment (e.g., formal model fitting) will result in excel-            58.
lent quantitative fits as well.                                      Kruschke, J. K., Johansen, M. K., & Blair, N. (1999). Exemplar
   EFM can be conceived of as an active learning theory in              Model Account of Inference Learning. Unpublished Manuscript.
that the interesting aspects of the model result from learners’      Medin, D. L., Altom, M. W., Edelson, S. M., & Freko, D. (1982).
active contributions. Only the feature dimensions that were             Correlated symptoms and simulated medical classification.
actively sampled by the learner are encoded, which in turn              JEP:LMC. 8, 37-50.
determines the model’s response via similarity with the cur-         Nelson, J., & Cottrell, G. (2007). A probabilistic model of eye
rently fixated dimension of the test item. It is an open ques-          movements in concept formation. Neurocomputing, 70, 2256-72.
tion if the sampling of features observed in these studies           Nilsson, H., & Olsson, H. (2005). Categorization vs. inference:
represents optimal information gain, though some related                Shift in attention or in representation? Proceedings of the 27th
work suggests it might (Nelson & Cottrell, 2005).                       Annual Conference of the Cognitive Science Society (pp. 1642-
   Another unique property of EFM of course is its use of               1647). Stresa, Italy: Cognitive Science Society.
eyetracking data. Previous applications of exemplar models           Rehder, B., & Hoffman, A. B. (2005). Eyetracking and selective
have made the (obviously incorrect) assumption that cate-               attention in category learning. Cognitive Psychology, 1, 1-41.
gory exemplars are encoded perfectly in memory. Eyetrack-            Rehder, B., Colner, R., Hoffman, A. (in press) Feature inference
ing allowed us to determine what information was attended               learning and eyetracking. Journal of Memory and Language.
and thus approximate what was encoded. Veridical repre-              Sweller, N., Hayes, B. K., & Newell, B. R. (2006). Category learn-
sentations of learners’ category knowledge was key to                   ing through inference and classification: Attentional allocation
EFM’s success at modeling test performance from multiple                causes differences in mental representation. Poster presented at
studies.                                                                The 47th Annual Meeting of the Psychonomic Society. Novem-
   Finally, it is important to consider the EFM within the              ber 16-19, Houston, TX.
broader theoretical scope of concept learning models. Spe-           Yamauchi, T., & Markman, A. B. (1998). Category Learning by
cifically, a multiple-systems view of category learning may             Inference and Classification. Journal of Memory and Language,
provide a useful framework to evaluate the parameters of                39, 124-48.
the EFM. For example, the COVIS multiple-systems model               Yamauchi, T., & Markman, A. B. (2000). Inference using catego-
assumes that two separate memory systems—an explicit                    ries. JEP:LMC, 3, 776-95.
verbal (rule-based) system and a procedural system—are               Yamauchi, T., Love, B. C., & Markman, A. B. (2002). Learning
involved in the acquisition of (perceptual) concepts (Ashby             nonlinearly separable categories by inference and classification.
et al. 1998). Fitting the EFM to inference data required set-           JEP:LMC, 3, 585-93.
                                                                 376

