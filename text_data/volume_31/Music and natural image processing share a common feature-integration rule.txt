UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Music and natural image processing share a common feature-integration rule
Permalink
https://escholarship.org/uc/item/9kv8t2mg
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
To, Michelle P.S.
Tolhurst, David J.
Troscianko, Tom
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       M usic and natural image processing share a common feature-integration rule
                                                M ichelle P. S. To (mpst2@cam.ac.uk)
                       Department of Physiology, Development and Neuroscience, University of Cambridge,
                                        Downing Street, Cambridge CB3 3EG, United Kingdom
                                         Tom T roscianko (tom.troscianko@bris.ac.uk)
                                    Department of Experimental Psychology, University of Bristol,
                                          12a Priory Road, Bristol BS8 1TU, United Kingdom
                                                David J. Tolhurst (djt12@cam.ac.uk)
                       Department of Physiology, Development and Neuroscience, University of Cambridge,
                                        Downing Street, Cambridge CB3 3EG, United Kingdom
                              A bstract                                components (e.g. Stromeyer & Klein, 1975; Mostafavi &
   The world is rich in sensory information, and the challenge
                                                                       Sakrison, 1976; Quick et al, 1978; Robson & Graham, 1981;
   for any neural sensory system is to piece together the diverse      Rohaly et al, 1997; Watson & Solomon, 1997; Watson &
   messages from large arrays of feature detectors. In vision and      Ahumada, 2005; Párraga, Troscianko & Tolhurst, 2005;
   auditory research, there has been speculation about the rules       Lovell et al, 2006). This might be a special case of a
   governing combination of signals from different neural              “universal law” of sensory encoding (Shepard, 1987):-
   channels: e.g. linear (city-block) addition, Euclidian (energy)
   summation, or a maximum rule. These are all special cases of                                         1
                                                                                               n m      m
   a more general Minkowski summation rule (Cue1m+Cue2m)1/m,
   where m=1, 2 and infinity respectively. Recently, we reported
                                                                                     Sc       Si                         Eqn.1
   that Minkowski summation with exponent m=2.84 accurately                                    i 1  
   models combination of visual cues in photographs [To et al.         where Sc is the sensitivity (reciprocal of threshold contrast)
   (2008). Proc Roy Soc B, 275, 2299]. Here, we ask whether
   this rule is equally applicable to cue combinations across
                                                                       for the compound stimulus, Si is the sensitivity to each
   different auditory dimensions: such as intensity, pitch, timbre     component stimulus, n is the number of components and m
   and content. We found that in suprathreshold discrimination         is the summating Minkowski exponent. It should be noted
   tasks using musical sequences, a Minkowski summation with           that an exponent of unity is simple linear summation (or
   exponent close to 3 (m=2.95) outperformed city-block,               ‘city-block summation’), an exponent m=2 is the Energy
   Euclidian or maximum combination rules in describing cue            summation or Euclidian distance (much favored by auditory
   integration across feature dimensions. That the same exponent       scientists), whilst the maximum is given by a high exponent
   is found in this music experiment and our previous vision
   experiments, suggests the possibility of a universal                (e.g. Li, 2002; Zhaoping & May, 2007).
   “Minkowski summation Law” in sensory feature integration.              Recently, we extended the applicability of the
   We postulate that this particular Minkowski exponent relates        Minkowski Summation rule to the perceptual integration of
   to the degree of correlation in activity between different          suprathreshold features in colored photographs of natural
   sensory neurons when stimulated by natural stimuli, and             visual scenes (To, Lovell, Troscianko and Tolhurst, 2008).
   could reflect an overall economical and efficient encoding          In particular, we studied the perception of the difference
   mechanism underlying perceptual integration of features in
                                                                       between paired images that contain visible and recognizable
   the natural world.
                                                                       differences, and asked how the perception of two composite
    K eywords: Music; Auditory perception; Feature integration;        differences (e.g. shape and blur) relates to the perception of
   Minkowski Summation; Visual perception.                             single differences (shape or blur separately), see Figure 1.
                                                                       Subjective rating for the double change in a natural image
                          Introduction                                 stimulus was most accurately modeled by Minkowski
A compound visual or auditory stimulus is easier to detect             summation of the ratings to the single changes:-
than either one of its components (e.g. Robson & Graham,
                                                                              predicted R3  R1m  R2 m 
                                                                                                                  1
1981; Green, 1958). Several models have been proposed to                                                            m        Eqn.2
describe the rules governing combination of signals from
different neural channels (Green, 1958; Livingstone &                  where R1 and R2 are the ratings for each component image
Hubel, 1987; von der Malsburg, 1995; Treisman, 1998;                   pair, R3 is the rating for the composite stimulus, and
Ghose & Maunsell, 1999): e.g. linear (city-block) addition,            m=2.84, a value similar to those reported in grating
Euclidian (energy) summation, or a maximum rule. Now,                  summation experiments (e.g. Graham, 1977; Robson &
Minkowski summation (Eqn.1) is widely used to model how                Graham, 1981; Watson & Solomon, 1997; Watson &
the detection thresholds of simple and complex visual                  Ahumada, 2005).
stimuli depend on the thresholds for the stimulus
                                                                   2481

                                                                                             M ethod
                                                                   Presentation and Construction of Stimuli
                                                                   Musical sequences were presented to subjects using a pair of
                                                                   Sennheiser HD 280 pro (64 Ω) headphones. All sounds were
                                                                   played on a DELL laptop XPS M1330 – Window Vista – at
                                                                   level 20 intensity with a sampling rate and bit depth of 44.1
                                                                   kHz and 16 bit, respectively. The sequences were generated
                                                                   using a free evaluation copy of Notion Demo (Notion Music
                                                                   Software, version 1.5.4.0), a piece of music composition
                                                                   and performance software. Subjects were presented with
                                                                   160 musical sequence pairs. The sets of stimuli were
                                                                   generated from 16 parent sequences, each matched with 10
                                                                   variants that differed in one or two of the following
                                                                   dimensions: intensity (by changing the dynamics to pp or
    Figure 1: Example of colored image pairs used in our           ff), timbre (by changing the instrument), pitch (by
     previous vision experiments (To et al., 2008). In this        transposing the sequence upward or downward by various
  combination set example, image pairs could differ in blur,       chromatic or diatonic intervals) and/or content (by
                shape, or both blur and shape.                     changing, adding or removing one or more notes). The time
                                                                   signature was the common (4/4) for all the 2 second
   The purpose of the present study is to determine whether        sequences and the tempo was Vivace – 175 crotchet beats
a Minkowski summation rule with exponent m≈3 is equally            (quarter notes) per minute. Each sequence comprised a
applicable to the summation of cues in natural sounds, in          single bar (8 eights). The reference sequence was always in
particular musical sequences. An Energy-summation model,           the C major key. Examples of sequences and differences are
analogous to a Minkowski summation with exponent 2, has            shown in Figure 2A.
been used to model detection of complex tones (Green,                 The experiment were based around combination sets.
1958). However, we need to explore whether Minkowski               Starting from one of 16 single reference stimuli, the subjects
summation with an exponent m≈3 (as in natural vision, To           rated the perceived difference between that stimulus and
et al, 2008) might be a closer description of auditory             three others, see Figure 2B. For example, a first pair
summation. We asked human subjects to discriminate pairs           (component pair) might differ in one dimension such as
of musical sequences, and to give magnitude estimation             Intensity, the second pair (a second component pair) might
ratings for the perceived suprathreshold differences between       differ in a second dimension such as Pitch (transposition),
pairs of stimuli. In addition, we wished to investigate            and the final pair (the composite) would differ in both
whether a single rule can accurately describe integration          Intensity and Pitch dimensions. All sound pairs contributed
across different dimensions: intensity, pitch, timbre and          to more than one combination set so that the 160 stimulus
content.                                                           pairs made up 96 combination sets.
   Our experiment differed from previous studies examining
integration of auditory features (e.g. Green, 1958; Berg &         Participants
Green, 1990; Hicks & Buus, 2000) in two ways. First, in            The experiment was performed on 15 subjects – 7 female
contrast to many discrimination studies, the differences           and 8 male. Although some had previously participated in
presented in this experiment were not only substantially           other (visual) rating experiments, they all remained naïve to
above threshold, but also spanned across a wide range of           the purpose of this experiment. Subjects were asked if they
categories – intensity, pitch, timbre and content (see             were aware of any hearing difficulties they might suffer.
Methods for examples). This allowed us to investigate how          Prior to the experiment, they were also presented with many
a larger array of cues integrate in more naturalistic stimuli.     examples of sound stimuli and asked to report any problems
Second, unlike typical detection and saliency experiments,         with hearing them.
no thresholds or reaction times were recorded: our subjects
were asked to enter magnitude ratings that indicated how           Procedure
they perceive differences between the sound pairs. The
present experiment shows that, consistent with our previous        Difference ratings were collected for 160 musical sequence
findings in vision, a Minkowski summation rule with                pairs from each subject, who was initially instructed during
exponent m=2.95 is most successful in modeling the                 a demonstration session, where they were shown the
perceptual feature integration in the processing of musical        different types of differences that could be presented to
sequences.                                                         them. A training session then followed the demonstration
                                                                   program. In this phase, subjects were asked to rate 51
                                                                   musical sound pairs presented in a random order. All
                                                                   sequences used in the demonstration and training phases
                                                               2482

were different from those to be used in the testing phase          also told that sometimes sound pairs may be identical and,
proper. During the demonstration and testing phases,               in such cases, they should set the rating to zero.
subjects were repeatedly presented with the same standard             The presentation order of musical pairs was randomized
pair whose magnitude difference was defined as ‘20’, see           differently for each subject. Each block started with the
Figure 2C. They were instructed that their ratings of the          presentation of the standard pair, and this standard was
subjective difference between any other test pair should be        regularly presented after every 10 trials to remind the
based on this standard pair: if they perceived the difference      subjects of the standard difference of ‘20’. The musical
between the test pairs to be lesser, equal or greater than the     sequences lasted 2 seconds each. Because auditory
standard pair, their ratings should be less, equal or greater      information is processed serially (time-dependent), to avoid
than 20, respectively. They were instructed to use a ratio         the task from being one relying too heavily on memory,
scale so that, if a given sound pair seemed to have a              subjects were allowed to replay test and standard sequences
difference twice as large as that of the reference pair, they      as often as they liked, before they entered a numerical
would assign a value twice as large to that sound pair (in         magnitude rating for that stimulus pair on the computer.
this case, 40). No upper limit was set so that subjects could
rate the differences as highly as they saw fit. Subjects were
      Figure 2: Examples of musical sequences used in the experiment. Panel A shows 4 different sequences (left) changing
  along four different dimensions: Intensity, Pitch, Timbre and Content. Sequences in the experiment could change along one
 or two of these dimensions. Panel B presents an example of a combination set: the first pair changes in Intensity, the second
   changes in Pitch and the third pair changes in both Intensity and Pitch. Panel C shows the specific standard pair used; the
                       difference between these two sequences was defined as having a magnitude of ‘20’.
                                                               2483

                                                                   performance of different combination rules – linear
                           Results                                 summation, Euclidian summation, the Maximum rule and
Fifteen subjects were presented with 160 pairs of musical          Minkowski summation – in predicting the measured rating
sequences and were asked to give numerical magnitude               (R3) to the composite stimulus in each combination set from
estimates for the perceived difference between the stimuli in      the separate ratings (R1 and R2) to its two component
each pair using a standard pair whose magnitude difference         sound pairs.
was defined as ‘20’ (Stevens, 1975; Gescheider, 1997, see            As in our previous studies (To et al., 2008), an iterative
Figure 2). The robustness of these measures of performance         search was used to determine the value of the exponent that
has been assessed in an earlier study [see supplementary           minimized the sum of squared deviations between the
materials in To et al. (2008)]. The purpose of this                predicted value of R3 (Eqn. 2) and the measured value. We
experiment was to determine the performance of the                 found that a Minkowski summation rule with exponent
Minkowski Summation with exponent m≈3 model on                     m=2.95 generated the most accurate estimations (see panels
auditory feature integration and to examine whether a single       A, B, C and D in Figure 3). The correlation coefficients
rule can accurately describe integration across different          between predicted and measured ratings ranged between
dimensions.                                                        0.85 and 0.87 in all cases. ANOVA revealed that the
   Sequences could change along one of four dimensions             Minkowski summation model was uniformly efficient in
(Intensity, Pitch, Timbre and Content) so that there were 6        predicting the ratings for all 6 ways of combining any two
different types of dimensional combinations (16                    of the four different dimensions investigated [Intensity,
combination sets of each type). The ratings for sequences          Timbre, Pitch and Content; F (5,95) = 1.69, P = 0.14] and
changing along a single dimension spanned different ranges:        post hoc Bonferroni analyses found no differences between
Intensity (7.34-24.10, median=17.34), Pitch (19.82-25.18,          squared difference between predicted and measured ratings
median=21.29), Timbre (23.72-36.70, median=28.45) and              among the different types of combinations.
Content (17.02-35.57, median=28.09). We compared the
      Figure 3: Predictions of the rating (R3) given to the composite sound pair in each combination set from the individual
  ratings (R1 and R2) to the two separate component sound pairs. In panel A, the linear sum of R1 and R2 is plotted against
the measured R3; in panel B, the Euclidian sum (Energy Sum) of R1 and R2 is plotted against R3; in panel C, the maximum
  of R1 and R2 is plotted against R3; in panel D, the Minkowski sum with exponent m=2.95 of R1 and R2 is plotted against
R3. For comparison, the results from our previous vision experiments [encompassing 704 combination sets; To et al. (2008)]
                                      are presented in panel E. Lines of equality are shown.
                                                               2484

                                                                  of correlation between actual neuronal responses implies
                         Discussion                               that the “universal” value of the Minkowski summation
The main finding of this study is that the Minkowski              exponent should be a little greater than suggested by
Summation rule for cue combination with exponent m≈3              Shepard, but still a lot lower than infinity (maximum rule).
can be extended from vision to audition, its accuracy is          Since this degree of correlation is likely to be shaped by the
consistent for feature integration across different naturally-    natural statistics of the world, we suspect that this reflects an
occurring stimulus dimensions. We have found that                 overall economical and efficient encoding mechanism
Minkowski summation with exponent m= 2.95 outperforms             underlying perceptual integration of features in the natural
city-block, Euclidian and maximum combination rules in            world (Field, 1994; Laughlin, de-Ruyter-van-Steveninck &
describing auditory cue integration across feature                Anderson, 1998; Nirenberg, Carcieri, Jacobs & Latham,
dimensions. A similar exponent (m=2.84) was previously            2001; Barlow, 2001; Lewicki, 2002).
reported for visual cue integration in natural scenes (To et
al., 2008). For comparison, we have plotted the results from      F uture directions
our previous vision experiments (encompassing 704 visual          The present findings have raised two questions. First, apart
combination sets) in Figure 3E. That the same exponent was        from vision and audition, might the Minkowski Summation
found across different dimensions and modalities, suggests        rule with exponent m≈3 also apply to feature integration in
the possibility of a universal "Minkowski Summation Law"          other modalities? We are currently examining analogous
underlying perceptual integration of features in the natural      feature integration in the sense of touch. Meredith and Stein
world.                                                            (1993) have demonstrated the role of the superior colliculus
   A long line of research has demonstrated the applicability     in the integration of visual, auditory, somatosensory and
of the Minkowski Summation rule in the integration of             nociceptive information. In addition, Blakemore (2008) has
visual information. Hearing experiments have previously           recently suggested the possibility that normal sensory
studied feature integration in complex auditory sequences         integration might rely on feedback to early sensory areas
(e.g. Melara & Marks, 1990), but Euclidian (energy)               from polysensory regions of the cortex, in particular the
summation has been the model of choice to describe                parietal cortex. These areas are known to be involved in
auditory cue combination. Indeed, our results (Figure 2B)         cross-modal integration, but what about within modality
almost support such a summation model (m=2). However,             integration? If these areas also process integration within
the results from our music experiment suggest that the            individual modalities, then this could explain why feature
Minkowski Summation with exponent m≈3 may just be a               integration in the visual and auditory systems follow the
superior model. That the integration of auditory features in      same Minkowski Summation rule. Assuming that perceptual
musical sequences follows the same rule as the integration        integration reflects an efficient encoding mechanism shaped
of visual features in natural scenes supports Shepard’s           by the statistics of natural stimuli and that polysensory
theory of a Universal Law for cue combination (Shepard,           regions are involved in the integration of information of all
1987).                                                            modalities, then feature integration in different modalities,
                                                                  such as touch, might follow the same rule as in vision and
O rigin of 3                                                      audition.
Shepard (1987) postulated that summation of cues in simple          Second, having demonstrated the applicability of the same
stimuli might either follow city-block (m=1) or energy            Minkowski summation rule to visual and auditory stimuli
(m=2) summation models Why should a slightly higher               separately, the next step is to study perceptual integration of
exponent actually be found. We postulate that the exponent        cues across these two modalities. At present, Bayesian
m≈3 relates to the degree of correlation in activity between      systems are commonly used to model cross-modal
different sensory neurons when stimulated by natural              integration (e.g. Ernst & Banks, 2002 and Battaglia, Jacobs
stimuli: city-block (linear) or Euclidian (energy) summation      & Aslin, 2003), however the simplicity of the Minkowski
can be argued to be appropriate if activity is independent,       Summation rule could provide an attractive alternative. We
since each neuron conveys a uniquely important signal. On         are presently investigating this possibility by performing
the other hand, if responses were highly correlated, the          suprathreshold discrimination experiments that present
information given by only one neuron would be sufficient          observers with changing auditory and visual stimuli
(the maximum rule). If the responses of sensory neurons or        concurrently.
channels showed small correlations in their responses to
natural stimuli, the most appropriate summating exponent                               A cknowledgments
would be slightly greater than expected if cues were coded        This research was supported by EPSRC/Dstl research grants
entirely independently. Yen, Baker and Gray (2007) have           (S56399, S56405) to DJT and TT, under the Joint Grant
recently shown that, when a cat was presented with natural        Scheme. MPST was employed by those grants. We are very
stimuli (movie clips), the signal correlation of neighboring      grateful for helpful discussions with Dr. R.J. Baddeley, Dr
V1 neurons was relatively low but it was greater than zero        M. Gilmore and Dr. I. Moorhead. We would also like to
(r=0.21±0.23 and 0.18±0.20, for neurons recorded using the        thank the reviewers for their helpful comments.
same or different electrode respectively). This small degree
                                                              2485

                        References                                Nirenberg, S. , Carcieri, S.M., Jacobs, A.L. & Latham, P.E.
                                                                    (2001). Retinal ganglion cells act largely as independent
Barlow, H.B. (2001). Redundancy reduction revisited.
                                                                    encoders. Nature, 411, 698-701.
  Network, 12, 241-253.
                                                                  Párraga, C.A., Troscianko, T. & Tolhurst, D.J. (2005). The
Battaglia, P.W., Jacobs, R.A. & Aslin, R.N. (2003).
                                                                    effects of amplitude-spectrum statistics on foveal and
  Bayesian integration of visual and auditory signals for
                                                                    peripheral discrimination of changes in natural images,
  spatial localization. Journal of the Optical Society of
                                                                    and a multi-resolution model. Vision Research, 45, 3145-
  America, 20, 1391–1397.
                                                                    3168.
Berg, B.G. & Green, D.M. (1990). Spectral weights in
                                                                  Quick, R.F. (1974). A vector magnitude model of contrast
  profile listening. The Journal of the Acoustical Society of
                                                                    detection. Kybernetik, 16, 65-67.
  America, 88, 758-766.
                                                                  Robson, J.G. and Graham, N.V. (1981). Probability
Blakemore, C. (2008). Interaction between cortical areas:
                                                                    summation and regional variation in contrast sensitivity
  lessons from synaesthesia. Perception, 37, 169.
                                                                    across the visual field. Vision Research, 21, 409-418.
Ernst, M.O. & Banks, M.S. (2002). Humans integrate visual
                                                                  Rohaly, A.M., Ahumada, A.J. & Watson, A.B. Object
  and haptic information in a statistically optimal fashion.
                                                                    detection in natural backgrounds predicted by
  Nature, 415, 429–433.
                                                                    discrimination performance and models. Vision Research,
Field, D.J. (1994). What is the goal of sensory coding?
                                                                    37, 3225-3235 (1997).
  Neural Computation, 6, 559–601.
                                                                  Schafer, T.H. & Gales, R.S. Auditory masking of multiple
Gescheider, G.A. (1997). Psychophysics – The
                                                                    tones by random noise. The Journal of the Acoustical
  Fundamentals. USA: Lawrence Erlbaum Associates.
                                                                    Society of America, 21, 392-398 (1949).
Ghose, G.M. & Maunsell, J. (1999). Specialized
                                                                  Shepard, R.N. (1987). Toward a universal law of
  representations in visual cortex: A role for binding?
                                                                    generalization for psychological science. Science, 237,
  Neuron, 24, 79-85l.
                                                                    1317-1323.
Graham, N.V. (1977). Visual detection of aperiodic spatial
                                                                  Stein, B.E. & Meredith, M.A. (1994). The Merging of the
  stimuli by probability summation among narrowband
                                                                    Senses. Cambridge MA: MIT Press.
  channels. Vision Research, 17, 637-652.
                                                                  Stevens, S.S. (1975). Psychophysics: Introduction to its
Green, D.M. (1958). Detection of multiple component
                                                                    Perceptual, Neural, and Social Prospects. New York:
  signals in noise. The Journal of the Acoustical Society of
                                                                    Wiley.
  America, 30, 904-911.
                                                                  Stromeyer, C.F. & Klein, S. (1975). Evidence against
Hicks, M.L. & Buus, S. (2000). Efficient across-frequency
                                                                    narrow-band spatial frequency channels in human vision:
  integration: Evidence from psychometric functions. The
                                                                    detectability of frequency modulated gratings. Vision
  Journal of the Acoustical Society of America , 107, 3333-
                                                                    Research, 15, 899-910.
  3342.
                                                                  To, M., Lovell, P.G., Troscianko, T. & Tolhurst, D.J.
Laughlin, S.B., de-Ruyter-van-Steveninck, R. & Anderson,
                                                                    (2008). Summation of perceptual cues in natural visual
  J.C. (1998). The metabolic cost of information. Nature
                                                                    scenes. Proceedings of the Royal Society Series B , 275,
  Neuroscience, 1, 36–41.
                                                                    2299-2308.
Lewicki, M. S. (2002). Efficient coding of time-varying
                                                                  Treisman, A. (1998). Feature binding, attention and object
  patterns using a spiking population code. In R. P. N. Rao,
                                                                    perception. Philosophical Transactions of the Royal
  B. A. Olshausen, and M. S. Lewicki (Eds), Probabilistic
                                                                    Society of London Series B – Biological Sciences, 353,
  Models of the Brain: Perception and Neural Function.
                                                                    1295-1306.
Li, Z. (2002). A saliency map in primary visual cortex.
                                                                  von der Malsburg, C. Binding in models of perception and
  Trends in Cognitive Sciences, 6, 9-16.
                                                                    brain function. Current Opinion in Neurobiology, 5, 520-
Livingstone M.S. & Hubel D.H. (1987). Psychophysical
                                                                    526 (1995).
  evidence for separate channels for the perception of form,
                                                                  Watson, A.B. & Ahumada, A.J. (2005). A standard model
  color, movement, and depth. Journal of Neuroscience, 7,
                                                                    for foveal detection of spatial contrast. Journal of Vision,
  3416-3468.
                                                                    5, 717-740.
Lovell, P.G., Párraga, C.A., Ripamonti, C., Troscianko, T.
                                                                  Watson, A.B. & Solomon, J.A. (1997). Model of visual
  & Tolhurst, D.J. (2006). Evaluation of a multi-scale color
                                                                    contrast gain control and pattern masking. Journal of the
  model for visual difference prediction. ACM Transactions
                                                                    Optical Society of America A, 14, 2379-2391.
  on Applied Perception, 3, 155-178.
                                                                  Yen, S.C., Baker, J. & Gray, C. M. (2007). Heterogeneity in
Melara, R.D. & Marks, L.E. (1990). Interaction among
                                                                    the Responses of Adjacent Neurons to Natural Stimuli in
  auditory dimensions: timbre, pitch, and loudness.
                                                                    Cat Striate Cortex. Journal of Neurophysiology, 97, 1326-
  Perception and Psychophysics, 48, 169-78.
                                                                    1341
Mostafavi, H. & Sakrison, D.J. (1976). Structure and
                                                                  Zhaoping, L. & May, K.A. (2007). Psychophysical tests of
  properties of a single channel in human visual system.
                                                                    the hypothesis of a bottom-up saliency map in the primary
  Vision Research, 16, 957-968.
                                                                    visual cortex. PLoS Computational Biology, 3, e62.
                                                              2486

