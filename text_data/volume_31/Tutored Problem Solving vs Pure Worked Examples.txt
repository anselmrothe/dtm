UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Tutored Problem Solving vs. “Pure” Worked Examples
Permalink
https://escholarship.org/uc/item/35w4h4zt
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Heffernan, Neil
Kim, Ryung
Krach, Nathan
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                            Tutored Problem Solving vs. “Pure” Worked Examples
                                                  Ryung S. Kim (rkim@wpi.edu)
    Department of Mathematical Sciences, Worcester Polytechnic Institute, 100 Institute Road Worcester, MA 01609 USA
                                                  Rob Weitz (weitzrob@shu.edu)
                 Department of Computing and Decision Sciences, Seton Hall University, South Orange, NJ 07079
                                                 Neil T. Heffernan (nth@wpi.edu)
                                  Department of Computer Science, Worcester Polytechnic Institute
                                                 Nathan Krach (nkrach@wpi.edu)
                                  Department of Computer Science, Worcester Polytechnic Institute
                            Abstract                                 opposed to TPS remediation, which appears to be the case
                                                                     in previous studies). Also, in this study neither condition
   At present a handful of comparisons have been made of
   different variants of worked examples and tutored problem         included a self-explanation component. In other words,
   solving. There is some evidence to report a benefit of            the WE condition was a “passive instructional event”
   adding worked examples (WE) to current tutored problem            (Koedinger and Aleven 2007). Second we examined the
   solving (TPS) environments. Our research investigated             effect of prior knowledge in the subject area as a
   how a “pure” WE condition could compete with a TPS                mediating factor. Third we investigated how well a
   condition. By pure we mean the WE condition does not              student’s preference for a particular form of instruction
   include tutoring, a self-explanation component, or fading.        predicted which approach was actually superior for that
   We report on two experiments. We showed statistically
   significant evidence of learning benefits, both in terms of       student in terms of learning outcomes.
   amount learned and rate of learning, from assigning WE to              The area of instruction was college-level introductory
   conceptual problems and TPS to procedural problems.               statistics. Problem solutions generally required multiple
   Higher prior knowledge students tended to learn more with         steps. The domain is naturally suited to both procedural
   WE, and those with low knowledge tended to learn more             and conceptual problems.             We conducted two
   with TPS, but these results were not significant. We found        experiments; the first focused on the application of the
   no statistically significant interaction between student
   preferences for one approach or the other and their
                                                                     binomial and Normal probability distributions and the
   performance. These results have important practical               second dealt with confidence intervals.
   ramifications and raise interesting questions regarding the
   nature of student learning.                                       Simple Problem Solving vs. Worked Examples
   Keywords: tutored problem solving, worked examples.               A number of studies have shown the benefits of learning
                                                                     from WE. Ward and Sweller (1990) and Sweller and
                         Introduction                                Cooper (1985) compared simple problem solving with a
                                                                     condition alternating WE with problem solving. Atkinson,
This study compares student learning using two
                                                                     Derry, Renkl, Wortham (2000) provides a comprehensive
approaches: tutored problem solving (TPS) and worked
                                                                     review of the WE (vs. simple problem solving) literature
examples (WE). We measured how much each student
                                                                     with a focus on how best to design WE. One of their
learned as well as the time spent they spent in each
                                                                     overarching conclusions (p. 197) is that “students who
condition. The study included both procedural and
                                                                     self-explain tend to outperform student who do not.”
conceptual problems. This research is relevant to those
                                                                          Renkl, Atkinson and Maier (2000) and Renkl,
working in instructional technology and to anyone
                                                                     Atkinson, Maier, & Staley (2002) explored the
interested in the nature of student learning. Certainly,
                                                                     effectiveness of fading (successively removing worked-
from a practical perspective if learning under worked
                                                                     out solution steps) WE vs. traditional WE. Atkinson,
examples can be comparable or better than tutored
                                                                     Renkl and Merrill (2003) combined fading with prompts
problem solving, then we can save the significantly more
                                                                     “designed to encourage learners to identify the underlying
time, money and effort on building tutors.
                                                                     principle illustrated in each worked-out solution step.”
                                                                     They reported improved far transfer over WE with fading
There is a long history of research in TPS and WE
                                                                     alone.
separately, and very little research comparing the two.
Our work contributes in three ways. First we compare
“pure” TPS with “pure” WE conditions. Students in the                Intelligent Tutoring vs. Worked Examples
TPS condition received TPS remediation, while students               Koedinger and Aleven (2007) review the literature
in the WE condition received solely WE remediation (as               regarding adding worked examples to cognitive tutors.
                                                                 1
                                                                3121

     McLaren, Lim and Koedinger (2008a, 2008b)                   Participating students were enrolled in an introductory
compare a cognitive tutor with a WE in the domain of             statistics course at Worcester Polytechnic Institute (WPI),
chemistry (stoichiometry). The WE condition included an          a private university specializing in engineering and the
interactive self-explanation component. (The explanations        sciences. Ninety-five students participated in each
are checked for correctness.) They found that students in        experiment. The tutorials and associated assessments
the WE conditions did not learn significantly more than          were conducted as part of the course’s regular statistics
students in the TPS condition, however the WE condition          lab sessions and as such were integrated elements of the
was more efficient,                                              course. Students in this study comprise freshmen (17%),
     Schwonke et al. (2007) and Schwonke et al. (2009)           sophomores (61%), juniors (15%), and seniors (7%).
describe two studies, both comparing a standard cognitive        Student majors comprise Engineering (65%), Math/
tutor with one augmented by faded worked examples (in            Physics/Chemistry (7%), and Social Science/Computer
the field of high school geometry). Both conditions              Science/ Biology (27%).
included an interactive self-explanation element. The
results of the first study showed no difference in                                     Experiment 1
conceptual or transfer learning though the WE group took
                                                                 In the first experiment, we compared the effect TPS and
less time. The second experiment indicated an advantage
                                                                 WE on learning of Binomial and Normal probability
to WE for conceptual learning, no difference regarding
                                                                 distribution. The problems were all procedural in nature,
procedural learning and, again, a time advantage for WE.
                                                                 and are typical of problems given in introductory statistics
There was no difference in students’ transfer knowledge.
                                                                 courses. The subject matter was taught on days preceding
     Salden. Aleven, Renkl, and Schwonke (2008) built
                                                                 the experiment. There were no assignments or tests on
on the above work, this time adding an adaptive fading
                                                                 these topics due before the experiment.
WE condition to the cognitive tutor and fixed-fading WE
                                                                      Each student was randomly assigned to one of the
conditions . (Adaptive here means that the rate of fading
                                                                 conditions listed in Table 1. Each student experienced
is based on student’s level of understanding.) The two
                                                                 both tutorial types. Each tutorial (TPS or WE) was
experiments (lab and classroom) they conducted indicated
                                                                 composed of two, two-part isomorphic problems.
an advantage to the adaptively faded condition.
     In all of the above cases, the WE example condition
                                                                  Table1: No. Students in Each Condition of Experiment 1
included self-explanation requirements and the WE
condition provided tutoring support when the student was
unable to solve the isomorphic problem. In the                       First tutorial       Second        Students
experiments described below we instead use a “pure”                (Method/Topic)        Tutorial       numbers
worked example condition that does not include any                  TPS/Binomial       WE/Normal            20
intelligent tutoring, self explanations or fading of                 TPS/Normal       WE/Binomial           30
prompts. This condition is meant to represent a “cleaner”           WE/Binomial        TPS/Normal           30
test of the WE condition compared to TPS alone.                      WE/Normal        TPS/Binomial          16
                    The Experiments                              The ASSISTment System
                                                                 Our experiment was conducted via the ASSISTment.org
As noted previously, our study involved college students
                                                                 intelligent tutoring system built by a team lead by
taking an introductory statistics course. Statistics is a
                                                                 Heffernan and Koedinger. It’s an intelligent tutoring
good domain for this research as it includes both
                                                                 system similar to the CTAT (Koedinger et al. 2004) used
procedural and conceptual components. The problems we
                                                                 in some of the previously mentioned studies (McLaren,
categorized as conceptual measure what Garfield (2002)
                                                                 Lim & Koedinger, 2008a). It is similar in that the system
has called as the third level of statistical reasoning, or
                                                                 provides the student with tutoring on the individual steps
transitional reasoning. They measures student's ability "to
                                                                 of a problem, generally breaking a problem down into 3-4
correctly identify one or two dimensions of a statistical
                                                                 steps. For each step, a student would be asked to provide
process without fully integrating these dimensions, such
                                                                 an answer, and would get feedback on their answer until
as, that a larger sample size leads to a narrower
                                                                 they got it correct. In this study ASSISTments was used
confidence interval, that a smaller standard error leads to
                                                                 for the TPS condition and the WE condition. In order to
a narrower confidence interval."
                                                                 help others understand, and possibly replicate our work,
     We performed two experiments: one for probability
                                                                 we have archived all the study materials (Heffernan
distributions (Binomial and Normal) and one for
                                                                 2009). Our system differs from the CTAT structure in
confidence intervals. The methodology undertaken for
                                                                 several ways including that there is only one solution path
each experiment is described below.
                                                                 and the intermediate solution goals are highlighted.
Student Characteristics                                          Tutored Problem Solving Condition
                                                             2
                                                            3122

In this study the system was modified to force students to        students either answer each question correctly or not. We
work through the TPS for the first problem of each pair.          use two regression models for repeated binary data: the
This “forced TPS” approach ensures that each student              marginal regression model (Liang and Zeger 1986) and
experiences tutoring. After completion of the first               the Generalized Linear Mixed Model, or GLMM (Bates
problem of the pair, the student is presented with an             and Sarkar 2007). If we follow the typical approach to use
isomorphic problem and is asked by the system to provide          the total score of each test for each student and perform
the answer. If the student gets this second question              repeated measures ANOVA, we would lose power in our
correct, the student is done with the problem. If the             analysis because information of how each student
student gets the answer incorrect or indicates that s/he          performed on each of the seven pairs of problems is lost.
needs help solving the problem, the system provides TPS           We include details of the statistical models used in this
support (and records that the student was unable to solve         article in Appendix 1.
the problem).
                                                                  Result of Experiment 1
“Pure” Worked Example Condition                                   In this experiment students worked on two problems, each
Student is presented with the first problem (same as the          with two parts. The design for the experiment is a pair-
first problem under the TPS condition) and a worked               matched randomized design with two conditions (TPS
solution to that problem. The student is then presented           and WE), each with two problems. We define learning in
with an isomorphic problem (same second problem as in             each case (TPS and WE) if the student gets the second
the TPS condition), which the student is expected to              isomorphic problem correct. From the number of students
solve. The student has access to the first WE while trying        with discordant performances between two tutorials (i.e.
to solve the second. If the student gets this second              off-diagonal numbers in table 3), it is clear more students
question correct, the student is done with the problem. If        did better under TPS. For example, there were 10 students
the student gets the answer incorrect or indicates that s/he      who got both questions correct after TPS but no problems
needs help solving the problem, the system provides the           correct after WE.
worked solution for the problem for review by the student              From the regression model (M1; Appendix 1), the
(and records that the student was unable to solve the             probability of a student solving the problem after a WE
problem).                                                         (pooled over two topics) is estimated as 53% and that
                                                                  after a TPS is 63%. This difference between the two
     Table 2: A Comparison of Intelligent Tutoring and            tutorials was significant (p=0.047).
                     Worked Examples
                                                                      Table 3: Number of question answered correctly by
              Tutored       Problem Worked Examples                                         condition
              Solving (TPS)            (WE)
First         Student studies with     Student studies                                           Number of questions
Problem       forced TPS               WE.                                                       answered correctly after WE
Second        Student is given opportunity to answer the                                            0          1          2
Problem       question. If student answer is incorrect, the                                 0       14         6          2
                                                                  Number of questions
              problem is marked incorrect and,
                                                                  answered correctly        1       11         5         11
              TPS is provided.         WE is provided.
                                                                  after TPS                 2       10         9         27
     Due to relatively little workload for these tutorials,
the students were allowed to work though both tutorials at                              Experiment 2
their own pace. Less than 5% of the students failed to
                                                                  The second experiment utilizes questions from the
finish the tutorials on time. Students were allowed to
                                                                  domain of one-sample confidence intervals of the mean
move to the second tutorial once they completed the first
                                                                  (with continuous observations). There were two types of
tutorial.
                                                                  problems: procedural and conceptual in nature. As in
                                                                  experiment 1, the general concepts of the topic were
Statistical Models                                                taught during the days preceding the trial, there were no
Embretson and Reise (2000) suggest the use of statistical         assignments or tests on this topic due before the trial, and
techniques that have more power than approaches                   on the day of experiment there was no additional teaching
typically taken in cognitive science research. They               from the instructor prior to the tutorials. The experiment
advocate the use of item response models, and we take             consisted of three parts: pre-test, tutorial, and post-test.
that a step further. Our main measurements are 1)                 The pre-test and post-test were identical, and comprised
repeated, because the same set of seven problems were             of three conceptual problems and four procedural
used in the pre-test and post-test and 2) binary, because         problems. In the experiment, we used a completely
                                                              3
                                                             3123

randomized design: approximately half the students took                                                 (learning)
the TPS version of the tutorial and the other half took a
                                                                  conceptual:TPS      43%     44%           1%          0.740
WE version. The students were given 20 minutes to go
through the pre-test without any feedback, 40 minutes for         conceptual:WE       41%     52%          11%          0.031
one of two types of tutorial, and 20 minutes for the post         procedural:TPS      25%     48%          23%         <0.0001
test (Table 4). In order to control time, students were not
allowed to move to next step until a designated time              procedural:WE       31%     44%          13%          0.020
passed. The design of the tutorials is equivalent to that of
experiment 1. That is to say, the problems are presented in       Interaction of Tutor Type and Problem Type We note
pairs using the same approach as experiment 1; the                the following trends in Table 5: in procedural problems,
contents of the two tutorials were as equivalent as               learning from TPS is 10% (11% vs. 1%) greater than that
possible. The tutorials in experiment 2 were comprised of         from WE. In conceptual problems, on the contrary,
three problems. The first two problems were procedural            learning from WE is 10% (23% vs. 13%) greater than that
and the last one (composed of four sub-problems) was              from TPS. Neither of these two main differences was
conceptual.                                                       significant. However the interaction in learning between
                                                                  tutor types and problem types was significant (p = 0.0347)
               Table 4: Outline of Experiment 2                   -- that is, and         are significantly different in M2a
       One Sample Confidence Interval for the Mean                Appendix 1). In other words, the experiment shows
                                                                  significant evidence of learning benefit from changing
  Several Days Prior to Lab Session                               tutorial types according to problem types. Put simply, WE
  • Lecture on the topic                                          was more effective for conceptual problems, while TPS
  During Lab Session                                              was more effective for procedural problems.
  1. Pre-Test (20 min; students’ initial knowledge)
      • 20 minutes                                                Comparison of Learning Rates
      • four procedural and three conceptual.                     In addition to comparing the amount of learning, we took
  2. Condition (TPS or WE)                                        into account time students spent on the tutorials. While
                                                                  we tried to control for the number of problems done, and
      • 40 minutes
                                                                  not for time, for practical reasons of running a classroom
      • 3 pairs of Problems: 2 procedural, one
                                                                  we set a 40 minute time window to complete the
           conceptual (3 parts)
                                                                  problems. We thought 40 minutes represents a reasonable
  3. Post-Test (20 min; students’ knowledge after trial)
                                                                  amount of time to complete the problems. Unfortunately,
      • Same problems as Pre-Test                                 of the 95 student in the experiment, 16 did not complete
                                                                  the problems (13 in TPS condition and 3 in WE
Results of Experiment 2                                           condition). Hence, student that did not finish the tutorial
Item-wise Learning Pooled Over the Two Conditions                 were recorded at 40 minutes. This represents uneven
Student learning was clearly shown in all items. The              censoring of the data. We address this issue at the end of
probability to solve the seven problems in two tests (pre-        this section. On average, students spent 31 minutes
test/post-test) were estimated at 22%/56%, 11%/21%,               (s=10.4) on TPS and 22 minutes (s=10.0) on WE. We
35%/71%, 15%/46%, 75%/87%, 42%/61%, and                           estimated the learning rates per minute in the two tutorial
33%/69%, respectively (M2c; Appendix 1).                          types. The rate in odds ratio per ten minutes by each
                                                                  condition is in Table 6 (M2b in Appendix 1). Under TPS,
Itemized Learning Pooled Over the Two Conditions                  odds of solving conceptual problems become 1.43 times
Table 5 shows WE improves learning significantly for              greater as students learn 10 more minutes, whereas odds
both problem types (p=0.031 and 0.020), and TPS                   of solving procedural problems stays unchanged. Under
improves learning significantly for procedural problems           WE, odds of solving conceptual problems become 1.29
(p < 0.0001) but only moderately in conceptual problems           times greater as students learn 10 more minutes, whereas
(p=0.740). The table shows the size of learning, in               odds of solving procedural problems become 1.33 times
probability estimated by our model (Appendix 1; M2a).             greater. (Table 6)
For example, on average, TPS helps 23% more students              WE is significantly more efficient in conceptual learning
to answer the procedural problems correctly (column four,         than TPS (p=0.008). On the contrary, two tutorial types
row three) and only 1% for the conceptual problems                have similar efficiencies in procedural learning. Figure 1
(column 4, row 1).                                                is a direct representation of Table 6 by converting odds
                                                                  ratio scale to more intuitive probability scale. The low
           Table 5: Probabilities to solve problem                learning rate of TPS for conceptual problems is notable in
                                                                  the figure (flat line). To see if uneven censoring caused
                    PRE    POST        Difference   p-value       bias, we repeated our analyses comparing only students
                                                              4
                                                             3124

who completed the tutorials, and the results remained                                              less time (i.e. was more efficient). On the other hand,
unchanged.                                                                                         TPS was superior at producing more learning on
                                                                                                   procedural knowledge but took more time. On procedural
              Table 6: Learning Rate (odds ratio per ten minutes)                                  questions the efficiency ratings of TPS and WE were not
                                                                                                   reliably different from each other. Given that creating
                                          TPS     WE        Ratio (WE/TPS)       p-value           worked examples is so much more cost effective than
Conceptual                               1.002    1.29            1.29            0.008            creating intelligent tutoring system, these results are of
Procedural                               1.430    1.33            0.93            0.550            practical importance. However, we hesitate to generalize
                                                                                                   these conclusions to other environments where the self-
                                                                                                   discipline to use WE might be lower. In fact in a separate
                                                                                                   paper submitted to this conference we report (Razzaq et
                               0.8
     The probability of
                                                                                                   al. submitted) that in an inner city middle school, albeit a
                                                                                                   slightly different implementation of a worked example
                               0.6
                                                                                                   condition, we found that TPS was more effective than the
                                                                                                   worked example condition. This suggests to us that self-
                               0.4                                                                 discipline to actively engage with the material may be a
 correctly solving a problem
                                                                      TPS conceptual
                                                                      WE conceptual                factor in the effectiveness of worked examples. Our
                               0.2                                    TPS procedural               results support previous research indicating that worked
                                                                      WE procedural                examples are superior to cognitive tutors in regards to
                               0.0                                                                 supporting conceptual learning. It has been suggested that
                                     0           10           20            30         40          worked examples yield improved learning as compared to
                                                      Minutes on Tutorial                          simple problem solving due to reduced cognitive load on
                                                                                                   the student (Merrienboër & Sweller 2005). McClaren et
Figure 1: Change of probabilities to solve a problem type                                          al. (2008) posit that the level of assistance is important in
      as student spends time on each tutorial type.                                                predicting learning results and that research indicates “a
                                                                                                   tendency for mid-level assistance being most beneficial to
Interaction of Tutorial Effect and Student Preference                                              learning.” (In their rubric, tutored problem solving and
We investigated whether there were interactions between                                            worked examples with no explanations are both counted
tutorial type and student preference. Students were                                                as mid-level assistance.) More work is required to further
overwhelmingly positive about the laboratory experience.                                           explore why and under which conditions this kind of
We asked students to indicate which method of                                                      straightforward WE condition performs so well.
instruction they preferred after the first experiment.
Student responses were about evenly split. There was a                                                      Appendix 1 – Statistical Models
trend indicating that students performed better on
experiment two when given their preferred method of                                                We describe here the statistical models more in detail. We
instruction but these results were not statistically                                               use two regression models for repeated binary data: the
significant.                                                                                       marginal regression model and the GLMM. While the
                                                                                                   former requires fewer model assumptions, the latter
Interaction of Tutorial Effect and Student Prior                                                   enables us to model multi-level effects and to predict
Knowledge                                                                                          individual performance. In the first experiment, we
We also investigated the interaction between prior                                                 modeled , the ith student’s probability of solving the jth
knowledge and tutor type. We measured student prior                                                problem correctly, to be determined by the tutorial type (k
knowledge from previous quizzes in class. The topics of                                            = 1 for TPS, 2 for WE). That is,
quizzes were not related to confidence interval: they were                                                      log                          M1
theoretical probability distributions and statistical design.                                                         1
The trend indicated that students with high prior                                                  for     1, … , 95,     1,2. For the second experiment, we
knowledge learned more with WE, and those with low                                                 used the following three models. First, we used model
knowledge learned more with TPS. However, these                                                    M2a where the probability is determined by problem type
results were not significant.                                                                      (m = 1 for procedural, 2 for conceptual), tutorial type (k =
                                                                                                   1, 2) and the test (s = 1 for pre-test, 2 for post-test). Two
                               Conclusions and Future Research                                     interesting parameters in this model are the learning
We report on two experiments and compared both student                                             difference between two tutorials in procedural problems,
procedural and conceptual knowledge on tutored and                                                           , ,      , , , and that in conceptual problems,
“pure” WE conditions. We found that the pure WE was                                                          , ,      , , .
superior to TPS on conceptual knowledge, and also used
                                                                                             5
                                                                                            3125

           log                                 M2a                    combining worked examples and intelligent tutoring. In
                             , ,
               1                                                      B. Woolf, E. Aimeur, R. Nkambou, S. Lajoie (Eds),
     We used model M2b to take into account the time                  Proceedings of the 9th International Conference on
each student spent on a tutorial (ti). In this model, , , is          Intelligent Tutoring Systems, Lecture Notes in
the rate of learning per minute for each problem type                 Computer Science, 5091 (pp. 677-680). Berlin:
(m=1,2) , and each tutorial type (k=1,2),.                            Springer.
                                                                    McLaren, B.M., Lim, S., & Koedinger, K.R. (2008b).
      log               ,         ,
                                                  M2b
          1                                                           When and how often should worked examples be given
     Finally, we used a multilevel model (M2c) to                     to students? New results and a summary of the current
estimate item easiness in the second experiment. In this              state of research. In B. C. Love, K. McRae, & V. M.
model, we have Gaussian random effects corresponding                  Sloutsky (Eds.), Proceedings of the 30th Annual
to student knowledge on pre-test,          , and on post-test,        Conference of the Cognitive Science Society (pp. 2176-
   , and problem difficulty, . This is an extension of the            2181). Austin, TX: Cognitive Science Society
Rasch IRT model (Doran et al. 2007) to measure student              Merrienboër, J. and Sweller, J. (2005). Cognitive load
performance on each test. We defined item                             theory and complex learning: Recent developments and
                                                                      future directions. Educational Psychology Review 17
easiness, ,         , averaging easiness over two tutorial
                                                                      (2) pp. 147-177.
types.
                                                                    Razzaq, L., Heffernan, N. Shrestha, P., Wei, X.,
                                                                      Maharjan, A. & Heffernan, C. (2009). Are worked
        log               ,                     M2c                   examples an effective feedback mechanism during
            1
                                                                      problem solving? Proceedings of the Annual Meeting of
                                                                      the Cognitive Science Society (to appear).
                       References                                   Renkl, A., Atkinson, R. K., & Maier, U. H. (2000). From
Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D.               studying examples to solving problems: Fading
  (2000). Learning from examples: Instructional                       worked-out solution steps helps learning. In L.
  principles from the worked examples research. Review                Gleitman & A. K. Joshi (Eds.), Proceeding of the 22nd
  of Educational Research, 70(2), 181–214.                            Annual Conference of the Cognitive Science Society
Atkinson, R.K., Renkl, A. & Merrill, M.M. (2003).                     (pp. 393–398). Mahwah, NJ: Erlbaum.
  Transitioning from studying examples to solving                   Renkl, A., Atkinson, R. K., Maier, U. H., & Staley, R.
  problems: Effects of self-explanation prompts and                   (2002). From example study to problem solving:
  fading worked-out steps. Journal of Educational                     smooth transitions help learning. Journal of
  Psychology, 95(4), 774–783.                                         Experimental Education, 70, 293–315.
Bates, D. & Sarkar, D. (2007). lme4: Linear mixed-effects           Salden, R., Aleven, V., Renkl, A., & Schwonke, R.
  models using s4 classes. R package version 0.9975-12,               (2008). Worked examples and tutored problem solving:
  URL http://CRAN.R-project.org/.                                     redundant or synergistic forms of support? In C.
Doran H., Bates D., Bliese P., Dowling M. (2007).                     Schunn (Ed.) Proceedings of the 30th Annual Meeting
  Estimating the multilevel rasch model: with the lme4                of the Cognitive Science Society, CogSci 2008 (pp. 659-
  package. Journal of Statistical Software. 20 (2).                   664). New York, NY: Lawrence Earlbaum
  http://www.jstatsoft.org/v20/i02                                  Schwonke, R, Wittwer, J., Alevan, V., Salden, R., Krieg,
Embretson, S. & Reise, S (2002) Item Response Theory                  C., & Renkel, A. (2007). Can tutored problem solving
  for Psychologists. LEA: Mahwah, NJ.                                 benefit from faded worked-out examples? In S.
Fitzmaurice G. M., Laird N. M. &Ware J. H., (2004).                   Vosniadou, D. Kayser & A. Protopapas (Eds.),
  Applied Longitudinal Analysis, Wiley-IEEE.                          Proceedings of EuroCogSci 07. The European
Heffernan, N. (2009) WPI Department of Computer                       Cognitive Science Conference 2007 (pp. 59 – 64). New
  Science Technical Report Number 2009-01.                            York, NY: Erlbaum.
  http://www.cs.wpi.edu/Research/techreports.html                   Schwonke, R., Renkl, A., Krieg, C., Wittwer, J., Aleven,
Garfield, J. (2002) the challenge of developing statistical           V., & Salden, R. (2009). The worked-example effect: is
  reasoning, Journal of Statistics Education. 10 (3).                 it just an artefact of lousy control conditions?
Koedinger, K. R., Aleven, V., Heffernan. T., McLaren, B.              Computers in Human Behavior. 25 (2) pp. 258-266.
  & Hockenberry, M. (2004). Opening the door to non-                Sweller, J. & Cooper, G. A. (1985). The use of worked
  programmers: Authoring intelligent tutor behavior by                examples as a substitute for problem solving in learning
  demonstration. In Lester et al (Eds.) Proceedings of 7th            algebra. Cognition and Instruction, 2, 59–89.
  Annual Intelligent Tutoring Systems Conference,                   Ward, M. and Sweller, J. (1990). Structuring effective
  Springer, 162-173.                                                  worked examples. Cognition and Instruction, 7(1), 1-
McLaren, B.M., Lim, S., & Koedinger, K.R. (2008a).                    39.
  When is assistance helpful to learning? Results in
                                                                6
                                                               3126

