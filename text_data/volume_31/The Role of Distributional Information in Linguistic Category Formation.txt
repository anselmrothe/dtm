UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Role of Distributional Information in Linguistic Category Formation
Permalink
https://escholarship.org/uc/item/9252m208
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Aslin, Richard
Newport, Elissa
Reeder, Patricia
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                      University of California

           The Role of Distributional Information in Linguistic Category Formation
                                         Patricia A. Reeder (preeder@bcs.rochester.edu)
                                         Elissa L. Newport (newport@bcs.rochester.edu)
                                            Richard N. Aslin (aslin@cvs.rochester.edu)
                                   Department of Brain & Cognitive Sciences, University of Rochester
                                                         Meliora Hall, Box 270268
                                                        Rochester, NY 14627 USA
                               Abstract                                  property linking items within the category (Braine, 1987).
   A crucial component of language acquisition involves
                                                                         This perceptual similarity relation might arise from identity
   organizing words into grammatical categories and discovering          or repetition of elements in grammatical sequences, or a
   relations between them. Many studies have argued that                 phonological or semantic cue identifying words across
   phonological or semantic cues or multiple correlated cues are         different sentences as similar to one another (for example,
   required for learning. Here we examine how distributional             words ending in –a are feminine, or words referring to
   variables will shift learners from forming a category of lexical      concrete objects are nouns). Learners of artificial languages
   items to maintaining lexical specificity. In a series of              have been unable to acquire grammatical categories and to
   artificial language learning experiments, we vary a number of
   distributional variables to category structure and test how           extend their linguistic contexts to new items correctly
   adult learners use this information to inform their hypotheses        without such cues (Braine et al., 1990; Frigo & McDonald,
   about categorization. Our results show that learners are              1998; Gomez & Gerken, 2000). However, this has been
   sensitive to the contexts in which each word occurs, the              somewhat of a puzzle: Maratsos & Chalkley (1980) argued
   overlap in contexts across words, the non-overlap of contexts         that in natural languages, grammatical categories do not
   (or systematic gaps), and the size of the data set. These             have reliable phonological or semantic cues; rather, learners
   variables taken together determine whether learners fully
                                                                         must utilize distributional cues about the linguistic contexts
   generalize or preserve lexical specificity.
                                                                         in which words occur to acquire such categories. Mintz,
                                                                         Newport & Bever (2002), as well as several other
                           Introduction
                                                                         researchers, have shown that computational procedures
   Language acquisition crucially involves finding the                   utilizing distributional contexts can form elementary
grammatical categories of words in the input.                    The     linguistic categories on corpora of mothers’ speech to young
organization of elements into categories, and the                        children from the CHILDES database, and Mintz (2002) and
generalization of patterns from some seen element                        Gerken et al. (2005) have shown that both adults and infants
combinations to novel ones, account for important aspects                can learn a simple version of this paradigm in the
of the expansion of linguistic knowledge in early stages of              laboratory, at least when there are multiple correlated
language acquisition. One hypothesis of how learners                     distributional cues. In the present series of experiments we
approach the problem of categorization is that the categories            also begin by demonstrating that there are distributional
(but not their contents) are innately specified prior to                 properties that lead to successful learning of linguistic
experiencing any linguistic input, with the assignment of                categories in artificial language paradigms. Importantly,
tokens to categories accomplished with minimal exposure.                 however, in order to understand how this mechanism works
A second possibility is that the categories are formed around            in human learners and why many previous experiments have
a semantic definition. A third hypothesis, explored in the               not found such learning, we present a series of experiments
present research, is that the distributional information in the          that manipulate various aspects of these distributional
environment is sufficient (along with a set of learning                  variables, in order to understand the computational
biases) to extract the categorical structure of natural                  requirements for successful category learning.
language. While it is likely that each of these sources of
evidence makes important contributions to language                                              Experiment 1
acquisition, this third hypothesis regarding distributional
learning has often been thought to be an unlikely
                                                                         An artificial grammar was created with the structure
contributor, given the information processing limitations of
                                                                         (Q)AXB(R), where each letter represents a set of 2 or 3
young children and the complexity of the computational
                                                                         words: the Q and R categories had 2 words each, and the A,
processes that would be entailed.
                                                                         X, and B categories had 3 words each. The words of the
   Furthermore, it has been difficult to test the importance of
                                                                         grammar were spad, klidum, flairb, daffin, glim, tomber,
such a distributional learning mechanism because the cues
                                                                         zub, lapal, fluggit, mawg, bleggin, gentif, and frag, and there
to category structure in natural languages are highly
                                                                         was no referential world to which the words were mapped.
correlated. In fact, it has been argued in many artificial
                                                                         All studies were run with two languages that assigned
language studies that the formation of linguistic categories
                                                                         different words to each of the categories. X was the target
(e.g., noun, verb) depends crucially on some perceptual
                                                                     2564

category under study, while A and B were the context                  Table 1: Possible AXB strings in Exp. 1-4. Items withheld
elements that formed the distributional cues to the category.           in Exp. 1 are denoted *; items withheld in Exp. 2 are
Q and R served as optional categories that made sentences             denoted ♦; items withheld in Exp. 3 & 4 are denoted .
of the language vary in length from 3 to 5 words and made
words of the language observe patterning in terms of                 A1 X1 B1 ♦          A1 X2 B1 * ♦        A1 X3 B1
relative order but not fixed position. Focusing on just the          A1 X1 B2 * ♦        A1 X2 B2            A1 X3 B2 ♦
AXB portion of the grammar, there were 3x3x3=27 possible             A1 X1 B3             A1 X2 B3 ♦          A1 X3 B3 * ♦
word strings in the language. In order to study whether              A2 X1 B1 * ♦        A2 X2 B1             A2 X3 B1 ♦
learners can acquire X as a category of words, rather than           A2 X1 B2             A2 X2 B2 ♦          A2 X3 B2 * ♦
simply learn the specific word strings to which they have
                                                                     A2 X1 B3 ♦           A2 X2 B3 * ♦        A2 X3 B3       
been exposed, we present some of these AXB’s but
                                                                     A3 X1 B1            A3 X2 B1 ♦           A3 X3 B1 * ♦
withhold others; and then we ask during post-exposure
testing whether learners recognize the withheld AXB’s as             A3 X1 B2 ♦          A3 X2 B2 * ♦        A3 X3 B2
grammatical.                                                         A3 X1 B3 * ♦        A3 X2 B3             A3 X3 B3 ♦
                                                                   Results
Method
                                                                   A repeated measures ANOVA was conducted with
Participants 17 monolingual native English-speaking
                                                                   condition (familiar, novel, and ungrammatical) as the within
students at the University of Rochester participated in
                                                                   subjects factor and language as the between subjects factor.
Experiment 1 and were paid for their time. Eight subjects
                                                                   There were no significant effects of language (F<1), so the
were exposed to language 1, and nine subjects were exposed
                                                                   two languages have been collapsed. The mean rating of
to language 2.
                                                                   grammatical familiar strings was 3.78 (SE=0.13), the mean
                                                                   rating of grammatical novel strings was 3.69 (SE=0.13), and
Stimulus Materials Out of the 27 basic AXB sentence
                                                                   the mean rating of ungrammatical strings was 2.58
types in the language, 18 were presented and 9 were
                                                                   (SE=0.19). There was no significant difference between
withheld (see Table 1). By varying whether the 2 Q words
                                                                   ratings of grammatical novel items and grammatical familiar
and the 2 R words were present or absent, the 18 AXB types
                                                                   items (F(1,15)=1.845, p=0.1). However, these items were
used for exposure were enlarged to a total of 72 different
                                                                   rated significantly higher than ungrammatical items
(Q)AXB(R) sentences. This exposure set of 72 sentences
                                                                   (F(1,15)=45.651, p<0.001).
was presented 4 times, forming 20 minutes of exposure to
the language. The 18 sentence types used in exposure
included each X word in the presence of each A word and
each B word. Thus the exposure set for this language is
dense (covering a high proportion of the overall language
space), and has complete overlap of contexts among the
various X words within the target category.
   Words were read in isolation by a native English-speaking
female and were spliced together to form the sentences of
the language. Each word was recorded with both non-
terminal and terminal intonation, and the words were
adjusted in Praat so the pitch, volume, and duration of
words were fairly consistent. Sentences were constructed by
assembling words in sequences in Sound Studio, with 50ms
silence between each word, and using the word token with a
terminal intonation contour as the final word in the
sentence. Exposure strings were recorded to mini-disc, with
approximately 1.5s of silence between sentences.
   After exposure, participants were asked to rate test strings       Figure 1: Difference scores of grammatical familiar items
on a scale of 1 to 5, where 1 meant that the string sounded
                                                                      and grammatical novel items, and grammatical familiar
like it definitely did not come from the exposure language
                                                                       items and ungrammatical items from Experiments 1-5.
and 5 meant that the string definitely came from the
exposure language. Test strings were all 3-word sentences          Discussion
of three types: grammatical familiar (9 AXB strings
presented during training), grammatical novel (9 AXB               In this first experiment, learners did not discriminate
strings withheld during training), and ungrammatical               between the presented and the withheld AXB’s, both of
(strings of the form AXA or BXB).                                  which were rated as highly grammatical and strongly
                                                                   preferred to ungrammatical sentences AXA or BXB. These
                                                                   findings show, therefore, that when the input densely
                                                               2565

samples the language space and words within a category             difference between the two types of items (F(1,14)=.558,
appear in highly overlapping contexts, learners will fully         p>0.5). The analysis further revealed that the ungrammatical
generalize within the category to novel contexts and novel         items were rated significantly lower than the grammatical
strings, even without any perceptual or semantic cues to           items (F(1,14)=28.767, p<0.001).
indicate that the words form a single category. In our
subsequent experiments, we investigate the degree to which         Discussion
category generalization is affected by manipulating these          These results show that learners’ performance is unchanged
distributional variables, in learning a single category and in     from Experiment 1 when density/sparseness is reduced but
learning subcategories.                                            other properties of the distributional information are
                                                                   maintained, despite the fact that the exposure is half as rich
               Experiment 2: Sparseness                            and half as long. This permits us to ask what happens, in
In Experiment 2, we explored what happens if we keep the           contrast, when the amount of overlap in the contexts of the
number and overlap among X-word contexts in the language           X-words is reduced.
the same, but during learning we present learners with
substantially fewer of the contexts that are possible in the                        Experiment 3: Overlap
language. We refer to this as reducing the density (or             In Experiment 3, as in Experiment 2, we presented only 9 of
increasing the sparseness) of the contexts for X words that        the 27 possible AXB combinations. Here, however, we
are presented during learning.                                     presented particular AXB combinations that reduced the
                                                                   degree of overlap among members of X in the contexts in
Method                                                             which they were heard, in order to assess the importance of
Participants 16 monolingual native English-speaking                the overlap in distributional information for category
students at the University of Rochester participated in            formation and generalization. In the present experiment, the
Experiment 2, eight in each of the two possible languages.         set of X-words, taken together, occurred in all of the A and
Subjects had not participated in any other categorization          B contexts, and the different X-words overlapped in part
experiment and were paid for participation.                        with all the other X-words. However, individual X-words
                                                                   did not fully share all their contexts with one another. The
Stimulus Materials Strings were created in the same                question we address, then, is the degree to which learners
manner as Experiment 1. Here, however, out of the 27               will restrict their generalization across the category as a
possible AXB combinations, only 9 were presented during            function of this reduction in overlap.
exposure (see Table 1). Crucially, every X-word was still
heard in combination with every A and every B. As in Exp.             A:                  B:
1, each sentence type was presented with optional category
elements Q and R present or absent, producing 36 sentences
in the exposure set. The exposure set was presented 4 times,
for a total exposure of about 10 minutes. (Each input
sentence type was thus presented with the same frequency in
this experiment as in Exp.1; the overall exposure was
                                                                        Figure 2: Full overlap in the grammar space for the X-
reduced in time and number of strings by reducing the size
                                                                      words in Experiment 2 (Fig 2A), compared to the partial
of the exposure set.) The test was the same as in Exp. 1,
                                                                                  overlap in Experiment 3 (Fig 2B).
except that the grammatical novel test items were
counterbalanced such that half of the participants in each         Method
language were tested on one subset of nine of the withheld
(grammatical novel) items, and the other participants were         Participants 24 monolingual native English-speaking
tested on the other nine grammatical novel items.                  students at the University of Rochester participated in
                                                                   Experiment 3 (12 in each language). Subjects had not
Procedure The procedure was the same as in Experiment 1.           participated in any other categorization experiment and were
                                                                   paid for their participation.
Results
                                                                   Stimulus Materials Strings were composed in the same
As in Experiment 1, there was no difference between the
                                                                   way as in Experiment 1, and only 9 of the 27 possible AXB
two counterbalanced languages (F<1), so all further
                                                                   combinations were heard. X1 was heard in the context of
analyses combine the languages. The mean rating of
                                                                   A1, A2, B1, and B2, but not in the context of A3 or B3. X2
grammatical familiar strings was 3.54 (SE=0.12), the mean
                                                                   was heard in the context of A2, A3, B2, and B3, but not A1
rating of grammatical novel strings was 3.47 (SE=0.12), and
                                                                   or B1. X3 was heard in the context of A1, A3, B1, and B3,
the mean rating of ungrammatical strings was 2.73
                                                                   but not A2 or B2. Thus, the overlap among contexts is
(SE=0.14). A repeated measures ANOVA showed that
                                                                   maintained over the X category as a whole, but individual
grammatical novel strings were rated just as highly as
                                                                   words in X do not have the degree and type of overlap in
grammatical familiar strings and there was no significant
                                                               2566

distributional contexts that they do in Experiments 1 and 2,      Method
where each X word occurs with each A and each B.                  Participants 16 monolingual native English-speaking
                                                                  students at the University of Rochester participated in
Procedure The procedure was the same as Experiment 1.             Experiment 4 (8 in each language). Subjects had not
                                                                  participated in any other categorization experiment and were
Results                                                           paid for their participation.
A repeated measures ANOVA was conducted and revealed
no differences between languages one and two                      Stimulus Materials The corpus was the same as in
(F(2,44)=1.581, p>0.1); therefore, all of the following           Experiment 3; however exposure was doubled, by
analyses collapse the two languages. The mean rating of           presenting the exposure corpus 8 times rather than 4. (The
grammatical familiar items was 3.79 (SE=0.1), the mean            exposure thus lasted for approximately 20 minutes, as in
rating of grammatical novel items was 3.48 (SE=0.16), and         Experiment 1, but contained only 9 contexts, as in
the mean rating of ungrammatical items was 2.85                   Experiments 2 and 3). The same test as in Experiment 3
(SE=0.15). The ANOVA revealed significant differences             was given after exposure.
between grammatical familiar and grammatical novel items
(F(1,22)=19.191, p<0.001) and between grammatical and             Procedure The procedure was the same as Experiment 1.
ungrammatical items (F(1,22)=70.271, p<0.001).
                                                                  Results
Discussion                                                        A repeated measures ANOVA revealed no significant
Whereas in Experiment 2 we tested how subjects would              differences between languages one and two (F<1), so they
respond to fewer contexts but full overlap of the context         have been combined for all following analyses. The mean
environment, Experiment 3 greatly reduced the overlap in          rating of grammatical familiar items was 4.05 (SE=0.14),
the exposure while keeping number the same (see Figure 2A         the mean rating of grammatical novel items was 3.64
as compared to Figure 2B). It is important to note that, at       (SE=0.16), and the mean rating of ungrammatical items was
some point along the sparseness and non-overlap                   2.83 (SE=0.24). There were highly significant differences
dimensions, learners must stop concluding that X is a             between all conditions. Novel items were rated significantly
category and must acquire lexical restrictions or shift to        different from familiar items (F(1,14)=26.865, p<0.001),
word-by-word learning. The results of Experiment 3 give           and ungrammatical items were rated significantly lower than
insight into the computational details of how this occurs by      novel items (F(1,14)=39.756, p<0.001).
showing that, despite full coverage over lexical items, the
incomplete overlap between words led to a slight decrease         Discussion
in generalization. At the same time, however, learners did        The results from Experiment 4 reveal that increased
continue by and large to generalize, showing a much higher        exposure to a corpus containing incomplete overlap reduces
rating for grammatical novel items than for ungrammatical         the likelihood that learners will generalize based on this
items. These results suggest that learners take into account      input. Instead, they are more likely to assume that gaps in
both the overlap and the non-overlap among items, modestly        the input are intentional.         Nevertheless, the novel
reducing their willingness to generalize when the data            grammatical test strings are judged to be more grammatical
supporting generalization are less strong.                        than the ungrammatical strings. Presumably, even more
                                                                  exposure to highly consistent gaps would confirm the
Experiment 4: Overlap with extended exposure                      ungrammaticality of the novel grammatical strings. In
One more variable that may impact generalization versus           contrast, more unsystematic gaps with extended exposure
lexical distinctness is the frequency or consistency with         should lead learners to generalize more.
which each type of context is presented (and therefore the
frequency with which contextual gaps recur). If learners                    Experiment 5: Subcategorization
operate in an optimal way when using the statistics of their      Experiments 1-4 tested whether learners can acquire a single
input corpus, the prediction is that very high frequencies of     category, generalizing from hearing some instances of the
sparse distributional information, with systematic and            distributional contexts of individual words (with some
recurring gaps, should lead learners to increased certainty       withheld) to the full range of contexts for all the individual
that the gaps are meaningful and should restrict                  words in the set. As previously noted, a large body of work
generalization. Indeed, this is the result obtained in work by    has concluded that linguistic categories in artificial language
Wonnacott, Newport and Tanenhaus (2008) in a miniature            experiments cannot be formed on the basis of distributional
verb-argument structure learning paradigm, as well as in          contexts alone, and that additional information (such as
work on concept acquisition by Xu and Tenenbaum (2007).           phonological or semantic cues) are required for successful
In Experiment 4, we explored how an increase in the               learning. Experiments 1-4 showed that additional cues are
amount of exposure to the very same corpus used in                not necessary for adults to induce a category from
Experiment 3 would affect categorization.                         distributional contexts alone. However, in some cases the
                                                              2567

category learning problems observed by other experimenters         grammatical items and subcategory violation items therefore
have been when the language contained subcategories –              indicates that participants have learned the subcategories in
subsets of words with distinct privileges of occurrence (such      the language and are not generalizing across the gaps
as nouns of different genders). Experiment 5 explores              created by the subcategory structure.
whether subcategories are also learnable from distributional
information, if the learner is given adequate overlap inside       Procedure The procedure was the same as Experiment 1.
each subcategory and adequate non-overlap between
subcategories.                                                     Results
                                                                   A repeated measures ANOVA revealed no differences
Method                                                             between language one and two (F<1), so the two languages
Participants 24 monolingual native English-speaking                were combined. The mean rating of grammatical familiar
students at the University of Rochester participated in            items was 3.61 (SE=0.1), the mean rating of grammatical
Experiment 5 (12 in each language). Subjects had not               novel items was 3.7 (SE=0.11), the mean rating of
participated in any other categorization experiment and were       subcategory violation items was 3.31 (SE=0.12), and the
paid for their participation.                                      mean rating of ungrammatical items was 2.55 (SE=0.12).
                                                                   Grammatical familiar and grammatical novel items were not
Stimulus Materials Experiment 5 utilized the same                  significantly different from each other (F(1,22)=1.559,
grammar as in Experiments 1-4, but more words were added           p>0.1). However, subcategory violation items were rated
to the language in order to allow for a subcategory structure      significantly      lower      than      grammatical        items
(mib, bliffin, zemper, roy, nerk, prog, and dilba). Categories     (F(1,22)=11.698, p<0.01). Ungrammatical items were rated
Q and R still had 2 words each, but categories A and B had         the lowest, significantly lower than subcategory violation
6 words each, and category X had 4 words. A subcategory            items (F(1,22)=19.648, p<0.001).
structure was devised such that A1,2,3 and B1,2,3 were only
seen with X1,2. A4,5,6 and B4,5,6 were only seen with X3,4 (see    Discussion
Figure 3).                                                         Once again, learning effects were observed based solely on
                                                                   distributional cues to subcategory structure. While the
                                                                   subcategorization results are weaker than the categorization
                                                                   results (as shown by the significant difference between
                                                                   subcategory violation items and ungrammatical items), it is
                                                                   important to keep in mind that this task involves a conflict
                                                                   of cues. The subcategory problem has an important
                                                                   distributional property that differentiates it from a single
     Figure 3: Subcategorization structure for Experiment 5.
                                                                   category problem: in the subcategory case, some of the
                                                                   distributional cues (e.g., word order) signal that there is only
   In this language, there are 6x4x6=144 possible
                                                                   one category, while other distributional cues (A and B
combinations of A, X, and B, but only 36 of those strings
                                                                   context words) signal that there is subcategorization within
are legal according to the subcategory structure. Of those
                                                                   this larger category. Not only must the learner figure out
legal strings, 24 AXB combinations were presented during
                                                                   that there are categories, as in Experiments 1-4, but now the
exposure and 12 AXB combinations were withheld.
                                                                   learner must also decide which gaps are systematic (the gaps
Optional Q and R elements were applied as in previous
                                                                   that create the subcategory structure) and which are
experiments, to create a training set of 96 strings. The
                                                                   accidental (the gaps that are legal but withheld items).
sparseness and overlap within each subcategory were
proportional to the sparseness and overlap of Experiment 1.
Pilot testing revealed that keeping exposure to 20 minutes                             General Discussion
(similar to Experiment 1) did not lead to systematic learning      Across five experiments, we observed robust evidence that
of the language (this is unsurprising given that the language      learners can extract the category and subcategory structure
is much larger). Therefore, exposure was increased to about        of an artificial language based solely on the distributional
45 minutes (5 times through the training set).                     patterning of the words and their surrounding contexts. We
   The test stimuli were comprised of 12 grammatical               saw no great difference between Experiments 1 and 2 when
familiar items, 12 grammatical novel items, 12                     only the number of contexts differed, but not the overlap in
ungrammatical AXA or BXB items, and 12 ungrammatical               contexts across words. However, learners began to reduce
subcategory violation items. The subcategory violation             their likelihood of generalizing (that is, increased the
items had either the A word or the B word from the opposite        difference in their ratings for familiar versus unfamiliar
subcategory as the X item. Crucially, the subcategory              grammatical sentences) when the overlap in contexts was
violation items would be grammatical if learners ignored the       reduced. Furthermore, they restricted generalization quite
subcategory structure of the language and generalized to           sharply in Experiment 4, when the same exposure corpus
form a single X category. A difference in ratings between          (and its gaps) was repeated. These results show that adult
                                                                   learners can skillfully use the data in the input to determine
                                                               2568

whether to ignore gaps in the input or whether to generalize                            Acknowledgments
over them. Participants in these experiments were able to
                                                                     This research was supported by NIH Grants HD037082 to
take account of a rich set of variables to aid them in this task
                                                                     RNA and DC00167 to ELN, and by an ONR Grant to the
– degree of overlap among category members, amount of
                                                                     University of Rochester.
input, consistency of gaps and overlaps, and conflicts or
consistency among cues.
   These results also highlight some types of information                                    References
that learners might be encoding or computing during                  Braine, M.D.S. (1987). What is learned in acquiring word
learning and other types that they do not appear to be                 classes – A step toward an acquisition theory. In B.
relying on. If learners were encoding the full set of exposure         MacWhinney (Ed.), Mechanisms of language acquisition.
sentences, or the trigrams or quadrigrams (e.g., AXB,                  Hillsdale, NJ: Lawrence Erlbaum Associates.
AXBR) and their frequencies of occurrence during                     Braine, M.D.S., Brody, R.E., Brooks, P., Sudhalter, V.,
exposure, they could discriminate between the familiar and             Ross, J.A., Catalano, L., & Fisch, S.M. (1990). Exploring
novel grammatical sentences in all three experiments. In               language acquisition in children with a miniature artificial
contrast, if they were only keeping track of simple word               language: Effects of item and pattern frequency, arbitrary
frequencies, they would fail in all experiments, since these           subclasses, and correction. Journal of Memory &
are carefully controlled. The results suggest that learners            Language, 29, 591-610.
are keeping track of word co-occurrences at a mid-sized              Frigo, L., & McDonald, J.L. (1998). Properties of
grain, such as bigram frequencies or probabilities (e.g., AX,          phonological markers that affect the acquisition of
XB). Alternatively, they could be keeping track of the                 gender-like subclasses. Journal of Memory & Language,
network of occurring contexts for individual words (as in              39, 218-245.
Figures 2 and 3) and collapsing the individual words into a          Gerken, L., Wilson, R., & Lewis, W. (2005). Infants can
category when these networks bear enough quantitative as               use distributional cues to form syntactic categories.
well as qualitative similarities to one another.                       Journal of Child Language, 32, 249-268.
   This process can be idealized in terms of a Bayesian              Gomez, R., & Gerken, L.A. (2000). Infant artificial
model estimating whether sample data are drawn from one                language learning and language acquisition. Trends in
hypothesis space or another. But there are potentially a               Cognitive Sciences, 4, 178-186.
number of models, in addition to a Bayesian model, that              Maratsos, M., & Chalkley, M.A. (1980). The internal
could simulate such results, and we are in the process of              language of children’s syntax: The ontogenesis and
testing which types of models perform as well as actual                representation of syntactic categories. In K. Nelson (Ed.)
human learners.                                                        Children’s language, Vol 2. New York: Gardner Press.
   Another question raised by these results is whether infants       Mintz, T.H. (2002). Category induction from distributional
and young children coordinate multiple variables as adults             cues in an artificial language. Memory & Cognition, 30,
do. We are in the process of testing child learners to                 678-686.
determine how they weigh the large number of variables               Mintz, T.H., Newport, E.L., & Bever, T.G. (2002). The
involved in forming categories in these tasks.              One        distributional structure of grammatical categories in
possibility is that young children are as skillful as adults at        speech to young children. Cognitive Science, 26, 393-424.
weighing variables to decide how to generalize. Another              Monaghan, P., Chater, N., & Christiansen, M.H. (2005).
possibility is that they are more likely to follow one or a few        The differential role of phonological and distributional
of these variables only (as found in related studies), or that         cues in grammatical categorization. Cognition, 96, 143-
they are more likely overall to generalize than adults are,            182.
regardless of the input.                                             Wonnacott, E., Newport, E.L. & Tanenhaus, M.K. (2008).
   These experimental results suggest that the number of               Acquiring and processing verb argument structure:
categories and their functional roles in a grammar are                 distributional learning in a miniature language. Cognitive
determined, at least in part, by a form of constrained                 Psychology, 51, 165-209.
statistical learning. The patterning of tokens in a substantial      Xu, F. & Tenenbaum, J.B. (2007) Word learning as
corpus of linguistic input appears to be sufficient, with a            Bayesian inference. Psychological Review, 114, 245-272.
small set of learning biases, to extract the underlying
structural categories in a natural language. At the same
time, we expect, along with other researchers (cf.
Monaghan, Chater & Christiansen, 2005), that distributional
variables combine with other types of information in natural
language acquisition, and that the integration of multiple
imperfect and uncertain cues – including the distributional
ones we have studied here – can serve to help learners
determine when to generalize and when to restrict
generalization in a complex problem space.
                                                                 2569

