UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Grammar-based object representations in a scene parsing task.
Permalink
https://escholarship.org/uc/item/4cb329jz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Jaekel, Frank
Savova, Virginia
Tenenbaum, Joshua
Publication Date
2009-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                  Grammar-based object representations in a scene parsing task
                                      Virginia Savova, Frank Jäkel, Joshua B. Tenenbaum
                                                       [savova, fjaekel, jbt]@mit.edu
                                                     Brain and Cognitive Science, MIT
                                                           Cambridge, MA 02139
                              Abstract                                    equivalence classes. The representation of individual parts is
                                                                          analogous the the representation of simple objects. However,
   This paper addresses the nature of visual representations asso-
   ciated with complex structured objects, and the role of these          the representation of the objects as a whole requires an ad-
   representations in perceptual organization. We use a novel ex-         ditional specification of part-part, or part-whole spatial rela-
   perimental paradigm to probe subjects’ intuitions about pars-          tionships, which also yields itself to a probabilistic interpre-
   ing a scene consisting of overlapping two-dimensional objects.
   The objects are generated from an abstract 2-dimensional im-           tation. We will refer to these representations as part-based.
   age grammar, which specifies the set of possible configura-            Finally, on the rarely examined far end of the spectrum we
   tions of object parts. We show that participants’ performance          may discover a variety of objects whose compositional struc-
   on the task depends on prior experience with the object class,
   and is based on structural cues. This indicates that structural        ture cannot be satisfactorily captured by part-to-part relation-
   representations exerted a top-down influence on parsing. To            ships, probabilistic or otherwise. Categories of this type in-
   address the question of representation type, we used a compu-          clude houses, churches, circuit boards, molecules, and vari-
   tational model of object matching in conjunction with various
   probabilistic representational models. Our simulations indi-           ous life-forms, most notably trees, as well as many plants and
   cate that grammar-based representations derived from the orig-         sea creatures. Unlike mid-spectrum categories, these objects
   inal grammars are superior to more restrictive exemplar-based          have a variable number of subparts, and their parts may be hi-
   representations in explaining human performance on this task,
   as well as to more inclusive, over-generalizing grammar-based          erarchically composed of other subparts of unbounded depth,
   representations.                                                       which complicates the specification of template-like part-part
   Keywords: visual representations, computational modeling,              and part-whole relationships. Elsewhere, we have argued that
   object categories                                                      such object classes are best represented as the extension sets
                                                                          of grammar-based generative models (Savova & Tenenbaum,
                          Introduction                                    2008).
Conscious visual perception is strikingly removed from the                   If we assume that the visual properties of these categories
patterns of light which stimulate our eyes, or even the low-              are faithfully represented, a more powerful representational
level visual features active in primary visual cortex. Rather             system, grammar-based or grammar-equivalent, would be re-
than experiencing the world as a collection of edges, bars or             quired. However, the mere existence of structural complex-
patches of color, we perceive scenes, hierarchically composed             ity in the distal stimulus does not provide direct evidence for
of objects, and parts. Compositionality is one of the defining            representational complexity in the visual system. It is pos-
characteristics of visual representations, a fact evidenced by            sible that the representation of these objects is impoverished
our ability to predict the location of an occluded part, identify         as compared to their actual structural characteristics. Alter-
an object despite change of relative part position, or imagine            natively, complex structured objects may be the exception,
a novel object as a combination of existing object parts. The             rather than the rule, and we might be limited in our ability
nature of these compositional representations raises a series             to acquire novel categories of this type naturally or effort-
of questions regarding their origin and limitations.                      lessly. In so far as full structural representations do exist,
   A cursory examination of just a few common visual ob-                  they might be of a post-visual, purely conceptual nature, and
ject categories reveals various degrees of structural complex-            not indicative of the representations engaged during normal
ity. On one end of the spectrum, we find simple categories,               visual processing. For example, representing the full spatial
such as ball, or plank, which have a degenerate compositional             structure of houses is not required for recognition or detec-
structure, consisting of a single part. In a probabilistic frame-         tion. Under normal circumstances, a few diagnostic features
work, individual objects within these categories may well be              might do. Therefore, it is essential to explore the nature of
thought of as samples from a probability distribution over a              visual representations in the context of a visual task which
feature space of homogeneous, smoothly varying character-                 directly engages the entire object representation.
istics such as size, shape, color. The probability distribution              The idea that objects and scenes are represented in terms
over the feature space forms the representation of the cate-              of structural descriptions involving parts and spatial relations
gory. The middle of the spectrum is occupied by those ob-                 is not new (Marr & Nishihara, 1978) (Palmer, 1999), and nei-
ject categories which are typically the target of computer vi-            ther is the idea that the formation of this representation is
sion algorithms and applications, such as faces, cars, bicycles           guided by the statistical properties of the input. Structural
or tools. These objects exhibit compositional structure. The              models are a classic idea in the field of cognitive psychology.
building blocks are relatively autonomous parts which enter               For example, the recognition-by-components theory sought
into specific spatial relationships with each other and form              to describe objects as 3D simple shapes composed with bi-
                                                                     857

nary spatial relations (Bierderman, 1987). Structural tem-
plate models such as constellation models (Fergus, Perona,
& Zisserman, 2003) have recently become popular in com-
puter vision, because they allow some deformation by encod-
ing a distribution on the relative position of parts. However,
few researchers have explicitly addressed the question from
the point of view of a generative object model, in particular                                       ,
the kind of model capable of generating complex structural
descriptions involving recursion and unbounded derivational          Figure 1: Segmentation decisions are informed by knowledge
depth. Grammar-based models of vision have been antici-              of object structure (Photograph by Markus Wiedemeier).
pated in some classic works in computer vision and syntactic         Right: same photo upside-down.
pattern recognition (Fu, 1974), but have received a new wave
of attention relatively recently (Zhu, Chen, & Yuille, 2006;
Wang et al., 2006) in a probabilistic setting.
                                                                       Investigating complex structured objects in a
                                                                                              parsing task
   While experiments have demonstrated the sensitivity of hu-        Models of representation
man adult and infant learners to object-level statistical infor-
mation (Fiser & Aslin, 2001), the nature of the representa-          To investigate the nature of representations, we defined a set
tions over which statistical learning operates is an open prob-      of generative models of increasing generality. We used a pars-
lem. Recently, there have been a few attempts to investigate         ing task to test subjects’ structural inference on stimuli gen-
the hypothesis that people learn about object categories by          erated from a grammar-based model, and assessed which of
inferring a generative model in classification and similarity        the models provides the best explanation for subject perfor-
judgement tasks (Hegde, Bart, & Kersten, 2008).                      mance by matching samples from each model to the regions
                                                                     segmented by the subject.
   It is not clear to what extent these tasks are solved on the         The exemplar model is a trivial generative model which
basis of the full category representation, rather than some          enumerates a set of objects. This model does not provide for
combination of salient diagnostic features or logical infer-         explicit generalization, but generalization may be achieved
ence. To assess the nature of internal visual representations,       indirectly in the matching procedure. The part model is a step
we investigate to what extent such representations can be            above the exemplar model. It generates objects from a set
spontaneously acquired from visual information, and can sub-         of templates which provide part-part relationships by varying
sequently be engaged. Usually, visual representations are in-        the size of parts independently. The grammar model uses a
vestigated in recognition and categorization tasks. However,         set of rules to recursively generate objects from parts. Unlike
these tasks can often be solved without engaging full object         the part model, the grammar model is in principle capable
representations, on the basis of discriminative features. More       of generating hierarchical object representations of differing
complicated tasks, such as parsing a scene are better suited         or unbounded depth. Finally, the supergrammar model al-
for the study of complex representations.                            lows all configurations allowed by individual realizations of
                                                                     the grammar model.
   Consider the town view in Figure 1. Local segmentation               In some sense, all of these models lie on a continuum.
cues cannot account for the full set of parsing decisions that       The exemplar model can be thought of as a degenerate part
need to be made by the visual system in this context. We             model, since it permits no independent variation among parts.
clearly perceive windows and doors as being on the houses,           The part model may be viewed as an impoverished grammar-
rather than floating in front of them; individual houses oc-         based model, since a template is equivalent to a grammar
cluding one another, rather than standing on top of each other;      which allows for only a finite set of fixed-depth derivations
smaller houses as being further away; the rooftops as the top-       and associated hierarchical descriptions. The supergrammar
most parts of houses, rather than floors of the houses above         model, on the other hand, is a generalization of the grammar
them. To explore the shift in perception when inconsistency          model. Thus, each of the models generates a superset of the
is detected, we can flip the image upside down. Notice that          objects generated from preceding models.
the grey rooftops are now parsed as above (and part of) the             A set of thirty grammars was randomly sampled from a
green-window house. This demonstration provides some ev-             metagrammar, which generated grammars by picking how
idence that our prior experience with houses informs the vi-         many rules of each type (obligatory, optional or recursive)
sual analysis of this image. Thus, scene parsing seems to tap        should be attached to each non-terminal, and the direction of
into the structural representations of objects. Consequently,        expansion for each rule (up, down, left or right) from a uni-
a controlled parsing task with novel complex structured ob-          form distribution. A typical grammar is shown in Table 1
jects may allow us to distinguish between exemplar-based                The grammar model was used to generate visual objects
representations and more powerful, grammar-based represen-           in two steps. Each object was generated by a) generating a
tations.                                                             parse tree and b) varying the size of the vocabulary parts in-
                                                                 858

                                                                            with the tablet before starting the experiment. In a demo ses-
                   Table 1: Typical grammar form
                                                                            sion, they were shown a cutout of a ballet scene with dancers
              A   →     A     B    right    obligatory                      partially occluding each other. They were shown the correct
              B   →     B     B     left     recursive                      outline for each object. In a practice session, they were given
              B   →     B     B    right     recursive                      three practice trials with practice stimuli drawn from simpler
              B   →     B     C    right    obligatory                      grammars which were not part of the stimuli in the experi-
              B   →     B     D    right      optional                      ment. In the test session, they were asked to complete fifteen
              C   →     C     D    right    obligatory                      trials, one per grammar. To ensure that participants treated
              C   →     C     E      up       optional                      the scenes as compositions of homogeneous objects, the ob-
              C   →     C     F    down       optional                      jects were assigned a different nonce-word category name in
                                                                            the instruction preceding each trial.
                                                                                For nine of the twelve subjects, each trial consisted of a
 dependently according to a scaling factor drawn from a trun-               study phase, which presented the subject with either a subset,
 cated Gaussian distribution with parameters mean = 0.75,                   or the full set of the examples generated from the grammar for
 var = 0.25, min = 0.5, max = 1. These parameters were cho-                 this trial. Three, six, or twelve examples were used, depend-
 sen to favor smooth variation of each part within the category.            ing on the group the subject was in. There were a total of three
 Each symbol was expanded to a set of right-hand symbols by                 groups, ensuring that each display was presented with a dif-
 the following procedure:                                                   ferent number of examples at least three times. After viewing
                                                                            the examples, the subject pressed a key to move to the pars-
1. Apply all obligatory rules for this symbol type.                         ing phase. Upon completion of a contour, they were given a
                                                                            chance to delete or accept it. Once a contour was accepted,
2. Apply all optional rules with a fixed optional rule probabil-            it could no longer be deleted. The subject was free to move
    ity p = 0.75.                                                           to the next trial whenever they considered the current pars-
                                                                            ing complete. Three additional participants were assigned to
3. Apply all recursive rules with a fixed recursive rule proba-
                                                                            a fourth group, for which the same stimuli were presented
    bility p = 0.5.1
                                                                            without the study phase. These subjects were simply asked
4. Enter all newly generated right hand symbols in the expan-               to outline the individual objects in each screen to the best of
    sion queue.                                                             their abilities, without any additional information about the
                                                                            objects.2
    Once all the rules were applied to a symbol in the expan-
 sion queue, the symbol was deleted from the queue. The parse                                          Data analysis
 tree was initialized with a unique start symbol.                           The data was analysed against ground truth using the stan-
                                                                            dard precision-recall analysis. First precision and recall were
 Experiment                                                                 calculated for each object-contour pair. Precision was defined
 Three sets of objects were generated from each grammar: a                  as
 stimulus set, containing between five and seven objects, an
                                                                                                                   TP
 example set containing twelve objects, and a sample set of a                                    Precision =
                                                                                                                T P + FP
 hundred objects used for modeling purposes. Fifteen of the
 thirty grammars were subsequently chosen to span a contin-                 where TP is the number of non-black pixels inside the contour
 uum of two grammar complexity measures, one taking into                    which belong to the object, and FP is the number of pixels
 account the number of rules, the other taking into account                 inside the contour that do not. Recall was defined as
 the presence of recursive rules. The stimulus set was used                                                      TP
 to generate a display of overlapping objects, where each ob-                                     Recall =
                                                                                                              T P + FN
 ject position was a sample from a horizontal and vertical beta
 distribution. The resulting scenes were artificial, simpler ana-           where FN is the number of non-black pixels outside the con-
 logues to the natural scene in Figure 1.                                   tour which belong to the object.
    The experiment included twelve participants total. Partic-                  The harmonic mean of the two measures (the F-measure),
 ipants were told that they will be segmenting alien objects                                           Precision ∗ Recall
 from NASA images which contain partially occluded objects.                                   F = 2∗                        ,
                                                                                                       Precision + Recall
 They were asked to outline where each object was approxi-
 mately located. A pen tablet was used as a tool for drawing                was then calculated for each pair, and contours were assigned
 contours on the screen. Subjects were given time to practice               to objects in a way that maximizes the F-measure for each
                                                                            object-contour assignment.
     1 this parameters were chosen to ensure that recursive and obliga-
 tory rules were applied a substantial number of times while keeping            2 It was not possible to alternate between study phase trials and
 the probability of generating very large or infinite objects low. Any      test-phase-only trials within subjects, for fear of introducing cross-
 such objects were filtered out                                             trial transfer-learning effects
                                                                        859

   If the subject draws fewer contours than there are objects
we can pretend the subject has drawn as many contours as
there are objects but the contours do not contain any of the
pixels of the objects, hence the F-score is always zero for
these contours (Figure 2). Conversely, if the subject has
drawn more contours more contours than there are objects
we can say that the subject tried to circle an object that is not
in the scene and therefore the F-score for this object is always      Figure 3: Box plots for example set size (left), number of
zero.                                                                 recursive rules (center), and number of rules overall.
                                                                                           Simulation results
                                                                      To address the question of what type of representations the
                                                                      subjects were using in generating contours, we sampled from
                                                                      the four generative models described earlier. The exemplar
                                                                      model for each subject and each trial “generated” exactly the
                                                                      object that person had seen during the study phase. For the
                                                                      subjects who saw no examples, the exemplar model was run
                                                                      with the full set of twelve examples, in order to assess the dif-
                                                                      ferential effects of human learning and the representativeness
                                                                      of the exemplars as a mini-sample from the grammar. The
                                                                      part model generated variants of the objects in the exemplar
                                                                      model by varying their parts according to the same scale fac-
                                                                      tor distribution used in the grammar generative model. The
                                                                      grammar model was equivalent to the original model used
                                                                      to generate the stimuli. Finally, the supergrammar model
A                                                                     was derived from all grammar models used in the experiment
                                                                      by concatenating all unique rules of their joint rule set and
                                                                      switching the status of obligatory rules to optional. Thus, the
                                                                      generative capacity of the supergrammar is a superset of the
                                                                      generative capacity of all used grammars. The same proce-
                                                                      dure was used for generating samples from the supergrammar
                                                                      as for each individual grammar. The supergrammar sample
                                                                      for each trial used the part-model specific for that trial.
B                                                                        One hundred samples were drawn from each of the mod-
                                                                      els. Each sample was compared to the content of each con-
Figure 2: Actual subject parses. Panel A first and third              tour drawn by each subject, and the mean likelihood of the
row: examples from a grammar with relatively high vari-               samples from each model was computed according to the fol-
ability (Grammar H) and examples from a grammar with low              lowing matching model:
variability (Grammar L). Second row on the left: An actual               Let x be an image of a scene that shows all the non-black
screen with stimuli Grammar H showing a correct instance of           pixels contained in one contour produced by a subject and
generalization (in green). Second row on the right: An ac-            has zeroes everywhere else. We want to evaluate how well
tual screen with stimuli from Grammar L. Panel B: A case of           each model would be able to explain this object x. To this end
oversegmentation and undersegmentation (in green).                    we compare x against all stimuli s that could be generated by
                                                                      each model Mi . Hence, we calculate
   The mean F-measure per grammar for all subjects against                               p(x|Mi ) = ∑ p(x|s)p(s|Mi )
                                                                                                      s
example set size and grammar complexity, as measured by
the number of recursive rules, and by the number of over-             for all i by means of a Monte-Carlo approximation with the
all rules, are plotted in Figure 3. The example set size and          hundred samples of s from p(s|Mi ), generated earlier as de-
the number or recursive rules were found to be significantly          scribed. Since x is an image of the size of the scene with some
correlated with the F-score (ρ = 0.32;ρ = −0.47,p < 0.002).           non-zero pixels at some position we need to take into account
In addition, the correlation analysis revealed that the factors       that the stimulus s could have appeared at all postions pos on
number of recursive rules, and number of overall rules were           the screen. Hence,
correlated. Therefore the exact source of the complexity ef-                            p(x|s) = ∑ p(x|s, pos)p(pos)
fect cannot be conclusively determined.                                                           pos
                                                                  860

is obtained by sliding the stimulus s as a template over the              odds of two models for all contours. The grammar model
whole display and assuming a flat prior.                                  outperforms all other model for those subjects who have seen
    Instead of modeling the exact relationship between the pix-           three examples or less, and continues to outperform both the
els in x and s we only model the counts of how many pixels                exemplar model, and the supergrammar model for all other
agree or disagree with each other. Let N be the overall num-              subjects. The comparison of the grammar model with the part
ber of pixels in the segmented image of the scence x (includ-             model for subjects who have seen six examples or more re-
ing black pixels) and let K be the number of non-black pixels             veals a slight advantage for the latter model which may be at-
of the stimulus s. For a given position pos that we assume the            tributed to the fact that, as the number of examples increases,
stimulus to be at in the scene the number of hits h that the sub-         the part model becomes more similar to the grammar model
ject would have obtained is given by the number of non-black              in terms of the diversity of its sample. Since one-shot learning
pixels in s that have been marked by the subject in x. Note that          in visual tasks has been experimentally demonstrated (Fei-
if the subject’s contour includes all the pixels of s the number          Fei, Fergus, & Perona, 2006), (Savova & Tenenbaum, 2008),
of hits h is exactly K. Since another object might overlap with           the good performance of the grammar model with few exam-
s the actual color of a pixel in x might not be the same as in s          ples is particularly important.
and hence we do not require the pixels in x and s to have the                The limitations of the part model are illustrated in Figure
same color. The number of misses is then m = K − h. Simi-                 5. A typical contour drawn by a subject in the study con-
larly, the number of false alarms f is given by the non-black             dition included the long object in its entirety. The grammar
pixels that were marked by the subject as belonging to s even             model can find a much better fit for this contour than the part
though they do not overlap with the template. The number of               model, which is based on the template provided by exem-
correct rejections is then c = N − K − f . Assuming that there            plars. All subjects who were not provided with any exemplars
is a hidden parameter p that determines the probability of a              segmented this object into several smaller objects.
hit and another parameter q that determines the probability
of a false alarm, we model the probability of obtaining the                                     mar xemplar rammar Part             m  ar uper
                                                                                          Gram    E        G                   Gram      S
subject’s response x assuming that s is at position pos as:                          50
                                                                          0 ex.          260       102      239       123      264      98
                            Γ(h + m + 1)      h        m
   p(x|s, pos, p, q) =                       p (1 − p)                                0
                          Γ(h + 1)Γ(m + 1)
                                                                                   50
                             Γ( f + c + 1)    f        c
                       ·                     q (1 − q) ,
                           Γ( f + 1)Γ(c + 1)                                3 ex.          157       74       125       106      211      20
                                                                                      0
the product of two binomial distributions: one for the pix-
                                                                                     50
els that lie on the template and one for the pixels outside the
template. Since the exact values of p and q are unknown                     6 ex.          138       113      115       136      213      38
we integrate them out using a prior. We first assume that p                           0
and q are independent of each other. The prior for p should
                                                                                     50
be peaked at zero because if the subject assumes s to be the
stimulus the contour that the subject draws should include all              12 ex.         136       111      108       139      226      21
the pixels in s. The subject will make mistakes due to over-                          0
lapping objects and sloppy drawing, however. A reasonable                                 −5       0    5    −5       0    5   −5       0    5
                                                                                               log odds           log odds          log odds
prior for p seems to be a beta distribution prefering values
close to one but with a mean on the order of a high proportion
γ = 0.9 of the pixels of the stimulus, i.e. p(p) = Beta(p; α, 1)          Figure 4: A comparison of the representational models. Log
with α = 1/(1/γ − 1). As a prior for q we choose a beta dis-              odds histograms. The red line is the median of the distri-
tribution that prefers not to produce false alarms. Again the             bution. The dotted line is at zero. Negative values indicate
number of false alarms that are produced should on average                higher log likelihood for the grammar model. Number of con-
be on the order of 1−γ times the number of pixels of the stim-            tours better fitted by each model are inside the plots.
                                          N−K
ulus, i.e. p(q) = Beta(1, β) with β = (1−γ)K    − 1. Integrating
out these priors we obtain
                                                                                                            Discussion
                         Γ(h + m + 1)     Γ(h + α)                        A basic finding of our experiment is that parsing depends on
     p(x|s, pos) = α                                  .
                           Γ(m + 1) Γ(h + m + 1 + α)                      the amount of top down structural information available about
                         Γ( f + c + 1)   Γ(c + β)                         the category, as evident by the effect of example set size on
                       β                                                  performance. If parsing was based on bottom-up cues alone,
                           Γ(c + 1) Γ( f + c + 1 + β)
                                                                          we would not expect such an effect.
  The results of the simulation are summarized by Figure 4.                  The results of the model comparison illustrate the advan-
Each graph in the figure represents a histogram of the log                tages and limitations along the continuum of increasing rep-
                                                                    861

resentational complexity. The exemplar model, which is a                                         Conclusion
highly constrained sample of the grammar model, is easily            In this paper, we asked to what extent visual representations
overtaken by the part model which provides greater flexibil-         reflect the complex structural characteristics of some classes
ity to capture at least the part-based variability within a cat-     of existing visual objects which exhibit recursion and hier-
egory, which leads to what is effectively a more lax repre-          archical organization of unbounded depth. Our results in-
sentation of relative part distance and location. This flexi-        dicate that structurally poor models which allow for some
bility of part models is exactly what makes them a current           part-based variation capture some but not all of the repre-
favorite in computer vision for recognition applications in-         sentational strategies of the visual systems. We find that
volving objects with relatively homogenous structure, such           under certain conditions people exhibit the kind of gener-
as faces. Since many objects may turn out to be face-like (at        alization more consistent with a grammar-based generative
least in computer image databases) part models perform well          model, rather than an exemplar-based matching model. Many
in many cases. This is not unlike certain linguistic applica-        questions remain unanswered, most notably, what inference
tions, in which a structurally poor model can successfully ac-       mechanisms are engaged in the process of acquiring such rep-
count for the majority of corpus sentences, even as they break       resentations from data, how much and what kind of data is
down dramatically upon encountering rare constructions or            necessary, and to what extent everyday visual tasks, such as
long sentences (Fong & Berwick, 2008). The limitations of            scene parsing, tap into the full range of available structural
the part models in comparison to human performance become            representations. Last but not least, the involvement of com-
clear when categories exhibit a high degree of structural vari-      plex structural generative models in the visual domain raises
ability. In such cases, investigating the boundaries of these        the tantalizing possibility that representations across different
categories might provide us with evidence of the representa-         cognitive domains share a single abstract foundation. Further
tional capacity of the visual system.                                research on the boundaries of human representational capac-
   Note however, that the more complex model is not always           ity promises to shed light on some of these important issues.
the better model. The supergrammar model would have pro-
vided a good fit in the cases of overgeneralization on the part                                  References
of the subjects. This is why the supergrammar model im-              Bierderman, I. (1987). Recognition-by-components: A theory of
                                                                        human image understanding. Psychological Review, 94(2), 115–
proves against the grammar model in the absence of a study              147.
phase, when the general uncertainty of subjects may lead to          Fei-Fei, L., Fergus, R., & Perona, P. (2006). One-shot learning
incorrect overgeneralization (Figure 4, right). However, in             of object categories. IEEE Transactions on Pattern Analysis and
                                                                        Machine Intelligence, 28(4).
the majority of cases, the supergrammar performs worse than          Fergus, R., Perona, P., & Zisserman, A. (2003). Object class recog-
the grammar model. This indicates that subjects were able to            nition by unsupervised scale-invariant learning. IEEE Conf. Com-
zero in not merely on the representation which afforded the             puter Vision and Pattern Recognition.
                                                                     Fiser, J., & Aslin, R. N. (2001). Unsupervised statistical learning of
greatest complexity, but on the representation which afforded           higher-order spatial structures from visual scenes. Psychological
the right degree of complexity for the data at hand.                    Science, 12(6), 499–504.
                                                                     Fong, S., & Berwick, R. (2008). Treebank parsing and knowledge
                                                                        of language: A cognitive perspective. Proceedings of CogSci.
                                                                     Fu, K. S. (1974). Syntactic methods in pattern recognition. Aca-
                                                                        demic Press.
                                                                     Hegde, J., Bart, E., & Kersten, D. (2008). Fragment-based learning
                                                                        of visual object categories. Current Biology, 18, 597-601.
                                                                     Marr, D., & Nishihara, H. K. (1978). Representation and recogni-
                                                                        tion of the spatial organization of three dimensional structure. In
                                                                        Proceedings of the royal society of london b, vol. 200.
                                                                     Palmer, S. (1999). Vision science: Photons to phenomenology.
                                                                        Bradford Books, MIT Press.
                                                                     Savova, V., & Tenenbaum, J. B. (2008). A grammar-based approach
                                                                        to visual category learning. In Proceedings of the 30th Annual
                                                                        Conference of the Cognitive Science Society.
                                                                     Wang, W., Pollak, I., Wong, T.-S., Bouman, C., Harper, M., &
                                                                        Siskind, J. (2006). Hierarchal stochastic image grammars for
                                                                        classification and segmentation. IEEE Transactions on Image
                                                                        Processing (TIP), 15.
                                                                     Zhu, L., Chen, Y., & Yuille, A. L. (2006). Unsupervised learning of
Figure 5: An illustration of the limitations of the part model.         a probabilistic grammar for object detection and parsing. NIPS,
Top left: a typical (correct) contour around a recursively con-         1617-1624.
structed object. Bottom left: A typical oversegmentation of
the same object. Top middle and right: Explanations of the
contour proposed by the grammar model (mean and max like-
lihood). Bottom middle and right: Explanation of the contour
proposed by the part model (mean and max likelihood).
                                                                 862

