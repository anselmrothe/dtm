UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Transfer of gender aftereffects in face silhouettes reveal face-specific mechanisms

Permalink
https://escholarship.org/uc/item/3j1558zc

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)

Authors
Davidenko, Nicolas
Winawer, Jonathan
Witthoft, Nathan

Publication Date
2009-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Transfer of gender aftereffects in face silhouettes reveals face-specific mechanisms
Nicolas Davidenko (ndaviden@psych.stanford.edu)
Nathan Witthoft (witthoft@stanford.edu)
Jonathan Winawer (winawer@stanford.edu)
Department of Psychology, 450 Serra Street, Building 420
Stanford, CA 94305 USA

Another aspect of face aftereffects that has influenced
our understanding of face representation is the degree to
which face aftereffects are robust to transformations
between the adaptor and the target. For example, studies
have shown that aftereffects subside when the adaptor and
target faces differ in their race (e.g. Jaquet, Rhodes,
Hayward, 2008) and that simultaneous but opposite
aftereffects can be driven by upright and inverted adaptor
faces, suggesting that there are distinct representational
resources for upright and inverted faces (Rhodes et al.,
2004). Other image transformations, such as changes in size
between the adaptor and the target, have relatively smaller
effects on the transfer of aftereffects (Zhao & Chubb, 2001)
suggesting that the underlying representations show a
degree of invariance to these changes. These results are
taken as evidence that face adaptation reflects a change in
tuning of high level neural mechanisms that represent faces,
as opposed to simply a conjunction of more generic visual
mechanisms that code for contrast, shape, or orientation.

Abstract
Profile face silhouettes have recently been used to generate a
behaviorally validated face space. An important method for
studying perceptual spaces is the elicitation of aftereffects,
shifts in perceptual judgments that occur after prolonged
exposure to stimuli that occupy one locus in the perceptual
space. Here we show that face silhouettes elicit gender
aftereffects (changes in gender judgments following exposure
to gendered faces) in a rapid, implicit adaptation paradigm.
Further, we observe that these aftereffects persist across
image transformations that preserve the perception of a
silhouette as a face but not across transformations that disrupt
it. Moreover, the aftereffects transfer between two-tone,
profile-view silhouettes and gray-scale, front-view face
photographs. Together these results suggest that gender
processing occurs at a high level of visual representation and
can be parametrically investigated within the silhouette face
space methodology.
Keywords: Face adaptation; gender aftereffects; face
silhouettes.

Introduction
A number of recent studies have shown that aftereffects
similar to those found in color and visual motion are also
present in high-level visual domains. These “figural
aftereffects” have been observed in the domain of face
perception (e.g., Webster & MacLin, 1999; Rhodes et al.,
2003). In such studies, prolonged exposure to a face with a
certain characteristic causes subsequently viewed faces to
appear to have more of the opposite characteristic. For
example, viewing a face that is distorted by a contracting
transformation causes subsequently viewed normal faces to
appear expanded (Webster & Maclin, 1999). Prolonged
viewing of a male face causes subsequently viewed genderneutral faces to appear female (Webster et al., 2004). These
behavioral aftereffects are critical to our understanding of
face representation because they are thought to reflect the
underlying neural mechanisms that respond and adapt to
different facial characteristics. For instance, prolonged
exposure to a male faces shifts the perceptual gender
boundary toward female faces, causing previously neutrallooking faces to appear female, and vice versa. One
interpretation of this result is that gender representation (and
face processing more generally) is norm-based, such that
face-related neural mechanisms code for gender and other
features as particular deviations away from a norm, or mean
face (e.g., Leopold et al., 2001).

While several researchers have begun to explore these
invariances and contingencies, a systematic analysis of the
relationship between adaptors and targets across the space
of human faces has been limited by the complexity of the
face domain itself (but see Leopold et al., 2001). We
propose that using a more simplified parameterization of
face space can be instrumental for quantifying the role of
different facial dimensions in describing the dynamics of
face adaptation and representation.
We have recently developed a parameterized face space
based on profile face silhouettes (Davidenko, 2007; Figure
1). Face silhouettes provide enough information for accurate
judgments of gender, age, and race, reliable ratings of
attractiveness, and distinctiveness that correspond to ratings
of front-view faces, elicit a face-inversion effect like frontview faces (see Yin, 1969), and selectively activate faceselective regions in the fusiform gyrus (Davidenko et al.,
2007). Critically, face silhouettes lend themselves to a
simple yet exhaustive parametric representation. A principal
components analysis (PCA) of the contours of a large
collection of face profiles selected from the FERET
database (Phillips et al. 2000; Phillips et al., 1998; Figure
1A) generates a behaviorally validated 20-dimensional
silhouette face space that captures the variation of human
face silhouettes (Figure 1B). This parameterization allows
us to (1) characterize the physical dimensions that affect
judgments of gender, race, distinctiveness, and other facial

2657

characteristics, and (2) generate novel face silhouettes with
desired values on these characteristics. Here we use these
stimuli to probe the representation of face gender by
implementing a novel rapid, implicit adaptation paradigm.

tests (e.g., Webster & MacLin, 1999). We believe this
method is also “implicit” because subjects were not
instructed to attend to gender of the 8 adaptor stimuli. They
simply provided 9 ratings on the silhouettes and were not
aware that some silhouettes were adaptors while the last
silhouette was the target. This implicit design was meant to
reduce possible effects of response bias in subjects’ gender
judgments. A practical advantage of this general
methodology is that we can measure aftereffects in a single
survey questionnaire, without requiring extensive
psychophysics on any individual subject. Previous results
(Davidenko, 2007), as well as a baseline study (Figure 2)
have validated this survey method as a means of providing
reliable, parametric judgments across a variety of stimulus
manipulations.

Figure 1. (A) Steps in the parameterization of a silhouette:
keypoints are placed along the contour of a profile face
image so that they correspond across many faces, the
keypoints are interpolated with splines, and the resulting
contour is filled in. (B) A sampling of silhouette face space,
where the center of the space represents the mean silhouette.

Method
Figure 2. An axis of silhouette face space highly correlated
with ratings of gender. Stimuli similar to the female and
male endpoints were used as female and male adaptors.

Rapid implicit adaptation
We recently developed a rapid, implicit adaptation method
(Davidenko, Witthoft, & Winawer, 2008) to test whether
face silhouettes elicit gender aftereffects and whether these
aftereffects are robust to various image transformations. We
constructed a set of 8 male and 8 female “adaptor”
silhouettes by sampling along an axis of silhouette face
space shown to be highly correlated with gender ratings
(Figure 2), and a 9th gender-neutral “target” silhouette
defined as the center of silhouette face space. Subjects
completed a one-page questionnaire consisting of 9 face
silhouettes (Figure 3) as part of a survey administered to
Introduction to Psychology students. The first 8 silhouettes
were either all female or all male adaptors, similar to the
endpoints on the gender axis in Figure 2. To make the 8
male or 8 female faces look different from one another, they
varied randomly along dimensions of silhouette space that
were not correlated with gender perception. The 9th
silhouette was always the same gender-neutral silhouette
(middle stimulus in Figure 2). The 8 adaptors were rated on
attractiveness, race, or age, and only the target silhouette
was rated on gender. We refer to this method as “rapid”
adaptation because subjects completed the questionnaire in
about one minute, as contrasted with top-up methods that
require an initial adaptation period and many subsequent

Figure 3. A sample questionnaire used in Study 1. The first
8 silhouettes are male adaptors to be rated on attractiveness,
age, or race, and the 9th silhouette is the gender-neutral
target to be rated on gender.

2658

In 5 studies, we tested whether face silhouettes elicit
gender aftereffects (Study 1), whether the aftereffects are
robust to transformations in the contrast polarity (Study 2),
left-right orientation (Study 3), and vertical inversion (Study
4) of the adaptors, and whether the aftereffects transfer
between face silhouettes and gray-scale, front-view face
images (Study 5). In a 6th study we replicated studies 1 and
3, except that the target face and 8 additional gender-neutral
targets were placed on the back side of the sheet. This
allowed us to test whether the aftereffects depended on the
simultaneous exposure to the adapting and target faces, or
whether the effects persisted over time.

Study 1: Baseline gender aftereffects

Study 3: Reversing left-right orientation
Next we considered the possibility that the aftereffects could
be explained by local shape or curvature adaptation (see
Suzuki and Cavanagh, 1998). To reduce the contribution of
local shape adaptation, we flipped the 8 adaptor face
silhouettes horizontally so that they faced right, while the
target remained facing left). Only 8 of 50 adapt-female
subjects, compared to 37 of 44 adapt-male subjects, rated
the target as “female” (Chi-square(1)=18, p<.001),
indicating 84% aftereffect-consistent ratings. These results
suggest that the aftereffects cannot be explained by lowlevel shape adaptation alone. In the next manipulation, we
tested whether aftereffects were also robust to vertical
inversion of the adaptors.

Of 122 subjects who participated in the first study, 59 were
randomly assigned to the adapt-female condition, and 63 to
the adapt-male condition. The variable of interest was the
proportion of female responses to the target silhouette, as a
function of the adaptation condition. Only 2 of 59 adaptfemale subjects rated the target silhouette as “female”,
compared to 39 of 63 adapt-male subjects (Chisquare(1)=47, p < .001), equivalent to 79% aftereffectconsistent ratings, significantly above 50% chance (Figure
4-Study1). These results indicate that face silhouettes elicit
gender aftereffects, and that these aftereffects can be
detected in a rapid, implicit adaptation paradigm. The fact
that more judgments consistent with adaptation were
obtained in the adapt-female condition likely reflects the
fact that our “neutral” target face looked slightly male to
some of our subjects. This bias is orthogonal to the effect of
interest and does not affect our result.
Because face silhouettes are relatively simple stimuli, it
is possible that the observed aftereffects were the result of
adaptation to low-level aspects of the two-tone images such
as local contours (Suzuki & Cavanagh, 1998) rather than
adaptation to gender per se. In Studies 2, 3, and 4, we tested
whether the aftereffects persist when we change image
properties of the adaptor silhouettes.

Figure 4. Percent of aftereffect-consistent ratings of the
gender-neutral silhouette in Studies 1 through 4. Strong
gender aftereffects were observed in the baseline (Study 1),
when the contrast polarity of the adaptors was reversed
(Study 2), and when left-right orientation of the adaptors
was reversed (Study 3), but not when the adaptors were
vertically inverted (Study 4).

Study 4: Vertical inversion
Study 2: Reversing contrast polarity
Reversing the contrast polarity of a silhouette does not
obviously alter the interpretation of the stimulus as a face
despite reversing the contrast of all local contours (see
Figure 4-Study2). Here we used the same procedure and
stimuli as in Study 1, except that the 8 adaptor face
silhouettes were white silhouettes on black background,
while the gender-neutral target remained black-on-white. If
the aftereffects observed in Study 1 were the result of
contrast-specific contour adaptation, they should be
eliminated in this manipulation. In fact, only 4 of 42 adaptfemale subjects, compared to 29 of 39 adapt-male subjects,
rated the target silhouette as “female” (Chi-square(1)=35, p
< .001), indicating 83% aftereffect-consistent ratings, again
well above chance. Thus, face silhouettes elicit gender
aftereffects that are robust to changes in contrast polarity
between the adaptor and target stimuli.

As with face photographs (Yin, 1969), vertical inversion of
face silhouettes disrupts behavioral face processing
(Davidenko, 2007) and attenuates the response of faceselective fusiform regions (Davidenko et al., 2007). We
reasoned that if gender aftereffects depend on face-specific
processing and are not simply the result of low-level
adaptation, inverting the adaptor stimuli should reduce or
eliminate aftereffects. Indeed, with inverted adaptor
silhouettes, 19 of 36 adapt-female subjects, compared to 29
of 42 adapt-male subjects, rated the upright target as
“female,” (Chi-square (1)=1.8, p>.15), indicating 58%
aftereffect-consistent ratings, not significantly different
from chance. Thus, gender aftereffects in face silhouettes
were not robust to vertical inversion of the adaptors.

Study 5: Transfer across view and image format
The results so far suggest that gender aftereffects are
sensitive to transformations that disrupt the face percept

2659

(vertical inversion) but robust to transformations that
preserve it (left-right inversion and contrast polarity
inversion). To test this hypothesis further, we measured
whether aftereffects transfer between face silhouettes
(which are in profile view) and gray-scale, front-view face
images. Since most image properties differ between these
two types of images, any preservation of aftereffects would
demonstrate that the aftereffects operate on a high, facespecific level of visual representation. Previous studies
using photographs of faces have shown transfer across
viewpoint (Jiang et al, 2007). The procedure for this study
was the same as in the previous studies, but the aftereffects
were tested in two directions: either the adaptor stimuli were
real face silhouettes (152 subjects, either adapt-female or
adapt-male) with a gender-neutral, gray-scale, front-view
target face constructed with the FaceGen Modeller software
from Singular Inversions (Figure 5-Study5a), or the adaptor
stimuli were the gray-scale front-view counterparts of the
silhouettes and the target stimulus was the gender-neutral
face silhouette used in the previous studies (151 subjects;
Figure 5-Study5b). Remarkably, gender aftereffects
persisted across these drastic changes in face image format,
although the size of the effect was smaller than in Studies 13. In the adapt-silhouette conditions, the proportion of
aftereffect-consistent ratings of the front-view target was
60% (Chi Square(1)=5.7, p<.02), while in the adapt-frontview conditions, the proportion of aftereffect-consistent
ratings was 64% (Chi Square(1)=11.6, p<.001).

perception), or whether the effects persist when the target
face is viewed in isolation of the adaptors, we repeated
Studies 1 (baseline) and 3 (reversing left-right orientation),
except that the study sheet contained two sides: side 1 with
adapting faces 1-8, and side 2 with 9 different neutral
silhouettes, all rated on gender. The adapting silhouettes on
side 1 and the first target silhouette on side 2 were identical
to the 9 silhouettes used in Studies 1 and 3, respectively.
The dependent variable of interest was the proportion of
aftereffect-consistent ratings of the first neutral silhouette on
side 2, and we obtained ratings on the subsequent
silhouettes to measure whether the aftereffect would persist.
In each condition, we observed significant adaptation,
similar to Studies 1 and 3: 84% aftereffect consistent
judgments in the baseline condition, and 69% in the leftright reversal condition. Furthermore, in the baseline
condition, an above-chance proportion of aftereffectconsistent ratings persisted after the first target silhouette
was rated (see Figure 6). These results demonstrate that the
effect of viewing 8 faces of the same gender alters
perception of faces in a way that persists even when novel
faces are viewed without the simultaneous context of the
adapting faces.

Figure 6. Proportion of aftereffect-consistent ratings of the
gender-neutral silhouettes in Study 6, baseline condition
(transfer across a page turn). Significant gender aftereffects
were observed in the first and second rated stimuli, despite
the lack of simultaneous exposure to the adaptors and target.
Figure 5. Stimuli used in Study 5. In both the adaptsilhouette (left) and the adapt-front-view condition (right)
conditions, gender aftereffects persisted across drastic view
and image changes between adaptor and target faces.

Discussion

Study 6: Transfer across a page turn
In Studies 1-5, the target face and the adapting faces were
all presented on a single sheet of paper, and hence were
available for simultaneous viewing. To test whether the
observed adaptation effects depended on simultaneous
viewing (similar to simultaneous contrast in brightness

Our results show that gender aftereffects are robust to
transformations that preserve the face percept, even when
the transformations result in drastic image differences
between adaptors and target faces. Eight simple judgments
made on profile silhouettes were sufficient to alter a
subsequent judgment on a front-view face photograph, and
vice versa. The transfer of gender aftereffects between twotone, profile-view face silhouettes and gray-scale, frontview face photographs suggests these vastly different
formats of a face image share an underlying neural

2660

representation. When the gender boundary is shifted in
silhouettes, it is also shifted for front-view images,
indicating that gender representation occurs at a highly
abstract level of visual representation.
Furthermore, we have shown that a rapid, implicit
adaptation paradigm can be effectively used to detect gender
aftereffects. Although the data obtained in this paradigm
represent only a single point in a psychometric curve
(specifically, the probability of labeling a neutral face as
male or female), this data can be gathered quickly across
many subjects and does not require extensive
psychophysical testing. Because subjects were not directed
to attend to the gender of the adapting faces, and because
there were not distinct “adapt” and “target” phases of the
study, the adaptation paradigm is implicit, reducing the
possibility of task demands biasing subjects’ responses.
Finally, our results demonstrate for the first time that
gender aftereffects, which have been previously found with
gray-scale front-view face images, also occur in two-tone,
profile-view face silhouettes. The transfer of aftereffects
between silhouettes and front-view images suggests that
gender processing in face silhouettes shares common
mechanisms with gender processing in front-view faces,
despite the drastic image differences between the two types
of faces. This provides further validation of the face
silhouette methodology and suggests that parameterized
face silhouettes can contribute to our understanding of the
dynamics of gender adaptation and face representation in
general. The finding that the aftereffects persist when the
target silhouettes are rated without the context of the
adapting faces (Study 6) demonstrates that briefly viewing a
small number of face silhouettes can cause a temporary shift
in the calibration of face-specific judgments, consistent with
the notion that face adaptation reflects a process that
normalizes perception to the statistics of the environment.
A key advantage of using face silhouettes is that they
provide a fully parameterized face space and, in particular,
the ability to construct face stimuli at any desired position in
face space. In addition to constructing face stimuli that are
more or less male, we can also construct face silhouettes at
specified distances from the norm face silhouette, or at
particular angular distances from other face silhouettes. This
ability will allow us to quantify face aftereffects in a way
that cannot be achieved using photographs or nonparameterized face stimuli. For example, we can test “how
male” a face must be in order to elicit an aftereffect, or how
the size of the aftereffect compares to the distortion of the
adaptor face. We can also test predictions made by normbased models of face adaptation. By constructing face
stimuli at specified positions in face space, we can
determine whether adaptation aftereffects always shift
perceptual boundaries across the mean face, or whether
there are instances in which the aftereffect shifts perception
in other directions. Addressing these questions will allow us
to further quantify the mechanisms of face adaptation, and
ultimately further our understanding of face representation.

Acknowledgments
This research was funded in part by Kirschstein-NRSA
postdoctoral fellowship 1F32 EY18279-01A1 from the
National Eye Institute awarded to ND. The authors would
like to thank Alex Carney for his assistance in collecting
and analyzing data.

References
Davidenko, N. (2007). Silhouetted face profiles: a new
methodology for face perception research. Journal of
Vision, 7(4):6, 1-17, http://journalofvision.org/7/4/6/,
doi:10.1167/7.4.6.
Davidenko, N., Remus, D., Glover, G., & Grill-Spector, K.
(2007). Sensitivity to face format and distinctiveness in
face-selective cortex. [Abstract]. Presented at the 2007
annual meeting of the Society for Neuroscience.
Davidenko, N., Witthoft, N., & Winawer, J. (2008). Gender
aftereffects in face silhouettes reveal face-specific
mechanisms. Visual Cognition 16, 1, 99-103.
Jaquet, E., Rhodes, G., & Hayward, W. (2008). Racecontingent aftereffects suggest distinct perceptual norms
for different race faces. Visual Cognition, 16(6), 734753.
Jiang, F,. Blanz, V., & O'Toole, A. (2007). The role of
familiarity in three-dimensional view transferability of
face identity adaptation. Vision Research, 47(4), 525531.
Leopold, D. A., O'Toole, A. J., Vetter, T., & Blanz, V.
(2001). Prototype-referenced shape encoding revealed by
high-level aftereffects. Nature Neuroscience, 4(1), 8994.
Phillips, P. J., Moon, H., Rizvi, S. A., Rauss, P. J. (2000).
The FERET evaluation methodology for face
recognition algorithms. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 22, 1090-1104.
Phillips, P. J., Wechsler, H., Huang, J., Rauss, P. (1998).
The FERET database and evaluation procedure for face
recognition algorithms. Image and Vision Computing
Journal, 16(5), 295-306.
Rhodes, G., Jeffery, L., Watson, T. L., Clifford, C. W. G., &
Nakayama, K. (2003). Fitting the mind to the world:
Face adaptation and attractiveness aftereffects.
Psychological Science, 14(6), 558-566.
Rhodes, G., Jeffery, L., Watson, T. L., Jaquet, E., Winkler,
C., & Clifford, C. W. G. (2004). Orientation-contingent
face aftereffects and implications for face-coding
mechanisms. Current Biology, 14(23), 2119-2123.
Suzuki, S. & Cavanagh, P. (1998). A shape-contrast effect
for briefly presented stimuli. Journal of Experimental
Psychology: Human Perception and Performance,
24(5), 1315-1341.
Watson, T. L., & Clifford, C. W. G. (2006). Orientation
dependence of the orientation-contingent face
aftereffect. Vision Research, 46(20), 3422-3429.
Webster, M. A., Kaping, D., Mizokami, Y., & Duhamel, P.
(2004). Adaptation to natural facial categories. Nature,
428, 557–561.

2661

Webster, M. A. & MacLin, O. H. (1999). Figural
aftereffects in the perception of faces. Psychonomic
Bulletin & Review, 6, 647-653.
Yin, R. K. (1969). Looking at upside-down faces. Journal of
experimental psychology, 81, 141–145.
Zhao, L., & Chubb, C. (2001). The size-tuning of the facedistortion after-effect. Vision Research, 41(23), 29792994.

2662

