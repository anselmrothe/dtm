UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Understanding Narrative Interest: Some Evidence on the Role of Unexpectedness
Permalink
https://escholarship.org/uc/item/8dt9f6v8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Dessalles, Jean-Louis
Dimulescu, Adrian
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

 Understanding Narrative Interest: Some Evidence on the Role of Unexpectedness
                                               Adrian Dimulescu, Jean-Louis Dessalles
                                                             Telecom ParisTech
                                {adrian.dimulescu, jean-louis.dessalles}@telecom-paristech.fr
                              Abstract                                 (Dessalles 2008a, 2008b)1 suggests that cognitive complex-
                                                                       ity is involved in some high-level cognitive processes as well,
   This study is an attempt to measure the variations of interest
   aroused by conversational narratives when definite dimensions       including narrative interest. The main claim of CDT is that
   of the reported events are manipulated. The results are com-        people find a situation interesting when its representation is
   pared with the predictions of the Complexity Drop Theory,           simpler than expected from the known workings of the world.
   which states that events are more interesting when they appear
   simpler, in the Kolmogorov sense, than anticipated.
                                                                                             U(s) = Cw (s) −C(s)
   Conversational narratives represent a significant part of
spontaneous language, maybe up to 40% (Eggins & Slade,                    Generation complexity Cw (s) involves the complexity of
1997, p.144). A significant part of individuals’ social con-           all parameters that must be set for the “world machine” i.e.
struction depends on their ability to tell interesting stories         the “world” as we know it, to generate situation s. C(s) is
about events drawn from their daily life (Polanyi, 1979, Eg-           the minimal amount of information needed to unambiguously
gins & Slade, 1997, p.16, Norrick, 2000, p.84). The study              describe the situation. The difference U(s) measures unex-
presented in this paper is an attempt to measure the influence         pectedness. For instance, CDT has been shown to correctly
on interest of definite dimensions of the reported events.             predict all dimensions of coincidences (Dessalles, 2008a).
   Most studies on conversational narratives have been fo-             When two analogous situations s1 and s2 occur indepen-
cused on sociolinguistic issues (e.g. Labov & Waletzky,                dently, their generation complexity Cw (s1 &s2 ) is close to
1967; Labov, 1997; Tannen, 1984). We concentrate here on               2 × C(s1 ), whereas their description requires only C(s1 ) +
cognitive aspects by investigating which factors best predict          C(s2 |s1 ), which is smaller if the analogy is close. Individuals
whether a narrative will be perceived as interesting. We de-           experience such situations as coincidences and consider them
signed an experiment in which participants were given two              worth telling. CDT’s scope includes other important aspects
options and had to decide which one they considered more               such as a new approach to subjective probability (Dessalles,
interesting (Table 1). For instance, in story 1, participants          2008b).
had to decide whether the stranger they encountered in the                Most situations are not unexpected, which means that their
street asked the time or gave them a slap, and which alter-            generation and their description require approximately the
native makes the better narrative. We compared results with            same amount of information. There are exceptions, however,
the predictions of the Complexity Drop Theory, which states            and these exceptions make the topic of conversational narra-
events are more interesting when they appear simpler, in the           tives.
Kolmogorov sense, than anticipated.
                                                                                                Experiment
                  Theoretical Background                               We conducted an experiment to test CDT’s predictions on in-
The factors of interest in real life narratives have not been di-      terest. A corpus of 18 stories in French was established, using
rectly investigated until recently. Studies in related domains,        material from personal recorded sources and from a French
especially episodic memory, showed that best remembered                community Web site (viedemerde.fr) where people describe
situations are atypical (Woll & Graesser, 1982; Shapiro &              short every-day life events, in an informal style, sometimes
Fox, 2002), are inconsistent or deviate from norm (Stangor             with a humorous touch. The stories were presented to 95 par-
& Mcmillan, 1992). A single property, unexpectedness, sub-             ticipants. The 14 most illustrative stories are listed below in
sumes all these characteristics. The main aim of the present           their English version. Answers to the stories may seem obvi-
paper is to show that unexpectedness determines narrative in-          ous, as individuals have a clear intuition of what contributes
terest as well. The other major determining factor of inter-           to interest. What is less obvious is that the rich phenomenol-
est, emotional intensity (Rimé, 2005), will not be considered         ogy of interest illustrated by the stories can be backed by a
here.                                                                  unified theory. The situation parallels the problem of syn-
   In previous work, we modeled unexpectedness as a com-               tax: people have a clear intuition of which sentences are syn-
plexity drop (Dessalles 2008a, 2008b). By analogy with                 tactically correct in their mother language, but designing a
the formal definition of Kolmogorov complexity, the cogni-             predictive model of syntactic correctness remains a scientific
tive complexity of a situation is defined as the length of its         challenge. Besides, experiment data offered some surprises,
shortest description available to the subject. This definition         as explained in the discussion.
makes correct predictions about some important aspects of
perception (Chater, 1999). Complexity drop theory (CDT)                    1 See also www.unexpectedness.eu
                                                                   1734

 1. I was walking quietly in the street when a total stranger        13. You know what? My neighbor, downstairs, she gave birth
    stops before me, looks at me and [...] before continuing his          to [...] a few days ago. It was a premature birth. She said
    walk. a gives me a phenomenal slap; b gives me a slap;                she was surprised to see them so small. a quadruplets;
     c asks me the time.                                                   b triplets; c twins.
 2. This afternoon, the police of Antibes discovered in the Baie     14. I had to pay a one year old fine of 400 euros because of
    des Anges area the floating dead bodies of two elegantly-             the Treasury, which didn’t send reminders to the correct
    dressed women. Apparently, the two accidents happened                 address. When the sum was debited, there was exactly [...]
    almost at the same time. Moreover, both women were wear-              euros on my account. a 400; b 401; c 419.
    ing [...]. a a red tattoo on the right arm representing the
    Tsuba-Kasai dragon; b a red tattoo on the right arm; c a              All stories were presented in random order to all partici-
    tattoo on the right arm.                                           pants. Most participants were engineers and students work-
 3. I’d just bought a small Peugeot 106 ColorLine for 2000             ing in fields other than cognitive science. For each story we
    euros. I had tried it the day before and it was very good.         isolated a parameter that we considered important to the rele-
    I turned the key, I started, I left the property of the for-       vance of the story and defined three options that would gradu-
    mer owner of the car when, coming from the left without            ally affect the overall interest. One given participant only got
    looking, another [...] crashed into me. a Peugeot 106              to mark a preference between two such options, so that the
    ColorLine; b Peugeot 106; c Peugeot.                               overall ranking purpose of the test be less transparent. The
 4. For the birthday of my little sister, my parents got her an        test was implemented as a Web application. Participants had
    82-cm black flat TV screen. A little while ago, for my own,        to fill-in a missing excerpt by clicking on one of two ran-
    they got me [...] a a 82-cm black baseball bat; b a black          domly chosen options that were displayed below the main
    baseball bat; c a baseball bat.                                    text. Participants had “to select the option that made the story
 5. Wednesday, the city of Amiens police seized [...] kg of            more interesting”. A reward (USB stick) was to be given to
    heroin at number 13 rue Fafet. a 10; b 5; c 2.                     those whose overall choices were most consistent with the
                                                                       majority. Results are listed in Table 1.
 6. For a year, I had been thinking of changing my mobile
    phone at SFR (mobile operator). I finally decided to do so
                                                                                                   Ranking
    even if I had to pay a part because I did not have enough
    Red Square Points. I bought the new phone at 13:00. [...] I        At the end of the process, each story produced a list of three
    got a message from SFR: ”Change your mobile, SFR offers            paired comparisons between its fill-in options. We computed
    you 15 000 Red Square Points.” a At 13:10; b At 14:00;             a ranking of story versions to see if it was congruent with
     c Two weeks later.                                                the predictions of CDT. In a manner similar to (Saaty, 1994),
 7. I was lying on the ground under the trees on an autumn             we want to calculate the rank ri of a version i, given pair-
    afternoon, when a leaf fell exactly [...]. a on my nose;           wise relations between versions. Knowing the win/lose his-
     b on my face; c on my body.                                       tory of competition between version i and j, we define wi j as
 8. Two weeks after my car had been stolen, the police in-             the ratio wins(i)/wins( j). In order to avoid division by zero,
    formed me that a car that might be mine was for sale on the        we accorded one vote by default to all versions. For exam-
    Internet. They showed me the ad. The phone number had              ple, if the comparison between two versions of a given story
    been identified. It was the mobile phone number of [...].          was presented to 30 participants of which 23 chose the first
     a my office colleague; b a colleague of my brother’s;             version while the remaining 7 participants chose the second,
     c someone of my neighbourhood.                                    then wi j = 24/8. Note that w ji = 1/wi j . We want a story
                                                                       version that performed well against other versions to have a
 9. I was walking in a street in downtown Paris when I heard
                                                                       rank that reflects its win, taking into account both the rank
    someone calling me: it was a guy who I’d been babysit-
                                                                       of the defeated version and the bluntness of the win. A possi-
    ting [...] when he was a child. We exchanged addresses, it
                                                                       ble calculation is ri = k ∑ j wi j r j , rewritten as 1k R = W R which
    was really nice. a for 2 years; b for 2 months; c a few
                                                                       amounts to finding an eigenvector of the symmetrically recip-
    evenings.
                                                                       rocal matrix W (Farkas, 2007). Ranks are then normalized so
10. It’s funny, I found this on the Internet: the town of St-          that each eigenvector sum to 100.
    Chéron has [...] inhabitants. a 4444; b 4000; c 3856.                Table 1 shows the overall results and rankings. For each
11. I got the license plate of my new car; I looked at the number      story, versions are ordered from most interesting to least in-
    I got, it was [...]. a 999 NNN 91; b 253 NNN 91; c 253             teresting according to CDT. Most of the comparisons (those
    UPV 91.                                                            marked with *) were found statistically significant (p < .05)
12. In front of the coffee machine, I was talking to a colleague       on a standard binomial test targetted at detecting a marked
    about SpongeBob and his best friend Patrick, the sea star.         preference for one particular version. Participants’ choices
    At some point I said: “I don’t like Patrick, he’s too stupid”.     are highly congruent with the predictions. Rankings show
    At this precise moment, my boss passed by, his name is [...]       that participants altogether never preferred option (c), which
     a Patrick Star; b Patrick; c Christopher.                         is excluded by the model. For 17 stories out of 18, option
                                                                   1735

                                                                      s1 , alone, is not unexpected, then Cw (s1 ) = C(s1 ), and:
Table 1: Comparison between paired options and the result-
ing option rankings for each story                                                           U = Cw (s2 ) −C(s2 |s1 )
            comp.       rank                 comp.      rank
                                                                          Stories 2, 3 and 12 in the corpus involved a coinci-
         a-b 22/18      a 53              a-b* 35/1     a 92          dence(story 4 was also intended to present a coincidence, but
    1    b-c* 25/4      b 41       10     b-c* 21/11    b4            see discussion). Participants were highly sensitive to it, as
         a-c* 27/3      c6                a-c* 30/2     c3            they very significantly rejected option (c) in each case. For
         a-b 17/14      a 40              a-b* 28/5     a 76          instance, in story 3, there is an accident between two nearly
    2    b-c* 34/5      b 49       11     b-c* 22/11    b 15          identical cars. Participants preferred the second car to be of
         a-c* 23/9      c 11              a-c* 30/4     c9            the same series as the first one (Peugeot/106/ColorLine) over
         a-b* 24/8      a 61              a-b 18/16     a 52          it being merely of the same type (Peugeot/106), and they pre-
    3    b-c* 32/4      b 32       12     b-c* 29/4     b 43          ferred the latter over of the second car being of the same make
         a-c* 28/5      c7                a-c* 31/3     c5            (Peugeot).
         a-b 18/16      a 38              a-b* 24/11    a 56              These preferences are consistent with CDT. To compute
    4    b-c* 22/11     b 39       13     b-c 21/12     b 27          Cw (s2 ), we may consider that the “world machine” had to
         a-c* 20/14     c 23              a-c* 25/8     c 17          ”choose” among N cars to pick the one involved in the ac-
         a-b* 28/13     a 54              a-b 13/20     a 33          cident. We thus have Cw (s2 ) = log2 N. The computation of
    5    b-c 20/11      b 28       14     b-c* 29/5     b 56          C(s2 |s1 ) can use the common feature f , which is available
         a-c* 21/8      c 18              a-c* 24/9     c 11          with no complexity from s1 . If the number of cars with fea-
         a-b* 29/4      a 79              a-b* 24/9     a 56          ture f is n f , then one needs log2 n f bits to discriminate the
    6    b-c* 28/6      b 16       15     b-c* 28/6     b 33          actual car. Unexpectedness thus amounts to:
         a-c* 31/3      c5                a-c* 26/8     c 11
         a-b* 26/4      a 68              a-b* 30/7     a 70                              U(s1 &s2 ) = log2 N − log2 n f
    7    b-c* 36/4      b 25       16     b-c 17/15     b 16
         a-c* 24/6      c7                a-c* 25/5     c 14              The prediction is that the most specific common feature f
         a-b* 25/6      a 65              a-b* 31/12    a 60          will be considered most interesting. This is indeed what we
    8    b-c* 24/10     b 22       17     b-c* 21/8     b 28          observed.
         a-c* 26/7      c 13              a-c* 24/6     c 12
                                                                      Quantitative Deviation
         a-b* 25/11     a 58              a-b* 32/5     a 66
    9    b-c 20/12      b 26       18     b-c* 30/1     b 31          According to CDT, situations that are unique (or easy to sin-
         a-c* 25/7      c 16              a-c* 28/4     c3            gle out) for a simple reason will be unexpected when they oc-
                                                                      cur. Atypical situations are interesting because they are easy
                                                                      to single out. For instance, in story 5, participants highly sig-
(a), which is the most congruent with the model, is signifi-          nificantly preferred option (a) (10 kilos of heroin) over option
cantly ranked best. In only one story, option (b) tended to be        (b) (5 kilos), and strongly preferred the latter over (c) (2 ki-
preferred to option (a) (see discussion).                             los).
                                                                          A situation s is considered atypical if it departs from a typi-
                           Analysis                                   cal reference r by k standard deviations along feature f . If the
                                                                      “world machine” is considered equivalent to a lottery, then
Stories are meant to test various parameters that influence in-
                                                                      Cw (s|r) = log2 N, where N is the number of situations corre-
terest: coincidences (stories 2, 3, 4, 12), quantitative devia-
                                                                      sponding to r. The complexity involved in describing s using
tion (5, 13), qualitative deviation (1), temporal (6, 17), spa-
                                                                      r and f is at most: C(s) = C(r) +C( f |r) +C(s|r& f ). We will
tial (7) and conceptual (8, 15, 16, 14) proximity, fortuitous
                                                                      suppose that C( f |r) = C( f ). To compute C(s|r& f ), one may
encounters (9) and structure (10, 11). Though probability-
                                                                      rank situations in r by values of f with negligible complexity
based theories provide approximations for quantitative devi-
                                                                      (note that complexity refers to the size of algorithms, not to
ation and proximity (Dessalles 2008b), no current theory can
                                                                      their execution time). If s is extreme, it will appear among
account for all of these influences. CDT makes predictions in
                                                                      the firsts in this ranking. At any rate, feature f distinguishes
each case, and they turn out to be generally confirmed by our
                                                                      a smaller number of situations n f inside the total N. We may
test.
                                                                      then write C(s|r& f ) = log2 n f = log2 pN, with p = n f /N.
Coincidences                                                          If A = − log2 p is an expression of the atypicality of s, then
                                                                      C(s|r& f ) = log2 N −A(k), where function A only depends on
CDT predicts analogies to be interesting because the “world           the statistical distribution of r along f . For a Laplace-Gauss
machine” must generate the two terms of the coincidence sep-          distribution, A(k) ∼ k2 . If r is not unexpected, we eventually
arately, whereas the “observation machine” can use one situa-         get2 :
tion to describe the other (Dessalles, 2008a). Unexpectedness
amounts to U(s1 |s2 ) = Cw (s1 ) +Cw (s2 ) −C(s1 ) −C(s2 |s1 ). If         2 See details on www.unexpectedness.eu/Fish.html
                                                                  1736

                                                                    the “observation machine”, however, the complexity of t2 is
                       U(s) ≈ A(k) −C( f )                          only C(t2 |t1 ) = log2 10 = 3.3 bits, as it can use the moment
                                                                    t1 when the mobile has been bought as reference point. This
   If participants perceive the two options proposed to them
                                                                    contrast contributes 13 bits to unexpectedness (note that the
in story 5 as involving different values of k, the prediction
                                                                    value would be the same with a different time resolution).
is that they will opt for the larger one. Our results clearly
                                                                       More generally, if the event is expected to occur with time
support this prediction.
                                                                    density D and is observed at temporal distance d, then CDT
Qualitative Deviation                                               predicts the contribution to unexpectedness to be3 :
Some events happen, though they were previously thought
to be nearly impossible. This property merely means that the                                U = − log2 (Dd)
complexity Cw (s) required to generate such an event s is large.       In a two-dimensional space, a factor of 2 must be included.
It amounts to C(H), where H is the simplest causal scenario            In story 6, the three options are unexpected by 13 bits, 10.5
that explains s given the workings of the known world (see          bits and 2 bits respectively. Participants’ preferences strongly
discussion). According to CDT, unexpectedness is U(s) =             confirm this effect, as (a) was favored over (b) (29/4) and over
C(H) −C(s).                                                         (c) (31/3), and (b) was favored over (c) (28/6). Story 7 shows
   For instance, in story 1, explaining why someone asked           a similar confirmation pattern, this time in space.
the time (option (c)) may be as simple as “because he forgot           Story 8 illustrates the role of social proximity. Unexpected-
his watch”, whereas an explanation of an unmotivated slap           ness here relies on the fact that the thief happens to be simpler
would require quite a bigger scenario, and consequently a           than expected. The generic unknown person P has a complex-
much larger C(H). On the other hand, complexity C(s) may            ity Cw (P) that we might estimate by the logarithm log2 N of
be computed through a reference frame r and a feature f of          the population in the region that the subject takes as refer-
s, as previously: C(s) = C(r) +C( f ) +C(s|r& f ). In story 1,      ence, probably the city. If P happens to be someone living in
r corresponds to a typical scene in the street. For options         a neighborhood of size n, then the contribution to unexpected-
(a) and (b), f corresponds to the fact of being slapped by a        ness is U = log2 N − log2 n −C(d), where d is the concept of
stranger. If such a description can be regarded as capturing a      neighborhood. This extensional computation represents a last
unique situation, then C(s|r& f ) = 0. Unexpectedness there-        resort, as a computation through the graph of acquaintances
fore amounts to:                                                    often provides a smaller value for C(P). In this case, the com-
                                                                    plexity of a node is the minimum information needed to reach
                  U(s) = C(H) −C(r) −C( f )                         the node of P. In story 8, the expression “my colleague” sug-
   For option (c) (asking the time), C(s|r& f ) has a signifi-      gests that the complexity of P is zero once the concept of col-
cant value, since scenes featuring one person asking the time       league is installed, as P comes first in the list. Results unam-
in the street are numerous and thus difficult to discriminate.      biguously confirm the prediction: option (a) (my colleague)
Unexpectedness will thus be high in options (a) and (b) and         is significantly preferred to (b) (a colleague of my brother),
close to zero in (c).                                               and both (a) and (b) are preferred to (c) (someone living in
   Experiment with story 1 confirms the prediction. Note that       my neighborhood).
option (a) (phenomenal slap) and (b) (slap) are not signifi-        Fortuitous Encounters
cantly distinguished in participants’ preferences. This is con-
                                                                    Fortuitous encounters make good conversational stories. The
sistent with the fact that the two corresponding causal scenar-
                                                                    unexpectedness they produce can be written as C(l) − C(P),
ios are of similar complexity.
                                                                    where l is the location of the encounter and P the person met
Proximity                                                           (Dessalles, 2008a).
Mentioning a reference point (spatial, temporal, social or             The options of story 9 vary C(P) by changing the duration
other) makes things that happened in its proximity worth            of the former acquaintance with P: two years (a), two months
telling. Proximity can be thought of as a relaxation of co-         (b) and a few days (c). A longer period of acquaintance puts P
incidence. In coincidences, C(s2 |s1 ) is lowered by identical      higher in rank in the list of people that one knows personally.
features shared by s1 and s2 . Proximity effects also dimin-        C(P) may be assessed by the logarithm of the rank in that
ish the amount of information needed to define s2 from s1 , by      list. Answers to story 9 confirm the prediction. Note that the
using the latter as a reference point from which it is easy to      preference of (b) over (c) is weak, which may be explained by
locate s2 . CDT thus predicts that events happening closer to       the fact the two options do not change the acquaintance with
each other than usual will add to the interest.                     P significantly.
   Seven stories in our experiment involve proximity effects.       Structure
In story 6, promotional offers by the mobile phone opera-
                                                                    One of the most immediate predictions of CDT is that the oc-
tor are expected to occur, say, once every two months. The
                                                                    currence of remarkable structures will increase interest. The
“world machine” requires Cw (t2 ) = log2 86400 = 16.4 bits
to locate the specific minute t2 when the offer arrives. For            3 See details on www.unexpectedness.eu/NextDoor.html
                                                                1737

“world” requires the same efforts to generate a typical, unre-        for the same story: Ua = 16 and Ub = 9.4), they preserve hi-
markable structure sr and the actual one: Cw (s) = C(sr ). But        erarchy and may be useful when complexity must be assessed
remarkable structures are simple and thus unexpected:                 by an automated system.
                                                                         Causal complexity Cw (H) is equivalent to explanation par-
                      U(s) = C(sr ) −C(s)                             simony (Feldman, 2004; Chaitin, 2004). The complexity of a
                                                                      causal scenario depends on the subject’s capacity to imagine
   Stories 10 and 11 in our corpus involved simple structures.        plausible causes through abduction. Generation complexity
In story 10 (a), number 4444 saves three instantiations, as           Cw (s) is then recursively computed from the generation com-
the digit 4 is merely copied. Unexpectedness is then Ua =             plexity of these causes (2008b). Since modeling abduction
3 × log2 10 = 10 bits. In option (b) unexpectedness, for the          is problematic when common sense is involved (Magnani,
same reason, amounts at least to Ub = 6.6 bits, whereas it is         2001), we are in search of an indirect method. A promising
zero for option (c). Similar computations for story 11 give           technique consists in using an information distance such as
Ua = 16, Ub = 9.4 and Uc = 0 bits. Results confirm these              the normalized Google distance (NGD) (Cilibrasi & Vitányi,
predictions. In both stories, the simplest structure (a) was          2007). The Web offers the textual trace of countless non-
strongly preferred to (b) and (c). Option (b) was preferred to        unexpected events. Statistical co-occurrence of words in texts
(c), though less significantly.                                       is thus expected to correlate negatively with the complexity
                                                                      Cw (s) of a situation s described using these words.
                          Discussion                                     In story 1, the occurrence of a man slapping another in
                                                                      the street is supposed to be more difficult to generate than
Most outcomes of the experiment described in this paper are
                                                                      if the man merely asks the time. Using a straightforward
in full accordance with the predictions of CDT. There are a
                                                                      application of the NGD formula, we calculated the distance
few discrepancies, though, that will be discussed below. Be-
                                                                      (normalized between 0 and 1) from “street” to “slap” (0.74);
fore, we must address the recurrent question of whether com-
                                                                      it is significantly larger than the distance from “street” to
plexity can be measured.
                                                                      “ask” (0.15). By comparison, “street” is close to “build-
Measuring Complexity                                                  ing” (0.08) and far from an abstract concept like “configure”
                                                                      (0.84). These distances are claimed to offer reliable estimates
A common claim, easy to prove, is that Kolmogorov com-                of complexity (Cilibrasi & Vitányi, 2007), although some ef-
plexity is not computable. We avoid this difficulty by con-           fort is still needed to render NGD-type calculations more ro-
sidering two restrictions. First, we define complexity as the         bust across search engines and text corpora (Lindsey, Veksler,
length of the most concise description currently available, and       Grintsvayg, & Gray, 2007) and less dependent on word mor-
not as the objective minimum. This may lead to an underesti-          phology.
mate of unexpectedness and explain why some subjects may
fail to capture the interest that other subjects find in a story.     Prediction Accuracy
   Our second restriction is that cognitive complexity is com-        Most judgments on the test stories are in accordance with pre-
puted on a specific machine, the “cognitive machine”, i.e. the        dictions of the CDT. Some results are, however, somewhat
cognitive tools considered available to humans. This presup-          surprising.
poses that the cognitive model we use be made explicit in
                                                                      • Stories 12 and 2: there is no preference for the most spe-
each case. In the examples previously commented on, most
                                                                         cific common characteristics over the second most specific
computations were made using minimal assumptions about
                                                                         one. For instance, Peugeot/106/Colorline is not signifi-
cognitive abilities. As we showed, the computation of cogni-
                                                                         cantly preferred to Peugeot/106, contrary to what CDT pre-
tive complexity is perfectly tractable in most cases. Three as-
                                                                         dicts. Our explanation is that participants might have found
pects of complexity are, however, external to the model: con-
                                                                         the former too unrealistic to make a credible story. One
ceptual complexity, structural complexity and causal com-
                                                                         participant’s comment reads: “It’s the second time I select
plexity.
                                                                         something less interesting but more credible.” Further in-
   Conceptual complexity is needed when prototypes and fea-              vestigation is needed to make this point clear.
tures, noted r and f in our examples, are involved. Though            • Story 4: the main point of the story is the contrast between
we did not explore it yet, a way to assess C(r) or C( f ) would          presents; many participants apparently did not pay atten-
be to use minimal path length in ontology graphs.                        tion to coincidental characteristics (82 cm and black color),
   Structural complexity can be approximated using common                which turned out to be irrelevant to them.
compression programs, such as gzip, bzip2 (Cilibrasi & Vi-            • Story 14: this is the only real surprise of the experiment.
tanyi, 2005). For each option of story 11, we measured bzip2             Participants tended to prefer 401 to 400 Euros, while CDT
output size (on input replicated 1000 times to compensate for            predicts that the latter be simpler. A possible explanation
compressor inadequacy for small strings). We got, in bytes:              is that 401 uses a frame/feature predicative representation
(a) 64, (b) 71 and (c) 73. If (c) is taken as the expected ref-          (400 and 1) that makes it both simple and unique, whereas
erence, we get in bits: Ua = 9,Ub = 2. Though these values               400 refers to a generic round-number frame (as for 1001
are underestimates (compare to the values computed above                 nights vs. 1000 nights). We plan to test this hypothesis.
                                                                  1738

                         Conclusions                                  Cilibrasi, R., & Vitányi, P. M. B. (2007). The Google sim-
Discovering a single cognitive account for the human sensi-             ilarity distance. Knowledge and Data Engineering, IEEE
tivity to interest is a challenging objective. One may think            Transactions on Knowledge and Data Engineering, 19(3),
of a variety of separate explanations for the different story           370–383.
types: one explanation for analogies, one for proximity, one          Dessalles, J. L. (2008a). Coincidences and the encounter
for structure, and so on. The experiment described in this pa-          problem: A formal account. In 30th annual conference of
per supports the idea that a single and simple principle: com-          the cognitive science society (pp. 2134–2139).
plexity drop, makes all correct predictions with no need to in-       Dessalles, J. L. (2008b). La pertinence et ses origines cogni-
voke ad hoc hypotheses. In particular, the feeling of improb-           tives. Hermes-Science publications.
ability that is often mentioned when reading the stories of our       Eggins, S., & Slade, D. (1997). Analysing casual conversa-
test is not a separate dimension of interest. Subjective prob-          tion. London: Equinox.
ability p can be deduced from unexpectedness U (Dessalles,            Farkas, A. (2007). The analysis of the principal eigenvector
2008b) through:                                                         of pairwise comparison matrices. Acta Polytechnica Hun-
                                                                        garica, 4(2).
                             p = 2−U
                                                                      Feldman, J. (2004, October). How surprising is a simple
   According to CDT, an interesting event is required to be             pattern? Quantifying ”Eureka!”. Cognition, 93(3), 199–
more complex to produce than to (unambiguously) describe.               224.
This requirement is quite difficult to match, and only relevant       Labov, W. (1997). Some further steps in narrative analysis.
stories seem to pass the test. Note that a common misconcep-            Journal of Narrative and Life History, 7(1-4), 395–415.
tion consists in considering the length of a verbal description       Labov, W., & Waletzky, J. (1967). Narrative analysis: Oral
as an indicator of description complexity. But if the descrip-          versions of personal experience. Seattle, WA: University
tion (e.g. the presence of a monstrous animal in my garden)             of Washington Press.
turns an ordinary situation into a unique one, the net benefit in     Lindsey, R., Veksler, V. D., Grintsvayg, A., & Gray, W. D.
terms of unexpectedness may be significant. The prediction              (2007). Be wary of what your computer reads: The effects
is, moreover, that only elements that contribute to unexpect-           of corpus selection on measuring semantic relatedness. In
edness will be mentioned in the verbal description.                     Proceedings of the 8th international conference on cogni-
   The main difficulty with our experimental approach to in-            tive modeling. Ann Arbor, MI.
terest is that stories in the test lie halfway between fiction        Magnani, L. (2001). Abduction, reason and science - pro-
and non-fiction. For instance, in story 13, 21 subjects chose           cesses of discovery and explanation. New York: Kluwer
“triplets” against “twins”, but 12 chose the latter. If partici-        Academic.
pants were to believe that both events really happened, they          Norrick, N. R. (2000). Conversational narrative: storytelling
would probably favor the newsworthiness of “triplets” more              in everyday talk. Amsterdam: John Benjamins Publishing
clearly. We are currently working at an experiment design in            Company.
which judgments of interest are closer to real-life experience.       Polanyi, L. (1979). So what’s the point? Semiotica, 25(3),
   Another perspective is to make complexity computations               207–241.
automatic, using conceptual knowledge retrieved from on-              Rimé, B. (2005). Le partage social des émotions. Paris: PUF.
tologies like Wordnet, and assessing judgments of typicality          Saaty, T. L. (1994). How to make a decision: The analytic
from Web-based distances. Anticipated applications are the              hierarchy process. Interfaces, 24(6), 19–43.
computation of newsworthiness and event-oriented search en-           Shapiro, M. A., & Fox, J. R. (2002). The role of typical and
gines.                                                                  atypical events in story memory. Human Communication
                                                                        Research, 28(1), 109–135.
                     Acknowledgements                                 Stangor, C., & Mcmillan, D. (1992). Memory for expectancy-
                                                                        congruent and expectancy-incongruent information: a re-
We are thankful to Yves Guiard for his advice.                          view of the social and social developmental literatures.
                                                                        Psychological Bulletin, 111(1), 42–61.
                          References                                  Tannen, D. (1984). Conversational style - analyzing talk
Chaitin, G. (2004). On the intelligibility of the uni-                  among friends. Norwood: Ablex Publishing Corporation.
   verse and the notions of simplicity, complexity and irre-          Woll, S. B., & Graesser, A. C. (1982). Memory dis-
   ducibility. In Hogrebe & Bromand (Eds.), Grenzen und                 crimination for information typical and atypical of person
   grenzüberschreitungen (pp. 517–534). Akademie Verlag.               schemata. Social Cognition, 1, 287–310.
Chater, N. (1999). The search for simplicity: A fundamental
   cognitive principle? The Quarterly Journal of Experimen-
   tal Psychology Section A, 52(2), 273–302.
Cilibrasi, R., & Vitanyi, P. M. B. (2005). Clustering by com-
   pression. Information Theory, IEEE Transactions on Infor-
   mation Theory, 51(4), 1523–1545.
                                                                  1739

