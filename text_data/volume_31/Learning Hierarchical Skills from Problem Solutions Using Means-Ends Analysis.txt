UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Hierarchical Skills from Problem Solutions Using Means-Ends Analysis
Permalink
https://escholarship.org/uc/item/1sz2v83h
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Langley, Pat
Li, Nan
Nejati, Negin
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                           Learning Hierarchical Skills from Problem Solutions
                                                 Using Means-Ends Analysis
                                                         Nan Li (nan.li.3@asu.edu)
                                          David J. Stracuzzi (david.stracuzzi@asu.edu)
                                                     Pat Langley (langley@asu.edu)
                       School of Computing and Informatics, Arizona State University, Tempe, AZ 85281 USA
                                                  Negin Nejati (negin@stanford.edu)
                      Computational Learning Laboratory, CSLI, Stanford University, Stanford, CA 94305 USA
                               Abstract                                                 The ICARUS Architecture
   Humans acquire skills in different ways, one of which involves       In previous work, Langley and Choi (2006) have presented
   learning from worked-out solutions to problems. In this paper,       I CARUS, a cognitive architecture that shares many features
   we present an extension to the I CARUS cognitive architecture        with other frameworks like Soar (Laird, Rosenbloom, &
   that lets it acquire complex hierarchical skills in this manner.
   Unlike previous work on this topic, our approach relies on an        Newell, 1986) and ACT-R (Anderson, 1993), including a
   existing architectural mechanism, means-ends analysis, to ex-        distinction between short-term and long-term memories, re-
   plain steps in the problem solution and to learn new structures.     liance on a recognize-act cycle, and a mixture of goal-driven
   We illustrate this method in the domains of multi-column sub-
   traction and football, after which we discuss related work and       with data-driven behavior. I CARUS also has distinctive fea-
   consider directions for future research in this area.                tures, such as separate memories for concepts and skills, in-
                                                                        dexing skills by the goals they achieve, and an architectural
                          Introduction                                  commitment to hierarchical structures. Before describing our
Research on cognitive architectures (Newell, 1990) attempts             approach to learning from problem solutions, we should re-
to explain the entire range of human cognition. In previous             view the framework’s basic assumptions.
papers, we have described I CARUS (Langley & Choi, 2006),
                                                                        Beliefs, Concepts, and Inference
an architecture that, in addition to other capabilities, acquires
hierarchical skills during problem solving. However, as Ohls-           Most cognitive architectures operate in discrete cycles that
son (2008) has noted, humans learn skills from many different           produce mental or physical action. However, before an agent
sources of input. Thus, an important research goal involves             takes action, it must first understand its situation. I CARUS
extending I CARUS to support the full range of human skill ac-          accomplishes this by matching conceptual structures in long-
quisition. In this paper, we report progress on modeling learn-         term memory against dynamic percepts and beliefs that it up-
ing from worked-out problem solutions, which often arise in             dates on each cycle. This process begins when descriptions
educational settings.                                                   of the environment are deposited into a perceptual buffer.
   Our approach builds on previous work, LIGHT, a system                The architecture complements this with a belief memory that
that constructs hierarchical skills from expert solutions to            encodes higher-level inferences about the environment, typi-
problems developed by Nejati, Langley, and Konik (2006).                cally about relations among entities.
Although LIGHT utilized I CARUS knowledge structures as                    I CARUS beliefs are instances of generalized concepts
input and output, it operated as a separate module that was not         stated in a long-term, hierarchical conceptual memory. Ta-
part of the unified architecture. At the same time, the system’s        ble 1 shows some concepts for multi-column subtraction.
approach to explaining problem solutions bore a close resem-            Primitive concepts match directly against the perceptual
blance to I CARUS’ existing mechanism for means-ends prob-              buffer, whereas nonprimitive concepts match against in-
lem solving. In response, we have adapted the latter mech-              stances of lower-level concepts. Each nonprimitive concept
anism to support explanation of, and learning from, worked-             specifies subconcepts that must be present for it to match. For
out solutions to acquire complex cognitive skills, extending            example, the all-processed concept in the table refers to pro-
I CARUS’ coverage of human cognition.                                   cessed and rightmost-column. An inference mechanism up-
   In the sections that follow, we briefly review the I CARUS           dates belief memory at the beginning of each cycle by match-
architecture, including its assumptions about representation,           ing the generalized concept definitions with percepts and ex-
performance, and learning, along with Nejati et al.’s approach          isting beliefs in a bottom-up manner, and stops when it infers
to learning from solution traces. After this, we describe our           all beliefs deductively implied by the concepts and percepts.
adaptation of the framework’s means-ends mechanism to ex-
plain and learn from such traces, followed by an example in             Goals, Skills, and Execution
the domain of multi-column subtraction. We then report ex-              After inferring a set of beliefs about its environment, I CARUS
periments that demonstrate the generality of our approach. In           uses its available skills to take action there. The system stores
closing, we discuss related research and propose avenues for            these structures in a skill memory, which also has a hierarchi-
additional work on this topic.                                          cal organization. Skill clauses are indexed by the concepts
                                                                    1858

   Table 1: Sample concepts from multi-column subtraction.                Table 2: Sample skills from multi-column subtraction.
; PROCESSED describes the situation in which the column              ; Achieve PROCESSED by writing down the difference in
; contains an answer.                                                ; cases where borrowing is not needed.
((processed ?col)                                                    ((processed ?col)
  :percepts ((column ?col below ?below))                               :percepts ((column ?col top ?top bottom ?bottom))
  :tests     ((not (equal ?below nil))))                               :start      ((top-greater ?col))
                                                                       :actions    ((*find-diff ?col ?top ?bottom)))
; ALL-PROCESSED describes the situation in which all the
; columns right of ?left have been processed, including ?left.       ; Achieve PROCESSED by achieving TOP-GREATER
((all-processed ?col)                                                ; followed by PROCESSED when borrowing is needed.
  :percepts ((column ?col))                                          ((processed ?col)
  :relations ((processed ?col)                                         :percepts ((column ?col) (column ?left))
              (rightmost-column ?col)))                                :start      ((left-of ?left ?col))
                                                                       :subgoals ((top-greater ?col) (processed ?col)))
((all-processed ?left)
  :percepts ((column ?left) (column ?right))                         ; Achieve ALL-PROCESSED by processing any column to
  :relations ((processed ?left) (left-of ?left ?right)               ; the right before processing the current column.
              (all-processed ?right)))                               ((all-processed ?col)
                                                                       :percepts ((column ?col))
                                                                       :start      ((rightmost-column ?col))
                                                                       :subgoals ((processed ?col)))
they aim to achieve. Table 2 shows some sample skill clauses
                                                                     ((all-processed ?left)
for multi-column subtraction. The body of a primitive clause           :percepts ((column ?left) (column ?right))
indicates actions that the agent can directly execute in the           :start      ((left-of ?left ?right))
world, as in the first example. In contrast, the body of a non-        :subgoals ((all-processed ?right) (processed ?left)))
primitive skill clause specifies subgoals the agent should pur-
sue to achieve the goal in the head, as in the second example.
    On each cycle, I CARUS retrieves skill clauses that could        a goal or subgoal G, I CARUS creates a new skill in which the
achieve its goal, and attempts to find an applicable path down-      head is a generalized version of G. If system achieved G by
ward through the skill hierarchy. Upon reaching a primitive          chaining off an existing primitive skill S, the new skill’s sub-
skill, the architecture executes its actions in the environment,     goals are S’s start condition plus S’s head in the order they
possibly changing its percepts and beliefs on the next cycle.        were achieved. If system achieved G by chaining off an exist-
                                                                     ing non-primitive skill S, the new skill’s subgoals are S’s start
Problem Solving and Skill Learning                                   condition plus S’s subgoals in the order they were achieved.
When its long-term memory contains relevant knowledge,               In both cases, the new skill’s start condition is the same as that
I CARUS retrieves and executes skills in an effort to achieve        for the first subgoal. If I CARUS achieved G through chaining
its goals. However, in some cases the system encounters an           on concept C, the new skill’s subgoals are the subconcepts of
impasse (VanLehn, 1990) in which it cannot find appropri-            C that were initially unsatisfied, again in the order they were
ate skills. When this occurs, it calls on a problem-solving          achieved. In this case, the start condition is the conjunction
module that carries out means-ends analysis. This mecha-             of C’s subconcepts that were true initially.
nism reasons backwards from known skills and concepts in                 In subsequent runs, I CARUS will apply the new skills
an attempt to construct a novel solution.                            whenever they are relevant to its goals and their start con-
    The problem solver prefers skills that, if applied, would        ditions match the current state. As a result, the agent can
achieve the current goal but that are not yet applicable. In         achieve its goals through reactive skill execution without call-
this case, I CARUS creates a subgoal based on the skill’s in-        ing the problem solver. Langley and Choi (2006) have re-
stantiated start condition and attempts to satisfy it. If it can-    ported encouraging results with this learning mechanism in a
not find such a skill, the problem solver examines the concept       driving environment, the Blocks World, and Freecell solitaire.
definition for the current goal, selects one of its unsatisfied
subconcepts, and makes this the active subgoal. Whenever                           Review of the LIGHT System
I CARUS finds an applicable path that could achieve the cur-         Despite I CARUS’ accomplishments, it provides an incomplete
rent subgoal, it executes that skill path in the environment.        account of human cognition in that it acquires skills only
Upon achieving a subgoal, the system either shifts to another        from its own attempts at problem solving. As Ohlsson (2008)
unsatisfied subgoal or marks the parent goal as achieved, con-       has argued, people learn from a variety of sources, including
tinuing this process until the top-level goal is satisfied.          worked-out problem solutions. Recently, Nejati et al. (2006)
    Although I CARUS’ problem solver lets it overcome im-            report one approach to acquiring knowledge in this manner.
passes and achieve goals for which it has no stored skills,              Their LIGHT system accepts as input a goal, a sequence
the process can require considerable search and backtrack-           of skill instances and the associated state sequence. Given
ing. For this reason, the architecture also includes a learning      this information as input, the learner parses the solution by
mechanism that caches the results of successful problem solv-        reasoning backward from the final state, at each step explain-
ing in skill memory. Whenever means-ends analysis achieves           ing how the action achieves the goal or one of its subgoals
                                                                 1859

by chaining over skills or concept definitions. LIGHT starts         cess tracks augments beliefs with time stamps that note when
by examining the final skill instance S in the trace and, if         they first became true and when they ceased to hold. This pro-
S’s effects include the goal, creates a subgoal for the earlier      vides a simple episodic memory, which we introduced into
steps based on S’s preconditions. If no skill instance in the        I CARUS for another project, but which also proved useful for
trace could have achieved the goal, the learner decomposes           the explanation process.
it into subgoals using its conceptual definition. LIGHT then            Once the system has observed the problem solution and
looks back through the solution trace to determine the order         stored it in the episodic belief memory, the tutor provides it
in which it achieved each subgoal, explaining recursively how        with the problem’s goal and an indication that it should learn
the observed actions achieved each one. The process termi-           from the trace. This leads I CARUS to invoke its means-ends
nates when it links the achievement of each goal to the trace.       analysis module, which we have extended to operate slightly
    Using this hierarchical explanation structure, LIGHT uses        differently when a solution trace is available. As usual, the
the I CARUS learning methods to create new skills for each           module begins by chaining backwards off the top-level goal,
explained goal and subgoal. If a given explanation step in-          selecting a skill from primitive or non-primitive skills that
volved chaining off a skill, then the system acquires the same       would produce the goal as its effect and selecting a concep-
structure that I CARUS would learn in this situation. If an          tual clause otherwise. In the first case, it creates a subgoal to
explanation step involved chaining off a concept definition,         achieve the skill’s instantiated start condition; in the second, it
then LIGHT constructs the same skill that the architecture           creates one subgoal for each unsatisfied subconcept. The pro-
would acquire under those conditions. Nejati et al. demon-           cess bottoms out whenever it finds a skill that explains how a
strated their approach on two domains from the AI planning           skill executed in one state in the solution leads to achieving a
literature, Blocks World and Depots, showing their system            goal or subgoal in a later state, with this activity continuing
acquires effective skills that solve most problems in each do-       until it accounts for the entire sequence of solution steps.
main, and also captures recursive structures that generalize to         This explanatory mode of means-ends analysis differs from
situations beyond those the system has encountered.                  the traditional problem-solving mode in two key ways. One
    Although LIGHT implements a novel and interesting                is that the system chains off a goal that is already satisfied
method for acquiring hierarchical skills from solution traces,       in an effort to explain how it occurred, rather than trying to
it operates as a standalone process. The system runs outside         alter the environment to achieve it. However, each step in
I CARUS’ basic cognitive cycle and connects to it only by us-        the process requires one cognitive cycle, so that explanation
ing the same knowledge structures and the same skill-caching         is deeply integrated into the architecture in the same manner
mechanism. Thus, it does not directly aid our goal of ac-            as the problem solver. The other difference is that chaining
counting for learning from problem solutions within a unified        is constrained by the contents of the episodic belief memory.
theory of the human cognitive architecture.                          This limits the search that arises during means-ends analysis
                                                                     greatly, although it may not eliminate it entirely, in which
     Extending ICARUS to Learn from Solutions                        case the system backtracks and considers another path.
Nevertheless, Nejati et al.’s system introduced some promis-            In addition, I CARUS prefers to explain the observed state
ing ideas that deserve further attention. Because LIGHT’s            sequence using its skills rather conceptual knowledge, and
approach to explanation bears a close relation to means-ends         it prefers skill instances that reach farther back in the se-
analysis, we decided to adapt I CARUS’ problem-solving mod-          quence. The second bias encourages the system to reuse
ule to support a similar ability to learn from solution traces.      learned, higher-level skills when they are available. In the
    We had two aims in mind when pursuing this work. First,          extreme case, when the means-ends module can explain the
we wanted to account for people’s ability to learn from              entire solution with a single high-level skill, then no learning
worked-out solutions within a unified cognitive architecture,        is necessary. However, typically the system uses a mixture
drawing on existing I CARUS mechanisms where possible.               of primitive skills, concept definitions, and possibly learned
Second, we wanted an approach that could take advantage of           skills to produce an explanation.
previously learned skills to aid later learning, which I CARUS
                                                                        As in means-ends problem solving, I CARUS interleaves the
supports but which LIGHT did not. Both characteristics add
                                                                     explanation process with skill learning. Whenever the system
to the psychological plausibility of our model.
                                                                     accounts for how an observed subsequence of states produces
    A typical run begins with the architecture passively observ-
                                                                     a goal or subgoal, it creates a new skill for that goal. The ar-
ing a state sequence that a tutor presents.1 As the state de-
                                                                     chitecture uses the same learning mechanism as for standard
scriptions appear in its perceptual buffer, I CARUS infers be-
                                                                     means-ends analysis that we described earlier. After storing a
liefs that describe each state in more abstract terms. For sub-
                                                                     new skill in memory, I CARUS returns to its efforts to account
traction, these include relations between columns and num-
                                                                     for other parts of the solution trace, continuing until it has ex-
bers that are relevant to the domain skills. One difference
                                                                     plained, and acquired skills for, the entire sequence. The new
from previous versions of I CARUS is that the inference pro-
                                                                     skills become available to solve new problems that the sys-
    1 We wanted to remove LIGHT’s assumption that traces include     tem encounters or, if presented with additional worked-out
skill instances, since humans observe only a sequence of states.     solutions, to explain and learn from them.
                                                                 1860

      Figure 1: Solution trace for a subtraction problem.
  An Example from Multi-Column Subtraction
In order to clarify the mechanism’s operation further, we pro-
vide an example from multi-column subtraction, a domain
that has been well studied by cognitive scientists with educa-
tional interests. Figure 1 shows a sequence of states for the
problem 35 − 17, which we provide to I CARUS along with                Figure 2: A multi-column subtraction explanation trace. Con-
a set of concepts that describe various situations in this do-         cept instances are shown as circles, and skill instances are
main, including the clauses for processed and all-processed            shown as rectangles.
in Table 1, as well as ones like left-of , rightmost-column, and
top-positive. We also provide the system with a set of prim-           understanding. In our example, the first subgoal explained
itive skills that describe basic subtraction actions, including        is (processed c2), using subtrace T14 . Since this involves a
finding differences, adding ten to the top of a column, and            skill instance with the instantiated start condition (top-greater
subtracting one from the top number. As Figure 2 depicts, the          c2), the system constructs a skill with generalized versions of
problem’s top-level goal is (all-processed c1), which means            (top-greater c2) and (processed c2) as its two subgoals, as Ta-
that the agent should process column c1 and all columns right          ble 2 indicates. The learned skill’s start condition is a gener-
of column c1. Since c1 is the leftmost column, achieving (all-         alized version of the start condition for the skill that achieved
processed c1) equates to solving the entire problem.                   (top-greater c2), that is, (left-of ?left ?col).
   Given the solution to this task, I CARUS first steps through           Having successfully explained (processed c2) with T14 ,
the states, inferring higher-level beliefs that hold in each case.     I CARUS acquires another skill for (all-processed c2) with this
Next, the system attempts to explain the solution trace using          as the only subgoal and with (rightmost-column c2) as the
means-ends analysis. Since it has no skill that would achieve          start condition – again, with variables substituted for argu-
the all-processed goal, it resorts to conceptual knowledge.            ments – as Table 2 shows. Having explained (all-processed
Belief memory indicates that (all-processed c1) is supported           c2) with subtrace T14 and (processed c1) with subrace T55 ,
by instantiated subconcepts (left-of c1 c2), (all-processed c2),       I CARUS constructs a skill for the top-level goal (all-processed
and (processed c1). The first held in the initial state, and the       c1). In this case, the skill includes two subgoals based on (all-
other two became true on cycles 4 and 5, respectively. As              processed c2) and (processed c1), along with a start condition
a result, the problem solver separates the solution trace into         based on (left-of c1 c2). Having acquired skills for each goal
subtraces. Trace T14 from cycle 1 to cycle 4, is associated            in the explanation tree, learning halts at this point.
with the subgoal (all-processed c2), while T55 , which involves
only cycle 5, is associated with (processed c1).                                      Generality of the Approach
   The problem solver then attempts to explain recursively             To determine the generality of our architectural extensions,
how each subtrace achieves its associated subgoals. For (all-          we carried out experiments with a number of problems from
processed c2), belief memory indicates that, since column c2           two domains. The first study involved multi-column subtrac-
is the rightmost column, (all-processed c2) was linked to ac-          tion. We provided I CARUS with 16 concepts and six prim-
complishing (processed c2). Since the system has a primitive           itive skills, then presented it with four solved subtraction
skill (see Table 2) for achieving processed, it uses this skill to     problems of increasing complexity. These involved, respec-
explain T14 . I CARUS notes that the start condition of the skill      tively, no borrowing (45 − 32), basic borrowing (35 − 17),
instance (top-greater c2) did not become true until cycle 3, so        borrowing from zero (805 − 237), and borrowing across ze-
it decomposes T14 into two subtraces, T13 and T44 , where T13          roes (2005 − 237). I CARUS learned seven new skills from the
is associated with (top-greater c2) and T44 with (processed            first three tasks, in each case building on ones it had acquired
c2). Among these subgoals, only (top-greater c2) cannot be             earlier. The final exercise produced no learning, since the
achieved with available skills; this leads to further chaining,        system solved it using previously acquired recursive skills.
but we will not present the details here for simplicity’s sake.           This result encouraged us to examine more closely the
   The explanation process does not proceed monolithically.            learned skills’ ability to generalize. When presented with
Whenever the problem solver explains how a solution trace              each of the six subtraction tasks in Table 3, I CARUS acquired,
or subtrace achieves a goal or subgoal, it triggers I CARUS’           in each case, a set of skills that transferred in expected ways to
learning mechanism to produce a new skill that encodes this            the other five problems. For instance, the architecture’s exe-
                                                                   1861

Table 3: Multi-column subtraction problems used for training        one form to another. However, it has closer ties to P RODIGY,
and testing the new learning mechanism.                             which used an analytical technique to acquire control rules
                                                                    for means-ends problem solving (Minton et al., 1989).
     45    − 32 = 13                 40 − 17 = 23                      Although research on cognitive architectures has not fo-
     35    − 17 = 18                 805 − 237 = 568                cused on the acquisition of skills from worked-out solutions,
     45    − 17 = 28                 2005 − 237 = 1768              there have been some efforts along these lines. Van Lent and
                                                                    Laird (2001) describe analogous work on learning Soar op-
                                                                    erators, but their approach relied on annotated traces that our
cution module could use recursive skills learned from 45 − 32       method does not require. Work by Neves (1978) and Mat-
to solve other nonborrowing tasks, even if they involved fewer      suda et al. (2008) on learning production rules for algebra
or more columns, but not to solve borrowing problems. Af-           also took advantage of solution traces, but neither acquired
ter learning on a task like 45 − 17, it could solve problems        complex hierarchical procedures.
that involved a mixture of basic borrowing and nonborrowing            Other research in AI has examined learning complex pro-
columns (i.e., the first four tasks in Table 3).                    cedures from problem solutions. Segre (1987), Mooney
   Because we also desired to show that our approach is not         (1990) and VanLehn and Jones (1993) report analytical ap-
limited to controlled educational settings, we carried out a        proaches to this task, but none of their systems acquired hier-
second study on learning from traces of observed football           archical or recursive structures. More recent work by Hogg,
plays. Here we provided I CARUS with segmented descrip-             Muñoz-Avila, and Kuter (2008) acquires hierarchical skills
tions of video footage for three separate plays that we spec-       from solution traces, but requires knowledge about high-level
ified with a set of 58 concepts. Hess and Fern (2007) report        tasks that our approach does not assume. Reddy and Tade-
the methods used to transform the pixel-based videos into           palli’s (1997) X-LEARN comes closest to our own in terms
sequences of percepts that characterize objects in terms of         of inputs and outputs, but it used a nonincremental method to
attribute-value pairs. After learning skills from each video,       learn conditions on its hierarchical skills.
I CARUS attempted to execute the same plays in football sim-
                                                                       Another closely related system, VanLehn’s (1990) Sierra,
ulator. We evaluated the quality of the learned skills qualita-
                                                                    also models the impasse-driven acquisition of hierarchical
tively by comparing plots of the player trajectories generated
                                                                    procedures for multi-column subtraction from sample solu-
from the video to plots generated in the simulator.
                                                                    tions. However, his work focused on explaining the origin
   During these runs, I CARUS acquired a total of 11 skills, in-    of bugs, which we have not attempted. Also, Sierra exam-
cluding seven from the first play, one from the second play,        ined similarities among a number of problem solutions dur-
and three from the third. The architecture acquired these           ing learning, whereas I CARUS acquires multiple skills from
skills cumulatively, with skills learned from later plays build-    individual problem solutions in an incremental manner.
ing upon those learned earlier. Most lower-level skills were
                                                                       Although our results to date provide a promising account of
acquired from the first trace, so that the system learned only
                                                                    skill learning within a theory of cognitive architecture, there
higher-level behaviors like complex receiver patterns from
                                                                    remain many avenues for additional research. We should
later ones. A qualitative comparison of player trajectories re-
                                                                    evaluate the extended I CARUS’ abilities in subtraction and
vealed that I CARUS’ execution of all three plays correspond
                                                                    football more extensively, as well as demonstrate the abil-
to idealized versions of plays in the video, which makes sense
                                                                    ity to learn from solution traces on other tasks of educational
because both I CARUS and the simulators are less hampered
                                                                    interest, such as physics problem solving.
by momentum than humans on the field. Taken together,
these results suggest that our approach to learning from ob-           In addition, we should make our framework more consis-
served behavior can acquire complex skills in both academic         tent with results on human skill acquisition. In particular,
domains like arithmetic and physical ones like sports.              our studies of multi-column subtraction revealed that I CARUS
                                                                    learns more rapidly than people, in that it masters all seven
                                                                    skills from a single problem 2005 − 237. A human student
                          Discussion
                                                                    typically requires a variety of simple training problems before
There has been considerable research on learning within cog-        he moves on to ones that involve complex combinations. The
nitive architectures. The best-known work involves Soar             system can acquire skills in a more gradual, cumulative fash-
(Laird et al., 1986), which acquires knowledge that con-            ion, but this is not necessary. The most promising response
strains problem-space search through a chunking mechanism,          would limit the architecture’s episodic memory to retain only
and ACT-R (Anderson, 1993), which creates new production            the most recent N beliefs. The revised version would still be
rules through a compilation process that gradually transforms       able to learn from complex solutions, but it would only ac-
declarative representations into procedural ones (Taatgen &         quire simpler skills that occur low in the explanation tree be-
Lee, 2003). The learning mechanisms in I CARUS, Soar, and           fore it forgot steps higher in the tree. Once I CARUS had mas-
ACT-R are all analytic but differ in their details, although        tered these skills, it could benefit from more complex prob-
I CARUS’ method is similar to Soar’s in that it reduces search      lems, since it would not need to explain the lower levels and
and akin to ACT-R’s in that it transforms knowledge from            could focus its efforts on higher levels of the solution trace.
                                                                1862

   Our longer-term agenda includes extending I CARUS on             Laird, J. E., Rosenbloom, P. S., & Newell, A. (1986). Chunk-
two additional fronts. The first involves even stronger uni-          ing in soar: The anatomy of a general learning mechanism.
fication between its explanation mechanism and other capa-            Machine Learning, 1, 11–46.
bilities. An improved system would resort to regular means-         Langley, P., & Choi, D. (2006). A unified cognitive architec-
ends problem solving when presented solutions with missing            ture for physical agents. In Proceedings of the Twenty-First
steps, using search to fill in the gaps. We should also make ex-      National Conference on Artificial Intelligence. Boston:
planation process as interruptable as problem solving, which          AAAI Press.
the current I CARUS will suspend if a higher-priority goal be-      Matsuda, N., Cohen, W. W., Sewall, J., Lacerda, G., &
comes unsatisfied unexpectedly. The second involves aug-              Koedinger, K. R. (2008). Why tutored problem solving
menting the architecture to learn from the additional sources         may be better than example study: Theoretical implica-
of information that Ohlsson (2008) discusses, such as external        tions from a simulated-student study. In Proceedings of
feedback and violated constraints. As in the current work, we         the Nineth International Conference on Intelligent Tutor-
should model these abilities with as few changes to I CARUS           ing Systems (pp. 111–121). Berlin: Springer-Verlag.
as possible, since our goal is a unified theory of cognition.       Minton, S., Carbonell, J. G., Knoblock, C. A., Kuokka, D. R.,
                                                                      & Etzioni, O. (1989). Explanation-based learning: A prob-
                  Concluding Remarks                                  lem solving perspective. Artificial Intelligence, 40, 63–118.
Learning from demonstrated solutions is one of the main             Mooney, R. J. (1990). A general explanation-based learning
ways that humans acquire skills, making it a crucial ability          mechanism and its application to narrative understanding.
for any broad theory of cognition to explain. In this paper,          San Mateo, CA: Morgan Kaufmann.
we reported extensions to an existing cognitive architecture,       Nejati, N., Langley, P., & Konik, T. (2006). Learning hi-
I CARUS, that provided it with the ability to learn in this man-      erarchical task networks by observation. In Proceedings
ner. The most important aspect of our account is that it uti-         of the Twenty-Third International Conference on Machine
lizes the framework’s mechanism for means-ends analysis to            Learning. Pittsburgh, PA: ACM Press.
explain the observed solution trace. This extension required        Neves, D. M. (1978). A computer program that learns al-
almost no changes to the architecture and used the same ma-           gebraic procedures by examining examples and working
chinery for creating subgoals, marking them as satisfied, and         problems in a textbook. In Proceedings of the Second Bien-
learning new skills as the standard means-ends process.               nial Conference of the Canadian Society for Computational
   We demonstrated the extended I CARUS’ behavior on multi-           Studies of Intelligence (pp. 191–195). Toronto, Canada.
column subtraction, showing that it can learn complex hier-         Newell, A. (1990). Unified theories of cognition. Cambridge,
archical and recursive skills in this domain that generalize          MA, USA: Harvard University Press.
correctly to new problems. Although the system learns sub-          Ohlsson, S. (2008). Computational models of skill acquisi-
traction procedures more rapidly than humans, it provides a           tion. In R. Sun (Ed.), The cambridge handbook of com-
promising initial account of learning from problem solutions          putational psychology. New York: Cambridge University
that is embedded within a unified theory of the human cog-            Press.
nitive architecture. We hope to take a similar approach when        Reddy, C., & Tadepalli, P.         (1997).     Learning goal-
we provide the framework with additional learning abilities.          decomposition rules using exercises. In Proceedings of the
                                                                      Fourteenth International Conference on Machine Learning
                   Acknowledgements                                   (pp. 278–286). San Francisco: Morgan Kaufmann.
This material is based in part on research sponsored by             Segre, A. (1987). A learning apprentice system for mechani-
DARPA under agreement FA8750-05-2-0283. The views                     cal assembly. In Proceedings of the Third IEEE Conference
contained herein are those of the authors and should not be in-       on AI for Applications (pp. 112-117).
terpreted as representing the official policies or endorsements,    Taatgen, N. A., & Lee, F. J. (2003). Production compilation:
expressed on implied, of DARPA or the U. S. Government.               A simple mechanism to model complex skill acquisition.
                                                                      Human Factors, 45, 61–76.
                          References                                Van Lent, M., & Laird, J. E. (2001). Learning procedural
Anderson, J. R. (1993). Rules of the mind. Hillsdale, NJ:             knowledge by observation. In Proceedings of the First In-
   Lawrence Erlbaum Associates.                                       ternational Conference on Knowledge Capture (pp. 179–
Hess, R., & Fern, A. (2007). Improved video registration              186). Victoria, BC: ACM Press.
   using non-distinctive local image features. In Proceedings       VanLehn, K. (1990). Mind bugs: The origins of procedural
   of the IEEE Conference on Computer Vision and Pattern              misconceptions. Cambridge, MA, USA: MIT Press.
   Recogntion. Minneapolis, MN: IEEE Press.                         Vanlehn, K., & Jones, R. M. (1993). Learning by explaining
Hogg, C., Muñoz-Avila, H., & Kuter, U. (2008). HTN-                  examples to oneself: A computational model. In S. Chip-
   Maker: Learning HTNs with minimal additional knowl-                man & A. L. Meyrowitz (Eds.), Cognitive models of com-
   edge engineering required. In Proceedings of the Twenty-           plex learning (pp. 25–82). Kluwer Academic Publishers.
   Third Conference on Artificial Intelligence (pp. 950–956).
   Chicago: AAAI Press.
                                                                1863

