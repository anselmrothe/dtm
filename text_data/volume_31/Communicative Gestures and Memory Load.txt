UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Communicative Gestures and Memory Load
Permalink
https://escholarship.org/uc/item/4wx1k0n2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Krahmer, Emiel
Maes, Alfons
Mol, Lisette
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                Communicative Gestures and Memory Load
                                                   Lisette Mol (L.Mol@uvt.nl)1
                                            Emiel Krahmer (E.J.Krahmer@uvt.nl)1
                                                   Alfons Maes (Maes@uvt.nl)1
                                              Marc Swerts (M.G.J.Swerts@uvt.nl)
                            1
                              Faculty of Humanities, Communication and Cognition, Tilburg University
                                          Warandelaan 2, 5037 AB, Tilburg, The Netherlands
                            Abstract                                 Jacobs & Garnham, 2006), whether there is dialogue
  Previous research has shown that (co-speech) hand gestures
                                                                     (Bavelas et al., 2008), and whether the addressee is human
  sometimes aid cognition and can reduce a speaker’s cognitive       or artificial (Mol et al., 2009). If speakers adapt their
  load. We argue that this is not the case for gestures that are     gesturing to such environmental factors, then this could
  produced primarily to communicate, which we think come at          mean that gesturing is sometimes intended for the addressee.
  a cognitive cost to speakers instead. In a production                 Jacobs and Garnham (2006) point out that the primary
  experiment with a narrative task, we show that speakers            functional role of gesturing may depend on the task a
  gesture more frequently with a less demanding task, but only       speaker is performing (also see Alibali, Kita & Young,
  if speaker and addressee can see each other. Our results
  support our theory, without contradicting previous findings.       2000). Their study shows that during a narrative task,
                                                                     gestures are produced primarily for the benefit of the
   Keywords: Gesture; Cognitive load; Audience design.               addressee. It has also been hypothesized that different kinds
                                                                     or sizes of gestures serve different purposes (i.e. Alibali et
                        Introduction                                 al., 2001; Bangerter & Chevalley, 2007; Bavelas et al.,
In this paper we explore the relationship between memory             2008; Beattie & Shovelton, 2002; Enfield et al., 2007).
load and gesturing. First we describe two alternate                  Especially larger gestures and gestures depicting some of
perspectives on why people gesture, which give rise to               the content of a speaker’s message (representational
different predictions about the relation between gesturing           gestures) have been shown to occur more frequently when a
and cognitive load. We then describe previous work                   speaker is visible to an addressee, and hence are associated
supporting the idea that speakers themselves benefit                 with the communicative functions of gesture.
cognitively from gesturing. This is followed by our present             The different functional perspectives on gesturing make
study, in which we test a prediction from the perspective            opposite predictions about the effect of gesturing on a
that gestures are produced to communicate.                           speaker’s total cognitive burden. Gestures that are produced
                                                                     mostly for the benefit of the speaker would ease the process
The functional roles of gesturing                                    of speech production and may thus lighten a speaker’s
Many studies have investigated the functional roles of hand          cognitive load. But gestures produced primarily for the
gestures that people spontaneously produce during speech.            benefit of the addressee would rather come at a cognitive
One function is that gesturing aids speech production. For           cost to speakers, just as verbal language production does.
example by aiding lexical retrieval (Hadar, 1989; Krauss,            We next present some evidence for this first effect, which in
1998), helping to hold a mental image while it is verbally           our view leaves open the possibility for the second.
expressed (De Ruiter, 1998), or by helping speakers to
“organize rich spatio-motoric information into packages              Gesturing and Cognitive Load
suitable for speaking” (Kita, 2000).                                   In Cohen (1977) an effect of task difficulty on gesturing is
  There is also a large body of evidence that gesturing              reported. It was found that participants produced more
serves communicative purposes. It has been shown that                gestures when giving route directions involving four inter-
addressees can gain information from gesture (Beattie &              sections (more demanding task) than when giving directions
Shovelton, 1999; Chawla & Krauss, 1994; Cutica & Buccia-             involving two intersections (less demanding task). The
relli, 2008; Goldin-Meadow & Sandhofer, 1999; Mol et al.,            average difference in gesture rate between the more and less
2009). Speakers also gesture differently depending on many           demanding task was equal in size when interlocutors could
features of the communicative setting, such as whether the           see each other and when they could not. This suggests that
addressee can see them or not (i.e. Alibali, Heath & Myers,          the effect resulted from gestures produced primarily for the
2001; Cohen, 1977), where the addressee is located relative          benefit of the speaker, since such gestures would be
to them (Özyürek, 2002), whether information is new or               produced both when the addressee is visible to the speaker
given to the addressee (Enfield, Kita & De Ruiter, 2007;             and when not. This is consistent with the direction of the
                                                                 1569

effect: more gestures with the more demanding task.               we have cut up the information to be described into smaller
However, since the differences in the average gesture rate        parts. We assume that the more demanding task is
between the more and less demanding task were close to 2,         sufficiently difficult, such that speakers are unable to
the effect may relate to the number of intersections that         produce all communicative gestures that an addressee could
needed to be described quite directly, rather than being a        benefit from. Since the content that addressees need to
more general result of the cognitive demands of the               remember is the same in both tasks, we also assume that
instruction task.                                                 addressees can still benefit from gestures in the condition
   In a picture description task, Melinger and Kita (2007)        with the less demanding task.
found that the complexity of the picture influenced gesture          The different theories on the primary function of
rates. For pictures of colored dots along a path with multiple    gesturing make different predictions on how the memory
branches gestures were produced more frequently than for          demands of a task influence the gesture rate. For gestures
pictures of dots along a continuous path, without any choice      that aid speakers by facilitating lexical access, we would not
points. They also found that in a dual-task situation, a          expect an effect of our manipulation of memory demand on
spatial secondary task lead to higher gesture rates than a        gesture rate. It seems unlikely that finding the words to
non-spatial secondary task. This is strong evidence that          describe a cartoon would be easier or harder when
gesturing can help a speaker, especially since speaker and        describing a shorter or longer part of it. Neither would we
addressee could not see each other in this study. However,        expect an effect of mutual visibility on such gestures, since
since visibility was blocked by a wooden screen, these            they are tied to the speech production process within the
results may not generalize to all gestures that are produced      speaker. This prediction is depicted in Figure 1a.
in face-to-face interaction.
  Goldin-Meadow et al. (2001) investigated the relation
between cognitive load and gestures by manipulating
gesturing rather than task difficulty. They made use of a
dual-task paradigm, in which participants performed a
memory task while explaining a math problem. They found
that children and adults performed better on the memory
task if they gestured during their explanation, provided that
the memory task was sufficiently challenging. This effect
was found both when people were instructed not to gesture
and when they refrained from gesturing spontaneously. This
indicates that gesturing can reduce the cognitive load of the
explanation task, thereby leaving more cognitive resources
available for the memory task.
  This result was refined in Wagner, Nusbaum, and Goldin-
Meadow (2004). Gesturing was found to benefit both
spatial and propositional memory, but especially when
gestures expressed the same content as the concurrent
speech. This leaves open the possibility that this result is
driven by gesturing for the speaker as well, rather than by
gesturing for the addressee. So the question remains open
whether communicative gestures come at a cognitive cost to         Figure 1: Predictions made by the different theories on how
speakers.                                                               task demand and visibility influence gesture rate.
Present Study                                                       If gesturing mostly aids cognitive processes within the
In our present study, we are interested in the relationship       speaker, such as holding a mental image or organizing
between cognitive load and gestures that are produced             information into packages suitable for speaking, then we
primarily to communicate. We expect such gestures to come         would expect a lower gesture rate when the task is split up.
at a cognitive cost to speakers, rather than reducing their       This less demanding task may give rise to fewer gestures
cognitive load. Therefore, we vary the demands that a             that are needed to facilitate cognition. If so, this effect
narration task makes on speakers’ memory. We expect that          should be present both when speaker and addressee can see
with a less demanding task, speakers will produce more            each other, and when they can not (see Figure 1b). Another
gestures that primarily aid the addressee than with a more        possibility is that these processes are automated to such an
demanding task. We compare a communicative setting in             extent, or take place on such a local scope, that there is no
which gestures can be used to communicate, to one in which        effect of our global manipulation of memory demand on
they can not. Especially in this first setting, we would          gesturing (like in Figure 1a).
expect speakers to gesture more with a less demanding task.          If most gestures are produced for the benefit of the
   For this study we have asked participants to retell an         addressee rather than the speaker, then a different pattern of
animated cartoon. To reduce the task’s memory demands,            results is predicted. In that case we would expect speakers
                                                              1570

needing to put cognitive effort into their gesture production,      no mutual visibility. The experimenter randomly assigned
rather than experiencing a reduction in memory load from it.        participants the role of narrator or listener.
Therefore, we would expect a higher gesture rate if the               Participants first read the instructions and could ask any
narration task is split up into smaller parts, and its demands      questions they had on the task. The instructions focused on
on memory are lower. However, such communicative                    the task of the addressee, namely summarizing the speaker’s
gestures are expected especially when speaker and                   narration. This way we implied that the study was on
addressee can see each other. So we would predict an                summarizing. Speakers were explicitly asked not to sum-
interaction between mutual visibility and task demand: The          marize, but to just retell the story. The instructions stated
gesture rate will be higher with the less demanding task, but       that they were videotaped with the purpose of comparing the
only if speaker and addressee can see each other. No effect         addressee’s summary to their narration afterwards.
of memory demand on gesture rate is predicted for the               Addressees were instructed not to interrupt the speaker.
condition in which speaker and addressee cannot see each              The animated cartoon we used was “Canary Row”, by
other. This prediction is depicted in Figure 1c.                    Warner Brothers. This is a seven-minute animated cartoon
   If we assume that with this narration task speakers will         in which a cat tries to capture a bird in eight different ways.
produce both gestures that aid their own cognition or speech        The cartoon was separated into its eight episodes, by
production and gestures that are intended primarily for the         inserting 10 seconds of blank video after each episode.
addressee, we need to combine the predictions for both                 Speakers watched the cartoon on a computer screen that
types of gestures. We would expect for-speaker gestures to          only they could see. While the speaker watched the cartoon,
form the majority in the no visibility condition. Therefore,        the addressee was seated across from the speaker, as
in this condition the gesture rate will be lower with the less      depicted in Figure 2, and was asked to listen to music
demanding task. However, in the visibility condition, where         through headphones. Once the episode had finished, the
we expect that most gestures are produced primarily for the         speaker paused the movie and signaled to the addressee that
benefit of the addressee (Jacobs & Garnham, 2006), the              the episode had ended. The addressee then took off the
gesture rate will be higher with the less demanding task.           headphones, and speaker and addressee moved into chairs
This is depicted in Figure 1d.                                      facing each other (see Figure 2). In the FtF condition, there
                                                                    was nothing in between speaker and addressee. The camera
                                                                    was right behind the addressee, slightly to the side. In the
                           Method                                   Screen condition, speakers were facing the camera, which
                                                                    was right in front of the Screen. The addressee was seated at
Design                                                              the same distance from the speaker as in the FtF condition.
   We have used a 2 x 2 between subjects design. The two               Before the experiment started, participants were seated as
independent variables are whether an animated cartoon is            in positions 3 and 4 in Figure 2. The experimenter explained
seen and retold all eight episodes at once, or one episode at       that the speaker was to address the addressee rather than the
a time, and whether speaker and addressee can see each              camera. Then followed a practice run, to make sure both
other or not. We have used a narrative task, because we             participants understood the procedure. The experimenter
would expect communicatively intended gestures to occur             then started the camera and left the room.
frequently with such a task (Jacobs & Garnham, 2006).                  After the retelling of the cartoon, the experimenter took
                                                                    the addressee to another room to write the summary using a
Participants                                                        common word processor. To exclude the possibility that the
                                                                    task with a screen separating speaker and addressee was
39 first year students of Tilburg University took part as           experienced as more difficult than the FtF task or vice versa,
speakers in this study, as part of their first year curriculum.     narrators were then asked to complete the NASA Task Load
They were all native speakers of Dutch. Addressees were             Index (Hart & Staveland, 1988), in which subjective
first year students and native Dutch speakers as well.              workload is assessed on six scales. They next completed a
                                                                    second questionnaire, which included questions on how they
Procedure                                                           had experienced the communication. We fully debriefed all
The two conditions with the more demanding task of                  participants and asked their consent for using the recordings
retelling the cartoon all at once were actually taken from an       and summaries. All participants agreed to the use of their
earlier study, which looked at the effect of the addressee          data for scientific purposes.
being human or artificial (Mol et al., 2009). The procedure
was similar to the one described below, except that speakers        Data Analysis
first saw the animated cartoon in its entirety, and then retold     The first author transcribed each narration from the video-
it to an addressee.                                                 tape. Repairs, repeated words, false starts, and filled pauses
   For the less demanding task, we randomly assigned                were included. The annotation of hand gestures was initially
participants to the no visibility (Screen) or visibility (Face-     done by the first author. Difficult cases were resolved by
to-Face) condition (after Alibali et al., 2001). The Screen         discussion among all authors. We first discriminated
condition differed from the FtF condition in that a wooden          between gestures and other movements such as self-
screen separated speaker and addressee, such that there was         adjustment. Then we labeled gestures that seemed to depict
                                                                1571

                                                                   no effect of visibility on the TTR, neither with the more (p =
                                                                   .44) nor with the less demanding task (p = .7).
                                                                   More gestures with less demanding task in FtF
                                                                   setting only
                                                                   Speakers produced more gestures per 100 words when
                                                                   speaker and addressee could see each other F(1,35) =
                                                                   28.804, p < .001, !p2 = .45. The main effect of task demand
                                                                   was not significant (p = .42), but there was a significant
                                                                   interaction of visibility and task demand, F(1,35) = 4.643, p
      Figure 2: Experimental Setup. 1 = position of speaker        < .05, !p2 = .12, see Figure 3. Pairwise comparisons showed
    while watching video, 2 = position of addressee while          that in the FtF condition, gestures were significantly more
  listening to music on headphones, 3 = position of speaker        frequent with the less demanding task. Similar results were
 during narration, 4 = position of addressee during narration.     obtained for the number of gestures per second.
some of the content of the cartoon as representational
gestures (McNeill, 1992). All other gestures, including
simple biphasic movements of the hands (beats) and other
interactive gestures (Bavelas, 1992), were labeled as non
representational gestures.
   In a separate round of gesture coding, we coded for
gesture size. Gestures that were produced using only the
fingers received a score of 1. If there was significant wrist
movement, the gesture received a score of 2. Gestures that
also involved significant movement of the elbow or lower
arm received a score of 3, and gestures in which the upper
arm was also used in a meaningful way or that involved
movement of the shoulder received a score of 4. This
allowed an average gesture size to be computed for each
participant.                                                            Figure 3: Means of the average number of gestures
   For all tests for significance we have used univariate                             produced per 100 words.
analysis of variance (ANOVA), with mutual visibility (2
levels: yes, no) and task demand (2 levels: high, low) as the        When looking at the mean total number of gestures
fixed factors and a significance threshold of .05. Where           produced, without normalizing by words or seconds, more
needed we have performed pairwise comparisons between              gestures were produced when visibility was not blocked,
all four conditions using the LSD method with a                    F(1, 35) = 31.98, p < .001, !p2 = .48, as well as with the less
significance threshold of .05. We have used partial Eta            demanding task, F(1, 35) = 20.36, p < .001, !p2 = .37. There
square as a measure of effect size.                                was an interaction between visibility and task demand, F(1,
                                                                   35) = 12.94, p < .01, !p2 = .27, see Figure 4.
                           Results
More (different) words with less demanding task
Speakers doing the less demanding task produced more
words (M = 1204, SD = 404) than speakers doing the more
demanding task (M = 610, SD = 189), F(1,35) = 34.250, p <
.001, !p2 = .50, regardless of whether visibility was blocked
(p = .22). The effect of visibility on the total number of
words used was not significant (p = .36). We found no
significant effects of visibility or task demand on the
number of words per second, or the number of filled pauses
per word.
  The type-token-ratio (TTR) is a measure of repetition of
words in a text. It is computed by dividing the number of              Figure 4: Means of the number of gestures produced.
unique words in a text or corpus by the total number of
words. The TTR was higher with the less demanding task                More representational gestures per 100 words were pro-
(33% vs. 26%), indicating greater word variety. We found           duced when visibility was not blocked, F(1, 35) = 32.461, p
                                                               1572

< .001, !p2 = .48. The main effect of task demand was not                serve a communicative purpose. This theory predicts more
significant (p = .28), but in the FtF setting, representational          gestures with a less demanding narration task, but only
gestures were more frequent with the less demanding task,                when gestures have the potential to communicate. This is
F(1, 35) = .4419, p < .05, !p2 = .11. For non representational           indeed what we found.
gestures, only the effect of visibility reached significance,               Clearly, the two tasks that we have used resulted in
F(1, 35) = 5.605, p < .05, !p2 = .14. Gestures were more                 different verbal and non-verbal behavior. But is this a result
frequent when visibility was not blocked, and like for                   of the different memory demands of retelling the cartoon all
representational gestures, the difference was larger with the            at once or one episode at a time? A difference in pragmatics
less demanding task.                                                     of these two tasks may have lead to different verbal
                                                                         behavior, which in turn resulted in different gesture rates.
Different gestures in FtF conditions                                     For this explanation one has to add that these different
Gestures were larger when speaker and addressee could see                pragmatics only influence gestures that have the potential to
each other (M = 2.8, SD = .4) compared to when they could                communicate, since the difference was not found when
not (M = 2.2, SD = .5), F(1, 35) = 14.669, p < .01, !p2 = .30.           visibility was blocked. To further address this issue, we are
We also found a higher percentage of gestures made from a                planning to do an additional analysis in which only
character viewpoint1 when visibility was not blocked, F(1,               utterances encoding certain key elements of information are
35) = 8.866, p < .01, !p2 = .21.                                         included. This should lead to more comparable language use
   The NASA Task Load Index indicated that the narration                 in the more demanding and less demanding task.
task was considered equally difficult when there was a                      In addition to more qualitative linguistic analysis, a dual-
screen in between speaker and addressee and when there                   task paradigm may help to discriminate between whether
was not. There was no significant difference between these               speakers produced communicative gestures more frequently
conditions on any of the six scales.                                     because of a lower cognitive load, or whether this resulted
                                                                         from another factor in our less demanding task. We are
                            Discussion                                   planning to use such a design in our future research.
                                                                            When visibility was blocked, there was no significant
The memory demand of a narration task had an effect on                   difference in gesture rate between the more and less
both verbal language production and gesture production.                  demanding task. This confirms that gestures produced in
With a less demanding task, speakers produced longer                     this setting differ from gestures produced when visibility
narrations and used a higher percentage of unique words.                 was unobstructed. It could very well be that most gestures
Though further linguistic analysis is needed, this suggests              produced when visibility was blocked were produced for the
that speakers added extra information to their narrations. We            benefit of the speaker. Our current study cannot clarify how
did not find a significant effect of visibility on the length of         exactly these gestures aid speakers. It has only shown that a
a narration or the percentage of unique words. Neither did               global manipulation of task demand does not seem to have a
visibility influence two measures of speech fluency: speech              large effect on the frequency with which such gestures are
rate and the number of filled pauses per 100 words. This                 produced (despite the more elaborate verbal descriptions
indicates that narrations were broadly similar when visibility           with the less demanding task).
was blocked and when it was not, though more detailed                       Our study did show several qualitative differences
linguistic analysis is needed to support this claim.                     between gestures produced when speaker and addressee
  As expected, gestures were more frequent when visibility               could not see each other vs. when they could. Gestures
was not blocked. But more importantly, this difference was               produced when visibility was blocked were smaller and
larger with the less demanding task. Though narrations were              characters were imitated less often. This supports the idea
longer with the less demanding task regardless of visibility,            that gestures (solely) serving a for-speaker purpose look
the gesture rate was higher only when visibility was not                 markedly different from gestures that have communicative
blocked. This suggests that the higher gesture rate resulted             potential.
from gestures produced mostly for the addressee, rather than               At first glance our results may seem contradictive to the
from gestures that the speaker needed in order to produce                results found by Cohen (1977). However, Cohen did not
the verbal narration (especially since we found no                       find an effect of whether participants were familiar or
significant effects of visibility on any of the variables we             unfamiliar with the routes to be described. This suggests
used to measure verbal behavior).                                        that both the complex and easy tasks were well within the
   Our results support the theory that speakers need to put              cognitive capacities of the participants. This could mean that
cognitive effort into the production of gestures that mostly             in both tasks, speakers had enough capacity left to produce
                                                                         any appropriate communicative gestures, and the difference
   1
      In the character viewpoint, body parts of the speaker map          in gesture rate was caused by gestures produced primarily
directly onto the same body parts of a character that is being           for the speaker. As explained earlier, the pattern of results
described, rather than part of the speaker representing a different      found matches this hypothesis.
part of a character or situation (see McNeill, 1992). For example, if      It may also be that in giving route directions, or explaining
speakers use their hands and arms to depict the cat’s paws and
                                                                         math problems, such as in the study by Goldin-Meadow et
forelegs, this is considered character viewpoint, whereas using
one’s fingers to represent the cat’s legs is not.                        al. (2001), gestures produced mostly for the benefit of the
                                                                     1573

speaker form the majority, as opposed to in narrative tasks       Chawla, P., & Krauss, M. (1994) Gesture and speech in
(Jacobs & Garnham, 2006). Wagner et al. (2004) did not              spontaneous and rehearsed narratives. Journal of
find a beneficial effect on memory of gestures that                 Experimental Social Psychology, 30, 580-601.
contained information that was not expressed in speech. It        Cohen, A.A. (1977) The communicative functions of hand
may very well be that most gestures produced to                     illustrators, Journal of Communication, 27 (4), 54-63.
communicate fell into this category. Therefore, our results       Cutica, I., & Bucciareli, M. (2008) The deep versus the
do not conflict with these latter two studies either. Rather,       shallow: Effects of co-speech gestures in learning from
our study identifies an important distinction that needs to be      discourse, Cognitive Science, 32, 921-935.
made when studying the relationship between gesturing and         De Ruiter, J.-P. (1998) Gesture and Speech production.
cognitive load, namely between gesturing primarily for              Unpublished dissertation, University of Nijmegen.
producer-internal purposes and gesturing primarily for            Enfield, N.J., Kita, S., & De Ruiter, J.-P. (2007) Primary
producer-external purposes.                                         and secondary pragmatic functions of pointing gestures.
                                                                    Journal of Pragmatics, 39, 1722-1741.
                                                                  Goldin-Meadow, S., Nusaum, H., Kelly, S.D., & Wagner, S.
                         Conclusion
                                                                    (2001) Explaining Math: Gesturing Lightens the Load.
   Our study has shown that on average, gestures are                Psychological Science, 12 (6), 516-522.
produced at a higher rate when people perform a narration         Goldin-Meadow, S., & Sandhofer, C.M. (1999) Gestures
task that places lower demands on memory, but only when             convey substantive information about a child's thoughts to
visibility between speaker and addressee is not blocked.            ordinary listeners. Developmental Science, 2, 67-74.
This supports the ideas that some gestures are produced           Hadar, U. (1989) Two types of gesture and their role in
primarily to communicate, and that speakers need to put             speech production. Journal of Language and Social
cognitive effort into producing such gestures.                      Psychology, 8, 221-228.
                                                                  Hart, S.G., & Staveland, L.E. (1988) Development of
                   Acknowledgements                                 NASA-TLX (Task Load Index): results of empirical and
We like to thank the anonymous reviewers for their                  theoretical research. In: P. Hancock, N. Meshkati (Eds.),
comments that helped us clarify this paper. We also like to         Human Mental Workload. Amsterdam: Elsevier Science.
thank Sotaro Kita for the helpful discussions on this topic       Jacobs, N., & Garnham, A. (2006) The role of
and Martin Reynaert for his technical support.                      conversational hand gestures in a narrative task. Journal
                                                                    of Memory and Language, 26, 291-303.
                         References                               Kendon, A. (2004) Gesture: Visible Action as Utterance.
                                                                    Cambridge: Cambridge University Press.
Alibali, M.W., Heath D.C., & Myers, H.J. (2001) Effects of        Keysar, B., Lin, S., & Barr, D. (2003) Limits on theory of
   visibility between speaker and listener on gesture               mind use in adults. Cognition, 89, 25-41.
   production : some gestures are meant to be seen. Journal       Kita, S. (2000) How representational gestures help
   of Memory and Language, 44, 169-188.                             speaking. In: D. McNeill (Ed.), Language and Gesture.
Alibali, M.W., Kita, S., & Young, A.J. (2000) Gesture and           Cambridge: Cambridge University Press.
   the process of speech production: We think, therefore we       Krauss, R. (1998) Why do we gesture when we speak?
   gesture, Language and Cognitive Processes, 15(6), 593-           Current Directions in Psychological Science, 7, 54-60.
   613.                                                           McNeill, D. (1992) Hand and Mind: what gestures reveal
Bangerter, A., & Chevalley, E. (2007) Pointing and                  about thought. Chicago and London: The University of
   describing in referential communication: When are                Chicago Press.
   pointing gestures used to communicate? In: I. Van der          Meligner, A & Kita, S. (2007) Conceptualisation load
   Sluis, M. Theune, E. Reiter & E. Krahmer (Eds.), CTIT            triggers gesture production. Language and Cognitive
   Proceedings of the Workshop on Multimodal Output                 Processes, 22 (4), 473-500.
   Generation (MOG), Aberdeen, Scotland, January 2007.            Mol, L., Krahmer, E., Maes, A., & Swerts, M. (2009) The
Bavelas, J., Chovil, N., Lawrie, D.A., & Wade, A. (1992)            communicative import of gesture: evidence from a
   Interactive gestures. Discourse Processes, 15, 469-489.          comparative analysis of human-human and human-
Bavelas, J., Gerwing, J., Sutton, C., & Prevost, D. (2008)          machine interactions. Gesture 9 (1), 98-126.
   Gesturing on the telephone: Independent effects of             Özyürek, A. (2002) Do speakers design their cospeech
   dialogue and visibility. Journal of Memory and                   gestures for their addressees? The effects of addressee
   Language, 58, 495-520.                                           location on representational gestures. Journal of Memory
Beattie, G., & Shovelton, H. (1999) Mapping the range of            and Language, 46, 688-704.
   information contained in the iconic hand gestures that         Wagner, S.M., Nusbaum, H, & Goldin-Meadow, S. (2004)
   accompany spontaneous speech. Journal of Language and            Probing the mental representation of gesture: is
   Social Psychology, 18, 438-462.                                  handwaving spatial? Journal of Memory and Language,
Beattie, G., & Shovelton, H. (2002) An experimental                 50, 395-407.
   investigation of some properties of individual iconic
   gestures that affect their communicative power. British
   Journal of Psychology, 93 (2), 179-72.
                                                              1574

