UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Interactional Geometry of a Three-way Conversation
Permalink
https://escholarship.org/uc/item/84k4g5hf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Battersby, Stuart A.
Healey, Patrick G.T.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                        The Interactional Geometry of a Three-way Conversation
                                               Patrick G.T. Healey (ph@dcs.qmul.ac.uk)
                                             Stuart A. Battersby (stuart@dcs.qmul.ac.uk)
                                                        Queen Mary University of London
                                                 Interaction, Media & Communication Group
                                            School of Electronic Engineering & Computer Science
                                                            London, United Kingdom
                                                                  London E1 4NS
                                Abstract                                   shared space to create three-dimensional configurations of
                                                                           gesture and head angle that have distinctive interactional ef-
   In this paper we describe patterns of spatial co-ordination that,
   we propose, are a distinctive characteristic of multi-person            fects.
   face-to-face interactions. The data come from a task in which
   participants describe some simple, non-spatial, computer code           Non-verbal Interaction
   in an instructor / learner scenario. Three participants take part;
   2 instructors and 1 learner. Using excerpts from these interac-         In the literature on non-verbal interaction there is a broad dis-
   tions we show that participants make frequent use of combi-             tinction between studies that focus on how individuals pro-
   nations of head angle, gesture and participants’ positions to           duce gestures that are integrated (or not) in various ways with
   ‘triangulate’ their contributions. We propose that these ex-
   amples show how face-to-face interaction is distinguished, in           their own speech towards a more detailed consideration of
   part, by the potential it offers for using physical space to create     how gestures are deployed in interaction.
   shared ‘interactional maps’ that provide a structured resource             Studies of speech-gesture co-ordination often use a ‘nar-
   for tracking conversational states.
                                                                           rative monologue’ paradigm in which participants re-tell a
   Keywords: multiparty; face-to-face; head angle; gaze; ges-
   ture; interaction                                                       story, typically from a video or cartoon, to camera. This pro-
                                                                           vides a controlled situation in which the relationship between
                           Introduction                                    gestures, such as metaphorics or iconics, and the content of
                                                                           the narrative can easily be analysed (e.g. McNeil (1992)).
   Embodied conversation in a shared space is the native habi-
                                                                           However it also reduces or removes effects of the interac-
tat for human interaction. It provides people with a rich va-
                                                                           tion with an addressee and the dynamics of more open-ended
riety of resources for communication that go well beyond the
                                                                           forms of interaction. Particularly clear cases of the kind of
speech signal including: body position, orientation, gesture,
                                                                           phenomena that can be missed by the story telling approach
gaze, expression, shared objects, shared spaces and the shared
                                                                           are where participants directly collaborate on the construction
environment.
                                                                           and deployment of a gesture (e.g. Furuyama (2000); Taben-
   In this paper we focus on how people deploy gestures and
                                                                           sky (2001))
head orientation in space to create shared interactional con-
                                                                              Of most interest here are the non-verbal signals which
figurations or ‘geometries’ that specifically exploit the poten-
                                                                           serve, not to convey the topic or content of the discussion, but
tial face-to-face interaction offers for the simultaneous co-
                                                                           to manage the interaction itself. This includes body posture
ordination of multiple points in space.
                                                                           (Kendon, 1990), gaze (Bavelas, Coates, & Johnson, 2002;
   We begin with a brief review of the literature on non-verbal
                                                                           Goodwin, 1979) and gesture (Bavelas, Chovile, Lawrie, &
communication and, in particular, a discussion of the kinds of
                                                                           Wade, 1992). Bavelas et al. (1992) coined the term interac-
distinctively interactional functions that have been identified
                                                                           tive gesture to refer to this class of interactive gestures. For
for gesture. Experimental evidence shows the importance of
                                                                           example, consider the following extract:
these signals for defining, amongst other things, when an in-
teraction starts and finishes, level of mutual-engagement, the               “and of COURSE there were chances that they would, uh,
roles of each participant (speaker, addressee, over-hearer),                  write something WRONG, you know”?
their relationship, the shared focus of attention, the bound-
aries of each turn and the syntactic and semantic organisation                At the same time as producing ‘you know’, the speaker
of elements within each turn (see e.g. Bavelas and Gerwing                 points to the recipient with the palm up and all fingers curled
(2007); Kendon (1970)).                                                    except the index finger. Bavelas et. al. suggest that this ges-
   We argue that although it might appear trivial to observe               ture is equivalent to the verbal ‘you know’ and means ‘do
that face-to-face interaction takes place in a shared space this           you understand what I am saying’. These gestures occur at
actually creates an additional set of communicative resources              a lower rate than those that relate to the topic of discussion
that is quite distinct from visual access per se. We go on                 and, as Bavelas et al have shown, appear to be exclusive to
to present two examples from a corpus of three-person task-                dialogue.
oriented interactions that illustrate how people naturally ex-                Goodwin (1979) (see also Bavelas et al. (2002)) de-
ploit their position with respect to their interlocutors in the            scribed how within a single turn the non-verbal actions of the
                                                                       785

speaker and the recipient(s) contribute to the incremental co-
production of the turn. For example, Goodwin showed that if
a recipient is not gazing at the speaker when the speaker gazes
at them, this normally leads to a recycling or reconstruction
of the utterance. Moreover, if an intended recipient does not
return the gaze of the speaker but a third party is gazing at
the recipient, the speaker can see the gaze between the third
party and the recipient and adjust his own gaze to be towards
the third party, upon which mutual gaze between these two
participants can be made and successful dialogue continue.                        Figure 2: Video Mediated Interaction
Shared Spaces
An intuitive response to the work cited above is to assume that
if people have visual access to each other i.e. if they can see        Perhaps the most explicitly spatial interactional configura-
each other’s gestures their communication should, all things        tions in the literature are the f-formation patterns identified by
being equal, be richer, smoother or more effective. However,        (Kendon, 1990). This refers to the orientational and postural
the extensive literature on video mediated communication            configurations of participants’ bodies during interaction, such
demonstrates that the advantage of face-to-face interaction is      that their own individual transactional segments (the area in
not due to visual access per se (e.g. Whittaker, 2003). There       front of the body in which one carries out their own, individ-
are significant differences between face-to-face interaction        ual activities) overlap to form a shared space. It is within this
and video mediated interaction. For example, participants           shared space that activities such as gesture can occur. An f-
use more words per turn when communicating over a video             formation shows that we can define an interactional unit spa-
mediated communication channel (Whittaker & O’Conaill,              tially, but also it communicates the availability and exclusivity
1993), find it harder to spontaneously take the floor requiring     of the participant to the interaction. A twisted posture (dis-
more formal handovers (Whittaker & O’Conaill, 1993; Whit-           cussed as ‘body torque’ by (Schegloff, 1998)) can signal that
taker, 2003) and gestures become exaggerated and mutated            the participant is still part of the interactional unit, but their
from their original forms (Heath & Luff, 1991). These differ-       attention is temporarily elsewhere (hence loosing the exclu-
ences are not due to technological factors such as the quality      sivity of that participant).
of the video communication channel (Whittaker & O’Conaill,             Further evidence for the interactional significance of a
1993).                                                              mutually-shared space is provided by Özyürek who examined
   The critical point for our argument is that although video       the effect of shared space upon gesture formation (Özyürek,
connections can provide high-quality, no-delay visual access        2000, 2002). She was concerned with how addressee location
to an interlocutor they are limited to collections of two-way       impacted upon the formation of gestures. Her experiments re-
peer-to-peer channels that do not reproduce the full mutually       quired a participant to recall a scene from a cartoon in which
shared space available in face-to-face interaction. This point      a cat was thrown out of a window to either one or two ad-
is illustrated schematically in Figures 1 and 2. Our claim          dressees. In the single addressee condition, the addressee
is that the effectiveness of non-verbal communication tech-         was to the side of the speaker wheres in the two addressee
niques depends not only upon visual access, but also on their       condition they were placed in a V formation (so in front and
deployment in a mutually accessible shared space.                   to the sides of the speaker). It was found that instead of the
                                                                    ‘out’ gesture being the same for each formation, it was ad-
                                                                    justed for each such that the ‘outwards’ action was out of the
                                                                    shared interactional space. Although this study was not fo-
                                                                    cussed on interactive gestures it shows that participants treat
                                                                    the shared space, or f-formation, defined by their collective
                                                                    body position and orientation as region with special interac-
                                                                    tional significance.
                                                                       This point is especially important for multiparty interac-
                                                                    tion. With the higher number of participants it is spatially
                                                                    more complex, and as the participants are not able to form a
                                                                    standard viz-a-viz formation, the interaction makes use more
                                                                    often of areas which are not in the space directly between par-
                                                                    ticipants. There is also an added layer of complexity involv-
                                                                    ing mutual knowledge and awareness; two or more people
                                                                    are able to be aware of something in the interaction, whilst
               Figure 1: Face to Face Interaction                   there are others who remain unaware. If we refer back to the
                                                                    discussion of Goodwin’s work on gaze, we see that what is
                                                                786

important is that the speaker can see that the third party is        Participants: To ensure familiarity with Java all the par-
gazing at the inattentive recipient. Over a video channel, this      ticipants were recruited from amongst Computer Science un-
spatial aspect is lost and as such any interactional implica-        dergraduate or postgraduate students at Queen Mary. Three
tions of this are also lost.                                         groups of three participants produced the data reported here.
   We turn now to consider some examples of spatial co-              All groups were arranged by the experimenter and consisted
ordination of gesture, head orientation and participant loca-        of 7 male and 2 female participants, aged between 20 and 30.
tion in a small corpus of 3-way interactions.
                                                                                    Using Space in Interaction
                            Methods                                  Overall the three groups of participants produced a total cor-
The Augmented Human Interaction (AHI) lab at Queen Mary              pus of 25mins 15secs of video and 3D motion capture record-
houses an optical motion capture system. The system consists         ings with the average length of each round of 2 mins 48secs.
of an array of infra-red cameras and, by attaching reflective           Our primary focus here is on patterns of interaction in this
markers to the bodies of participants, we are able to track          sample that are constitutively spatial in character i.e., that
their movements in three dimensional space through the mo-           make direct use of the potential face-to-face interaction offers
tion capture system. This technology allows us to analyse the        for co-ordinating multiple communicative resources in space.
participants’ movements in more detail than traditional video        Before moving on to this we first provide a brief overview of
alone as we have the precise 3D coordinates of discrete seg-         the way participants approached the task and their general use
ments of the body which preserves the spatial nature of the          of gesture and body orientation.
interaction. This three dimensional data can be reconstructed           In a typical round one instructor would take the lead in
as wireframe representations of the body and analysed along          describing the code to the learner, checking with the other
with video and audio data (see Battersby, Lavelle, Healey, and       instructor at various points and occasionally directly inviting
McCabe (2008) for more detail). In the current study these           comments or elaboration from them. The ‘second’ instructor
have been used to aid in the analysis, however the data is dis-      would sometimes interject during these expositions or, more
played as images from traditional video. Three camera angles         often, provide additional clarification or elaboration at the end
were used, one above and one either side of the participants.        of the exchange. Both instructors’ head orientation and con-
                                                                     tributions during these explanations were predominantly ori-
Task Description: The data reported here is is drawn from            ented towards the learner, even when not taking a primary role
a corpus of exploratory studies of multi-party interaction           in the explanation. However, during checks or interjections
which have taken place in the AHI lab. In these studies three        the instructors would normally briefly orient to each other
participants take part in three rounds of collaborative inter-       before returning their attention to the learner. The learners
action. On each round two participants, the ‘instructors’, are       typically adopted a relatively passive role. Sometimes asking
given one printed copy of a Java application with its associ-        for clarification during the initial explanation but more often
ated class hierarchy. Each class is printed on a separate sheet      waiting until the instructors signaled that their description of
of paper. Before the round begins the instructors are asked          the code was complete. Learners would then read back there
to discuss the code together, make sure they both understand         understanding of what had been presented with both instruc-
it and then return the printed code to the experimenter. The         tors providing feedback.
third participant, the ‘learner’ then joins them and they sit on
pre-positioned stools in a circle (see e.g. Figure 3).               Simple Uses of Gesture and Orientation
   The instructors then have as long at they like to explain         During these interactions the speaker (instructor or learner)
the code to the learner, notifying the experimenter when they        produced most of the gestures and the silent participants nor-
are satisfied that the tuition is complete. No restrictions are      mally kept their hands resting on their knees or in their lap
placed on how they explain the code, or on the interaction           (see e.g. Figure 4 and Figure 5).
other than they must not use pen and paper. To provide par-             A common feature of gesture in these interactions was in-
ticipants with a criterion of understanding and to assess the        structors would use different spatial locations between the
learners comprehension at the end of each round the learner          participants to represent different elements of the hierarchy.
was asked to reassemble the hierarchy on their own using a           These iconic gestures were not only restricted to a personal
drag and drop interface on a laptop.                                 gesture space in front of the speaker, but in some cases also
   Three different Java class hierarchies were created: ‘Stu-        extended into the shared interaction space.
dent’, ‘MP3 Player’ and ‘Retailer’. These materials were de-            Figure 3 illustrates an example of the learner sharing an
signed to embody hierarchical relationships but without in-          iconic gesture space directly with an instructor. One instruc-
volving any simple spatial relations (such as those involved         tor has his back to the camera, with his fellow instructor to
in describing a route or the layout of a kitchen). A different       his left and the learner in front of him. This image shows
set of Java materials is used on each trial, with order of pre-      the instructor drawing out the hierarchy, and the learner co-
sentation controlled across groups of participants, and roles        referencing this hierarchy (see Furuyama (2000) for similar
are systematically changed so that each participant acts as the      examples from instructional dialogues). Notice that here the
learner once.                                                        participants are using the shared gesture as the spatial frame
                                                                 787

of reference and not, for example, their own body centered           and undergraduate”. At the start of this turn he is facing the
co-ordinates which would involve a left-right reversal of the        learner and not gesturing but as he reaches “masters” he cre-
hierarchy.                                                           ates a left handed palm up gesture towards Instructor 1 while
                                                                     maintaining shared gaze with the learner.
                Figure 3: Shared Gesture Space
                                                                       Figure 4: Divergent Orientation of head angle and Gesture
   In addition to these primarily iconic gestures, participants         A more complex example that illustrates the third possi-
also used familiar non-verbal interactional cues. For exam-          bility is provided by the sequence illustrated in Figures 5,
ple, using their gaze (both with and without accompanying            6 and 7. Here, Instructor 1 (female, white cap) is explain-
speech) to address people, seek confirmation and seek clarifi-       ing some of sections of code (methods) which are part of the
cation and using interactive gestures such as short hand flicks      Playlist class to the learner (male, black cap). As she does
to reference another person while speaking (see e.g. Bavelas         this she gestures with both hands; the left hand is held out be-
and Gerwing (2007); Kendon (1970)).                                  tween her and the learner with her fingers extended, the right
                                                                     hand is counting along the fingers (by pointing at them) as
Triangulated Uses of Gesture and Orientation                         she lists each method. She is also looking (gazing) towards
The discussion so far has highlighted the use of gesture and/or      the learner. The learners hands are resting on his legs and he
orientation in a shared space and the parallels with previous        is back channeling verbally and with head nods. The second
work on non-verbal interactions described in the introduction.       instructor (male, blue cap) is looking towards the learner but
We turn now to patterns of non-verbal interaction that make          not gesturing or speaking.
essential use of the spatial arrangement of participants. In
the context of this task these patterns most commonly oc-
curred where participants engaged a third party, typically the
other instructor, while addressing a second party, typically the
learner. We gloss these patterns of simultaneous engagement
as moments of triangulation to highlight the way that they
make direct use of the mutually-known spatial arrangement
of the three participants in space.
   Restricting our attention to head and gesture orientation
there are three basic spatial possibilities: 1) the speaker ori-
ents to the third-party with a gesture while continuing to ori-
ent to the addressee with their head; 2) the speaker orients to
the addressee with a gesture and orients to the third party with
their head or 3) the speaker uses a combination of head and                      Figure 5: Listing Methods to the Learner
gesture orientation to the third party.
   An example of the first of these three possibilities is given        She continues her list with “add to track” but then initiates
in Figure 4. Here Instructor 1 is in the middle of the scene         a repair on this to change it to “add track”. In the middle of
facing the camera. On the left of the image is Instructor 2,         this repair she poses the question “is it add track”. As she
and on the right of the image is the learner. Prior to this sit-     says this her gesture & head configuration changes; her head
uation, Instructor 2 had described the class hierarchy to the        turns towards Instructor 2, and her right hand moves from
learner. Instructor 1 then takes over and explains how the           being a counter on the left hand to a point in the direction
application works and makes use of the classes described by          of Instructor 2. Instructor 2 responds by changing his head
Instructor 2 saying “l-lower hierarchy classes like the masters      orientation towards Instructor 1. Note, however, Instructor 1
                                                                 788

                                                                          add track yeah”. As her right handed point comes into the
        Table 1: Excerpt from Example 2 “Add track”
                                                                          space between herself and the learner her left hand drops from
Instructor 1: “add play playlist” (0.1) (Fig. 5)
                                                                          its holding position, the learner turns his gaze back towards
Head: Towards the learner, angled down slightly
                                                                          her and the instructional dialogue continues. It is worth em-
Gesture: Left hand is between herself and the learner with
                                                                          phasizing the fact that it is only after Instructor 1 turns her
fingers extended. Right hand is counting along the left hand’s
                                                                          right handed point back towards the learner that left handed
fingers with a pointing gesture
                                                                          ’hold’ gesture is dropped.
Instructor 1 : “add to track” (0.1)
Instructor 1: “is1 it add track”2 (0.3) (Fig. 6)
Head1&2 : Turns from learner to face Instructor 2
Gesture2 : Left hand stays stationary between herself and
learner, right hand moves to be placed between herself and
Instructor 2, pointing towards Instructor 2
Instructor 1: “I think1 add track”2 (Fig. 7)
Head1 : Turns from Instructor 1 to face the learner
Gesture1 : Right handed point turns in an arced motion
around her body to be placed between herself and the
learner, now pointing at the learner. Left hand remains in
place.
Gesture2 : Left handed gesture ends and rests on the leg.
                                                                                                  Figure 7: Resume
                                                                             Our claim is that this example illustrates how participants
continues to hold the floor, actually answering the question              can make simultaneous use of two different spatial orienta-
herself as she turns her head back to the Learner (Figure 7).             tions, in this case involving two gestures with different forms
   During this sequence her left ‘list’ hand maintains it’s po-           and orientations to the co-instructor and to the Learner, as a
sition and shape between herself and the learner. Thus, al-               resource for managing the interaction. In particular, as a re-
though she has temporarily changed orientation to her co-                 source for understanding the incremental structure of the turn
instructor, it appears natural to interpret her left hand as help-        under construction and the varying status of each participant
ing to maintain both the relevance of the business of listing             with respect to those increments (cf. (Goodwin, 1979))
the methods while the repair is completed and to maintain the             The Distribution of Triangulations
fact that this list, unlike the repair that is part of it, is primar-
                                                                          In order to get a better understanding of the distribution of
ily addressed to the Learner. The effect is one of keeping the
                                                                          these patterns of triangulation the video recordings were tran-
conversation between herself and the Learner ‘on hold’ and
                                                                          scribed and coded using Elan. All occurrences where partic-
limiting the rights of the co-instructor to take the floor.
                                                                          ipants created one of these configurations of gaze and ges-
                                                                          ture were coded. The coding focussed only on situations
                                                                          where there was a visible change in the orientation of the
                                                                          head and/or hands of the speaker relative to the other partici-
                                                                          pants during the production of a turn and not at turn comple-
                                                                          tion points or during explicit hand-over of the floor. In these
                                                                          cases we coded whether the gesture and/or head orientation
                                                                          changed or maintained. We did not include cases if only the
                                                                          head moved whilst the hands were ‘resting’, either placed on
                                                                          the knees or clasped together in the lap and not gesturing
                                                                             This coding yielded 61 cases of triangulation of which 44
                                                                          were where the hands and head had divergent orientations and
                                                                          17 where they were combined. This indicates that this use of
                                                                          shared space, at least in the kinds of interaction we studied is
               Figure 6: Repairing “Add to track”                         relatively common with one instance of an observable trian-
                                                                          gulation occurring approximately every 25 seconds of inter-
   Instructor 1 answers her own question with “I think add                action.
track” as she completes “think” she synchronously turns her                  It is also clear from this data that there is a systematic
gaze and point (in a slightly arced trajectory around herself)            contrast in the significance of these movements for the pri-
towards the Learner. As she is doing this, i.e. after she has             mary addressee and the third party. In 63% of cases the third
turned away, the co-instructor confirms her repair with “yeah             party responds to the change of orientation by turning away
                                                                      789

from the primary addressee and towards the speaker. By con-           Furuyama, N. (2000). Gestural interaction between the in-
trast the primary addressee changes orientation away from the           structor and learner in origami instruction. In D. McNeil
speaker (and towards the third party) in only 16% of cases.             (Ed.), Language and gesture (p. 99-117). Cambridge Uni-
                                                                        versity Press.
                          Conclusion                                  Goodwin, C. (1979). The interactive construction of a sen-
The central claim of this paper is that people use their phys-          tence in natural conversation. In G. Psathas (Ed.), Every-
ical arrangement in space during multi-party interactions as            day language: Studies in ethnomethodology (p. 97-121).
an additional specialised resource for communication. More              Irvington Publishers.
specifically, that the mutually-known arrangement of partici-         Heath, C., & Luff, P. (1991). Disembodied conduct: Com-
pants, gestures and orientation in physical space can be used           munication through video in a multi-media office environ-
to create and manage what amount to ‘interactional maps’ of             ment. Conference on Human Factors in Computing Sys-
how each contribution is constructed, maps of the relation-             tems, Proceedings of the SIGCHI conference on Human
ships between different contributions (and elements of con-             factors in computing systems: Reaching through technol-
tributions) and maps of different people’s stance toward or             ogy, 99-103.
participant role with respect to those contributions.                 Kendon, A. (1970). Movement coordination in social inter-
   As the contrast with video-mediated communication high-              action: Some examples described. Acta Psychologica, 32,
lights, this is more than a matter of being able to see the other       100-125.
participants. It critically depends on the fact that the partic-      Kendon, A. (1990). Conducting interaction: patterns of be-
ipants are in the same shared space and that they mutually              havior in focused encounters. University of Cambridge.
know this is the case.                                                McNeil, D. (1992). Hand and mind: What gestures reveal
                                                                        about thought. University of Chicago Press.
   The evidence from the present study suggests that when
                                                                      Özyürek, A. (2000). The influence of addressee location
people have the opportunity they naturally make extensive
                                                                        on spatial language and representational gestures of direc-
use of this potential. We can only speculate on the func-
                                                                        tion. In D. McNeil (Ed.), Language and gesture (p. 64-83).
tion of these different interactional geometries but our study
                                                                        Cambridge University Press.
minimally suggests that they support, amongst other things,
                                                                      Özyürek, A. (2002). Do speakers design ther cospeech ges-
references to locations as representative of prior turns and
                                                                        tures for their addressees? the effects of addressee location
as representative of the producers of those turns. They also
                                                                        on represetational gestures. Journal of Memory and Lan-
support patterns of turn management, helping participants to
                                                                        guage, 46, 688-704.
keep sub-dialogues visually (as well as structurally and se-
                                                                      Schegloff, E. A. (1998). Body torque. Social Research, 65,
mantically) distinct.
                                                                        535-596.
   We have described these configurations as constitutively
                                                                      Tabensky, A. (2001). Gesture and speech rephrasings in con-
spatial. What we mean by this is that they involve a use of
                                                                        versation. Gesture, 1:2, 213-235.
space that could not, in principle, be reproduced, for mutli-
                                                                      Whittaker, S. (2003). Theories and methods in mediated
party interactions using point-to-point video. This may help
                                                                        communication. In A. C. Graesser, M. A. Gernsbacher, &
to explain the paradoxical finding in the literature that, while
                                                                        S. R. Goldman (Eds.), Handbook of discourse processes (p.
face-to-face is clearly better than audio only interaction, there
                                                                        243-286). Lawrence Erlbaum Associates Inc.
is little or no difference between video and audio only. It ap-
                                                                      Whittaker, S., & O’Conaill, B. (1993). An evaluation of video
pears that it is not the visual channel per se but the shared
                                                                        mediated communication. In Chi ’93: Interact ’93 and chi
space itself which provides the critical interactional advan-
                                                                        ’93 conference companion on human factors in computing
tage.
                                                                        systems (pp. 73–74). New York, NY, USA.
                          References
Battersby, S. A., Lavelle, M., Healey, P. G., & McCabe, R.
   (2008, May). Analysing interaction: A comparison of 2d
   and 3d techniques. In Conference on multimodal corpora.
   Marrakech.
Bavelas, J. B., Chovile, N., Lawrie, D. A., & Wade, A.
   (1992). Interactive gestures. Discourse Processes, 15, 469-
   489.
Bavelas, J. B., Coates, L., & Johnson, T. (2002). Listener re-
   sponses as a collaborative process: The role of gaze. Jour-
   nal Of Communication, 52, 566-580.
Bavelas, J. B., & Gerwing, J. (2007). Conversational hand
   gestures and facial displays in face-to-face dialogue. In
   K. Fiedler (Ed.), Social communication. Psychology Press.
                                                                  790

