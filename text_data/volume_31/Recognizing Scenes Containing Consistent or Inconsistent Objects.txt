UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Recognizing Scenes Containing Consistent or Inconsistent Objects
Permalink
https://escholarship.org/uc/item/9q28n6nq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Mack, Michael
Palmeri, Thomas
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

               Recognizing Scenes Containing Consistent or Inconsistent Objects
                                        Michael L. Mack (michael.mack@vanderbilt.edu)
                                       Department of Psychology, 111 21st Avenue South
                                                    Nashville, TN 37240 USA
                                      Thomas J. Palmeri (thomas.j.palmeri@vanderbilt.edu)
                                       Department of Psychology, 111 21st Avenue South
                                                    Nashville, TN 37240 USA
                            Abstract                               Indeed, Davenport and Potter (2004) found that scene
                                                                   categorization was facilitated when the scene contained a
How does object perception influence scene perception? A
                                                                   consistent object (e.g., a football field with a football player)
recent study of ultrarapid scene categorization (Joubert et
                                                                   compared to an inconsistent object (e.g., a football field
al., 2007) reported facilitated scene categorization for scenes
                                                                   with a priest).
with consistent objects compared to scenes with inconsistent
                                                                      A recent study (Joubert, Rousselet, Fize, & Fabre-Thorpe,
objects. One proposal for this consistent-object advantage
                                                                   2007) reported a similar advantage for scenes containing
is that ultrarapid scene categorization is influenced directly
                                                                   consistent objects versus inconsistent objects in ultrarapid
by explicit recognition of particular objects in the scene. We
                                                                   scene categorization. Participants were presented with
instead asked whether a simpler mechanism that relied only
                                                                   scenes for only 26ms and performed a go/no-go decision
on scene categorization without any explicit object
                                                                   about the scene’s superordinate category (natural or man-
recognition could explain the consistent-object advantage.
                                                                   made). As illustrated in Figure 1, scene images either
We combined a computational model of scene recognition
                                                                   contained objects consistent with the scenes’ category (e.g.,
based on global scene statistics (Oliva & Torralba, 2001)
                                                                   an urban street scene with a parked car) or contained objects
with a diffusion model (Ratcliff, 1978) of perceptual
                                                                   inconsistent with the scenes’ category (e.g., an urban street
decision making. Simulations show that this model is
                                                                   scene with a large tree). A post-hoc analysis comparing
sufficient to account for the consistent-object advantage.
                                                                   these two types of scenes showed a consistent-object
Importantly, this effect need not arise from explicit object
                                                                   advantage such that participants made fewer errors and were
recognition, but from the inherent influence certain objects
                                                                   faster to respond when categorizing a scene containing a
have on the global scene statistics diagnostic for scene
                                                                   consistent object. Joubert et al. explained this consistent-
categorization.
                                                                   object advantage with the interacting, dual-system account:
   Keywords: scene categorization; object recognition              Information extracted by the object recognition system
                                                                   influences the rapid processing and categorization decision
                       Introduction                                by the scene perception system. For a scene containing an
What is the relationship between scene perception and              inconsistent object, the object information conflicts with the
object perception? Past research has examined how objects          evidence for the scene’s category, leading to more errors
are recognized in consistent or inconsistent scenes (e.g.,         and slower reaction times.
Biederman, Mezzanotte, & Rabinowitz, 1982; Davenport &                Previous work has shown that ultrarapid scene
Potter, 2004; Palmer, 1975). The general finding is that it is     categorization is largely determined by coarse, global scene
easier to recognize objects in semantically consistent scenes,     properties (Oliva & Schyns, 1997; Schyns & Oliva, 1994).
such as recognizing a toaster in a kitchen compared to             Furthermore, computational models that represent scenes
recognizing a toaster in a bedroom (Davenport & Potter,            based on their global spatial structure are sufficient for
2004; Henderson & Hollingworth, 1999; Palmer, 1975).               ultrarapid scene categorization (Oliva & Torralba, 2001).
   One proposed mechanism for facilitated recognition of           Importantly, such models capture only the diagnostic global
objects contained in consistent scenes is an interacting, dual     features of scenes without explicitly representing any local
system account (Davenport, 2007; Davenport & Potter,               content of the scene, such as the location, presence, or
2004). At the same time that the object recognition system         identity of particular objects (Greene & Oliva, 2009). The
is extracting information for an object categorization, the        feature set used by these models is based on global image
scene perception system is extracting evidence for a scene         statistics calculated across the entire scene, such as the
categorization. Object and scene perception systems operate        scene’s spatial frequency content.
in parallel, sharing information and converging on a full             A possibility suggested by the Joubert et al. (2007) results
description of the environment, facilitating categorizations       is that ultrarapid scene categorization based on global image
that are consistent with one another.                              properties is influenced in some way by ultrarapid
   The interacting, dual-system account is supported by            categorization of particular objects in the scene that are
evidence for scene perception facilitating object recognition.     either consistent or inconsistent with the scene’s category.
Of course, the converse should be the case as well. Scene             We instead asked whether the consistent-object advantage
recognition can also be influenced by object perception.           could be explained by a simpler mechanism that relied only
                                                               2528

on scene categorization without any explicit object
recognition whatsoever.
   Consider a forest scene. A small shed in that scene would
be considered an inconsistent object. We could replace that
shed with a consistent object, say a large bush. The global
image statistics of a forest scene with a small shed will only
be slightly different from those of a forest scene with a large
bush. But they will not be identical. And that’s the key.
While perhaps quite small, is the difference in image
statistics between scenes containing consistent objects
versus scenes containing inconsistent objects sufficient to
account for the consistent-object advantage? If so, then the
consistent-object      advantage     in    ultrarapid    scene
categorization can be explained by scene categorization
alone, without any explicit object recognition.
   To explore this possibility, we combined a computational
model of scene recognition based solely on global scene
statistics (Oliva & Torralba, 2001) with a diffusion model
(Ratcliff, 1978) of perceptual decision making.
Interpretation of global scene statistics provides evidence           Figure 1: Examples of scene stimuli. Natural scenes (left)
that drives a stochastic diffusion of perceptual evidence to a         and man-made scenes (right) are shown with consistent
decision threshold. The model aims to explain both response             objects (top) and inconsistent objects (bottom). Color
probabilities and reaction time distributions for categorizing                    images were used in Experiment 1.
scenes containing consistent or inconsistent object. The
model includes no explicit object recognition.                      Procedure Participants performed a go/no-go categorization
   This paper is organized as follows: We first attempt a           task with target “go” category (natural or man-made scene)
replication of the consistent-object advantage in scene             randomized for each participant. On each trial, a fixation
categorization. We then analyze the behavioral data using           cross was presented for 500-800ms followed by a brief
the pure diffusion model, for reasons that will be made             presentation of the scene image for 26ms. Participants were
apparent. Finally, we present fits to observed data of our          instructed to press the response key if the scene belonged to
computational model combining a scene categorization                the target category and withhold any response otherwise.
front-end with the diffusion model of decision making.              Responses could be made for 1000ms after onset of the
                                                                    scene image and any responses made after this time window
                 Behavioral Experiment                              were considered no-go responses. The trial concluded with
This experiment attempted to replicate Joubert et al. (2007).       a 500ms blank period before the next trial began.
                                                                       The experiment consisted of two blocks of 192 trials with
Methods                                                             an even split of target and distractor trials. Scene images
Participants Fifty Vanderbilt University undergraduate              used as target trials for half of the participants served as
students (twenty-four male; age 18-23 years) participated in        distractors for the other half of participants. The entire
the experiment for course credit.                                   experiment lasted approximately 25 minutes.
Stimuli The stimuli consisted of color images of naturalistic
                                                                    Results
scenes from an online image database (Oliva & Torralba,             Performance was analyzed separately by target category
2001). Scene images were divided into categories of natural         (natural and man-made) according to accuracy and reaction
and man-made environments. The natural scene category               times for correct responses (see Figure 2). Both target
included images of beaches, fields, mountains, and forests          category groups showed a consistent-object effect, with
and the man-made scene category included images of                  higher accuracy for scenes containing consistent objects
skyscrapers, urban cities, and streets. Two independent             compared to inconsistent objects; this effect was larger for
observers tagged scenes that contained a salient object that        the natural scene group (11.6% difference; paired Wilcoxon
was consistent or inconsistent with the scenes’ natural or          test: Z=4.17, p<0.001) than the man-made scene target
man-made category (reliability = 0.93). 192 natural scenes          group (1.4% difference; Z=2.648, p=0.008). Both groups
(64 with inconsistent objects) and 192 man-made scenes (64          also showed a consistent-object effect in mean reaction
with inconsistent objects) were randomly selected from the          times, with faster responses to scenes containing consistent
database for the experiment. Scene images were presented            objects; the effect was larger for the natural scene group
in color and subtended 10.2°10.2° of visual angle.                 (28ms difference; Z=4.167, p<0.001) than the man-made
Example stimuli are shown in Figure 1.                              scene group (10ms difference; Z=2.435, p=0.015).
                                                                2529

                                                                     boundary diffusion model, with one boundary for a go
                                                                     response and the other boundary for a no-go nonresponse.
                                                                        Before combining the diffusion model with a scene-
                                                                     recognition front end, we wanted to use the pure diffusion
                                                                     model as a data analysis device in order to pinpoint the
                                                                     source of the consistent-object advantage in accuracy and
                                                                     reaction time. First, the consistent-object advantage could
                                                                     arise from a differences in the time to perceptually process
                                                                     and encode scenes containing consistent versus inconsistent
                                                                     objects, which could be reflected by a difference in the Ter
                                                                     parameter. Second, recognizing consistent versus
                                                                     inconsistent objects might bias the decision process, leading
     Figure 2: Average accuracy (left) and RT for correct            to a potential difference in the decision threshold of the
      responses (right) for consistent-object scenes (dark           accumulation process (the a parameter). Third, our
  columns) and inconsistent-object scenes (light columns).           hypothesized simple single process account might suggest
        Error bars represent 95% confidence intervals.               that the consistent-object advantage will arise from a
                                                                     difference in the quality of the perceptual evidence (the drift
Discussion                                                           rate, v) driving the accumulation process.
We replicated the consistent-object advantage found by
Joubert et al. (2007). For both man-made or natural scene
targets, scenes with consistent objects were categorized
faster and with fewer errors than scenes with inconsistent
objects. The consistent-object advantage was larger for
natural scenes, but this may be explained by stimulus factors
as we did not attempt to equate the natural and man-made
scene images in terms of visual properties or similarity.
               Diffusion Model Analysis
   The diffusion model is a well-known model of perceptual            Figure 3: The diffusion model. At starting point z, evidence
decision making (Ratcliff, 1978). Decisions are made                 accumulates at drift rate, v, towards decision bounds defined
through a stochastic accumulation of noisy evidence over                by a and 0. Overall reaction time is given by the time of
time toward a decision threshold (see Figure 3). The rate of             accumulation plus time for non-decision factors (Ter).
accumulation (called the drift rate, v) is determined by the
quality of the perceptual evidence. Higher quality evidence
leads to faster accumulation and faster reaction times.              Model Fitting
Changing the decision threshold (a) affects the tradeoff             The diffusion model was fitted to reaction time distributions
between speed and accuracy. Overall reaction time is given           using standard techniques (see, Ratcliff & Tuerlinckx,
by the time for the perceptual decision made by the                  2002). For each individual participant, RT data for scenes
diffusion plus time for non-decision factors (Ter), such as          containing consistent versus inconsistent objects were
stimulus encoding and motor response. Furthermore, in the            grouped into 6 RT bins defined by the 0.1, 0.3, 0.5, 0.7, and
full diffusion model, variability in drift rate, starting point,     0.9 quantiles. Quantile RTs averaged across participants
and nondecision time can be present and allow for the                were then used to generate predicted cumulative
diffusion model to account for more detailed patterns of             distributions of response probabilities (Vandekerckhove &
reaction time distributions.                                         Tuerlinckx, 2007, 2008). Best-fitting model parameters
   The diffusion model is typically applied to two-alternative       were found using the SIMPLEX method that minimized the
forced-choice categorization. A recent study compared                Pearson chi-square for the observed versus predicted
different versions of the diffusion model to account for             number of RTs within each RT bin (an additional bin was
go/no-go categorization (Gomez, Ratcliff & Perea, 2007).             included in the fitting to count the number of no-go
They tested two versions of the diffusion model, one where           responses). The full diffusion model is defined by seven
evidence accumulates towards a single decision boundary              parameters: starting point of the accumulation process and
for the “go” response with the other boundary at negative            its variability (z, sz), decision threshold (a), drift rate and its
infinity, and another where evidence accumulates to both             variability (v, nu), and the nondecision time and its
“go” (explicit response) and “no-go” (no response)                   variability (Ter, st). For our model fits, starting point (z=a/2)
boundaries. The two-boundary model was found to provide              and its variability, variability of drift rate (nu), and
the best account of behavior associated with several go/no-          variability of nondecision time (st) were held constant across
go categorization tasks (Gomez et al., 2007). Therefore, we          the consistent and inconsistent conditions. We fitted
modeled the go/no-go scene categorization using a two-
                                                                 2530

versions of the diffusion model where the three key                                Scene Categorization Model
parameters, decision threshold (a), nondecision time (Ter),
                                                                     To test this further, we extended a successful model of scene
and drift rate (v), were either free to vary or were held
                                                                     categorization (Oliva & Torralba, 2001). Their model is the
constant across the consistent and inconsistent conditions.
                                                                     perceptual front-end that extracts evidence for a scene’s
                                                                     category that then drives the diffusion model of decision
Results
                                                                     making. Specifically, the scene categorization model
The variant of the diffusion model with only drift rate as a         establishes the drift rate of the diffusion process, rather than
free parameter provided a significantly better fit to the            allowing the drift rate to be a free parameter.
behavioral data than variants with only nondecision time or
decision threshold as a free parameter. Table 1 shows                Model Description
values for the chi-square statistic and the appropriate
                                                                     We started with a scene categorization model developed by
significance tests for each version of the diffusion model.
                                                                     Oliva and Torralba (2001). In this model, scenes are
                                                                     represented by a set of features that describe the global
                 Table 1: Diffusion model fits
                                                                     spatial structure of the scene (Greene & Oliva, 2009; Oliva
                                                                     & Torralba, 2001). The feature space, known as the spatial
    Free parameters       Chi-square               p                 envelope, is defined by measures of global shape properties
        All fixed           5.318                  --                that are extracted using a bank of Gabor filters of varying
            a               2.746         0.109 (vs. fixed)          spatial scale and orientation.
           Ter              3.645         0.196 (vs. fixed)             We followed the procedure outlined by Oliva and
                                                                     Torralba (2001). A bank of Gabor filters spanning four
            v               1.346         0.046 (vs. fixed)          spatial scales and eight orientations were used to extract the
                                                                     scenes’ global features. To reduce the dimensionality of the
                                                                     filter responses, each filter output was down-sampled to a
Discussion                                                           lower-resolution (4x4) summary. PCA was then used to
Diffusion model analyses of the data from Experiment 1               further reduce the dimensionality creating a final scene
revealed that a model with a separate drift rates for the            representation consisting of a 50-element vector. Natural
consistent and inconsistent object condition provided the            versus man-made scene categories were defined by a
best account of the behavioral data. Allowing a freely               hyperplane boundary extracted using linear discriminant
varying nondecision time did not provide a good fit,                 analysis (see Figure 4).
suggesting that the time necessary for scene encoding was               We used the results of the linear discriminant function to
not affected by the consistency of the embedded object. The          establish the drift rate of the diffusion model for each scene
consistent-object advantage is best accounted for by                 image to be categorized. Specifically, for a given scene, the
assuming that the quality of the perceptual evidence is              output of the linear classifier corresponds to the distance of
affected by the presence of an inconsistent object.                  that scene from the boundary separating natural versus man-
                                                                     made scenes. The sign of the distance signifies which
                                                                     category the scene is classified in and the magnitude of the
       Figure 4: The extended scene categorization model. Scenes are first classified by the scene categorization front-end.
      The scene’s global spatial frequency is extracted with a bank of Gabor filters (a - polar plot of global spatial energy,
        spatial scale and orientation of filters shown by ellipses) and summarized into a low-resolution representation (b -
    subimages in the 4x4 grid show the global energy at that spatial location). Scene representations are projected onto a 50-
    dimensional principal component space and classified by linear discriminant analysis. The resulting classification value
                       drives a stochastic accumulation of evidence towards go or no-go response boundaries.
                                                                2531

distance represents the quality of that classification.             Results
Distance is transformed into drift rate with a sigmoid              Performance was analyzed separately by target category
function that includes a scaling parameter. Using that drift        (natural and man-made) according to accuracy and reaction
rate, the decision process is carried out by the diffusion as a     times for correct responses across simulation repetitions (see
stochastic accumulation of evidence to a threshold.                 Figure 5). The model showed a consistent-object effect only
   We want to emphasize that this model assumes no                  when the target was a natural scene. Accuracy was higher
parameters that vary across scenes containing consistent            (Z=4.24, p<0.001) and reaction times were faster (Z=4.37,
versus inconsistent objects. The scene categorization front-        p<0.001) for consistent-object scenes compared to
end uses the same discriminant function for scenes with             inconsistent-object scenes. With man-made scenes as the
consistent and inconsistent objects. Distance from the              target, mean differences in both accuracy and reaction time
discriminant function is transformed into drift rate using the      trended in the manner of a consistent-object advantage, but
same function for all scenes. The diffusion process                 did not reach significance (Z=0.977, p=0.328; Z=1.44,
determining the time-course of the decision is the same for         p=0.15); recall that the difference observed for human
all scenes. It should also be clear that the model contains no      subjects was also quite small.
explicit object recognition process. Scenes are represented
by global features that capture the scene’s spatial frequency
structure. The only difference between scenes containing
consistent versus inconsistent object is in the global content,
not recognition of any individual objects in the scenes.
Simulation Method
First, a set of 200 natural and 200 man-made scene images
were randomly selected from the scene database (same as
used in Experiment 1) for creating the PCA. A fifty-
dimensional principal component space was extracted from
these scenes’ Gabor-filtered representations and saved for
the simulations. Next, a training set consisting of another
100 natural and 100 man-made scenes was randomly
                                                                      Figure 5: Simulation results. Average accuracy (left) and
selected from the scene database. These scenes were passed
                                                                      correct response RTs (right) for consistent (dark columns)
through the Gabor filters, projected into the principal
                                                                            and inconsistent (light columns) object scenes.
component space, and used to train the linear discriminant
classifier.                                                         Discussion
   The scene database we used had fewer inconsistent-object
scenes compared to consistent-object scenes, since by               Simulations of ultrarapid natural scene categorization with
definition, inconsistent objects are not typically found in         the extended scene categorization model showed a
those scenes. In order to test an equivalent number of scenes       significant consistent-object advantage for categorizing
with consistent and inconsistent objects, we randomly               natural scenes as targets and a small (but not significant)
selected 500 consistent object scenes and inconsistent object       advantage for man-made scenes; this difference across
scenes with replacement from the scene database. Scenes             target scene category is qualitatively comparable to what
used for training were never included in the testing sets.          was observed in Experiment 1. These initial simulations
Test trials consisted of first passing a scene through the          suggest that the global features extracted by the perceptual
scene categorization front-end. This stage generated a              front-end of our model were influenced by the presence of
classification value from the discriminant function that was        an inconsistent object. This subtle influence may be
transformed into a drift rate for the diffusion. The drift rate     sufficient to explain the lower accuracy and slower reactions
drove the stochastic accumulation of evidence until a               times associated with scenes containing inconsistent objects.
decision threshold (go or no-go) was reached or 1000ms had
elapsed (tallied as a no-go response).                                                      Conclusions
   The three parameters of the model (drift rate scaling            The aim of our work was to test whether the consistent-
factor, decision threshold, nondecision processing time)            object advantage observed by Joubert et al. (2007) could be
were optimized by fitting the predicted reaction time               explained using global scene categorization mechanisms
distributions to the observed data using the same procedure         without object recognition. By this account, semantically
used in the earlier diffusion model analysis. We tested the         inconsistent objects in scenes can influence the global
model’s performance with both natural and man-made                  perceptual evidence diagnostic for scene categorization
scenes as targets. The entire simulation procedure was              without any explicit recognition of consistent versus
repeated with twenty-five separate training and testing sets.       inconsistent objects in the scene.
                                                                       Consistent with this simple scene categorization account,
                                                                    we presented evidence from a diffusion model analysis that
                                                                2532

suggests a difference in the quality of the perceptual            Davenport, J. L. (2007). Consistency effects between
evidence available from scenes containing consistent versus          objects in scenes. Memory & Cognition, 35(3), 393-401.
inconsistent objects. Furthermore, we showed that a scene         Davenport, J. L., & Potter, M. C. (2004). Scene consistency
categorization model coupled with the diffusion model                in object and background perception. Psychological
accounts well for the consistent-object advantage. Instead of        Science, 15(8), 559-564.
distinct scene and object perception systems operating in         Greene, M., & Oliva, A. (2009). Recognition of natural
parallel and competing or cooperating for categorization, the        scenes from global properties: Seeing the forest without
consistent-object advantage can be explained by a single             representing the trees. Cognitive Psychology, 58(2), 137-
scene perception system that interprets the global statistics        176.
found in natural scenes.                                          Gomez, P., Ratcliff, R., Perea, M. (2007). A model of the
   It is important to place our findings in their appropriate        go/no-go task. Journal of Experimental Psychology:
context. First, we are not arguing that explicit recognition         General, 136(3), 389-413.
of objects never matters for scene categorization. It goes        Henderson, J. M., & Hollingworth, A. (1999). High-level
without saying that fully understanding the environments             scene perception. Annual Review of Psychology, 50(1),
we encounter during our everyday visual experience                   243-271.
requires successful object recognition. However, in the case      Joubert, O. R., Rousselet, G. A., Fize, D., & Fabre-Thorpe,
of ultrarapid ultrasuperordinate scene categorization, we            M. (2007). Processing scene context: Fast categorization
have shown that explicit representation and recognition of           and object interference. Vision Research, 47(26), 3286-
objects in those scenes is not necessary to account for the          3297.
influence of consistent or inconsistent objects. Second, it       Oliva, A., & Schyns, P. G. (1997). Coarse blobs or fine
goes without saying that this demonstration is evidence of           edges? Evidence that information diagnosticity changes
sufficiency and not necessity. Further converging evidence           the perception of complex visual stimuli. Cognitive
is needed to know whether mechanisms described in our                Psychology, 34(1), 72-107.
model underlie ultrarapid scene categorization in humans.         Oliva, A., & Torralba, A. (2001). Modeling the shape of the
   The computational model we proposed extends a current             scene: A holistic representation of the spatial envelope.
class of successful scene categorization models to predict           International Journal of Computer Vision, 42(3), 145-
both response probabilities and reaction times. This model           175.
offers a richer description of scene categorization by            Palmer, S. (1975). The effects of contextual scenes on the
accounting for the time course of the perceptual decision.           identification of objects. Memory & Cognition, 3(5),
Further behavioral research and application of this model is         519-526.
necessary to better understand the underlying mechanisms          Ratcliff, R., & Tuerlinckx, F. (2002). Estimating parameters
of scene categorization and to characterize the relationship         of the diffusion model: approaches to dealing with
between scene and object perception.                                 contaminant reaction times and parameter variability.
                                                                     Psychonomic Bulletin & Review, 9(3), 438-481.
                    Acknowledgments                               Schyns, P. G., & Oliva, A. (1994). From blobs to boundary
This work was supported by a grant from the James S.                 edges: Evidence for time- and spatial-scale-dependent
McDonnell Foundation, NSF grant HSD-DHBS05, and by                   scene recognition. Psychological Science, 5(4), 195-200.
the Temporal Dynamics of Learning Center (NSF Science             Vandekerckhove, J., & Tuerlinckx, F. (2007). Fitting the
of Learning Centers grant SBE-0542013).                              Ratcliff diffusion model to experimental data.
                                                                     Psychonomic Bulletin & Review, 14(6), 1011-1026.
                        References                                Vandekerckhove, J., & Tuerlinckx, F. (2008). Diffusion
                                                                     model analysis with MATLAB: A DMAT primer.
Biederman, I., Mezzanotte, R. J., & Rabinowitz, J. C.                Behavioral Research Methods, 40(1), 61-72.
     (1982). Scene perception: Detecting and judging objects
     undergoing relational violations. Cognitive Psychology,
     14(2), 143-177.
                                                              2533

