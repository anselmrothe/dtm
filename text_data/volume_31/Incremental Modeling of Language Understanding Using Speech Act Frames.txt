UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Incremental Modeling of Language Understanding Using Speech Act Frames
Permalink
https://escholarship.org/uc/item/66v9r6hq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Bugajska, Magdalena
Frost, Wende
Trafton, Greg
Publication Date
2009-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

      Incremental Modeling of Language Understanding Using Speech Act Frames
                                            Wende Frost (wende.frost@asu.edu)
                                                      Arizona State University
                                   School of Computing and Informatics, 699 S. Mill Avenue
                                                      Tempe, AZ 85281 USA
                                  Magdalena Bugajska (magda.bugajska@nrl.navy.mil)
                                     J. Gregory Trafton (greg.trafton@nrl.navy.mil)
                                   Navy Center for Applied Research in Artificial Intelligence
                                    Naval Research Laboratory, 4555 Overlook Avenue SW
                                                   Washington, DC 20375 USA
                            Abstract                                current state of the world and what existing past world
                                                                    knowledge a model has in memory, rather than a
  Using the cognitive architecture ACT-R/E, we designed a
  framework for implementing cognitively plausible spoken           syntactically exact parse of the utterance (i.e. what the
  language understanding on an embodied agent using                 speaker said) divorced from an outside environment.
  incremental frame representations for multiple levels of          Processing in our framework is done at all levels for each
  linguistic knowledge. Emphasis is placed on semantics,            word as it comes in. It retrieves, creates, and edits frames of
  pragmatics, and speaker intent.                                   knowledge from the phonological to the pragmatic at each
   Keywords: cognitive      modeling;   language   processing;      step, enabling an agent to have a constantly developing
   pragmatics; semantics                                            picture of the utterance.
                                                                       Our framework differs from other natural language work
                        Introduction                                in the ACT-R family of architectures by focusing on
One of the greatest challenges in building and interacting          processing spoken natural language in real-time and on
with embodied agents is integrating cognitive plausibility          emphasizing pragmatic and semantic roles in the utterance.
without sacrificing usability. This challenge is very evident       It was also created to be easily expandable in other useful
when looking at natural language understanding in spoken            embodied directions, including processing gestural
language environments. In real-life scenarios, agents need to       information as part of an utterance structure. In keeping
respond to commands, gather information, and answer                 with the fundamental notion that language processing is
queries quickly even when faced with unexpected input               another aspect of human cognition subject to the same
from human users. Unexpected input can occur at many                representations and processes as other cognitive activities,
different linguistic levels, whether due to the agent’s speech      our framework does not implement a dedicated “language
recognition software failing to recognize a word, the need to       module.” (Croft, 2004) Instead, language processing is
process and understand an irregular syntactic utterance, or         done across existing modules. This non-dedicated module
by verbal interruptions in the middle of a task. While failure      approach differentiates our framework from much other
to promptly cope with all kinds of unexpected input leads to        ACT-R work on language, such as Ball (2007) and Emond
an agent being less useful in the field, it also exposes a lack     (2006). As with other work in ACT-R that does not have a
of cognitive plausibility in the framework of the model.            dedicated language module (Lewis & Vasishth, 2005;
Humans do not reach long-lasting impasses when faced with           Lewis, Vasishth, & Van Dyke, 2006), we have included an
any of these relatively simple situations (Gibson, 1991). In        additional buffer to store language information. Unlike this
addition to performing such tasks, the agent should also be         work, however, we do not have any parallel lexical access
able to hear, process, and remember utterances the speaker          mechanisms. Our divergence from a modular approach is
directed at other agents in the environment without                 also similar to the NL-SOAR language comprehension
mistaking them for commands or queries the speaker                  theory implemented in the SOAR cognitive architecture, but
expected the agent to achieve. A cognitively plausible agent        NL-SOAR focuses on explaining a large number of
would then be able to use these utterances directed toward          sentence-level syntactic phenomena (Lewis, 1993), whereas
others, especially relatively recent ones, and incorporate          we place more emphasis on semantics and pragmatics.
them with world knowledge for use in future goals.                     To achieve a cognitively plausible framework to model
  We have implemented a framework within the ACT-R/E                natural language understanding, we used the ACT-R/E
6 cognitive architecture (Anderson et al., 2004; Anderson &         cognitive architecture with the default ACT-R parameters
Lebiere, 1998) which aims to fulfill these requirements at          set. ACT-R 6 is a production system architecture composed
both functional and plausible levels. The framework’s focus         of two kinds of knowledge: declarative and procedural.
is to obtain a correct interpretation of the speaker’s              Declarative knowledge, also known as factual knowledge, is
intentions (i.e. what the speaker wants) based upon the             stored in long term declarative memory as “chunks.” These
                                                                    chunks, as well as chunks based upon perceptual
                                                                3093

information gained from sensors, are retrieved into central        sound of content kind “word.” This is the difference
cognition by way of “buffers.” Procedural knowledge is a           between a model likely understanding the meaning of a
set of condition-action rules, from which one is chosen to         word and a model dismissing a word not in its vocabulary.
fire after a conflict-resolution process based on the expected     When it does not find at least one meaning chunk for a
gain to alter the state of the buffers. Different chunks have      sound in its declarative memory, the sound is dismissed as a
different levels of activation affecting time taken for            completely unknown word with no need for further
retrieval. Standard ACT-R interfaces with the outside world        processing. The framework does not try to fit unknown
through visual, aural, motor, and vocal modules. The               words into higher-level representations, which makes the
architecture supports other faculties through intentional,         recovery time very fast for a lexical error or filler word. The
imaginal, temporal, and declarative modules.                       activation level of the 3000 most commonly used words in
   ACT-R/E is a modified version of ACT-R that allows the          the English language has been set very high. All words and
architecture to perceive the physical world by attaching           word senses are hand-entered, as they will be until the
robotic sensors and effectors to it. It includes a new module      definitional frames are regularized.
(spatial) and modifications to the visual, aural, and motor           The most basic meaning frame, as shown in Figure 2,
modules to work with our robot and to use real-world sensor        consists of a unique identifier for the word sense, the
modalities. The rest of the architecture was not modified.         general identifier for the lexeme, the part of speech1 of the
                                                                   word, and whether or not this word is a catalyst for
               Language Representation                             changing to a new phrase frame. Catalysts include verbs,
From the time a model hears a sound to the time a model is         some types of nouns (e.g. vocative), prepositions,
acting on a fully processed utterance, we have identified          conjunctions, and complementizers.
four major representation types; content of sound, meaning,           Currently, the catalyst slot can be filled by three values:
phrase, and speech act, based on Clark (1996). To represent        “yes,” “no,” and “nil.” A catalyst of “yes” indicates a
these types, we have used a form of frame representations          change to a new phrase frame. A catalyst of “no” indicates
(Langacker, 1999) which integrates well with the format of         that a word is a content word and should be integrated with
chunks in ACT-R/E. Each frame consists of an identifier            the rest of the utterance. A catalyst of “nil” indicates that the
and a type, followed by a list of slots that will later be         word should either be disregarded immediately, or after a
matched against by the productions.                                minor change is made to a value in an existing frame.
   Simply using frames or schemas to represent linguistic
expressions appears similar to the family of Construction             [to-1              isa                  meaning
Grammar theories (Fillmore & Kay, 1993; Goldberg, 1995),                                 identifier           to
but our framework differs from Construction Grammar in                                   pos                  locative-prep
fundamental ways, including the recognizance of                                          catalyst             yes]
synonymy.
   Due to the structure of our representations, the same                            Figure 2: Basic Meaning Frame
representation will work for languages besides English,
including most analytic, SVO, head-first languages. Our               In addition to the basic items listed above, the meaning
representation is currently limited to languages with              frame also contains the necessary agreement information
structural differentiation between grammatical moods.              about verbs and nouns, such as tense, plurality, person, etc.
                                                                   Definitional information about function words will be stored
Content of Sound                                                   as separate types of chunks.
The content of sound representation is an existing ACT-R/E         Phrase Frames
construct. Sound events are processed in the aural module,
with the sound location in the aural-location buffer and the       Once a model has a meaning frame for a word, it next fills
sound content in the aural buffer. The sound content in the        in a phrase frame where appropriate with the meaning. The
aural buffer on the first word of the sentence “Go to the          phrase frames are composed of a loosely linked set of
corner office by the lobby,” is represented in Figure 1.           information from the meaning frames compiled into a
                                                                   higher-level semantic structure. The same phrase frame is
   [word0-0            isa                sound                    used for incoming meaning until a word functioning as a
                       kind               word                     catalyst is heard. This means that each phrase has several
                       content            go                       optional slots in the frame to accommodate the different
                       event              audio-event1]            configurations of phrases in natural language and only two
                                                                   basic slots. The basic slot is the phrasetype slot, which is
                   Figure 1: Word Sound Frame                      filled with the type of phrase being created. In addition, the
                                                                   phrase frame usually contains the head of phrase, or the
Meaning Frames
The frame of meaning representation is the first type of              1
                                                                        Verb and noun types are stratified based upon their WordNet
chunk our framework tries to retrieve when it knows it has a       classifications.
                                                               3094

word which triggered the phrase change, any modifiers to                  The speech act frame has three basic slots: type, actual
the phrase itself, what thematic role the modifier plays, any          state, and desired state. Type is filled with the appropriate
thematic words in the phrase, as well which thematic role              modality for that speech act: “indicative,” “imperative,” or
they play, and any modifiers to the thematic words in the              “declarative.” Other moods, such as subjunctive or jussive,
phrase.                                                                are not recognized at this time due to difficulty in
                                                                       recognizing their structural components. The currently
   [locative          isa                phrase                        recognized moods form the set of recognized structural
                      phrasetype         locative-prep                 pragmatic markers (Fraser, 1990). Other discourse markers,
                      head               to                            such as phrasal patterns (Pitler, et al., 2008; Saito,
                      modifier           by                            Yamamoto & Sekine, 2006), will be integrated later, adding
                      modifier-role      locative-prep                 to the possible values in the type slot.
                      thematic           office                           Actual state is based on a model’s perceptual and
                      thematic-role      destination                   declarative knowledge of the state of the world. Desired
                      thematic-mod1      corner]                       state stores any speaker intent as to the desired state of the
                                                                       world, which is gleaned from their utterances. Comparing
                   Figure 3: Basic Phrase Frame                        the two states is useful when following commands or
                                                                       checking the mood of a statement.
   The phrase frame listed in Figure 3 shows the phrase                   The other content of the speech act frame includes
headed by “to” in the utterance “Go to the corner office by            actiontype, who, how, when, where, what, and any more
the lobby now.” Since “to” is a catalyst, a new frame was              specific values, such as where-exactly, that are needed to
created containing it as the head. As previously noted, non-           understand an intention. They were named to be as easy as
content words that have little bearing on the eventual                 possible for the human user to interpret, as this is the frame
intention of the utterance (such as “the” in this example) are         level used by a human to check for understanding of intent.
not stored in a slot. As in Altmann (1999), thematic roles for         The actiontype is the high level action the agent needs to
the slots are filled partially based on context. The first and         take, such as implementing a verb of motion. The specificity
only thematic role related to locative prepositions is                 of verb types can be tailored to the capabilities of the robot.
destination. Since “office” does not fall in the role of               Limiting the actiontype field to types of actions (e.g. verb of
catalyst or in the role of non-content word, it is seen to play        motion) rather than specific actions (e.g. walk) in every case
a thematic role in the sentence, filling in the expected role of       allows for easier analysis of unknown verbs. The verb itself
“destination.” As soon as the word “by” is uttered with its            is stored in the how slot in case there is an action or
catalyst value of “yes,” a new phrase frame is created to              production based on a specific verb.
hold the information “by the lobby now.”                                  The who slot contains who the utterance was directed
   Phrase frames hold much of the semantic content of the              toward. By default, all utterances are assumed to be directed
utterance, as well as the syntactic linkages. They do not              at our robot unless specifically stated otherwise. Similarly
contain any immediate method of unifying the phrases                   by default, all when slots are assumed to be “now” unless
created. The goal of the framework is not to immediately               another modifier is given, such as “in two hours” or “after.”
have perfect recall of utterance parses and integrations at all        The where slot is filled with destination or source
levels, but rather to derive the intention of the utterance.           information gleaned from the phrase frames, and the what
This goal is plausible based on Langacker (1999).                      slots refer to patients, instruments, recipients and other
                                                                       thematic roles not already covered. Unlike phrase frames,
Speech Act Frames                                                      speech act frames can contain multiple lexemes in the same
Speech act frames, roughly based on the speech acts of                 slot, such as “corner office.”
Austin (1962) and Searle (1969), are composed over the                    An example of the speech act frame from the command
course of the utterance with a recognized cue creating a               for the robot to walk to the corner office by the lobby is
barrier between utterances2 and ending the speech act. For             given in Figure 4.
every new addition or alteration to a phrase, there are
productions to update the current speech act frame. As                    [general             isa              speech-act
many speech acts are composed of multiple utterances or                                        type             imperative
sentences, there will have to be another level of composition                                   actiontype      verb-motion-intran
added in the future to distinguish between the intention of                                    who              robot
single utterances and the intention of the speech act as a                                     where            corner office
whole.                                                                                         where-exactly    by lobby
                                                                                               when             now
                                                                                               actual state     n
   2
     This cue is currently the word “now.” With fine-tuning of                                 desired state    y]
speech recognition software, we hope to instead use prosodic
analysis tools to correctly identify the end of the utterance based                      Figure 4: Speech Act Frame
on length of pauses correlated with surrounding pitch.
                                                                   3095

                  Utterance Processing                               In the intermediate case, after the initial retrieval gains the
                                                                  meaning of the word, another retrieval is necessary for a
The primary goal of our language understanding framework
                                                                  new phrase type chunk. This case is signaled by the catalyst
is to have an embodied agent operate in real-time in a
                                                                  slot in the meaning retrieved being filled with the value
cognitively plausible fashion, integrating information from
                                                                  “yes.” While this case takes slightly more time, it is
the perceptual modules as well as declarative memory to
                                                                  theoretically plausible that changing to a new phrase type
form a picture of the speaker’s intentions. Cognitive
                                                                  requires more cognitive effort than filling in slots in an
plausibility requires both representations and processes to be
                                                                  existing phrase type. The speech act frame in this instance is
plausible. Plausibility in the representations is gained
                                                                  still the same.
through the use of linguistic frames (Langacker, 1999),
                                                                     In the most extreme serial case, a new utterance is being
while processing gains plausibility by matching human
                                                                  processed. This requires retrievals not only of the word
perceptual and cognitive data over a series of processing
                                                                  meaning and phrase type, but of the speech act itself. In this
steps.
                                                                  case, however, the simultaneity component is not as relevant
                                                                  since Hagoort’s data did not assume any semantic, syntactic,
Audio Processing
                                                                  or pragmatic information was present before speech began.
The first step of processing spoken language is recognizing
incoming sounds. In the framework, a model has                    Cognitive Response Time
productions to continually monitor the environment for
                                                                  Speech understanding is normally done at a rate of 150-160
sound, even as it’s processing or achieving another goal.
                                                                  WPM (Williams, 1998) or an average of one word per 40
This is done by attending to the audio events appearing in
                                                                  ms. According to Card, Moran, and Newell (1983), this rate
the aural location buffer. Once an audio event has been
                                                                  corresponds with the cognitive cycle time for processing
attended to, its content is placed in the aural buffer.
                                                                  information about each word: from 25-170 ms. The
   We have tested the audio processing of the framework in
                                                                  utterance understanding time in our framework, 84 ms, was
two different ways: by receiving aural input by means of the
                                                                  measured between the time the last word was uttered and
commercial speech-recognition engine ViaVoice and by
                                                                  the time the phrase was fully understood. This fits well
simulating the arrival of audio events in the aural location
                                                                  within the range given by Card et al. The average WPM
buffer through text input. The latter method is useful for
                                                                  rate, 41, was found by dividing the time the utterance was
precise testing of input speed. Though there is evidence that
                                                                  fully understood by the number of words in the phrase. This
humans interacting with what they know to be non-human
                                                                  is very close to the rate found by Williams. The default
systems speak more slowly than usual (Lewis, 1999), when
                                                                  ACT-R/E retrieval and conflict-resolution values were used.
we used the manual input method, we set the event arrivals
                                                                  These initial constraints, along with the serial retrieval
at the speed of humans interacting with other humans,
                                                                  mechanism of ACT-R/E, contributed to the cognitively
which varies from 180 to 250 words per minute (WPM)
                                                                  plausible cycle times gained.
(Picard, 1997). The event arrival was set accordingly at one
word per 30 ms. In addition, the default sound decay time
                                                                  Data Retrieval
value is 3.0 sec. This means that if an audio event is not
attended to within that time from its onset, it will become       After the word sound has been attended to, it is checked
unavailable to a model.                                           against all word senses in memory to see if a meaning can
                                                                  be retrieved. If a meaning is located, it is retrieved and a
Serial Processing                                                 speech act is created. Once the speech act is created, a
                                                                  phrase frame is retrieved; the type depends upon the
Since work has been done showing that humans
                                                                  meaning. If the meaning cannot retrieve phrase frames (i.e.
comprehend utterances at all linguistic levels nearly
                                                                  it is not marked as a catalyst), it is either placed into the
simultaneously (Hagoort, 2008), our framework has the
                                                                  speech-act or into declarative memory. Most words in this
ability to process the different frames of an utterance
                                                                  situation will be sent to declarative memory, as the speech-
extremely quickly, with all levels of processing done for
                                                                  act role will not be obvious at the onset.
each word.
                                                                     Once a phrase frame has been retrieved, the slots are
   This processing speed is reached by means of the
                                                                  filled based upon incoming meanings until a word of a
aforementioned addition of the language buffer with a
                                                                  separate or embedded phrase type comes into the system.
minimum one retrieval and maximum three retrievals per
                                                                  Though no productions are firing in parallel, there is conflict
each recognized word heard.
                                                                  resolution between the productions to fill slots in the phrase
   In the most rapid case, one retrieval is necessary to
                                                                  frame and the productions to fill slots in the speech act
retrieve the meaning of the heard word. The word is either a
                                                                  frame, leading to interleaving of the completion of the two
catalyst of “nil,” it is a thematic role to both a phrase and
                                                                  frames as words are heard.
speech act currently being processed, or it is a modifier to a
thematic role in an existing phrase. In these cases, the word
                                                                  Interruption, Resumption, and Disregard
and its role are written to the existing chunks in the
appropriate buffers and sent to declarative memory.               Once an utterance in the imperative mood is complete, a
                                                                  model checks to see if there are any appropriate productions
                                                              3096

which support the achievement of this command. If the                so. The robot does not act upon any commands other than
utterance was unfinished (e.g. important information such as         those the speaker intended, which provides functionality for
the destination in a movement command was missing), the              directing an agent as part of a team. The robot does not start
model will wait for another utterance.                               achieving goals given in the commands until the utterance is
   If there is sufficient information encoded to complete the        complete. Future work on priming will give the robot the
command and a production has been fired to start achieving           ability to begin achieving goals directed toward it even
the command, the slot in the speech act frame for actual             before the speaker has finished the utterance.
state will change from “n” to “in process.” If the command              While not yet as large-scale as language understanding
is interrupted by another command directed to the robot, it          systems such as Ball (2007) and Lewis (1993, 2005, 2006)
will follow the new command instead, and place the                   have created, we feel that by placing minimal reliance on
interrupted speech act in the declarative memory. If the             syntax and focusing on semantics and pragmatics, our
robot is later told to “never mind,” “keep going,” or                language framework has the potential to become a
“continue,” it will retrieve the interrupted speech act and set      worthwhile addition to the field of natural language
about achieving it again. If the robot has been interrupted          understanding.
multiple times, it will only be able to go back to the
interrupted command with the highest activation, unless                                     Future Work
specific information about which interrupted command is              Future work on this framework will proceed along two
desired is given.                                                    complementary avenues. Both avenues will more fully take
   Since a speaker may be directing commands or dispensing           advantage of the embodied aspect of the framework. The
facts to multiple agents at the same time, the framework             short term work will concentrate on integrating more
only regards commands that have been addressed to it as              technical capabilities with the existing framework and on
goals to fulfill. The commands and statements directed at            gathering data for other languages and situations (such as
other agents or humans are organized as speech act frames,           gestural recognition) currently within its capacity. An
then put into declarative memory for future use.                     example of expanded technical capabilities would be
                                                                     incorporating speech-recognition software that contains the
                           Discussion                                prosodic analysis tools for pause and pitch mentioned
Our framework operates incrementally in ACT-R/E on                   earlier. Integration with a lexical database, such as
simple3 commands and declarative statements, with                    WordNet, is also paramount.
representations, perceptual cycles, and cognitive cycles that           Currently, data has been gathered in the framework using
are cognitively plausible. The framework is reasonably error         simple commands, declaratives, interruptions, and
tolerant at both a lexical and syntactic level, with more            resumptions in English using a variety of verbs,
attention given to the intention of the speaker than to the          prepositions, and location phrases. To ensure robustness and
preciseness of the input. Some of this flexibility is gained by      continued plausibility of the run times, further studies
not relying on syntax for more than clues about the                  should be run on more complicated or multi-sentential
utterance and intention. As spoken word input is often               utterances, queries, and non-English domains. None of these
syntactically flawed while remaining semantically coherent,          examples should require major changes to the existing
we felt this was a reasonable approach. A slightly higher            framework.
level of syntactic productions will be added in the future.             Long term work to make a larger scale framework will
The focus of the framework is on understanding the intent            focus on three major areas: priming for upcoming words
of the utterance and creating the speech act frame according         and parts of speech, stable left branching, and definitional
to the pragmatic information gained by the modal structure.          frame regularization.
   Since the framework operates in a cognitively plausible              The existing framework implementation does not have
cycle time, it is able to analyze and act upon speech acts as        any priming. This, on top of not being cognitively plausible
they are given in real time, as humans do. There is no               (McNamara, 2005), hampers it in regard to unknown words.
backlog of words that “decay” or are “forgotten” before a            With the addition of priming for upcoming parts of speech
model analyzes them, due to the high activation of common            or thematic roles, the role of an unknown word in an
words, so it can continue virtually indefinitely. The only           utterance may be inferred, even if the exact meaning of the
situation that would result in a model lagging significantly         word itself remains unknown. This will let the robot query
behind the speaker would be that in which more than 50%              the speaker when there is a barrier to understanding an
of the lexical items are unknown or extremely rare.                  important part of an utterance, yet continue to discard
   The framework is able to divert attention from achieving          unknown words that play no key role in a speech act.
one goal when it is interrupted by another goal. In addition,        Priming will also aid in the framework’s currently weak
it can retrieve these interrupted goals when directed to do          word sense resolution.
                                                                        Since the framework was created using simple English
                                                                     head-first grammar as a template, all productions are
   3
     “Simple,” in this case, means no more than two prepositional    currently geared toward right branching phrases. There are
phrase embeddings, minimal left branching, and no center             only a few instances of left branching permitted through the
embedding or compound utterances.
                                                                 3097

current productions. While the representations will handle        Fillmore, C. & Kay, P. (1993). Construction grammar
left branching with very few modifications, the productions         coursebook. Berkeley, CA: Copy Central.
will need to undergo significant changes. Once left               Fraser, B. (1990). An approach to discourse markers.
branching is integrated more thoroughly into the framework,         Journal of Pragmatics, 14, 383-398.
it will also be able to process utterances in SOV analytic        Gibson, E. A. F. (1991). A computational theory of human
languages.                                                          linguistic processing: memory limitations and processing
   Definitional frame regularization will involve defining the      breakdown. PhD thesis, Carnegie Mellon. Available as
different senses of the words in such a way that they can be        Center for Machine Translation technical report CMU-
retrieved by major features or roles held. This will be a           CMT-91-125.
fairly substantial undertaking, as even once a regularization     Goldberg, A. (1995). Constructions: A Construction
is decided upon, which is no small task, there is no                Grammar Approach to Argument Structure. Cognitive
guarantee that data from an existing database can be easily         Theory of Language and Culture. Chicago University
altered to fit the chosen chunk format.                             Press.
   In addition to modifying the framework, we will also           Hagoort, P. (2008). The fractionation of spoken language
show that the model executed on the framework has                   understanding by measuring electrical and magnetic brain
plausible reaction times by dataset matching.                       signals. Philosophical Transactions of the Royal Society
   Supplementing these additions and expansions to the              B: Biological Sciences, 363, 1055-1069.
framework within ACT-R/E, work will begin towards                 Langacker, R. W. (1999). Foundations of Cognitive
integrating the underlying principles of the framework with         Grammar: Volume II: Descriptive Application. Stanford
other cognitive architectures, such as SOAR and Icarus              University Press.
(Langley & Choi, 2006). This integration will lend credence       Langley, P. & Choi, D. (2006). A unified cognitive
to the robustness of the framework while making the                 architecture for physical agents. In Proceedings of the
framework more accessible to users of different cognitive           twenty-first national conference on artificial intelligence.
architectures.                                                      Boston: AAAI Press.
                                                                  Lewis, J. R. (1999). Effect of error correction strategy on
                     Acknowledgments                                speech dictation throughput. In Proceedings of the Forty-
This work was supported by the Office of Naval Research             Third Annual Meeting of the Human Factors and
under funding document N0001409WX20173 to JGT. The                  Ergonomics Society (pp. 457-461).
views and conclusions contained in this document should           Lewis, R. L. (1993). An architecturally-based theory of
not be interpreted as necessarily representing the official         sentence comprehension. In Proceedings of the Fifteenth
policies, either expressed or implied, of the U. S. Navy.           Annual Conference of the Cognitive Science Society.
                                                                  Lewis, R. L. & Vasishth, S. (2005). An activation-based
                                                                    model of sentence processing as skilled memory retrieval.
                         References                                 Cognitive Science, 29, 375-419.
Altmann, G. T. (1999). Thematic role assignment in context.       Lewis, R. L., Vasishth, S. and Van Dyke, J. A. (2006).
   Journal of Memory and Language, 41(1), 124-145.                  Computational principles of working memory in sentence
Anderson, J.R., Bothell, D., Byrne, M. D., Douglass, S.,            comprehension. Trends in Cognitive Science, 10, 447-
   Lebiere, C., & Qin, Y. (2004). An integrated theory of the       454.
   mind. Psychological Review, 111(4), 1036-1060.                 McNamara, T. P. (2005). Semantic priming. Psychology
Anderson, J. R. & Lebiere, C. (1998). The Atomic                    Press.
   Components of Thought. Lawrence Erlbaum Associates.            Picard, R. W. (1997). Affective computing. Cambridge, MA:
Austin, J. L. (1962). How To Do Things With Words.                  MIT Press.
   Cambridge: Harvard University Press.                           Pitler, E., Raghupathy, M., Mehta, H., Nenkova, A., Lee,
Ball, J. (2007). Construction-driven language processing. In        A., & Joshi, A. (2008). Easily identifiable discourse
   Proceedings of the Second European Cognitive Science             relations. To appear in Proceedings of COLING 2008.
   Conference, Delphi, Greece.                                      Manchester, UK.
Card, S. K., Moran, T. P., & Newell, A. (1983). The               Saito, M., Yamamoto, K., & Sekine, S. (2006). Using
   psychology of human-computer interaction. Academic               phrasal patterns to identify discourse relations. In
   Press.                                                           Proceedings of the Human Language Technology
Clark, H. H. (1996). Using language. Cambridge University           Conference of the NAACL. (pp. 133-136). New York, NY:
   Press.                                                           Association for Computational Linguistics.
Croft, W. & Cruse, D. A. (2004). Cognitive Linguistics.           Searle, J. (1969). Speech Acts. Cambridge University Press.
   Cambridge University Press.                                    Williams, J. R. (1998). Guidelines for the use of multimedia
Emond. B. (2006). WN-LEXICAL: An ACT-R module                       in instruction. In Proceedings of the Human Factors and
   built from the WordNet lexical database. In Proceedings          Ergonomics Society Forty-Second Annual Meeting (1447-
   of the Seventh International Conference on Cognitive             1451).
   Modeling (pp. 359-360). Trieste, Italy.
                                                              3098

