UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Coevolution of Punishment and Prosociality Among Learning Agents
Permalink
https://escholarship.org/uc/item/99z662f7
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Cushman, Fiery
Macindoe, Owen
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         The Coevolution of Punishment and Prosociality Among Learning Agents
                                           Fiery Cushman (cushman@wjh.harvard.edu)
                                 Department of Psychology, 1484 William James Hall, 33 Kirkland St.,
                                                         Cambridge, MA 02138 USA
                                                  Owen Macindoe (owenm@mit.edu)
                    Computer Science and Artificial Intelligence Laboratory, Building 32-G585, 32 Vassar Street
                                                         Cambridge, MA 02139 USA
                               Abstract                                 mechanism: their innate belief about the probability of pun-
                                                                        ishment (i.e., a prior distribution over hypotheses) along with
   We explore the coevolution of punishment and prosociality in         their experience of past punishment (i.e., data) is used to as-
   a population of learning agents. Across three models, we find
   that the capacity to learn from punishment can allow both pun-       sess the probability of future punishment (i.e. the probability
   ishment and prosocial behavior to evolve by natural selection.       of a new datum given the posterior distribution over hypothe-
   In order to model the effects of innate behavioral dispositions      ses). Thus, it should be clear how we can use prior proba-
   (such as prosociality) combined with the effects of learning
   (such as a response to contingent punishment), we adopt a            bilities to model innate prosociality versus antisociality. A
   Bayesian framework. Agents choose actions by considering             prior expectation of punishment will translate into an innate
   their probable outcomes, calculated from an innate, heritable        prosocial tendency not to steal. Conversely, a prior expec-
   prior distribution and agents’ experience of actual outcomes.
   We explore models in which an agent learns about the disposi-        tation against punishment will translate into an innate anti-
   tions of each individual agent independently, as well as models      social tendency to steal. Critically, we allow heritable prior
   in which an agent combines individual-level and group-level          probabilities to mutate in a system of replicating agents—
   learning. Our results illustrate how the integration of Bayesian
   cognitive models into agent-based simulations of natural selec-      thereby changing innate contributions to prosocial vs. anti-
   tion can reveal evolutionary dynamics in the optimal balance         social behavior—and explore the resultant evolutionary dy-
   between innate knowledge and learning.                               namics.
   Keywords: costly punishment; hierarchical Bayesian models;              Modeling innate behavioral tendencies as prior probabil-
   prosociality; evolution; societal modeling.
                                                                        ities allows for these tendencies to vary in strength and
                                                                        persistance—in biological terms, innate tendencies can vary
                           Introduction                                 in their degree of canalization versus plasticity. For instance,
Why isn’t theft more common? To respect others’ property                an agent could have an innate belief that it will not be pun-
is nice, but pilfering is more profitable. One family of ex-            ished that is very strong (highly canalized), in which case it
planations posits a key role for punishment (e.g. Boyd &                will continue to steal in the face of consistently experienced
Richerson, 1992). In brief, when people can learn from pun-             punishment for theft. Or, an agent could have an innate be-
ishment, it pays to punish theft. And, when people punish               lief that it will be punished that is very weak (highly plas-
theft, it pays not to steal. Thus, the coevolution of punish-           tic), in which case it will cease stealing after experiencing
ment and prosociality depends critically upon the manner in             a small amount of consistent punishment. This feature of the
which perpetrators learn from punishment. Here, we compare              Bayesian approach provides an important advantage over past
the evolutionary dynamics that result under several different           attempts to model the coevolution of punishment and proso-
learning models, demonstrating sometimes dramatically dif-              ciality. Other studies have considered a restricted set of spe-
ferent outcomes. These findings have implications for our               cialized behavioral responses to punishment: for instance,
understanding of the evolution of social behavior in particu-           adopting pure prosocial behavior after a single instance of
lar, but also provide a case study of a more general problem:           punishment, (e.g. Sigmund, Hauert, & Nowak, 2001; Brandt,
how can cognitive models of learned behavior and evolution-             Hauert, & Sigmund, 2003). This corresponds to a high degree
ary models of innate behavior be integrated?                            of plasticity—but in the model we present, rather than stipu-
   We model agents equipped with Bayesian learning mech-                lating a high degree of plasticity we explore the evolutionary
anisms. One key advantage of a Bayesian approach is that it             dynamics that lead to plasticity versus canalization.
provides a natural means of combining heritable, innate dis-               A second key advantage of a Bayesian approach is the ease
positions with experience to determine an agent’s behavior              with which so-called “hierarchical” learning can be modeled
(see also Kirby, Dowman, & Griffiths, 2007). In our model,              (Griffiths, Kemp, & Tenenbaum, 2008; Tenenbaum, Griffiths,
an agent decides whether or not to steal from a potential vic-          & Kemp, 2006). For instance, in our model a potential thief
tim by considering the probability that it will be punished for         might guess whether a victim is likely to punish by consid-
theft, and then using this probability to calculate the expected        ering not only that specific victim’s prior record of punish-
value of theft (the antisocial choice) versus abstaining from           ment, but also the prior record of punishment from other vic-
theft (the prosocial choice). Agents’ guesses about the prob-           tims. Thus, inferences about individual-level behavior might
ability of punishment are generated by a Bayesian updating              be hierarchically embedded in inferences about group-level
                                                                    1774

behavior. Experimental evidence suggests that people do, in-          interval (0, 1). Punishment carries a cost of 0.5 fitness units
deed, adopt more prosocial behavior with novel group mem-             to the punisher.
bers when past group members have punished antisocial be-                At the end of each generation all agents die are and re-
havior (Fehr & Gachter, 2002). We directly compare learn-             placed using a modified version of the pairwise comparison
ing models operating exclusively at the individual level with         process for natural selection (Traulsen, Pacheco, & Nowak,
learning models that operate across the individual and group          2007). In this process, each agent’s fitness, Fa , is compared
levels, demonstrating notably different evolutionary dynam-           with the fitness of another agent selected randomly, Fb , and
ics. Specifically, when everybody else punishes, and peo-             the agent passes its heritable traits to the replacement with
ple predict that you will do what everybody else does, there          probability:
is no need to pay the costs of punishment. Thus, a non-                                                               1
punitive strategy can invade a population dominated by costly                         P(self replacement) =                           (2)
                                                                                                                 1 + eFb −Fa
punishment when inferences from group-level behavior to
                                                                      Otherwise, the randomly selected other passes its heritable
individual-level behavior are strong.
                                                                      traits to the replacement.
   Throughout this paper we model an agent’s innate behav-
ior in terms of its innate beliefs. We do not choose this ap-         Model 1: Uniform prior
proach because we believe that all innate behaviors are a con-        In the uniform prior model, perpetrators estimate the proba-
sequence of innate beliefs, as such. Rather, we choose this           bility of being punished for theft P(pun|theft) for each vic-
approach because Bayes’ rule provides a framework in which            tim independently, given its history of interactions with that
innate and experienced factors can be formally combined, and          victim. This is calculated from a posterior probability dis-
in which innate factors can vary both in their consequences           tribution over the interval of possible θ values [0, 1] that vic-
(i.e. degree of prosociality) and strength (i.e. degree of canal-     tim might possess, given a uniform prior probability for all
ization). Thus, a formal model of beliefs can yield a useful          θ values and a binomial distribution parameterized by the
functional model of behavior. We will consider both the ben-          victim-specific history of punishment: the number of times
efits and drawbacks of this approach.                                 Npun that the agent has been punished by the victim for theft,
                                                                      and the total number of thefts Nthe f t from the victim. The pos-
                            Methods
                                                                      terior predictive distribution of punishment given theft—that
We explored evolutionary dynamics for three different cog-            is, the agent’s best guess as to whether it’s next theft will be
nitive models through computer simulation. Each simulation            punished by that individual—has a simple analytic solution
involved a population size of 25 agents over 4000 genera-             (Griffiths et al., 2008):
tions. In every generation, each agent interacts with each                                                  Npun + 1
other agent 50 times: 25 times in the “perpetrator” role (de-                              P(pun|theft) =                             (3)
                                                                                                           Nthe f t + 2
ciding whether or not to steal) and 25 times in the “victim”
role (deciding whether or not to respond to theft with punish-        Thus, a perpetrator estimates P(pun|theft) at .5 in its first in-
ment).                                                                teraction with that agent, and will tend to make more accurate
   Each time a perpetrator decides whether to steal, it has per-      predictions over the course of subsequent interactions.
fect knowledge of the value of the theft (always 1 fitness unit)
as well as the value of some behavioral alternative to theft,         Model 2: One-level
Valt , randomly chosen from (−2, 2) fitness units at the outset       A simple extension of the uniform prior model allows the
of each interaction. It also has perfect knowledge of the cost        evolution of non-uniform prior probability distributions over
of being punished (always 2 fitness units), but must estimate         θ, so that individual perpetrators apply an inherited prior to
the probability of being punished for theft, P(pun|theft). It         each individual victim and calculate a victim-specific poste-
estimates this probability by one of three Bayesian methods,          rior distribution over θ given that victim’s history of punitive
described below. It then calculates the expected value of theft,      responses. We define the prior distribution over θ using a
Ethe f t = 1 - 2P(pun|theft). Finally, the agent chooses whether      beta distribution parameterized Beta(α, β), α, β > 0. Here,
to steal by applying a softmax function with temperature pa-          again, the posterior predictive distribution (agent’s estimate
rameter λ = 3 to the expected value of theft and known value          P(pun|theft) has an analytic solution (Griffiths et al., 2008):
of the behavioral alternative (Daw & Doya, 2006):                                                         (Npun + α)
                                                                                       P(pun|theft) =                                 (4)
                                      eλEthe f t                                                       (Nthe f t + α + β)
                   P(theft) =    (λEthe f t )
                                                              (1)
                               e              + e(λValt )                The agent’s initial estimate P(pun|theft) is given by α+β    α
                                                                                                                                        .
   If the perpetrator choses not to steal, no social interaction      When this initial estimate is large, the agent exhibits an in-
takes place and therefore the victim does not punish. If the          nate bias towards prosociality; when this initial estimate is
perpetrator chooses to steal, the victim punishes with prob-          small, the agent exhibits an innate bias towards antisocial-
ability θ. An agent’s θ is fixed over the course of its life-         ity. Additionally, large values of α and β make an agent’s es-
time, and inherited by that agent’s “children” subject to a 1%        timated P(pun|theft) resistant to experiential modification—
chance of mutation; mutant θs are drawn uniformly from the            that is, large values of α and β dominate Npun and Nthe f t . Thus,
                                                                  1775

canalization is captured by (α + β) >> 0, and plasticity by
(α + β) ≈ 0.                                                                                        P(history|hi )P(hi )
                                                                                 P(hi |history) =                                 (5)
   In this one-level model, an agent’s α and β parameters are                                          P(history)
heritable traits. During replacement, α and β parameters are        Where P(history|hi ) is the likelihood of each victim’s re-
each subject to a 1% rate of mutation, with new values se-          sponses under a given hypothesis as calculated by equation 4,
lected from exponential distributions with mean 2. In the first     and P(history) is the average P(history|hi ) for all 45 hypothe-
generation of each simulation, all individuals were initialized     ses, weighted by their prior probabilities.
with parameters α = 1, β = 1, that is, a uniform prior over θ.         We allowed replication and mutation in the prior proba-
                                                                    bilities assigned to the 45 hypotheses that each hierarchical
Model 3: Hierarchical                                               learner considered. In order to simplify the evolution of prior
                                                                    probabilities over this hypothesis space, we calculated each
Finally, we consider a hierarchical Bayesian learning model         agent’s prior probabilities with two heritable parameters: a
that combines inferences across the individual and group lev-       “prosociality” parameter ψ and a “group bias” parameter γ.
els. In essence, a hierarchical model tests whether indi-           All 45 hypotheses were classified according to nine levels of
viduals’ θ values are consistent or inconsistent across the           α
                                                                    α+β ranked from -5 to 5 (R p ) and five levels of (α + β) ranked
group, and makes inferences about individuals’ future behav-        from -2 to 2 (Rc ). The probabilistic weighting of each hypoth-
ior based on that decision. Thus, an agent’s prior history of       esis was calculated:
punishment with one victim can exert an influence on its pre-
dictions about another victim’s punitive behavior. In order to                             Shi = eψR pi eγRci                     (6)
perform this inference, each perpetrator calculates the poste-      Scores were then normalized to sum to 1 in order to derive
rior probability of several different probability distributions     the prior probability of each hypothesis. In the first genera-
over θ (hereafter, “hypotheses”). For instance, consider three      tion of each simulation, all individuals were initialized with a
particular hypotheses: (1): Beta(100,1), (2): Beta(1,100) and       uniform prior over the 45 hypotheses.
(3): Beta(1,0.01). If an agent consistently experiences pun-
ishment from all victims of theft, it will select (1) as the most   Non-learning control models
likely hypothesis; conversely, if it never experiences punish-      As a control, we also tested three corresponding non-learning
ment, it will select (2). However, if an agent experiences          models: a uniform prior non-learning model, a one-level non-
a mixed population where some victims consistently punish           learning model, and a hierarchical non-learning model. Each
and others consistently do not, it will select (3) as the most      of these models was constructed by eliminating the calcula-
likely hypothesis, because (3) allows the posterior probabil-       tion of posterior probability distributions given a history of
ity of θ to be strongly determined by the unique history of         punishment. Thus, in the uniform-prior non-learning model,
punishment with each individual victim.                             all agents always estimated the probability of punishment at
   In a hierarchical model, an individual’s behavior is char-       exactly .5. In the one-level and hierarchical non-learning
acterized by high levels of prosociality when it favors hy-         models, agents always estimated the probability of punish-
potheses with values of α+β α
                               ≈ 1 and an individual’s behav-       ment according to their inherited prior distribution. The latter
ior is characterized by strong “group bias” (i.e., tendency to      two cases test whether punishment and prosociality can co-
infer from group behavior to individual behavior) when it fa-       evolve in the absence of learning.
vors hypotheses with values of (α + β) >> 0. Agents inherit
an innate probability distribution over hypotheses, subject to
                                                                                               Results
mutation. If this probability distribution is even across all hy-   Uniform prior model
potheses, prosociality and group bias are highly plastic traits.
                                                                             1
As this innate probability distribution is increasingly skewed
across hypotheses, either prosociality, group bias, or both be-
come increasingly canalized.                                           θ   0.5
                                                                                                                  one-level
   In the hierarchical model we implemented, each agent                                                            uniform
considers 45 different probability distributions over θ:                    0
                                                            α               1000           2000        3000                4000
a full crossing of nine levels of prosociality ( α+β           ∈                              Generations
{.1, .2, ....9}) with five levels of group bias (α + β ∈
{0.2, 2, 20, 200, 2000}). An estimate of P(pun|theft) is ob-        Figure 1: Average population θ values for 50 simulations over
tained by applying equation 4 to each of the 45 hypotheses,         generations 1000-4000 (following the introduction of θ > 0
and then taking the average estimate weighted by the poste-         as an evolvable strategy in generation 1000) for the uniform
rior probability of each hypotheses, P(hi |history). For a given    prior model and the one-level model.
prior distribution over the 45 hypotheses P(h), and a history          Following the introduction of mutations in punishment
of punitive responses, the posterior probability of each hy-        strategies, population levels of punishment rapidly climbed
pothesis can be calculated:                                         towards the maximum level in the uniform prior model. That
                                                                1776

is, once θ was heritable and could mutate towards values > 0,       tion values of θ (innate punishment level) closely.
population θ values approached 1 within a few hundred gen-
erations (Figure 1). In the final, 4000th generation of each        Hierarchical model
simulation, the average population θ across 50 independent          Unlike the one-level models, in which population levels of
simulations was .98 (SE < .01).                                     both punishment and prosociality climbed rapidly towards 1
   Throughout the results section, we describe “population          (always punish theft, always expect theft to be punished) and
parameters” (e.g., “population θ”) meaning the average value        then remained relatively constant, simulations using a hierar-
of the parameter over the 25 individuals comprising the pop-        chical model typically exhibited large, synchronized fluctua-
ulation of a single simulation. Often, we discuss the ”average      tions of punishment and prosociality. A representative exam-
population parameter” across 50 simulations, referring to in-       ple of a single simulation is plotted in Figure 3a. (Because av-
dependent simulations of 50 different populations, each com-        eraging across distinct simulations masks these fluctuations,
prising 25 individuals. That is, we assess whether multiple         we have chosen to present graphical data from only a sin-
independent simulations are characterized by similar average        gle simulation. We selected an example with slightly more
values of the parameters of interest.                               fluctuations than typical, in order to provide several viewable
                                                                    instances for the reader. However, the degrees of synchro-
One-level model                                                     nization exhibited in Figures 3a and 3b were chosen from the
As in the uniform prior model, in the one-level model pop-          median).
ulation levels of punishment climbed towards the maximum               Figure 3a exhibits the relationship between population lev-
level (θ ≈ 1) within a few hundred generations, and the strat-      els of θ and population levels of the prior P(pun|theft), which
egy θ ≈ 1 typically continued to dominate the population            reflects an innate bias towards prosociality or antisociality.
for the remainder of the simulation (Figure 1). In the final,       At the end of the initial 1000 generations of each simulation,
4000th generation of each simulation, the average population        during which θ values were fixed at 0, the average popula-
θ across 50 independent simulations was .98 (SE < .01).             tion prior P(pun|theft) across 50 simulated populations was
   Unlike the uniform prior model, the one-level model al-          .12 (SE < .01), indicating a behavioral bias towards antiso-
lowed prior probabilities of punishment to mutate and evolve.       cial behavior. Over the course of the remaining 3000 simula-
At the end of the initial 1000 generations of each simulation,      tions, population levels of θ fluctuated between 0 and 1. And,
during which θ values were fixed at 0, the average popula-          the population prior P(pun|theft) typically tracked these fluc-
        α
tion α+β   across 50 distinct simulated populations was .05         tuating θs with a slight delay. Thus, innate expectations of
(SE < .01), indicating a behavioral bias towards antisocial         punishment tended to track actual punishment levels.
behavior. The average population α + β was 2.23 (SE .17),              Figure 3b exhibits the relationship between population lev-
indicating low levels of canalization of this innate antisocial     els of “group bias” and population levels of θ. The bright
bias.                                                               blue underlay indicates generations during where the herita-
   By the 2000th generation, however—following 1000 gen-            ble group bias parameter γ exceeded a value of 1.5. During
erations during which population θ values climbed towards           these periods, individuals tended to draw strong inferences
1—this innate behavioral tendency had reversed. The average         about the behavior of an individual based on their experience
population α+βα
                 was .91 (SE .01), indicating a behavioral bias     with others in the group. High levels of group bias were typ-
towards prosocial behavior. The average population α + β            ically followed by a drop in population levels of θ, while low
was 3.2 (SE .25), indicating low levels of canalization of this     levels of group bias were typically followed by an increase in
innate prosocial bias. For the remaining 2000 generations of        population levels of θ. Thus, punishment was favored most
each simulation, population levels of prosociality and canal-       strongly when levels of group bias were low.
ization remained largely stable.                                       A possible explanation for the relationship between group
                                                                    bias and punishment, discussed further below, can be suc-
      1                                                             cinctly stated: when most people punish, and potential per-
                                                                    petrators infer that you’ll do what most people do, you can
                                                                    get away with not punishing and avoid its associated fitness
    0.5
                                                     θ              costs.
                                               prosociality            If this explanation is correct then, given enough interac-
      0                                                             tions, it should be possible for perpetrators to learn who does
        1000           2000             3000           4000
                            Generations                             and who does not punish (overcoming a strong innate group
                                          α                         bias). In order to test this prediction, we ran 10 independent
Figure 2: Average population levels of α+β   and θ for 50 sim-      simulations of the hierarchical model where each agent con-
ulations over generations 1000-4000 (following the introduc-        siders stealing from each other agent 100 times, rather than
tion of θ > 0 as an evolvable strategy in generation 1000) for      the standard 25 times used above. At the final, 4000th gen-
the one-level model.                                                eration, average population θs were significantly higher for
                                                α
   As Figure 2 reflects, population values of α+β  (innate esti-    100 meeting simulations (M = .99, SE < .01) than for 25
mate of others’ punishment levels) typically tracked popula-        meeting simulations (M = .86, SE = .04, Mann-Whitney U
                                                                1777

                 1
               0.5                                                                θ
                                                                          P(pun|theft)
                 0
                 1000               1500             2000              2500              3000             3500             4000
                                                                   Generations
           (a) Population levels of prior P(pun|theft) and θ for a representative simulation over generations 1000-4000 (following
           the onset of θ > 0 as an evolvable strategy in generation 1000) for the hierarchical model.
                 1
               0.5                                                                 θ
                                                                               γ > 1.5
                 0
                 1000               1500             2000              2500              3000             3500             4000
                                                                   Generations
           (b) Population levels of θ (dark blue line) overlaid on a representation of generations with a population γ > 1.5 (light
           blue bars), for the same representative simulation over generations 1000-4000.
                                Figure 3: Median hierarchical simulation demonstrating cyclic behavior.
test: Z = −3.06, p < .01). Inspection of the individual simu-              a selective advantage to the strategy of punishing antisocial
lations revealed that fluctuations of punishment, prosociality             behavior.
and group bias were substantially less frequent in 100 meet-                  Additionally, our findings demonstrate that innate behav-
ing simulations, compared to 25 meeting simulations; how-                  ioral tendencies towards prosocial behavior are adaptively fa-
ever, some fluctuations did occur even with 100 meetings.                  vored in an environment where antisocial behavior is pun-
                                                                           ished. This was evident both in simulations implementing
Non-learning control models                                                one-level and hierarchical learning models. As population
All three of the non-learning control models tested yielded                levels of θs changed, innate levels of prosociality changed in
similar results: punitive strategies failed to emerge, and in-             response to closely track the true P(pun|theft). These models
nate prior probabilities of punishment tended towards canal-               provide a case-study in the use of Bayesian priors to model
ized antisociality. The average population thetas on the                   innate behavioral dispositions. This approach has attractive
4000th generation for the uniform prior model was .01 (SE                  characteristics: with a ready set of formal methods for com-
< .01), for the one-level model was .01 (SE < .01), and for                bining innate factors with experienced data, it allows innate
the hierarchical model was .01 (SE < .01). For the one-level               factors to vary in their behavioral consequences as well as in
                                                                   α
model, on the 4000th generation the average population α+β                 their developmental persistence (see also Kirby et al., 2007).
was .01 (SE < .01) and the average population (α + β) was                     Our findings confirm previous models suggesting that
1.09 (SE 1.3). For the hierarchical model, on the 4000th gen-              costly punishment and contingent prosociality can coevolve,
eration the average population ψ was -10.45 (SE 0.73), and                 (e.g. Boyd & Richerson, 1992; Gardner & West, 2004). In-
the average population γ was 1.09 (SE 1.31).                               deed, behavioral studies show that people will pay a cost to
                                                                           punish antisocial behavior, which can stabilizes prosocial be-
                            Discussion                                     havior (Fehr & Fischbacher, 2004). However, this same ex-
Our findings suggest that costly punishment of antisocial be-              perimental evidence demonstrates that punishment of anti-
havior is adaptively favored when it causes others to act                  social behavior by one individual will reliably induce more
prosocially in future interactions—that is, when agents learn              prosocial behavior when the perpetrator interacts with a dif-
to avoid punishment. This was evident in evolutionary sim-                 ferent individual. In the most extreme case of such a group-
ulations using three cognitive learning models: learning with              level bias, in which the perpetrator does not differentiate be-
a fixed uniform prior, a one-level model with evolvable pri-               tween the punishment rates of individual victims at all, pun-
ors, and a hierarchical model with evolvable priors. The evo-              ishment by any individual becomes a public good and should
lution of costly punishment was not observed in any of the                 not be selectively favored.
corresponding non-learning models. It is particularly notable                 Consequently, we explored the coevolution of punishment
that punishment readily invaded in the uniform prior model,                and prosociality using a hierarchical Bayesian model of learn-
which plausibly approximates the operation of a domain-                    ing in which inferences about an individual’s likelihood of
general learning mechanism (Courville, Daw, & Touretzky,                   punishing depends jointly on the prior history of punishment
2006; Tenenbaum et al., 2006). Thus, widely-shared psy-                    by that individual and the prior history of punishment by oth-
chological learning mechanisms may be sufficient to render                 ers. Critically, we allowed for mutation and natural selection
                                                                      1778

in the degree of group bias exhibited by learning agents—that         of evolutionary processes, exploring how adaptive pressures
is, their propensity to infer one individual’s punitive response      shape the boundary between the innate and the learned.
from past experience with others.
   The specific set of parameters we tested revealed a strik-
                                                                                          Acknowledgments
ing cyclical dynamic involving innate levels of group bias,           The authors acknowledge the Mind, Brain and Behavior Ini-
punishment, and prosociality. Inspection of the timing of             tiative at Harvard University and AFOSR under a MURI for
this cyclical dynamic suggests a simple course of events.             financial support. We thank Lisa Stewart, Joshua Tenenbaum,
First, population levels of punishment increase in the popula-        David Rand, Chris Barker, Daniel Roy, Whitman Richards
tion due to the benefits of teaching social partners contingent       and Joshua Greene for their advice and assistance.
prosociality. Next, population levels of prosociality increase,
                                                                                               References
reflecting an innate bias towards prosociality that is benefi-
cial in an environment where antisocial behavior is reliably          Boyd, R., & Richerson, B. R. (1992). Punishment allows
punished. In this environment a strong innate group bias can             the evolution of cooperation (or anything else) in sizable
also emerge, perhaps reflecting the homogeneity of punitive              groups. Ethology and Sociobiology, 13(3), 171–195.
strategies when θ ≈ 1 dominates the population. But when              Brandt, H., Hauert, C., & Sigmund, K. (2003). Punishment
this innate group bias emerges in a population dominated by              and reputation in spatial public goods games. Proceedings
punishment, it establishes a selective pressure favoring non-            of the Royal Society: Biological Sciences, 270, 1099–1104.
punitive strategies (i.e. θ ≈ 0). When individuals expect in-         Courville, A., Daw, N., & Touretzky, D. (2006). Bayesian
dividual punishment because it is frequent at the group level,           theories of conditioning in a changing world. TRENDS in
there is a selective advantage to not punishing, thereby avoid-          Cognitive Sciences, 10(7), 294–300.
ing its costs. Thus, the emergence of a strong group bias in a        Daw, N. D., & Doya, K. (2006). The computational neurobi-
population dominated by punitive strategies frequently leads             ology of learning and reward. Current Opinion in Neurobi-
to a rapid invasion by the strategy θ ≈ 0. Following such a              ology, 16(2), 199–204.
shift, population levels of prosociality fall, and then the cycle     Fehr, E., & Fischbacher, U. (2004). Social norms and human
stands ready to be repeated anew.                                        cooperation. TRENDS in Cognitive Sciences, 8(4), 185–
                                                                         190.
   The cyclical dynamic revealed in our hierarchical learning
                                                                      Fehr, E., & Gachter, S. (2002). Altruistic punishment in
model depends on several features of a Bayesian approach to
                                                                         humans. Nature, 415(6868), 137–140.
modeling the evolution of social behavior: the ability to cap-
                                                                      Gardner, A., & West, S. A. (2004). Cooperation and punish-
ture prosocial behavioral tendencies in terms of innate prior
                                                                         ment, especially in humans. American Naturalist, 6(6868),
probabilities; the ability to model group bias in the form of
                                                                         753–764.
a hierarchical learning model; and the ability to flexibly bal-
                                                                      Gintis, H., Bowles, S., Boyd, R., & Fehr, E. (2005). Moral
ance innate and learned factors along the dimensions of canal-
                                                                         sentiments and material interests: Origins, evidence, and
ization and prosociality.
                                                                         consequences. In H. Gintis, S. Bowles, R. Boyd, & E. Fehr
   However, the choice of a Bayesian framework to repre-                 (Eds.), Moral sentiments and material interests: The foun-
sent innate behavioral tendencies carries a definite cost. It            dations of cooperation in economic life. Cambridge, MA:
has been repeatedly demonstrated in experimental settings                MIT Press.
that individuals engage in prosocial behavior even when they          Griffiths, T. L., Kemp, C., & Tenenbaum, J. B. (2008).
have no expectation—at least explicitly—of contingent re-                Bayesian models of cognition. In R. Sun (Ed.), The
ward or punishment (reviewed in Gintis, Bowles, Boyd, &                  Cambridge handbook of computational cognitive model-
Fehr, 2005). A standard inference from these findings is that            ing. Cambridge, UK: Cambridge University Press.
some prosocial behaviors have intrinsic utility (innate or oth-       Kirby, S., Dowman, M., & Griffiths, T. L. (2007). Innateness
erwise) beyond the expected value of contingent reward or                and culture in the evolution of language. Proceedings of
punishment. Thus, it is unlikely that prosocial behavior can             the National Academy of Sciences, 104(12), 5241–5245.
be understood at a mechanistic level just in terms of poste-          Sigmund, K., Hauert, C., & Nowak, M. A. (2001). Reward
rior probabilities of punishment and reward. Nevertheless,               and punishment. Proceedings of the National Academy of
the Bayesian framework we adopt here has apparent value in               Sciences, 98(19), 10757–10762.
modeling innate behavioral tendencies at a functional level.          Spelke, L. (2000). Core knowledge. American Psychologist,
   Moreover, beyond the specific case of prosocial behavior, it          55, 1233–1243.
appears that humans are equipped with certain forms of innate         Tenenbaum, J., Griffiths, T. L., & Kemp, C. (2006). Theory-
knowledge and constraints on knowledge acquisition (Spelke,              based bayesian models of inductive learning and reasoning.
2000). The ease with which innate knowledge and constraints              TRENDS in Cognitive Sciences, 10(7), 309–319.
can be combined with experience is among the principle ben-           Traulsen, A., Pacheco, J., & Nowak, M. (2007). Pair-
efits of a Bayesian framework. We suggest that a fruitful di-            wise comparison and selection temperatiure in evolutionary
rection for future research in social cognition will be to in-           game dynamics. Journal of Theoretical Biology, 246(3),
troduce these Bayesian models into agent-based simulations               522–529.
                                                                  1779

