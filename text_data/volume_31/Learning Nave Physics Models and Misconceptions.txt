UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Naïve Physics Models and Misconceptions
Permalink
https://escholarship.org/uc/item/79q4p98w
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Forbus, Kenneth
Friedman, Scott
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                           Learning Naïve Physics Models and Misconceptions
                                      Scott E. Friedman (friedman@northwestern.edu)
                              Qualitative Reasoning Group, Northwestern University, 2133 Sheridan Rd
                                                          Evanston, IL 60208 USA
                                       Kenneth D. Forbus (forbus@northwestern.edu)
                              Qualitative Reasoning Group, Northwestern University, 2133 Sheridan Rd
                                                          Evanston, IL 60208 USA
                             Abstract                                     We next briefly summarize the relevant aspects of
  Modeling how intuitive physics concepts are learned from
                                                                       qualitative process theory and structure-mapping theory
  experience is an important challenge for cognitive science.          used in the simulation. Then we describe how our stimuli
  We describe a simulation that can learn intuitive causal             are represented and encoded, motivated by results and ideas
  models from a corpus of multimodal stimuli, consisting of            from the cognitive science literature (diSessa, 1993; Talmy,
  sketches and text.         The simulation uses analogical            1988; Zacks, Tversky, & Iyer, 2001). The learning process
  generalization and statistical tests over qualitative                itself is described next, followed by how the learned models
  representations it constructs from the stimuli to learn abstract     are used in reasoning. We show that the simulation’s
  models. We show that the explanations the simulation
  provides for a new situation are consistent with explanations        explanations of a situation where a book is at rest on a table
  given by naïve students.                                             are compatible with student explanations (Brown, 1994).
                                                                       We close with other related work and future work.
   Keywords: Cognitive modeling; conceptual change;
   misconceptions; naïve physics; qualitative reasoning
                                                                                               Background
                        Introduction                                   People’s intuitive physical knowledge appears to rely
                                                                       heavily on qualitative representations (Forbus & Gentner,
Many people have intuitive models of physical domains that
                                                                       1986; Baillargeon, 1998). Consequently, we use qualitative
are at odds with scientific models (Minstrell, 1982;
                                                                       process theory (Forbus, 1984) as part of our model. In QP
McCloskey, 1983; diSessa, 1993; Brown, 1994). While
                                                                       theory, physical processes are the mechanism of causality
productive for reasoning about everyday physical
                                                                       for changes in dynamic systems. However, the learning we
phenomena, these naïve models cause patterns of
                                                                       are describing here is what provides the foundation for
misconceptions. These misconceptions may result from
                                                                       ultimately learning physical processes; in the framework of
improperly generalizing or contextualizing experience
                                                                       (Forbus & Gentner, 1986), we are modeling the construction
(Smith, diSessa, & Roschelle, 1994) or from incorporating
                                                                       of protohistories from experience, and building on those a
instruction into a flawed intuitive framework (Vosniadou,
                                                                       causal corpus consisting of causal relationships between
1994). Understanding how such intuitive models come
                                                                       those typical patterns of behavior. To model these patterns
about is an important problem for understanding how people
                                                                       of behavior, we use the concept of encapsulated history
learn physical domains (Forbus & Gentner, 1986).
                                                                       (EH) from QP theory.
   We believe it is important for computational models of
                                                                          An encapsulated history represents a category of
domain learning and conceptual change (e.g. Ram, 1993;
                                                                       abstracted behavior, over some span of time. It can include
Esposito et al., 2000) to encompass the learning of the initial
                                                                       multiple qualitative states and events.         Encapsulated
intuitive concepts. This paper describes a simulation of
                                                                       histories are used when a learner does not yet understand
learning intuitive physics models from experience.
                                                                       how to reduce a behavior to physical processes.
Experiences are provided as combinations of sketches and
                                                                       Encapsulated histories are a type of schema, and
natural language, which are automatically processed to
                                                                       consequently have variables. The participants are the
produce symbolic representations for learning. The system
                                                                       entities that an EH is instantiated over. The conditions are
identifies and encodes instances of the concepts to be
                                                                       statements which must be true for an instance of the EH to
learned and constructs qualitative representations of
                                                                       be active. When an instance of an EH is active, the
behavior across time. Analogical generalization is used
                                                                       statements in its consequences are assumed to be true.
with a statistical criterion to induce abstract models of
                                                                       Encapsulated histories are a form of explanatory schema:
typical patterns of behavior, which constitutes our
                                                                       When instantiated, they provide an explanation for a
representation of intuitive models. These models can be
                                                                       behavior via recognizing it as an instance of a typical
used to make predictions and perform simple counterfactual
                                                                       pattern, and furthermore can provide causal explanations, if
reasoning. We compare its explanations to those of human
                                                                       there is causal information in the consequences.
students on a simple reasoning task (Brown 1994).
                                                                   2505

   Since EHs can include multiple qualitative states, they
can be used for learning causal relationships between
behaviors and properties of the world. In naïve mechanics,
for example, the models of movement, pushing, and
blocking learned by the simulation are represented by
encapsulated histories. Figure 1 shows an EH learned by
the simulation. This can be read as: P1 pushes P2 while P1
and P2 touch; the direction from the pusher P1 to the                                   Figure 2: A sketched behavior
pushed P2 matches the direction of the push; and pushed P2
consequently moves (M1) in the direction of the push.
When given a novel test scenario, the EHs learned by the
                                                                                         Multimodal Stimuli
system are checked to see if there are entities that match the      To reduce tailorability, we provide experiences to the
participants. If so, instances of those EHs are created. Each       simulation in the form of sketches accompanied by natural
EH instance is active only if the statements in its conditions      language text. This serves as an approximation to what
hold in the scenario. If the consequences fail to hold, that is     learners might perceive and hear in the world. The sketches
a prediction failure for the EH.                                    are created in CogSketch1 (Forbus et al., 2008), an open-
                                                                    domain sketch understanding system. In CogSketch, users
  define-encapsulated-history Push05                                draw and label glyphs to link the content of the sketches to
  Participants:                                                     concepts in CogSketch’s knowledge base2. CogSketch
  Entity(?P1), Entity(?P2), PushingAnObject(?P3),
  Direction(?dir1), Direction(?dir2)
                                                                    automatically computes qualitative spatial relations between
  Conditions:                                                       the glyphs such as topological relations, relative size, and
  providerOfMotiveForce(?P3, ?P1), objectActedOn(?P3,               positional relationships (e.g., above). Behaviors are
  ?P2), dir-Pointing(?P3, ?dir1), touches(?P1, ?P2),
  dirBetween(?P1, ?P2, ?dir1), dirBetween(?P2, ?P1,                 segmented according to qualitative differences in behavior,
  ?dir2)                                                            such as changes in contact and actions of agents. This is
  Consequences:
  causes-SitProp(Push05,
                                                                    common practice in qualitative reasoning research, and
                   (exists ?M1                                      seems psychologically plausible (Zacks, Tversky, and Iyer,
                      (and MovementEvent(?M1),                      2001). Each distinct state is drawn as a separate sketch.
                           objectMoving(?M1, ?P2),
                           dir-Pointing(?M1, ?dir1)))               The sequential relationships between them are drawn as
                                                                    arrows on the metalayer, where other sub-sketches are
     Figure 1: An encapsulated history relating pushing and         treated as glyphs, as shown in Figure 2. Figure 3 shows a
                           movement.                                close-up of one of the sketched states. The child, truck, and
                                                                    car are glyphs in the sketch. The two right-pointing arrows
   Our hypothesis is that people use analogical                     are pushing annotations.
generalization to construct encapsulated histories. To model
this process, we use SEQL (Keuhne et al., 2000). SEQL is
grounded in structure-mapping theory (Gentner, 1983), and
uses the Structure-Mapping Engine, SME (Falkenhainer et
al 1989) as a module. Given two representations, a base and
a target, SME computes a set of mappings that describe how
they can be aligned (i.e. correspondences), candidate
inferences that might be projected from one description to
the other, and a structural evaluation score that provides a
numerical similarity score. SEQL uses SME as follows.                         Figure 3: Example state drawn in CogSketch.
SEQL maintains a list of exemplars and generalizations.
Given a new exemplar, it is first compared against each             Our encoding of the physical phenomena of pushing,
generalization. If the score is over the assimilation               movement, and blocking as separate concepts is motivated
threshold, they are combined to update the generalization.          by two lines of evidence. diSessa (1993) notes that people
Otherwise, the new exemplar is compared with the                    are unlikely to confuse successful resistance (i.e. a wall
unassimilated exemplars. Again, if the score is high                blocking a person’s push) from nonsuccess (i.e. a ball
enough, the two exemplars are combined to form a new                moving due to tugging a string) in recalling events, and that
generalization. Otherwise, the exemplar is added to the list        these phenomena are encoded separately. Talmy (1988)
of unassimilated exemplars. The combination process                 attributes this separation of success and nonsuccess
maintains a probability for each statement in a
generalization, based on how frequently it occurred in the             1
                                                                         CogSketch is available online at
exemplars generalized within (Halstead & Forbus, 2005).             http://spatiallearning.org/projects/cogsketch_index.html
These probabilities are used in our simulation for doing               2
                                                                         CogSketch uses a combination of knowledge extracted from
statistical tests.                                                  OpenCyc (www.opencyc.org) and our own extensions for
                                                                    qualitative, analogical, and spatial reasoning.
                                                                2506

encoding to varying language schemata between the two             pattern that is used to determine when an exemplar is
conditions.                                                       relevant. For example, the entry pattern for pushing is (and
   For information not easily communicated via sketching,         (isa ?x PushingAnObject) (providerOfMotiveForce ?x
we use simplified English, which is converted to predicate        ?y) (objectActedOn ?x ?z)).             Figure 4 shows the
calculus via a natural language understanding system              generalization contexts and their contents after the learning
(Tomai & Forbus, 2009). Here is one of the sentences from         experiment described below. Multiple generalizations exist
our example: “The child child-13 is playing with the truck        in Pushing and Moving contexts because certain exemplars
truck-13.” The special names child-13 and truck-13 are            are not structurally similar enough to share a generalization.
the internal tokens used in the sketch for the child and the      Consequently, each generalization within a context
truck respectively, so that linguistically expressed              represents a different behavior of the same concept. Our
information is linked with information expressed via the          simulation currently operates in batch mode, only
sketch. This sentence leads to these assertions being added       constructing models after all stimuli have been processed.
to the exemplar:
   (isa truck-13 Truck)
   (isa play1733 RecreationalActivity)
                                                                         Pushing
   (performedBy play1733 child-13)
   (with-UnderspecifiedAgent play1733 truck-13)
   If the NLU system finds an ambiguity it cannot handle, it
displays alternate interpretations for the experimenter to
choose. But again, the choices are created by the NLU                    Moving                             Generalization
system: No hand-coded predicate calculus statements are                                                     Contexts
included in the stimuli.
   To be sure, this method of simulation input has
limitations: Sketches are less visually rich than images, and                                               Ungeneralized
                                                                         Blocking
they do not provide opportunities for the learner to                                                        Exemplars
experiment.      Nevertheless, we believe that this is a                               Generalizations
significant advance over the hand-coded stimuli typically
used by other systems, given the reduction in tailorability.
                                                                          Figure 4: Generalization contexts after learning
CogSketch is being developed in part as a model of human
visual perception, so there is independent support for many
of its representational choices. Sketching and simplified
                                                                  Constructing intuitive models
English are natural human communication methods, so               The simulation creates encapsulated histories from
preparation of stimuli is simplified as well.                     protohistories in two steps: (1) Statistics are used to
                                                                  determine which generalizations are worth modeling with
                          Learning                                encapsulated histories, and (2) worthwhile generalizations
                                                                  are parameterized to create encapsulated histories. We
The simulation is provided with a set of target phenomena
                                                                  discuss each step in turn.
that it is trying to learn, here pushing, movement, and
blocking. We assume that for a truly novice learner, words
                                                                  Filtering generalizations
used in contexts of behaviors that they do not understand are
                                                                  Not all analogical generalizations lead to useful
clues that there is something worth modeling.
                                                                  encapsulated histories. If the conditions are too broad,
   Given a new stimulus, a set of exemplars is produced, one
                                                                  inaccurate predictions will result.           The probability
for each occurrence of a target phenomenon. Since an
                                                                  information constructed during generalization provides an
instance of a particular phenomenon may continue across
                                                                  important filter. We assume a probability threshold t (here,
state boundaries, these occurrences can span multiple states.
                                                                  0.9) for correlation. That is, if any target phenomenon p is
Temporal relationships between these occurrences are
                                                                  in a generalization with probability P(p) ≥ t, then p is
derived to support learning of preconditions and
                                                                  considered a correlated phenomenon within that
consequences. For example, consider a series of states S1-
                                                                  generalization’s context. A generalization is decisive if the
S3, where a man is pushing a crate in S1-S2 and not in S3,
                                                                  binary entropy H(P(p)) ≤ H(t), for all phenomena p
and the crate moves in S2-S3 but not in S1. The motion
                                                                  correlated with its generalization context. Entropy is the
would have a startsDuring relationship with the
                                                                  appropriate criterion to use because it measures information
pushing. Each stimulus observed by the simulation is              gain (i.e., low entropy implies high gain). All decisive
automatically temporally encoded into exemplars using this        generalizations are parameterized into encapsulated
strategy.                                                         histories.
Generalizing behaviors                                            Extracting Causal Models from Generalizations
For each target phenomenon, the simulation maintains a            The system creates one encapsulated history per decisive
separate copy of SEQL, a generalization context (Friedman         generalization. Expressions whose probability is lower than
& Forbus, 2008). A generalization context has an entry
                                                              2507

the probability threshold t are filtered, thus reducing              participants be identifiable in the scenario.           Event
contingent phenomena.         Expressions that remain are            participants need not be identified because these can be
analyzed to determine what role they should play in the              instantiated as predictions.
encapsulated history. An expression is held to be either (a)
a cause of the state, (b) a consequence of the state, or (c) a
condition that holds during the state, based on analyzing the
temporal relationships involved. If the expression occurs
before the start of the current state and persists until or
throughout the current state, it is a possible cause. If an
expression temporally subsumes or coincides with the state,
it is a possible condition. If it begins during, with, or
immediately after the end of the current state, it is a possible
                                                                       Figure 5: An example from Brown (1994) for testing learned
consequence.                                                                                   knowledge
     Probabilities and temporal relationships are used to
hypothesize causal relationships. For instance, in one                  Specifically, activating Block00 to explain gravity
generalization, movement starts with a pushing event with
                                                                     pushing the book requires assuming two additional events:
P=0.5, and starts after a pushing event with P=0.5. In this
                                                                     (1) the book ?P2 pushes some adjacent object ?P3 in the
case, movement is not a likely condition for pushing
                                                                     direction ?dir1 of the initial push, and (2) the entity ?P3
because it only satisfies the temporal requirement half the
                                                                     blocks the book ?P2. The table alone satisfies the
time. Conversely, movement is a likely consequence,
                                                                     constraints on ?P3, binding the last of the non-event
because starting with and starting after are both permissible
                                                                     participants. This is sufficient grounds for the simulation to
temporal relations of consequences.
                                                                     instantiate new pushing and blocking events, binding them
   After the causes, conditions, and consequences are
                                                                     to ?P6 and ?P7, respectively.
determined, the simulation defines an encapsulated history
by introducing variables for the entities that appear in the           define-encapsulated-history Block00
conditions, existence statements for the entities that only            Participants:
appear in the consequences, and using the attribute                    Entity(?P1), Entity(?P2), Entity(?P3), Entity(?P4),
                                                                       PushingAnObject(?P5), PushingAnObject(?P6),
information in the generalization to construct the                     Blocking(?P7)
participants information. Figure 1 and 6 illustrate. Notice
that, while the learning process removes most irrelevancies,           Conditions:
                                                                       providerOfMotiveForce(?P5, ?P2), objectActedOn(?P5,
in Block00 the entity ?P1 is included even though it is                ?P3), providerOfMotiveForce(?P6, ?P3),
not causally relevant. It is there because the examples                objectActedOn(?P6, ?P4), doneBy(?P7, ?P4),
                                                                       objectActedOn(?P7, ?P3), dir-Pointing(?P5, ?dir1), dir-
involving pushing all involve the pushing agent standing or            Pointing(?P6, ?dir1), dirBetween(?P2, ?P3, ?dir1),
sitting on a surface – so to the simulation, blocking must             dirBetween(?P3, ?P4, ?dir1), dirBetween(?P3, ?P2,
                                                                       ?dir2), dirBetween(?P4, ?P3, ?dir2), touches(?P2, ?P3),
involve touching something else.                                       touches(?P3, ?P4), touches(?P2, ?P1)
       Reasoning with Encapsulated Histories                             Figure 6: An encapsulated history relating pushing and
Given a new scenario, the simulation attempts to make                                     blocking phenomena
sense of it by instantiating its encapsulated histories. For
each EH, it finds combinations of entities that satisfy its             The simulation has two strategies for answering questions
Participants and Conditions constraints. When these                  about a scenario. If the question concerns a phenomenon
constraints are completely satisfied for a set of entities, an       that is predicted by the EH instances it has created for the
instance of that EH is considered to be active, meaning that         scenario, it answers based on that information, including
the statements in its Consequences are assumed to hold.              any causal argument provided as part of the EH. If the
As shown in Figure 1, this can include predicting new                question concerns some phenomenon that is not predicted, it
phenomena. When some of these constraints are violated,              assumes that phenomenon occurs and looks at what new
or some of the consequences are not satisfied, the EH                EHs could be instantiated to explain it. The instantiation
instance can be used for generating counterfactual                   failures for those EH instances are provided as the reasons
explanations, as explained below.                                    for the phenomenon not occurring, as shown below.
   To illustrate, consider a scenario used by Brown (1994)
and others, illustrated in Figure 5. The sketch shows a book                                 Experiment
on a table. Gravity pushes down on the book and the table.           To test whether this model can learn psychologically
The scenario description includes two occurrences of                 plausible encapsulated histories from multimodal stimuli,
pushing: gravity pushing the book and gravity pushing the            we compare explanations it provides for a question from
table. The encapsulated history in Figure 6 can be                   Brown’s (1994) assessment of student mental models. We
instantiated sufficiently to be considered for inference by          start by summarizing Brown’s results, and then we describe
the simulation, since the criterion is that all non-event            the conditions used for the simulation and compare its
                                                                 2508

results. If the explanations used by the students and the           active, the simulation gets a new prediction: The book
simulation are compatible on the same reasoning task, then          should move upward as a result of the push. This prediction
the simulation has learned psychologically plausible                contradicts the book’s lack of motion in the scenario.
intuitive models.                                                   Consequently, it answers that the table does not push up on
                                                                    the book, because in that case the book would move
Brown’s results                                                     upward, and it does not. This is essentially the same as
A question about the scenario in Figure 5 was asked of              answer 5, given by four students.
students: Does the table exert a force against the book?               After the proof by contradiction, the system cites
   Brown reported that 33 of 73 students agreed that the            activated EHs in which the book and table jointly participate
table exerts an upward force on the book, because it must, in       to explain their behavior in the scenario. Consequently, it
order to counteract the downward force of the book. This is         uses the EH in Figure 6 to explain that gravity pushes down
the scientifically correct answer. However, the 40-student          on the book, that the book pushes down on the table, and
majority denied that the table exerted this force. Their            that the table blocks the book. This is similar to answer 4,
reasons fell into five categories:                                  given by four students. This explanation also resembles
     1. Gravity pushes the book flat, and the book exerts a         answer 1, given by 19 students, though the students cite the
          force on the table. The table merely supports the         concept of support, which was not among the simulation’s
          book (19 students)                                        target phenomena. These results support the hypothesis that
     2. The table requires energy to push (7 students)              the models learned by the simulation are like those used by
     3. The table is not pushing or pulling (5 students)            naïve students.
     4. The table is just blocking the book (4 students)               Could the system learn models corresponding to the other
     5. The book would move up if the table exerted a               answers? If the target phenomena and corpus included the
          force (4 students)                                        concept of support and energy, it seems likely to us that it
   We query our simulation similarly, to determine whether          could, but this is an empirical question. With a different
it can reproduce some of the reasons that students gave.            corpus of examples – perhaps including examples like those
                                                                    used by Camp & Clement (1994) and the rest of Brown
Simulation setup                                                    (1994) – the simulation may be capable of coming to the
                                                                    correct model. Answer 3 may rest on an interpretation of
Our simulation was implemented using the Companions
                                                                    events being mutually exclusive, i.e., if the table is blocking,
Cognitive Systems architecture (Forbus et al., 2008). We
                                                                    then it cannot be doing the other actions.               Further
used 17 multi-state sketches as stimuli, using examples
                                                                    experiments should clarify this.
motivated by the mental models literature cited earlier. This
set did not include the test scenario. The SEQL assimilation
threshold was set to 0.5 and the encapsulated history                                     Related Work
probability threshold was set to 0.9. The temporal encoding         The closest simulations are the COBWEB (Fisher, 1986)
step resulted in 28 pushing exemplars, 16 moving                    model of conceptual clustering and INTHELEX (Esposito et
exemplars, and 6 blocking exemplars. These exemplars                al., 2000), which develops and revises prolog-style theories.
produced ten generalizations across the three generalization        COBWEB does unsupervised learning of hierarchical
contexts, as illustrated in Figure 4.           Six of these        relationships between concepts, in contrast with our use of
generalizations were decisive, leading to the pushmove             supervised learning (via entry patterns in generalization
model of Figure 1, the pushblock model in Figure 6, and            contexts) of causal models.            COBWEB calculated
four additional models.                                             probabilities of features, whereas SEQL provides
   The four additional models learned by the system were            probabilities of structured relations. INTHELEX uses
not activated during this test scenario. Three EHs described        refinement operators to model multiple steps in a trajectory
movement behaviors caused by pushing, with minor                    of learned models, whereas we focus only on one transition,
variations in the conditions. The fourth EH describes               the first. Both COBWEB and INTHELEX used hand-
classic “billiard ball” causality, with a push causing motion,      represented input stimuli, whereas ours is derived by the
which then causes another push and setting another entity           simulation from sketches and natural language. Ram (1993)
into motion.                                                        discusses SINS, a robot navigation system that retrieves
                                                                    cases, adapts control parameters, and learns new
Comparison with human results                                       associations incrementally. While both our system and
                                                                    SINS develop concepts incrementally from experience, our
Given these EHs, how does the system perform? Upon
                                                                    system learns models of physical behaviors and causal laws,
receiving the test scenario, the system activates EHs to infer
                                                                    and SINS learns associations between environmental
the additional events of the book pushing down against the
                                                                    conditions and control parameters.
table and the table pushing down against the ground.
                                                                       Lockwood et al. (2005) used CogSketch and SEQL to
   For the query, since the simulation does not have the
                                                                    model the learning of spatial prepositions, using single
event of the table pushing the book as a current prediction, it
                                                                    sketches labeled with words, in contrast to the sequence of
uses the counterfactual strategy. Only the EH of Figure 1
                                                                    sketches labeled with sentences used here.
can provide a possible explanation. Assuming this EH is
                                                                2509

               Discussion & Future Work                             Fisher, D. H. (1987). Knowledge acquisition via incremental
                                                                      concept clustering. Machine Learning, 2,139-172.
We have described how analogical generalization and
                                                                    Forbus, K. (1984). Qualitative process theory. Artificial
qualitative representations can be used to model the process
                                                                      Intelligence, 24, 85-168.
of learning initial intuitive models. To reduce tailorability,
                                                                    Forbus, K. and Gentner, D. (1986). Learning Physical
the simulation inputs were combinations of sketches and
                                                                      Domains: Towards a Theoretical Framework. In
simplified English. The resulting explanations resemble a
                                                                      Michalski, R., Carbonell, J. and Mitchell, T. (Eds.),
subset of those of given by human students on a scenario.
                                                                      Machine Learning: An Artificial Intelligence Approach.
   While we believe that this is a significant first step, there
                                                                    Forbus, K., Lovett, A., Lockwood, K., Wetzel, J., Matuk,
is much more to be done. First, a broader variety of
                                                                      C., Jee, B., and Usher, J. (2008). CogSketch. Proceedings
phenomena must be tested, to provide more evidence as to
                                                                      of AAAI 2008.
generality. Second, we need to conduct statistical tests to
                                                                    Forbus, K., Klenk, M. and Hinrichs, T. (2008). Companion
determine how order-sensitive the simulation is, and how
                                                                      Cognitive Systems: Design Goals and Some Lessons
the quality of models learned varies with the number of
                                                                      Learned. AAAI Fall Symposium on Naturally Inspired
examples provided. By comparing models learned with
                                                                      Artificial Intelligence.
different numbers of examples, can we find sequences of
                                                                    Friedman, S. & Forbus, K. (2008). Learning Causal Models
models that correspond to known developmental
                                                                      via Progressive Alignment & Qualitative Modeling: A
trajectories? That will help determine how much of the
                                                                      Simulation. Proceedings of CogSci 2008.
development of mental models this simulation can explain.
                                                                    Gentner, D. (1983). Structure-mapping: A theoretical
Finally, we plan to incorporate these ideas in a larger-scale
                                                                      framework for analogy. Cognitive Science, 7(2).
model of conceptual change, where the quality and content
                                                                    Halstead, D. and Forbus, K. (2005). Transforming between
of its predictions guide future learning.
                                                                      Propositions and Features: Bridging the Gap. Proceedings
                                                                      of AAAI-2005. Pittsburgh, PA.
                      Acknowledgments                               Kuehne, S., Forbus, K., Gentner, D. and Quinn, B. (2000).
This work was funded by the Office of Naval Research                  SEQL: Category learning as progressive abstraction using
under grant N00014-08-1-0040. We wish to thank Dedre                  structure mapping. Proceedings of CogSci 2000.
Gentner and Jason Taylor for discussions of concept                 Lockwood, K., Forbus, K., & Usher, J. (2005). SpaceCase:
formation with SEQL.                                                  A model of spatial preposition use. Proceedings of the
                                                                      27th Annual Conference of the Cognitive Science Society.
                          References                                McCloskey, M. (1983). Naive theories of motion. In: D.
Baillargeon, R. (1998). A model of physical reasoning in              Gentner and A.L. Stevens, Eds. Mental models. Erlbaum,
   infancy. Advances in infancy research, 3, 305-371.                 Hillsdale, NJ. 299–324.
Brown, D. (1994). Facilitating conceptual change using              Minstrell, J. (1982). Explaining the “at rest” condition of an
   analogies and explanatory models. International Journal            object. The Physics Teacher, 20(1), 10-14.
   of Science Education, 16(2), 201-214.                            Ram, A. (1993). Creative conceptual change. Proceedings
Brown, D. & Clement, J. (1989). Overcoming                            of CogSci 1993.
   misconceptions via analogical reasoning: abstract transfer       Smith, J., diSessa, A., & Roschelle, J. (1994).
   versus explanatory model construction. Instructional               Misconceptions Reconceived: A Constructivist Analysis
   Science, 18(4), 237-267.                                           of Knowledge in Transition. Journal of the Learning
Camp, C. W., & Clement, J. J. (1994). Preconceptions in               Sciences, 3(2), 115-163.
   mechanics. Lessons dealing with students' conceptual             Talmy, L. (1988). Force dynamics in language and
   difficulties. Dubuque, IA: Kendall/Hunt Publishing                 cognition. Cognitive Science, 12(1), 49-100.
   Company.                                                         Tomai, E. and Forbus, K. (2009). EA NLU: Practical
Chi, M., Slotta, J., & De Leeuw, N. (1994). From things to            Language Understanding for Cognitive Modeling.
   processes: A theory of conceptual change for learning              Proceedings of the 22nd International Florida Artificial
   science concepts. Learning and Instruction, 4(1), 27-43.           Intelligence Research Society Conference.
diSessa, A. (1993). Toward an Epistemology of Physics.              Vosniadou, S. (1994). Capturing and modeling the process
   Cognition and Instruction, 10(2-3), 105-225.                       of conceptual change. Learning and Instruction, 4, 45-69.
Esposito, F., Semeraro, G., Fanizzi, N., & Ferilli., S. (2000).     Zacks, J., Tversky, B., & Iyer, G. (2001). Perceiving,
   Conceptual Change in Learning Naive Physics: The                   remembering, and communicating structure in events.
   Computational Model as a Theory Revision Process. In E.            Journal of Experimental Psychology. General. 130(1),
   Lamma and P. Mello (Eds.), AI*IA99: Advances in                    29-58.
   Artificial Intelligence, Lecture Notes in Artificial
   Intelligence 1792, 214-225, Springer: Berlin.
Falkenhainer, B., Forbus, K. and Gentner, D. (1989). The
   Structure Mapping Engine: Algorithm and examples.
   Artificial Intelligence, 41, 1-63.
                                                                2510

