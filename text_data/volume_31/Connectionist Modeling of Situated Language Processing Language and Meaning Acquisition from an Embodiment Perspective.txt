UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Connectionist Modeling of Situated Language Processing: Language and Meaning
Acquisition from an Embodiment Perspective
Permalink
https://escholarship.org/uc/item/1sm072jg
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Baumann, Peter
Konieczny, Lars
Muller, Daniel
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       Connectionist Modeling of Situated Language Processing:
              Language and Meaning Acquisition from an Embodiment Perspective
    Helmut Weldle (helmut.weldle@misc.uni-freiburg.de), Lars Konieczny (lars@cognition.uni-freiburg.de),
      Daniel MÃ¼ller (daniel@cognition.uni-freiburg.de), Sascha Wolfer (sascha@cognition.uni-freiburg.de),
                                Peter Baumann (peter.baumann@cognition.uni-freiburg.de)
                                 Center for Cognitive Science, University of Freiburg, Friedrichstr. 50
                                                     D-79098 Freiburg i. Br., Germany
                             Abstract                                  analogical nature this could be a guideline for subsymbolic
                                                                       accounts for grounding language comprehension.
   Recent connectionist models and theories of embodied
   cognition offer new perspectives on language comprehension.         Connectionist models of language comprehension
   We review the latest accounts on the issue and present an SRN-
   based model, which incorporates ideas of embodiment theories        Several connectionist architectures deal with the task of
   and avoids (1) vast architectural complexity, (2) explicit          language comprehension and integration of language and
   structured semantic input, and (3) separated training regimens      events, proposing different realizations of semantic
   for processing components.                                          representation and implementations of the integration process.
   Keywords: language acquisition, comprehension, production;             Rohde (2002) introduced the Connectionist Sentence
   sentence processing; language-vision integration; visual            Comprehension and Production Model, an architecture based
   attention; embodied cognition; connectionist modeling; SRNs.        on extended simple recurrent networks (SRNs, Elman, 1990)
                                                                       which is capable of comprehending and producing complex
                                                                       sentences, covering a wide range of well-known empirical
                         Introduction                                  phenomena. The model clearly focuses on scalability,
'Gavagai!' If we heard a native speaking a foreign language            however possibly at the expense of explanatory power and
utter this word upon seeing a rabbit, we would be faced with           psychological plausibility. Especially relevant for our issue is
the problem Quine described in Ontological Relativity                  the realization of the semantic component: Rohde's model is
(1968): How do we know what exactly an utterance refers to             trained with explicit propositional representations prior to the
in an infinitely rich set of objects, events and relations our         corresponding target sentence. This greatly assists the
environment provides? But this problem appears almost                  network, leaving no way to tell whether it simply succeeds
trivial compared to a human child confronted with the task to          because the semantic representation provided all crucial
acquire its mother's language. Several sub-tasks have to be            information explicitly. Learning of the propositions is
solved simultaneously to achieve this grounding of speech to           achieved through a query mechanism, inquiring each of its
referential meaning: there is the problem of a highly complex          parts, a process questionable in its cognitive adequacy.
world rich in details, happenings and relations. There is the             The problem of explicit information holds similarly for the
problem of a continuous stream of words. There is the large            Incremental Nonmonotonic Self-organization of Meaning
problem of relating the one to the other. And there is the             Network (Mayberry, 2003). The semantic representations
problem that there is no previously given language to help             used in the model are based on Minimal Recursion Semantics
finding this relation.                                                 (Copestake et al., 2005), which makes them very powerful
   In other words, the task is to bind a holistic situation to a       and complex information carriers. The model is capable of
sequential series of related linguistic expressions. This affords      parsing natural language corpora, an impressive achievement,
to integrate representations of language and the outside world,        reached at the expense of a highly complex, opaque
both represented in distinctive forms, following completely            architecture and pre-fabricated semantic content. In a more
different rules and depending on different hierarchical and            recent study Mayberry, Crocker and Knoeferle (2005)
causal relations. A central aspect of models of language               introduced the Coordinated Interplay Account Network
comprehension and acquisition is how they account for these            which integrates a scene representation with the incremental
questions. In connectionist models, language interpretation            input of a sentence description, enabling adaptive use of
and integration of situational context is based on mechanisms          context information. Since the presented scenes are externally
of association and self-organization.                                  segmented into agent, action and patient, the major part of
   Theories in embodied cognition research offer an account            semantic interpretation is provided to the model explicitly.
for assignment of linguistic structures to constructions of               While these models certainly achieved good results
coherent semantic interpretations. Language comprehension              concerning their aims, they show several shortcomings
is considered to be a simulation of perceptual experiences of          making them unsuitable for our approach. Firstly, extensive
the hearer, and the linguistic structure serves as an instruction      use of different layers and components makes it impossible
for the correct construction of the situation. Due to its              to deduce responsible structures and working mechanisms
                                                                  827

from internal states of the model, prohibiting analysis of             Zwaan (2004) introduces an explicit framework for
ongoing processes. Secondly, reliance on explicit, extremely        embodied language comprehension that integrates several
powerful semantic representations that do most of the work          empirical findings. In his Immersed Experiencer Framework,
of semantic processing prevents clear assignment of                 situational entities correspond to activated functional neural
performance properties to inherent connectionist                    webs instantiated by lexical items. These webs become
mechanisms. Thirdly, the use of separated training for the          integrated to construals by means of constraint-satisfaction
components (e.g., pre-training of the semantic layer before         mechanisms, representing events corresponding to clauses.
coupling it with sequential linguistic input) reduces               The approach claims to replace propositional representations,
integration to an interface between independent modules.            which are stated to be merely illustrative shorthand.
This contradicts the idea of grounded language acquisition,
inhibiting examination of mutual and synergetic effects                 Modeling situated language comprehension
between syntactic and semantic components.                          Our model directly addresses the discussed issues by
   The Distributed Situation Space model (Frank et al., 2007)       imposing restrictions on the architecture, the nature of
does not use explicit propositions. It uses Self Organizing         representations and tasks. Basically we assume that meaning
Maps (Kohonen, 1995) to represent simple and combined               is not an inherent feature of language, but must be assigned
events in a microworld and maps descriptive sentences on            by grounded language acquisition: the meaning of a linguistic
corresponding situation vectors using SRNs. The model               expression is the activated mental simulation of the
implements the idea of non-propositional semantic                   corresponding event. Interpretation processes are guided by
representations, preserving analogy of internal representations     mechanisms of constraint-satisfaction, naturally inherent in
to external states on the dimension of transition and               artificial neural networks. Our focus lies on the integration of
combination probabilities of events. Frank, Haselager and           sequential linguistic and static situational information. The
van Rooij (2009) explored the capability of this model to           network is trained to achieve the simultaneous completion of
capture semantic systematicity beyond simply implementing           different tasks: prediction of the sequential succession of
symbolic computation. They concluded that connectionist             linguistic units and recognition and classification of visual
systematicity emerges from interaction with the environment,        patterns related to the linguistic input. The tasks pose
reflecting the observed and derived structural correlations.        different requirements: extraction of sequential structures and
Considered from an embodied cognition perspective, the              their probabilities as well as extraction and generalization of
model preserves analogy in its internal representations. But        diverse static patterns. Our aim is to explore the ability of the
it still waives central qualities that need to be explored: it      model to integrate these tasks, the mechanisms to map the
reduces semantic content to co-occurrences of events and            contents of the differing information systems, and the usage
does not aim at modality at all, thereby leaving out                of corresponding information of the respective system as an
inferences on behalf of event-internal relations.                   additional source of constraints.
Embodiment theories of language comprehension                       Architecture and flow of information
Embodied cognition posits that the structure of embedded            We tried to avoid the inflationary use of hidden layers and
systems emerges as a consequence of interaction with the            different modules to keep functional assignments transparent
environment. This leads to an alternative perspective on            and interrelated effects of the components analyzable. The
cognitive processes and conceptualizations, which is highly         base architecture is an SRN, with different input and output
compatible with recent connectionist and emergentist                layers for linguistic and visual/situational information
assumptions and enables the development of proposition-free         processing (Figure 1).
comprehension systems.                                                 The syntax component 1 gets linguistic input (at Input I) in a
   With the Perceptual Symbol Systems framework, Barsalou           sequential manner â sentences word by word â and is trained
(1999) emphasizes cognition to be grounded in perception,           to predict the next input (at Output I), thereby extracting word
operating on modal and analogue symbols. These are derived          classes, word transition probabilities and exploring structural
directly as neural substrates of activations corresponding to       relations in the input. Activation is forwarded from Input I
perceptions of the external world and share the same                over the Integration Layer to Output I. Learning of sequential
functional brain areas. This is claimed to obviate the              structures is enabled through a context layer, which provides
grounding      and     transduction     problem.     Language       information about previous states of activation by copying the
comprehension is seen as a mental simulation process of             hidden layer and returning it at the next cycle.
perceptual states of neural activation, triggered by linguistic        The situational component propagates compressed simple
input. Joyce et al. (2003) proposed connectionism as a              static situations and is trained to reproduce its crucial
suitable framework for closing some explanatory gaps                information. The actual representations of the situational
concerning the question, how such a system could actually           component are provided by the visual input and teaching
be implemented. Based on an SRN-model of perceptual                 examples: Input II presents static situations with simple
symbol formation they drew further specifications of the
required mechanisms and how they come to work.
                                                                    1
                                                                      The labels syntax and semantics are used as abbreviations for
                                                                    sequential linguistic vs. situational semantic component.
                                                                828

objects on a two-dimensional grid, constituting a retina-like          positively interacting systems, as proposed in syntactic and
interface for the model. Activation is forwarded to the                semantic bootstrapping theories.
Integration Layer through an additional hidden layer
                                                                       Visual patterns. To generate visual patterns, we used four
(Encoder: Semantics) encoding a distributed representation of
                                                                       discrete distinctive objects, named minus (-), pipe (|), slash (/)
Input II and reaches Output II via a second additional hidden
                                                                       and backslash (\), distributed freely on a two-dimensional
layer (Decoder: Semantics). Output II provides a prototype
                                                                       grid. Up to three of these objects were placed in different
version of the scene, forcing the network to extract crucial
                                                                       locations on that grid. Our situations differ in the number of
information about space and objects.
                                                                       involved objects, the identity of the selected objects, the exact
                                                                       location of these objects, and, as a consequence, in the spatial
          Output I: Syntax                 Output II:                  relation between those objects. The left panel of Figure 3 in
                                           Prototyped situations       the results section provides an example of an input situation
                                                                       depicting a backslash positioned roughly above the minus and
                              Decoder: Semantics                       slightly left above the pipe (this is obviously just one of
                                                                       several equally possible descriptions).
            Integration layer                                             Concerning the retina-like implementation: our intention is
                                                                       not to provide a cognitively plausible model of visual
                                                                       processing, as for example realized by Coventry et al.
                               Encoder: Semantics                      (2005) in the Functional Geometric Framework. The retinal
                                                                       grid merely provides an intuitive and simplistic presentation
                                                                       format and offers several advantages: orientation towards
          Input I: Syntax                                              modal features, analogy on the spatial dimension on the
                                             Input II: Visual grid     situational level and sparsely structured, non-explicitly
                                             for 2-D situation         encoded access to information about the situations.
                                                                          The target grids contain prototype versions of
    Figure 1: Extended SRN-architecture for integration of
                                                                       corresponding input situations, reduced in several ways: they
              linguistic and situational information.
                                                                       represent only two objects of an arbitrary number of initially
                                                                       presented objects, reflecting attentional focus on selected
   Both types of information â static situation and
                                                                       entities. It reduces the spatial expansion and idealizes the
corresponding sequential linguistic input â are presented
                                                                       relative positions of considered objects to a prototypical
simultaneously. The situation is maintained as long as
                                                                       spatial relation. Again using Figure 3 as illustrative example,
linguistic processing is in progress. The information from
                                                                       the selected prototype for the input situation is the backslash
both components is integrated in the Integration Layer â
                                                                       positioned directly above the minus, blinding out the pipe.
allowing generalization over co-occurrences of incremental
                                                                       Mapping onto prototypes forces the network to instantiate
linguistic and static situational input. The network is forced to
                                                                       self-organized internal representations of the situations that
find common representations to solve the differing tasks of
                                                                       are selective and schematic in nature, extracting relevant
both components. In contrast to other connectionist models
                                                                       information. This enables the model to distinguish the objects
covering sequential tasks, we did not use a separated training
                                                                       and to develop the concept of relative spatial positions, a
regimen for the syntax and semantics components, but trained
                                                                       presupposition for the mapping of corresponding linguistic
the complete network in a holistic fashion on the different
                                                                       input. Dominey (2003) demonstrated such a purely
information sources.
                                                                       associative mechanism to be sufficient to inductively acquire
Semantics and situational representation                               productive grammatical constructions.
Following the idea of embodied language comprehension                       Table 1: Syntactic inventory for situation description.
theories, conceptualization is assumed to be modal and
analogue, encoded as schematic abstractions of events and                object-A be-located deictic-particle eos
objects in the environment. Meaning is assigned to linguistic            deictic-particle be-located object-A eos
units on different levels by mapping the units onto the internal         object-A be-located location-relative object-B eos
structure that simulates the corresponding object, action or             object-B be-located inverse-location-relative object-A eos
event structure. We can distinguish between a non- or pre-               location-relative object-A be-located object-B eos
linguistic representation that conceptualizes the perceived              inverse-location-relative object-B be-located object-A eos
world independently of linguistic labeling and a linguistic
semantics that is constituted by assignment processes,                    We used a very limited microlanguage for situation
corresponding to the relation between prototype theory and             description (Table 1). The linguistic input consists of
prototype semantics (Rosch, 1978). So, semantics is seen as a          sentences presented sequentially word by word. The
process rather than a state, led by constraint-satisfaction            vocabulary contains lexical units for the distinguishable
mechanisms, which dynamically adjust categories based on               objects, for relative positions of the objects in space, a state
new experiences. We assume an intertwined development of               verb, a deictic particle and an end-of-sentence marker. It is
                                                                   829

encoded in a localist fashion, each active unit representing           softmax function to enforce output activation complying with
one word. Visual situations are complex in that they entail            an interpretation of word probability. The test set used a
several possible spatial relations between several objects. By         sample of scene constellations excluded during the training
expressing one of these relations between exactly two objects,         phase. It was constructed corresponding to the training
the network is forced to direct its focus of attention.                stimuli, providing full or single-sided reduced information:
                                                                       testComplete, testProduction and testComprehension.
Hypotheses on network performance
We expect language to have a positive effect on the                    Results and discussion
discrimination and categorization of the components                    The proposed architecture has the potential to simulate and
establishing the corresponding situations. Vice versa, we              predict behavior relevant to research areas ranging from
expect beneficial effects of the visual input on word                  language acquisition to visual attention. What we present here
prediction, based on the assumption that the network makes             are preliminary results of network performance using a subset
use of mutual informative cues. This is not as obvious as it           of the possible training and test variations. The results are
may appear, since one could just as well assume that the tasks         reported in three sections, treating (1) vision/comprehension,
interfere with each other due to their different representation        (2) word prediction and (3) language production, including
formats and the narrow resource of representational space.             relevant aspects concerning their interaction.
   In the test phase the network should be able (1) to derive
                                                                       Vision/Comprehension In the testComplete condition with
the situational prototype without relying on the information of
                                                                       two objects in the input the model manages to produce the
the situational input by exclusively using the sequential
                                                                       correct vision prototype at time step 1 already, without
linguistic input and (2) to derive a coherent and correct
                                                                       showing wrong objects. Over successive time steps, already
sequential linguistic output, exclusively using the information
                                                                       clear objects get activated even stronger receiving additional
of the static situation input. Furthermore the network is
                                                                       support from the linguistic input. In ambiguous visual
expected (3) to show systematic performance when coping
                                                                       situations the vision output provides a preferred reading (due
with ambiguous cases occurring several times. When tested
                                                                       to slightly different frequencies in the training set). If the
on the complete information including vision and language,
                                                                       interpretation is falsified by the linguistic input, it adjusts the
we expect the network (4) to use the integrated crossover
                                                                       visual image to the linguistically referred position
information to draw inferences on the correct output and to
                                                                       immediately.
rule out irrelevant possibilities.
                                                                          In the three objects condition, the vision output first
Materials and simulations                                              provides a diffuse but by no means arbitrary activation
                                                                       pattern: it contains all possible objects in their possible
We ran the simulations on LENS (Rohde, 1999). Language                 relations, in most cases with preferences for one constellation.
input and output layers consisted of 16 units each, vision             During the time course of the incoming sentence, affirmation
input had a grid size of 9 x 9 (= 81) units, prototyped vision         of the selected constellation by the linguistic description
output had a grid of 7 x 7 (= 49) units. Hidden layers                 guides the vision output to adjust the pattern to the
consisted of 40 units each. The presented visual scenes                predetermined state, using at each step the available
showed up to three out of four different objects (minus,               information at hand. New information reducing the possible
pipe, slash, backslash), forming complex spatial relations.            constellation leads directly to a correction. At the last step
The training sets contained 60% randomly chosen situations             only the requested pattern is produced, leaving no deviant
of the 130708 possible constellations of objects.                      activation (compare Figure 2). Importantly, at the final steps
   The training regimen consisted of three different stimuli           in both conditions the vision output contains only the
settings. (1) trainComplete provides visual and linguistic             activation of the correct predetermined constellation.
stimuli in parallel, (2) trainProduction provides only visual             For the two-objects condition, this adjustment process
stimuli to force the network to perform language production            could best be described in terms of disambiguation and
for observed scenes, (3) trainComprehension provides only              discrete categorization. The process for the three-objects
linguistic stimuli forcing the language comprehension                  condition is rather a shift of attentional focus. Corresponding
process. The target information always included both visual            to the linguistic information, irrelevant aspects of the scene
scene and corresponding linguistic description. The three              are shifted out of the focus of interpretation, while the
training conditions were presented in an alternating manner.           relevant information receives highlighting by exclusive
   The networks were trained for 10 epochs, but already                activation (Figure 3). This high context sensitivity emerges
showed very good performance on early epochs. We used the              from implicit constraint-satisfaction mechanisms of the
backpropagation-through-time           algorithm,       applying       network, inherently establishing a frame-of-attention
momentum 0.3, an initial weight range of 0.3 and a learning            mechanism not built into the system artificially.
rate of 0.2, which was incrementally decreased by a factor of
0.02 per epoch. 2 The language output layer received a
                                                                       Results were largely robust for most combinations of parameters,
2
  We ran several sets of networks, varying learning rate (0.05 to      showing slight performance loss for some combinations, but
0.2), momentum (0.0 to 0.6) and initial weight range (0.1 to 1.0).     preserving the qualitative systematicity of performance.
                                                                   830

   In the testComprehension condition we can observe the             Word prediction. Like the vision output the linguistic output
same behavior of direct correspondence between provided              is highly accurate in the testComplete condition with two and
linguistic information and constructed scene prediction.             three objects. At time step 1 the network prefers to predict the
Slightly different from the testComplete set, it produced even       spatial relations. It states only possible relations according to
clearer constellation predictions, since input is less distorted     the visual input. The same holds for the following time steps.
by competing relations. The comprehension process succeeds           During object prediction, the network predicts only objects
incrementally, using all new information to construct a scene        observed at the visual retina. At functional syntactic positions
prediction as complete as possible. As soon as all relevant          (verb, end-of-sentence marker), the network produces optimal
information is provided by the linguistic input, a stable visual     activation.
scene prediction is constructed, containing only correct                Moreover, in successive time steps, it predicts only those
activations. This proves that the comprehension mechanism            objects and relations that can occur corresponding to the
works independently from provided visual information and is          descriptive sequence given before (e.g., after the object
able to construct complete visual scenes from linguistic             location 'right-of', only objects are linguistically predicted,
descriptions, when no visual information is provided.                that can occur in a 'right-of' constellation). So it achieves far
                                                                     more than POS-tagging or grammatical probability matching
                                                                     (as criticized by Steedman, 1999). Its predictions are sensitive
                                                                     to word transition probabilities and grammatical category,
                                                                     and at the same time sensitive to possible descriptions of the
                                                                     scenes as provided by the visual context. We interpret this as
                                                                     visual priming, determining the linguistic performance by
                                                                     pre-activation of the relevant lexical items. In the condition
                                                                     testComprehension, the word prediction component could not
                                                                     rely on additional visual information. Therefore it activated
                                                                     all possible objects and relations at the respective syntactic
                                                                     positions, which are the only constraints provided by the
                                                                     preceding linguistic information.
                                                                     Language production. For the testProduction set we
                                                                     reconfigured the trained network with a copy-connection
                                                                     from the language output layer (Output I) to the language
                                                                     input layer (Input I) and equipped the output layer with a
                                                                     winner-take-all functionality. 3 We have just begun analyzing
        Figure 2: Comprehension and inference effect.                production data, so the results are somewhat preliminary. The
                                                                     network produces mainly correct and complete sentences.
   During the incremental construction of the situation model        These sequences contained only objects and relations that
one can observe different strategies for using given and             were given in the visual input, however not always expressing
inferring missing information. As soon as a spatial relation is      the correct constellation of objects. The network always
referred to, the vision component displays placeholders for          instantiated linguistic starting points driven in correspondence
the respective positions. In some cases, these take the shape        to the distinctiveness of the visual input (e.g., clarity of spatial
of some object, indicating an expected default. If an object is      relation). While the network did rarely produce wrong
already given, it is positioned correctly, leaving the second        sentences, it sometimes produced sentences that did not
underspecified. With no spatial relation given, an introduced        accurately correspond to the visual scene. Sometimes, objects
object is instantiated with weak and slightly obscured               were repeated (slash is left-of slash), or objects appeared in
activation on multiple positions.                                    reverse order. The majority of sentences however expressed
                                                                     the correct constellation of objects.
                                                                        The successful integration of information and interaction
                                                                     between the two components is reflected in the strong
                                                                     correspondence between language and vision: even when the
                                                                     network assumes a wrong constellation (e.g., for ambiguous
                                                                     cases and for three objects with initially wrong preferred
                                                                     constellations), this is predicted consistently on the vision and
                                                                     language output. Moreover, activation strengths for the
                                                                     objects and locations in the visual output and their respective
                                                                     word nodes correspond to each other (Figure 2, second
                                                                     3
                                                                       This feedback loop triggers sequential routines to control the
                                                                     production process, providing the actual output as input stimulus
     Figure 3: Comprehension and attentional focus effect.           on the next time step (e.g., Rohde, 2002).
                                                                 831

pattern). Furthermore, new linguistic information can lead to                                 References
a reconstruction of the visual prototype preferred so far,
                                                                      Barsalou, L.W. (1999). Perceptual symbol systems.
revising both spatial relation and concerned objects.
                                                                        Behavioral and Brain Sciences, 22, 577-660.
   One important aspect to analyze the achieved integration is
                                                                      Copestake, A., Flickinger, D., Pollard, C., & Sag, I. A.
still to be done: the examination of representational structures
                                                                        (2005). Minimal recursion semantics: an introduction.
in the internal layers. This is the key to understanding the
                                                                        Research on Language & Computation, 3 (4), 281-332.
actual achievements of the model. Since we have ensured its
                                                                      Coventry, K.R., Cangelosi, A., Rajapakse, R., Bacon, A.,
performance quality, this will be the next step of our research.
                                                                        Newstead, S., Joyce, D., & Richards, L.V. (2004). Spatial
                                                                        prepositions and vague quantifiers: implementing the
                         Conclusions                                    functional geometric framework. Proceedings of the
The proposed model performed constantly well over all test              Spatial Cognition Conference, FrauenwÃ¶rth.
sets in every imposed task. It comprehends language in an             Dominey, P.F. (2003). Learning grammatical constructions
incremental manner and produced correct syntactic strings,              in a miniature language from narrated video events.
even with only the mutually restricted information available.           Proceedings of the 25th Annual Meeting of the Cognitive
It showed systematic behavior for different demands and                 Science Society, Boston.
conditions concerning missing or ambiguous information.               Elman, J.L. (1990). Finding structure in time. Cognitive
Notably, all specifics of the behavior resulted from inherent           Science, 14, 179-211.
properties and were not imposed artificially. The model               Frank, S.L., Haselager, W.F.G., & van Rooij, I. (2009).
integrates different information sources, which enables it to           Connectionist semantic systematicity. Cognition, 110,
produce context sensitive behavior, to reduce irrelevant                358-379.
information and to draw inferences on possible target states.         Frank, S.L., Koppen, M., Vonk, W., & Noordman, L.G.M.
This leads to effects best described in terms of visually               (2007). Modeling multiple levels of text representation. In
induced linguistic performance and language driven shift of             F. Schmalhofer, & C.A. Perfetti (eds.). Higher level
visual attentional focus.                                               language processes in the brain: inference and
   Our retina-like representation format clearly limits the             comprehension processes. Mahwah, Erlbaum, 133-157.
possibilities of representing world situations. But it avoids the     Joyce D., Richards L., Cangelosi, A., & Coventry K.R.
theoretical shortcomings of using explicitly assigned                   (2003). On the foundations of perceptual symbol systems:
relations. We assume that it is an inherent and distinctive             Specifying embodied representations via connectionism.
feature of connectionist models to extract and assign the               Proceedings of the 5th International Conference on
relations given in the world by themselves.                             Cognitive Modeling, Bamberg.
   Further elaboration of the model will first of all encourage       Kohonen, T. (1995). Self-organizing maps. Berlin: Springer.
an independent generation of prototype situations. The                Mayberry, M.R. (2003). Incremental nonmonotonic parsing
weakest point of the model at present is the explicitly                 through semantic self-organization. Doctoral Thesis.
provided prototypicality, i.e. the supervised training of the           University of Texas, Austin.
situations using pre-structured prototypes. To ensure                 Mayberry, M.R., Crocker, M.W., & Knoeferle, P. (2005). A
complete independence of the model, we need to equip it with            connectionist model of sentence comprehension in visual
an unsupervised training algorithm that self-organizes                  worlds. Proceedings of the 27th Annual Conference of the
prototype extraction using auto-associative learning                    Cognitive Science Society, Nashville.
mechanisms. This way, the model could construct its own               McClelland, J.L., & Rumelhart, D.E. (1985). Distributed
prototypical instantiations, corresponding to the achievement           memory and the representation of general and specific
of auto-associative lexical models (e.g., McClelland &                  information. Journal of Experimental Psychology, 114
Rumelhart, 1985). A further improvement of the expressive               (2), 159-188.
and predictive power is the extension of situational                  Quine, W.V. (1968). Ontological Relativity. The Journal of
complexity. The dimensional aspects of time and causality               Philosophy, 65 (7), 185-212.
could be introduced by object movement and interaction. This          Rohde, D.L.T. (1999). LENS: the light efficient network
will subsequently extend the vocabulary and the syntactic               simulator. MIT, Carnegie Mellon University Pittsburg.
complexity of the linguistic input, enabling us to construct          Rohde, D.L.T. (2002). A connectionist model of sentence
richer and more language-like descriptions.                             comprehension and production. Doctoral Thesis. MIT,
   Embodiment theories guided the implementation of the                 Carnegie Mellon University Pittsburg.
connectionist model. On the other hand, explorations of the           Rosch, E. (1978). Cognition and categorization. Hillsdale,
inherent systematic performance of artificial neural networks           N.J., Erlbaum.
can provide a useful subsidiary explanation base to sharpen           Steedman, M. (1999). Connectionist sentence processing in
some opaque conceptualizations in the embodied cognition                perspective. Cognitive Science, 23 (4), 615-634.
literature.                                                           Zwaan, R.A. (2004). The immersed experiencer: toward an
                                                                        embodied theory of language comprehension. In B.H.
                                                                        Ross (ed.). The Psychology of Learning and Motivation,
                                                                        44. New York, Academic Press, 35-62.
                                                                  832

