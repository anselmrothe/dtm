UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Integrating graphical information into cognitive modeling of web navigation
Permalink
https://escholarship.org/uc/item/72k5t9rh
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Indurkhya, Bipin
Karanam, Saraschandra
Puerta Melguizo, Mari Carmen
et al.
Publication Date
2009-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       Integrating graphical information into cognitive modeling of web navigation
                                Saraschandra Karanam (saraschandra@research.iiit.ac.in)
                            Cog Sci Lab, International Institute of Information Technology, Gachibowli,
                                                            Hyderabad, India.
                                             Herre van Oostendorp (herre@cs.uu.nl)
               Center for Content and Knowledge Engineering, Institute of Information and Computing Sciences,
                                               Utrecht University, Utrecht, Netherlands.
                                      Mari Carmen Puerta Melguizo (puerta@cs.uu.nl)
               Center for Content and Knowledge Engineering, Institute of Information and Computing Sciences,
                                               Utrecht University, Utrecht, Netherlands.
                                                Bipin Indurkhya (bipin@iiit.ac.in)
                            Cog Sci Lab, International Institute of Information Technology, Gachibowli,
                                                             Hyderabad, India
                             Abstract                                    To predict navigational choices, Pirolli and Fu (2003)
  Cognitive models of web navigation like CoLiDeS, use only
                                                                      developed an architecture called Scent-based Navigation
  textual information from hyperlinks to compute information          and Information Foraging in ACT (SNIF-ACT). This
  scent and ignore so far the impact of visual and graphical          architecture considers the whole of world-wide web as a
  widgets. We conducted an experiment to study the extent to          semantic space, and predicts navigational choices — such as
  which textual and especially graphical information, plays a         which link to click, where to go next, when to leave the
  role in identifying web page widgets. Four different versions       website, and so on — based on a parameter called
  of a webpage were created by systematically varying text and        information scent, which is calculated as the mutual
  graphics. In general, task completion times and number of
  clicks were significantly less in the presence of graphics than     relevance between the user goals and the link texts based on
  in their absence. This was particularly the case when there         word occurrences and co-occurrences on the internet.
  was no textual information available. We conclude that for             Miller and Remington (2004) proposed a Method for
  identifying graphical widgets, text and graphics interact and       Evaluating Site Architectures (MESA), which gives a model
  complement each other and it is important for a cognitive           for explaining user backtracking behaviour. It models
  model on web navigation to include information from                 various navigation styles and strategies to recover from
  graphics. In this direction we propose a method to integrate
                                                                      selecting misleading links, and gives an account of the
  information extracted from pictures into CoLiDeS and we
  demonstrate its usefulness with a simulation done on a mock         effectiveness of selecting various links given their relevance
  web site.                                                           to the search goal.
                                                                         Finally, Juvina and Van Oostendorp (2007) and Van
  Keywords: Web navigation; web usability; cognitive model;
                                                                      Oostendorp and Juvina (2008) developed CoLiDeS+, which
  information scent; semantics; graphics
                                                                      extends CoLiDeS by including contextual information such
                                                                      as information from the selected links on previously visited
                         Introduction                                 web pages, namely the navigation path. CoLiDeS+ defines
Navigating the Internet and searching for information                 path adequacy as the semantic similarity between the
requires the processing of (at least) visual and textual              navigation path and the goal. When the incoming
information (Paivio, 1986). Cognitive modeling of web                 information from links on the current page increases path
navigation behaviour has been extensively studied and a               adequacy, it is considered for selection, otherwise alternate
number of models have been developed. However, these                  paths are chosen.
models do not pay much attention to the role of visual or                All these models are based on the concept of semantic
graphical information. Kitajima, Blackmon, and Polson                 similarity or information scent since it has been verified that
(2000) developed a theoretical model of web-navigation                this drives the user’s search behaviours and navigation
called Comprehension-based Linked model of Deliberate                 patterns (Chi et al., 2000, 2001, Pirolli & Card, 1999).
Search (CoLiDeS). This model assumes that comprehension               CoLiDeS and CoLiDeS+ use a mathematical technique
of texts and images is the key to web navigation.                     called Latent Semantic Analysis (LSA) developed by
Comprehension processes build, elaborate and compare the              Landauer et al. (1998). LSA estimates semantic relatedness
mental representations of screen objects to determine which           of texts, based on a statistical analysis of large corpus.
hyperlink or image to select and click. This comparison               These similarity measures between user-goals and
involves computing semantic similarity between the search             hyperlinks on a webpage, as given by LSA, are used to
goal and the screen objects (Pirolli & Card, 1999).                   predict the likelihood of a user selecting each of those
                                                                      hyperlinks.
                                                                  2807

  All these models, however, seem to ignore the semantic            variables were the mean task completion time and the
information gained from the visual/graphical modality.              number of clicks a user takes to locate the correct widget.
Although the models acknowledge the importance of
comprehension of images in web navigation, CoLiDeS                  Material and Apparatus
computes the influence of semantics derived from only text.         Four versions of each webpage were created using a 2 (text
Research on visual search and visual saliency highlights the        vs. no text) X 2 (graphics vs. no graphics) manipulation –
fact that our visual system is not only adept at perceiving         (1) Normal Version with both text and graphics intact (T+
salient objects (Desimone & Duncan, 1995; Itti & Koch,              G+), (2) No Text Version with text removed (greeked) and
2001) but also quicker (Paivio, 1986; Mayer & Moreno,               graphics intact (T− G+), (3) No Graphics Version with
2003). Although it seems worthwhile to study the impact of          graphics removed and text intact (T+ G−), and (4) No
semantics derived from graphics in the domain of web                Graphics and No Text Version with both text and graphics
navigation, there is almost no existing research on it. In this     removed (T− G−). Other variables such as size and location
paper, we explore the role of graphical and visual                  were maintained constant across all versions of 8 web
information, in contrast with textual information, in locating      pages. For the no text versions, all text was replaced with
web page widgets.                                                   character ―X‖ in the same font, spacing and style. For the no
  Hinesley (2005) examined the impact of graphics in                graphics versions, all images were removed leaving the text
locating widgets on a webpage by taking original and                in Arial typeface with 8-point size in the original positions.
greeked web pages (pages in which any textual information           Fig1 shows a small portion of a webpage in all 4 versions.
has been substituted by sequences of X’s, as shown in the
Figure 1). She found that in the absence of textual
information (greeked pages), widgets with mostly graphical
information (e.g., a conventional search box, advertisement)
were found more quickly than widgets that were purely
textual (e.g., Contact Link, Privacy Statement). In a second
experiment Hinesley and Blackmon (2008) systematically
varied two variables: graphics (Graphics vs. No Graphics)
and location expectations (Location vs. No Location) on
greeked pages. The loss of graphical information was found
to have twice as large an impact as the violation of location
expectations. This research claims that graphics, and not
text, seems to be the key to how users find and recognize
popular conventional graphical widgets like the search
engine.
  While text was manipulated in the presence of graphics in
one experiment, graphics was manipulated in greeked text in
another. The role of text in finding graphical widgets was
not addressed in Hinesley's work. This forms the main focus
of our first study. We hypothesize that the difference
between graphics and no-graphics conditions is smaller in
the presence of textual information.
  In the second study we present the results of our
                                                                                Figure 1: Four versions of a webpage
preliminary simulation of CoLiDeS including pictures. We
hypothesize that when including semantic information from
                                                                    All widgets were divided into purely textual widgets
graphics into the model, the right navigation path can be
                                                                    (Contact Us, Privacy Statement, Newsletter Sign Up, Left
found more frequently and more accurately than when it is
                                                                    Navigation, Top Navigation and Register/Login) and
not included.
                                                                    graphical widgets (Accreditation, Logo, Search Engine,
                                                                    Advertisement, Print Icon and Drop-Down Menu). Some
                          Study 1                                   widgets were mostly graphical in the sense that they had
                                                                    some text in fancier format (the text ―Go‖ for a search
Participants
                                                                    engine). These were also classified under graphical widgets.
Forty students, from Utrecht University, including post-            An image map was created for each web page, based on
graduate and research scholars, participated in the                 functional web units, assigning a clickable region to each
experiment.                                                         object so that when a user hovered over any widget, the
                                                                    mouse pointer changed to a hand, indicating that the user
Design                                                              could click. Participants were tested using a Dell 17‖ flat-
We used a 2 (text vs. no text) X 2 (graphics vs. no graphics)       panel displays running Windows XP with SP2. Browser
X 12 Widget repeated measures design. The dependent                 used was Internet Explorer 7.0.
                                                                2808

Procedure                                                           widget as dependent variable. The main effect of text is
Participants performed a total of 56 trials on eight different      significant (F(1,39) =49.70, p<.001). The number of clicks
web pages. Their task was to locate widgets and click on            is significantly greater in the absence of text. Also, the main
them. Each participant was asked to locate six widgets              effect of graphics is significant (F(1,39) =37.06, p<.001).
(three textual and three graphical) on one version of each of       The number of clicks in the absence of graphics is
the eight websites. Participants first saw the task description     significantly greater than in the presence of graphics.
on the screen and then started performing the tasks. A              Finally, the interaction of text and graphics is also
description of the task was always present on top of the            significant F(1,39) =35.6, p<.001). Figure 3 depicts this
page. Care was taken to ensure that each participant saw            relationship for average number of clicks.
only one version of any webpage.
Results
Task Completion Time A 2X2 within subjects ANOVA
was conducted with text and graphics as independent
variables and mean task completion time as dependent
variable. Results show a main effect of graphics (F(1,39)
=28.17, p<.001). The task completion times are significantly
less in the presence of graphics when compared to the times
with no graphics. The main effect of text is not significant
(p>.05). The interaction of text and graphics is significant
(F(1,39) =5.83, p<.05). Figure 2 shows the interaction
between text and graphics.
                                                                        Figure 3: Mean number of clicks in relation to text and
                                                                                                graphics
                                                                    T-tests reveal two significant pairs (T− G+)-(T− G−) and
                                                                    (T+ G−)-(T− G−). These effects emphasize the importance
                                                                    of semantic information derived from text in locating
                                                                    widgets since the comparison between the conditions (T+
                                                                    G+) and (T+ G−) is not significant while (T− G+) compared
                                                                    with (T− G−) is highly significant. Furthermore, the effect
                                                                    of graphics is significant only in the absence of text.
                                                                    Nature of Task A 2X2X2 within subjects ANOVA was
                                                                    performed with text, graphics and task type (localising
                                                                    textual vs. graphical widgets) as independent variables and
  Figure 2: Mean Task Completion Times in relation to text          mean task completion times and mean number of clicks as
                         and graphics                               dependent variables.
                                                                       Both for task completion times and number of clicks,
   T-tests reveal significant differences between all pairs         graphical tasks followed the same pattern as in Figure 2 and
except (T+ G+)-(T− G+). Moreover, the difference between            3. This implies that for graphical tasks, graphics are very
(T-G+)-(T-G-) is much greater than the difference between           important. For textual tasks, presence or absence of either
(T+G+)-(T+G-). These values support our hypothesis that             text or graphics does not play any significant role.
that the difference between graphics and no-graphics
conditions is smaller in the presence of textual information.       Discussion
Also, under the no-graphics condition, participants took
significantly less time in locating widgets in the presence of      The results of this experiment show that both text and
text than in its absence. Semantic information from text            graphics play an equally important role in locating web-
helped users in locating widgets when no graphics are               page widgets. Consequently, in contrast to Hinesley and
presented.                                                          Blackmon (2008), it is not graphics alone, but both sources
                                                                    that are important for identifying objects. They both interact
Number of Clicks A similar 2X2 within subjects ANOVA                in the sense that text assumes a greater role in the absence of
was conducted with text and graphics as independent                 graphics, and graphics assumes a greater role in the absence
variables and the number of clicks taken to find the right
                                                                2809

of text. Removing both text and graphics results in the worst         First we describe the method we use to extract semantic
performance results.                                               information from pictures. This extraction method is to our
   The implication of this study for cognitive models of web       knowledge not used before, and it is in our opinion
navigation behaviour is that while text is important,              interesting to examine whether it leads to useful results.
graphical information is equally important. This effect is         Next we describe a simulation study, which is based on
especially prominent for conventional graphical widgets.           CWW - Cognitive Walkthrough for the Web (Blackmon et
Consequently, we claim that models of web navigation               al., 2002, 2005). CWW is a usability inspection method that
would predict navigation behaviour more accurately if the          identifies problems in web-page design. Our method adds
information from both text and graphics is taken into              certain additional steps to CWW to incorporate semantic
consideration in computing information scent. In the second        information from pictures.
study we present a way to do it and evaluate our results.
                                                                   Steps involved in extracting semantics from
CoLiDeS + Pic                                                      pictures
We propose an extension of CoLiDeS to include the                  According to the Construction Integration Theory of Text-
semantic information coming from pictures in a webpage in          Comprehension (Kintsch, 1998), as the reader proceeds
addition to the information scent computed from hyperlinks.        through a piece of text, he/she constructs a mental
We call it CoLiDeS + Pic as it shares all the main                 representation of the incoming piece of text by using his
assumptions of the original cognitive model with only a few        background and domain knowledge. Only a small portion of
changes at the level of computation of similarity.                 human memory is active at any point of time. The incoming
   CoLiDeS + Pic is based on the hypothesis that the               text element, the previously read text, user goal and user
presence of pictures that are semantically close to the            background knowledge determine in that order of priority
current context would aid the user in selecting the correct        which concepts are active at any given point of time.
link predicted by CoLiDeS. Context is provided by the user         Similarly, when a user looks at a picture, many concepts are
goal, visible hyperlinks and the picture.                          activated, influencing the interpretation of other information
                                                                   in that context, for instance, the hyperlinks. So we assume
Cognitive grounds of CoLiDeS + Pic                                 that the activated features co-determine the link that will be
   Though CoLiDeS assumes that comprehension of text and           chosen. Thus, the first step is to extract the semantic
images is key to web navigation, it never modeled images.          features that a picture activates in user’s memory.
CoLiDeS + Pic takes the first steps in that direction.                User goals in our case correspond to the questions the
   CoLiDeS considers that all different objects in the website     user needs to answer (e.g. ―Name three layers of tissue that
are related to each other and to the user goal by three            form the heart wall?‖). For each user goal, five pictures
measures of relevance – similarity, frequency and literal          varying in degree of relevance to the context of those pages
matching. The similarity measures used by CoLiDeS                  are collected. Participants are then asked to write down five
compute the similarity between the user goal and each of the       semantic features based on the concepts that come to their
objects separately and consider only textual objects.              mind looking at the picture in context (See Figure 4 for an
CoLiDeS + Pic fills this gap to some extent by including           example).
semantic information coming from pictures, thereby making             By combining the features from participants, we obtain a
the model more consistent with the theoretical assumptions.        collection of semantic features for each picture. By selecting
   According to CoLiDeS, selecting an object on a webpage          common features given by two or more users, we generate a
is an outcome of four cognitive processes – parsing all the        frequency distribution of these re-occurring features. A
objects contained in the webpage into 5-10 top level               feature is deemed to be representing the picture if it is
schematic objects (e.g. Window Controls, Left Navigation           among the top five in the frequency distribution and is
Column, Top Navigation Column), focusing on one of the             mentioned by at least 50% of all the users. The picture is
top level schematic objects, comprehending and elaborating         now represented by these top five most frequently
the objects within the focused area and selecting one of           mentioned features.
them as a target for the next action. CoLiDeS + Pic in a way
combines the two phases of elaboration and focusing on. It
is during the parsing phase that the user glances at all the
objects. After elaborating each of the objects, the user
decides to focus on one of them based on three measures of
relevance. By including elaborations done for pictures along
with elaborations done for hyperlinks, CoLiDeS + Pic is
using more information from the elaboration phase to decide
which final object to select. Thus, CoLiDeS + Pic provides a
more accurate cognitive model.
                                                                    Figure 4: Snapshot of Webpage with High relevant picture
                                                                                     used for Feature Extraction
                                                               2810

                                                                   important biological purpose in addition to aiding in speech
High and Low Relevant Pictures For each page, LSA is               - to prevent foreign substances from entering the windpipe
used to compute the semantic similarity between the goal           while swallowing, to forcefully expel foreign substances by
and five sets of concatenated features representing one of         coughing etc. Hyoid bone is horseshoe shaped and is the
the 5 pictures. The picture corresponding to the highest           only bone in the body that floats, unconnected to another
cosine value is taken to be the high relevant picture and the      bone. A ring shaped cartilage is connected to the windpipe.
picture corresponding to the lowest cosine value as the low        The fat pad provides cushion to all the organs. What name is
relevant picture.                                                  given to the organ present in our throat that drops down
                                                                   when we swallow in order to protect our lungs and
Integrating semantic information from pictures into                trachea?‖ Similarly the hyperlinks were elaborated.
CoLiDeS CWW is a usability inspection method that
attempts to account for the four phases of CoLiDeS                 Step4: Elaborating features from pictures; Semantic
(parsing, comprehension and elaboration, focusing on and           features for five pictures were collected for this context
selecting). CWW assumes that a user selectively attends to         from ten participants. Table 1 shows the five most frequent
that sub-region of a page whose description is most similar        features obtained for the picture in Figure 4. Two features
to her goal. It uses LSA to compute this similarity. The           satisfying our criterion are shown in bold. Similarly,
main steps involved in CWW (Blackmon et al., 2002) are:            features representing other four pictures were selected. The
for each goal selecting a semantic space that best fits the        features obtained for each picture were elaborated. High and
user profile, compiling a set of realistic user goals,             low relevant pictures were then computed.
elaborating the goal and the links, and finally estimating
semantic similarity of goal and links. In our approach, these                     Table1: Most frequent features
four steps remain the same. As a fifth step, we collect
semantic features from pictures relevant to each goal,                                  Feature             Frequency
elaborate the features obtained from pictures along with
                                                                              Larynx, Vocal folds              7
elaboration of goal and the links. The elaborated features are
appended to the elaborated links. Final step is to compute                    Respiratory system               6
semantic similarity between the elaborated user-goal and the                  Wind pipe                        4
elaborated new links. The link with the highest cosine value
is the link predicted by CoLiDeS + Pic.                                       Some bone                        3
                                                                              Front view and Back              3
Simulation Study
                                                                              view
A pilot study with a mock website on Human Body was
conducted to verify the accuracy of CoLiDeS + Pic. The
website had 4 levels of depth. We designed 8 user-goals, 2         Step5 and 6: Computation of Final Cosine Values; For
for each level. We present here only the results of a goal         each level, using LSA, cosine values were computed in the
concerning information on level3. Would there be any               three conditions:
difference in predicting the right link after including                 1) Elaborated Goal and Elaborated Links – Simple
features from a picture that is semantically close to the                   CoLiDeS (Step5)
context? And, also what happens when we include a picture               2) Elaborated Goal and Elaborated Links appended
that is not so relevant?                                                    with Elaborated Features of High Relevant Picture
                                                                            – CoLiDeS + High Pic (Step6)
Step1: Selecting Semantic Space; LSA provides many                      3) Elaborated Goal and Elaborated Links appended
semantic spaces to facilitate representing accurately the                   with Elaborated Features of Low Relevant Picture
background knowledge and general reading ability of                         – CoLiDeS + Low Pic (Step6)
different target user groups. We did choose the semantic
space – ―General Reading upto 1st Year College‖                       Table 2 shows the final cosine values computed between
(http://lsa.colorado.edu/ )                                        the elaborated goal and the elaborated links appended with
                                                                   elaborated features in the three conditions. The correct links
Step2: User goal; User goal at level3 was – ―In the                (Link1 for level1, Link1.1 for level2 and Link1.1.3 for
respiratory system, what name is given to the valve that           level3) and the predicted links are shown in bold. We can
drops down when we swallow in order to protect our lungs           see from the table that the correct link is predicted rightly by
and trachea?”                                                      CoLiDeS and CoLiDeS + High Pic methods for all three
                                                                   levels. Furthermore, the cosine values obtained from
Step3: Elaborating Goal and Hyperlinks; LSA analysis is            CoLiDeS + High Pic are clearly higher than those obtained
used to simulate the process of elaboration that happens           from simple CoLiDeS. CoLiDeS + Low Pic predicts the
during the comprehension phase of CoLiDeS. The goal                right link only at level 2. Moreover, the cosine values
mentioned in Step2 was elaborated as – ―Larynx serves an           obtained from CoLiDeS + Low Pic are lower than those of
                                                               2811

simple CoLiDeS. Similar computations for the other goals          Chi, E. H., Pirolli, P., Chen, K., & Pitkow, J. (2001). Using
were conducted and they showed the same pattern.                     information scent to model user information needs and
                                                                     actions and the Web. Proceedings of CHI 2001, ACM
       Table 2: Final Cosine Values in the 3 Conditions              Press, 490–497.
          Link       CoLiDeS CoLiDeS CoLiDes                      Chi, E., Pirolli, P., & Pitkow, J. (2000). The scent of a site:
                                  + High       + Low                 A system for analyzing and predicting information scent,
                                    Pic          Pic                 usage, and usability of a website. Proceedings of CHI
                            Level1                                   2000, ACM Press, 161–168.
       Link1            0.19        0.29          0.09            Desimone, R., & Duncan, J., (1995), Neural Mechanisms of
                                                                     Selective Visual Attention, Annual Review of
       Link2            0.01         0.23         0.03               Neuroscience, March 1995, Vol. 18, 193-222.
       Link3            0.16         0.26         0.13            Hinesley, G.A. (2005). The impact of graphical conventions
       Link4            0.01         0.24         0.04               and layout location on search for webpage widgets.
                                                                     Unpublished Dissertation, University of Colorado,
                            Level 2                                  Boulder.
       Link1.1         0.22        0.29         0.19              Hinesley, G.A., & Blackmon, M.H. (2008). The Impact of
                                                                     Graphics and Location Expectations on the Search for
       Link1.2         0.18        0.27         0.08
                                                                     Webpage Widgets. Workshop on Cognition and the Web,
                            Level 3                                  Granada, Spain.
       Link1.1.1       0.19        0.26         0.12              Itti, L., & Koch, C. Computational Modelling of Visual
                                                                     Attention, Nature Reviews Neuroscience, 2(3)194-203.
       Link1.1.2       0.18        0.27         0.17              Juvina, I., Oostendorp, H. van, Karbor, P., & Pauw, B.
       Link1.1.3       0.32        0.46         0.12                 (2005). Toward Modeling Contextual Information in Web
                                                                     Navigation. XXVII Annual Conference of the Cognitive
Discussion & General Conclusion                                      Science Society, Stresa, Italy.
                                                                  Juvina, I. & Oostendorp, H. van (2008). Modeling Semantic
Our first study showed that graphical information is equally         and Structural Knowledge in Web Navigation. Discourse
important as textual information, and consequently should            Processes, 45(4-5), 346-364.
be incorporated in cognitive modelling of web-navigation.         Kintsch, W. (1998). Comprehension: A Paradigm for
The second study in which we incorporated semantic                   Cognition. Cambridge University Press,
features from pictures into CoLiDeS is giving higher cosine       Kitajima, M., Blackmon, M.H., & Polson, P.G. (2000). A
values in the highly relevant picture condition. Furthermore         Comprehension-based Model of Web Navigation and Its
the results of the simulation show that if the information           Application to Web Usability Analysis. Proceedings of
from pictures is included into modelling of navigation               CHI2000, ACM Press, 357-373.
behaviour, the correct links are predicted with greater           Landauer, T. K., Foltz, P.W., & Laham, D. (1998).
information scent. And most importantly, CoLiDeS + Pic               Introduction to Latent Semantic Analysis. Discourse
would lead more frequently and more clearly to the right             Processes, 25, 259-284.
navigation path than the other conditions. We are also            Mayer, R. E. & Moreno, R. (2003). Nine ways to reduce
planning to corroborate these results with actual user               cognitive load in multimedia learning. Educational
behaviour in terms of number of clicks predicted by both the         Psychologist, 38, 43-52.
models. Whether the presence of a relevant picture                Miller, C. S., & Remington, R. W. (2004). Modelling
decreases the perceived disorientation and the time taken to         Information Navigation: Implications for Information
finish the task is to be tested. Finally, more computations          Architecture. Human-Computer Interaction, 19(3), 225-
with stricter conditions will be done to refine the procedure        271.
further.                                                          Oostendorp, H. van, & Juvina, I. (2007). Using a Cognitive
                                                                     Model to generate Web Navigation support, International
                        References                                   Journal of Human Computer Studies, Volume 65(10),
                                                                     887-897.
Blackmon, M.H., Polson, P.G., Kitajima, M., & Lewis, C.           Paivio, A (1986). Mental representations: a dual coding
   (2002). Cognitive Walkthrough for the Web. 2002 ACM               approach. Oxford. England: Oxford University Press.
   conference on human factors in computing systems               Pirolli, P., & Card, S.K. (1999). Information Foraging.
   (CHI'2002), 463-470.                                              Psychological Review, 106(4), 643-675.
Blackmon, M.H., Kitajima, M., & Polson, P.G. (2005). Tool         Pirolli, P., & Fu, W.T. (2003). SNIF-ACT: a model of
   for Accurately Predicting Website Navigation Problems,            information foraging on the World Wide Web. 9th
   Non-Problems, Problem Severity, and Effectiveness of              International Conference on User Modeling (UM 2003);
   Repairs. 2005 ACM conference on human factors in                  Johnstown; PA. Berlin: Springer Verlag; LNCS 2702: 45-
   computing systems. 31-40.                                         54.
                                                              2812

