UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Recommender Systems for Literature Selection: A Competition of Decision Making and
Memory Models
Permalink
https://escholarship.org/uc/item/0z95s3zd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Marewski, Julian
Van Maanen, Leendert
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Recommender Systems for Literature Selection:
                    A Competition between Decision Making and Memory Models
                                             Leendert van Maanen (leendert@ai.rug.nl)
                                     Department of Artificial Intelligence, University of Groningen
                                            P.O.Box 407 9700 AK Groningen, The Netherlands
                                     Julian N. Marewski (marewski@mpib-berlin.mpg.de)
                    Max Planck Institute for Human Development, Center for Adaptive Behavior and Cognition
                                                   Lentzeallee 94, 14195 Berlin, Germany
                              Abstract                                  otherwise required to separate the relevant from the
   We examine the ability of five cognitive models to predict
                                                                        irrelevant. In particular, here we will evaluate six models
   what publications scientists decide to read. The cognitive           that can solve the problem of information selection for the
   models are (i) the Publication Assistant, a literature               scientific domain.
   recommender system that is based on a rational analysis of              All models select relevant scientific papers from a large
   memory and the ACT-R cognitive architecture; (ii-iv) three           collection of scientific abstracts. They include the
   simple decision heuristics, including two lexicographic ones         Publication Assistant (Van Maanen, Van Rijn, Van Grootel,
   called take-the-best and naïveLex, as well as unit-weight            Kemna, Klomp, & Scholtens, in press), a recommender
   linear model, and (v) a more complex weighted-additive
   decision strategy called Franklin’s rule. In an experiment with      system that was recently developed to assist scientists in
   scientists as participants, we pit these models against (vi)         identifying relevant articles. We will compare the
   multiple regression. Among the cognitive models, take-the-           performance of this system to that of three simple decision
   best best predicts most scientists’ literature preferences best.     heuristics, including a unit-weight linear model (see Dawes,
   Altogether, the study shows that individual differences in           1979; Dawes & Corrigan, 1974), and two lexicographic
   scientific literature selection may be accounted for by              rules, called take-the-best (Gigerenzer & Goldstein, 1996),
   different decision-making strategies.
                                                                        and naiveLex. We will also pit all models against two
   Keywords: Recommender system; ACT-R; rational analysis;              complex linear weighted-additive models, one being
   simple heuristics; take-the-best; literature search                  Franklin’s rule (Gigerenzer & Goldstein, 1999) and the
                                                                        other multiple regression.
                     Literature Selection                                  While we do not aim to model the cognitive processes
In 2006, the number of scientific publications in the                   that are actually going on when scientists make literature
relatively small ISI subject category Information Science &             choices, except for multiple regression all models tested
Library Science was 2054. In other words, researchers                   here are grounded in cognitive theories. The Publication
working in this area had to scan through over 2,000 papers a            Assistant is a memory model that is based on the rational
year to keep up with the current developments. However,                 analysis framework (Anderson, 1990; Oaksford & Chater,
this number is, if anything, an underestimation of the total            1998), as incorporated in the ACT-R cognitive architecture
number of potentially relevant papers, as this number only              (Anderson & Lebiere, 1998). The heuristics are models of
holds if a researcher is interested in a single subject area. In        decision making that are grounded in the fast and frugal
practice, most researchers work on the intersection of                  heuristics framework (Gigerenzer, Todd, & the ABC Group,
multiple domains, increasing the number of potentially                  1999). The linear weighted additive model, Franklin’s rule,
relevant papers enormously. Not only professionals in the               is also a model of decision making (Gigerenzer &
scientific domain are confronted with masses of potentially             Goldstein, 1999). All models are common in the memory
relevant information. Also, government or business                      and judgment and/or decision making literature.
employees often need to decide which of numerous reports,                  In what follows, we will give an outline of the Publication
leaflets, and bulletins to read, and which to ignore—a                  Assistant. Next, we will introduce the five alternative
challenge that is aggravated by the continuously increasing             models. In an experiment, we will then evaluate the models’
amount of information that is available online. For instance,           performance in predicting scientists’ literature preferences.
many press agencies produce over 12.500 bulletins a year.
Reporters therefore have to make selections, and although                  The Publication Assistant: A Memory Model
the agencies often tag their bulletins, the sheer mass of               An example of the problem addressed in this paper is the
information makes that it is easy to miss important ones.               selection of relevant talks when attending a large, multi-
   In this paper, we will focus on one solution to this                 track scientific conference such as the Annual Cognitive
problem: recommender systems. Typically, corresponding                  Science Conference. The information selection process
decision aids automatically come up with a pre-selection of             starts when a researcher registers and receives a copy of the
information that is worth further consideration, saving                 conference program. For instance, a strategy often employed
institutions, firms, and people parts of the time and effort            by many conference attendees is to scan talk titles, author
                                                                    2914

names, or abstracts for words or names that sound familiar.          influences a researcher’s familiarity with the fact. These
If an entry contains enough interesting words, it is selected        relations are captured by Equation 1, in which B stands for
for more careful reading, and the corresponding talk might           the base-level activation of a fact i, ti stands for the time that
be attended. In order to determine if a word qualifies as            has passed since the last exposure to that fact, and d
interesting in the context of the conference, a researcher           represents the speed with which the influence of each
might assess whether she has used the word in her own                exposure decays away. The summation takes place over all
research in the past. The assumption is that the words used          n previous encounters with the fact.
by someone in the context of her own research reflect her                        & n (d #
scientific interests. The Publication Assistant is a literature          B = ln $' ti !.                       (1)
                                                                                 % i =1   "
selection tool that could be run over a (digitized) conference
                                                                        Besides frequency and recency of encounters with facts,
program prior to attending the conference. The model
                                                                     the context in which these facts occur also plays a role in the
recommends talks a given scientist might find useful to
                                                                     activation of the facts. This spreading activation (Quillian,
attend, saving that researcher the time and effort required to
                                                                     1968) component represents the likelihood that a fact will be
scan the conference program on her own. To this end, the
                                                                     needed if another one is currently being used. These
model searches through the scientist’s own work, examining
                                                                     likelihoods depend on the pattern of prior exposures with
in how far words that appear in conference abstracts also
                                                                     the facts, as represented by the relatedness measure Rji
occur in the scientist’s work. Specifically, the model bases
                                                                     between two facts j and i (Anderson & Lebiere, 1998):
its recommendations on the following properties of words in
an abstract:                                                                    F(W j & W i )F(N)
                                                                         R ji =                                         (2)
   Recency of occurrence in the scientist’s own work                                F(W j )F(W i )
   • The year in which a word from a conference abstract
                                                                        where F(Wj) is the frequency of fact i, F(N) is the total
        appears for the first time in the abstracts the scientist
                                                                     number of exposures, and F(Wj & Wi) is the number of co-
        has published in the past,                           !       occurrences of the facts j and i.
   • The year in which a word from a conference abstract
                                                                        With the equations that are provided by the rational
        appears for the last time in the abstracts the scientist
                                                                     analysis of memory, one can calculate the base-level
        has published in the past,
                                                                     activation of a word based on its occurrences in publications
   Frequency of occurrence in the scientist’s own work               of the user. However, rather than using Equation 1 directly,
   • The frequency of appearance of a word from a                    the Publication Assistant uses Petrov’s (2006) version of it.
        conference abstract in the abstracts the scientist has       In Equation 3, the decay parameter is fixed at .5 and a
        published in the past,                                       history factor h is added, which represents a free parameter:
   • The frequency of co-occurrence of a word from the                         # 1
        conference abstract with another word in the abstracts                                   2n " 2 &
                                                                       B = ln%            +                 ( with h > 0     (3)
        the scientist has published in the past.                               $ t1 + h       t n + t1 + h '
   Based on these properties, the model creates an individual           The Publication Assistant makes recommendations by
representation of a researcher’s interests. The Publication          combining the base-level activation of a word (i) with the
Assistant applies these user models to predict the relevance !       weighted base-level activation of related words (j) in the
of words that occur in other scientific abstracts, essentially       abstract (Pirolli & Card, 1999):
estimating how familiar the contents of these abstracts
would be to the scientist. In the next section, we will                  Ai = Bi + " B j R ji                             (4)
                                                                                        j
describe in more detail how the Publication Assistant
                                                                        To compare the relevance of abstracts with each other,
estimates familiarity.
                                                                     each one is represented by the average activation of the
Model Equations                                                      words that occur in it. In a comparison of two abstracts, the
                                                              !
                                                                     Publication Assistant then recommends the more activated
The Publication Assistant works like a model of the                  one. Abstracts in which many words have high base-level
contents of a researcher’s memory. Its equations are based           and spreading activation values have a high match with the
on Anderson and Schooler’s (1991) rational analysis of               researchers own word usage, and thus may be more
memory. According to their analysis, the probability that a          interesting.1 The Publication Assistant’s recommendations
fact (e.g., a word) stored in memory will be needed to               are thus based on the structure of the environment of a
achieve a processing goal can be predicted from the
organism’s pattern of prior exposure to the corresponding
piece of information. For example, the probability that a fact          1
                                                                          Van Maanen et al. (in press) found that the frequency of words in
about a scientific topic is of relevance to a researcher may         scientific abstracts differs from normal word usage in written English. To
depend on the frequency and recency of his writings about it         counter the unwanted influence of normally high-frequent words (e.g,
                                                                     “the”), van Maanen et al. built a filter for these words when they developed
in the past. Frequency and recency, in turn, feed into a             the Publication Assistant. Here, we run all analyses using that filter. As
memory currency called base-level activation, which                  they showed, the filtering does not interfere with how well an abstract
                                                                     represents the contents of a paper.
                                                                 2915

particular researcher. In particular, the structure of word         Lexicographic Heuristics: take-the-best, naïveLex
usage in previously published abstracts. The only parameter         The first model to be considered here is take-the-best. To
that may be varied is the history parameter, h, which               make literature recommendations, take-the-best uses
represents the relative importance of recency versus                attributes of articles as cues. In our context, cues are the
frequency in determining activation. In the research reported       words that occur in an abstract. If such a word also occurs in
here, we kept h constant at the same value reported in Van          a scientist’s own publication, then it is considered a positive
Maanen et al. (in press).                                           cue, suggesting that an abstract is of interest to that scientist.
                                                                    Take-the-best considers all cues sequentially (i.e., one at a
      Alternative Models: Decision Strategies                       time; hence lexicographic) in the order of their validity. The
To evaluate the performance of the Publication Assistant in         validity of a cue is the probability that an alternative A (e.g.,
predicting scientists’ literature preferences, we compared it       an article) has a higher value on a criterion (e.g., relevance
to five alternative models. While the Publication Assistant         for a researcher) than alternative B, given that alternative A
essentially mimics a model of memory, these alternative             has a positive value on that cue and alternative B does not.
models have originally been proposed as decision strategies         In a comparison of two abstracts, take-the-best bases a
in the judgment and decision making literature                      decision on the first cue that discriminates between the
   In particular, we focus on a class of models that have been      abstracts, that is, on the first cue for which one abstract has
prominent in the fast and frugal heuristics framework.              a positive value and the other one does not. The heuristic is
According to this framework, humans often make decisions            defined in terms of three rules:
under the constraints of limited information processing
capacity, knowledge, and time—be they about the relevance           (1) Look up cues in the order of their validity.
of scientific articles, or the likely performance of stocks, or     (2) Stop when the first cue is found that discriminates
the nutritional value of food. Such decisions can                   between the abstracts.
nevertheless be made successfully because humans can rely           (3) Choose the abstract that this cue favors.
on a large repertoire of simple decision strategies, called            The second lexicographic model, here called naiveLex, is
heuristics. These rules of thumb can perform well even              identical to take-the-best, except that it does not estimate the
under the above-mentioned constraints. They do so by                validity order of cues. Rather, cues are simply considered in
exploiting the structure of information in the environment in       the order of the frequency of occurrence of the
which a decision maker acts and by building on the ways             corresponding words in each researcher’s published
evolved cognitive capacities work, such as the speed with           abstracts. This aspect of the model is similar to the
which the human memory system retrieves information (for            Publication Assistant, in which the word frequency is also
recent overviews, see Cokely, Schooler, & Gigerenzer, in            taken into account (but weighted with recency).
press; Marewski, Galesic, Gigerenzer, 2009).
   One of the heuristics tested here, the unit-weight linear        A Unit-weight-linear Heuristic
model, is particularly simple, requiring no free parameters
                                                                    Lexicographic heuristics such as take-the-best can avoid
to be fitted. Related models have proved to perform quite
                                                                    going through all words (i.e., cues) from an abstract, which
well in predicting unknown events and quantities. Just as the
                                                                    can save effort, time, and computations once the order of
unit-weight linear model, also naiveLex dispenses with all
                                                                    cues is known. Unit-weight linear heuristics, in contrast,
free parameters. If these two particularly simple heuristics
                                                                    integrate all cues into a judgment by adding them. These
predicted scientist’s literature preferences successfully, then
                                                                    models can nevertheless simplify the task by weighing each
they would simplify the selection of abstracts more than the
                                                                    cue equally (hence unit-weight). In a comparison of two
Publication Assistant does. Take-the-best is a little more
                                                                    abstracts, it reads as follows:
complex, requiring free parameters to be fitted for each
individual scientist. Take-the-best and related models have         (1) For each abstract, compute the sum of positive cues.
been found to be, on average, more accurate than multiple           (2) Decide for the abstract that is favored by a larger sum.
regression in predicting various economic, demographic,
and environmental, variables (e.g., Czerlinski, Gigerenzer,         Weighted-Additive models: Franklin’s Rule and
& Goldstein, 1999). Finally, the most complex models                Multiple Regression
tested here, Franklin’s rule and multiple regression, require       Franklin’s rule (Gigerenzer & Goldstein, 1999) is similar to
for each individual researcher as many free parameters to be        the unit-weight linear heuristic, but instead weights all the
fitted as there are words in the abstracts under consideration.     cues by their validities prior to summation. (The cue
While these two models are prominent in the judgment and            validities are identical to those relied on by take-the-best.)
decision making literature, due to their large complexity           Multiple regression, in turn, estimates the weights of the
they are not considered heuristic decision strategies in the        cues by minimizing the error in the calibration set using
fast and frugal heuristics framework. Rather, they are often        maximum likelihood estimation. In a comparison of two
used as benchmark to evaluate the performance of heuristics         abstracts, Franklin’s rule and multiple regression read as:
in model comparisons (Gigerenzer & Goldstein, 1996).
                                                                2916

(1) For each abstract, compute the
weighted sum of cues.
(2) Decide for the abstract that is
favored by a larger sum.
              Experiment
To compare the Publication Assistant to
the alternative models’ capability of
predicting actual scientist’s literature
                                               Figure 1. The performance of the non-calibrated models. A-J represent individual
preferences, we re-analyzed data from a
                                                 participants. PA: Publication Assistant; UWL: unit-weight linear heuristic.
study by Van Maanen et al. (in press,
Experiment 2). They had asked researchers from the field of         predict the largest proportion of literature preferences. Take-
cognitive science to rate how much they were interested in a        the-best, Franklin’s rule, and multiple regression will
paper after reading the abstract. In this study, Van Maanen         therefore be referred to as the calibrated models.
et al. had found that the Publication Assistant could fit              We used these optimal values to compute the proportion
researcher’s interests reasonably well; however, they did not       of preferences consistent with each model in the other half,
compare its performance to that of alternative models.              the validation set, where the models’ generalizability is
                                                                    evaluated. For each partition, we also computed the
Methods                                                             proportion of preferences consistent with the three not-
Participants Ten researchers (2 full professors, 2 associate        calibrated models (the Publication Assistant, naiveLex, and
professors, 5 assistant professors, and 1 post-doc) from            the unit-weight linear heuristic). The free parameter of the
various subfields of cognitive science and from various             Publication Assistant, h, was set to 10. In fitting the very
countries were asked to participate.                                same participants as we do here, van Maanen et al. (in
                                                                    press), had found this value to work reasonably well.
Procedure For each of the researchers, Van Maanen et al.               We ran these analyses for a subset of possible sizes of the
(in press) constructed user models of the Publication               calibration  and validation sets; that is, we first computed the
Assistant based on the abstracts of their published work            proportion    of each model’s correct predictions for a
insofar it was indexed by PsycINFO. They then ordered all           calibration  set size of 1 and a test set size of 209, then for a
abstracts from the last three volumes (2004-2006) of the            calibration  set size of 11, and a test set size of 199, and so
Cognitive Science Journal according to the predicted                on. The   larger  the size of the calibration sets, the larger is
relevance for the researcher, based on the researcher’s             the   sample     of  paired comparisons from which the
published abstracts. From the ordered list of abstracts, they       parameterized decision models can estimate an individual
presented each researcher the top five abstracts, the bottom        researcher’s interests, that is, the more “experience” these
five abstracts, and five abstracts from the middle of the list.     models can accumulate before making their predictions.
For each researcher, the presentation order of these 15             This procedure was repeated enough times to average out
abstracts was randomized. Each researcher indicated with a          noise due to the random selection of calibration sets.
grade between 0 and 9 how much he or she was interested in
the papers, based on the abstracts.                                 Results When comparing the Publication Assistant with the
                                                                    other non-calibrated models (naiveLex and the unit-weight
Analyses When comparing models that differ in terms of              linear model), we found that the three models performed
their complexity, it is advisable to assess the models’ ability     differently for different participants (Figure 1). The
to generalize to new data (e.g., Marewski & Olsson, 2009;           Publication Assistant made the most correct inferences for
Pitt, Myung, & Zhang, 2002). This holds especially true             three participants (A, D, and J), while unit-weight linear
when the models have been designed to generalize to new             heuristic outperformed the other two non-calibrated
data, as it is the case with the recommender systems tested         competitors on four occasions (B, C, E, and H). NaiveLex
here. To compare the performance of the Publication                 scored best for three participants (F, G, and I). Overall, the
Assistant to that of the five alternative models in predicting      performance of the models did not differ much (MPA = .60,
each researcher’s ratings, we ran a cross-validation. To this       MnaïeveLex = .59, MUWL = .60).
end, we constructed paired comparisons of all 15 abstracts             For each of the 10 participants, Figure 2 shows the
for each participant individually (210 pairs). We divided           proportion of correctly predicted preferences for the three
each participant’s abstracts pairs randomly into two parts.         calibrated models as a function of the size of the calibration
The first part represented the calibration set in which we          set. As one would expect, for all participants the accuracy
calculated for each participant that person’s optimal values        of the predictions of the parameterized models increases
for the free parameters in take-the-best, Franklin’s rule, and      with the size of the calibration set. Of the calibrated models,
multiple regression, respectively. That is, we identified the       Franklin’s rule was consequently outperformed by the take-
parameter value at which each model would correctly                 the-best heuristic and the multiple regression model, which
                                                                2917

performed equally well, but differed among participants.           calibrated models varied across participants. However, it
Take-the-best was the best predictor for participants B, C, E,     should be realized that naiveLex and the Publication
G, I, and J, while the regression model performed best for         Assistant only differ with respect to the use of the recency
participants A, D, F, and H. Overall, take-the-best                component. Both models use the frequency of words in
performed best (MTTB = .84, MMR = .81, MFranklin = .71).           published abstracts in the same way. Therefore, the
                                                                   variation in performance between the models may be
                         Discussion                                attributable to the importance the recency component plays
We examined the ability of six models to predict scientists’       in the models. That is, the Publication Assistant
literature preferences: (i) the Publication Assistant, a           overestimates the importance of more frequent words in the
recommender system that is based on a rational analysis of         published abstracts relative to the importance of recent word
memory and the ACT-R architecture; (ii-iv) three simple            usage. Since the h factor scales the relative contributions of
heuristics, including take-the-best, a naive lexicographic         word frequency and word recency, recommendations of the
model, and a unit-weight linear model, and (v-vi) two              Publication Assistant could improve if one would allow for
complex weighted-additive models, Franklin’s rule and              the h parameter to be fit individually to each scientist’s data.
multiple regression.                                                  The fact that the non-calibrated models performed
   For some participants and calibration set sizes, the            differently across participants is in agreement with other
regression model outperformed take-the-best. One reason            findings in the judgment and decision making literature,
why take-the-best did not fare as well as multiple regression      where individual variation in people’s use of decision
on every occasion might be that the structure of information       strategies is commonly observed (Bröder & Gaissmaier,
available in the abstracts was not well suited for this simple     2007; Mata, Schooler, & Rieskamp, 2007; Pachur, Bröder,
heuristic (see Martignon & Hoffrage, 2002). For instance,          & Marewski, 2008). In fact, based on this literature, one
take-the-best essentially bets on a noncompensatory                might expect that the most useful approach for designing
information structure, always preferring the most valid            recommender systems would have been to build different
discriminating cue to all others. In the domain of literature      systems for different users, depending on which model
selection, such information structures might not be                predicts the respective scientist’s preferences best.
prevalent. To give an example, the words “Memory” and                 Our results also complement findings by Lee, Loughlin,
“Retrieval” might be equally good predictors of some               and Lundberg (2002), who, in a study on literature search,
cognitive scientist’s research interests.                          examined the performance of a simple heuristic in
   Another result was that the performance of the non-             identifying articles that are relevant to a given topic (e.g.,
       Figure 2. The calibrated models’ individual predictions of literature selections. Each panel represents one participant.
                             TTB: take-the-best; Franklin: Franklin’s rule; MR: multiple regression.
                                                               2918

memory). Their analyses show that a researcher going by a           Dawes, R. M. (1979). Robust beauty of improper linear-
variant of take-the-best would have had to search through             models in decision-making. American Psychologist,
fewer articles in order to find the relevant ones than a person       34(7), 571-582.
behaving in accordance with a weighted-additive model.              Dawes, R. M., & Corrigan, B. (1974). Linear-models in
                                                                      decision-making. Psychological Bulletin, 81(2), 95-106.
Why was the Publication Assistant outperformed?                     Gigerenzer, G., & Goldstein, D. G. (1996). Reasoning the
Take-the-best, Franklin’s rule, and the regression model              fast and frugal way: Models of bounded rationality.
learned about the scientists’ interests directly from the             Psychological Review, 103(4), 650-669.
paired comparisons between abstracts that were included in          Gigerenzer, G., & Goldstein, D. G. (1999). Betting on one
the calibration sets. The Publication Assistant, in turn, was         good reason: The take the best heuristic. In G. Gigerenzer,
trained on a participant’s published abstracts (Van Maanen            P. M. Todd & the ABC Group (Eds.), Simple heuristics
et al. in press), under the assumption that word frequencies          that make us smart. New York: Oxford UP.
in those abstract would reflect the participants’ interests.        Gigerenzer, G., Todd, P. M., & the ABC Group. (1999).
While this way of training the model better reflects real-life        Simple heuristics that make us smart. New York: Oxford
situations of information selection, in which people’s                UP.
appraisal of items (such as abstracts) is often unknown, it         Lee, M. D., Loughlin, N., & Lundberg, I. B. (2002).
might have been detrimental for the model’s performance.              Applying one reason decision-making: The prioritisation
                                                                      of literature searches. Australian Journal of Psychology,
                         Conclusion                                   54(3), 137-143.
                                                                    Martignon, L., & Hoffrage, U. (2002). Fast, frugal, and fit:
In this paper, we evaluated the ability of models of memory
                                                                      Simple heuristics for paired comparison. Theory and
and decision making to serve as literature recommender
                                                                      Decision, 52(1), 29-71.
systems. As it turned out, the performance of the models in
                                                                    Marewski, J. N., Galesic, M., & Gigerenzer, G. (2009). Fast
predicting literature preferences differed substantially across
                                                                      and frugal media choices. In T. Hartmann (Ed.), Media
participants, indicating that there may be substantial
                                                                      choice: A theoretical and empirical overview (pp. 107-
individual differences in the ways scientists decide which
                                                                      128). New York & London: Routledge.
papers to read. This finding suggests that for successful
                                                                    Marewski, J. N., & Olsson, H. (2009). Beyond the null
recommendation, the best predicting model should be
                                                                      ritual: Formal modeling of psychological processes.
determined first on an individual basis.
                                                                      Journal of Psychology, 217, 49–60.
   To conclude, in today’s world of mass media, the choice
                                                                    Mata, R., Schooler, L. J., & Rieskamp, J. (2007). The aging
which information to attend to, and which to ignore
                                                                      decision maker: Cognitive aging and the adaptive
becomes an ever more important challenge for
                                                                      selection of strategies. Psychology and Aging, 22, 796-
professionals. Automatic recommender system might help
                                                                      810.
to cope with these demands of the information age—savings
                                                                    Oaksford, M., & Chater, N. (1998). Rational models of
in time and effort that can eventually be invested elsewhere.
                                                                      cognition. Oxford: Oxford UP.
We hope that comparisons between different approaches,
                                                                    Pachur, T., Bröder, A., & Marewski, J. N. (2008). The
such as the ones tested here, help along that way.
                                                                      recognition heuristic in memory-based inference: Is
                                                                      recognition a non-compensatory cue? Journal of
                         References                                   Behavioral Decision Making, 21(2), 183-210.
Anderson, J. R. (1990). The adaptive character of thought.          Petrov, A. A. (2006). Computationally efficient
   Hillsdale, NJ: Erlbaum.                                            approximation of the base-level learning equation in
Anderson, J. R., & Lebiere, C. (1998). The atomic                     ACT-R. In D. Fum, F. Del Missier & A. Stocco (Eds.),
   components of thought. Mahwah, NJ: Lawrence Erlbaum.               Proceedings of the Seventh International Conference on
Anderson, J. R., & Schooler, L. J. (1991). Reflections of the         Cognitive Modeling (pp. 391-392). Trieste, ITA.
   environment in memory. Psychological Science, 2(6),              Pirolli, P., & Card, S. (1999). Information foraging.
   396-408.                                                           Psychological Review, 106(4), 643-675.
Bröder, A., & Gaissmaier, W. (2007). Sequential processing          Pitt, M. A., Myung, I. J., & Zhang, S. (2002). Toward a
   of cues in memory-based multiattributte decisions.                 method for selecting among computational models for
   Psychonomic Bulletin & Review, 14(5), 895-900.                     cognition. Psychological Review, 109, 472–491.
Cokely, E.T., Schooler, L.J., & Gigerenzer, G. (in press).          Quillian, M. R. (1968). Semantic memory. In M. Minsky
   Information use for decision making. In M.N. Maack &               (Ed.), Semantic information processing (pp. 216-270).
   M.J. Bates (Eds.), Encyclopedia of Library and                     Cambridge, MA: MIT Press.
   Information Sciences.                                            Van Maanen, L., Van Rijn, H., Van Grootel, M., Kemna, S.,
Czerlinski, J., Gigerenzer, G., & Goldstein, D. G. (1999).            Klomp, M., & Scholtens, E. (in press). Personal
   How good are simple heuristics? In G. Gigerenzer, P. M.            Publication Assistant: Abstract recommendation by a
   Todd & the ABC Group (Eds.), Simple heuristics that                cognitive model. Cognitive Systems Research.
   make us smart (pp. 97-118). New York: Oxford UP.
                                                                2919

