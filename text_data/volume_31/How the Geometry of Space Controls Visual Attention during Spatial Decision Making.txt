UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How the Geometry of Space Controls Visual Attention during Spatial Decision Making
Permalink
https://escholarship.org/uc/item/5r52j3zx
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Buchner, Simon
Holscher, Christoph
Konieczny, Lars
et al.
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                          How the Geometry of Space controls Visual Attention
                                              during Spatial Decision Making
                                     Jan M. Wiener (jan.wiener@cognition.uni-freiburg.de)
                            Christoph Hölscher (christoph.hoelscher@cognition.uni-freiburg.de)
                                 Simon Büchner (simon.buechner@cognition.uni-freiburg.de)
                                  Lars Konieczny (lars.konieczny@cognition.uni-freiburg.de)
                  Center for Cognitive Science, Freiburg University, Friedrichstr. 50, D-79098 Freiburg, Germany
                               Abstract                                    The features people attend to when inspecting images of
   In this paper we present an eye-tracking experiment investi-
                                                                        scenes have been investigated in numerous studies revealing
   gating the control of visual attention during spatial decision       both, bottom-up (stimulus derived) as well as of top-down
   making. Participants were presented with screenshots taken at        (e.g., task) influences (for an overview see Henderson, 2003).
   different choice points in a large complex virtual indoor en-        Already in the 60s, Yarbus (1967) demonstrated influences
   vironment. Each screenshot depicted two movement options.
   Participants had to decide between them in order to search for       of the task on the control of visual attention: participants’
   an object that was hidden in the environment. We demonstrate         gaze patterns when inspecting the same drawing systemati-
   (1.) that participants reliably chose the movement option that       cally differed when asked to judge the ages of people depicted
   featured the longest line of sight, (2.) a robust gaze bias to-
   wards the eventually chosen movement option, and (3.) using          or when asked to estimate their material circumstances. The
   a bottom-up description that captures aspects of the geometry        most widely used bottom-up approach is that of saliency maps
   of the sceneries depicted, we were able to predict participants’     (Itti & Koch, 2000, 2001). A saliency map is a representa-
   fixation behavior. Taken together, results from this study shed
   light onto the control of visual attention during navigation and     tion of the stimulus in which the strength of different fea-
   wayfinding.                                                          tures (color, intensity, orientation) are coded. Several studies
   Keywords: visual attention; wayfinding; navigation; gaze be-         demonstrated that saliency maps are useful predictors of early
   havior; spatial cognition; spatial perception.                       fixations, particularly when viewing natural complex scenes
                                                                        (e.g., Foulsham & Underwood, 2008).
                           Introduction
                                                                           It is important to stress that bottom-up approaches usu-
What controls visual attention when navigating through
                                                                        ally do not explicitly account for the fact that images or pic-
space? In the context of navigation, eye-tracking studies so
                                                                        tures are two-dimensional projections of three-dimensional
far primarily investigated the role of gaze for the control of
                                                                        scenes. In other words, the geometrical properties of the
locomotory or steering behavior (Grasso, Prevost, Ivanenko,
                                                                        scenes depicted in the images are not necessarily captured
& Berthoz, 1998; Hollands, Patla, & Vickers, 2002; Wilkie
                                                                        or highlighted by, for example, saliency maps. For naviga-
& Wann, 2003). Wayfinding, however, also includes pro-
                                                                        tion and wayfinding, however, the interpretation and under-
cesses such as encoding and retrieving information from spa-
                                                                        standing of the depicted three dimensional structure may be
tial memory, path planning, and spatial decision making at
                                                                        inevitable. This opens up intriguing questions: Is it possible
choice points (c.f. Montello, 2001). So far, very few, if
                                                                        to predict gaze behavior by analyzing geometrical properties
any, studies made use of eye-tracking techniques to investi-
                                                                        of the sceneries depicted if the viewer is solving a navigation
gate such higher level cognitive processes involved in navi-
                                                                        task? If so, can the analysis of gaze behavior be used to infer
gation and wayfinding. For example, which information do
                                                                        the strategies and heuristics underlying different navigation
navigators attend to and process when deciding between path
                                                                        or wayfinding tasks? And, which kind of description systems
alternatives? And, how does gaze behavior relate to spatial
                                                                        of spatial form and structure captures properties of space that
decision making at all? To approach these questions we pre-
                                                                        are relevant for the control of visual attention?
sented participants with images of choice points and asked
them to decide between two movement options while record-                  Promising candidates are isovists or viewshed polygons
ing their eye-movements.                                                (Benedikt, 1979), which both describe the visible area from
   In non-spatial contexts, gaze behavior has been shown to             the perspective of the observer. Isovists are essentially depth
reflect preferences in visual decision tasks (Glaholt & Rein-           profiles and several quantitative descriptors such as the visi-
gold, in press). In two alternative forced choice paradigms             ble area, the length of the perimeter, the number of vertices,
in which participants have to judge attractiveness of faces,            etc., can be derived that reflect local physical properties of the
for example, gaze probability is initially distributed equally          corresponding space. Moreover, isovists have been shown
between alternatives. Only briefly before the decision, gaze            to capture properties of the geometry of environments that
gradually shifts towards the eventually chosen stimulus (Shi-           are relevant for experience of the corresponding space and
mojo, Simion, Shimojo, & Scheier, 2003; Simion & Shimojo,               locomotion within the space (Wiener et al., 2007; Franz &
2007). It is an open question whether similar effects can also          Wiener, 2008).
be observed in spatial decision making such as path choice                 The specific research questions for this study were as fol-
behavior.                                                               lows:
                                                                    2286

 Figure 1: Two examples of decision points presented to par-
 ticipants (in high contrast).                                         Figure 2: Left: Position in the maze from which one of the
                                                                       snapshots was taken. The Grey area represents the isovist
                                                                       (depth profile) at this position; right: corresponding view in
1. How does gaze behavior relate to spatial decision making?           the ego-perspective. The depth profile that is approximated
    Is it possible to predict participants’ movement choices           by the dashed line is equivalent to the isovist displayed on the
    during navigation and wayfinding by analyzing their fix-           right. Note, however, that large distances are compressed in
    ation patterns?                                                    the depth profile obtained from the image as compared to the
                                                                       actual spatial situation captured by the isovist.
2. Where do navigators look when exploring unfamiliar en-
    vironments? Is it possible to predict gaze behavior by an-
    alyzing geometrical properties of the spatial situations en-       fact, the visual system has been shown to be able to use angu-
    countered?                                                         lar declination below the horizon for distance judgments (e.g.
                                                                       Ooi, Wu, & He, 2001).
                             Method                                       The depth profiles were used to compare spatial properties
 Participants                                                          of the left and right path alternative (left and right half of the
 Twenty subjects (14 women, mean age: 22.45 ± 2.83 years)              stimulus). In particular, we calculated the proportion of the
 participated in the experiment. They were mostly university           length of the longest line of sight, and compared the number
 students and were paid 8 Euro per hour for participation in           of vertical and horizontal edges. The latter two measures are
 that study.                                                           thought to capture aspects of the spatial complexity of the
                                                                       path alternatives.
 Stimuli
                                                                       Procedure
 The stimuli were 30 screenshots from within large virtual ar-
 chitectural environments (for examples, see Figure 1). Each           Participants first read a description of the experiment along
 screenshot was taken at a decision point, depicting two path          with a set of instructions stating that their task was to search
 alternatives that differed with respect to their spatial form.        for an object (a gold bar) that was placed somewhere in the
 Pilot experiments suggested that high contrast images as de-          environment. They would be presented with a series of single
 picted in Figure 1, could be well comprehended parafoveally           choice points at which they had to decide whether to go left or
 without gaze shifts. We therefore reduced the contrast of the         right in order to search for the object. Note that participants
 stimuli by adjusting the colors of floor and ceiling to that of       had no clue about where to find the target object; in other
 the walls. By this mean participants were forced to overtly           words, they either had to apply decision strategies that were
 attend to the relevant information.                                   independent of the stimulus (always turn right, choose ran-
    Two versions of each stimulus were generated by mirror-            domly, etc) or they had to decide according to other stimulus-
 ing the original stimulus along the vertical axis. Presentation       related criteria. In the latter case any such criterion would
 of the original and the mirrored version of the stimuli were          require visual attention and should be reflected in gaze pat-
 balanced between participants.                                        terns. Instead of actually walking through the environment
    The spatial structure of the scenes were analyzed using a          they would then be presented with the next choice point they
 variant of isovist analysis (Wiener et al., 2007): for each stim-     would have encountered in the environment. In order to illus-
 ulus a depth profile was calculated by contouring the edge            trate this procedure, participants were presented with a series
 between the ground and the walls (see Figure 2 right). The            of snapshots taken between two choice points.
 resulting contour essentially describes the distance from the            Before a novel stimulus was presented, participants were
 observer to the walls in the stimulus. Although such depth            required to fixate a small cross in the center of the screen and
 profiles were measured in the 2d pictorial projection of the          press the ’Space’ bar. Participants pressed the left or right cur-
 scenes and are thus compressed around the horizon, they are           sor key to report their decision. Each stimulus was presented
 functionally equivalent to isovists. The angular declination of       for 5 seconds, irrespective of when participants responded.
 the lower border of distant walls is smaller than the declina-           Participants movement decisions (left or right) at individ-
 tion of the lower border or walls close-by (see Figure 2). In         ual choice points did not influence which image was pre-
                                                                   2287

Figure 3: Left: the three interest areas superimposed on one
of the stimuli.
                                                                     Figure 4: The likelihood that the observer’s gaze was di-
                                                                     rected towards the chosen part of the image (left/right) plotted
sented next, images were presented in random order. The              against time (synchronized at time of decision). The data rep-
experiment was divided into 5 trials containing 4, 5, 6, 7, or       resent the average across observers (n=20) and trials (n=30).
8 decisions. After the last decision of each trial, participants
were presented with an image of a gold bar hovering in a
small room.                                                          movement option) revealed that in 54.78% of the trials, they
                                                                     switched from left to right or from right to left (T-test against
Apparatus                                                            chance level [50%]: t(19)=1.30, p=.21). These analyses sug-
The stimuli were displayed at a resolution of 1024 x 768 pix-        gest that participants in fact reacted to the stimuli rather than
els on a 20” CRT monitor. The screen refresh rate was 100            using other search or navigation strategies such as making
Hz. Eye movements were recorded using a SR Research Ltd.             right or left turns only.
EyeLink II eye tracker, sampling pupil position at 500 Hz.              The absolute difference in the length of the longest line of
The eye tracker was calibrated using a 9-point grid. A second        sight between the left and the right part of the stimuli strongly
9-point grid was used to calculate the accuracy of the cali-         correlated with participants relative frequency to select the
bration. Fixations were defined using the detection algorithm        left or the right movement option (r=.64, p<.001). Specif-
supplied by SR Research.                                             ically, participants reliably chose the movement option that
                                                                     featured the longer line of sight.
Analysis
Behavioral data For each stimulus presented participants’            Eye Movement Data
decisions (left/right) as well as the corresponding response         Fixation Duration. The mean fixation duration towards the
time was recorded.                                                   left or right interest area before participants reported their de-
                                                                     cision was 313ms. Fixation durations significantly differed
Eye movement data For each stimulus we defined three                 depending on whether or not the eventually chosen interest
interest areas vertically dividing the image in a left part, a       area was inspected. Fixations directed towards the chosen
central part, and a right part (see Figure 3). The width of the      interest area were longer, lasting 339ms, while fixations to-
central interest area was adjusted such as to cover the central      wards the non-chosen interest area lasted 280ms (t(19)=-5.58,
wall. Fixations were assigned to the different interest areas.       p<.001).
For most of the analyses conducted (unless stated otherwise),
we removed the initial fixations directed towards the central        Time-Course Analyses. The likelihood that observer’s
interest area, because these initial fixations most likely re-       gaze was directed towards the (eventually) chosen part of the
sulted from the requirement to look at the fixation cross be-        stimulus changed over the time course of the trials (see Figure
fore the stimulus was presented.                                     4 left). Approximately 700 msec before participants pressed
                                                                     the button to report their decisions, the likelihood that they
                           Results                                   inspected the chosen part of the image significantly increased
Behavioral Data                                                      above chance level, reaching a maximum of 82.18% around
Response times for the different images ranged between 1793          the time of decision.
ms and 2654 ms (mean: 2277 ms). Participants displayed a
small yet significant tendency to choose the right over the left     Fixation Patterns. Where did participants look when in-
movement option (54.07%: T-test against chance level (50%):          specting the stimuli until drawing their decisions? Figure 5
t(19)=2.28, p=.03) which might be related to the majority            summarizes fixation patterns for the horizontal and vertical
of them being right-handed (80%). An analysis of single              stimulus location separately. Most noticeably the distribu-
participants’ tendencies to produce stereotypical responses          tion of fixation density along the vertical image position was
(i.e. to repeatedly choose left movement option or the right         sharply tuned around the horizontal center line of the images.
                                                                 2288

                                                                     Figure 6: Exemplary fixation densities superimposed on three
                                                                     of the stimuli: Fixations densities (black lines) are plotted as
                                                                     a function of the horizontal position in the image.
Figure 5: Left: Exemplary fixation pattern for one of the stim-
uli in the experiment. Single fixations are depicted as black        dimensional projection in an image?
crosses; right: fixation densities for all stimuli for the hori-
zontal (top) and vertical (bottom) image location. Grey lines        The predictors. In order to derive quantitative measures of
depict fixation densities for the single stimuli (areas under        the geometry of the spatial scenes depicted in the 30 stimuli,
curve sum up to 1); the black lines reflect the average over all     we chose to apply a spatial analysis inspired by isovists. This
30 stimuli.                                                          was done for two reasons, (1) because isovists describe the
                                                                     geometry of space from the perspective of the beholder and
Furthermore, there was very little variance in the fixation po-      (2), because earlier studies already demonstrated that isovist
sitions along the vertical position between stimuli. The distri-     analysis captures psychologically and behaviorally relevant
bution of fixation density along the horizontal image position,      properties of space (Wiener et al., 2007). For each stimulus
in contrast, was rather broad and there were considerable dif-       we extracted a depth profile directly from the image. This
ferences between the different stimuli (see Figure 5). In other      depth profile relates to the distances of the walls from the
words, participants scanned all spatial scenes approximately         camera’s (i.e. from the observer’s) position (see Section Stim-
at the horizon. Differences in fixation patterns between the         uli and Figure 2). Next, this depth profile was downsampled
different scenes were primarily due to differences in the hor-       from 1024 bins (the images were 1024x768 pixel) to 30 bins
izontal dimension. The further analysis will therefore focus         (see Figure 7 A) and normalized such that the area under the
on the horizontal axis.                                              curve summed up to 1.0. The resulting depth profile, describ-
   The averaged fixation density along the horizontal image          ing the local geometry, was used as the first predictor for the
location reveals two maxima, left and right of the vertical cen-     model.
terline of the images. These peaks relate to the two movement           The depth profile was also used to generate the second
options that participants had to inspect and compare in order        predictor, the depth-edge detector. Starting from the verti-
to decide between them. Figure 6 illustrates typical fixation        cal centerline, it progresses both to the left and to the right
densities along the horizontal position for three single stim-       and detects all positions along the depth profile at which its
uli. A qualitative analysis of fixation behavior for these stim-     orientation changed and exceeded 45 degrees. From these po-
uli suggests that participants paid close attention to the parts     sitions only those were taken into account that related to an
of the image in which the lines of sight were particularly long      increase in depth. In other words, starting from the center of
(see left and right example in Figure 6). Furthermore, fix-          the image the depth-edge detector highlights all positions at
ations densities for the middle image in Figure 6, in which          which the length of the line of sight increases sharply. We
the longest lines of sight are equivalent for both choice alter-     then applied a Gaussian kernel to the single edges to obtain
natives, suggests that fixation density was also modulated by        a smoothed depth-edge profile (see Figure 7 B). Again, the
aspects of the local complexity of spatial scene. Note that the      resulting curve was normalized such that the total area under
fixation density for the left choice alternative, in which sev-      curve was 1.0.
eral columns are depicted, is higher than for the right choice          To obtain a model prediction, the two predictors (depth
alternative.                                                         profile and depth-edge detector) were simply added (see Fig-
   Taking these qualitative observations into account we will        ure 7).
now present a tentative model of the control of visual atten-
tion in spatial decision making. The model derives its predic-       Model evaluation. For each of the 30 stimuli we calculated
tion for gaze behavior by analyzing geometrical features of          the prediction of the model and correlated it with the fixation
the depicted scene.                                                  densities for each stimulus obtained in the experiment. The
                                                                     correlations ranged between r=.30 and r=.83. Average cor-
      Towards a minimalistic model of visual
                                                                     relation between, the model’s predictions and the empirical
         attention in spatial decision making                        data was r=.67 (correlation coefficients were Fisher’s Z trans-
Does the three-dimensional form of a spatial situation al-           formed for averaging). The predictive power of the model
low predicting gaze behavior when inspecting its two-                increased when we smoothed the experimental data with a
                                                                 2289

                                                                       Figure 8: Model prediction, experimental data, and experi-
Figure 7: A tentative model of how the geometry of space in-           mental data smoothed by a Gaussian kernel for an exemplary
fluences control of visual attention in spatial decision making.       stimulus.
(A) depth profile of the original stimulus; (B) Depth-edge de-
tector and smoothed depth-edge profile; (C) The model’s pre-
diction and the experimental data. For this particular stimulus        igation studies (e.g., Conroy Dalton, 2003), it remains un-
the correlation between the model’s prediction and the exper-          clear why participants chose the option with the longest line
imental data was r=.74.                                                of sight. A possible explanation is that the movement option
                                                                       with the longest line of sight promises greater information
                                                                       gain when traveling along than the alternative. However, fur-
Gaussian kernel (mean correlation between model predic-                ther research is needed to investigate this behavior.
tions and smoothed experimental data: r=.78; see Figure 8                 The analysis of gaze behavior revealed a number of interst-
for an example).                                                       ing results. First, gaze behavior reflected the spatial decision
   It should be noted at this point, that the model described          making process: approximately 700msec before observers re-
above is of tentative nature for a number of reasons: (1) In           ported their decisions, the likelihood that they inspected the
its current form, the two predictors are not weighted, as if           eventually chosen movement option significantly increased
equally contributing to the control of visual attention. Possi-        above chance level. These results are in line with earlier re-
bly, better fits are obtained if the weights of the two predictors     sults on visual decision tasks in non-spatial domains (e.g.,
were optimized; (2) The fact that smoothing of the experi-             Shimojo et al., 2003; Simion & Shimojo, 2007; Glaholt &
mental data resulted in a noticeable increase of the predictive        Reingold, in press). Moreover, the duration of fixations was
power of the model suggests that we might currently suffer             longer when inspecting the eventually chosen movement op-
from a sparse data problem; (3) In order to extract the pre-           tion than when inspecting the alternative.
dictors, we used depth profiles that were distorted: the depth            Which parts of the scenery did participants attend to while
profiles were extracted from the stimuli directly rather than          deciding between path alternatives? Most noticeably, partic-
from the corresponding floorplans. While it has been shown             ipants’ gaze behavior was narrowly tuned along the vertical
that the visual system can use angular declination below the           axis of the stimuli: irrespective of the specific stimulus in-
horizon for distance judgments (e.g. Ooi et al., 2001), better         spected, viewers focused their fixations around the horizon.
fits may be obtained using non-distorted depth profiles.               This appears to be a sensible viewing strategy in a spatial con-
   Future versions of the model will address the points raised         text, because (1.) information about the geometry of space is
above.                                                                 most dense around the horizon, and (2.) because by scan-
                                                                       ning a scenery along the horizon one makes sure that all be-
                           Discussion                                  haviorally relevant geometrical information is perceived (at
In this study, we investigated gaze behavior in the context            least in architectural spaces as used in this study). This sug-
of navigation and spatial decision making. Participants were           gests that participants were not merely responding to areas
presented with images of choice points displaying two dif-             with high visual complexity, but were actually analyzing the
ferent movement options and were asked to decide between               spatial structure. Fixation densities along the horizontal axis
them in order to search for an object that was hidden in the           systematically differed between stimuli, demonstrating that
environment. We demonstrated that both, participants’ move-            participants directed their attention to specific features in the
ment decisions, as well as their gaze behavior could be pre-           environment.
dicted by certain geometrical features of the spatial scenes de-          To account for these differences in gaze behavior between
picted. With respect to movement decisions, participants re-           different scenes we developed a tentative, minimalistic model
liably chose the option that featured the longest line of sight.       of the control of visual attention during spatial decision mak-
While related strategies have been demonstrated in other nav-          ing. Inspired by isovist analysis, the model extracts a depth
                                                                   2290

profile describing the visible geometry of the scene and cal-         Foulsham, T., & Underwood, G. (2008). What can saliency
culates salient geometrical features from that profile. Specif-          models predict about eye movements? Spatial and sequen-
ically, starting from the center line and progressing to the             tial aspects of fixations during encoding and recognition.
edges, the model detects spatial situations in which the line            Journal of Vision, 8, 1–17.
of sight suddenly increases in length. We refer to this as            Franz, G., & Wiener, J. (2008). From space syntax to
the depth-edge detector. By a simply (unweighted) additive               space semantics: a behaviorally and perceptually oriented
model using the depth profile the depth-edge detector, we ob-            methodology for the efficient description of the geometry
tained quite strong correlations between the model’s predic-             and topology of environments. Environment & Planning
tions and the experimental data (r=.67; this correlation even            B: Planning and Design, 35(4), 574-592.
increased when smoothing the experimental data). In other             Glaholt, M. G., & Reingold, E. M. (in press). The time course
words, by analyzing certain features of the geometry of the              of gaze bias in visual decision tasks. Visual Cognition.
depicted scenes – the depth profile, and local changes in the         Grasso, R., Prevost, P., Ivanenko, Y., & Berthoz, A. (1998).
depth profile – we are able to predict where viewers look                Eye-head coordination for the steering of locomotion in hu-
when deciding which of two movement options to select.                   mans: an anticipatory synergy. Neuroscience Letters, 253,
                                                                         115–118.
                          Conclusion                                  Henderson, J. (2003). Human gaze control during real-world
Taken together, results from this study provide evidence that            scene perception. Trends in Cognitive Sciences, 7(11),
participants did interpret the presented stimuli as three dimen-         498–504.
sional scenes rather than as flat pictures. While this appears        Hollands, M. A., Patla, A. E., & Vickers, J. N. (2002, Mar).
trivial at first glance, it strongly suggests that the geometry          ”Look where you’re going!”: gaze behaviour associated
of scenes is a relevant factor contributing to the control of vi-        with maintaining and changing the direction of locomotion.
sual attention when inspecting corresponding images (at least            Experimental Brain Research, 143, 221–230.
when faced with spatial tasks such as navigation or wayfind-          Itti, L., & Koch, C. (2000). A saliency-based search mecha-
ing). Earlier bottom up approaches such as the widely used               nism for overt and covert shifts of visual attention. Vision
saliency maps (e.g., Itti & Koch, 2001) as well as recent                Res., 40, 1489–1506.
models combining bottom-up saliency, scene context, and top           Itti, L., & Koch, C. (2001, Mar). Computational modelling
down influences (Torralba, Oliva, Castelhano, & Henderson,               of visual attention. Nature Reviews Neuroscience, 2, 194–
2006), do not explicitly analyze the spatial structure of the            203.
inspected scenes but concentrate on features in the two di-           Montello, D. R. (2001). Spatial cognition. In Interna-
mensional projection of the scene. Here we presented a novel             tional encyclopedia of the social & behavioral sciences (p.
bottom-up model that could contribute to a more comprehen-               14771-14775). Oxford: Pergamon Press.
sive understanding of the control of visual attention. The            Ooi, T., Wu, B., & He, Z. (2001, Nov). Distance determined
model specifically analyzes the spatial structure of the scene           by the angular declination below the horizon. Nature, 414,
presented and highlights situations in which the line of sight           197–200.
or the depth profile, respectively, suddenly changes. Appar-          Shimojo, S., Simion, C., Shimojo, E., & Scheier, C. (2003,
ently these spatial features attract visual attention when visu-         Dec). Gaze bias both reflects and influences preference.
ally exploring unfamiliar environments.                                  Nature Neuroscience, 6, 1317–1322.
   Overall, the results suggest that the integrated analysis of       Simion, C., & Shimojo, S. (2007). Interrupting the cascade:
navigation behavior and gaze behavior can play a key role in             Orienting contributes to decision making even in the ab-
the investigation of the information processing mechanisms               sence of visual stimulation. Perception & Psychophysics,
and the cognitive strategies underlying human wayfinding be-             69(4), 591-595.
havior.                                                               Torralba, A., Oliva, A., Castelhano, M. S., & Henderson,
                                                                         J. M. (2006, Oct). Contextual guidance of eye movements
                     Acknowledgments                                     and attention in real-world scenes: the role of global fea-
                                                                         tures in object search. Psychological Review, 113, 766–
This work was supported by the Volkswagen Foundation                     786.
and the SFB/TR8 ’Spatial Cognition’. Special thanks to J.             Wiener, J., Franz, G., Rossmanith, N., Reichelt, A., Mallot,
Wendler, J. Henschel, and A. Günther for their help in carry-           H., & Bülthoff, H. (2007). Isovist analysis captures proper-
ing out the experiment and analyzing the data.                           ties of space relevant for locomotion and experience. Per-
                                                                         ception, 36(7), 1066–1083.
                           References                                 Wilkie, R., & Wann, J. (2003). Eye-movements aid the con-
Benedikt, M. L. (1979). To take hold of space: Isovists and              trol of locomotion. Journal of Vision, 3, 677–684.
   isovist fields. Environment and Planning B, 6, 47-65.              Yarbus, A. (1967). Eye movements and vision. New York:
Conroy Dalton, R. (2003). The secret is to follow your nose:             Plenum.
   Route path selection and angularity. Environment & Be-
   havior, 35(1), 107–131.
                                                                  2291

