UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The effect of distributional information on feature learning
Permalink
https://escholarship.org/uc/item/9fq3k14t
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Austerweil, Joseph
Griffiths, Thomas
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

                      The effect of distributional information on feature learning
                                      Joseph L. Austerweil (Joseph.Austerweil@gmail.com)
                                        Thomas L. Griffiths (Tom Griffiths@berkeley.edu)
                   Department of Psychology, University of California, Berkeley, Berkeley, CA 94720-1650 USA
                               Abstract                                   over objects and demonstrate in a behavioral experiment that
                                                                          people infer features according to distributional cues as our
   A fundamental problem solved by the human mind is the for-
   mation of basic units to represent observed objects that support       model predicts.
   future decisions. We present an ideal observer model that in-             A large body of previous research has demonstrated the
   fers features to represent the raw sensory data of a given set of      powerful effect of statistical cues on human learning (Saffran,
   objects. Based on our rational analysis of feature representa-
   tion, we predict that the distribution of the parts that compose       Aslin, & Newport, 1996; Aslin, Saffran, & Newport, 1998).
   objects should affect the features people use to infer objects.        Artificial language research has shown that human language
   We confirm this prediction in a behavioral experiment, sug-            learning faculties use the pattern of statistics of speech primi-
   gesting that distributional information is one of the factors that
   determines how people identify the features of objects.                tives to segment a continuous speech stream into words (Saf-
   Keywords: representational change, features, rational analy-
                                                                          fran et al., 1996; Aslin et al., 1998). We complement these
   sis, Bayesian modeling                                                 results by performing a rational analysis of feature represen-
                                                                          tation inference and demonstrating that people use statistical
                           Introduction                                   cues to infer feature representations for novel objects.
                                                                             Our model is a nonparametric Bayesian model that allows
   I stand at the window and see a house, trees, sky. The-
                                                                          for an unbounded amount of features to be expressed in the
   oretically I might say there were 327 brightnesses and
                                                                          observed data. The model creates features to reproduce the
   nuances of colour... And yet even though such droll cal-
                                                                          objects it observes, but is penalized for each feature it pro-
   culation were possible and implied, say, for the house
                                                                          duces. Thus, the model can infer the number of features nec-
   120, the trees 90, the sky 117 – I should at least have
                                                                          essary to represent the objects it observes. To the best of our
   this arrangement and division of the total, and not, say,
                                                                          knowledge, it is the only model of feature inference that infers
   127 and 100 and 100; or 150 and 117.
                                                                          the number of features from raw sensory data. Additionally, it
                                       Wertheimer (1938, p. 71)           has been shown to use distributional and categorization cues
   A fundamental problem faced by any learner is the for-                 as people do (Austerweil & Griffiths, 2009).
mation of the basic units that represent observed stimuli and                This model makes a prediction based on how distributional
support generalizations from a set of primitives. Wertheimer              information should affect the features people infer, which we
(1938) describes a visual form of the problem: how does the               now test in a behavioral experiment. If the parts that com-
perceptual system form larger representations of observed ob-             prise objects vary independently over objects, then an ob-
jects from the information given by varying primitive units?              server should infer the parts as features. On the other hand,
Although the investigation of Gestalt principles has led to a             if the parts that compose objects covary over objects, an ob-
fruitful body of research, there currently does not exist a for-          server should infer the objects themselves as features.
mal computational account of why people form representa-                     The plan of the paper is as follows. In the first section we
tions for novel objects. In this paper, we present a formal               discuss previous empirical and computational work on human
model of how feature representations should be inferred from              feature inference. Next, we present our ideal observer model
a set of observed objects and demonstrate that people use sta-            and its predictions based on distributional cues. Third, we
tistical cues to infer the same features to represent novel ob-           demonstrate people use the distributional cue as our model
jects that our ideal observer model would infer.                          predicts in a behavioral experiment. Finally, we discuss the
   There are many factors that influence the features people              implications of our work for the nature of human concepts
infer to represent objects, like the changes of concavity of its          and future directions for research.
contour (Hoffman & Richards, 1985), the usefulness for ex-
plaining categorization of objects (Schyns & Murphy, 1994;                                     Inferring features
Pevtzow & Goldstone, 1994), background knowledge of the                   Perceptual and conceptual cognitive psychologists have been
function of objects (Lin & Murphy, 1997), and prior knowl-                investigating the features people use to represent the world
edge of what types of features have been useful in the past               and both have been interested in how the features are created
(e.g., Gestalt principles, Palmer, 1977). However, we will fo-            and change, for reviews of results from both fields see Gold-
cus on one particular factor: the distribution of features over           stone (2003) and Schyns, Goldstone, and Thibaut (1998). To
objects. Intuitively, a feature representation is useful if know-         distinguish between the parts that exist in the objects and the
ing an unknown object has a feature gives you information as              features people use to represent observed objects, we will use
to which object it is. We propose an ideal observer model of              “part” or “primitive” to refer to the aspect of the object and
feature inference that is sensitive to the distribution of parts          “feature” to refer to the representation of that object.
                                                                      2765

                                                                    ically motivated. Two factors that are important for any psy-
                                                                    chologically plausible model of feature learning are (a) the
                                                                    number of features should not be specified a priori and (b) the
                                                                    features should be inferred from raw sensory data. Previous
                                                                    work by Ghahramani (1995) and Goldstone (2003) described
           x1           x2          x3            x4                models that infer feature representations from raw pixel val-
                                                                    ues; however, both models require the number of features to
                                                                    be specified ahead of time. This is a serious issue because
                                                                    finding the appropriate number of features to use is a difficult
               x1     1    1    1     0    0    0                   part of the problem of inferring features. For example, it is
               x2     0    1    0     1    0    1                   clear what the best feature representations are of sizes four
               x3     0    0    1     1    1    0                   and six for the objects in Shiffrin and Lightfoot (1997), but
               x4     1    0    0     0    1    1                   which of these two representations is more appropriate? Peo-
                                                                    ple are not given this information and thus a model of feature
                                                                    inference should not receive it either.
Figure 1: The four objects used in Shiffrin and Lightfoot
                                                                       More recently, Orban, Fiser, Aslin, and Lengyel (2008) de-
(1997) and their feature ownership matrix.
                                                                    fined a Bayesian learning model of visual chunks that can
                                                                    be interpreted as a model of feature representation inference.
                                                                    By training participants on scenes where novel objects occur
Empirical Studies                                                   in groups, they showed people infer representations that cap-
Previous research has demonstrated two major influences of          ture correlations between the groups as their model predicts.
human perceptual feature learning: categorization and dis-          Although their model does infer the dimensionality of its rep-
tributional information. In general, people infer features to       resentations, it is given each scene pre-processed as a binary
represent objects that are useful for categorizing (the func-       string of whether or not objects occur. It does not infer its
tionality principle of Schyns & Murphy, 1994). For example,         features from raw sensory input.
Pevtzow and Goldstone (1994) demonstrated that participants
inferred the diagnostic features useful to categorize each ob-       A Rational Analysis of Feature Representation
ject into its appropriate category. They trained two groups         We will outline, following Austerweil and Griffiths (2009), a
of participants to repeatedly categorize the same four objects      rational analysis of inferring features from raw sensory data
into different category schemes (objects A and B in one cate-       without pre-specifying a specific number of features. First,
gory vs. A and C in one category). Participants who learned         we formalize the problem as finding the best feature repre-
to categorize A and B together inferred the shared part of A        sentation Z for a set of observed objects X. We define Z to
and B as a feature and those who learned to categorize A and        be a feature ownership matrix, where Zik = 1 indicates that
C together inferred the shared part of A and C as a feature.        object i possesses feature k (as in the matrix in the bottom of
   In addition to categorization cues, Shiffrin and Lightfoot       Figure 1. The problem of inferring Z from X can be solved by
(1997) showed that the distribution of parts over objects can       applying Bayes’ rule, with the posterior probability P(Z|X)
affect the feature representation participants infer. In their      being given by
visual search experiment, participants searched for one of the
                                                                                                              P(X|Z)P(Z)
objects shown in the top of Figure 1 in a scene where the other           Ẑ = arg max P(Z|X) = arg max                           (1)
three objects were distractors. The objects were designed so
                                                                                     Z                  Z   ∑Z ′ P(X|Z ′ )P(Z ′ )
that each object shares one line segment with every other ob-       where P(Z) is the prior probability of the feature matrix, and
ject (and thus, two line segments must be known to discrimi-        P(X|Z), the likelihood, indicates the probability of the ob-
nate between objects). At first, participants do not experience     served data given these features. This splits the problem into
“popout,” meaning that response time in a visual search is          two subproblems: finding a representation that conforms to
nearly independent of the number of distractors. Popout typ-        our prior assumptions, P(Z), and finding one that can repro-
ically only occurs when the target and distractor differ in a       duce the observed objects with high probability, P(X|Z).
single feature. Thus, the objects must differ by more than             As a prior on feature ownership matrices, we chose a non-
one feature in the participants’ representations (most likely       parametric Bayesian prior, the Indian Buffet Process (IBP)
a conjunction of line segments). However, after about 20            (Griffiths & Ghahramani, 2006). The IBP can be interpreted
days of training, participants in the experiment experience         to be a probability distribution over feature ownership matri-
popout. Therefore their feature representation of the objects       ces with varying numbers of features. The probability of a
must have changed to be the objects themselves.                     particular feature ownership matrix under the IBP is:
Computational Models                                                                αK                    K
                                                                                                             (N − mk )!(mk − 1)!
                                                                       P(Z) =      N         exp{−αHN } ∏
 Schyns et al. (1998) identified the need for computational                     ∏2h=1−1 Kh !             k=1          N!
accounts that infer feature representations and are psycholog-                                                                    (2)
                                                                2766

where N is the number of objects, Kh is the number of fea-
tures with history h (the history is the column of the feature
interpreted as a binary number), K is the number of features,
HN is the N-th harmonic number, and mk is the number of
objects that have feature k. One sensible prior assumption is
that we should favor feature representations with a smaller
number of features. By choosing α such that Nα < 1, the IBP
captures this intuition because the Nα term decreases when
                                        K
the number of features of the representation, K, grows.              Figure 2: The six primitives used to create objects. The bias,
   In addition to the prior probability on feature represen-         which was in all objects, is shown in gray for reference, and
tations, we present two probability distributions to use for         the primitives are in black. Any combination of three features
recreating the observed objects X given a feature ownership          forms a connected object when combined with the bias.
matrix Z depending on the representation of the raw pixels. If
the raw pixels are real valued, then a linear-Gaussian model
(Griffiths & Ghahramani, 2006) can be used and if the raw            three levels: test type, indicating whether the test objects were
pixels are binary, then a noisy-OR model (Wood & Griffiths,          previously seen, previously unseen, or made of shuffled parts.
2006) can be used. Using the noisy-OR model, Austerweil
and Griffiths (2009) demonstrated that the model uses distri-        Methods
butional and categorization information to infer representa-         Participants A total of 56 undergraduates from the Uni-
tions as people do in both Pevtzow and Goldstone (1994) and          versity of California, Berkeley participated in exchange for
Shiffrin and Lightfoot (1997).                                       course credit. There were 28 participants in each of the cor-
   One prediction the model makes is that when the parts             related and independent conditions with training set and test
weakly covary over objects (like those in Shiffrin & Light-          order counterbalanced.
foot, 1997), objects should be inferred as features, but when        Stimuli Figure 2 shows the images of the primitives and
the parts occur independently over objects, the parts should be      bias used to create the objects shown to participants. The ob-
inferred as features. It has not been shown yet that people use      jects were created by combining three primitives with the bias
distributional information as the latter prediction suggests.        and were binary images. The primitives were designed such
Additionally, the rational analysis predicts people should in-       that any combination of three with the bias was connected,
fer objects as features even after observing the set of objects      and so that people would have minimal prior knowledge (e.g.,
only a small number of times. To test the predictions of our         from Gestalt principles).
model, Experiment 1 investigates how people infer feature               There were two distribution types: correlated, where
representations after observing sixteen novel objects whose          primitives covary imperfectly over objects, and independent,
parts either weakly covary or are independent.                       where primitives were combined independently over objects.
                                                                     There were twenty possible objects, corresponding to all pos-
  Testing the predictions: Martian Inscriptions                      sible ways of choosing three features from a set of six. The
                                                                     correlated sets of objects were created to have the same cor-
The goal of the experiment was to test the prediction of our ra-     relation over primitives as Shiffrin and Lightfoot (1997) (see
tional analysis: when primitives are correlated over observed        Figure 1). Two correlated sets were created using disjoint
objects, people infer the objects as features, and when primi-       combinations of primitives, so that different objects appeared
tives are independent over observed objects, people infer the        in each set. Each set consisted of four copies of four objects
primitives as features. To investigate this prediction, we show      each with its own random added noise. The independent sets
participants a group of objects and look at how willing they         consisted of sixteen of the twenty possible objects. Again,
are to call a new object that is a combination of three prim-        two independent sets were created, with the four objects miss-
itives a member of the previous group. According to our              ing from each set corresponding to the four objects contained
model, participants in the independent group should gener-           in one of the correlated sets. This method of generating stim-
alize to this new object (as they should infer the primitives),      uli guaranteed that each correlated set had a corresponding
but participants in the correlated group should not (as they         independent set in which each primitive appeared with the
should infer the objects they observe as features and these          same frequency, allowing us to control for familiarity. Fi-
cannot be combined to form the new object).                          nally, noise was added to all of the images by flipping each
                                                                                                           1
   There were three between-subjects factors each with two           pixel in the image with probability 75  .
levels: distribution type (correlated or independent), training         Each participant was shown a training set – correlated or
set (1 or 2, which represents which of the primitives were           independent – with the specific set of objects depending on
correlated), and test order (1 or 2, which represents which of       which training set condition they were in. Figure 3 shows
the two random orderings of the test stimuli were shown to           the images in one independent and one correlated condition.
participants). There was also one within-subjects factor with        Participants viewed their training set by exploring the objects
                                                                 2767

       (a)                                                             (a)                                   (b)
                                                                                          (c)
       (b)
                                                                       Figure 4: The three sets of test images. (a) seen for training
                                                                       set 1 (shown in Figure 3) and unseen for training set 2. (b)
                                                                       unseen for training set 1 (shown in Figure 3) and seen for
                                                                       training set 2. (c) shuffled parts for all conditions.
                                                                       Procedure Participants were given the sixteen images on
                                                                       business cards randomly shuffled in front of them appropriate
                                                                       to their conditions and given the following cover story:
Figure 3: One of the correlated and one of the independent             Recently a Mars rover found a cave with a collection of different
training sets given to the participants. (a) One of the two cor-       images on its walls. A team of scientists believe the images could
related training sets. (b) One of the two independent training         have been left by an alien civilization. The scientists are hoping to
sets. These two sets share four objects.                               understand the images so they can find out about the civilization.
                                                                       They were asked to alert the experimenter after “investigat-
                                                                       ing the images” by “laying all the cards out on the table and
printed on cards, as described in more detail below. The same          organizing them in any way you think might help you learn
test set was given to all participants in one of two random or-        about the images” and told that “no longer than 5-10 minutes
ders. There were twelve objects in the test set, as shown in           is necessary.” After they finished investigating the images,
Figure 4. The twelve objects fell into three test types: four          they were given the following test instructions:
objects seen by the participant already (seen), four objects the       It looks like there are many more images on the cave wall that the
participant had not seen already that were composed of the             rover has not yet had a chance to record. If the rover explored the
same primitives (unseen), and four objects created by com-             cave wall further, which images do you think it would be likely to
                                                                       see?
bining primitives inconsistent with the statistical information
                                                                       Your task is to rate how likely you believe it is that the rover sees
from both training sets (shuffled parts). As a consequence             each image as it explores further through the cave.
of the way the stimuli were constructed, the seen and unseen
test objects corresponded to one of the two correlated sets –          In the booklet in front of you are twelve images, each on its own
which objects participants had seen or not was determined by           page. After you are finished rating each image, turn the page to the
the training set condition. This allowed us to control for the         next image. Once you have turned to the next image, please DO
possibility that one set of objects was naturally more appeal-         NOT TURN BACK to any previous images.
ing than the other. The shuffled parts tests were created by           To minimize memory effects, the images from the training set
first taking the image formed by joining all six parts and seg-        were not taken away from the participants. Each image was
menting it into six different parts. The shuffled parts images         shown on a single page and participants were asked to gener-
used in the tests were four objects formed by a combination            alize to the test set (“rate from 0-10 how likely you believe the
of three of the six shuffled parts. This was done so that the          rover is to see this image on another part of the cave wall”).
four shuffled images would have the same gross properties as
the other test images.                                                 Results
   The stimuli and test sets were carefully constructed to en-         Figure 5 shows mean responses and model predictions. Par-
sure that: (1) the variance at each pixel was equal for all train-     ticipant responses were grouped into the three test types
ing sets, (2) the features that were used in constructing the          (seen, unseen, and shuffled parts) and then averaged. Model
correlated set were counterbalanced, and (3) the average sim-          predictions were calculated from the probability of the new
ilarity (in terms of pixel overlap) between any training set and       images given the images from either the independent or cor-
any test set was equal.                                                related conditions, and averaged in the same way. The model
                                                                   2768

                     Human Generalization Likelihood for Test Images          pants in the correlated condition were more likely to gener-
               10
                                                          Seen in set         alize to the seen images than those in the independent con-
  Likelihood
               8                                          Unseen in set       dition (t(54) = 2.97, p < 0.005). Participants in both train-
               6                                          Shuffled parts
                                                                              ing conditions are more likely to generalize to the seen im-
               4                                                              ages than the shuffled parts images (t(54) = 10.07, p < 0.001
               2
                                                                              and t(54) = 4.63, p < 0.001 respectively). There was no dif-
                                                                              ference between participiants in training conditions on the
               0                                                              shuffled parts images (t(54) = −0.12, p > 0.05). Finally,
                     Factorial Cards            Correlated Cards
                                   Training Condition                         participants in both the correlated and independent condi-
             0.8            Model Predictions for Test Images                 tions are more likely to generalize to the unseen images
                                                          Seen in set         than the shuffled parts images (t(54) = 2.89, p < 0.01 and
Likelihood
             0.6                                          Unseen in set       t(54) = 5.31, p < 0.001, respectively).
                                                          Shuffled parts
             0.4                                                              Discussion
             0.2                                                              The main results of our experiment confirm the predictions
                                                                              of our model: participants in the independent condition do
               0                                                              not differentiate between the seen and unseen images; how-
                    Factorial Images           Correlated Images
                                Image Set Given to Model                      ever, participants in the correlated condition do. Addition-
                                                                              ally, participants in the independent condition are more likely
   Figure 5: Experiment results. The upper panel shows mean                   to generalize to the unseen objects than those in the corre-
   ratings participants for test items as a function of training con-         lated condition. Since participants in the correlated condition
   dition. Error bars show one standard error. On bottom, model               should expect fewer objects under the feature representation
   predictions for the same test images given images from either              predicted by our model (just the four objects they observed),
   the independent or correlated conditions.                                  it is sensible that they rate the seen objects higher than the in-
                                                                              dependent group. Finally, both groups rate the shuffled parts
                                                                              images lower than the seen and unseen images.
   predictions were computed by approximating the full poste-                     Participants in the independent group generalized to the un-
   rior predictive distribution with the probability of the new               seen objects, while those in the correlated group did not. Nei-
   images using the most likely features as determined by a                   ther group generalized to the shuffled parts objects and there
   Markov chain Monte Carlo simulation (see Austerweil &                      is no significant difference between the groups on the shuf-
   Griffiths, 2009 for details). Since there was a large difference           fled parts. Our results cannot be explained by participants
   in the probabilities of different types of test images, we use a           in the independent group just expecting more variance in test
   monotonic but non-linear transformation to produce the val-                objects than those in the correlated group. First, as noted
   ues shown in the plot, raising the probabilities to the power              above, the variance at each pixel was equal across training
   of 0.0005 and renormalizing. Qualitatively, the model and                  sets. Second, if participants in the independent group simply
   people show the same pattern of responses on all test items.               expect more variance, this should predict that they would be
      A four-way ANOVA revealed a main effect of test type                    more willing to generalize to the shuffled parts as well as the
   (F(2, 52) = 61.01, p < 0.001), an interaction between test                 unseen objects, which was not the case. The pattern of judg-
   type and distribution type (F(2, 52) = 10.57, p < 0.001), and              ments on the different test items made by participants in the
   no other significant main effects or two-way interactions (all             two groups also cannot be explained by a simple categoriza-
   F < 1). There was a three-way interaction of test type, test or-           tion model with the pixels as features because it would not
   der, and distribution type (F(2, 52) = 19.11, p < 0.05). How-              distinguish between the types of test items due to the way the
   ever, the effect is irrelevant to the question of whether people           training and test sets were constructed: the similarity (in pixel
   use distributional information as it is caused by participants             overlap) was equal between all training and test sets. Thus,
   in the first test order, independent condition rating the seen             our results suggest that participants infer features appropri-
   images higher than those in the second test order, indepen-                ate to the distributional cues between parts in the objects they
   dent condition. Since there were no major effects of training              observe.
   set or test order, we collapsed over these conditions in the                   One might argue that participants in the correlated condi-
   subsequent pre-planned analyses.                                           tion still differentiate between the unseen and shuffled parts
      Confirming our hypothesis, participants in the independent              images and that this in some way invalidates the predictions
   condition are more likely to generalize to the unseen im-                  of the model; however, most of the images in the shuffled
   ages than those in the correlated condition (t(54) = 3.05, p <             parts set are poorly formed according to Gestalt principles
   0.005). There was no difference between the seen and unseen                and our model does not take into account these effects. In a
   image ratings for the participants in the independent condi-               follow-up experiment, we are creating a new shuffled parts set
   tion (t(54) = 0.27, p > 0.05); however, there was for those in             that does not violate our prior notions of what a good object
   the correlated condition (t(54) = 8.74, p < 0.001). Partici-               looks like. Additionally, one might argue that these results are
                                                                           2769

due to some aspect of the particular primitives we correlated            Austerweil, J. L., & Griffiths, T. L. (2009). Analyzing
together (e.g., they form some pre-existing salient object), but           human feature learning as nonparametric Bayesian infer-
since there was no effect of training set, we demonstrate this             ence. In D. Koller, Y. Bengio, D. Schuurmans, & L. Bottou
was not the case. Since participants in both the correlated                (Eds.), Advances in Neural Information Processing Sys-
and independent conditions observe the parts the same num-                 tems (Vol. 21). Cambridge, MA: MIT Press.
ber of times throughout the object set, they must be sensitive           Ghahramani, Z. (1995). Factorial learning and the EM al-
to the covariation of parts in objects and not just the overall            gorithm. In Advances in Neural Information Processing
occurrence of the parts themselves.                                        Systems (Vol. 7, p. 617-624). Cambridge, MA: MIT Press.
                                                                         Goldstone, R. L. (2003). Learning to perceive while perceiv-
         General Discussion and Conclusions                                ing to learn. In Perceptual Organization in Vision: Behav-
We have demonstrated that the statistics of how parts vary                 ioral and Neural Perspectives (p. 233-278). Mahwah, NJ:
over objects affects the features inferred by participants.                Lawerence Erlbaum Associates.
Based on our ideal observer model, we predicted participants             Griffiths, T. L., & Ghahramani, Z. (2006). Infinite latent fea-
should infer the parts of novel objects as features when they              ture models and the Indian buffet process. In B. Schölkopf,
occur independently over objects and the objects themselves                J. Platt, & T. Hofmann (Eds.), Advances in Neural Informa-
as features when they covary. Participants who observe a set               tion Processing Systems (Vol. 18). Cambridge, MA: MIT
of only 16 objects whose parts covary do not believe an un-                Press.
seen valid combination of parts is a member of the original              Hoffman, D. D., & Richards, W. A. (1985). Parts in recogni-
set; however, those observe a set of 16 objects whose parts                tion. Cognition, 18, 65-96.
occur independently do believe the same unseen valid com-                Lin, E. L., & Murphy, G. L. (1997). Effects of back-
bination of parts is a member of the original set. Thus, peo-              ground knowledge on object categorization and part detec-
ple use statistical cues to infer features that represent objects,         tion. Journal of Experimental Psychology: Human Percep-
which influence later decisions about the objects.                         tion and Performance, 23(4), 1153-1169.
   Is this effect something unique to visual perception, or does         Orban, G., Fiser, J., Aslin, R. N., & Lengyel, M. (2008).
it reflect a general cognitive ability to appropriately extract            Bayesian learning of visual chunks by human observers.
parts or wholes of objects as features? The previous work                  Proceedings of the National Academy of Sciences, 105(7),
demonstrating the importance of statistical cues for inferring             2745-2750.
words and actions suggests it is a general cognitive capacity.           Palmer, S. E. (1977). Hierarchical structure in perceptual
To test this, we hope to run a follow-up experiment using the              representation. Cognitive Psychology, 9, 441-474.
same paradigm in a conceptual domain.                                    Pevtzow, R., & Goldstone, R. L. (1994). Categorization and
   Our analysis provides a principled computational frame-                 the parsing of objects. In Proceedings of the Sixteenth An-
work to investigate this problem, identifies key factors influ-            nual Conference of the Cognitive Science Society (p. 712-
encing the learning of feature representations, demonstrates               722). Hillsdale, NJ: Lawrence Erlbaum Associates.
people use these factors in the same way as an ideal observer,           Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996). Statis-
and predicted a new empirical result in how people infer fea-              tical learning by 8-month old infants. Science, 274, 1926-
ture representations. In addition to furthering our knowledge              1928.
of human feature learning, our results are important to ma-              Schyns, P. G., Goldstone, R. L., & Thibaut, J. (1998). De-
chine learning because the problem of representing the world               velopment of features in object concepts. Behavioral and
in a useful way is shared between machine learning and cog-                Brain Sciences, 21, 1-54.
nitive psychology. Finally, our results are first steps towards          Schyns, P. G., & Murphy, G. (1994). The ontogeny of part
a larger goal. We hope to extend our computational model to                representation in object concepts. In The Psychology of
capture the effects of categorization, causality, relations, and           Learning and Motivation (Vol. 31, p. 305-354). San Diego:
prior knowledge and how people infer features.                             Academic Press.
                                                                         Shiffrin, R. M., & Lightfoot, N. (1997). Perceptual learn-
Acknowledgments. We thank Rob Goldstone, Stephen Palmer,                   ing of alphanumeric-like characters. In The Psychology of
Karen Schloss, Tania Lombrozo, Charles Kemp, Noah Goodman,                 Learning and Motivation (Vol. 36, p. 45-82). San Diego:
and Eleanor Rosch for insightful discussions, Amy Perfors and three        Academic Press.
anonymous reviewers for comments, and Brian Tang and David               Wertheimer, M. (1938). Laws of organization in perceptual
Belford for help with experiment construction, running participants,       forms. In W. Ellis (Ed.), A source book of Gestalt psychol-
and data analysis. This work was supported by grant FA9550-07-1-           ogy (p. 71-88). London: Routledge and Kegan Paul.
0351 from the Air Force Office of Scientific Research.                   Wood, F., & Griffiths, T. L. (2006). Particle filtering for non-
                                                                           parametric Bayesian matrix factorization. In B. Schölkopf,
                          References                                       J. Platt, & T. Hofmann (Eds.), Advances in Neural Informa-
Aslin, R. N., Saffran, J. R., & Newport, E. L. (1998). Compu-              tion Processing Systems (Vol. 18). Cambridge, MA: MIT
   tation of conditional probability statistics by 8-month-old             Press.
   infants. Psychological Science, 9, 321-324.
                                                                     2770

