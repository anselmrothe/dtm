UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Cause and Intent: Social Reasoning in Causal Learning
Permalink
https://escholarship.org/uc/item/1vv3v9d0
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Baker, Chris
Goodman, Noah
Tenenbaum, Joshua
Publication Date
2009-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                        Cause and Intent: Social Reasoning in Causal Learning
                                   Noah D. Goodman, Chris L. Baker, Joshua B. Tenenbaum
                                                        {ndg, clbaker, jbt}@mit.edu
                                                MIT, Dept. of Brain and Cognitive Sciences
                               Abstract                                  the structure of the world as background knowledge avail-
                                                                         able to all agents. We combine these modeling approaches by
   The acquisition of causal knowledge is a primary goal of child-
   hood; yet most of this knowledge is known already to adults.          constructing a model of intuitive psychology in which beliefs
   We argue that causal learning which leverages social reason-          about the causal structure of the world are represented and
   ing is a rapid and important route to knowledge. We present           used for action selection, and showing how such an intuitive
   a computational model integrating knowledge about causality
   with knowledge about intentional agency, but using a domain-          theory of causal-agency can explain the source of interven-
   general mechanism for reasoning. Inference in this model pre-         tions and speed causal learning.
   dicts qualitatively different learning than an equivalent model          We test this model experimentally by studying adult intu-
   based on causality alone or a hybrid causal-encoding model.
   We test these predictions experimentally with adult partici-          itions in a set of scenarios that provide both social and causal
   pants, and discuss the relation of these results to the devel-        information. These scenarios are chosen to distinguish be-
   opmental phenomenon of over-imitation.                                tween the combined social-causal model and two alternatives:
   Keywords: Causal learning, social cognition, Bayesian mod-            a similar causal-only model, and a hybrid gated-inference
   eling, imitation.                                                     model. We then use these results to explain a puzzling phe-
                                                                         nomenon of imitation-based learning in children.
                           Introduction
How do children acquire conceptual knowledge? One answer                                  Computational modeling
is that children are adept at rational inference from direct             Our goal is to construct a formal model which simultaneously
experience with the world—children as scientists (Gopnik,                represents knowledge about causality and knowledge about
Meltzoff, & Kuhl, 1999). Human culture suggests another an-              intentional agency, and to explore how Bayesian inference
swer: the quickest route to conceptual knowledge may be by               over the combination differs from inference over each piece
learning what others already know (Tomasello, 1999; Gergely              in isolation. Knowledge can be represented as probabilis-
& Csibra, 2006). Indeed, a vast majority of the knowledge                tic generative models; Bayesian inference then “inverts” this
that a child will acquire is already known by adults in their            generative knowledge, specifying appropriate beliefs about
society. This suggests that children come equipped with so-              latent states given observed evidence. We begin by recalling
cial learning mechanisms to encode the knowledge of adults               standard generative models capturing (aspects of) causality
(Lyons, Young, & Keil, 2007). We suggest a middle ground                 and intentional agency, then describe how they may be inte-
between these two views: that an understanding of intentional            grated, and finally describe predictions of the resulting model.
agency makes it possible to use social context as a source of
                                                                         Causality A causal Bayes net (CBN) model describes the
evidence to enable rapid learning without requiring dedicated
                                                                         probability P(E|A, S) of observing a set of events E, given
psychological mechanisms.
                                                                         the causal structure S, and the interventions, or exogenous
   Among the most profound achievements of human knowl-
                                                                         actions, A (Fig. 1a). More formally, a CBN consists of a di-
edge is an understanding of causal structure in the world; not
                                                                         rected acyclic graph on a set of variables, together with a
coincidentally, causality has been a major area of research
                                                                         specification of the probabilistic dependence of each variable
into children’s ability to learn from evidence (Gopnik et al.,
                                                                         on its parents in the graph. The variables represent events
2004). In this paper we therefore focus on the acquisition
                                                                         or states, and the edges represent the fact of a causal depen-
of causal knowledge in a social, but non-linguistic, setting.
                                                                         dence. For some variables there is an intervention: an ex-
To explore the hypothesis that social learning emerges from
                                                                         ogenous event that forces the variable to a particular value,
the interaction, under domain-general inference processes,
                                                                         irrespective of the values of its parents. We will assume that
of existing conceptual structures, we construct a computa-
                                                                         the dependencies between variables are described by noisy-
tional model integrating social and causal representations.
                                                                         or functions (each parent is a sufficient cause) or noisy-and
Recent modeling of human causal reasoning has focused on
                                                                         functions (parents are jointly sufficient and individually nec-
the causal Bayes nets approach (Pearl, 2000; Gopnik et al.,
                                                                         essary); the causal strength of these dependencies, ε, is a fixed
2004). This view helps explain how causal learning can suc-
                                                                         parameter. (See Pearl (2000) for more about the formalism
ceed based on observed co-occurance between events and
                                                                         and uses of causal Bayes nets.)
well-chosen interventions. The interventions, however, are
treated as unexplained actions on a system. In contrast, recent          Agency Bayesian decision theory (Berger, 1985) describes
models of intuitive psychology have focused on the selec-                the choices made by a rational agent facing a stochastic de-
tion of actions by agents given their goals and beliefs (Baker,          cision problem (SDP) (Fig. 1b). A SDP consists of a set of
Tenenbaum, & Saxe, 2007; Goodman et al., 2006), but treated              possible actions the agent may take, a utility function U(E),
                                                                   2759

                                                                                                                          Desired
                                                                                         Causal          Belief about
                                                                                                    =                     outcome
                                                                                        structure     causal structure
                                                                                                                       (events, costs)
               Causal Bayes net:                 Stochastic decision process:
                  Causal
                              Actions                Beliefs       Desires                                   Actions
                 structure
                       Events                            Actions                                  Events
             (a)                               (b)                                  (c)
Figure 1: Schematic representations of generative models for causality (a), intentional agency (b), and the social-causal combination (c).
Equality between the true causal structure and an agent’s belief about causal structure embodies the knowledgeable agent assumption.
capturing the agent’s desires (reward for each possible out-               represents a combined model in which the interventions of
come E), and a belief function PB (E|A), capturing the agent’s             the CBN have been identified with the actions of the SDP.
beliefs about how the world works (the likely outcomes of an                  We will simplify by making the knowledgeable agent as-
action A). Bayesian decision theory specifies that the agent               sumption: the beliefs of the observed agent about the causal
should choose an action to maximize her expected utility:                  structure of the world reflect the true (but unknown to the
EPB (E|A)U(E). If we assume that agents are only approx-                   observing agent) causal structure of the world. While this
imately rational, and hence only softly maximize expected                  is clearly not always the case, people, and especially chil-
utility:                                                                   dren, are often in situations where they can observe the ac-
                    P(A|U, PB ) ∝ eβ·EPB (E|A)U(E) ,              (1)      tions of an expert on a novel-to-the-observer causal system.
                                                                           In Fig. 1c this is represented with the equality between the
where the parameter β determines the amount of decision
                                                                           true causal structure of the world and the observed agent’s
noise.
                                                                           beliefs about the causal structure. (It is possible to relax this
   Eq. 1 can be used to model the intuitive theory of inten-
                                                                           assumption, leading to a model which incorporates explicit
tional agency of a person who makes the rational agent as-
                                                                           reasoning about belief formation and update; see Goodman
sumption (Baker et al., 2007).
                                                                           et al. (2006) for a related model.)
Integration In order to capture reasoning about an inten-                     Given this setup, Bayesian inference can be used to in-
tional agent choosing actions based on their causal knowl-                 fer a causal structure from observation of events and actions
edge, we construct a model which integrates the above ap-                  in two ways: assuming only causal knowledge (causal-only
proaches to causality and agency. We first assume that the                 inference), and assuming both causal and social knowledge
observed agent represents the world in terms of causal Bayes               (social-causal inference). For causal-only inference, the pos-
net S: the set of outcomes is the set of all possible events               terior over causal structures is given by:
(variable values), the set of actions is all combinations of in-
terventions, and the belief function is described by the CBN                                   Pc (S|A, E) ∝ P(E|A, S)P(S),              (2)
dependency: PB (E|A)=P(E|A, S). Further, we assume that
the utility function of the agent splits into a cost, C , for each         where P(S) is the prior probability over causal structures—
intervention made, and a reward, R , for each desired event                we take this to be given by an independent prior probability
achieved.1                                                                 P(vi →v j ) that each potential edge is in S.
   This CBN-based stochastic decision problem describes a                     For social-causal inference the joint posterior over causal
simple theory of mind for reasoning about a causal agent—                  structure, S, and the (unknown) utility function, U, of the
the intuitive theory one person has about another person’s                 agent performing the actions is given by:
causal knowledge, desires, and actions. Note that a per-
son might represent the causal structure of the world via a                        Ps-c (S,U|A, E) ∝ P(A, E|S,U)P(S)P(U)
                                                                                                                                         (3)
CBN, and represent another agent’s beliefs via a second CBN                                          ∝ P(E|A, S)P(A|S,U)P(S)P(U),
(wrapped inside a SDP). When the interventions that enter
the person’s own causal reasoning are the actions of the other             where P(A|S,U) is given by Eq. 1. (Note that the same causal
agent, they need not be treated as unexplained events. Fig. 1c             structure, S, enters both the CBN term and the SDP term of
    1 The model described in this section can be easily extended to        Eq. 3—this is the knowledgeable agent assumption.) We as-
capture temporal effects by using dynamic Bayes nets and Markov            sume a uniform prior on sets of desired events, which deter-
decision process models.                                                   mines P(U). If we are interested in the causal structure alone,
                                                                     2760

 (a)                                                                (b)                                                                              (c)
                                     Social−causal model                             Causal−only model                                                                        Social−causal, strong prior
                         0.5                                         0.5                                                                               0.5
                         0.4                                         0.4                                                                               0.4
 Posterior probability
                         0.3                                         0.3                                                                               0.3
                         0.2                                         0.2                                                                               0.2
                         0.1                                         0.1                                                                               0.1
                          0                                           0                                                                                 0
                               A     B      AorB    A&B    none            A         B     AorB                    A&B                none                         A             B       AorB       A&B     none
                                                                                         Cause of C
Figure 2: Model predictions: the social-causal (a) and causal-only (b) models (both with uniform causal prior: P(A→C)=P(B→C)=0.5),
and (c) the social-causal model with prior disfavoring cause B: P(B→C)=0.15. (In all cases R =6, C =1, ε=0.85.)
we can marginalize over these utility functions:                                            The social-causal inference model has a number of free
                                                                                         parameters—the causal strength ε, the action cost C , the goal
                                   Ps-c (S|A, E) = ∑ P(S,U|A, E).              (4)       reward R , and the decision noise β—that affect quantita-
                                                      U
                                                                                         tive predictions. However, the qualitative predictions seen in
Predictions We describe the simplest scenario in which the                               Figs. 2 and 3 hold over a wide range of parameters. These
causal-only and social-causal models make qualitatively dif-                             predictions differ from the predictions of a causal-only infer-
ferent predictions about causal learning. Imagine a situation                            ence model (which is unable to use social information to de-
with three causal variables: two potential causes, A and B,                              confound ambiguous evidence), and a gated-encoding model
and one potential effect, C. Simultaneous interventions on                               (which fails to continuously integrate prior causal knowledge
A and B are observed, and activation of C follows. To the                                with social information).
causal-only model this is confounded evidence, and it is un-                                                                  0.6
able to distinguish possible causal relations2 (Fig. 2b). If we                                                                                                                            A only
                                                                                                                                                                                           A&B
assume, however, that the simultaneous interventions on A                                                                     0.5
                                                                                                      Posterior probability
and B are the actions of a knowledgeable agent, the social-
                                                                                                                              0.4
causal model makes the (strong) inference that both A and B
are required to bring about C (Fig. 2a). This inference fol-                                                                  0.3
lows from the tradeoff of costs and goals in the social-causal
model. Informally: the agent wishes to minimize action cost                                                                   0.2
while achieving a desired outcome, because each interven-
                                                                                                                              0.1
tions has a cost, the most parsimonious inference is that the                                                                   0.1   0.15    0.2    0.25    0.3       0.35      0.4    0.45    0.5
                                                                                                                                             Prior probability of relation B−>C
agent believes both actions are required to bring about her
desired outcome—if her goal is to bring about C, this means                              Figure 3: The graded effect of prior knowledge on inferences of the
that she must believe the causal structure is A&B→C.                                     social-causal model.
   If the prior probability of cause B is significantly less than
that of cause A (i.e. P(B→C)P(A→C)) the social-causal
inference model overrides the social inference, instead con-                              Experiment: Causal learning in social context
cluding that A is the only cause of C; Fig. 2c. However,                                 In the following experiment we test the qualitative predictions
prior beliefs integrate continuously, coming to dominate the                             of the social-causal model that critically distinguish it from
inference when they are fairly strong, but influencing infer-                            the other possible models: that people will use social context
ence even when they are weak (Fig. 3). This graded behavior                              as a source of information to disambiguate confounded causal
contrasts with another possible mechanism for incorporating                              evidence (Fig. 2a), that this relies on a knowledgeable agent
causal knowledge, the gated-encoding model, in which so-                                 assumption (Cf. Fig. 2b), and that this interacts (in a graded
cial context is used for inference, but prior beliefs serve as                           fashion) with prior causal knowledge (Figs. 2c and 3). We
a gating mechanism, forming the “boundary conditions” for                                constructed scenarios in which a knowledgeable agent per-
attention to social context (Lyons et al., 2007).                                        formed two actions (simultaneously) and an effect followed
    2 The causal-only model exhibits a slight preference for the struc-                  (the Social condition). To show that inferences follow from
ture AorB→C because the evidence is most likely given this struc-                        rational- and knowledgeable-agent assumptions, and not ex-
ture: either of the events is a sufficient cause of C.                                   traneous non-social factors of the scenarios, we controlled
                                                                                 2761

for mere agency by manipulating the knowledgeability of the              A (and not B)
actor about the causal system—in the Self condition we de-               B (and not A)
scribed the actions as being taken by “you” (the participant).           Either A or B (or both together)
Finally, to explore the effect of prior causal knowledge we              Both A and B together (but not either one alone)
constructed a third variant of the scenarios (the Prior condi-           C is unrelated to A and B,
tion) in which one of the two actions was relatively implau-
sible as a cause of the effect. To verify that these causes           with A, B, and C were replaced with the appropriate events.
were implausible we followed the main experiment by elic-             The order of the response options was consistent for each par-
iting plausibility judgments for each potential causal relation.      ticipant, but randomized between participants.3 Following
                                                                      the main portion of the experiment participants were asked
Method                                                                to rate the plausibility (on a seven-point scale) of each action
Participants Participants were fifteen members of the MIT             causing the corresponding effect.
community who received a small compensation for their time.
                                                                      Results and discussion
Materials We constructed a series of scenarios based on the
abstract causal scenario described above. Each scenario con-          Fifteen (out of 135) responses failed to sum to 100 (never
sisted of three sentences: (1) setup of scenario, (2) agent/you       by more than 10); these responses were normalized to 100.
performs two actions simultaneously, (3) effect follows. Each         Ratings on the plausibility check were left blank on two re-
scenario had three variations differing only in the second sen-       sponses; these were omitted from our analyses.
tence: in the Social condition the agent performed two equiv-            In no condition was there a significant effect of domain; we
alent actions, in the Self condition “you” (the reader) perform       collapse across domains for the remaining analyses. Fig. 4
two equivalent actions, in the Prior condition the agent per-         summarizes the causal structure inferences of participants in
forms two dissimilar actions, one of which is an implausible          each of the three conditions.
cause of the effect. In order to rule out the hypothesis that so-        Consistent with the predictions of the social-causal model
cial reasoning effects are peculiar to a single domain (e.g. ar-      (Fig. 2a), bets placed on “A and B” in the Social condition
tifacts), we constructed scenarios drawn from three different         were significantly greater than bets placed on any other op-
domains: mechanical (artifact), biological, and chemical. In          tion (vs. “A only”: t(44)=8.58, p<0.001; vs. “B only”:
each domain we constructed three different scenarios, for a           t(44)=8.59, p<0.001; vs. “A or B”: t(44)=3.25, p<0.01;
total of nine scenarios. Each of the nine scenarios had three         vs. “no relation”: t(44)=8.47, p<0.001). (All t-tests are two-
variants: one for each of the three conditions.                       tailed and, where appropriate, correlated-samples.) Thus, in
   For example, one Social condition scenario in the biologi-         contrast to the predictions of a causal-only learning model,
cal domain was:                                                       participants infered that A and B together cause C, despite
                                                                      confounded evidence. To verify that this inference was based
   You work at a genetically-engineered plants nursery, and
                                                                      on social context information, we compare the Social condi-
   one of your coworkers is tending to some almost-dead
                                                                      tion to the Self condition, in which the knowledgeable agent
   flowers that you havent seen before. Your coworker si-
                                                                      assumption should be weakened. Indeed, the “A and B” bets
   multaneously pours a yellow liquid and a blue liquid on
                                                                      were significantly less in the Self condition than in the Social
   the flowers. By the end of the day, the flowers are grow-
                                                                      condition (t(44)=3.34, p<0.001), and in the Self condition
   ing again.
                                                                      there was no longer a significant difference between “A and
In the Self condition the middle sentence was changed to:             B” and “A or B” responses (t(44)=1.71, p=0.094)4 .
   One day when your coworker is gone, you find a yellow                 The prior plausibility check confirmed that the causal re-
   liquid and a blue liquid in his supplies and simultane-            lations intended to be implausible were significantly less
   ously pour them on the flowers.                                    plausible than those intended to be plausible (t(44)=19.27,
                                                                      p<0.001). As predicted (Fig. 2c), prior plausibility affected
In the Prior condition the middle sentence was changed to:            causal structure inferences: the bets on “A and B” were sig-
   Your coworker simultaneously drinks a yellow liquid                nificantly greater in the Social condition than in the Prior con-
   and pours a blue liquid on the flowers.                            dition (t(44)=5.11, p<0.001). Thus participants used prior
Procedure Participants were assigned to conditions such                   3 To verify that participants were considering each scenario, we
that each participant received one scenario in each condi-            inserted an attention check at a random position within the experi-
tion in each domain (assignments were counterbalanced in              ment packet. This page looked visually similar to other pages but
                                                                      contained instructions to write only “I have read the instructions”
a latin square design). The order of scenarios was random-            and proceed. No participant failed this check.
ized between participants. After reading each scenario partic-            4 In the Self condition there was a trend toward “A and B” bets.
ipants were asked for their causal structure inferences (“What        Informal debriefing suggested that some participants misunderstood
causes C?”) in the form of bets (which were required to sum           the fictional assumption of the scenario, treating “themselves” as
                                                                      knowledgeable agents. If this was the case, we would expect to
to $100—hence, providing a natural elicitation of probability         observe a mixture of the causal-only model with the social-causal
judgments). The five options were of the form:                        model; this is consistent with the observed trend.
                                                                  2762

 (a)                                                          (b)                                                                               (c)
                                   Social condition                          Self condition                                                                              Prior condition
                     0.5                                       0.5                                                                                 0.5
 Likelihood rating
                     0.4                                       0.4                                                                                 0.4
                     0.3                                       0.3                                                                                 0.3
                     0.2                                       0.2                                                                                 0.2
                     0.1                                       0.1                                                                                 0.1
                      0                                         0                                                                                   0
                           A   B        AorB     A&B   none          A   B        AorB                                    A&B       none                     A       B        AorB     A&B   none
                                                                             Causal relation
Figure 4: The mean bet (likelihood rating) placed on each of the five possible causes of C. The Social condition (a) confirms the social-
causal model predictions (Fig. 2a). The Prior condition (c) confirms predictions of the social-causal model with strong prior (Fig. 2c). The
Self condition (b) reflects a reversion to the causal-only model (Fig. 2b), as expected, but seems to be mixed with residual social-causal
inferences—see Footnote 4.
causal knowledge to inform inferences, even when social con-                                                            0.7
text information was available. To see whether this is a graded
                                                                                                                        0.6
integration of information sources, as predicted by the social-
                                                                                      Likelihood rating for "A and B"
causal model (Fig. 3), or an all-or-nothing gating effect of                                                            0.5
prior knowledge, we exploit natural variation among the sce-
narios. The relationship between the plausibility rating of a                                                           0.4
participant and their bet on “A and B” in the corresponding
scenario, can be used to further examine the effect of prior                                                            0.3
knowledge on inferences. Pooling Social and Prior scenar-
                                                                                                                        0.2
ios, prior plausibility ratings explain 43% of the variance in
bets (r=0.66, p<0.001), as shown in Fig. 5.5 Within con-                                                                0.1
ditions, causal structure inferences remain significantly cor-
related with the variation in plausibility judgments (r=0.46,                                                            0
                                                                                                                                1          2   3         4       5   6         7
p<0.01 within the Social condition, r=0.56, p<0.001 within                                                                                     Plausibility rating
the Prior condition). This result indicates that participants
continuously integrate prior causal knowledge with social                      Figure 5: The mean bet (likelihood rating) of participants on “A
                                                                               and B” according to their plausibility rating for B as a cause of C.
context information, rather than using prior causal knowledge                  The graded effect of prior knowledge confirms the model predictions
as a gate on social inference.                                                 (Fig. 3).
                                     Over-imitation
The results of the previous sections show that generic infer-                  outcome, but one is not (for example, touching a rod to the top
ence abilities, combined with an understanding of causality                    of the box). When invited to retrieve the prize, children per-
and agency, can result in rapid learning of causal knowledge.                  form all the actions, including the superfluous one. Chimps
Yet where there is rapid learning there is the possibility of go-              in a similar experiment did not over-imitate, leaving out the
ing rapidly astray—are there situations in which social-causal                 implausible action. Lyons et al. (2007) investigated a num-
inference might lead to incorrect conclusions?                                 ber of possible explanations for over-imitation in children but
   A number of authors have reported that children seem to                     found it to be remarkably robust; the only manipulation they
over-imitate adults, copying even actions which are, to adults,                report that reversed children’s over-imitation was removal of
clearly superfluous to bringing about an effect (Horner &                      physical contact between cause and (potential) effect (Lyons
Whiten, 2005; Lyons et al., 2007; Meltzoff, 1995). For in-                     et al., 2007, Expt. 2b). On the basis of these findings Lyons et
stance Horner and Whiten (2005) present a “puzzle box” to                      al. (2007) suggest that over-imitation reflects an “automatic
children and demonstrate a series of actions which culminate                   causal encoding” mechanism, with “boundary conditions” to
in retrieving a prize from within the box. The box is trans-                   switch off this encoding (such as physical contact).
parent, and some of these actions are plausibly related to the                    Our modeling results indicate that a separate principle
   5 The correlation is higher for group means (r=0.85); we are,               (such as automatic causal encoding) needn’t be invoked to
however, primarily interested in the relationship within individual            explain children’s over-imitation. If children’s prior beliefs
participants.                                                                  are weaker than adults’ (and, like adults, contact-causality is
                                                                         2763

amongst the strongest priors), then over-imitation behavior          flower). Different inferences might be licensed when the
follows as the result of domain-general probabilistic infer-         agent has a social goal, such as communication or pedagogy
ence, assuming that children use social context as a source of       (e.g. teaching how to revive a flower—see Shafto and Good-
evidence. Our experimental results, which demonstrate simi-          man (2008)). Further work will be required to distinguish
lar inferences in adults, further support this interpretation by     learning based on inference of concrete goals from that based
showing that the interaction between prior causal knowledge          on social goals.
and social inference is not a gating mechanism (as suggested            We have suggested that rapid social learning follows from
by “boundary conditions” on automatic causal encoding), but          domain-general inference abilities and an intuitive theory
a graded integration as required by Bayesian inference.              of other minds. This emerged naturally in our computa-
   It is interesting to ask what the differences between chimps      tional model by considering a powerful inference mecha-
and children mean, in light of this interpretation. The causal-      nism (Bayesian inference) operating over complex knowl-
only model predicts little over-imitation, since even a small        edge structures. Since the compositionality of concepts is a
amount of prior bias dominates the inference. This suggests          crucial feature of human cognition, it is likely that other im-
that chimps too are acting rationally on the basis of causal         portant aspects of human thought also lurk in the interactions
structure inferences, but are failing to use social information      between representations that are well understood in isolation.
to guide these inferences. That is, the quixotic over-imitation      Studying the effects of such interaction is thus an especially
of children may reflect a deep understanding of other minds,         important and potentially fruitful direction for computational
while the lack of this behavior in chimps might reflect poor         cognitive science.
theory of mind.
                                                                                                References
                           Conclusion                                Baker, C., Tenenbaum, J., & Saxe, R. (2007). Goal inference as
                                                                        inverse planning. Proceedings of the 29th annual meeting of the
We have presented a computational model of the social ac-               cognitive science society.
                                                                     Berger, J. (1985). Statistical Decision Theory and Bayesian Analy-
quisition of causal knowledge. This model integrates existing           sis. Springer.
Bayesian approaches to causal reasoning and intuitive psy-           Gergely, G., & Csibra, G. (2006). Sylvias recipe: The role of im-
chology. It predicts qualitatively different inferences about           itation and pedagogy in the transmission of cultural knowledge.
                                                                        Roots of human sociality: Culture, cognition, and human interac-
causal structure, given social context, than an equivalent              tion, ed. NJ Enfield & SC Levenson.
model based on causality alone, and predicts that prior causal       Goodman, N., Baker, C., Bonawitz, E., Mansinghka, V., Gopnik,
knowledge will be integrated into inferences in a graded fash-          A., Wellman, H., et al. (2006). Intuitive Theories of Mind: A
                                                                        Rational Approach to False Belief. Proceedings of the Twenty-
ion. We verified these predictions experimentally with adult            Eigth Annual Conference of the Cognitive Science Society.
participants, and discussed the relation of these results to the     Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E., Kushnir, T.,
developmental phenomenon of over-imitation.                             & Danks, D. (2004, Jan). A theory of causal learning in children:
                                                                        causal maps and Bayes nets. Psychological Review, 111(1), 3–32.
   While research on imitation and social cognition has              Gopnik, A., Meltzoff, A., & Kuhl, P. (1999). The Scientist in the
stressed the tendency of children to gain knowledge directly            Crib: Minds, Brains, and How Children Learn. William Morrow
                                                                        & Col., Inc.
from adults, research on causal learning has focused on the          Horner, V., & Whiten, A. (2005). Causal knowledge and imita-
ability of children to extract causal structure from observation        tion/emulation switching in chimpanzees (Pan troglodytes) and
and interaction directly with causal systems. Our results sug-          children (Homo sapiens). Animal Cognition, 8(3), 164–181.
                                                                     Kushnir, T., Wellman, H., & Gelman, S. (2008). The role of
gest that social context may provide a crucial, and often ig-           preschoolers social understanding in evaluating the informative-
nored, source of information that children use to learn causal          ness of causal interventions. Cognition, 107(3), 1084–1092.
knowledge. However, the ability to learn from disparate              Lyons, D., Young, A., & Keil, F. (2007). The hidden structure of
                                                                        overimitation. Proceedings of the National Academy of Sciences,
sources of evidence raises an important empirical question:             104(50), 19751-19756.
to what extent do children actually rely on social evidence          Meltzoff, A. N. (1995). Understanding the intentions of others:
(vs. observation, exploration, etc.) in acquiring causal knowl-         Re-enactment of intended acts by 18-month-old children. Devel-
                                                                        opmental Psychology, 31(5), 838–850.
edge? Our results indicate that social learning depends on a         Pearl, J. (2000). Causality: models, reasoning, and inference. Cam-
knowledgeable-agent assumption, thus it is reasonable to start          bridge University Press.
by asking when children are aware that adults have knowl-            Shafto, P., & Goodman, N. D. (2008). Teaching games: Statistical
                                                                        sampling assumptions for learning in pedagogical situations. In
edge that they themselves lack. Kushnir, Wellman, and Gel-              Proceedings of the thirtieth annual meeting of the cognitive sci-
man (2008) have recently shown that children are sensitive to           ence society.
the knowledgeability of others, and treat intentional actions        Tomasello, M. (1999). The Cultural Origins of Human Cognition.
                                                                        Harvard University Press.
by knowledgeable agents as more informative about causal
structure than actions by unknowledgeable agents. This is
consistent with our experimental results; our modeling results
show that such inferences are an appropriate response to so-
cial context, rather than a rough heuristic, or incorrect bias.
   Throughout this paper, social context consisted of observed
actions of an agent with a concrete goal (e.g. reviving a
                                                                 2764

