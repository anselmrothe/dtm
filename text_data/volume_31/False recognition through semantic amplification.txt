UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
False recognition through semantic amplification
Permalink
https://escholarship.org/uc/item/8jw3x622
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 31(31)
Authors
Johns, Brendan
Jones, Michael
Publication Date
2009-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

                              False Recognition through Semantic Amplification
                                              Brendan T. Johns (johns4@indiana.edu)
                                             Michael N. Jones (jonesmn@indiana.edu)
                              Department of Psychological and Brain Sciences, Indiana University
                                           1101 E. Tenth St., Bloomington, In 47405 USA
                              Abstract                                 represent word meaning. However, we believe that in order
   This paper describes a computational model to explain a             to model semantic behaviors, such as is seen with false
   variety of results in false recognition. The processing             recognition, one must use a representation of words that
   mechanism in the model is built around a co-occurrence              contains semantic information. One promising avenue for
   representation of lexical semantics, affording an account of        these semantic representations are those created by co-
   both structure and process. We show that this model can
   naturally account for levels of false recognition that are seen
                                                                       occurrence learning models.
   in studies using the DRM paradigm, including item-level               In a co-occurrence model, a word’s semantic
   effects, reaction times, and event-related brain potentials.        representation is constructed by observing statistical
                                                                       regularities in a large corpus of text. These models can
   Keywords: False recognition; co-occurrence representations;
   memory models; recognition memory; semantics
                                                                       account for a variety of different semantic behaviors (for a
                                                                       review see Jones & Mewhort, 2007). Due to the success of
                          Introduction                                 co-occurrence models in other domains, it seems natural to
                                                                       assume that they could also be used to account for semantic
False recognition is one of the most empirically studied               effects in recognition memory. The models are particularly
phenomena in recent times, however very little formal                  promising given the observation that associative variables
modeling of this effect has been conducted. False                      are important predictors of false recognition and false recall,
recognition has been most studied using the                            particularly backward association strength (Deese, 1959;
Deese/Roediger-McDermott (DRM) paradigm (Deese,                        Gallo & Roediger, 2002). Because co-occurrence
1959; Roediger & McDermott, 1995). In this task, lists of              representations correlate with backward association strength
words that are associated with specific critical words are             (Johns & Jones, 2008), their representations are appealing to
presented to subjects, and on subsequent memory tests the              be used in a processing model of false recognition. By using
unpresented critical items are falsely recognized at almost            a representation of words that is built up through exposure
the same level as studied items (Roediger & McDermott,                 to the environment, we are not simply assuming a particular
1995). For example, given nurse, hospital, sick, and cure to           semantic organization. Instead we are both explaining how a
remember, subjects are likely to subsequently produce a                certain memory structure is created, and how this structure
false alarm to doctor.                                                 interacts with the processing mechanism.
  Work within the DRM paradigm has provided
fundamental evidence about the organization of human                            The Recognition through Semantic
memory. The paradigm demonstrates that humans use
semantic information to both store and retrieve items, and
                                                                                    Amplification (RSA) Model
the use of this information can lead to profound memory                Our false recognition model is based on the Iterative
errors. However, the exact mechanisms that underlie the                Resonance Model (IRM) of recognition memory (Mewhort
false recognition of associates have evaded a formal                   & Johns, E., 2005). The motivation for IRM comes from a
explanation. Rather, theorists have focused more on general            series of experiments demonstrating that Old responses and
conceptual frameworks of cognition, such as Fuzzy Trace                New responses are based upon different types of information
Theory (FTT; Brainerd & Reyna, 2002), the source-                      (Mewhort & E. Johns, 2000). Note that a subject responds
monitoring framework (Johnson, Hashtroudi, & Lindsay,                  Old if the probe item was in the encoded list, and New if it
1993), and the discrepancy-attribution hypothesis                      was not. In particular, the authors found that the amount of
(Whittlesea, 2002), to explain false memories.                         contradictory information contained within a probe
  There are now many different computational models of                 predicted New responses, whereas Old responses were based
recognition memory. However, a principled problem with                 on the similarity of the probe to the memory items. The
these models is that the representations they use do not               original IRM used this dual-criterion decision process. If a
contain semantic information about specific words, due to              decision is not made on a particular information sample,
the fact that their representations are typically constructed          then successive iterations are employed to sharpen the
with random number generators. This practice is natural                evidence. The number of iterations required for the model to
because the models are not typically used to simulate                  make a decision is taken as a proxy of response latency.
semantic effects in recognition memory. Further, it is still             Our Recognition through Semantic Amplification (RSA)
the subject of much debate what are the correct features to            model is kept within the same formal framework as IRM,
                                                                   2795

but differs mainly in its representation assumptions. Rather          1. Semantic Representations
than a set of randomly generated arbitrary features, RSA
                                                                      A word’s semantic representation in memory is built using a
uses vectors that are built from a co-occurrence learning
                                                                      recent co-occurrence model entitled the Semantic
process. The model assumes that the semantic
                                                                      Distinctiveness Memory (SDM) model (Johns & Jones,
representations for words presented in a DRM list are
                                                                      2008). The SDM model is a co-occurrence learning model
retrieved from long-term memory and are stored in a
                                                                      that was created in order to account for the effect of
composite memory store (containing a mix of semantic
                                                                      semantic distinctiveness on a word’s strength in memory.
vectors for all the items on the list). When presented with a
                                                                      We have shown, in both a corpus analysis (Johns & Jones,
probe, the model uses a searching (amplification) process to
                                                                      2008) and an artificial language learning experiment
determine whether the probe is similar enough to the
                                                                      (Recchia, Johns, & Jones, 2008), that words that occur in
composite store to respond Old, whilst simultaneously
                                                                      more semantically distinct contexts are more strongly
searching for contradictory information between the
                                                                      represented within memory. Johns & Jones (2008) showed
elementwise comparison of the probe and the composite
                                                                      that this SDM model produces a better fit to both lexical
store to respond New (i.e., old and new responses are based
                                                                      decision/naming times and semantic organization than
on different information, and the response is the winner of a
                                                                      classic learning models, and these representations give a
race between the processes). In addition, we demonstrate
                                                                      good account of semantic isolation effects, semantic
that the model can be used to simulate both choice
                                                                      similarity ratings, and association norms.
probability and response latency results within false
                                                                        For the purpose of the current paper, the SDM vector
recognition by using the number of iterations to make a
                                                                      representations can be thought of as similar to those created
decision (as in Mewhort & E. Johns, 2005).
                                                                      by other co-occurrence learning models, such as LSA
   The RSA model may be divided into four main
                                                                      (Landauer & Dumais, 1997). A principled difference is that
components: 1) a co-occurrence representation 2) encoding,
                                                                      SDM vectors are sparse vectors representing the weighted
3) amplification, and 4) decision. The processing model
                                                                      contexts in which words have co-occurred; this sparsity is
works by first encoding all the words that are seen in a
                                                                      optimal for our recognition process borrowed from IRM.
specific study list into a single composite vector. This
                                                                      The SDM semantic representation for every possible word
represents the ‘gist’ of the words that were seen. Then at
                                                                      is stored in long-term memory, and the representations for
test, the model attempts to amplify the probe word in this
                                                                      words presented are retrieved from this store and cast into a
composite vector. If the probe word is in the memory store,
                                                                      short-term store when encoding a DRM list.
its representation should be efficiently amplified. If the
probe is not contained in the memory store, it will not be
efficiently amplified. Each of these processes will be
                                                                      2. Encoding Phase
described in turn. The pseudocode routine for the RSA                 The memory store that the processing model operates on is a
model is displayed in Figure 1, and the different processes           single composite vector. Every word presented during the
are described formally in this figure.                                study phase is retrieved from the SDM mental lexicon and is
                                                                      added into this composite vector. Word vectors are first
                                                                      normalized, so that each word adds in approximately the
   do i=1, number_studied            % encoding process
      memory = memory + (normalize(item(i)) * random)                 same amount of information. Each vector is multiplied by a
   enddo                                                              uniform random number between 0 and 1 to simulate
   probe = normalize(probe)                                           encoding failure. The composite representation may be
   repeat                                                             thought of as a superposition of items presented in the list.
    iter = iter + 1                                                      Other models, such as TODAM (Murdock, 1982), also
    do i = 1, length_vec            % calculate contradictory         use a composite vector to create a representation of an
       if (probe(i) > 0)                                              event. The different TODAM models use holographic
      cont_info += |norm_to_1(comp(i)) – norm_to_1(probe(i))|         vectors, whereas our vectors are simply summations of
      endif                                                           semantic traces, but both assume a single vector to create a
    enddo                                                             representation of a study list. The practice is also a similar
    cont_count += cont_info                                           flavor to the proposal of fuzzy-trace theories, where a ‘gist’
    similarity =cosine(probe, memory)/iter % similarity               representation of an episode is created. Even though fuzzy-
    do i = 1, length_vec            %amplification process            trace theory seems to entail more sophisticated processes of
        if (probe(i) > 0)                                             gist extraction, this encoding phase does correspond with
           memory(i) = memory(i) + (probe(i) * (similarity/iter))     some of the claims of this theory.
       else memory(i) = memory(i) * random
    enddo
    memory = normalize(memory)
                                                                      3. Amplification Process
   until ( (similarity > YES_crit) .or. (cont_count > NO_crit) )      The amplification process that the RSA model employs
                                                                      essentially works by attempting to ‘turn up the volume’ of
         Figure 1. Pseudocode listing for the RSA model.              the probe’s representation in memory, while dampening all
                                                                      other items. This causes the probe’s representation within
                                                                  2796

memory to increase across iterations. How strongly the              representation is amplified within the composite. Old
probe is amplified in the composite is determined by a              decisions are based on a similarity value between the probe
normalized similarity value. This value is determined by            word and the memory vector, whilst New decision are based
taking the cosine between the probe and the memory vector           on the amount of evidence that the word did not occur. The
and dividing it by the current iteration. Hence, even though        amplification process essentially works by attempting to
the cosine increases due to the amplification process, the          filter the probe out of the composite representation,
amount of increase is constrained by the current iteration          emphasizing signal (if present) while simultaneously
that the model is in. If a decision is not made on the current      dampening noise. If either signal or noise is strong enough,
iteration, the amplification process is repeated.                   a confirmation/contradiction decision can be made.
   The second mechanism works by iteratively dampening                 This model should be particularly effective at explaining
the non-defining elements of the probe in the composite.            false memory paradigms because the searching mechanism
This is accomplished by simply multiplying the memory               is dependent on the amount of semantic information
vector by a random number between 0 and 1 at each                   contained within the composite vector shared with the
location where the probe word contains no information (i.e.         probe. When the composite contains a large amount of
where the probe vector is 0). With this process, a word that        information about a word, then it is amplified efficiently
occurred in the study list is amplified more efficiently            increasing the likelihood of reaching the Old criterion than
within the composite because it contains more semantic              the New criterion. Hence, even though a word was not
information and also contains less contradictory information        contained in the study list, it could be accepted with a high
that needs to be filtered out of the composite.                     probability if it shares semantic information with study
                                                                    words. There is very little complexity built into processing
4. Decision Process                                                 model; instead the main locus is put on the contents of
                                                                    memory. To this point, there are only two fixed parameters
The model uses two different sources of information to
                                                                    (both decision parameters) that drive this model.
make a decision about whether to accept or reject a probe.
As in the IRM, Old responses will be based on the similarity
of the probe to the memory vector, while New responses                                       Simulations
will be based on the amount of contradictory information            The methodology that we use in simulating false recognition
that the probe did not occur in the study list. The similarity      results is very simple: for the exact words used in an
value will be assessed with a cosine between the probe and          experiment we retrieve the semantic representations learned
the memory vector. If this similarity value exceeds a certain       by the SDM model and encode these words into a composite
criterion then the probe is accepted. In the following              vector representing the list. The two parameters of the RSA
simulation, this yes criterion is set at 0.99.                      model are fixed across simulations. Instead, the locus of
   The amount of contradictory information is assessed by           memory effects are dependent on the different words in
measuring the difference in the pattern of the probe and the        memory, not different processing for different experiments.
memory vector. This is computed as the absolute difference
between the defining portions of the probe and the                  Simulation #1: Levels of False Recognition
corresponding locations within the memory vector, when
both of the vectors are normalized to have a magnitude of 1.        We first test the RSA model on is whether it attains similar
This returns a value between 0 and 1, which will be 0 if all        levels of false recognition to those seen in behavioral data.
of the probe information is contained in memory, and it will        We will simulate three different sets of DRM lists: 1) the
be 1 if none of the probe information is contained within           lists from Roediger and McDermott’s (1995) classic study,
memory. Since the amount of contradictory information will          2) the extended DRM list set from Stadler, Roediger, &
decrease across iterations (due to the amplification process),      McDermott (1999), and 3) the more variable lists from
the amount of contradictory information is a running count.         Gallo & Roediger (2002).
If this count exceeds a certain criterion, then the probe is
rejected. In the following simulations this No criterion is set     Method The DRM lists for the above described studies
to 4.5. Thus, contradictory evidence is the difference in the       were attained from the specified papers. One list (that for
values that define the probe word’s semantic representation         man) was excluded because it was in the stop list that the
(the non-zero entries in the word’s episodic trace) and the         SDM model was trained with. For a single trial, four DRM
corresponding values in the composite vector.                       lists were randomly selected and added into the composite.
                                                                    The model was then tested with studied items and critical
Discussion of RSA                                                   lures. Average hit and false recognition rates were recorded
                                                                    across 1000 trials. To test levels of false recognition to
The model that we propose here is based on a simple                 unrelated items, five words were randomly selected from the
representation assumption – that all the words seen in a            Toronto Word Pool (Friendly, et al., 1982), for each trial.
study list are added into a single composite vector, or in
other words, the composite contains the ‘gist’ of the study         Results The levels of recognition for studied, critical, and
list. To determine whether a word occurred in a specific list,      unrelated words for the model and each of the studies are
a simple mechanism is employed where a word’s
                                                                2797

displayed in Figure 2. This figure shows that the model             contribution of the memory structure and the process in
gives a very good approximation to the qualitative trends           creating false recognition.
seen in the behavioral data across the different word types.
Hence, the RSA model seems to be susceptible to the same            Results Across the 55 critical words (with repeats
type of memory illusions that humans are. This is because           removed), a significant correlation of r = 0.476, p < 0.001
the model amplifies the critical word trace efficiently due to      was obtained between the data and predictions of the model.
the memory vector containing a large amount of semantic             If the five lists that the model does worst on are removed
information about the meaning of that word. This figure also        (thief, needle, king, trash, and car), the correlation increases
shows that the model has close approximation to the level of        to r = 0.649, p < 0.001. To assess what impact the memory
recognition for unrelated lures.                                    structure is having on false recognition, the cosine was
                                                                    computed between the composite list vector and the
                                                                    individual word vector for each list. A correlation of r =
                                                                    0.333, p < 0.05 was obtained between the level of false
                                                                    recognition and cosine across the 54 lists. This demonstrates
                                                                    the semantic representation of words has sufficient power
                                                                    within it to predict item-level amounts of false recognition.
                                                                    When combined with a simple process mechanism that is
                                                                    designed to exploit word structure, we see a better fit to the
                                                                    data than either structure or process alone can accomplish.
                                                                    Hence, it is the interaction between the structure of memory
                                                                    and the process mechanism that produces the superior fit to
                                                                    the data, not simply the structure or process alone.
                                                                    Simulation #3: Effect of the Number of Associates
                                                                    Robinson and Roediger (1997) have demonstrated that as
                                                                    the number of associates to a critical word contained within
                                                                    a study list is increased, a systematic increase in false
                                                                    recognition rates to that critical item is also observed. This
      Figure 2. RSA levels of true and false recognition.           is an interesting study for the RSA model to simulate
                                                                    because it suggests that the number of semantic associates is
                                                                    the causal factor in determining the false recognition rates of
Simulation #2: Item-Level Analyses
                                                                    a critical item. Hence, we expect a similar pattern of results
Stadler, Roediger, & McDermott (1999) and Gallo &                   to Robinson and Roediger because the more semantic
Roediger (2002) both published the levels of false                  associates that are studied, the more efficiently a critical lure
recognition that are seen with different DRM lists. As both         should be processed, which in turn should lead to an
of these studies show, there is considerable variability in the     increased hit rate for these items.
levels of false recognition elicited by different DRM lists.
To test the model’s quantitative predictions of false               Method We used the same lists as Robinson, et al. (1999).
recognition, we correlated the levels of false recognition for      On each repetition, five DRM lists were selected and 3, 6, 9,
both the model and the behavioral data using the same               12, or 15 items from the list were randomly selected and
words reported in behavioral data. This allows us to be             added into the current study list. The levels of false
confident that both the memory structure that the model is          recognition for the critical lures at the different level of
utilizing, and the processing mechanism that is operating on        associates, as well as the hit rates for the studied items, were
these representations, are working together to produce false        recorded across 1000 replications.
recognition in a manner coherent with experimental data.
                                                                    Results Figure 3 shows the human data and simulated
Method Levels of false recognition were attained from               results for both the hit rate and the false alarm rate for
Stadler, et al., (1999) and Gallo & Roediger (2002). Again,         critical words from the Robinson, et al. (1999) study. This
four DRM lists from the different studies were added to             figure shows that as the number of associates to a critical
form a single study list. The level of false recognition for        word in a study list is increased, the false alarm rate to the
each critical word was recorded across 1000 simulated               critical lure is also increased. The model produces slightly
trials. In addition, we computed the raw cosine between the         more false alarms (especially with 15 associates), but the
critical word vector and the composite vector for each              same general trend is observed. This simulation
critical word (i.e., how much variance is predicted by solely       demonstrates that high levels of false recognition are seen
by the structural representations without the process               with the RSA model due to the increased amount of
mechanism). This allows us to test the respective                   semantic information contained within a study list’s
                                                                    episodic representation.
                                                                2798

Figure 3. RSA simulation of Robinson & Roediger (1997).
Simulation #4: Effect of Number of Associates on
Short-Term Recognition RT and Accuracy
                                                                             Figure 4. RSA simulation of Coane, et al. (2007).
Coane, McBride, Raulerson, & Jordan (2007) conducted a
short-term recognition experiment in which they created set            Simulation #5: ERP Patterns
sizes of 3, 5, and 7 by sampling from a single DRM list.
Reaction time and accuracy were recorded as a function of              In order to test whether the process that the RSA employs is
the number of associates within a list. They found a greater           cognitively plausible, we compared the change in activation
RT for critical lures than studied items, and also an increase         across iterations in RSA with ERP studies examining
in RT as a function of set size for both word types. In                recognition memory. We do not wish to attempt to localize
addition, they found that the proportion of false alarms to            this process or propose that there is a specific neurological
the critical lure increases as a function of set size, showing         mechanism of this model; instead we simply test whether
that there is a false recognition effect even at small list sizes.     the model’s temporal dynamics change in a similar manner
A compelling feature of the RSA model is that it provides a            as neurological processes seem to. There are two main
framework to account for both choice probabilities and                 results that we would like to focus on.
reaction time, making this an attractive study to simulate.               The first ERP result that we wish to test is the ‘N400
                                                                       strength effect’ described in Finnegan, Humphreys, Dennis,
Method As in Coane, et al. (2007), set sizes of 3, 5, and 7            & Geffen (2002). In this study, subjects made old/new
were created by sampling from DRM lists from the Sadler,               recognition judgments to strong words (presented three
et al. (1999) set of DRM lists. Reaction time was assessed             times), weak words (presented one time), and new words.
by taking the number of iterations to accept or reject a probe         The authors found a greater N400 wave for strong items vs.
as a proxy of RT. Accuracy for both studied items and                  weak items, and for weak items vs. new items. The second
critical lures was assessed for the three set sizes.                   ERP result that we would like to simulate is a study by
                                                                       Johnson, Nolde, Mather, Kounios, Schacter, & Curran
Results Figure 4 displays the results for both simulated               (1997). In this study, the experimenters monitored subject’s
reaction time (top panels) and choice probability (bottom              ERP response during old/new recognition decisions when
panels) as a function of set size, for both the RSA model              tested in the DRM paradigm. They found a greater
(left panels) and the data from Coane, et al. (2007; right             waveform for studied words vs. critical words, and for
panels). As can be seen from this figure the model gives an            critical words vs. unrelated new words. The value we use to
excellent approximation for both reaction time and choice              predict activation in the RSA model will be the normalized
probability data as a function of set size. The reason the             activation value used in the amplification process.
model can capture the reaction time data is that even though
the composite contains a considerable amount of semantic               Method In order to simulate the results of Finnegan, et al.
information about the critical word, this word is still not as         (2002), list sizes of 50 were created by sampling randomly
similar as a studied word to the memory store. This means              from words within the Toronto Word Pool (Friendly, et al.,
that the word is not amplified as efficiently, so it takes             1982). In this list, twenty five words were encoded three
longer for the composite to become similar enough to be                times (the ‘strong’ words), while 25 words were only
accepted or to accumulate enough contradictory information             encoded once (the ‘weak’ words). Then the activation levels
to reject the probe. An increase in set size slows responses           for both the strong, weak, and new words (attained by
to studied items more than the critical word because the               randomly sampling from the word pool) were recorded
unique information for a presented item becomes mixed in               across iterations.
with a greater amount of information from other items.
                                                                   2799

   To simulate the results of Johnson, et al. (1997), DRM           share semantic information with studied words and, hence,
lists of size four were created by randomly sampling lists          they are more efficiently amplified in the composite
from the Stadler, et al. (1999) study. The activations for          memory store. Our model leaves much of the complexity
studied items, critical words, and unrelated words (obtained        required to produce false recognition behavior in the
by randomly sampling 4 critical words whose list did not            semantic representations (learned from language), allowing
occur in the study list) were computed across iterations.           it to use a much simpler processing mechanism, and without
                                                                    reliance on hand-coded word representations.
Results Figure 5 displays the simulation results for both
Finnegan, et al. (2002) (top panel), and Johnson, et al.                                      References
(1997) (bottom panel). In the simulation of Finnegan, et al.        Barinerd, C. J., & Reyna, V. F. (2002). Fuzzy-trace theory
the model produces a higher activation across iterations for           and false memory. Current Directions in Psychological
strong vs. weak words, and weak vs. new words, similar to              Science, 11, 164-169.
the pattern seen in their study. Strong words are more easily
                                                                    Coane, J. H., McBride, D. M., Raulerson, B. A., & Jordan,
amplified within the composite vector compared with weak
                                                                       J. S. (2007). False Memory in a Short-Term Memory
words, and weak presented words are more easily amplified
                                                                       Task. Experimental Psychology, 54, 62-70.
compared with unpresented words. In addition, the time
                                                                    Deese, J. (1959). On the prediction of occurrence of
course of activation change in the model qualitatively
                                                                       particular verbal intrusions in immediate recall. JEP, 58,
mimics the N400 pattern found by Finnegan et al.
                                                                       17-22.
                                                                    Finnegan, S., Humphreys, M. S., Dennis, S., & Geffen, G.
                                                                       (2002). ERP ‘old/new’ effects: memory strength and
                                                                       decisional factor(s). Neuropsychologia, 40, 2288-2304.
                                                                    Johns, B.T., & Jones, M.N. (2008). Predicting lexical
                                                                       decision and naming times from a semantic space model.
                                                                       Proceedings of the 30th Annual Cognitive Science Society
                                                                       (pp. 279-284). Austin, TX: Cognitive Science Society.
                                                                    Johnson, M. K., Hashtroudi, S., & Lindsay, D. S. (1993).
                                                                       Source Monitoring. Psychological Bulletin, 114, 3-28.
                                                                    Johnson, M. K., Nolde, S. F., Mather, M., Kounios, J.,
                                                                       Schacter, D. L., & Curran, T. (1997). The similarity of
                                                                       brain activity associated with true and false recognition
                                                                       memory depends on test format. Psychological Science, 8,
                                                                       260-257.
                                                                    Mewhort, D. J. K., & Johns, E. E. (2005). Sharpening the
                                                                       echo: An iterative-resonance model for short-term
       Figure 5. ERP simulations with the RSA model.                   recognition memory. Memory, 13, 300-307.
                                                                    Mewhort, D. J. K., & Johns, E. E. (2000). The extra-list
   We see a similar pattern of results in the simulation of            feature effect: A test of item matching in short-term
Johnson, et al. (1997), where studied words have the highest           recognition memory. JEP: General, 129, 262-284.
level of activation, but the activation levels for the critical     Murdock, B. B. (1982). A theory for the storage and
lures are also quite high compared with unrelated lures. This          retrieval of item and associative information.
demonstrates why the model is able to attain false                     Psychological Review, 89, 609-626.
recognition: a greater amount of semantic information about         Recchia, G., Johns, B. T., & Jones, M. N. (2008). Context
the critical lure is contained within memory, so it is                 repetition benefits are dependent on context redundancy.
amplified more efficiently, which in turn makes it easier to           Proceedings of the 30th Cognitive Science Society
accept. As with the previous simulation, the dynamics of               Meeting, 267-272.
activation change over time nicely match the qualitative            Robinson, K., & Roediger, H. L. (1997). Associative
waveforms presented in Johnson et al. (1997).                          processes in false recall and false recognition.
                                                                       Psychological Science, 8, 389-393.
                         Conclusion                                 Roediger, H. L., & McDermott, K. B. (1995). Creating false
                                                                       memories: Remembering words not presented in lists.
   We have described a new model of false recognition built            JEP:LMC, 21, 803-814.
on a representation that has proven useful at accounting for        Stadler, M.A., Roediger, H.L., & McDermott, K.B. (1999).
other elusive effects in memory. Our RSA model is                      Norms for word lists that create memories. Memory &
successful at simulating a range of false recognition data             Cognition, 29, 424-432.
because it fuses a simple process account with a structural         Whittlesea, B. W. A. (2002). False memory and the
representation for words generated from experience with                discrepancy-attribution hypothesis: The prototype-
environmental regularities. Critical lures are more likely to          familiarity illusion. JEP: General, 131, 96-115.
                                                                2800

