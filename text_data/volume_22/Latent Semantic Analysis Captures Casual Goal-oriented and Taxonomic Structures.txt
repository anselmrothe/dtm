UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Latent Semantic Analysis Captures Casual, Goal-oriented, and Taxonomic Structures
Permalink
https://escholarship.org/uc/item/2mw8430f
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Authors
Graesser, Arthur
Karnavat, Ashish
Pomeroy, Victoria
et al.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                                                                                                             1
             Latent Semantic Analysis Captures Causal, Goal-oriented, and Taxonomic
                                                               Structures
                                            Arthur Graesser (a-graesser@memphis.edu)
                         Department of Psychology, University of Memphis, CAMPUS BOX 526400
                                                       Memphis, TN 38152 USA
                                            Ashish Karnavat (akarnavat@hotmail.com)
                    Department of Computer Science, University of Memphis, CAMPUS BOX 526429
                                                       Memphis, TN 38152 USA
                                           Victoria Pomeroy (vpomeroy@memphis.edu)
                         Department of Psychology, University of Memphis, CAMPUS BOX 526400
                                                       Memphis, TN 38152 USA
                                       Katja Wiemer-Hastings (kwiemer@cc.memphis.edu)
                         Department of Psychology, University of Memphis, CAMPUS BOX 526400
                                                       Memphis, TN 38152 USA
                                                   and the Tutoring Research Group
                              Abstract                                relational arcs that also are assigned to various categories,
                                                                      e.g., is-a, has-as-parts, cause, reason, enables, contains, etc.
   Latent Semantic Analysis (LSA) has been used to represent          A particular package of knowledge may incorporate spatial
   the domain of computer literacy in AutoTutor, a fully              composition, causal networks, goal hierarchies, taxonomic
   automated computer tutor. The analyses in the present study
                                                                      hierarchies and other viewpoints. All of these viewpoints
   support the claim that the 200-dimensional LSA space
   captures aspects of the structured mental models that underlie     allegedly can be represented as a set of categorized nodes
   computer literacy. Knowledge structures were constructed           that are integrated by a set of directed, relational arcs.
   that contained causal networks, goal/plan/action hierarchies,         It is a time consuming, methodical task to map out
   and taxonomic hierarchies. The proximity of a pair of nodes        knowledge structures for a domain of knowledge.
   (i.e., concept, state, event, action, goal) in these structures    Developers of expert systems and other knowledge based
   predicted the cosine similarity scores that are routinely          systems would require a decade to perform the knowledge
   computed in LSA analyses.                                          engineering that is needed for a system of reasonable scope
                                                                      with widespread practical applications (Lenat, 1995). There
         Representing World Knowledge with                            are authoring tools that guide either experts or novices in the
              Conceptual Graph Structures                             building of the knowledge structures (Williams, Hultman, &
World knowledge has traditionally been captured by                    Graesser, 1998). The structures are built in a principled
knowledge structures throughout the history of cognitive              fashion that caters to the constraints of the composition
science, artificial intelligence, and discourse processes. The        rules, so guidance is needed to prevent illegal compositional
knowledge structure structures include semantic networks,             structures. All of this takes training and experience that can
taxonomies, causal networks, planning networks, ontological           be measured in months or years. However, conceptual
trees, spatial region hierarchies, and various other classes of       graph structures are powerful theoretical entities because
conceptual graph structures (Golden, 1997; Graesser &                 they support the intelligent procedures and processes that
Clark, 1985; Kiel, 1979; Lehmann, 1992; Lenat, 1995;                  operate on the representations, as in the case of retrieval,
Norman & Rumelhart, 1975; Schank & Abelson, 1977;                     classification, summarization, problem solving, question
Trabasso, van den Broek, & Suh, 1989; Sowa, 1983). A                  asking, question answering, and so forth.
knowledge structure contains a set of categorized nodes that             The distance between two nodes in a conceptual graph
refer to concepts, events, processes, states, actions, goals,         structure is frequently regarded as a metric of conceptual
and other ontological classes. The nodes are connected by             relatedness. That is, the conceptual relatedness between

                                                                                                                             2
nodes A and B decreases as a function of the number of arcs    comparison word. The LSA model answered 64.4% of the
that exist on a legal path between A and B. For example, if    questions correctly, which is essentially equivalent to the
1 arc separates A and B on a causal chain, then A and B are    64.5% performance for college students from non-English
strongly related, compared to the case where 4 arcs separate   speaking countries. LSA has had remarkable success in
two nodes on a causal chain. The structural proximity          capturing the world knowledge that is needed to grade
between any two nodes that are connected by a legal path of    essays of students (Foltz, 1996), to assign texts to students
arcs is designated as its structural-proximity (A, B).         of varying abilities to optimize learning (Wolfe, Schreiner,
                                                               Rehder, Laham, Foltz, Kintsch, & Landauer, 1998), and to
   Representing World Knowledge with Latent                    provide effective feedback in the training of summarization
                    Semantic Analysis                          skills (E. Kintsch, W. Kintsch, Laham, Landauer, DePaula,
                                                               Schreiner, Stahl, & Steinhart, 2000). There are now LSA-
Researchers have more recently turned to Latent Semantic       based graders of essays that assign grades to essays with the
Analysis (LSA) because it provides an approximation of the     validity and reliability of human experts in composition
representation of world knowledge, but in a very short         (Foltz, 1996). In our research on computer literacy, LSA
period of time -- measured in weeks, days or even hours.       has been quite successful in evaluating the quality of college
LSA is a statistical representation of a body of world         students’ answers to deep reasoning questions and to the
knowledge that is reflected in a large corpus of textual       contributions of learners during the tutorial interactions with
documents (Landauer & Dumais, 1997; Landauer, Foltz, &         AutoTutor (Graesser, Wiemer-Hastings, Wiemer-Hastings,
Latham, 1998). LSA capitalizes on the fact that particular     Harter, Person, & the TRG, 2000; Wiemer-Hastings,
words appear in particular texts (called “documents”); the     Wiemer-Hastings, Graesser, and the TRG, 1999).
cooccurrence of words in documents reflects the constraints       The success of LSA is quite remarkable given that it was
that exist in world knowledge. The input to LSA is a           never designed to capture many of the traditional problems
cooccurrence matrix that specifies the number of times that    in language understanding systems, such as word order,
word Wi occurs in document Dj. These frequencies are           syntax, quantification, and negation. There are other
adjusted with a logarithm transformation that also corrects    corpus-based probabilistic models that capture word order
for the base rates of words appearing across documents. A      and syntax (Burgess, Livesay, & Lund, 1998; Charniak,
word is a distinctive index for a document to the extent that  1993) but the present study focuses on the capabilities of
its occurrence in the document is above the base rate for that LSA.
word across documents. A standard statistical method,             At this point, there is a great deal of uncertainty about
called singular value decomposition, reduces the large WxD     what is being represented in the K-dimensional spaces of
cooccurrence matrix to K dimensions (typically, 100 to 500     LSA. One optimistic possibility is that the K dimensions
dimensions). Each word, sentence, or text ends up being        reflect ontological categories, semantic features, and
represented as a weighted vector on the K dimensions.          structural compositions of mental models that would be
   The similarity or conceptual relatedness between two bags   directly adopted in structural theories of world knowledge
of words (A and B) is computed as a geometric cosine (or       representation. For example, a simple and straightforward
dot product) between the two vectors. The values normally      assumption would be that particular banks of the K
range from 0 to 1. This LSA match between two language         dimensions of LSA would have a one-to-one or many-to-one
strings is designated as its LSA-match (A, B). The LSA         mapping onto ontological categories (Chi, Slotta, & de
match can be high even though there are few, if any words in   Leeuw, 1994; Keil, 1979), to conceptual primitives (Miller
common between the two strings. LSA allegedly goes well        & Johnson-Laird, 1976; Norman & Rumelhart, 1975;
beyond simple string matches because the meaning of a          Schank & Abelson, 1977), or to the domain-specific features
language string is partly determined by the company (other     that are associated with a particular topic. Very few
words) that each word keeps (Landauer & Dumais, 1997).         researchers would go out on the limb and propose an elegant
   The empirical success of LSA has been promising and         mapping between the K dimensions of LSA and
sometimes remarkable. Landauer and Dumais (1997)               sophisticated theories of world knowledge. However, most
created an LSA representation with 300 dimensions from 4.6     researchers would seriously entertain the possibility of
million words that appeared in 30,473 articles in Grolier’s    weaker correspondences. At the other end of the continuum,
Academic American Encyclopedia. They submitted to the          there are researchers who believe that the K dimensions
LSA representation the synonym portion of the TOEFL test,      have nearly an arbitrary mapping to the attributes of mature
a test developed by the Educational Testing Service to         theories of world knowledge (Landauer & Dumais, 1997).
assess how well non-native English speakers have mastered         A somewhat different question addresses whether the LSA
the words in the English language. The test has a four-        space is capable of recovering aspects of the deeper mental
alternative, forced choice format, so there is a 25% chance    models that underlie text (Forbus, Gentner, & Law, 1995),
of answering the questions correctly. The LSA model            or what is sometimes called situation models (Kintsch,
selected the alternative that had the highest match with a     1998). Foltz, Britt, and Perfetti (1996) reported evidence

                                                                                                                            3
that suggested that LSA does capture mental model              answer, or piece of a solution in the case of the curriculum
representations to some extent, whereas Perfetti (1998) has    script. An LSA analysis was performed on the 2.3 MB
expressed doubts that LSA captures the representations and     corpus of documents, yielding a solution with 200
processes of psychological models. LSA may capture             dimensions.
shallow knowledge rather than deep knowledge. That is,            The 200-dimensional LSA was validated in our
LSA may capture the sort of word associations that are         assessments of AutoTutor (Graesser et al., 2000; Wiemer-
reflected in the archives of dictionaries and encyclopedias,   Hastings et al., 1999). For example, Wiemer-Hastings et al.
but may not penetrate the deeper mental models. On the         (1999) analyzed how well the LSA space on computer
other hand, LSA may be successful in capturing aspects of      literacy could accurately evaluate a sample of 192 answers
the deeper situation model. An accomplished expert on          to the questions in the curriculum script. College students
some topic certainly does know how to use the right bags of    enrolled in the computer literacy course answered the
words at the right time; the systematic use of words in        questions in the curriculum script by typing in their answers
particular documents may be recovered in the LSA solution      into a web cite facility. The data were collected after the
spaces. At this point in the science, however, there is not    college students had read the relevant chapters in the book
enough empirical evidence to support one position or           and had received a lecture on each macrotopic (i.e.,
another.                                                       hardware, operating system, Internet). Trained experts (such
   The present study hopes to shed additional light on what is as graduate research assistants) also rated the 192 answers to
captured by the LSA representations. An LSA space has          the questions. The results of correlational analyses revealed
been developed in the domain of computer literacy. This        that the LSA did an excellent job evaluating the quality of
LSA representation has been used in a fully automated          student answers. The correlation between LSA’s answer
computer tutor, called AutoTutor (Graesser, Franklin,          quality scores and the mean quality scores of the experts was
Wiemer-Hastings, & the TRG, 1998; Graesser et al., in          .49. This correlation is indistinguishable from the .51
press; Graesser et al., 2000; Wiemer-Hastings, Graesser,       correlation between the ratings of the two intermediate
Harter, & the TRG, 1998). In addition to the LSA space,        experts (i.e., the individuals who normally grade exams in a
AutoTutor has dozens of conceptual graph structures that       college computer literacy course). Graesser et al. (2000)
capture knowledge in a more structured form. The present       reported that AutoTutor’s LSA component did an excellent
study examines whether the structural composition of the       job discriminating the ability of learners who interact with
conceptual graph structures can predict the LSA match          AutoTutor in a multi-turn tutorial dialog. LSA was capable
scores. That is, is there a significant correlation between    of discriminating different classes of student ability (good,
structural proximity and LSA match scores when we              vague, erroneous, versus mute students) and in tracking the
examine taxonomic hierarchies, causal networks, and goal       quality of contributions in tutorial dialog.
structures? A positive correlation would support the claim        The LSA space in AutoTutor was adopted in the present
that LSA spaces to some extent recover aspects of the          study. We computed the LSA-match scores between pairs
mental models. A zero correlation supports the claim that      of nodes in the conceptual graph structures that had been
the K dimensional LSA spaces have an unsystematic              prepared for topics on hardware, operating systems, and the
mapping onto structural theories of knowledge                  internet.
representation.
                                                                   Conceptual Graph Structures on Topics in
 Corpus of Texts and LSA Space on Computer                                         Computer Literacy
                         Literacy                              AutoTutor’s architecture includes a set of conceptual graph
A 200-dimensional LSA space was developed for the              structures on the various topics in the curriculum script. A
domain of computer literacy during the development of          typical structure contains approximately 10 to 30 nodes. We
AutoTutor. The corpus of included (a) two books on             randomly selected 12 conceptual graph structures in the
computer literacy, (b) 30 articles that focus on hardware,     present analysis, including 4 structures for hardware, 4 for
operating systems, and the internet, and (c) AutoTutor’s       operating systems, and 4 for the internet.
curriculum script of lessons, example problems + solutions,       The 12 knowledge structures were composed by applying
and questions + answers. An LSA analysis requires the          the conceptual graph structure (CGS) representations
preparation of a document by word (D x W) co-occurrence        developed by Graesser (Graesser & Clark, 1985; Graesser et
matrix. Each cell in the matrix specifies the number of        al., 1992; Graesser, Wiemer-Hastings, & Wiemer-Hastings,
occurrences of word Wi in Document Dj. In order to             in press; Williams, Hultman, & Graesser, 1998). The CGS’s
prepare the DxW matrix, the researcher needs to define what    have 5 node categories: concepts, states, events, goals, and
constitutes a document unit. A single document was defined     style specifications. There are 22 basic arc categories. The
as (a) a paragraph in the case of the textbooks and 30         composition of these conceptual graph structures is not
articles and (b) a sentence that conveys a lesson, a good      arbitrary, but is based on formal and conceptual constraints

                                                                                                                            4
that have been studied for several decades in artificial      The goals are triggered by various events and states in the
intelligence (Lehmann, 1992). The categories of nodes and     world by virtue of Initiate arcs, whereas Outcome arcs
arcs are sufficient for implementing computational models     specify whether or not the goals are achieved.
of question answering which have been validated in
experiments on adults (Baggett & Graesser, 1995; Graesser     Scaling of Pairs of Nodes on Structural Proximity
& Hemphill, 1991; Graesser, Lang, & Roberts, 1991).           Pairs of nodes in the 12 conceptual graph structures were
   Three types of knowledge structures were directly          scaled on structural proximity with respect taxonomic
analyzed in the present study: taxonomic hierarchies, causal  hierarchies, causal networks, and goal structures. A node in
networks, and goal hierarchies. A node was included in the    a structure was included in the analysis if and only if it was
present analysis if and only if it was part of any of these   part of one or more of these three types of structures. When
three types of structures. The composition of these three     considering all 12 conceptual graph structures, there were
types of structures is specified below.                       536 pairs of nodes in the analysis. A pair of nodes (A and
                                                              B) was scaled on causal proximity by computing the
Taxonomic Hierarchies                                         reciprocal of the structural distance on a legal causal path
Concept nodes are connected by is-a arcs. For example, the    between A and B (i.e., 1/distance). Thus, if two nodes have
concepts Norton Antivirus, utility program, and tool would    a structural distance of 1, 2, 3, versus 4 arcs on a legal path,
be connected by two is-a arcs:                                then the causal proximity scores would be 1.00, .50, .33, and
                                                              .25, respectively. If there is no legal causal path that
(concept-1: Norton Antivirus) –isaÅ                           connects A and B, the causal proximity score is 0. Goal
(concept-2: utility program) –isaÅ                            proximity and taxonomic proximity was computed in a
(concept-3: tool)                                             similar fashion for all 536 nodes. The mean proximity
                                                              scores were .07, .31, and .40 for the taxonomic, causal, and
The structure distance is 1 between concepts 1 and 2 and      goal proximity scores, respectively; the corresponding
between concepts 2 and 3; the structural distance is 2        standard deviations were .26, .40, and .45.
between concepts 1 and 3.
                                                                Relationship Between LSA Match Scores and
Causal Networks                                                            Structural Proximity Scores
   State and event nodes are connected by arcs that signify   The analyses uncovered a robust relationship between the
Cause, Enables, Subprocess, and Implies (see Graesser &       LSA match scores and the structural proximity scores.
Clark, 1985 and Graesser, Wiemer-Hastings, & Wiemer-          Consider first the causal proximity scores. The mean LSA
Hastings, in press for more complete definitions of arcs).    match scores were .47, .35, and .24 when the causal
Some of these categories of nodes and arcs are illustrated in proximity scores were 1.00, .50, and .33 or lower (but not
the following chain.                                          0), respectively. When analyzing the goal proximity scores,
                                                              the LSA match scores were .53 and .42 for goal proximity
(state-1: the operating system is stored on the hard disk) –  scores of 1.00 and .50 or lower (but not 0), respectively.
EnableÅ                                                       The taxonomic proximity scores rarely went lower than 1.00
(event-2: the operating system is loaded onto the computer)   when considering nonzero values, so we could not isolate a
–SubprocessÅ                                                  sensitive gradient for this proximity score. The overall
(event-3: the operating system gets into RAM) –CauseÅ         mean LSA match score was .44 (SD = .30).
(event-4: the CPU executes instructions)                         A multiple regression was conducted to assess the extent
                                                              to which the LSA match scores could be predicted by the
The structural distance is 1 between nodes 1&2, 2&3, and      taxonomic, causal, and goal proximity scores. The three
3&4, is 2 between nodes 1&3 and 2&4, and is 3 between         predictor variables together explained a significant 9% of
nodes 1&4.                                                    variance in the LSA match scores, F(3, 532) = 16.46, p <
                                                              .05, R2 = .09. All three predictors had a significant unique
Goal-structures                                               impact on the LSA scores, with beta weights of .14, .31, and
   Goal nodes are connected to other nodes by virtue of arcs  .47 for taxonomic, causal, and goal proximity, respectively.
that signify Reason, Manner, Initiate, and Outcome. For          We performed some follow-up multiple regression
example, the following three goal nodes form a goal           analyses that statistically controlled for some potential
hierarchy via a Reason arc.                                   extraneous variables. One extraneous variable was the
                                                              length of the node descriptions, as defined by the number of
(goal-1: user types in command) –ReasonÅ                      words in the pair of nodes. Those who have conducted
(goal-2: user starts word processing software) –ReasonÅ       research on LSA have reported that lengthier descriptions
(goal-3: user writes article)                                 have a slight tendency to produce higher LSA matches when

                                                                                                                             5
two bags of words are compared (Rheder, Schreiner, Wolfe,                                Conclusions
Laham, Landauer, & Kintsch, 1998; Wiemer-Hastings et al.,
                                                                 The results of this study support the claim that LSA captures
1999). The mean length of the node descriptions in our
                                                                 aspects of the mental models that underlie computer literacy.
sample was 10.62 words in the node pair (SD = 4.03), or
                                                                 The content of the mental models includes taxonomic
5.31 words per node. A second extraneous variable was the
                                                                 structures, causal networks, and goal/plan/action hierarchies.
number of nouns that overlap between the pair of nodes.
                                                                 The LSA match scores between pairs of nodes in the
Overlapping nouns are analogous to argument overlap in
                                                                 conceptual graph structures can be predicted by taxonomic,
propositional theories of text processing (Graesser, Millis, &
                                                                 causal, and goal structural proximity. The structural
Zwaan, 1997; Kintsch, 1998); the fact that constituents refer
                                                                 proximity scores predict LSA match scores over and above
to the same entity is one important foundation for coherence
                                                                 noun overlap, keyword overlap, and the number of words in
in discourse processing. However, from the standpoint of
                                                                 the node descriptions.
the present analyses, we would not be particularly surprised
                                                                    Aside from demonstrating that LSA captures aspects of
if the LSA match scores could be explained by mere noun
                                                                 mental models, we have demonstrated that LSA can be
overlap because it is analogous to a keyword overlap. The
                                                                 useful for performing semantic and conceptual analyses on
mean number of overlapping nouns in a node pair was .71
                                                                 relatively short verbal descriptions. Researchers have
(DS = .67).
                                                                 sometimes claimed that LSA is only useful when analyzing
   Table 1 presents the results of the multiple regression
                                                                 lengthier verbal descriptions on the order of a paragraph.
analysis that predicted LSA match scores as a function of the
                                                                 The present study supports the claim that LSA can be useful
three structural proximity scores, length, and noun overlap.
                                                                 for compositional analyses on individual words and short
The five predictor variables accounted for a significant 55%
                                                                 sentences of 5-6 words. Additional research is needed to
of the variance in LSA match scores, , F(5, 530) = 128.05, p
                                                                 identify the limits of LSA in recovering different aspects of
< .05, R2 = .55. When considering the two extraneous
                                                                 semantics and world knowledge.
variables, noun overlap had a robust impact on the LSA
match scores whereas length had no significant effect.
Although noun overlap was robust, the three structural                              Acknowledgements
proximity variables still had a significant unique impact on     This research was funded by the National Science
the LSA match scores in the multiple regression analyses.        Foundation (SBR 9720314) in a grant awarded to the first
Interestingly, we did not find the noun overlap scores to be     author of this manuscript. The following members of the
correlated very highly with the taxonomic, causal, and goal      Tutoring Research Group at the University of Memphis
proximity scores, r = -.18, .25, and -.02, respectively.         conducted research on this project: Ashraf Anwar, Laura
Overlap in predicates was also analyzed but the correlations     Bautista, Myles Bogner, Tim Brogdon, Patrick Chipman,
were also modest or nonsignificant. These results support        Scotty Craig, Rachel DiPaolo, Evan Drumwright, Stan
the claim that the structural proximity scores have an impact    Franklin, Max Garzon, Barry Gholson, Art Graesser, Doug
on LSA match scores over and above keyword matches.              Hacker, Peggy Halde, Derek Harter, Jim Hoeffner, Xiangen
                                                                 Hu, Jeff Janover, Ashish Karnavat, Bianca Klettke, Roger
Table 1: Multiple regression analyses that predict LSA           Kreuz, Kristen Link, Shulan Lu, Johanna Marineau, William
match scores                                                     Marks, Lee McCaulley, Brent Olde, Para Orfanides, Natalie
                                                                 Person, Victoria Pomeroy, Penelope Price, Sonya Rajan,
---------------------------------------------------------------- Akshay Thota, Mat Weeks, Holly Yetman White, Shannon
Predictor Variable               beta-weight            t-score  Whitten, Katja Wiemer-Hastings, Peter Wiemer-Hastings,
---------------------------------------------------------------- Shonijie Yang, and Zhaohua Zhang.
Taxonomic proximity               .14                     4.08 *
Causal proximity                  .11                     2.17 *                         References
Goal proximity                    .15                     2.94 *
Length (number of words) -.02                              .75   Baggett, W.B., & Graesser, A.C. (1995).              Question
Noun overlap                      .72                   23.20 *     answering in the context of illustrated expository text.
---------------------------------------------------------------     Proceedings of the 17th Annual Conference of the
* significant at p < .05.                                           Cognitive Science Society (pp. 334-339). Hillsdale, NJ:
                                                                    Lawrence Erlbaum.
                                                                 Burgess, C., Livesay, K., & Lund, K. (1998). Exploring
                                                                    context space: Words, sentences, discourse. Discourse
                                                                    Processes, 25, 211-257.
                                                                 Charniak, E. (1993).         Statistical language analysis.
                                                                    Cambridge, MA: Cambridge University Press.

                                                                                                                            6
Chi, M.T.H., Slotta, J.D., & de Leeuw, N. (1994). From        Kintsch, E., Kintsch, W., Laham, D., Landauer, T.K.,
  things to processes: A theory of conceptual change for        DePaula, R., Schreiner, M.E., Stahl, G., & Steinhart, D.
  learning science concepts. Learning and Instruction, 4,       (2000). Learning how to summarize using LSA-based
  27-43.                                                        feedback. Interactive Learning Environments.
Foltz, P.W. (1996). Latent semantic analysis for text-based   Kintsch, W. (1998). Comprehension: A paradigm for
  research. Behavior Research Methods, Instruments, and         cognition. Cambridge, MA: Cambridge University Press.
  Computers, 28, 197-202.                                     Landauer, T.K., & Dumais, S.T. (1997). A solution to
Foltz, PW., Britt, M.A., & Perfetti, C.A. (1996). Reasoning     Plato’s problem: The latent semantic analysis theory of
  from multiple texts: An automatic analysis of readers’        acquisition, induction, and representation of knowledge.
  situation models. In G. Cottrell (Ed.), Proceedings of the    Psychological Review, 104, 211-240.
  18th Annual Cognitive Science Conference (pp. 110-115).     Landauer, T.K., Foltz, P.W., Laham, D. (1998). An
  Mahwah, NJ: Erlbaum.                                          introduction to latent semantic analysis.          Discourse
Forbus, K., Gentner, D., & Law, K. (1995). MAC/FAC: A           Processes, 25, 259-284.
  model of similarity-based retrieval. Cognitive Science,     Lehmann, F. (1992)(Eds.). Semantic networks in artificial
  19, 141-205.                                                  intelligence. New York: Pergamon.
Golden, R.M. (1997). Causal network analysis validation       Lenat, D.B. (1995). CYC: A large-scale investment in
  using synthetic recall protocols. Behavior Research           knowledge infrastructure. Communications of the ACM,
  Methods, Instruments, and Computers, 29, 15-24.               38, 33-38.
Graesser, A.C., & Clark, L.C. (1985). Structures and          Miller, G.A., & Johnson-Laird, P.N. (1976). Language and
  procedures of implicit knowledge. Norwood, NJ: Ablex.         perception. Cambridge, MA: Harvard University Press.
Graesser, A.C., Franklin, S., & Wiemer-Hastings, P. and the   Norman, D.A., & Rumelhart, D.E. (1975). Explorations in
  TRG (1998). Simulating smooth tutorial dialog with            cognition. San Francisco, CA: Freeman.
  pedagogical value.       Proceedings of the American        Perfetti, C.A. (1998). The limits of cooccurrence: Tools and
  Association for Artificial Intelligence (pp. 163-167).        theories in language research. Discourse Processes, 25,
  Menlo Park, CA: AAAI Press.                                   363-377.
Graesser, A. C., Gordon, S. E., & Brainerd, L. E. (1992).     Rheder, B., Schreiner, M.E., Wolfe, M.B.W., Laham, D.,
  QUEST: A model of question answering. Computers and           Landauer, T.K., & Kintsch, W. (1998). Using latent
  Mathematics with Applications, 23, 733-745.                   semantic analysis to assess knowledge: Some technical
Graesser, A. C. & Hemphill, D. (1991). Question                 considerations. Discourse Processes, 25, 337-354.
  answering in the context of scientific mechanisms.          Schank, R.C., & Abelson, R. (1977). Scripts, plans, goals,
  Journal of Memory and Language, 30, 186-209.                  and understanding. Hillsdale, NJ: Erlbaum.
Graesser, A. C., Lang, K. L., & Roberts, R. M. (1991).        Sowa, J.F. (1983). Conceptual structures: Information
  Question answering in the context of stories. Journal of      processing in mind and machine.             Reading, MA:
  Experimental Psychology: General, 120, 254-277.               Addison-Wesley.
Graesser, A.C., Millis, K.K., & Zwaan, R.A. (1997).           Trabasso, T., van den Broek, P.W. & Suh, S. (1989).
  Discourse comprehension. Annual Review of Psychology,         Logical necessity and transitivity of causal relations in the
  48, 163-189.                                                  representation of stories. Discourse Processes, 12, 1-25.
Graesser, A.C., Wiemer-Hastings, P., & Wiemer-Hastings,       Wiemer-Hastings, P., Graesser, A.C., Harter, D., and the
  K. (in press). Constructing inferences and relations during   TRG (1998). The foundations and architecture of
  text comprehension. In T.Sanders, J. Schilperoord, & W.       AutoTutor.      Proceedings of the 4th International
  Spooren (Eds.), Text representation: Linguistic and           Conference on Intelligent Tutoring Systems (pp. 334-
  psycholinguistic aspects. Amsterdam: Benjamins.               343). Berlin, Germany: Springer-Verlag.
Graesser, A.C., Wiemer-Hastings, K., Wiemer-Hastings, P.,     Wiemer-Hastings, P., Wiemer-Hastings, K., and Graesser,
  Kreuz, R., and the TRG (in press). AutoTutor: A               A. (1999). Improving an intelligent tutor's comprehension
  simulation of a human tutor. Journal of Cognitive             of students with Latent Semantic Analysis. Artificial
  Systems Research.                                             Intelligence in Education (pp. 535-542). Amsterdam:
Graesser, A.C., Wiemer-Hastings, P., Wiemer-Hastings, K.,       IOS Press.
  Harter, D., Person, N., and the TRG (2000). Using latent    Williams, K.E., Hultman, E., & Graesser, A.C. (1998).
  semantic analysis to evaluate the contributions of students   CAT: A tool for eliciting knowledge on how to perform
  in AutoTutor. Interactive Learning Environments.              procedures. Behavior Research Methods, Instruments, &
Kiel, F.C. (1979). Semantic and ontological development:        Computers, 30,565-572.
  An ontological perspective. Cambridge, MA: Harvard          Wolfe, M.B.W., Schreiner, M.E., Rehder, B., Laham, D.,
  University Press.                                             Foltz, P.W., Kintsch, W., Landauer, T.K. (1998).
                                                                Learning from text: Matching readers and texts by latent
                                                                semantic analysis. Discourse Processes, 25, 309-336.

