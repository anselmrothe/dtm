UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Six-Unit Network is All You Need to Discover Happiness
Permalink
https://escholarship.org/uc/item/3j28p6z3
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Authors
Dailey, Matthew N.
Cottrell, Garrison W.
Adolphs, Ralph
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            A Six-Unit Network is All You Need to Discover Happiness
          Matthew N. Dailey Garrison W. Cottrell                             Ralph Adolphs
                     fmdailey,garyg@cs.ucsd.edu                        ralph-adolphs@uiowa.edu
              UCSD Computer Science and Engineering            University of Iowa Department of Neurology
           9500 Gilman Dr., La Jolla, CA 92093-0114 USA        220 Hawkins Dr., Iowa City, IA 52242 USA
                            Abstract                          show \categorical perception" of facial expressions (Et-
   In this paper, we build upon previous results to show      co and Magee, 1992; Young et al., 1997). Categorical
   that our facial expression recognition system, an ex-      perception is a discontinuity characterized by sharp per-
   tremely simple neural network containing six units,        ceptual category boundaries and better discrimination
   trained by backpropagation, is a surprisingly good com-    near those boundaries, as in the bands of color in a rain-
   putational model that obtains a natural t to human         bow. But as research in the classi cation literature has
   data from experiments that utilize a forced-choice clas-   shown (e.g. Ellison and Massaro, 1997), seemingly cate-
   si cation paradigm. The model begins by computing a        gorical e ects naturally arise when an observer is asked
   biologically plausible representation of its input, which
   is a static image of an actor portraying a prototypical    to employ a decision criterion based on continuous infor-
   expression of either Happiness, Sadness, Fear, Anger,      mation. Neural networks also possess this dual nature;
   Surprise, Disgust, or Neutrality. This representation of   many networks trained at classi cation tasks map con-
   the input is fed to a single-layer neural network contain- tinuous input features into a continuous output space,
   ing six units, one for each non-neutral facial expression.
   Once trained, the network's response to face stimuli can   but when we apply a decision criterion (such as \choose
   be subjected to a variety of \cognitive" measures and      the biggest output") we may obtain the appearance of
   compared to human performance in analogous tasks. In       sharp category boundaries and high discrimination near
   some cases, the t is even better than one might expect     those boundaries, as in categorical perception.
   from an impoverished network that has no knowledge            Our model, which combines a biologically plausible
   of culture or social interaction. The results provide in-
   sights into some of the perceptual mechanisms that may     input representation with a simple form of categoriza-
   underlie human social behavior, and we suggest that the    tion (a six-unit softmax neural network), is able to ac-
   system is a good model for one of the ways in which the    count for several types of data from human forced-choice
   brain utilizes information in the early visual system to   expression recognition experiments. Though we would
   help guide high-level decisions.
                                                              not actually propose a localist representation of the fa-
                                                              cial expression category decision (we of course imagine a
                       Introduction                           more distributed representation), the evidence leads us
In this paper, we report on recent progress in under-         to propose 1) that the model's input representation bears
standing human facial expression perception via compu-        a close relationship to the representation employed by
tational modeling. Our research has resulted in a facial      the human visual system for the expression recognition
expression recognition system that is capable of discrimi-    task, and 2) that a dual continuous/categorical model,
nating prototypical displays of Happiness, Sadness, Fear,     in which a continuous representation of facial expres-
Anger, Surprise, and Disgust at roughly the level of an       sions coexists with a discrete decision process (either of
untrained human. We propose that the system provides          which could be tapped by appropriate tasks), may be a
a good model of the perceptual mechanisms and deci-           more appropriate way to frame human facial expression
sion making processes involved in a human's ability to        recognition than either a strictly categorical or strictly
perform forced-choice identi cation of the same facial        continuous model.
expressions. The present series of experiments provides
signi cant evidence for this claim.                               The Expression Classi cation Model
   One of the ongoing debates in the psychological lit-       For an overview of our computational model, refer to
erature on emotion centers on the structure of emotion        Figure 1. The system takes a grayscale image as input,
space. On one view, there is a set of discrete basic emo-     computes responses to a lattice of localized, oriented
tions that are fundamentally di erent in terms of phys-       spatial lters (Gabor lters) and reduces the resulting
iology, means of appraisal, typical behavioral response,      high dimensional input by unsupervised dimensionality
etc. (Ekman, 1999). Facial expressions, according to this     reduction (Principal Components Analysis). The result-
categorical view, are universal signals of these basic emo-   ing low-dimensional representation is then fed to a single-
tions. Another prominent view is that emotion concepts        layer neural network with six softmax units (whose sum
are best thought of as prototypes in a continuous, low-       is constrained to be 1.0), each corresponding to one ex-
dimensional space of possible emotional states, and that      pression category. We now describe each of the compo-
facial expressions are mere clues that allow an observer      nents of the model in more detail.
to locate an approximate region in this space (e.g. Rus-
sell, 1980; Carroll and Russell, 1996).                       The Training Set: Pictures of Facial A ect
   One type of evidence sometimes taken as support for        The model's training set is Ekman and Friesen's Pictures
categorical theories of emotion involves experiments that     of Facial A ect (POFA, 1976). This database is a good

                                      .                                          the problem that most of an image's power lies in lower
                                      .
                                      .                                          spatial frequency ranges, without destroying information
                                                                                 possibly present in the relative magnitude of response at
                                                                                 each orientation. Since even the smallest lters in our
                                      .
                                      .                                          representation overlap with their neighbors, and Gabor
                                      .                      Six-way Forced      magnitudes are mildly invariant to slight translation, we
                                                           Choice Classification
                                                                                 lose very little of the information in the higher spatial fre-
                                                                       Happy     quency ranges, with a small price paid (due to ignoring
                                                                                 phase information) in loss of precise feature localization
                                      .
                                      .       P                        Sad
                                                                                 and a larger price paid in that the resulting representa-
                                      .
                                              C                        Afraid
                                              A
                                                                       Angry     tion is very high dimensional (41,760 elements).
                                      .
                                      .
                                                                       Surprised
                                                                                 Evaluation of the representation In this section,
                                                                                 we examine the representation's utility and plausibility.
                                      .                                Disgusted
                                                                                    Donato et al. (1999) found that a nearest neighbor
                                      .                                          classi er with a cosine similarity metric applied directly
                                                                                 to a Gabor grid-based representation achieved 95.5%
                                      .               Low
                                      .        Dimensional
                                                                                 correct classi cation of image sequences containing in-
                                                                                 dividual facial actions (Ekman and Friesen, 1978), e.g.
   Spatial Filtering with Gabor Jets High
                                     Dimensional
                                                                                 facial action 1, the inner brow raiser. We evaluated this
    Figure 1: Facial Expression Classi cation Model.                             type of classi er on our task, classi cation of full-face
                                                                                 expressions in static images. Nearest neighbor classi ca-
                                                                                 tion of the 96 expressive faces in POFA using leave-one-
training set because the face images are reliably identi-                        actor-out cross validation and a cosine similarity metric
  ed as expressing the given emotion by human subjects                           achieves an expected generalization accuracy of 74.0%.
(at least 70% agreement), and the images are commonly                            There are several possible reasons for this sub-par per-
used in psychological experiments. We digitized the 110                          formance: the need to simultaneously integrate informa-
POFA slides by scanning them at 520x800 pixels, per-                             tion from multiple facial actions, the small size of the
forming a histogram equalization, aligning the eyes and                          POFA database, and/or the lack of information on the
mouths to the same location in every image by a lin-                             dynamics of facial movement. But the simple system's
ear transformation, and cropping o most of the back-                             performance is well above chance (16.7% correct), giving
ground. The result is a set of 110 240x320 grayscale                             an indication that a more complicated (and more psy-
images of 14 actors portraying prototypical expressions                          chologically plausible) model such as a neural network
of six basic emotions and neutral.                                               could do much better.
                                                                                    One way of visualizing the e ectiveness of a represen-
Feature Extraction: The Gabor Jet Lattice                                        tation, and gaining insight into how an agent might use
The system represents input stimuli using a lattice of re-                       the representation to support decision-making, is to ap-
sponses of 2-D Gabor wavelet lters (Daugman, 1985).                              ply discriminant analysis.1 For the Gabor magnitude
The Gabor lter, essentially a sinusoidal grating local-                          components at a given location and spatial frequency,
ized by a Gaussian envelope, is a good model of sim-                             we nd Fisher's Linear Discriminant (Bishop, 1995), the
ple cell receptive elds in cat striate cortex (Jones and                         projection axis w~ that maximizes the criterion J (w~ ), the
Palmer, 1987). It provides an excellent basis for recog-                         ratio of between-class to within-class scatter along w~ .
nition of facial identity (Wiskott et al., 1997), individual                     J (w~ ) is a measure (invariant to linear transformations)
facial actions (Donato et al., 1999), and facial expres-                         of the diagnosticity of that portion of the representation
sions (Dailey and Cottrell, 1999; Lyons et al., 1999). We                        for determining the class of the stimulus. That is, we
use phase-invariant Gabor magnitudes with a parame-                              can determine exactly how well (in the linear sense) the
terization of the lter at ve scales ranging from 16{96                           representation separates individual facial expressions.
pixels in width and eight orientations ranging from 0                               We applied this method to the 85 expressive faces of
to 78 as described by Donato et al. (1999). Thus, at                            a 12-actor subset of the POFA database The results for
each point in the lattice (in our representation a 29  36                       Fear, the most dicult to recognize expression in POFA
grid of lter locations placed at regular 8-pixel intervals                       (for both humans and machines), are shown in Figure 2.
over the face), we extract a 40-element vector of Gabor                          The size of the dots placed over each grid location in the
magnitudes (sometimes called a \jet") that character-                            face is proportional to how easy it is to separate Fear
izes a localized region of the face. A few of the lters                          from all of the other expressions based on the 8 Gabor
are displayed graphically in Figure 1. To extract the                              lter responses extracted at that position of the grid.
29  36  40 = 41; 760 lter responses, we rst convolve                           There are two interesting aspects to the result. First,
the entire image with each lter and take the magnitude                           the lowest spatial frequency channel (using lters about
of each complex valued response. We then (globally) di-                              1
                                                                                       We introduced this visualization method for the Gabor
visively normalize the vector of responses at each lter                          representation in a recent technical report (Dailey and Cot-
scale to unit length. By equalizing the contribution of                          trell, 1999), and Lyons et al. (1999) have independently in-
each lter size to the nal representation, we overcome                            troduced a similar technique.

                                                                               P a weighted sum of the input pat-
                                                            putes its net input,
                                                            ter ~x: ai P= bi + j wij xj . Then the softmax function
                                                            yi = ea = k ea is applied to the net inputs to produce
                                                                    i        k
                                                            a 6-element output vector ~y. The network is trained
                                                            with the relative entropy error function (Bishop, 1995).
                                                            Since the outputs of this network must sum to 1.0, we
          Scale 1          Scale 2         Scale 3          use a constant target vector of ( 16 ; 16 ; 61 ; 16 ; 16 ; 16 )T for the
                                                            neutral training stimuli.
                                                               With no hidden layer and just 35 elements in its input,
                                                            the network is very small, but its number of parameters,
                                                            216, is still large compared to the number of training
                                                            examples (88-99). Therefore, we must avoid overtrain-
                                                            ing the network; we have found that too-fast optimiza-
                                                            tion techniques lead to poor generalization. We have
                  Scale 4          Scale 5                  obtained the best results using stochastic gradient, mo-
                                                            mentum, weight decay, and early stopping using a hold-
Figure 2: Diagnosticity of Gabor lter locations for         out set. For the experiments reported here, we used a
Fear discrimination, separated by lter spatial frequency,   learning rate  = 0:0017 (the number of units divided by
from scale 1 (highest SF) to scale 5 (lowest).              the number of inputs times 0.01), a momentum = 0:9,
                                                            and weight decay rate  = 0:01.
                                                               The early stopping technique bears some explanation.
96 pixels in width, compared to the total image width of    We obtain expected generalization results by leave-one-
240) is best for this expression, implying that improve-    actor-out cross validation. For POFA, this means a net-
ment might be obtained by dropping the smaller scales       work is trained on the images of 13 actors and tested on
from the representation and even increasing the lter        generalization to the 14th. Rather than training on the
size. Second, the technique hints at which facial actions   full 13 actors, we leave one out as a holdout set to help
are most reliable for distinguishing expressions from one   determine when to stop training. After each epoch of
another, readily making predictions for psychological ex-   training on the remaining 12 actors' faces, we test the
periments. According to Ekman and Friesen (1978), pro-      network's performance on the 13th actor (the holdout
totypical displays of Fear include facial action 1 (inner   set). If classi cation accuracy on the holdout set has not
brow raise), 2 (outer brow raise), 4 (scrunching together   improved in 6 epochs, we stop training and restore the
of the eyebrows), and 5 (upper eyelid raise) in the upper   weights from the best epoch. Training time under this
face, along with 25 (lips part) and some combination of     paradigm varies greatly; it ranges anywhere from 60 to
20 (lip stretch), 26 (jaw drop), or 27 (mouth stretch) in   300 epochs depending on which partition into training,
the lower face. Although some discriminability can be       holdout, and test set is used.
obtained in the higher spatial frequencies in the region of
the mouth (presumably detecting facial action 25), our      Evaluation of the Network's Performance
model nds that the best regions are in the lower spatial    How does the network perform the expression recogni-
frequencies around the eyes, especially around the upper    tion task? An examination of the trained network's rep-
eyelids.                                                    resentation provides some insight. The idea is to project
Principal Components Analysis for                           each unit's weight vector back into image space in order
                                                            to visualize what the network is sensitive to in an image.
Dimensionality Reduction                                    But this is not a trivial task; though PCA is linear and
We use Principal Components Analysis (PCA) as a sim-        easily inverted, the Gabor magnitude representation, be-
ple, unsupervised, linear method to reduce the dimen-       sides being subsampled, throws away important phase
sionality of the network's input patterns by projecting     information. Normalization of the power in each spatial
each 41,760-element pattern onto the top k eigenvectors     frequency channel could also be problematic for inver-
of the training set's covariance matrix. This speeds up     sion. Current techniques for inverting Gabor magnitude
classi er training and improves generalization. We ex-      representations (C. von der Malsburg, personal commu-
perimented with various values of k and achieved the        nication) are computationally intensive and make several
best generalization results with k = 35, so in all exper-   assumptions that do not apply here. So we instead take
iments reported here we project training and test pat-      a simpler approach: learning the function from the 35-
terns onto the top 35 principal component eigenvectors      element input space into facial image space with linear
of the training set, then use the standard technique of     regression, then using the regression formula to produce
\z-scoring" each input to a mean of 0 and a standard        an image that visualizes each network unit's weight vec-
deviation of 1.0 (Bishop, 1995).                            tor.
                                                               The results for one network trained on an arbitrary
Classi cation by a Six Unit Network                         12-actor subset of POFA are shown in Figure 3. In each
The classi cation portion of the model is a six-unit        image, each pixel value is the result of applying the re-
neural network. Each unit in the network rst com-           gression formula predicting the value of the pixel at that

                                                            show the same rank order We have also found that it
                                                            is possible to boost classi er accuracy on this task if
                                                            the classi er is given the opportunity to \peek" at the
                                                            test set (without labels) before actually classifying it.
  Happy      Sad      Afraid Angry Surpr.           Disg.   This \batch mode" classi cation technique is a plausible
                                                            model for familiarizing subjects with the stimuli in an
Figure 3: Images reconstructed by linear regression from    experiment prior to testing them. It boosts classi er ac-
a trained network's weight vectors.                         curacy to up to 95%; details are available in a technical
                                                            report (Dailey and Cottrell, 1999).
location as a linear function of the 35-element weight vec- Visualization with Multidimensional Scaling
tor for the given network output unit. Dark and bright      Multidimensional Scaling (MDS) is a frequently-
spots indicate the features that excite or inhibit a given  used technique for visualizing relationships in high-
output unit depending on the relative gray values in the    dimensional data. It aims to embed stimuli in a low di-
region of that feature. Note that the representations are   mensional space (usually two or three dimensions) while
very much like one might predict given the linear dis-      preserving, as best possible, observed distances or sim-
criminant analysis described earlier: each unit combines    ilarities between each pair of stimuli. MDS has long
evidence based upon the presence or absence of a few        been used as a tool for exploring the psychological struc-
local features; for Fear, the salient criteria appear to be ture of emotion. Russell has proposed a \circumplex"
the eyebrow raise and the eyelid raise, with a smaller      model of a ect (Russell, 1980) that describes the range
contribution of parted lips.                                of human a ective states along two axes, pleasure and
   An important factor not shown in Figure 3 is the ef-     arousal. Russell and colleagues have found support for
fect output units have on each other. Due to the di-        their theory in a wide range of studies for which MDS
visive normalization of the softmax function, an active     consistently yields two-dimensional solutions whose axes
output unit can e ectively inhibit other units that are     resemble pleasure and arousal.
only mildly activated. Nevertheless, it seems clear from       A similar technique can be applied to Ekman and
the reconstructions that the network's e ective strategy    Friesen's forced-choice data. We computed a 96  96 Eu-
is to learn how the combination of facial actions involved  clidean distance matrix from the 6-dimensional response
in each prototypical expression can be reliably detected    vectors supplied by Ekman and Friesen and used non-
in a static image. We hypothesize that, when faced with     metric MDS2 to nd a 2-dimensional con guration of
a forced choice expression recognition task, humans must    the 96 stimuli. This con guration, shown in the rst
use similar representations and classi cation strategies.   graph of Figure 4, yielded a Kruskal stress S = 0:205.
In the next two sections, we provide some indirect sup-     The circumplex embedded in Ekman and Friesen's data,
port for this hypothesis with both qualitative and quan-    Happiness { Surprise { Fear { Sadness { Anger { Disgust,
titative comparisons between the model's performance        or HSFMAD (using M for Maudlin in place of Sadness
and human performance on the same stimuli.                  to distinguish it from Surprise), is di erent from that
   Modeling Forced-Choice Classi cation                     typically reported by Russell and colleagues. This is
                                                            not surprising, however, because a large portion of Rus-
Ekman and Friesen (1976) presented subjects with the        sell's circumplex (a ective states that are negative on the
task of 6-way forced choice classi cation of the expressive arousal dimension and positive or neutral on the pleasure
stimuli in POFA and provide the results of their exper-     dimension, such as sleepiness, content, and relaxation) is
iment with the dataset. Their criterion for admission       simply not represented in POFA. The HSFMAD circum-
into the nal database was that at least 70% of subjects     plex is the same, however, reported by Katsikitis (1997),
should agree on each face's classi cation into one of the   who used the same set of expressions, a similar forced-
six POFA expression categories. On average, the pro-        choice arrangement, but an entirely di erent set of pho-
portion of agreement (or chance of correct classi cation)   tographs in which the actors were not instructed on how
was 91.7%.                                                  to portray each expression.
Classi cation accuracy comparison                              Does the facial expression similarity structure induced
                                                            by the network resemble the human psychological sim-
We trained 14  13 = 182 networks, one for each of the      ilarity structure in any way? We have performed MDS
possible partitions of the database into a training set of  analyses at three levels in this network: at the input layer
12 actors, a holdout set of one actor, and a test set of    (on the Gabor/PCA representation), at the net inputs
one actor. After training using the method described        to the network's output units (the units' un-softmaxed
earlier, we tested each network's classi cation accuracy    activations ai ), and at the softmax output layer. As
on its generalization (test) set and averaged their per-    one might expect, at the input layer, the patterns form
formance. The 182 networks, on average, obtain a clas-
si cation accuracy of 85.9% (compared to a human ac-            2
                                                                  There are many varieties of MDS; we implemented the
curacy of 91.7%), and interestingly, the rank order of      Guttman-Lingoes SSA-1 algorithm as described in Borg and
expression category diculty, Happy { Disgusted { Sur-      Lingoes (1987). Put brie y, the algorithm iteratively derives
                                                            a con guration X that minimizes Kruskal's stress S , which
prised { Sad { Angry { Afraid, is identical to that of the  is the proportion of variance in a monotonic regression unex-
humans. We also nd that the humans and networks             plained by X.

                   0.6
                            Derived MDS Configuration, Human Data
                                                                       Happiness
                                                                       Sadness
                                                                       Fear
                                                                       Anger
                                                                                                            0.3
                                                                                                            0.2
                                                                                                                  Derived MDS Configuration, Network Linear Activations
                                                                                                                                                              Happiness
                                                                                                                                                                                             Modeling Perception of Morphs
                                                                                                                                                              Sadness
                   0.4                                                 Surprise
                                                                                                                                                                                     Beyond the forced-choice classi cation data provided by
                                                                                                                                                              Fear
                                                                       Disgust                                                                                Anger
                                                                                                                                                              Surprise
                                                                                                            0.1                                               Disgust
                                                                                                                                                                                     Ekman and Friesen, the literature on categorical percep-
                   0.2
MDS Dimension 2                                                                          MDS Dimension 2
                                                                                                             0
                                                                                                                                                                                     tion of facial expressions transitions is a treasure trove
                    0
                                                                                                           âˆ’0.1
                  âˆ’0.2
                                                                                                           âˆ’0.2                                                                      of data for modeling. Previous work (Padgett and Cot-
                  âˆ’0.4
                                                                                                                                                              Stress = 0.231
                                                                                                                                                                                     trell, 1998) compared a somewhat di erent facial ex-
                                                                                                                                                                                     pression recognition model to human behavior in a large
                                                                                                           âˆ’0.3
                                                                 Stress = 0.205
                                                                                                                                                                                     study by Young et al. (1997) (henceforth referred to as
                  âˆ’0.6                                                                                     âˆ’0.4
                    âˆ’0.8   âˆ’0.6   âˆ’0.4    âˆ’0.2      0      0.2      0.4            0.6                                âˆ’0.2   âˆ’0.1    0     0.1    0.2   0.3          0.4       0.5
                                         MDS Dimension 1                                                                             MDS Dimension 1
Figure 4: MDS con gurations derived from human                                                                                                                                       \Megamix"). In the Megamix study, the researchers cre-
                                                                                                                                                                                     ated morph stimuli interpolating each of the 21 possi-
classi cation data and the linear activations of the                                                                                                                                 ble transitions between six expressive images and one
units in the network model. The circumplex (order of                                                                                                                                 neutral image of POFA actor \JJ." They then tested
stimuli around the graph) is the same: H-S-F-M-A-D                                                                                                                                   subjects on forced-choice identi cation of the perceived
(M=Maudlin/Sadness).                                                                                                                                                                 expression in the morphs (they also measured response
                                                                                                                                                                                     times, discrimination, and the subjects' ability to detect
                                                                                                                                                                                     mixed-in expressions in the morph stimuli). Padgett and
a cloud in the plane with little structure. At the net-                                                                                                                              Cottrell (1998) simulated the Megamix morph stimuli
work's output, the responses on the training set tend                                                                                                                                with dissolves, or linear combinations of each source im-
to be so nearly binary that there is very little similar-                                                                                                                            age and target image. Their linear feature extraction
ity structure. But using the net inputs to the softmax                                                                                                                               technique (projection of eye and mouth regions onto a
units, averaged over all 182 networks, we obtain a solu-                                                                                                                             Local PCA basis) and neural network classi er applied
tion (stress = 0:231) that orders the expressions in the                                                                                                                             to the linear dissolves produced good results. However,
same way as the human circumplex, as shown in the                                                                                                                                    when we created true morphs and attempted to apply
second graph of Figure 4.                                                                                                                                                            the same techniques, we found that the model no longer
   With the caveat that this only occurs in the linear part                                                                                                                            t the human data | there were large intrusions of un-
of the network, the fact that the human and network                                                                                                                                  related expressions along the morph transitions, indicat-
MDS solutions contain the same ordering is striking. It                                                                                                                              ing that linear feature extraction is unable to produce a
is very unlikely (p = 0:017 for a single trial and p = 0:033                                                                                                                         smooth response to nonlinear changes in the image. One
for two trials) that we would obtain the same ordering if                                                                                                                            might expect that the Gabor magnitude representation,
the human and network similarity structure were in fact                                                                                                                              with its built-in invariance to phase, might better cap-
unrelated.                                                                                                                                                                           ture the smooth, categorical transitions observed in the
Correlation of network and human errors                                                                                                                                              Megamix study on nonlinear morphs. In this section,
                                                                                                                                                                                     we very brie y show that this is indeed the case: the
MDS analysis is useful as a visualization tool, but the                                                                                                                              Gabor/PCA-based model does produce smooth transi-
correspondence between the human circumplex and net-                                                                                                                                 tions between expression categories without intrusions
work circumplex is not a formal test of the model. Is the                                                                                                                            and a very good t to the human identi cation data
correspondence between the human and network MDS                                                                                                                                     without any free parameters.
solutions simply a fortuitous coincidence? One way to
address this concern is with a direct comparison of the                                                                                                                              Network training
confusion matrices for the humans and networks. For the
humans and networks, we computed the 6  6 confusion
matrix whose ij -th entry gives the probability that when                                                                                                                            We used a slightly di erent methodology for modeling
a face from class i is present, the humans or networks                                                                                                                               this data because we wanted to model each human sub-
(on the training set) respond with expression j . Since                                                                                                                              ject with one trained network. This requires as much
the network was explicitly trained to produce label i for                                                                                                                            between-subject variability as possible (although vari-
members of class i, we removed the diagonal elements                                                                                                                                 ability is dicult to achieve given POFA's small size).
from each confusion matrix and compared the network                                                                                                                                  We trained 50 networks on di erent random partitions
and human error patterns, i.e. the 30 o -diagonal terms                                                                                                                              of the 13 non-JJ actors' images into training and holdout
of the confusion matrices. Note that it is not \cheat-                                                                                                                               sets. Each network's training set consisted of 7 examples
ing" to use the network's responses on the training set                                                                                                                              of each expression plus neutrality, with the remaining
here; the network was never biased in any way to make                                                                                                                                data used as a holdout set. As before, neutral stimuli
errors similar to humans. We found that the correlation                                                                                                                              were assigned the uniform target vector [ 16 ; 16 ; 61 ; 16 ; 16 ; 16 ]T
between the o -diagonal elements of the confusion matri-                                                                                                                             and the expressive faces were assigned binary target vec-
ces for the humans and networks is r = 0:567. An F -test                                                                                                                             tors.
(F (1; 28) = 13:3; p = 0:0011) con rms the signi cance of                                                                                                                               After training each network until holdout set classi -
this result. These results lead us to claim that much                                                                                                                                cation error was minimized, we tested its performance on
of the facial expression similarity structure observable                                                                                                                             JJ's prototypes as well as all morphs between them. We
in forced-choice experiments is due to direct perceptual                                                                                                                             then extracted identi cation, response time, discrimina-
similarity, and that our model does an excellent job of                                                                                                                              tion, and faint morph detection response variables from
capturing that structure.                                                                                                                                                            the model.

                                                                                                                                                                                                tion to make), we suggest that the model captures the
                    1.0
                    0.8
                                                                                                                                                                                    Happiness
                                                                                                                                                                                                essentials of the visual processing used to make many
 % identification
                                                                                                                                                                                                social judgments.
                                                                                                                                                                                    Surprise
                    0.6                                                                                                                                                             Fear
                                                                                                                                                                                    Sadness
                                                                                                                                                                                    Disgust
                                                                                                                                                                                                                Acknowledgments
                    0.4
                                                                                                                                                                                    Anger
                                                                                                                                                                                    Neutral
                    0.2
                    0.0
                                                                                                                                                                                                We thank Gary's Unbelievable Research Unit (GURU)
                                                                                                                                                                                                for valuable comments on this research, Curtis Padgett
                          H 10   30   50   70   90 S 10   30   50   70   90 F 10   30   50   70   90 M 10   30   50   70   90 D 10   30   50   70   90 A 10   30   50   70   90 H
                                                                                        Human data
                    1.0
                                                                                                                                                                                                for laying the foundation for the work, and Andrew
                    0.8
                                                                                                                                                                                                Young for data obtained in his \Megamix" study. The
                                                                                                                                                                                                research was funded by NIH grant MH57075 to GWC.
 % identification
                                                                                                                                                                                    Happiness
                    0.6                                                                                                                                                             Surprise
                                                                                                                                                                                    Fear
                                                                                                                                                                                                                     References
                                                                                                                                                                                    Sadness
                    0.4                                                                                                                                                             Disgust
                                                                                                                                                                                    Anger
                    0.2
                                                                                                                                                                                                Bishop, C. M. (1995). Neural networks for pattern recog-
                                                                                                                                                                                                     nition. Oxford University Press, Oxford.
                    0.0
                          H 10   30   50   70   90 S 10   30   50   70   90 F 10   30   50   70   90 M 10   30   50   70   90 D 10   30   50   70   90 A 10   30   50   70   90 H
                                                                             Model predictions                                                                                                  Carroll, J. M. and Russell, J. A. (1996). Do facial ex-
Figure 5: Human and network responses to JJ morphs                                                                                                                                                   pressions signal speci c emotions? Judging emotion
                                                                                                                                                                                                     from the face in context. Journal of Personality and
along the transitions HSFMDA.                                                                                                                                                                        Social Psychology, 70(2):205{218.
                                                                                                                                                                                                Dailey, M. N. and Cottrell, G. W. (1999). PCA = Gabor
                                                                                                                                                                                                     for expression recognition. UCSD CSE TR CS-629.
Model t                                                                                                                                                                                         Daugman, J. G. (1985). Uncertainty relation for reso-
Using the same response variable measurements as Pad-                                                                                                                                                lution in space, spatial frequency, and orientation
gett and Cottrell (1998), we do nd the Megamix pat-                                                                                                                                                  optimized by two-dimensional visual cortical lters.
tern of sharp categorical transitions, scallop-shaped re-                                                                                                                                            J. Optical Society America A, 2:1160{1169.
sponse time curves, improved discrimination near cate-                                                                                                                                          Donato, G., Bartlett, M. S., Hager, J. C., Ekman, P., and
gory boundaries, and a close correspondence between hu-                                                                                                                                              Sejnowski, T. J. (1999). Classifying facial actions.
mans and networks on detection of the secondary expres-                                                                                                                                              IEEE PAMI, 21(10):974{989.
sion in morph transitions. Due to space limitations, we                                                                                                                                         Ekman, P. (1999). Basic emotions. In Dagleish, T.
cannot report all of the Megamix modeling results here,                                                                                                                                              and Power, M., editors, Handbook of Cognition and
but we do show the model's t to the human responses                                                                                                                                                  Emotion. Wiley, New York.
on one series of morph transitions. Forced-choice identi-                                                                                                                                       Ekman, P. and Friesen, W. (1976). Pictures of Facial
  cation results for the Happy { Surprised { Afraid { Sad                                                                                                                                            A ect. Consulting Psychologists, Palo Alto, CA.
{ Disgusted { Angry { Happy transition series are shown                                                                                                                                         Ekman, P. and Friesen, W. (1978). Facial Action Coding
in Figure 5. The human data and model prediction are                                                                                                                                                 System. Consulting Psychologists, Palo Alto, CA.
                                                                                                                                                                                                Ellison, J. W. and Massaro, D. W. (1997). Featural eval-
quite similar, but the networks appear to place slightly                                                                                                                                             uation, integration, and judgment of facial a ect.
sharper boundaries between expressions; this is because                                                                                                                                              JEP: HPP, 23:213{226.
there is not as much variation in our population of net-                                                                                                                                        Etco , N. L. and Magee, J. J. (1992). Categorical per-
work \subjects" as that occurring in the Megamix data.                                                                                                                                               ception of facial expressions. Cognition, 44:227{240.
Nevertheless, the correspondence (r2 = 0:846) is remark-                                                                                                                                        Jones, J. P. and Palmer, L. A. (1987). An evaluation of
able considering that the networks were never trained on                                                                                                                                             the two-dimensional Gabor lter model of receptive
images of JJ or morph stimuli and that there are abso-                                                                                                                                                 elds in cat striate cortex. Journal of Neurophysi-
lutely no free parameters involved in tting the model                                                                                                                                                ology, 58(6):1233{1258.
to the data.                                                                                                                                                                                    Katsikitis, M. (1997). The classi cation of facial expres-
                                                                                                                                                                                                     sions of emotion: A multidimensional scaling ap-
                                                                                    Discussion                                                                                                       proach. Perception, 26:613{626.
We have shown that a simple, mechanistic computa-                                                                                                                                               Lyons, M. J., Budynek, J., and Akamatsu, S. (1999). Au-
tional model obtains a natural t to data from several                                                                                                                                                tomatic classi cation of single facial images. IEEE
psychological studies on classi cation of human facial ex-                                                                                                                                           PAMI, 21(12):1357{1362.
pressions. Exploring the space of possible expression                                                                                                                                           Padgett, C. and Cottrell, G. W. (1998). A simple neu-
classi cation models has led us to reject several alter-                                                                                                                                             ral network models categorical perception of facial
native models (including local PCA-based input repre-                                                                                                                                                expressions. In Proc. 20th Cognitive Science Con-
sentations and more complicated ensembles of networks                                                                                                                                                ference, pages 806{807, Mahwah, NJ. Erlbaum.
containing hidden layers). Since one simple model, de-                                                                                                                                          Russell, J. A. (1980). A circumplex model of a ect. J.
spite its lack of culture and social experience, explains so                                                                                                                                         Personality and Social Psych., 39:1161{1178.
much data without any free parameter tting, we claim                                                                                                                                            Wiskott, L., Fellous, J.-M., Kruger, N., and von der
                                                                                                                                                                                                     Malsburg, C. (1997). Face recognition by elastic
that it is a strong model for how the human visual sys-                                                                                                                                              bunch graph matching. IEEE PAMI, 19(7):775{779.
tem perceives facial expressions in static images. To the                                                                                                                                       Young, A. W., Rowland, D., Calder, A. J., Etco , N.,
extent that performance in the controlled forced-choice                                                                                                                                              Seth, A., and Perrett, D. I. (1997). Facial expression
psychological experiments cited here generalizes to more                                                                                                                                             megamix. Cognition, 63:271{313.
naturalistic social situations (an admittedly big assump-

