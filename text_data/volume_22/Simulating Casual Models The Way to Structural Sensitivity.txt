UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Simulating Casual Models: The Way to Structural Sensitivity
Permalink
https://escholarship.org/uc/item/7wb380c6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Authors
Hagmayer, York
Waldmann, Michael R.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                       Simulating Causal Models: The Way to Structural Sensitivity
                                       York Hagmayer (york.hagmayer@bio.uni-goettingen.de)
                                            Department of Psychology, University of Göttingen,
                                                Gosslerstr. 14, 37073 Göttingen, Germany
                                 Michael R. Waldmann (michael.waldmann@bio.uni-goettingen.de)
                                            Department of Psychology, University of Göttingen,
                                                  Gosslerstr. 14, 37073 Göttingen, Germany
                             Abstract                                    32 probabilities of the joint probability distribution,
                                                                         P(X1, X2, X3, X4, X5), by considering every combination of
   The majority of psychological studies on causality have fo-           present and absent events. Another possible strategy is to
   cused on simple cause-effect relations. Little is known               encode the base rates and all covariations that can be
   about how people approach more realistic, complex causal
                                                                         computed between five events. However, even with mod-
   networks. Two experiments are presented that investigate
   how participants integrate causal knowledge that was ac-              estly complex structures the number of covariations be-
   quired in separate learning tasks into a coherent causal              comes very large, especially when more complex higher-
   model. To accomplish this task it is necessary to bring to            order covariations between multiple events also are con-
   bear knowledge about the structural implications of causal            sidered. Bayesian network models reduce the complexity
   models. For example, whereas common-cause models im-                  of representing causal knowledge by distinguishing be-
   ply a covariation among the different effects of a common             tween direct causal relations (the arrows in Fig. 1), and
   cause, no such covariation between the different causes of a          covariations that can be derived by using information
   joint effect is implied by a common-effect model. The ex-             encoded in the structure of the causal models. The struc-
   periments show that participants have virtually no explicit           ture of causal models primarily expresses information
   knowledge of these relations, and therefore tend to misrep-
                                                                         about conditional independence between events. For ex-
   resent the structural implications of causal models in their
   explicit judgments. However, an implicit task that only re-           ample, in Figure 1 event X4 is coded as being independent
   quired predictions of singular events showed surprisingly             of event X5 conditional upon event X3. Conditional inde-
   accurate sensitivity to the structural implications of causal         pendence greatly simplifies computations by allowing the
   models. This dissociation supports the view that people’s             derivation of the indirect relations from products of the
   sensitivity to structural implications is mediated by running         relevant components (see Pearl, 1988; Glymour & Coo-
   simulations on mental analogs of the causal situations.               per, 1999). In Figure 1 the joint probability distribution
                                                                         can be factorized into the product of a small number of
                          Introduction                                   unconditional and conditional probabilities,
In everyday life as well as in scientific research we                         P(X1,X2,X3,X4,X5) = P(X5|X3)·P(X4|X2,X3)· P(X3 |X1)·
rarely observe the behavior of complex causal networks                                           P(X2)·P(X1).
at once. A more typical scenario is that we learn about
single causal relations separately, and later try to inte-
grate the different observed relations into a more com-
plex interconnected causal model. For example, we                                                    X1   Headaches
might first learn that aspirin relieves headache. Later
we may observe that aspirin unfortunately also creates
stomach problems. Now we are in the position of put-                      Helicobacter                               Aspirin
                                                                                          X2                   X3
ting these two pieces of knowledge together. The ques-                     Infection                                 Consumption
tion is how? How are different fragments of causal
knowledge integrated into coherent complex structures?
                                                                                        Stomach      X4          Pain      X5
Bayesian Causal Models                                                                  Problems                 Relief
One recent approach to this problem that has become
increasingly popular in the past few years postulates                               Figure 1: Example of a Bayesian Network
Bayesian network models for representing causal knowl-
edge (see Pearl, 1988, 2000; Glymour & Cooper, 1999).                    The distinction between direct causal relations and indi-
Bayesian network models provide compact, parsimonious                    rect relations can also be used for the integration of sepa-
representations of causal relations. For example, Figure 1               rate pieces of causal knowledge. Combining the informa-
displays a causal model that connects five events, X1, X2,               tion that aspirin relieves headache with the information
X3, X4, X5. One way to represent this domain is to list the              that it additionally causes stomach problems yields a

common-cause model with aspirin playing the role of the       1988). For common-effect models, the noisy-or schema
common cause of two independent effects, relief of head-      has been proposed as a plausible integration schema (see
ache and stomach problems (see Fig. 2, left). By contrast,    also Waldmann & Martignon, 1998). According to this
integrating the two causal relations “Aspirin causes stom-    schema P(X4|X2,X3) can be reduced to [1-(1-P(X4|X2))·(1-
ach problems” with “Helicobacter pyloris causes stomach       P(X4|X3))], an expression that only contains probabilities
problems” would yield a different structure, a common-        referring to direct causal relations. The noisy-or schema
effect model, in which two independent causes converge        assumes that different causes have independent and addi-
on a joint effect (see Fig. 2, right). In both examples, two  tive influences on the common effect. Given that com-
independent causal relations are being integrated. How-       mon-effect models do not imply covariations among the
ever, the outcome of the integration process is different.    causes a further reasonable default assumption is that they
The two different causal models entail different implica-     occur independently. A number of psychological experi-
tions for the indirect relations between events.              ments have shown that learners indeed tend to initially
                                                              assume independence (see Waldmann, Holyoak, & Fra-
Structural Implications of Causal Models                      tianne, 1995).
The basis for the possibility of integrating different causal
links into coherent wholes are the structural implications    Sensitivity to Structural Implications:
of causal models. In our experiments we focused on two        Computation vs. Causal Simulation
simple models, a common-cause and a common-effect             Previous research has demonstrated sensitivity to struc-
model. Both models integrate two causal links but entail      tural implications of causal models in causal learning
distinctly different implications for the non-causal rela-    (Waldmann & Holyoak, 1992; Waldmann, 2000), causal
tions.                                                        reasoning (Waldmann & Hagmayer, 1998), and categori-
                                                              zation (Waldmann et al., 1995). The processes underlying
    Common-Cause Model            Common-Effect Model         this sensitivity are unclear, however. The standard ap-
             C                               E                proach within the area of Bayesian modeling is to explic-
                                                              itly derive the predicted event patterns or covariations and
                                                              test these predictions against the data at hand. It appears
        E1          E2                C1           C2         unlikely that this strategy could be followed in intuitive
                                                              everyday reasoning. Despite the fact that Bayesian models
                                                              provide a parsimonious way of representing domain
                                                              knowledge it is also clear that the explicit derivation of
       Figure 2: Implications of Different Causal Models      indirect relations is often complex and computationally
                                                              demanding (Glymour & Cooper, 1999). In fact, one rea-
Figure 2 (left) depicts a common-cause model with a           son for the increasing number of automated statistical
common cause C producing two independent effects E1           tools that are currently offered to researchers lies with the
and E2. Common-cause models of this kind entail a (spu-       fact that the task surpasses the capacity limitations of
rious) covariation among the effects. Provided the com-       intuitive reasoning.
mon cause independently generates the two effects, the            However, there is an alternative, more implicit strat-
joint probability of the effects, P(E1,E2), can be calculated egy. Instead of explicitly computing covariations we may
by taking the product of the base rate of the cause, P(C),    form mental representations of causal structures that are
and the two conditional probabilities, P(E1|C) and P(E2|C)    analogous to the graphical structures used in Bayesian
(see also Appendix). Thus, although the two effects may       network modeling (e.g., Fig. 1). Similar to toy models,
never have been observed together, the causal model still     these causal models can then be used to run mental simu-
allows it to derive a prediction for the patterns that should lations (see also Barsalou, 1999). For example, instead of
be expected. Common-cause models clearly differ from          calculating the probability of patterns within a common-
common-effect models. Figure 2 (right) shows an exam-         cause model with one cause and two effects we could
ple in which two causes, C1 and C2, are linked with a joint   mentally imagine the presence or absence of the cause,
effect E. Common-effect models do not imply covaria-          and then generate predictions for each individual effect
tions among the different causes of the joint effect. The     based on the observed covariations between the cause and
causes may covary in a specific learning situation but this   either effect. Since these predictions are triggered by a
covariation is not implied by the model, it is something      common event within a mental common-cause model the
that has to be explicitly encoded. This is the reason why     predicted patterns should show the covariations that are
in the example shown in Figure 1 common effects were          implied by the structure of the mental model. These co-
conditionalized on patterns of its direct causes (e.g., P(X4| variations are not the consequence of an explicit computa-
X2, X3)). However, this is only possible when all the rele-   tion, they rather are a side effect of the structure of the
vant events have been observed together, and when the         causal model used to simulate the causal situation in the
number of relevant patterns is small enough not to surpass    real world. Therefore it may well be that the predicted
information processing limitations. In more complex           patterns exhibit covariations of which the learners are not
cases and in situations in which causal knowledge has to      aware. For the learner it is only necessary to focus on the
be generated from different learning experiences, causal      direct causal relations. All the indirect relations are taken
schemas have been postulated in the literature (Pearl,

care of by running simulations on mental analogs of the       rence of either the enzyme or the protein on the backside.
objective causal situation.                                   The learning phase consisted of 80 cards, 40 for each
    Two experiments will be presented in which partici-       substance.
pants acquired partial knowledge about separate frag-             Two factors, type of causal model and degree of co-
ments of common-cause or common-effect models. To             variation, were manipulated yielding four experimental
test whether they were sensitive to the additional covaria-   conditions. The first factor contrasted two different causal
tions implied by the different causal models, two types of    models. One group of participants read in the initial in-
measures were collected. Explicit knowledge was assessed      structions that the researchers were interested in finding
by means of probability estimates in which participants       out whether the mutation causally influences the two
were requested to estimate the strength of the indirect, not  substances (common-cause model)(see Fig. 2, left). In
directly observed relation. Based on the assumption that      contrast, for the second group the two substances were
explicit computations of the answers to these questions       described as potential causes of the mutation (common-
are hard we expected poor performance with this task.         effect model)(see Fig. 2, right). The second factor ma-
However, the second task was designed to tap into im-         nipulated the strength of the relation between mutation
plicit knowledge generated by causal simulations. In this     and the two substances. The strength was always equal for
task, participants were requested to predict the pattern of   both substances and either weak or strong. Table 1 dis-
events they expected to see. For example, in a common-        plays the absolute frequencies used in this experiment.
cause condition (see Fig. 2) the experimenter instructed      Thus, for example, participants in the condition with
participants to imagine that the cause was present and to     strong connections saw 16 cases for each substance in
make a prediction about the two effects. A typical finding    which the presence of a mutation of the gene was paired
with this type of task is that participants tend to match the with the presence of the substance.
probabilities they have seen in the learning situation.
Since in the present task the two effects never have been         Table 1: Frequencies in Experiment 1
seen together, direct experience with the patterns is not
available. However, it is possible that participants match                       Strong Condition       Weak Condition
the probabilities for each relation independently within a
mental analog of a common-cause model. The model                                           No Sub-                No Sub-
                                                                              Substance              Substance
itself generates covariations that have never been ob-                                      stance                 stance
served directly. The crucial measure in this task is the       Mutation           16           4         10          10
covariation between the predicted effects that can be de-
rived from participants’ responses. The causal-simulation      No Mutation         0          20          6          14
account predicts that these patterns should display the
covariations implied by the causal models even when no        Apart from the different initial instructions about the
explicit knowledge could be detected in the explicit task.    underlying causal model the learning phases and the test
                                                              phases were identical within the conditions with strong or
                      Experiment 1                            weak relations. Regardless of whether the mutation of the
The goal of this experiment was to investigate whether        gene was introduced as a cause or as an effect, informa-
learners who have acquired partial knowledge about            tion about its presence or absence was delivered before
fragments of causal models are sensitive to the structural    information about the substances was given.
implications of these models. Participants were given the         The learning phase was followed by a test phase in
task to learn about the causal relations between the muta-    which participants’ assumptions about the covariation
tion of a gene and the prevalence of two (fictitious) sub-    between the two substances was assessed. This covaria-
stances (enzyme BST and brasus protein). We used a            tion had to be inferred because the two substances had
trial-by-trial learning procedure in which participants       never been seen together. To test whether participants
worked through a stack of index cards with information        were sensitive to the different implications of the two
on the front side about whether a mutation of the gene        causal models we compared an implicit with an explicit
occurred or not. By turning around the individual cards       measure of knowledge. In the implicit test procedure
participants received information about the presence or       participants received 20 new index cards in a random
absence of either the enzyme BST or the brasus protein.       order, half of them indicating that in this particular case a
To ensure that no covariation between the enzyme and the      mutation had occurred. The rest of the index cards de-
protein could be observed the cards were divided into two     scribed cases in which no mutation had occurred. Partici-
different stacks, one for each substance. Participants were   pants’ task was to predict for each case individually
instructed to alternate between the stacks in the course of   whether either of the two substances was present or ab-
the learning phase. In the initial instruction the separate   sent. No feedback about the substances was provided
stacks were characterized as displaying the raw data of       during this test phase. Since patterns of substances had to
two different research projects located at different univer-  be predicted it was possible to analyze the amount of
sities. The task and the presentation of the data were iden-  covariation between the substances in the responses of the
tical for all participants. They first received information   participants. We used the phi correlation coefficient as a
about the mutation of the gene on the front side of the       measure of the degree of the implicitly predicted covaria-
cards, and then were shown information about the occur-       tion (see Appendix). In a second task that followed the

implicit task, we investigated participants’ explicit expec-   condition in which they received identical learning inputs
tations. In this task they had to estimate the probability     as participants in the corresponding common-cause condi-
that the second substance is present conditional upon the      tion the prediction responses displayed generally low
first being present (P(substance2|substance1)) and being       correlations in both conditions. An analysis of variance
absent (P(substance2|~substance1)). As with the implicit       revealed a significant main effect for the factor causal
measures the explicit estimates were transformed into phi      model, F(1, 44)=7.28, p<.05, MSE =.14, and a significant
correlations that allowed us to directly compare the im-       main effect for the factor strength of covariation, F(1,
plicit with the explicit measure.                              44)=18. 4, p<0.01, MSE=.14. The interaction failed to be
    What are the normative Bayesian predictions for the        significant, F(1, 44)=2.33, p=.13, MSE=.14.
presented data? When a common-cause model is assumed
it is appropriate to encode the conditional probabilities                Table 2: Means of Implicit and Explicit Meas-
directed from the cause (i.e., mutation) to its effects (i.e.,           ures (Experiment 1)
substances). In this direction, the data display a condi-
tional probability of either substance in the presence of                      Implicit Measure:         Explicit Measure:
the mutation (i.e., P(substance|mutation)) of .80 in the                    Generated Correlations    Estimated Correlations
strong and .50 in the weak condition. The corresponding                     Common- Common-           Common- Common-
values in the absence of a mutation (P(substance|~mu-                         Cause        Effect      Cause         Effect
tation)) are 0 in the strong versus .30 in the weak condi-                    Model        Model       Model         Model
tion. Taking the difference of these numbers yields the         Strong
widely used contingency (∆P) measure of statistical                            .622         .168        .286          .161
                                                                Relations
strength (Eells, 1991). Accordingly, the contingency is ∆P
=.80 in the strong and ∆P =.20 in the weak condition.           Weak
                                                                              -.004         -.130       -.109         .039
    Within the framework of a common-effect model the           Relations
same data should again be analyzed from causes to ef-
fects. In this condition the substances play the role of the       The explicitly estimated correlations clearly differed
causes. Thus, it is appropriate to compare P(mutation|         from the implicitly generated ones (see Table 2). There
substance) with P(mutation|~substance). The data yield a       was no significant difference of the estimated correlations
probability of the mutation in the presence of the sub-        in the two contrasted causal models, F<1. Only the differ-
stance of 1 in the strong and of .63 in the weak condition.    ence between the conditions in which strength of covaria-
The corresponding values in the absence of the substance       tion was manipulated proved significant, F(1,44)=8.05,
are .17 in the strong and .42 in the weak condition. These     p<.01, MSE=.10.
numbers imply almost the same contingencies as in the              These results indicate that participants showed little
common-cause condition of ∆P=0.83 (strong condition)           sensitivity to the implications of causal models when the
and ∆P=.21 (weak condition).                                   task required explicit estimates. They seemed to be aware
    On the basis of structural information from the causal     of the fact that the inferred covariations somewhat depend
models these numbers can be used to derive the predicted       on the strength of the causal links responsible for the
covariation between the substances. While the common-          covariations, but they did not explicitly grasp the struc-
effect model does not imply a covariation, the common-         tural difference between common-cause and common-
cause model entails that the observed joint probability        effect models. By contrast, the implicit measure displayed
should correspond to the product of the base rate of the       surprisingly accurate predictions. In this task, participants
cause and the conditional probabilities observed for each      clearly differentiated between common-cause and com-
causal link. These probabilities can be transformed into a     mon-effect models despite identical learning inputs. In
phi coefficient of correlation (see Appendix). The data        our view, this finding supports the prediction that sensitiv-
presented imply a phi correlation of r=.67 between the         ity to structural implications can be achieved by running
substances in the strong condition and of r=.042 in the        simulations on mental analogs of causal models.
weak condition.
                                                                                      Experiment 2
Results and Discussion
                                                               In Experiment 1 participants first were informed about
The results are based on 48 students from the University       whether a mutation of the gene occurred or not, and then
of Göttingen who were randomly assigned to one of the          learned for each substance separately whether it was pre-
four learning conditions. Table 2 shows the means for          sent or absent. This procedure served the goal of present-
both the explicit and the implicit measure obtained in the     ing identical learning inputs to participants in the different
four conditions.                                               conditions. It raises the question, however, whether the
    The correlations that the participants generated in the    observed asymmetries of sensitivity to implied covaria-
implicit prediction task resemble very closely the ones        tions are due to the contrasted causal models or rather to
normatively implied by the causal models. Participants in      differences in the direction of required inferences during
the common-cause condition generated a high mean cor-          learning. In the common-cause condition learning was
relation of .62 between the substances when the causal         directed from cause to effects (predictive learning),
connections were strong and a mean correlation of -.004        whereas in the common-effect conditions the very same
when they were weak. In contrast, in the common-effect

learning items implied that learning proceeded from effect   size is to be expected in the present experiment. In con-
to causes (diagnostic learning). Thus, it may be speculated  trast to the common-cause model, the common-effect
that differences between predictive and diagnostic learn-    model does not imply any covariation between the causes.
ing rather than differences in the underlying causal mod-    These different structural implications are, of course,
els may be the reason for the obtained results.              independent of the direction of learning.
    The goal of Experiment 2 was to replicate the results        As in Experiment 1, sensitivity to implied covariations
of Experiment 1 and to control for the direction of learn-   was assessed by means of implicit and explicit measures.
ing. Moreover, unlike in Experiment 1 the conditional        Regardless of the learning direction the implicit test al-
probabilities and contingencies were equalized in the        ways presented information about the mutation of the
contrasted conditions. Material and procedure were taken     gene as the cue for the predictions. Participants were
from Experiment 1. All participants had the task to learn    shown 20 new cases, half of which describing mutations,
about the causal connection between mutation and the two     and had to predict for each case individually whether
substances. Again, as learning input they received index     either of the substances was present or not. The explicit
cards separated into two stacks which either provided        task in which participants estimated conditional probabili-
information about the relation between the mutation and      ties followed the implicit one (see Experiment 1).
the enzyme BST or between the mutation and the brasus
protein. Table 3 shows the frequencies of the different      Results and Discussion
patterns that were presented during the learning phase.      64 students from the University of Göttingen were ran-
                                                             domly assigned to one of the four conditions. The means
          Table 3: Frequencies in Experiment 2               of the phi correlations that were either generated (implicit
                                                             measure) or estimated (explicit measure) in the four dif-
                        Substance        No Substance        ferent conditions are shown in Table 4.
       Mutation              25                5
                                                                       Table 4: Means of Implicit and Explicit Meas-
       No Mutation            5               25                       ures (Experiment 2)
These frequencies implied conditional probabilities be-                       Implicit Measure:       Explicit Measure:
tween the mutation and the substances that were com-                         Generated Correla-      Estimated Correla-
pletely symmetric (P(mutation|substance) = P(substance|                             tions                   tions
mutation) =.8, and P(mutation|~substance)= P(substance|                    Common- Common- Common- Common-
~mutation)=.2). Thus, the contingencies were identical in     Learning        Cause       Effect      Cause       Effect
both directions (∆P=.60).                                     Direction      Model        Model      Model        Model
    Two factors were manipulated in Experiment 2. The         Predictive       .243        .013        .258        .239
first factor manipulated the assumed causal model by
means of differential initial instructions. As in Experiment  Diagnostic       .186       -.001        .129        .210
1, the mutation of the gene was either introduced as the
cause of the two substances (common-cause model) or as       As in Experiment 1, assumptions about the underlying
their effect (common-effect model). The second factor        causal model clearly influenced the implicit measure. The
manipulated the learning direction. Learning proceeded       main effect for the factor causal model was significant for
either from causes to effects (predictive learning) or from  the generated correlations, F=4.97, p<.05, MSE=.14. In
effects to causes (diagnostic learning). Thus, half of the   general, participants generated higher correlations be-
participants received information about the mutation first   tween the substances when they were viewed as effects
before learning about the substances whereas the other       (common-cause model) than when they had been charac-
half first read information about the presence or absence    terized as causes of the mutation (common-effect model).
of one of the substances, and then received feedback         In the common-effect condition the generated covaria-
about the mutation. In fact, the same index cards were       tions between the two substances (i.e., the causes) were
used for all participants, the only difference was which     very close to 0 which supports our prediction that inde-
side they saw first. Information about the mutation was      pendence between causes is assumed in common-effect
shown first in the predictive version of the common-cause    models. Neither the factor learning direction nor the inter-
condition and in the diagnostic version of the common-       actions with this factor proved significant (F<1).
effect condition. The reversed cards showing information         In contrast to the implicit measures, no sensitivity to
about the substances first were given to participants in the the structural implications of causal models could be
predictive common-effect and the diagnostic common-          detected with the explicit measures. In general, partici-
cause conditions. Using the procedures described in the      pants tended towards correlations that clearly differed
Appendix, a phi correlation of r=.37 between the sub-        from 0 but showed no sensitivity to the assumed causal
stances can be derived for the common-cause model in         model. None of the effects approached significance in an
which they played the role of effects. This is about half    analysis of variance in which type of causal model and
the size of the implied covariation in the condition with    learning direction entered as factors (F<1).
strong relations of Experiment 1. Thus, a smaller effect         These results clearly support the conclusions of Ex-

periment 1 by demonstrating sensitivity to structural im-                                                  References
plications with an implicit but no sensitivity with an ex-   Barsalou, L. W. (1999). Perceptual symbol systems. Be-
plicit measure. Consistent with the normative analysis, the    havioral and Brain Sciences, 22, 577-660.
implicit measures yielded higher covariations for the        Glymour, C. N., & Cooper, G. F. (1999). Computation,
common-cause than for the common-effect model. The             causation, and discovery. Cambridge: MIT Press.
present experiment also shows that this pattern of results   Eells, E. E. (1991). Probabilistic causality. Cambridge:
is not due to differences in the learning procedure (predic-   Cambridge University Press.
tive vs. diagnostic) but rather is based on differences of   Pearl, J. (2000). Causality: Models, reasoning, and infer-
the assumed causal models.                                     ence. Cambridge: Cambridge University Press.
                                                             Pearl, J. (1988). Probabilistic reasoning in intelligent
                       Conclusions                             systems. San Francisco: Morgan Kaufmann.
Research on causality belongs to the truly interdiscipli-    Waldmann, M. R. (2000). Competition among causes but
nary topics of cognitive science. There are differences in     not effects in predictive and diagnostic learning. Journal
the research focus between disciplines, however. Whereas       of Experimental Psychology: Learning, Memory, and
the majority of studies within cognitive psychology have       Cognition, 26, 53-76.
focused on single cause-effect relations, researchers in the Waldmann, M. R., & Hagmayer, Y. (1998). Estimating
areas of computer science and philosophy have become           causal strength: The role of structural knowledge and
increasingly interested in complex causal structures (e.g.,    processing effort. Unpublished manuscript.
Glymour & Cooper, 1999; Pearl, 2000). The goal of the        Waldmann, M. R., & Holyoak, K. J. (1992). Predictive
present research is to bridge this gap without forgetting      and diagnostic learning within causal models: Asymme-
the inherent information processing limitations of hu-         tries in cue competition. Journal of Experimental Psy-
mans. It is unlikely that untutored human learners are able    chology: General, 121, 222-236.
to store and use the complex information embodied in         Waldmann, M. R., Holyoak, K. J., & Fratianne, A.
even fairly simple causal structures. Therefore we have        (1995). Causal models and the acquisition of category
focused on a more realistic task in which participants         structure. Journal of Experimental Psychology: Gen-
learned about different fragments of a causal model sepa-      eral, 124, 181-206.
rately, and later were confronted with the task to integrate Waldmann, M. R., & Martignon, L. (1998). A Bayesian
the different pieces in order to predict unobserved co-        network model of causal learning. In M. A. Gernsbacher
variations. To solve this task correctly, knowledge about      & S. J. Derry, Proceedings of the Twentieth Annual
structural implications of different causal models has to      Conference of the Cognitive Science Society. Mahwah,
be activated. Research on Bayesian networks has shown          NJ: Erlbaum.
that structural information greatly simplifies causal com-
putations but it also has demonstrated that the task still                                                   Appendix
remains complex. Consistent with this analysis both ex-      The following derivation shows how joint probabilities
periments have demonstrated that participants showed         and correlations can be derived for common-cause mod-
little explicit knowledge about differences between causal   els. In the formulas, s1, s2 represent the two substances and
models, even when the models were extremely simple.          m the mutation. “~” signifies the absence of an event.
Participants’ explicit judgments did not distinguish be-     The joint probability of the two substances can be com-
tween a condition in which the target events were two        puted by
effects of a common cause and a condition in which these                     P(s1.s2) = P(s1.s2|m)·P(m)+P(s1.s2|~m)·P(~m) (1)
events represented two causes of a common effect. This       Common-cause models assume that the effects are inde-
result raises doubts as to humans’ competence to correctly   pendent conditional upon the states of the common cause,
learn about causal structures in the world. However, a       that is:
second, more implicit measure displayed surprisingly                         P(s1.s2|m) = P(s1|m) ·P(s2|m)
accurate inferences. When the task required predicting       Thus, Equation 1 can be simplified:
individual events, participants proved sensitive to the                      P(s1.s2) = P(s1|m) ·P(s2|m) ·P(m) +
difference between common-cause and common-effect                                                        P(s1|~m) ·P(s2|~m) ·P(~m)
models. This dissociation between explicit and implicit      The joint probabilities for the other patterns (e.g.,
measures is consistent with the view that mental simula-     P(s1.~s2)) can be calculated in a similar fashion. These
tions of causal models support the implicit task. Generat-   probabilities can be used to compute phi correlation coef-
ing predictions by means of a mental simulation capital-     ficients based on the following formula:
izes on causal structure without requiring explicit knowl-
                                                                                                    P(s1.s2 ) ⋅ P(~ s1. ~ s2 ) − P(s1. ~ s2 ) ⋅ P(~ s1.s2 )
edge. As long as the mental representation mirrors the       r=
                                                                 (P( s1.s2 ) + P(s1. ~ s2 )) ⋅ (P( s1.s2 ) + P(~ s1.s2 )) ⋅ (P( s1. ~ s2 ) + P(~ s1. ~ s2 )) ⋅ (P(~ s1.s2 ) + P(~ s2 . ~ s2 ) )
causal features of the represented domain, simulations
should display the same structural constraints. Therefore    This procedure of computing phi correlations can be ap-
causal simulations allow us to generate correct predictions  plied to the patterns predicted by the participants (implicit
without requiring complex, explicit computational infer-     task) as well as to the estimated conditional probabilities
ences.                                                       (explicit task).

