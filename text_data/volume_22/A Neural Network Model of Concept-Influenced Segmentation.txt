UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Neural Network Model of Concept-Influenced Segmentation
Permalink
https://escholarship.org/uc/item/9pg2d2xs
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
Goldstone, Robert L.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                  A Neural Network Model of Concept-influenced Segmentation
                                        Robert L. Goldstone (rgoldsto@indiana.edu)
                                         Department of Psychology, Indiana University
                                                 Bloomington, IN 47405 USA
                           Abstract                             experience with particular feature combinations determines
                                                                whether or not features will be integrated into a single
   Several models of categorization assume that fixed           object.
   perceptual representations are combined together to             Pevtzow and Goldstone (1994; reported in Goldstone et
   determine categorizations. This research explores the
   possibility that categorization experience alters, rather    al., 2000) explored the influence of category learning on
   than simply uses, descriptions of objects. Based on          segmentation with the materials shown in Figure 1. We
   results from human experiments, a model is presented         pursued the idea that how psychologically natural a part is
   in which a competitive learning network is first given       might depend on whether it has been useful for previous
   categorization training, and then is given a subsequent      categorizations. Naturalness was measured by how quickly
   segmentation task, using the same network weights.           subjects could confirm that the part was contained within a
   Category learning establishes detectors for stimulus
   parts that are diagnostic, and these detectors, once         whole object (Palmer, 1978). To test this conjecture, we
   established, bias the interpretation of subsequent           gave participants a categorization task, followed by
   objects to be segmented.                                     part/whole judgments. During categorization, participants
                                                                were shown distortions of the objects A, B, C, and D shown
Concept Learning and Perception                                 in Figure 1. The objects were distorted by adding a random
The current research explores the influence that learning a     line segment that connected to the five segments already
new concept has on the segmentation of objects into             present. Subjects were given extended training with either a
component parts. Recently a number of researchers have          vertical or horizontal categorization rule. For participants
argued that in many situations, concept learning influences     who learned that A and C were in one category, and B and
the featural descriptions used to describe a set of objects.    D were in another (a vertical categorization rule) the two
Rather than viewing perceptual descriptions as fixed by         component parts at the bottom of Figure 1 were diagnostic.
low-level sensory processes, this view maintains that           For participants who learned that A and B belonged in one
perceptual descriptions are dependent on the higher-level       category, and C and D belonged to the other category (a
processes that use the descriptions (Goldstone, Steyvers        horizontal rule), the components on the right were
Spencer-Smith, & Kersten, 2000; Schyns, Goldstone, &            diagnostic.
Thibaut, 1998). Evidence for this view comes from the
study of expert/novice differences (Lesgold et al., 1988),
influences of acquired concepts on the interpretation of
stimuli (Wisniewski & Medin, 1994), and influences of
category learning on psychophysical measurements of                       A             B
perceptual sensitivity (Goldstone, 1994).
Experiential Influences on Object Segmentation
One type of influence of concept learning on perceptual
learning may be to alter how objects are segmented into                   C              D
parts. Objects often have more than one possible
segmentation. The letter “X” can be viewed as comprised                                             Component
of two crossing diagonal lines, or as a “V” and an upside-                                          Parts of
down “V” that barely touch at their vertices. The                                                   Objects
segmentation of scenes into parts depends upon experience.         Figure 1: Pevtzow and Goldstone (1994) stimuli
Behrmann, Zemel, and Mozer (1998) found that judgments
about whether two parts had the same number of humps               During part/whole judgments, participants were shown a
were faster when the two parts belonged to the same object      whole, and then a part, and were asked whether the part was
rather than different objects. Further work has found an        contained in the whole. Participants were given both
influence of experience on subsequent part comparisons.         present and absent judgments, and examples of these
Two stimulus components are interpreted as belonging to
                                                                judgments are shown in Figure 2. Note that the two parts
the same object if they have co-occurred many times
                                                                shown in Figure 2 were both potentially diagnostic during
(Zemel, Behrmann, Mozer, & Bavelier, 1999). Thus,

the earlier categorization training. Whether or not a part       over time, splitting the input patterns into categories
was diagnostic was independent of the appearance of the          represented by the detectors. The competitive learning
part itself, depending only on how the four objects of Figure    algorithm automatically learns to group input patterns into
1 were grouped into categories.                                  the clusters that the patterns naturally form. However, given
                                                                 that we want the detectors to reflect the experiment-supplied
                                                                 categories, we need to modify the standard unsupervised
                                                                 algorithm. This is done by including a mechanism such that
                                                                 detectors that are useful for categorizing an input pattern
  Whole           Par t         Whole            Par t           become more likely to win the competition to learn the
         Present                         Absent
                                                                 pattern. The usefulness of a detector is assumed to be
  Figure 2: Part/whole present and absent judgments              directly proportional to the weight from the detector to the
                                                                 presented category which is provided as a label associated
  The major result was that subjects were faster to correctly    with an input pattern. The input-to-detector weights do not
respond “present” when the part was diagnostic than when it      have to be set before the weights from detectors to
was non-diagnostic. To the extent that one can find              categories are learned.
response time analogs of signal detection theory sensitivity       In addition to modifying the unsupervised development of
and bias, this effect seems to be a sensitivity difference       hidden-layer detectors by considering their usefulness for
rather than a bias difference, because absent judgments also     categorization, a second modification of the standard
tended to be faster for diagnostic than nondiagnostic parts.     competitive learning algorithm is required to fix one of its
Given that a category part that was diagnostic for the           general problems in optimally making use of all detectors to
horizontal categorization group was nondiagnostic for the        cover a set of input patterns. This problem is that if
vertical group, these results indicate that it is not simply the multiple input patterns are presented that are fairly similar to
physical stimulus properties that determine how readily a        each other, there will be a tendency for one detector to be
person can segment an object into a particular set of            the winner for all of the patterns. As a result, the winning
components; segmentation is also influenced by the learned       detector’s weight vector will eventually become similar to
categorical diagnosticity of the components                      the average of the input patterns’ activations, while the rest
                                                                 of the detectors do not learn at all. This situation is
     Modeling Interactions Between Concept                       suboptimal because the input patterns are not covered as
              Learning and Segmentation                          well as they would be if the unchanging detectors learned
                                                                 something. The standard solution to this problem is called
We model the result from these experiment using a modified       "leaky learning" and involves adjusting both winning and
competitive learning network (Rumelhart & Zipser, 1985).         losing detectors, but adjusting losing detectors at a slower
As with the experiment, the network is first given               rate (Rumelhart & Zipser, 1985). To understand the more
categorization training, and then is given a subsequent          subtle problem with this solution, imagine, for example, that
segmentation task, using the same network weights. The           four input patterns naturally fall into two groups based on
goal of the modeling is to show how categorization training      their similarities, and the network is given four detectors.
can prime the segmentation network such that objects will        Ideally, each of the detectors would become specialized for
tend to be segmented into parts that were previously             one of the input patterns. However, under leaky learning,
diagnostic for categorization.                                   one detector will tend to become specialized for one cluster,
                                                                 a second will become specialized for the other cluster, and
The Categorization Network                                       the remaining two detectors will be pulled equally by both
  The categorization network has three layers of units: one      clusters, becoming specialized for neither. Note that it does
representing the input patterns, one representing a bank of      not help to supplement leaky learning by the rule that the
learned detectors, and one reflecting the category               closer a detector is to an input pattern, the higher its learning
assignments of the inputs. Both the weights from the input       rate should be. There is no guarantee that the two "losing"
patterns to the detectors and the weights from the detectors     units will evenly split such that each is closer to a different
to categories are learned. The categorization task uses a        cluster.
modified unsupervised competitive learning algorithm               Other researchers have noted related but not identical
(Rumelhart & Zipser, 1985), but includes a top-down              problems with competitive learning and have suggested
influence of category labels that incorporates supervised        solutions (Grossberg, 1987). Our current solution is to
learning. The network begins with random weights from a          conceptualize competitive learning as not simply a
two-dimensional input array to a set of detector units, and      competition among detectors to accommodate a presented
from the detectors to the category units. When an input          input pattern, but also as a competition among input patterns
pattern is presented, the unit with the weight vector that is    to be accommodated by a given detector. Input patterns are
closest to the input pattern is the "winner," and will           presented sequentially to the network, and as they are
selectively adjust its weights to become even more               presented, the closest input pattern to each detector is
specialized toward the input. By this mechanism, the             determined. The learning rate for a detector is set to a
originally homogenous detectors will become differentiated       higher value for its closest input pattern than for other

inputs. In this manner, detectors that are not the winning             same abstract construction. When the patterns were
detector for a pattern can still become specialized by                 categorized as shown in Figure 3A, such that the first two
becoming unequally influenced by different patterns. In                patterns belonged to Category 1, and the second two
addition, the learning rate for a detector when presented              patterns belonged to Category 2, then on virtually every run,
with an input pattern will depend upon how well the input is           the detectors that emerged were those reflecting the
currently covered by existing detectors. This dependency is            diagnostic segments -- those segments that were reliably
required to allocate detectors to input regions where they are         present on Category 1 or Category 2 trials. The picture
required. Putting these considerations together, the                   within a detector unit in Figure 3 reflects the entire weight
activation of detector i when presented with pattern p, is             vector from the 15 X 15 input array to the detector. When
                                                                       the same patterns are presented, but are categorized in the
            n               c
                                                                       orthogonal manner shown in Figure 3B, then different
 Ai, p = ∑ Ih, pWi,h + ∑ STW j,i                                       detectors emerge that again reflect the category-diagnostic
           h =1           j =1
                                                                       segments. In both cases, each detector will have a strong
where Ih,p is the activation of input unit h for pattern p, Wi,h
                                                                       association to one and only one of the category units. This
is the weight from input h to detector i, S is the strength of
                                                                       is expected given that one of the factors influencing the
the top-down pressure on detector development, T is the
                                                                       development of detectors was their categorical diagnosticity.
teacher signal (if Pattern p belongs to Category j then T=1,
                                                                       For the results shown here, and the later simulations to be
otherwise T=-1), and Wj,i is the weight from Detector i to
                                                                       reported, the following parameter values were chosen:
Category Unit j. The second term increases the activation of
                                                                       M=0.1, N=0.05, O=0.02, and S=0.1. Activation values
a detector to the extent that it is useful for predicting the
                                                                       were between –1 and +1. One hundred passes through the
input pattern’s categorization. The detector activation will
                                                                       input materials were presented to the network. In the
determine which detector is the “winner” for an input
                                                                       example shown in Figure 3, only 30 passes with each of the
pattern. As such, detectors that are useful for categorization
will tend to become winners, thus increasing their learning
rate.
   Input-to-detector weights are learned via top-down biased               1       1       2        2       1       2       1       2
competitive learning using the following equation for
changing weights from input pattern h to Detector i:
                        M(Ih, p − Wi,h ) if ∀x(Ai, p ≥ Ax, p )
                 N(I − W )K if ∀y(A ≥ A )
  ∆Wi,h      =     h, p      i,h p          i, p    i, y 
                 O(Ih, p − Wi,h )K p otherwise 
                                                             otherwise
                                                         
where M, N, and O are learning rates (M>N>O), and Kp is
the distance between pattern p and its closest detector. This                1               2                1               2
distance is inversely related to the cosine of the angle
between the vector associated with the closest detector and
p. This set of learning rules may appear non-local in that all
                                                                                     A                                B
detectors are influenced by the closest detector to a pattern,         Figure 3: Categorization-dependent detectors are acquired
and depend on previous presented inputs. However, the
rules can be interpreted as local if the pattern itself transmits      4 patterns was required for the complete specialization of
a signal to detectors revealing how well covered it is, and if         detectors to input patterns.
detectors have memories for previously attained matches to
patterns. When an input pattern is presented, it will first            The Segmentation Network
activate the hidden layer of detectors, and then these                 The basic insight connecting categorization and
detectors will cause the category units to become activated.           segmentation tasks is that segmentation can also be modeled
The activation of the category unit Aj will be                         using competitive learning, and thus the two tasks can share
        d                                                              the same network weights and consequently influence on
Aj = ∑ Ai W j,i                                                        each other. Competitive learning for categorization sorts
      i =1
                                                                       complete, whole input patterns into separate groups.
where d is the number of detectors. Detector-to-category
weights are learned via the delta rule ∆W j,i = L(T − Aj )Ai           Competitive learning for segmentation takes a single input
                                                                       pattern, and sorts the pieces of the pattern into separate
where L is a learning rate and T is the teacher signal                 groups. For segmentation, instead of providing a whole
described above.                                                       pattern at once, we feed in the pattern one pixel at a time, so
   We formed a network with 2 detectors units and 2                    instead of grouping patterns, the network groups pixels
category units, and presented it with four input patterns. We          together. Thus, each detector will compete to cover
gave the network four patterns that were used in                       individual pixels of an input pattern such that the detector
experiments with human subjects. These patterns are not                with the pixel-to-detector weight that is closest to the pixel’s
identical to the patterns shown in Figure 1, but are of the

actual value will adapt its weight toward the pixel’s value,        The segmentation network works by fully connecting a 15 X
and inhibit other detectors from so adapting. With this          15 input array of pixel values to a set of N detectors.
technique, if the pattern in Figure 4 is presented to the        Although ideally the value of N would be dynamically
network, the network might segment it in the fashion shown       determined by the input pattern itself, in the current modeling,
in Panel A. Panels A-D show the weights from the 15 X 15         we assume that each object is to be segmented into two parts
input array to each of two detectors, and reflect the            (as did Palmer, 1978). When an input pattern is presented, the
specializations of the detectors. The two segments are           pixels within it are presented in a random sequence to the
complements of each other — if one detector becomes              detectors, and the activation of Detector i which results from
specialized for a pixel, the other detector does not.            presenting Pixel p is
   Unfortunately, this segmentation is psychologically                                       n
implausible. No person would decompose the original                                 Ai, p = ∑ Ih Wi,h Sh, p
figure into these parts. To create psychologically plausible                                h =1
segmentations, we modify the determination of winners.           where Ih is the activation of Pixel h, Wi,h is the weight from
Topological constraints on detector creation are                 Pixel h to Detector i, and S is the similarity between pixels h
incorporated by two mechanisms: A) input-to-detector             and p. As such, detectors are not only activated directly by
weights "leak" to their neighbors in an amount proportional      presented pixels, but are also activated indirectly by pixels that
to their proximity in the 15 X 15 array, and B) input-to-        are similar to the presented pixels. Thus, a detector will be
detector weights also spread to each other as a function of      likely to be strongly activated by a certain pixel if it is already
their orientation similarity, defined by the inner-product of    activated by other pixels similar to this pixel.
four orientation filters The first mechanism produces               The similarity between two pixels h and p is determined by
detectors that tend to respond to cohesive, contiguous                               n
                                                                                     ∑ Gih Gip Li,h, p
regions of an input. The second mechanism produces                                                          − Dh, p C
detectors that follow the principle of good continuation,              Sh, p = T i=1        n          + Ue
dividing the figure "X" into two crossing lines rather than      Where T and U are weighting factors, Gih is the response of
two kissing sideways "V"s, because the two halves of a           orientation filter i to Pixel h, Li,h,p is the degree to which Pixels
diagonal line will be linked by their common orientation.        h and p fall on a single line with an orientation specified by
Thus, if a detector wins for pixel X (meaning that the           filter i, Dh,p is the Euclidean distance between Pixels h and p,
detector receives the more activation when Pixel X is on         and C is a constant that determines the steepness of the
than any other detector), then the detector will also tend to    distance function. Four orientation filters were applied, at 0,
handle pixels that are close to, and have similar orientations   45, 90, and 135 degrees. The response of each filter was
to, Pixel X. The segmentation network, augmented by
spreading weights according to spatial and orientational
similarity, produces segmentations such as the one shown in
                                                                                                       Original pattern
Panel B of Figure 4.
   Although the segmentation in Panel B is clearly superior
to Panel A’s segmentation, it is still problematic. The pixels
are now coherently organized in line segments, but the line
segments are not coherently organized into connected parts.
                                                                                                              Segmentation
Spreading weights according to spatial similarity should
                                                                      A                                      by competitive
ideally create segmentations with connected lines, but such                                                       learning
segmentations are often not found because of local minima
in the harmony function (the value N defined on the next                                                     Segmentation
page). Local minima occur when a detector develops
specializations for distantly related pixels, and these               B                                     with perceptual
specializations develop into local regions of mutually                                                         constraints
supporting pixels. Adjacent regions will frequently be
controlled by different detectors. Each of the detectors may
have sufficiently strong specializations for local regions that                                                Segmentation with
they will not be likely to lose their specialization, due to the      C                                      perceptual constraints
local relations of mutual support.                                                                                  and annealing
   Our solution to local minima is to incorporate simulated
annealing, by which randomness is injected into the system,
and the amount of randomness decreases as a function of
time. Unlike standard annealing techniques, we reduce the
                                                                                                             Segmentation when
amount of randomness in the system over time, but do so by            D                                              was previously
basing the amount of randomness on the current structural                                                              diagnostic
goodness of a solution (Hofstadter & Mitchell, 1994).                    Figure 4. Segmentations of the original figure with
                                                                                 incremental improvements from A-D.

found by finding the inner product of the image centered             categorization. Object segmentation can be viewed as the
around a pixel and a 5 X 5 window with the image of one of           specialization of detectors for particular parts within a single
the four lines. Thus, the greater the overlap between the line       input pattern. Object segmentation can isolate single parts
and the image, the greater will be the output of the filter for      of an input pattern that are potentially useful for
the line. The alignment of two pixels along a certain direction      categorization, and categorization can suggest possible ways
was found by measuring the displacement, in pixels, between          of parsing an object that would not otherwise have been
the infinite length lines established by the two                     considered.
pixel/orientation pairs.                                               In order to model the results from the earlier human
Pixel-to-Detector weights are learned via competitive                experiments, the network was first trained on distortions of
learning:                                                            the patterns A, B, C, and D shown in Figure 1, with either a
           M(I p − Wi, p ) + Random(− N, + N) if ∀x(Ai, p ≥ Ax, p ) horizontal or vertical categorization rule. As with the
 ∆Wi, p = 
                          Random(− N, + N) otherwise                human experiment, the distortions were obtained by adding
Where M is a learning rate, and Random(-N,+N) generates              one random line segment to each pattern in a manner that
                                                                     resulted in a fully contiguous form. Following 30 randomly
Gaussian random noise between + and – N. The amount of
                                                                     ordered presentations of distortions of the four patterns, the
noise, N, in adjusting weights is a function of the harmony
                                                                     segmentation network was then presented with the original
across all detectors relative to R, the maximal harmony in the
                                                                     object shown in Figure 5. Segmentations were determined
system:
               n   m   m
                                                                     by examining the stable input-to-detector weight matrix for
  N = R − ∑ ∑ ∑ Ih I pWi,h Wi, p Sh, p                               each of the two detector units.
             i =1 p=1 h =1
                                                                             Parsing Net work Performance
  As such, if similar pixels in similar states have similar
weights to detectors, then the harmony in the system will be
high, and the amount of noise will be low. Thus, the amount                          Or ig inal      Diagnost ic Feat ures From
of randomness in the weight learning process will be inversely                       Object             Prior Cat egorizat ion
proportional to the coherency of the current segmentation.
These learning equations allow the network to regularly create
the segmentation shown in Panel C of Figure 4.
  In the simulations of the segmentation network to be
reported, no attempt was made to find optimally fitting values
of the constants. T and U were set at 0.5, M was set at 0.1,
and C was set to 1.
                                                                                                      20%             60%
Combining the Networks
Considered separately, the categorization and segmentation
networks each can be considered to be models of their
respective tasks. However, they were also designed to
interact, with the aim of accounting for the results from
Pevtzow and Goldstone’s (1994) experiments with human
subjects. The segmentation network, because it shares the                                                            35%
                                                                                                      70%
same input-to-detector weights that were used for the
categorization network, can be influenced by previous
category learning. Detectors that were diagnostic for
categorization will be more likely used to segment a pattern             Figure 5. The segmentation of an ambiguous object is
because they have already been primed. Thus, if a                                 influenced by prior category learning.
particular shape is diagnostic and reasonably natural, the
network will segment the whole into this shape most of the             One hundred subjects were simulated in each of the two
time, as shown in Panel D Figure 4. In short, category               pre-segmentation categorization conditions. As the results
learning can alter the perceived organization of an object.          from Figure 5 indicate, the segmentation of the ambiguous
By establishing multi-segment features along a bank of               original object is influenced by category learning. In
detectors, the segmentation network is biased to parse               particular, the original object tends to be segmented into
objects in terms of these features. Thus, two separate               parts that were previously relevant during category learning
cognitive tasks can be viewed as mutually constraining self-         (column percentages do not add up to 100% because of
organization processes. Categorization can be understood in          rarely occurring alternative segmentations). As such, the
terms of the specialization of perceptual detectors for              results from Pevtzow and Goldstone (1994) are predicted
particular input patterns, where the specialization is               under the additional assumption that response times in a
influenced by the diagnosticity of a segment for

part/whole task are related to the likelihood of generating a subsequently encountered objects. To the person who has a
segmentation that includes the probed part.                   hammer, the world looks like a nail, and to the person who
   In a subsequent test of the networks, the actual wholes    has learned that a particular configuration is relevant for
used by Pevtzow and Goldstone (1994) in their part/whole      categorization, the world looks like it is composed out of
task were presented to the segmentation network. Each         that configuration.
whole was presented 200 times, 100 times preceded by each
of the two possible categorization rules. Out of the 24       Acknowledgments
whole objects tested, segmentations involving                 This research was funded by National Institute of Health
categorization-relevant parts were produced more often than   Grant R01MH56871-01A2, and a Gill fellowship.
segmentations involving irrelevant parts for 19 of the
objects. This comparison controls for any intrinsic           References
differences in naturalness between segmentations of a whole   Behrmann, M., Zemel, R. S., & Mozer, M. C. (1998).
object because the parts that are categorization-relevant for   Object-based attention and occlusion: Evidence from
half of the simulated subjects are irrelevant for the other     normal participants and a computational model. Journal
half. As such, the results from Figure 5 generalize to the      of Experimental Psychology: Human Perception and
actual materials used in the experiment. Human subjects         Performance, 24, 1011-1036.
and the simulation were exposed to same image-based           Goldstone, R. L. (1994). influences of categorization on
materials, rather than presenting a digested and abstracted     perceptual discrimination. Journal of Experimental
stimulus representation to the simulation.                      Psychology: General, 123, 178-200.
                                                              Goldstone, R. L., Steyvers, M., Spencer-Smith, J., &
                                                                Kersten, A. (2000). Interactions between perceptual and
                        Conclusions                             conceptual learning. in E. Diettrich & A. B. Markman
                                                                (Eds.) Cognitive Dynamics: Conceptual Change in
A pair of neural networks were presented that learned to        Humans and Machines. (pp. 191-228). Lawrence
group multiple objects into categories, and learned to group    Erlbaum and Associates.
parts from a single object into segments. More importantly,   Grossberg, S. (1987). Competitive learning: From
the computational modeling provides a mechanism by              interactive activation to adaptive resonance. Cognitive
which one type of grouping influences the other. Category       Science, 11, 23-63.
learning causes detectors to develop, and once these          Hofstadter, D. R., & Mitchell, M. (1994). The Copycat
detectors have developed, there is a tendency to use the        project: A model of mental fluidity and analogy-making.
detectors when segmenting an object into parts.                 In K. J. Holyoak and J. A. Barnden (Eds.) Advances in
   Future work will be necessary compare the model to other     Connectionist and Neural Computation Theory, Volume
existing models that allow for experience-dependent visual      2. (pp. 31-112). Norwood, NJ: Ablex.
object segmentation (e.g. Behrmann et al., 1998; Mozer,       Lesgold, A., Glaser, R., Rubinson, H., Klopfer, D.,
Zemel, Behrmann, & Williams, 1992). Two extensions of           Feltovich, P., & Wang, Y. (1988). Expertise in a complex
the model would clearly be desirable: 1) allowing the model     skill: Diagnosing x-ray pictures. In M. T. H. Chi, R.
to determine for itself how many segments a pattern should      Glaser, & M. J. Farr (Eds.), The nature of expertise. (pp.
be decomposed into, and 2) allowing the computed                315-335). Hillsdale, NJ: Erlbaum.
segmentation of a single pattern to influence its             Mozer, M. C., Zemel, R. S., Behrmann, M., & Williams, C.
categorization. The latter extension is required to fit human   K. I. (1992). Learning to segment images using dynamic
                                                                feature binding. Neural Computation, 4, 650-665.
experimental evidence suggesting that not only does
                                                              Palmer, S. E. (1978). Structural aspects of visual similarity.
category learning influence segmentation, but the perceived
                                                                Memory & Cognition, 6, 91-97.
segmentation of an object influences its categorization
                                                              Pevtzow, R., & Goldstone, R. L. (1994). Categorization and
(Schyns et al, 1998; Wisniewski & Medin, 1994).                 the parsing of objects.     Proceedings of the Sixteenth
   The computational model, and associated experimental         Annual Conference of the Cognitive Science Society.
results, support theories that propose that categorization      (pp. 717-722). Hillsdale, New Jersey: Lawrence Erlbaum
does not simply employ fixed descriptions such as geons,        Associates.
textons, holons, oriented lines segments, or spatial filters, Rumelhart, D. E., & Zipser, D. (1985). Feature discovery
but also creates new object descriptions. The primary           by competitive learning. Cognitive Science, 9, 75-112.
advantage of such a state of affairs is that the perceptual   Schyns, P. G., Goldstone, R. L, & Thibaut, J. (1998).
system can become tuned and specialized to environmental        Development of features in object concepts. Behavioral
demands. Cognitive science researchers who have proposed        and Brain Sciences, 21, 1-54.
particular fixed sets of primitives have been clever, and     Wisniewski, E. J., & Medin, D. L. (1994). On the
have designed primitives that are useful for representing       interaction of theory and data in concept learning.
words, objects, and events. However, everyday people may        Cognitive Science, 18, 221-281.
be almost as clever as these researchers have been, and may   Zemel, R. S., Behrmann, M., Mozer, M. C., & Bavelier, D.
be able to come up with their own sets of elements tailored     (1999). Experience-dependent perceptual grouping and
to important categorizations (Schyns et al, 1998). Once         object-based attention. Unpublished manuscript.
created, these elements are then used for interpreting

