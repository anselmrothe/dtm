UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Babies, Variables, and Relational Correlations
Permalink
https://escholarship.org/uc/item/146148qw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Authors
Gasser, Michael
Colunga, Elianna
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                 Babies, Variables, and Relational Correlations
                                            Michael Gasser (GASSER @ CS . INDIANA . EDU)
                                         Eliana Colunga (ECOLUNGA @ CS . INDIANA . EDU)
                                        Computer Science Department, Cognitive Science Program
                                                               Indiana University
                                                            Bloomington, IN 47405
                               Abstract                                   can learn relationships such as the tendency for ti to imme-
                                                                          diately follow ga. It is sensitive to the content of the items,
   Recent studies have shown that infants have access to highly           not caring about the similarity among different items. For
   useful language acquisition skills. On the one hand, they can          Pinker (1999), this is just the associationism proposed in the
   segment a stream of unmarked syllables into words, based only          eighteenth century by Hume and still proposed as the funda-
   on the statistical regularities present in it. On the other, they
   can abstract beyond these input-specific regularities and gen-         mental mechanism of the mind by modern connectionists and
   eralize to rules. It has been argued that these are two separate       others. The other mechanism, revealed in the experiments of
   learning mechanisms, that the former is simply associationist          Marcus et al. (1999), can learn relationships such as the fact
   whereas the latter requires variables. In this paper we present        that the first syllable in a sequence is the same as the second
   a correlational approach to the learning of sequential regular-
   ities, and its implementation in a connectionist model, which          but different from the third. This mechanism ignores spe-
   accommodates both types of learning. We show that when a               cific content, caring only about sameness or difference. In
   network is made out of the right stuff, specifically, when it has      this sense the second mechanism seems to require variables,
   the ability to represent sameness and the ability to represent         placeholders which are ignorant of their specific content. For
   relations, a simple correlational learning mechanism suffices          Pinker (1999), this mechanism is an instantiation of what was
   to perform both of these tasks. Crucially the model makes dif-
   ferent predictions than the variable-based account.                    proposed by the early rationalists and what we think of today
                                                                          as “symbolic.” Thus Marcus et al. (1999) and Pinker (1999)
                                                                          now believe that the mind, specifically the portion of it used
                           Background                                     in language learning, is both associationist and symbolic.
                                                                             The question, as Marcus et al. (1999) make clear, is not
Two recent papers in Science have demonstrated the remark-                whether connectionist networks can learn to solve both kinds
able language learning abilities that are possessed by infants.           of tasks, but what sorts of mechanisms are required and
In both cases the infants were presented with sequences of                whether these differ for the two tasks. In this paper, we
syllables embodying some sort of regularity and later tested              present a model of the learning of regularities in patterns
with sequences that agreed or disagreed in certain ways with              which accommodates both kinds of patterns in terms of cor-
the training set. In the experiments of Saffran, Aslin, and               relations. We argue that a correlational account, to deal with
Newport (1996), eight-month-olds heard strings of syllables               the tasks in Marcus et al.’s experiment, needs two mecha-
consisting of randomly concatenated three-syllable “words,”               nisms in addition to those usually found in such accounts,
sequences which never varied internally. Thus the transition              neither of which amounts to explicit variables. We show
probabilities within words were higher than between words.                how a connectionist network implementing this theory (the
Later the infants were able to differentiate between these                PLAYPEN architecture) can learn aspects of the Saffran et al.
words and non-word three-syllable sequences which they had                task, as well as the Marcus et al. task. What is crucial about
either heard with less frequency than the words or not heard              this account is not that it handles variable-like behavior within
at all. This is taken as evidence that they had picked up the             a correlational framework but that it makes predictions that
statistics in the training set. Marcus, Vijayan, Bandi Rao,               differ from the variable-based account.
and Vishton (1999) presented seven-month-olds with series
of three-syllable sequences separated by gaps. Each sequence
consisted of two different syllables arranged in a fixed pat-
                                                                                        Pattern Regularity Learning
tern, AAB, ABB, or ABA. For example, in the ABB condi-                    Saffran et al.’s and Marcus et al.’s experiments are not di-
tion, the presented patterns included sequences such as le di             rectly comparable. In Saffran et al.’s experiments, the bound-
di and ji je je. Later the infants responded differently to novel         aries between the patterns must be extracted, while these are
sequences of three syllables which matched the pattern they               provided in Marcus et al.’s task. However, both are learning
had been trained on than to novel sequences which did not.                tasks in which the learner is presented repeatedly with pat-
This is taken as evidence that they had in some sense picked              terns consisting of sequences of syllables and extracts some
up the rule implicit in the training patterns.                            sort of regularity from the sequences.
   Marcus et al. (1999) and Pinker (1999) argue that the two                 We agree with Marcus et al. and Pinker that there are other
studies, taken together, point to at least two distinct learn-            differences in what is going on in these two tasks, but we
ing mechanisms which are behind language learning. One                    believe that both are fundamentally statistical, based on the
of these, revealed in the experiments of Saffran et al. (1996),           extraction of correlations from input patterns. The main dif-

ference, we argue, lies in what sort of correlations: whether     that higher-order regularities presuppose the pairwise regu-
they are content-specific, as in Saffran et al.’s experiments, or larities which they are built on. Note also that when there are
relational and based on similarity among the elements within      multiple higher-order regularities, as in Saffran et al.’s experi-
the sequences, as in Marcus et al.’s experiments.                 ments, for example, the CORRELATION layer permits these
   We will consider tasks that are more general than those in     different regularities to be kept separate: one set of units and
the two original sets of infant experiments, what will refer      connections might represent the ba gu mi pattern, another the
to as pattern regularity learning. A learning trial for such      vi ja lo pattern.
a task consists of a pattern (not necessarily auditory) com-
posed of elements arranged in a particular way (either sequen-                         CORRELATIONS
tially or spatially), and the regularity consists of tendencies
for patterns to resemble each other in particular ways. Re-
semblances between patterns make reference to the position
of elements within their patterns, where position may be de-
fined spatially or temporally. Regularity could be concerned
only with a single pattern position and not with intra-pattern
relationships; for example, all patterns begin with ba. But we
will only be concerned with regularities that make reference
to intra-pattern relationships, as was the case in both sets of
infant experiments.
Content-Specific Regularities
In Saffran et al.’s experiments, the resemblances between pat-
terns concern the specific content of the patterns. That is, it           position 1          position 2             position 3
is particular syllables which are involved in the regularities;
certain combinations of syllables tend to recur. The simplest                                PATTERN
content-specific regularities (other than those that make ref-
                                                                  Figure 1: Network for learning content-specific regularities. Only
erence to only a single pattern element) are those involving      some units and connections are shown.
pairwise co-occurrences of specific elements or element fea-
tures. Examples of such regularities are the following: ba
tends to be followed by gu; syllables beginning with b tend          Just what gets learned by such a network and how it gener-
to be followed by syllables beginning with g.                     alizes depend on how the pattern elements are represented.
   But the regularities in Saffran et al.’s experiments are more  We assume multiple levels of representations differing in
complex than these. Rather than simple pairwise regulari-         coarseness. That is, at the least coarse level, the elements
                                                                  are represented in terms of the largest number of classes; at
ties, the regularities concern co-occurrences of pairwise co-
occurrences. Examples of such higher-order regularities are:      the most coarse level, they are grouped in terms of a small
when gu is preceded by ba, it tends to be followed by li;         number of classes. Representations in connectionist networks
                                                                  also differ in the extent to which they are distributed vs. lo-
when a syllable beginning with g is preceded by a syllable
beginning with b, it tends to be followed by a syllable begin-    cal. Assuming local representations for the sake of simplicity,
ning with l.                                                      syllables might be represented at multiple levels of coarse-
                                                                  ness as shown in Figure 2. Thus the syllable bis turns on a
   Not surprisingly, these statistical, content-specific regular- unit specific to that syllable, a unit responding to all syllables
ities can be handled in a straightforward fashion in connec-      beginnin with b and a unit responding to all consonant-vowel-
tionist networks. Weights in most connectionist networks          consonant syllables.
represent correlations between elements, and the regulari-
ties we have been describing are just that. However, correla-
tions between correlations, as in the higher-order regularities,
require “handle” units responsible for pairs of particular ele-                            CV                CVC
ments. These handle units can then be joined by connections
whose weights encode the higher-order correlations. Figure 1
shows a network of this type. The network is of the attractor
                                                                                         b_          _i          _s
(generalized Hopfield) type, and weights are adjusted using
the Contrastive Hebbian Learning algorithm (Hopfield, 1984;
Movellan, 1990). For simplicity’s sake, we assume separate
units for the different pattern positions, ignoring the (non-                     bi      ba        ti       bis      tas
trivial) problem of how element representations are shared
across different positions, and we consider only the case of
patterns consisting of three elements. Pairwise regularities      Figure 2: Representation of syllables at multiple levels of coarse-
are represented by strong weights joining pairs of PATTERN        ness. Only a few units are shown. Arrows represent excitatory con-
units to single CORRELATION units. Higher-order regular-          nections joining units at different levels of coarseness. Not shown
                                                                  are inhibitory connections forcing winner-take-all at a given level.
ities are represented by strong weights on connections join-
ing CORRELATION units. Note that this approach assumes

Relational Regularities                                            tectures and algorithms with a further dimension in addition
Alternately, regularity within a set of patterns may be in terms   to activation along which processing units can vary. We will
of the similarity of elements within patterns; that is, the reg-   refer to this as the “binding dimension.” Binding two units
ularity may be relational rather than content-specific. Again      then corresponds to coincidence of those two unit’s values
the regularities may be pairwise or higher-order. Examples         on the binding dimension. Most often the binding dimension
of pairwise relational regularities are the following: the first   involves the firing of units, and binding itself is synchroniza-
element is the same as the second element; the first element       tion of firing (Hummel & Biederman, 1992; Mozer, Zemel,
tends to begin with the same consonant as the second ele-          Behrmann, & Williams, 1992; Shastri & Ajjanagadde, 1993;
ment; the first element is different from the second. Examples     Sporns, Gally, Reeke, & Edelman, 1989). In PLAYPEN we
of higher-order relational regularities are the following: the     make use of a simpler approach: alongside its activation, each
first element tends to be the same as the second element and       unit is characterized by an angle, ranging from 0 to 2 radi-
different from the third; when the first element begins with the   ans. The particular value taken by a unit’s angle is not what
same consonant as the second element, the second element           is relevant; it is its value relative to that of other units in the
has the same vowel as the third.                                   network. Units with similar angles are temporarily “bound”
   In these terms, then, Marcus et al.’s experiments involved      together, treated as “the same thing”; units with very different
both pairwise and higher-order relational regularities, as well    angles (differences close to  radians) are treated as “different
as pairwise and higher-order content-specific regularities,        things.”
though only the relational regularities are reflected in the test     To permit the representation and learning of relational cor-
items.                                                             relations, we need one further augmentation. Rather than
   In what follows, we discuss how relational regularities, as     taking the form of simple connections between units, rela-
well as content-specific regularities, are handled within the      tional correlations are implemented via “handle” units called
PLAYPEN architecture.                                              relation units. These are of two types, sameness units,
                                                                   which tend to be activated if their input units are activated
Accommodating Relational Regularities in a                         and have similar angles, and difference units, which tend to
Connectionist Network                                              be activated if their input units are activated and have dif-
                                                                   ferent angles. Each of these units represents a pairwise re-
Our claim is that relational regularities, like content-specific   lational correlation of one type or the other, and the con-
regularities, are correlations, that is, that they involve statis- nections joining these units represent higher-order relational
tical patterns of co-occurrence. Further we show how rela-         correlations. Thus the architecture we proposed for learning
tional correlations can be learned in a connectionist network      content-specific correlations (Figure 1) becomes that shown
that differs from more conventional networks in that it has        in Figure 3 for relational regularities. Again the network is
an explicit means of representing and learning about similar-      of the attractor type. We have modified the standard input
ity/difference. This requires two augmentations to conven-         and activation functions and the Contrastive Hebbian Learn-
tional networks: (1) a second dimension (the “binding” di-         ing algorithm (Movellan, 1990) to accommodate angles and
mension), in addition to activation, along which units vary,       relation units. For details, see Gasser and Colunga (1998).
and (2) “handle” units which respond to either sameness or
difference on the binding dimension.
   We view the task presented to the learner in Marcus et al.’s                           CORRELATIONS
experiments as one of grouping, a fundamental aspect of all
perceptual processing, both by humans and machines. Pre-
                                                                                                        01                  1
                                                                                                                            0
sented with a visual or auditory scene, people attempt both to
                                                                                                         10                 1
                                                                                                                            0
segment it into distinct regions and to group regions together.
They segment and group by making use of featural similarity,
proximity, and common fate, as well as top-down knowledge
of the domain. For segmentation, proximity obviously plays a
large role, but for grouping, featural similarity may override
proximity. Thus in rhythm perception, where grouping has
been studied extensively (Handel, 1989), two elements that
are separated by another may be grouped together because
of their similarity to each other on some dimension. While
segmentation and grouping are in some sense opposing pro-
cesses, both amount to the binding together of regions that
                                                                                                                       00
                                                                                                                       11
                                                                                                                       00
                                                                                                                       11
would otherwise not be associated with one another.
   Thus any cognitive architecture that handles segmentation               position 1           position 2            position 3
or grouping must offer a solution to the “binding problem,”
the problem of how to represent the short-term situation in                                    PATTERN
which distinct cognitive units are treated as part of the “same
thing.” This problem has been discussed extensively in recent      Figure 3:    PLAYPEN network for learning relational regularities.
                                                                   Only a few units are shown. Difference relation units appear as di-
connectionist literature, and a family of related connectionist    amonds, sameness relation units as ovals. Unit angles are indicated
solutions has been proposed (Shastri & Ajjanagadde, 1993).         by arrows. A single unit within each pattern position has been acti-
All of these involve the augmentation of conventional archi-       vated, leading to the activation of some relation units.

   Note that each unit in this network (as in the network in                             CORRELATIONS
Figure 1) has specific content, but in addition, at any point in
time, through its angle, each unit also represents a hypothesis
about how the elements in the pattern are to be grouped.
Simulation of Marcus et al.’s Experiment                                                                     0110          1
                                                                                                                           0
                                                                                                                           1
                                                                                                                           0
Now consider again the task of Marcus et al.’s experiment.
First, we agree with Seidenberg and Elman (1999) that
knowledge about syllable similarity would have been learned
prior to the experiment so should already be in place in the
architecture. For the PLAYPEN model, this knowledge takes
                                                                                                                         11
                                                                                                                         00
                                                                                                                         00
                                                                                                                         11
                                                                                                                         11
                                                                                                                         00
the form of connections (via sameness and difference units)                  CV                      CV                     CV
representing the similarity or difference between syllables or
syllable features. When the units representing pairs of sylla-
bles are clamped in the PATTERN layer, that is, when their
activations are fixed at some positive value but their angles          le    di     ko        le      di    ko        le
                                                                                                                         11
                                                                                                                         00 di     ko
are still allowed to vary, these connections cause similar syl-           position 1            position 2              position 3
lables to have the same angle and different syllables to have
different angles.                                                                             PATTERN
   We again assume a range of degrees of coarseness in sylla-
ble encodings and, for simplicity, local encodings. The pre-      Figure 4:   PLAYPEN Network implementing Marcus et al. Only a
                                                                  few units are shown. Connections implementing similarity between
sentation of a pattern, say, le le di, takes the form of the      PATTERN element units and inhibitory connections between incom-
clamping of PATTERN units corresponding to these sylla-           patible element units are not shown. The activated (black) units in
bles in the relevant sequential positions. Syllable units at      the PATTERN layer are those that would be active following the pre-
greater degrees of coarseness are activated (inhibitory con-      sentation of the pattern le le di. Four of the relation units that would
                                                                  be activated as a result of this are shown, and ten connections that
nections between incompatible syllable units prevent all syl-     would be strengthened during the resulting learning. Two of these
lable units from being activated as a result of feedback from     connections, those joining the units in the CORRELATIONS layer,
the coarse units). Further because of the built-in (or previ-     represent higher-order relational correlations.
ously learned) relational connections implementing similar-
ity, the angles of the syllables take on a pattern representing
the grouping of the pattern elements: the first two elements      units. Because the PATTERN units include very general ones
make up one group, the third element another. The activated       (for example, one that is activated for any CV syllable in
PATTERN units cause particular CORRELATION units to be            second position), the CORRELATIONS layer should be acti-
activated. For example, the difference unit representing le in    vated relatively highly even by specific syllable sequences it
second position and di in third position and the difference unit  has not been trained on, as long as they are consistent with
representing some CV syllable in second position and some         the training rule.
CV syllable in third position are both activated. Contrastive        The average results from 10 networks trained on each
Hebbian Learning results in the strengthening of connections      grammatical pattern are shown in Figure 5. The total activa-
both into and between the activated CORRELATION units,            tion of the CORRELATIONS layer was averaged over four
as well as possibly the weakening of other connections that       trials of each of the test words. The expected interaction
are not joined by activated units. Figure 4 shows some of the     between training rule and testing rule is highly significant
units and connections that are involved.                          (p < :001). As shown in Figure 5, the CORRELATIONS
   We simulated Marcus et al.’s task by training networks of      layer is more activated for novel sequences that follow the
this type on one of the three grammatical rules: AAB, ABA,        grammatical rule the network was trained on than for novel
or ABB. In each case, the set of training patterns consisted of   sequences that follow either of the other two rules.
four different syllable sequences, each formed by randomly           There are several points to note about the way the network
combining syllables following the appropriate grammatical         learns the tasks.
rule. Each network was trained on 50 repetitions of the train-
                                                                 1. Each unit in the network encodes content information as
ing set.
                                                                     well as relational information. Thus an activated COR-
   The networks were then tested on 12 sequences, four each          RELATION unit represents at the same time the co-
of the three kinds of grammatical rules, by clamping the units       occurrence of particular syllables (or syllable types if it is
corresponding to each sequence. Each of the test sequences           connected to relatively coarse PATTERN units) and the co-
was novel; that is, it was formed by combinations of syllables       occurrence of syllables bearing a particular similarity rela-
that had never been seen before.                                     tion to one another.
   Since training the network leads to the strengthening and
weakening of connections into and within the CORRELA-            2. Though it cannot perform the segmentation that is a part
TIONS layer, test patterns should result in more activation          of Saffran et al.’s task, this network can learn the content-
on the CORRELATIONS layer if they are consistent with the            specific correlations in the three-syllable patterns in the
training set. Thus familiarity with a test pattern was mea-          task. Since each of the patterns consists of three different
sured in the network as activation of the CORRELATIONS               syllables, the PATTERN units would take on three differ-

                                                                                            appearing during training are familiar; if the learner heard the
                               2.5                                                          sequence le le di during training, that sequence will be recog-
activation of grammar layer
                                                                                            nized later on because it matches the AAB rule. Likewise any
                                  2                                                         pattern consisting of three members of the relevant class for
                                                                                            the variables in which the first two elements are identical also
                               1.5                                                          matches. So if the relevant class is CV syllables, even if the
                                                                                            syllables ko and bi did not appear during training, the pattern
                                                                                            ko ko bi will be treated as familiar, apparently just as familiar
                                  1
                                                                                            as le le di since all members of the class match the variables
                                                                                            equally well. Furthermore, the sequences le le le and ko ko ko
                               0.5                                                          are also familiar since, assuming these variables behave like
                                                                                            those in first-order predicate calculus, the rule does not force
                                  0                                                         the third element to be different from the first and second.1
                                            ABB             AAB             ABA                Now consider what patterns would fail to be treated as fa-
 test                                                 training type                         miliar. Since identity is all-or-none, patterns in which the first
type                                  ABB   AAB    ABA                                      two elements are only similar, such as le l" di (where " is the
                                                                                            vowel in bed) would be treated as unfamiliar. Likewise pat-
                                                                                            terns in which the elements are outside the class over which
Figure 5: Networks that have been trained on sequences follow-                              the variables are defined would not be recognized. Thus,
ing a certain grammatical pattern respond with more activation to
novel sequences obeying that same pattern than to novel sequences                           again assuming that CV syllables are the relevant class, les
obeying other patterns.                                                                     les dis would not be seen as familiar.
                                                                                            The Relational Correlation Account
                              ent angles for each pattern, activating difference units in
                                                                                            The relational correlation account that we have presented in
                              the CORRELATIONS layer and resulting in learning on
                                                                                            this paper differs from the rule-based account in that content
                              the connections between these units (representing higher-
                                                                                            still matters. This is because, even when what is learned are
                              order content-specific regularities).
                                                                                            relational, rather than content-specific, correlations, the cor-
3. While this was not true of Marcus et al.’s task, a set of pat-                           relations apply only to a certain range of elements. The ex-
   terns may embody more than one higher-order relational                                   tent of this range depends on the encoding coarseness of the
   regularity. For example, in a set of four-element patterns,                              PATTERN units in question, but given a range of degrees of
   some patterns might be consistent with the rule AABB and                                 coarseness, we can expect some relatively content-specific re-
   others consistent with the rule ABBA. While we are un-                                   lational correlations to be learned, along with some more gen-
   aware of experiments testing the ability of subjects to ex-                              eral relational correlations.
   tract such rules, we assume that the ability to learn multiple                              The implication is that the network’s response will depend
   rules is necessary for language acquisition. A network like                              on the degree of similarity between the training and test pat-
   that in Figure 4 (but with four positions) could learn both                              terns, as well as on whether the training rule is followed. Pat-
   regularities, each as patterns of connections between the                                terns that are identical to the training patterns should result
   six pairwise relational regularities.                                                    in the greatest familiarity. Those that are similar should be
                                                                                            treated as less familiar. Those that are quite different, as in
                                Contrasting Two Accounts of Relational                      Marcus et al.’s experiments, should be still more surprising
                                                                                            (though still less so than novel patterns that do not follow the
                                          Pattern Learning                                  rule).
A Rule-Based Account                                                                           For the network, the notion of the class over which a vari-
A number of models have been proposed to handle the re-                                     able is defined does not exist. Because CVC syllables share
sults of Marcus et al.’s experiments (Christiansen & Curtin,                                some features with CV syllables, we can expect some gen-
1999; Seidenberg & Elman, 1999). Here we contrast only                                      eralization to CVC patterns that follow the rule, especially if
ours and the rule-based account proposed by Marcus (forth-                                  they share segments with the training syllables.
coming). Marcus argues that tasks such as this one, in fact                                    Further, sameness and difference have equal status in the
higher cognition and language generally, rely on the learning                               network, so trained on AAB patterns, the network cannot help
and manipulation of explicit rules containing abstract vari-                                but learn that the third element is different from the first and
ables, placeholders that apply to any member of a given class.                              second, as it learns that first and the second are the same.
   Having been trained on a pattern learning task of the type                               This contrasts with the rule-based approach which requires
in Marcus et al.’s experiments, the learner extracts an explicit                            the learning of an extra predicate to encode the distinctness
rule of the form AAB, where A and B are now abstract vari-                                  of the third element.
ables in Marcus’s sense, and the variables are all associated                                  Finally, difficulty of pattern learning should depend on the
with some class, say the class of CV syllables (the experi-                                 number of distinct syllables in the word. When a pattern has
ments demonstrate only that infants generalize to other mem-                                   1
                                                                                                 Of course, the learner could also extract in addition the explicit
bers of this class).                                                                        constraint that the third element differs from the first and second, but
   Now consider what patterns will be recognized as familiar                                this would seem to be learning “more” than just the rule, so harder
after training. Obviously patterns that are identical to those                              or less likely.

three distinct elements, the built-in connections implement-             ings of the Annual Conference of the Cognitive Science
ing inter-element similarity and difference cause the activated          Society, 21, 114–119.
PATTERN units to repel each other’s angles, resulting in three
different angles. However, depending on the magnitude of           Gasser, M. & Colunga, E. (1998). Where do relations come
the weights connecting the units, there is also an attractor in          from?. Tech. rep. 221, Indiana University, Cognitive
the network at which there are only two different phase an-              Science Program, Bloomington, IN.
gles. At the same time, relation units can represent only bi-      Handel, S. (1989). Listening: An Introduction to the Percep-
nary relations, and strong associations between relation units
                                                                         tion of Auditory Events. MIT Press, Cambridge, MA.
can only develop for different relational regularities involv-
ing the same two objects (as in Marcus et al.’s experiments).      Hopfield, J. (1984). Neurons with graded response have col-
Thus PLAYPEN has a strong preference for two, and in a four-             lective computational properties like those of two-state
syllable version of Marcus et al.’s experiment, we would ex-             neurons. Proceedings of the National Academy of Sci-
pect that sequences such as ABCC would be confused with                  ences, 81, 3088–3092.
AABB and ABBB. In symbolic models, on the other hand,
there is no built-in preference for a particular number of vari-   Hummel, J. E. & Biederman, I. (1992). Dynamic binding in
ables.                                                                   a neural network for shape recognition. Psychological
                                                                         Review, 99, 480–517.
             Conclusions and Future Work
                                                                   Marcus, G. F., Vijayan, S., Bandi Rao, S., & Vishton, P. M.
In this paper we have shown how a connectionist network                  (1999). Rule learning by seven-month-old infants. Sci-
with a mechanism for grouping together activated units (an-              ence, 283, 77–80.
gles) and a mechanism for representing primitive relational
knowledge explicitly (relation units) can learn the task of        Marcus, G. F. (forthcoming). The Algebraic Mind: Integrat-
Marcus et al.’s experiments. While a PLAYPEN network is                  ing Connectionism and Cognitive Science. MIT Press,
perhaps not a conventional neural network, we do not believe             Cambridge, MA.
it has variables hidden in it. But whether it does or not, the
key issue should be whether this model makes different pre-        Movellan, J. (1990). Contrastive Hebbian learning in the con-
dictions from alternate models, specifically from rule-based             tinuous Hopfield model. In Touretzky, D., Elman, J.,
models. We have argued in the last section that this is the              Sejnowski, T., & Hinton, G. (Eds.), Proceedings of the
case. Most of these predictions are testable, and we are cur-            1990 Connectionist Models Summer School, pp. 10–17.
rently performing an experiment using visual patterns and                Morgan Kaufmann, San Mateo, CA.
adult subjects to test the role of similarity to training patterns Mozer, M. C., Zemel, R. S., Behrmann, M., & Williams, C.
in the learning of relational regularities. Preliminary results          K. I. (1992). Learning to segment images using dy-
indicate that subjects are more accurate and faster at judging           namic feature binding. Neural Computation, 4, 650–
the familiarity of patterns following the training rule when             665.
their content is similar to that in the training patterns, as pre-
dicted by our model.                                               Pinker, S. (1999). Out of the minds of babes. Science, 283,
   Another potential contribution of our model is the placing            40–41.
of “rule” learning in the context of segmentation and group-
ing. If we are right, then for auditory patterns such as those     Saffran, J., Aslin, R., & Newport, E. (1996). Statistical learn-
in the two sets of infant experiments discussed here, the con-           ing by eight-month-old infants. Science, 274, 1926–
siderable research on rhythm processing (Handel, 1989) is                1928.
relevant and should lead to a range of predictions. For ex-
ample, we might expect the relative timing or loudness of the      Seidenberg, M. S. & Elman, J. L. (1999). Do infants learn
syllables in patterns to play a role in what is learned.                 grammar with statistics or algebra?. Science, 284, 433.
   Relations obviously play a fundamental role in human cog-       Shastri, L. & Ajjanagadde, V. (1993). From simple asso-
nition, and we have argued elsewhere that the relational cor-            ciations so systematic reasoning: a connectionist rep-
relation framework embodied in PLAYPEN accommodates re-                  resentation of rules, variables, and dynamic bindings
lations without sacrificing the distributed representations and          using temporal synchrony. Behavioral and Brain Sci-
simple Hebbian learning that characterize connectionist net-             ences, 16, 417–494.
works. Indeed the original motivation for PLAYPEN was the
learning of spatial relation terms in language rather than the     Sporns, O., Gally, J. A., Reeke, G. N., & Edelman, G. M.
learning of sequences of syllables. We believe the importance            (1989). Reentrant signaling among simulated neuronal
of Marcus et al.’s experiments is not to demonstrate that in-            groups leads to coherency in their oscillatory activity.
fants can make use of variables but to show that they are good           Proceedings of the National Academy of Sciences, 86,
learners of relational correlations, a capacity that will be cru-        7265–7269.
cial as they are exposed to language in all its complexity.
                          References
Christiansen, M. H. & Curtin, S. L. (1999). The power of sta-
       tistical learning: no need for algebraic rules. Proceed-

