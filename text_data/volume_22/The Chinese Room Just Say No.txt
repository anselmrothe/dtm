UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Chinese Room: Just Say "No!"
Permalink
https://escholarship.org/uc/item/9062452s
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
French, Robert M.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                              Powered by the California Digital Library
                                                                University of California

                                     The Chinese Room: Just Say “No!”
                                                      Robert M. French
                                       Quantitative Psychology and Cognitive Science
                                                       University of Liège
                                                      4000 Liège, Belgium
                                                   email: rfrench@ulg.ac.be
                           Abstract                                Turing’s Test. Unlike other critics of the Chinese Room
   It is time to view John Searle’s Chinese Room thought
                                                                   argument, however, I will not take issue with Searle’s
   experiment in a new light. The main focus of attention          argument per se. Rather, I will focus on the argument’s
   has always been on showing what is wrong (or right)             central premise and will argue that the correct approach
   with the argument, with the tacit assumption being that         to the whole argument is simply to refuse to go beyond
   somehow there could be such a Room. In this article I           this premise, for it is, as I hope to show, untenable.
   argue that the debate should not focus on the question “If
   a person in the Room answered all the questions in                               The Chinese Room
   perfect Chinese, while not understanding a word of
   Chinese, what would the implications of this be for             Instead of Turing’s Imitation Game in which a
   strong AI?” Rather, the question should be, “Does the           computer in one room and a person in a separate room
   very idea of such a Room and a person in the Room who           both attempt to convince an interrogator that they are
   is able to answer questions in perfect Chinese while not        human, Searle asks us to begin by imagining a closed
   understanding any Chinese make any sense at all?” And
   I believe that the answer, in parallel with recent
                                                                   room in which there is an English-speaker who knows
   arguments that claim that it would be impossible for a          no Chinese whatsoever. This room is full of symbolic
   machine to pass the Turing Test unless it had                   rules specifying inputs and outputs, but, importantly,
   experienced the world as we humans have, is no.                 there are no translations in English to indicate to the
                                                                   person in the room the meaning of any Chinese symbol
                       Introduction                                or string of symbols. A native Chinese person outside
                                                                   the room writes questions — any questions — in
Alan Turing’s (1950) classic article on the Imitation              Chinese on a piece of paper and sends them into the
Game provided an elegant operational definition of                 room. The English-speaker receives each question
intelligence. His article is now exactly fifty years old           inside the Room then matches the symbols in the
and ranks, without question, as one of the most                    question with symbols in the rule-base. (This does not
important scientific/philosophical papers of the                   have to be a direct table matching of the string of
twentieth century. The essence of the test proposed by             symbols in the question with symbols in the rule base,
Turing was that the ability to perfectly simulate                  but can include any type of look-up program, regardless
unrestricted human conversation would constitute a                 of its structural complexity.) The English-speaker is
sufficient criterion for intelligence. This way of                 blindly led through the maze of rules to a string of
defining intelligence, for better or for worse, was                symbols that constitutes an answer to the question. He
largely adopted as of the mid-1950’s, implicitly if not            copies this answer on a piece of paper and sends it out
explicitly, as the overarching goal of the nascent field           of the room. The Chinese person on the outside of the
of artificial intelligence (AI).                                   room would see a perfect response, even though the
      Thirty years after Turing’s article appeared, John           English-speaker understood no Chinese whatsoever.
Searle (1980) put a new spin on Turing’s original                  The Chinese person would therefore be fooled into
arguments. He developed a thought experiment, now                  believing that the person inside the room understood
called “The Chinese Room,” which was a reformulation               perfect Chinese.
of Turing’s original test and, in so doing, produced                    Searle then compares the person in the room to a
what is arguably the second most widely read and hotly             computer program and the symbolic rules that fill the
discussed paper in artificial intelligence. While Turing           room to the knowledge databases used by the computer
was optimistic about the possibility of creating                   program. In Searle’s thought experiment the person
intelligent programs in the foreseeable future, Searle             who is answering the questions in perfect written
concluded his article on precisely the opposite note:              Chinese still has no knowledge of Chinese. Searle then
“...no [computer] program, by itself, is sufficient for            applies the conclusion of his thought experiment to the
intentionality.” In short, Searle purported to have                general question of machine intelligence. He concludes
shown that real (human-like) intelligence was                      that a computer program, however perfectly it managed
impossible for any program implemented on a                        to communicate in writing, thereby fooling all human
computer. In the present article I will begin by briefly           questioners, would still not understand what it was
presenting Searle’s well-known transformation of the               writing, any more than the person in the Chinese Room

understood any Chinese. Ergo, computer programs                       Subcognitive Questioning and
capable of true understanding are impossible.                                   the Turing Test
                                                           To understand why such a Room would be impossible,
              Searle’s Central Premise                     which would mean that the person in the Room could
But this reasoning is based on a central premise that      never fool the outside-the-Room questioner, we must
needs close scrutiny.                                      look at an argument concerning the Turing Test first put
     Let us begin with a simple example. If someone        forward by French (1988, 1990, 2000a). French’s claim
began a line of reasoning thus: “Just for the sake of      is that no machine that had not experienced life as we
argument, let’s assume that cows are as big as the         humans had could ever hope to pass the Turing Test.
moon,” you would most likely reply, “Stop right there,     His demonstration involves showing just how hard it
I’m not interested in hearing the rest of your argument    would be for a computer to consistently reply in a
because cows are demonstrably NOT as big as the            human-like manner to what he called “subcognitive”
moon.” You would be justified in not allowing the          questions. Since Searle’s Chinese Room argument is
person to continue to his conclusions because, as          simply a reformulation of the Turing Test, we would
logical as any of his subsequent reasoning might be,       expect to be able to apply these arguments to the
any conclusion arising from his absurd premise would       Chinese Room as well, something which we will do this
be unjustified.                                            later in this paper.
     But when are we justified in accepting                     It is important to spend a moment reviewing the
demonstrably false premises for the sake of argument?      nature and the power of “subcognitive” questions.
If a discussion began by supposing that the work week      These are questions that are explicitly designed to
was 30 hours long, instead of 40, it would be ridiculous   provide a window on low-level (i.e., unconscious)
to reply, “But the work week is demonstrably NOT 30        cognitive or physical structure. By "low-level cognitive
hours long, therefore I am not interested in hearing the   structure", we mean the subconscious associative
rest of your argument.” On the other hand, if a            network in human minds that consists of highly
discussion began by assuming that Lee Harvey Oswald        overlapping activatable representations of experience
was an ice-cream cone — however logically possible         (French, 1990). Creating these questions and,
this might be — one would certainly be justified in        especially, gathering the answers to them require a bit
evoking the I-don’t-want-to-hear-anymore response.         of preparation on the part of the Interrogator who will
Space prevents us from attempting to delineate these       be administering the Turing Test.
two types of counterfactual premises, but suffice it to         The Interrogator in the Turing Test (or the
say that the mere logical possibility of a premise is not  Questioner in the Chinese Room) begins by preparing a
necessarily enough for it to serve as the basis of an      long list of these questions — the Subcognitive
argument in which we hope to derive truths about the       Question List. To get answers to these questions, she
real world, especially if we can demonstrate the           ventures out into an English-language population and
nomological impossibility of the premise. Dennett          selects a representative sample of individuals from that
(1996) makes a similar point regarding Davidson’s          population. She asks each person surveyed all the
(1986) Swampman argument.                                  questions on her Subcognitive Question List and
     In this light, let us consider the central premise on records their answers. The questions along with the
which Searle’s argument hangs — namely, that there         statistical range of answers to these questions will be
could be such a thing as a “Chinese Room” in which an      the basis for her Human Subcognitive Profile. Here are
English-only person could actually fool a native-          some of the questions on her list (French, 1988, 1990).
Chinese questioner. I hope to show that this premise is
no more plausible than the existence of lunar-sized        Questions using neologisms:
cows and, as a result, we have no business allowing           "On a scale of 0 (completely implausible) to 10
ourselves to be drawn into the rest of Searle’s               (completely plausible):
argument, any more than when we were asked to accept            - Rate Flugblogs as a name Kellogg's would give
that all cows were the size of the moon.                           to a new breakfast cereal.
     Ironically, the arguments in the present paper             - Rate Flugblogs as the name of start-up computer
support Searle’s point that symbolic AI is not sufficient          company
to produce human-like intelligence, but do so not by            - Rate Flugblogs as the name of big, air-filled bags
comparing the person in the Chinese Room to a                      worn on the feet and used to walk across
computer program, but rather by showing that the                   swamps.
Chinese Room itself would be an impossibility for a             - Rate Flugly as the name a child might give to a
symbol-based AI paradigm.                                          favorite teddy bear.
                                                                - Rate Flugly as the surname of a bank accountant
                                                                   in a W. C. Fields movie.

     - Rate Flugly as the surname of a glamorous female            fingers, your two thumbs, etc.). What happens to
        movie star.                                                your other fingers? (Try it!)
     “Would you like it if someone called you a            We can imagine many more questions that would be
        trubhead? (0= not at all, ..., 10 = very much)”    designed to test not only for subcognitive associations,
                                                           but for internal physical structure. These would include
     “Which word do you find prettier: blutch or           questions whose answers would arise, for example,
        farfaletta?”                                       from the spacing of a human’s eyes, would be the
                                                           results of little self-experiments involving tactile
Note that the words flugblogs, flugly, trubhead, blutch    sensations on their bodies or sensations after running in
and farfaletta are made-up. They will not be found in      place, and so on.
any dictionary and, yet, because of the uncountable             People’s answers to subcognitive questions are the
influences, experiences and associations of a lifetime of  product of a lifetime of experiencing the world with our
hearing and using English, we are able to make             human bodies, our human behaviors (whether culturally
judgments about these neologisms. And, most                or genetically engendered), our human desires and
importantly, while these judgments may vary between        needs, etc. (See Harnad (1989) for a discussion of the
individuals, their variation is not random. For example,   closely related symbol grounding problem.)
the average rating of Flugly as the surname of a                I have asked people the question about Coca-Cola
glamorous actress will most certainly fall below the       and pins-and-needles many times and they
average rating of Flugly as the name for a child’s teddy   overwhelmingly respond that holding a soft-drink in
bear. Why? Because English speakers, all of us, have       their mouth feels more like having pins and needles in
grown up surrounded by roughly the same sea of             their foot than having cold water poured on them.
sounds and associations that have gradually formed our     Answering this question is dead easy for people who
impressions of the prettiness (or ugliness) of particular  have a head and mouth, have drunk soft-drinks, have
words or sounds. And while not all of these associations   had cold water poured on their head, and have feet that
are identical, of course, they are similar enough to be    occasionally fall asleep. But think of what it would take
able to make predictions about how, on average,            for a machine that had none of these to answer this
English-speaking people will react to certain words and    question. How could the answer to this question be
sounds. This is precisely why Hollywood movie moguls       explicitly programmed into the machine? Perhaps (after
gave the name “Cary Grant” to a suave and handsome         reading this article) a programmer could put the
actor born “Archibald Alexander Leach” and why             question explicitly into a vast CYC-like computer
“Henry Deutschendorf, Jr.” was re-baptised “John           database (Lenat & Guha, 1990), but there are infinitely
Denver.”                                                   many questions of this sort and to program them all in
                                                           would be impossible. A program that could answer
Questions using categories:                                questions like these in a human-like enough manner to
      - Rate banana splits as medicine.                    pass a Turing Test would have had to have experienced
      - Rate purses as weapons.                            the world in a way that was very similar to the way in
      - Rate pens as weapons.                              which we had experienced the world. This would mean,
      - Rate dry leaves as hiding places.                  among many other things, that it would have to have a
                                                           body very much like ours with hands like ours, with
No dictionary definition of “dry leaves” will include in   eyes where we had eyes, etc. For example, if an
its definition “hiding place,” and, yet, everyone who      otherwise perfectly intelligent robot had its eyes on its
was ever a child where trees shed their leaves in the fall knees, this would result in detectably non-human
knows that that piles of dry leaves make wonderful         associations for such activities as, say, praying in
hiding places. But how could this information, and an      church, falling when riding a bicycle, playing soccer, or
infinite amount of information just like it that is based  wearing pants.
on our having experienced the world in a particular             The moral of the story is that it doesn’t matter if we
way, ever be explicitly programmed into a computer?        humans are confronted with made-up words or
                                                           conceptual juxtapositions that never normally occur
Questions relying on human physical sensations:            (e.g., dry leaves and hiding place), we can still respond
                                                           and, moreover, our responses will show statistical
     - Does holding a gulp of Coca-Cola in your mouth
                                                           regularities over the population. Thus, by surveying the
        feel more like having pins-and-needles in your
                                                           population at large with an extensive set of these
        foot or having cold water poured on your head?
                                                           questions, we draw up a Human Subcognitive Profile
     - Put your palms together, fingers outstretched and   for the population. It is precisely this subcognitive
        pressed together. Fold down your two middle        profile that could not be reproduced by a machine that
        fingers till the middle knuckles touch. Move the   had not experienced the world as the members of the
        other four pairs of fingers (i.e., your two index  sampled human population had. The Subcognitive
                                                           Question List that was used to produce the Human

Subcognitive Profile gives the well-prepared             symbolic rules would require essentially an infinite
Interrogator a sure-fire tool for eliminating machines   amount of space. And while rooms in thought
from a Turing test in which humans are also              experiments can perhaps be infinitely large, the
participating. The Interrogator would come to the        computers that they are compared to cannot be.
Turing Test and ask both candidates the questions on           In other words, the moral of the story here, as it
her Subcognitive Question List. The candidate most       was for the machine trying to pass the Turing Test, is
closely matching the average answer profile from the     that no matter how many symbolic rules were in the
human population will be the human.                      English Room they would not be sufficient for someone
                                                         who did not understand written English to fool a
                 The English Room                        determined English questioner. And this is where the
                                                         story should rightfully end. Searle has no business
Now let us see how this technique can be gainfully       taking his argument any further — and, ironically, he
applied to Searle’s Chinese Room thought experiment.     doesn’t need to, since the necessary inadequacy of an
We will start by modifying Searle’s original             such a Room, regardless of how many symbolic rules it
Gedankenexperiment by switching the languages            contains, proves his point about the impossibility of
around. This, of course, has no real bearing on the      achieving artificial intelligence in a traditional symbol-
argument itself, but it will make our argument easier to based framework. So, when Searle asks us to accept
follow. We will assume that inside the Room there is a   that the English-only human in his Chinese Room could
Chinese person (let’s call him Wu) who understands not   reply in perfect written Chinese to questions written in
a word of written English and outside the Room is a      Chinese, we must say, “That’s strictly impossible, so
native speaker/writer of English (Sue). Sue sends into   stop right there.”
the Room questions written in English and Wu must
produce the answers to these questions in English.
Now, it turns out that Sue is not your average naive          Shift in Perception of the Turing Test
questioner, but has read many articles on the Turing     Let us once again return to the Turing Test to better
Test, knows about subcognitive questions and is          understand the present argument.
thoroughly familiar with John Searle’s argument. She           It is easy to forget just how high the optimism once
also suspects that the person inside the (English) Room  ran for the rapid achievement of artificial intelligence.
might not actually be able to read English and she sets  In 1958 when computers were still in their infancy and
out to prove her hunch.                                  even high-level programming languages had only just
     Sue will not only send into the Room questions      been invented, Simon and Newell, two of the founders
like, “What is the capital of Cambodia?”, “Who painted   of the field of artificial intelligence, wrote, “...there are
The Mona Lisa?” or “Can fleas fly?” but will also ask a  now in the world machines that think, that learn and
large number of “subcognitive questions.” Because the    that create. Moreover, their ability to do these things is
Room, like the computer in the Turing Test, had not      going to increase rapidly until – in a visible future – the
experienced the world as we had and because it would     range of problems they can handle will be coextensive
be impossible to explicitly write down all of the rules  with the range to which the human mind has been
necessary to answer subcognitive questions in general,   applied.” (Simon & Newell, 1958). Marvin Minsky,
the answers to the full range of subcognitive questions  then head of the MIT AI Laboratory, wrote in 1967,
could not be contained in the lists of symbolic rules in “Within a generation the problem of creating ‘artificial
the Room. Consequently, the person in the Room would     intelligence’ will be substantially solved” (Minsky,
be revealed not to speak English for exactly the same    1967).
reason that the machine in the Turing Test would be            During this period of initial optimism, the vast
revealed not to be a person.                             majority of the authors writing about the Turing Test
     Take the simple example of non existent words like  tacitly accepted Turing’s premise that a machine might
blutch or trubhead. These words are neologisms and       actually be able to be built that could pass the Test in
would certainly be nowhere to be found in the symbolic   the foreseeable future. The debate in the early days of
rules in the English Room. Somehow, the Room would       AI, therefore, centered almost exclusively around the
have to contain, in some symbolic form, information      validity of Turing’s operational definition of
not only about all words, but also non-words as well.    intelligence — namely, did passing the Turing Test
But the Room, if it is to be compared with a real        constitute a sufficient condition for intelligence or did it
computer, cannot be infinitely large, nor can we assume  not? But researchers’ views on the possibility of
infinite fast search of the rule base (see Hofstadter &  achieving artificial intelligence shifted radically
Dennett, 1981, for a discussion of this point). So, we   between the mid-1960’s and the early 1980’s. By 1982,
have two closely related problems: First, and most       for example, Minsky’s position regarding achieving
crucially, how could the rules have gotten into the      artificial intelligence had undergone a radical shift from
Room in the first place (a point that Searle simply      one of unbounded optimism 15 years earlier to a far
ignores)? And secondly, the number of explicit           more sober assessment of the situation: “The AI

problem is one of the hardest ever undertaken by           generating rules that would be put in the Chinese
science” (Kolata, 1982). The perception of the Turing      Room.
Test underwent a parallel shift. At least in part because        This is much closer to what would be required to
of the great difficulties being experienced by AI, there   have the appropriate “rules,” but still leaves open the
was a growing realization of just how hard it would be     question of how you could ever come up with such a
for a machine to ever pass the Turing Test. Thus,          Robot. The Robot would have to be able to interact
instead of discussing whether or not a machine that had    seamlessly with the world, exactly as a Chinese person
passed the Turing Test was really intelligent, the         would, in order to have been able to produce all the
discussion shifted to the question of whether it would     “rules” (high-level and subcognitive) that would later
even be possible for any machine to pass such a test       allow the person in the Room to fool the Well-Prepared
(Dennett, 1985; French, 1988, 1990; Crockett 1994;         Questioner. But then we are back to square one, for
Harnad, 1989; for a review, see French, 2000b).            creating such a robot amounts to creating a robot that
                                                           would pass the Turing Test.
 The Need for a Corresponding Shift in the
        Perception of the Chinese Room                        The Chinese Room: a Simple Refutation
A shift in emphasis identical to the one that has          It must be reiterated that when Searle is attacking the
occurred for the Turing Test is now needed for Searle’s    “strong AI” claim that machines processing strings of
Chinese Room thought experiment. Searle’s article was      symbols are capable of doing what we humans call
published in pre-connectionist 1980, when traditional      thinking, he is explicitly talking about programs
symbolic AI was still the dominant paradigm in the         implemented on computers. It is important not to ignore
field. Many of the major difficulties facing symbolic AI   the fact, as some authors unfortunately have (e.g.,
had come to light, but in 1980 there was still little      Block, 1981), that computers are real machines of finite
emphasis on the “sub-symbolic” side of things.             size and speed; they have neither infinite storage
     But the growing difficulties that symbolic AI had     capacity nor infinite processing speed.
in dealing with “sub-symbolic cognition” were                    Now consider the standard Chinese Room, i.e., the
responsible, at least in part, for the widespread appeal   one in which the person inside the Room has no
of the connectionist movement of the mid-1980’s.           knowledge of Chinese and the Questioner outside the
While several of the commentaries of Searle’s original     Room is Chinese. Assume that the last character of the
article (Searle, 1980) briefly touch on the difficulties   following question is distorted in an extremely phallic
involved in actually creating a Chinese Room, none of      way, but in a way that nonetheless leaves the character
them focus outright on the impossibility of the Chinese    completely readable to any reader of Chinese: “Would
Room as described by Searle and reject the rest of the     the last character of this sentence embarrass a very shy
argument because of its impossible premise. But this       young woman?” In order to answer this question
rejection corresponds precisely to rejecting the idea that correctly — a trivially easy task for anyone who
a machine (that had not experienced the world as we        actually reads Chinese — the Chinese Room would
humans have) could ever pass the Turing Test, an idea      have to contain rules that would not only allow the
that many people now accept. We are arguing for a          person to respond perfectly to all strings of Chinese
parallel shift in emphasis for the Chinese Room            characters that formed comprehensible questions, but
Gedankenexperiment.                                        also to the infinitely many possible legible distortions
                                                           of those strings of characters. Combinatorial explosion
          Can the “Robot Reply” Help?                      brings the house down around the Chinese Room.
                                                           (Remember, we are talking about real computers that
It is necessary to explore for a moment the possibility    can store a finite amount information and must retrieve
that one could somehow fill the Chinese Room with all      it in a finite amount of time.)
of the appropriate rules that would allow the non-               One might be tempted to reply, “The solution is to
Chinese-reading person to fool a no-holds-barred           eliminate all distortions. Only standard fonts of Chinese
Chinese questioner. Where could rules come from that       characters are permitted.” But, of course, there are
would allow the person in the Chinese Room to answer       hundreds, probably thousands, of different fonts of
all of the in-coming questions in Chinese perfectly?       characters in Chinese (Hofstadter, 1985) and it is
One possible reply is a version of the Robot Reply         completely unclear what would constitute “standard
(Searle, 1980). Since the rules couldn’t have been         fonts.” In any event, one can sidestep even this
symbolic and couldn’t have been explicitly                 problem.
programmed in for the reasons outlined above (also see           Consider an equivalent situation in English. It
French, 1988, 1990), perhaps they could have been the      makes perfect sense to ask, “Which letter could be most
product of a Robot that had experienced and interacted     easily distorted to look like a cloud: an ‘O’ or an ‘X’?”
with the world as we humans would have, all the while      An overwhelming majority of people would, of course,
                                                           reply “O”, even though clouds, superficially and

theoretically, have virtually nothing in common with       Davidson, D. (1990) Turing's test. In Karim A. Said et
the letter “O”. But how could the symbolic rules in           al. (eds.), Modelling the Mind. Oxford University
Searle’s Room possibly serve to answer this perfectly         Press, 1-11.
legitimate question? A theory of clouds contained in the   Davidson, D. (1986). Knowing One's Own Mind,
rules certainly wouldn’t be of any help, because that          Proceedings and Addresses of the American
would be about storms, wind, rain and meteorology. A           Philosophical Association, 60 (3), p.443.
theory or database of cloud forms would be of scant        Dennett, D. (1985) Can machines think? In How We
help either, since clouds are anything but two                Know. (ed.) M. Shafto. Harper & Row
dimensional, much less round. Perhaps only if the          Dennett, D. (1996). Cow-Sharks, Magnets, and
machine/Room had grown up scrawling vaguely                   Swampman. Mind and Language, 11(1):76-77.
circular shapes on paper and calling them clouds in        French, R. M. (1988). Subcognitive Probing: Hard
kindergarten and elementary school, then maybe it             Questions for the Turing Test. Proceedings of the
would be able to answer this question. But short of           Tenth Annual Cognitive Science Society Conference,
having had that experience, I see little hope of an a         Hillsdale, NJ: LEA. 361-367.
priori theory of correspondence between clouds and         French, R. M. (1990). Subcognition and the Limits of
letters that would be of any help.                            the Turing Test. Mind, 99(393), 53-65. Reprinted in:
                                                              P. Millican & A. Clark (eds.). Machines and
                      Conclusion                              Thought: The Legacy of Alan Turing Oxford, UK:
                                                              Clarendon Press, 1996.
The time has come to view John Searle’s Chinese            French, R. M. (2000a). Peeking Behind the Screen: The
Room thought experiment in a new light. Up until now,         Unsuspected Power of the Standard Turing Test.
the main focus of attention has been on showing what is       Journal of Experimental and Theoretical Artificial
wrong (or right) with the argument, with the tacit            Intelligence. (in press).
assumption being that somehow there could be such a        French, R. M. (2000b). The Turing Test: The First Fifty
Room. This parallels the first forty years of discussions     Years. Trends in Cognitive Sciences, 4(3), 115-122.
on the Turing Test, where virtually all discussion         Harnad, S. (1989) Minds, machines and Searle. Journal
centered on the sufficiency of the Test as a criterion for    of Experimental and Theoretical Artificial
machine intelligence, rather than whether any machine         Intelligence, 1, 5-25
could ever actually pass it. However, as the               Hofstadter, D. (1985). Variations on a Theme as the
overwhelming difficulties of AI gradually became              Crux of Creativity. In Metamagical Themas. New
apparent, the debate on the Turing Test shifted to            York, NY: Basic Books. p. 244.
whether or not any machine that had not experience the     Hofstatder, D. & Dennett, D. (1981). The Mind’s I.
world as we had could ever actually pass the Turing           New York, NY: Basic Books.
Test. It is time for an equivalent shift in attention for  Kolata, G. (1982) How can computers get common
Searle’s Chinese Room. The question should not be, “If        sense? Science, 217, p. 1237
a person in the Room answered all the questions in         Lenat, D. & Guha, R. (1990). Building Large
perfect Chinese, while not understanding a word of             Knowledge-Based Systems. Reading, Mass.:
Chinese, what would the implications of this be for            Addison-Wesley.
strong AI?"” Rather, the question should be, “Does the     Minsky, M. (1967) Computation: Finite and Infinite
very idea of such a Room and a person actually be able        Machines. Prentice-Hall, p. 2
to answer questions in perfect Chinese while not           Searle, J. R. (1980). Minds, brains, and programs.
understanding any Chinese make any sense at all?” And         Behavioral and Brain Sciences, 3, 414-424.
I believe that the answer, in parallel with the            Simon, H. and Newell, A. (1958) Heuristic problem
impossibility of a machine passing the Turing Test, is         solving: The next advance in operations research.
no.                                                            Operations Research, 6
                  Acknowledgments
The present paper was supported in part by research
grant IUAP P4/19 from the Belgian government.
                      References
Block, N. (1981) Psychologism and behaviourism.
    Philosophical Review, 90, 5-43
Crockett, L. (1994) The Turing Test and the Frame
    Problem: AI’s Mistaken Understanding of
    Intelligence. Ablex

