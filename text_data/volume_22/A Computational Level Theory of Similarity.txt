UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Level Theory of Similarity
Permalink
https://escholarship.org/uc/item/6j78d0zm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
Love, Bradley C.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                   A Computational Level Theory of Similarity
                                                                Bradley C. Love
                                                          Department of Psychology
                                                      The University of Texas at Austin
                                                                    MEZ 330
                                                            Austin, TX 78712 USA
                                                             love@psy.utexas.edu
                               Abstract                                      Tversky’s (1977) contrast model is a non-metric set-
   Why are some pairs of objects (or events) perceived to be more
                                                                          theoretic account of perceived similarity that aims to address
   similar to each other than other pairs? A computational level          some of the shortcoming of the distance models. Tversky’s
   theory of perceived similarity is presented that extends previ-        model is based on evaluating sets of matching and mismatch-
   ous geometric and set-theoretic formulations. Like previous            ing features:
   approaches, the current account posits that the similarity of
   two objects is a function of the common and distinctive fea-
   tures of the two objects. Unlike previous approaches, simi-            sim(x; y) = 1F(X \ Y )           2 F(X     Y)       3 F(Y    X)   (1)
   larity is also a function of higher-order compatibility relations
   among features (as it is in models of analogy). Objects (or con-
                                                                                                                    where    1 ; 2; 3 0
   cepts) are represented as directed feature graphs as opposed
   to feature vectors or sets. Like current accounts of human
                                                                          where   sim  (x; y) reads “the similarity of x to y,” X is the
   analogical processing, the approach presented here holds that          set of features that represents x, Y is the set of features that
   representational elements are put into correspondence during           represents y , X \ Y is the set of features common to x and y ,
   the comparison processes. Correspondences are chosen in or-
   der to maximize an objective function. The function contains
                                                                          X Y is the set of features uniquely possessed by x, Y X
   four terms that are motivated by theories of human compari-            is the set of features uniquely possessed by y , 1 , 2 , and 3
   son. The maximum of the function is monotonically related              are free parameters, and F is a function over sets of features
   to perceived similarity. Thus, similarity is characterized as the      related to the features’ saliency. For simplicity and without
   byproduct of comparison and structural alignment. The objec-
   tive function serves as a quantitative computational level the-        loss of generalization, we assume here that all features are
   ory of human comparison.                                               equally salient:
                                                                                                    F (X ) = jX j                       (2)
                           Introduction                                   where jX j denotes the cardinality of the set X . Of course, in
Since William James (1890/1950), psychologists have held                  many situations certain features will weigh more heavily on
that detecting the “sameness” or similarity of objects is at              the evaluation of similarity than other features.
the backbone of cognition. Clearly, detecting similarities be-               Tversky’s contrast model can account for asymmetries that
tween novel events and previous experiences is crucial in rea-            occur in similarity judgments. For example, “North Korea”
soning, analogy, and object recognition. Many theories of                 is rated as being more similar to “China” than vice versa.
category learning hold that similarity is the basis for catego-           The contrast model can explain such asymmetries by setting
rization (see [7]). A fundamental question then is what makes               2 > 3 . Ostensibly, when comparing x and y , the focus is
two objects similar?                                                      on first term x, which I will refer to as the target, and not on
   Almost all accounts of perceived similarity hold that sim-             the second term, which I will refer to as the base. Both x and
ilarity increases as the number of feature matches increases              y will be referred to as analogs. In the example above, most
and decreases as the number of feature mismatches increases.              people know more about China than North Korea. Accord-
In geometric models of similarity, such as multidimensional               ingly, when evaluating how similar China is to North Korea
scaling (MDS) models of similarity, concepts or objects are               jX Y j will be larger than jY X j. Another comparison
represented as points in a multidimensional space and sim-                related explanation for asymmetries is that subjects prefer the
ilarity is inversely related to the distance between points in            base to be the object out of an object pair that allows for more
the space [20]. Objects that match on many features will be               analogical inferences to be projected [1]. Such asymmetries
closer together in the space than objects that mismatch on                may be attributable to the similarity predicate in particular.
a number of features. Unfortunately, the axioms of metric                 Another alternative is that asymmetries arise from general
spaces (e.g., minimality, symmetry, and the triangle inequal-             principles related to sentence interpretation such as the fig-
ity) appear to be violated by human similarity judgments (see             ure/ground relationship between the target and base [21] or
[22]). More recently, Medin, Goldstone, and Gentner (1993)                from general syntactic properties [6].
have demonstrated that an object can be rated as both more                   Although the contrast model can address a wide range of
similar and more dissimilar to the same object in an object               data, it cannot account for judgments of similarity that are re-
pair, which seems problematic for distance models.                        lational or analogical in nature. Two analogs can be similar

                                                                                                                                            Relational Match                                             Relational Mismatch
even when the analogs do not have many features in common.
To use Gentner’s example, one reason people judge the solar                                                                               Likes                               Respects                   Likes                               Respects
system and an atom as being similar is that our representa-
                                                                                                                                                                                                                                                                Feature Match
                                                                                                                                  Liker            Likee            Respecter        Respectee   Liker            Likee            Respecter        Respectee
tions of these two systems share a number of higher-order re-                                                                                     Bill                    Steve                                  Bill                    Steve
lational matches (as opposed to simple feature matches). For                 Likes                             Respects
                                                                                                                                                         Male     Human                                                 Male     Human
example, electrons revolving around a larger nucleus can be          Liker            Likee          Respecter        Respectee
                                                                                                                                                    Bill likes Steve.                                              Bill likes Steve.
put in correspondence with planets revolving around a larger                                                                                        Steve respects Bill.                                           Bill respects Steve.
                                                                                     Jeff                  Keith
sun. Although the elements of the two systems are not in-                                                                                 Likes                               Respects                   Likes                               Respects
                                                                                            Male   Human
herently similar (e.g., a nucleus and the sun differ in size
                                                                                                                                                                                                                                                                Feature Mismatch
                                                                                       Jeff likes Keith.                          Liker            Likee            Respecter        Respectee   Liker            Likee            Respecter        Respectee
and composition), the two analogs are judged to be similar                             Keith respects Jeff.
because a mapping between the two systems exists that pre-                                                                                        Lisa                    Anne                                   Lisa                    Anne
serves higher-order commonalities (e.g., the sun maps to the                                                                                             Female   Human                                                 Female   Human
                                                                                                                                                    Lisa likes Anne.                                               Lisa likes Anne.
nucleus and the planets map to the electrons). Of course,                                                                                           Anne respects Lisa.                                            Lisa respects Anne.
there are simpler cases of different dimensions being put in
correspondence. For example, people equate high-pitched             Figure 1: The target analog and its corresponding represen-
sounds with bright lights and when asked, “Which is brighter,       tation S x are shown to the left of the dividing line (subjects
a sneeze or a cough?” people readily answer that a sneeze is        were not shown S x , just the text). To the right of the dividing
brighter [16]. The contrast model assumes that only identical       line, an example base analog is shown for each of the four
features can match and does not envisage a matching process         conditions (along with its S y ).
that attempts to preserve higher-order compatibilities.
   More current models of comparison and analogy (e.g.,
                                                                    “added value.” Many current models do have “added value.”
[2, 13, 11]) do establish relational correspondences when
                                                                    For example LISA [11] makes predictions about how working
comparing objects. These models tend to prefer mappings
                                                                    memory limitations and discourse setting affects comparison,
between analogs when 1) identical features can be mapped
                                                                    MAC/MAC [3] explicitly models retrieval processes in com-
to one another, 2) there are higher-order compatibilities and
                                                                    parison, and IAM [13] focuses on the incremental nature of
structures replicate in both analogs, 3) the mapping between
                                                                    analogical mapping.
the two analogs is or almost is one-to-one. Although these
                                                                      Although theories of comparison hold that similarity and
constraints are common to all successful models of human
                                                                    analogical processing are deeply related [5], the linkage be-
comparison, it is not always clear how these constraints are
                                                                    tween similarity and comparison is even more direct in the
weighted and manifested in models. In other words, different
                                                                    similarity equation. In the similarity equation, the correspon-
models may adopt widely different matching algorithms (e.g.,
                                                                    dences (i.e., mappings) between the two analogs are chosen
[2, 11]), but can be quite similar at the computational level of
                                                                    so as to maximize the similarity equation, much like how an
analysis (in the sense of Marr, 1982). It is important to know
                                                                    energy function is minimized in a Hopfield network when
what the commonalities and differences of competing models
                                                                    performing a computation [10]. The maximal value of the
are in order to identify the critical issues that deserve empiri-
                                                                    similarity equation is monotonically related to the perceived
cal investigation.
                                                                    similarity of the two analogs. Thus, similarity both drives
   The goal of this paper is to specify a computational level       the comparison process and is an outcome of it. In the re-
theory of comparison and similarity that is quantitative, eas-      mainder of the paper, the details of the similarity equation are
ily understood, and falsifiable. The computational level the-       presented as well as some data fits.
ory takes the form of a similarity equation consisting of four
terms that combine linearly (weighted by parameters). Unlike                                                       Mathematical Formulation
algorithmic level models where principles are often obscured        Analogs x and y are represented as directed graphs. Analog
within the details of the processing mechanisms, principles in      x has m different representational elements or nodes, while
the similarity equation appear as separate terms and it is clear    analog y has n. S x is an m by m matrix that capture the
how different principles are weighted. Best fitting parameters      connectivity of analog x. Each entry in S x is either 0 or 1.
for a data set are interpretable and clear predictions can be       S24
                                                                      x
                                                                          set to 1 signifies that node 2 binds to node 4. Notice that
made about how the best fitting parameters should change as         this relationship is not symmetrical — part 4 is a parent of part
task demands change.                                                2, but part 2 is not necessarily a parent of part 4. Analog y is
   Such a theory might make the common ground between               represented in an identical fashion by S y . Figure 1 illustrates
models more obvious to the extent that process models con-          some examples of analogs and the graphs that represent them.
form to the same underlying computational level theory. A              In evaluating the similarity of x to y , correspondences are
successful computational level theory would also make each          established between the representational elements of x and y
algorithmic model’s contribution to the field clearer. For in-      (i.e., the nodes in S x and S y ) . These correspondences or
stance, a model that simply conformed to the computational          mappings are recorded in the m by n matrix A. Each entry
level theory and made no new predictions would have no              in A is either 0 or 1. A ij equal to 1 indicates that element x i

(of x) maps to element y j (of y ). The mappings are selected          than commonalities (or matches) that are not in correspon-
so as to maximize the value of the similarity equation. The            dence [8]. Likewise, differences that can be put into corre-
idea is that perceived similarity arises out of a comparison           spondence are psychologically distinct from differences that
process that establishes mappings between the two analogs.             cannot be put into correspondence [15].
Such mappings would prove useful in analogical reasoning                  Humans are also sensitive to higher-level matches (i.e.,
and inference.                                                         compatibility relations), as in the solar system/atom example.
   For real world problems, it is impractical to try all ( mn  2 )
                                                                   2   Analogs are perceived as similar when they have a common
combinations in search of the best mapping. The theory pre-            relational structure. The term captures this type of simi-
sented here is a computational level theory of comparison              larity and it is high when elements from one analog map to
and similarity and does not address this issue. The solutions          elements in the other analog and their parents are also in cor-
to difficult real world problems can be approximated using             respondence.
combinatoric optimization procedures such as simulated an-
nealing [14]. In essence, every algorithmic model of anal-                                                                   (x; y) =    (7)
                                                                        Xm
                                                                             Xm
                                                                                 Xn
                                                                                     X n
                                                                                           S S A A F(x )F(x )F(y )F(y ):
ogy solves this combinatoric optimization problem by heuris-                                 x  y
                                                                                            ij  kl   ik  jl     i    j        k     l
tically combining mapping constraints.
                                                                        i=1 j =1 k=1 l=1
   The similarity equation consists of four terms that combine
linearly:                                                                 The  term is purely structural and ranges from 0 to 1. The
                                                                        term is 1 when the mapping between x and y is a bijection
E(x; y) = 1(x; y) + 2(x; y) +               3   (x; y) + 4 (x; y)  (3)
                                                                       (one-to-one and onto). In general people prefer analogies or
                                          where    1 ; 2 ; 3 ; 4  0:  mappings that are one-to-one [4]. Here, we assume that com-
                                                                       plete mappings are also preferred. The  term is defined as:
The four terms are defined below. The terms are organized                              0                                            1
from most semantic in nature to most structurally focused.
                                                                       (x; y) = Æ1 B@                        1                     C
   The      term is analogous to Tversky’s (1977) contrast                                     Pm                 Pn           2 A + (8)
model and captures raw semantic similarity:                                                1+      i=1
                                                                                                        F(x ) 1
                                                                                                            i          j =1
                                                                                                                             Aij
                                                                                            0                                          1
                
                            (x; y) = '1 f (X \ Y )             (4)
                                                                                 (1    Æ1 ) B
                                                                                                                  1                    C
                                                                                            @                                      2 A
      (1 '1 ) Æ1 f (X Y ) + (1 Æ1 )f (Y X )                                                    1+   Pn
                                                                                                       i=1
                                                                                                           F(y ) 1
                                                                                                               i
                                                                                                                        Pm
                                                                                                                           j =1
                                                                                                                                Aij
                    where 1  '1   0; and 1  Æ1  0
                                                                       The data sets considered in the next section are all from con-
where '1 determines the relative importance of common-                 trolled experiments and mappings exist that lead to maximal
alities and differences in determining the similarity of two           values of . Under these conditions, only these solutions are
analogs. The parameter Æ 1 determines how asymmetric the               considered by subjects (i.e., the parameter 4 , weighting ,
similarity judgment is. Given that the focus of a comparison           is set to a value large enough to prohibit consideration of in-
is usually on the target, Æ 1 should be greater than :5.               complete or conflicting mappings).
   The second term captures semantic similarity arising from
correspondences:
                                                                           The Similarity Equation and Human Data
                                                                       In this section, data from Goldstone (1994) and data from
                             X m
                                 X n                                   two new experiments is fit by the similarity equation. The fits
                 (x; y) =            Aij C(xi ; yj )            (5)   are intended to illustrate how the similarity equation can be
                             i=1 j =1                                  applied to human data and should not be taken as a definitive
where   C(x ; y ) is:
             i    j
                                                                       test of the equation’s form. The equation’s form will certainly
                                                                       be refined as it is applied to more data sets.
       C(x ; y ) = '1 F(x ) if x
           i    j            i      i is identical to yj ,       (6)   Goldstone (1994) Experiment 2
                                  else ('1      1)F(x ).
                                                       i               The similarity equation was applied to data from Goldstone’s
                                                                       (1994) Experiment 2. Subjects rated the similarity of two
      
The term and Tversky’s contrast model do not distinguish               displays. Each display consisted of a pair of schematic but-
between commonalities and differences that arise from rela-            terflies. Each butterfly could be represented by four features
tional elements that are in correspondence and those that are          (type of tail, type of body, type of wings, type of head). The
not in correspondence. The  term specifically addresses               number of matches in place (correspondences as in Equa-
commonalities and differences that are in correspondence               tion 5) and the number of matches that were not in corre-
(i.e., elements linked in A). Commonalities arising from               spondence was manipulated, yielding fifteen conditions. Ta-
correspondences are processed differently (i.e., have differ-          ble 1 illustrates the fifteen within subject conditions. Only the
ent time courses and differentially affect perceived similarity)        and the  terms from the similarity equation are relevant

                                                                level theory.
Table 1: Various feature transformation from Goldstone’s
(1994) Experiment 2. In the Target column, each of the four     Experiment 1
positions in each letter string represents a part of the target
stimulus (i.e., the second position in each string could denote In Goldstone’s (1994) Experiment 2, the term was not rel-
the head). Each letter (A, B, C, D, W, X, Y, or Z) represents   evant to the data fit. To further test the predictions of the
a particular feature value. The base stimulus is always repre-  similarity equation, I collected data from subjects in a task
sented as ABCD. The next two columns list the number of        in which higher-order relations could impact the similarity
and  matches. The Rated Similarity column denotes human        equation’s predictions (i.e., the term’s value varies across
subjects’ rated similarity of the base and target stimuli.      conditions). In Experiment 1, subjects rated the similarity of
   Target  Matches  Matches Rated Similarity                  two situations. The number of higher-order relations shared
  WXYZ             0              0              1.91           by the two situations was manipulated (as well as the number
  XYDZ             1              0              1.48           of  and/or  matches). The main prediction the similarity
  YZDD             1              1              3.09           equation makes in Experiment 1 is that feature and relation
  XYCZ             1              1              3.12           matches will affect rated similarity additively.
   BAYZ            2              0              3.11           Subjects Twenty-one Northwestern University undergrad-
  YZCD             2              2              4.65           uate students participated in the experiment for course credit.
  BADZ             3              0              3.60
   BACZ            3              1              4.52           Design and Overview of the Experiment The
  BADD             3              1              4.57           two variables (Feature Match/Mismatch and Relation
  ABDZ             3              2              4.96           Match/Mismatch) were crossed for a 2 X 2 within subjects
  ABDD             3              3              6.56           factorial design. The design is illustrated in Figure 1.
  ABCZ             3              3              6.78           The value of each term in the similarity equation for each
  BADC             4              0              4.82           condition is shown in Table 2. On each trial, subjects rated
  BACD             4              2              6.38           the similarity of two situations. Subjects completed 20 trials
  ABCD             4              4              8.79           in each condition for a total of 80 trials. The order of trials
                                                                was randomized for each subject.
                                                                Stimuli and Counterbalancing Each stimulus contained
for fitting this dataset, along with the 1 and 2 parameters,    the descriptions of two situations. Each situation description
because 1) asymmetries were not a concern (jX j is equal to     consisted of two sentences (see Figure 1). One situation de-
jY j), 2) differences and commonalities in Equations 4 and      scription was displayed on the left side of the screen. The
5 are perfectly correlated allowing all difference terms to be  other situation description was displayed on the right side
dropped (i.e., ' 1 is set to 1), 3) the value of and  do not   of the screen. Above the description on the left side of the
vary across conditions.                                         screen was the label “Situation A.” Above the description on
   For simplicity, a linear relationship was assumed between    the right side of the screen was the label “Situation B.” Un-
the maximal value generated by the similarity equation and      derneath the descriptions was a rating scale (1 indicated low
subjects’ similarity ratings. Of course, similarity is probably similarity and 9 indicated high similarity).
                               E
a more complex function of (x; y ) for a number of reasons,        Each situation contained two characters that were either
including the presence of scale effects [19]. Nevertheless,     both male or both female. Character names were randomly
with this simplifying assumption, the similarity equation ac-   chosen (subject to constraints imposed by the trial’s condi-
counted for 97.0 % of the variance in the data. The similarity  tion) without replacement from the following list of names:
equation states that different sources of similarity combine    Anne, Jennifer, Linda, Susan, Wendy, Bill, Jeff, John, Keith,
additively. A modified version of the equation was fit to the   and Steve. On Feature Match trials, the gender of the charac-
data that contained a term capturing the interaction between    ters in both situations matched (i.e., all characters were male
 and . This augmented equation did not capture signifi-       or female). Whether the common gender was male or fe-
cantly more variance (97.3%), supporting the stance that the    male was randomly determined for each Feature Match trial.
terms combine additively. The fit for SIAM, a special pur-      On Feature Mismatch trials, the genders of the characters in
pose interactive connectionist model developed by Goldstone     the two situations were different such that the two charac-
(1994), was equivalent (it accounted for 97.7 % of the vari-    ters from one situation were both male and the two characters
ance). The similarity equation offers a simpler account of      from the other situation were both female. On each Feature
the data — perceived similarity arises from a linear weight-    Mismatch trial, it was randomly determined whether situation
ing of the  and  terms. To SIAM’s credit, it can account      A contained the male or female characters.
for aspects of the time course data, like that subjects tend       Both characters from a situation appeared in both sen-
to weight matches in correspondence (i.e.,  matches) more      tences. Each sentence contained a predicate that linked
later in processing than  matches (this is SIAM’s added        the two characters. The same predicates appear in both
value). Such data is outside the province of a computational    situations. Two predicates were randomly chosen without

Table 2: The values of the four terms for the four conditions     Table 3: Similarity ratings for each condition (averaged over
in Experiments 1 and 2. Notice that  and  are perfectly         subjects) in Experiment 1.
correlated.                                                                                Relational Match Relational Mismatch
                                                                 Feature Match                8.23                  4.50
  Feature Match/Relational Match                8    8    12    1   Feature Mismatch             7.51                  3.39
  Feature Mismatch/Relational Match             7    7    12    1
  Feature Match/Relational Mismatch             8    8    10    1
                                                                  target and base analogs corresponded to one another. This
  Feature Mismatch/Relational Mismatch          7    7    10    1
                                                                  judgment should force subjects to focus more on high-order
                                                                  relational matches and should lead to a higher weighting of
                                                                  the term relative to the  term in the similarity equation.
replacement for each trial from the following list: is taller
than, respects, and likes. Which predicate appeared in the        Subjects Seventy-one Northwestern University undergrad-
first or second sentence within a situation was random. It was    uate students participated in the experiment for course credit.
also random whether or not the same character appeared first      The subjects were from the same population as the subjects
in both sentences in situation A (the character order is fixed    in Experiment 1. Experiments 1 and 2 were run concurrently
for situation B given the character order in situation A and      (though no subjects participated in both experiments).
the trial’s condition). Again, Figure 1 illustrates an example
situation pair for each condition.                                Design and Overview of the Experiment The design was
                                                                  very close to that of Experiment 1. The main difference was
                                                                  that subjects made a correspondence judgment after making
Procedure Text was displayed in black on a white back-
                                                                  a similarity judgment. Another difference was that subjects
ground. Trials began with a message displayed in the upper
                                                                  performed sixty trials (fifteen in each condition) as opposed
left corner of the screen alerting the subject to prepare for the
                                                                  to the eighty trials performed in Experiment 1.
next trial. After 1000 ms, this message was removed and the
stimulus was displayed (i.e., the two situations along with       Stimuli and Counterbalancing The stimuli and counter-
the rating scale). Subjects then pressed a key (1 through 9)      balancing were identical to Experiment 1 with the following
to indicate how similar the two situations were (1 indicated      addition — after making a similarity judgment, one character
low similarity and 9 indicated high similarity). After subjects   was randomly chosen from situation A and another charac-
responded, there was a 1500 ms pause and then the next trial      ter was randomly chosen from situation B and subjects were
began.                                                            asked if they corresponded to one another.
Results Table 2 shows the values of the four terms for each       Procedure The procedure was identical to Experiment 1
condition. As in the previous fit, the number of relevant pa-     except that subjects made a correspondence judgment imme-
rameters required can be reduced to 2 (the 1 parameter for        diately after making a similarity judgment. After making the
the  term and the 3 parameter for the term). The mean            similarity judgment, a text message appeared below the rat-
similarity ratings (averaged across subjects) for each condi-     ing scale. The message asked if a particular character from
tion are shown in Table 3. The similarity equation fit 99.9%      situation A corresponded to a particular character from situ-
of the variance in the data. To provide a stronger test, indi-    ation B. Subjects were instructed to press the ‘Y’ key if they
vidual subjects’ data was fit. Of course, the fit for this data   thought the two characters corresponded and to press the ‘N’
will not be as good because the data for individual subjects      key if they thought the two characters did not correspond.
is not as stable and each subject uses a slightly different rat-  The Yes/No question was displayed along with both situation
ing scale (i.e., high similarity for one subject may result in    descriptions and the rating scale. After making the correspon-
a rating of 8, while another subject may give a rating of 7).     dence judgment, there was a 1500 ms pause and then the next
Nevertheless, the equation fit 71.9% of the variance (df=81).     trial began.
A modified version of the equation was fit to the data that
contained a term capturing the interaction between  and .
                                                                  Results The main predictions held. Table 4 shows the mean
                                                                  ratings for each condition. Feature matches had a small effect
This augmented equation did not capture significantly more
                                                                  on rated similarity while relational matches had a large effect
variance (72.1%, df=80), supporting the stance that the terms
                                                                  on rated similarity. The ratio 3 = 1 was three times larger
combine additively.
                                                                  in Experiment 2 than it was in Experiment 1. Subjects also
Experiment 2                                                      made the correspondence judgments in the manner predicted
                                                                  by the similarity equation’s mapping matrix A. In terms of
A second experiment explored how task demands affect com-         fit, 99.9% of the variance in the averaged data was accounted
parison. The materials and procedure were identical to the        for. For individual subject fits, 66.1% (df=281) of the vari-
previous experiment except that after making a similarity         ance was accounted for and adding an interaction term did
judgment subjects were asked to state how the people in the       not improve the fit (66.1%, df=280).

                                                                     [3] F ORBUS , K. D., G ENTNER , D., AND L AW, K. MAC/FAC:
Table 4: Similarity ratings for each condition (averaged over            a model of similarity-based retrieval. Cogntive Science 19
subjects) in Experiment 2                                                (1994), 141–205.
                           Relational Match Relational Mismatch      [4] G ENTNER , D. Structure-mapping: A theoretical framework
   Feature Match                  8.32                  4.47             for analogy. Cogntive Science 7 (1983), 155–170.
   Feature Mismatch               8.02                  4.08
                                                                     [5] G ENTNER , D., AND M ARKMAN , A. B. Structure mapping
                                                                         in analogy and similarity. American Psychologist 52 (1997),
                                                                         45–56.
    While the fits from Experiments 1 and 2 (as well as from
                                                                     [6] G LEITMAN , L. R., G LEITMAN , H., M ILLER , C., AND O S -
Goldstone’s Experiment 2) suggest different sources of sim-              TRIN , R. Similar, and similar concepts. Cognition 58 (1996),
ilarity combine additively, I predict that after consideration           321–376.
of more diverse data sets (e.g., [9]) the similarity equation        [7] G OLDSTONE , R. L. Similarity, interactive activation, and
will be revised to make allowances for interactions between              mapping. Journal of Experimental Psychology: Learning,
terms under certain conditions. The equation and data pre-               Memory, & Cognition 20 (1994), 3–28.
sented here are simply intended to motivate a new framework          [8] G OLDSTONE , R. L., AND M EDIN , D. Time course of compar-
for approaching comparison and similarity.                               ison. Journal of Experimental Psychology: Learning, Memory,
                                                                         & Cognition 20 (1994), 29–50.
                            Discussion                               [9] G OLDSTONE , R. L., M EDIN , D., AND G ENTNER , D. Rela-
                                                                         tional similarity and the nonindependence of features in simi-
The similarity equation presented here is a computational                larity judgments. Cognitive Psychology 23 (1991), 222–262.
level theory of human comparison and perceived similarity
that can account for basic findings in the similarity and anal-     [10] H OPFIELD , J. J., AND TANK , D. W. Neural computation of
                                                                         decision in optimation problems. Biological Cybernetics 52
ogy literatures. The equation provides clarity to the discus-            (1985), 141–152.
sion of similarity because it distinguishes between a number
of different factors that can affect perceived similarity. An ac-   [11] H UMMEL , J. E., AND H OLYOAK , K. J. Distributed represen-
                                                                         tations of structure: A theory of analogical access and map-
curate characterization of similarity is critical given its central      ping. Psychological Review 104 (1997), 427–466.
role in theories of categorization, decision making, analogy,
                                                                    [12] JAMES , W. The Principles of Psychology: Volume 1. Dover,
problem solving, and object recognition.                                 New York, 1890/1950.
    Twenty years after Tversky’s (1977) classic paper, many
of the same questions remain. How are the representations           [13] K EANE , M. T., L EDGEWAY, T., AND D UFF , S. Constraints on
                                                                         analogical mapping: A comparison of three models. Cogntive
of analogs determined, how do they change as an outcome                  Science 18 (1994), 387–438.
of comparison, and how is feature saliency modulated? One
possibility is that instead of static representations being com-    [14] K IRKPARTICK , S., G ELATT, C. D., AND V ECCHI , M. P. Op-
                                                                         timization by simulated annealing. Science 220 (1983), 671–
pared, retrieval and comparison are interleaved such that the            680.
current mappings between the analogs direct which other in-
                                                                    [15] M ARKMAN , A. B., AND G ENTNER , D. Splitting the differ-
formation is retrieved and represented in the base and target.           ences: A structural alignment view of similarity. Journal of
Analogical inference may also direct the construction of the             Memory and Language 32 (1993), 517–535.
target analog’s representation. In other words, properties or
                                                                    [16] M ARKS , L. E. Bright sneezes and dark coughs, loud sunlight
features can emerge as a result of the comparison process                and soft moonlight. Journal of Experimental Psychology: Hu-
[18]. Hopefully this work will demarcate what is known and               man Perception and Performance 8 (1982), 177–193.
what is common to competing models so that researchers can          [17] M ARR , D. Vision. W. H. Freeman, San Francisco, 1982.
wisely focus their efforts.
                                                                    [18] M EDIN , D. L., G OLDSTONE , R. L., AND G ENTNER , D. Re-
                       Acknowledgments                                   spects for similarity. Psychological Review 100, 2 (1993), 254–
                                                                         278.
I would like to thank John Hummel and Keith Holyoak for il-         [19] PARDUCCI , A. Category judgment: A range-frequency model.
luminating discussions. I would like to thank Dedre Gentner              Psychological Review 72 (1965), 407–418.
and Arthur Markman for their helpful comments on a previ-
                                                                    [20] S HEPARD , R. N. The analysis of proximities: Multidimen-
ous draft. Finally, I would like to thank Rob Goldstone for              sional scaling with an unkown distance function. Part 1. Psy-
providing me with his data.                                              chometrika 1 (1962), 125–140.
                            References                              [21] TALMY, L. Figure and ground in complex sentences. In Uni-
                                                                         versals of human language, J. Greenburg, C. Ferguson, and
  [1] B OWDLE , B. F., AND G ENTNER , D. Informativity and asym-         M. Moravcsik, Eds. Stanford University Press, Stanford, 1978,
      metry in comparisons. Cognitive Psychology 34 (1997), 244–         pp. 625–649.
      286.
                                                                    [22] T VERSKY, A. Features of similarity. Psychological Review 84
  [2] FALKENHAINER , B., F ORBUS , K. D., AND G ENTNER , D.              (1977), 327–352.
      The structure mapping engine: Algorithm and examples. Arti-
      ficial Intelligence 41 (1989), 1–63.

