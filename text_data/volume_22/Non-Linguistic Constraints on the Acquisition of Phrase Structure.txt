UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Non-Linguistic Constraints on the Acquisition of Phrase Structure
Permalink
https://escholarship.org/uc/item/3cf0n85j
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
Saffran, Jenny R.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                    University of California

          Non-Linguistic Constraints on the Acquisition of Phrase Structure
                                         Jenny R. Saffran (jsaffran@facstaff.wisc.edu)
                                          Department of Psychology; 1202 W. Johnson Street
                                                        Madison, WI 53706 USA
                              Abstract                               ple, to language learners equipped with the right distribu-
   To what extent is linguistic structure learnable from statisti-   tional tools. But are humans such learners? A wealth of sta-
   cal information in the input? One set of cues which might as-     tistical cues are useless unless humans can detect and use
   sist in the discovery of hierarchical phrase structure given se-  them. In fact, recent research suggests that humans are ex-
   rially presented input are the dependencies, or predictive rela-  tremely good at some statistical language learning tasks,
   tionships, present within phrases. In order to determine          such as word segmentation (e.g., Aslin, Saffran, & New-
   whether adult learners can use this statistical information,
   subjects were exposed to artificial languages which either        port, 1998; Goodsitt, Morgan & Kuhl, 1993; Saffran,
   contained or violated the kinds of dependencies which charac-     Aslin, & Newport, 1996; Saffran, Newport, & Aslin, 1996)
   terize natural languages. The results suggest that adults pos-       These results suggest that humans possess powerful sta-
   sess learning mechanisms which detect and utilize statistical     tistical language learning mechanisms, which are likely to
   cues to phrase and hierarchical structure. A second experiment    provide important contributions to the language learning
   contrasted the acquisition of these linguistic systems with
   the same grammars implemented as non-linguistic input (se-        process. At the same time, it is important to recognize that
   quences of non-linguistic sounds or shapes). These findings       these mechanisms would not be useful in language acquisi-
   suggest that constraints on the mechanisms which highlight        tion unless they are somehow constrained or biased to per-
   the statistical cues which are most characteristic of human       form only certain kinds of computations over certain kinds
   languages are not specifically tailored for language learning.
                                                                     of input. The pertinent generalizations to be drawn from a
                                                                     linguistic corpus are awash in irrelevant information. Any
                         Introduction
                                                                     learning device without the right architectural, representa-
   While the idea that surface distributional patterns point to      tional, or computational constraints risks being sidetracked
pertinent linguistic structures holds a distinguished place in       by the massive number of misleading generalizations avail-
linguistic history (e.g., Bloomfield, 1933; Harris, 1951),           able in the input (e.g., Gleitman & Wanner, 1982; Pinker,
statistical learning has only recently re-emerged as a poten-        1984). There are an infinite number of linguistically irrele-
tial contributing force in language acquisition (though see          vant statistics that an overly powerful statistical learner
Maratsos & Chalkley, 1980). This renewed interest in sta-            could compute: for example, which words are presented third
tistical learning has been fueled by developments in compu-          in sentences, or which words follow words whose second
tational modeling, by the widespread availability of large           syllable begins with th (e.g., Pinker, 1989).
corpora of child-directed speech, and most recently by em-              One way to avoid this combinatorial explosion would be
pirical research demonstrating that human subjects can per-          to impose constraints on statistical learning which perform
form statistical language learning tasks in laboratory ex-           only a subset of the logically possible computations. It is
periments. For example, computational algorithms can use             clear that learning in biological systems is limited by inter-
the co-occurrence environments of words to discover form             nal factors; there are species differences in which specific
classes in large corpora (e.g., Cartwright & Brent, 1997;            types of stimuli serve as privileged input (e.g., Garcia &
Finch & Chater, 1994; Mintz, 1996; Mintz, Newport, &                 Koelling, 1966; Marler, 1991). External factors also
Bever, 1995). Similarly, individual verb argument structures         strongly bias learning, because input from structured do-
can be induced by models which tracks the co-occurrences of          mains consists of non-random information. In order for sta-
verbs and their arguments in the input (e.g., Schütze, 1994;         tistical learning accounts to succeed, learners must be simi-
Seidenberg & MacDonald, 1999). Extensive modeling work               larly constrained: humans must be just the type of statistical
has also examined the statistical cues available for the dis-        learners who are best suited to acquire the type of input ex-
covery of word boundaries in continuous speech (e.g., Aslin,         emplified by natural languages, focusing on linguistically
Woodward, LaMendola, & Bever, 1996; Brent & Cartwright,              relevant statistics while ignoring the wealth of available
1996; Cairns, Shillcock, Chater, & Levy, 1997; Christian-            irrelevant computations. Such constraints might arise from
sen, Allen, & Seidenberg, 1998; Perruchet & Vintner,                 various sources, either specific to language or from more
1998).                                                               general cognitive and/or perceptual constraints on human
   These models provide invaluable explorations of the ex-           learning.
tent to which statistical information is available, in princi-

    We have recently begun to explore the possibility that        between word categories afforded predictive cues to phrases,
statistical learning itself is constrained. This line of research as in natural languages (e.g., if D is present, A must be
focuses the acquisition of hierarchical phrase structure.         present). Importantly, attempts to impose English predictive
While words are spoken and perceived serially, our represen-      structure onto the input would mislead learners, as the
tations of sequences of words are highly structured. Consider     phrase structure of Language P was head-final while English
the sentence The professor graded the exam. This sequence of      is head-initial. The second language was equally complex in
words cannot be grouped as follows – (The) (professor graded      terms of its size and formal characteristics, but contained a
the) (exam) – because words that are part of the same phrase      phrase structure unlike natural languages (Language N, for
are separated. For example, determiners like the require          non-predictive). This language did not contain predictive
nouns; separating these two types of words violates the de-       dependencies marking phrases. Rather, it was characterized
pendency relations which are part of native speakers’ knowl-      by overarching optionality: the presence of one word type
edge of English. The correct groupings, (The professor)           never predicted the presence of another, which generates sta-
(graded (the exam)), reflect English phrase structure, which      tistical properties unlike natural languages (note, however,
generates a non-linear hierarchically organized structure. Hi-    that this language still possesses phrase structure of a sort –
erarchical phrase structure represents a fascinating learning     the absence of one word type predicts the presence of an-
problem, because the child must somehow arrive at non-            other; e.g., if A is not present, D must be present). Each
linear structure which is richer than is immediately sug-         form class (A, C, etc.) included 2 - 4 nonsense words (e.g.,
gested by the serial structure of the input. How do children      the words for the A category were BIFF, RUD, HEP, and
make this leap? Innate knowledge is one possibility; pro-         MIB).
sodic regularities may also serve to chunk the input into
phrasal units (e.g., Morgan, Meier, & Newport, 1987).             Table 1. Phrase structure grammars for Experiments 1 - 2.
   Another type of potentially useful information in the in-      Letters refer to word classes; items in parentheses are op-
put suggests a statistical learning solution (see also Morgan     tional. In Language N, one member of each phrase type
& Newport, 1981). Linguistic phrases contain dependency           must be present; if both are present, they must be in the
relations: the presence of some word categories depends on        order described by the grammar.
others. For example, English nouns can occur without de-
terminers like the or a. However, if a determiner is present, a   Language P                     Language N
noun almost always occurs somewhere downstream. This
type of predictive relationship, which characterizes basic        S → AP + BP + (CP)             S →    AP + BP
phrase types, may offer a statistical cue that highlights         AP → A + (D)                   AP →   (A) + (D)
phrasal units for learners. Research using artificial languages   BP → CP + F                    BP →    CP + F
with phrase structure grammars suggests that adult and child      CP → C + (G)                   CP →   (C) + (G)
learners can exploit predictive dependencies to discover
phrases (Saffran, 2000).                                               The language generated by Language N is no larger than
    These studies suggest that people are skilled statistical     the language generated by Language P. In fact, Language N
learners. But what about the constraints required for the suc-    contained fewer sentence types (nine) than Language P
cessful acquisition of languages? A particularly useful type      (twelve). Language N also had shorter sentences on average,
of constraint would bias statistical learning mechanisms to       presumably making it less daunting to the learner: Language
preferentially acquire the types of structures observed in        P generated 60% more five word sentences than Language N,
natural languages. To address this issue, Experiment 1 as-        and only 40% as many three word sentences. For both lan-
sessed the extent to which adults’ ability to acquire an artifi-  guages, only sentence types with five or fewer words were
cial grammar is affected by the availability of predictive de-    used (eight types for Language P, nine for Language N).
pendencies as cues to linguistic phrase structure.                Both languages contained the same number of grammatical
                                                                  categories and vocabulary items.
                        Experiment 1                                   Because the languages were so similar in terms of their
                                                                  non-structural attributes, comparison of learning outcomes
Participants. 40 monolingual English speaking under-              is valid. Language P is larger, and contains longer sentences,
                                                                  which could make it more difficult to acquire. However, if
graduates at the University of Rochester participated in this
                                                                  predictiveness affects learning, then the structure of Lan-
study, and were each paid $6. Subjects were randomly as-
                                                                  guage N might have hindered its acquisition.       A    trained
signed to the two experimental conditions.
                                                                  speaker recorded a corpus of 50 sentences from each lan-
                                                                  guage, with uniformly descending prosody but no grouping
Materials. The artificial grammars were adapted from the
                                                                  cues to phrase structure. Subjects were randomly assigned to
language used by Morgan & Newport (1981). One of the
                                                                  hear either Language P or Language N sentences. Following
languages used in this study was a small phrase structure
                                                                  approximately 30 min. of auditory exposure to one of the
grammar (Language P, for predictive), in which dependencies

two languages (the corpus was repeated eight times during                                Experiment 2
exposure), all participants received the same forced-choice
test consisting of novel grammatical and ungrammatical           Participants. 154 monolingual English speaking under-
sentences, in order to assess acquisition of the rules of the    graduates at the University of Wisconsin - Madison partici-
two languages. Importantly, attempts to impose English           pated in this study participated in this study for course extra
syntax on either language would hinder performance. No           credit. Forty-four subjects were randomly assigned to the
cues other than the statistical information mirroring the un-    non-linguistic auditory condition, forty subjects to the non-
derlying phrase structure of the language were available to      linguistic visual condition, and thirty subjects to the lin-
learners.                                                        guistic visual condition. Within each exposure condition,
                                                                 half of the subjects were assigned to Language P and half
Results. Each group’s overall performance was signifi-           were assigned to Language N.
cantly better than would be expected by chance: for Lan-
guage P, the total score was 22.8 out of a possible 30: t(19)    Method. For the non-linguistic visual condition, we trans-
= 10.46, p < .0001; for Language N, the total score was          lated the Language P and N grammars shown above into
20.55: t(19) = 6.62, p < .0001 (see Figure 1). The principal     languages of shapes (for a similar methodology, see
hypothesis of interest concerns differences in learning as a     Goldowsky, 1995). For example, consider the phrase struc-
function of structural differences between the two languages.    ture rule: AP → A + (D). In the linguistic version of this
To address this question, the scores for the two language        language, the category A consisted of 4 nonsense words. In
groups for items testing each of the five rules were submit-     the visual version, the category A consisted of 4 distinct
ted to an ANOVA. The main effect of Language (P versus           shapes (such as a red circle with stripes). Category member-
N) was significant: F(1, 38) = 4.2, p < .05.                     ship could not be induced by shape similarity, unlike prior
   These findings suggest that humans may be constrained to      studies by Morgan & Newport (1981). Participants observed
learn most readily via exactly the types of cues present in      the language on a computer monitor: each shape was pre-
languages. To the extent that this is the case, the structure    sented in the middle of the screen, one at a time, with the
of natural languages may have been shaped by the nature of       same timing parameters as the auditory linguistic stimuli
human learning (e.g., Bever, 1970; Christiansen, 1994;           used in Experiment 1. Following exposure, participants
Christiansen & Devlin, 1997; Morgan, Meier, & Newport,           were tested using a forced-choice test analogous to the lin-
1987; Newport, 1990). According to the constrained statisti-     guistic task, in which they saw two shape sequences, one
cal learning hypothesis, the mechanisms underlying lan-          after the other, and decided which shape sequence more
guage acquisition are biased to assist learners in detecting the closely approximated the exposure stimuli. The linguistic
‘right’ statistical properties of the input. On this view, hu-   visual condition was identical to the non-linguistic visual
man languages have been sculpted by human learning and           condition except that the nonsense words from Experiment 1
processing mechanisms – thereby creating input which con-        were shown typed on the computer screen. In the non-
tains the types of properties most useful for human learners,
                                                                 linguistic auditory condition, we translated Language P and
and rendering a close match between constraints on human
                                                                 N into non-linguistic sounds drawn from the digitized bank
learning and constraints on natural language structure.
                                                                 of alert sounds provided with Windows 98. Each word corre-
   If learners are biased to preferentially acquire structures
                                                                 sponded to a different sound, chosen to be maximally dis-
where one item predicts another, is this constraint on learn-
                                                                 criminable (an ascending buzz, a chord, chimes, etc.). Sound
ing particularly tailored for linguistic input? Biases in learn-
                                                                 “sentences” generated by Language P and N were presented
ing mechanisms may develop tightly coupled with the par-
                                                                 auditorily at the same rate as the linguistic and visual stim-
ticular structure they are designed to acquire. Alternatively,
                                                                 uli. Following exposure, participants received the same
constraints to use predictive statistics may be more generally
                                                                 forced choice test, translated into non-linguistic sounds. Nei-
applied to other types of sequentially presented information,
                                                                 ther of the two non-linguistic conditions contained any lin-
as suggested by the constrained statistical learning hypothe-
                                                                 guistic information.
sis. Constraints on statistical learning which are not specific
to language acquisition, but rather on the acquisition and
                                                                 Results. Each group’s overall performance was significantly
processing of serial information, may have shaped the struc-
                                                                 better than would be expected by chance: for Language P
ture of natural languages. Experiment 2 thus utilized non-
                                                                 Non-linguistic auditory, Nonlinguistic visual, and Linguis-
linguistic stimuli from two different modalities: visual
                                                                 tic visual, p < .0001; for Language N Nonlinguistic visual,
shapes and complex sounds. An additional condition included
                                                                 p < .001; for Language N Nonlinguistic auditory, p < .001;
visual linguistic stimuli (written words). As in Experiment
                                                                 and for Language N Linguistic visual, p < .05 (see Figure
1, we contrasted the acquisition of Language P and N.
                                                                 1). As in Experiment 1, the principal hypothesis concerns

                             30
                                      a.                b.
                             25
                                      *                      *                   *
                             20
 Mean scores (chance = 15)
                                                                                                                                  N
                             15                                                                                                   P
                             10
                              5
                              0
                                  Linguistic auditory   Linguistic visual   Nonlinguistic auditory Nonlingustic visual
 Figure 1: a. Mean scores from Experiment 1. b. Mean scores from Experiment 2.
differences in learning as a function of structural differences                                         General Discussion
between Language P and Language N. To address this ques-
tion, the scores for the two language groups for items test-                             These studies ask whether predictive dependencies serve a
ing each of the five rules were submitted to an ANOVA.                                learnability function in the acquisition of language. The
The main effect of Language P versus N was significant for                            results of Experiment 1 suggest that adult learners are better
the Nonlinguistic auditory [F(1, 42) = 7.72, p < .01] and the                         able to acquire an artificial language which contains predic-
Linguistic visual condition [F(1, 28) = 4.56, p < .05], but                           tive dependencies as a cue to phrase structure than a compa-
not for the Nonlinguistic visual condition [F(1, 38) = .23,                           rable language which does not. Experiment 2 extends these
n.s.].                                                                                results to demonstrate that the use of predictive dependencies
     In order to ask whether the linguistic or non-linguistic                         in learning phrase structure is not limited to language learn-
status of the input influenced performance differentially as a                        ing tasks. These findings mirror prior results suggesting that
function of the availability of linguistic dependencies, we                           transitional probability computation in word segmentation
performed a two-way between-subjects ANOVA contrasting                                tasks can occur when ‘words’ are created from non-linguistic
Language (P versus N) and Linguistic Status (language ver-                            tones (Saffran, Johnson, Newport, & Aslin, 1999) or visuo-
sus non-language materials), including the auditory linguis-                          motor sequences (Hunt & Aslin, 1998).
tic data from Experiment 1. There was a significant main                                 Predictive dependencies are a hallmark of natural lan-
effect of Language: F(1, 150) = 15.17, p< .0001. Neither                              guages. However, it is of interest to note that these general
the main effect of Linguistic Status [F(1, 150) = 1.09, n.s.]                         organizational principles are by no means unique to lan-
nor the interaction between Language and Linguistic Status                            guage. Lashley (1951) observed that hierarchical organiza-
[F(1, 150) = .71, n.s.] were significant. These analyses indi-                        tion characterizes an enormous variety of behaviors: “the
cate that the linguistic status of the input – that is, whether                       coordination of leg movements in insects, the song of birds,
the grammars were implemented in linguistic or non-                                   the control of trotting and pacing in a gaited horse, the rat
linguistic tokens – did not affect overall performance. In-                           running the maze, the architect designing a house, and the
stead, the dominant factor was whether the input was derived                          carpenter sawing a board present a problem of sequences of
from Language P, which contained predictive dependencies                              action which cannot be explained in terms of successions of
as a statistical cue to phrase structure, or Language N, which                        external stimuli” (p. 113). Such observations suggest that
did not. This overall non-effect of linguistic status occurred                        learners may be biased to process information in a particular
despite the fact that performance on the visual non-linguistic                        fashion, enabling a learning process which results in phrases
task did not show the predicted difference between Language                           and hierarchically structured representations.
P and N (see Figure 1). We are currently testing hypotheses                              The kinds of structure at issue here serve to organize and
concerning why the visual nonlinguistic task patterned dif-                           package serial information into manageable chunks, which
ferently from the other three conditions included in Experi-                          then enter relationships with one another. This process pre-
ments 1 and 2.                                                                        sumably maximizes cognitive economy, facilitating the

transmission of more complex information than could be              With respect to statistical learning, the present research
transmitted otherwise. Pinker and Bloom (1990) argue that        runs counter to the assumption that statistical language
“hierarchical organization characterizes many neural systems,    learning accounts -- and any other type of theory which as-
perhaps any system, that we would want to call com-              signs an important role to linguistic input -- are necessarily
plex...Hierarchy and seriality are so useful that for all we     underconstrained. As animal research has amply demon-
know they may have evolved many times in neural systems”         strated, learning in biological systems is highly constrained
(p. 726). When applied to syntax, this kind of argument          (e.g., Garcia & Koelling, 1966; Marler, 1991). There is
suggests that grammars look the way they do because these        every reason to believe that statistical learning is similarly
kinds of organizational principles are the human engineering     constrained; the purported intractability of statistical learning
solution to the problem of serial order.                         need not be asserted prima facie. What exactly these con-
   It is conceivable that this type of packaging of serial in-   straints will turn out to be, and whether they will confer
puts into higher-order organization facilitates not only lan-    sufficient explanatory power, remain empirical questions.
guage production and processing, but also language acquisi-      Nevertheless, there are grounds for optimism. Learners are
tion. Systems which are highly organized are more learnable      not, and never have been, blank slates. The more we learn
than systems which are not -- as long as the system of orga-     about the mechanisms engraved upon that slate, the more we
nization is consistent with the learner's cognitive structure.   learn about learning.
We anticipate that future research will be extremely useful in
further clarifying the extent to which the constraints ob-                          Acknowledgments
served during the process of language acquisition subserve
other learning processes as well.                                   This research was supported by NIH Training Grant
   With respect to linguistic structure, one potential theo-     5T32DC0003 to the University of Rochester, by NIH grant
retical implication of this research concerns an alternative to  DC00167 to Elissa Newport, and by NIH grant 144HN72 to
the traditional innate universal grammar explanation for the     Jenny Saffran.
pervasiveness of particular linguistic features cross-
linguistically.. If human learners are constrained to preferen-                          References
tially acquire certain types of structures, then some of the
universal structures of natural languages may have been             Aslin, R. N., Woodward, J. Z., LaMendola, N. P., &
shaped by these constraints (see also, e.g., Bever, 1970;        Bever, T. G. (1996). Models of word segmentation in ma-
Christiansen, 1994; Christiansen & Devlin, 1997; Newport,        ternal speech to infants. In J. L. Morgan & K. Demuth
1982, 1990). Perhaps languages fit our learning abilities so     (Eds.), Signal to syntax. Hillsdale, NJ: Erlbaum.
neatly precisely because languages have no choice. If the           Aslin, R. N., Saffran, J. R., & Newport, E. L. (1998).
pertinent learning mechanisms preceded the advent of lan-        Computation of conditional probability statistics by 8-
guages, then there must have been intense pressure for lan-      month-old infants. Psychological Science, 9, 321-324.
guages to be learnable, with learnability dictated by the           Bever, T. (1970). The cognitive basis for linguistic struc-
structure of human learning mechanisms. On this view,            tures. In J. Hayes (Ed.), Cognition and the development of
languages evolve to fit the human learner. To the extent that    language. New York: Wiley.
this type of view is correct, then the striking similarities of     Bloomfield, L. (1933). Language. New York: Henry Holt.
human languages may be in part the direct reflections of            Brent, M. R., & Cartwright, T. A. (1996). Distributional
constraints on human learning abilities.                         regularity and phonotactic constraints are useful for segmen-
   The present research begins the task of recharacterizing      tation. Cognition, 61, 93-125.
language universals in terms of constraints on learning by          Cairns, P., Shillcock, R., Chater, N., & Levy, J. (1997).
recasting the distributional features and dependencies inherent  Bootstrapping word boundaries: A bottom-up corpus-based
in hierarchical phrase structure into cues detected during the   approach to speech segmentation. Cognitive Psychology,
learning process. In the case of the constraint to interpret     33, 111-153.
predictive relations as signaling a linguistic unit, the phrase,    Cartwright, T. A., & Brent, M. R. (1997). Early acquisi-
we find the beginnings of an explanation for why languages       tion of syntactic categories: A formal model. Cognition, 63,
ubiquitously contain the within-phrase dependencies initially    121-170.
characterized by structural linguists. Future research will         Christiansen, M. H. (1994). Infinite languages, finite
continue to pursue the hypothesis that constraints on learn-     minds: Connectionism, learning and linguistic structure.
ing play an important role in shaping the structure of natural   Unpublished Ph.D. dissertation, University of Edinburgh.
languages. For example, recent computational research sug-          Christiansen, M. H., Allen, J., & Seidenberg, M. S.
gests that universal word order typologies may in fact reflect   (1998). Learning to segment speech using multiple cues:
the ease with which different types of systems are learned       A connectionist model. Language and Cognitive Processes,
(Christiansen & Devlin, 1997).                                   13, 221-268.

   Christiansen, M. H., & Devlin, J. T. (1997). Recursive         Morgan, J. L., & Newport, E. L. (1981). The role of
inconsistencies are hard to learn: A connectionist perspective constituent structure in the induction of an artificial lan-
on universal word order correlations. In Proceedings of the    guage. Journal of Verbal Learning and Verbal Behavior, 20,
Nineteenth Annual Meeting of the Cognitive Science Soci-       67-85.
ety. Hillsdale, NJ: Erlbaum.                                      Newport, E. L. (1982). Task specificity in language learn-
   Finch, S. P., & Chater, N. (1994). Distributional boot-     ing? Evidence from speech perception and American Sign
strapping: From word class to proto-sentence. Proceedings      Language. In E. Wanner and L. R. Gleitman (Eds.), Lan-
of the Sixteenth Annual Conference of the Cognitive Sci-       guage acquisition: The state of the art. Cambridge: Cam-
ence Society. Hillsdale, NJ: Erlbaum.                          bridge University Press.
   Garcia, J. & Koelling, R. A. (1966). Relation of cue to        Newport, E. L. (1990). Maturational constraints on lan-
consequence in avoidance learning. Psychonomic Science, 4,     guage learning. Cognitive Science, 14, 11-28.
123-124.                                                          Perruchet, P., & Vintner, A. (1998). PARSER: A model
   Gleitman, L. R., & Wanner, E. (1982). Language acquisi-     for word segmentation. Journal of Memory and Language,
tion: The state of the state of the art. In E. Wanner and L.   39, 246-263.
R. Gleitman (Eds.), Language acquisition: The state of the        Pinker, S. (1984). Language learnability and language de-
art. Cambridge: Cambridge University Press.                    velopment. Cambridge, MA: MIT Press.
   Goldowsky, B. (1995). Learning structured systems from         Pinker, S. (1989). Learnability and cognition: The acqui-
imperfect information. Unpublished Ph.D. dissertation,         sition of argument structure. Cambridge, MA: MIT Press.
University of Rochester.                                          Pinker, S., & Bloom, P. (1990). Natural language and
   Goodsitt, J. V., Morgan, J. L., & Kuhl, P. K. (1993).       natural selection. Behavioral and Brain Sciences, 13, 707-
Perceptual strategies in prelingual speech segmentation.       784.
Journal of Child Language, 20, 229-252.                           Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
   Harris, Z. S. (1951). Methods in structural linguistics.    Statistical learning by 8-month-old infants. Science, 274,
Chicago: University of Chicago Press.                          1926-1928.
   Hunt, R. H., & Aslin, R. N. (1998). Statistical learning       Saffran, J. R., Johnson, E. K., Aslin, R. N., & Newport,
of visuomotor sequences: Implicit acquisition of sub-          E. L. (1999). Statistical learning of tone sequences by hu-
patterns. In Proceedings of the Twentieth Annual Meeting of    man infants and adults. Cognition, 70, 27-52.
the Cognitive Science Society. Hillsdale, NJ: Erlbaum.            Saffran, J. R., Newport, E. L., & Aslin, R. N. (1996).
   Lashley, K. S. (1951). The problem of serial order in be-   Word segmentation: The role of distributional cues. Journal
havior. In L. A. Jeffress (Ed.), Cerebral mechanisms in be-    of Memory and Language, 35, 606-621.
havior: The Hixon Symposium. New York: Wiley.                     Saffran, J. R., Newport, E. L., Aslin, R. N., Tunick, R.
   Maratsos, M., & Chalkley, M. A. (1980). The internal        A., & Barrueco, S. (1997). Incidental language learning:
language of children’s syntax: The ontogenesis and repre-      Listening (and learning) out of the corner of your ear. Psy-
sentation of syntactic categories. In K. Nelson (Ed.), Chil-   chological Science, 8, 101-195.
dren’s language, Vol. 2. New York: Gardner Press.                 Schütze, H. (1994). A connectionist model of verb sub-
   Marler, P. (1991). The instinct to learn. In S. Carey & R.  categorization. Proceedings of the 16th Annual Conference
Gelman (Eds.), The epigenesis of mind: Essays on biology       of the Cognitive Science Society. Hillsdale, NJ: Erlbaum.
and cognition. Hillsdale, NJ: Erlbaum.                            Seidenberg, M. S., & MacDonald, M. C. (1999). A prob-
   Mintz, T. H. (1996). The roles of linguistic input and in-  abilistic constraints approach to language acquisition and
nate mechanisms in children’s acquisition of grammatical       processing. Cognitive Science, 23, 569-588.
categories. Unpublished Ph.D. dissertation, University of
Rochester.
   Mintz, T. H., Newport, E. L., & Bever, T. G. (1995).
Distributional regularities of form class in speech to young
children. Proceedings of NELS 25. Amherst, MA: GLSA.
   Morgan, J. L., Meier, R. P., & Newport, E. L. (1987).
Structural packaging in the input to language learning: Con-
tributions of prosodic and morphological marking of phrases
to the acquisition of language. Cognitive Psychology, 19,
498-550.
   Morgan, J. L., Meier, R. P., & Newport, E. L. (1989).
Facilitating the acquisition of syntax with cross-sentential
cues to phrase structure. Journal of Memory and Language,
28, 360-374.

