UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Adding syntactic information to LSA
Permalink
https://escholarship.org/uc/item/7r89x190
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
Wiemer-Hastings, Peter
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                Adding syntactic information to LSA
                                                         Peter Wiemer-Hastings
                                               Peter.Wiemer-Hastings@ed.ac.uk
                                School of Cognitive Science / ICCS, Division of Informatics
                                   University of Edinburgh, Edinburgh EH8 9LW Scotland
                           Abstract                                  approximate understanding of student inputs by com-
                                                                     paring them to expected answers, and using the LSA
   Much eﬀort has been expended in the ﬁeld of Natural               cosines as a metric of the extent to which the student
   Language Understanding in developing methods for de-              entered what was expected.
   riving the syntactic structure of a text. It is still unclear,       We evaluated this approach by randomly selecting a
   however, to what extent syntactic information actually
   matters for the representation of meaning. LSA (La-               set of 8 student answers to each of 24 questions in our do-
   tent Semantic Analysis) allows you to derive informa-             main of computer literacy (Wiemer-Hastings, Graesser,
   tion about the meaning without paying attention even              Harter, & the Tutoring Research Group, 1998). We
   to the order of words within a sentence. This is consis-          asked human raters to evaluate these answers by pro-
   tent with the view that syntax plays a subordinate role
   for semantic processing of text. But LSA does not per-            viding an aggregate measure of the percentage of stu-
   form as well as humans do in discriminating meanings.             dent answer propositions that “match” some expected
   Can syntax be the missing link that will help LSA? This           answer proposition. Proposition was deﬁned loosely as
   paper seeks to address that question.                             an atomic sentence. Match was left to the human raters
                                                                     to deﬁne. Then we performed the same analysis with
                                                                     LSA, modeling the match function by adjusting the co-
                       Introduction                                  sine threshold. The best performance was realized with
In the beginning, there was syntax. And it was good.                 a 200-dimensional space with a cosine threshold of 0.5.
But it did not give us what we really want to know about             This provided a correlation of r = 0.49 with the average
a text — what it means. Then there was latent seman-                 rating of the human judges. Because the distribution
tic analysis (Deerwester, Dumais, Furnas, Landauer, &                of ratings was skewed, we also calculated Cronbach’s al-
Harshman, 1990, LSA), which provided a means of com-                 pha. The average alpha score between human raters was
paring the “semantic” similarity between a source and                α = 0.76. The alpha score between LSA and the aver-
target text, and thereby giving some idea of meaning of              age human rating was α = 0.60. These results were very
the source. That was good too, almost as good as hu-                 encouraging. LSA provided much of the discrimination
mans in a simple task, but not quite. Because LSA pays               shown by human raters, enough to use in the AutoTutor
no attention to syntax at all — not even word order —                system. It could however, be improved.
one promising approach to improving LSA is by giving                    The obvious information source that LSA ignores is
it some of the information that is provided by syntax.               syntax. It is a “bag-of-words” approach, simply adding
Knowledge about the syntactic structure of a sentence                together term vectors to make a vector for a text. This
provides information about the relationships between the             paper is an attempt to identify whether the addition of
words: which words modify which other words, and the                 syntactic knowledge can strengthen LSA judgments.
relationships between verbs and their arguments or the-
matic roles. The research presented here is an attempt               Related work
to evaluate the beneﬁts of providing LSA with thematic               Partially as a result of the Behaviorist movement in psy-
role information which comes from syntactic knowledge.               chology, linguistics and natural language processing fo-
                                                                     cused for a long time primarily on the syntactic structure
Previous work                                                        of sentences (Chomsky, 1981, for example). In the 70’s
The primary goal of the AutoTutor project (Graesser,                 and 80’s, Schank sought to change this by claiming that
Franklin, Wiemer-Hastings, & the Tutoring Research                   semantics alone was suﬃcient (Schank & Riesbeck, 1981,
Group, 1998; Wiemer-Hastings, Wiemer-Hastings, &                     for example). More recently, researchers from psychol-
Graesser, 1999) is to model human tutorial dialogue.                 ogy have championed LSA as both a technique for de-
It is based on studies of the discourse patterns of hu-              termining the meaning of texts and as a model of human
man tutors during tutoring sessions (Person, Graesser,               language.
Magliano, & Kreuz, 1994). These analyses have shown                     Much of the recent interest (and controversy) regard-
that human tutors do not have complete understanding                 ing LSA can be traced to Landauer, Kintsch, and col-
of their students’ answers to questions, but the do get              leagues. They imported LSA from the realm of infor-
an approximation. For AutoTutor, LSA provides such                   mation retrieval and hailed it as part or parcel of a psy-

chological model of language understanding. Landauer          could be provided. One obvious possibility is to use more
and Dumais (1997) described LSA as a model of human           classical natural language understanding techniques as a
language acquisition, using it to explain how the pace of     pre-ﬁlter for LSA. The idea is to use parsing, anaphora
lexical acquisition apparently outstrips the exposure to      resolution and other dialogue-processing techniques to
new words. Landauer has gone on to claim that LSA is          prepare chunks of text for LSA to process semantically.
a complete model of language understanding (Landauer,         Alternatively, this could be viewed as using LSA as the
Laham, Rehder, & Schreiner, 1997). He explains away           semantic component of a classical natural language un-
the existence of syntax by suggesting that it is only there   derstanding system.
to simplify the computational complexity of getting the          We preprocessed the student sentences and the ex-
words into an LSA-like representation in the ﬁrst place.      pected answer sentences in the following way: First,
   Other psychologists have stressed the role which syn-      we performed a basic syntactic segmentation of the sen-
tax can play in lexical acquisition. The syntactic boot-      tences. Although there are surface-level parsing meth-
strapping(Gleitman & Gillette, 1994) theory shows how         ods generally available (Abney, 1996, for example), their
pre-verbal children can use their knowledge of syntax to      grammars must be modiﬁed to conform to the appli-
help guide their acquisition of verbs.                        cation. If this approach is successful, we will move to
   Kintsch (1998) has appended LSA to his Construc-           automated methods. For this test, we simply separated
tion/Integration model of text understanding as the se-       the sentences into atomic clauses or propositions, and
mantic component. LSA provides a sort of spreading            then segmented them by hand, breaking them down into
activation-like inclusion of related concepts when new in-    strings which corresponded to:
formation is integrated into a knowledge structure. This
allows the system to perform a type of inference, making,     • subject noun phrase
for example, “driver” and “computer” available when           • verb, including adverbs and adverbial phrases
“bus” is mentioned in a text.
   In other related psychological approaches, MacDonald       • object noun phrase (when applicable)
has proposed a used a variant of LSA to predict semantic
priming (McDonald, 2000). And Ramscar and colleagues             This provides two types of additional information:
have used LSA to model analogical reasoning (Packiam-
Alloway, Ramscar, & Corley, 1999).                           1. the grouping of words which belong together into
   The HAL system (Burgess & Lund, 1997) is similar              “components”
to LSA in the sense that it is based on co-occurrences,      2. the pseudo-semantic role of the components as derived
but word order information enters the representation             from syntactic argument structure
space through a weighting mechanism: A co-occurrence
is weighted more heavily the fewer words intervened be-          Second, we resolved anaphora in the sentences, replac-
tween the two words, within a window of usually ten           ing pronouns by their antecedents. Finally, when there
words. So, two words that co-occur in immediate adja-         was a conjunction, we distributed the arguments. For
cency are weighted most strongly. This is not syntax,         example, if there was a sentence like, “Subject verb ob-
but it does grant some sensitivity to word order.             ject1 and object2”, it was broken into (“verb” “Subject”
   Burgess and Lund replicated earlier work by Finch          “object1”) and (“verb” “Subject” “object2”), using a
and Chater (Finch & Chater, 1992) which showed that           verb-preﬁx notation.
by applying a high-dimensional method to clustering the          We made no attempt to do any other processing based
co-occurences of words in a corpus, it is possible to in-     on discourse relations for two reasons. First, LSA nor-
fer lexical categories that correspond well with standard     mally ignores “stop words” like “if” and “because” any-
syntactic theories. Finch and Chater also showed that         way. Second, extracting any more complex discourse
you could use these categories to infer basic grammati-       relations would require the use of semantic understand-
cal rules (see also (Siskind, 1996; Christiansen & Chater,    ing which is the goal of this process. Table 1 gives some
1999) for other corpus-based approaches to acquiring          some examples of sentences and their representations in
such information). Thus, there seems to be suﬃcient           this scheme.
information in a corpus of text to statistically infer some-     There are three competing hypotheses of the eﬀect on
thing about the syntactic structure of that corpus.           similarity judgments of using this additional information
   This does not mean, however, that a technique like         along with LSA:
LSA already has the type of syntactic information that
we are attempting to incorporate here. For any particu-      1. Component grouping will increase discrimination be-
lar sentence, LSA creates a vector just based on the bag         cause it adds information — the role of diﬀerent com-
of words that are in that sentence. It has no information        ponents.
about the word order within that sentence or about the
relationships between the words.                             2. Component grouping will hurt discrimination because
                                                                 LSA works better on longer strings.
Approach                                                     3. Component grouping will hurt grouping due to some
Our initial success with LSA and the potential for im-           complexity of combining individual component simi-
provement led us to examine how additional information           larity scores.

                                  Table 1: Example sentences and their representations
        RAM stores the instructions to your programs.          (“stores” “RAM” “the instructions to your pro-
                                                               grams”)
        If the new motherboard uses the same type of (“if uses” “the new motherboard” “the same type
        RAM, you can just take the SIMMs out of your old of RAM”) (“can just take out of your old mother-
        motherboard and install them in your new moth- board” “you” “the SIMMs”) (“and install in your
        erboard.                                               new motherboard.” “you” “the SIMMs”)
   The following section describes our ﬁrst attempt to          mance. The performance steadily increased from there
test these hypotheses using a straightforward combina-          up to their 200 word maximum. Despite this ﬁnding, we
tion of the between-component cosines.                          have found performance approaching human abilities on
                                                                our tutoring texts which have an average length of 16
                      Experiment 1                              words. Thus, we thought that any minor reduction in
Given this type of representation, there remain a variety       performance due to length would be oﬀset by increased
of ways to calculate the overall similarity between propo-      information provided by the pre-processing.
sitions based on the similarities of the components. In            Analysis of cases of disagreement between LSA and
experiment one, we took the most straightforward ap-            the human raters showed that some items got very bad
proach, simply averaging the cosines of the respective          scores because one component consisted only of a “stop
components. In other words, we calculated the LSA co-           word” — a member of a list of 440 common words that
sine between the verb string from a student proposition         includes prepositions, pronouns, and some very common
and the verb string from an expected answer. We re-             adjectives, adverbs, verbs, and nouns. For example, one
peated this for the other sentence components. If there         student proposition has a verb component group consist-
was an object string for one sentence and not for the           ing of the string, “stores”, and the expected answer has
other, a component score of zero was recorded. Then we          the verb string, “has”. In this case (“RAM stores infor-
averaged across the (normally two or three) components          mation being worked with”), the meanings of these two
of the propositions.                                            verbs are quite similar. But because “has” is on the stop
   Next, we aggregated the scores for each student an-          word list, it has no representation in the LSA space, and
swer proposition by taking the maximum average cosine           the cosine comparison returns a value of 0.
across the diﬀerent expected answer propositions. As in            On the other end of the spectrum, there was often an
the previous experiment, the ﬁnal score was the percent-        exact match between the subjects. For example, “RAM”
age of student answer propositions that achieved a score        and “CPU” are frequent subjects which, if they match at
above the empirically-determined threshold. We tested           all, tend to match exactly, getting a 1.0 cosine. Because
thresholds between 0.05 and 0.95 in 0.05 increments. We         average “good” cosine matches are often in the 0.4 to 0.6
measured the correlation between the LSA scores with            range, this tends to inﬂate the cosine average. This is
the human ratings.                                              especially the case for intransitive sentences where there
   The best correlation was r = 0.18 (not signiﬁcant),          are only two components. At the threshold that provided
with the threshold at 0.10.1 This is far below the per-         the best correlation with human raters, 0.10, the verb
formance of the previous approach which used LSA to             string only had to match at the 0.20 cosine level to put
compare entire sentences. Thus, these ﬁndings do not            the entire proposition over threshold.
support hypothesis 1.                                              Another factor which seemed to aﬀect the ratings was
   The decrease in the overall performance could poten-         the fact that there are so diﬀerent ways in which the
tially be due to the diﬀerence between comparing sen-           same content can be expressed in natural language. For
tences (as in the original experiment) and comparing            example, “RAM stores things being worked with” should
propositions. But the aggregate score essentially factors       have a fairly high semantic match for “The CPU uses
that out to the extent that length of string does not af-       RAM as a short-term memory storage” (whole string
fect LSA discrimination. String length does aﬀect LSA           LSA cosine = 0.48). But because the components do
discrimination however. Rehder et al (1998) used LSA            not line up at all in this approach, the cosine average
to assess the domain knowledge of essay writers. To de-         score is 0.03.
termine the eﬀect of essay length on LSA discrimination,           Based on these analyses, and under the hope that hy-
they truncated each essay after 10 words, 20 words, and         potheses 3 was the case instead of hypothesis 2, the ap-
so on. Below 60 words, they found fairly poor perfor-           proach was modiﬁed as described in the next section.
    1
      Due to the tediousness of pre-processing the sentences                        Experiment 2
by hand, these results were only calculated on the ﬁrst third   As previously mentioned, the shortness of the subject
of the test set. Analyses of the correlations on the original   components seemed to have an inordinate eﬀect on the
task on this part of the test set showed that it had lower
performance (r = 0.32, p = .01), but not as low as the results  overall scores. The average number of words in subject
of experiment 1. Immediate future work will be to process       components was 1.6, and many subject strings include
the rest of the test set.                                       stop words like “the” which do not contribute to LSA

cosines. Because of this, we tested in experiment two,                  Discussion and Future work
an alternative scoring strategy. In this strategy, the score  In some ways our approach has been to ﬁnd the best
between two propositions was calculated as follows:           formula for combining the similarity ratings between the
                                                              diﬀerent components. The one which worked best, the
   If there is a suitable match between the subjects,         one used in experiment 3, is non-linear. Perhaps a fur-
   then return the average of the cosines of the other        ther search of combination methods can out-perform the
   components.                                                basic LSA approach.
                                                                 Taking the cue from other statistical NLP approaches
   Here, “suitable match” was deﬁned as either a cosine       and neural networks, perhaps we just have to ﬁnd the
of 0.72 , or a cosine of zero. In theory a zero cosine        right weight space which gives the best correspondence
means a complete lack of semantic similarity. In prac-        between the parameters (components) and the training
tice, however, the cosine is only exactly 0 when one of the   data (human judgments). Ideally, if we were to attempt
strings is empty modulo stop words. Thus, this allows         such an implementation, instead of aggregate human
the matching of vague subjects like “you”.                    judgments over a set of items, we would have a rating for
   There are psychological theories of discourse which        each pair of items. That would be much more demand-
(vaguely) support this approach. One is the Given-New         ing on the human raters, but would give more data to
distinction of referents in discourse (Clark & Haviland,      train the approach on.
1977; Brennan, 1995). The theory includes a discourse            Future work will focus on two fronts. First, we will ac-
processing strategy in which the hearer searches the prior    quire more data on which to evaluate this approach, both
discourse context for an antecedent for Given informa-        by adding more test items, and by getting additional hu-
tion which is commonly the syntactic subject of a sen-        man judgments as outlined above. Second, we will ex-
tence. The rest of the sentence is New information which      plore other methods of combining the added syntactic-
is attached to the antecedent. In our approach, we ﬁl-        derived information into LSA.
ter out expected answers which do not have matching
Given information. Then we rate the similarity with the                        Acknowledgments
remaining items based on the similarity of the New in-        This project was partially supported by grant number
formation.                                                    SBR 9720314 from the National Science Foundation’s
   For this approach, the results were better than for        Learning and Intelligent Systems Unit. Many thanks to
experiment 1. The maximum correlation between the             Mark Core for comments on this approach and to Katja
system and the human raters was r = 0.24, (p = 0.06).         Wiemer-Hastings for comments on the paper.
This still does not approach the level of performance of
the original system, however. This led us to attempt to                             References
address the other concerns raised above in experiment 3.      Abney, S. (1996). Partial parsing via ﬁnite-state cas-
                                                                    cades. In Proceedings of the ESSLLI ’96 Robust
                       Experiment 3                                 Parsing Workshop.
In experiment 3, we built on the Given-New approach           Brennan, S. (1995). Centering attention in discourse.
presented above. This time, however, we joined the verb             Language and Cognitive Processes, 10, 137–167.
component of each proposition with its object compo-
nent into one larger component. This corresponds to the       Burgess, C., & Lund, K. (1997). Modelling parsing con-
VP in the basic S → NP VP sentence, or to the predi-                straints with high-dimensional context space. Lan-
cate in the Subject/Predicate description of a sentence.            guage and Cognitive Processes, 12, 177–210.
Obviously this is a partial reversal from our previous ap-    Chomsky, N. (1981). Principles and parameters in syn-
proach of adding more information derived from syntax.              tactic theory. In Hornstein, N., & Lightfoot, D.
The justiﬁcation was to make the LSA comparisons less               (Eds.), Explanation in Linguistics: The Logical
brittle with respect to distinctions between information            Problem of Language Acquisition. Longman, Lon-
in the verb and in the object.                                      don.
   The results for this approach were better than for ex-
periment 2. The maximum correlation was r = 0.40(p <          Christiansen, M., & Chater, N. (1999). Connectionist
0.01), with a cosine threshold of 0.3. (The Cronbach’s              Natural Language Processing: the state of the art.
alpha score was α = 0.49.)                                          Cognitive Science, 23 (4), 417–437.
   Although this is an improvement, it is still not as good   Clark, H. H., & Haviland, S. E. (1977). Comprehension
as the 0.49 correlation achieved by matching the entire             and the given-new contract. In Freedle, R. (Ed.),
sentence strings. Thus, these results do not support hy-            Discourse production and comprehension, pp. 1–
pothesis 1. And taken together, their support for hy-               40. Earlbaum, Hillsdale NJ.
pothesis 3 is ambiguous at best. This leaves us with the
question: Why, when getting more information, does the        Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer,
discrimination still suﬀer?                                         T. K., & Harshman, R. (1990). Indexing by Latent
                                                                    Semantic Analysis. Journal of the American Soci-
    2
      0.5 was also tested, but it made a negligible diﬀerence       ety for Information Science, 41, 391–407.

Finch, S., & Chater, N. (1992). Bootstrapping syntactic    Wiemer-Hastings, P., Graesser, A., Harter, D., & the
      categories using unsupervised learning. In Proceed-      Tutoring Research Group (1998). The foundations
      ings of the Fourteenth Annual Meeting of the Cog-        and architecture of AutoTutor. In Goettl, B., Halﬀ,
      nitive Science Society, pp. 820–825 Hillsdale, NJ.       H., Redﬁeld, C., & Shute, V. (Eds.), Intelligent
      Lawrence Erlbaum Associates Inc.                         Tutoring Systems, Proceedings of the 4th Interna-
                                                               tional Conference, pp. 334–343 Berlin. Springer.
Gleitman, L., & Gillette, J. (1994). The role of syntax in
      verb learning. In Fletcher, P., & MacWhinney, B.     Wiemer-Hastings, P., Wiemer-Hastings, K., & Graesser,
      (Eds.), The Handbook of Child Language. Black-           A. (1999). Improving an intelligent tutor’s compre-
      well, Oxford UK.                                         hension of students with Latent Semantic Analysis.
                                                               In Lajoie, S., & Vivet, M. (Eds.), Artiﬁcial Intelli-
Graesser, A. C., Franklin, S. P., Wiemer-Hastings, P., &       gence in Education, pp. 535–542 Amsterdam. IOS
      the Tutoring Research Group (1998). Simulating           Press.
      smooth tutorial dialogue with pedagogical value.
      In Proceedings of the 11th International Florida
      Artiﬁcial Intelligence Research Symposium Con-
      ference, pp. 163–167. AAAI Press.
Kintsch, W. (1998). Comprehension: A paradigm for
      cognition. Cambridge University Press, Cam-
      bridge, MA.
Landauer, T. K., Laham, D., Rehder, R., & Schreiner,
      M. E. (1997). How well can passage meaning be
      derived without using word order? A comparison
      of Latent Semantic Analysis and humans. In Pro-
      ceedings of the 19th Annual Conference of the Cog-
      nitive Science Society, pp. 412–417 Mahwah, NJ.
      Erlbaum.
Landauer, T., & Dumais, S. (1997). A solution to Pla-
      to’s problem: The latent semantic analysis the-
      ory of acquisition, induction, and representation
      of knowledge. Psychological Review, 104, 211–240.
McDonald, S. (2000). Environmental determinants of
      lexical processing eﬀort. Ph.D. thesis, University
      of Edinburgh, Edinburgh, Scotland.
Packiam-Alloway, T., Ramscar, M., & Corley, M. (1999).
      Verbal versus embodied priming in schema map-
      ping tasks. In Proceedings of the Twenty-First An-
      nual Conference of the Cognitive Science Society.
      Laurence Earlbaum Assocs. Vancouver, Canada,
      August, 1999.
Person, N. K., Graesser, A. C., Magliano, J. P., & Kreuz,
      R. J. (1994). Inferring what the student knows in
      one-to-one tutoring: The role of student questions
      and answers. Learning and Individual Diﬀerences,
      6, 205–229.
Rehder, B., Schreiner, M., Laham, D., Wolfe, M., Lan-
      dauer, T., & Kintsch, W. (1998). Using Latent
      Semantic Analysis to assess knowledge: Some tech-
      nical considerations. Discourse Processes, 25, 337–
      354.
Schank, R., & Riesbeck, C. (Eds.). (1981). Inside com-
      puter understanding. Erlbaum, Hillsdale, NJ.
Siskind, J. M. (1996). A computational study of
      cross-situational techniques for learning word-to-
      meaning mappings. Cognition, 61, 39–91.

