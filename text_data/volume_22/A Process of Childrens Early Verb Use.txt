UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Process of Children's Early Verb Use
Permalink
https://escholarship.org/uc/item/6516w442
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Authors
Jones, Gary
Gobert, Fernand
Pine, Julian M.
Publication Date
2000-01-01
Peer reviewed
  eScholarship.org                             Powered by the California Digital Library
                                                                University of California

                              A Process Model of Children’s Early Verb Use
                                     Gary Jones (gaj@Psychology.Nottingham.AC.UK)
                                   Fernand Gobet (frg@Psychology.Nottingham.AC.UK)
                                   Julian M. Pine (jp@Psychology.Nottingham.AC.UK)
                                         School of Psychology, University of Nottingham,
                                                 Nottingham, NG7 2RD, England
                           Abstract                                    In agreement with Ninio (1988), Tomasello argues that
                                                                    children will only start to construct word categories such as
   The verb-island hypothesis (Tomasello, 1992) states that         noun and verb when they begin to use instances of these
   children’s early grammars consist of sets of lexically-          categories as the arguments of predicates (e.g., using “ball”
   specific predicate structures (or verb-islands). However,        as an argument to the predicate “kick”). As verb-islands
   Pine, Lieven and Rowland (1998) have found that                  often use nouns as their arguments, children should form
   children’s early language can also be built around lexical       noun categories relatively early in their language
   items other than verbs, such as pronouns (this contradicts       development. Verb categories will only be formed later
   a strict version of the verb-island hypothesis). This paper
   presents a computational model (called MOSAIC), which
                                                                    when children begin to use verbs as the arguments of other
   constructs a network of nodes and links based on a               predicates (e.g., in double-verb constructions such as
   performance-limited distributional analysis of the input         “Want to + V” or “Can’t + V”).
   (mother’s speech). The results show that utterances                 The verb-island hypothesis can account for a number of
   generated from MOSAIC: (1) more closely resemble the             phenomena in children’s early multi-word speech. First, it
   child’s data than the child’s mother’s data on which             can explain the lexically-specific patterning of children’s
   MOSAIC is trained; and (2) can readily simulate both the         early verb use. For example, Tomasello (1992) has shown
   verb-island and other-island phenomena which exist in            that in the early stages of grammatical development his
   the child’s data.                                                daughter’s ability to generate longer sentences built up
                                                                    piecemeal around particular verbs, and failed to generalise to
                         Introduction                               new verbs which typically entered her speech in very simple
One of the most influential recent constructivist accounts of       structures. Second, it can explain the restricted nature of
early grammatical development is Tomasello’s (1992) verb-           children’s early word order rules. For example, Akhtar and
island hypothesis. According to this view children start            Tomasello (1997) have shown that young children not only
producing multi-word speech without knowledge of                    fail to generalise Subject-Verb-Object (SVO) word order
syntactic categories, such as noun and verb. Instead,               knowledge from one verb to another, but are also unable to
children’s early language use is based on a “functionally           use it as a cue for sentence comprehension with novel verbs.
based distributional analysis” (Tomasello, 1992, p.28) of           Third, it can explain differences in the flexibility with
the language they hear. This analysis assigns predicate1            which children use nouns and verbs in their early multi-
status to specific words based on their function in sentences.      word speech. For example, Tomasello and his colleagues
For example, in the sentence “Adam kicks the ball”, the             have shown that young children will readily use novel
roles of Adam and the ball are centred around “kicks”, such         nouns as arguments in familiar verb structures but tend to
that Adam is someone who can kick things, and the ball is           restrict their use of novel verbs to the structures in which
something that can be kicked. The lexical item “kick” is            they have heard those same verbs modelled in the input
therefore assigned a predicate role which takes as arguments        (Akhtar & Tomasello, 1997; Olguin & Tomasello, 1993;
a “kicker” (Adam) and a “kickee” (the ball).                        Tomasello & Olguin, 1993).
   The notion of “verb-island” arises because most predi-              One weakness of the hypothesis is that there are aspects of
cates are verbs in adult language and the arguments the             children’s early multi-word speech that do not fit a strict
predicate takes are specific to that predicate (e.g., “kickers”     version of the verb-island hypothesis. For example, Pine,
and “kickees”). Based on this idea, children’s early gram-          Lieven and Rowland (1998) have shown that many children
mar will consist of inventories of verb-specific predicate          acquire structures based around high frequency items which
structures (i.e., verb-islands). For example, the child will        Tomasello would not define as predicates (e.g., case-marked
use any object which it knows has performed kicking as the          pronouns such as “I” and “He” and proper-nouns such as
antecedent to “kick”. Verb-general marking (e.g., knowing           “Mummy” and the child’s name). Moreover, these pronoun
that someone who kicks can also be someone who hits)                and proper-noun islands not only seem to be functioning as
does not occur until the formation of a verb category.              structuring elements in children’s speech, but as structuring
                                                                    elements which accept verbs as slot fillers. These data
                                                                    suggest that the lexical specificity of children’s early multi-
1 For Tomasello, a predicate is a lexical item (typically a verb)
                                                                    word speech is not always “verb-specificity” or even
which forms the main relational structure of a sentence.            “predicate-specificity” (because verbs can be slot fillers of
Arguments are the lexical items to which the predicate relates.     other structures). Verb-island effects may simply be a
Therefore in the sentence “John walks the dog”, “walks” is the
predicate and “John” and “dog” are the arguments.
                                                                  1

special case of more general frequency effects on children’s         will relate to the next immediate mismatched feature in
acquisition of lexically-specific structures.                        the input.
   This paper presents a computational model called
MOSAIC (Model of Syntax Acquisition in Children),                    2. Familiarisation. When the input information is under-
which combines naturalistic input (mother’s speech) and a            represented by the image (the information given at the
performance-limited distributional learning mechanism in             node), additional feature(s) from the input are added to the
order to produce child-like utterances as output. The results        image. The information in the node will contain all
will show that MOSAIC is able to: 1) simulate verb-island            information that led to the node during traversal, plus any
phenomena that are consistent with children’s early multi-           additional feature(s).
word speech; 2) simulate other-island phenomena which
exist in children’s early multi-word speech but which are            Discrimination therefore creates nodes and test links, and
problematic for a strict version of the verb-island               familiarisation creates or modifies the information contained
hypothesis; and hence 3) provide a process-based                  in nodes. The amount of information stored at nodes
explanation of why some lexical items come to function as         increases with their distance from the root, because each
“islands” in the child’s grammar and others do not.               node contains the accumulation of information of all the
                                                                  nodes that were accessed in traversing to the node.
                  The MOSAIC model                                   There are two constraints that are imposed when learning
MOSAIC is a variant of EPAM/CHREST (De Groot &                    by discrimination and familiarisation. First, before creating
Gobet, 1996; Gobet, 1996; Gobet & Simon, in press)                a node containing more than one input feature (i.e., a
which creates a discrimination network (a hierarchical            sequence of features), the individual features in the sequence
structure of nodes which are linked together) based on a          must have been learnt (each input element is said to be a
given input. Discrimination networks have a root node at          primitive). Second, all nodes containing just one input
the top of the hierarchy, with all other nodes cascading from     feature are linked to the root node (i.e., all primitives are
the root node (see Figure 1 for an example). Nodes are            immediately below the root node; in this way all sequences
connected to each other by links. This section will describe      of input features are below the node which represents the
the basic working of MOSAIC, and then give an example of          initial feature in the sequence).
MOSAIC’s learning mechanisms using mother’s speech as                Learning can also occur whilst traversing the network.
input.                                                            MOSAIC compares each node traversed with other nodes in
                                                                  the network to see if they have a similar usage. Similar
A general overview of MOSAIC                                      usage means that there are common test links below each of
                                                                  the two nodes. When this is the case, a lateral link is
MOSAIC’s discrimination network begins with a root node
                                                                  created between the nodes (this is explained further in the
(which always contains no information). As in other models
                                                                  following section).
of the EPAM family (Feigenbaum & Simon, 1984),
learning occurs in two steps. The first step involves             An example              of   MOSAIC          learning        an
traversing the network as far as possible with the given
input, taking one feature of the input at a time. This is done
                                                                  utterance
by starting at the root node and examining all the test links     The input given to MOSAIC consists of a set of mother’s
from the root node, selecting the first test link whose test is   utterances. Each line of input corresponds to a single
fulfilled by the first feature in the input (when beginning       utterance (delimited by an END marker which signifies the
learning, only the root node will exist and therefore no tests    end of the utterance), and each word in the utterance is an
can be fulfilled). The node at the end of the test link now       input feature. The example utterance “Who came to see you
becomes the current node and the next feature of the input is     on the train?” will be used as input to illustrate how
applied to all the test links immediately below this node.        MOSAIC learns.
The traversal continues until a node is reached where no             The first input feature (“who”) is applied to all of the root
further traversing can be done (either because the current        node’s test links in the network. As the network is empty,
input feature fulfilled none of the tests of the node’s test      there are no test links. At this point MOSAIC must
links, or the current node has no test links below it).           discriminate because the input feature “who” mismatches
Traversing the network in this way is also how information        the information at the root node (the root node information
can be output from the network (this will be explained            is null). The discrimination process creates a new node, and
later).                                                           a test link from the root node to the new node with the test
   The second step involves adding new information, nodes,        “who” (see Figure 1). MOSAIC must then familiarise itself
and test links. The full input is compared to the                 with the input feature, in order to create the “who”
information at the final node that was reached by traversal.      information in the image of the node.
Based on this comparison, learning can arise in two ways:            When encountering the same input for a second time, the
                                                                  test link “who” can be taken, and the input can move to the
   1. Discrimination. When the input information                  next feature, “came”. As the node “who” does not have any
   mismatches the information given at the node (the              test links below it, then under normal circumstances
   image), a new test link and node are added to the tree         discrimination would occur below the “who” node.
   below the node that has just been reached. The new test        However, MOSAIC has not yet learnt the input feature
                                                                2

                                                                          When there is a significant amount of overlap between
                         ROOT
                                                                       words or phrases that follow a particular word in the input
               who                    to                               (i.e., there is significant overlap between the test links that
                            came                                       are below two particular nodes) then the two nodes can be
         WHO             CAME
                                                                       linked by a lateral link. The minimum number of test links
                                           TO
                                                                       which must overlap for a lateral link to be created is
             came                                                      determined by an overlap parameter. Using the network in
         WHO                                                           Figure 2 as an example, “cat” and “dog” will have a lateral
         CAME            Network after first presentation              link between them when the overlap parameter is set to 3
             to                                                        because at least 3 of the test links below “cat” and “dog”
                         Network after third presentation
          WHO                                                          are shared. The next section shows how lateral links are
        CAME TO          Network after fifth presentation              used when generating output from MOSAIC.
       Figure 1: Structure of the MOSAIC net after five                Generating           utterances      from     a   MOSAIC
     presentations of the input “Who came to see you on                network
                           the train”.                                 Utterances can be generated from MOSAIC by beginning at
                                                                       the root node and traversing down until encountering a
“came”, and so discrimination occurs below the root node.              node which contains an END marker (i.e., the last word in
Familiarisation will then fill the image of the new node               the utterance must be one which ended an utterance in the
with “came”. The third time the input is seen, the “who”               input). Whilst traversing down the network, both test links
test link can be taken, and the input can move onto the next           and lateral links can be taken. To help explain how
feature (“came”). No further test links are available, but the         utterances are generated from the network, test links will be
input “who came” mismatches the information at node                    called rote links hereafter, and lateral links will be called
“who” and so discrimination occurs. A new node “who                    generative links. This is because test links are created from
came” is created (see Figure 1). Familiarisation will fill in          rote learning, and lateral links are created from overlap in
the image of the new node.                                             node use. When traversing the network, if only rote links
   After a total of five presentations of “Who came to see             are taken then the resulting utterance must have been
you on the train?”, the network will have learnt the phrase            present in the input (because of the dynamics of the creation
“Who came to” (see Figure 1). This simple example serves               of the discrimination network, traversing down from the
to illustrate how MOSAIC works; in the actual learning                 root node will always produce a phrase that existed as a full
phase each utterance is only used once, encouraging a                  utterance or part of an utterance in the input). However,
diverse network of nodes to be built.                                  when a generative link is taken, the resulting utterance may
   During traversal of the network, lateral links can be               never have been seen before in the input.
created. A lateral link is a link between any two nodes in a              When generative links exist, MOSAIC can take these
MOSAIC network (excepting the root node). Lateral links                links as part of the traversal of the network. For example, in
are designed to link together nodes which are used in the              the network shown in Figure 2, the generated utterance
same manner. Usage is based on the test links that are                 could begin with “cat”, take the generative link across to
immediately below a particular node. The way that                      “dog”, and then continue the utterance with any phrase that
MOSAIC creates nodes and test links means that all the                 follows “dog” (i.e., the remainder of the phrase is built up
test links that are below a particular node will consist of the        by traversing the nodes below “dog”). This produces novel
word or words that follow that node in the input (as shown             utterances that were not seen before in the input, such as
in the previous section). For example, in Figure 2, the                “cat runs” and “dog moves”. Currently, only one
words “moves”, “sits”, “walks”, and “chases” must have                 generative link is taken per traversal of the network in order
followed “cat” in the input, meaning sentences such as “cat            to limit the number of generated utterances (the next section
sits down” have been seen in the input.
                                                                 ROOT
                                                     cat                         dog
                                              CAT                                       DOG
                                                            Lateral link
                                    moves           chases                        sits          runs
                                           sits walks                                walks chases
                                   CAT     CAT     CAT     CAT             DOG     DOG      DOG    DOG
                                  MOVES    SITS  WALKS CHASES              SITS   WALKS CHASES RUNS
                                                     Contextual overlap which
                                                         leads to lateral link
                                         Figure 2: Example of how lateral links are created.
                                                                    3

shows that taking only one generative link enables the            MOSAIC when trained using Anne’s mother’s utterances
network to produce over seven generated utterances to every       as input. The utterances for Anne and her mother were taken
one rote learned utterance).                                      from the Manchester corpus (Theakston, Lieven, Pine &
                                                                  Rowland, in press) of the CHILDES database
          Modelling verb-island phenomena                         (MacWhinney & Snow, 1990). The corpus consists of
The verb-island hypothesis states that children’s early           transcripts of the mother-child interactions of twelve
language consists of lexical items (typically verbs) existing     children over a period of twelve months. The transcripts
as predicates, which take other lexical items as arguments.       contain both the utterances and the syntactic categories
As lexical items such as pronouns cannot, in Tomasello’s          (e.g., noun, verb) of all words in the utterances. The child
terms, be predicates, then for flexibility the terms frame and    focused on here, Anne, began at age 1;10.7 and completed
slot filler will be used in place of predicate and argument. A    the study at age 2;9.10. Her starting MLU (Mean Length of
frame is therefore a relational structure of a sentence and the   Utterance) was 1.62 with a vocabulary size of 180.
slot fillers to the frame are the lexical items which relate to     For Anne there were 17,967 utterances (i.e., utterance
the frame. For example, the sentence “Daddy moves the             tokens), of which 8,257 utterances were unique (i.e.,
chair” has “moves” as the frame and “Daddy” and “chair”           utterance types). There were 7,331 multi-word utterance
as the slot fillers.                                              types. For Anne’s mother, there were 33,390 utterance
   The verb-island hypothesis can be confirmed if the             tokens, 19,358 utterance types, and 18,684 multi-word
language data contain verbs which exist as frames (i.e.,          utterance types. A random sample of 7,331 of Anne’s
verbs which take several different lexical items as slot          mother’s multi-word utterance types were taken to match
fillers), and contain very few other lexical items which exist    Anne for quantity of data.
as frames. To examine this, the language data will be
analysed by extracting verb+common-noun and common-               MOSAIC data
noun+verb sequences. Common-nouns, rather than all                MOSAIC was trained on the full 33,390 utterance tokens of
lexical items, are examined because: 1) they are the most         Anne’s mother in chronological order, one utterance at a
common category in children’s speech; 2) Tomasello                time (as a list of words). MOSAIC’s overlap parameter was
(1992) predicts that children form noun categories earlier        set to 15. The input to MOSAIC did not contain any
than verb categories based on their use as slot fillers (i.e.,    coding information. This means that MOSAIC was not
they should be used often as the slot fillers of verb frames);    presented with any information about the categories of
and 3) the analysis is more tractable with only two types of      words (e.g., that “dog” was a noun or “go” was a verb) or
lexical item.                                                     about noun or verb morphology (e.g., “going” was seen
   To investigate whether other-island phenomena exists,          rather than the morpheme “-ing” attached to the root form
pronoun+verb and proper-noun+verb combinations will be            of the verb “go”).
extracted and analysed. Pronouns are used because a strict          After MOSAIC had seen all of the input utterances, every
version of the verb-island hypothesis does not allow              possible utterance that could be generated was output. This
pronouns to act as islands. Also, pronouns occur with high        resulted in 178,068 utterance types (21,510 produced by
frequency in the child’s data and are often followed by a         rote and 156,558 produced by generation). Examples of the
verb (i.e., they may show verbs being used as slot fillers to     utterances generated from MOSAIC are shown in Table 1.
other frames). Proper-nouns are used for an additional test of    The analyses of the data from MOSAIC are based on a
                                                                  random sample of 7,331 (i.e., matching Anne for quantity)
other-islands.
                                                                  of the multi-word utterance types produced by generation,
Method                                                            because these are the novel utterances that will not have
                                                                  existed as part of the mother’s input.
Subject data                                                      Procedure
Three sets of data are compared for the verb-island               The utterances for both the child and mother included the
phenomena: the utterances from one child, Anne; the               syntactic category for each word in an utterance. The
utterances from Anne’s mother; and the utterances from            codings for the child’s utterances were used to determine
                                                                  the categories of words in the utterances of the child; the
                                                                  codings for the mother’s utterances were used to determine
Table 1: Sample of the utterances generated from MOSAIC.          the categories of words in the utterances of the mother.
            MOSAIC utterance                                      Some words (such as “fire”) belong to more than one
            I forgotten                                           category. In these cases, a category was only assigned if the
            That’s my toes again                                  word was used as that category in at least 80% of the
            Where’s the magic bag                                 instances in which the word was used. For MOSAIC’s
            And she like them                                     utterances, the categories were calculated based on the
            Baby put the sheep in the farmyard                    codings from the mother’s utterances.
            What about the camel                                    The three sets of data were analysed in the same way.
            All on the settee                                     The method of extracting verb+common-noun
            Who can you see on here                               combinations is detailed here but the method is the same
            He didn’t catch me
                                                                4

     Table 2: Percentage of the 7,331 multi-word utterances from Anne, Anne’s mother, and MOSAIC that contain
     nominal+verb or verb+nominal combinations. The nominals are broken down into pronoun, proper-noun, and
                                             common-noun combinations.
                                          Anne                  Anne’s mother                       MOSAIC
          Pair distribution    Nominal+        Verb+       Nominal+           Verb+        Nominal+           Verb+
                                   Verb       Nominal         Verb           Nominal           Verb          Nominal
              Pronouns            4.73%        4.60%          8.83%           6.15%           5.16%           2.58%
            Proper-nouns          1.31%        0.61%          1.94%           1.49%           0.55%           0.64%
          Common-nouns            1.91%        7.41%          5.65%           10.42%          1.16%           5.18%
for the extraction of common-noun+verb, pronoun+verb,           Anne much more closely than they do Anne’s mother (on
and proper-noun+verb combinations.                              whose utterances MOSAIC was trained). For example,
  Each utterance was searched for a word which was              5.16% of MOSAIC’s utterances and 4.73% of Anne’s
categorised as a verb. The two words following the verb-        utterances contain pronoun+verb combinations, compared
category word were examined to see if either occurred as a      with 8.83% for Anne’s mother. In fact, despite all three
common-noun. If so, the verb+common-noun pair was               datasets having been matched for overall sample size,
stored for analysis. Verbs were then converted to their root    Anne’s mother produces many more instances of every
form (e.g., “going” and “goes” both become “go”) and            combination shown in Table 2 (e.g., producing over twice
common-nouns to their singular form (e.g., “dogs”               as many different nominal+verb combinations [16.42%] as
becomes “dog”), and any duplicate pairs were removed.           Anne [7.95%] and MOSAIC [6.87%]).
Analysis was therefore conducted on types, not tokens. The
number of slot fillers for a verb is the number of different    Verb-islands exist in the data
common-noun types that were paired with that verb.              As explained earlier, the data are expected to show that
                                                                verbs act as frames (taking lots of different common-nouns
How well does the output of MOSAIC match                        as slot fillers) whereas common-nouns are not expected to
the subject data?                                               act as frames. Whether this is true can be examined by
Table 2 shows the percentage of each set of 7,331 multi-        looking at the number of common-noun types that follow
word utterances from Anne, Anne’s mother, and MOSAIC            verb types, and vice versa. We operationalise the concept of
that contained verb+nominal and nominal+verb                    an “island” as a lexical item which acts as a frame for at
combinations (the label “nominal” refers to the group of all    least ten different slot fillers (e.g., a verb type would have to
pronouns, proper-nouns, and common-nouns).                      have ten different common-noun types as slot fillers). For
  The data show that the utterances from MOSAIC match           example, for Anne, the verb “Find” is an island because it
  Table 3: Verb-island data for Anne, Anne’s mother, and MOSAIC (mean=mean number of slot fillers for each frame
                            type; islands=number of frames that have 10 or more slot fillers).
              Data source            Mean           Islands             Islands having the most slot fillers
                           VERB+COMMON-NOUN (frame=verb; slot filler=common-noun)
                  Anne                6.24             10                 Get, Put, Want, Go, Need, Make
                 Mother               5.97             13                Get, Put, Want, Need, Have, Find
               MOSAIC                 9.74             10                Get, Put, Eat, Think, Want, Find
                           COMMON-NOUN+VERB (frame=common-noun; slot filler=verb)
                  Anne                1.51              1                                Baby
                 Mother               2.08              4                  Baby, Animal, Dolly, Penguin
               MOSAIC                 1.57              1                                Baby
                                 PRONOUN+VERB (frame=pronoun; slot filler=verb)
                  Anne               21.69             10                  I, You, He, It, That, They, We
                 Mother              27.65             11                   You, I, He, We, She, They, It
               MOSAIC                25.20             12                   You, It, That, I, He, We, She
                             PROPER-NOUN+VERB (frame=proper-noun; slot filler=verb)
                  Anne                5.65              3                       Anne, Mummy, Daddy
                 Mother               3.23              3                       Anne, Mummy, Daddy
               MOSAIC                 6.67              2                           Anne, Mummy
                                                              5

is followed by ten common-noun types (“Dolly”, “Plate”,           Gobet, F. (1996). Discrimination nets, production systems
“Seat”, “Welly-boot”, “Baby”, “Ribbon”, “Hat”,                      and semantic networks: Elements of a unified framework.
“Duck”, “Pen”, and “Bird”). Table 3 shows these data for            In Proceedings of the 2nd International Conference on the
Anne, Anne’s mother, and MOSAIC. This shows that                    Learning Sciences, 398-403. Evanston, Il: Northwestern.
there are many verb-islands for all three sources of data, but    Gobet, F., & Simon, H. A. (in press). Five seconds or
very few common-noun islands. In both cases, MOSAIC                 sixty? Presentation time in expert memory. Cognitive
provides an identical match to Anne for number of islands.          Science.
                                                                  MacWhinney, B., & Snow, C. (1990). The Child
Other-islands exist in the data                                     Language Data Exchange System: An update. Journal of
Table 3 shows that both pronoun-islands and proper-noun             Child Language, 17, 457-472.
islands exist for Anne, Anne’s mother, and MOSAIC. The            Ninio, A. (1988). On formal grammatical categories in early
pronoun-islands are particularly strong (the mean number of         child language. In Y. Levy, I. M. Schlesinger, & M. D.
slot fillers for pronouns is more than 20 for all three sets of     S. Braine (Eds.), Categories and processes in language
data) and because pronouns take verbs as slot fillers, these        acquisition. Hillsdale, NJ: Lawrence Erlbaum Associates.
islands are problematic for a strict version of the verb-island   Olguin, R., & Tomasello, M. (1993). Twenty-five-month-
hypothesis which predicts that only verbs are initially used        old children do not have a grammatical category of verb.
as frames. The other-islands, as Table 3 shows, are readily         Cognitive Development, 8, 245-272.
simulated by MOSAIC.                                              Pine, J. M., Lieven, E. V. M., & Rowland, C. F. (1998).
                         Discussion                                 Comparing different models of the development of the
The output from MOSAIC more closely resembles the                   English verb category. Linguistics, 36, 807-830.
child than the child’s mother, demonstrating that MOSAIC          Theakston, A. L., Lieven, E. V. M., Pine, J. M., &
is doing more than just a straightforward distributional            Rowland, C. F. (in press). The role of performance
analysis of its input. In fact, it is a combination of the          limitations in the acquisition of ‘mixed’ verb-argument
performance-limitations imposed on the model (e.g.,                 structure at stage 1. In M. Perkins & S. Howard (Eds.),
learning one word at a time), and the frequency of                  New directions in language development and disorders.
occurrence of items in the input, that enable MOSAIC to             Plenum.
match the child data. MOSAIC seeks to maximise the                Tomasello, M. (1992). First verbs: A case study of early
information held at nodes in the network, but can only do           grammatical development. Cambridge: CUP.
so for input sequences that occur frequently (e.g., due to        Tomasello, M., & Olguin, R. (1993). Twenty-three-
limitations in only learning one item at a time). MOSAIC            month-old children have a grammatical category of noun.
therefore offers a process-based explanation of why some            Cognitive Development, 8, 451-464.
lexical items come to function as “islands” in children’s
grammar and others do not: children are maximally
sensitive to the high frequency lexical items that exist in
their input.
   The results presented here show that when combined
with naturalistic input, a simple distributional learning
mechanism is able to provide an effective simulation of
child language data. The simulations show that first, it is
possible to model verb-island phenomena as the product of
a frequency-sensitive distributional analysis of the child’s
input, and, second, that the same mechanism can also
simulate other-island patterns which are problematic for a
strict version of the verb-island hypothesis.
                    Acknowledgements
This research was funded by the Leverhulme Trust under
grant number F/114/BK.
                        References
Akhtar, N., & Tomasello, M. (1997). Young children’s
   productivity with word order and verb morphology.
   Developmental Psychology, 33, 952-965.
De Groot, A. D., & Gobet, F. (1996). Perception and
   memory in chess: Studies in the heuristics of the
   professional eye. Assen: Van Gorcum.
Feigenbaum, E. A., & Simon, H. A. (1984). EPAM-like
   models of recognition and learning. Cognitive Science, 8,
   305-336.
                                                                6

