UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reflective Introspective Reasoning Through CBR
Permalink
https://escholarship.org/uc/item/15w61917
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
Fox, Susan Eileen
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                      Reflective Introspective Reasoning Through CBR
                                                        Susan Eileen Fox
                                                      fox@macalester.edu
                                                       Macalester College
                                                       1600 Grand Avenue
                                                  Saint Paul, MN 55105 USA
                           Abstract                                  A key issue for a reflective reasoner is deciding when
                                                                  to reflect. RILS uses failure-driven learning; reflective
   In recent years, “introspective reasoning” systems have        introspection occurs when an impasse is reached.
   been developed to model the ability to reason about               In the next section, we provide some background on
   one’s own reasoning performance. This research exam-           “reflection,” introspective learning in humans, and other
   ines “reflective” introspective reasoning: introspecting
   about the introspective reasoning process, itself. We in-      introspective reasoning systems. We then describe the
   troduce a reflective introspective reasoning system that       RILS approach to reflective introspection, and we clas-
   uses case-based reasoning (CBR) as its central reasoning       sify the kinds of reasoning failures RILS uses to trigger
   method. We examine the advantages of such a system,            reflective introspective reasoning.
   and attempt to classify the reasoning failures within in-
   trospective system that indicate a need to reflect higher.
                                                                                        Background
                                                                  Reflection
                       Introduction                               The term reflection, as it is used in this paper, refers to
In artificial intelligence, meta-reasoning systems have           systems which can shift the focus of their processing from
been used for a variety of purposes: to predict the behav-        the current task to the problem-solving task itself, and
ior of other agents, to guide the acquisition and applica-        can repeat this shift of processing indefinitely (Ibrahim,
tion of domain knowledge, and to “learn” by adjusting             1992). As a system shifts to a higher-level task, it con-
the system’s own reasoning processes in response to ex-           structs a “reflective tower” of reasoning processes. Each
perience. Meta-reasoning systems model the ability hu-            process analyzes and alters the one beneath it, which
mans have to reason about our own and others’ reasoning           is suspended until the higher-level process completes its
performance. Systems that apply meta-knowledge and                task.
meta-reasoning to improvement of their own reasoning                 While not a requirement, Reflection is easiest to
processes are called “introspective learning” systems.            achieve if the same reasoning method is used at all rea-
   The ability to reason introspectively requires knowl-          soning levels. In order to introspect, the system must
edge of one’s own reasoning methods, and observa-                 have a model of its own reasoning processes. The model
tion, evaluation, and alteration of those methods when            becomes more complex as the number of different rea-
needed. A similar ability has been documented in stud-            soning methods grows. Simplicity in the model enables
ies of human reasoning behavior, and modeled with a               the system to meaningfully alter more features of its pro-
variety of artificial intelligence techniques. Introspective      cessing, leading to greater flexibility.
reasoning systems often lack a critical component of hu-             The strength of a reflective system is its flexibility:
man meta-reasoning: the ability to introspect about our           every aspect of the system is open to adaptation and
introspections themselves. Introspective reasoning is of-         improvement, as the system responds and learns from
ten applied only to reasoning in service of some underly-         its experiences.. The drawback to a reflective system
ing task, such as navigation planning. An introspective           is the potential of the system to reflect infinitely with-
reasoner that can apply its reasoning to its own intro-           out making forward progress at any level. The system,
spective processes and repeat this reflection upon itself         when in doubt, must choose not to reflect and continue
indefinitely is called “reflective” (Ibrahim, 1992).              processing. Many reflective systems only shift attention
   We have developed a reflective introspective reasoner          to a higher level when an explicit failure, particularly a
that learns by altering its reasoning methods at all levels.      catastrophic failure occurs.
RILS1 analyzes both its task-level planning process and
                                                                  Human Introspective Reasoning Behavior
its introspective reasoning process, using a unified rea-
soning method, case-based reasoning (CBR), for all its            Several studies have found evidence that humans engage
tasks. Re-using CBR simplifies the introspective model            in introspective learning behavior: altering their reason-
of the system’s reasoning processes and facilitates reflec-       ing strategies as their experience grows.
tion.                                                                Chi & Glaser (1980) found differences between the
                                                                  reasoning strategies of experts and novices: experts ap-
    1
      Reflective Introspective Learning System                    proach problems in a more planful way, spend more time

analyzing of a problem before attempting to solve it, and         Domain Task
understand better the important features of a problem.
They suggest these strategies are learned as part of the         Determine case
process of becoming an expert.
   Flavell, Friedrichs, & Hoyt (1970) found that older         1. Create plan index
                                                               2. Retrieve plan
children were better than younger children at monitoring
how well they had performed a given task and judging
when they had completed it. The development demon-
strated here indicates an awareness of one’s own reason-           Adapt case                             Index Creation
ing processes, as well as learning from that awareness       Repeat:
to perform better. Kreutzer, Leonard, & Flavell (1975)          1. Select portion to adapt
                                                                2. Create adaptation strategy index
found that children improved their understanding of             3. Retrieve applicable strategies
their own memory processes as they became older: asked          4. Apply strategy
to describe strategies for remembering things, older chil-                                                   Retriever
dren tended to describe many strategies and their out-
comes, younger children very few.                                 Execute case
   Kruger & Dunning (1999) found that competence at a        Repeat
task was related to the ability to accurately judge one’s       1. Determine current state and goal
                                                                2. Create reactive plan index             Case Memory
own competence. This suggests that introspective skills         3. Retrieve reactive plan
are integrally intertwined with particular domain skills.       4. Apply reactive plan
   In all these cases humans show an improved perfor-
mance on a domain task when they also show evidence
of planful, introspective learning behaviors.                    Store new case
                                                              1. Determine index of new case
Introspective Reasoning Systems                               2. Add new case to memory
A variety of approaches to introspective reasoning sys-
tems exist. A few have examined reflective introspection.
   SOAR is a rule-based system which does deliberately      Figure 1: The domain task architecture of RILS: reuse
address reflection (Rosenbloom, Laird, & Newell, 1993).     of CBR
SOAR’s rule base may contain rules which control the
rule selection process, among others. SOAR can learn
new behaviors by creating new meta-rules. Its meta-         ing failures. It is not reflective; its introspective model
rules cannot affect all portions of its reasoning process.  describes only its underlying planning system. ROBBIE
                                                            does reuse its CBR processes for multiple planning tasks.
   The Massive Memory Architecture performs both in-
                                                            RILS was developed from ROBBIE as a case-based in-
trospective reasoning and case-based reasoning in a task-
                                                            trospective learner that retains an explicit model of its
driven manner (Arcos & Plaza, 1993). Autognostic uses
                                                            reasoning embodied in a set of introspective cases.
a “Structure-Behavior-Function” model to represent rea-
soning processes (Stroulia & Goel, 1995). RAPTER uses
model-based reasoning: an explicit model of “assertions”
                                                               The Reflective Introspective Learning
describing the ideal reasoning behavior is used to diag-                                           System
nose failures (Freed & Collins, 1994). These systems do     RILS performs route planning for a simulated robot, sup-
not include reflective capabilities.                        ported by case-based and introspective learning. Case-
   Meta-AQUA maintains reasoning trace templates            based reasoning is the central reasoning method for all
(Meta-XPs) which describe the patterns of reasoning         RILS tasks. The case memory stores cases for creat-
that indicate reasoning failures (Cox, 1996). Meta-         ing and executing route plans, and also stores “assertion
AQUA’s Meta-XPs could be applied to the introspec-          cases” that, taken together, comprise its introspective
tive process itself, but reflection is not the focus of the model. The model captures the reasoning processes of
project.                                                    both planning and introspective tasks.
   IULIAN integrates introspective learning with the
overall domain task in a way that permits reflection        RILS’ Domain Task
(Oehlmann, Edwards, & Sleeman, 1994). IULIAN uses           RILS operates in the same domain as the ROBBIE sys-
case-based planning to generate both domain introspec-      tem (Fox & Leake, 1995); it navigates a simulated robot
tive plans, but, as in SOAR, its introspective plans have   through a domain of streets, using case-based planning
incomplete access to the mechanisms which use them.         to create high-level plans and case-based reactive plan-
   The ROBBIE system (Fox & Leake, 1995), the pre-          ning to interactively execute the plans in its simulated
cursor to RILS, is related to the model-based reasoning     domain. Figure 2 shows a sample of RILS’ domain.
systems described above. It contains an explicit collec-       RILS reuses its case-based index creation, retrieval,
tion of assertions which describe the ideal reasoning pro-  and case memory for multiple domain tasks: creation
cess of its case-based planner. ROBBIE’s uses its model     of an index, selection of a high-level plan, adaptation
to perform detection, diagnosis, and repair of reason-      of the plan, and selection of reactive planlets to execute

                                           Fir Street
                                                                                                                              Introspective Task
                                                         Cedar Street
                                                                                                                                   Monitoring Module
                                                                                                                            1. Describe current process
                                                                                         Planning System for Domain Task
                                                                                                                            2. Build assertion case index
                                                                                                                            3. Retrieve relevant assertions
                                                                                                                            4. Apply assertions
                                                                                                                            5. If nofailures, stop
                                          Apple Street
                                                                                                                            6. Else move to Diagnosis
                                                                                                                                                                       Index Creation
 Elm Street                  Oak Street                                  Date Street
                                                                                                                                  Diagnosis Module
                                                                                                                           Repeat with assertions until repair found    Retriever
                                                                                                                              1. Select a link to follow
                                                                                                                              2. Build assertion index from link
                                                                                                                              3. Retrieve assertion
              Birch Street                                                                                                   4. Apply assertion
                                                                                                                             5. Add new links to collection            Case Memory
                                                         Cherry Street                                                                Repair Module
                                                                                                                             1. Select repair strategy
                                                                                                                             2. Implement repair
                                          Maple Street
                                                                                       Figure 3: The introspective task architecture of RILS:
              Figure 2: A sample of RILS’ domain                                       monitoring applies only to domain-level reasoning; diag-
                                                                                       nosis and repair apply to both domain and introspective
                                                                                       modules.
its goals. Learning occurs at the domain level through
the storage of new high-level plans once they have been
successfully executed, and through the addition of index                               RILS’ Introspective Task
creation rules which are learned through introspective                                 The goal of the introspective reasoning system is to de-
reasoning. The introspective reasoner recognizes and re-                               tect reasoning failures in all portions of the system itself
pairs those times when the plan case retrieval retrieves                               and, where possible, to correct the system’s processing
a suboptimal match to a given situation.                                               to avoid repeating the reasoning failure in the future.
   The following example demonstrates how RILS’ oper-                                  A “reasoning failure” is any situation which is not pre-
ates at the domain level, and how introspective learning                               dicted by the system itself, whether it is a failure or a
occurs to the domain reasoning. Suppose that RILS has                                  success in terms of the domain task. For example, an
as a new goal to move from the corner of Maple and Elm                                 unanticipated opportunity to achieve a goal is as much
Streets to the corner of Cherry and Maple Streets. It has                              of a reasoning failure as a failure to achieve a goal.
in its case memory two potential matches to this prob-                                    In order to reason about its own reasoning, RILS
lem: a plan from the corner of Maple and Elm to the                                    has a model of its ideal reasoning behavior. Figure 1,
corner of Birch and Oak, and a plan from the corner of                                 which shows RILS’ domain reasoning, also represents ab-
Apple and Elm to the corner of Apple and Oak. Without                                  stractly one portion of the introspective model. Figure 3
any learned indexing rules, RILS prefers the first plan to                             shows RILS’ introspective reasoning, represents the rest
the second one, because it shares the same starting lo-                                of its introspective model, as well. For each component
cation as its current problem. RILS adapts the selected                                of the reasoning process, RILS has a collection of “asser-
plan and successfully executes it to arrive at its goal.                               tions” at multiple levels of abstraction which describe in
   The process of executing the plan also streamlines it,                              detail RILS’ expectations about its own performance.
so that the plan RILS stores back into its case memory                                    RILS actively monitors each step in the domain rea-
involves merely turning east and moving along Maple to                                 soning to verify that the actual behavior corresponds to
Cherry Street. The storage of new plan cases is the most                               its model. When an assertion fails to be true of the
basic level of learning in RILS.                                                       system’s actual behavior, RILS suspends the lower-level
   The introspective reasoning system monitors the                                     reasoning task and takes over, attempting to diagnose
domain-level reasoning process, and detects a reasoning                                and repair the detected failure. The diagnosis module
failure: the plan being stored into memory is more simi-                               searches through its model, examining those assertions
lar to an unretrieved case (from Apple and Elm to Apple                                which are causally related to the detected failure, until it
and Oak) than to the retrieved one. This triggers intro-                               finds a related assertion which has a repair recommended
spective reasoning to diagnose and repair the domain                                   for it. Once a repair is performed, control returns to the
level reasoning. The ultimate repair is to add an in-                                  planning process.
dexing rule to detect and prefer case matches where the                                   While RILS may actively monitor its underlying rea-
general direction of movement is the same (i.e., “move                                 soning task, it cannot actively monitor its introspective
straight east”). We discuss the introspective task in                                  reasoning process. To do so would lead immediately
more detail in the next section.                                                       to an infinite reflective tower: RILS would monitor1 its

monitoring, then have to monitor2 the monitoring1 , and       (diagnose-spec2
                                                                   (assertion diagnosis specific 2 during)
so forth. Instead, RILS waits for “impasses” in its in-            (and (contains-part assert-case links)
trospective process: places where the reasoning process                  (member-of-structure
cannot continue, including unexpected catastrophic fail-                      (part-value assert-case links)
ures at the domain task level. If RILS discovers explicit                     checked-assertions))
                                                                   (variables assert-case checked-assertions)
evidence that the introspective reasoning process itself is        (links (abstr (diagnosis general 2))
flawed, it suspends the introspective process and reflec-                  (prev (diagnosis specific 1))
tively applies its diagnosis and repair processes to the                   (next (diagnosis specific 3)))
introspective task. These impasses are detailed in the             (repair)
next section.                                                      (statistics (uses 12)
                                                                                 (failures 0)))
   It seems intuitive that RILS should actively monitor
its domain-level reasoning and passively monitor its in-
trospective reasoning. Route planning and execution in-       Figure 4: An assertion case for the diagnosis component:
teract with a highly complex, poorly understood world,        “Every assertion retrieved during diagnosis will have a
where reasoning failures are common. RILS’ under-             link to one already under consideration”
standing of the state of the world at any time is lim-
ited. On the other hand, the introspective reasoner has
a much more restricted domain: the reasoning of the           Birch and Elm Streets to the corner of Birch and Oak.
system itself, and must be assumed to be more reliable.       It should apply the new indexing rule, but fails to find
   Each component of RILS’ introspective reasoning is         it. It therefore retrieves an inappropriate case in exactly
implemented using the same case memory and case re-           the same manner as described above. When the domain-
trieval mechanisms as are used in the planning task. The      level reasoning failure is discovered and diagnosed, RILS
introspective model, rather than being a monolithic col-      notices that this is exactly the same error as it suppos-
lection of assertions, is represented by “assertion” cases    edly corrected earlier. This is the evidence RILS needs in
stored separately in the case memory. When monitor-           order to invoke reflective introspection. It will suspend
ing the planner’s reasoning, RILS constructs an index         the introspective task, and apply the diagnosis and re-
representing the current point in the reasoning process,      pair modules to the introspective task itself.
and uses it to retrieve those assertion cases which are          Diagnosing and repairing this type of introspective
applicable to that point. When diagnosing a reasoning         reasoning failure is difficult, because of the long time
failure, RILS retrieves cases based on causal links which     lag between the actual failure and its detection. RILS
are stored in each assertion case. RILS’ repair module        keeps a history of its past reasoning decisions in order to
retrieves and applies repair plans from the case memory.      be able to diagnose an unbounded distance into its past
                                                              reasoning. At present this history is used to attempt
   Assertion cases must contain sufficient information to
                                                              a diagnosis on introspective reasoning failures: repair-
retrieve them when needed. Consider the sample as-
                                                              ing such failures is still work in progress. In the next
sertion case show in figure 4: the assertion case says
                                                              section we classify the kinds of impasse situations and
that the diagnosis module will only consider assertions
                                                              reasoning failures RILS uses to determine opportunities
causally relevant to the current problem. Each assertion
                                                              for reflective introspection.
case contains an assertion (and information to help apply
it), links to other causally-related assertions, applicable
repair strategies, and statistics on the assertion’s use and
                                                                  Reflective reasoning failures in RILS
success. Assertion cases are retrieved to support mon-        RILS responds reflectively only to explicit failures which
itoring and diagnosis of reasoning failures. As part of       indicate a flaw in the introspective reasoner. Because
the ROBBIE process, a general vocabulary was devel-           each module reuses CBR for its reasoning, the sorts of
oped which describes a wide range of assertions about         failures RILS must look for are similar for each mod-
reasoning processes: the generality of this vocabulary is     ule. The underlying cause of each failure type differs
demonstrated by the ease with which the introspective         depending on the module in question: we will examine
model was transformed to include a reflective compo-          each module in turn below. The basic categories of fail-
nent.                                                         ures are:
   We illustrate the reflective aspect of RILS with the fol-
                                                             1. Case memory lacks a required case;
lowing example, extending the example in the previous
section. Suppose that RILS experiences the reasoning         2. RILS fails to retrieve a relevant case;
failure described above: it selects an inappropriate case,
diagnoses the failure, and learns a new indexing rule to     3. RILS retrieves an irrelevant case; and
avoid the faulty selection in the future. All this requires
introspection only about the planner. RILS performs re-      4. RILS improperly applies a retrieved case.
flective introspection when the introspective reasoner it-
self is faulty. In this case, suppose that the repair module     Currently, RILS detects these reasoning failures and
incorrectly instantiated the new indexing rule, so that it    attempts to reflectively introspect about them. It does
will not be retrieved when it is applicable. Some time        not yet repair its introspective process, though work on
in the future, RILS plans a route from the corner of          that aspect is underway.

The Monitoring Module                                        each possibility.
The monitoring process examines only the route planner.         A missing assertion case is just as much of a problem
It retrieves those assertions which are currently relevant   for diagnosis as for monitoring. RILS could distinguish
and checks that no assertion is violated.                    between diagnosis and monitoring by which module was
   If an assertion case is missing from the case memory,     most recently in use, but would have just as much diffi-
that implies that the introspective model is incomplete,     culty recognizing the lack and determining a repair.
and hence inaccurate. This is a troubling failure, because      Failing to retrieve a relevant case for the diagnosis
RILS alters its reasoning processes based on the assump-     module could be due to two different failures. Like the
tion that its introspective model captures the ideal be-     monitoring module, diagnosis could miss a case due to in-
havior of the system. If a case is missing, then it is       dexing problems. Because diagnosis is performing highly
possible that RILS would alter itself incorrectly. This is   targeted retrievals, however, this is a problem likely to
not a failure type that we anticipate RILS handling in       be discovered as it happens. Alternatively, if assertion A
any deep manner: It might be able to conjecture that a       should contain a link to a causally related assertion B,
case is missing and then let a human user/programmer         but lacks that link, then B could be overlooked. This
assist in correcting the situation.                          problem must be detected by examining the cases in
   Failing to retrieve a relevant case is an easier problem  memory and their usage statistics. Retrieving an irrele-
to detect, though detection may be delayed some period       vant case is, again, easy to detect.
from the occurrence of the failure. A failure to retrieve       Circumstances that indicate a problem with the diag-
reflects some flaw in the index of the assertion case, or    nosis module include times when the diagnosis process
a flawing the index creation and retrieval mechanism.        fails to find any applicable repair. Alternatively, the di-
RILS can examine its case memory for cases that are          agnosis module may attempt to evaluate an assertion
referred to by other assertion cases in memory but that      whose value depends on one that was overlooked or mis-
have not been retrieved along with them. RILS keeps          applied, and may be unable to complete its evaluation.
statistics on the application of assertion cases to help
with this analysis. Correcting this failure requires the     The Repair Module
alteration of the indexing and retrieval methods for as-     The repair component retrieves and uses repair cases
sertion cases; we expect RILS to incorporate this repair     which describe how to change the system to correct a
in the future.                                               diagnosed reasoning failure.
   Because the monitoring module knows the context of           A missing repair case is, as for assertion cases, difficult
the planner at a given moment, recognizing an irrelevant     to detect, unless a repair is referred to in an assertion
assertion case is easy to detect on the spot: one case in    case and does not exist in the case memory.
which reflection can occur at the moment of the reason-
                                                                Failing to retrieve a relevant repair or retrieving an
ing failure. As before, this indicates either a flaw in the
                                                             irrelevant one may be detected immediately, as the repair
index of the particular case retrieved, which is easy to
                                                             module performs very targeted case retrieval. It would
check and correct, or a flaw in how the system creates
                                                             be repaired, as above, by either altering the indexing
indices and retrieves assertion cases. RILS can alter the
                                                             of the repair case, or altering the index and retrieval
indexing rules for plan cases; we should be able to extend
                                                             methods of the system.
this to altering the indexing of assertion cases as well.
                                                                Misapplying a repair strategy is a difficult failure to
   A misapplication of a retrieved case could be detected
                                                             detect. A repair could be executed, and might not cor-
if the lack of it leads to an unexpected catastrophic fail-
                                                             rect the experienced failure. As in the example in the
ure of some sort. RILS examines catastrophic failures at
                                                             previous section, RILS may detect this type of failure if it
the route planning level to determine if the monitoring
                                                             faces a similar situation again and generates an identical
process failed to detect a problem before the catastrophic
                                                             repair.
failure occurred, and considers the possibility that an as-
sertion was misapplied.
                                                                                   Conclusions
The Diagnosis Module                                         RILS demonstrates the power of case-based reasoning to
The diagnosis module retrieves assertion cases and eval-     serve as the central reasoning method of a system per-
uates them in much the same way as the monitoring            forming a wide range of reasoning tasks. By having one
module. Therefore, many of the comments made about           approach to reasoning, RILS has a fairly simple, power-
monitoring also apply to diagnosis. The main difference      ful model of its reasoning processes. It uses that model
is in how the diagnosis module chooses which cases to        to introspect about its reasoning process: learning from
retrieve: it starts with an assertion case which is known    failures of its domain-level reasoning, detecting opportu-
to be a failure, and then performs a heuristic-guided        nities to reflectively introspect and, eventually, learn by
breadth-first search through those assertions which are      improving its introspective reasoning processes.
causally related to the detected failure. It uses the causal    A system that combines task reasoning with a reflec-
links each assertion contains.                               tive introspection capability should be able to respond
   For reflective diagnosis, it may be initially unclear     with flexibility to a complex environment, by re-tooling
which assertion has failed, RILS creates a set of potential  its knowledge and processes at all levels of abstraction.
failed assertions and searches in parallel starting from     This seems to be a talent which humans possess, as we

improve our reasoning strategies with experience. RILS       Rosenbloom, P., Laird, J., & Newell, A. (1993). Meta
provides one possible abstract model of this process.             Levels in Soar, Vol. I, chap. 26. The MIT Press.
   Reflection permits a system to adapt itself to its sur-
roundings, but poses a hazard if left unchecked. We have     Stroulia, E. & Goel, A. (1995). Functional representa-
demonstrated here a “failure-driven” approach to con-             tion and reasoning in reflective systems. Applied
trolling reflection: only when clear evidence exists that         Artificial Intelligence: An International Journal,
the introspective reasoning is flawed will RILS choose to         Special Issue on Functional Reasoning, 9 (1), 101–
reflect. Our future work on RILS will complete the re-            124.
flective skills it has by giving it the tools to repair, not
just diagnose, its introspective reasoning processes,
                        References
Arcos, J. & Plaza, E. (1993). A reflective architecture
       for integrated memory-based learning and reason-
       ing. In Wess, S., Altoff, K., & Richter, M. (Eds.),
       Topics in Case-Based Reasoning. Springer-Verlag,
       Kaiserslautern, Germany.
Chi, M. & Glaser, R. (1980). The measurement of ex-
       pertise: a development of knowledge and skill as
       a basis for assessing achievement. In Baker, E. &
       Quellmalz, E. (Eds.), Educational testing and eval-
       uation: Design, analysis and policy. Sage Publica-
       tions, Beverly Hill, CA.
Cox, M. (1996). Introspective multistrategy learning:
       Constructing a learning strategy under reasoning
       failure. Ph.D. thesis, College of Computing, Geor-
       gia Institute of Technology. Technical Report GIT-
       CC-96-06.
Flavell, J., Friedrichs, A., & Hoyt, J. (1970). Develpmen-
       tal changes in memorization processes. Cognitive
       Psychology, 1, 324–340.
Fox, S. & Leake, D. (1995). An introspective reasoning
       method for index refinement. In Proceedings of
       14th international Joint Conference on Artificial
       Intelligence. IJCAI.
Freed, M. & Collins, G. (1994). Adapting routines to
       improve task coordination. In Proceedings of the
       1994 Conference on AI Planning Systems, pp. 255–
       259.
Ibrahim, M. (1992). Reflection in object-oriented pro-
       gramming. International Journal on Artificial In-
       telligence Tools, 1 (1), 117–136.
Kreutzer, M., Leonard, M., & Flavell, J. (1975). An in-
       terview study of children’s knowledge about mem-
       ory. Monographs of the Society for Research in
       Child Development, 40. (1, Serial No. 159).
Kruger, J. & Dunning, D. (1999). Unskilled and unaware
       of it: how difficulties in recognizing one’s own in-
       competence lead to inflated self-assessments. Jour-
       nal of Personality and Social Psychology, 77 (6).
Oehlmann, R., Edwards, P., & Sleeman, D. (1994).
       Changing the viewpoint: re-indexing by introspec-
       tive questioning. In Proceedings of the Sixteenth
       Annual Conference of the Cognitive Science Soci-
       ety, pp. 675–680. Lawrence Erlbaum Associates.

