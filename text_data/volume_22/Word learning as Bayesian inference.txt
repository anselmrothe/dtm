UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Word learning as Bayesian inference
Permalink
https://escholarship.org/uc/item/8b67v4q2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Authors
Tenenbaum, Joshua B.
Xu, Fei
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Word learning as Bayesian inference
                        Joshua B. Tenenbaum                                       Fei Xu
                      Department of Psychology                        Department of Psychology
                          Stanford University                           Northeastern University
                      jbt@psych.stanford.edu                                  fxu@neu.edu
                         Abstract                           word. Having heard Sox called \cat" as well as Rover
                                                            called \dog", we can rule out any subset including both
   We apply a computational theory of concept learning      Rover and Sox (e.g. mammals, animals) as the exten-
   based on Bayesian inference (Tenenbaum, 1999) to the
   problem of learning words from examples. The theory      sion of \dog". But some uncertainty in how far to gen-
   provides a framework for understanding how people can    eralize always remains: does \dog" refer to all dogs, all
   generalize meaningfully from just one or a few positive  labradors, all black labradors, or just Rover himself?
   examples of a novel word, without assuming that words       Inspired by the work of Rosch et al. (1976), Markman
   are mutually exclusive or map only onto basic-level cat- (1989) suggested the even stronger assumption that a
   egories. We also describe experiments with adults and
   children designed to evaluate the model.                 new word maps not to just any level in a taxonomy,
                                                            but to an intermediate or basic level. Basic-level cate-
                                                            gories are intermediate nodes in a taxonomic tree that
                      Introduction                          maximize many di erent indices of category utility and
Learning even the simplest names for object categories      are widely recognized throughout a culture (Rosch et
presents a di√Ücult inference problem (Quine, 1960).         al., 1976). Whether children really have a bias to map
Given a typical example of the word \dog", e.g. Rover,      words onto basic-level kinds is controversial (Callanan et
a black labrador, the possible inferences a learner might   al., 1994), but it is certainly a plausible proposal. More-
make about the extension of \dog" are endless: all (and     over, the basic-level constraint, together with the taxo-
only) dogs, all mammals, all animals, all labradors, all    nomic constraint and mutual exclusivity, actually solves
black labradors, all black things, all running things,      the induction problem, because each object belongs to
this individual animal (Rover), all dogs plus the Lone      one and only one basic-level category. However, this so-
Ranger's horse, and so on. Yet, even children under ve      lution only works for basic-level words like \dog", and
can often infer the approximate extension of words like     in fact is counterproductive for all the words that do
\dog" given only a few relevant examples of how they        not map to basic level categories. How do we learn all
can be used, and no systematic evidence of how words        the other words we know at superordinate or subordinate
are not to be used (Carey, 1978; Markman, 1989; Regier,     levels? Some experimenters have found that seeing more
1996). How do they do it?                                   than one labeled example of a word may help childern
   One in uential proposal has been that people come        learn superordinates (Callanan, 1989), but there have
to the task of word learning equipped with strong prior     been no systematic theoretical explanations for these
knowledge about the kinds of viable word meanings             ndings. Regier (1996) describes a neural network learn-
(Carey, 1978; Clark, 1987; Markman, 1989), allowing         ing algorithm capable of learning overlapping words from
them to rule out a priori the many logically possible       positive evidence only, using a weakened form of mutual
but unnatural extensions of a word. For learning nouns,     exclusivity that is gradually strengthed over thousands
one of the most basic constraints is the taxonomic as-      of learning trials. However, this model does not address
sumption, that new words refer to taxonomic classes,        the phenomenon of \fast mapping" (Carey, 1978) { the
typically in a tree-structured hierarchy of natural kind    meaningful generalizations that people make from just
categories (Markman, 1989). Given the one example of        one or a few examples of a novel word { that is arguably
\dog" above, the taxonomic assumption would rule out        the most remarkable feat of human word learning.
the subsets of all black things, all running things, and       To sum up the problem: taking the taxonomic, mu-
all dogs plus the Lone Ranger's horse, but would still      tual exclusivity, and basic-level assumptions literally as
leave a great deal of ambiguity as to the appropriate       hard-and-fast constraints would solve the problem of in-
level of generalization in the taxonomic tree that in-      duction for one important class of words, but at the
cludes labradors, dogs, mammals, animals, and so on.        cost of making the rest of language unlearnable. Admit-
Other, stronger constraints try to reduce this ambiguity,   ting some kind of softer combination of these constraints
at the cost of dramatically oversimplifying the possible    seems like a reasonable alternative, but no one has of-
meanings of words. Under the mutual exclusivity con-        fered a precise account of how these biases should inter-
straint, the learner assumes that there is only one word    act with each other and with the observed examples of
that applies to each object (Markman, 1989). This helps     a novel word, in order to support meaningful generaliza-
to circumvent the problem of learning without negative      tions from just one or a few examples. This paper takes
evidence, by allowing the inference that each positive ex-  some rst steps in that direction, by describing one possi-
ample of one word is a negative example of every other      ble learning theory that is up to the task of fast mapping

and applying it to model a simple experimental situa-       example sets.
tion. Our experiments use real, everyday objects with          The test set consisted of objects matching the labeled
an intuitively clear taxonomic organization, but they re-   examples at all levels: subordinate (e.g., other dalma-
quire subjects to learn multiple words at di erent levels   tians), basic (non-dalmatian dogs), and superordinate
of generality which violate the strict versions of mutual   (non-dog animals), as well as many non-matching ob-
exclusivity and the basic-level constraint. Our theory      jects (vegetables and vehicles). In particular, the test set
is formulated in terms of Bayesian inference, which al-     always contained exactly 2 subordinate matches (e.g. 2
lows learners to combine probabilistic versions of a priori other dalmatians), 2 basic-level matches (labrador, hush-
constraints with the statistical structure of the examples  puppy), 4 superordinate matches (cat, bear, seal, bee),
they observe, in order to acquire the sort of rich, multi-  and 16 nonmatching objects.
leveled vocabulary typical of natural languages.
                                                            Procedure.        Stimuli were presented on a computer
   The paper is organized as follows. Section 2 describes   monitor at normal viewing distance. Participants were
our basic word learning experiment and presents data        told that they were helping a puppet who speaks a di er-
from adult participants. Section 3 describes the Bayesian   ent language to pick out the objects he needs. Following
learning theory and its application to modeling the data    a brief familiarization in which participants saw all 24
in Section 2. Section 4 concludes and discusses some pre-   of the test objects one at a time, the experiment began
liminary data from a parallel experiment with children.     with the word learning phase. This phase consisted of
       Experiments with adult learners                      32 trials in which learners were shown pictures of one or
                                                            more labeled examples of a novel monosyllabic word (e.g.
Our initial experiments were conducted with adult learn-    \blick") and were asked to pick out the other \blicks"
ers, although the studies have been designed to carry       from the test set of 24 objects by clicking on-screen with
over to preschoolers with minimal modi cation. The ex-      the mouse. On the rst three trials, participants saw
periment consists of two phases. In the word learning       only one example of each new word, while on the next
phase, participants are given one or more examples of       nine trials they saw three examples of each word.1 Sub-
words in a novel language and asked to pick out the other   ject to these constraints, the 12 example sets appeared
instances that each word applied to, from a large set of    in a pseudo-random order that counterbalanced the or-
test objects. In the similarity judgment phase, partici-    der of example content (animal, vegetable, vehicle) and
pants judge the similarity of pairs of the same objects     example speci city (subordinate, basic, superordinate)
used in the rst phase. The average similarity judg-         across participants. The frequencies with which each
ments are then submitted to a hierarchical clustering al-   test objects was selected by participants when asked to
gorithm, in order to reconstruct a representation of the    \pick out the other blicks" were the primary data.
taxonomic hypothesis space that people were drawing on         In the similarity judgment phase that followed these
in the word learning phase.                                 trials, participants were shown pairs of objects from the
                                                            main study and asked to rate their similarity on a scale
Participants.     Participants were 25 students from        of 1 to 9. They were instructed to base their ratings on
MIT and Stanford University, participating for pay or       the same aspects of the objects that were important to
partial course credit. All participants carried out the     them in making their choices during the main experi-
word learning task and the rst nine also participated in    ment. Similarity judgments were collected for all but six
the similarity judgment phase that followed.                of the 45 objects used in the word learning experiment;
Materials.     The stimulus set consisted of digital color  these six were practically identical to six of the included
photographs of 45 real objects. This set was structured     objects and were omitted to save time. Each partici-
hierarchically to mirror, in limited form, the structure    pant in this phase rated the similarity of all pairs of ob-
of natural object taxonomies in the world. Objects          jects within the same superordinate class and one-third
were distributed across three di erent superordinate cat-   of all possible cross-superordinate pairs chosen pseudo-
egories (animals, vegetables, vehicles) and within those,   randomly, for a total of 403 judgments per participant
many di erent basic-level and subordinate categories.       (executed in random order). Similarity ratings for all
The 45 stimuli were divided into a test set of 24 stimuli   nine participants were averaged together for analysis.
and a training set of 21 stimuli.                           Results and discussion.             The results of the word
   The training stimuli were grouped into 12 nondisjoint    learning phase are depicted in Figure 1. Figure 1a
sets of examples. The rst three sets contained one ex-      presents data collapsed across all category types (ani-
ample each: a dalmatian, a green pepper, or a yellow        mals, vehicles, and vegetables), while Figures 1b-d show
truck, representing the three main branches of the mi-      the data for each category individually. The four plots
croworld's taxonomy. The remaining nine sets contained      in each row correspond to the four di erent kinds of ex-
three examples each: one of the three objects from the      ample sets (one, three subordinate, three basic, three su-
single-example sets (the dalmatian, green pepper, or yel-   perordinate), and the four bars in each plot correspond
low truck), along with two new objects that matched the     to test objects matching the example(s) at each of four
  rst at either the subordinate, basic, or superordinate    di erent levels of speci city (subordinate, basic, super-
level of the taxonomy. For example, the dalmatian was       ordinate, nonmatching). Bar height (between 0 and 1)
paired with two other dalmatians, with two other dogs
(a mutt and a terrier), and with two other animals (a           1
                                                                  The last 20 trials used di erent stimulus combinations to
pig and a toucan) to form three of these nine multiple-     explore a di erent question and will not be analyzed here.

              (a) Generalization judgments (averaged over all stimulus categories)           (b) Animals
                                                                                                 1             1     1        1
                                                                                              0.5             0.5   0.5     0.5
                                                                                             (c) Vehicles
                                                                                                 1             1     1        1
          Training                                                                            0.5             0.5   0.5     0.5
          examples:          1           3 subordinate     3 basic   3 superordinate
                         1                 1              1           1
                                 *                                                           (d) Vegetables
                       0.5               0.5             0.5         0.5
                                     *           **              *               *
                                                                                                 1             1     1        1
                                                                                              0.5             0.5   0.5     0.5
                          su
        Test object         bo
                        su ba rd.
        match level:   no e sic
                          p
                         nm ror            ...             ...             ...
                            at d.
                              ch
Figure 1: Generalization judgments averaged across categories (a) and broken down into individual categories (b-d).
represents the average probabilities with which partici-                               categories, and this bias could exist over and above any
pants chose to generalize to the corresponding kind of                                 preference children or adults might have to map words
test object. In Figure 1a, asterisks denote probabilities                              for unfamiliar objects onto basic-level categories. Sec-
that are signi cantly lower than the probabilities to the                              ond, we found that giving participants more than one
immediate left (p < :05, one-tailed paired t-tests (df =                               example had a dramatic e ect on how they generalized
24) with Bonferonni correction for 12 comparisons), in-                                to new objects, causing them to select all objects at the
dicating signi cant gradients of generalization.                                       most speci c taxonomic level spanned by the examples
   The rst plots in each row represent trials in which                                 and no objects beyond that level. This nding is consis-
only a single labeled example was provided. Across all                                 tent with developmental studies in which children given
three major categories, participants generalized almost                                two examples from di erent basic-level categories were
always (97% of trials) to test objects matching the exam-                              signi cantly more likely to generalize to other objects
ple at the subordinate level (e.g., other dalmatians), of-                             of the same superordinate category, relative to children
ten but not always (76% of trials) to basic-level matches                              given only a single example (Callanan, 1989).
(e.g., non-dalmatian dogs), rarely (9% of trials) to su-                                  Our results also di er from the developmental litera-
perordinate matches (e.g., non-dog animals), and prac-                                 ture in important ways. First, we found a qualitative dif-
tically never (< 1% of trials) to nonmatching test objects                             ference in generalization from one labeled example ver-
(e.g., vegetables or vehicles). Thus, generalization from                              sus several labeled examples. While generalization from
one example appears to fall o according to a gradient                                  a single example decreased according to a gradient of
of exemplar similarity, with a threshold located around                                similarity to the test objects, generalization from three
the basic level.                                                                       examples followed more of an all-or-none, threshold pat-
   A di erent pattern emerges in the last three plots of                               tern. Second, we found that people could use multiple
each row, representing trials on which three labeled ex-                               examples to infer how far to generalize a new word at
amples were provided. Instead of a gradient of general-                                any level of speci city in a multi-level taxonomy of ob-
ization decreasing with similarity to the example, there                               ject kinds, not just at the basic or superordinate levels.
appears in most cases to be a sharp transition from near-                                 Figure 2 shows the results of a hierarchical cluster-
perfect generalization to near-zero generalization. The                                ing (\average linkage") analysis applied to participants'
cut-o occurs at the level of the most speci c category                                 similarity judgments from the second phase of the exper-
containing all three labeled examples. That is, given                                  iment. Each leaf of the tree corresponds to one object
three dalmatians as examples of \blicks", participants                                 used in the word learning phase. (For clarity, only ob-
generalized to all and only the other dalmatians; given                                jects in the training set are shown.) Each internal node
three dogs, to all and only the dogs, and so on.                                       corresponds to a cluster of stimuli that are on average
   Two aspects of these results are consistent with the                                more similar to each other than to other, nearby stimuli.
existing literature on word learning in children. First,                               The height of each node represents the average pairwise
we found what appears to be a basic-level bias in gen-                                 dissimilarity of the objects in the corresponding cluster,
eralizing from one example. This interpretation is com-                                with lower height indicating greater average similarity.
plicated by the fact that our participants already knew                                The length of the branch above each node measures how
a very familiar word in English for each of the basic-                                 much more similar on average are that cluster's members
level categories used in our study, \pepper", \truck",                                 to each other than to objects in the next nearest cluster,
and \dog". The tacit knowledge that objects are almost                                 i.e., how distinctive that cluster is.
always named spontaneously at the basic level (Rosch et                                   This cluster tree captures in an objective fashion much
al., 1976) may have increased participants' propensity                                 of people's intuitive knowledge about this domain of ob-
to map words in a new language onto these basic-level                                  jects. Each of the main classes underlying the choice of

                                         37                                                            Cluster height Prior probability   Likelihood
                                                                                                                       [~branch length] [~1/(height+Œµ)]
                                                                       36
                                                                                                                   1
                                                                                             34
                                                                                                                  .582                      1.58
                                                21                           33                           35
                                                   20
                                                                                 32
                                                      19
                                                                                    31 30
                     9       8                                                                                    .417                      2.14
                                   7
                                                         18
                                       6                     17
                                            23
             11
                                                                16                        29
                  10                                                                          27
                                                                                                                  .236 .417‚àí.236 = .181     3.50
                                               22                   14
                                                            15
                                                                                       28
                                                                                                 26               .208 .236‚àí.208 = .028     3.88
                           4
                               3
                        5
                                 2                               13       12                        25
                                     1                                                        24                  .021                      14.08
                                                                                                                   0
   Figure 2: Hierarchical clustering of similarity judgments yields a taxonomic hypothesis space for word learning.
stimuli (vegetable, vehicle, animal, pepper, truck, dog,                        rior re ects the learner's degree of belief that h is in fact
green pepper, yellow truck, and dalmatian) corresponds                          the true extension of C , given a rational combination
to a node in the tree (marked by a circled number).                             of her observations X with her relevant prior knowledge
Moreover, most of these clusters are highly distinctive,                        about possible word meanings.
i.e., well-separated from other clusters by long branches,                          The hypothesis space. Tenenbaum (1999) intro-
as one would expect for the targets of kind terms. Other                        duced this Bayesian framework for learning simple con-
naturally \nameable" nodes include cluster #23, con-                            cepts with hypotheses that could be represented as rect-
taining the tractor, the bulldozer, and the crane, but no                       angular regions in a multidimensional continuous fea-
other vehicles, or cluster #33, containing all and only                         ture space. Here we adapt that framework to the task
the mammals. Still other clusters re ect more subtle                            of word learning, assuming that the hypotheses can be
similarities. For example, cluster #18 includes all of the                      represented as clusters in a tree-structured taxonomy
trucks and also the yellow schoolbus. While the school-                         (e.g., Figure 2). Such a hypothesis space is clearly
bus does not fall into the class of trucks, it intuitively                      not appropriate for learning all kinds of words, but it
comes much closer than any other non-truck object in                            may be a good rst approximation for learning com-
the set. This intuitive taxonomy of objects will form                           mon nouns under the taxonomic assumption. Assum-
the basis for the formal Bayesian model of fast mapping                         ing a tree-structured hypothesis space makes the model
described next.                                                                 more tractable but is by no means a requirement of the
                                                                                Bayesian framework. In principle, any subset of objects
                    A Bayesian model                                            could be a hypothesis under consideration.
We rst describe the general approach, saving the details                            Priors and likelihoods. Both priors and likelihoods
for below. We assume that the learner has access to a                           can be de ned in terms of the geometry of the cluster
hypothesis space H of possible concepts and a proba-                            tree. The crucial geometrical feature is the height of
bilistic model relating hypotheses h 2 H to data X . Let                        node h in the tree, which is scaled to lie between 0 (for
X = fx(1) ; : : : ; x(n) g denote a set of n observed examples                  the lowest node) and 1 (for the highest node) and mea-
of a novel word C . Each hypothesis h can be thought of                         sures the average dissimilarity of objects within h.
as a pointer to some subset of objects in the world that                            We take the prior p(h) to be proportional to the
is a candidate extension for C . The Bayesian learner                           branch length separating node h from its parent:
evaluates these hypotheses by computing their posterior
probabilities p(hjX ), proportional to a product of prior                                    p(h)   / height(parent(h))                height(h):       (2)
probabilities p(h) and likelihoods p(X jh):                                     This captures the intuition that more distinctive clusters
                           j
                       p(h X )   / p(X jh)p(h)                         (1)      are a priori more likely to have distinguishing names.
                                                                                For example, in Figure 2, the class containing all and
The prior, along with the structure of the hypothe-                             only the dogs (#29) is highly distinctive, but the classes
sis space, embodies the learner's pre-existing (though                          immediately under it (#27) or above it (#30) are not
not necessarily innate) biases, such as the taxonomic or                        nearly as distinctive; accordingly, #29 receives a much
basic-level assumptions. The likelihood captures the sta-                       higher prior than #27 (proportional to .181 vs. .028).
tistical information inherent in the examples. The poste-                           The likelihood function comes from assuming that

the observed positive examples are sampled at random        too much generalization to superordinate matches given
(and independently) from the true concept to be learned.    three basic-level examples. All of these errors would
Imagine that each hypothesis consisted of a nite set of     be explained if participants in the word learning task
K objects. Then the likelihood of picking any one ob-       had an additional basic-level bias that is not captured
ject at random from a set of size K would be 1=K , and      in their similarity judgments. Figure 3b shows the t
for n objects (sampled with replacement), 1=K n . Hence     of the Bayesian model after adding a bias to the prior
set size is crucial for de ning likelihood. While we do     that favors the three basic-level hypotheses. With this
not have access to the \true" size of the set of all dogs   one free parameter, the model now provides an almost
in the world, or all vegetables, we do have access to a     perfect t to the average data (R2 = :98). Figures 3c
psychologically plausible proxy, in the average within-     and 3d illustrate respectively the complementary roles
cluster dissimilarity (as measured by cluster height in     played by the size principle (Equation 3) and hypothe-
Figure 2). Moving up in the tree, the average dissimilar-   sis averaging (Equation 4) in the Bayesian framework.
ity within clusters increases as they become larger. Thus   If instead of the size principle we weight all hypotheses
equating node height with approximate cluster size, we      strictly by their prior, Bayes reduces to a similarity-like
have for the likelihood                                     feature matching computation that is much more suited
                                         n                to the generalization gradients observed given one exam-
                                  1
                    j /
               p(X h)
                            height(h) + 
                                             ;          (3) ple than to the all-or-none patterns observed after three
                                                            examples (R2 = :74 overall). If instead of averaging
                                                            hypotheses we choose only the most likely one, Bayes es-
if xi 2 h for all i, and 0 otherwise. (We add a small       sentially reduces to nding the most speci c hypothesis
constant  > 0 to height(h) to keep the likelihood from     consistent with the examples. Here, that is a reasonable
going to in nity at the lowest nodes in the tree (with      strategy after several examples but far too conservative
height 0). The exact value of  is not critical; we found   given just one example (R2 = :78 overall). Similarity-
best results with  = 0:05.) Equation 3 embodies the size   based models of category learning that incorporate selec-
principle for scoring hypotheses: smaller hypotheses as-    tive attention to di erent stimulus attributes (Kruschke,
sign greater likelihood than do larger hypotheses to the    1992) could in principle accomodate these results, but
same data, and they assign exponentially greater like-      not without major modi cation. These models typically
lihood as the number of consistent examples increases.      rely on error-driven learning algorithms, which are not
This captures the intuition that given a dalmatian as       capable of learning from just one or a few positive exam-
the rst example of \blick", either all dalmatians or all    ples and no negative examples, and low-dimensional spa-
dogs seem to be fairly plausible hypotheses for the word's  tial representations of stimuli, which are not well-suited
extension (with a likelihood ratio of 14:08=3:50  4 in     to representing a broad taxonomy of object kinds.
favor of just the dalmatians). However, given three dal-
matians as the rst three examples of \blick", the word
seems much more likely to refer only to dalmatians than
                                                                  Conclusions and future directions
to all dogs (with a likelihood ratio now proportional to    Research on word learning has often pitted rule-based
(14:08=3:50)3  65 in favor of just the dalmatians).        accounts (Clark, 1973) against similarity-based accounts
   Generalization. Given these priors and likelihoods,      (Jones & Smith, 1993), or rationalist accounts (Bloom,
the posterior p(hjX ) follows directly from Bayes' rule     1998) versus empiricist accounts (Quine, 1960). In con-
(Equation 1). Finally, the learner must use p(hjX ) to      trast, our work suggests both a need and a means to
decide how to generalize the word C to new, unlabeled       move beyond some of these classic dichotomies, in order
objects. p(y 2 C jX ), the probability that some new        to explain how people learn a hierarchical vocabulary of
object y belongs to the extension of C given the obser-     words for object kinds given only a few random positive
vations X , can be computed by averaging the predictions    examples of each word's referents. Rather than nd-
of all hypotheses weighted by their posterior probabili-    ing signs of exclusively rule- or similarity-based learn-
ties p(hjX ):                                               ing, we found more of a transition, from graded gener-
                          X                                 alization after only one example had been observed to
          p(y 2 C jX ) =       p(y 2 C jh)p(hjX ):      (4) all-or-none generalization after three examples had been
                          h2H                               observed. While special cases of the Bayesian framework
                                                            corresponding to pure similarity or rule models could
To evaluate Equation 4, note that p(y 2 C jh) is simply     accomodate either extremes of this behavior, only the
1 if y 2 h, and 0 otherwise.                                full Bayesian model is capable of modeling the transi-
   Model results. Figure 3a compares p(y 2 C jX ) com-      tion from similarity-like to rule-like behavior observed on
puted from the Bayesian model with the average gener-       this task. The Bayesian framework also brings together
alization data from Figure 1a. The model achieves a rea-    theoretical constraints on possible word meanings, such
sonable quantitative t (R2 = :93) and also captures the     as the taxonomic and basic-level biases, with statistical
main qualitative features of the data: a similarity-like    principles more typically associated with the empiricist
gradient of generalization given one example, and more      tradition, such as the size principle and hypothesis aver-
all-or-none, rule-like generalization at the most speci c   aging. No one of these factors works without the others.
consistent level, given three examples. The main errors     Constraints provide su√Ücient structure in the learner's
seem to be too little generalization to basic-level matches hypothesis space and prior probabilities to enable rea-
given one example or three subordinate examples, and        sonable statistical inferences of word meaning from just

          Examples: 1         3 subordinate      3 basic     3 superordinate
           (a) Bayesian model                                                   (c) Pure similarity model (Bayes minus size principle)
                    1             1             1              1                       1              1           1             1
                  0.5           0.5           0.5           0.5                      0.5            0.5         0.5           0.5
           (b) Bayesian model (including basic‚àílevel bias in prior)             (d) Pure rule model (Bayes minus hypothesis averaging)
                    1            1             1              1                        1              1           1             1
                  0.5          0.5           0.5            0.5                      0.5            0.5         0.5           0.5
              Figure 3: Predictions of the basic Bayesian model and three variants for the data in Figure 1.
a few random positive examples.                                              early word learning { at least, not as distinct from the
   Still, the hardest questions of learning remain un-                       more general bias in favor of labeling distinctive clusters
solved. Where does the hypothesis space come from?                           that the Bayesian model assumes { but rather develops
Are constraints on the hypothesis space learned or in-                       later as the child gains experience about how words are
nate? In ongoing work, we are exploring how unsuper-                         typically used. This issue is one aspect of a broader ques-
vised learning algorithms might be used to bootstrap a                       tion: to what extent should di erences between child and
hypothesis space for supervised concept learning. For                        adult word learners be attributed to di erences in their
example, can clustering algorithms like the one we used                      hypothesis spaces, probability models (e.g., priors), or
to construct our taxonomic hypothesis space still be suc-                    learning algorithms? We hope to answer these questions
cessfull when applied to more primitive perceptual repre-                    as we conduct more extensive studies with child learners.
sentations of objects, instead of adult humans' similarity
judgments? Generalizations of the Bayesian framework                                                      References
also hold some promise as bootstrapping mechanisms,                          Bloom, P. (1998). Theories of word learning: Rational-
in virtue of their ability to propagate probabilistic in-                       ist alternatives to associationism. In Bhatia, T. K. and
                                                                                Ritchie, W. C. (eds.), Handbook of Language Acquisition.
formation from raw data up to increasingly higher levels                        Academic Press.
of abstraction. Perhaps we begin life with a hypothesis                      Carey, S. (1978). The child as word learner. In Halle, M.,
space of hypothesis spaces { each embodying di erent                            Bresnan, J., and Miller, G. A. (eds.), Linguistic Theory
possible constraints on word meanings { and grow into                           and Psychological Reality. MIT Press.
the most useful ones { those which consistently contain                      Callanan, M. A. (1989). Development of object categories
the best explanations of the word-to-world pairings we                          and inclusion relations: Preschoolers' hypotheses about
encounter { through the same mechansims of Bayesian                             word meanings. Developmental Psychology, 25(2):207{
inference used to learn any one novel word.                                     216.
                                                                             Callanan, M. A., Repp, A. M., McCarthy, M. G., and Latzke,
    Examples: 1
                                                                                M. A. (1994). Children's hypotheses about word meanings:
                        3 subordinate     3 basic    3 superordinate
                                                                                Is there a basic level constraint? Journal of Experimental
              1            1             1             1                        Child Psychology, 57:108{138.
            0.5          0.5           0.5          0.5                      Clark, E. V. (1973). What's in a word? On the child's
                                                                                acquisition of semantics in his rst language. In Moore,
                                                                                T. E. (ed.), Cognitive Development and the Acquisition of
         Figure 4: Data from child word learners.                               Language. Academic Press.
                                                                             Clark, E. V. (1987). The principle of contrast: A constraint
   We are also working to extend this line of research to                       on language acquisition. In MacWhinney, B. (ed.), The
                                                                                20th Annual Carnegie Symposium on Cognition. Erlbaum.
studies of child learners, and to studies of both adults                     Jones, S. S. and Smith, L. B. (1993). The place of perception
and children learning words for novel objects. Figure 4                         in children's concepts. Cognitive Development, 8:113{140.
shows some promising pilot data from a study with 4-                         Kruschke, J. K. (1992). ALCOVE: An exemplar-based con-
year-old children, using familiar objects in a design ap-                       nectionist model of category learning. Psychological Re-
proximately parallel to the above adult study. Like the                         view, 99:22{44.
adults, children given three examples of a novel word                        Markman, E. M. (1989). Categorization and Naming in Chil-
adapt their generalizations to the appropriate level of                         dren: Problems of Induction. MIT Press.
speci city, although their superordinate generalizations                     Quine, W. V. (1960). Word and Object. MIT Press.
are less consistent. When given just one example, chil-                      Regier, T. (1996). The Human Semantic Potential: Spatial
dren show a gradient of generalization much like the                            Language and Constrained Connectionism. MIT Press.
adults, but with signi cantly fewer responses at the basic                   Rosch, E., Mervis, C. B., Gray, W., Johnson, D., and Boyes-
level and above. If anything, children's overall patterns                       Braem, P. (1976a). Basic objects in natural categories.
of responses look more like the Bayesian model's pre-                           Cognitive Psychology, 8:382{439.
dictions without the added basic-level bias (Figure 3a)                      Tenenbaum, J. B. (1999). Bayesian modeling of human con-
than with that added bias (Figure 3b). Consistent with                          cept learning. In Kearns, M. J., Solla, S. A., and Cohn,
Callanan et al. (1994), this suggests that a strong basic-                      D. A. (eds.), Advances in Neural Information Processing
                                                                                Systems 11. MIT Press.
level bias may not be a fundamental building block of

