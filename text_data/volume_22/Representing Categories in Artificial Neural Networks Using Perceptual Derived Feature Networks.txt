UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Representing Categories in Artificial Neural Networks Using Perceptual Derived Feature
Networks
Permalink
https://escholarship.org/uc/item/60w3w1gm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 22(22)
Author
Branstrom, Robert B.
Publication Date
2000-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

  Representing Categories in Artificial Neural Networks Using Perceptually Derived
                                                         Feature Networks
                                  Robert B. Branstrom (branstrm@socrates.berkeley.edu)
                                              Department of Psychology; 3210 Tolman Hall
                                                           University of California
                                                            Berkeley, CA 94720
                                                                              What approach might be taken to model categories?
                             Abstract                                      The classical view can be represented by formal set
                                                                           theory. Modifications to this view have been made to
   How might categories be represented in artificial neural                accommodate the probabilistic view and the graded
   networks while satisfying biological constraints? This                  structure view. In the probabilistic view, something is in
   article proposes using feature networks, an architecture                the category if it has, say, eight of the necessary 10
   based on two types of neural organization in perceptual                 conditions (Medin & Smith, 1984). The graded structure
   systems, receptive fields and topographic representation.               view has been approximated by fuzzy set theory (Zadeh,
   Using these two organizing principles, category features                1965). However, these views were developed for their
   are represented in distributed networks that allow precise,             formal properties, not their biological realism, so they
   graded or probabilistic interpretations. Simulations are                don’t offer plausible mechanisms that might underlie
   illustrated that show these networks have characteristics
   consistent with human behaviors of assimilation, contrast,
                                                                           categorization processes.
   and chunking. A brief discussion and simulation show how                   An approach that steps closer to the biological
   these feature networks can be combined associatively to                 structures of the brain is connectionism. Loosely,
   form complex multiple-feature categories. Implications of               connectionist (or artificial neural network) models, assert
   the architecture for representation and the nature of symbol            that the brain is composed of many highly interconnected
   processing are discussed.                                               neurons, and that the processing power of the brain comes
                                                                           from these many connections. Network models of
                         Introduction                                      categorization typically represent categorical structure as
                                                                           a set of nodes representing characteristics (cf., Anderson,
Regardless of the nature of the representation (i.e., visual
                                                                           1995). The characteristic may be absent or present
image, verbal, etc.), categories are a foundational aspect
                                                                           (valued at 0 and 1, respectively). This vector of
of higher level cognition. The nature of categories
                                                                           characteristics can also have graded values between 0 and
remains a topic of considerable debate. The classical, or
                                                                           1. These values could represent either the probability or
Aristotelian, view is that characteristics or traits define
                                                                           degree of the characteristic being present.
categories: things which have those characteristics are in
                                                                              While these network models of categorization have
the category and those which do not are not. This is
                                                                           useful functional characteristics, it’s generally accepted
simplistic, because sometimes something is in a category
                                                                           that they still do not represent an approach that is close to
but does not have all necessary characteristics. For
                                                                           the brain’s actual organization. Among other things, real
example, a three-legged animal that chases cats and cars
                                                                           brains are expected to have more distributed
would still be classified as a dog, even if it doesn’t have
                                                                           representations for high level concepts. Anderson (1995,
the requisite four legs. Two approaches, both dealing with
                                                                           p. 345-6) proposed a number of principles to guide the
uncertain information, have evolved to address this
                                                                           development of "natural data representations," based on
problem. The first approach is probabilistic, asserting that
                                                                           what is known about vertebrate nervous systems. These
something may be in a category if its characteristics are
                                                                           are worth summarizing here:
likely, rather than necessary. Thus the three-legged dog is
                                                                                1. Similar events should give rise to similar
still a dog because dogs usually, but not always, have four
                                                                                     representations.
legs. The second approach applies the concept of graded
                                                                                2. Things should have separate representations if
structure (Rosch, 1973), asserting that membership in the
                                                                                     they need to be separated, thus categories could
category is a matter of degree, not an all-or-nothing
                                                                                     be separated by their features.
feature. Thus a three-legged dog would still be a dog,
                                                                                3. If something is important it should be
albeit not as good an example as a four-legged dog. The
                                                                                     represented by multiple elements.
condition "has four legs" is only partly satisfied, so the
                                                                                4. Preprocess information as much as possible in
animal is not as good an example of a dog.
                                                                                     the hardware.

    5.   Make the representation flexible so it is not                              1.0
         problem specific.
                                                                     Activation
  Anderson also asserts (p. 346) that it would be easy to                           0.5
use "rather crude spatial means--say, spatially organized
excitation and inhibition--to emphasize or deemphasize                              0.0
one or another aspect of the computation." Following
Anderson’s guidelines, this article proposes a network                              -0.5
model of categorical and conceptual representation in                                                          Output
which each feature is represented by a set of spatially
organized nodes. The model accommodates both
probabilistic and graded structure theories. The paper is                             1
                                                                       Activation
organized as follows. First, two key structures of brain
organization in perceptual systems are introduced and
adapted for representation of category features. Then a                              0.5
number of simulations are provided to illustrate key
behavioral characteristics of the features model. A                                   0
proposal is then made for how these feature networks                                       1   2   3   4   5    6   7   8   9   10   11   12   13
could be interconnected to provide an aggregate model of
                                                                                                               Input
a category or concept. Finally, some implications of the
model for cognitive science are discussed.
          Representing single attributes                                            Figure 1: Edge contrast--Interconnected receptive
                                                                                    fields enhance differences in input values at the
There are two common characteristics of perceptual                                  edge where the difference occurs.
systems that are spatially based. The first is the
organization of sensory inputs using receptive fields.           For example, dogs typically have fur. This can be
Receptive fields are sets of input cells that are                represented on a scale from no-fur (Mexican hairless) to
interconnected such that closer cells have a common              heavily furred (St. Bernard). Second, characteristics may
effect (excitatory or inhibitory) on the next level of           be precise (24 inches tall) or vague (about 24 inches tall).
processing. More distant cells have the opposite effect. In      This model allows for both of these characteristics. The
two dimensions, these are described as center-on,                ordered nature of a feature (i.e., the degree to which it
surround-off if the closer cells are excitatory, or center-      holds) is mapped topographically onto the ordered
off, surround-on if the closer cells are inhibitory. The         organization of the nodes in the network. Precise values
second characteristic of perceptual systems is analogical        are represented as single nodes and vague values are
representation of the physical world in neural structure. In     represented as a cluster of adjacent nodes.
visual and haptic systems this is spatially based                  Several comments are in order before describing the
topographic representation, and in the auditory system it        model more specifically. First, the use of conceptual
is frequency based tonographic representation. In both           topographic mappings (as compared to physical or spatial
cases, the principle is the same: values close to each other     topographic mappings) shouldn’t be surprising if we take
in the physical world are close to each other in the neural      seriously the claim of evolutionary biologists, who argue
structure.                                                       that the easiest way to create a new structure is to borrow
   Sometimes these structures are combined, with rows of         an old one. Second, representations of number are
interconnected receptive fields. In the visual system, this      assumed to be at the level of an interval scale, so that both
architecture is responsible for the well-known effect of         the order and distance between nodes is relevant to the
Mach bands, in which differences in contrast in input data       representation. Third, nodes in the model’s feature
are enhanced at edges to increase contrast sensitivity. This     network are not suggested to be at the level of neurons,
effect is illustrated in Figure 1. The lower graph of the        nor are they intended to be physically adjacent to each
figure shows the specific inputs to each cell. The upper         other. The organization of the nodes is the important
graph shows the output pattern across many cells,                factor; if this architecture holds in real brains it is
including the enhanced contrast where the input pattern          expected that each node would be made up of many
changes.                                                         neurons and that connections would be distributed over
   This model applies the same architecture (rows of             wide areas. Finally, it should be noted that the idea of
interconnected receptive fields) to features of categories       distributing features over multiple nodes was used by
and concepts. Two important observations are important           Shultz and Lepper (1996) to model cognitive dissonance.
here. First, features are usually scalar in nature, i.e., they   They distributed features across two-node polarized pairs.
carry ordinal (and sometimes higher level) information.

                        1.5                                                                                 1.5
                        1.0                                                                                 1.0
     Activation                                                                                Activation
                        0.5                                                                                 0.5
                        0.0                                                                                 0.0
                        -0.5                                                                                -0.5
                                                   Output                                                                              Output
                         1.5                                                                                1.5
           Activation                                                                          Activation
                           1                                                                                  1
                         0.5                                                                                0.5
                           0
                                                                                                              0
                               1   2   3   4   5   6     7     8   9   10   11   12   13
                                                                                                                   1   2   3   4   5   6     7     8   9   10 11 12 13
                                                       Input                                                                               Input
    Figure 2: Point-valued representation--Input to a                                               Figure 3: Vague-valued representation--Input to
    single node results in a characteristic "Mexican                                                several adjacent nodes results in the same output
    hat" output pattern.                                                                            pattern, but one that is more dispersed.
                                                                                           This is consistent with empirical findings on subjective
The model                                                                                  estimates of probabilities (Edwards, 1961).
The model was created on a spreadsheet. Specifically, a
one-dimensional row of nodes (cells) was used to                                           Assimilation and contrast effects
represent a feature. Each node’s activation was calculated                                 In addition to probabilities, judgments of similarity are
as the sum of its input and the weighted-sum of the inputs                                 also subjective. Sherif, Taub, and Hovland (1958) found
of the six nearest nodes. Neighboring node inputs were all                                 that, when comparing two weights, subjects’ estimates of
weighted at 0.2 of their actual value, and were positive for                               the weight of one item depended on the similarity of the
adjacent nodes and negative otherwise. In other words,                                     comparison weight. When the two weights were very
the neural representation was a set of one-dimensional,                                    similar, subjects shifted their weight judgments of the test
overlapping, center-on/surround-off receptive fields.                                      weight (relative to when there was no comparison weight)
Inputs are modeled as values from 0 to 1, and outputs can                                  towards the value of the comparison weight. This effect
be either positive or negative. (Although this latter effect                               (or bias) they labeled assimilation. As the difference
is neurally unrealistic--neurons don’t have negative                                       between weights increased, subjects shifted their
activations--it is assumed this is reasonable given the                                    estimates of the test weight more than the actual changes.
usual positive base activation rate, which may be reduced.                                 This effect (or bias) was labeled contrast. In short, when
The zero base rate is used for simplicity of exposition.)                                  two items were compared, the subjective judgment of
                                                                                           difference depended upon the amount of the actual
Point-valued vs. vague-valued representations                                              difference. Small initial differences were reduced so the
Representations may be either point-valued or vague. This                                  two items appeared more similar than they actually were,
is modeled as either a single input or input spread across                                 while larger initial differences were enhanced so the two
several nodes. Figure 2 shows a point-valued                                               items appeared more different than they actually were.
representation and Figure 3 shows a vague-valued                                              The feature model yields the same effects. Figure 4
representation. In both cases, the effects are similar: from                               illustrates two point-valued inputs that are close to each
the center of input the activation spreads slightly to                                     other, yet still separated by another node. Their output,
neighboring cells, with closer cells being less activated                                  however, is merged into a single lump. (In this case, the
than the central point and further cells being inhibited to                                output is two-peaked. The actual shape depends upon
negative values.                                                                           several factors, including the number of cells between
   Vague representations may be interpreted as either                                      inputs, the size of the receptive fields and the value used
probabilistic or graded. Thus, in Figure 3, the input value                                to weight neighboring cell inputs.)
for 7 may be interpreted as a 40% probability of 7                                            A contrast effect, which occurs when the distance
occurring or as 7 to degree 0.4. When interpreted as                                       between the initial inputs is increased, is illustrated in
probabilities, it isn’t required that these values sum to 1.                               Figure 5. The contrast occurs in two ways. First, the

                   1.5                                                                              1.5
      Activation
                   1.0                                                                              1.0
                                                                                       Activation
                   0.5                                                                              0.5
                   0.0                                                                              0.0
                   -0.5                                                                             -0.5
                                              Output                                                                           Output
                   1.5                                                                               1.5
      Activation                                                                       Activation
                     1                                                                                 1
                   0.5                                                                               0.5
                     0                                                                                 0
                          1   2   3   4   5   6     7     8   9   10 11 12 13                              1   2   3   4   5   6   7   8   9   10 11 12 13
                                                  Input                                                                        Input
    Figure 4: Assimilation effect--When two inputs                                   Figure 5: Contrast effects--When two inputs are
    are close to each other, the outputs from the                                    slightly further apart, the outputs enhance the
    feature network are merged into a single output.                                 difference, both horizontally and vertically
activation value of the most intermediate node between                          the illustrated point-valued representations. Finally, this
the input values is inhibited below its normal base rate of                     contrast effect is similar to the peak shift found in
zero, heightening the vertical contrast with the activation                     stimulus learning (Hanson, 1959). Peak shifts occur when
values of the nodes where the input actually occurs.                            a correctly learned stimulus (which generalizes over a
Second, the "center of mass" of the output activations is                       symmetric gradient) must be discriminated from a new,
shifted horizontally, slightly away from the actual value                       closely related stimulus. The original stimulus gradient
where the input occurs. This is seen in the actual output                       shifts slightly, creating an asymmetric gradient, but one
activation values. For example, input occurs at node 5,                         that enhances discrimination. Because peak shifts are
which has the highest output (activation value equal to 1).                     learned, they occur over time, whereas contrast effects
But node 4’s activation is .2 and node 6’s activation is 0.                     occur immediately in real time. But both are adaptive
This asymmetry, in effect, shifts the mean activation of                        mechanisms that enhance contrast.
the representation for that input slightly away from its
actual value.                                                                   Chunking
  Several observations are in order here. First, the effects                    One of the best known effects in cognitive science is
are a result of the size of the receptive field. The                            chunking, the combination of several smaller bits of
assimilation effect occurs when the center (excitatory)                         information into a single larger piece (Miller, 1956).
parts of the receptive fields overlap and the contrast effect                   When multiple pieces of information are represented as
occurs when the surround (inhibitory) parts of the                              inputs in the feature network, assimilation and contrast
receptive fields overlap. Second, the assimilation effect                       effects provide a type of chunking. Figure 6 illustrates
could put a lower bound on what differences can be                              this, with seven inputs in two clusters of five and two,
perceived; in effect they represent a just noticeable                           separated by one node with no input. The resulting output
difference (Gregory, 1987, p. 405) for whatever is                              is two distinct "chunks," which could be called "low" and
represented in the network. Third, if learning features                         "high" on the particular feature in question.
from environmental inputs has created appropriately sized
receptive fields, these effects are functionally adaptive.                                                     Multiple features
Essentially, assimilation allows for very small (and likely                     Typically, categories are made up of items with complex
irrelevant) differences to be ignored, because they are                         combinations of multiple features. This section begins an
merged and treated as one. Slightly larger (and likely                          exploration of this issue by considering how feature
more important) differences, which might not otherwise                          networks might be combined to represent more complex
be noticeable, have their differences enhanced. (Even                           concepts and categories. Due to the dynamic complexities
larger differences, which presumably would be easier to                         of interconnected features, this section provides only a
notice, aren’t enhanced at all because the receptive fields                     sketch of how multiple attributes might be represented.
of nodes receiving inputs don’t overlap at all.) Fourth,                          Because each feature is represented as a network of
these effects occur with vague representations as well as

                   1.5
                                                                                                        wings
      Activation
                   1.0
                                                                                           poor wings         good wings
                   0.5
                                                                                         1 2 3 4 5 6 7 8 9 10 11 12 13
                   0.0
                   -0.5
                                              Output
                   1.5                                                                   1 2 3 4 5 6 7 8 9 10 11 12 13
      Activation
                     1                                                                         flies poorly         flies well
                   0.5
                                                                                                      flying ability
                                                                                   Figure 7: Multiple feature networks can be
                     0
                          1   2   3   4   5   6     7     8   9   10 11 12 13
                                                                                   connected based on the correlations of features.
                                                                                   Solid lines represent positive correlations and
                                                  Input
                                                                                   dashed lines represent negative correlations.
    Figure 6: Chunking--When many input nodes are                                  Here, good flying ability (node 13) is positively
    activated, their outputs are clustered into related                            correlated with good wings (node 13) and
                                                                                   negatively correlated with poor wings (node 1).
    groupings, such as "high" and "low."
                                                                                   Double     arrowheads      indicate   that    the
ordered values, these networks can be related based on                             connections are bilateral.
correlations between features. For example, the ability to
fly is correlated with the presence of wings. Both are                          secondary feature’s output are the weaker level of
characteristics of birds and other flying species. Thus                         activation relative to the activated feature and the drop in
positive connections can be made between corresponding                          activation on the poor side of the scale, creating a contrast
nodes in the two different attributes, such as good flying                      with the activated end of the feature network. The first
ability and good wings. Similarly, negative correlations                        characteristic is due to the weight of the correlation
can be made between opposite ends of the network.                               connections being less than one. The second characteristic
Figure 7 illustrates how these connections would be made                        results from the inhibitory connections that cross over to
from two nodes in a "flying ability" feature network to                         the opposite end of the secondary feature. The net effect
two nodes in a "wings" feature network. The straight-                           of these two characteristics is that the activation level is
across connections are positive (shown as solid lines)                          lowered, but this is offset by an induced contrast effect.
representing positive correlations, and the diagonal
connections are negative (shown as dashed lines),                               Categories
representing negative correlations. The double arrows on                        Treating categories as features can extend the use of
all connections represent that the connections are                              interconnected feature networks to categories. For
bilateral, that is they are mutually excitatory or inhibitory.                  example, "birdness" is descriptive of a category, but can
This allows a dynamic interplay between the features,                           also be treated as a feature that is correlated with features
such that each node includes among its inputs the                               like flight, wings, feathers, and egg laying. Because they
activations of the other feature’s nodes from the previous                      are correlated, all the features of the category would be
iteration. These recurrent connections require a more                           connected to the category network. Thus, networks for
complex formulation of the node activation functions,                           features like flying ability, wings, feathers, lays eggs, etc.
particularly the use of decay to dampen each node’s                             would all connect to a bird feature network. When some
activations over time. In the simulations presented here,                       of the features of being a bird are activated, the activation
correlative connections were weighted ± 0.2 and each                            spreads to other features, including the bird feature.
node’s activation value was decayed 80% from the prior                             Levels of categories (superordinate, basic, and
period before computing the net input values.                                   subordinate) also appear to be easily computed in this
  When interconnected in this way, activation spreads                           structure, because the assimilation and contrast effects of
from one feature to another. Figure 8 shows the spread of                       the feature networks allow for generalization to higher
activation from an activated feature (flies well) in one                        category levels via chunking, and discrimination between
period to a secondary feature (has good wings) in the                           lower level categories via contrast effects. Further
following period. Two interesting characteristic of the                         simulations are needed to explore these dynamics.

                             wings (secondary activation)
                                                                                  basic tasks is intriguing.
                                                                                     Because these networks provide a means of
                  0.5
                                                                                  representing symbolic information, they may shed light
                                                                                  on the nature of symbolic thought. Those who view the
     Activation
                                                                                  mind as a symbolic processor and those who view the
                  0.0
                                                                                  mind as a vast connectionist network have reached an
                                                                                  uneasy truce. While not held universally, the view
                                                                                  promoted by Smolensky (1988) is common: The mind is a
                  -0.5
                                                                                  symbol processor that runs on top of a neural network
                                 <--poor w ings          good w ings-->           computing platform. The feature network model
                                                                                  presented here suggests that this simple dichotomy may
                                            flying ability                        be unrealistic because the nature of the symbol processing
                                                                                  itself may be important. In particular, dynamic grouping
                  0.5                                                             and splitting of fuzzy neural representations (i.e.,
                                                                                  generalizing and discriminating) and associations between
     Activation
                                                                                  correlated features may characterize thought more than
                  0.0                                                             logical operations.
                                                                                                  Acknowledgements
                  -0.5                                                            I appreciate the comments provided by Christine Diehl,
                                  <--flies poorly         flies well-->
                                                                                  Janek Nelson, and Michael Ranney on an earlier version
                                                                                  of this paper.
                   1                                                                                    References
                                                                                  Anderson, J. A. (1995). An introduction to neural
     Activation
                                                                                    networks. Cambridge, MA: MIT Press.
                  0.5
                                                                                  Edwards, W. (1961). Behavioral decision theory. Annual
                                                                                    Review of Psychology, 12, 473-498.
                                                                                  Gregory, R. L. (Ed.). (1987). The Oxford companion to
                                                                                    the mind. New York: Oxford Press.
                   0
                                                                                  Hanson, H. M. (1959). Effects of discrimination training
                         1   2     3    4    5   6   7    8   9   10   11 12 13
                                                                                    on stimulus generalization. Journal of Experimental
                                  <--flies poorly         flies well-->             Psychology, 58, 51-65.
    Figure 8: Activation of a correlated feature--Input                           Medin, D. L., & Smith, E. E. (1984). Concepts and
    (bottom graph) characterized vaguely as "good                                   concept formation. Annual Review of Psychology, 35,
    flyer" causes a similarly vague output of the                                   113-138.
    "flying ability" feature network (middle graph).                              Miller, G. A. (1956). The magical number seven plus or
    Both positive and negative correlations with the                                minus two: Some limits on our capacity for information
    "wings" feature network (top graph) result in a                                 processing. Psychological Review, 63, 81-97.
    slight contrast effect.                                                       Rosch, E. H. (1973). On the internal structure of
                                                                                    perceptual and semantic categories. In T. Moore (Ed.),
                                                                                    Cognitive Development and the Acquisition of
                                       Conclusions                                  Language: Academic Press.
If categories provide the foundation of higher level                              Sherif, M., Taub, D., & Hovland, C. I. (1958).
thought, then their representation in neural structures is an                       Assimilation and contrast effects of anchoring stimuli
important nut to crack. The proposed method of                                      on judgments. Journal of Experimental Psychology, 55,
representing categories via their features in ordered                               150-155.
feature networks is promising because it is simple and                            Shultz, T. R., & Lepper, M. R. (1996). Cognitive
based on known patterns of neural organization. These                               dissonance reduction as constraint satisfaction.
networks allow for crisp, vague, and probabilistic                                  Psychological Review, 103(2), 219-240.
representations. Perhaps most unusual, they provide a                             Smolensky, P. (1988). On the proper treatment of
natural way to dynamically generalize and bifurcate                                 connectionism. Behavioral and Brain Sciences, 11, 1-
concepts because of their assimilation and contrast                                 74.
effects. While further research about the characteristics of                      Zadeh, L. (1965). Fuzzy sets. Information and Control,
these networks (especially more complex interconnected                              8(3), 338-353.
feature networks) is needed, their ability to perform these

