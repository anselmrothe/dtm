UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Human and Automated Indoor Route Instruction Following
Permalink
https://escholarship.org/uc/item/2398n3br
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
MacMahon, Matt
Stankiewicz, Brian
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

           Human and Automated Indoor Route Instruction Following
                                  Matt MacMahon (adastra@mail.utexas.edu)
                                   Department of Electrical and Computer Engineering;
                                               The University of Texas at Austin
                                 Brian Stankiewicz (bstankie@psy.utexas.edu)
                                                  Department of Psychology;
                                                Center for Perceptual Systems
                                         Consortium for Cognition and Computation
                                               The University of Texas at Austin
                                                  1 University Station A8000
                                                   Austin, Texas 78712 USA
                          Abstract                                 that can typically be followed is remarkable. The current
                                                                   paper investigates how people give route instructions
   Humans possess the remarkable ability to give and               about indoor environments they have learned through
   follow natural language route instructions through large-
   scale spaces. In this process, a director describes             navigation. We present a computational model of route
   the actions and observations along the route, recalling         instruction following called Marco and investigate the
   the environment’s topology, metrical layout, and visual         following three questions:
   features.   A follower interprets these descriptions,         1. How do quality and style vary in route instructions?
   navigating by applying the instructions to the possibly
   unfamiliar environment. Furthermore, followers must           2. How well does Marco follow route instructions and
   account for mistakes, ambiguities, and omissions in                how closely does the model’s behavior correlate with
   the route description. To study how instructions are               human behavior?
   written and followed, we collected 756 free-form route        3. Can Marco differentiate good versus bad instruc-
   instructions from six participants for 126 routes in three
   virtual environments. A second group of participants               tions, by both human performance and ratings?
   and a computational model (Marco) followed these
   instructions. Humans successfully reached the destina-          Why are some route instructions reliable?
   tion on 68% of the instructions and Marco followed
   61% of the instructions. Marco’s performance was a              Though a large literature examines route instructions,
   strong predictor of human performance and ratings of            there is no consensus about what differentiates good
   individual instructions.                                        instructions from bad. Vanetti and Allen (1988) found
                                                                   spatial ability had a larger effect in the accuracy of sub-
Keywords Artificial Intelligence; Spatial Cognition;               jects’ described routes than verbal ability. Daniel et al.
Natural Language Understanding; Cognitive architec-                (2003) found “good”, “poor”, and “skeletal” instructions
tures; Human experimentation; Symbolic computational               were differentiated by whether the proper action was
modeling Knowledge representation                                  associated with the proper landmark. Allen (2000)
                                                                   suggests descriptives clauses and action delimiters should
                      Introduction                                 be inserted at choice points and near the destination,
Imagine while walking across a campus, a stranger                  instead of en-route. Lovelace et al. (1999) found good
approaches you to ask how to get to another location.              route instructions mentioned many landmarks along the
The destination is not within sight, so you cannot simply          paths, off the route, and at the choice points.
point at the goal. Instead, you must reference your                   Some of these studies rate route instructions sub-
memory of routes between you and the goal. Once a                  jectively (Vanetti and Allen, 1988; Lovelace et al., 1999;
route is selected, you need to access your knowledge of            Tversky and Lee, 1999), but do not test if navigation
specific landmarks and distances to provide references             success is affected. Others have participants follow a
for the follower . You translate this knowledge into a             small number of participant- and experimenter-written
verbal description of the route. Remarkably, a short               instructions (Daniel et al., 2003; Allen, 2000). Our
verbal description is often sufficient to guide a follower         work implements a study suggested by Lovelace et al.
through an unfamiliar large-scale space.                           (1999), where participants follow route instructions from
   Despite directors’ best efforts, not all instructions are       different routes and directors in virtual reality.
perfectly clear and reliable for reaching the goal. Often
instructions contain ambiguous information (e.g. which             Computational models of route instructions
tree is “the oak tree”), qualitative mistakes within               Software systems that analyze or follow route in-
the instruction (e.g. “turn right” where no right turn             structions can be distinguished by how they represent
is possible) or metrical mistakes (e.g. “go forward 3              space. Freundschuh and Egenhofer (1997) survey a
blocks” when the distance is 4 blocks). Because of                 variety of spatial representation models and define broad
these failings, the follower must treat the instructions           categories based on (1) if the objects in the space
as guidance, not as strict commands.                               are manipulable, (2) if the space requires locomotion
   With all the potential for miscommunication arising             to experience, and (3) the size, or scale, of the
from the complexity of giving and understanding route              space. This work focuses on non-manipulable, large-
instructions, the human ability to provide instructions            scale spaces that cannot be experienced from any one
                                                              1759

“turn to face the green hallway”                       “walk forward three times”
               T URN                                                                             modules. For details, see MacMahon et al. (2006).
     T URNV          P URPOSE                                   T RAVEL                          Text Interpreter
      turn
              P URPOSE P         S
                                                                                                 The Text Interpreter models the surface structure of
                                                  T RAVEL V       D IR         D IST             an utterance and the surface meaning of an utterance.
                  to
                      FACE V           PATH
                                                    walk       forward C OUNT U NIT              The Syntactic Parser parses raw text into grammatical
                      face                                                three times
                                                                                                 structures. Our grammar directly models verb-argument
                             D ET    A PPEAR PATHN
                                                                                                 structure, instead of part-of-speech syntax (see the parse
        2
                             the     green hallway
                                                3
                                                                                                 tree in Figure 1). Next, the Text Interpreter translates
          T URN
        62                                     37     2                                   3      the surface structure of an utterance to a model of the
        6 V /TURN Turn_V_1                              T RAVEL
        66
        66P URPOSE
                                                7
                                               77
                                               77
                                                      62
                                                      6 V /TRAVEL Walk_V_1
                                                                                         37      surface meaning, that drops arbitrary word ordering
                                                                                                 and marks words with meaning sense, abstracting over
        662                                                                               7
        66                                    377     66                                 77
        66 V /FACE Face_V_1                    77
                                                7     66D IR         Forward_ADV_1       77
                                                                                        #77
                                                                                                 changes in morphology, spelling, and synonyms.
                                                      66
        66
        66          2                        377
                                               77     66            "
                                                                                         77
        66 6
           6          D EF        +           777
                                              7 7     64
                                                      4 D IST         C OUNT 3           57
                                                                                          5
        66                                     7
                                             7777
        444PATH 4 A PPEAR Green_ADJ_15555
        66 6        6                           7                     U NIT    Time_N_2
                      PATH        Hall_N_1                                                       Instruction Modeler
                       object=Path,
                                                                                                 The Instruction Modeler translates the surface meaning
        Turn(until=( appear=Green, ))
                        side=Front
                                                       Travel(dir=Forward, dist=3)               of what was said into an imperative model of what
                                                                                                 to do, when.        The Instruction Modeler combines
                                                                                                 information across phrases and sentences to generate
Figure 1: The Text Interpreter parses each sentence to
                                                                                                 either imperatives (specific action instructions; e.g. “go
get a syntactic tree, then labels the word senses and                                            until”) or declaratives (i.e. information about the envi-
transforms the tree to a content frame. The Instruction                                          ronment; e.g. Path(appearance:Blue, length:Long). The
Modeler interprets the frame as an underspecified                                                representation captures the underspecified commands
command that the Route Executor acts to fulfill, guiding                                         in the route instructions, modeling the route as a
the follower’s navigation through the environment.                                               sequence of simple actions (Turn, Travel, Verify) to be
                                                                                                 taken under certain perceptual (e.g. seeing a view) or
                                                                                                 cognitive conditions (e.g. estimating a distance). This
perspective: the agent must turn (panoramic space) or                                            step is similar to the “minimal units of information”
move (environmental space) to see the space.                                                     Denis (1997) derived manually. Figure 1 shows the
   Skubic et al. (2004) developed software that can                                              transformation from text to the imperative model.
recognize and reason about spatial relations. It moves
a robot within a room to achieve a spatial command.                                              Route Executor
Bugmann et al. (2004) compared the performance for a                                             To navigate, Marco interprets the imperative model in
robot navigating through a tabletop model environment                                            the context of the environment. The Route Executor
a system following (1) programs translated by hand                                               picks actions given the context from perceiving the
from speech, (2) software-generated models of the                                                environment and tracking the state within the route in-
instructions, and (3) people controlling the motion.                                             structions. It checks symbolic view descriptions against
Bugmann’s participants saw an outside, panoramic                                                 sensory observations and spatial models.          Marco
perspective of a small model of a town neighborhood the                                          performs symbol anchoring (Coradeschi and Saffiotti,
robot navigated. This paper builds on Simmons et al.                                             2003) by tying each concept to its experience. It
(2003), a system that follows route instructions through                                         verifies if the described attributes of the environment
large-scale environments.                                                                        are consistent with the observation stream and acts to
                                                                                                 reach the described states along the route.
             Marco Route Follower Model
Marco is designed to follow route instructions in                                                        Route Instruction Experiment
large-scale spaces, between places not mutually visible                                          To understand how humans give and follow instructions,
and separated by travel.                           We tested Marco on                            we developed a collection of novel virtual environments.
instructions written from memory by people who learned                                           We collected route instructions from six participants
the environments from a first-person perspective while                                           who learned to navigate efficiently in the environ-
navigating. Marco follows these route instructions                                               ments. Thirty-six human participants and two variants
without any a priori environmental model by reasoning                                            of Marco followed these instructions. The human
about actions, views, and topology. These are the Causal                                         participants subjectively rated the instructions. We are
and Topological representation levels of the Spatial                                             interested in how well Marco can follow these instruc-
Semantic Hierarchy (Kuipers, 2000).                                                              tions and how Marco’s performance correlates with
   Marco has modules for interpreting and                                                        human navigatation and ratings of route instructions.
following written, natural language route instructions
(MacMahon et al., 2006). Marco consists of three                                                 Methods
primary modules (see Figure 1 for a trace of the                                                 Apparatus These experiments used desktop virtual
linguistic modeling): A Text Interpreter , an Instruction                                        reality, with human participants with a first-person
Modeler , and a Route Executor . For the sake of brevity,                                        perspective moving through a computer-animated three-
we describe only the fundamental properties of these                                             dimensional world. Figure 2 provides an overhead map of
                                                                                            1760

one of environments (Top) and the first-person perspec-
tive of the participants navigating through it (Bottom).
The experiments are controlled by Python scripts using
the WorldViz Vizard software (Vizard, 2003). Subjects
navigate in discrete motions using the keyboard: ’8’ key
moves forward one hallway, ’4’ turns left, and ’6’ turns
right.
Stimuli These environments and the experiment con-
trol software build on top of previous studies on spa-
tial navigation (Stankiewicz et al., 2001; Kuipers et al.,
2003). To provide useful cues for the directors, we placed
11 objects of 6 different types within each environment.
Furthermore, each environment was divided into three
separate regions, designated by distinct pictures on the
walls (see figure 2). Finally, 7 long hallways within each
environment had a visually distinct texture mapped onto
the floor. Figure 2 (Top) shows the layout for one of the
environments and Figure 2 (Bottom) shows the view of
an easel on a black stone hallway in the fish region.
   The three testing enviroments varied in the density
of the layout, as measured by the shortest travel routes
betweeen the named positions. The most compact had
a mean shortest path length of 4.2 (median 4), the
most spread-out enviroment, mean 6.0 (median 6). The
shortest route was one travel action, the longest was 13.
Procedure Two sets of participants were used in this
study: Directors and Followers. Directors learned each
environment until they could navigate efficiently, then
wrote text route instructions, navigated the routes, and
rated themselves. Followers followed the Directors’
instructions without any previous knowledge of the
layout, rated the quality of the instruction, and rated         Figure 2: Top: Map of one of three virtual environments
their certainty of reaching the described destination.          (not seen by participants). Three regions share a wall
Directors Directors were instructed to learn the                hanging of a fish, butterfly, or Eiffel Tower. Each long
environment and the location of the seven target                hallway has a unique flooring. Letters above mark
locations. The name of each target was announced by             objects (e.g. ’C’ is a chair), numbers indicate named
a computer-generated voice (e.g. “Position 3”) when the         positions. Bottom: Participants’ first-person view from
participant entered a location. The directors were told         the easel (’E’) at the end of the black hall in the map.
that later they would give instructions to travel between
these target locations. Directors had free exploration
sessions of 120 travel actions to learn the spatial layout.     experienced the following sequence of events:
   After each free exploration period, we evaluated how       1. The director was placed at the starting location, facing
well the director knew the environment by giving a                 a random direction.
navigation efficiency test . In this test, the computer       2. The position name was announced (e.g. “Position 7”)
started the participant at one of the target locations             and the director was allowed to turn freely to orient,
and instructed the participant to travel to a target               but not to move forward. Once ready, the participant
location (e.g. “Go to position 2.”). The participant               pressed a button.
was instructed to travel to that location by the shortest     3. A text-entry window then appeared on the screen.
route. After reaching the designated target location,              The director typed their instructions without a time
the computer compared the number of travel actions                 limit. The director could also move the cursor to
used to the shortest route. When director reached all              correct previously typed text in this step. The director
goals within 150% of the shortest path for each route              clicked a button when the instructions were finished.
for seven consecutive routes, the navigation efficiency       4. After giving instructions, the director navigated from
test ended. After three routes over this threshold, the            her current location to the specified target location.
director returned to the free exploration phase.                   Upon reaching the target location, the director pressed
   After passing the navigation efficiency test, the               the space bar indicating that she was at the goal.
director entered the route instruction phase of the study.    5. On a six-point scale, the director rated:
In this phase, the director gave instructions for routes         (a) how certain she was she reached the destination
between the target locations. For each route, the director      (b) and the quality of her own instructions.
                                                           1761

   For the seven locations within an environment there
 are 42 possible pairs (7 choose 2). Each participant           Table 1: Example instructions for routes from same start
 gave instructions between all 42 ordered pairs of named        and end. Instructions include errors (e.g. “halllway”).
 positions in a random order. Each director repeated this
 procedure for all three environments, on separate days.          EDA: turn to face the green halllway, walk
                                                                  three times forward, turn left, walk forward
 Followers Participants in the follower group were told           six times, turn left, walk forward once
 that they would be given a set of instructions written           EMW: Follow the grassy hall three segments
 previously by other participants. The followers were
                                                                  to the blue-tiled hall. Turn left. [...]
 instructed that they should follow the instructions to
                                                                  Turn left. Go one segment forward to the
 the best of their ability. The route instructions were
 presented on the computer screen as text as typed by the         corner. This is Position 5.
 director. However, any reference to a target position by         KLS:     take the green path to the red brick
 name (e.g. “This is Position 1”) was replaced with               intersection. go left towards the lamp to
 an anonymizing ’X’ or ’Y.’ The followers recognized              the very end of the hall. at the chair,
 destinations from the descriptions, not a name.                  take a right. [...] at the end of this
   Each follower followed and rated 126 instructions              hall at the corner, you are at position 5
 balanced across routes, directors and environments.              KXP: head all the way toward the butterfly
 The procedure interleaved instructions from all three            hallway, keep going down it until you reach
 environments to discourage the followers learning the            a dead end square area. pos 5 is in the
 environments. No follower experienced exactly the same           corner to the left as you enter the block.
 route twice, so none repeated a route with new route
                                                                  TJS:     go all the way down the grassy hall,
 instructions.
   Each follower experienced the following sequence of            take a left, go all the way down the blue
 events for each route instruction:                               hall until you see a coat rack, take another
1. The computer presented a text box containing the               immediate left.
   route instruction text. The follower was allowed to            WLH:       from four face the grass carpet and
   read the instructions without a time limit, selecting          move to the hat rack, [...] move into the
   an ’OK’ button when finished.                                  corner such that the lamp is behind you and
2. The follower was placed at the starting position facing        to your right you see a gray carpeted alley
   a random direction.
3. The follower navigated through the environment.
4. At any time, the follower could review the instructions      sentence. We also used Marco and the test corpus to
   by pressing ’d’ on the keyboard. The instruction             examine why people prefer some instructions over others,
   display fully obscured the view of the environment.          even when both lead to the goal.
5. When the follower believed that he had reached the              We ran Marco with and without an error recovery
   destination described in the instructions (or finished       strategy. The recovery strategy is a Find behavior,
   trying), he pressed the space bar.                           which simply performs a “drunkard’s walk” when the
6. The follower rated how confident he was that he had          follower does not see a view that matches a necessary
   reached the goal and the quality of the instructions,        description in the instructions. The follower randomly
   both on a six-point scale.                                   picks one of the paths at the current location to travel
                                                                along, then checks whether the sought-after view is now
 Participants Forty-two participants were used in the           visible. There is also a small chance of giving up, which
 study. Six participants were directors (3 females) and         gradually increases with each forward move.
 thirty-six were followers (15 females). The directors were
 paid $10.00/hour for an average of 7 hours. The followers             Marco and Human Comparison
 participated for one or two hours to help satisfy course
 credit in an undergraduate psychology course.
 Human Instruction Experiment Results                           Table 2: Marco model’s success predicts people’s with
                                                                84% precision, 75% recall, and 79% F-measure.
 Table 1 provides a sample of the instructions given by
 the six directors. The instructors’ styles varied from very                         Human Success      Human Failure
 sparse instructions providing specific move sequences            Marco Success            1809               338
 (EDA) to very rich and elaborate instructions (KLS).             Marco Failure             618               758
 Marco Performance Study
                                                                   Human followers successfully followed the instructions
 Over runs through the 756 route instructions (42 routes        on 68% of the route instruction runs. Tables 2 and 3
 in 3 environments for 6 directors), we measured how            and Figure 3 summarize the success rates of Marco and
 often Marco successfully reaches and recognizes the            people and how subjects rated the instructions.1
 destination. For analysis, we focus on the 682 of the
                                                                    1
 route instructions where director typed at least one                 Comparisons are with Marco as of April 21, 2006.
                                                            1762

Table 3: Correlations of success rates and human                                                100%
subjective ratings. Spearman rank-order correlation                                                        Human
                                                                                                           Marco
                                                                                                           Without Find
coefficients (RS ) are all significant at p < 0.001.
                                                                                                80%
                                                                   Routes Correctly Navigated
                       Route      Human         Human
                       Success    Subjective    Success
                                                                                                60%
                       Rate       Rating RS     Rate RS
         Human           68%         0.578         1.000                                        40%
    Full Marco           61%         0.544         0.607
 Marco w/o Find          53%         0.610         0.585
                                                                                                20%
   As expected, there is a strong correlation between the                                        0%
instruction rating and the human rate of stoping at the                                                1          2           3          4          5   6
                                                                                                                          Human Subjective Rating
goal (RS =0.578). The mean human subjective rating
has a slightly lower correlation to the success rate of the
full Marco model (RS =0.544), but a higher correlation         Figure 3: Route instruction following success for runs by
to the success rate of Marco without Find (RS =0.610).         human followers and Marco with and without Find.
   Comparing the success rates, a different pattern
emerges. Human success rate per route instruction
correlates more highly with the success rate of the            modeling of discourse context will allow interpretation
full Marco (RS =0.607) than with the success rate of           when one utterance depending on the prior utterance.
Marco without Find (RS =0.585). The full Marco                 One example is “Go down two intersections. At
model is a better predictor of the objective human             the third, turn right,” which was also a difficulty
success rate for a route instruction, while Marco              for Bugmann et al. (2004).
without Find is better predicts human subjective rating.       Analysis of Director Performance
Analysis of Follower Performance                              Figure 4 shows the mean success rate on instructions
Figure 3 shows the navigation success rates for people,       from each director for people, Marco and Marco
the full Marco and Marco without the Find behavior.           without Find. Each bar represents the mean percentage
Each plotted point is the arithmetic mean over the set        of routes successfully followed over multiple runs through
instructions with post-hoc human subjective rating of         the route instructions by a director (all directors for
n ± 0.125, with poor instructions (from 1.0) on the left      ’All’). Each group of bars displays the performance for
to and excellent on the right.                                runs using the instructions from one director.
   The top line (◦) shows the success rate by human              Marco best approximates human performance on
followers increasing with instruction rating. The default     two of the directors who give the more reliable and
Marco () system approximates human performance               highest rated instructions (EDA and EMWC). These
for highly-rated instructions (> 4.0), while succeeding       directors also show the least drop off without the Find
less often on poorly-rated instructions (< 4.0). On           behavior. Marco does not perform quite as well
highly-rated instructions (right side), using the Find        on these instructions from the next two most reliable
error recovery method (⊲) does not greatly affect             directors, KLS and WLH, but still does not require the
performance. However, for poor instructions, Find             Find behavior often. These directors all tend to give
actions become as crucial, as can be seen as the              instructions explicitly covering entire route.
performance of the system without Find (⊲) drops on              On instructions from the two poorest performing
the poor instructions on the left.                            directors, KXP and TJS, Marco does not perform
   We coded the primary reason for failure on 118             as well as people do. Both of these directors wrote
instructions where Marco’s success rate is 50 percentage      instructions that require frequent use of the Find
points less than people’s. There were 8 errors in model-      behavior, as can be seen by the decrease in performance
ing word meaning, 28 errors in modeling phrases, 8 errors     without it. The routes from these directors are often
in combining phrases within an utterance, 50 errors           fragmentary and error-laden.
in combining information from separate utterances, 5
perceptual errors, 6 anaphora errors, and 8 errors of over-                                                               Conclusions
relying on part of the description.                               This study examined what separates highly- and poorly-
   Based on this discrepancy analysis, the most effective         rated verbal route instructions. One human study
ways for Marco to improve are in better and more                  collected a large corpus of text route instructions de-
comprehensive modeling of phrases and in modeling                 scribing three complex large-scale virtual environments.
discourse context. Some phrases are not yet inter-                A second human study followed and rated these route
preted, such as some fictive motion phrases, while                instructions. A software system that can parse, model,
others are misinterpreted in some contexts. Some                  and reactively enact route instructions is presented. The
                                                           1763

                                                                                                             Coradeschi, S. and Saffiotti, A. (2003). An introduction
                                            100%                                                               to the anchoring problem. Robotics & Autonomous
                                                                                          Human
                                                                                                               Systems, 43(2-3):85–96.
 Mean success rate over the entire corpus
                                                                                          Marco
                                                                                          Without Find
                                                                                                             Daniel, M.-P., Tom, A., Manghi, E., and Denis, M.
                                            80%                                                                (2003). Testing the value of route directions through
                                                                                                               navigational performance.       Spatial Cognition and
                                                                                                               Computation, 3(4):269–289.
                                            60%
                                                                                                             Denis, M. (1997). The description of routes : A cognitive
                                                                                                               approach to the production of spatial discourse.
                                            40%                                                                Current Psychology of Cognition, 16(4):409–458.
                                                                                                             Freksa, C. and Mark, D. M., editors (1999). Spa-
                                                                                                               tial Information Theory: Cognitive and Computa-
                                            20%                                                                tional Foundations of Geographic Information Science
                                                                                                               (COSIT ’99), volume 1661 of Lecture Notes in
                                                                                                               Computer Science, Stade, Germany. Springer.
                                             0%
                                                   EDA
                                                   4.88
                                                          EMWC
                                                           4.90
                                                                    KLS
                                                                    4.70
                                                                           KXP
                                                                           3.45
                                                                                  TJS    WLH
                                                                                         4.31
                                                                                                    All      Freundschuh, S. and Egenhofer, M. (1997). Human
                                                                                  3.18             4.32
                                                                                                               conceptions of spaces: Implications for GIS. Trans. on
                                                                                                               Geographic Information Science, 2(4):361–375.
Figure 4: Route instruction following success and mean                                                       Kuipers, B. J. (2000). The Spatial Semantic Hierarchy.
human instructions rating for each of the 6 directors by                                                       Artificial Intelligence, 119:191–233.
people and Marco with and without Find.                                                                      Kuipers, B. J., Tecuci, D. G., and Stankiewicz, B. J.
                                                                                                               (2003). The skeleton in the cognitive map : A com-
                                                                                                               putational and empirical exploration. Environment
system, Marco, approximates human performance, as                                                              &Behavior, 35(1):80–106.
measured by whether the follower successfully navigates                                                      Lovelace, K. L., Hegarty, M., and Montello, D. R. (1999).
from a starting place to the destination and correctly                                                         Elements of good route directions in familiar and
declares reaching the goal.                                                                                    unfamiliar environments. In Freksa and Mark (1999),
   We find that the base Marco system is a strong                                                              pages 56–82.
predictor of which instructions people can follow, while                                                     MacMahon, M., Stankiewicz, B., and Kuipers, B. (2006).
the Marco system without an error recovery behavior                                                            Walk the talk: Connecting language, knowledge,
is a strong predictor of how people will rate the                                                              action in route instructions. In Proc. of the 21st
instructions. If Marco successfully reaches the goal,                                                          National Conf. on Artificial Intelligence (AAAI-2006),
people most likely will also. If Marco must use its error                                                      Boston, MA.
recovery Find behavior to reach the destination, people                                                      Simmons, R., Goldberg, D., Goode, A., Montemerlo,
will be able to reach the goal less often and will rate                                                        M., Roy, N., Sellner, B., Urmson, C., Schultz, A.,
the instructions lower. Further work will use Marco                                                            Abramson, M., Adams, W., Atrash, A., Bugajska,
to investigate how people think and communicate about                                                          M., Coblenz, M., MacMahon, M., Perzanowski, D.,
large-scale spaces and provide a practical interface for                                                       Horswill, I., Zubek, R., Kortenkamp, D., Wolfe, B.,
assistive technologies such as smart wheelchairs.                                                              Milam, T., and Maxwell, B. (2003). GRACE: An
                                                                                                               autonomous robot for the AAAI Robot Challenge. AI
                                                          Acknowledgments                                      Magazine, 24(2):51–72.
This work was supported by AFOSR grants FA9550-04-1-                                                         Skubic, M., Perzanowski, D., Blisard, S., Schultz,
0236, FA9550-05-1-0321 and NIH grant EY016089 to B.J.                                                          A., Adams, W., Bugajska, M., and Brock, D.
Stankiewicz, by NSF grant IIS-0413257 to Benjamin J.                                                           (2004). Spatial language for human-robot dialogs.
Kuipers, and under support for Matt MacMahon through                                                           IEEE Trans. on Systems, Man&Cybernetics – Part C,
ONR work order N0001405WX30001 for the NRL Research                                                            34(2):154–167.
Option, Coordinated Teams of Autonomous Systems. We                                                          Stankiewicz, B. J., Legge, G. E., and Schlicht, E. (2001).
gained insights from discussions with Benjamin Kuipers, the                                                    The effect of layout complexity on human and ideal
members of the UT CS Intelligent Robotics Laboratory, and                                                      navigation performance. Journal of Vision, 1(3).
the UT Psychology Space and Shape Laboratory.                                                                Tversky, B. and Lee, P. U. (1999). Pictorial and verbal
                                                                                                               tools for conveying routes. In Freksa and Mark (1999),
                                                                  References                                   pages 51–64.
Allen, G. L. (2000).     Principles and practices for                                                        Vanetti, E. J. and Allen, G. L. (1988). Communicating
  communicating route knowledge. Applied Cognitive                                                             environmental knowledge : The impact of verbal and
  Psychology, 14(4):333–359.                                                                                   spatial abilities on the production and comprehension
Bugmann, G., Klein, E., Lauria, S., and Kyriacou, T.                                                           of route directions. Environment &Behavior, 20:667–
  (2004). Corpus-based robotics : A route instruction                                                          682.
  example. In Proc. of the Intelligent Autonomous                                                            Vizard (2003). WorldViz Vizard virtual reality software.
  System, pages 96–103, Amsterdam, The Netherlands.                                                            http://www.worldviz.com/vizard.htm.
                                                                                                          1764

