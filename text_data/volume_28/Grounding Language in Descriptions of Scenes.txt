UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Grounding Language in Descriptions of Scenes
Permalink
https://escholarship.org/uc/item/9cf2q184
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Miikkulainen, Risto
Williams, Paul
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                 Grounding Language in Descriptions of Scenes
                                                Paul Williams (pwilly@cs.utexas.edu)
                                  Department of Computer Sciences, The University of Texas at Austin
                                           1 University Station C0500, Austin, Texas 78712 USA
                                              Risto Miikkulainen (risto@cs.utexas.edu)
                                  Department of Computer Sciences, The University of Texas at Austin
                                           1 University Station C0500, Austin, Texas 78712 USA
                                Abstract                                  by machines to have directly grounded meanings as well as
                                                                          provide insight into how grounding may be accomplished by
    The problem of how abstract symbols, such as those in sys-            the human brain.
    tems of natural language, may be grounded in perceptual in-              Artificial neural network (ANN) architectures provide
    formation presents a significant challenge to several areas of
    research. This paper presents the GLIDES model, a neural              strong candidates for computational models of symbol
    network architecture that shows how this symbol-grounding             grounding. Several such architectures have been previously
    problem can be solved through learned relationships between           proposed, as will be reviewed in the following section. While
    simple visual scenes and linguistic descriptions. Unlike previ-       these models have provided many insights, the problem is by
    ous models of symbol grounding, the model’s learning is com-
    pletely unsupervised, utilizing the principles of self organiza-      no means solved. First, most of these models are based on
    tion and Hebbian learning and allowing direct visualization of        supervised learning, utilizing corrective feedback. Assuming
    how concepts are formed and grounding occurs. Two sets of             that symbol grounding is a developmental cognitive process,
    experiments were conducted to evaluate the model. In the first        it is unclear what the source of the error signals might be.
    set, linguistic test stimuli were presented and the scenes that       Second, the previous models are often opaque, i.e. difficult
    were generated by the model were evaluated as the grounding
    of the language. In the second set, the model was presented           to interpret. A model of symbol grounding should ideally
    with visual test samples and its language generation capabili-        do more than simply show that grounding can be achieved;
    ties based on the grounded representations were assessed. The         it should demonstrate how the grounding occurs and what
    results demonstrate that symbols can be grounded based on             grounding looks like on a conceptual level.
    associations of perceptual and linguistic representations, and
    the grounding can be made transparent. This transparency                 This paper presents the GLIDES (Grounding Language in
    leads to unique insights into symbol grounding, including how         DEscriptions of Scenes) model, a neural network architec-
    many-to-many mappings between symbols and referents can               ture that learns to ground linguistic descriptions into visual
    be maintained and how concepts can be formed from cooccur-            scenes. The model uses an unsupervised learning proce-
    rence relationships.
                                                                          dure based on self-organizing maps and Hebbian adaptations,
                                                                          learning associations between descriptions and scenes. It al-
                            Introduction                                  lows directly examining the representations and associations
                                                                          that are formed from the linguistic and visual inputs. The
In order to create an intelligent symbol system, symbols must             model therefore provides a unique framework for studying
be grounded in perceptual information (Harnad, 1990; Barsa-               the grounding task.
lou, 1999). Regardless of how intelligent the behavior of a                  GLIDES was evaluated in two sets of experiments. The
system seems, if its symbols depend on external interpreta-               first set assesses the model’s symbol grounding by evaluating
tion to attain meaning then it cannot be said to have achieved            the scenes it generates for linguistic test inputs of three types:
understanding. For understanding to occur, the symbols must               (1) single words/concepts, (2) complex descriptions present
have inherent meaning in terms of the system’s experiences                in the training set, and (3) complex novel descriptions. The
of the external world. In order to develop a symbol system,               second set validates the model’s grounding by evaluating its
it is therefore necessary to understand how symbols become                language generation ability when describing visual samples
grounded in their perceptual correlates (Cottrell, Bartell, &             from two test sets: (1) scenes from the training set and (2)
Haupt, 1990; Chalmers, 1992).                                             novel scenes. The results demonstrate unique insights into
    Technically, symbol grounding means establishing percep-              symbol grounding, including how many-to-many mappings
tual categories and associating these categories with abstract            between symbols and referents can be maintained and how
tokens. In order to do that, it is first necessary to determine the       concepts can be formed from cooccurrence relationships.
commonalities of all the external objects to which a symbol
refers that are distinct from attributes of objects in other cate-
gories. This process involves emphasizing the differences be-                            Prior Grounding Research
tween categories and minimizing the differences within cat-               An early solution to the symbol-grounding problem was pro-
egories, a process called “categorical perception” (Harnad,               posed by Harnad (1993), a combined connectionist/symbolic
1987). Once the boundaries of a category have been estab-                 model trained by supervised learning. Similar models have
lished, it can be associated with an abstract token, at which             been used in several studies since, successfully demonstrat-
point symbol grounding has occurred. Successfully model-                  ing the strength of connectionist learning in the grounding
ing this process computationally could allow symbols used                 task (Cangelosi, Greco, & Harnad, 2000; Riga, Cangelosi, &
                                                                     2381

Greco, 2004). Symbols can be grounded with connection-
ist networks, allowing for transfer of meaning from grounded
symbols to higher level symbols. Others have proposed that
connectionist models may be capable of learning grounding
for complex concepts and even syntactic structure (Gasser,
1993).
   A valuable touchstone task for the symbol-grounding prob-
lem was proposed by Feldman, Lakoff, Stolcke, & Weber
(1990). The task is to learn the meanings of symbols from
pairings of visual scenes and linguistic descriptions. With
minimal complexity of scenes and descriptions, this task ad-
dresses many important facets of the grounding problem. The
task allows for a vast simplification of the symbol grounding
accomplished by human infants. However, if completed suc-
cessfully, the results could provide valuable insight into how
more complex grounding is accomplished.
   Numerous studies have adopted this methodology for ex-           Figure 1: The network consists of two SOMs, a linguistic
amining grounding, several of which are discussed by Feld-          map and a visual map. The units of the maps are connected
man, Lakoff, Bailey, Narayanan, Regier & Stolcke (1996).            with many-to-many associative connections. Each unit of the
One of the most compelling models in this line of research is       maps contains a prototype formed from the inputs to the net-
the DETE architecture, an ANN model that learns relation-           work. The associative connections between the units repre-
ships between sequences of scenes and descriptions (Nenov           sent the learned relationships between linguistic and visual
& Dyer, 1993; 1994). While this model learned impres-               information. The network is able to form prototypes and learn
sive performance, it was difficult to understand how it devel-      associations from inputs in an unsupervised fashion.
oped conceptual representations, i.e. how its symbols became
grounded.
   In sum, although previous models have shown that ground-         map (SOM) is a system for unsupervised learning that maps
ing is possible, it has been difficult to show how exactly it       high-dimensional input vectors onto a two-dimensional fea-
is achieved and what the grounded representations look like.        ture map (Kohonen, 1989; 1997). The input vectors con-
This paper presents a new model with the goal of providing          tain descriptions of observations about the environment. The
such an account.                                                    map consists of an array of interconnected nodes, where
                                                                    each node i has an associated representation vector mi =
                   The GLIDES Model                                 [µi 1, µi 2, ..., µi n]T ∈ Rn . During training, an input vec-
GLIDES is a neural network architecture that accomplishes          tor x = [ξ1 , ξ2 , ..., ξn ]T ∈ Rn is compared with the repre-
symbol grounding by learning correlations between visual            sentation vectors for all map nodes in parallel and the node
scenes and linguistic descriptions. The model consists of           whose representation vector is most similar to the input vec-
two memory modules, one each for the linguistic and vi-             tor is chosen to represent the input on the map. This node
sual modalities, as well as associative connections between         is referred to as the Best Matching Unit (BMU). A standard
the two that store learned relationships (Figure 1).                Euclidean distance measure is used to determine the similar-
   This design was inspired by similar architectures that have      ity between the vectors. Once the BMU has been determined,
been used for tasks analogous to symbol grounding. In               the map is modified by updating the BMU and the nodes in its
one study, such an architecture was shown to successfully           neighborhood to reflect the new input. The reference vectors
learn associations between linguistic modalities (phonolog-         for the nodes are adjusted so that they more closely resemble
ical and orthographic) and the semantic meanings of words           the input vector. The adjustment is determined by topological
(Miikkulainen, 1997). Another study used a like architec-           distance from the BMU. The nodes are modified such that:
ture in modeling the acquisition of verb semantics (Li, 1999).           mi (t + 1) = mi (t) + α(t) · hci (t)[x(t) − mi (t)],  (1)
These models were able to form robust prototypes and learn
meaningful associations between different modalities such          where t is an integer discrete-time coordinate, α is the learn-
that they could later be used for generalization. The archi-       ing rate, and hci is a neighborhood function. The function hci
tectures also allow direct inspection of what prototypes are       determines the amount of modification for map nodes with
formed and how these prototypes are associated with each           respect to their distance from the BMU. The neighborhood
other. These properties are precisely what are needed to ac-       function used is a square area around the BMU; nodes within
complish grounding as well, as will be discussed in this sec-      a square neighborhood around the BMU are adjusted towards
tion.                                                              the input vector with a uniform learning rate.
                                                                       When the map is trained, nodes of the maps become pro-
Network Architecture                                               totypes of the input vectors. Additionally, similar inputs are
The GLIDES architecture consists of two memory modules,            mapped onto topologically proximal nodes. The result is that
one each for the linguistic and visual modalities, with as-        nodes on the maps that are close together contain prototypes
sociative connections between them. The memory modules             for similar inputs. SOM models often lead to cognitively
are implemented as self-organizing maps. A self-organizing         valid behavior, as has been demonstrated in several areas of
                                                               2382

cognition, including vision, audition, memory, decision mak-
ing, and language processing (Oja, Kaski, & Kohonen, 2001).
   In GLIDES, the two SOMs are connected to each other
with many-to-many associative connections. Each node on
one map has unidirectional connections to each node on the
other map. The strengths of these connections represent the
strength of associations between a given description and pos-          Figure 2: The visual inputs were 400-dimensional vectors
sible scenes, or conversely between a given scene and pos-             representing 20 × 20 grayscale bitmaps. The vector com-
sible descriptions. When training samples are presented to             ponents were either 0 (black) or 1 (white). The scenes had
the maps, each map node produces an activity strength. This            either one or two objects. These inputs provided the model
strength is proportional to the similarity between the input           with a significantly complex visual domain for grounding.
vector and the node’s representation vector, as determined
by Euclidean distance. The associative connections between
map nodes are then adjusted with respect to their activity
                                                                       Linguistic Descriptions
strengths, using Hebbian learning (Hebb, 1949). The connec-
tion between two nodes is strengthened proportional to their           The linguistic descriptions for the visual scenes were gener-
activity levels:                                                       ated from a 31-word vocabulary. The vocabulary contains
                                                                       words for describing attributes of individual objects (size,
                   ∆wij,uv = α(t)nS,ij nD,uv ,                (2)      shape, and position) as well as relationships between objects.
                                                                       The generative rules for scene descriptions are shown in Table
where wij,uv is the unidirectional weight between the source           1. A given scene may be described by a number of possible
map node at location (i, j) and the destination node at loca-          descriptions, and similarly there may be a number of differ-
tion (u, v), and nS,ij and nD,uv represent the activations of          ent scenes given the same description. This complex mapping
these units, respectively. Thus, the connections between si-           is a key aspect of the symbol grounding problem. There are
multaneously active nodes are strengthened. The associative            many-to-many mappings between scenes and descriptions, as
weight vectors are then normalized, which serves to decrease           is the case in the real world. In order to successfully complete
the strengths of connections to inactive units. In this way,           the task, it is necessary to learn the meanings of individual
the model is able to learn cooccurrence relationships between          symbols. This learning task amounts to categorical percep-
nodes on the different maps.                                           tion and, if successfully accomplished, allows the network to
   The model is trained by presenting complementary [scene,            generalize the meanings of the symbols to novel situations.
description] pairs to both SOMs simultaneously. The data
stored in the SOMs is modified based on the inputs and the
associative connections between the maps are updated. Af-                     Table 1: Generative Rules for Scene Descriptions
ter training, it is possible to present a description to the lin-           Description = NP | REL
guistic SOM, propagate through the associative connections,
                                                                            REL = NP relterm NP
and generate the visual scene which the network associates
with that description. Similarly, it is possible to present a vi-           NP = [size] object [position]
sual scene and view the corresponding linguistic description                object = specobj | “object”
or descriptions.                                                            relterm = “above” | “to the left of” | “inside of” | ...
                                                                            specobj = “open square” | “filled diamond” | ...
Visual Inputs                                                               size = “small” | “medium” | “large”
The visual inputs for the model were 20 × 20 grayscale                      position = “in the top left” | “on the right” | ...
bitmaps, represented by 400-dimensional vectors with each
component between 0 and 1. The visual inputs consisted
                                                                          The linguistic descriptions were represented by 31-
of one-object and two-object scenes (Figure 2). There were
                                                                      dimensional vectors, with each unit of the vector correspond-
8 types of objects used in the scenes: open squares, filled
                                                                      ing to a distinct word in the vocabulary. The vector com-
squares, open diamonds, filled diamonds, left triangles, right
                                                                      ponents were between 0 and 1. The sequential information
triangles, X’s and Z’s. The objects varied in their sizes and
                                                                      of the descriptions was represented by decaying the activa-
positions. The size of an object was described as either
                                                                      tions of the vector components linearly with respect to their
“small”, “medium”, or “large”. There were 13 possible de-
                                                                      positions in the sequences. This technique for representing
scriptions for the position of an object: “in the top left”, “in
                                                                      sequential information through activation decay was inspired
the top middle”, “in the top right”, “in the middle left”, “in
                                                                      by the SARDNET model (James & Miikkulainen, 1995).
the middle”, “in the middle right”, “in the bottom left”, “in
the bottom middle”, “in the bottom right”, “on the left”, “on
the right”, “on the top”, and “on the bottom”. Scenes with two                                  Experiments
objects presented various relationships between objects: “in-         The GLIDES model was first trained with a corpus of [scene,
side of”, “around”, “to the left of”, “to the right of”, “above”      description] pairs and its symbol grounding and language
and “below”. These dimensions for variation provided a sig-           generation abilities were then evaluated. This section de-
nificantly large set of possible scenes, making the learning          scribes the procedure for training the model, the experiments
task considerably difficult.                                          conducted with the trained model, and the results.
                                                                  2383

Training Procedure
The network was trained for 2000 epochs with 2500 training
pairs. The pairs consisted of 50% one-object scenes and 50%
two-object scenes. The descriptions were generated so that
size, shape, and position information was included in 80% of
                                                                                “in the         “filled diamond”            “x”
the samples. The idea was that the network can learn more
                                                                           bottom middle”
from a description such as “small open square on the left”
than it can from the description “object”, which lacks any                         0                     0.5                1.0
meaningful information. The training pairs were presented in
random order. The same learning rate α(t) was used for both
maps and the associative connections. The learning rate was
decreased linearly from 0.1 to 0.05 over the first 500 epochs
and then decreased linearly to 0 during the remaining epochs.
At the same time, the neighborhood size for both maps de-                      “small z           “medium right        “small object
creased linearly from 4 to 1 and then from 1 to 0.                         in the top right”          triangle        inside of large
                                                                                               above open square”      open square”
Testing Procedure                                                                  0                     0.5                1.0
During testing, a test stimulus (either linguistic or visual) was
presented to its appropriate map and the best matching unit
(BMU) was determined. The associative connections for the
BMU were then displayed. The strongest associative con-
nection for the BMU was propagated through and the corre-
sponding unit on the other map was considered the network’s              “small open square    “large filled square “small open square
response. The network’s responses were then scored subjec-                 in the top right”     in the top right”    to the right of
tively based on their relevance for the given test stimulus, as                                                        large object”
will be discussed for each experiment below.                                       0                     0.5                0.7
Experiment 1: Symbol Grounding
                                                                       Figure 3: The scenes generated by the network were assigned
In order to evaluate the symbol grounding in the model, lin-           scores between 0 and 1 in increments of 0.1 based on their
guistic test samples were presented and the scenes that the            relevance to the description. Sample scenes, descriptions, and
network generated in response were evaluated. Because vi-
                                                                       scores are shown for each of the three test sets: simple, com-
sual scenes are highly variable, there is no mechanical pro-
cedure that could be used to automatically judge how appro-            plex, and novel descriptions. The top three images are from
priate a visual scene is for a given description. Thus, the re-        the simple test set, the middle three are from the complex test
sponses can only be scored subjectively. If done systemati-            set, and the bottom three are from the novel test set. These
cally, however, such scoring can provide useful information            samples provide a sense of the scoring system that was used,
about the performance of the system. Therefore, each scene             as well as the level of performance achieved.
was assigned a score from 0 to 1 in increments of 0.1 based on
how appropriate it was for the description. Sample responses
and their corresponding scores are presented in Figure 3 to               These results indicate that the network performed best on
provide a sense for this system.                                       examples which were in its training set, as is to be expected.
   In testing, the network was presented with three groups             The network also learned the meanings of simple symbols
of stimuli: simple symbols, complex descriptions, and novel            well. Its performance on novel descriptions indicate that the
descriptions. The first group, simple symbols, consisted of            network was somewhat capable of generalizing the mean-
individual words from the network’s vocabulary. This form              ings it had learned, as indicated by the examples in Figure
of testing examined the network’s grounding of individual              3. The evaluation of the network’s performance was by ne-
concepts. The second testing set, complex descriptions, was            cessity subjective, but indicates that the network is capable of
composed of examples from the network’s training corpus.               accomplishing symbol grounding.
This form of testing examined how well the network had
learned the information it was given. For the third testing set,       Experiment 2: Language Generation
the network was presented with complex descriptions which              The second set of experiments analyzed the ability of the
it had not seen in training. This testing set examined the net-        GLIDES model to generate linguistic descriptions when pre-
work’s ability to generalize to novel stimuli.                         sented with scenes as input. The idea was to test whether
   For each of the three testing sets, 30 samples were                 the grounding was functionally adequate. If grounding was
presented. The means and standard deviations for the scores            sufficiently established the model should be able to apply its
were calculated and were:                                              knowledge about word meanings to describe novel scenes.
                                                                       The model was presented with samples from two test sets:
            Simple Symbols: µ = 0.48, σ = 0.31                         (1) scenes from the training set and (2) novel scenes.
            Complex Descriptions: µ = 0.62, σ = 0.23                      Again there is no straightforward mechanistic technique
            Novel Descriptions: µ = 0.25, σ = 0.14.                    for evaluating how appropriate the linguistic responses are.
                                                                  2384

                                                                        and position dimensions. The model was presented with 30
                                                                        test samples from each testing group: training samples and
                                                                        novel samples. To provide a sense of the scoring system,
                                                                        sample test scenes, descriptions, and their corresponding
                                                                        scores are presented in Figure 4. The means and standard
           “open square”: 0.16     “medium”: 0.13                       deviations for the scores were:
           “open diamond”: 0.43    “on the left”: 0.14
           “large”: 0.60           “in the middle”: 0.22                           Training Samples: µ = 0.64, σ = 0.24
           “small”: 0.66           “to the right of”: 0.25                         Novel Samples: µ = 0.32, σ = 0.13.
           “around”: 0.83          “small”: 0.63                           The performance, together with samples in Figure 4, shows
           “right triangle”: 1.00  “right triangle”: 0.93              that the model learned the training data well and was some-
           score: 0.8              score: 0.6                          what capable of generalizing to scenes resembling those in
                                                                       the training corpus. These results provide evidence that the
                                                                       model can ground meanings and, given sufficient training
                                                                       data, generalize them to novel situations.
                                                                       Insights on Grounded Representations
           “Z”: 0.21               “small”: 0.19                       Direct examination of representations and associations
           “small”: 0.28           “on the right”: 0.19                learned by the GLIDES model leads to interesting insights
           “open square”: 0.51     “around”: 0.22                      into how grounding is attained. One such insight is the way in
           “right triangle”: 0.54  “square”: 0.63                      which the many-to-many mappings between symbols and ref-
           “medium”: 0.73          “large”: 0.79                       erents is retained by the model. The associative connections
           “above”: 0.83           “object”: 0.93                      for a certain concept, such as “large square”, have strong links
           score: 0.2              score: 0.5                          to scenes containing large squares in different positions (Fig-
                                                                       ure 5). Another insight concerns how concepts can be learned
                                                                       from their cooccurrence. The visual responses for various lin-
Figure 4: The descriptions generated by the model were as-             guistic inputs show clearly the information that was extracted
signed scores between 0 and 1 in increments of 0.1 based on            from the training data and grounded in the concepts. As the
their relevance to the visual input. The top two scenes are im-        description of a concept becomes more specific, the associa-
ages from the training set and the bottom two are novel test           tions similarly narrow in scope and the grounded image be-
samples. The activation strengths are listed for all those that        comes more precise. In this way, the model retains concepts
were over 0.10. These samples provide a feel for the scoring           of both a coarse and fine granularity. Insights such as these
system and performance of the network.                                 have been difficult to obtain with previous models of ground-
                                                                       ing, which did not have the transparent representation of cat-
                                                                       egories and associations that GLIDES has. Such observations
For each scene, the network should ideally retain numerous             may prove valuable in future work in building grounded sys-
descriptions because many such descriptions can be deemed              tems.
appropriate. It is therefore unclear what “correct” descrip-
tion a given response should be compared against. Even if
it were possible to discern what the desired answer should
be, the encoding of sequential information in the descriptions
additionally complicates the scoring process. It does not suf-
fice to directly compare activation strengths of corresponding                        (a)                (b)
units in the response description and the “correct” description
because decreasing activation strength is used to encode se-
quential information. Therefore, the linguistic response were
scored similarly to the visual responses, using a systematic
subjective valuation based on appropriateness for a given test                        (c)                (d)
scene. The scoring system assigned values between 0 and 1
in increments of 0.1, taking into consideration the activation          Figure 5: Image (a) displays the associative connections for
strengths for appropriate words in describing a given scene             the linguistic input “large square” with the three strongest
and weighing them against strong activations for inappropri-            areas of activation identified. Images (b), (c), and (d) dis-
ate words. Additionally, if the sequence indicated by the acti-         play the strongest scenes stored for each of these activation
vation values was meaningful, the score was improved 20%.               areas. This figure demonstrates how the model is able to re-
   Due to the large number of possible scenes and computa-              tain many-to-many mappings between symbols and referents.
tional constraints with training the system, the training set
                                                                        Such visualizations have been difficult to do with previous
only covered a small portion of possible images. In order
to account for the poverty of training stimuli, the novel test          models but the two-map architecture of GLIDES makes them
samples were generated so that they overlapped with at least            explicit.
ten samples in the training set in at least two of the size, shape
                                                                   2385

              Discussion and Future Work                              Cottrell, G.W., Bartell, B., & Haupt, C. (1990). Grounding
                                                                        Meaning in Perception. Proceedings of the German Work-
The GLIDES model is a neural network architecture that
                                                                        shop on Artificial Intelligence (GWAI) (pp. 307–321).
demonstrates how symbol grounding can be accomplished
by learning relationships between visual scenes and linguis-          Feldman, J.A., Lakoff, G., Bailey, D.R., Narayanan, S.,
tic descriptions. The model learns in an unsupervised fash-             Regier, T. & Stolcke, A. (1996). L0 –The first five years
ion and allows inspecting concepts and mappings that it has             of an automated language acquisition project. Artificial In-
learned. This ability provides a unique perspective on the              telligence Review, 10(1-2), 103–129.
grounding problem that has been difficult to achieve with pre-        Feldman, J.A., Lakoff, G., Stolcke, A., & Weber, S.H. (1990).
vious models. The architecture provides a potential platform            Miniature Language Acquisition: A Touchstone for Cog-
for further investigations of symbol grounding and early lan-           nitive Science. Proceedings of the Twelfth Annual Con-
guage acquisition.                                                      ference of the Cognitive Science Society (pp. 686–693).
   A possible direction for future work is to compare the               Hillsdale, NJ: Lawrence Erlbaum Associates.
learning in the model to child language acquisition. For ex-
                                                                      Gasser, M. (1993). The Structure Grounding Problem. Pro-
ample, the network can be analyzed at different times dur-
                                                                        ceedings of the Fifteenth Annual Conference of the Cog-
ing its training to determine how well it has learned different
                                                                        nitive Science Society (pp. 149–152). Hillsdale, NJ:
concepts. These results can then be analyzed to see if the net-
                                                                        Lawrence Erlbaum Associates.
work exhibits observed phenomena from child language stud-
ies, such as the over- and undergeneralization of the meanings        Harnad, S. (ed.) (1987). Categorical Perception: The
of words. Such a study could serve to verify or falsify the net-        Groundwork of Cognition. New York: Cambridge Univer-
work as a cognitive model.                                              sity Press.
   Another possible extension is to implement a more robust           Harnad, S. (1990). The Symbol Grounding Problem. Physica
representation for sequential information. Such an extension            D, 42, 335–346.
would allow more complex scenes and descriptions to be rep-
resented and more complex phenomena to be studied, such               Harnad, S. (1993). Grounding Symbols in the Analog World
as complex grammatical constructs and moving objects. The               with Neural Nets. Think, 2, 12–78.
model could attempt to learn verbs and changes in object              Hebb, D.O. (1949). The Organization of Behavior: A Neu-
states over time. One possibility for efficiently representing          ropsychological Theory. New York: Wiley.
sequential information in both the visual and linguistic input        James, D.L. & Miikkulainen, R. (1995). SARDNET: A self-
domains would be to create SARDNET encodings of the in-                 organizing feature map for sequences. Advances in Neural
put sequences and then present those encodings to the SOMs              Information Processing Systems, 7, 577–584.
(James & Miikkulainen, 1995). Such encodings of complex
scenes and descriptions could be used to identify the limits of       Kohonen, T. (1989). Self-Organization and Associative Mem-
what can be effectively grounded in perceptual input and what           ory. New York: Springer. Third Edition.
can be more effectively represented as higher-level symbolic          Kohonen, T. (1997). Self-Organizing Maps. Berlin: Springer-
constructs.                                                             Verlag.
                                                                      Li, P. (1999). Generalization, Representation, and Recovery
                          Conclusion                                    in a Self-Organizing Feature-Map Model of Language Ac-
The GLIDES model provides a way for accomplishing the                   quisition. Proceedings of the Twenty First Annual Con-
grounding task in a straightforward and explicit manner. The            ference of the Cognitive Science Society (pp. 308–313).
model learns to associate linguistic descriptions and visual            Hillsdale, NJ: Lawrence Erlbaum Associates.
scenes in an unsupervised process, which results in trans-            Miikkulainen, R. (1997). Dyslexic and Category-Specific
parent representations for grounded symbols. Such trans-                Aphasic Impairments in a Self-Organizing Feature Map
parency provides unique insights into the grounding process,            Model of the Lexicon. Brain and Language, 59, 334–366.
and can serve as a foundation for future psychological studies
                                                                      Nenov, V.I. & Dyer, M.G. (1993). Perceptually Grounded
of grounding as well as implementations of grounded artifi-
                                                                        Language Learning: Part 1 – A Neural Network Architec-
cial systems.
                                                                        ture for Robust Sequential Association. Connection Sci-
                                                                        ence, 5(2), 115–138.
                          References
                                                                      Nenov, V.I. & Dyer, M.G. (1994). Perceptually Grounded
Barsalou, L. (1999). Perceptual Symbol Systems. Behavioral              Language Learning: Part 2 – DETE: A Neural/Procedural
   and Brain Sciences, 22, 577–609.                                     Model. Connection Science, 6(1), 3–41.
Cangelosi, A., Greco, A., & Harnad, S. (2000). From robotic           Oja, M., Kaski, S., & Kohonen, T. (2001). Bibliography of
   toil to symbolic theft: Grounding transfer from entry-               self-organizing map (SOM) papers: 1998-2001 addendum.
   level to higher-level categories. Connection Science, 12(2),         Neural Computer Surveys, 3, 1–156.
   143–162.
                                                                      Riga, T., Cangelosi, A., & Greco, A. (2004). Symbol Ground-
Chalmers, D. J. (1992). Subsymbolic computation and the                 ing Transfer with Hybrid Self-Organizing/Supervised Neu-
   Chinese room. In J. Dinsmore (Ed.), The Symbolic and                 ral Networks. IJCNN04 International Joint Conference on
   Connectionist Paradigms: Closing the Gap. Hillsdale, NJ:             Neural Networks (pp. 686–693). Budapest, July 2004.
   Lawrence Erlbaum
                                                                 2386

