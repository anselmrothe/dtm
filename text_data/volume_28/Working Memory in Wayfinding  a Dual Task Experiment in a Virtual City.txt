UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Working Memory in Wayfinding – a Dual Task Experiment in a Virtual City

Permalink
https://escholarship.org/uc/item/19j2h6sj

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Bulthoff, Heinrich H.
Knauff, Markus
Meilinger, Tobias

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Working memory in wayfinding – a dual task experiment in a virtual city
Tobias Meilinger (tobias.meilinger@tuebingen.mpg.de)
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tübingen, Germany

Markus Knauff (knauff@cognition.iig.uni-freiburg.de)
University of Freiburg - Centre for Cognitive Science
Friedrichstr. 50, 79098 Freiburg, Germany

Heinrich H. Bülthoff (heinrich.buelthoff@tuebingen.mpg.de)
Max-Planck-Institute for Biological Cybernetics
Spemannstr. 38, 72076 Tübingen, Germany
(cf. Denis 1997), the wayfinding should involve resources
of the PL and thus interfere with a verbal secondary task. If
the wayfinding knowledge is represented and processed in
visuo-spatial format, it should rely on the VSSP. However,
recent studies indicate that the VSSP itself has two
subcomponents—one visual and one spatial (e.g., Klauer &
Zhao, 2004; McConnell & Quinn, 2000). We therefore
applied two visuo-spatial secondary tasks. One secondary
task focused more on the visual component, the other one
focused more on the spatial component of the VSSP. If the
wayfinding knowledge is represented and processed in a
“picture-like” format e.g., in a snapshot of the environment
(Mallot & Gillner, 2000) or a map, it should rely on the
visual component of the VSSP and thus interfere with a
visual secondary task. If wayfinding relies on more abstract
spatial representations and processes, e.g., the geometric
layout of an environment (Cheng, 1986; Gallistel, 1990), it
should involve the spatial component and interfere with a
spatial secondary tasks. The goal of the present paper is to
test these competing hypotheses.

Abstract
This study examines the working memory systems involved
in human wayfinding. In the learning phase 24 participants
learned two routes in a novel photorealistic virtual
environment displayed on a 220° screen, while they were
disrupted by a visual, a spatial, a verbal or - in a control group
- no secondary task. In the following wayfinding phase the
participants had to find and to “virtually walk” the two routes
again. During this wayfinding phase a number of dependent
measures were recorded. We show that encoding wayfinding
knowledge interfered with the verbal and with the spatial
secondary task. These interferences were even stronger than
the interference of wayfinding knowledge with the visual
secondary task. These findings are consistent with a dual
coding approach of wayfinding knowledge.

Introduction
“…it seems plausible to assume that the [visuo-spatial]
sketchpad might have a role […] for spatial orientation
and geographical knowledge. So far, there seems to
have been little work on this potentially important
topic.” (Baddeley, 2003, p. 834)

Methods

The role of working memory in spatial orientation has rarely
been explored. Still, is the intuitive impression true that the
visuo-spatial sketchpad is so important? If so, is it the visual
or more the spatial component of this subsystem that is
linked to wayfinding? And how important is the processing
of verbal information if humans find their way in known or
new environments? In the quotation Baddeley refers to his
working memory theory, in which short-term maintenance
of information is achieved by the phonological loop (PL),
which is responsible for verbal information, the visuospatial sketch pad (VSSP), handling visual and/or spatial
information, and the central executive which is described as
a supervisor responsible for the coordination of the
subsystems and the selection of appropriate reasoning and
storage strategies (Baddeley, 2003; Baddeley & Hitch,
1974).
So, which subsystem of working memory is essential in
human wayfinding? If wayfinders process the wayfinding
information in a verbal format, e.g., in the form of verbal
directions such as “next left”, “at the church to the right”

We used a virtual environment displayed on a 220° screen.
The participants learned two different routes through
“Virtual Tübingen” a photorealistic model of the medieval
city centre of Tübingen (see Figure 1). During this learning
phase they were disrupted by a visual, a spatial, or a verbal
secondary task. In the control condition, no secondary task
was given. In the following wayfinding phase the
participants had to find and to “virtually walk” the two
routes with a joystick. During this wayfinding phase a
number of dependent measures were recorded. Secondary
task performance was recorded during the learning phase.
Note that the secondary task was applied to the learning and
encoding phase and the performance measures were
collected during the wayfinding, i.e. when the participants
had to remember what they had learned in the learning
phase. In this way we could measure to which degree the
secondary task interfered with the encoding and
maintenance of wayfinding knowledge, while the
wayfinding itself was not disrupted by any secondary task.

585

consisted of nine mainly 90° intersections, with 21 possible
choices (for further discussion of these routes see Meilinger
& Knauff, submitted). Presentation of the long route took
240 seconds; the short route took 160 seconds. The order of
presentation of the routes was controlled.
While the participants learned a route they were
confronted with one of the secondary tasks. They were
randomly assigned to one of four conditions: the verbal
secondary task, the visual secondary task, the spatial
secondary task and the control group where no secondary
task had to be completed. This resulted in six participants
per group. All three secondary tasks were presented via
headphones with active noise cancellation. The participants
had to respond by pressing a button on a response box.
In the verbal task, the participants had to perform a
lexical-decision task. They had to decide whether a
presented word existed in German or not. All 100 German
nouns consisted of two syllables and were among the 10000
most frequent German words published in newspapers or
magazines (Quasthoff, 1998). The 100 non-words not
existing in German language were constructed from the 100
words by exchanging the vowel of the first syllable e.g.,
“Montag” was changed to “Mintag”. Each vowel was
equally often used in the words as well as in the non-words.
Therefore 100 non-words paralleling 100 words were
constructed. They were spoken by a television speaker,
recorded via microphone and cut into 200 sound files with
the start of the file matching the onset of the vocalisation.
In the visual task the participants heard times and had to
imagine a clock with watch hands. E.g., at “six o’clock” the
short watch hand points downwards, the long watch hand
upwards. If the clock is divided in an upper and a lower
half, both watch hands point into different halves. At
“twelve o’clock” or “twenty past four” both watch hands
point into the same half. The participants had to indicate
whether the watch hands point to the same or to different
halves. All possible times in steps of five minutes were used
e.g., 11:55 with times in the third or ninth hour e.g., 3:10
and times a quarter to or after an hour e.g., 5:45 excluded as
at these times the watch hands could not easily be classified
as pointing upwards or downwards. The resulting 100 times
of day again were spoken by a television speaker, recorded
.

Figure 1: A snapshot of Virtual Tübingen.

Participants
Twelve female and twelve male participants, mainly
students between 19 and 32 (M = 24; SD = 4) participated in
the experiment which took place in Tübingen. None of them
had visited Tübingen before. In travelling to the experiment
no part of Tübingen used in the experiment could be seen.
All selected participants were German native speakers and
were paid for their participation. Two of original 26
participants did not complete the experiment due to
simulator sickness and were therefore excluded from all
subsequent analysis.

Procedure, Apparatus, and Materials
The experiment was separated into two phases. In the
learning phase the participants were acquainted with two
routes (see below). In the wayfinding phase they had to
walk these ways by using a joystick. In both phases, the
participants were sat on a chair positioned 3.5 metres from a
circular 220° screen (width: 13m, height: 3m), which
covered the whole horizontal visual field (see Figure 2). A
pc-cluster rendered the projection for an eye position 1.20
meter above the ground referring to average eye-height in
when seated. The frame rate was 60Hz using 2 x hardware
anti-alising and hardware soft-edge blending to display the
images on the curved screen. Three projectors with a
resolution of 1024 x 768 each projected the pictures. Note
that learning and wayfinding phases for each route followed
one another immediately, i.e. the learning phase for the first
route was immediately followed by the wayfinding phase
for the first route etc.
Learning Phase In the learning phase the participants were
passively carried on two routes through virtual Tübingen.
The transportation speed was two metres per second
corresponding to a fast walking speed. The two routes
presented in Figure 3 were the same as those used in a
previous study conducted in “Real Tübingen” (Meilinger,
2005; Meilinger & Knauff, submitted). The 120 m ‘long
route’ consisted of ten mainly oblique intersections with 23
possible choices. With a length of 80 m the short route

Figure 2: The experimental setup.
586

translation speed was two metres per second. In order to
reduce simulator sickness the participants were not able to
rotate faster than 30° per second. All relevant parameters
were recorded with approximately 100 Hz in order to
compute (1) the time from the first movement to reach the
goal, (2) the traversed distance, (3) the number of stops and
(4) the number incidents when participants got lost. Stops
were counted if they at least lasted one second and if they
started at least one second after a previous stop. A
participant was considered to be lost when turning into a
wrong street and hitting an invisible wall, which was located
at about five meters after entering the wrong street. In this
case the participant had to turn around. From these four
parameters getting lost was the most important, because in
real settings each incident of taking a wrong direction can
result in a much longer distance and time to reach the goal
or even in not reaching the goal at all. Distance and getting
lost correlated by .89 (n = 24, p < .001). So both measures
almost showed identical results and therefore only getting
lost, stops and time are reported.
Prior to the experiment, the participants were familiarized
with the virtual reality setting and the joystick. They
navigated around in a small area of Virtual Tübingen not
encountered during the rest of the experiment. This also
included an invisible wall indicating a wrong choice of route
later in the experiment.

via microphone and cut into sound files with the start of the
file matching the onset of the vocalisation. The participants
were explicitly instructed to solve the tasks by imaging the
clock.
In the spatial task the participants had to indicate the
direction a sound was coming, either from the left, the right
or the front, by pressing one of three corresponding keys.
The pleasant sound of a wooden temple block was used for
that. The sound was spatialised using a “Lake DSP Card”,
with which the sound source can be accurately positioned in
space, both in terms of angle and distance to the listener,
using a generic Head Related Transfer Function (HRTF).
Again, the sound files started with the onset of the sound.
To ensure that the secondary tasks interfered with the
encoding of environmental information the task difficulties
had to be identical. Therefore, the trial durations were
adjusted in within-subject pre tests, so that failing to react
fast enough was considered an error. The trials followed
immediately after each other with no break in between.
Very fast reactions in any trial were ignored, as they
possibly were initiated during the last trial. Within-subject
pre-tests with 18 participants led to trial durations of 1.2
seconds in the verbal, 4 seconds in the visual and 0.8
seconds in the spatial task. The corresponding hit rates in
the pre-tests were 86% for the verbal, 85% for the visual
and 87% for the spatial task. The task difficulty was
assessed the same way as in the baseline condition of the
main experiment, that is while presenting a video showing a
walk up and down a street for several times. The area of
Virtual Tübingen used for the baseline was not encountered
during the rest of the experiment. The participants’ task was
to keep their eyes open and do the choice reaction task as
fast and accurate as possible. In the main experiment all
participants, including participants from the control group
without the secondary task, had to watch this presentation.
The baseline lasted 200 seconds. This is the average of the
160 seconds for presenting the short route and the 240
seconds for presenting the long route. All secondary tasks
were presented in random order with accuracy and reaction
time recorded. For the visual and the verbal task the
positions of the buttons were selected randomly for each
participant. Prior to the baseline the participants trained the
secondary task for several minutes.

Results
For the statistical analysis values deviating more than three
standard deviations from the overall mean were replaced by
the most extreme value inside this interval. For group
differences one-way ANOVAS for performance over both
routes were computed followed by planned contrasts
between the experimental groups. Additionally, t-tests
accounted for differences due to gender, the order of routes
and dependent differences between the two routes.

Wayfinding Performance
No differences for the order of route presentation could be
found (time: t(22) = 0.18, p = .863, effect size d = 0.037; got
lost: t(22) = 0.32, p = .752, d = 0.065; stops: t(16.7) = 0.46,
p = .654, d = 0.094). The data was collapsed across both
orders for the further analysis.
The main effect of secondary tasks on wayfinding
performance is shown in Figure 4. The groups differed in
their frequency of getting lost (ANOVA F(3, 20) = 5.43, p =
.007; η2 = 0.45). The single contrasts show that the spatial
secondary task influenced the encoding of environmental
information used for wayfinding compared to the control
group (t(20) = 3.05, p = .006, d = 0.62). Also the verbal
secondary task had an influence (t(20) = 3.78, p = .001, d =
0.77). The visual secondary task had no general significant
influence compared to the control group (t(20) = 1.89, p =
.074, d = 0.39).
We also compared the groups performing a secondary
task with each other. As seen in Figure 4 the verbal
secondary task had a bigger influence than the visual

Figure 3: Maps of the long route (left) and the short route
(right).
Wayfinding Phase In the wayfinding phase participants
had to walk the two routes by using a joystick to control for
heading and forward translation speed. The maximal
587

Getting lost [n]

secondary task. This difference attained significance on the
short route (t(20) = 2.55, p = .019, d = 0.52), but not on the
long route (t(20) = 0.59, p = .571, d = 0.12). From visual
inspection the spatial secondary task had a bigger influence
than the visual secondary task. This effect nearly attained
statistic significance on the short route (t(20) = 2.03, p =
.056, d = 0.41; long route: t(20) = 0.20, p = .840, d = 0.041).
We found no differences between participants with a spatial
and a verbal secondary task (t(20) = 0.73, p = .476, d =
0.15). There were no effects for time (F(3, 20) = 2.21, p =
.118; η2 = .25) and stops (F(3, 20) = 0.80, p = .510; η2 = .11)
which excludes a speed accuracy trade-off as an explanation
for our results.
8
7
6
5
4
3
2
1
0

difficulty. There was also no main effect of secondary task
during encoding (see right hand side of Figure 5; F(2, 15) =
3.12, p = .074; η2 = 0.29). No trade-off between main and
secondary task, therefore, could explain the results. The
direction of the contrasts even point into the same direction
as in wayfinding performance: The accuracy in the visual
task was higher compared to the spatial task (t(15) = 2.45, p
= .027, d = 0.58). The accuracy in the visual task compared
to the verbal task showed the same pattern of results, but did
not reach significance (t(15) = 1.66, p = .118, d = 0.39). No
differences between the spatial and the verbal task were
found (t(15) = 0.79, p = .444, d = 0.19).
There was no gender effect in secondary task
performance. Neither in the baseline (t(16) = 1.51, p = .151,
d = 0.36) nor during encoding of the route (t(16) = 0.90, p =
.929, d = 0.21). There was also no difference between the
routes (t(17) = 0.22, p = .829, d = 0.052).

Wayfinding
performance

Discussion

None

Visual Spatial
Secondary task

The present study examined the working memory systems
relevant for wayfinding. A verbal task put additional load on
the PL. A visual and a spatial secondary task were used to
put additional load on the VSSP, and to distinguish between
the visual and spatial components of this subsystem. The
main finding of the study is that the verbal and the spatial
secondary task interfered with wayfinding performance.
First, they interfered compared to a control group. In
contrast, the visual secondary tasks only had mild effects on
wayfinding performance. Second, the verbal and the spatial
secondary task also interfered stronger than the visual
secondary task. For the verbal secondary task this was found
in wayfinding performance on the short route. For the
spatial secondary this was found in secondary task
performance. These results cannot be explained by a
performance shift between first and secondary task, as
participants with the visual secondary task performed better
in wayfinding and in the secondary task compared to
participants with the verbal or the spatial secondary task.
So, what is the relation between human wayfinding and
the modality specific systems in Baddeley’s working
memory theory? Overall, both the PL and the VSSP seem to
be involved in the encoding of environmental information
used for wayfinding. The involvement of the PL indicates
that the wayfinders use a kind of “verbal encoding” when
they learn a route. As Denis (1997) argued they might use
verbal directions such as “next left”, “at the church to the
right”. In our experiment, producing such directions is
inhibited by the verbal secondary task leading to worse
performance during wayfinding. Participants without verbal
secondary task could use such verbal directions. This is also
supported by a questionnaire that had to be answered after
the experiment. In this questionnaire the verbal strategy of
rehearsing route directions correlated highest with good
wayfinding performance (n = 24; getting lost: r = .49, p =
.016; time: r = .44, p = .034; stops: r = .55, p = .006). The
availability of various landmarks in our realistic setting
might have eased encoding the routes verbally. However,

Verbal

Figure 4: Getting lost per person on both routes as a
function of the secondary task during encoding. Means and
standard deviations are shown.

Secondary Task Performance
One possible explanation for our findings could be that the
differences in the main tasks are only due to differences in
the secondary tasks. To rule out this explanation we
conducted a further analysis over the secondary tasks during
learning., Overall, the three groups with secondary tasks did
not differ in accuracy on the baseline measure taken before
the main experiment (see left hand side of Figure 5; F(2, 15)
= 1.68, p = .220; η2 = 0.18). As in the pre-tests the
secondary tasks were comparable with regard to their
..
1

Secondary task performace

Accuracy

0,8
0,6
0,4
0,2
0
Visual Spatial Verbal
Baseline

Visual Spatial Verbal
During encoding

Figure 5: Accuracy in the secondary tasks during baseline
(left) and during encoding of the routes the participants had
to walk immediately afterwards (right).
588

performance levels for map instruction and verbal directions
can be explained.
In reorientation research the dual-coding approach can
provide an alternative interpretation for the empirical
findings. The debate mainly focused on the question of
whether language processes were necessary to combine
geometric and feature information – in our terms spatial and
visual information - as proposed by Hermer-Vasquez,
Spelke and Katsnelson (1999). For example, they showed
that adults generally use both geometric and feature
information unless they are disturbed by a verbal shadowing
task where they have to immediately repeat words from a
text presented via headphones. This interference does not
occur during clapping a rhythm or repeating syllables. The
assumption that language is necessary for combining
geometric and feature information, however, is questioned
by the finding that primates, birds and even fish are able to
accomplish this (e.g., Gouteux, Thinus-Blanc & Vauclair,
2001; Sovrano, Bisazza & Vallortigara, 2002). Also, the
shadowing effects of language do not occur when the adults
receive a training trial and more explicit instructions
(Ratkliff & Newcombe, 2005). Our dual-coding approach
assumes spatial (geometric) and visual (feature) information
to be additionally coded in verbal format. It can explain the
usefulness of language, without assuming language to be
necessary for reorientation. It also explains the boost in
reorientation performance within children around the ages
of five and six years regarding their emerging spatial
language abilities e.g., verbal expressions involving the
terms “left” and “right” (Hermer-Vazquez, Moffett &
Munkholm, 2001; Learmonth, Nadel & Newcombe, 2002).
Another recent explanation about this issue focuses on
hemispheric crosstalk as a prerequisite for combining
geometric and feature information (Newcombe, 2005). In
the present form this approach does not explain why a
verbal secondary task would inhibit hemispheric crosstalk as
found in our experiment and by Hermer-Vasquez et al.
(1999), whereas a visual secondary task or repeating only
syllables would not inhibit hemispheric crosstalk.
The dual-coding approach can explain several results in
our experiment and other areas of spatial orientation
research. Are there alternative explanations for our results?
Contrary to the pre-tests, the spatial secondary task showed
a numerically higher difficulty than the baseline. The better
performance in the visual compared to the spatial secondary
task might therefore stem from a higher difficulty of the
spatial secondary task and not from the higher importance of
the spatial memory. This alternative explanation, however,
does not contradict the dual-coding approach and it can not
account for the importance of verbal memory.
We can not completely rule out that our effects were due
to a different encoding strategy i.e. participants with a
verbal secondary task were forced to rely on a potentially
less efficient visual encoding strategy. In this case
participants could, however, also rely on a spatial encoding
strategy. With each secondary task the participants always
could apply two alternative strategies. We think, therefore,

learning these routes from a map without landmark would
also suggest verbal encoding (Meilinger & Knauff,
submitted).
Not only the PL, but also the VSSP was involved in
wayfinding. However, it is a novel finding that an effect was
found for the spatial, but not for the visual secondary task
(cf. Garden, Cornoldi, & Logie, 2002). Participants with the
visual secondary task performed better than participants
with the spatial secondary task. The spatial component of
the VSSP seemed to be more important than the visual one.
This points towards a higher importance for abstract spatial
features like the geometry of an environment compared to
mere visual surface features as proposed by Cheng (1986)
and Gallistel (1990). It also points against heavy reliance on
pictorial information in form of snapshots of the
environment (Mallot & Gillner, 2000) or in form of a map
as seen from birds eye view.
Our results show that environmental information is not
encoded in one single memory system, i.e. representational
format. The participants used spatial and verbal memory
components for encoding wayfinding knowledge. These
findings are in accordance with the assumption that similar
representations are built from direct experience and textual
descriptions (cf. Taylor & Tversky, 1992). The findings
extend this position by showing that more than just one
representation is involved. This fits nicely with the dualcoding approach of human wayfinding (Meilinger &
Knauff, submitted). The account is inspired by Paivio’s
(1971) dual coding theory. It assumes that environmental
information is encoded not only in visual or spatial format
but also in verbal format. Our data suggests that during
learning, the environmental information is at least in parts
re-coded into verbal directions like “2nd right, at the church
to the left”. However, our findings also suggest that
participants represent the environmental information in a
non-verbal format, too. This representation primarily
accounts for spatial information, while visual features of the
environment seem to play only a marginal role in the
corresponding mental representations. In the following we
want to show that the dual coding approach of human
wayfinding not only explains our data, but also fits nicely
with many other findings reported in the literature on
wayfinding and reorientation.
In wayfinding Garden et al. (2002) found similar
performance levels in participants who learned and retraced
a route either during a visuo-spatial or a verbal secondary
task. As in the present study, the dual coding approach
predicts encoding this route in a spatial and a verbal format.
Equal interference levels are therefore expected. In
wayfinding with maps and directions several studies found
similar wayfinding performance for both wayfinding aids
(Meilinger & Knauff, submitted; Pazzaglia & De Beni,
2001; Schlender, Peters, & Wienhöfer, 2000). According to
the dual-coding approach the participants additionally
encoded the map in a verbal format that is verbal directions.
If they also focused on these verbal directions, the similar

589

that a more consistent explanation of our results involves
different memory systems. An open question remains
whether an effect would be obtained when applying a motor
secondary task e.g., finger tapping.
Another result of our experiment showed males to
perform slightly better in wayfinding than females. This
result is well in line with many in other experiments (for a
recent review see Coluccia & Louse, 2004).

Gouteux, S., Thinus-Blanc, C., & Vauclair, J. (2001).
Rhesus monkeys use geometric and nongeometric
information during a reorientation task. Journal of
Experimental Psychology: General, 130, 505-519.
Hermer-Vasquez, L., Spelke, E.S., & Katnelson, A.S.
(1999). Sources of Flexibility in Human Cognition: DualTask Studies of Space and Language. Cognitive Psychology,
39, 3-36.
Hermer-Vazquez, L., Moffet, A., & Munkholm, P.
(2001). Language space, and the development of cognitive
flexibility in humans: The case of two cognitive memory
tasks. Cognition, 79, 263-299.
Klauer, K., & Zhao, Z. (2004). Double dissociations in
visual and spatial short-term memory. Journal of
Experimental Psychology, 133, 355-381.
Learmonth, A. E., Nadel, L., & Newcombe, N. S. (2002).
Children’s use of landmarks: Implications for modular
theory. Psychological Science, 13, 337-341.
Mallot, H.A., & Gillner, S. (2000). Route navigation
without place recognition: What is recognized in
recognition-triggered responses? Perception, 29, 43-55.
McConnell, J., & Quinn, J.G. (2000). Interference in
visual working memory. Quarterly Journal of Experimental
Psychology, 53A, 53-67.
Meilinger, T. (2005). Wayfinding with maps and verbal
directions. Proceedings of the 26th Annual Conference of
the Cognitive Science Society.
Meilinger, T., & Knauff, M. (submitted). Ask for your
way or use a map: A field experiment on spatial orientation
and wayfinding in an urban environment.
Newcombe, N. (2005). Evidence for and against a
geometric module: The roles of language and action. In J.
Rieser, J. Lockman, & C. Nelson (Eds.), Action as an
organizer of learning and development. Minnesota
Symposium on Child Development Series: Lawrence
Erlbaum Associates.
Pazzaglia, F., & De Beni, R. (2001). Strategies of
processing spatial information in survey and landmarkcentred individuals. European Journal of Cognitive
Psychology, 13, 493-508.
Paivio, A (1971). Imagery and verbal processes. New
York: Holt, Rinehart, & Winston.
Ratkliff, K.R., & Newcombe, N.S. (2005). Human Spatial
Reorientation using Dual Task Paradigms. Proceedings of
the 26th Annual Conference of the Cognitive Science
Society.
Schlender, D., Peters, O.H., & Wienhöfer, M. (2000). The
effect of maps and textual information on navigation in a
desktop virtual environment. Spatial Cognition and
Computation, 2, 421-433.
Sovrano, V., Bisazza, A., & Vallortigara, G. (2002).
Modularity and spatial reorientation in a simple mind:
encoding of geometric and nongeometric properties of a
spatial environment by fish. Cognition, 85, B51-B59.
Taylor, H.A. & Tversky, B. (1992). Descriptions and
depictions of environments. Memory & Cognition, 20, 483496.

Conclusions
As Baddeley (2003) pointed out, little work has been done
on the role of the VSSP in spatial orientation. This
experiment is a small step towards changing this situation.
On the one side, our results point towards a further
differentiation of the VSSP into spatial and visual
subsystems in the context of spatial orientation, with the
spatial subsystem being involved more strongly. On the
other side, our results highlight the involvement of the PL
for spatial orientation. Although PL and VSSP might have
developed for different demands posed from our
environment, we seem to leverage both of them in order to
solve our tasks in experimental situations as well as in daily
life. The dual-coding approach aims to reflect this
incorporation of both systems.

Acknowledgments
This research was supported by grants to M.K. from the
DFG (German National Research Foundation) in the
Transregional Collaborative Research Center, SFB/TR 8
project and by the EU grant “Wayfinding” (6th FP - NEST).
The authors thank Anna Widiger for help in data collection
and processing, Michael Weyel for support in programming,
Hans-Günther Nusseck, Harald Teufel and Benjamin Turski
for the virtual reality environment, Franck Caniard for
spatialising the sounds, Bernhard Riecke for discussing
ideas and Lara Webber for proofreading.

References
Baddeley, A. (2003). Working memory: Looking back
and looking forward. Nature Reviews Neuroscience, 4, 829839.
Baddeley, A. D., & Hitch, G. J. (1974). Working memory.
In G.A. Bower (Ed.), The Psychology of Learning and
Motivation Vol. VIII. New York: Academic Press.
Cheng, K. (1986). A purely geometric module in the rat’s
spatial representation. Cognition, 23, 149-178.
Coluccia, E., & Louse, G. (2004). Gender differences in
spatial orientation: A review. Journal of Environmental
Psychology, 24, 329-340.
Denis, M. (1997). The description of routes: a cognitive
approach to the production of spatial discourse. Current
Psychology of Cognition, 16, 409-458.
Gallistel, C.R. (1990). The organisation of learning.
Cambridge, MA: MIT Press.
Garden, S., Cornoldi, C., & Logie, R.H. (2002). VisuoSpatial Working Memory in Navigation. Applied Cognitive
Psychology, 16, 35-50.
590

