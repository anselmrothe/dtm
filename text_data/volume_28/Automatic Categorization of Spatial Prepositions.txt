UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic Categorization of Spatial Prepositions
Permalink
https://escholarship.org/uc/item/5287598r
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Forbus, Kenneth
Halstead, Daniel T.
Lockwood, Kate
et al.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                             Automatic Categorization of Spatial Prepositions
                                        Kate Lockwood (kate@cs.northwestern.edu)
                                          Ken Forbus (forbus@northwestern.edu)
                                   Daniel T. Halstead (halstead@cs.northwestern.edu)
                                        Jeffrey Usher (usher@cs.northwestern.edu)
                            Qualitative Reasoning Group, Northwestern University, 2145 Sheridan Rd
                                                      Evanston, IL 60208 USA
                            Abstract                                 allowing users to conceptually label the glyphs in a sketch.
                                                                     We use this conceptual information along with visual
   Learning spatial prepositions is an important problem in          properties of the ink itself to focus on understanding the
   spatial cognition. We describe a model for learning how to        relationships in the sketch. The possibilities for conceptual
   classify visual scenes according to what spatial preposition
                                                                     labels are limited only by the underlying database (currently
   they depict. We use SEQL, an existing model of analogical
   generalization, to construct relational descriptions from         a subset of the Cyc database containing over 35,000
   stimuli input as hand-drawn sketches. We show that this           concepts). In addition to the conceptual label, users can
   model can distinguish between in, on, above, below, and left,     give each glyph a name to reference it by. Basic qualitative
   after being trained on simple sketches exemplifying each          spatial relationships are extracted from the ink in the sketch
   preposition.                                                      (Forbus, Tomai & Usher, 2003). In sKEA, the frame of
                                                                     reference is also specified by allowing the user to select the
                         Introduction                                view of the sketch (i.e., “looking from side”, “looking from
Spatial reasoning is a skill central to many human tasks, as         another object”).
is being able to communicate about space. One way we                    We previously used sKEA as input into SpaceCase, a
share spatial information is through the use of prepositions         Bayesian model that assigned prepositions to individual
to describe relationships between entities in the world.             sketches (Lockwood, Forbus, & Usher, 2005). In that
These utterances involve at minimum two objects: a                   model, update rules fired based on properties in the sketch
reference object (the ground) and a located object (the              such as animacy of the ground and figure objects. In that
figure) as well as the preposition that describes their              work, the rules were motivated by results from
relationship. The set of spatial prepositions in English is          psychological studies indicating what properties of scenes
quite small when compared with other word categories;                were important for preposition assignment.             In the
however computationally modeling the assignment of                   experiments described here, we use sKEA to automatically
preposition labels to visual scenes remains a difficult and          compute a set of spatial relationships from sketches. These
important problem.                                                   relationships are suggested by, and consistent with, those
   Many recent psychological studies have focused on                 features which have been shown to influence spatial
understanding which properties of the figure and ground              preposition judgments with human subjects. Analogical
objects play a role in the assignment of spatial prepositions.       generalization is used to automatically create groupings
Some of the properties studied are extracted directly from           based on the features we have extracted.                  The
the spatial arrangement of objects and surface features.             generalizations created group the sketches together based on
Spatial language has garnered so much attention since it is          the relationship (in, on, above, below, and left) between the
considered to be an important organizing structure for               two objects.
conceptual information (Talmy, 1983). Studies have also
shown that children learn how to use spatial language                               Analogical Generalization
through interactions with objects in the world and without
negative evidence.                                                    We use SEQL (Skorstad, Gentner, & Medin, 1988; Kuehne,
   In this paper, we automatically categorize simple two-             Forbus, Gentner, & Quinn, 2000) as our model of
dimensional geometric sketches based on the preposition               categorization. SEQL is a computer model of category
that would best describe them. Sketching is particularly              learning that is based on Gentner’s (1983) structure-
suited to studying this domain as our understanding of                mapping theory of analogy and similarity. In SEQL
spatial terms is grounded in perception. Perceptual features          categories are created through a process of successive
can be automatically computed using sketching systems,                comparison with incoming exemplars. The comparisons are
thus removing a source of tailorability in modeling. For              carried out with SME, the Structure-Mapping Engine
these experiments, we used sKEA (Forbus, Ferguson &                   (Falkenhainer, Forbus & Gentner, 1986; Forbus, Ferguson
Usher, 2001), the first open-domain sketching system.                 & Gentner, 1994).           For each category, a set of
sKEA sidesteps traditional recognition problems by                    generalizations and exemplars is maintained. Each new
                                                                 1705

exemplar that arrives is compared against existing                  focusing on simple two-dimensional geometric shapes. The
generalizations. If the comparison is very close, i.e. over a       sketches for above and on were taken in part from examples
given threshold, the exemplar is merged into the                    provided in Regier (1995). Other sketches for left and
generalization and the generalization is replaced with the          above were created based on information from Gapp
overlap between them. If it is sufficiently similar to an           (1995a, 1995b), whose experiments explored the effect of
existing exemplar, the overlap between the two exemplars is         distance and shape (extent)/size of the ground in judgments
stored as a new generalization. Finally, if the incoming            of applicability for projective spatial relationships. The
exemplar is not similar enough to any of the existing               sketches were also informed by a variety of experiments that
generalizations, it is maintained as a separate exemplar.           discuss limitations on regions of acceptability for
   The determination of “similar enough” is controlled by           prepositions, such as Logan and Sadler (1996) and Regier
the match threshold parameter, which is 1.0 when the two            and Carlson (2001).
descriptions are identical. If this threshold is too high, it is
difficult to find any exemplars that are similar enough to          Visual Processing. Initial processing is done on the sketch
create generalizations. If too low, then the generalizations        to extract visual information from the ink. This information
created are meaningless. Previous experiments suggest that          is meant to approximate high-level visual processing. For
a match threshold between 0.75 and 0.9 tends to yield the           example, RCC-8 relations (Cohn, 1996) are computed
most useful results.                                                between the objects in the sketch to determine topological
   SEQL can now use probabilities in producing                      relationships such as touching (RCC8-EC) and inside (RCC8-
generalizations (Halstead & Forbus, 2005).                When      nTPP). We use these qualitative spatial relations as one
generalizations are created or extended, the union of the           source of perceptually salient relationships in the sketches.
descriptions is used, with the probability of an expression             sKEA automatically computes a variety of other
being in the generalization calculated by the frequency of          qualitative spatial relationships from the ink. For example,
occurrence in the exemplars that make up the generalization.        spatial processing identifies groups of glyphs that form
                                                                    connected glyph groups and contained glyph groups. In the
                  Experimental Design                               latter case it also specifies which glyph acts as the container
                                                                    and which acts as the insider. sKEA computes positional
Experiment 1                                                        relations (i.e., above and to the right of between all pairs of
                                                                    glyphs in a sketch that are disjoint from each other.
Input. Input was provided as sketches created using sKEA.
                                                                        Our model does some minimal additional processing
Each sketch contained two geometric shapes named
                                                                    based on the spatial relationships computed from the sketch.
figure/ground and conceptually labeled with their common
                                                                    For example, positional relations are always computed with
shape names (for example, in figure 1 below, the square was
                                                                    the figure in the first argument and the ground in the second
named figure and conceptually labeled “square”). The
                                                                    argument, i.e., (above ground figure) would be translated
shapes used were circles, triangles, rectangles, and squares.
                                                                    to (below figure ground)1. For each sketch, this visual
                                                                    information and any conceptual information about the
                                 Figure 1. An example of
                                 the sketched input used in         objects in the sketches is recorded as an exemplar.
                                 this experiment.                   Unnecessary information, like bookkeeping facts
                                                                    representing specifics of our implementation, are filtered out
                                                                    since we do not view them as psychologically relevant. All
                                                                    filtering and processing procedures were done over the
                                                                    entire case library of sketches. Individual sketches were
                                                                    never singled out for specific processing.
   In the first experiment the library of sketches used
contained 50 sketches. Each sketch was designed to be a             Classification. All 50 sketch cases were run through
good example of one of five spatial prepositions: in, on,           SEQL, using a match threshold of 0.9. Our goal in doing
above, below, or left, with 10 sketches created for each            these experiments is to see whether we can achieve human-
preposition. By “good example” we mean that it would be             like classification results automatically, and what specific
easily and unequivocally recognized as a good                       sets of relationships are needed to do so.
representative of the English use of that preposition. For
example, in all of the in sketches, the figure object was
smaller than the ground object and the figure object was
completely enclosed in the boundary of the ground object.            1
                                                                       Above as computed by sKEA is very different from its English
Each preposition had examples containing different shapes            language counterpart. The spatial relationship above in sKEA is
in the ground and figure roles. All sketches were 2D and             derived by comparing the relative positions of the centers of area
drawn from the same side view perspective.                           of the bounding boxes of the glyphs. This alone is not enough
   The sketches were drawn from stimuli in the                       information to parse different prepositions. For example, the
psychological literature studying spatial prepositions,              positional relationship above shows up in the generalizations for
                                                                     both above and on.
                                                                1706

Results. The fifty simple sketches were classified into the              Relationship                           Categories
five generalizations expected (corresponding to in, on,                  Horizontal enclosure                   below, above, on
      (enclosesHorizontally ground figure)                               Vertical enclosure                     left
      (connectedGlyphGroupTangentialConnection                           Left of                                left
                figure ground)                                           RCC8-DC (disjoint)                     below, above, left
      (connectedGlyphGroupTangentialConnection                           Above                                  above, on
                ground figure)                                           Below                                  below
      (rcc8-EC figure ground)                                            Above Grazing Line                     above
      (above figure ground)                                              Below Grazing Line                     below
                                                                         Contained Glyph Group                  in
      Figure 2. The SEQL generalization created for the
                                                                         RCC8-NTPP/TPP (inside)                 in
      preposition on.
                                                                         Connected Glyph Group                  on
                                                                         RCC8-EC (touching)                     on
above, below, and left). These results were stable over a
variety of match threshold values between 0.8 and 0.9.
Inspection of the generalizations generated shows the                         Figure 3. A summary of the spatial
overlap between the sketches that creates the generalization.                 relationships used for generalization.
Figure 2 shows the generalization created for on.
                                                                    When glyphs partially overlap, a fact is also asserted based
   The information included in the generalization is visual
                                                                    on percentage of total area overlap (LessThan10Overlap,
information based on the spatial arrangement of the glyphs
                                                                    DefiniteOverlap, or GreaterThan90Overlap). These facts
in the sketch. Looking at the facts generalized, it makes
                                                                    are useful for disambiguating cases of partial overlap from
sense that the salient perceptual information needed to
                                                                    those that are just poorly drawn examples of in or on and are
assign the relationship on would be a combination of
                                                                   computed for every sketch. Since none of the simple
tangential connection between the figure and the ground and
                                                                   sketches had overlap cases, none of these facts shows up
the figure being above the ground. Currently, every fact in a
                                                                   here. It is interesting that this small set of relationships is
case is weighted the same as every other fact.
                                                                   sufficient to distinguish between these prepositions. Efforts
   These are surprisingly good results considering that we
                                                                   were made to remove redundant and unnecessary
only used 10 sketches for each preposition and no prior
                                                                   information. For example, in addition to designating
training was needed. Also, relatively few facts were needed
                                                                   contained glyph groups, sKEA also asserts information
in each case to determine which category a sketch fell into.
                                                                   about which object is designated as the container and which
The average number of facts per generalization was 5.6.
                                                                   is the insider. At this level of classification removing that
The most facts needed was 7 for on.
                                                                   information had no impact on the generalizations created.
   It is important to note that not just any set of facts will
                                                                   Keeping just the information that the ground and the figure
result in a useful classification. If bookkeeping information
                                                                   form a contained glyph group is enough to ensure the
is not filtered out, it will overwhelm the cases and
                                                                   correct generalization will form.
categories that result are meaningless. Also, object-centric
perceptual information had to be filtered out, as it ended up
                                                                    Experiment 2
being irrelevant to the spatial preposition categories and was
adding noise to the similarity comparisons. For example,            Input. The input for Experiment 2 was very similar to that
the spatial properties that sKEA automatically computes             for Experiment 1. The same 50 sketches from Experiment 1
includes an estimation of roundness of glyphs. If the               were used. In addition, 20 new sketches which were more
roundness facts are left in the cases, they sometimes cause         complicated (non-standard) and/or ambiguous cases of
sketches to classify based on similar roundness facts instead       spatial prepositions were used. Figure 4 below shows two
of on the relationship between the glyphs. So the set of            sketches from the 20 added and illustrate two different
facts that ended up in each case ends up being focused on           reasons for inclusion. The sketch on the left shows an
those facts that specifically related to the relationship           ambiguous case where the circle could be considered above
between the two glyphs.                                            or to the left of the square. The sketch on the right shows an
   Likewise, while doing these experiments, we found               instance of in where the figure is only partially contained
several additional spatial relationships that had not              within the boundaries of the ground (this is similar to the
previously been computed that were needed to create                case “the flowers are in the vase”). For the rest of this
meaningful generalizations. In order to get the above and          discussion, the 50 original sketches from Experiment 1 will
below cases to generalize, we added information about the          be referred to as the simple sketches and the 20 additional
grazing line. The grazing line is a horizontal line, that          sketches from Experiment 2 will be referred to as the
grazes (is tangential to) the very top of the ground object.       complex sketches.
Regier and Carlson (2001) suggest that above ratings are
sensitive to the grazing line and we found the same result in
our experiments.
   The set of facts retained in generalizations is summarized
in the table below along with the categories they appear in:
                                                               1707

                                                                                            on                        on
                                                                           Figure 5. Two dissimilar examples, both instances of on.
                                                                           The sketch on the left is a simple example, and the one on
           (a)                     (b)                                     the right is complex in that it involves vertical rather than
                                                                           horizontal support.
      Figure 4. Two examples of the stimuli used
      for experiment 2.
The 20 complex sketches obviously could not cover every                  --DEFINITE FACTS:
                                                                         (connectedGlyphGroupTangentialConnection
possible arrangement of figure and ground, so we focused                                     figure ground)
on the following deviations:                                             (connectedGlyphGroupTangentialConnection
• Sketches where the figure overlaps the ground by                                           ground figure)
     varying amount (ambiguous between in and on)                        (rcc8-EC figure ground)
                                                                         --POSSIBLE FACTS:
• Sketches ambiguous between above and left (as in                       88% (above figure ground)
     Figure 4a above)                                                    65% (enclosesHorizontally ground figure)
• Sketches where the figure is attached to the side of the               18% (enclosesHorizontally figure ground)
                                                                         12% (leftOf figure ground)
     ground – vertical as opposed to horizontal support (on              12% (enclosesVertically ground figure)
     as in “the picture is on the wall”) or where the ground is          6% (rightOf figure ground)
     sloped.
• On and above examples where the figure was larger
     (larger vertical extent) than the ground                            Figure 6. The new generalization created for on after the
The idea that some scenes are better examples of certain                 complex sketch examples are added.
prepositions than others is common in the literature. For
example, Logan and Sadler (1996) argue that for spatial
templates, there are three regions of acceptability for spatial
                                                                         Clearly this new generalization covers a wide variety of
relationships: the good region, the region of examples that
                                                                      sketches. However, it is important to note that all sketches
are not good, but are acceptable, and the region of
                                                                      that were included in this generalization depict a
unacceptable examples. These sketches are intended to fall
                                                                      relationship that would be classified using the preposition
into the acceptable but not good category.
                                                                      on.     Another interesting result is that the sketches
                                                                      representing those cases where the figure overlaps the
Classification. First, the simple geometric sketches were
                                                                      ground, but is not fully contained in it, formed a separate
classified using SEQL. Once the base generalizations were
                                                                      generalization. While they would most likely be labeled as
created, the complex sketch examples were added to SEQL
                                                                      in (although some might be on depending on the context of
and the generalization algorithm was run again. Several
                                                                      the scene) they did not join the generalization that contained
different runs were done with varying match thresholds.
                                                                      the simple cases of in.
Good results were found at both the 0.8 and 0.9 levels.
                                                                         Although there were a variety of new sketches added, the
                                                                      group of facts used to create the generalizations did not
Results. As mentioned above, the original 50 sketches
                                                                      change that much from Experiment 1. In addition to the
created 5 generalizations, one corresponding to each
                                                                      facts listed in Figure 3, the following facts showed up in the
relationship represented. This result was unchanged in this
                                                                      generalizations created in Experiment 2:
experiment. The ambiguous above/left sketches divided –
the one that was most like the left sketches joined that              • RCC8-PO (i.e., partially overlaps)
generalization while the others created a separate                    • DefiniteOverlap2
generalization. The sketches where the figure overlapped             • rightOf
the ground by varying amounts formed another                         • The horizontal and vertical inclusion was expanded to
generalization. The on category assimilated all of the other               include cases where the figure included the ground.
sketches that were meant as complex or ambiguous
examples of that preposition. The incorporation of these
instances into the overall generalization altered the facts that
                                                                      2
were considered part of the generalization as can be seen in            For all sketches where an RCC8-PO relationship exists, one of
the figures at the top of the next column.                            {DefiniteOverlap,                          LessThan10Overlap,
                                                                      GreaterThan90Overlap} gets asserted based on the
                                                                      percentage of area overlap (<10%, between 10% and 90%, or
                                                                      >90%) between the figure and ground.
                                                                 1708

                      Related Work                                                           Discussion
   A number of models of spatial prepositions involve                  We have shown that we can successfully classify simple
representational templates that are created by hand. For            two-dimensional geometric sketches by the spatial
example, Herskovits (1980, 1986) categorizes spatial                preposition that would be used to describe them by
language into use cases based on object and contextual              extracting a sufficient set of spatial relationships. Our
features as well as typicality, and Logan and Sadler (1996)         contribution is unique in two ways. The first is our use of
classify geometric scenes using spatial templates. These            sketch-based input. This allows us the flexibility to quickly
models require an exhaustive list of the use cases/templates        and easily create a variety of stimuli, including being able to
needed, mechanisms for selecting the correct one, and an            recreate similar examples to stimuli from different
account of what modifications can be made to fit an                 psychological experiments. Automatically extracting the
imperfect template to a scene. By contrast, our use of              salient perceptual information eliminates the need for hand
SEQL produces relational templates automatically, and               coding of representations. The second unique aspect of our
reduces the imperfect fit problem to structural alignment.          model is the use of analogical generalization to
   Regier’s (1995) connectionist model was able to learn            automatically create categories. By altering the contents of
spatial prepositions for a variety of languages. However, it        our case libraries, through variations of the automatic
required labeled training data, and a total of 3000 epochs of       encoding process, we were able to explore what
training on 126 movies. Since we do not label our stimuli,          relationships are sufficient to create the correct
there are no cues for our system as to which sketches should        generalizations.
be classified together. Their system operated on videos of
scene sequences allowing it to also handle dynamic                                         Future Work
prepositions such as through.                                       We plan to extend the corpus of sketches to include
   Regier and Carlson’s (2001) attentional vector sum               everyday objects in addition to abstract geometric shapes.
(AVS) model is able to reproduce similar results to humans          Psychological studies show that functional information
for several different prepositions.       Recent extensions         about objects in scenes contributes heavily to the choice of
(Regier, Carlson, & Corrigan, 2005) modified the original           preposition used to describe them (Coventry, Prat-Sala, &
AVS model to account for functional information. This is            Richards, 2001; Feist & Gentner, 1998; Carlson-Radvansky,
done by focusing attention on the functional parts of objects       Covey, & Lattanzi, 1999; Coventry & Mather, 2002;
(such as the bristles of a toothbrush). This work predicts          Coventry & Garrod, 2004).            Since we are already
acceptability judgments of spatial terms as opposed to              conceptually labeling the objects in our sketches, we can use
categorizing stimuli.                                               the knowledge base to infer the functional properties of
   Coventry et al. (2004; Cangelosi et al 2005) have                figure and ground objects, and verify that the figure and
developed a model which implements the constraints of the           ground are fulfilling their functional roles. We also plan to
functional geometric framework (Coventry & Garrod, 2004)            extend the corpus to include sequences of sketches
for the prepositions over/under/above/below. The model              representing dynamic situations.
has been shown to be consistent with human data on the                 Another direction involves testing with human subjects.
appropriateness of these four prepositions in describing            The sKEA interface provides an interesting opportunity to
scenes involving both geometric and functional information.         run human subjects with the exact same stimuli (sketches)
Martinez, Cangelosi, and Coventry (2001) describe another           provided to the computational model. For example, we plan
                                                                    to present people with a categorization task similar to what
model that simulates the same set of data, using a neural
                                                                    was given to SEQL, and determine how they classify the
network whose input is descriptions of visual scenes. These
                                                                    harder sketches to inform subsequent versions of our model.
descriptions are created using variables to encode various             Finally, we also plan to explore categorization of
factors that were found to influence over/under/above/below         prepositions in other languages (cf. Regier, 1995;
judgments in experiments (Coventry, Prat-Sala, & Richards,          Bowerman, 1999). There are competing theories as to how
2001): orientation, function, appropriateness, and object           spatial reasoning and spatial language develop. One theory
type. The encoding of variables is done by hand, however,           is that all humans share a small set of spatial primitives that
unlike our automatic encoding scheme.                               we then learn to map to prepositions. Some recent work
   We find all of these projects to be complementary to our         suggests that these primitives may be more varied than
work; there are tradeoffs to the different approaches. The          previously suspected (Choi et al, 1999). By comparing the
main benefit of our approach is the flexibility and                 relationships necessary to correctly classify prepositions in
extendibility of the system. Since the input is sketches, it is     different languages we hope to shed some light on this
very quick and easy to create more stimuli and to test more         discussion.
arrangements of objects. Since conceptual labeling ties to
the underlying off-the-shelf knowledge base, functional                                Acknowledgments
information can be added through inference.                No       This work was supported by a grant from the Artificial
information for any case needs to be hand coded or added            Intelligence division of the Office of Naval Research.
individually.
                                                               1709

References                                                          Proceedings of the 17th International Workshop on
                                                                    Qualitative Reasoning, Brasilia, Brazil, August.
                                                                  Gapp, K-P. (1995a). An Empirically Validated Model for
Bowerman, M.. (1996). Learning How to Structure Space               Computing Spatial Relations. 19th Annual German
  for Language: A Crosslinguistic Perspective. In P.                Conference on Artificial Intelligence. (245-256).
  Bloom, M.A. Peterson, L. Nadel, & M.F. Garrett (eds.)            Gapp, K-P. (1995b). Angle, Distance, Shape and their
  Language and Space (493-530). Cambridge, Mass. MIT                Relationship to Projective Relations. In Proceedings of
  Press                                                             the 17th Annual Conference of the Cognitive Science
Cangelosi, A., Coventry, K.R., Rajapakse, R., Joyce, D.,            Society. (112-117).
  Bacon, A., Richards, L., & Newstead, S.N. (2005).                Gentner, D. (1983). Structure-mapping: A Theoretical
  Grounding Language in Perception: A Connectionist                 Framework for Analogy. Cognitive Science 7: 155-170.
  Model of Spatial Terms and Vague Quantifiers. In A.              Halstead, D., & Forbus, K. (2005). Transforming between
  Cangelosi, G, Bugmann, & R. Borisyuk (eds.). Modelling            Propositions and Features: Bridging the Gap.
  Language, Cognition, and Action: Proceedings of the 9th           Proceedings of AAAI – 2005. Pittsburgh, PA.
  Neural Computation and Psychology Workshop.                      Herskovits, A. (1980). On the Spatial Uses of Prepositions.
Carlson-Radvansky, L.A., Covey, E.S., & Lattanzi, K.M.              Proceedings of the 18th Annual Meeting of the ACL.
  (1999).      “What” effects on “Where”: Functional              Herskovits, A. (1986). Language and Spatial Cognition: An
  influences on spatial relations. Psychological Science,           Interdisciplinary Study of the Prepositions in English.
  10(6): 516-521.                                                   Cambridge. Cambridge University Press.
Choi, S., McDonough, L., Bowerman, M., & Mandler, J.M.            Kuehne, S., Forbus, K., Gentner, D., & Quinn, B. (2000).
  (1999). Early Sensitivity to Language-Specific Spatial            SEQL: Category learning as progressive abstraction using
  Categories in English and Korean.               Cognitive         structure mapping.        Proceedings of the Annual
  Development, 14: 241-268.                                         Conference of the Cognitive Science Society.
Cohn, A.G. (1996).          Calculi for Qualitative Spatial       Lockwood, K., Forbus, K., & Usher, J. (2005). SpaceCase:
  Reasoning. In J. Calmet, J.A. Campbell, J. Pfalzgraf              A model of spatial preposition use. Proceedings of the
  (Eds.) Artificial Intellignece and Symbolic Mathematical          27th Annual Conference of the Cognitive Science Society.
  Computation. Springer Verlag. (124-143).                          Stressa, Italy.
Coventry, K.R., & Mather, G. (2002). The Real Story of            Logan, G.D., & Sadler, D.D. (1996). A Computational
  “Over”? In K.R. Coventry, & P. Oliver (Eds) Spatial               Analysis of the Apprehension of Spatial Relations. In P.
  Language: Cognitive and Computational Aspects.                    Bloom, M.A. Peterson, L. Nadel, & M.F. Garrett (eds.)
  Kluwer Academic Publishers.                                       Language and Space (493-530). Cambridge, Mass. MIT
Coventry, K.R., Cangelosi, A., Rajapakse, R., Bacon, A.,            Press.
  Newstead, S., Joyce, D., & Richards, L.V. (2004).               Martinez, G.C., Cangelosi, A., & Coventry, K.R. (2001). A
  Spatial     Prepositions     and    Vague      Quantifiers:       Hybrid Neural Network and Virtual Reality System for
  Implementing the Functional Geometric Framework. In               Spatial Language Processing. In the Proceedings of the
  Proceedings of the Spatial Cognition Conference, 2004.            International Joint Conference on Neural Networks. (16-
Coventry, K.R., & Garrod, S.C. (2004). Saying, Seeing, and          21). Washington, D.C.
  Acting: The Psychological Semantics of Spatial                  Regier, T. (1995). A Model of the Human Capacity for
  Prepositions. Lawrence Erlbaum Associates. Essays in              Categorizing Spatial Relations. Cognitive Linguistics,
  Cognitive Psychology Series.                                      6(1): 63-88.
Coventry, K.R., Prat-Sala, M., & Richards, L.V. (2001).           Regier, T. & Carlson, L.A. (2001). Grounding Spatial
  The interplay between geometry and function in the                Language in Perception: An Empirical and Computational
  comprehension of ‘over’, ‘under’, ‘above’, and ‘below’.           Investigation.    Journal of Experimental Psychology,
  Journal of Memory and Language, 44: 376-398.                      130(2): 273-298.
Falkenhainer, B., Forbus, K., & Gentner, D. (1986). The           Regier, T., Carlson, L.A., & Corrigan, B. (2005). Attention
  Structure-Mapping Engine. Proceedings of the Fifth                in Spatial Language: Bridging Geometry and Function.
  National Conference on Artificial Intelligence.                   In L.A. Carlson, & E. van der Zee (Eds.) Functional
Feist, M.I., & Gentner, D. (1998). On Plates, Bowls, and            features in language and space: Insights from perception,
  Dishes: Factors in the Use of English ‘in’ and ‘on’.              categorization, and development.          Oxford: Oxford
  Proceedings of the 20th Annual Conference of the                  University Press.
  Cognitive Science Society.                                      Skorstad, J., Gentner, D., & Medin, D. (1988). Abstraction
Forbus, K., Ferguson, R., & Gentner, D.             (1994).         Process During Concept Learning: A Structural View.
  Incremental Structure-Mapping.       Proceedings of the           Proceedings of the 10th Annual Conference of the
  Cognitive Science Society.                                        Cognitive Science Society: 419-425.
Forbus, K., Ferguson, R., & Usher, J. (2001). Towards a           Talmy, L. (1983). How Language Structures Space. In H.,
  computational model of sketching. IUI’01, January 14-17,          Pick, & L. Acredolo (Eds.) Spatial Orientation: Theory,
  2001, Santa Fe, New Mexico.                                       research, and application. New York, Plenum Press (225-
Forbus, K., Tomai, E., & Usher, J. (2003). Qualitative              282).
  spatial reasoning for visual grouping in sketches.
                                                              1710

