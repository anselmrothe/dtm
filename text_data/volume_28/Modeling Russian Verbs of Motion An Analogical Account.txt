UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Russian Verbs of Motion: An Analogical Account

Permalink
https://escholarship.org/uc/item/5f66083n

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Dodge, Inna Danielyan
Lonsdale, Deryle

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Modeling Russian Verbs of Motion: An Analogical Account
Inna Danielyan Dodge (innadan@byu.edu)
Department of Linguistics and English Language; 4039 JFSB
Provo, UT 84602 USA

Deryle Lonsdale (lonz@byu.edu)
Department of Linguistics and English Language; 4039 JFSB
Provo, UT 84602 USA
a machine learning system called analogical modeling (Skousen, Lonsdale, & Parkinson, 2002). The system analyzes
data instances based on a set of lexical and semantic features.
Through a process of analogy it eliminates all the inconsistent
(heterogeneous) outcomes and chooses the most analogous
result for the given context.
Usage instances were extracted from an online corpus, encoded as feature vectors, and tested for prediction of correct
prepositions in verb of motion phrases based on the semantic
features of the verbs, their prefixes, and objects with relevant
case markings. We illustrate how the process of analogy in
AM serves to predict the choice of the preposition in VOM
phrases on the basis of the semantic features of the verbs and
their nominal arguments with relevant case markings.

Abstract
This paper presents research into verb of motion (VOM)
constructions in Russian. These constructions are difficult
since they involve (i) selection of an appropriate verb (with
possible prefixation); (ii) selection of an appropriate preposition; and (iii) selection of an appropriate case for marking
the prepositional object. A brief sketch of relevant literature
frames the problem. We then discuss how a few thousand
instances of VOM usage were extracted from an online
tagged corpus of Russian literature. The usage instances were
then vectorized using a combination of lexical and semantic
class features via automatic, semiautomatic, and hand-coded
methods. The instance base was then processed via the analogical modeling paradigm to account for predictability of the
case, the preposition, and both simultaneously. Discussion of
the results and possible future research directions then follows.

Background

Keywords: Russian; verbs of motion; analogical modeling; morphosemantics.

Introduction
A complex and challenging facet of the Russian language is
the group of verbs variably referred to as verbs of motion, location, or transport (hereafter VOM‚Äôs). The simple English
sentence ‚ÄúHe brought me to his house.‚Äù may be rendered into
Russian differently depending on the conveyance used (or absence thereof), means of displacement (e.g. by foot or by vehicle), the vectoriality or directionality, and the perfectivity
(degree of completion) of the event in question. VOM constructions typically have four relevant core parts: a subject,
a VOM, a preposition, and a prepositional object. The VOM
may be conjugated for tense and inflected (e.g. via a prefix)
for aspect. The prepositional object is inflected appropriately
for case (usually with suffixes). Selection of which verb and
which preposition to use in a given instance, as well as the
case marking on the prepositional object, is a difficult task
that involves re-expressing the target situation via a grammatically correct VOM construction.
This research focuses on functional relations between
verbs of motion (unprefixed and prefixed) and their nominal
arguments with relevant case markings. We consider 14 pairs
of VOM‚Äôs in all of their possible prefixed and conjugated
forms. We also describe a set of semantic features for describing their aspectual, syntagmatic, and spatial/directional
properties, and how we use these features for language modeling.
In this paper we address the question of modeling VOM
constructions by using a corpus-derived exemplar base and

Even native speakers of Russian occasionally produce certain
types of case errors (Demidenko, 1986) including those involving the prepositional case, which is often used in VOM‚Äôs.
Less unexpected is the fact that learners of Russian as a second language show several difficulties in acquiring Russian
case (Rubinstein, 1995). This research confirms our personal
observation that non-native learners of Russian often confuse
the accusative case with the prepositional.
A limited amount of pedagogical material exists for
VOM‚Äôs (Mahota, 1996); the topic is apparently underexplored in the Russian linguistic literature (though see (Muravyova, 1986)). It would appear that more work in this area
has done by Western linguists (Titelbaum, 1972; Pahomov,
1977; Vaimberg, 1981; Launer, 1987)). Still, to our knowledge, no work has focused on language modeling and Russian
(or any other Slavic language‚Äôs) verbs of motion. In this paper, we use AM to study relevant aspects of this construction.
In this paper we adopt a standard set1 of fourteen VOM‚Äôs
(Karcevski, 1927; Muravyova, 1986; Andrews, Averyanova,
& Pyadusova, 1997), plus their conjugations.
One distinction that is pertinent for these verbs involves
their indeterminate/determinate status. Determinate verbs
have a single appreciable vectoriality or directionality; indeterminate ones are repeated, habitual, autonomous, or unspecified for space or time. The determinate verbs are considered
marked and hence non-default.
Each of the verbs can acquire about 17 prefixes, primarily spatial/directional in nature. When this happens, the
(in)determinate dichotomy disappears. Other effects arise;

1239

1 Various researchers have developed slightly different sets of
VOM‚Äôs.

Indeterminate


  
  
  
 
  
 
  

Indeterminate

 !"
#   
!  
   # 
 
  

Intransitive verbs of motion
Determinate Gloss
  
to go on foot, to walk

to go by means of transport, conveyance
  
to run
  
to fly

to swim, to sail
   
to crawl
   
to wander, to roam
  
to climb
Transitive verbs of motion
Determinate Gloss
 ! 
to chase, to drive
#  
to roll, to push on wheels
!   
to carry, to take by hand
 $%
to drag, to pull
   
to lead, to take on foot
   
to transport, to take by transport

Figure 1: Infinitival forms of Russian verbs of motion.
for example, both types of verbs, when prefixed, can become
perfective. A listing of the possible VOM categories is given
in Figure 2.
Unprefixed
Imperf.
Indeterm. Determ.

Prefixed
Perf.
Indeterm. Determ.

Figure 2: Partial hierarchy of verbs of motion
This raises an interesting issue: is there a hierarchical relationship between these components? If so, which determine
the choice of the others, and what is their relative importance?
The usual and traditional claim is that the preposition governs
the choice of case marking for its object, though this has been
challenged (Whibley, 1982; Bethin, 1983). We thus believe
that the topic is germane for exploration.
Several different language modeling paradigms have
served to investigate language use. Connectionist, rulebased, memory-based, statistical, competition-based, and
information-theoretical accounts have been advanced for different language-specific and crosslinguistic phenomena. To
our knowledge no modeling work has been done in Russian
VOM‚Äôs in any of these frameworks. Similarly, no detailed
theoretical accounts of cognitive processing‚Äîwhether psychologically plausible or not‚Äîhave yet addressed the use of
VOM‚Äôs. Our intent here is to at least initiate work in this area;
we seek to benchmark the exploration of the complexities involved in Russian VOM‚Äôs and to raise relevant issues. In
this effort we adopt one established paradigm of language use
modeling: analogical modeling (AM). While cross-paradigm
comparisons could naturally follow from this work, we restrict this description to our efforts within AM.
Analogical modeling (AM) is a symbolic exemplar-based
language modeling paradigm that establishes analogical comparisons between a set of instance data and test items, each

represented as a feature vector2 (Skousen, 2002). The data
instances represent exemplars of separate linguistic usages.
Each test item is systematically evaluated against the data instances in order to predict its appropriate outcome. Not all
features need be fully specified; some may be absent or erroneous, thus representing partial or noisy data.
From a vector of n test item features, we choose m (where
0 & m ' n) specified features (i.e. a subset thereof) and test
them against the data instances for similarity. These so-called
supracontexts (of which there are 2m ) can be categorized as
being heterogeneous or homogeneous based on whether their
subcontexts all behave identically (i.e. have the same outcome). Only results from homogeneous supracontexts are
kept; the other contexts are discarded. The analogical character of the approach lies in measuring the disagreements
among the outcomes associated with these feature subsets.
In particular, a homogeneous supracontext has no subcontext
that increases this number of disagreements.
For a given test item, only two types of homogeneous contexts can exist: (i) deterministic supracontexts with only one
outcome, and (ii) nondeterministic contexts where all occurrences are equidistant from the test item. The ‚Äúanalogical
set‚Äù combines these two types of homogeneous supracontexts. The system chooses one of the outcomes from this analogical set as the outcome for the test item in question; the
choice can either be done randomly, or else by plurality (i.e.
the most frequent outcome). Based on this notion of similarity, analogs often‚Äîbut not always‚Äîcorrespond to nearest neighbors; regular items further away can sometimes conspire together in ‚Äúgangs‚Äù to affect the outcome. Various parameters control such phenomena as imperfect memory and
frequency effects; hooks into the core engine allow for visibility into and interaction with the algorithm‚Äôs operations.

1240

2 We should note that we use the term ‚Äúvector‚Äù throughout,
though in fact the features are purely discrete and symbolic; they
are not continuous-valued or numeric.

 Russian is a pro-drop language, meaning that the subject

AM has been successfully applied to a wide range of linguistic phenomena, though primarily in the lexical, phonological, and morphological realms. The semantic realm is relatively unexplored in the paradigm3, and this paper addresses
semantic phenomena within this approach. Detailed analyses are available elsewhere of the analogical procedure itself
(Skousen, 1992), its application to language modeling problems (Skousen, 1989), and its algorithmic implementations
(Skousen et al., 2002).

is optional and hence often missing in the exemplar sentences.

 Only VOM‚Äôs listed in Figure 1, along with their various
conjugations, were extracted.

 There are forty-three prepositions and thirteen further variant forms (i.e. allomorphs) of these in the exemplar base.
In this work we did not collapse them, thus incurring a
slight reduction in accuracy in the system‚Äôs performance.

Methodology

 The Russian case paradigm consists of six cases, namely:

In this section we discuss how the data instances were collected, how they were mapped to an appropriate feature vector representation, and then how they were processed by the
AM system.

nominative, genitive (gen), dative (dat), accusative (akk),
instrumental (ins), and prepositional (prp). Only the last
five cases appear in the outcomes; nominative marks subjects and hence can never mark prepositional objects.

 Some prepositions occur with various cases: the prepositions  ‚Äúin, into‚Äù and !  ‚Äúon, onto‚Äù are shared by accusative and prepositional,   ‚Äúfor, behind‚Äù is shared by
accusative and instrumental, the preposition  ‚Äúwith, off,

Instance collection
The exemplar base for this research was built from several
thousand instances of VOM constructions extracted from the
TuÃàbingen online corpus4 . The corpus consists of a morphologically tagged collection of literary texts, newspaper articles, and magazine articles.
A one-sentence context was retrieved from all available
corpora for each verb form using a regular exression. For example, the verb    , ‚Äúto approach, come up, walk up
by foot‚Äù in its infinitive and past tense forms produced 415
instances of tagged sentences, such as the extracted example
below5 :

approximately‚Äù is used with instrumental, genitive and accusative, and so on.

 The Perl lexical feature extractor did not always correctly
process some corpus instances, so occasional incorrect
subjects or objects resulted. This presence of errors in the
input data is in fact interesting since it reflects the fact that
real language data is indeed inherently noisy to a language
learner, and also since AM is robust enough to deal with
such data.

Bazarov/substantiv_masc_pl_gen_unb
vstal/verb_finit_prt_0_sg_masc_nref_pf
i/konj_koor
podoshel/verb_finit_prt_0_sg_masc_nref_pf
k/praep_dat
oknu/substantiv_neut_sg_dat_unb
./satzzeichen_punkt

 Some incorrect case tagging was found in the corpus. For
example, za_dat for, behind dative is impossible in Russian, as were other forms we encountered in the corpus:
v_akk encoded as v prp and vice versa.

meaning ‚ÄúBazarov got up and walked up to the window.‚Äù

Feature encoding
Once the instances were retrieved from the corpus, a Perl program then extracted from each sentential context the four lexical features that participate in VOM constructions.
The following information was thus extracted for our example sentence:
k_dat, bazarov podoshel k oknu

So far, then, the features consist of: (i) the outcome
k_dat, meaning that the VOM has the preposition k
and is dative; and (ii) four lexical features or variables
bazarov podoshel k oknu, representing the subject of the
sentence, the verb of motion, the preposition and the casemarked prepositional object.
Several points regarding these lexical features are worthy
of mention:
3 though see the discussion on Arabic lexical selection in (Skousen, 1989)
4 See www.sfb441.uni-tuebingen.de/bl/en/korpora.html.
5 We adopt the fairly idiosyncratic Romanization scheme used in
the corpus for our data representations and hence our examples in
this paper.

We then added semantic features manually to each feature
vector, based on the semantics of the VOM construction. The
featured we chose were based upon Frawley‚Äôs claims about
the universality of his spatial concept definitions (Frawley,
1992). He distinguishes two kinds of locations encoded by
language: topological (i.e. objective) locations and projective (i.e. subjective) locations (see Figure 3). Our choice, of
course, is not meant to be all-encompassing of the problem
and is somewhat prescient since it is conditioned on our existing knowledge of the language, so our feature set cannot be
taken as a complete necessary and sufficient specification of
the features required for this task. It is rather an opportunistic
leveraging of pre-existing work in this area.
After adding these semantic encodings our sample vector
is as follows:
k_dat, v y o l bazarov podoshel k oknu

Here we see the four semantic features prepended to the
lexical ones described above. The first three semantic features
belong to the verb of motion   ‚Äúcame up by foot, approached‚Äù, and the last letter represents a semantic feature of
the object  # ! ‚Äúwindow‚Äù. Here the letter v stands for intransitive, y for determinate, o for ‚Äúby foot: regular speed‚Äù,
and l means laterality. See Figure 4 for a further explanation of the semantic features and Figure 5 for sample instance
vectors.

1241

Coincident
Interior
Exterior
Inferior
Superior
Anterior
Posterior
Lateral

bez_gen, v y o i ego vojti bez predstavlenij,
dlja_gen, v y h i ja priexala dlja togo,
do_gen, v y o a zhelanija dojti do cherty,
izo_gen, v y o e nogi vyshla izo rta,
k_dat, v y o l zvenqev idet k paraskeve,
k_prp, v q o l cypochkax podxodit k dveri,
mimo_gen, v y o l vse projdet mimo shkoly,
na_akk, v y o c a vyshla na ulicu,
na_prp, v y h c zhizni exala na letuchke,
o_prp, z y a i vernoj vesti o smerti,
ob_akk, v y o ? vymyvanie idut ob prakticheski,
okolo_gen, v y o ? pqesa proshla okolo raz,
ot_gen, v y o e bankovskij ujti ot melochnogo,
po_akk, v q o i vse xoditq po griby,
po_dat, v q o c arapy vxodjat po trapu,
po_prp, v y o c on shel po tropke,
pod_akk, z y a f ee vesti pod ruku,
posle_gen, v y o p oni ushli posle akta,
pri_prp, z y a l zhivyx vyveli pri ehtom,
pro_akk, z y a ? ehtogo vyvela pro shilku,
protiv_gen, v y o l vy idete protiv naroda,
putem_gen, v y o i rudin doshel putem filosofii,
s_akk, v y o i my proshli s chetvertq,
s_gen, v y o i my proshli s chetvertq
s_ins, v q o i schastlivoe prixodit s glotkom,
sredi_gen, v q o l my xodim sredi palatok,
v_akk, z q a n kotoroe vvoditq v dom,
v_prp, v y h n vysokoj vyexala v triko,
za_ins, v q o i ty xodil za doktorom,

Topological
The fly is on the wall.
The books are in the box.
The ball is out of the box.
Projective
The cat is below the table.
The shelf is above the table.
The spoon is in front of the pumpkin.
The pumpkin is behind the spoon.
Donna is beside the car.

Figure 3: Semantic features from (Frawley, 1992)

Figure 5: Sample instance vectors.

Running the system

Feature 1
Intransitive/transitive
Feature 2
Indeterminate/determinate
Feature 3
Foot: regular speed/slow/fast
Arms & legs: ground/into/air/water
Vehicle: car/plane/ship
Coincidence: slow
Feature 4
Features from Figure 2, plus:
Completely: through
Direction
Instrument/benefactive
Superiority
All features
Don‚Äôt know

v/z
q/y
o/w/b
u/g/r/m
h/x/j
k

t
d
i
s
?

Figure 4: Semantic features used in instance vectorization.

The analogical modeling system takes two input files: the
data file of instance (or example or exemplar) vectors, and
the test file, consisting of similarly vectorized queries to the
system. Each test item is compared to the input instances,
analogies are computed, outcomes are scored, and a report is
output. Several parameters can be controlled during processing via a Perl wrapper to the basic underlying system. For
example, a threshold can limit what percent of the input data
should be randomly selected for processing, precluding the
rest. In addition, instances of the test items in the input data
can be included in processing (resulting in simple retrieval of
their outcome) or excluded from processing if they also occur in the input data (hence forcing analogical processing to
take place). In fact, a common experimental condition is to
exclude the givens.
A report for each test item illustrates which outcomes are
possible, and gives a percentage weight for each. Figure 6
shows part of a listing of results with slightly different features than those described above. The first instance was correctly guessed with a confidence of 100%. The second instance was incorrectly guessed to be v_akk when in fact it
should have been cherez_akk, and so on.
The system can be run to predict either the preposition-case
combination simultaneously, or the preposition first and then
the case, or vice versa.

Results and discussion
Several different feature combinations were tried with the full
data set described above. All tests were done in leave-one-out
fashion, testing each item from the data set in turn against the
full data set (minus any occurrences of the item in question).

1242

We first tested the system using only the lexical features.
When three features were tried (i.e. excluding the preposition), a 44.19% score was obtained. This low score is not
too surprising since the lexical forms themselves are merely
symbolic tokens that can only be compared via direct equality/inequality tests.
On the other hand, adding the fourth lexical feature, the
preposition, to each instance upped the score considerably to
83.74% correct. This is an understandably high result since
once the preposition is known the only decision left is to
choose the relevant case.
On the other hand, adding case (but not the preposition) to
the three lexical features on the input vectors, and thus forcing the system to guess the preposition, only yielded a score
of 67.32%. Clearly the system had more trouble predicting
the preposition than predicting the case. This,too, is understandable since there are more possible preposition outcomes
(43) than case outcomes (5).
We next tested the hypothesis that the semantic features of
verbs of motion and their nominal arguments with relevant
case markings will help in predicting the choice of the preposition. To do this, we ran the data set whose instances all
had the additional four semantic features. When guessing the
case given the preposition, the system scored 89.2% correct,
an improvement of 5.46% over similar runs with only lexical
features.
A further question arises: is it easier for the program
to guess the preposition-case combination simultaneously or
would it be more efficient to guess the preposition first and
then the case and vice versa? Does the case of the nominal
argument depend of the preposition or on the verb of motion?
Does the preposition depend on the nominal argument with
its relevant marking or on the verb of motion?
To force simultaneous preposition/case guessing, both the
prepositional and case features were excluded from the vectors. AM scored a very low 13% This remarkably poor result
(verses the score of 44.19% using only three lexical features)
shows the effect of added complexity given the four new semantic features. Both trials, though, demonstrate the difficulty of guessing the preposition and the case simultaneously.
We also tested the third option‚Äîguessing the preposition
given the case. In this the system scored a reasonable 86%.
Based on these scores, it can be concluded that, based on the
feature set we implemented, it is more difficult to simultaneously select the appropriate preposition/case VOM combinations than it is to have a staged decision process. The two-step
treatment of VOM constructions as a preferential production
strategy also meshes well with current pedagogical practice,
based on the first author‚Äôs personal teaching experience, and
confirms the challenging nature of simultaneous guessing.
A ranking of the relative strength of the features using
TiMBL‚Äôs gain ratios (Daelemans, Zavrel, Sloot, & Bosch,
2003) showed that the relative importance of the features was
(in decreasing order): (1) the semantic feature of prepositional object; (2) the transitivity/intransitivity of the VOM;
(3) the object‚Äôs lexical form; (4) specific semantic feature of
the verb of motion (e.g. foot: regular speed or vehicle: car,
arms and legs etc.) (5) the indeterminate/determinate status
of the verb of motion; (6) the preposition itself, when present;
and (7) the verb of motion itself, the only lexical feature.

Test: akk v y o t skvoznym idut galerei,
If context is in data file then exclude
Statistical Summary
cherez_akk

16
-16

100.000%

Expected outcome: cherez_akk
Correct outcome predicted.
Test: akk v q o t solomin perexodil komnatu,
If context is in data file then exclude
Statistical Summary
cherez_akk
skvozq_akk
v_akk

624
168
880
---1672

37.321%
10.048%
52.632%

Expected outcome: cherez_akk
Incorrect outcome predicted.
Test: akk v y o t strana proshla ispytanija,
If context is in data file then exclude
Statistical Summary
cherez_akk
k_dat

16
8
-24

66.667%
33.333%

Expected outcome: cherez_akk
Correct outcome predicted.
Test: akk v q o t svet proxodit atmosferu,
If context is in data file then exclude
Statistical Summary
cherez_akk
k_dat
skvozq_akk
za_akk

240
1
160
2
--403

59.553%
0.248%
39.702%
0.496%

Expected outcome: cherez_akk
Correct outcome predicted.

Figure 6: Sample output from the system.

1243

One interesting aspect of AM is its ability to model human
errors. Leakage occurs when one outcome is favored over
another when errors are produced (Skousen, 1989). For example, the production of a versus an in English favors leakage
towards the former; ‚Äúa apple‚Äù is more likely to be heard than
‚Äúan telephone‚Äù.
Consider the summary of the distribution of results for all
1108 items having the outcome v_akk:

even be helpful from a methodological standpoint, setting
aside the linguistic issues. Further research could also investigate the problem under other machine learning approaches
(e.g. TiMBL or decision trees), comparing and contrasting
the results of the various approaches.
Finally, possible applications of this research can be used
in developing Russian language learning software and computerized Russian text processing.

Test items with outcome v_akk
0.090% k_dat (1/1108)
0.090% na_akk (1/1108)
0.090% na_prp (1/1108)
0.090% o_prp (1/1108)
0.090% s_gen (1/1108)
97.022% v_akk (1075/1108)
2.527% v_prp (28/1108)

References

The correct outcome na_akk was almost always guessed.
However, the system also demonstrates slight leakage towards v_prp as the second choice, thus exhibiting a confusion similar to that of learners as they acquire Russian.

Andrews, E., Averyanova, G., & Pyadusova, G. (1997). Russian verb: Forms and functions. Moscow: Russky
Yazyk.
Bethin, C. Y. (1983). On the spatial dative in Russian. The
Slavic and East European Journal, 27(4), 465-477.
Daelemans, W., Zavrel, J., Sloot, K. van der, & Bosch, A.
van den. (2003). TiMBL: Tilburg Memory-Based
Learner version 5.0 Reference Guide (Tech.
Rep.).
   #  (speech erDemidenko, L. P. (1986).   
rors). Minsk:       " #  .
Frawley, W. (1992). Linguistic semantics. Hillsdale, NJ:
Lawrence Erlbaum Associates Publishers.
Karcevski, S. (1927). SysteÃÄme du verbe russe: Essai de linguistique synchronique. Prague: Legiographie.
Launer, M. (1987). The semantic structure of verbs of motion
in Russian. Russian Language Journal, 41, 77-105.
Mahota, W. (1996). Russian motion verbs of intermediate
students. New York: Yale University.
Muravyova, L. (1986). Verbs of motion in russian. Moscow:
Russky Yazyk.
Pahomov, G. (1977). Bull, boar, and orbit/trajectory: On presenting the verbs of motion. Russian Language Journal, 31, 1-6.
Rubinstein, G. (1995). On case errors made in oral speech
by American learners of Russian. The Slavic and East
European Journal, 39(3), 408-429.
Skousen, R. (1989). Analogical modeling of language. Dordrecht: Kluwer.
Skousen, R. (1992). Analogy and structure. Dordrecht:
Kluwer.
Skousen, R. (2002). An overview of analogical modeling.
In R. Skousen, D. Lonsdale, & D. B. Parkinson (Eds.),
Analogical modeling: An exemplar-based approach to
language (p. 11-26). Amsterdam: John Benjamins.
Skousen, R., Lonsdale, D., & Parkinson, D. B. (Eds.). (2002).
Analogical modeling: An exemplar-based approach to
language (Vol. 10). Amsterdam: John Benjamins.
Titelbaum, O. A. (1972). The effects of prefixing on aspect
in Russian verbs of transposition. The Slavic and East
European Journal, 16(2), 206-213.
Vaimberg, S. (1981). On the semantic structure of the verbs
of motion in Russian. Revue romaine de linguistique,
26(3), 289-293.
Whibley, K. (1982). On prefix-preposition combinations with
Russian verbs of motion. Papers in Slavonic Linguistics, 1, 211-225.

Future work and possible applications
This preliminary work is promising and several further directions for future research are possible.
Of course, a larger dataset would be useful for more thorough testing of the hypothesis. Other tagged corpora would
be necessary for this effort, or alternatively more work on our
part to identify, tag, and extract contexts of interest from other
sources.
We also envision adding more semantic features to the instance vectors. For example, though prefixes play a crucial
part in VOM‚Äôs, we did not encode any prefixation information into the vectors. It is unclear at this point whether such
features would serve to complicate the problem or instead to
add more information to that would be helpful in determining
outcomes.
We would like to have a more automatic way of encoding
the semantic features, perhaps by using some lexico-semantic
resource that could provide such information.
It would also be interesting to conduct a study involving
human subjects and their second-language acquisition of Russian VOM‚Äôs, including errors, in order to arrive at a more
thorough account of cognition in VOM‚Äôs. The participants
would be given the same task of predicting prepositions based
on the semantic features of verbs of motion and nominal arguments with their relevant case markings. Then the results
from this and previous acquisition data would be compared
to the AM outcomes in order to draw analogies between language modeling and human acquisition of language.
We recognize without reserve that other cognitive frameworks beyond AM have the potential for addressing these
same phenomena. For example, since we have cast the issues
in this paper as a categorization problem, several alternative
approaches exist, for example statistical, causal, or entropybased. Each warrants further investigation.
We could perform a more thorough version of the testing using tests for statistical significance and precision/recall
measures so that the results are more directly commensurate
with comparable investigations of similar phenomena in the
literature. These types of testing regimes have yet to be done
within the AM research paradigm, so such work would be

1244

