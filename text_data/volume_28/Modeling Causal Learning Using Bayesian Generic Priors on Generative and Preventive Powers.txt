UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Causal Learning Using Bayesian Generic Priors on Generative and Preventive
Powers
Permalink
https://escholarship.org/uc/item/93h735b9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Cheng, Patricia W.
Holyoak, Keith J.
Liljeholm, Mimi
et al.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       Modeling Causal Learning Using Bayesian Generic Priors
                                        on Generative and Preventive Powers
                                                Hongjing Lu (hongjing@ucla.edu)
                          Department of Statistics, UCLA, Box 951563, Los Angeles, CA 90095-1563, USA
                                                Alan Yuille (yuille@stat.ucla.edu)
                                                    Department of Statistics, UCLA
                                                 Mimi Liljeholm (mlil@ucla.edu)
                                                   Department of Psychology, UCLA
                                          Patricia W. Cheng (cheng@lifesci.ucla.edu)
                                                   Department of Psychology, UCLA
                                          Keith J. Holyoak (holyoak@lifesci.ucla.edu)
                                                   Department of Psychology, UCLA
                             Abstract                                elemental causal induction, in which the learner is using
                                                                     observations to decide between Graph 0 versus Graph 1 (Fig.
   We present a Bayesian model of causal learning that               1), where B is a constantly-present background cause that
   incorporates generic priors on distributions of weights           may generate E, and C is a candidate cause that may be either
   representing potential powers to either produce or prevent an
                                                                     present or absent (varying from trial to trial).
   effect. These generic priors favor necessary and sufficient
   causes. Across three experiments, the model explains the
   systematic pattern of human judgments observed for questions               B         C                      B          C
   regarding support for a causal link, for both generative and
   preventive causes.                                                        w0                                w0        w1
   Keywords: causal learning; Bayesian inference
                                                                                   E                                  E
    Causal Inference in a Bayesian Framework
Intelligent behavior in a complex and potentially hostile                       Graph 0                           Graph 1
environment depends on acquiring and exploiting knowledge
of “what causes what.” It is likely that the cognitive               Figure 1. Graphs contrasting hypotheses that C causes E
mechanisms for causal learning have deep evolutionary roots,         (Graph 1) or does not (Graph 0). B, C, and E are binary
a conjecture supported by many parallels between phenomena           variables. Weights w0 and w1 indicate causal strength of the
in animal conditioning and human causal learning (see                background cause (B) and the candidate cause (C),
Shanks, 2004). Ever since the philosopher David Hume, the            respectively.
fundamental question about causal knowledge has been how
a learner can take non-causal inputs (notably, observations             A major strength of Bayesian inference is that it enables
regarding temporal order and covariation) and induce cause-          beliefs to be updated by integrating prior beliefs with new
effect relations as outputs. Cheng (1997) developed a theory         observations. Bayesian inference involves two basic
that integrates the Humean covariational view of causality           components, likelihood probabilities and prior probabilities.
with Kant’s conception of causal “powers”. Her power PC              Likelihoods assess the probability that particular observed
theory assumes that learners have a tacit understanding that         data would be expected under some hypothesis, and are
causes in the world have powers (i.e., strengths) to produce or      determined by the generating model for the data (e.g., how
prevent effects, and use observations to infer unobservable          multiple independently-operating causes produce an effect).
causal powers (for a review see Cheng et al., in press).             Priors assess beliefs about the world held before observing
   The view that learners have a tacit theory of causal powers       any particular data (e.g., beliefs about causal powers).
can be incorporated into a Bayesian framework for inference.            One variant of the “causal support” model developed by
Griffiths and Tenenbaum (2005) developed a Bayesian                  Griffiths and Tenenbaum (2005) used a generating model
model, closely related to the power PC theory, for inferring         proposed by Cheng (1997), based on a logical “noisy-OR”
whether a causal link exists between cause C and effect E            function (Eq. 4) for generative causes and “noisy-AND-
(i.e., model selection for the structure of the causal graph;        NOT” (Eq. 5) for preventive causes. (See Glymour, 2001, for
Mackay, 2003). Their model addressed the simplest variant of         a more general definition of what he termed “Cheng
                                                                 519

models”.) This causal-support variant yields causal power           necessary and sufficient causes (NS priors) would encourage
(Cheng, 1997) as the maximum likelihood estimate of a               causal networks that are inherently simple (ideally, one cause
causal strength parameter. The value of causal support (Eq. 2)      reliably predicts the effect). Such a prior would create a
is a measure of whether a causal link exists. As Griffiths and      generic expectation in accord with what Holland, Holyoak,
Tenenbaum (2005) noted, “Speaking loosely, causal support           Nisbett and Thagard (1986, p. 160) termed “the “unusualness
is the Bayesian hypothesis test for which causal power is an        rule, unexpected events signal other unexpected events.” For
effect size measure: it evaluates whether causal power is           example, rats often show initial conditioning to a novel cue
significantly different from zero” (p. 359).                        that precedes shock, even though the cue is in fact
                                                                    uncorrelated with shock (Rescorla, 1972). Readiness to “jump
    Necessity and Sufficiency as Generic Priors                     to causal conclusions” consistent with NS priors (assuming
   The second component of Bayesian inference, priors, will         they can be overturned if contradicted by later experience)
be especially important in guiding learning when data are           may have important survival value in a natural environment.
sparse or noisy, as is often the case for naturalistic causal          In the remainder of this paper we formulate the Bayesian
learning. In particular, the Bayesian formulation can take          model incorporating NS priors. We then summarize three
account of priors on the causal powers (i.e., w0 and w1). When      human experiments, and compare model predictions using
learners have no obvious reason to have specific priors about       NS versus uniform priors with human causal judgments.
weights (e.g., the power of a novel medicine to stop
headaches), one might suppose that the priors are simply                          Bayesian Model with NS Priors
uniform (e.g., Griffiths & Tenenbaum, 2005).                        A Bayesian decision can be formalized to infer causal
   It is possible, however, that even when the inputs are           structure by assessing whether a causal relationship exists
entirely novel, learners may be guided by generic priors—           between C and E after observing contingency data D. The
systematic assumptions about the abstract quantitative              decision variable is obtained from the posterior probability
properties of a variable. In the case of motion perception, for     ratio of Graphs 1 and 0 by applying Bayes’ rule:
example, human judgments of velocity are guided by the                    P(Graph1 | D)                 P( D | Graph1)          P(Graph1)
prior that motion tends to be slow and smooth. This generic          log                        = log                   + log
                                                                          P(Graph0 | D)                P( D | Graph0)          P(Graph0)
prior explains a wide range of visual illusions and motion
                                                                                                                                         (1)
perception phenomena (Lu & Yuille, 2006; Weiss, Simoncelli
                                                                    Griffiths and Tenenbaum (2005) defined the first term on the
& Adelson, 2002; Yuille & Grzywacz, 1988).
                                                                    right of Eq. 1 (log likelihood ratio) as “causal support” (the
   We propose that in the case of causal learning, people (and
                                                                    second term, the log prior odds, is a constant). In general,
possibly other animals) have a prior favoring causes that are
                                                                    support can be defined as the log posterior odds,
necessary and sufficient (e.g., a genetic defect on
chromosome 4 is necessary and sufficient to cause                                                            P(Graph1 | D)              (2)
                                                                                        support = log                        ,
Huntington’s disease). The importance of necessity and                                                      P(Graph0 | D)
sufficiency in causal inference was first discussed by J. S.        a measure of the evidence that data D provide in favor of
Mill (1843). Causal necessity is the focus of the “but for”         Graph 1 over Graph 0.
condition in law, and of the concept of attributable risk in           The likelihoods on graphs are computed by integrating out
epidemiology. In psychology, some have placed particular            the unknown causal strengths w0 and w1, which are
emphasis on sufficiency (e.g., Mandel & Lehman, 1998).              parameters in the range {0,1} associated with the powers of B
Pearl (2000) reinterpreted various well-known causally-             and C, respectively,
related measures in terms of probabilistic necessity and                                   1 1
sufficiency (causal power as “probability of sufficiency”;
                                                                     P ( D | Graph1) =   ∫ ∫ P ( D | w ,w , Graph1) P ( w , w | Graph1)dw dw
                                                                                           0 0
                                                                                                        0  1             0   1            0   1
attributable risk as “probability of necessity”; and ΔP as
                                                                                            1
                                                                     P ( D | Graph 0) = ∫ P ( D | w , Graph 0) P ( w | Graph 0) dw
                                                                                                      0             0               0    (3)
                                                                                            0
“probability of necessity and sufficiency”). Lien and Cheng
                                                                    where      P( D | w0 , w1 , Graph1) and P( D | w0 , Graph0) are the
(2000) proposed and provided evidence that a tacit goal of
maximizing ΔP (i.e., necessity and sufficiency jointly),            likelihood probabilities of the observed data given specified
conditional on “no confounding”, guides human induction of          causal strengths and structures. P( w0 , w1 | Graph1) and
categories and causal powers at multiple hierarchical levels.        P( w0 | Graph0) are prior probabilities that model the learners’
However, previous researchers have not considered the
                                                                    beliefs about the values of causal strengths.
possibility that the goal of maximizing the necessity and
                                                                       The likelihood terms are derived using the generating
sufficiency of causes may provide relational generic priors
                                                                    functions specified by the power PC theory. Let +/− indicate
that guide elemental causal induction.
                                                                    the value of the variable to be 1 vs. 0. For a Cheng model
   Bayesian inference focuses on probabilistic rather than
                                                                    (noisy-OR) in which B and C are both potential generative
strictly deterministic relations. It would seem that most
                                                                    causes, the probability of observing E is given by
naturally-occurring causal relations are probabilistic, such
that C is in fact neither necessary nor sufficient to produce E          P (e + | b, c; w 0 , w1 ) = 1 − (1 − w0 ) b (1 − w1 ) c          (4)
(e.g., the link between smoking and cancer). Nonetheless, a          b, c ∈ {0,1} varies with absence vs. presence of C (b is
prior with weight peaks indicative of “approximately”
                                                                    always 1). In the preventive case, B is assumed to be
                                                                520

potentially generative (following the “no background                                                               where α and Z are defined as in Eq. 7. As in the generative
preventers” assumption of the power PC theory) and C is                                                            case, P( w0 | Graph0) is obtained as the marginal of
potentially preventive. The resulting noisy-AND-NOT
generating model for preventive causes is                                                                           P( w0 , w1 | Graph1) :
            P (e + | b, c; w0 , w1 ) = w0 (1 − w1 ) c
                                                          b
                                                                                                       (5)                             P ( w0 | Graph0) = e −α (1− w0 ) / Z              (10)
   If data D is summarized by contingencies N(e,c), the                                                            By substituting Eqs. 6 ~ 10 into Eq. 3, we can incorporate NS
number of cases for each combination of presence vs. absence                                                       priors into computation of support for a causal link (Eq. 2).
of the effect and cause, then the likelihood given causal                                                          Fig. 2 depicts the prior distributions used in generative and
strengths (w0, w1) and structures (Graph 0,1) is                                                                   preventive cases.
 P ( D | w0 , w1 , Graph1)
      ⎛ N (c −) ⎞ N ( e + , c − )
  = ⎜⎜                     ⎟⎟ w0            (1 − w0 ) N ( e −, c − )
      ⎝ N   ( e + , c −  )  ⎠
         ⎛ N (c + ) ⎞
         ⎜⎜                    ⎟⎟[1 − (1 − w0 )(1 − w1 )]N ( e + , c + ) [(1 − w0 )(1 − w1 )]N ( e −, c + )
          ⎝ N (e +, c + ) ⎠
 P ( D | w0 , Graph0)
    ⎛ N (c −) ⎞⎛ N (c +) ⎞ N ( e + , c − ) + N ( e + , c + )
 = ⎜⎜                   ⎟⎟⎜⎜                   ⎟⎟ w0                 (1 − w0 ) N ( e −, c − ) + N ( e −, c + )
    ⎝ N  ( e +  , c − )  ⎠⎝   N  ( e + , c + )  ⎠
                                                                                              (6)
                                                                                                                   Figure 2: Prior distributions over w0 and w1 with NS priors.
              ⎛n⎞                                                                                                  Left: Generative case, α = 30 (peaks at 0,1 and 1,0); right:
where ⎜⎜ ⎟⎟ denotes the number of ways of picking k                                                                Preventive case, α = 30 (peak at 1,1).
              ⎝k ⎠
unordered outcomes from n possibilities.                                                                                                Overview of Experiments 1-3
  The second component in Eq. 3 is the prior on causal
strength, P( w0 , w1 | Graph1) and P( w0 | Graph0) . Griffiths and
                                                                                                                   Methods
Tenenbaum (2005) assumed that the priors on weights w0 and
w1 follow a uniform distribution. Our guiding hypothesis is                                                        Materials and procedure were very similar across all 3
that generic priors will favor necessary and sufficient causes.                                                    experiments. Experiments 1-2 are from Liljeholm (2006). A
Accordingly, we set priors favoring NS generative causes,                                                          simultaneous presentation format, adapted from that used by
with the prior distribution peaks for w0, w1 at 0,1 (C is an NS                                                    Buehner, Cheng and Clifford (2003, Ex. 2), was used to
cause) and 1,0 (B is). We use the exponential formulation                                                          minimize memory demands and other processing issues
                                                                                                                   extraneous to causal inference (see Fig. 3). The cover story
                                           1
                                                [
 P( w0 , w1 | Graph1) = e −αw0 e −α (1− w1 ) + e −α (1− w0 ) e −αw (7)
                                           Z
                                                                                               ]                   always involved a set of allergy patients who either did or did
                                                                                                                   not have a headache (E), and either had or had not received a
where α is a parameter controlling how strongly necessary                                                          new allergy medicine (C); the query concerned whether as a
and sufficient causes are preferred, and Z is a normalizing                                                        side effect the medicine caused headache (generative
term that ensures the sum of the prior probabilities equals 1.                                                     conditions) or relieved headache (preventive conditions).
When α = 0, the prior follows a uniform distribution,                                                              Each patient was represented by a cartoon face
indicating no preference to any values of causal strength.                                                         that was either frowning (headache) or smiling (no headache).
Griffiths and Tenenbaum’s (2005) support model is thus                                                             The data were divided into 2 subsets, each an
derived as a special case. The present formulation provides an                                                     array of faces. The top subset represented patients who had
analytic calculation of support values.                                                                            not received the medicine; the bottom subset represented
    P( w0 | Graph0) is                       obtained as the marginal of                                           patients after receiving the medicine.
 P( w0 , w1 | Graph1) by integrating out w1,                                                                                               = headache
                                                                                                                                                                      Figure 3. Example
                                                   1
                                                   Z
                                                     [
             P ( w0 | Graph 0) = e −αw0 + e −α (1− w0 )                         ]                      (8)                  When t hese pat ient s were not given any
                                                                                                                            medicine, t his is how t hey w ere:
                                                                                                                                                                      of an experimental
                                                                                                                                                                      display,     showing
   In the preventive case B is again assumed to be generative,                                                        No   Medicine
                                                                                                                                                                      patients who had not
hence only C could be a preventer (i.e., B and C do not                                                                                                               (top)     or     had
compete). Evidence for C as an NS preventer will be clearest                                                                                                          (bottom) received an
when B is a sufficient generative cause (w0 = 1), yielding a                                                                                                          allergy    medicine,
likelihood peak for w0, w1 at 1,1:                                                                                          When Medicine A w as given to them,       and who either had
                                                                                                                            t his is how t hey were:
                P( w0 , w1 | Graph1) = e −α (1− w0 ) e −α (1− w1 ) / Z                                 (9)                                                            or had not developed
                                                                                                                     Medicine     A
                                                                                                                                                                      headaches.
                                                                                                               521

   The specific contingency conditions in each experiment are       “virtual sample” (Liljeholm, 2006), defined as the number of
shown in Figs. 4-5. The code in the figures indicates number        cases in which C could potentially reveal its influence; the
of patients with headache out of number who had not                 complementary maximally suboptimal base rates lead to
received the medicine (i.e., base rate of the effect), and          ceiling effects such that the power of C cannot be determined
number with headache out of number who did receive the              from the data. (4) Direction of causation: In Ex. 1, there was
medicine. The number of cases in the sample was varied. In          evidence of a possible interaction between causal direction
the figures and all analyses, generative and preventive             and contingency condition. In particular, for conditions where
conditions are identical except that the frequencies of             w1 = 1, preventive ratings tended to be higher than generative
headache and no headache are transposed. For example, the           ratings when the base rate was far from optimal, with the
generative case 2/8, 8/8, where P(E|C) = .25, P(E|C) = 1,       difference diminishing as the base rate approached optimal. A
power = 1, is matched to the symmetrical preventive case 6/8,       comparison of the direction effect for the conditions in which
0/8, where P(E|C) = .75, P(E|C) = 0, power = 1. Ex. 1           the generative base rate was .75 (.25 preventive) vs. .25 (.75
included a series of contingency conditions in which the            preventive) yielded a significant interaction, F(1, 51) = 4.71,
causal power of the medicine was 1 but the base rate of             p = .035. Similar differences between preventive and
headache was varied, plus additional conditions with lower          generative judgments have been observed for causal strength
causal power.                                                       judgments (Liljeholm, 2006; Wang & Fu, 2005).
   The specific query regarding existence of a causal link
varied across experiments. In Ex. 1 the query (generative                 Model Fits to Human Causal Judgments
conditions) was, “ How likely is it that this medicine              Data from all 3 experiments were fit using the Bayesian
produces headaches?＂ with the response being a numerical            model with either NS or uniform priors. An α value of 30 for
rating on a line marked in units of 10 from 0 (extremely            NS priors was selected using data from Ex. 1, and then held
unlikely) to 100 (extremely likely). For preventive conditions,     constant in fitting data from Ex. 2-3. The model with uniform
“produces＂ was replaced by relieves＂. The dependent                 priors (α = 0) is identical to that of Griffiths and Tenenbaum
measure was the rating in each condition. In Ex. 2 the query        (2005). For both NS and uniform priors, support values were
was, "Does this medicine cause headache? Rate how                   scaled to human data (a 100-point confidence scale) using a
confident you are that this medicine causes headache" on a          best-fitting power transformation (the same procedure
100-point confidence scale. The dependent measure was the           employed by Griffiths & Tenenbaum).
rating in each condition. In Ex. 3, the query was to select one        Figs. 4-5 each show the data for human causal judgments
of two alternatives: “This medicine has absolutely no               (top) along with predictions based on NS priors (middle) and
influence on headache ＂ (no link) or “ This medicine                uniform priors (bottom). Ex. 1 tested 30 contingency
produces headache＂ (link exists), rating confidence in the          conditions (15 generative and 15 preventive) with sample
answer on a 100-point scale. The dependent measure was              sizes of 32 (left side of Fig. 3) and 128 (right side). Although
mean confidence that a link exists (treating the rating as          both Bayesian models fit the human data reasonably well, the
negative when the answer was that no link exists).                  overall correlation was substantially higher with NS priors (r
   Participants were UCLA undergraduates in the Psychology          = .94) than with uniform priors (r = .71).
Department subject pool. Generative versus preventive                  Two qualitative aspects of the data favor the model with
conditions in Ex. 1 was a between-subject variable. In Ex. 1-       NS priors. First, NS priors capture the fact that human
2, contingency condition was a within-subjects variable, with       judgments of confidence in a causal link were more sensitive
order of presentation randomized. In Ex. 3 each participant         to causal power and P(E+|C−) (base rate of the effect; e.g.,
evaluated a single condition. The data points for humans            increasingly optimal across left 6 contingencies in Fig. 4)
shown in Figs. 4-5 are each mean ratings based on responses         than to sample size. Uniform priors place relatively greater
from 20-33 participants.                                            weight on sample size. Second, NS priors capture the
                                                                    apparent asymmetry between generative and preventive
Judgment Patterns                                                   judgments for cases matched on causal power and optimality
   Before presenting the modeling results, it will help to          of the base rate. For the human data, for 9 of the 10 matched
characterize the major factors that influenced link judgments       conditions in which the base rate is non-optimal, the
for both generative and preventive conditions (see Figs. 4-5).      preventive rating exceeds the generative case. The
(1) Causal power: high power led to higher confidence there         asymmetric NS priors (1 peak for preventive causes, 2 for
is a link. (2) Sample size: an overall larger sample tended to      generative) capture this subtle interaction between preventive
yield higher confidence (a surprisingly weak but statistically      and generative judgments. In contrast, the model with
reliable factor in Ex. 1). (3) Base rate of effect, P(E+|C−):       uniform priors (like all previous formal models of causal
confidence was higher when the base rate was more optimal           judgments) predicts strict equality of matched generative and
for revealing any influence of the candidate cause, where the       preventive conditions.
optimal base rate is 0 for the generative case and 1 for the
preventive case. More optimal base rates lead to a larger
                                                                522

                                                                                                        Figure 4: Confidence in a
                                                                                                        causal link (Ex. 1).
                                                                                                        Numbers along top show
                                                                                                        stimulus contingencies for
                                                                                                        generative cases; those
                                                                                                        along      bottom    show
                                                                                                        contingencies for matched
              Confidence in causal link
                                                                                                        negative cases. Top: Data
                                                                                                        from Ex. 1 (error bars
                                                                                                        indicate 1 standard error);
                                                                                                        middle: Predictions of
                                                                                                        Bayesian model with NS
                                                                                                        priors, α = 30 ; bottom:
                                                                                                        Predictions with uniform
                                                                                                        priors, α = 0 .
   Ex. 2 provided a further test of the relative potency of                    In the extreme, when the presented contingencies closely
power and sample size as determinants of human causal                       match the NS priors, the model with these generic priors
judgments. This study employed two intermediate                             predicts that people will be highly confident in the presence
contingencies (powers of .4 and .67) at sample sizes 36 and                 of a causal link after only a few observations. Ex. 3 was
72 (generative conditions only). As shown in Fig. 5A, NS                    designed to test this prediction, comparing judgments for
priors provided a far better fit to the human data (r = .97)                contingencies close to NS priors with a small sample size
than did uniform priors (r = .20). As in Ex. 1, NS priors                   of 16 to contingencies far from NS priors with a
capture the greater potency of power relative to sample                     substantially larger sample size of 128. As shown in Fig.
size, whereas uniform priors erroneously predict the                        5B, NS priors again provided a much better fit (r = .84)
opposite trade-off.                                                         than did uniform priors (r = −.15). As predicted, people
                                                                            placed much greater weight on match to NS priors than on
                                                                            sample size. In the most dramatic case, where the data fit
  A                                       B                                 the generative peak at w0 = 0, w1 = 1, human mean
                                                                            confidence was 85 on the 100-point scale after just 16
                                                                            observations. NS priors closely match the human level of
                                                                            high confidence, whereas uniform priors erroneously
                                                                            predict a confidence level below 50. Moreover, uniform
   Confidence in causal link              Confidence in causal link
                                                                            priors generate the wrong ordinal ranking of this favorable
                                                                            contingency relative to the rightmost condition in Fig. 5B
                                                                            (a case of lower power with a much high sample size).
                                                                                   Conclusions and Future Directions
                                                                              We have established that a Bayesian formulation of
                                                                            causal inference that incorporates (1) a theory of learners’
                                                                            model of the generating model for binary causal variables
                                                                            and (2) generic priors favoring necessary and sufficient
                                                                            causes can explain the pattern of human causal judgments
                                                                            about existence of causal links. In contrast, a formulation
                                                                            assuming uniform priors (Griffiths & Tenenbaum, 2005) is
  Figure 5. Confidence in a causal link. A: Ex. 2.                          unable to account for key findings. Humans place greater
  B: Ex. 3. See Fig. 4 caption for additional information.                  weight on match to NS priors than on size of the sample of
                                                                      523

observations, and their causal judgments reveal a                         for coherence. In M. O’Rourke (Ed.), Topics in
systematic interaction between preventive and generative                  contemporary philosophy (Vol. 4): Explanation and
ratings. NS priors are a special case of a general preference             causation. Cambridge, MA: MIT Press.
for simplicity in causal networks (cf. Novick & Cheng,               Glymour, C. (2001). The mind’s arrows: Bayes nets and
2004, p. 471).                                                            graphical causal models in psychology. Cambridge,
   The present Bayesian formulation, like that of Griffiths               MA: MIT Press.
and Tenenbaum (2005), is based on a noisy-OR and noisy-              Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure and
AND-NOT generating model (Cheng model). Griffiths and                     strength in causal induction. Cognitive Psychology, 51,
Tenenbaum also discussed an alternative formulation based                 334-384.
on a linear generating model that yields ΔP (i.e., P(E+|C+ −         Holland, J. H., Holyoak, K. J., Nisbett, R. E., & Thagard, P.
P(E+|C−)) as a strength measure. This model gives an                      (1986). Induction: Processes of inference, learning,
incoherent account of independent causal influence (Cheng,                and discovery. Cambridge, MA: MIT Press.
1997; Cheng et al., in press). It is clear the linear model will     Lien, Y., & Cheng, P. W. (2000). Distinguishing genuine
fail for the data modeled in the present paper. To take one               from spurious causes: A coherence hypothesis.
simple example, each contingency in Ex. 2 (Fig. 5A) is                    Cognitive Psychology, 40, 87-137.
equated for ΔP (.33); accordingly for paired conditions at           Liljeholm, M. (2006). Structure learning, parameter
each sample size, values of P(E+|C−) and P(E+|C+) vary                    estimation and causal assumptions. Ph.D. dissertation,
symmetrically around .5. Since generative priors (either                  UCLA Department of Psychology.
uniform or NS) for w0 and w1 are also symmetrical around             Lu, H., & Yuille, A. (2006). Ideal observers for detecting
.5, for these contingencies the linear model with either set              motion: Correspondence noise. Proceedings of Neural
of priors will necessarily predict support values that vary               Information Processing Society.
only with sample size. Clearly, however, people’s                    Mackay, D. (2003). Information theory, inference and
confidence ratings varied with power within each sample-                  learning algorithms. Cambridge, UK: Cambridge
size condition even though ΔP was constant.                               University Press.
   A major advantage of the Bayesian formulation of causal           Mandel, D. R., & Lehman, D. R. (1998). Integration of
learning, when coupled with the concept of causal power, is               contingency information in judgments of cause,
that it is compositional: it allows the formulation of                    covariation, and probability. Journal of Experimental
coherent answers to a wide variety of causal queries. Here                Psychology: General, 127, 269-285.
we have focused on modeling support for a causal link, but           Mill, J. S. (1843). System of logic, Vol. 1. London: John
the same formulation can also be used to model judgments                  Parker.
of causal strength and confidence in strength judgments.             Novick, L. R., & Cheng, P. W. (2004). Assessing
Additional work will be required to extend the formulation                interactive causal influence. Psychological Review,
to situations involving multiple candidate causes, potential              111, 455-485.
interactive influences among causes, sequential                      Pearl, J. (2000). Causality. Cambridge, UK: Cambridge
presentation of data, and diagnostic inference from                       University Press.
observed effects to possible causes.                                 Rescorla, R. A. (1972). Informational variables in
                                                                          Pavlovian conditioning. In G. H. Bower (Ed.), The
                                                                          psychology of learning and motivation. New York:
                   Acknowledgments
                                                                          Academic Press.
Preparation of this paper was supported by a grant from the          Shanks, D. R. (2004). Judging covariation and causation. In
W. H. Keck Foundation to AY, NIH grant MH64810 to                         D. Koehler & N. Harvey (Eds.), Blackwell handbook
PC, and NSF grant SES-0350920 to KH.                                      of judgment and decision making. Oxford, UK:
                                                                          Blackwell.
                        References                                   Wang, M. Y., & Fu, X. L. (2005). Causal judgments in the
Buehner, M. J., Cheng, P. W., & Clifford, D. (2003). From                 trial-by-trial presentation. Acta Psychologica Sinica,
      covariation to causation: A test of the assumption of               37, 51-61.
      causal power. Journal of Experimental Psychology:              Weiss, Y., Simoncelli, E.P., & Adelson, E.H. (2002).
      Learning, Memory, and Cognition, 29, 1119-1140.                     Motion illusions as optimal percepts. Nature
Cheng, P. W. (1997). From covariation to causation: A                     Neuroscience, 5, 598-604.
      causal power theory. Psychological Review, 104, 367–           Yuille, A., & Grzywacz, N. M. (1988). A computational
      405.                                                                theory for the perception of coherent visual motion.
Cheng, P. W., Novick, L. R., Lijeholm, M., & Ford, C. (in                 Nature, 333, 71-74.
      press). Explaining four psychological asymmetries in
      causal reasoning: Implications of causal assumptions
                                                                 524

