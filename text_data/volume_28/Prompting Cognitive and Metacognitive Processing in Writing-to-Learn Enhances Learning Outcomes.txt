UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Prompting Cognitive and Metacognitive Processing in Writing-to-Learn Enhances Learning
Outcomes

Permalink
https://escholarship.org/uc/item/6t560264

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Hübner, Sandra
Nückles, Matthias
Renkl, Alexander

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Prompting Cognitive and Metacognitive Processing in Writing-to-Learn Enhances
Learning Outcomes
Sandra Hübner (huebner@psychologie.uni-freiburg.de)
Matthias Nückles (nueckles@psychologie.uni-freiburg.de)
Alexander Renkl (renkl@psychologie.uni-freiburg.de)
University of Freiburg, Educational Psychologie, Engelbergerstr. 41
79085 Freiburg, Germany

instructional support procedure for writing learning protocols. We present an experiment that analyzed the effects that
various types of instructions for writing a learning protocol
had on understanding and retention. Furthermore, we examined how the specific instructions are reflected in the learning protocols.

Abstract
Learning protocols are a promising follow-up course work. A
learning protocol is a written explication of one’s learning
processes and outcomes. According to the self-regulation
view of writing-to-learn, such writing assignments have to be
supported. In this study, learning protocols were structured by
prompts to elicit important learning activities as they are postulated in a cyclical model of self-regulated learning. An experiment (N = 103) was conducted in which students received
either (a) no prompts, (b) cognitive prompts, (c) metacognitive prompts, (d) mixed prompts without planning-ofregulation prompts or, (e) mixed prompts including planningof-regulation prompts. The groups with prompts outperformed the control group on comprehension and retention
measures. Furthermore, prompting all essential sub-processes
of self-regulated learning (mixed prompts including planningof-regulation prompts) was most effective.

Theoretical Approaches to Writing-to-Learn
Learning by writing can be considered from different theoretical perspectives (Bangert-Drowns, Hurley, & Wilkinson,
2004). According to the strong text view of writing-to-learn
(e.g., Emig, 1977), the processes involved in writing share
intrinsic similarities with thinking and learning processes. It
is assumed that writing inherently fosters thinking and
learning. In line with this assumption, empirical studies
generally showed a superiority of learning journal groups
over non-writing groups (Connor-Greene, 2000). However,
following the meta-analysis of Bangert-Drowns et al., most
writing-to-learn assignments yielded rather small effects,
typically showing an effect size of .20 on average. Hence,
writing per se does not necessarily foster learning to a practically relevant degree. Rather, following Bangert-Drowns
et al. conclusions, it is the specific type of writing assignment that strongly influences the learning processes and
outcomes. In their meta-analysis, the most important moderator variable was the presence of prompts that stimulated
metacognitive processing such as monitoring and regulation
of one’s own learning processes. Bangert-Drowns et al. concluded that the available evidence clearly supports a selfregulation view of writing-to-learn rather than the strong
text view. According to the self-regulation view, writing as
such does not produce learning. Nevertheless, writing may
serve as medium that facilitates the application of beneficial
cognitive and metacognitive learning activities. However, as
argued by Bangert-Drowns et al. (2004), students should
explicitly be prompted to elicit the desirable learning activities to a satisfactory degree. For example, Nückles et al.
(2004) analysed “naïve” learning protocols of students who
had only received brief and informal advice on how to write
their protocols. They found that cognitive and metacognitive
learning activities did not occur frequently. These results
underscore the necessity to support the writing of learning
protocols.
How should the writing of learning protocols be supported? Following current models of self-regulated learning
(Winne, 1996; Zimmerman, 1999), students should be as-

Keywords: writing-to-learn; self-regulated learning; prompts;
cognitive and metacognitive learning processes; learning
journals

Introduction
Typically, lesson or lecture contents “evaporate” rather
quickly, for after the students have left the classroom, only a
few continue to reflect on the learning contents. The students rarely elaborate and organize learning contents in a
meaningful and coherent fashion. For example, they seldom
come up with examples to put abstract concepts into effect.
Also, students neither routinely monitor their understanding
nor employ corresponding remedial activities. The writing
of learning protocols is a method that helps to overcome
these shortcomings (McCrindle & Christensen, 1995). A
learning protocol represents a written explication of one’s
own learning processes and outcomes. When such protocols
are written in an extended period of time (e.g., a whole term
or school year) we call it a “learning journal” (cf. McCrindle
& Christensen). Learning protocols are especially
appropriate for follow-up course work. They help students
apply the previously mentioned cognitive and metacognitive
activities. The writing of learning protocols has been shown
to be effective in improving students’ learning across various educational settings and subjects (Cantrell, Fusaro, &
Doughtery, 2000; McCrindle & Christensen, 1995). However, there is also evidence that without appropriate instructional support, students do not apply the learning protocol
method in an optimal way (Nückles, Schwonke, Berthold, &
Renkl, 2004). To bridge this gap, we have developed an
357

sisted to elicit both cognitive and metacognitive learning
activities. They should start with organizing and elaborating
the learning contents. Organizational activities (e.g., identifying main points) help establish internal links, that is, finding a meaningful structure of the learning contents. Elaboration activities (e.g., generating examples) serve to build external links that relate the new material to the learner’s prior
knowledge (Mayer, 1984). Additionally, students should
continuously monitor their cognitive activities in order to
prevent illusions of understanding that might inhibit further
learning (Chi, DeLeeuw, Chiu, & LaVancher, 1994). Such
metacognitive activities help to identify knowledge gaps,
comprehension difficulties or impasses. For example, work
on cognitive skill acquisition found that impasses were often
associated with learning (VanLehn, Siler, Murray, Yamauchi, & Baggett, 2003). If impasses are detected, students
endeavour to actively construct a better understanding.
Therefore, they plan regulation activities to overcome the
impasses. In the context of this regulation students go back
to remedial organizational and elaborative activities. Following Zimmerman (1999), this sequence of cognitive and
metacognitive activities can ideally be conceived of as a
cyclical and interactive process (see Figure 1).

prompt productive learning activities in learning protocols.
However, only the elicitation of cognitive activities or the
simultaneous elicitation of both cognitive and metacognitive
activities fostered learning success. Although the metacognitive prompts yielded a higher amount of metacognitive
activities in the learning protocols, this increase in metacognitive activities did not result in a greater learning advantage. Hence, it may be the case that metacognitive strategies
alone do not contribute to learning success. In order to be
effective, metacognitive strategies apparently had to be applied in combination with cognitive learning strategies. On
the other hand, it has to be acknowledged that the experimental setting did not provide ample opportunity for metacognitive activities to become effective. Although the metacognitive prompts induced the students to monitor their
comprehension and to detect difficulties, the opportunities
for engaging in regulation were rather limited. For example,
it was neither possible for the learners to study critical parts
of the videotaped lecture once again nor to read the text on
which the lecture was based. The inefficacy of metacognitive activities could therefore alternatively be explained by
the assumption that the cycle of self-regulation (see Figure
1) was interrupted. According to this model of self-regulated
learning, remedial activities could actually be planned, but
in this case, there was no possibility to carry them out. To
answer the question whether metacognitive activities per se
do not improve learning success we conducted another experiment. An experimental procedure was applied that was
nearly identical to Berthold et al. (2004). First, the students
watched a videotaped lecture. Next they wrote a learning
protocol about the lecture contents. However, in contrast to
the Berthold et al. study, the participants in our experiment
were then given ample opportunity to engage in regulation
activities. After the students had produced a first draft of
their learning protocol, they received an instructional text
that was based on the lecture they had just viewed. Hence,
the participants had the opportunity to resolve their comprehension problems with the help of the lecture text. If they
detected a comprehension problem during the monitoring of
their cognitive learning processes, they could plan and realize concrete regulation activities, such as reading a specific
passage in the lecture text.
Given that the modified experimental setting better allowed for the realization of regulation activities, we were
further interested in ascertaining if those regulation activities would occur spontaneously or if they had to be explicitly prompted. Therefore we extended the design of Berthold
et al. (2004). In their experiment, the “combination group”
(cognitive and metacognitive prompts) did not receive planning-of-regulation prompts to support this particular metacognitive activity. In our study, we additionally introduced
another “combination group”. Following the cyclical model
of self-regulated learning (cf. Figure 1), this group received
prompts stimulating all three essential sub-processes: a)
prompts for organization and elaboration, b) prompts for
monitoring, and c) prompts for planning of regulation. Accordingly, this group should perform the highest compared

Monitoring

Organization &
Elaboration

Planning
of Regulation

Figure 1: Cyclical model of self-regulated learning.
Berthold, Nückles, and Renkl (2004) conducted an experiment in which they prompted the use of cognitive and
metacognitive learning activities in writing a learning protocol. In their study, students received one of four instructions
for writing a learning protocol about a videotaped lecture
they had previously viewed. The instruction either included
six cognitive (i.e., organizational and elaborative) prompts
(e.g., “How can you best organize the structure of the learning content?”), six metacognitive prompts (e.g., “Which
main points haven’t I understood yet?”), a mixture of three
cognitive and three metacognitive prompts, or no prompts at
all (control condition). Results showed that learners who
received cognitive, or cognitive and metacognitive prompts
significantly outperformed the control group with regard to
(a) the amount of cognitive and metacognitive activities in
the learning protocols, (b) the learning outcomes on both an
immediate comprehension test and a seven-days delayed
retention test. These findings show that it is possible to
358

with all other groups. Furthermore, if regulation activities
(i.e., remedial cognitive activities) do not occur spontaneously in our modified experimental design, but have to be
explicitly prompted, the group who received mixed prompts
including planning-of-regulation prompts should outperform
the participants who received only a mixture of cognitive
and metacognitive prompts without planning-of-regulation
prompts.

struction in the third condition presented six metacognitive
prompts including monitoring and planning-of-regulation
prompts (“metacognitive prompts condition”, n = 20). The
instruction in the fourth condition existed of a combination
of three cognitive (organization and elaboration) and three
metacognitive prompts, whereas the metacognitive prompts
existed only of monitoring prompts and did not include
planning-of-regulation prompts (“mixed prompts without
planning-of-regulation prompts”, n = 20). The instruction in
the fifth condition presented two cognitive prompts (organization and elaboration) and four metacognitive prompts,
whereas two monitoring and two planning-of-regulation
prompts were included (“mixed prompts including planning-of-regulation prompts”, n = 20). Dependent variables
encompassed students’ knowledge acquisition and measures
of learning activities in the learning protocol.

Research Questions
Based on these theoretical considerations, we addressed the
following four research questions: (1) Do cognitive prompts
and the combination of cognitive and metacognitive
prompts foster learning outcomes? This question basically
investigates whether the results of the Berthold et al. study
(2004) can be replicated. (2) Can metacognitive prompts
foster learning outcomes if the experimental setting allows
for the realization of remedial regulation activities? (3) Will
a mixture of cognitive and metacognitive prompts including
planning-of-regulation prompts produce the highest learning
outcomes in comparison to all other conditions? (4) Does
the mixture of cognitive and metacognitive prompts including planning-of-regulation prompts lead to higher learning
outcomes than the combination of cognitive and metacognitive prompts without planning-of-regulation prompts, because planning of regulation has to be explicitly prompted?
Furthermore, we analyzed whether the various combinations of prompts did in fact elicit the corresponding activities in the learning protocols. Accordingly, we assumed that
(5) organization and elaboration prompts would increase the
amount of organizational and elaborative activities in the
learning protocols, and (6) monitoring prompts would successfully stimulate monitoring activities. We further expected that (7) planning-of-regulation prompts would raise
students’ planning of regulation activities in the initial version of their learning protocol and accordingly help them
realize remedial cognitive activities (“realized regulation”)
in the revision of the learning protocol.

Materials and Instruments
Videotaped lecture and pretest A videotaped lecture (duration: ca. 30 min) on Cognitive Load Theory (Sweller, van
Merrienboer, & Paas, 1998) was presented. This assured
that the lecture content and the presentation were standardized across all experimental conditions. A pretest assessed
the students’ prior knowledge about Cognitive Load Theory.
It consisted of four open-ended questions (e.g., “What is the
meaning of the notion of cognitive overload? How it is related to knowledge acquisition?”).
Types of prompts Except for the control group, the participants in the other groups received instructions that included
specific combinations of cognitive and metacognitive
prompts as described previously. Cognitive prompts were
intended to stimulate organizational activities (e.g., “How
can you best organize the structure of the learning content?”) and elaboration activities (e.g., “What example can
you think of that illustrates, confirms, or conflicts with the
learning contents?”). We applied two types of metacognitive
prompts. Whereas monitoring prompts were meant to elicit
monitoring activities (e.g., “Which main points haven’t I
understood yet?”), planning-of-regulation prompts were
provided to support regulation activities (e.g., “What possibilities do I now have to overcome my comprehension problem?”).

Method
Participants and Design
Undergraduate students (N = 103) from different departments of the University of Freiburg participated in the experiment. Most of them attended courses in Educational
Psychology as part of their studies. Only students who had
no relevant prior knowledge with regard to the concrete
learning material provided in the videotaped lecture were
eligible for participation. For the experiment, we used a onefactorial between-subjects design that comprised five different experimental conditions. In the first condition, the participants received a brief and rather informal advice on protocol composition without any prompts at all. This was our
control group (“no prompts condition”, n = 22). In the second condition, the participants additionally obtained six
cognitive prompts including organization and elaboration
prompts (“cognitive prompts condition”, n = 21). The in-

Posttest A comprehension test was administered that consisted of nine open-ended questions (e.g. “What is the meaning of the modality effect? How is it related to knowledge
acquisition?”). In order to measure retention of the learning
contents, the same test was administrated once again seven
days later (“delayed retention test”).

Procedure
The experiment consisted of two sessions. In the first session the participants took the pretest assessing their prior
knowledge. Next, they attended the videotaped lecture on
Cognitive Load Theory. Then, the participants spent 30
minutes writing an initial version of their learning protocol.
359

They received one of the five instructions. When the students had finished the first draft of their learning protocol,
all participants obtained an instructional text on which the
videotaped lecture was based. They were told that they
could use the text to revise their learning protocol. The students then spent another 30 minutes on this revision. The
initial instruction was still available. No additional prompts
were provided. Immediately after the completion of their
revisions, students were asked to complete a comprehension
test. In the second session seven days later, the students
completed the delayed retention test.

were resolved by discussion. The interrater reliability was
high (ICC = .85) as determined by the intraclass-coefficient.

Results
Learning Outcomes
A one-factorial ANOVA revealed that there were no significant differences between the conditions with respect to prior
knowledge, F < 1. Table 1 shows the mean scores and standard deviations of the outcome measures (first two rows)
and the applied learning activities in the learning protocols
separately for the five experimental conditions.

Analyse and Coding
Immediate and delayed test Two independent raters scored
the level of comprehension in the students’ answers to the
nine open-ended questions in the immediate comprehension
test and in the delayed retention test. The level of comprehension was assessed by using the SOLO Taxonomy
(“Structure of Observed Learning Outcome”) proposed by
Biggs and Collis (1982). According to the SOLO Taxonomy, for each answer we differentiated six levels of knowledge structure ranging from 1 (= no central points, no relation to the Cognitive Load Theory, incoherent) to 6 (= all
central points, high relation to the Cognitive Load Theory,
very coherent). The interrater reliability as determined by
the intraclass-coefficient was very high (ICC = .94).

Table 1: Means and Standard Deviations (in Brackets) of the
Dependent Variables of the Experiment.
Experimental Condition

Learning protocols For the content analysis of the learning
protocols, a coding scheme was developed that aimed at
identifying the cognitive and metacognitive activities displayed in Figure 1. Therefore, statements concerning the
purpose of structuring the contents in a meaningful way
(e.g., organizing the learning content) and statements in order to relate new material to prior knowledge (e.g., generating examples) were assigned to the category Organization
& Elaboration. To measure the different types of metacognitive activities (monitoring and planning of regulation) we
conducted two metacognitive categories. The category
Monitoring comprised of statements indicating the level of
understanding (e.g., “I did not understand the concept germane load.”) and comments concerning the reason for those
problems (“This section in the lecture was confusing.”). In
order to identify articulated planned regulation in the initial
version of the protocol (e.g., “I could refer this in a textbook.”) we used the category Planning of Regulation. The
category Realized Regulation included cognitive activities
in the second draft of the protocol that are executed by the
students to solve problems or to overcome impasses. As a
preparation for the coding, the learning protocols were first
segmented into single statements as the coding unit. To this
purpose, we used a procedure originally suggested by Erkens, Kanselaar, Prangsma, and Jaspers (2003). The sentences of each learning protocol were split into smaller units
on the basis of grammatical and organizational markers such
as and, or, because, for example, such as, and that is. Every
single unit was assigned to one of the four categories that
the coding scheme existed of. Disagreements between raters

Dependent
Variable

mix.
mix.
Prompt
Prompt
No
Cogn. Metac. withwith
Prompt Prompt Prompt
out
planplanning
ning

Immediate
Test

3.18
(0.94)

3.84
(1.09)

3.96
(0.99)

3.93
(0.91)

4.41
(0.86)

Delayed
Test

2.94
(0.91)

3.62
(1.23)

3.61
(0.99)

3.60
(0.87)

4.18
(0.70)

Organization
35.45 47.43 26.30 40.60 44.45
& Elabora(12.09) (22.05) (15.86) (14.99) (17.63)
tion
Monitoring

0.73
(1.35)

0.61
(1.38)

14.00
(7.51)

5.75
(4.74)

4.40
(4.06)

Planning of
Regulation

0.00
(0.00)

0.00
(0.00)

5.55
(4.33)

0.10
(0.31)

1.55
(1.88)

Realized
Regulation

1.18
(3.72)

0.19
(0.87)

7.05
(8.45)

3.10
(4.81)

7.60
(6.59)

To answer our research questions, we computed a series
of a priori contrasts. Following Rosenthal, Rosnow, and
Rubin (2000), such a contrast analysis is the preferred
method if a set of theoretically derived predictions is to be
tested. We analyzed the learning outcomes in the immediate
comprehension test, in the delayed retention test, and the
applied learning activities in the protocols.
(1) If the results from Berthold et al. (2004) can be replicated in the present experiment, the availability of cognitive
prompts (cognitive prompts condition), just like the combination of cognitive and metacognitive prompts (mixed
prompts without planning-of-regulation prompts), should

360

lead to an increased knowledge acquisition as compared
with the no prompts condition. This prediction was
represented by the following contrast: no prompts:-2,
cognitive prompts:1, mixed prompts without planning-ofregulation prompts:1. The contrast was significant for the
direct comprehension test, F(2, 60) = 3.70, p =.009, Cohen’s
ƒ = 0.35 (medium to large effect), and for the delayed
retention test, F(2, 59) = 2.99, p =.018, ƒ = 0.32 (medium
effect). Hence, the results from Berthold et al. were
replicated indeed. When the students wrote their learning
protocols, either with the help of cognitive or cognitive and
metacognitive prompts, they reached a higher level of comprehension and retention as the control group.
(2) Our second research question investigated whether
metacognitive activities alone would unfold its potential to
improve learning success provided that the experimental
setting allowed for the realization of regulation activities.
Hence, it was assumed – in contrast to the Berthold et al.
(2004) study – that the students who received metacognitive
prompts would outperform the students in the no prompts
condition. This hypothesis was represented by the following
contrast: no prompts:-1, metacognitive prompts:1. The contrast was statistically significant for the direct comprehension test, F(1, 40) = 6.88, p = .012, ƒ=0.42 (large effect),
and for the delayed retention test, F(1, 39) = 5.12, p = .029,
ƒ= 0.36 (medium to large effect). Metacognitive prompts
clearly fostered learning when the experimental setting allowed for the realization of regulation activities, for example, when the students were given the opportunity to revise
their learning protocol and to resolve their comprehension
problems with the help of the lecture text.
(3) According to the third hypothesis, the combination of
cognitive and metacognitive prompts including planning-ofregulation prompts should yield the highest learning success
of all conditions because this mixture of prompts
encouraged the students to engage in all three essential subprocesses involved in self-regulated learning. This prediction was represented by the following contrast: no prompts:1, cognitive prompts:-1, metacognitive prompts:-1, mixed
prompts without planning-of-regulation prompts:-1, mixed
prompts including planning-of-regulation prompts:4. The
test of this contrast was significant both for the immediate
comprehension test, F(4, 98) = 4.44, p = .006, ƒ = 0.43
(large effect), and also for the delayed retention test, F(4,
97) = 4.26, p = .003, ƒ= 0.42 (large effect). Hence, students’
performance in the comprehension and retention test was
highest when the prompts they received for writing their
learning protocol stimulated all three essential sub-processes
involved in self-regulated learning.
(4) The fourth research question investigated whether
mixed prompts including planning-of-regulation prompts
would lead to higher learning outcomes than mixed prompts
without planning-of-regulation prompts. To answer this
question, we compared the mixed prompts without planningof-regulation prompts condition with the mixed prompts
including planning-of-regulation prompts condition. This
contrast, however, failed to reach the conventional 5%-level

of statistical significance in the immediate comprehension
test, F(1, 38) = 2.97, p = .093., ƒ= 0.29 (medium effect).
Nevertheless, in line with our predictions, it was statistically
significant in the delayed retention test, F(1, 38) = 5.30, p =
.027, ƒ= 0.37 (medium to large effect). Hence, providing
students with planning-of-regulation prompts, in addition to
cognitive and monitoring prompts, proved to be particularly
beneficial to learning in the long run in regards to sustained
retention of the acquired knowledge.

Learning Activities in the Protocols
In order to investigate whether the different combinations of
prompts elicited the corresponding learning activities, we
computed a further series of a priori contrasts.
(5) To analyze whether organizational and elaborative
prompts did indeed result in more cognitive activities in the
corresponding prompted groups, the following contrast was
computed: no prompts:-3, cognitive prompts:2, metacognitive prompts:-3, mixed prompts without planning-ofregulation prompts:2, mixed prompts including planning-ofregulation prompts:2. The contrast was statistically significant, F(4, 98) = 4.98, p = .001, ƒ= 0.45 (large effect).
Hence, cognitive prompts were shown to be effective in
increasing cognitive learning activities while writing.
(6) In order to examine whether monitoring prompts increased corresponding activities in groups who received
those prompts, we computed the following contrast: no
prompts:-3, cognitive prompts:-3, metacognitive prompts:2,
mixed prompts without planning-of-regulation prompts:2,
mixed prompts including planning-of-regulation prompts:2.
The test of this contrast was significant F(4, 98) = 31.21, p
= .001, ƒ = 1.13 (large effect). Monitoring prompts also
turned out to be successful in promoting monitoring activities in learning protocols.
(7) To answer the question whether students demonstrated
more planed regulation in the first draft of their learning
protocol when given planning-of-regulation prompts and
thus realizing more effective regulation activities in the second draft, we compared the groups who received planningof-regulation prompts with those groups who did not receive
those prompts. This question was represented by the following contrast: no prompts:-2, cognitive prompts:-2, metacognitive prompts:3, mixed prompts without planning-ofregulation prompts:-2, mixed prompts including planningof-regulation prompts:3. This contrast reached statistical
significance both for planning of regulation in the first version, F(4, 98) = 26.65, p = .001, ƒ = 1.04 (large effect), and
the realized cognitive regulation activities in the second
version, F(4, 98) = 7.81, p = .001, ƒ = 0.57 (large effect).
The planning-of-regulation prompts increased planning activities in the first draft of the learning protocol and resulted
in a higher degree of implemented regulation activities in
the final version. In summary it can be ascertained that the
manipulation check was succesful in demonstrating that
prompts are an appropriate method to support students who
are applying beneficial learning activities.

361

Discussion

References

The experiment presented in this paper successfully
replicated results found in a previous study (Berthold et al.,
2004). Supporting the writing of a learning protocol by
means of cognitive or a combination of cognitive and
metacognitive prompts fostered students’ knowledge
acquisition both on comprehension and retention measures.
The prompts helped the students represent the learning
contents in a more productive manner which enabled them
to encode more and to better retain new information. In
contrast to the results of Berthold et al., the present study
further demonstrated that metacognitive prompts alone
improved learning outcomes. Metacognitive prompts in our
study seemed to prevent students from being caught by an
illusion of understanding (Chi et al., 1994). In line with
findings concerning cognitive skill acquisition (VanLehn et
al, 2003), detecting impasses through monitoring appeared
to be beneficial to learning. Furthermore, it was unequivocally a requirement to provide students with a better opportunity to engage in regulation activities. Accordingly, when
the students detected a comprehension problem during the
monitoring of their cognitive learning processes, they had
the chance to realize concrete regulation activities, such as
reading a specific passage in the lecture text that helped
them solve their comprehension problem. Thus, one major
implication of our study is the importance of ensuring
students the opportunity to accomplish regulation activities
in a learning environment. Simply offering the opportunity
to engage in those activities, however, evidently did not
result in the highest knowledge acquisition. Rather, our
results suggest that it was particularly beneficial to
explicitly prompt the students to plan regulation activities.
Learning success was highest – especially with regard to the
achieved level of retention – when students received
prompts for writing their learning protocol that triggered all
three essential sub-processes involved in self-regulated
learning: (1) organization and elaboration activities, (2)
monitoring of one’s comprehension and (3) planning of
regulation (cf. Figure 1). Finally, the content analyses of the
learning protocols suggested that prompts are a profitable
and very effective method to support students in applying
beneficial cognitive and metacognitive learning activities.
Together, the results are in line with a cyclical model of
self-regulated learning as it has been proposed, for example,
by Zimmerman (1999). They provide empirical support for
the self-regulation view of writing-to-learn (BangertDrowns et al., 2004) that emphasizes the important contribution of metacognitive activities within the learning process. In contrast to the strong text view of writing-to-learn
(e.g., Emig, 1977), the self-regulation view assumes that
writing as such does not necessarily entail learning. Rather,
writing can function for students as a medium that facilitates
the application of beneficial cognitive and metacognitive
learning activities. Our results suggest that students are actually able to take part in these desirable learning activities
when writing a learning protocol. However, they should be
explicitly prompted to do so.

Bangert-Drowns, R. L., Hurley, M. M., & Wilkonson, B.
(2004). The Effects of school-based writing-to-learn interventions on academic achievement: A meta-analysis.
Review of Educational Research, 74, 29-58.
Berthold, K., Nückles, M., & Renkl, A. (2004). Writing
learning protocols: Prompts foster cognitive and metacognitive activities as well as learning outcomes. In P.
Gerjets, J. Elen, R. Joiner, & P. Kirschner (Eds.), Instructional design for effective and enjoyable computersupported learning (pp. 193-200). Tübingen: Knowledge
Media Research Center.
Biggs, J. B., & Collis, K. F. (1982). Evaluating the quality
of learning: the SOLO taxonomy. New York. Academic
Press.
Cantrell, R. J., Fusaro, J. A., & Dougherty, E. A. (2000).
Exploring the effectiveness of journal writing on learning
social studies: A comparative study. Reading Psychology,
21, 1-11.
Chi, M. T. H., De Leeuw, N., Chiu, M.-H., & LaVancher,
Ch. (1994). Eliciting self-explanations improves understanding. Cognitive Science, 18, 439-477.
Connor-Greene, P. A. (2000). Making connections: Evaluating the effectiveness of journal writing in enhancing student learning. Teaching of Psychology, 27, 44-46.
Emig, J. (1977). Writing as a mode of learning. College
Composition and Communication, 28, 122-128.
Erkens, G., Kanselaar, G., Prangsma, M., & Jaspers, J.
(2003). Computer support for collaborative and argumentative writing. In E. de Corte, L. Verschaffel, N. Entwistle, & J. van Merrienboer (Eds.), Powerful learning
environments: Unravelling basic components and dimensions (pp. 159-177). Amsterdam: Pergamon.
Mayer, R. E. (1984). Aids to text comprehension. Educational Psychologist, 19, 30-42.
McCrindle, A., & Christensen, C. (1995). The impact of
learning journals on metacognitive and cognitive processes and learning performances. Learning and Instruction, 5, 167-185.
Nückles, M., Schwonke, R., Berthold, K., & Renkl, A.
(2004). The use of public learning diaries in blended
learning. Journal of Educational Media, 29, 49-66.
Rosenthal, R., Rosnow, R. L., & Rubin, D. B. (2000). Contrasts and effect sizes in behavioral research. A correlational approach. Cambridge: Cambridge University Press.
Sweller, J., van Merrienboer, J. J. G. & Paas, F. G. (1998).
Cognitive Architecture and Instructional Design. Educational Psychology Review, 10, 251 – 296.
VanLehn, K., Siler, S., Murray, C.,Yamauchi, T., & Bagget,
W.B. (2003). Why do only some events cause learning
during human tutoring? Cognition and Instruction, 21(3),
209-249.
Winne, P.H. (1996). A metacognitive view of individual
differences in self-regulated learning. Learning and Individual Differences, 8, 327-353.
Zimmerman, B. J. (1999). Commentary: Toward a cyclically interactive view of self-regulated learning. International Journal of Educational Research, 31, 545-551.

362

