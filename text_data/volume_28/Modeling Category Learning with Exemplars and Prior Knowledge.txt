UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Modeling Category Learning with Exemplars and Prior Knowledge
Permalink
https://escholarship.org/uc/item/2802n9fw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Harris, Harlan D.
Rehder, Bob
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

     Modeling Category Learning with Exemplars and Prior Knowledge
                                   Harlan D. Harris (harlan.harris@nyu.edu)
                                        Bob Rehder (bob.rehder@nyu.edu)
                                      New York University, Department of Psychology
                                                  New York, NY 10003 USA
                           Abstract                              will show that only a very particular pattern of connec-
                                                                 tivity among representations is warranted.
   An open question in category learning research is how
   prior knowledge affects the process of learning new con-         We pursue this question by extending an existing
   cepts. Rehder and Murphy’s (2003) Knowledge Reso-             model of category learning, the Knowledge Resonance
   nance (KRES) model of concept learning uses an inter-         (KRES) model introduced by Rehder and Murphy
   active neural network to account for many observed ef-        (2003). KRES is a connectionist model of knowledge
   fects related to prior knowledge, but cannot account for      effects in concept learning that uses interactive activa-
   the learning of nonlinearly separable concepts. In this
   work, we extend the KRES model by adding exemplar             tion among representations of stimulus features, cate-
   nodes. The new model accounts for the fact that linearly      gory labels, and prior knowledge, then uses a supervised
   separable concepts are not necessarily easier than non-       learning algorithm called Contrastive Hebbian Learning
   linearly separable concepts (Medin & Schwanenflugel,          (CHL: O’Reilly, 1996) to learn symmetrical weights be-
   1981), and more importantly, accounts for a notable in-
   teraction between the presence of useful prior knowledge      tween the representations. KRES accounts for effects of
   and linear separability (Wattenmaker, Dewey, Murphy,          prior knowledge on learning rate, generalization patterns
   & Medin, 1986). Two architectural variants of the model       and reaction time.
   were tested, and the dependence of good results on a             KRES builds on the Baywatch model introduced by
   particular architecture, indicates how formal modeling
   can uncover facts about how the prior knowledge which         Heit and Bott (2000). Baywatch is a standard feed-
   influences concept learning is used and represented.          forward connectionist network supplemented with prior
                                                                 concept nodes that can be used as the basis for cat-
   Most current theories of category learning address how        egorization. Baywatch accounts for knowledge effects
new concepts are learned on the basis of empirical reg-          on responses to novel but knowledge-related features, as
ularities in the environment. Considerable progress has          well as to prior knowledge that is incongruent with the
been made in determining how learners encode empirical           empirical stimuli (Heit, Briggs, & Bott, 2004). KRES
information about how features, and sets of features, co-        goes beyond Baywatch in being able to also represent
vary with category labels. However, these models fail to         prior knowledge that relates stimulus features to (a) one
account for the important role of prior knowledge. Other         another, and (b) concept nodes (allowing the model to
models of category learning address the effects of prior         account for “top down” effects in learning).
knowledge, but they in turn fail to account for the wide            Nevertheless, the published versions of both Baywatch
range of empirical effects that have been observed. The          and KRES have a significant restriction. They are lim-
work reported here aims to integrate these two veins of          ited to learning linearly separable concepts. Their archi-
concept learning research.                                       tectures are similar to a classical prototype model, where
   Prior knowledge is known to have a number of effects          the weights compute a monotonic function of the input
on concept learning. When knowledge is related to a              representation. However, people are able to learn nonlin-
learning task, learning is often faster (Murphy & Al-            early separable concepts, and often find such concepts as
lopenna, 1994; Wattenmaker et al., 1986). In addition,           easy to learn as linearly separable ones (Medin & Schwa-
when new concepts are related to prior knowledge, struc-         nenflugel, 1981). In part as a result of this, exemplar
tural effects that have been found in empirical concept          models of classification (Medin & Schaffer, 1978; Nosof-
learning studies may not be found or may even be re-             sky, 1986; Kruschke, 1992) have become prominent, as
versed (Pazzani, 1991; Wattenmaker et al., 1986).                they naturally account for learning of nonlinearly sep-
   In this research we introduce a new category learning         arable concepts. Some recent work has challenged ex-
model whose goal is to account for effects of both prior         emplar models (Smith & Minda, 1998, but see Nosofsky
knowledge and empirical regularities on concept learn-           & Zaki, 2002; Rehder & Hoffman, 2005), and some re-
ing. We address the question of which kinds of represen-         cent models of classification have proposed alternatives,
tations (exemplars? prototypes? rules?) are involved             such as using clusters instead of exhaustive sets of ex-
in learning tasks and how those representations become           emplars (Love, Medin, & Gureckis, 2004). However, our
related to one another and to representations of prior           goal is to build a new model with the ability to learn
knowledge as a result of experience. By fitting variants         nonlinearly separable concepts, and exemplars are a rea-
of our new model to two human learning data sets, we             sonable starting place with much empirical evidence to
                                                            1440

                                                                  cles of spreading activation, the network settles, and the
                                                                  activations of the output nodes are transformed using a
                                                                  Luce choice rule into the probability that the input is
                                                                  categorized as an X or a Y. The model learns when a
                                                                  teaching signal is then applied to the output nodes. For
                                                                  details, see Rehder and Murphy (2003).
                                                                     To account for the learning of nonlinearly separable
                                                                  concepts, we added exemplar nodes to KRES. As with
                                                                  ALCOVE (Kruschke, 1992) and related models, we used
                                                                  fixed exemplar nodes activated by matching stimuli. The
                                                                  first time a new exemplar is seen, an exemplar node is
                                                                  connected to the input nodes with fixed weights set to
                                                                  match the stimuli and scaled by a parameter, we . The
                                                                  new node is also connected to the output nodes with
                                                                  weights initialized and learned in the usual manner for
Figure 1: Architecture of new KRES network. I = input             KRES. Activation of the new exemplar nodes then pro-
nodes; O = output nodes; P = prior knowledge nodes;               ceeds as with any other node in a KRES network.
E = exemplar nodes. Connections depicted with solid                  As shown in Figure 1, there are a number of possi-
lines are fixed weights; with fine dashed lines are set-once      ble variations of the new network’s connectivity. In the
exemplar weights; with dashed lines are CHL-learnable             original KRES model, there were connections between
                                                                  the feature nodes (layer I) and the output nodes (layer
weights. The KRES/EFK model includes all three of the
                                                                  O), and the prior-knowledge nodes (layer P if present)
links labeled E, F, and K; other models include subsets.          and the output nodes. With the addition of the new
                                                                  exemplar nodes (layer E), the full model, which we no-
                                                                  tate as KRES/EFK, has three separate possible bases
support them.                                                     for classification: the exemplar, feature, and knowledge
   We first describe how we incorporated exemplars into           nodes. However, each of those connections is theoreti-
KRES, noting several possible architectural variations.           cally optional (although one must be present), and each
We then give the results of our work simulating exper-            is theoretically interesting. The exemplar connections
iments by Medin and Schwanenflugel (1981) and Wat-                are essential if nonlinearly separable concepts are to be
tenmaker et al. (1986), focusing on the architectural             learned, so we did not consider variations without them.
variations and their implications for theories of concept            The KRES/E model has only these exemplar connec-
learning. We conclude with a discussion of the results            tions, and no other connections to the output nodes.
and their implications for a comprehensive theory of cat-         The feature nodes influence categorization only by ac-
egory learning with and without prior knowledge.                  tivating the exemplar nodes, while the prior-knowledge
                                                                  nodes (if present) can influence categorization only by
                     New Models                                   influencing the activation of the input nodes. Note that
Our new models are simple extensions of the KRES                  in KRES/E the sole effect of the prior concept nodes is to
model (Rehder & Murphy, 2003). Figure 1 shows the                 modify the activation of the input features so that they
overall architecture. The models work as follows.                 are more consistent with those concepts. For example, a
   In KRES, connections between nodes are bi-                     stimulus with many P0-linked features will strongly acti-
directional, and those connections can either be fixed in-        vate P0, which in turn will reinforce those features (and
hibitory, fixed excitatory, or learned with experience. In        thus dampen the activation of any features associated
Figure 1, there are fixed inhibitory connections between          with P1). The feature nodes, thus partially canonical-
the two prior-knowledge nodes in layer P, fixed excita-           ized (i.e., made more consistent with P0), will then exert
tory connections between each of the prior-knowledge              their influence on the category labels via the exemplar
nodes and one of the two banks of input nodes (e.g., be-          nodes.
tween P0 and I0), learned connections between the two                In the KRES/EK model, output nodes have connec-
prior-knowledge nodes and the output nodes in layer O,            tions from both the exemplar and the prior knowledge
etc. Note that the input (layer I) is represented as pairs        nodes. The prior knowledge concepts not only modulate
of mutually exclusive values of a particular attribute, so        input feature activation, they can also be used as the ba-
nodes A0 and A1 also have fixed inhibitory connections.           sis for categorization, with (potentially) no contribution
To make a categorization prediction, the inputs to the            from the exemplar nodes.
model have constant signals applied to them. Activation              The KRES/EF model has connections from the exem-
then spreads throughout the model, both forward and               plar nodes as well as direct connections from the input
backwards. For example, if the I0 input nodes are ac-             features. It can be seen as a model that combines ex-
tive, that activity will resonate with the prior knowledge        emplar and prototype-like computations in its effort to
P0 node, and their activation will increase as a result.          categorize. As with KRES/E, prior-knowledge nodes can
Activation of nodes is a sigmoidal function of the total          influence the activation of the input nodes, but cannot
input, with a steepness parameter α. After many cy-               be directly used as the basis for categorization.
                                                             1441

                                                                                                            KRES/E
                                                                                             70
Table 1: Category structure for Preliminary Simulation,
based on Medin & Schwanenflugel (1981, Experiment 1).                                        60
                                                                       NLS training errors
       Linearly Separable    Non-linearly Separable                                          50
       Stimuli Category      Stimuli     Category
                                                                                             40
       1011         A        1000           A
       1010         A        0111           A                                                30
       1101         A        1110           A
       0110         A        1011           A                                                20
       1001         B        0110           B
       0010         B        1001           B                                                10
       0100         B        0000           B
                                                                                             0
       0001         B        0001           B                                                 0   10   20   30 40      50    60   70
                                                                                                            KRES/EF
                                                                                             70
   KRES/EFK has all three sets of connections to the                                         60
                                                                       NLS training errors
output nodes, allowing categorization decisions to be                                        50
made with any combination of prior concept, input, or
exemplar activations.                                                                        40
   By comparing these models, we hope to show that a                                         30
particular pattern of connectivity among representations
                                                                                             20
is needed to account for the experimental findings.
                                                                                             10
         Preliminary Simulation:                                                             0
                                                                                              0   10   20 30 40 50           60   70
       Nonlinearly separable concepts                                                                   LS training errors
We begin by confirming that our new model can indeed
learn nonlinearly separable concepts, and (more ambi-         Figure 2: Performance of two KRES variants on Medin &
tiously) by testing whether one of its variants exhibits
                                                              Schwanenflugel (1981) task, showing overall error counts
the same learning patterns as people. In their Experi-
ment 1, Medin and Schwanenflugel (1981) notably found         with various parameter settings. Grey circles are exper-
that linearly separable categories were not necessarily       imental error counts. Chance performance is 64 errors.
easier to learn than nonlinearly separable categories.
This highly influential result was one of several that un-
dermined the independent-cue, or prototype, models of         each item. The results were compared with the per-
category learning. We investigated whether one of the         item error rates reported by Medin and Schwanenflugel
variants of our new model would reproduce the equiv-          (1981). Overall, the strength of inhibitory weights was
alent learning difficulty of Medin and Schwanenflugel’s       not critical, as long as they were adequately inhibitory.
linearly separable and nonseparable category structures.      We thus set the strength of inhibitory weights to win =
   The new model, with exemplar nodes but without             −2 for the simulations reported here.
prior knowledge, was trained on the two conditions               For KRES/EF, the best results were found with LR =
shown in Table 1. Both KRES/E and KRES/EF (see                0.1, α = 1.5. The MSE and χ2 error, relative to the
Figure 1) were fit. (Because of the absence of prior          experimental per-item error rates, were 2.84 and 11.41,
knowledge, KRES/EK reduces to KRES/E for this                 respectively. For KRES/E, the best results were found
task.) Three parameters were explored systematically.         with LR = 0.4, α = 1.2. The MSE and χ2 error were
These were the learning rate, LR, the strength of the         much lower, at 0.66 and 2.59.
fixed inhibitory weights, win , and α, the sharpness of          Medin and Schwanenflugel (1981) reported a mean
the sigmoidal squashing function. (High values of α force     33.3 errors on the LS problems and 30.9 errors on the
node activations to be either very high or very low.) The     NLS problems. KRES/E made about the same number
strength of exemplar weights, we , was fixed at 1. The        of errors on the LS and NLS problems (32.6 and 31.6,
bias on the exemplar nodes, be , was set to be a function     respectively), while KRES/EF showed easier learning of
of α such that the activation of the exemplar nodes was       the linearly separable category (26.6 versus 35.2 errors).
 1
n (where n is the number of exemplars) when the net           Figure 2 shows a scatter plot of the number of train-
input to a node was 0: be = − log(n−1)
                                     α    . Other parame-     ing errors on the two problems for the two models, over
ters, such as the gain, remained at the defaults reported     a wide range of parameter settings. KRES/E accounts
in Rehder and Murphy (2003).                                  for the qualitative Medin and Schwanenflugel (1981) re-
   A parameter search was performed, with replications        sult, regardless of parameter settings; for KRES/E, the
to reduce effects of noise. Each replication involved a run   two concepts are about equally difficult. For KRES/EF,
of the model, learning the stimuli shown in Table 1, with     however, no parameter settings were able to reproduce
the same number of blocks as in the experimental work.        this result; for KRES/EF, the LS problem is easier, re-
Erroneous predictions during training were counted for        gardless of parameter settings.
                                                          1442

                                                                                                                                           WDMM86
Table 2: Category structure for Main Simulation, based                                            60                                       KRES/EK
on Watternmaker et al. (1986).
                                                                      Number of Training Errors
                                                                                                  50   Knowledge-Unrelated
       Linearly Separable    Non-linearly Separable
       Stimuli Category      Stimuli     Category
       1110         A        1000           A                                                     40
       1011         A        1010           A
       1101         A        1111           A                                                                                 Knowledge-Related
       0111         A        0111           A
                                                                                                  30
       1100         B        0001           B
       0001         B        0100           B                                                          LS                                    NLS
       0110         B        1011           B                                                                      Category Structure
       1010         B        0000           B
                                                              Figure 3: Performance of KRES/EK on Wattenmaker
                                                              et al. (1986, Experiments 1 and 2) task, compared with
   KRES/E is successful because exemplar nodes allow
equally rapid learning of linearly and nonlinearly sep-       experimental results. Chance performance was 64 errors.
arable concepts, and direct connections from input to
output nodes are not present. Other exemplar models of
                                                              addition to accounting for the Wattenmaker et al. (1986)
classification, such as ALCOVE, share this architecture.
                                                              results, the Main Simulation examined whether adding
(We have also successfully fit ALCOVE to the Medin
                                                              direct connections between the output nodes and the
& Schwanenflugel, 1981 results.) The next simulation,
                                                              prior knowledge and/or feature nodes is necessary.
however, goes beyond ALCOVE’s scope as a model of
                                                                 As before, the parameter space of the three varia-
concept learning.
                                                              tions was systematically explored. The learning rate,
 Main Simulation: Prior knowledge and                         LR, exemplar weight, we , and α were varied, while
                                                              the other parameters were held constant. The excita-
          linear separability                                 tory weights were set to wex = 1 and the inhibitory to
Wattenmaker et al. (1986) showed an interaction be-           win = −2. Training replicated the experimental proce-
tween category structure and prior knowledge. Subjects        dure and replications were performed to get stable es-
learned either the linearly separable or nonlinearly sep-     timates of average performance. We combined the re-
arable structure shown in Table 2. In the knowledge-          sults of Wattenmaker et al.’s Experiments 1 and 2 (which
related condition but not the knowledge-unrelated (con-       had identical category structures but different stimuli),
trol) condition the features were correlated with person-     weighted by numbers of subjects, to get a less noisy set
ality traits (e.g., the ”1” and ”0” features were behaviors   of numbers for comparison.
which exemplified ”honesty” and ”dishonesty,” respec-            Table 3 shows the best fit for each model, along with
tively). In the knowledge-unrelated condition, Watten-        the mean squared error. The KRES/EK model was able
maker et al. found that the two category structures were      to closely fit the quantitative and qualitative patterns in
about equally easy to learn (there were nonsignificantly      the error counts (see Figure 3), while the other models
fewer errors for the nonlinearly separable structure, Fig-    could not. The failures of KRES/EFK to account for
ure 3). When knowledge was present, both structures           these results confirm the model selection results in the
became easier to learn, illustrating that prior knowl-        first experiment, showing that direct connections from
edge can speed learning. Importantly however, this ef-        features to the output are not helpful for reproducing
fect was stronger with the linearly-separable categories      the human learning pattern. In addition, the success of
(Figure 3). Apparently, the prior knowledge that the          KRES/EK relative to KRES/E indicates that connec-
category features independently instantiated known per-       tions from prior knowledge nodes to the output nodes
sonality traits biased learners toward a “summing” strat-     are helpful. It could have been that prior concepts af-
egy consistent with a linearly-separable concept but less     fected learning in the model merely by changing the ac-
helpful for a nonlinearly-seperable concept (also see Mur-    tivations of the nodes in the input layer, increasing acti-
phy & Kaplan, 2000).                                          vation levels and pulling the representation towards the
   KRES was able to account for the speedup due to            prior knowledge prototype. The results of the simula-
prior knowledge in the linearly separable case (Rehder        tions, however, suggest that this is not the case. The
& Murphy, 2003, Simulation 2), but it could not even          model is unable to account for the experimental results
attempt to account for the interaction with the nonlin-       without connections from the prior knowledge nodes to
early separable case. The present simulation used both        the output nodes.
prior concept nodes and exemplar nodes to account for            Per-item fits were quite good for KRES/EK, with a
this interaction.                                             few exceptional points–see Figure 4. We suspect that
   We focused on three of the six possible variants           these exceptions may be partly due to KRES’s lack of
on KRES: KRES/E, KRES/EK, and KRES/EFK. (As                   feature attention weights. The dimensions in Table 2
shown above, KRES/EF was unable to account for the            are not equally diagnostic, and KRES does not shift at-
basic pattern of results in the Medin and Schwanenflugel      tention away from less diagnostic dimensions to more
(1981) data, and thus was not considered.) That is, in        diagnostic dimensions.
                                                          1443

    Table 3: Best fits for the Main Simulation. Parameters, number of training errors, and Mean Squared Error (vs.
    experimental data) are shown. “Rel” and “Unrel” specify the related (theme) and unrelated (control) conditions.
                                                                 LR     we     α      Rel / LS     Rel / NLS    Unrel / LS    Unrel / NLS     MSE
                                             WDMM86                                     29.4          40.6        53.9           49.6
                                             KRES/E               0.7   1.0   1.0       45.0          32.6        52.3           39.2         105.4
                                             KRES/EK             0.55   0.6   0.9       31.4          43.2        58.1           48.1           7.6
                                             KRES/EFK            0.15   0.6   0.9       36.0          46.6        49.3           49.3          25.3
                                         Linearly Separable              Non-Linearly Separable
                                 15                                15                                  ble ones (Medin & Schwanenflugel, 1981). Of course,
Knowledge-Related
                                                    WDMM86
                                                                                                       nonlinearly separable category learning is not the only
               Training Errors
                                                    KRES/EK                                            important empirical learning result, but we are confi-
                                 10                                10
                                                                                                       dent, based on prior work (Rehder & Murphy, 2003),
                                                                                                       that the KRES framework exhibits a number of the other
                                  5                                 5
                                                                                                       standard effects, such as sensitivity to features’ category
                                                                                                       and cue validity and prototype effects. Our new model
                                  0                                 0
                                                                                                       has thus shown itself to be an empirical learning system
                                 15                                15
Knowledge-Unrelated
                                                                                                       faithful to many facets of human learning. We therefore
                                                                                                       conclude that it is suitable as a platform to model the
               Training Errors
                                 10                                10                                  additional effects of prior knowledge.
                                                                                                          We next investigated whether KRES/EK was able to
                                  5                                 5                                  account for the intriguing interaction in the difficulty of
                                                                                                       learning linear and nonlinear concepts with and with-
                                  0 A A A A B B B B                 0 A A A A B B B B                  out prior knowledge (Wattenmaker et al., 1986). With-
                                     01 11 10 11 01 11 10 00           11 10 01 10 00 01 00 10
                                       11 01 11 10 10 00 10 01           11 00 11 10 01 00 00 11       out knowledge, people found those nonlinearly concepts
                                              Items                              Items                 easier to learn, a preference which was reversed when
                                                                                                       knowledge was present. Our Main Simulation showed
    Figure 4: Performance of KRES/EK on Wattenmaker                                                    that KRES/EK was able to reproduce this interaction,
    et al. (1986, Experiments 1 and 2) task, showing mean                                              and even more detailed error results as well. KRES/EK
                                                                                                       is the only model of category learning able to fully ac-
    per-item training error rates. The dotted line is chance
                                                                                                       count for these data1 .
    performance.
                                                                                                          We have also shown that successfully accounting for
                                                                                                       the experimental results involves creating connections
                                                                                                       among certain kinds of representations and not others.
       The results of the Main Simulation validate the                                                 This result is exemplified in our rejection of KRES/EF
    KRES/EK model, showing that it (and not its cousins)                                               (in the Preliminary Simulation) and KRES/EFK (in the
    can account for the interaction between the presence                                               Main Simulation). When concepts could be built on a
    or absence of prior knowledge and the linear separabil-                                            basis of raw features, in addition to exemplars and con-
    ity of the concept to be learned. Without knowledge,                                               cepts due to prior knowledge, the model was unable to
    the model finds Wattenmaker et al.’s linearly separable                                            fit the experimental data well. We suggest that this is
    structure slightly more difficult to learn than the nonlin-                                        support for a theory of concept learning where the effect
    early separable structure, consistent with the empirical                                           of a stimulus on a categorization decision is mediated by
    data, and due to the use of exemplar representations.                                              exemplars and prior knowledge. However, the categories
    With knowledge, the effect of linear separability reverses,                                        studied here both had weak family resemblance struc-
    as the model can use prior knowledge nodes directly as                                             tures, which would necessarily impair the usefulness of
    the basis for effective learning. Overall, collapsing across                                       direct feature-category weights. Future work with other
    category structures, the model accounts for faster learn-                                          category structures will be needed to confirm that our
    ing with prior knowledge, as prior knowledge nodes both                                            conclusion holds up more generally.
    directly and indirectly (through influencing representa-                                              KRES/EK shares some central architectural assump-
    tions of feature nodes) aide classification.                                                       tions of ALCOVE (Kruschke, 1992). Like ALCOVE,
                                                                                                       exemplar nodes are used to form the basis for con-
                                                      Discussion                                       cept learning, with category node activation being a
    In this paper we have introduced a new model of con-                                               monotonic function of exemplar activation. Of course,
    cept learning with the potential to account for effects of                                         KRES/EK extends significantly beyond ALCOVE’s
    both empirical regularities and prior knowledge on con-                                            scope by being able to incorporate prior knowledge
    cept learning. We first showed that KRES/E was able to                                               1
                                                                                                           Heit (2000) uses the integration model of category learn-
    account for a critical result regarding how empirical reg-                                        ing (Heit, 1994), a generalization of Medin and Schaffer’s
    ularities affect learning difficulty–nonlinearly categories                                       (1978) context model, to account for other results from Wat-
    are not intrinsically more difficult than linearly separa-                                        tenmaker et al. (1986).
                                                                                                   1444

through prior concept nodes and to account for exper-          Kruschke, J. K. (1992). ALCOVE: An exemplar-based
imental results with prior knowledge. As discussed in               connectionist model of category learning. Psycho-
the introduction, KRES/EK also has similarities to Bay-             logical Review, 99, 22–44.
watch, with prior knowledge nodes that can act as the          Love, B. C., Medin, D. L., & Gureckis, T. M. (2004).
basis for categorization (Heit & Bott, 2000). However,              SUSTAIN: A network model of category learning.
our results suggest that Baywatch, without exemplar
                                                                    Psychological Review, 111, 309–332.
representations, cannot account for learning of nonlin-
early separable concepts, and also cannot account for the      Medin, D. L., & Schaffer, M. M. (1978). Context theory
Wattenmaker et al. (1986) results. Baywatch is most                 of classification learning. Psychological Review, 85,
similar to the versions of KRES with feature-category               207–238.
links, which did not fit the data.                             Medin, D. L., & Schwanenflugel, P. J. (1981). Lin-
   Overall, this work supports a particular view of con-            ear separability in classification learning. Journal
cept learning and prior knowledge. Categorization is                of Experimental Psychology: Human Learning and
based on a process of parallel constraint satisfaction,             Memory, 7, 355–368.
where stimuli, prior knowledge and concepts all inter-         Murphy, G. L., & Allopenna, P. D. (1994). The locus
act to find the most consistent category response. Prior            of knowledge effects in concept learning. Journal
knowledge can either be based on relationships among                of Experimental Psychology: Learning, Memory, &
features, or (as in this work) can be prior concepts that           Cognition, 20, 904–919.
interact with the stimulus representations and also act
                                                               Murphy, G. L., & Kaplan, A. S. (2000). Feature dis-
as a potential basis for categorization. Exemplars, or
perhaps more abstract representations, form the basis               tribution and background knowledge in category
for empirical categorization.                                       learning. The Quarterly Journal of Experimental
   Planned future work includes further investigation of            Psychology, 53A, 962–982.
the architectural constraints discovered here, of other        Nosofsky, R. M. (1986). Attention, similarity, and the
interactions with knowledge, and of KRES’s limitations.             identification-categorization relationship. Journal
Most current models of concept learning include a mech-             of Experimental Psychology, 115, 39–57.
anism for selective attention, and some also can account       Nosofsky, R. M., & Zaki, S. R. (2002). Exemplar
for unsupervised learning effects, but KRES currently               and prototype models revisited: Response strate-
does neither. We also plan to investigate the effects of            gies, selective attention, and stimulus generaliza-
redundant, irrelevant, and incongruent knowledge. The               tion. Journal of Experimental Psychology: Learn-
work described here is a significant step towards devel-            ing, Memory, & Cognition, 28, 924–940.
oping a truly comprehensive model of concept learning
                                                               O’Reilly, R. C. (1996). Biologically plausible error-
and how it interacts with other aspects of cognition.
                                                                    driven learning using local activation differences:
                  Acknowledgements                                  The generalized recirculation algorithm. Neural
                                                                    Computation, 8, 895–938.
Support for this research was provided by NIMH Grant           Pazzani, M. J. (1991). Influence of prior knowledge on
MH041704 to Gregory L. Murphy. Thanks to Gregory                    concept acquisition: Experimental and computa-
Murphy and the anonymous reviewers for helpful com-                 tional results. Journal of Experimental Psychology:
ments.
                                                                    Learning, Memory, & Cognition, 17, 416–432.
                                                               Rehder, B., & Hoffman, A. B. (2005). Thirty-something
                        References
                                                                    categorization results explained: Attention, eye-
Heit, E. (1994). Models of the effects of prior knowl-              tracking, and models of category learning. Journal
       edge on category learning. Journal of Experimen-             of Experimental Psychology: Learning, Memory,
       tal Psychology: Learning, Memory, and Cognition,             and Cognition, 31, 811–829.
       20, 1264–1282.                                          Rehder, B., & Murphy, G. L. (2003). A knowledge-
Heit, E. (2000). Background knowledge and models of                 resonance (KRES) model of category learning.
       categorization. In U. Hahn & M. Ramscar (Eds.),              Psychonomic Bulletin & Review, 10, 759–784.
       Similarity and categorization. Oxford University        Smith, J. D., & Minda, J. P. (1998). Prototypes in the
       Press.                                                       mist: The early epochs of category learning. Jour-
Heit, E., & Bott, L. (2000). Knowledge selection in                 nal of Experimental Psychology: Learning, Mem-
       category learning. In D. Medin (Ed.), Psychology             ory, and Cognition, 23, 1411–1436.
       of learning and motivation (Vol. 39, pp. 163–199).      Wattenmaker, W. D., Dewey, G. I., Murphy, T. D.,
       Academic Press.                                              & Medin, D. L. (1986). Linear separability and
Heit, E., Briggs, J., & Bott, L. (2004). Modeling the               concept learning: Context, relational properties,
       effects of prior knowledge on learning incongruent           and concept naturalness. Cognitive Psychology, 18,
       features of category members. Journal of Experi-             158–194.
       mental Psychology: Learning, Memory, and Cog-
       nition, 30, 1065–1081.
                                                          1445

