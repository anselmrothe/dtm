UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Simulating Time-Course Phenomena in Perceptual Similarity via Incremental Encoding
Permalink
https://escholarship.org/uc/item/8v51z4jz
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Forbus, Kenneth
Gentner, Dedre
Lovett, Andrew
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       Simulating Time-Course Phenomena in Perceptual Similarity via Incremental
                                                                Encoding
 Andrew Lovett (andrew-lovett@northwestern.edu)                               Dedre Gentner (gentner@northwestern.edu)
    Qualitative Reasoning Group, Northwestern University                      Department of Psychology, Northwestern University
         2133 Sheridan Road, Evanston, IL 60201 USA                              2029 Sheridan Road, Evanston, IL 60201 USA
                                            Kenneth Forbus (forbus@northwestern.edu)
                                          Qualitative Reasoning Group, Northwestern University
                                              2133 Sheridan Road, Evanston, IL 60201 USA
                                 Abstract                               of comparison. We use SME to simulate both studies,
                                                                        providing evidence that supports the time course of
   If people are required to respond very quickly in a same-            encoding interpretation.
   different task, their judgments of sameness are heavily reliant
   on attribute matches, despite the fact that when given ample
   time, the judgments seem to rely chiefly on relational matches
   (Goldstone & Medin, 1994). One interpretation of this
   temporal pattern is that attribute matches enter into the
   comparison process before relational matches. However, an
   alternate explanation, suggested by findings of Sloutsky &
   Yarlas (submitted) is that attributes are encoded before
   relations. In this case, if the comparison process begins before
   the encoding is completed, early matches will involve
   attributes but not relations. We show via a simulation that
   SME can model the Goldstone & Medin results, as well as the                 Figure 1. Scenes from Goldstone & Medin (1994)
   Sloutsky & Yarlas (submitted).
                                                                                2. Time-Course Effects in Comparison
                          1. Introduction                                In Experiment 1 of Goldstone and Medin’s (henceforth
There is considerable evidence that the processes that                   G&M) study, participants were told to compare two scenes,
govern analogical mapping may also apply to similarity                   each composed of two drawings of butterflies. The
comparisons (Markman & Gentner, 1996; Gentner &                          butterflies varied along four dimensions: head shape, tail
Markman, 1997). For example, Markman and Gentner                         shape, body texture, and wing texture. The two butterflies
(1996) found that when rating the similarity of two images,              in the base scene differed on all four dimensions (see Figure
subjects attended more to differences connected to the                   1). The two butterflies in the comparison scene were
common structure of the two images (alignable differences)               systematically varied to produce different degrees of feature
than to differences unrelated to the common structure. These             overlaps with the base two. For example, if the two base
findings suggest that when asked to find a difference,                   butterflies were classified as AAAA and BBBB, where each
participants first carried out a structural alignment between            letter is a value along one of the four dimensions, then a
the images. Results such as this suggest that the same                   comparison butterfly labeled AAAB would have three
cognitive process may underlie both analogy and similarity.              features in common with one of the base butterflies and one
Consistent with this, the Structure-Mapping Engine (SME)                 feature in common with the other. A butterfly labeled
(Falkenhainer, Forbus & Gentner 1989), a computational                   BBBD would have three features in common with one of
model of analogy, has successfully modeled perceptual                    the base scene butterflies and one novel feature.
similarity results (Kuehne, Gentner, & Forbus, 2000;                         G&M assessed the similarity between two scenes by
Loewenstein & Gentner, 2005).                                            looking at subjects’ abilities to label them as different in a
      A critical issue in modeling the psychological processes          same-different task under a deadline. The assumption was
of analogy and similarity is simulating the time course of              that participants would align each butterfly in the
processing. In an important study, Goldstone and Medin                  comparison scene with one of the butterflies in the base
(1994) found that participants in a similarity task showed              scene, based on the overall degree of attribute overlap.
relatively greater sensitivity to attribute matches early in            Participants were told to disregard the butterflies’ relative
processing, and to relational matches later. This suggests              positions; e.g., the top butterfly in one scene could match
that in perceptual similarity computations, attribute matches           the bottom butterfly in the other.
are made before relational matches. We begin by reviewing                    There were three deadlines, which varied within-subject:
this study and then discuss results from Sloutsky and Yarlas            short (1 s), medium (1.84 s), and long (2.68 s). The
(submitted) that suggest that the lag between attributes and            dependent measure was the error rate on different trials: the
relations arises from the time course of encoding rather than
                                                                    1723

number of times subjects mistakenly believed that two              structurally consistent with the (yet to be determined)
different scenes were the same.                                    maximal alignment (i.e., whether they were MIPs or
                                                                   MOPs). More generally, these findings could suggest that
                                                                   the comparison process is chiefly sensitive to attribute
                                                                   matches during the early stages of comparison, with
                                                                   sensitivity to relational consistency (e.g., attention to 1-1
                                                                   correspondences) entering later in the process. Goldstone
                                                                   (1994) simulated these results with his SIAM model. Such
                                                                   an effect might also be captured in SME by assuming that in
                                                                   speeded judgments, an early sense of similarity can be
                                                                   generated from SME’s initial parallel matching stage, in
                                                                   which all possible matches are generated between the two
                                                                   items, with no regard for structural consistency (Forbus et
                                                                   al., 1995).
                                                                        However, before drawing strong conclusions concerning
                                                                   the comparison process, we must consider a second possible
                                                                   interpretation of the G&M findings. The results just
                                                                   discussed could reflect the time course of encoding, rather
                                                                   than the time course of comparison. Results by Sloutsky and
                                                                   Yarlas (submitted) (hereafter S&Y) suggest that when
                                                                   subjects see an image, their construction of a representation
                                                                   may begin with entities and their attributes, with relations
                                                                   between entities added to the representations later.
                                                                        We next describe S&Y’s findings. Then we describe a
                                                                   simulation of the G&M findings based on the idea that
                                                                   relations may be encoded more slowly than attributes.
                                                                   Finally, we apply this simulation to the S&Y results as well.
                                                                             3. Evidence for Encoding Effects
                                                                   In G&M’s study, participants had to both encode the two
                                                                   scenes and compare them during the limited time given
                                                                   them. In order to separate encoding from comparison (at
     Figure 2. Results from Goldstone & Medin (1994)               least partly), S&Y used a sequential same-different task
                                                                   instead of simultaneous presentation. Subjects first saw the
    G&M analyzed the pairs in terms of matches in place            base scene for a limited time, followed by a mask. Then the
(MIPs) and matches out of place (MOPs). A MIP refers to a          comparison scene was presented for an unlimited time.
match between features in corresponding butterflies. For           Thus, only the time to encode the base scene was limited.
example, if an AAAB butterfly were matched to the AAAA             Any relational lag must thus be attributed to encoding
butterfly, they would share three common features, or MIPs.        processes, not to comparison processes.
A MOP refers to a match between features that belong to
non-corresponding butterflies: in other words, a cross-
mapped attribute. In the example, the final feature of the
AAAB butterfly matches that of the BBBB butterfly,
producing a MOP. G&M looked at the effect of adding two
MIPs with a constant number of MOPs and the effect of
adding two MOPs with a constant number of MIPs. At the
short deadline, there was no significant difference between
increasing the number of MIPs or the number of MOPs
(Figure 2). In both cases, as the number of matches
increased, subjects were more likely to confuse the two
scenes. At the long deadline this relationship changed
significantly. The error rate became more sensitive to MIPs
and less sensitive to MOPs, with one additional MIP having
a greater effect than two additional MOPs.
    As Goldstone and Medin noted, these results suggest                 Figure 3. Scenes from Sloutsky & Yarlas (submitted)
that early in the process, local attribute matches contributed
to a sense of similarity regardless of whether they were
                                                              1724

    The scenes were rows of three objects. All three objects         the currently available data at any point in the encoding
had different colors, but two had the same shape. The                process, using incremental mapping techniques to update
shapes appeared in one of three relational patterns: A-B-A,          the mapping after new information is encoded.
A-A-B, or A-B-B. Figure 3 shows a base scene with an A-                   To simulate performance on the same-different task, we
B-A pattern. The comparison scene could differ from the              used the number of differences produced by SME. This is a
base scene either in its elements or in its relations. An            reasonable measure because time required to detect that two
element match (E+) contained the same three shapes with              stimuli are different increases with the number of
the same three colors (though not necessarily in the same            differences between them (Farell, 1985). Thus given
pattern), while an element mismatch (E-) contained different         limited time for a comparison, accuracy should increase
shapes and colors. A relational match (R+) contained the             with the number of differences detected. Interestingly, the
same pattern (e.g., A-B-A / C-D-C), whereas a relation               accuracy in detecting that two scenes are different does not
mismatch (R-) contained a different pattern (e.g., A-B-A /           vary with the number of differences; given a sufficient time
C-C-D). S&Y varied the amount of time that the base scene            to make a decision, subjects’ accuracy should remain high
was displayed. In the ample time condition, the base scene           regardless of the number of differences.
was shown for 2100 ms, but in the limited time condition, it              To measure the number of differences, we used the
was shown for only 150 ms. The dependent measure was                 number of candidate inferences that SME produced. When
d’, accuracy in detecting whether the scenes were different.         computing an analogy between base and target cases, SME
    The results, shown in Figure 7, indicated that when the          produces candidate inferences whenever the base contains
attributes were changed (in the E-/R+ and E-/R- conditions),         an expression (connected with the mapping) that is not
performance was extremely accurate, regardless of whether            present in the target. Candidate inferences do not capture
the relations changed or remained the same. In both cases,           non-alignable differences, (i.e., differences not connected at
performance was only slightly lower with limited encoding            all to the mapping) and so in general they are not adequate
time than with ample encoding time. A very different                 for measuring differences. However, they suffice for the
pattern held when the relational pattern changed, but the            simple stimuli used in these experiments. (The stimuli were
attributes did not (the E+/R- condition). With ample initial         always completely alignable, so all differences are alignable
encoding time, performance was high, as in the other two             differences.) Importantly, this measure will also note a
conditions. However, performance dropped sharply with                difference when, due to time pressure, some information is
limited encoding time, far more than in the other conditions.        not encoded in the target.
    In sum, subjects’ accuracy at detecting a change in the               To avoid hand-coding the stimuli, we sketched the visual
relational pattern was high given a long encoding time, and          scenes for these simulations using sKEA, the sketching
very low given a short encoding time. Their accuracy at              Knowledge Entry Associate (Forbus & Usher, 2002). sKEA
detecting changes in attributes was high in both cases.              is an open-domain sketch understanding system designed to
These results suggest that more encoding time was needed             produce structural representations of a sketch. Objects in
for relations than for attributes. Indeed, S&Y conjectured           the sketch (called glyphs) can be identified as instances of
that encoding attributes may be necessary for encoding               categories from a large off-the-shelf knowledge base. sKEA
relations (see also Goldstone, Medin & Gentner, 1991).               automatically computes various spatial relationships,
    Assuming that the process of comparison can begin                including relative positions and sizes of glyphs, and has
before the encoding is complete, then matches among                  some limited shape recognition capabilities.
attributes may be discovered before the potentially matching
relations have all be computed. If so, then an early similarity
judgment will be dominated by local attribute matches,
without regard for their relational role. As the encoding
process continues and relations are added to the
representations, then the mapping may be updated using
incremental mapping techniques (Forbus et al., 1994; Keane
et al., 1988). We explore this possibility in two simulations.
                                                                                   Figure 4. Sketch of G&M stimuli
        4. Simulation: Incremental Encoding
Our goal in the first simulation was to test whether SME              Simulating Goldstone & Medin’s (1994) Results
could simulate the G&M results by assuming (a) that
                                                                      For our simulation of the G&M study, we drew each of the
attribute encoding precedes relation encoding; and (b) that
                                                                      butterfly body parts (head, wings, body, and tail) as separate
mapping can begin before the encoding is complete, and be
                                                                      glyphs (Figure 4). This captures the fact that the individual
incremented as the encoding proceeds. For the G&M
                                                                      parts were perceptually differentiable entities that could
simulation we assumed a two-stage process in which all
                                                                      match on their own with each other. Thus SME could align
attributes are encoded first, followed by all relations. This is
                                                                      parts from corresponding butterflies (MIPs) or non-
clearly an oversimplification; in our S&Y simulation we
                                                                      corresponding butterflies (MOPs).
also tested a gradual encoding process. SME can compare
                                                                 1725

     For convenience, we used color, rather than texture or          same influence on similarity. At long intervals, increasing
shape, as the dimension along which all four butterfly parts         the number of MIPs by two continued to have a strong
varied. This is because sKEA can identify colors readily and         influence, whereas increasing the number of MOPs by two
this choice does not seem to be of theoretical importance.           had a much weaker influence. Thus, we successfully
G&M made no distinction between changes in shape, the                replicated the effect of MOPs increasing similarity more at
dimension used for the head and tail, and changes in texture,        short intervals than at long intervals. This was the effect of
the dimension used for the body and wings. There were                primary interest to us, as it led the original experimenters to
four different colors that could be used for each butterfly          conclude that attributes played a stronger role early on in the
part: the color for the first butterfly in the base scene, the       comparison process than later in the process. We believe
color for the second butterfly in the base scene, and two            this result demonstrates that incremental encoding is a
novel colors. To avoid confusion, different sets of colors           plausible alternative explanation for this effect.
were used for each butterfly part. This follows a decision
made in the original study, in which the texture of the
                                                                                                   Matches Out of Place
butterfly body never matched the texture of the wings.
                                                                                                    0       1          2
     To draw the butterflies, we drew glyphs for each part,
                                                                                               0
applying the closest conceptual label from the knowledge
base (e.g., the body was labeled Trunk-BodyCore). The                                          1
                                                                                 Differences
glyphs for the parts were selected as a group and declared                                     2                           short
(using sKEA’s interface) to be a group glyph, which was                                                                    long
                                                                                               3
given the label Butterfly. Most of the visual relationships
computed by sKEA were automatically filtered out for this                                      4
simulation, since subjects were told in the original study that                                5
the positions of the butterflies were irrelevant. The glyph
group information was used to automatically compute part-
                                                                                                    Matches In Place
of relationships between a butterfly and its parts.
                                                                                                    4       5          6
     For this simulation we sketched one base scene (Figure                                    0
4) and 13 comparison scenes, representing the variations of
                                                                                               1
MIPs and MOPs used in the original Goldstone & Medin
                                                                                 Differences
(1994) study. Because there was no theoretical difference                                      2                           short
between the different shapes and textures used in the                                          3                           long
original study and no functional difference between the
                                                                                               4
colors used in our simulation, we were able to use a single
base scene without loss of generality. While the original                                      5
study used short, medium, and long deadlines, only the
differences between the short and long deadlines were
analyzed in detail, so we used only two deadline conditions.                Figure 5. Simulation results for G&M stimuli
In the short deadline condition, only the attributes of each
scene were encoded and fed into SME. In the long deadline                We also note that our results differ from the G&M
condition, an initial SME mapping was built using only the           results in a few respects. First, those results showed a
attributes, and then the relations were added and SME                greater difference between performance at the short and
remapped. The dependent measure was the number of                    long intervals. For example, the error rate for 0 MOPs was
differences SME found. SME mapped every butterfly part               much higher in the short deadline condition than in the long
to another butterfly part of the same type and every part-of         deadline condition in the original study, whereas in our
relation to another part-of relation, so the only differences        simulation the number of differences was the same for these
found were differences in color. For example, a light blue           two conditions. We suspect that the human results arise
tail might be matched to a brown tail.                               from the greater likelihood of decision errors under very
     In analyzing our results, we were primarily concerned           short decision deadline—if so, this is a general effect, not
with the effects of adding two MIPs or MOPs (see Figure 5,           specific to the comparison task. Second, G&M found a
and compare to Figure 3). Keep in mind that a decrease in            small effect of the number of MOPs even in the long
the number of differences identified by SME corresponds to           deadline condition, whereas in our simulation the number of
an increase in confusability of the stimuli and thus an              MOPs had no effect at all on the number of differences in
increase in error rate in the original study. For robustness,        the long deadline condition. This result suggests that MOPs
we focus on replicating the ordinal properties of the results        may actually affect similarity even when subjects have time
in the original studies, as is common in such simulations.           to fully encode and compare stimuli. Other studies have
     Our results matched G&M’s results for human subjects            also found evidence that MOPs can affect similarity in the
in two important respects. At short intervals, increasing the        absence of time constraints (Goldstone, 1994; Larkey &
number of MIPs or the number of MOPs by two had the                  Markman, 2005). We hope to explore this phenomenon
                                                                     further in a later paper.
                                                              1726

Simulating the Sloutsky & Yarlas Results
We tested whether SME could simulate the S&Y results,                    For this simulation, we sketched six base scenes (see
using the same assumptions of incremental encoding and              Figure 6 for an example) along with the E-/R-, E-/R+, and
mapping processes that are launched before encoding has             E+/R- comparison scenes for each base. As in the initial
been completed. Given unlimited time to make a                      study, E+ indicated a scene in which the three objects
comparison, the evidence suggests that even a single                shared all their attributes with the base scene, whereas E-
difference should generally allow subjects to correctly             indicated a scene with objects possessing entirely different
determine that two scenes are not the same. Thus. our               colors and shapes. R+ indicated a scene with objects in the
measure of performance for this study was the presence of           same relational pattern as in the base scene (A-B-A, A-A-B,
any differences produced by SME.                                    or A-B-B), whereas R- indicated a scene with objects in a
    In S&Y’s limited time condition, subjects had limited           different relational pattern.
time to look at the base scene, but had unlimited time to                We sketched two base scenes for each of the three
look at the comparison scene while making their                     relational patterns. The R- comparison scenes for these
comparison. To simulate this, in the limited time condition         bases each used one of the other patterns. Thus, the six sets
we limited the number of facts encoded about the base               of stimuli covered all possible combinations of relational
scene, but always encoded every fact about the comparison           patterns in the base and R- comparison scene. Because
scene. We entered the base scene as the base case for SME           there was no theoretical or functional difference between
and the comparison scene as the target case, so SME only            shapes or colors, we were able to use these six stimulus sets
made inferences from the base scene to the comparison               for our results without loss of generality. We ran each
scene. (This ensured that it would find differences when            condition 15 times per stimulus set, producing 90 total
there were facts in the representation of the base scene that       trials, and averaged the results.
were not in the representation of the comparison scene, but              In contrast to the previous simulation, in this simulation
not in the other direction, where spurious differences might        no information about the sketches was entered manually by
have been found simply because not all the facts from the           the user. sKEA automatically determined the color and
base scene had been encoded.)                                       shape of each glyph, as well as the relative positions of the
    However, one complexity in the human data should be             glyphs, which were encoded as right-of relations. Our
noted. The prediction from the preceding paragraphs is that         system also encoded a same-shape relation for the two
subjects should perform at only two levels (mostly correct          glyphs that shared the same shape.
for E-/R- and E-/R+ (E-) trials and mostly wrong for limited             Our results closely matched S&Y’s findings for humans
time E+/R- trials). But S&Y’s subjects exhibited at least           (see Figure 7). As in that study, when there was ample time
three levels, with medium levels of performance in the              to encode the base scene, performance in difference
limited-time condition for the E- trials (see Figure 7). Of         detection was roughly equal (and very high) for the E-/R-,
course, in the limited-time trials, it is expected that subjects    E-/R+, and E+/R- pairs. When the base encoding time was
might fail to encode some of the attributes (as well as failing     limited, our results for the three scenes showed the same
to encode relations). However, on the E- trials, the second         divergence as in the human results. For the E-/R- and E-/R+
scene differed from the first with respect to all object            pairs, there was only a small drop in performance. For the
attributes, so the only way to explain the lower performance        E+/R- pair, the drop was much greater. (We concede that
in the limited time condition would be if subjects failed to        the size of the drop in performance with the E-/R- and E-
encode any of the attributes. This might be the case. Given         /R+ pairs was dependent on the probability of encoding
that subjects received a large number of trials (60) with no        attributes from the initial scene, as determined by our
break between trials, they might occasionally have failed to        probability distribution. However, the ordinal properties of
attend during the 150 ms during which the base scene was            the results were relatively insensitive to changes in that
displayed. We suspect that this accounts for the slight drop        distribution. As long as there is some chance of subjects’
in performance from ample to limited time in the E- trials.         failing to encode any attributes and some chance of
    To capture these patterns, we varied the number of facts        encoding some attributes but no relations, the results would
that were encoded for the base scene in the limited time            still replicate the human ordinal results.)
condition. 1/5 of the time, the system failed to encode any              Most importantly, the simulation captures the large
attributes. 1/3 of the time, the system encoded all the             advantage of ample time over limited time for pairs with
attributes and a random subset of the positional relations.         relational differences (E+/R-), and shows that it exceeds the
The rest of the time, the system encoded a random subset of         small gain that occurs for ample time over limited time for
the attributes. We ran each condition 90 times and                  pairs with attributional differences (E-/R+ or E-/R-). Thus,
calculated the percentage of the time that the system found         performance with relations is more sensitive to time
at least one difference between the scenes.                         constraints than performance with attributes, suggesting that
                                                                    relations are encoded later.
     Figure 6. Sketch of Y&S stimuli with A-B-A pattern
                                                                1727

                                                                                                          References
                                                                                   Falkenhainer, B., Forbus, K. and Gentner, D. (1986). The
                                                                                     Structure-Mapping Engine. Proceedings of the Fifth
                                                                                     National Conference on Artificial Intelligence (pp. 272-
                                                                                     277). San Francisco, CA: Morgan Kaufmann.
                                                                                   Farell, B. (1985). Same-Difference judgments: A review of
                                                                                     current controversies in perceptual comparisons.
                                                                                     Psychological Bulletin, 98, 419-456.
                                                                                   Forbus, K.D, Ferguson, W. R., & Gentner, D. (1994).
                                                                                     Incremental structure mapping. Proceedings of the
                                                                                     Fourteenth Annual Conference of the Cognitive Science
                                                                                     Society (pp. 313-318). Hillsdale, NJ: Lawrence Erlbaum
                                                                                     Associates.
                                                                                   Gentner, D. (1983). Structure-mapping: A theoretical
                                  100%
                                                                                     framework for analogy. Cognitive Science, 7, 155-170.
                                                                                   Gentner, D., & Markman, A. B. (1997). Structure mapping
        Prob. of Distinguishing
                                  80%
                                                                                     in analogy and similarity. American Psychologist, 52, 42-
                                  60%                                                56.
                                                                 Ample Time
                                                                                   Gentner, D., Rattermann, M. J., & Forbus, K. D. (1993).
                                                                 Limited Time
                                  40%                                                The roles of similarity in transfer: Separating
                                                                                     retrievability from inferential soundness. Cognitive
                                  20%                                                Psychology, 25, 524-575.
                                                                                   Goldstone, R. L. (1994). Similarity, interactive activation,
                                   0%
                                                                                     and mapping. Journal of Experimental Psychology:
                                         E-/R-   E-/R+   E+/R-
                                                                                     Learning, Memory, and Cognition, 20, 3-28.
                                                                                   Goldstone, R. L., & Medin, D. L. (1994). Time course of
     Figure 7. Results of S&Y’s study (top) and of our                               comparison. Journal of Experimental Psychology:
                   simulation (bottom)                                               Learning, Memory, and Cognition, 20, 29-50.
                                                                                   Goldstone, R. L., Medin, D. L., & Gentner, D. (1991).
                                           5. Discussion                             Relational similarity and the non-independence of
                                                                                     features in similarity judgment. Cognitive Psychology,
We believe we have successfully replicated the Goldstone                             23, 222-264.
and Medin (1994) and Sloutsky and Yarlas (submitted)                               Keane, M.T., & Brayshaw, M. (1988). The incremental
studies. Our simulation suggests that the early effects of                           analogy machine: A computational model of analogy. In
structurally inconsistent attribute matches (cross-mapped                            D. Sleeman (Ed.), Third European Working Session on
attributes, or MOPs) found by G&M may reflect the time                               Machine Learning (pp. 53-62). London: Pitman.
course of encoding, instead of (or in addition to) the time                        Kuehne, S. E., Forbus, K. D., & Gentner, D. (2004).
course of comparison itself.                                                         Modeling infant learning via symbolic structural
    Further research will be necessary to determine the                              alignment. Proceedings of the Twenty-Second Annual
generality of the claim that attributes are encoded before                           Conference of the Cognitive Science Society, (pp. 286-
relations. The possibility that the encoding of relations may                        291). Hillsdale, NJ: Lawrence Erlbaum Associates.
depend on prior encoding of attributes should also be tested                       Larkey, L. B., & Markman, A. B. (2005). Processes of
further.                                                                             similarity judgment. Cognitive Science, 29, 1061-1076.
    Finally, while our simulations suggest that an                                 Loewenstein, J., & Gentner, D. (2005). Relational language
incremental comparison process may not be needed to                                  and the development of relational mapping. Cognitive
explain the early effect of cross-mapped attributes on                               Psychology, 50, 315-353.
similarity, the possibility of such a process remains open. It                     Markman, A. B., & Gentner, D. (1996). Commonalities and
is possible that attributes have priority both during encoding                       differences in similarity comparisons. Memory &
and during comparison. Further studies that independently                            Cognition, 24(2), 235-249.
manipulate encoding time and comparison time are needed                            Sloutsky, V. M., & Yarlas, A. S. (submitted). Processing of
to decide this.                                                                      information structure: Mental representations of elements
                                                                                     and relations.
                                         Acknowledgments
This research was supported by NSF-ROLE Award REC-
0337360 and ONR Cognitive Science Program Award
N00014-02-1-0078.
                                                                                1728

