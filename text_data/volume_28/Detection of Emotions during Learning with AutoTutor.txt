UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Detection of Emotions during Learning with AutoTutor
Permalink
https://escholarship.org/uc/item/2tb300fm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Chipman, Patrick
D'Mello, Sidney K.
Gholson, Barry
et al.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                            Detection of Emotions during Learning with AutoTutor
        Art Graesser (a-graesser@memphis.edu)                                                      Amy Witherspoon
    Department of Psychology, 202 Psychology Building                                  (awthrspn@mail.psyc.memphis.edu)
                     Memphis. TN 38152 USA                                       Department of Psychology, 202 Psychology Building
                                                                                                 Memphis. TN 38152 USA
    Bethany McDaniel (btmcdanl@memphis.edu)
    Department of Psychology, 202 Psychology Building                               Sidney D’Mello (sdmello@memphis.edu)
                     Memphis. TN 38152 USA                                       Institute for Intelligent Systems, 365 Innovation Drive
                                                                                                 Memphis, TN 38152 USA
    Patrick Chipman (pchipman@memphis.edu)
    Department of Psychology, 202 Psychology Building                              Barry Gholson (b.gholson@memphis.edu)
                     Memphis. TN 38152 USA                                       Department of Psychology, 202 Psychology Building
                                                                                                 Memphis. TN 38152 USA
                               Abstract                                    between cognition and emotions, they do not directly explain
   The relationship between emotions and learning was                      and predict the sort of emotions that occur during complex
   investigated by tracking the affective states that college students     learning, such as attempts to master physics, biology, or
   experienced while interacting with AutoTutor, an intelligent            computer literacy. Researchers in many different fields are
   tutoring system with conversational dialogue. An emotionally            familiar with Ekman’s work on the detection of emotions
   responsive tutor would presumably facilitate learning, but this
   would only occur if learner emotions can be accurately
                                                                           from facial expressions (Ekman & Friesen, 1978). However,
   identified. After a learning session with AutoTutor, the                the emotions that Ekman intensely investigated (e.g., sadness,
   affective states of the learner were classified by the learner, a       happiness, anger, fear, disgust, surprise) have minimal
   peer, and judges trained on Ekman’s Facial Action Coding                relevance to learning per se (Kort et al., 2001). The pervasive
   system. The classification of the trained judges was more               affective states during complex learning include confusion,
   reliable and matched the learners much better than the low              frustration, boredom, flow/engagement, interest, and being
   scores of untrained peers. This result suggests that peer tutors        stuck (Craig, Graesser, Sullins, & Gholson, 2004;
   may be limited in detecting the affective states of peer learners.      Csikszentmihalyi, 1990).
   Classification accuracy was poor at constant intervals of polling                  There are a number of ways in which tutors (and
   (every 20 seconds) but much higher when individuals declared
   that an affect state had been experienced.
                                                                           other types of learning environments) might adaptively
                                                                           respond to the learner’s affective states in the course of
   Keywords: Emotion; Instruction and teaching; Human                      enhancing learning (D’Mello, Craig, Sullins, & Graesser, in
   computer interaction; AutoTutor; Affective states                       press; Graesser et al., 2005; Lepper & Woolverton, 2002). If
                                                                           the learner is frustrated, for example, the tutor can give hints
                            Introduction                                   to advance the learner in constructing knowledge or can make
Connections between complex learning and emotions have                     supportive empathetic comments to enhance motivation. If
received increasing attention in the fields of psychology                  the learner is bored, the tutor needs to present more engaging
(Carver, 2004; Deci & Ryan, 2002; Dweck, 2002), education                  or challenging problems for the learner to work on. The tutor
(Lepper & Henderlong, 2000; Linnenbrink & Pintrich, 2004;                  would probably want to lay low and stay out the learner’s
Meyer & Turner, 2002), neuroscience (Damasio, 2003), and                   way when the learner is in a state of flow (Csikszentmihaly,
computer science (Kort, Reilly, & Picard, 2001; Picard,                    1990), i.e., when the learner is so deeply engaged in learning
1997). A deep understanding of such affect-learning                        the material that time and fatigue disappear. The flow
connections is needed in order to design engaging educational              experience is believed to occur when the learning rate is high
artifacts that range from responsive intelligent tutoring                  and the learner has achieved a high level of mastery at the
systems on technical material (DeVicente & Pain, 2002;                     region of proximal learning (Metcalfe & Kornell, 2005).
Graesser, Person, Lu, Jeon, & McDaniel, 2005; Guhe, Gray,                             The affective state of confusion is particularly
Schoelles, & Ji, 2004; Litman & Silliman, 2004) to                         interesting because it is believed to play an important role in
entertaining media and games (Conati, 2002; Gee, 2003;                     learning (Graesser et al., 2005; Guhe et al., 2004) and has a
Vorderer, 2003).                                                           large correlation with learning gains (Craig et al., 2004).
           There have been several theories that link cognition            Confusion is diagnostic of cognitive disequilibrium, a state
and affect very generally (Bower, 1981; Mandler, 1984;                     that occurs when learners face obstacles to goals,
Ortony, Clore, & Collins, 1988; Russell, 2003; Stein &                     contradictions, incongruities, anomalies, uncertainty, and
Levine, 1991). While these theories convey general links                   salient contrasts (Festinger, 1957; Graesser, Lu, Olde, Pye-
                                                                           Cooper, & Whitten, 2005; Graesser & Olde, 2003; Piaget,
                                                                       285

1952). Cognitive equilibrium is restored after thought,                        The present study investigated the extent to which
reflection, problem solving and other effortful cognitive              trained judges and untrained peers can accurately identify the
activities. When the learner is confused, there might be a             affective states of learners who interact with AutoTutor. This
variety of paths for the tutor to pursue. The tutor might want         immediate objective feeds into the long-term goal of building
to allow the learner to continue being confused during the             a version of AutoTutor that identifies and responds adaptively
cognitive disequilibrium (and the affiliated increased                 to the affective states of the learner. AutoTutor will never be
physiological arousal that accompanies all affective states);          able to adapt to the learner’s emotions if it cannot detect the
the learner’s self-regulated thoughts might hopefully restore          learner’s emotions. Peer tutors and expert tutors similarly
equilibrium. Alternatively, after some period of time waiting          will be unable to adapt to the learner’s emotions if they
for the learner to progress, the tutor might give indirect hints       cannot identify such affective states.
to nudge the learner into more productive trajectories of
thought.                                                                                           Methods
          Goleman (1995) stated in his book, Emotional
Intelligence, that expert teachers are able to recognize a             Participants
student’s emotional state and respond in an appropriate                The participants were 28 undergraduates at the University of
manner that has a positive impact on the learning process.             Memphis who participated for extra course credit.
This is an important claim, but would be seriously limited if
teachers are unable to detect the affective states of the learner.     Materials and Procedure
One important question needs to be addressed by all
                                                                       The experiment was divided into two sessions. Session 1 took
theoretical frameworks and pedagogical practices that relate
                                                                       two hours and consisted of a pretest, interaction with
emotions and learning: How are affective states detected and
                                                                       AutoTutor, a posttest, and judgments of emotions they
classified? That is, how are the emotions recognized by
                                                                       experienced while interacting with AutoTutor (self
tutors, peers, automated sensing devices, and the learners
                                                                       judgments, see below). Session 2 lasted one hour and
themselves? This question motivated the present study.
                                                                       consisted of judgments of the emotions of a peer while the
          One preliminary step in answering the fundamental
                                                                       peer had interacted with AutoTutor (peer judgments).
question of how affective states are classified is to investigate
a simple measurement question: How reliably can emotions
                                                                       AutoTutor Participants interacted with AutoTutor for 32
be classified by the learners themselves versus peers versus
                                                                       minutes on one of three randomly assigned topics in
trained judges (experts)? An emotionally sensitive learning
                                                                       computer literacy: hardware, Internet, or operating systems
environment, whether it be human or computer, requires
                                                                       (see Graesser et al., 2001 for detailed information about
some degree of accuracy in classifying the learners’ affect
                                                                       AutoTutor). Each of these topics had 12 questions that
states. The emotion classifier need not be perfect, but it must
                                                                       required about a paragraph of information (3-7 sentences) in
have some modicum of accuracy. The present study tracked
                                                                       an ideal answer. The questions required answers that
the affective states that college students experience while
                                                                       involved inferences and deep reasoning, such as why, how,
interacting with AutoTutor, an intelligent tutoring system that
                                                                       what-if, what if not, how is X similar to Y?. Although each
helps students learn by holding a conversation in natural
                                                                       question required 3-7 sentences in an ideal answer, learners
language (Graesser, Chipman, Haynes, & Olney, 2005;
                                                                       rarely give the complete answer in a single turn. A
Graesser et al., 2004; Graesser, Person, & Harter, 2001;
                                                                       conversation occurs with multiple turns that take a few
VanLehn et al., in press).
                                                                       minutes. A typical learner could only answer 3-5 questions
        AutoTutor was designed to simulate human tutors
                                                                       within the allotted 32 minutes.
while it converses with students in natural language.
                                                                                 The AutoTutor interface had 4 windows, as shown
AutoTutor begins by presenting a challenging question to the
                                                                       in Figure 1. Window 1 (top of screen) was the main question
learner that requires about a paragraph of information to
                                                                       that stayed on the computer screen throughout the
answer correctly. The typical response from the learner,
                                                                       conversation that involved answering the question. Window
however, is usually only one word to two sentences in length.
                                                                       2 (bottom of screen) was affiliated with the learner’s answer
Therefore, AutoTutor uses a series of pumps (“What else?”,
                                                                       in any one turn and echoed whatever the learner typed in via
“uh huh”), prompts for the learner to express a specific word,
                                                                       keyboard. Window 3 (left middle) was an animated
hints, assertions, and feedback to elicit responses from the
                                                                       conversational agent that spoke the content of AutoTutor’s
learner that lead to a complete answer of the question. Before
                                                                       turns. The talking head had facial expressions and some
the learner is able to give AutoTutor a paragraph of correct
                                                                       rudimentary gestures. Window 4 (right middle) was either
information, there can be between 30 to 200 student and tutor
                                                                       blank or had auxiliary diagrams.
turns, about the length of a dialogue with a human tutor.
                                                                   286

Figure 1: Interface of AutoTutor                                      Frustration was defined as dissatisfaction or annoyance.
                                                                      Delight was a high degree of satisfaction. Surprise was
                                                                      wonder or amazement, especially from the unexpected.
                                                                      Neutral was defined as no apparent emotion or feeling.
                                                                                The judgments for a learner’s tutoring session
                                                                      proceeded by playing a video of the face along with a screen
                                                                      capture video of interactions with AutoTutor. Judges were
                                                                      instructed to make judgments on what affective states were
                                                                      present in each 20-second interval at which the video
                                                                      automatically stopped. There was a checklist of emotions for
                                                                      them to mark, along with an “other” category for them to
                                                                      provide additional emotions that they viewed as relevant.
                                                                      They were also instructed to indicate any affective states that
                                                                      were present in between the 20-second stops. If the
                                                                      participant was experiencing more than one affective state in
                                                                      a 20-second block, judges were instructed to mark each state
          Each turn of AutoTutor in the conversational                and indicate which was most pronounced.
dialogue had three information slots (i.e., units, constituents).               In summary, each video of the tutorial interaction
The first slot of most turns was feedback on the quality of the       was judged by the self (the learner), a peer (another learner),
learner’s last turn. This feedback was either positive (very          and two trained judges.
good, yeah), neutral (uh huh, I see), or negative (not quite, not
really). The second slot advanced the conversation with                                          Results
either prompts for specific information, hints, assertions with       Interjudge reliability in judging emotions was computed
correct information, corrections of misconceptions, or                using Cohen’s kappa for all possible pairs of judges: self,
answers to student questions. The third slot was a cue for the        peer, trained judge1, and trained judge2. Altogether, there
floor to shift from AutoTutor as the speaker to the learner.          were six possible pairs (see Table 1). The reliability scores
Discourse markers (and also, okay, well) connected the                were based on the first-choice affect state the learner gave.
utterances of these three slots of information. The                   The observations included those judgments at the 20-second
conversations managed by AutoTutor are sufficiently smooth            interval polling (approximately 2500 observations) and those
that learners can get through the session with minimal                in-between observations in which learners stated that they had
difficulties.                                                         an emotion in between two successive pollings (between 78
                                                                      and 180 observations for each of the 6 pairs in Table 1).
Judging Affective States Four sets of emotion judgments               Cohen’s kappa scores were computed separately for each of
were made for the observed affective states of each                   the 28 learners. Statistical analyses were performed on these
AutoTutor session. First, for the self judgments, the learner         kappa scores when comparing agreement of the 6 pairs of
watched his or her own session with AutoTutor immediately             judges in Table 1.
after having interacted with AutoTutor. Second, for the peer                    The scores in Table 1 revealed that the trained
judgments, each learner came back a week later to watch and           judges had the highest agreement, the self-peer pair had near
judge another learner’s session on the same topic in computer         zero agreement, and the other pairs of judges were in
literacy. Finally, there were two trained judges: undergraduate       between. An ANOVA was performed on the left column of
research assistants who were trained extensively on tutorial          scores that included all observations, namely those at fixed
dialogue characteristics and how to detect facial action units        20-second intervals plus those at voluntary timestamps. The
according to Paul Ekman’s Facial Action Coding System                 results reveal that there were significant differences in kappa
(Ekman & Friesen, 1978). The two trained judges judged all            scores among the six pairs, F(5, 135) = 33.34, MSe =.008, p <
sessions separately.                                                  .01. Fisher LSD post hoc tests revealed that the self-peer pair
          A list of the affective states and definitions was          had the lowest inter-judge reliability scores (p < .05) when
provided for the learners, peers, and two trained judges. The         compared to the other five pairs. The two trained judges had
states were boredom, confusion, flow, frustration, delight,           significantly higher kappa scores than the other five pairs.
neutral and surprise, the emotions that were most frequently          These results support the conclusion that peers are not
experienced in a previous study of AutoTutor (Craig et al.,           particularly good at detecting learner emotions. Another
2004). Boredom was defined as being weary or restless                 conclusion is that training on Ekman’s facial action coding
through lack of interest. Confusion was defined as a                  system and tutorial dialogue can enhance the reliability and
noticeable lack of understanding, whereas flow was a state of         accuracy of judgments of affective states.
interest that results from involvement in an activity.
                                                                  287

 Table 1: Kappa scores for judgments of affective states at all      are either in a neutral state or in a subtle affective state
     points, 20-second intervals, and voluntary timestamps.          (boredom or flow).
     Pair of Judges      All       20-second      Voluntary                                    Discussion
     Self/Peer           0.08        0.06         0.12               An emotion-sensitive AutoTutor would presumably promote
     Self/Judge1         0.14        0.11         0.31               both learning gains and more engagement in the learner.
     Self/Judge2         0.16        0.13         0.24               AutoTutor should have different strategies and dialogue
     Peer/Judge1         0.14        0.11         0.36               moves when the learner is confused or frustrated than when
                                                                     the learner is bored. However, both human and automated
     Peer/Judge2         0.18        0.15         0.37
                                                                     tutors can be emotionally adaptive only if the emotions of the
     Judge1/Judge2       0.36        0.31         0.71               learner can be detected. The accuracy of the detection need
                                                                     not be perfect, but it should be approximately on target.
          Further analyses were performed after segregating
judgments that were made at the regularly polled timestamps                    The results of this study support a number of
(every 20 seconds) and those which were made at voluntary            conclusions about emotion detection. First, trained judges
timestamps in between the automatic 20-second stop points.           who are experienced in coding facial actions and tutorial
For example, if a judge made a judgment at 4 minutes, when           dialogue provide affective judgments that are more reliable
the video playback automatically paused, that judgment               and that match the learner’s self reports better than the
would be in the “regularly polled sample” group. If the same         judgments of untrained peers. Second, the judgments by peers
judge manually paused the video and made a judgment at 4             have very little correspondence to the self reports of learners.
minutes and 16 seconds, that particular judgment would be in         Peers apparently are not good judges of the emotions of
the “voluntary” judgment sample. There were substantially            learners. Third, an emotion labeling task is more difficult if
fewer observations in the voluntary sample than the regularly        judges are asked to make emotion judgments at regularly
polled sample because judges were not required to stop and           polled timestamps, rather than being able to stop a video
make judgments in between.              The voluntary sample         display to make spontaneous judgments. The states at regular
presumably had more salient affective states than the                timestamps are much less salient so there is minimal
regularly polled sample, so agreement should be higher.              information for judges to base their judgments, compared
          The inter-judge reliability increased considerably for     with those points when affective states are voluntarily
all pairs of judges when computed only on those observations         spotted. Training on facial expressions makes judges more
that were voluntary judgments. The highest inter-judge score         mindful of relevant facial features and transient facial
was between the trained judges (kappa = 0.71) whereas the            movements, but judges can do this only if the expressions
lowest was between the self and peer (kappa = 0.12). The             have enough information to fortify these judgments.
kappa for self and peer did increase for voluntary timestamps,                 Many advocates of peer tutoring have extolled the
but the voluntary kappa for self and peer was not appreciably        virtues of having peers tutor each other. One potential
above the kappa for all judgments (.12 versus .08). When             advantage of peer tutoring is that there is no appreciable
considering only those judgments made at the 20-second               status difference between peers, compared to when a teacher
interval stops, inter-judge reliability was substantially lower      tutors a student or an older tutor helps a younger learner
and closely corresponded to the kappa scores for all                 (Rogoff, 1990). The results of the present study suggest,
judgments.                                                           however, that there may be a drawback of peer tutoring. Peer
          The judgments made in the voluntary sample                 tutors apparently are not very good at classifying emotions of
involved more animated emotions (and theoretically higher            learners. It takes expertise in tutoring or emotion detection
physiological arousal) compared to the more subtle emotions          before accurate detection of learner emotions can be
at the 20-second intervals. An analysis was performed on the         achieved. This requirement of expertise is apparently quite
proportions of emotion categories at the 20-second intervals.        important because, according to Lepper and Woolverton
We examined the proportion of judgments that were made for           (2002), roughly half of expert tutors’ interactions with the
each of the affect categories, averaging over the 4 judges.          student are focused on affective elements. Our trained judges
The most common affective state was neutral (.369), followed         were simply trained on Ekman’s facial action coding system
by confusion (.212), flow (.188), and boredom (.167); the            and characteristics of tutorial dialogue. We are uncertain at
remaining states of delight, frustration and surprise totaled        this point whether it is the detection of facial expressions that
.065 of the observations. The more salient voluntary points          is important in tutoring or a seasoned experience with domain
had a rather different distribution. The most prominent affect       knowledge and pedagogy. Future research is needed to
state was confusion (.377), followed by delight (.192) and           resolve this.
frustration (.191), whereas the remaining affective states                     It is unclear what exactly should be the gold
comprised .240 of the observations (boredom, surprise, flow,         standard for deciding what emotions a learner is truly having.
and neutral, in descending order). Most of the time learners         Should it be the learner or the expert? We are uncertain about
                                                                 288

the answer to this question, but it is conceivable that some       Craig, S.D., Graesser, A.C., Sullins, J., & Gholson, B. (2004).
emotions may best be classified by learners and others by            Affect and learning: An exploratory look into the role of
experts. Perhaps a composite score that considers both               affect in learning with AutoTutor. Journal of Educational
viewpoints would be most defensible.                                 Media, 29, 241-250.
           Whatever the gold standard might be, there is the       Csikszentmihalyi, M. (1990). Flow: The psychology of
challenge of identifying what sensing devices and automated          optimal experience, Harper-Row: NY.
affect classifiers we should integrate with AutoTutor. An          Damasio, A. R. (2003). Looking for Spinoza: Joy, sorrow,
automated affect classifier is of course needed to make              and the feeling brain. Orlando, FL:Harcourt.
AutoTutor responsive to learner emotions.            We have       De Vicente, A., & Pain, H. (2002). Informing the detection of
previously reported some studies that collected verbal               students' motivational state : An empirical study. In S.A.
expressions of emotions (an emote-aloud protocol) from               Cerri, G. Gouarderes, and F. Paraguacu (Eds Proceedings
college students while interacting with AutoTutor. These             of the sixth international conference on intelligent tutoring
learners say out loud whatever emotions come to mind while           systems (pp.933-943). Berlin, Germany: Springer.
interacting with the system. We have simultaneously                Deci, E. L., & Ryan, R. M. (2002). The paradox of
recorded the dialogue history and facial action units while          achievement: The harder you push, the worse it gets. In J.
they learn and emote aloud. There are systematic relations           Aronson (Ed.), Improving academic achievement: Impact
between these sensing channels and particular emotions. For          of psychological factors on education (pp. 61-87). Orlando,
example, verbalized emotions are prevalent after AutoTutor’s         FL: Academic Press.
feedback (positive, neutral, negative), the directness of          D'Mello, S. K., Craig, S. D., Gholson, B., Franklin, S., Picard,
AutoTutor’s dialogue moves (hints are less direct than               R.,& Graesser, A. C. (2005). Integrating affect sensors in
assertions), and the quality of learner’s contributions              an intelligent tutoring system. In Affective Interactions: The
(D’Mello, Craig, Sullins, & Graesser, in press). Particular          Computer in the Affective Loop Workshop at 2005
facial expressions are correlated with particular emotions           International conference on Intelligent User Interfaces (pp.
(D’Mello et al., 2005). Frustration is associated with outer         7-13) New York: AMC Press.
brow raise, inner brow raise, and the dimpler whereas              D’Mello, S.K., Craig, S.D., & Graesser, A.C. (in press).
confusion is associated with brow lowerer, lid tightener, and        Predicting affective states through an emote-aloud
lip corner puller. Posture may be correlated with interest           procedure from AutoTutor’s mixed-initiative dialogue.
(Mota & Picard, 2003). If we record speech, then affective           International Journal of Artificial Intelligence in
states may be induced from a combination of lexical,                 Education.
acoustical, and prosodic features (Litman & Forbus-Reilly,         Dweck, C. S. (2002). Messages that motivate: How praise
2004). We believe that most of these features from the               molds students’ beliefs, motivation, and performance (in
various modalities can be detected in real time automatically        surprising ways). In J. Aronson (Ed.), Improving academic
on computers. Whether an automated affect detector can be            achievement: Impact of psychological factors on education
achieved awaits future research and technological                    (pp. 61-87). Orlando, FL: Academic Press.
development.                                                       Ekman, P, & Friesen, W. V. (1978). The facial action coding
                                                                     system: A technique for the measurement of facial
                    Acknowledgements                                 movement. Palo Alto: Consulting Psychologists Press.
This research was supported by the National Science                Festinger, L. (1957). A theory of cognitive dissonance.
Foundation (REC 0106965 and ITR 0325428), the Institute of           Stanford, CA: Stanford University Press.
Education Sciences (R305H050169), and the DoD                      Gee, J.P. (2003). What video games have to teach us about
Multidisciplinary University Research Initiative administered        language and literacy. New York: Macmillan.
by ONR under grant N00014-00-1-0600. Any opinions,                 Graesser, A.C., Chipman, P., Haynes, B.C., & Olney, A.
findings and conclusions or recommendations expressed in             (2005). AutoTutor: An intelligent tutoring system with
this paper are those of the authors and do                           mixed-initiative dialogue. IEEE Transactions on
not necessarily reflect the views of NSF, DoD, or ONR.               Education. 48, 612-618.
                                                                   Graesser, A.C., Lu, S., Jackson, G.T., Mitchell, H., Ventura,
                          References                                 M., Olney, A., & Louwerse, M.M. (2004). AutoTutor: A
                                                                     tutor with dialogue in natural language. Behavioral
Bower. G.H. (1981). Mood and memory. American
                                                                     Research Methods, Instruments, and Computers, 36, 180-
   Psychologist, 36, 129-148.
                                                                     193.
Carver, C. S. (2004). Negative affects deriving from the
                                                                   Graesser, A.C., Lu, S., Olde, B.A., Cooper-Pye, E., &
   behavioural approach system. Emotion, 4, 3-22.
                                                                     Whitten, S. (2005). Question asking and eye tracking
Conati, C. (2002). Probabilistic assessment of user's emotions
                                                                     during cognitive disequilibrium: Comprehending illustrated
   in educational games. Journal of Applied Artificial
                                                                     texts on devices when the devices break down. Memory
   Intelligence, 16, 555-575.
                                                                     and Cognition, 33, 1235-1247.
                                                               289

Graesser, A. C. & Olde, B. (2003). How does one know                  Proceedings of the 42nd annual meeting of the association
  whether a person understands a device? The quality of the           for computational linguistics (pp. 352-359). East
  questions the person asks when the device breaks down.              Stroudsburg, PA: Association for Computational
  Journal of Educational Psychology, 95, 524–536.                     Linguistics.
Graesser, A. C., Person N., Harter, D. & The Tutoring               Litman, D. J., & Silliman, S. (2004). ITSPOKE: An
  Research Group (2001) Teaching tactics and dialog in                intelligent tutoring spoken dialogue system. In proceedings
  AutoTutor, International Journal of Artificial Intelligence         of the human language technology conference: 3rd meeting
  in Education, 12, 257–279.                                          of the North American chapter of the association of
Graesser, A.C., Person, N., Lu, Z., Jeon, M.G., & McDaniel,           computational linguistics (pp. 52-54). Edmonton, Canada:
  B. (2005). Learning while holding a conversation with a             ACL.
  computer. In L. PytlikZillig, M. Bodvarsson, & R. Bruning         Mandler, G. (1984). Mind and body: Psychology of emotion
  (Eds.), Technology-based education: Bringing researchers            and stress. New York: Norton.
  and practitioners together (pp. 143-167). Greenwich, CT:          Metcalfe, J., & Kornell, N. (2005). A region or proximal of
  Information Age Publishing.                                         learning model of study time allocation. Journal of Memory
Goleman, D. (1995). Emotional intelligence (New York,                 and Language, 52, 463-477.
  Bantam Books).                                                    Meyer, D. K., & Turner, J. C. (2002). Discovering emotion in
Guhe, M., Gray, W. D., Schoelles, M. J., & Ji, Q. (2004,              classroom motivation research. Educational Psychologist,
  July). Towards an affective cognitive architecture. Poster          37, 107-114.
  session presented at the Cognitive Science Conference,            Mota, S. & Picard, R. W. (2003). Automated posture analysis
  Chicago, IL.                                                        for detecting learner’s interest level. Workshop on
Kort, B., Reilly, R., & Picard, R. (2001). An affective model         Computer Vision and Pattern Recognition for Human-
  of interplay between emotions and learning: Reengineering           Computer Interaction, CVPR HCI, June, 2003.
  educational pedagogy—building a learning companion. In            Ortony, A., Clore, G. L., & Collins, A. (1988). The cognitive
  T. Okamoto, R. Hartley, Kinshuk, & J. P. Klus (Eds.),               structure of emotions. New York: Cambridge University
  Proceedings IEEE International Conference on Advanced               Press.
  Learning Technology: Issues, Achievements and                     Piaget, J. (1952). The origins of intelligence. New York:
  Challenges (pp.43-48).        Madison, Wisconsin: IEEE              International University Press.
  Computer Society.                                                 Picard, R. W. (1997). Affective computing. Cambridge, Mass:
Lepper, M. R., & Henderlong, J. (2000). Turning "play" into           MIT Press.
  "work" and "work" into "play": 25 years of research on            Rogoff, B. (1990). Apprenticeship in thinking. New York:
  intrinsic versus extrinsic motivation. In C. Sansone & J. M.        Oxford University Press.
  Harackiewicz (Eds.), Intrinsic and extrinsic motivation:          Russell, J.A. (2003). Core affect and the psychological
  The search for optimal motivation and performance (pp.              construction of emotion. Psychological Review, 110, 145-
  257-307). San Diego, CA: Academic Press.                            172.
Lepper, M. R., & Woolverton, M. (2002). The wisdom of               Stein, N. L., & Levine, L. J. (1991). Making sense out of
  practice: Lessons learned from the study of highly effective        emotion. In W. Kessen, A. Ortony, & F. Kraik (Eds.),
  tutors. In J. Aronson (Ed.), Improving academic                     Memories, thoughts, and emotions: Essays in honor of
  achievement: Impact of psychological factors on education           George Mandler (pp. 295-322). Hillsdale, NJ: Erlbaum.
  (pp. 135-158). Orlando, FL: Academic Press.                       VanLehn, K., Graesser, A.C., Jackson, G.T., Jordan, P.,
Linnenbrink, E. A., & Pintrich, P. A. (2004). Role of affect in       Olney, A., & Rose, C.P. (in press). When are tutorial
  change processing in academic contexts. In D. Y. Dai, & R.          dialogues more effective than reading? Cognitive Science.
  J. Sternberg (Eds.), Motivation, emotion, and cognition:          Vorderer, P. (2003). Entertainment theory. In B. Jennings, D.
  Integrative perspectives on intellectual functioning and            Roskos-Ewoldsen, & J. Cantor (Eds.), Communication and
  development (pp. 57-88). Mahwah, New Jersey: Lawrence               emotion: Essays in honor of Dolf Zillmann (pp. 131-153).
  Erlbaum Associates.                                                 Mahwah, NJ: Erlbaum.
Litman, D. J., & Forbes-Riley, K. (2004). Predicting student
  emotions in computer-human tutoring dialogues. In
                                                                290

