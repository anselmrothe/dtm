UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Understanding the Causal Logic of Confounds
Permalink
https://escholarship.org/uc/item/53q52925
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Hagmayer, York
Meder, Björn
Waldmann, Michael R.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                   Understanding the Causal Logic of Confounds
                                             Björn Meder (bmeder@uni-goettingen.de)
                                    York Hagmayer (york.hagmayer@bio.uni-goettingen.de)
                              Michael R. Waldmann (michael.waldmann@bio.uni-goettingen.de)
                                    Department of Psychology, University of Göttingen, Gosslerstr. 14,
                                                         37073 Göttingen, Germany
                               Abstract                                 independent of each other. Under these circumstances the
                                                                        impact of the cause variable can be seen as an increase (gen-
   The detection of causal relations is often complicated by con-       erative influence) or decrease (inhibitory influence) of the
   founding variables. Handbooks on methodology therefore sug-          probability of the effect given the presence of the cause.
   gest experimental manipulations of the independent variable             Methodology textbooks (e.g., Keppel & Wickens, 2000)
   combined with randomization as the principal method of deal-         strongly recommend controlled experiments to eliminate the
   ing with this problem. Recently, progress has been made within
   the literature on causal Bayes nets on the proper analysis of
                                                                        relations between the cause and potentially confounding vari-
   confounds with non-experimental data (Pearl, 2000). The pre-         ables. Experiments involve the random assignment of partici-
   sent paper summarizes the causal analysis of two basic types of      pants to experimental and control groups (i.e., randomization)
   confounding: common-cause and causal-chain confounding.              and a manipulation of the putative cause variable by an out-
   Two experiments are reported showing that participants under-        side intervention. This procedure ensures independence of the
   stand the causal logic of these two types of confounding.            cause variable from all other potentially confounding vari-
                                                                        ables. However, in some sciences (e.g., astronomy) and in
                                                                        many everyday contexts controlled experimentation is impos-
                           Introduction                                 sible. Thus, people have to deal with the problem of con-
Scientific studies and everyday causal learning aim to reveal           founding variables quite often. This paper intends to show (i)
the structure and strength of causal relations among events:            under which conditions valid causal inferences are possible
Does event C cause event E? Will a manipulation of C gener-             on the basis of observations even in the presence of con-
ate E? In order to answer these questions, data have to be              founding variables, and (ii) that people are capable of reason-
gathered. But even with data it is often hard to answer these           ing correctly with causal models that contain confounds.
questions because the statistical relation observed between C              Throughout this paper we focus on the most basic type of
and E not only may reflect a direct causal relation but a spuri-        causal induction, the detection and evaluation of a single
ous relation due to other, confounding variables.                       causal relation. In addition, we assume that there is a known
   For example, in the 1950’s, a series of studies with non-            confounding variable which is related to both the cause and
experimental data was published showing that lung cancer                the effect. First, we will provide a causal analysis of con-
was found to be more frequent in smokers than in non smok-              founding. Then we will show how causal Bayes net theory
ers (e.g., Doll & Hill, 1956). This data was interpreted as             models confounding and causal inferences. Finally, we will
evidence that smoking is a cause of lung cancer. However,               report two experiments investigating whether participants are
some prominent statisticians (e.g., Fisher, 1958) argued that           able to take confoundings into account.
such a conclusion was not justified on the basis of the avail-
able data. Fisher (1958) offered an alternative causal model in         The Causal Basis of Confounding
which the observed covariation was not interpreted as a direct
                                                                           Two basic causal structures may underlie confounding.
causal relation but as a spurious correlation generated by a
                                                                        One possibility is that the confounding variable X is a cause
common cause, a specific genotype causing both a craving for
                                                                        of both the candidate cause C and the effect E (com-
nicotine and the development of lung cancer.
                                                                        mon-cause confound, Fig. 1a). Another possibility is a causal-
   Confounding variables are statistically related to both the
                                                                        chain model in which the cause variable C not only directly
potential cause C (independent variable) and the presumed
                                                                        influences the effect E but also generates the confounding
effect E (dependent variable). It is the relation between the
                                                                        variable X, which, in turn, influences E (causal-chain con-
confounding variable and the cause that creates serious prob-
                                                                        found, Fig. 1b). The crucial point is that both models imply a
lems. In the most extreme case the cause and the other vari-
                                                                        correlation between cause C and effect E, even when there is
able are perfectly confounded, that is, they are either both
                                                                        no direct causal relation between them (i.e., without the
present or both absent all the time. In this case it is impossible
                                                                        causal arrow C→E). If the confounding variable is present,
to tell whether the effect is generated by the cause or by the
                                                                        both the cause and the effect should tend to be present; if X is
confounding variable. Note that the problem of confounding
                                                                        absent both C and E should tend to be absent. In addition to
does not originate in the relation between the extraneous vari-
                                                                        the causal relations connecting the confounding variable to C
able and the effect. Even if the extraneous variable has a very
                                                                        and E there is a direct causal relation between C and E whose
strong influence, the impact of the cause variable can be de-
                                                                        existence and strength has to be identified.
tected as long as the extraneous variable is not permanently
present and the cause variable and the extraneous variable are
                                                                    579

               (a)                            (b)                   causal model representing events and their directed causal
  Common-Cause Confound             Causal-Chain Confound           relations (see Fig. 1). Associated with the model are parame-
                                                                    ters (e.g., conditional probabilities) encoding the strength of
                                                                    the causal relations and the events’ base rates. At the heart of
                                                                    the causal Bayes nets framework lies the causal Markov con-
                                                                    dition (Spirtes et al., 1993; Pearl, 2000) which states that the
                                                                    value of any variable X in a causal model is independent of all
                                                                    other variables (except for its causal descendants) conditional
                                                                    on the set of its direct causes. By applying the Markov condi-
             Figure 1: Two Types of Confounding                     tion the joint probability distribution of a causal model can be
   The two models shown in Fig. 1 represent two different           factorized using components representing only direct causal
kinds of confounding. The common-cause confound model               relations. For example, the joint probability distribution of the
represents the situation that some extraneous variable is caus-     common-cause confound model can be factorized into
ally affecting both the cause and the effect. The hypothesis          (1) P(X.C.E) = P(X) · P(C|X) · P(E|C.X)
that smoking and lung cancer are both caused by a specific
                                                                    Similarly, the causal-chain confound model can be formalized
genotype exemplifies this type of confounding. There are
                                                                    by
several possibilities to eliminate the causal relation between
the common cause X and the candidate cause C. For example,            (2) P(X.C.E) = P(C) · P (X|C) · P(E|C.X)
X might be eliminated or held constant (e.g., only people           The conditional probabilities of the decomposed models can
without the carcinogenic genotype are studied). In addition, C      be directly estimated from the conditional frequencies in the
might be manipulated independently of X (which would not            available data, provided the confounding variable is observed
be possible in the case of smoking for ethical reasons). Such       along with the cause and effect variables.
an independent manipulation is equivalent to a randomized              However, the causal consequences of possible interventions
experiment (Fisher, 1951).                                          cannot always be read off from conditional frequency infor-
   However, simple randomization combined with manipula-            mation alone. Consider the common-cause confound model
tions of the candidate cause C cannot eliminate causal-chain        depicted in Figure 1a. The conditional probability of the ef-
confounding. This type of confounding calls for other con-          fect in the presence of the cause (i.e., P(e|c)) reflects both the
trols because a manipulation of C would directly affect X.          direct causal influence of C on E and the spurious relation
Thus, other ways have to be found to block the causal relation      arising from the confounding common cause X. However,
connecting the cause C to the confound X. For example, aspi-        intervening in C renders the cause independent of the con-
rin (C) might not only have a direct influence on headache but      founding variable because the intervention fixes the variable’s
also make your blood thinner (X), which, in turn, might also        state. Therefore the probability of E given an intervention in
have an impact on your headache (E). One way to get rid of          C reflects the causal influence of C on E and the causal influ-
confounding in this case is to administer aspirin to people         ence of X on E but is not distorted by a spurious relation.
who all have thin blood or who are resistant against the side          To formalize the notion of an external intervention, Pearl
effect, which is equivalent to holding the confound constant.       (2000) introduced the so-called ‘Do-Operator’, written as
Another possibility is to manipulate the confounding variable       Do (•). Formally, the Do-operator renders a variable inde-
in addition to the cause variable and thereby eliminate their       pendent of all its causes, which is graphically represented by
causal relation.                                                    deleting all causal links pointing towards the variable fixed by
   In summary, there are two fundamental types of confound-         the intervention (‘graph surgery’). Based on the modified
ing which call for different measures of control. While exter-      causal model and the factorized joint probability distribution,
nal manipulations of the candidate cause eliminate common-          the probabilities of the other events can be computed. For
cause confounding, this is not true for causal-chain confound-      example, in the common-cause confound model the probabil-
ing. However, controlled experiments are not the only way to        ity of E given an intervention in C is formalized by
avoid confounding. Observational studies in combination               (3) P(e|Do c) = P(x) · P(e|x.c) + P(¬x) · P(e|¬x.c).
with other control techniques (e.g., holding constant hypothe-
sized confounds) may also allow us to draw valid causal in-            Contrary to the original factorization (cf. equation (1)), in
ferences. Causal Bayes net theories provide a general frame-        this formula C is no longer conditionalized on X. This formal-
work to model confounds.                                            izes the idea that intervening in C eliminates the dependence
                                                                    on its cause X. Based on the assumption that the confounding
Causal Bayes Net Theories                                           variable X and the cause variable C independently influence
                                                                    the effect variable (modularity assumption) the direct causal
   Causal Bayes net theories (Pearl, 2000; Spirtes, Glymour,
                                                                    impact of C on E can be estimated. We can only provide a
& Scheines, 1993) allow us to model causal structures with
                                                                    rough description of the inference’s logic (for more details
confounding variables. Provided the confounding variable is
                                                                    and formal derivations, see Pearl, 2000). If C is generated by
observable, causal Bayes nets also enable valid inferences
                                                                    an intervention, the probability of the effect is a summary
about the existence and strength of confounded causal rela-
                                                                    effect of the causal impact of the cause variable C and the
tions. Moreover, they allow us to derive predictions for the
                                                                    base rate and causal influence of the confounding variable X.
consequences of interventions in causal models.
                                                                    If C is prevented by an intervention the probability of the
   Causal Bayes nets theory integrates graph theory and prob-
                                                                    effect depends solely on the base rate and the causal impact of
ability calculus. A causal Bayes net consists of a structural
                                                                580

the confounding variable. According to the modularity as-             lay people’s understanding. Whereas previous research has
sumption the causal influence of the cause and the confound-          focused on whether learners consider the influence of alterna-
ing variable are independent of each other. Therefore, the            tive causes (e.g., Spellman, 1996; Waldmann & Hagmayer,
difference of the two interventional probabilities corresponds        2001) or known alternative causal pathways (Meder et al.,
to the direct causal influence of cause C.                            2005), the present experiments go one step further by com-
   The predictions for the causal-chain confound model differ.        bining the task of model identification with different kinds of
Again the conditional probabilities of the effect given an            causal inferences. Learners generally are provided with com-
observation of the cause variable can be directly estimated.          peting causal model hypotheses and then passively observed
What about an intervention on C? As C is the cause of both E          trial-by-trial learning data. In the test phase participants are
and X the dependence of X and C is not eliminated by an               asked about hypothetical observations and interventions in
intervention on C. Therefore, the interventional and observa-         causal situations that contain different kinds of confoundings.
tional probabilities are equal:                                       Thus, our main interest is to investigate whether learners are
   P(e|Do c) = P(e|c) and P(e|Do ¬c) = P(e|¬c)                        capable of making correct inferences about hypothetical situa-
                                                                      tions in scenarios that contain confounds.
Unfortunately, this implies that the direct causal influence of          While Experiment 1 confronted participants with a com-
the cause variable on the effect cannot be estimated on the           mon-cause confounding, Experiment 2 focused on a causal-
basis of the two conditional interventional probabilities.            chain confounding. In both experiments we manipulated the
Given a causal-chain confounding model the difference of the          strength of the target causal relation, which was distorted by a
interventional probabilities represents the sum of the cause          superimposed spurious relation. The target causal relation
variable’s direct causal impact on E and its indirect causal          was in one condition present and in the other absent. In order
influence on E via X. In order to assess only the cause’s di-         to tap onto participants’ understanding we gave them several
rect causal influence the causal relation between the cause           tasks. First, we asked them explicitly to indicate whether
and the confounding variable has to be eliminated by a sec-           there is a direct causal relation between the cause and effect
ond intervention. This aim could be achieved by eliminating           variable. In order to answer this question correctly, partici-
the confounding variable or by blocking the causal pathway            pants have to separate the causal from the spurious relation
connecting the cause and confound. If this is done, the differ-       (in the case of common-cause confounding) or to disentangle
ence of the resulting interventional probabilities again reflects     the direct from the indirect causal influence (in the case of
the cause’s direct causal impact upon the effect.                     causal-chain confounding). Second, we asked participants
   In sum, causal Bayes nets allow us to model various infer-         about the probability of the effect given an observation of the
ences within causal models that contain confounding vari-             absence or presence of the candidate cause. These questions
ables. Necessary prerequisites for these inferences are as-           refer to the summary effect of the direct and indirect causal
sumptions about the underlying causal structure and observa-          pathways. Third, we asked participants about the probability
tional data from which the model’s parameters can be esti-            of the effect given the cause was generated or prevented by an
mated. No experiments are required.                                   intervention in the cause. In case of a common-cause con-
                                                                      founding, the estimated interventional probabilities should
           Causal Learning with Confounds                             differ from the observational probabilities, whereas in the
A number of studies have investigated whether people distin-          case of the causal-chain confounding simple interventions are
guish between observations and interventions. For example,            not able to eliminate confounding. Thus, in this situation the
Gopnik and colleagues (e.g., Gopnik, Glymour, Sobel,                  interventional probabilities should include the confounded
Schulz, Kushnir, & Danks, 2004) showed that even pre-                 causal relation and therefore equal the observational prob-
schoolers grasp the difference between observing and inter-           abilities. To test whether participants are able to extract the
vening, and learn better when they are allowed to intervene in        direct causal relation in this case, we added questions about
a causal system. Sloman and Lagnado (2005) provided evi-              combinations of interventions. We asked participants what
dence that participants understand that events targeted by            would happen if the cause was set by an intervention when
interventions are rendered independent of their actual causes         simultaneously the causal relation to the confounding variable
(‘undoing’). Thus, people seem to understand the causal logic         was blocked by a second intervention. If participants under-
of intervention (i.e., graph surgery). In our own work (Meder,        stand the causal logic of confounding, the estimated prob-
Hagmayer, & Waldmann, 2005; Waldmann & Hagmayer,                      abilities should reflect the direct impact of the cause upon its
2005) we were able to show that participants base their infer-        effect.
ences about hypothetical interventions not only on the struc-
ture of the causal model but also take into account the                                       Experiment 1
model’s parameters which could be estimated from passive              Participants and Design. Participants were 36 psychology
observations. Some of the studies also provided first evidence        undergraduates at the University of Göttingen. The factor
that participants are able to take into account alternative           ‘learning data’ was varied between conditions.
causal pathways in complex models. However, other findings            Task. Experiment 1 investigated participants’ under-standing
cast doubt on the possibility to generalize this finding. For         of common-cause confounding. Participants were told that
example, Luhmann (2005) found that participants tend to               ornithologists recently had discovered a new species of bird.
overestimate how informative confounded data are.                     The biologists hypothesized that in this species singing (C) is
   The two experiments reported in this paper focus more              causally related to reproduction (E). It was pointed out that it
closely on different types of confoundings to further explore         was difficult to assess this direct causal relation because of a
                                                                  581

gene (X), which is known to influence both the birds’ capacity        correct answers to these questions derived from a causal
to sing and their fertility. Participants were then suggested         Bayes net analysis are shown in Table 1 in parentheses. Fi-
two candidate causal models representing either the hypothe-          nally, participants were given a graphical representation of
sis that there is an additional direct causal relation between        the two alternative causal models and requested to select the
singing and breeding (common-cause confound model) or the             correct one.
hypothesis that there is none (common-cause model). Learn-
ers were also shown a graphical representation of the two               Table 1: Mean probability judgments for hypothetical obser-
causal models and were requested to find out which of the                          vations and hypothetical interventions.
two models was correct. This phase was identical for all par-                            Observations                 Interventions
ticipants.                                                                         P(e|c)         P(e|¬c)      P(e|Do c)       P(e|Do ¬c)
Learning Phase. To assess whether there is a direct causal
                                                                                    63.89          22.78         50.00           41.39
relation between birdsong and breeding, learners received 50
index cards depicting observational data from individual                             [58]           [05]          [38]            [38]
birds. Two data sets either implemented a common-cause
model without a direct causal relation between C and E or a                         58.33          14.44         63.06           20.56
common-cause confound model. The two parameterized                                   [84]           [05]          [78]            [40]
models and the resulting patterns of data are shown in Figure          Note. Probabilities derived from Bayes nets are presented in paren-
2. Participants received one of the two data sets and were free        theses.
to explore the data at will and take notes.                           Results. 27 out of 36 participants (75%) chose the correct
         Common-Cause                    Common-Cause                 model. Thus, a majority of participants was able to disentan-
             Model                      Confound Model                gle a causal relation from a spurious relation. Table 1 shows
                                                                      learners’ probability judgments for hypothetical observations
                                                                      and hypothetical interventions. Participants’ judgments for
                                                                      observations reflected the statistical relation between the
                                                                      cause and the effect. In both conditions they rated P(e|c)
                                                                      higher than P(e|¬c). An analysis of variance with ‘data sets’
                                                                      and ‘presence versus absence of C’ as variables only yielded
                                                                      a significant main effect for the presence of C, F(1,34)=63.70,
        Data pattern                     Frequencies
                                                                      p<.001, MSE=510.38. In contrast, learners’ estimates for the
   X         C         E        Common cause        Confound          outcomes of interventions differed. As expected, an analysis
  yes       yes       yes            18                18
                                                                      of variance resulted in a significant interaction, F(1,
  yes       yes       no              1                1              34)=27.95, p<.01, MSE=420.63, which we further analyzed
  yes       no        yes             1                1              by planned comparisons. In the common-cause condition,
  yes       no        no              0                0              only a small, non-significant difference was obtained between
   no       yes       yes             0                8              the interventional probabilities, F(1,17)=1.09, p=.31,
   no       yes       no             12                4
   no       no        yes             0                0
                                                                      MSE=614.42. This result indicates that learners understood
   no       no        no             18                18             that the observed correlation is spurious and that intervening
                                                                      in C will not make E more or less likely to occur. In the
  Figure 2: Parameterized causal models and data sets of 50
                                                                      common-cause confound condition the probability of E being
  cases, each generated from these graphs. Arrows indicate
                                                                      present was judged higher when C was generated, P(e|Do c),
causal relations between variables; conditional probabilities         than when it was prevented, P(e|Do ¬c), F(1,17)=71.67,
            encode the strength of these relations.                   p<.001, MSE=226.84. Thus, participants had detected the
Test Phase. After the learning phase participants were given          direct causal link connecting the cause to its effect.
two blocks of questions referring to hypothetical observations
and hypothetical interventions. The order of blocks was coun-                                   Experiment 2
terbalanced. Participants were allowed to refer back to the           Participants and Design. Participants were 36 psychology
index cards and instructions while answering the questions.           undergraduates at the University of Göttingen. The factor
The observational questions stated that the researchers had           ‘learning data’ was varied between conditions.
captured a new bird and observed that this bird sings [does           Task. While Experiment 1 investigated participants’ under-
not sing]. Based on this observation, learners were asked to          standing of a common-cause confounding, Experiment 2
estimate the probability that this bird would breed (i.e., P(e|c)     focused on a causal-chain confounding (see Fig. 1). We used
and P(e|¬c)). The generative interventional question stated           the same scenario as in Experiment 1. However, now partici-
that the ornithologists had attached a miniature speaker to a         pants were told that ornithologists were investigating whether
bird which imitates birdsong (i.e., Do c). The inhibitory inter-      a specific gene (C) has a direct causal impact upon the birds’
ventional question stated that the biologists had surgically          reproduction (E). As in Experiment 1, participants were in-
modified the bird’s vocal cords, thereby preventing the bird          formed about the presence of a confounding variable. They
from singing (i.e., Do ¬c). Again, participants had to estimate       were told that the gene was known to affect the birds’ ability
the probability that these birds would breed (i.e., estimate the      to sing (X) by a (non-observable) hormone mechanism (H)
interventional probabilities P(e|Do c) and P(e|Do ¬c)). The           which affects the birds’ ability to sing. Moreover, singing (X)
                                                                  582

has, according to the instructions, a causal influence upon          mone production had been deactivated by inhibitory interven-
reproduction (E). Participants were then presented with two          tions (i.e., Do ¬c. Do ¬h). For both questions participants
competing causal hypotheses, a causal-chain model and a              were asked about the probability of procreation (i.e., P(e|Do
causal-chain confound model (Fig. 3). The causal-chain               c. Do ¬h) and P(e|Do ¬c. Do ¬h)). In both cases, participants
model represents the hypothesis that the gene affects repro-         received no information about whether the individual birds
duction only via singing, whereas the causal-chain confound          had the capacity to sing or not. Finally, participants had to
model represents the assumption that the gene has both an            select the correct model from a graphical representation of the
immediate and an indirect causal impact upon reproduction.           two alternative causal models.
                                                                     Results. 31 of the 36 participants (86%) picked the correct
         Causal-chain                     Causal-chain               causal model. Thus, as in Experiment 1 a majority of partici-
            model                       confound model               pants was able to separate the causal relation between C and
                                                                     E from the spurious relation. Table 2 shows the mean prob-
                                                                     ability estimates for the six questions along with the values
                                                                       Table 2: Mean probability judgments for observations, sim-
                                                                           ple interventions, and combinations of interventions
                                                                                                                        Combination of
                                                                                  Observations        Interventions
                                                                                                                          Interventions
                                                                                                                 P(e|  P(e|Do c. P(e|Do ¬c.
          Data pattern                     Frequencies                          P(e|c)   P(e|¬c)   P(e|Do c)
                                                                                                              Do ¬c)    Do ¬h)    Do ¬h)
    X         C          E       Causal-Chain          Confound
                                                                                76.89     16.72     77.08      17.28    29.03       7.83
   yes       yes        yes            29                23
   yes       yes        no              0                 0                      [88]     [06]       [88]       [06]     [06]       [06]
   yes       no         yes             1                 1
   yes       no         no              0                 0                     76.11     8.61      81.11      14.72    62.22      15.28
    no       yes        yes             0                 6                      [88]     [06]       [88]       [06]     [62]       [06]
    no       yes        no              4                 4
    no       no         yes             0                 0           Note. Probabilities derived from Bayes nets are presented in paren-
    no       no         no             16                16           theses.
  Figure 3: Parameterized causal models and data sets of 50          derived from causal Bayes nets. Again participants gave on
                cases generated from these graphs.                   average the same ratings to the observational questions in
                                                                     both conditions and judged the effect to be more likely in the
Learning Phase. As in the first experiment, learners received        presence than in the absence of the observed cause,
50 index cards displaying observational data from individual         F(1,34)=317.25, p<.01, MSE=231.19. Contrary to Experi-
birds. The models used to generate the two sets of data and          ment 1 and consistent with the Bayesian causal analysis par-
the resulting distributions of event patterns are shown in Fig-      ticipants’ estimates for the simple interventional questions did
ure 3. Note that participants were never informed about the          not differ between conditions. An analysis of variance re-
state of H, the mechanism connecting C to X. The causal-             sulted in a significant main effect of ‘presence versus absence
chain data indicated that the observable relation between C          of C’, F(1,34)=250.20, p<.01, MSE=286.42, but no interac-
and E was merely indirect, while the data corresponding to           tion with the given data set (F<1). Participants apparently
the causal-chain confound model pointed to a fairly strong           understood that intervening in C would generate E no matter
direct relation between the gene and reproduction. The un-           whether the underlying causal model was a causal-chain or a
conditional relation between C and E was identical in both           causal-chain confound model. Participants’ answers to the
data sets. As before, participants were free to explore the data     combination questions showed that they differentiated be-
at will.                                                             tween the two models. An analysis of variance yielded the
Test Phase. In this phase participants were given three blocks       expected interaction, F(1,34)=7.80, p<.01, MSE=382.55, but
of questions with the order of blocks being counterbalanced.         also main effects of the variables ‘presence versus absence of
The observational questions asked participants to estimate the       C’, F(1,34)=54.62, p<.01, and ‘data sets’, F(1,34)=9.39,
probability that a new bird possessing the gene [not possess-        p<.01. A closer look at individual ratings revealed that 10 out
ing the gene] would breed (i.e., P(e|c) and P(e|¬c)). The gen-       of the 18 participants in the causal-chain condition judged E
erative interventional question stated that the researchers had      to be equally likely when C was generated or prevented by an
activated the gene of a new bird by means of an intervention         intervention while the causal mechanism linking C to X was
(i.e., Do c). The inhibitory interventional question mentioned       blocked. In contrast, all participants in the causal-chain con-
that the gene was deactivated by an outside intervention (i.e.,      found condition assumed that an intervention in C would
Do ¬c). Again, participants were requested to estimate the           increase the probability of E despite the blocked link. Thus, a
probability that these new birds would breed (i.e., P(e|Do c)        majority of participants seemed to have grasped the causal
and P(e|Do ¬c)). Then, a question referring to a combination         logic of causal-chain confounding.
of interventions was given which requested participants to
assume that researchers had activated the gene of a newly                                        Discussion
caught bird while simultaneously blocking the generation of
the hormone affecting singing (i.e., Do c. Do ¬h). The second            Causal Bayes nets allow us to analyze non-experimental
combination question stated that both the gene and the hor-          data that reflect the impact of confounding variables. As long
                                                                 583

as the confounding variable is observed and not perfectly                                  Acknowledgments
confounded with the target cause, inferences about the causal
                                                                       We thank Momme von Sydow for helpful comments and
impact and the consequences of hypothetical interventions
                                                                       Julia Iwen and Irene Warnecke for collecting the data.
can be derived from observational data. Two basic causal
structures containing confounds can be distinguished: A
common-cause confound model, in which a cause and an
                                                                                                References
effect are directly and spuriously related, and a causal-chain         Doll, R., & Hill, A. B. (1956). Lung cancer and other causes
confound model, in which a cause is directly and indirectly              of death in relation to smoking. A second report on the
affecting its effect. Manipulating the cause by an external              mortality of British doctors. British Medical Journal, 233,
intervention eliminates common-cause confounding but not                 1071-1076.
causal-chain confounding, which requires that the second               Fisher, R. A. (1951). The design of experiments. Edinburgh:
causal pathway is blocked by other means (Pearl, 2000).                  Oliver and Boyd.
     The results of the two experiments show that participants         Fisher, R. A. (1958). Smoking, cancer, and statistics. Centen-
understand the causal logic of these two types of confound-              nial Review, 2, 151-166.
ing. A majority of participants in both experiments was able           Gopnik, A., Glymour, C., Sobel, D. M., Schulz, L. E.,
to disentangle the direct causal relation from the additional            Kushnir, T., & Danks, D. (2004). A theory of causal learn-
spurious relation. How did people achieve this? Previous                 ing in children: Causal maps and Bayes nets. Psychological
research on causal judgments has shown that participants tend            Review, 111, 3-32.
to control for extraneous causal variables when estimating the         Keppel, G., & Wickens, T. D. (2000). Design and analysis.
causal impact of a target variable (e.g., Spellman, 1996;                Upper Saddle River, NJ: Pearson.
Waldmann & Hagmayer, 2001). Confounding variables are                  Luhmann, C. C. (2005). Confounded: Causal inference and
such extraneous variables. Controlling for these variables, for          the requirement of independence. In B.G. Bara, L. Barsalou
example by only considering cases in which they are absent,              & M. Bucciarelli (Eds.) Proceedings of the Twenty-Seventh
enables us to derive correct inferences. Observations of par-            Annual Conference of the Cognitive Science Society (pp.
ticipants’ behavior during the experiment and their written              1355-1360). Mahwah, NJ: Erlbaum
comments indicate that participants used the strategy to focus         Meder, B., Hagmayer, Y., & Waldmann, M. R. (2005). Doing
on the events in which the confound was absent when assess-              after Seeing. In B.G. Bara, L. Barsalou & M. Bucciarelli
ing whether a direct causal relation was present or not.                 (Eds.) Proceedings of the Twenty-Seventh Annual Confer-
     How does our research relate to findings showing that               ence of the Cognitive Science Society (pp. 1461-1466).
people occasionally fail to understand confounding? One                  Mahwah, NJ: Erlbaum
critical factor might be the data that is shown to participants.       Pearl, J. (2000). Causality. Cambridge: Cambridge University
In some studies (e.g., Luhmann, 2005) participants did not               Press.
receive data that allowed them to focus on the absence of the          Sloman, S. A., & Lagnado, D. A. (2005). Do we “do”? Cog-
confounding variable (i.e., holding it constant), which may              nitive Science, 29, 5-39.
explain participants’ failure. But even when participants re-          Spellman, B. A. (1996). Acting as intuitive scientists: Contin-
ceive this information, they may not succeed when the critical           gency judgments are made while controlling for alternative
cases are rare and highly separated from each other (see                 potential causes. Psychological Science, 7, 337-342.
Waldmann & Hagmayer, 2001). Common-cause confounding                   Spirtes, P., Glymour, C., & Scheines, P. (1993). Causation,
may serve as an example: If the common-cause confound has                prediction, and search. New York: Springer-Verlag.
a high base rate and strongly affects the target cause, there          Waldmann, M. R., & Hagmayer, Y. (2001). Estimating causal
will occur only very few cases in which the target cause oc-             strength: The role of structural knowledge and processing
curs in the absence of the confounding variable. In the two              effort. Cognition, 82, 27-58.
experiments reported here we have provided data to partici-            Waldmann, M. R., & Hagmayer, Y. (2005). Seeing versus
pants that contained a relatively large number (>10) of such             doing: Two modes of accessing causal knowledge. Journal
critical cases. In a pilot study (not reported here) we had pre-         of Experimental Psychology: Learning, Memory, and Cog-
sented fewer of these critical observations and participants             nition, 31, 216-227.
consequently had failed to arrive at correct conclusions.
     In summary, people are able to understand the causal ba-
sics of confounding. Whereas previous studies have shown
that people sometimes can separate direct from spurious rela-
tions (e.g., by controlling for co-factors), our results addition-
ally show that learners have the capacity to reason with causal
models containing confounds. Based on trial-by-trial learning
data they were surprisingly good at deriving correct predic-
tions for hypothetical observations and hypothetical interven-
tions, and were capable of separating causal from spurious
relations in these predictions. This remarkable capacity may
fail, however, with more complex models or less salient data.
                                                                   584

