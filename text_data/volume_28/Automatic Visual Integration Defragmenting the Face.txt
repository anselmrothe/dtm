UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Automatic Visual Integration: Defragmenting the Face
Permalink
https://escholarship.org/uc/item/48f0j9w5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Barrington, Luke
Cottrell, Garrison W.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                          Automatic Visual Integration: Defragmenting the Face
                                             Luke Barrington (lbarrington@ucsd.edu)
                     Electrical & Computer Engineering Department, University of California, San Diego
                                                          La Jolla, CA 92093 USA
                                             Garrison W. Cottrell (gary@cs.ucsd.edu)
                      Computer Science & Engineering Department, University of California, San Diego
                                                          La Jolla, CA 92093 USA
                              Abstract                                  visual memory. Since snapshots of the environment are
                                                                        unlikely to be repeated, a straightforward template matching
  We describe a computational model of saccadic visual                  procedure is unlikely to work. For a simple task like face
  memory applied to the task of facial recall. Each saccade             recognition, it is therefore important that there be a
  provides a mixed-resolution, quasi-stationary snapshot of a
                                                                        matching procedure that probabilistically assesses how well
  visual scene to the striate cortical areas yet the brain recreates
  spatially and temporally smooth perceptions and memories by           samples drawn from the current environment could have
  combining these visual fragments. We build on the work of             been generated by previous observations. Here we describe
  (Lacroix et al., 2006) to model this integration of saccades in       how the model developed by Lacroix et al. (2006) can be
  a facial recall task by selecting fixation points based on low-       viewed as a kernel density estimate of the likelihood that
  level saliency of a face image. At each fixation point, this          new visual patches of faces were generated by our memory.
  model stores discrete visual samples with multiple resolutions        We then show how we can use the same model for face
  as activation patterns without knowledge of their temporal or         identification. Finally, we explore the issue of the scale-
  spatial origin to create a kernel density estimate of the studied     space representation used and show how different spatial
  faces. These visual fragments are then integrated and
                                                                        frequencies affect the matching process.
  compared to new fixations during recall. We replicate
  Lacroix’s results by demonstrating that the model achieves
  human levels of performance on the standard psychological             We begin by presenting an improvement to the model of
  memory test of facial recall. We then extend the model to             (Lacroix et al., 2006) that uses a saccade selection routine
  facial identity recognition and examine the task-dependent            that uses the same filters that are used for the memory
  effects of visual resolution.                                         representation. In Experiment 1, we demonstrate that this
                                                                        model can solve the challenge of visual integration by
                      Visual Integration                                modeling the facial recall task. Experiment 2 extends the
Visual perception begins with retinal sampling information              model to perform a new task; recognition of facial identity.
of localized areas of a scene before our eyes. These                    Finally, Experiment 3 examines the effect of allowing the
saccades are discrete in space and time. High-resolution                model to process Gabor filter bands separately and indicates
visual information is only available from the fovea,                    a potential method for task-based control of visual attention.
covering only a small portion of the observed scene. In
order to perceive all parts of a visual scene with great detail                          Visual Memory Model
as well as to maintain neural activation in the visual cortex,
we repeatedly foveate different areas of the scene, spending            Saccade Selection
the most time fixating on the parts that are most salient or            Given a current fixation point, the choice of where to
most task-relevant (Yarbus 1967).                                       saccade to next is driven by a number of external cues
                                                                        including motion, peripheral complexity and non-visual
It seems reasonable to suppose that the sequences of                    stimuli (e.g. sound) as well as top down task-dependant
saccades or scan paths that collect the visual data do not, in          directives such as attention and expectation. Though many
general, follow exactly the same path and thus can not                  methods (Mozer, Shettel & Vecera 2005; Wolfe, 1994;
reconstruct the exact sequence of stored visual memories                Zelinsky et. al 2005) have been proposed for how to
when examining a previously-viewed object (although the                 integrate these cues, in this work we concentrate only on
distribution of saccades tends to be similar, see Henderson,            bottom-up salience of static images. We model the saccade
Williams, & Falk, 2005). Yet we can mentally comprehend                 selection process using an interest operator for determining
and recreate spatially and temporally complex constructs                the scan paths introduced in (Yamada & Cottrell, 1995).
using only a combination of these static, non-uniform retinal           This simplified model uses the rotational variance of low-
samples stored in memory. How is this discrete information              resolution Gabor filter responses to construct a distribution
integrated into a continuous, dynamic construct?                        of the contour complexity (read: salience) over all pixels in
                                                                        a given image:
The solution to this visual jigsaw puzzle must come from
the way that retinal frames are stored in and retrieved from
                                                                     48

                                                       2
                             8
                                         πn       
                           ∑    G i, j ,  − µ G 
                                           8 
        Salience (i, j ) = n=1                      
                                           8
where G(i, j, θ ) is the response of a Gabor filter with
orientation θ, centered at pixel (i, j) and µG is the mean
response across all orientations. A similar technique
developed by (Renninger et al, 2004) uses entropy rather
than variance of local image contours to define salience.
We convert this salience map into a probability distribution
by normalizing with the softmax function (Bishop, 1995).
A fixation point is then chosen randomly, according to this
distribution. We relax the salience around the fixated point          Figure 1(a): An image from the FERET database.
by subtracting a univariate Gaussian, centered at the point       Figure 1(b): The corresponding salience map generated
from the salience distribution and renormalizing. This           using the technique of (Yamada & Cottrell, 1997) with a
inhibits repeated fixations at the same location. Figure 1       sample distribution of ten fixation points. Fixations tend
shows a salience map generated in this manner as well as a         to cluster around highly salient areas but relaxation of
sample distribution of fixation points.                           sampled points enforces an even distribution across the
                                                                                             image.
This purely bottom-up model is simple but the resulting
scan paths for face recognition task qualitatively               The highest spatial-frequency filter responses correspond to
approximate those observed in humans (Yamada & Cottrell,         the high-resolution foveated area around the fixation point.
1995). The model satisfies 3 of the 5 criteria identified by     The responses of the low-frequency filters are each
(Itti & Koch, 2001) for a computational model of visual          computed from an area surrounding the fixated pixel that
attention: it derives perceptual saliency of a fixation point    has spatial context greater than that of the foveated patch
from the surrounding context, it creates a salience              and thus provide extra-foveal information, corresponding to
distribution over the visual scene and it inhibits return to     the low-resolution data from the retinal periphery. By
previously attended locations. We ignore the other 2 criteria    extracting just a square patch from these Gabor response
that concern the top-down influence of attention and object      images, we are in fact producing a foveated representation
recognition on fixation point selection. Future work intends     of the fixated point.
to augment this model by extending the results of (Nelson &
Cottrell, 2005) to use top-down feedback to direct the           The size of the stored patch of filter responses and the
selection of eye-movements by examining which queries            number of patches that the model may examine for each
(i.e. eye movements) would be most useful in enhancing           image are experimental parameters that correspond, in
performance of the current visual task.                          human vision, to the distance of the eye from the image (and
                                                                 thus the size of the foveated area) and the time spent
Retinal / Cortical Image Transform                               studying the image (determining the number of saccades
Once it has been fixated, an input image undergoes many          made).      For a fixation patch size of 35x35 pixels
stages of neural processing before being stored as a pattern     (corresponding to a visual angle of 1.5° for a subject about
of activation in high-level visual cortex. In all experiments    75cm from a 96 dpi computer monitor: an approximation of
below, we use as input 128x192 pixel grayscale image from        the conditions for human studies discussed below), the input
the FERET database of (Phillips et. al 1998). Male and           feature vector to our model has;
female Caucasian faces without facial hair or glasses were
chosen and the images were centered and normalized to            35 x 35 x 8 orientations x 4 frequencies = 39200 dimensions
have common eye positions and equal contrast.
                                                                 In order that the memory be able to generalize to recognize
Gabor filter responses at 8 orientations and 4 frequencies       familiar faces under new conditions where different fixation
form our biologically-motivated, V1 processing model             points may be chosen and also so that it has the capacity to
(Jones & Palmer, 1987). We transform an image into the           remember a large number of faces, the dimensionality of the
Gabor-filtered domain by calculating the response of each        input features is reduced while maintaining the majority of
filter at every image pixel. In these experiments, we use        their representational ability by using principal component
Gabor filter frequencies of 1/4, 1/8, 1/12 and 1/16              analysis. This is analogous to the concise encoding of the
cycles/radian.                                                   over-complete retinal and V1 data in higher levels of visual
                                                                 cortex. This feature extraction procedure of wavelet-based
                                                                 image decomposition followed by PCA is a standard
                                                              49

approximation for biologically motivated vision models            model which controls required distinctiveness for an input
(Dailey et al., 2002; Palmeri & Gauthier, 2004; Lacroix et        fragments, that is the strictness required for it to be judged a
al., 2006)                                                        match. The familiarity, Fi, of an image i, is defined as the
                                                                  average number of memories matching each of the S fixated
We chose to retain just the first 80 principal components in      samples taken from the image;
order to make the model tractable as well as biologically
feasible while still accounting for 87% of the variance in the                 1 S
feature data when processing all frequency bands together.               Fi =     ∑ nif
                                                                               S f =1
                                                                                                ∀ fragments, f ∈ image, i
Experiment 3 will present an alternative treatment where we
do individual PCA decompositions on each of the 4
frequency bands.                                                  As outlined in Bishop (1995), this is an (un-normalized)
                                                                  kernel density estimate of the probability that the new face
Memory storage and retrieval                                      was generated by the memory. For a subject to decide
Given the natural input patterns of activation or image           whether the image is familiar or not, they must threshold
fragments described above, the role of the brain is to            this probability. To visually assess the hypothesis that
analyze them and retrieve similar or related patterns. The        proximity in the memory vector space corresponds to
nature of this analysis and the methods of storage and recall     similarity in the world, figure 2(c) shows the distance from
are the focus of our modeling work.                               a fragment taken from the image in figure 2(a) to all other
                                                                  possible fragments from that image while figure 2(d) shows
The memory model used is based on the Natural Input               the distance from the same fragment to all possible
Memory from (Lacroix et. al, 2006). The “memory” in this          fragments from a different image, shown in figure 2(b).
case is a high-dimensional vector space and “memories” are        Given the strong peak in similarity around the fixation
vectors in this space. Given an input vector derived from an      point, it can be seen that fragments that are close to the
image as described above, the memory storage process is           memorized fragment match very well. Moving away from
simply to assign this vector to the memory space. This            this point, similarity drops off quickly so that even
approach of conceiving of memories as patterns of neural          fragments from similar locations on the unfamiliar image do
activation in a sparse vector space has been successfully         not respond strongly.
applied in many domains of cognitive modeling such as
(Nosofsky & Palmeri, 1997 - response-time modeling; Sagi
et al., 2002 - speech processing and Dollar et al., 2004 -
video behavior analysis), among others.
The retrieval process is instigated when a new sample is
input to the system. The patterns of activation of this novel
input are compared to all the stored instances in the memory
vector space. As with the models in (Lacroix et. al, 2006;
Nosofsky & Palmeri, 1997), proximity in this space is
designed to relate to similarity in the perceived world.
Multi-dimensional patterns can now be compared for
similarity using simple vector-based methods such as
Euclidean distance, suitable for comparing integral-
dimension stimuli.
There is no guarantee that the fixation points chosen in the
testing phase by our stochastic interest operator will exactly
match those used in training; scan paths are not repeatable
(Henderson, Williams, & Falk, 2005). Therefore (as with
human vision), fixated samples will rarely be a perfect
match for anything stored in memory and we must instead
use a more tolerant metric. In order to judge the familiarity
of an input pattern, the model uses a form of kernel density
estimation (Bishop, 1995) a technique that has been applied         Figure 2: A target and lure image and their similarity
by (Lacroix et al, 2006; Dailey, Cottrell & Busey, 1999) for       maps. Figure 2(c) compares distances from the outlined
facial memory modeling. For each M-dimensional fragment             patch of the face in figure 2(a) to all possible patches
input to the system, we count the number of stored                  from the same image. Figure 2(d) compares the same
memories, nf, that lie within an M-dimensional volume of          patch to all possible patches from the face in figure 2(b).
radius r, centered on that input. r is a free parameter of the
                                                               50

               Experiment 1 – Facial Recall                                                               3.5
To confirm that our modifications of Lacroix’s model still
                                                                                                           3
perform tasks similar to those she performed with it, we
applied it to a face recognition experiment. In this paradigm                                             2.5
the subject studies a sequence of N briefly presented faces.
                                                                                       Detecability, d'
                                                                                                           2
In the test phase, a second list of faces is shown where
(typically) half are from the original studied list (targets)                                             1.5
and half are unfamiliar distracters (lures). The goal is to test                                           1
the subject’s ability to recognize the studied faces (hits)
without classifying the lures as familiar (false alarms).                                                 0.5
                                                                                                           0
In order to quantify the relationship between hits and false                                                      Hum an        10          20          30          40
                                                                                                                  Res ults   s am ples   s am ples   s am ples   s am ples
alarms, we look to signal detection theory and the
detectability index, d’ which compares the normalized
familiarity scores for the target and lure images (Kay,                             Figure 3: Recall performance for humans as reported by
1998);                                                                                   (Lewis & Johnston, 1997) and for our model
                                 µF − µF                                                                        Experiment 2 - Identity recognition
                          d'=       T             L
                                                                                    The second memory task we tested our model on was
                                  σ F2 + σ F2
                                        T             L                             identity recognition. In order to frame the task in the same
                                            2                                       terms as Experiment 1, we again present the model with a
                                                                                    set of images for study and then examine its performance on
        µF            σ        ( µ FL and       σ F2
                          2
where           and       FT                          L
                                                          ) are the mean and        a set of test images. In this paradigm, we can evaluate
           T
variance of the familiarity scores for images from the target                       performance with the same familiarity and d’ metrics as
(lure) list. All results are the average of 10 trials.                              before. Here the study list is comprised of 6 different
                                                                                    images of the same person (with changes in lighting and
To compare our model’s performance with the results from                            expression). Given a test list of 39 images containing 3
human subjects, we examine the psychological data from                              novel images of the studied face (the targets) as well as 9
(Lewis & Johnston, 1997). Note that in this experiment,                             different images of 4 other identities (the lures), the task
subjects viewed ¾ profile faces whereas in our experiments,                         now is to discriminate this original identity from the
we use frontal views. Other human studies testing frontal                           unfamiliar faces. For each image, we allow the model to
views such as (Hancock, Burton & Bruce, 1996; O’Toole et                            make 20 fixations.
al., 1994) used far larger test lists (174 faces) albeit with
unconstrained study times and had correspondingly lower d’                          This task introduces an extra challenge for the kernel
scores (average 1.37). The results of (Lewis and Johnston,                          density estimate model in that it must now generalize to
1997) do give us a baseline comparison level for human                              recognize images that it has never seen before. While the
performance in a facial recall task. In their work, the study                       stochastic nature of the saccade selection model made it
list had N = 20 images, each displayed for 5–10 seconds.                            unlikely that same fragment would be examined in study
Allowing for approximately 4 saccades per second, we                                and test in the recall task, this is impossible now. This
allow our model to take 10–40 samples from the studied                              further tests the capabilities of the kernel density method of
images. For each saccade, we sample 35x35 patches from                              memory modeling by requiring the model to integrate
the Gabor-filtered responses of the studied 128x192 pixel                           fragments from multiple images to form an estimate of the
grayscale image from the FERET database. We then test on                            identity and to compare this density estimate to a
40 images, including the 20 from the study set. Results are                         completely unfamiliar set of fragments.
shown in Figure 3. These data replicate the human-like
performance of the model found by (Lacroix et. al, 2006).                           Figure 4 demonstrates that the model performs successfully
These results make the intuitive prediction that as more                            on the identification task. The d’ scores of around 2
samples are taken from the study and test lists                                     indicate human-like performance. As expected, overall
(corresponding to longer viewing time by the human                                  recognition performance was somewhat worse than for the
subjects), recall performance improves.                                             simple recall task (compare the results for this experiment in
                                                                                    Figure 4 to the middle bar of Figure 3). Again, reported
                                                                                    results are the average of 10 repeated trials where, in each
                                                                                    trial, variability arises from the fact that a different sample
                                                                                    of saccades is taken from salience distribution and thus a
                                                                                    different set of fragments are stored and analyzed for the
                                                                                    study and test images.
                                                                               51

                       2.5                                             capacity to features that are less useful for the memory
                                                                       task1.
                        2
                                                                                  Table 1: Variance of Gabor filter bands.
   Detectability, d’
                       1.5
                                                                         Gabor Filter           Kernel         Variance Accounted for
                                                                       Spatial Frequency       Radius (r)     by PCA to 20 Dimensions
                        1
                                                                            0.0625                1.5                  90.3%
                                                                            0.0883               1.05                  86.5%
                       0.5
                                                                             0.125                0.6                  76.1%
                                                                             0.25                0.15                  61.3%
                        0
                             1   2      3       4     5
                                     Identity
                                                                       Rather than coalesce all frequency bands into one feature
                                                                       vector, we have extended our model to process each band
                                                                       individually and calculate detectability based on average
   Figure 4: ID Performance (20 fragments per image,                   familiarity values. In this way, fragments which are
                      radius = 1.5)                                    ambiguously familiar at one scale (Fi,scale a ≈ 0) but distinct
                                                                       at another (Fi,scale b > 0) can still be recalled.
  Experiment 3 - Multi-resolution processing
                                                                       The interesting result is that the effect of the 4 frequency
Combining resolutions                                                  bands in the identity task is different from the recall task.
                                                                       Figure 5 shows the detectability score for both tasks using
The results presented above and in (Lacroix et. al, 2006) as
                                                                       just one frequency band (with 20 principal component
well as many of previous models from our lab. (Dailey et.
                                                                       features stored for each example). We see that, for recall,
al, 2002) consider each level of resolution together by
                                                                       the lowest frequency was the most significant in detecting
concatenating them into a single feature vector. Though it
                                                                       familiar faces, with a gradual fall off as the resolution is
is the most straightforward method for processing image
                                                                       increased. Identity recognition relies more on the
data, this approach disregards the fact that the scale most
                                                                       intermediate-low frequency (though the low is also
appropriate for a given visual object recognition task can
                                                                       important) but receives very little useful information from
vary greatly, depending on both the object and the task. As
                                                                       the highest frequency band. This makes the intuitive
an example, low-resolution, peripheral vision might be
                                                                       prediction that, for identifying familiar objects under novel
enough to tell you that there is a page of text in front of you
                                                                       conditions, excessive detail is in fact distracting.
but would be useless for discerning the individual letters
printed there.     On the other hand, the fine-detailed
                                                                       A second result that springs from our multi-resolution
discrepancies between a friend’s face from one year to the
                                                                       analysis is that the distance between fragments (and
next would not prevent you from recognizing her. Thus, it
                                                                       therefore radius parameter of the kernel, inside of which
seems necessary to allow a memory model to have control
                                                                       they will be classified as familiar) changes with scales. This
over how it uses information of varying resolution, rather
                                                                       is illustrated in the center column of Table 1. These radii
than forcing it to consider all scales as equal.
                                                                       are roughly inversely proportional to the frequencies they
Implementation of this idea can provide insight into how
                                                                       correspond to (we found setting the high-frequency radii
multi-resolution data is combined in visual recognition tasks
                                                                       even lower improved results). This demonstrates that the
and gives clues about how to apply task-based (top-down)
                                                                       criterion for successful fragment matches, distinctiveness, is
controls on attention.
                                                                       coarser at low spatial frequencies due to the imprecise
                                                                       nature and low variability of these features than those
We examined methods for improving our model by
                                                                       required for features from higher frequency bands and adds
allowing it to process each frequency band separately. The
                                                                       weight to the argument for treating bands individually.
first observation is that the variance in the feature data is
proportional to the frequency of the filter as shown in Table
1. While this may not be surprising of itself (higher
frequency filters capture more rapidly varying data), it
makes a strong argument for treating each frequency band
individually. PCA allocates components in directions where
the data has most variance, in this case, the high frequency
bands. However, as shown in Figure 5, these are not the
most useful bands for recall tasks. Therefore, treating all            1
bands as equal and using a single PCA transform to                       We should note here that in previous models from our lab, the
represent them all will allocate more representational                 filter responses are whitened on a per-filter basis, so all bands have
                                                                       the same energy, and PCA only collects covariances.
                                                                  52

                           2
                                                                                                   Dollar, P., Rabaud, V., Cottrell, G. & Belongie, S. (2005)
                                                                             Identification
                                                                                                       Behavior recognition via sparse spatio-temporal features.
                          1.8
                                                                             Recall                    Proceedings Joint IEEE Workshop on Visual Surveillance &
                          1.6
                                                                                                       Performance Evaluation of Tracking & Surveillance.
                          1.4                                                                      Hancock, P.J.B., Burton A.M. & Bruce, V. (1996) Face
                                                                                                       processing: human perception and principal components
      Detectability, d'
                          1.2
                           1                                                                           analysis. Memory & Cognition, 24, 26-40.
                          0.8
                                                                                                   Henderson, J.M., & Williams, C.C. & Falk, R.J. (2005). Eye
                                                                                                       movements are functional during face learning. Memory &
                          0.6
                                                                                                       Cognition, 33, 98-106.
                          0.4
                                                                                                   Itti, L. & Koch, C. (2001) Computational Modeling of Visual
                          0.2                                                                         Attention. Nature Reviews Neuroscience, 2, No. 3, 194-203.
                           0                                                                       Jones, J.P. & Palmer, L.A. (1987). An evaluation of the two-
                                0.0625         0.0833            0.125         0.25                   dimensional Gabor filter model of simple receptive fields in cat
                                            Gabor Filter Spatial Frequency
                                                                                                      striate cortex. Journal of Neurophysiology, 58(6) 1233-1258.
                                                                                                   Kay, S.M. (1998) Fundamentals of Statistical Signal Processing,
                                                                                                      Vol 2: Detection Theory.
Figure 5: Per-band detectability for recall and identification                                     Lacroix, J.P.W., Murre, J.M.J., Postma E.O., & Van den Herik H.J.
     tasks, from low to high frequency (left to right).                                               (2006). Modeling recognition memory using the similarity
                                                                                                      structure of natural input. Cognitive Science, 30, 121-145.
                                            Discussion                                             Lewis, M.B. & Johnston, R.A. (1997). Familiarity, target set and
We have introduced an extension of the facial recall                                                  false positives in face recognition. European Journal of
memory model of (Lacroix et. al, 2006) and shown how it                                               Cognitive Psychology, 9, 437-459.
                                                                                                   Mozer, M.C., Shettel M. & Vecera S. (2005) Top-Down
can also be applied successfully to the task of identity
                                                                                                       Control of Visual Attention- a Rational Account. Neural
recognition. Using inspiration from neurobiology, this                                                 Information Processing Systems 2005.
model is able to integrate a non-uniform sampling of a                                             Nelson, J.D. & Cottrell, G.W. (2005) A probabilistic model of
visual scene, potentially containing much novelty and                                                  eye movements in concept formation. Neurocomputing
without explicit knowledge of the spatial or temporal                                              Nosofsky, R.M. & Palmeri, T.J. (1997). An exemplar-based
ordering of the samples it achieves human-levels of memory                                            random walk model of speeded classification. Psychological
performance. This discrete sampling, concentrating on the                                             Review, 104, 2, 266-300.
salient parts of images could be the genesis for bottom-up,                                        O’Toole, A.J., Defffenbacher, K.a., Valentin, D. & Abdi, H.
parts-based object representations where extracted                                                    (1994) Structural aspects of face recognition and the other race
fragments are stored, grouped and recalled according to                                               effect. Memory & Cognition, 22, 208-224
                                                                                                   Palmeri, T.J. & Gauthier, I. (2004). Visual object understanding.
their locations in our memory vector space.
                                                                                                      Nature Reviews Neuroscience, 5, 291-303.
                                                                                                   Phillips, J., Wechsler, H., Huang, J., & Rauss, P.J. (1998). The
By examining visual fragments at multiple scales, we have                                             FERET database and evaluation procedure for face-recognition
also demonstrated a possible method for implementing top-                                             algorithms. Image & Vision Computing, 16, 5, 295-306.
down, task-specific controls on familiarity. We have shown                                         Renninger, L.W., Coughlan, J., Verghese, P. & Malik, J. (2004).
that the constraints imposed by fragment matches at one                                               An information maximization model of eye movements.
scale could be used to set expectations for matches at others                                         Proceedings Neural Information Processing Systems 2004.
dynamically. Our future work plans to incorporate these                                            Sagi, B., Nemat-Nasser, S.C., Kerr, R., Hayek, R., Downing, C. &
insights by developing a model that can learn task- and                                               Hecht-Nielsen, R. (2001). A biologically motivated solution to
                                                                                                      the cocktail party problem. Neural Computation, 13, 7, 1575-
scale-specific match thresholds, corresponding to the
                                                                                                      1602
versatile development of task-dependant perceptual                                                 Seiple, W., Holopigian, K., Szlyk, J.P., & Wu, C. (2004)
expertise in humans.                                                                                  Multidimensional visual field maps: Relationships among local
                                                                                                      psychophysical and local electrophysiological measures.
                                         Acknowledgments                                              Journal of Rehabilitation Research and Development, 41 (3a),
This research project was supported by NIMH grant                                                     359–372
                                                                                                   Wolfe, J.M. (1994) Guided Search 2.0: A Revised Model of
MH57075 to GWC.
                                                                                                       Visual Search. Psychonomic Bulletin & Review, 1, 2, 202-
                                                                                                       238
                                            References                                             Yamada, K. & Cottrell, G.W. (1995). A model of scan paths
Bishop, C. (1995) Neural networks for Pattern Recognition.                                            applied to face recognition. Proceedings of the 17th Annual
  Oxford University Press.                                                                            Cognitive Science Conference 55-60.
Dailey, M.N., Cottrell, G.W. & Busey, T.A. (1998) Facial Memory                                    Yarbus, A.L. (1967). Eye Movements and Vision. Plenum Press,
  is Kernel Density Estimation (almost). Proceedings Neural                                           New York.
  Information Processing Systems.                                                                  Zelinsky, G.J., Zhang, W., Yu, B., Chen, X., Samaras, D. (2005)
Dailey, M.N., Cottrell, G.W., Padgett, C. & Adolphs, R. (2002)                                        The role of top-down and bottom-up processes in guiding eye
  EMPATH: a neural network that categorizes facial expressions.                                       movements during visual search. Neural Information Processing
  Journal of Cognitive Neuroscience. 14, 1158-1173.                                                   Systems 2005.
                                                                                              53

