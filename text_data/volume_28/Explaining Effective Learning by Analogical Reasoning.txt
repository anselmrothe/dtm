UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Explaining Effective Learning by Analogical Reasoning
Permalink
https://escholarship.org/uc/item/0651k8dm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Gust, Helmar
Kuhnberger, Kai-Uwe
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                          Explaining Effective Learning by Analogical Reasoning
                                                      Helmar Gust (hgust@uos.de)
                                         Institute of Cognitive Science, University of Osnabrück
                                                Albrechtstr. 28, 49076 Osnabrück, Germany
                                             Kai-Uwe Kühnberger (kkuehnbe@uos.de)
                                         Institute of Cognitive Science, University of Osnabrück
                                                Albrechtstr. 28, 49076 Osnabrück, Germany
                               Abstract                                    Both classes of learning strategies are based on a common
                                                                        idea: As input data a (more or less) large number of exam-
    Machine learning algorithms are usually considered as explicit      ples is needed to guarantee a successful learning procedure.
    learning strategies requiring large data samples. Contrary          Based on these examples the corresponding learning algo-
    to these accounts, cognitive learning seems to be based on          rithms can establish generalized hypotheses. Although the
    significantly less amounts of training data and occurs often
    in the form of implicit learning. In order to close this gap we     mentioned techniques are reasonable accounts from an engi-
    propose to explain these discrepancies by a form of analogical      neering perspective, cognitive adequacy cannot be achieved
    learning, bridging these two traditions. Using heuristic-driven     by these learning concepts:
    theory projection (HDTP) as the framework for analogy
    making we can productively model learning aspects with              • The available data samples for successful human learning
    sparse training data.                                                  are in general rather limited, as can be seen in language
                                                                           acquisition, learning of new concepts, or perception. The
    Keywords: Analogical Reasoning, Learning, Creativity.                  mentioned machine learning accounts usually fail in learn-
                                                                           ing effectively from sparse data samples.
                           Introduction                                 • Human learning abilities are embedded in and crucially
                                                                           connected to a context, for example, coordinated with a
In cognitive science, cognitive modeling, and artificial intelli-          particular perception or a motor action. Learning occurs
gence, a large number of different learning theories were pro-             often implicitly in these context, i.e. as a side-effect of
posed. Considering learning mechanisms from a computer                     problem solving. In contrast to human learning, machine
science perspective, two major types of learning theories can              learning accounts are often based on explicit learning ac-
be roughly distinguished:                                                  counts and usually abstract from the situational context.
• On the one hand, lazy learning algorithms have been pro-              • The ability of humans to learn new concepts cannot be un-
    posed, i.e. learning theories which store each exemplar (or            derestimated as one of the most important cognitive capac-
    example) explicitly in a database without identifying ab-              ities. In contrast, machine learning algorithms are rather
    stract features.                                                       limited concerning their productivity in generating new
                                                                           concepts.
• On the other hand, eager learning algorithms have been ex-
    tensively discussed, i.e. learning theories which minimize             Considering this situation from a cognitive science per-
    the storage load by an abstraction process. The identifica-         spective, other learning models need to be developed, in order
    tion of important (common) features of the exemplars is a           to take the mentioned points into account. We will propose to
    necessary prerequisite for this type of learning algorithm.         use analogical reasoning as a possibility to partially bridge
                                                                        this gap between machine learning accounts and cognitive
    Lazy learning occurs in a variety of different versions: It         learning. The paper has the following structure: First, we
is also called instance-based learning (Aha, Kibler & Albert,           will roughly discuss some aspects of learning and cognition.
1991), exemplar-based learning (Salzberg, 1991), case-based             We will continue by presenting the crucial ideas of heuristic-
learning (Kolodner, 1993), or memory-based learning (Stan-              driven theory projection (HDTP) as a model for analogy mak-
fill & Waltz, 1986). Eager learning is a collection of learn-           ing. After sketching a simple example, we will discuss how a
ing algorithms that abstracts from the sample data like in              learning theory based on analogies can be developed.
ID3 (Quinlan, 1986), version space (Mitchell, 1982), induc-
tive learning (Muggleton & Feng, 1990), connectionist-style                              Learning and Cognition
learning algorithms (Bishop, 1995), or explorative learning              The algorithms mentioned in the introduction have a com-
(Watkins & Dayan, 1992). The proposed learning paradigms                 mon feature: Large data samples are usually necessary for
were applied to a variety of different domains: Examples are             successful learning. Dependent on the particular learning al-
perception, and motor control in artificial agents, induction of         gorithm the size of the necessary training data sample may
grammars in natural language processing, expert systems, or              vary. In the case of learning by neural networks, a larger data
categorization. The different accounts have been proven to be            sample is usually needed than in applications where case-
successfully applicable to many domains of interest.                     based reasoning techniques are applied. On the other hand,
                                                                    1417

neural networks may perform better in some domains than                  for example, in the IT world: Concepts like (computer)
case-based reasoning. Nevertheless the required data of both             mouse, daemon, virus, or backbone are metaphors that can
accounts exceeds by far corresponding learning data for cog-             be explained by establishing a metaphorical relation (Gust,
nitive agents like humans.                                               Kühnberger & Schmid, 2006a).
   In many cases, cognitive learning seems to work differ-
ently in comparison to the proposed learning approaches: The         • Learning of abstract concepts: Learning in high schools
Chomsky - Skinner debate can be seen as a prominent exam-                and universities as well as insights of scientists in research
ple focusing on this gap (Chomsky, 1959). In order to explain            projects are strongly based on a concept interpretation “as
the human ability to learn natural language, Chomsky’s con-              if it were” a well-known concept. To a large extent this can
clusion was that a universal grammar must be presupposed.                be explained by an analogical transfer.
Researchers from the psychological field put a certain empha-            In the following section, we will sketch the ideas of a math-
size on imitation, projecting the behavior of others to oneself,     ematically sound theory that can be used for establishing ana-
like in observational learning (Bandura & Walters, 1963), or         logical transfers. We propose a model for analogical reason-
stressed the influence of situations, like in situated learning      ing where no large numbers of examples are needed. Rather
(Lave & Wenger, 1990). Unfortunately no convincing ma-               it is the case that analogical learning occurs as a side-effect by
chine learning approach realizing these psychologically mo-          the process of generating generalizations, i.e. learning is an
tivated theories in a computer is available yet.                     implicit feature of the system. Furthermore learning occurs in
   We propose to bridge the gap between machine learning             stepwise processes, where generating generalizations is only
on the one hand and the rather effective learning strategies         one part among others. An equally important part of ana-
of cognitive agents on the other hand by analogical reason-          logical learning concerns the transfer of knowledge from the
ing. Analogical reasoning was discussed in domains like              source to the target governed by a testing procedure (experi-
proportional analogies in string domains (Hofstadter & The           ment) that either accepts or rejects certain transfers. Last but
Fluid Analogies Research Group, 1995) and analogies be-              not least, even dynamic updates of the source domain may be
tween geometric figures (Dastani, 1998; Evans, 1968). Fur-           possible in case the analogical relation cannot be established
ther discussions were based on the relation between analo-           using the given input data.
gies and metaphors (Indurkhya, 1992; Gentner et al., 2001)
and on analogical problem solving (Anderson & Thompson,                         Heuristic-Driven Theory Projection
1989). Methods used for modeling analogies range from
algebraic accounts (Dastani, Scha & Indurkhya, 1997; In-              The Idea of HDTP
durkhya, 1992) to graph-based approaches (Gentner, 1983;              Heuristic-Driven Theory Projection (HDTP) is a formally
Falkenhainer, Forbus & Gentner, 1989) and similarity-based            sound theory for computing analogical relations between a
approaches (Gentner, 1989). Although the mentioned models             source domain and a target domain. HDTP computes ana-
for analogical reasoning differ quite significantly from each         logical relations not only by associating concepts, relations,
other in some aspects certain other aspects issues seem to be         and objects, but also complex rules and facts between target
uncontroversial: Analogical relations between a well-known            and source domain. In Gust, Kühnberger & Schmid (2006b)
domain (source domain) and a formerly unknown domain                  the syntactic, semantic, and algorithmic properties of HDTP
(target domain) can be established without taking much input          are specified. Unlike to well-known accounts for modeling
data into account. Rather it is the case that a conceptualiza-        analogies like the structure-mapping engine (Falkenhainer,
tion of the source domain is sufficient to productively gener-        Forbus & Gentner, 1989) or Copycat (Hofstadter & The Fluid
ate knowledge about the target domain. This can be achieved           Analogies Group, 1995), HDTP produces abstract descrip-
by associations of attributes and relations of the source do-         tions of the underlying domains, is heuristic-driven, i.e. al-
main and the target domain. Moreover, a projection of at-             lows to include various types of background knowledge, and
tributes and relations from source to target can productively         has a model theoretic semantics induced by an algorithm.
introduce new concepts on the target domain. The result is            HDTP was applied to a variety of domains, for example,
that cognitive agents can learn a new conceptualization of the        naive physics (Schmid, Gust, Kühnberger & Burghardt, 2003;
target domain without perceiving a huge number of examples.           Gust, Kühnberger & Schmid, 2003a) and metaphors (Gust,
   We mention some domains where we think analogical rea-             Kühnberger & Schmid, 2006a). The algorithm HDTP-A is
soning can be used, in order to explain learning aspects of           implemented in SWI-Prolog. The core program is available
human cognition:                                                      online (Gust, Kühnberger & Schmid, 2003b).
                                                                         Syntactically, HDTP is defined on the basis of a many-
• Learning how to use new software: If a human knows how              sorted first-order language. First-order logic is used in or-
   to use a text-processing software like MS-Word, she can            der to guarantee the necessary expressive power of the ac-
   easily adapt to a new software like the text processing tool       count. An important assumption is that analogical reasoning
   of Open Office, although the menu and the overall struc-           crucially contains a generalization (or abstraction) process. In
   ture of the new software may be completely different. An           other words, the identification of common properties or rela-
   explanation can be given by an analogical transfer.                tions is represented by a generalization of the input of source
                                                                      and target. Mathematically this can be modeled by an ex-
• Learning new concepts: The productivity of metaphoric               tension of the so-called theory of anti-unification (Plotkin,
   expressions to generate new meanings can be modeled by             1970), a mathematically sound account describing the pos-
   analogies (Gust, Kühnberger & Schmid, 2006b). A well-             sibility of generalizing terms of a given language using sub-
   known domain is the introduction of technical concepts,            stitutions. More precisely, an anti-unification of two terms
                                                                 1418

Table 1: A simplified description of the algorithm HDTP-A                 High      Volume flowrate                 Charge Flowrate = Current
                                                                          Pressure
omitting formal details. A precise specification of this algo-
rithm can be found in Gust, Kühnberger & Schmid, 2006b.                                                       High
                                                                                                             Voltage
Input:      A theory T hS of the source domain and a theory                                       R                                           R
            T hT of the target domain represented in a many-                    Pump                                     Battery
            sorted predicate logic language.                                                                   Low
Output: A generalized theory T h G such that the input                   Low                                Voltage
                                                                         Pressure
            theories T hS and T hT can be reestablished by
            substitutions.
                                                                                           Poiseuille‘s                              Ohm‘s Law
                                                                              Reservoir    Law                                          'V
Selection and generalization of fact and rules.                                                'P             Ground                 I=
                                                                                           F=                                            R
            Select an axiom from the target domain                                              R
            (according to a heuristics h).
            Select an axiom from the source domain and                    Figure 1: The analogy between a water pipe system and an
            construct a generalization (together with                     electric circuit in a diagrammatic representation. The Figure
            corresponding substitutions).                                 contains more information than is necessary for an interpre-
Optimize the generalization w.r.t. a given heuristics h  .               tation of the metaphorical description (1).
            Update the generalized theory w.r.t. the result of
                                                                          First, an axiom from the target domain is selected, guided by
            this process.
                                                                          an appropriate heuristics h, for example, measuring the syn-
Transfer (project) facts of the source domain to the target               tactic complexity of the axiom. Then an axiom of the source
            domain provided they are not generalized yet.                 domain is searched in order to construct a generalization to-
            Test (using an oracle) whether the transfer is                gether with substitutions. The generalization is optimized us-
            consistent with the target domain.                            ing another heuristics h  , for example, the length of the nec-
                                                                          essary substitutions. Finally axioms from the source domain
t1 and t2 can be interpreted as finding a generalized term t              are projected to the target domain. Then the transferred ax-
(or structural description t) of t 1 and t2 which may contain             ioms are tested for empirical validation with the target do-
variables, together with two substitutions Θ 1 and Θ2 of vari-            main using an oracle. If the test renders the axiom as invalid
ables, such that tΘ1 = t1 and tΘ2 = t2 . Because there are                the transfer is blocked. 2 Furthermore the transferred must be
usually many possible generalizations, anti-unification tries             consistent with the target theory, i.e. if a contradiction can be
to find the most specific one. An example should make                     detected the transfer must rejected. Technically this can be
this idea clear. Assume two terms t 1 = f (X, b, c) and                   implemented by a theorem prover.
t2 = f (a, Y, c) are given. Generalizations are, for exam-
ple, the terms t = f (X, Y, c) and t  = f (X, Y, Z) together                                 Learning with HDTP
with their corresponding substitutions. 1 But t is more specific
than t , because the substitution Θ substituting Z by c can be
                                                                          An Example
applied to t . This application results in: t  Θ = t. Most spe-         Many prototypical examples of analogies and analogical
cific generalizations of two terms are commonly called anti-              transfers can be found in the analogy related literature (like
instances.                                                                the Rutherford analogy establishing an analogical relation
   In order to guarantee the necessary expressive strength,               between the solar system and the atom model or the heat-flow
HDTP extends the theory of anti-unification in several ways:              analogy in which water-flow and heat-flow are associated
First, not only terms but also formulas can be generalized.               by an analogy). In this subsection, we emphasize some
Second, predicates and functions can be generalized (second-              important aspects of our modeling with HDTP. Consider the
order case). Third, we allow to generalize whole theories,                following analogy (represented as a metaphorical expres-
because the input for the source and the target domains are               sion):
usually given as a (more or less complex) theory about this
domain. Fourth, the account is heuristic-driven, i.e. back-                  (M1) Current is the water in the electric circuit.
ground knowledge governs the generalization process. Fifth,
data from the source domain can be projected to the target               Figure 1 depicts the situation represented by this analogy. 3
domain in order to make the introduction of new concepts on               The analogy associates water-flow in a water pipe system
the target side possible.                                                 with the flow of current in an electric circuit. In a learn-
   Given two input theories T h S and T hT for source and tar-                2
get domain respectively, the algorithm HDTP-A computes                          In our view, an oracle represents a function mapping formu-
                                                                         las containing only observables to truth values. Such formulas can
anti-instances together with a generalized theory T h G. Ta-             be interpreted as specifying an experiment, i.e. they can loosely
ble 1 specifies the most important steps of this algorithm:              be compared with the role of a physicist who is performing experi-
                                                                         ments.
    1
      We assume that symbols a, b, c, . . . denote constants whereas          3
                                                                                The figure is based on a graphical representation of this anal-
capital symbols X, Y, Z, . . . denote variables, similar to the usage    ogy found on a physics webside of the Georgia State University (cf.
in Prolog.                                                               http://hyperphysics.phy-astr.gsu.edu/hphys.html.)
                                                                     1419

Table 2: Examples of corresponding concepts in the source and the target domains of the analogy between water-flow and the
flow of current in an electric circuit after a successful establishment of an analogical relation. The shortcut ws1 denotes an
instance of a water pipe system and es1 an instance of an electric circuit.
                       Source                                            Target                                   Generalization
    (1)        water circuit(ws1,water,p1)                  electric circuit(es1,current,b1)                       Circuit(A,C,S1)
    (2)                closed(ws1)                                    closed(es1)                                     closed(A)
    (3)                 pump(p1)                                      battery(b1)                                    Source(S1)
    (4) pres(p1) > 0 → flow in circuit(water)          pres(b1) > 0 → flow in circuit(current)          pres(S1) > 0 → flow in circuit(C)
    (5)           flow in circuit(water)                        flow in circuit(current)                         flow in circuit(C)
ing situation of a high school student, clearly Ohm’s law                 alization of a formerly unknown concept, namely some prop-
and Poiseuille’s law are not available to the students. There-            erty current depicts in an electric circuit. The acquired type
fore, Figure 1 depicts more than what can be learned by this              of knowledge is clearly not a precise physical theory about
analogy. Nevertheless an important new conceptualization                  electricity, rather a type of pre-conceptualization of a new do-
about electricity can be learned by students using this anal-             main.
ogy, namely that current is flowing in a circuit and that a                  It should be stressed that this type of learning does not re-
battery has the function similar to a pump in the water pipe              quire a large amount of input data. Only a sufficiently rich
system.                                                                   conceptualization of the source domain is necessary, usually
   We would like to achieve a modeling of metaphor (M1)                   given by background knowledge. In the following discussion
using HDTP. Table 2 specifies the corresponding concepts                  we sketch how this can be used in order to develop a theory
in the target and the source domains that are associated with             of learning by analogical reasoning.
each other. The association established by HDTP is realized
by a generalization process of the input theories. Hence                  Discussion
the concept of a closed water system and a closed electric                Contrary to the case of inductive learning, HDTP provides a
system generalize to an abstract concept closed(A) where                  generalization of quite parsimonious input data. Instead of
A is a variable. The terms water and current are associated               extracting abstract features of a given sample of examples,
explicitly in the metaphoric expression (M1). From the                    or storing large data samples in a data base, the heuristics
background knowledge a rule is available stating that if the              and a relatively rich source domain govern the generaliza-
pressure caused by the pump p1 in a water pipe system is                  tion process. Because of the fact that various generalizations
different from 0, then water is flowing in the circuit (from              are possible, a testing procedure needs to be implemented in-
high pressure to low pressure). This can be projected to                  spired by the idea of performing experiments. Two criteria
the target side, inferring that due to the “pressure” of the              are implemented in the underlying algorithm HDTP-A and
battery b1 (realized by a positive voltage), current is flowing           seem to be crucial for the design of such experiments.
in the electric circuit. Hence, we end up with the conclusion
(5 in Table 2) that current is flowing in the electric circuit            • Is the resulting theory logically consistent?
(provided there is a “pressure” source). By the generalization            • Does the theory predict the right outcome of measurements
process and the corresponding substitutions of the variables,                of the observables?
we get a structural description of the two domains. The
substitutions Θ1 and Θ2 can be summarized as follows:                        Clearly the real situation is more complicated. If we leave
                                                                          the very broad qualitative modeling of the example towards
                                                                          the quantitative modeling (the linear relation between pres-
   Θ1 /Θ2 :          A −→        ws1 / es1
                                                                          sure and throughput), the situation changes. We have to dis-
                     C −→        water / current                          tinguish between charge and current, because current is de-
               Source −→         pump / battery                           fined by charge per time. In this situation, water must be re-
                     S1 −→       p1 / b1                                  lated to charge and not current. On the other side, Poiseuille’s
               Circuit −→        water circuit / electric circuit         law must be constrained to the case of laminar flow (smooth
                                                                          flow). Therefore, the correctness of an analogical relation can
   Clearly the proposed modeling is more complex than a                   be restricted by the range of certain parameters. 4
pure and direct modeling of metaphor (M1). We tried to cover                 We think that this dependency on parameters is impor-
some important aspects of Figure 1 in the representation. In              tant for all types of analogical learning. Concrete analogies
the case of metaphor (M1) the situation would be quite sim-               are based on instantiations of more or less abstract concepts
ple. Concepts like battery, pump, or pressure do not occur.               building a conceptual basis of the reasoning process. The task
Rather from the conceptualization that in a circuit of water, it          is to figure out which properties of the source and target do-
is usually the case that water is flowing, we achieve the fact            mains are dependent on the particularly chosen instantiation
that current is flowing in an electric circuit directly by pro-           and which properties are dependent on the underlying con-
jecting the source to the target.                                         cepts. Whereas the latter ones are not explicitly considered
   Establishing successfully an analogical relation between                   4
                                                                                As long as these parameters are in a certain range, the above
the involved domains by projecting facts and rules from                   analogy is able to make quite good predictions about fairly complex
source to target domains results in learning a new conceptu-              situations, for example, circuits of parallel and serial components.
                                                                     1420

                                                                                        Learning by Levels
                                  Identify general Principles                           Considering classical artificial systems containing a machine
                                                                                        learning module, it is typically assumed that learning takes
                          Project the results back to the target domain                 places in a special component of the system that is not inher-
                                                                                        ently integrated into the system. Classical architectures result
                     Project the results back to the source domain, test,               therefore in a learning device that is (more or less) indepen-
                                            and adjust                                  dent from the other modules and learns explicitly form input
                        Select a parameter configuration for which the
                                                                                        data.6 In our approach, learning occurs as a side-effect of
                                   analogy does no longer hold                          the modeling and can be considered as implicit: The gener-
                                                                                        alization process yields new conceptualizations of the target
                         Range parameters and test using experiments                    domain for nothing. Furthermore analogical learning in our
                                     Generalized Theory ThG
                                                                                        modeling does not end with a successful establishment of an
                                                                                        analogical relation. Learning continues in stages as was al-
                  Substitution 41                              Substitution 42          ready sketched above. We will give an idea what that means
                                                                                        by specifying three levels of learning (Figure 2):
            Source Theory ThS                                    Target Theory ThT
                                                                                        • First level of learning: Finding the most specific general-
                                                                                           ization to establish the analogical relation.
    Figure 2: A graphical representation of learning stages.                            • Second level of learning: Adjusting the parameters in order
                                                                                           to find new (and finer) conceptualizations of the source and
to be under revision in HDTP, it is the first class of properties                          the target domains by projecting the new facts and rules in
that need to be investigated and updated under appropriate                                 both directions.
circumstances.
   The overall strategy of analogical learning in HDTP is                               • Third level of learning: Identifying general principles that
summarized in a modular way in the following list:                                         can be applied in a variety of domains
• Given a source and a target input S and T , apply theory                                 The first step in our modeling is the task to find a general-
   projection based on the algorithm HDTP-A in order to get                             ization of the two input theories T h S and T hT . Because there
   a generalized theory for the source and the target together                          are many possibilities for generalizations we introduced the
   with corresponding substitutions.                                                    idea of anti-instances that determine the most specific gen-
                                                                                        eralization. Finding such anti-instances is already a learning
• Find ranges of parameters such that theory projection can                             step: They are well-known in the ILP community as (rela-
   be established in a basic way using experiments as valida-                           tive) least general generalization (Plotkin, 1969; Muggleton
   tion tool.                                                                           & Feng, 1990). Clearly the differences between these ILP
                                                                                        approaches and the presented account are significant, due to
• Explore the boundaries of the ranges of parameter values                              the aspect of HDTP to be theory-based. Notice that the space
   for which the established analogy holds. 5                                           of possible generalizations is strongly restricted by the source
                                                                                        and the target domain. Hence, the search for possible gener-
• Select a parameter configuration on a boundary for which                              alizations is governed by the overall conceptualization of the
   the analogy does not hold and project the conflicting results                        two domains and certain heuristics.
   of the experiment back to the source domain.                                            The second step in the learning process concerns the reli-
                                                                                        ability of the generalization and the identification of the pa-
• Use an inference machine on the source domain in order to                             rameters telling us to which extent a certain analogy holds:
   adjust parameters to become consistent with the projected                            Both aspects can be tested by performing experiments or –
   results of the experiment. This may require a refinement                             as in our case – by asking an oracle that functions as an ab-
   or extension of the source domain using a heuristics for                             stract experiment generator. Clearly an experiment can fail,
   relevant parameters.                                                                 resulting in a rejection of an analogical relation. Then, a new
                                                                                        search for a generalization has to be performed. In case the
• Project the refined or extended theory back to the target                             experiment supports the analogy, not only an analogy can be
   domain and test using experiments.                                                   established, but also an explanation for the conceptualization
                                                                                        of the target domain is found.
   Notice that experiments in the field of qualitative physics                             The third level of learning is the identification of general
are restricted to observables. In other words, what cannot be
                                                                                        principles in physics. In our running example we would
measured is not subject for considerations in a testing proce-                          end up with general laws of thermodynamics, in the case
dure. This idea governs also the inference machine used to                              of the Rutherford analogy (identifying revolving electrons
adjust the parameters, because only things that are measur-
                                                                                        with planets of a solar system) the principle would be the
able functions in the particular modeling of the problem can
be adjusted.                                                                                6
                                                                                              New AI is probably an approach trying to circumvent this idea
                                                                                       of modularity. Nevertheless there does not seem to exist a holistic
    5
      The exploration of boundaries can loosely be identified with ex-                 approach in New AI to higher cognitive capabilities that are able to
plorative learning (Watkins & Dayan, 1992).                                            model our domains.
                                                                                   1421

equilibrium of forces (actio = reactio). Because of the               Evans, T. (1968). A program for the solution of a class of geometric-
generality of such principles the modeling can be extended               analogy intelligence-test questions, in: M. Minsky (ed.), Seman-
to other domains as well. It is clear that this third level of           tic information processing, MIT press, pp. 271-353.
learning presupposes further applications of our modeling.            Falkenhainer, B., Forbus, K. & Gentner, D. (1989). The structure-
                                                                         mapping engine: Algorithm and example, Artificial Intelligence,
                                                                         41(1):1-63.
                   Concluding Remarks                                  Gentner, D. (1983). Structure-mapping: A theoretical framework
                                                                         for analogy, Cognitive Science, 7:155-170.
Analogical reasoning is a crucial ability of human cognition,         Gentner, D. (1989). The mechanisms of analogical learning, in: S.
because analogies can be used to explain many aspects of                 Vosniadou & A. Ortony (editors): Similarity and Analogical Rea-
cognitive creativity, productivity, and adaptivity: In the field         soning, New York, Cambridge University Press.
of natural language, the creative interpretation of metaphoric        Gentner, D., Bowdle, B., Wolff, P. & Boronat, C. (2001). Metaphor
expressions are an important reason for semantic productivity            is like analogy, in The analogical mind: Perspectives from cog-
and in the field of concept learning, the analogical transfer of         nitive science, editors: Gentner, Holyoak, Kokinov, Cambridge,
knowledge to new domains can explain the power of human                  MA 2001, pp. 199-253.
conceptualization. In short, learning by analogies is a crucial       Gust, H., Kühnberger, K.-U. & Schmid, U. (2006a). Ontologies
factor for the adaptivity of humans without large input data.            as a Cue for the Metaphorical Meaning of Technical Concepts,
                                                                         to appear in Andrea Schalley & Drew Khlentzos (Eds.): Mental
   In our modeling of analogical reasoning using HDTP,                   States: Evolution, Function, Nature, John Benjamins Publishing
learning occurs implicitly due to the generalization process             Company, Amsterdam, Philadelphia.
(together with the substitutions). Learning aspects are not            Gust, H., Kühnberger, K.-U. & Schmid, U. (2006b). Metaphors and
represented as additional modules that are somehow added                 Heuristic-Driven Theory Projection (HDTP). Theoretical Com-
to the analogical reasoning process, rather is learning a side-          puter Science 354(1):98-117.
effect of analogy making. In other words, learning occurs im-          Gust, H., Kühnberger, K.-U. & Schmid, U. (2003a). Solving Pre-
plicitly as a part of a more complex reasoning process. This             dictive Analogy Tasks with Anti-Unification. In: P. Slezak (ed.),
complex reasoning process can be divided into three main                 Proceedings of the Joint International Conference on Cognitive
                                                                         Science 2003 (ICCS/ASCS-2003), 145-150, Sydney, Australia.
stages, starting with simple generalizations, continuing with
an exploration of parameter settings, and ending in the estab-         Gust, H., Kühnberger, K.-U. & Schmid, U. (2003b). Anti-
                                                                         unification of axiomatic systems. Available on the www:
lishment of general principles. In naive physics, for example,           http://www.cogsci.uni-osnabrueck.de/∼ helmar/analogy/.
knowledge gathered from different domains is generalized to
                                                                      Hofstadter, D. & The Fluid Analogies Research Group (1995). Fluid
abstract principles like the law of the conservation of energy.          concepts and creative analogies, New York.
   The proposed model presupposes crucially background
                                                                      Indurkhya, B. (1992). Metaphor and Cognition, Dordrecht, The
knowledge: Without any conceptualization of the source do-               Netherlands, Kluver.
main learning is simply not possible. Hence, the question
                                                                      Kolodner, J. (1993). Case-based reasoning, San Mateo, CA, Mor-
about the bootstrapping aspect remains open. Humans start                gan Kaufmann.
to learn somehow, but the presented theory cannot give an
                                                                      Lave, J. & Wenger, E. (1990). Situated Learning: Legitimate Pe-
explanation how. Nevertheless a large part of cognitive learn-           ripheral Participation. Cambridge University Press.
ing abilities seems to be covered by an approach of learning
                                                                      Mitchell, T. (1982). Generalization as Search, Artificial Intelligence,
by analogies.                                                            18(2):203-226.
                                                                      Muggleton, S. & Feng, C. (1990). Efficient induction of logic
                     Acknowledgments                                     programs, First Conference on Algorithmic Learning Theory,
This research was partially supported by the grant KU                    Omsha, pp. 368-381.
1949/2-1 of the German Research Foundations (DFG).                    Plotkin, G. (1970). A note on inductive generalization. Machine
                                                                         Intelligence 5:153-163.
                          References                                  Quinlan, J. (1986). Induction of decision trees, Machine Learning,
Aha, D., Kibler, D. & Albert, M. (1991). Instance-based learning         1:81-106.
   algorithms, Machine Learning, 7:37-66.                             Rojas, R. (1996). Neural Networks – A Systematic Introduction.
Anderson, J. & Thompson, R. (1989). Use of analogy in a produc-          Springer, Berlin, New York.
   tion system architecture, in Vosniadou, S. & Ortony, A. (eds.):    Salzberg, S. (1991). A Nearest Hyperrectangle Learning Method,
   Similarity and analogical reasoning, 267-297, Cambridge.              Machine Learning, 6(3):251-276.
Bandura, A. & Walters, R. (1963). Social Learning and personality     Schmid, U., Gust, H., Kühnberger, K.-U. & Burghardt, J. (2003).
   development. New York.                                                An Algebraic Framework for Solving Proportional and Predictive
Bishop, C. (1995). Neural Networks for Pattern Recognition, Ox-          Analogies, in Schmalhofer, F., Young, R., and Katz, G. (eds.):
   ford University Press.                                                Proceedings of EuroCogSci 03. The European Cognitive Science
                                                                         Conference 2003, 295-300. Lawrence Erlbaum Associates.
Chomsky, N. (1959). A Review of B. F. Skinner’s Verbal Behavior.
   Language, 35(1):26-58.                                             Stanfill, C. & Waltz, D. (1986). Toward memory-based learning,
                                                                         Communications of the ACM, 29(12):1213-1228.
Dastani, M. (1998). Languages of Perception, ILLC Disseration Se-
   ries 1998-05, 1998, http://www.illc.uva.nl/Publications/           Watkins, C. & Dayan, P. (1992). Technical Note: Q-Learning, Ma-
   Dissertations/DS-1998-05.text.ps.gz                                   chine Learning, 8(3):279-292.
Dastani, M., Scha, R. & Indurkhya, B. (1997). An algebraic method
   for solving proportional analogy problems involving sequential
   patterns, Mind II: Computational Models of Creative Cognition
   (Dublin, September 1997), pp. 1- 15.
                                                                  1422

