UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Melodic Expectancy: Musical Predictability in an SRN
Permalink
https://escholarship.org/uc/item/1tt5m02v
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Abbs, Brandon
Gupta, Prahlad
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                   Learning Melodic Expectancy: Musical Predictability in an SRN
                                            Brandon Abbs (brandon-abbs@uiowa.edu)
                                              Department of Psychology, E11 Seashore Hall
                                                          Iowa City, IA 52242 USA
                                            Prahlad Gupta (prahlad-gupta@uiowa.edu)
                                              Department of Psychology, E11 Seashore Hall
                                                          Iowa City, IA 52242 USA
                              Abstract
                                                                               The Implication-Realization (I-R) Model
   Descriptive models of music cognition propose various
   principles as underlying melodic expectancy, however there is         One model that has gone to great lengths in describing the
   very little discussion regarding the processes involved in the        role of local context in melodic expectancy is the Implication-
   acquisition of melodic expectation. To explore the potential          Realization (I-R) Model (Narmour, 1990). This model de-
   role of learning processes, a simple recurrent network (SRN)          emphasizes a global, or stylistic, analysis of music and
   was trained on a set of musical sequences to examine the degree       instead focuses on note-to-note relationships to examine how
   to which the principles described by Schellenberg’s (1997) two-       musical implications and realizations are perceived (Narmour,
   factor model might be learned through musical exposure. The           p. ix). According to this model, and other theoretical
   principle of pitch proximity, but not pitch reversal constrained      descriptions of music cognition upon which it was built, an
   the model’s expectations of tones following melodic fragments.        implication is created whenever two notes (an interval) are
   Implications for this model in the area of music perception and       perceived as incomplete, or open. This implicative interval
   sequential modeling are discussed, as are potential extensions        creates an expectation for the next note of the melody, which
   of this simple system.                                                is the realization of this interval. The interval between the
   Keywords: melodic expectancy; simple recurrent network;               realized note and the second tone of the implicative interval is
   learning                                                              the realized interval.
                                                                                   For any given implicative interval, there will be a set
              Expectancy in Music Cognition                              of tones that are implied by the interval and the strength of
                                                                         their implication will be graded. That is, certain tones will be
When hearing music, much of the listener’s experience                    strongly implied, while others will be weakly implied, and
depends upon how much a given note is expected given the                 still others will fall in between these extremes. The goal of
current musical context. This expectancy may be thought of               theoretical models of music cognition like the I-R model is to
as a dynamic probability distribution that changes depending             determine where individual notes fall along this continuum
on global context variables, such as the style, mode, or key of          for different types of implicative intervals and what general
a musical piece, as well as local context variables, such as the         principles may be used to describe similar types of
specific notes that have recently been heard (Carlsen, 1981;             expectancies. While an entire volume (Narmour, 1990) has
Krumhansl et al., 1999).                                                 been dedicated to the details of the I-R model, the present
            Many investigations in music cognition have                  discussion will focus on Schellenberg's (1997) simplification
determined what musical variables lead to what expectancies              of the model into two orthogonal principles.
in order to understand both the psychology and art of music
(see Krumhansl, 1995; 2000 for a review). The focus of the                                The Two-Factor Model
present investigation will be the local context with the goal of         One criticism of the full I-R model is that its principles are
investigating how the underlying musical knowledge being                 over specified and overlap with one another (Schellenberg,
probed in these types of investigations may be learned                   1997). In recognition of this fact, and in order to uncover the
through musical exposure. This goal will be pursued by                   fundamental components of melodic expectation,
examining how a connectionist network designed for                       Schellenberg advocated a reduction of the I-R model down to
sequential processing, Elman’s (1988) Simple Recurrent                   two orthogonal principles, pitch proximity and pitch reversal.
Network (SRN), develops melodic expectancy from a small                  Apart from being orthogonal, these principles are also
corpus of simple melodies. The novelty of this work in                   dependent on different contextual windows: Pitch proximity
relation to previous models (e.g., Bharucha & Todd, 1989;                considers only the last note of a sequence, but pitch reversal
Krumhansl et al., 1999; Mozer, 1991; Page, 1999) is the                  requires the consideration of the last two notes (i.e., the
model's simplicity and the analysis of the model's                       implicative interval) of a sequence.
performance.
                                                                     931

Pitch Reversal                                                        old as well as those of adults and children of intermediate
Pitch reversal collapses the registral return and registral           ages (Schellenberg et al., 2002). Further, this principle
direction principles in the I-R model into one principle.             explains a majority of the variance as compared to the
Following a large implicative interval (≥ 7 semitones), the           principle of pitch reversal in all groups. Pitch reversal, on the
realized interval should either be lateral or in the reverse          other hand, only emerges as a significant predictor in adults,
direction, thus changing the melodic contour established by           or children with an elevated musical ability. For this latter
the interval. Further, with a change in direction, the note           group, pitch reversal emerges in children as young as five
should be either a complete return, or a near return. With a          years old.
small interval, the only contributor to expectation is the return                The evidence for the emergence of pitch reversal
characteristic.                                                       only after significant musical experience has thus been
                                                                      presented, but the emergence of pitch proximity (as opposed
Pitch Proximity                                                       to an innate predisposition) is still in question. Its presence in
Pitch proximity is essentially identical to the proximity             children as young as seven and five years old may provide
principle of the I-R model in that, the closer a tone is to the       evidence against a learning-based account, however this
previous pitch, the greater the expectation for that tone. The        depends largely on how easily such a principle might be
unison tone (i.e., the same tone) is the most expected tone and       learned in a given stimulus environment. It is the goal of the
expectations fall off linearly and absolutely from this tone.         present examination to determine just how easily such a
                                                                      principle might be learned by an SRN exposed to sequences
           Schellenberg (1997) evaluated the predictive power         of simplistic melodies, such as those found in nursery rhymes
of the I-R and Two-Factor models by applying them to a set            and folk songs. The choice of an SRN for the present project
of expectancy ratings reported by Cuddy and Lunney (1995).            was driven by the fact that it is a computational system with
Expectancy ratings are collected through a melodic                    very little structure, yet the ability to process sequences of
expectation task wherein participants are played a melodic            information and the fundamental characteristic of expectancy
fragment (i.e., a melody ending in an implicative interval)           in its operation. Further, the SRN's demonstrated success
followed by a probe tone. The participants are asked to rate          with a wide variety of procedural learning tasks (e.g., syntax,
the tone according to how well it completes the melodic               artificial grammar, digit entering, word form, and action
fragment following the logic that a highly expected tone will         learning) links the computational model to a potential
be given a high rating. Typically, multiple fragments, each           learning process that further empirical investigations can aim
with a unique implicative interval, are used and over the             to verify.
course of the entire experiment these fragments are heard in
conjunction with a wide range of probe tones. This procedure                         The Computational Model
results in an expectancy profile for each melody for each
subject. A multiple regression is then performed on these             Architecture
ratings using the principles of the models as predictors, with a
model’s success being determined by its predictive power.             In order to maintain the focus of the present investigation on
           Schellenberg (1997) found that the Two-Factor              the note-to-note processing of melodies with notes being
model explained 72.5% of the variance in the expectancy               described as abstract primitives, and thus maintain the spirit
ratings reported by Cuddy and Lunney (1995), compared to              of Narmour’s (1990) original analysis, the representation of
the I-R model's 64.0%. In a prospective study of similar              notes in the network were localist. Specifically, twelve nodes
design, Schellenberg et al. (2002) again found the two-factor         in the input layer and twelve nodes in the output layer
model to be as successful or more successful than the I-R             represented each of the tones on a chromatic scale (see Figure
model in accounting for the variance of the listener’s ratings        1). Taking advantage of the principle of enharmonic
(but see Krumhansl, 1995; Krumhansl et al., 1999;                     equivalence (whereby sharpening a note is perceptually
Thompson, Cuddy, & Plaus, 1997). These results raise the              equivalent to flattening a note one whole tone above the
question of whether pitch proximity and pitch reversal are the        sharpened note), one node was used to represent equivalent
fundamental principles of melodic expectancy. Further, the            sharps and flats (e.g., A-sharp/B-flat).
fact that these principles require different degrees of context,                 In order to easily expand the representational
as well other evidence that these principles appear to be             capability of the network and represent similarity between the
sensitive to one’s musical culture (Carlsen, 1981; Thompson           same notes in different octaves, octave information was also
et al., 1997) raises the question of whether these principles         represented by a single localist node. Four nodes in the input
might be learned through musical exposure. The goal here is           layer and the output layer each represented a different octave
to test the feasibility of learning through mere exposure and to      according to the number given to them in musical notation
propose a candidate learning process.                                 (e.g., the octave below middle C=3, the octave containing
                                                                      middle C=4, and so on). Together, these sixteen input and
            Developing Melodic Expectation                            output nodes can represent any note from C3 – B6.
                                                                                 Inherent within the SRN is the abstract
The proximity principle of the two-factor model is predictive         representation of local musical context through recurrence
of the expectancy ratings of children as young as seven years         between the hidden layer and a separate context layer, both of
                                                                  932

which lie between the input and output layers. The hidden            prediction and the actual next note. The learning parameters
unit sends activation through one-to-one, non-modifiable,            of this algorithm were set as follows: learning rate = .01,
connections to the context layer, which in turn sends                momentum = .9, hysteresis, or µ, = .3. One training epoch
activation through modifiable connections back to the hidden         constituted one pass through the training set, or one
layer. Upon presentation of a note, the resultant activation at      presentation of all one hundred songs.
the hidden layer is copied onto the context layer. This context
is then presented alongside the next input event and the             Testing Procedure
context's influence is determined by the strength of the             The testing materials were notations of the melodic fragments
connection weights between the context and the hidden layer.         presented to participants by Schellenberg et al. (2002, Figure
Thus, information about previous notes and the current note is       3). Each fragment was 14 - 16 notes in length and selected
available to the model. The hidden layer and context layer           from an Acadian (French-speaking Canadians from the
were each made up of four units.                                     Maritime Provinces) folk song. Fragments were selected
                                                                     from songs in the Acadian culture to eliminate the possibility
Training Corpus                                                      that participants would have any a priori familiarity with the
The training set for the model was created from 100 melodic          fragments. Further, fragments were selected from these songs
sequences. These sequences were actual songs chosen from             such that they ended in an upward implicative interval, which
three books containing traditional, Western, children’s and          is considered to be more implicative than a downward
folk songs (Mitchell, 1968, Raph, 1964; Seeger, 1948).               interval. Lastly, two of the implicative intervals were large (9
Transcriptions of these songs in the ABC ASCII notation              & 10 semitones), providing an opportunity for the pitch
were downloaded from an on-line depository (Chambers,                reversal principle to emerge, while the other two intervals
n.d.). 84 of these sequences were completely unique and 16           were small (2 & 3 semitones).
of these sequences were repeated titles transposed into                        The model was tested on every epoch. At test,
different keys. The downloaded text files were then                  learning was turned off and each of the melodic fragments
processed so as to extract the sequence of tones that make up        was presented to the model. Following the final stimulus
the melody of the song. In all, 9,175 stimulus events were           event of a fragment (the second tone of the implicative
represented.                                                         interval), the activation levels of the output nodes were
                                                                     recorded. The model’s prediction of a particular note in a
Training Procedure                                                   specific octave (e.g., C4) was computed as the dot product of
During training, songs from the training corpus were selected        this final output vector and the target vector for the note in
randomly without replacement. For each song, notes were              question. This dot product was then treated as the expectancy
presented one at a time to the SRN’s input layer, resulting in       rating of the model and scaled so as to match the likert scale
activation at the output layer, which will be interpreted as the     ratings reported by Schellenberg et al. (2002, Figure 4). This
network’s prediction, or expectation, of what the next note          measure was used in order to functionally bind note and
will be. In order to train the network, the actual next note (or     octave information, which must be done in order to translate
in the case of the last note of a song, a blank vector) was used     the activation of the output vector into a metric akin to an
as a target and the back-propagation learning algorithm was          expectancy rating. After this measure was taken for each test
used to modify the connection weights of the system after            sequence, learning was turned back on and the model was
each stimulus event based on the error between the model’s           trained for another epoch before being tested again.
                                                                               We did not expect that this simple model, learning
                                                                     from a simple training set, would be able to capture all the
   C C# D D# E F F# G G# A A# B 3 4 5 6                              nuances in expectancy ratings that human data show. Rather,
                                                                     we wished to examine whether the principles developed as
                                                                     descriptions of these expectancy ratings might emerge as a
                                                                     result of learning through exposure to nursery rhymes. Given
                                                                     the pervasiveness across age groups and explanatory power of
                                                                     pitch proximity in the ratings reported by Schellenberg et al.
                                                                     (2002), this principle seemed the one most likely to be
                                                                     evident in the computational model. Pitch reversal, on the
                                                                     other hand, would only be evident to the extent that a.) the
   C C# D D# E F F# G G# A A# B 3 4 5 6                              model was able to take larger units of context into account (as
                                                                     proposed by Schellenberg et al. for humans) and b.) large
                                                                     implicative intervals were prevalent in the simple melodies
 Figure 1: Representational scheme used in the present               of the training set.
 SRN. The first 12 input and output nodes are localist units
 representing each note on the chromatic scale. The final 4          Simulation Results & Analysis
 nodes are localist units representing each octave region the                  Table 1 shows correlations between the model’s
 network might encounter.                                            expectancy ratings and the behavioral data, estimated from
                                                                 933

Figure 4 of Schellenberg et al. (2002). Overall, the model              model. This three-factor model is again a significant
correlates the best with expectancy ratings generated for               predictor of rating behavior, F(3, 59) = 35.92, p < .05,
smaller implicative intervals than for larger implicative               adjusted R2 = .640. Further, the simple frequency factor is a
intervals and the ratings of older children better than adults          nearly significant contributor to the model, t (59) = 1.97, p =
and younger children (see Table 1). Furthermore, these                  .05, while pitch proximity remains a significant contributor, t
correlations are evident after just one epoch of training. For          (59) = -6.58, p < .05. Thus the model was not simply
melody 1, the model shows a significant correlation (p < .05            tracking stimulus frequency, but it does contribute to its
for all correlations) with ratings from all age groups [rs (13) =       expectancies.
.829, .843, .761 for adults, older children, and younger                           The simple correlations and multiple regressions
children respectively]. For melody 2, the model correlates              indicate that the model is producing ratings that conform most
significantly with only the adults (r = .699) and the older             to those that are predicted by Schellenberg's (1997) proximity
children (r = .866). For melody 3, which ends in a large                principle and which are most like the profiles of older
implicative interval, the model again correlates significantly          children, who have also been shown to produce profiles that
with adults (r = .515) and older children (r = .602), but not           are primarily predicted by the proximity principle. The
younger children. Lastly, for melody 4, which also ends in a            regressions also revealed that the model's ratings are
large implicative interval, the model only correlates                   influenced by the melodic context of the test sequence, not
significantly with adults (r = .480) and older children (r =            just the simple frequencies of notes in the training set. We
.582). Interestingly, these correlations are robust to additional       turn now to a more in-depth analysis of the training set to
learning. With 30 more epochs of training, the correlations             examine whether the data set differentially embodies pitch
change an average of only .004.                                         proximity, or if pitch reversal could be reasonably expected to
           The correlations suggest that the model settles              emerge from this set.
quickly into a state that creates expectancies that are most like
the older children (see Figure 2) and, in the current                   Corpus Analysis
architecture, are robust to further learning1. However, it is           The main motivation for this analysis is to determine the
also clear that the model has difficulty in generating a                prevalence of large implicative intervals compared to simple
psychologically valid expectation when given a large                    frequencies and small intervals, both of which have proven to
implicative interval, where pitch reversal is at its height in          be significant predictors of the model's expectancy ratings.
terms of creating expectations. To further investigate these            These data are also interesting in and of themselves, as they
results, we performed a multiple regression analysis,                   reveal information about the degree of support for the
including pitch proximity and pitch reversal as predictors of           theoretical principals being examined here in the intervallic
the model’s expectancy ratings, as Schellenberg et al. did for          statistics of real songs.
step two of a hierarchical regression for the human ratings.                       In terms of simple frequencies, the 4 most frequent
The analysis revealed that the two-factor model is indeed a             notes (A4, G4, B4, and D5 respectively) each occur more than
significant predictor of the model's rating behavior, F(2, 59) =        1,000 times. The next most frequent are 11 notes that occur
49.45, p < .05, adjusted R2 = .622. However, only the                   between 100 and 900 times. This second group includes only
proximity factor was a significant contributor to the model, t          two sharps (F#4 and A#4) and all of the tones are in the fourth
(59) = -9.90, p < .05. This regression confirmed that the               and fifth octave. The least frequent group includes most of
model behaves according to the principle of pitch proximity,            the sharps in the corpus as members, and the only two notes
but not reversal.                                                       that fall outside of the fourth and fifth octave (B3 and A3).
           Inspection of the pitch profiles generated by the                       Moving to note intervals, 4,263 of the transitions are
model, compared to the profiles of older children provides              small intervals and the two most common intervals involving
visual indication of statistical findings (see Figure 2). While         pitch movement are +/- 2 semitones (1,129 and 1,226
the expectancy ratings of notes within the same octave as the           occurrences, respectively). However, even more frequent
final tone (the center point of the graph) are high, there is a         than these two interval sizes are unison intervals, which occur
sharp drop off between octaves, while the ratings of the                1,657 times. A visual inspection of Figure 2 indicates that the
humans show smoother transitions in ratings between                     model appears to favor movement over laterality.
octaves. Further, expectancy ratings in the model do not show
an elevation at the first note of the implicative interval
(denoted by an asterisk on the x-axis) or surrounding tones,            Table 1: Correlations between the ratings of the model after
which is predicted by the principle of pitch reversal.                  one epoch of training and the three human groups. * p < .05.
           A second multiple regression analysis revealed that
adding the simple frequency of a note in the training set as a                     Melody       Adult        Old        Young
predictor variable does improve the predictive power of the                       (Interval                  Child      Child
                                                                                    Size)
1                                                                               1 (Small)       .829*        .843*      .761*
  Support for this claim can also be gathered from a procedurally-              2 (Small)       .699*        .866*      .180
identical simulation which was done with an SRN with 100 hidden
                                                                                3 (Large)       .515*        .602*      .188
units that was trained for 10,000 epochs at a learning rate of .001
and produced approximately the same results at test.
                                                                                4 (Large)       .480*        .582*      .134
                                                                    934

                           Melody 1 Profile                                                           Melody 3 Profile
   7                                                                           7
   6                                                                           6
   5                                                                           5
   4                                                             Model         4                                                          Model
   3                                                             Old           3                                                          Old
                                                                 Child                                                                    Child
   2                                                                           2
   1                                                                           1
   0                                                                           0
      G3  A3 A#3 C4 D4  E4 F4* G4    A4 A#4 C5     D5  E5 F5 G5                   G3 A3 A#3 C4* D4 D#4 F4  G4   A4 A#4 C5    D5 D#5 F5 G5
                               Note                                                                       Note
                           Melody 2 Profile                                                           Melody 4 Profile
   7                                                                           7
   6                                                                           6
   5                                                                           5
   4                                                             Model         4                                                          Model
   3                                                             Old           3                                                          Old
                                                                 Child                                                                    Child
   2                                                                           2
   1                                                                           1
   0                                                                           0
      D#3 F3 G3 G#3 A#3 C4* D4 D#4 F4       G4 G#4 A#4 C5 D5 D#5                  F3 G3 A3  B3 C4* D4  E4  F4   G4     A4 B4 C5 D5  E5 F5
                               Note                                                                       Note
 Figure 2: Rating profiles for the SRN and older children from Schellenberg et al (2002). The center note on the x-axis
 is the last note of the melodic fragment, the asterisk denotes the next-to-last note heard. The profiles of the small
 implicative intervals (Melody 1 and Melody 2) are on the left, the profiles for the large intervals (Melody 3 and 4) are
 on the right.
           In terms of large intervals, there are only 3,255 large                                    Discussion
intervals, or slightly more than one-third of the corpus. Given
                                                                           In the area of music cognition there are descriptions of
a large implicative interval, the realization interval does tend
                                                                           perceptual principles that dictate human expectations for
to return back towards the first note of the implicative interval
                                                                           musical notes and which may be a result of learning. The
(there are 1,412 such returns), but it is also just as likely to
                                                                           present investigation determined the extent to which an SRN
stay near the last note. A small interval following a large
                                                                           acts in accordance with such principles following training on
interval occurs 1,240 times and is only slightly more likely to
                                                                           a small set of musical sequences. This project was
be a reversal of pitch contour. There are also 514 unison
                                                                           undertaken in the spirit of Schellenberg’s (1997)
tones following a large interval, which means that proximity
                                                                           simplification of a larger, more specific theory of musical
is a general property of the data set, rather than one that is
                                                                           expectancy as well as the spirit of the many cognitive
specific to small or large intervals, and is thus learned by the
                                                                           scientists who have applied SRNs to procedural learning
model as this more general property, blocking the learning of
                                                                           tasks.
the much lower frequency large returns following large
                                                                                     The expectancy ratings generated by the model after
intervals.
                                                                           just one epoch of training were most like those generated by
           While large intervals are a large part of the data set,
                                                                           older children in Schellenberg et al. (2002) and were
they are not as common as smaller intervals (including
                                                                           indicative of a system operating according to a combination
unisons). This presents the question of whether more
                                                                           of simple frequency and pitch proximity, but not pitch
sensitive listeners, who adhere to pitch reversal, have greater
                                                                           reversal. An analysis of the training set revealed that pitch
experience with large implicative intervals or if the
                                                                           proximity indeed appears to be a general property of both
responsible learning mechanisms are able to extract these less
                                                                           large and small implicative intervals, rather than a principle
dominant characteristics of music.
                                                                           which is specific to one or the other. It also revealed that
                                                                           pitch reversal is a much smaller component of the training set
                                                                       935

than proximity, leading to the question of how the principle        Cuddy, L.L. & Lunney, C.A. (1995). Expectancies generated
emerges in more experienced listeners.                                by melodic intervals: Perceptual judgments of melodic
           Future work on this model should be directed               continuity. Perception & Psychophysics, 57, 451-462.
towards providing more information to the network in order          Elman, J.L. (1989).       Representation and structure in
to establish how these factors might influence the                    connectionist models (Tech. Rep. No. 8903), San Diego,
expectations of the network. For instance, adding a self-             California: University of California, San Diego, Center for
organizing map that interacts with the output layer of the            Research in Language.
model may provide the model with top-down information               Krumhansl, C.L. (1995). Music psychology and music
regarding modes and keys, would allow the model to make               theory: Problems and prospects. Music Theory Spectrum,
contact with previously mentioned models, and would                   17, 53-80.
implement Narmour's (1990) top-down versus bottom-up                Krumhansl, C.L., Louhivouri, J., Toivianen, P., Jarvinen, T.
distinction. Another line of inquiry may be in determining            & Eerola, T. (1999). Melodic expectancy in Finnish folk
the extent to which varied and more complex musical                   hymns: Convergence of behavioral, statistical, and
exposure might account for the experience-based findings of           computational approaches. Music Perception, 17, 151-196.
Schellenberg et al. (2002).                                         Krumhansl, C.L. (2000). Rhythm and pitch in music
           Another potential extension of the model could be to       cognition. Psychological Bulletin, 126, 159-179.
explicitly represent larger amounts of context by adding            Mansfield, S. (2000). How to interpret abc music notation.
additional layers to the recurrent portion of the model. This         Retrieved       December         15,       2005       from
would force the model to represent longer time sequences and          http://www.lesession.co.uk/abc/abc_notation.htm.
potentially allow it to learn the principle of pitch reversal       Mitchell, D. (1968). Every child’s book of nursery songs.
from the few examples found in the current training set. An           New York: Corwn Publishers.
additional benefit to this architecture would be that the model     Mozer, M. (1991). Neural network music composition by
might begin to memorize individual songs because it would             prediction: Exploring the benefits of psychophysical
have some basis for recognizing songs and this memorization           constraints and multiscale processing. Connection Science,
might allow the model to develop, rather than maintaining the         6, 247-280.
stable state it currently displays (cf. Bharucha & Todd (1989).     Narmour, E. (1990). The analysis and cognition of melodic
           In general, the current application of an SRN to the       complexity. Chicago: University of Chicago Press.
musical domain is a novel contribution in this area, which          Page, M.P.A. (1999). Modelling the perception of musical
may help to provide information about the role of experience          sequences with self-organizing neural networks. In Griffith,
and learning in musical perception and the processes involved         N. & Todd, P.M. (Eds). Musical networks, 175-198.
in the acquisition of melodic expectation. It also proposes a         Cambridge, MA: MIT Press.
                                                                    Raph, J. (1964). American song treasury: 100 favorites.
candidate learning process for the acquisition of melodic
                                                                      New York: Dover.
expectancy, procedural learning, and the success of the model
                                                                    Schellenberg, E.G., Adachi, M., Purdy, K.T., & McKinnon,
in this task provides evidence that pursuing the exploration of
                                                                      M.C. (2002). Expectancy in melody: Tests of children and
an empirical relationship between expectation and
                                                                      adults. Journal of Experimental Psychology: General, 131,
performance on a procedural task may be a fruitful line of
                                                                      511-537.
experimental inquiry.
                                                                    Schellenberg, E.G. (1997). Simplifying the implication-
                                                                      realization model of melodic expectancy.            Music
                           References                                 Perception, 14, 295-318.
Bharucha, J.J. (1994). Tonality and expectation. In R. Aiello       Seeger, R.C. (1948). American folk songs for children. New
   & J.A. Sloboda. (Eds). Musical perceptions, 213-239.               York: Doubleday.
   London: Oxford University Press.                                 Seidenberg, M.S. (1997). Language acquisition and use:
Bharucha, J.J. & Todd, P.M. (1989).               Modeling the        Learning and applying probabilistic constraints. Science,
   perception of tonal structure with neural nets. Computer           275, 1599-1604.
   Music Journal, 13, 44-53.                                        Thompson, W.F., Cuddy, L.L., & Plaus, C. (1997).
Carlsen, J.C. (1981). Some factors which influence melodic            Expectancies generated by melodic intervals: Evaluation of
   expectancy. Psychomusicology, 1, 12-29.                            principles of melodic implication in a melody-completion
Chambers, J.C. (n.d.) JC’s ABC tune finder. Retrieved                 task. Perception & Psychophysics, 59, 1069-1076.
   December,                15,            2005            from
   http://trillian.mit.edu/~jc/music/abc/findtune.html.
                                                                936

