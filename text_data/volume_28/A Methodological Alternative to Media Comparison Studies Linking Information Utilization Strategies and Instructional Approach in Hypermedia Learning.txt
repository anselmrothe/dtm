UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Methodological Alternative to Media Comparison Studies: Linking Information Utilization
Strategies and Instructional Approach in Hypermedia Learning

Permalink
https://escholarship.org/uc/item/7569q7dx

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Catrambone, Richard
Gerjets, Peter
Scheiter, Katharina
et al.

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

A Methodological Alternative to Media Comparison Studies: Linking Information
Utilization Strategies and Instructional Approach in Hypermedia Learning
Katharina Scheiter (k.scheiter@iwm-kmrc.de)

Department of Applied Cognitive Psychology and Media Psychology, University of Tuebingen
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany

Peter Gerjets (p.gerjets@iwm-kmrc.de)

Hypermedia Research Unit, Knowledge Media Research Center
Konrad-Adenauer-Strasse 40, 72072 Tuebingen, Germany

Brigitte Vollmann (vollmann_cmr@gmx.de)

Center for Media Research, Freie Universitaet Berlin,
Malteserstr. 74-100, 12249 Berlin, Germany

Richard Catrambone (rc7@prism.gatech.edu)
School of Psychology, Georgia Institute of Technology
Atlanta, Georgia 30332-0170, USA
Abstract
Literature reviews on hypermedia learning have yet failed to
show consistent positive effects of learner-controlled nonlinear information access. We argue that a possible reason for
this lack of evidence in favor of hypermedia learning results
from the fact that not sufficient attention is paid to the strategies of information utilization learners deploy. The few studies that do analyze these strategies fail to link them to an instructional approach, which hampers a deeper interpretation
of strategy patterns. Our study showed that different groups of
learners can be distinguished according to their strategies used
in an example-based hypermedia environment and that these
groups differ with regard to learning outcomes, but not individual learner characteristics.

Is Learning with Hypermedia Ineffective?
Hypermedia environments are nonlinear information networks, which can be explored in multiple ways with the
learner having control over the selection, sequencing, and
pacing of information. Learner control is seen as beneficial
for knowledge acquisition for different reasons: First, learners can adapt the presentation of information to their preferences and needs. Second, learner control requires a deeper
information processing, because learners have to compare
the options offered to come to an informed decision. Third,
learner control may train meta-cognitive self-regulation
abilities. Fourth, it may improve motivation to learn and
learners’ attitude towards the topic. Despite these hypothesized advantages, literature reviews have yielded ambiguous
results concerning the effectiveness of hypermedia learning
over other forms of instruction (Dillon & Gabbard, 1998).
In the remainder of the paper, two arguments will be
brought forward and supplemented by some initial empirical
support: First, it is proposed that analyzing the way learners
make use of information offered in hypermedia environments might be a promising methodological alternative to
global media comparisons. Most of the existing studies tend

to ignore that once learner control is provided, learners’
information utilization behavior will show an increased
variance. Thus, whether hypermedia is effective will depend
on whether learners use the available information in a way
that knowledge acquisition processes are facilitated.
Second, the analysis of information utilization strategies
should be linked to the instructional approach implemented
in a hypermedia environment. Based on cognitive task
analyses and empirical evidence, an instructional approach
(e.g., learning from worked-out examples) can be characterized by a set of cognitive processes (e.g., example elaborations and comparisons) that enable knowledge acquisition
(e.g., construction of a problem schema), where different
cognitive processes require different information as input.
Thus, an effective information utilization strategy can be
defined a priori by the fact that information is selected, sequenced, and paced in a way that cognitive processes relevant to the instructional approach are facilitated.
Until now, there are only a few studies that have considered strategies of information utilization when studying hypermedia learning. Barab, Bowdish, Young, and Owen
(1996) used students’ navigational profiles based on different strategy indicators (e.g., number of pages retrieved,
depth of search) to predict whether a user had been given a
specific information search goal for browsing the system.
Balcytiene (1999) identified different groups of learners
(i.e., self-regulated learners, cue-dependent learners) by
means of logfile and video analyses for her hypertext system
on gothic architecture. Cue-dependent learners did not
browse the environment in a systematic way and oriented
themselves towards its local aspects, while self-regulated
learners reflected on the accessed information and were oriented towards the global structure of the system. In accordance with this interpretation of the navigational profiles
and video data, the posttest revealed superior retention for
self-regulated learners. Lawless and Kulikowich (1996)
used a cluster-analytical approach to identify different

2117

groups of users (i.e., knowledge seekers, feature explorers,
and apathetic users), which were then compared with regard
to different external criteria. Knowledge seekers, who had
used the information most intensively, had a higher prior
knowledge and showed better learning outcomes than the
other groups. The authors conclude that “the navigational
strategies employed by the ‘knowledge seekers’ are the
most like the sophisticated reading strategies used by competent traditional text processors” (p. 395f.). Moreover,
apathetic users may lack the prior knowledge necessary to
deploy effective information utilization strategies.
The aforementioned studies take a first step into the right
direction by focusing on users’ information utilization
strategies. However, their interpretation of learners’ navigational profiles is done in a post-hoc way without linking
them to the instructional approach implemented in the hypermedia environment (if there is one approach to begin
with). In the next section, we illustrate how an analysis of
information utilization strategies can be based on an instructional approach and its underlying cognitive processes.

Defining Information Utilization Strategies for
an Example-based Hypermedia Environment
For our study we chose the instructional approach of example-based learning to illustrate the claim that research on
hypermedia learning can be improved by analyzing learners’ strategies of information utilization in terms of the instructional approach implemented in the hypermedia system: The advantage of choosing example-based learning is
that there are already many findings on cognitive strategies
supporting this instructional approach – many of them being
based on cognitive load theory (CLT, Sweller, 1999).
The CLT is an instructional design theory that specifies
helpful conditions for cognitive skill acquisition. These
skills are assumed to be represented as problem schemas.
Many of the instructional settings analyzed on the basis of
cognitive load theory involve the use of worked-out examples for conveying problem schemas, as examples have
been shown to be very successful for this purpose at least
for novice learners (cf. Atkinson, Derry, Renkl, &
Wortham, 2000). CLT assumes a direct causal relationship
between a specific instructional design, cognitive activities,
the resulting pattern of cognitive load, and the learning outcomes is assumed. Recently, Gerjets and colleagues (Gerjets
& Hesse, 2004; Gerjets & Scheiter, 2003) have extended the
CLT so that it can be used to analyze learner-controlled settings, where learners can select among different strategies of
handling the instructional materials. In the augmented CLT,
it is thus proposed that whether an instructional design results in either helpful or harming cognitive load depends on
learners’ strategies of information utilization. Moreover,
learner characteristics are included as factors that may influence strategy selection. The augmented CLT may thus serve
as a framework for analyzing information utilization strategies in example-based hypermedia environments.
From a cognitive load perspective, effective information
utilization strategies with respect to examples consist in

selecting examples that facilitate cognitive processes relevant to the acquisition of problem schemas. Examples that
support schema acquisition have the following characteristics: First, effective examples reduce the intrinsic load inherent to the domain (cf. Gerjets, Scheiter, & Catrambone,
2004). Second, examples that foster schema acquisition
keep extraneous cognitive load, which results from cognitive processes not relevant to learning, at a minimum. Third,
they facilitate higher-level cognitive processes that go beyond the mere activation of information in working memory, and that result in germane cognitive load. These processes consist in example elaborations and comparisons.
Elaborations occur when learners draw inferences concerning the structure of example solutions, the rationale behind
solution procedures, and the goals that are accomplished by
individual solution steps (i.e.. self-explanations, Renkl,
1997). Beyond self-explanations, learners should engage in
example comparisons in order to notice structural features
that differ among problem categories and that are shared by
problems within a category (Quilici & Mayer, 1996).
Based on these characteristics, four groups of example
utilization strategies were identified: Learners should retrieve examples that (1) result in low intrinsic cognitive
load, (2) support processes of comparison (3) stimulate selfexplanations, (3) and compensate for lacking selfexplanations. In the following, these strategies will be illustrated in the domain of probability theory, where extensive
research has been done on the differential effectiveness of
different example formats in system-controlled settings. In
the hypermedia environment used in the study all these example formats were included and learners could select
among formats that had been proven either effective or noneffective in the prior system-controlled studies.

Low Levels of Intrinsic Cognitive Load
A low intrinsic cognitive load has been found for modular
rather than molar examples (Gerjets et al., 2004; Gerjets,
Scheiter, & Catrambone, 2006). Molar examples have a
recipe-like structure and refer to complex entities like problem categories, clusters of structural task features, and category-specific solution procedures. In modular examples,
solution procedures are broken down into smaller meaningful groups of solution steps that can be understood in isolation. They require learners to keep only a limited number of
elements active simultaneously in working memory. Evidence for the superiority of modular examples was found in
terms of learning time, self-reported cognitive load, and
later problem-solving performance for isomorphic and novel
problems (Gerjets et al., 2004, 2006). Accordingly, an effective example utilization strategy consists in preferring
modular over molar examples.

Supporting Example Comparisons
Comparing examples with different surface features within
problem categories and comparing examples with similar
surface features across categories are both helpful cognitive
processes to identify the relevant structural problem features

2118

of problem categories (Scheiter & Gerjets, 2005). Comparing examples with different surface features within categories may help to identify varying features, which must be
irrelevant for category membership, while commonalities
may indicate structural features. On the other hand, comparing examples with the same surface features across
problem categories may highlight structural differences
among the examples. In general, differences among instances become more salient, the more other features are
shared by them. Thus, for comparisons examples should be
selected that differ with regard to only a few features, which
can then be identified and interpreted more easily.

sist in retrieving modular examples, in comparing examples
that differ only in a few, but relevant features, and in finding
the right balance between using examples with or without
self-explanation prompts and explanations depending on
their level of understanding. This also implies that strategy
patterns should be analyzed rather than investigating the
effects of single strategy variables in isolation. This is why a
cluster-analytical approach was preferred over conducting
correlational analyses.

Study
Method

Stimulating Self-explanations
Self-explanations are an important aspect of meaningfully
processing examples although they seldom occur spontaneously (Renkl, 1997). Self-explanations can be fostered by
presenting incomplete examples whose gaps need to be
filled in (Paas, 1992), by presenting prompts that ask learners to generate self-explanations (Berthold & Renkl, 2005),
or by a combination of both methods (Atkinson, Renkl, &
Merrill, 2003). However, in our own studies we could not
find any beneficial effects of prompting learners to give an
explanation for why a specific step to solve a probability
problem had been selected (Gerjets et al., 2006). In fact,
while self-explanation prompts did not affect learning from
molar examples, they even hindered learning from modular
examples. We explained these results by assuming that
learners in the modular-examples condition were forced to
generate self-explanations for material that they had already
sufficiently understood and that was thus redundant to them.
Accordingly, one might argue that at least for those learners
who have already understood the principles illustrated, an
effective example utilization strategy might consist in not
retrieving examples that contain self-explanation prompts.
On the other hand, it might well be that if learners can decide by themselves whether to select these examples, only
learners who need processing support will retrieve them.

Participants. Seventy-six students of the University of
Tuebingen, Germany, were paid to participate in the study.
Average age was 25.0 years (32 male, 44 female).
Materials and Procedure. We used a hypermedia environment that taught learners how to calculate the probability
of complex events. It consisted of an example-based learning phase, and a test phase with problem-solving tasks, and
a declarative knowledge test. In the learning phase, each of
four problem categories was explained by two worked
examples, which differed with regard to their cover story:
Always one example dealt with selecting marbles from an
urn, while the other was related to daily-life situations.
Thus, the same surface features were used across categories
for the urn examples, but varied for the daily-life examples.
To access an example, learners first had to select one of
the problem statements from the left navigation bar (Figure
1). The problem statement was then displayed on the format-selection page together with eight links that allowed
retrieving different formats for the presentation of the solution procedure. These formats varied with regard to the solution approach by offering either molar or modular structured solution procedures and with regard to the degree of
elaboration and completeness of examples.

Compensating for Lacking Self-explanations
Students often overestimate their understanding of examples
and thus refrain from further elaborating them. Moreover,
even if they have noticed gaps in their knowledge, they may
not be able to generate self-explanations to overcome those
gaps. These problems may be solved by providing additional instructional explanations, particularly for learners
with low prior knowledge. Doing so can show learners that
they suffer from an illusion of understanding and may help
them to overcome comprehension difficulties. Thus, an effective example utilization strategy for novices would be to
retrieve examples with instructional explanations. However,
as explanations sometimes do not affect learning (Gerjets et
al., 2006) or are even harmful because they hinder learners
in generating explanations by themselves (Aleven & Koedinger, 2000), learners should retrieve them only if they cannot produce explanations by themselves.
To conclude, effective example utilization strategies con-

Incomplete examples with feedback

Incomplete examples with feedback

Figure 1: The format-selection page
Highly-elaborated examples provided detailed explanations
for why a solution step had been chosen. Mediumelaborated examples mentioned facts concerning the solu-

2119

tion steps, but no further explanations were given, while in
low-elaborated examples only the mathematical information
was given.Moreover, incomplete examples with selfexplanation prompts / feedback could be selected. Here the
solution procedure was medium elaborated and learners
were prompted to provide the missing explanations by
themselves. After they had typed in the explanation, a feedback page appeared, which contained the learner’s response
and the system-provided expert explanation. This procedure
had to repeated until explanations had been given for all
solution steps; only then another example could be selected.
In total, learners could choose among 64 options (i.e., 8
problem statements x 8 solution formats). All participants
received the same options to retrieve examples. Learners
could decide on their own when to enter the test phase.

knowledge was assessed by domain-unspecific and specific
indicators (i.e., final high school grade, math grade, and
performance in a declarative pretest, which was the same as
the declarative posttest).

Results

Analyses and Measures. The analyses consisted in three
steps: First, the students’ example utilization strategies were
subjected to a cluster analysis to identify learner groups
with distinct strategies. Second, the relationship between
group membership and learning outcomes was investigated.
Third, it was tested whether the groups differed with regard
to individual learner characteristics.
The variables used to describe example utilization strategies were the overall example study time, the overall frequency of retrieving examples, the frequency of retrieving
either modular or molar examples as well as the frequency
of retrieving either highly-elaborated, medium-elaborated,
low-elaborated or incomplete examples. Moreover, we assessed the time spent on the format-selection page as a potential indicator for meta-cognitive awareness. Beyond these
measures for the selection and pacing of information, sequencing activities were registered by Markov-chain analyses. The resulting variables comprised the number of transitions between the examples’ cover stories, the average
number of dimensions changed within a transition from one
example to another (e.g., ‘1’ for only changing the degree of
elaboration vs. ‘4’ for changing the cover story, solution
approach, degree of elaboration, and the category in parallel), and the number of transitions between the molar and
modular solution approach. These variables were supposed
to provide information on learners’ comparison strategies.
The dependent measures consisted in overall performance
for solving three isomorphic and six novel problems and in
the declarative knowledge test. For each of the nine test
problems as well as for the eleven items of the declarative
posttest one point was assigned for a correct answer; no
partial credit was given. Moreover, we assessed individual
learner characteristics, which were expected to be associated with strategy selection. These included a questionnaire
on cognitive and meta-cognitive strategies in mathematics
(Wolters, 2004), the Epistemological Beliefs Instrument
(Jacobson & Jehng, 1999), the Attitudes Towards Mathematics Inventory (Tapia & Marsh, 2004) and items to assess
the preference for amount of instruction (Hannafin & Sullivan, 1996). The original questionnaires were slightly modified and shortened in order not to overwhelm students. Prior

To identify groups of learners that differ in their example
utilization strategies, a cluster analysis (based on the Ward
algorithm) was performed on the strategy variables. The so
called ‘elbow-criterion’ was used to stop the clustering
process after four clusters had been identified. A threeclusters solution would have increased the within-group
variance for the new cluster substantially and thus would
have resulted in a loss of information.
For the four-clusters solution, the groups of learners
differed significantly in their example utilization strategies
(with the exception of ‘number of transitions between the
cover stories’ and ‘number of dimensions changed within
one transition’, cf. Table 1). Cluster 1 – called the unreflective-intermediate example users –spent less time on
selecting examples than students of Clusters 3 and 4. They
studied the selected examples more intensively than students
in Clusters 2 and 3, but less than students in Cluster 4. The
longer overall example time was the only variable that distinguished between Cluster 1 and 2. Cluster 2 – the unreflective-lazy example users – did invest less time on reflecting on the appropriateness of the different formats for displaying the solution procedure and on processing examples
than any of the other clusters. Moreover, students in Cluster
2 refrained from switching between modular and molar examples compared to students in Clusters 3 and 4 and did not
control for possible illusions of understanding compared to
Cluster 4 students. Cluster 3 – the reflective-sparse example
users – seemed to make well thought-over decisions regarding the solution procedure’s format. Learners in this
group processed an intermediate number of examples comparable to that of students in Cluster 1, but used less time to
study them. Cluster 4 – the excessive example users – spent
less time on the format-selection page than students of
Cluster 3, but retrieved the most examples, which were
moreover extensively processed. In particular, they differed
from the other groups in their frequent use of molar and of
incomplete examples.
In a second step, problem-solving performance and performance in the declarative knowledge test were analyzed
by an ANOVA using group membership as a betweensubjects factor. Unreflective-intermediate example users and
unreflective-lazy example users both performed poorly in
the problem-solving task, while reflective-sparse example
users and excessive example users performed rather well.
These differences across the four groups were significant
(F(3,72) = 5.13; p < .01), while post-hoc comparisons highlighted differences between Clusters 1 and 3, and Clusters 2
and 3, respectively. Conducting the same ANOVA for the
declarative knowledge test revealed slightly different results
(F(3,72) = 3.72; p < .05). Unreflective-intermediate example

2120

Table 1: Example utilization and performance in the four clusters
Means
CL 1
CL 2
CL 3
(n = 21) (n = 12) (n = 34)
Time (sec)
Format selection **
Overall
**

1.95
11.12

1.83
3.20

8.30
8.02

Results of the post-hoc Tukey tests
CL 1 - CL 1 - CL 2 - CL 2 CL 3
CL 4
CL 3
CL 4

CL 4
(n = 9)

CL 1 CL 2

5.33
25.89

ns
**

**
**

*
**

**
**

*
**

*
**

ns
ns
ns
ns
ns
ns
ns

ns
ns
ns
ns
(*)
*
ns

**
**
ns
ns
*
ns
ns

**
ns
ns
ns
(*)
ns
ns

**
**
(*)
*
*
ns
**

**
**
ns
ns
ns
ns
**

ns
ns
ns

ns
ns
*

ns
ns
**

ns
ns
*

ns
ns
**

ns
ns
ns

ns
ns
ns

*
*
*

ns
*
ns

*
ns
ns

ns
ns
ns

ns
ns
ns

Frequencies
Overall
**
15.00
10.33
19.24
31.11
Molar
**
7.62
4.50
8.91
16.56
Modular
*
6.62
5.67
9.88
13.44
Highly-elab.
*
8.38
3.00
7.00
10.89
Medium-elab.
**
1.90
1.00
5.15
7.44
Low-elab.
*
1.57
5.75
5.68
6.22
Incomplete
*
3.14
0.58
1.41
6.56
Transitions
Cover story
ns
1.48
1.42
1.41
1.44
Dimensions
ns
1.53
1.58
1.50
1.45
Approach
*
2.33
1.00
6.18
9.56
Performance (%)
Problem-solving
29.87
25.67
50.80
48.48
Declarative knowledge
76.19
84.09
86.10
98.90
High school grade
2.29
2.28
1.87
2.20
Note: ns = not significant; ** = p ≤ .01; * = p ≤ .05; (*) = p ≤ .10.
users achieved 76.19% correct in the test, which was less
then for the reflective-sparse and excessive example users.
There were no other differences among the groups.
Contrary to our expectations, there were no differences between the four groups with regard to individual learner
characteristics with the exception of the final high school
grade (F(3,72) = 3.02; p < .05). Reflective-sparse example
users had better high school grades than unreflectiveintermediate example users.

Summary and Discussion
We were able to demonstrate that the analysis of information utilization strategies that have been defined with respect
to a specific instructional approach implemented in a hypermedia learning environment helps to identify groups of
learners with distinct strategy patterns. These strategy patterns can account for differences in subsequent problemsolving performance as well as in declarative knowledge
acquisition. Interestingly, more than one effective strategy
pattern could be identified: First, an excessive example
utilization proved to be successful, even though these students preferred examples with a high intrinsic cognitive load
(i.e., molar examples). One possible explanation for the latter might be that these students at the same time most frequently monitored their understanding by selecting incomplete examples. Thus, they might not have chosen the most
efficient strategy – which would have been to focus on
modular examples – but compensated for that by a very
thorough example processing. Second, learners also performed well when using examples only sparingly. In the

CL 3 CL 4

latter case, the display format for the solution procedure
seemed to have been rather carefully selected as indicated
by the time spent on the format-selection page. Thus,
studying only a few examples can be an effective strategy as
long as one invests more thinking on selecting the most
suitable examples (i.e., meta-cognitive effort). Moreover,
the time spent on the format-selection page might also be
interpreted as a learner’s attempt to reason about a possible
solution to the problem, before looking at a specific solution
procedure (cf. anticipative reasoning, Renkl, 1997). Interestingly, learners with this example utilization strategy had
better average high school grades than at least one of the
other groups. This might indicate better general abilities that
help to regulate one’s learning activities in an efficient way.
Contrary to results by Renkl (1997) or Lawless and
Kulikowich (1997), learners with this efficient, but probably
knowledge-rich strategy formed a large group in our sample.
While the pacing and selection variables were suited to
distinguish among different behavioral patterns, the sequencing variables only accounted for a small part of the
variance. These variables were problematic, because they
were defined at a very coarse level making it hard to interpret them unambiguously. For instance, looking only at examples from different problem categories embedded in the
same cover story might be as effective as repeatedly comparing examples within a problem category embedded into
different cover stories – both strategies resulting in completely different values for the respective variable. Thus, in
the future a more fine-grained definition and analysis of
sequencing strategies needs to be deployed.

2121

Unfortunately, although we assessed a variety of learner
characteristics, we could not identify characteristics that
differentiated between different example utilization groups.
We used constructs that have been identified as being relevant to learner-controlled instruction in the literature from a
theoretical perspective and we selected the most reliable
measures available to assess these constructs. Thus, there
might be something wrong with questionnaires that assess
cognitive and meta-cognitive knowledge and attitudes in
general. Accordingly, Winne, Jamieson, and Muis (2001)
have suggested using unintrusive data like logfiles not only
to analyze strategic behavior, but also to interpret this data
as indicators for meta-cognitive abilities. Moreover, most of
the questionnaires that have been used to predict behavior in
learner-controlled settings assess global cognitive and metacognitive abilities rather than domain-specific ones.
Beyond these methodological difficulties, analyzing the
way learners make use of the information provided seems to
be a more fruitful approach to investigating hypermedia
than global media comparisons. The latter fail to consider
the specific characteristics of the media and thus produce
ambiguous results. Analyses of learners’ information utilization may furthermore help to improve instruction by informing the design of strategy prompts and trainings to support students in learning with hypermedia.

References
Aleven, V., & Koedinger, K. R. (2000). Limitations of student control: Do students know when they need help? In
G. Gauthier, C. Frasson, & K. VanLehn (Eds.), Proceedings of the 5th International Conference on Intelligent
Tutoring Systems (pp. 292-303). Berlin: Springer.
Atkinson, R. K., Derry, S. J., Renkl, A., & Wortham, D.
(2000). Learning from examples: Instructional principles
from the worked examples research. Review of Educational Research, 70, 181-214.
Atkinson, R. K., Renkl, A., & Merrill, M. M. (2003). Transitioning from studying examples to solving problems:
Combining fading with prompting fosters learning. Journal of Educational Psychology, 95, 774-783.
Balcytiene, A. (1999). Exploring individual processes of
knowledge construction with hypertext. Instructional Science, 27, 303-328.
Barab, S. A., Bowdish, B. E., Young, M. F. & Owen, S. V.
(1996). Understanding kiosk navigation: Using log files to
capture hypermedia searches. Instructional Science, 24,
377-395.
Berthold, K., & Renkl, A. (2005). Fostering the understanding of multi-representational examples by selfexplanation prompts. In B. G. Bara, L. Barsalou, & M.
Bucciarelli (Eds.), Proceedings of the 27th Annual Conference of the Cognitive Science Society (pp. 250-255).
Mahwah, NJ: Erlbaum.
Dillon, A., & Gabbard, R. (1998). Hypermedia as an educational technology: A review of the quantitative research
literature on learner comprehension, control, and style.
Review of Educational Research, 68, 322-349.

Gerjets, P. H., & Hesse, F. W. (2004). When are powerful
learning environments effective? The role of learner activities and of students’ conceptions of educational technology. International Journal of Educational Research,
41, 445-465.
Gerjets, P., & Scheiter, K. (2003). Goal configurations and
processing strategies as moderators between instructional
design and cognitive load: Evidence from hypertext-based
instruction. Educational Psychologist, 38, 33-41.
Gerjets, P., Scheiter, K., & Catrambone, R. (2004). Designing instructional examples to reduce intrinsic cognitive
load: Molar versus modular presentation of solution procedures. Instructional Science, 32, 33-58.
Gerjets, P., Scheiter, K., & Catrambone, R. (2006) Can
learning from molar and modular worked-out examples be
enhanced by providing instructional explanation and
prompting self-explanation? Learning and Instruction, 16,
104-121.
Hannafin, R. D., & Sullivan, H. J. (1996). Preferences and
learner control over amount of instruction. Journal of
Educational Psychology, 88, 162-173.
Jacobson, M. J., & Jehng, J-C. (1999). Epistemological beliefs instrument: Scales and Items. [Unpublished manuscript]
Lawless, K. A. & Kulikowich, J. M. (1996). Understanding
hypertext navigation through cluster analysis. Journal of
Computing Research, 14, 385-399.
Paas, F. G. W. C. (1992). Training strategies for attaining
transfer of problem-solving skill in statistics: A cognitiveload approach. Journal of Educational Psychology, 84,
429-434.
Quilici, J. L. & Mayer, R. E. (1996). Role of examples in
how students learn to categorize statistics word problems.
Journal of Educational Psychology, 88, 144-161.
Renkl, A. (1997). Learning from worked-out examples: A
study on individual differences. Cognitive Science, 21, 129.
Scheiter, K., & Gerjets, P. (2005). When less is sometimes
more: Optimal learning conditions are required for
schema acquisition from multiple examples. In B. G.
Bara, L. Barsalou, & M. Bucciarelli (Eds.), Proceedings
of the 27th Annual Conference of the Cognitive Science
Society (pp. 1943-1948). Mahwah, NJ: Erlbaum.
Sweller, J. (1999). Instructional design in technical areas.
Camberwell: ACER.
Tapia, M. & Marsh, G. E. (2004). An instrument to measure
mathematics attitudes. Academic Exchange Quarterly, 8,
2534-2541.
Winne, P. H., Jamieson-Noel, D. & Muis, K. (2001). Methodological issues and advances in researching tactics,
strategies, and self-regulated learning. New Directions in
Measures and Methods, 12, 121-155.
Wolters, C. A. (2004). Advancing achievement goal theory:
Using goal structures and goal orientations to predict students’ motivation, cognition, and achievement. Journal of
Educational Psychology, 96, 236- 250.

2122

