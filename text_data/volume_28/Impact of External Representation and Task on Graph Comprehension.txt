UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Impact of External Representation and Task on Graph Comprehension

Permalink
https://escholarship.org/uc/item/21t770pn

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Ferres, Leo
Lindgaard, Gitte
Rasouli, Maria
et al.

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Impact of External Representation and Task on Graph Comprehension
Avi Parush (avi_parush@Carleton.ca), Leo Ferres (lferres@ccs.carleton.ca),
Maria Rasouli (mariarasouli@gmail.com), Gitte Lindgaard (Gitte_Lindgaard@carleton.ca)
Department of Psychology, Carleton University, 1125 Colonel By Drive
Ottawa, ON K1S 5B6 Canada

Abstract
This study examined the relationship between the external
representation, verbal encoding vs. visual encoding, of graph
information and the impact on graph comprehension. Graph
comprehension tasks included responses to true/false
statements addressing global and local graph information,
visual recognition, and graph drawing. The findings suggest
that the specific modality of the external representation play a
role in the encoding and retrieval of some aspects of global
vs. local graph information. The findings are discussed with
reference to theories of spatial cognition.

Introduction
Numerical data is often externally represented in graphical
visualizations to convey information that otherwise would
be harder to extract from numbers presented in tables. The
advantages of visual graphical presentations (such as bar,
pie, line, charts) have been studied extensively (e.g., Meyer,
Shinar, & Leiser, 1997). People, however, do not only look
at graphs or data tables but also talk about them. Many tasks
we perform with data graphs require the use of words to
complete the task. For example, one may be asked to
describe in words the annual trend in stock behavior of a
certain company based on a graph. Or a mathematics
teacher describes the graph she just drew on the blackboard
to her students. Moreover, there is an increasing need to
convey graph information also in verbal form. Examples
include people with visual impairments who often need to
utilize graph information, or people discussing graph
information via online channels such as email, chats, or
discussion boards, etc for training, education, or business
purposes. The question is: what is the impact of such
diverse external representations of numerical data, i.e.,
visual depictions vs. verbal descriptions, on graph
information encoding and comprehension? The objective of
the study reported here was to examine the impact of the
external representation, graph and verbal description, on
simple tasks of graph comprehension.
There is a growing need to present graph information in
modalities other than the visual. One such need emerges
from the community of people with a visual impairment.
This major obstacle prevents the access to much information
visualized graphically and it has been recognized and
addressed (e.g., Brown, Brewster, Burton, Riedel, &
Ramloll, 2003). Some of the more researched technological
solutions include haptic or tactile displays (e.g., Challis &
Edwards, 2001; Sjostrom, Danielson, Magnusson, &
Rassmus-Grohn, 2003). Another approach is to use nonspeech sounds or sonifications to convey the information

1932

expressed in visual graphs (e.g., Brown et.al, 2003; Flowers,
Buhman, & Turnage, 1997). The growing need to present
graph information in other modalities also emerges from the
real and online, virtual world of communication,
collaboration, training, and education (e.g., Pimm, 1987;
Kramarski, 2002). This is particularly evident in teaching
mathematics and the graphing of numerical information
where there is a need to describe graphs in words. Taken
together, such technological trends and research directions
reflect the need to study the impact of various external
representation of graph information and re-examine the
current theoretical approaches to graph comprehension,
particularly with respect to verbal encoding.
There are several commonly cited theories of graph
comprehension (Carpenter & Shah, 1998; Freedman &
Shah, 2002; Lohse, 1993; Pinker, 1990). Pinker (1990), for
instance, suggests that a propositional representation is
formed on the basis of a visual array constructed from the
visual graph. Such a representation can trigger the
appropriate graph schema which helps extract the required
information from the graph. Similar to Pinker, Lohse (1993)
also postulates the presence of a graph schema, although he
never explicitly indicates if the representation is
propositional. Freedman and Shah (2002) outline a model
of graph comprehension that is based on the constructionintegration theory of text comprehension.
In the
construction phase, the graph viewer perceives the visual
features of the graph, including the peripheral information
such as axes, labels and legends. During the integration
phase, the visual features are comprehended based also on
previous experience and domain knowledge, which is again
reminiscent of Pinker’s graph schema. It is interesting that
the theories imply a propositional representation of graph
information while primarily addressing the visual, pictorial
external representation of graph information rather than
verbal external representations of graphs.
There are very few studies looking at the verbal
descriptions of graphs (e.g., Carswell, 1993; Carswell et.al.,
1998; Shah, Hagerty, & Mayer, 1999; Katz, Xi, Kim, &
Cheng, 2002). Katz et.al. (2002), for instance, proposed a
theory of graph comprehension that also accounts for the
aspects of communicating graph descriptions within the
context of tests of spoken English. The main premise of
their theory is the visual chunks hypothesis, where fewer
visual chunks can lead to better verbal communication of
graph information. However, even this approach did not
address the issue of encoding graph information through a
verbal, natural language description.
The main question of this research is: what is the impact
of encoding graph information through verbal descriptions

as compared to visual encoding? A follow-up question is:
can any of the current theoretical approaches account for
such potential impact? Some theoretical approaches suggest
that graph cognition is associated with processes of spatial
transformation (e.g., Trickett & Trafton, 2004; Webber &
Feeney, 2002; Feeney & Webber, 2003). However, these
studies did not extend or link their discussion to spatial
cognition which may provide some new insights on graph
cognition.
Similar to graphs, people can use words to describe the
area they live in or what they learned from a map. People
can also draw a map of an area they directly experienced or
learned from a verbal description (e.g., Taylor & Tversky,
1992a, 1992b, 1996; Tversky and Lee, 1998). Such
everyday anecdotes and research findings are indicative of
our ability to encode, retrieve, and reason with spatial
information both in image-based and verbal formats.
Based on such empirical similarities and theoretical links
between graph and spatial cognition, we have adopted here
the general experimental paradigm used in spatial cognition
to examine the relationships between image-based and
verbal information encoding. Tversky and Lee (1998)
compared route descriptions (verbal) and route maps
depictions (image-based) and found that both verbal
descriptions and map drawings had a similar structure (e.g.,
starting and ending landmarks) and content. Tversky and
Lee (1999) examined whether people can construct a
meaningful whole verbal route description or route map
depiction from limited spatial information given as either
graphical depictions or verbal expressions. They found that
participants did construct whole maps or verbal directions
from the partial information given in each format. In the
graph comprehension study reported here we also asked
participants to encode graph information in different
external
representations
and
then
tested
their
comprehension.
In addition, the approach adopted here is partially based
on the experimental paradigm suggested by Feeney, Hola,
Liversedge, Findlay and Metcalf (2000). They suggested an
experimental paradigm in which participants need to
indicate whether the information in a simple graph matched
a verbal written description of the graph. The sentencegraph verification paradigm was appropriate here for
examining the relationship between the verbal encoding vs.
visual encoding of graph information.

graph information consisted of a visual presentation of a line
graph (see example in figure 1), a written-verbal description
of the graph, and a spoken-verbal description of the graph.
There were three graph cognition tasks each performed by
a different group of participants to avoid carry-over effects
and provide a within-participant comparison between the
three external representations. Participants in group 1
responded to true/false statements about the graphs. The
true/false statements consisted of two categories: global
(overall pattern), and local (specific values). The global,
overall pattern category included two statements: 1. Increase
or decrease trends between certain x values (e.g., There is an
increase between X2 and X3); 2. The relationships between
two y values with respect to which is higher or lower, (e.g.,
the value at X3 is higher than the value at X5). The local,
specific values category included two statements: 1. The y
value for a specific x point (e.g., the value for X5 is 52); 2.
The highest or lowest y value (e.g., the highest value is 97).
Each graph was assigned four statements, one of each
statement type.
Group 2 received a visual recognition task. The
recognition task required the participant to view four line
graphs, one of which was the test graph (presented in one of
the three modes), and the other three served as distracters.
Finally, group 3 received a graph drawing task. The task
required participants to draw the graph from memory. The
drawing was performed on a blank page.

Figure 1: Example of a simple line graph used in this
experiment.

Apparatus and Stimuli

Method

The experimental stimuli were generated by a prototype
application that automatically provides descriptions of
graphs and allows for natural language interaction with a
given graph (the inspectGraph system or iGraph). Input to
the system comprised the encoding of the necessary
properties of a graph in the EXtended Markup Language
(XML) format (titles of the axes, values and the interval
labels for the X-Axis). To allow for the description and the
querying, our system implements the three following
subsystems. The first takes the XML, parses it and writes a
logic version of the given graph, together with several
mathematical properties of the input graph (minimums and
maximums, slope of the increase or decrease between two
points, etc). The second subsystem stores different kinds of
rules for describing and querying the logic-mathematical
version of the input graph generated by the P-System. We
call this the C-System. Third, the language subsystem takes

Participants
A total of 37 people participated in the study. This sample
was divided into three groups; each performed a different
graph comprehension task. There were 15 participants for a
visual recognition task, 18 for a true-false questions task,
and 10 for a graph drawing task. All participants were
undergraduate students at Carleton University.

Study Design
Impact of graph external representation was tested as a
within-participant factor. External representation of the
1933

the logic-like representations (and, in principle, all possible
inferences) from the rest and second subsystems and outputs
a natural language text (both as a description and/or as the
response to a query) plus the handling of a dialogue
modeling algorithm for querying the graph. We call this the
L-System.
The following verbal description was generated by
inspectGraph for the line graph presented in figure 1: “The
graph starts at 10 at x0. There is an increase at x1 to 27.
There is an increase at x2 to 30. There is an increase at x3 to
98. There is a decrease at x4 to 37. There is an increase at
x5 to 84. Finally, there is a decrease at x6 to 71”. Note that
at present, the verbal output includes a straightforward
description of each point and its relationship to the
preceding neighboring point. This verbal description can
either be presented as text or be synthesized into a spoken
description.
A total of 36 different line graphs were generated. The 36
graphs were divided into the three external representations:
12 graphs presented as a visual depiction, 12 as a written
description displayed on the test monitor, and 12 as a
spoken description.

The largest differences between the two statement
categories, global and local, were found for the visual
encoding condition. Post hoc comparisons showed that the
mean number of correct responses to statements in the
overall pattern category was higher than responses to the
specific values category when graph information was
encoded from a visual graph. Such large difference was not
found when encoding was based on verbal description,
visual or spoken.

Mean Correct Responses to T/F
Questions

10
9
8
7
6

Global

5

Local

4
3
2
1
0
Written Description

Visual Graph

Spoken Description

External Representation

Procedure
Participants were randomly assigned to one of the three
graph cognition tasks. Each participant was presented with
all 36 graphs. The order of graph presentations in any one
of the three external representations was randomized across
participants.
Participants started with the first presentation, viewing a
graph, reading a graph description, or listening to a graph
description. After each graph presentation, participants
completed the relevant task, then went on to the next graph,
completed the task, and so on until all 36 graphs had been
presented. Exposure times for the three presentation modes
were X and were determined by preliminary pilot trials with
a few users. It should be emphasized that the graph
depiction or verbal description were not available to
participants while performing the task.

Results

Figure 2: Mean number of correct responses to true/false
questions by question category as a function of encoding
modalities.
Response Times Mean response times for each of the four
statements were computed as a function of external
representation. A two-way ANOVA with repeated measures
(3 modalities by 4 statements) was performed to test the
impact of external representation and statements on
response times. The interaction was significant (F6,102=3.7,
p=0.01). Since similar patterns were found for both
statements in each category, an overall mean correct
response was calculated for each category and an additional
two-way ANOVA with repeated measures (3 modalities by
2 categories) was performed to test the impact of external
representation and statement category. This interaction was
also significant (F2,34= 7.5, p=0.003) as can be seen in figure
3.

True/False Questions

1934

Mean RT to T/F Questions

7000

Correct Responses The mean number of correct responses
was computed for each of the four statements (two global
and two local) as a function of the external representation. A
two-way ANOVA with repeated measures (3 modalities by
4 statements) was performed to test the impact of external
representation and statement. There was a significant
interaction (F6,102=7.1, p=0.00) between the two variables.
Since similar patterns were found for both statements in
each category, an overall mean correct number of responses
was calculated for each category. An additional two-way
ANOVA with repeated-measures (3 modalities by 2
categories) was performed to test the impact of external
representation and statement category and it also yielded a
significant interaction (F2,34= 22.5, p=0.00). This interaction
is shown in figure 2.

6000
5000
4000

Global

3000

Local

2000
1000
0
Written Description

Visual Graph

Spoken Description

External Representation

Figure 3: Mean times in ms to respond to true/false
questions by question category as a function of encoding
modalities.

The figure shows that mean response times for the
statements in the global category were longer than response
time to local statements for all three encoding modalities.
Post-hoc comparisons showed that response times for the
spoken graphs did not differ for the two statement categories
whereas it did for the visual and textual modes.

Drawing

between global and local aspects. It took significantly longer
to respond to true/false statements addressing global
information (i.e., overall trends) compared to responding to
statements on local information (specific values) in the test
graphs. These findings are generally in line with previous
research suggesting that it is more difficult and takes longer
to answer questions on global information than on local
information (e.g., Ratwani, Trafton, and Boehm-Davies
2003).
In addition, when encoding was based on a visual graph,
there were significantly more correct responses to the
global-information questions than to the local information
questions. No such differences were found when encoding
was based on the verbal written or spoken descriptions. It
should be emphasized that mean number of correct
responses to local information was significantly lower in the
visual graph encoding condition than in the written and
spoken verbal encoding conditions.
The impact of the external representation was also found
with one part of the drawing task. Correctly drawing the
highest and lowest points in the graph was significantly
better in the visual graph encoding condition than in the
spoken verbal description condition. No differences were
found between the visual graph encoding and the spoken
verbal description in drawing all the inter-point trends.
While inter-point trends can be viewed as global graph
information, the lack of difference between the two
modalities can be accounted for by the fact that the verbal
descriptions included explicit trend information such as:
“There is an increase at x2 to 30”. Finally, the visual graph
encoding was associated with the best performance in the
straightforward task of visual recognition of the test graph.
The superior performance was observed with both the
number of correct responses and with a shorter response
time of the recognition.
Taken together, the findings here reflect a relationship
between the external representation of graph information
and graph comprehension performance. More specifically,
the particular modality of the external representation seems
to play a role in the encoding and retrieval of some aspects
of global vs. local graph information.

Two indices were computed to reflect goodness of graph
drawing. Index 1, number of correctly drawn inter-point
trends, increase or decrease (with a maximum of six correct
trends in the graphs used here). Index 2, number of correctly
drawn highest and lowest points (with a maximum of two in
the graphs used here). Due to a technical problem in
encoding the data from the written description encoding
condition, only the visual graph and spoken description
conditions were analyzed.
Paired-samples Student t-tests were performed to test the
impact of encoding modality on the two map drawing
goodness indices. A significant difference was found for
index 2. When encoding was based on the visual graph, the
mean number of correct drawings of the highest and lowest
points (mean = 1, SE = 0.11) was higher than the spoken
description encoding (mean = 0.7, SE = 0.10). No
significant difference was found between the two modalities
for the number of correctly drawn inter-point trends.

Visual Recognition
The mean number of correct responses was computed for
the visual recognition tests for each of the three encoding
modalities. A one-way ANOVA with repeated measures
performed to test the impact of encoding modality on
success in the recognition task resulted in a significant main
effect (F2,28= 4.6, p<0.05). The mean number of correct
recognition responses was highest for the visual encoding
condition (mean = 11, SE=0.2) as compared with the written
description encoding (mean= 9.7, SE= 0.6) and the spoken
description (mean = 9.6, SE= 0.5).
The one-way ANOVA computed for the mean
recognition response times in the three encoding conditions
was significant (F2,28= 40.4, p=0.00). Response times were
shorter for the visual encoding condition (mean = 6627ms,
SE=566) than for the written description encoding (mean=
13407ms, SE= 947) and the spoken description (mean =
14528ms, SE= 1060).

Discussion

Theoretical Implications

Summary of Findings
Generally, the findings here show that people can encode
graph information from a verbal description in natural
language. A verbal description, either written or spoken,
was associated with graph comprehension performance that
occasionally was equivalent to the performance with visual
encoding.
When graph information was encoded visually or in
written verbal descriptions, durations of graph
comprehension performance were significantly different
1935

Impact of external representation What are the
theoretical implications of the ability to encode and
comprehend graphs, both verbally and image-based? The
findings here reveal two aspects in graph comprehension as
a function of the external representation. One, visual graph
encoding leads to better performance with global graph
information whereas verbal descriptions are less sensitive to
differences between global and local information. This is
indirectly in line with findings comparing tables and graphs
(e.g., Meyer et.al., 1997) where graphs have an advantage
when the task requires comprehension of relationships and
trends (global features here) as opposed to specific values
(local features here). The second aspect is the possible
speed-accuracy tradeoff associated with visual encoding
conditions. The findings here suggest that while it may take
longer to answer questions on global aspects, the responses
are more accurate when graph information was encoded

visually. Can this imply that graph information encoded
visually may be internally represented differently from
verbal encoding? As will be discussed in the next paragraph,
such implication is not supported by some of the theoretical
approaches in spatial cognition.
Paivio (1969, 1991) suggested the dual-coding theory
addressing the way in which visual and non-visual
information is encoded and represented. Dual-coding theory
suggests that memory consists of two separate but interrelated codings and representations, verbal and visual. The
inter-connections allow for dual-coding of information
received in one modality. In spatial cognition, Tversky
(1991) and Cohen (1996) suggested that mental models of
the environment are based on analogue visuo-spatial codes
and abstract propositional codes. Tversky and Lee (1999)
postulated a possible automatic translation between the
mechanisms encoding verbal and image-based types of
spatial information (also, Franklin, 1992). Earlier on,
Jackendoff (1987), Jackendoff and Landau (1991), and
Bryant (1992) have made a general argument that perceptual
and linguistic inputs of spatial information are initially
analyzed by separate systems through various levels of
representation,
modality-specific
encoding
and
representation, and then translated into a common
representation that is modality independent (empirical
evidence reviewed in Bryant, 1992). Further studies of the
speed-accuracy tradeoff found here are needed to assess
whether in graph cognition there is a modality-specific
encoding and representation.
Global vs. local information Ratwani et.al., (2003)
claimed that few graph comprehension theories address
various aspects of graph comprehension tasks. Specifically,
they claimed that the theories do not address and account for
performance with global vs. local aspects of graph
information. However, this problem can be viewed from a
different perspective. Freedman and Shah’s model (2002)
suggests that both top-down (e.g., graph skills, domain
knowledge) and bottom up (perception of visual features)
processes are involved in graph comprehension. The copresence of such processes has been addressed in perception
and cognition, and is often expressed in the contrast
between feature extraction and integration theories, on the
one hand, and the more structuralist, Gestalt theories of
perception and attention, on the other hand. Earlier studies
implied the precedence of top-down processing by
demonstrating the global precedence phenomena in
perception (Navon, 1981; Pomrantz, 1981). Extending the
analog to findings of spatial cognition, the precedence of
global vs. local landmark impact on spatial cognition was
shown previously (e.g., Steck & Mallot, 2000). It is
possible that with image-based encoding there is more
global feature precedence, which is similar in perceiving
global graph features or landmarks in one’s environment. In
other words, verbal information tends to be more detailed
and elaborate, thus providing more local, specific valueoriented information. The image-based information tends to
convey the more general trends and relationships in the
information (e.g., Meyer et.al. 1997).
Summary While there is no conclusive evidence in the
spatial cognition literature to support any one specific

theoretical approach, some similarities can be drawn to
graph comprehension. Graph information can be encoded by
separate mechanisms and then translated into a common
internal representation that is modality independent. More
research is needed to examine the possible theoretical link
between graph comprehension and spatial cognition. In the
study reported here we demonstrated that the crossmodality comparison in graph information encoding can
provide some new insights as to the internal cognitive
process of graph comprehension.

Acknowledgments
Part of the work reported here was supported by the
Cybercartography and the New Economy project funded by
the Social Sciences and Humanities Research Council
(SSHRC) of Canada under the Initiative on the New
Economy (INE) Collaborative Research Initiative Grant.

References

1936

Brown, L.M., Brewster, S.A., Burto9n, M., Riedel, B. and
Ramloll, R. (2003). Design guidelines for audio
presentation of graphs and tables. In the Proceedings of
the 2003 International Conference of Auditory Display.
Boston, MA, USA, July 6-9, 2003.
Bryant, D.J. (1992). A spatial representation system in
humans. Psycholoquy, 3, #16 Space (1).
Carpenter, P. A., and Shah, P.A. (1998). A model of the
perceptual and conceptual processes in graph
comprehension. Journal of Experimental Psychology:
Applied, 4, 75-100.
Carswell, C.M. (1993). Stimulus complexity and
information integration in the spontaneous interpretations
of line graphs. Applied Cognitive Psychology, 7, 341357.
Carswell, C.M., Bates, J.R., Pregliasco, N.R., Lonon, A.,
and Urban, J. (1998). Finding graphs useful: Linking
preference to performance for one cognitive tool.
International Journal of Cognitive Technology, 3, 4-18.
Challis, B, and Edwards, A.D.N. (2001). Design principles
for tactile interaction. in Haptic Human-Computer
Interaction (LNCS 2058), S. A. Brewster and R. MurraySmith, Eds. Berlin, Germany: Springer.
Cohen, G. (1996). Memory in the real world. 2nd Edition.
Hove: Psychology Press.
Feeney, A., Hola A.K.W., Liversedge, S.P., Findlay, J.M.,
and Metcalf, R. (2000). How people extract information
from graphs: Evidence from a sentence-graph verification
paradigm. In M. Anderson, P. Cheng, and V. Haarslev
(Eds.): Diagrams 2000, LNAI 1889, pp. 149-16.
Feeney, A. & Webber, L. J. Analogical representation and
graph comprehension. Lecture Notes in Computer
Science Vol. 2733 (2003) 212-221.
Flowers, J., Buhman, D., Turnage, K. (1997). Cross-modal
equivalence of visual and auditory scatterplots for
exploring bivariate data samples. Human Factors 39(3)
341.
Franklin, N. (1992). Spatial representation for described
environments. Geoforum, 23 (2), 165-174.

Freedman, E.G., and Shah, P. (2002). Toward a model of
knowledge-based graph comprehension. In M. Hegarty,
B. Meyer, and N. Hari Narayanan (Eds.): Diagrams 2002,
LNAI 2317, pp. 18–30.
Jackendoff, R. (1987). Consciousness and the computational
mind. Cambridge, MA: MIT Press.
Jackendoff, R. & Landau, B. (1991). Spatial language and
spatial cognition. In D. J. Napoli & J. A. Kegl (Eds.),
Bridges between psychology and linguistics: A
Swarthmore festschrift for Lila Gleitman. Hillsdale, NJ:
Lawrence Erlbaum Associates.
Katz, I. R., Xi, X., Kim, H.-J., & Cheng, P. C. H. (2002).
Graph Structure Supports Graph Description. In W. Gray
& C. Schunn (Eds.), Proceedings of the Twenty Fourth
Annual Conference of the Cognitive Science Society (pp.
530-535). Mahwah, NJ: Lawrence Erbaum.
Klatzky, R.L., Lippa, Y., Loomis, J.M., & Golledge, R.G.
(2003). Encoding, learning, and spatial updating of
multiple object locations specified by 3-D sound, spatial
language, and vision. Exp. Brain Res., 149, 48-61.
Kramarski, B. (2002). Enhancing mathematical discourse:
The effects of e-mail conversation on learning graphing.
In the proceedings of the International Council for
Education Media Annual Conference, Taipei, pp. 101106.
Lohse, G.L. (1993). A cognitive model for understanding
graphical perception. Human Computer Interaction, 8,
353-388.
Mevarech, ZR and Kramarski, B (1997b) From verbal
descriptions to graphic representations: misconceptions
regarding the construction of linear graphs, Educational
Studies in Mathematics, 32, 229–263.
Meyer, J., Shinar, D., & Leiser, D. (1997). Multiple factors
that determine performance with tables and graphs.
Human Factors, 39/2, 268–286.
Navon, D. (1981). The forest revisited: More on global
precedence. Psychological Resrach, 43, 1-32.
Paivio, A. (1969). Mental imagery in associative learning
and memory. Psychological Review, 76, 241-263.
Paivio, A. (1991). Dual coding theory: retrospect and
current status. Canadian Journal of Psychology 45, 25587.
Pimm,
D.
(1987).
Speaking
Mathematically:
Communication Mathematics Classroom, Routledge &
Kegan Paul, London.
Pinker, S. (1990). A theory of graph comprehension. In R.
Freedle (Ed.), Artificial Intelligence and the Future of
Testing. Mahwah, NJ: Earlbaum.
Pomerantz, J.R. (1981). Perceptual organization in
information processing. In M. Kubovy and J.R.
Pomerantz, (Eds.), Perceptual organization (pp. 141-180).
Hillsdale, NJ: Erlbaum.
Ratwani, R. M., Trafton, J. G., & Boehm-Davis, D. A.
(2003). Thinking graphically: Extracting local and global
information. In R. Alterman & D. Kirsch (Eds.),
Proceedings of the 25th Annual Meeting of the Cognitive
Science Society, Boston, MA.
Shah, P., Hagerty, M., and Mayer, R.E. (1999). Graphs as
aids to knowledge construction: Signaling techniques for

guiding the process of graph comprehension. Language
Testing, 16, 399-425.
Sjosrom, C., Danielsson, H., Magnusson, C., and RassmusGrohn, K. (2003). Phantom-based haptic line graphics for
blind persons. Visual Impairment Research. 5 (1), 13-32.
Steck, S.D., & Mallot, H.A., (2000). The role of global and
local landmarks in virtual
environment navigation.
Presence, 9 (1), 69–83
Taylor, H.A. and Tversky, B. (1992a). Descriptions and
Depictions of Environments, Memory and Cognition
20(5): 483–496.
Taylor, H.A. and Tversky, B. (1992b). Spatial Mental
Models Derived from Survey and Route Descriptions,
Journal of Memory and Language 31: 261–292.
Taylor, H.A. and Tversky, B. (1996). Perspective in spatial
descriptions, Journal of Memory and
Language 35,
371–391.
Taylor, H.A., Uttal, D.H., Fisher, J., & Mazepa, M. (2001).
Ambiguity in acquiring spatial representations from
descriptions compared to depictions: The role of spatial
orientation. In D.R. Montello (Ed.): COSIT, LNCS 2205,
pp. 278-291.
Trickett, S.B., and Trafton, G. (2004). Spatial
transformation in graph comprehension. In Blackwell
et.al. (Eds.): Diagram 2004, Springer_verlag Berlin
Heidelberg, pp. 372-375.
Tversky, B. (1991). Spatial Mental Models. Psychology of
Learning and Motivation Advances in Research and
Theory, 27, 109-145.
Tversky, B., Kim, J., & Cohen, A. (1999). Mental models of
spatial relations and transformations from language. In C.
Habel & G. Rickheit (Eds.): Mental models in discourse
processing and reasoning. Pp. 239-258, Amsterdam:
North-Holland.
Tversky, B. (2003a). Structures of Mental Spaces; How
people think about space. Environment and Behavior, 35,
66-80.
Tversky, B. & Lee, P.U. (1998). How space structures
language. In C. Freska, C. Habel, & K.F. Wender (eds.),
Spatial Cognition: An interdisciplinary approach to
representation and processing of spatial knowledge, pp.
157-175. Berlin: Springer-Verlag.
Tversky, B. & Lee, P.U. (1999). Pictorial and verbal tools
for conveying routes. In C. Freksa, D.M. Mark (Eds.):
Spatial Information Theory. Cognitive and Computational
Foundations of Geographic Information Science:
International Conference COSIT'99, Stade, Germany,
August 1999. Pp. 51.
Webber, L. J. & Feeney, A. How people represent and
reason from graphs. In Proceedings of the 25th Annual
Conference of the Cognitive Science Society. Mahwah,
NJ: LEA (2003) 1206-1211.

1937

