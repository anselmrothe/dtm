UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Theory of Reflexive Relational Generalization
Permalink
https://escholarship.org/uc/item/7fp431fn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Bassok, Miriam
Doumas, Leonidas A.A.
Guthormson, Amy
et al.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         A Theory of Reflexive Relational Generalization
                                 Leonidas A. A. Doumas (adoumas@indiana.edu)
                           Department of Psychological and Brain Science, 1101 E. Tenth Street
                                                    Bloomington, IN 47405
                     Miriam Bassok & Amy Guthormson (mbassok@u.washington.edu)
                                           Department of Psychology, Box 351525
                                                   Seattle, WA 98195-1525
                              John E. Hummel (jehummel@cyrus.psych.uiuc.edu)
                                      Department of Psychology, 603 E. Daniel Street
                                                     Champaign, IL 61820
                            Abstract                                           While relational reasoning is reflective, in that it is
                                                                       effortful and deliberate, many of the inferences we routinely
  We present the beginnings of an account of how                       make are so effortless that we are hardly even aware of the
  representations and processes developed for the purposes of          fact that we are making them. For example, if you are told
  reflective reasoning provide a basis for reflexive reasoning as      that Susan went to the movie theater you might infer that
  well. Specifically, we show how the symbolic-connectionist           Susan saw a movie. Moreover, you probably assume that
  representations that underlie the DORA model (Doumas &
  Hummel, 2005), and the comparison based routines that
                                                                       Susan is human and a female (as opposed to, say, a male
  DORA exploits in the service of addressing reflective                raccoon). This kind of inference is made so automatically
  problems, such as analogy making and the discovery of novel          that it is often referred to as reflexive (e.g., Shastri and
  relations, can be extended to address reflexive reasoning            Ajjanagadde, 1993).
  phenomena.      We use the reflexive reasoning routines                   In the study of human cognition, reflexive and
  developed in DORA to simulate findings demonstrating that            reflective inference have, for the most part, been examined
  reflexive processes operate when subjects solve real-world           separately. For example, reflexive inference is often studied
  mathematics problems.                                                in the context of reading and story comprehension (e.g.,
                                                                       Kintsch & van Dijk, 1978; Shastri & Ajjanagadde, 1993; St.
Keywords: Reflexive reasoning, reflective reasoning, relational        John, 1992; St. John & McClelland, 1990), while reflective
reasoning, representation.
                                                                       inference is emphasized in studies of problem solving and
                                                                       higher level reasoning (e.g., Anderson & Lebiere, 1998;
         Reflective and Reflexive Reasoning                            Byrne & Johnson-Laird, 1989; Forbus, Gentner, & Law,
     Relational processing plays a central role in human               1995; Gentner, 1983, 2003; Holyoak & Thagard, 1989,
perception and thought. It permits us to perceive and                  1995; Newell, 1990). Consequently, most computational
understand the spatial relations among an object’s parts               models of reflexive reasoning are not suited to account for
(Hummel, 2000; Hummel & Biederman, 1992; Hummel &                      reflective processes (e.g., Shastri & Ajjanagadde, 1993; St.
Stankewicz, 1996), comprehend arrangements of objects in               John, 1992), and models of reflective reasoning are not
scenes (see Green & Hummel, 2004, for a review), and                   suited to account for more reflexive inferences (e.g.,
comprehend abstract analogies between otherwise very                   Falkenhainer et al., 1989; Forbus et al., 1995; Holyoak &
different situations or systems of knowledge (e.g., between            Thagard, 1989).
the structure of the solar system and the structure of the                  While reflexive and reflective processes do seem to
atom; Gentner, 1983; Gick & Holyoak, 1980, 1983;                       follow different kinds of computational constraints (Shastri
Holyoak & Thagard, 1995). Relational thinking is powerful              & Ajjanagadde, 1993), in many cases, these two types of
because it allows us to generate inferences and                        processes interact and need to be integrated in the
generalizations that are constrained by the roles that                 performance of a single task. For example, a mathematical
elements play, rather than strictly the properties of the              solution that requires a reflective rule-based reasoning often
elements themselves. For example, in the analogy between               involves retrieval of arithmetic facts (e.g., 3 + 5 = 8). The
the an atom and a solar system the sun is similar to the               activation of such facts is highly reflexive (e.g., LeFevre,
nucleus of the atom, not because of its literal features, but          Bisanz, & Mrkonjic, 1988; Niedeggen & Rosler, 1999).
because of their shared relations to planets and electrons,            For this reason, it might be limiting to view reflective and
respectively. Moreover, given that gravity causes the earth            reflexive reasoning as isolated phenomena. After all, both
to revolve around the sun, you can infer that some force               occur within the same cognitive architecture, and both
might also cause electrons to revolve around atoms. This               processes should operate on the same set of mental
kind of inference is effortful and requires reflective thought         representations (Hummel & Choplin, 2000).
(Hummel & Choplin, 2000; Hummel & Holyoak, 2003).
                                                                  1245

      In this paper we provide initial ideas about how a
representational architecture that can support structured
relational (i.e., heavily reflective) reasoning might also
provide a basis for more reflexive forms of reasoning. This
work follows from initial ideas presented by Hummel and
Choplin (2000).        We show how the same basic
representations and processes that underlie DORA
(Discovery Of Relations by Analogy; Doumas & Hummel,
2005; Doumas, Hummel & Sandhofer, submitted), a model
built to handle heavily reflective reasoning processes such
as relational reasoning and inference, and the discovery and          Figure 1. A proposition in DORA. Triangles are used to
predication of relational concepts, can also provide the basis        denote roles and circles to denote objects for clarity. In
for an account of reflexive reasoning.                                DORA, the same types of units code both roles and fillers.
                    The DORA Model                                      In this representation, the long-term binding of roles to
      DORA is a symbolic connectionist network that learns         their fillers is captured by conjunctive RB and P units. This
structured representations of relations from unstructured          is sufficient for storage in LTM, however, when a
inputs. DORA is an extension of Hummel and Holyoak’s               proposition enters WM, its role-filler bindings must also be
(1997, 2003) LISA model of relational reasoning. Like              represented dynamically on the units that maintain role-filler
LISA, DORA dynamically binds distributed (i.e.,                    independence (i.e., POs and semantics). In DORA, roles are
connectionist) representations of relational roles and objects     dynamically bound to their fillers by systematic asynchrony
into explicitly relational (i.e., symbolic) structures. The        of firing (see also Love, 1999). When a proposition enters
resulting representations enjoy the advantages of both             working memory (i.e., becomes active), bound objects and
connectionist and traditional symbolic approaches to               roles fire in direct sequence, carrying the binding
knowledge representation, while suffering the limitations of       information in the proximity of firing and the role/filler
neither (see Doumas & Hummel, 2005). DORA’s basic                  distinction in the order of firing (e.g., with fillers following
representational scheme is adapted from LISA. In DORA,             the roles to which they are bound). To illustrate, in order to
propositions are encoded in LTM by a hierarchy of structure        bind Fido to the biter role and Brian to the bitten role (and
units (Figures 1). Predicate and Object (PO) units (triangles      so represent bite (Fido, Brian)), the units corresponding to
and large circles in Figure 1) locally code for specific roles     the biter role fire directly followed by the units
and fillers. While LISA must use different types of units to       corresponding to Fido, then the units for the bitten role fire
code for roles and their fillers, DORA uses the same types         directly followed by the units for Brian. A system that is
of units to code both roles and fillers and differentiates         sensitive to couplets (or pairs) of activation can use this
between roles and fillers via its binding mechanism (see           information to represent the bindings of Fido to the biter
below; though for the purposes of clarity, in figures we use       role and Brian to the bitten role. As a result, DORA (as
triangles for POs representing roles and circles for POs           opposed to LISA) uses the same pool of semantic units to
representing fillers). For example, the proposition bite           represent both predicates and objects (Doumas & Hummel,
(Fido, Brian) would be represented in part by PO units             2005).
representing the relational roles biter and bitten, and the             DORA uses comparison-based intersection discovery to
fillers Fido and Brian. POs are connected to semantic units        isolate and explicitly predicate the shared properties of
(smaller circles in Figure 1) that code their semantic features    compared objects and to bind these new predicates to fillers
and represent both objects and relational roles in a               to form bound role-filler pairs. DORA can then learn whole
distributed fashion. For example, the PO unit representing         relational representations by joining sets of role-filler pairs
Fido would be connected to a set of semantic units denoting        (see Doumas & Hummel, 2005; Doumas et al., submitted).
Fido’s features (e.g., “dog”, “male”, “fierce”) and the PO              DORA provides an account for a number of empirical
unit representing Brian to a set of semantic units denoting        phenomena including the discovery of relational
Brian’s features (e.g., “cat”, “male”, “tabby”). Similarly,        representations that support analogical thinking (i.e.,
the biter and bitten roles would be connected to the               representations that are both structure sensitive and
semantic units denoting their features. Role-binding units         semantically rich), children and adult’s learning of
(RBs; rectangles in Figure 1) bind roles to objects in LTM.        dimensions and relational representations, the role of
Bite (Fido, Brian) requires by two RBs, one binding Fido to        comparison and progressive alignment in relation learning,
biter, and one binding Brian to bitten. At the top of the          and the shape bias observed in early childhood
hierarchy, proposition (P) units (oval in Figure 1) binding        categorization (see Doumas & Hummel, 2005; Doumas et
sets of RBs into whole relational propositions. In Figure 1 a      al., submitted; Hummel & Doumas, 2005). DORA is a
P unit binds the RBs representing biter+Fido to bitten+Brian,      model of reflective reasoning, however, as noted by
thus encoding the relational proposition bite (Fido, Brian).       Hummel and Choplin (2000), the representational structure
                                                                   of LISA (and, by extension, DORA) provides an interesting
                                                               1246

starting point for an account of reflexive reasoning as well.                   semantics. For example, during reflexive inference the
In both DORA and LISA, propositions are retrieved into                          activation of semantics can be graded as a function of when
WM from LTM via a form of guided pattern matching.                              they became active: Semantics that become active earlier
During retrieval and comparison, propositions are divided                       have more of an effect than semantics that become active
into two mutually exclusive sets: a driver and one or more                      later during inference. In DORA this is accomplished by
recipients. Comparison is controlled by the driver.                             scaling the activation of semantic units by an inverse
      As a proposition in the driver becomes active, it                         exponential function of the iteration they become active (i.e.,
generates a systematic pattern of activation on the semantic                    scaled(ai) = aie-t, where ai is the activation of semantic unit i,
units. During retrieval, propositions in LTM are allowed to                     scaled(ai) is the scaled activation of unit i, and t is the time
respond to this activation pattern via their shared semantic                   that unit i became active). There is evidence for this type of
connections. For example, if the proposition bites (Fido,                       graded spreading activation from the literature on memory
Brian) becomes active in the driver, units encoding biter                       (e.g., Anderson, 1974).
will become active, followed by units encoding Brian, and                            We are not claiming that either of these methods is the
so forth. As each PO unit becomes active, it activates a                        only form of limiting activation spread during reflexive
subset of the propositions in LTM (those with shared                            inference (the two are, after all, not mutually exclusive).
semantics). As propositions in LTM become active in                             We are simply using these methods as a demonstration that
response to patterns of activation imposed by units in the                      it is that not difficult to avoid the spreading activation
driver, they will themselves feed-back activation to the                        problem that arises during reflexive inference, in a network
semantic units. For example, as Fido becomes active in the                      like DORA. What is interesting is that this account of
driver, it might activate other propositions about dogs in                      reflexive reasoning arises from the same processes and
LTM (recall that Fido is a dog). These propositions will, in                    representations that underlie DORA’s account of explicitly
turn, pass activation to any semantic units to which they are                   reflective processes like analogy, relation discovery, and
connected. The basic idea is to use the feedback from                           relational inference.
structures in LTM (including both general schemas and                                Below, we use DORA’s reflexive inference algorithm
specific situations) to reflexively infer additional semantic                   to simulate subjects N400 ERP responses. Because the N
content of predicates and objects in the driver. As a PO in                     400 response occurs between 300-500ms after the onset of
the driver becomes active and excites a set of propositions                     the stimulus, there is only a short amount of time during
in LTM, the semantics that are activated by those LTM                           which reflexive inference can occur.
representations can be inferred about the PO in the driver.
      Consider a minimal case where Fido in the bite (Fido,                                             Simulations
Brian) proposition was connected only to the semantic unit
                                                                                     Bassok and her colleagues (e.g., Bassok et al., 1998)
“dog” (i.e., all DORA knows about Fido is that it is a dog).
                                                                                have demonstrated that people are sensitive to the fit
When the biter role becomes active it activates a subset of
                                                                                between a mathematical operation and the elements upon
propositions in LTM about biting, and when Fido becomes
                                                                                which the operation is performed. For example, people are
active, it activates propositions about dogs. The result is a
                                                                                happy to add cars and trucks but refrain from adding cars
set of active propositions in LTM about biting dogs, which
                                                                                and mechanics.        Similarly, people are much happier
activate a set of semantics connected to biting dogs. These
                                                                                dividing cars among mechanics then cars among trucks.
semantics can then be inferred about Fido (i.e., connected to
                                                                                Such “semantic alignments” make sense in light of the fact
the Fido PO via simple Hebbian learning). The result is a
                                                                                that people frequently apply arithmetic operations to solve
set of features of biting dogs reflexively inferred about an
                                                                                real world problems (Bassok et al., 1998). Guthormsen and
object based on its relational context.
                                                                                colleagues (2004) used ERP methodology to test the fluency
      However, in order for this form of reflexive inference to
                                                                                of such alignments. Subjects watched aligned and
work, the amount of activation that propositions in LTM can
                                                                                misaligned addition or division “applied” problems, such as
pass to semantic units must be limited. The reason is that,
                                                                                8 roses + 9 daises, flash across a computer screen in
left unchecked, spreading activation will simply activate all
                                                                               sequence. For example, a subject would see the number 8,
propositions in LTM.1 There are a number of ways to limit
                                                                               followed by the word roses, followed by +, followed by the
the spreading activation that results during reflexive
                                                                               number 9, followed by the word daisies (each number, word,
inference. One simple way, and one often imposed by the
                                                                               or symbol was presented for 650ms). The subject’s task
constraints of the task at hand, is to use time. Often we
                                                                               was to solve the problem and generate a numerical answer
simply do not have the time to allow runaway activation
                                                                               with an object label. The ERP recording was locked to the
because we must make inferences quickly. Another way to
                                                                               second (target) word.
limit the effects of spreading activation is to tier or grade the
                                                                                     Guthormsen and colleagues (2004) found that the N400
effect that LTM propositions have on the activation of the
                                                                               magnitude was significantly larger for target words that
                                                                               created misaligned problems than for those that created
1
  In short, as a result of one set of LTM propositions becoming active and     aligned problems. This pattern of brain responses is similar
then activation their semantics, a new set of LTM propositions (those that     (in its polarity, timing, and scalp distribution) to that
shared some semantic overlap with the active propositions) will become         observed in language comprehension, when people integrate
active, and so forth.
                                                                           1247

the meaning of consecutive words in a sentence; it is                  To simulate a trial in Guthormsen et al.’s (2004)
commonly referred to as the N400 effect (Kutas & Hilyard,           experiment we presented DORA with one of the words in its
1980). That is, presented with a word that does not fit the         LTM (i.e., a word it knew) by placing a representation of
mathematical operation (e.g., baskets in: 5 apples + 3              that word in the driver as a PO unit attached to a single
baskets), subjects demonstrated the same neural response            semantic unit (the semantic unit named the object; e.g., if
that is observed when people encounter words that are               the word was “apple” the PO unit was attached to the
difficult to integrate in a sentence (e.g., shoes in “he drove      semantic “apple”). This corresponded to the first word
to the shoes”). These findings provide strong evidence that         subjects in Guthormsen et al.’s (2004) experiment saw. We
people integrate mathematical and conceptual knowledge in           then allowed DORA’s reflexive inference algorithm to run
“real time,” while reading the problem.                             by allowing the PO in the driver to activate propositions in
     Our goal was to simulate the effects observed by               LTM, and allowing these propositions to feedback
Guthormsen et al. (2004) using DORA’s reflexive inference           activation to the semantics (see Figure 3a). For example, if
algorithm.      We constructed DORA’s LTM (i.e., the                the word was “apple”, a PO attached to the semantic “apple”
knowledge structures that would drive reflexive inference)          was activated in the driver, it began to activate propositions
to reflect the fact that people learn and use mathematics in        in LTM about apples. We then placed a representation of
the context of solving real-world problems. To this end, we         either addition or division in the driver. 2 Addition was
randomly selected 22 addition and 22 division word                 represented by a PO unit attached to the semantics,
problems constructed by undergraduates in a different study        “addition”, “addend1”, and “addend2”, and division by a PO
(Reaume & Bassok, 2005). In that study, students were              unit attached to the semantics, “division”, “dividend”, and
presented with simple addition or division arithmetic              “divisor”. Of course we are not claiming that these are the
problems (e.g., 2 + 7 = 9; 12 / 3 = 4, respectively) and asked     “right” semantic primitives of the relations addition and
to generate corresponding word problems. An example of an          division. Rather, our claim is that relations and their roles
addition word problem is: “You have 2 oranges and 7 apples,        are coded by distributed sets of features. The labels we
how many fruit do you have in all?” An example of a                attach to these features are arbitrary and mean nothing to
division word problems is: “Johnny has 12 puppies and              DORA. They are only used to help interpret the model’s
wants to put them in 3 baskets, how many puppies should he         behavior.
put in each basket?” These word problems reflected                       Again, we allowed DORA’s reflexive inference
people’s experience with real world situations in which            algorithm to run by allowing the PO in the driver to activate
simple arithmetic operations might be used, and with word          propositions in LTM, and allowing these propositions to
problems they encountered in school.                               feedback activation to the semantics (Figure 3b). For
     To construct DORA’s LTM, we first listed the objects          example, when the addition semantics became active they
involved in the mathematical operations (i.e., what was            began to activate propositons in DORA’s LTM about
being added/divided). Then, we had two undergraduate               addition. As a result of activating the initial word
research assistants create lists of features describing each of    representation (e.g., apple), and the representation of the
these objects. Each of the 44 word problems (22 addition           mathematical operation (e.g., addition) propositions in LTM
and 22 division) was input into DORA’s LTM as a single             about performing the given mathematical operation on the
proposition (see Figure 2). Each proposition consisted of          object tended to become most active, and thus activate
the objects involved in the mathematical operation (e.g.,          semantics about objects that commonly entered the specific
added (roses, tulips), divided (apples, baskets)). Each object     mathematical operation with the specific object. Continuing
was attached to the features the undergraduate coders had          our example, if apple was activated followed by addition,
used to describe it. Each mathematical operation was tied to       then propositions about adding apples tended to become
semantics describing the operation itself (i.e., “division”,       active in LTM, which tended to activate the semantic
“dividend”, “divisor”).                                            features of objects that were frequently added to apples
                                                                   (namely, “fruit”).
                                                                         We used the set of semantics that had become active as
                                                                   a measure of what DORA expected to see when the second
                                                                   word appeared. The second word was also a word from
                                                                   DORA’s LTM (i.e., one it already knew). The difference
                                                                   between the semantics that had become active during
                                                                   reflexive inference and the semantics of the second word
                                                                   was used as a measure of DORA’s “surprise” given the
                                                                    2
                                                                      We did not present DORA with numbers on these trials because it was
                                                                   not our goal to simulate the mathematical reasoning subjects performed.
                                                                   Rather, we were concerned with whether DORA’s reflexive inference
     Figure 2. Example of a proposition in DORA’s LTM.
                                                                   algorithm would lead it to expect a certain semantic category given a
                                                                   semantic prime (a word) and a specific mathematical operation (addition or
                                                                   division).
                                                               1248

second word. The less over-lap between the semantics that         students, DORA reflects the same biases for the fit between
had become active by reflexive reasoning and the second           mathematical problems and real world elements
word, the greater the “surprise”.                                 demonstrated by adult reasoners. Just like the subjects in
     Just like the subjects in Guthormsen et al.’s experiment     Guthormsen et al.’s experiment, DORA was more
DORA demonstrated greater surprise for mathematical               “surprised” when encountered mathematical word problems
problem where the elements did not fit with the                   where the elements did not fit naturally with the
mathematical operation (e.g., when apples were added to           mathematical operation, then when it encountered word
baskets). Just as Guthormsen et al.’s subjects showed a           problems where the elements did fit naturally with the
significantly higher N400 response (i.e., between 300 and         mathematical operation. This suggests that the symbolic-
500 ms) in response to a word that did not fit with the           connectionist representational structure and the mapping
mathematical context than did subjects who were shown a           based reflexive inference routines that DORA performs in
word that did fit the mathematical context, DORA was more         the service of reflective tasks like analogical mapping,
“surprised” by words that did not fit with a given                memory retrieval, and relation discovery might provide the
mathematical context, than by words that did. Specifically,       beginnings of an account of reflexive inference as well. At
when elements did not fit, only 8% of the semantic features       the very least DORA, following from Hummel and
attached to the second word were already active upon              Holyoak’s (1997, 2003) LISA model provides evidence that
presentation. However, when the second word did fit with          the same representational structures and basic processes
the mathematical operation, 31% of the semantic features          might underlie and operate in the service of both reflective
attached to the second word were already active upon              and reflexive reasoning process.
presentation. In other words, DORA reflexive inference                 As a theory of reflexive inference, however, DORA is
algorithm predicted the words that did fit, but did not           far from complete. We have demonstrated DORA’s ability
predict the words that did not. Exactly as we had hoped,          to account for simpler reflexive inferences, but it is not clear
DORA provides an encouraging beginning for                        whether DORA would scale up to account for more
understanding how a system built to model reflective              complex reflexive inference. For example, as noted in the
processes might be extended to address the problems of            introduction, if you are told that Susan went to the movie
reflexive inference.                                              theater you might infer she saw a movie. If DORA’s LTM
                                                                  contained a number of propositions about seeing movies at
                         Discussion                               movie theaters it might be able to infer that Susan saw a
                                                                  movie when she went to the theater, but it is not clear how
     Using simple operations that were already in place for
                                                                  DORA could reflexively infer structured propositions such
the purposes of reflective reasoning, DORA has been able to
                                                                  as saw (Sally, movie) solely given feedback to semantic
account for the reflexive reasoning phenomena observed by
                                                                  units from LTM. However, DORA does suggests a
Guthormsen and colleagues (2004). When DORA’s LTM
                                                                  promising starting point for investigating the requirements
consists of math word problems generated by undergraduate
                                                             1249

that a representational system must meet in order to account     Hummel, J. E., & Biederman, I. (1992). Dynamic binding
for both reflective and reflexive inference.                       in a neural network for shape recognition. Psychological
                                                                   Review, 99, 480-517.
                         References                              Hummel, J.E., & Choplin, J.M. (2000). Toward an
                                                                   integrated account of reflexive and reflective reasoning.
Anderson, J. R. & Lebiere, C. (1998). The atomic
                                                                   In L.R. Gleitman & A.K. Joshi (Eds.), Proceedings of the
  components of thought. Mahwah, NJ: LEA.
                                                                   Twenty-Second Annual Conference of the Cognitive
Bassok, M, Chase, V. M, & Martin, S. A. (1998). Adding
                                                                   Science Society (pp. 232–237). Mahwah, NJ: Erlbaum.
  apples and oranges: Alignment of semantic and formal
                                                                 Hummel, J. E. & Doumas, L. A. A. (2005). Some
  knowledge. Cognitive Psychology, 35, 99-134.
                                                                   speculations on the development of the role of visual
Byrne, R. M. J., & Johnson-Laird, P. N. (1989). Spatial
                                                                   invariants in shape perception. Paper presented at the
  reasoning. Journal of Memory and Language, 28, 564-
                                                                   biennial meeting of the Society for Research in Child
  575.
                                                                   Development.
Doumas, L. A. A., & Hummel, J. E. (2005). A symbolic-
                                                                 Hummel, J. E., & Holyoak, K. J. (1997). Distributed
  connectionist model of relation discovery. In B. G. Bara,
                                                                   representations of structure: A theory of analogical
  L. Barsalou, & M. Bucciarelli (Eds.), Proceedings of the
                                                                   access and mapping. Psychological Review, 104, 427-466.
  Twenty-Third Annual Conference of the Cognitive Science
                                                                 Hummel, J. E., & Holyoak, K. J. (2003). A symbolic-
  Society, 606-611. Mahwah NJ: LEA.
                                                                   connectionist theory of relational inference and
Doumas, L. A. A., Hummel, J. E., & Sandhofer, C. M.
                                                                   generalization. Psychological Review.
  (submitted).       A symobolic-connectionist model of
                                                                 Hummel, J. E., & Stankiewicz, B. J. (1996). Categorical
  predication and relation discovery.
                                                                   relations in shape perception. Spatial Vision, 10, 201-236.
Falkenhainer, B., Forbus, K. D., & Gentner, D. (1989). The
                                                                 Kintsch, W. & van Dijk, T. A. (1978). Toward a model of
  structure-mapping engine: Algorithm and examples.
                                                                   text comprehension and production.           Psychological
  Artificial Intelligence, 41, 1-63.
                                                                   Review, 85, 363-394.
Forbus, K. D., Gentner, D., & Law, K. (1995). MAC/FAC:
                                                                 Kutas, M., & Hilyard, S. A. (1980). Reading senseless
  A model of similarity-based retrieval. Cognitive Science,
                                                                   sentences: Brain potentials reflect semantic incongruity.
  19, 141-205.
                                                                   Science, 207, 203-205.
Gentner, D. (1983). Structure-mapping: A theoretical
  framework for analogy. Cognitive Science, 7, 155-170.          LeFevre, J-A., Bisanz, J., and Mrkonjic, L. (1988).
Gentner, D. (2003). Why we’re so smart. In D. Gentner and          Cognitive arithmetic: Evidence for obligatory
  S. Goldin-Meadow (Eds.), Language in mind: Advances              activation of arithmetic facts. Memory & Cognition,
  in the study of language and thought (pp.195-235).               16(1), 45-53. Love, B. C. (1999). Utilizing time:
  Cambridge, MA: MIT Press.                                        Asynchronous binding. Advances in Neural Information
Gick, M. L., & Holyoak, K. J. (1980). Analogical problem           Processing Systems, 11, 38-44.
  solving. Cognitive Psychology, 12, 306-355.                    Niedeggen, M., & Rosler, F. (1999). N400 Effects Reflect
Gick, M. L., & Holyoak, K. J. (1983). Schema induction             Activation Spread During Retrieval of Arithmetic Facts.
  and analogical transfer. Cognitive Psychology, 15, 1-38.         Psychological Science, 10(3), 271-276.
Guthormsen, A., Bassok, M., Osterhout, L. (2004,                 Reaume, G.& Bassok. M. (2005): Apples and Apples of
  November). ERP Measure of Conceptual Integration                 Alignment: The Interaction of Semantic and Formal
  Between Mathematical and Semantic Relations. Poster              Knowledge in Simple Arithmetic. Poster presented at the
  presented at the 45th annual meeting of the Psychonomic          7th annual meeting of NOWCAM, Bellingham,
  Society, Minneapolis, MN.                                        Washington.
Holyoak, K. J., & Thagard, P. (1989). Analogical mapping         Shastri, L., & Ajjanagadde, V. (1993). From simple
     by constraint satisfaction. Cognitive Science, 13, 295-       associations to systematic reasoning: A connectionist
     355.                                                          representation of rules, variables and dynamic bindings.
Holyoak, K. J., & Thagard, P. (1995). Mental Leaps:                Behavioral and Brain Sciences, 16, 417-494.
  Analogy in Creative Thought. Cambridge, MA: MIT                St. John, M. F. (1992). The Story Gestalt: A model of
  Press.                                                           knowledge-intensive processes in text comprehension.
Hummel, J. E. (2000). Where view-based theories break              Cognitive Science, 16, 271-302.
  down: The role of structure in shape perception and           St. John, M. F., & McClelland, J. L. (1990). Learning and
  object recognition. In E. Dietrich and A. Markman (Eds.),        applying      contextual    constraints     in     sentence
  Cognitive Dynamics: Conceptual Change in Humans and              comprehension. Artificial Intelligence, 46, 217-257.
  Machines. Hillsdale, NJ: Erlbaum.
                                                            1250

