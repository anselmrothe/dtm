UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Children Learn from Gestures Not Grounded in the Here-and-Now

Permalink
https://escholarship.org/uc/item/4t9498cg

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Goldin-Meadow, Susan
Ping, Raedy M

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Children Learn from Gestures Not Grounded in the Here-and-Now
Raedy M. Ping (rping@uchicago.edu)
Department of Psychology, 5848 S. University Avenue
Chicago, IL 60637 USA

Susan Goldin-Meadow (sgm@uchicago.edu)
Department of Psychology, 5848 S. University Avenue
Chicago, IL 60637 USA

explanations of physics problems, with visible objects as
one layer, explanation-rich speech as a second layer, and a
third layer consisting of meaningful iconic gestures that
ground the language in the world by tying the speech to the
objects to which it refers (Roth & Welzel, 2001).
In addition, children can understand the information their
teachers put forth in gesture. Preschool-aged children can
understand a message that is divided between gesture and
speech better than they can understand either speech or
gesture alone (Kelly, 2001). Seven- and eight-year-old
children who watched video tapes of other children
participating in conservation tasks were able to glean
information from the gestures those children produced, even
when the gestures included information that was not
included in the children’s speech (Kelly & Church, 1997;
see also Singer & Goldin-Meadow, 2005).
Children not only pay attention to information conveyed
in gesture, but they also learn from it. When children were
presented with instruction in math equivalence that had both
speech and matching pointing gestures, they were more
likely to learn than children who received instruction that
had speech only (Perry et al., 1995). In addition,
preschoolers who were instructed in symmetry learned more
when their instruction included both speech and matching
pointing and tracing gestures than when it included speech
alone (Valenzeno et al., 2003). When Church, AymanNolley and Mahootian (2004) presented children with
training on Piagetian conservation tasks, the children
learned better when the training included both speech and
iconic gestures than speech alone.
Although different kinds of gestures were used in each
of these three studies, all of the gestures directly indexed the
objects or problems being considered. In contexts such as
these, gesture may serve as a sort of bridge between
arbitrary, symbolic speech and the highly perceptual,
experienced physical world. Gesture can be seen as living
between these two worlds, as it has iconic properties that are
symbolic in that they are not literally the things they
indicate or stand for, but they are also highly perceptual and
are produced in real space. It has been proposed that
“gestures ‘ground’ teachers’ speech by linking abstract,
verbal utterances to the concrete, physical environment”
(Valenzeno et al., 2003 p. 187). This may be true, but it is
also possible that gestures can help children learn even
when they stand on their own. That is, when the “concrete,

Abstract
Children learn better when their instructions include both
gesture and speech than when instructions consist of speech
alone (Perry, Berch & Singleton, 1995; Valenzeno, Alibali, &
Klatzky, 2003; Church, Ayman-Nolley & Mahootian, 2004).
The present research investigates whether this effect is due
solely to gesture’s ability to ground words in the world. We
found that children improved more on Piagetian conservation
tasks when their instruction included both iconic gestures and
speech than when instruction consisted of speech alone. This
was true even when the objects to which the gestures referred
were not visible. These findings suggest that, although
gesture’s ability to direct attention to objects and actions in
the visible world may be important in learning contexts,
gesture is capable of doing more for learners than simply
grounding arbitrary, symbolic language in the physical,
observable world.
Keywords: gesture, instruction, development, embodiment,
education, psychology

Introduction
Although we may not be explicitly aware of the gestures we
produce or the gestures that our communicative partners
produce, gesture is a pervasive part of our communicative
interactions with other people. Gesture is out there, as
“underground information [that] is integrated with the
information conveyed in speech by both speaker and
listener” (Goldin-Meadow, 2003, p. 103). One type of
communicative situation in which gesture appears to be
particularly important is the adult-child learning interaction.
Children’s gestures communicate information about what
they know and how they view a problem (e.g., Church &
Goldin-Meadow, 1986; Perry, Church & Goldin-Meadow,
1988; Goldin-Meadow, Alibali & Church, 1993; Alibali &
Goldin-Meadow, 1993), and teachers’ gestures help children
learn about a multitude of tasks (e.g., Perry, Berch &
Singleton, 1995; Valenzeno, Alibali & Klatzky, 2003;
Church, Ayman-Nolley & Mahootian, 2004).
Teachers use gesture in children’s everyday learning
environments across a variety of domains and age groups.
When teachers teach first graders about mathematics, they
use gesture more than other nonverbal materials, such as
counting blocks and other instructional aids (Flevares &
Perry, 2001). High school science teachers appear to “layer”
675

on the table, within the child’s view, as the experimenter
said the training statement: “One of the glasses is taller and
the other one is shorter, but the shorter glass is wider and the
taller glass is skinnier. So it makes up for it.” This statement
demonstrates the compensation strategy, the idea that there
is more than one dimension on which the glasses can be
measured and that those dimensions compensate for one
another. In the objects absent conditions, the experimenter
takes the glasses off the table before saying the training
statement. In the gesture + speech conditions, appropriate
iconic gestures were performed near the glasses (in the
objects present condition) or in the air near where the
glasses had been (in the objects absent condition) along
with the training statement. For example, the experimenter
indicated the height of the glasses with palms flat and
perpendicular to the table and then indicated the width of
the glasses with appropriately sized C-shapes at the height
of the glass. The gestures in this case demonstrated both the
height and the width of the glasses at the same time, a key
component of understanding the compensation strategy. In
the speech only conditions, the experimenter produced the
same training statement (using precisely the same words and
intonation pattern) but produced no gesture. The stimuli
were then returned to their initial state and the experimenter
said, “I think these two glasses have the same amount of
water in them.”
The second half of each training trial consisted of the
child solving one problem and getting feedback. For
example, the experimenter put two identical glasses with
equal amounts of water up on the table and asked the child
whether the two had the same amount of water. One of the
stimuli was then transformed and the child was asked if the
two had the same amount of water. In the objects absent
conditions, the glasses were taken off the table, out of view
of the child. In the objects present conditions, the glasses
were left on the table. The child was asked the reason for his
or her judgment. If the child gave a correct answer, the
experimenter said, “I think you’re right. I think they do have
the same amount of water” and then gave the training
statement again. If the child gave an incorrect answer, the
experimenter said, “Actually, I think they have the same
amount of water” and then gave the training statement. In
the gesture + speech conditions, the training statement was
accompanied by appropriate iconic gestures, and in the
speech only conditions, the training statement was the same
but there were no gestures presented. The stimuli were then
returned to their initial state and the child was asked
whether the two glasses had the same amount of water.
Training trials followed a similar protocol for the number
training.
The posttest was administered by the same
experimenter who administered the pretest. No feedback
was given.
The child’s equality judgment (same or different) for
each question on the pretest, training, and posttest was
recorded, along with the strategies he or she expressed in
speech and gesture. The strategies expressed in both speech

physical environment” to which gestures refer is not
immediately accessible to children, will gesture still help
them learn? Alternatively, is this hypothesized bridging
function the only way that viewing gesture can help children
learn?
The present research investigates these possibilities by
examining whether children can learn from gesture even
when the objects to which the gestures refer are not visible.
In this experiment, children participated in a pretesttraining-posttest paradigm. They received instruction either
with speech only or with speech plus iconic gesture, and
with or without the objects to which the training referred. In
the objects present conditions, we expect that children will
improve more with training that includes both speech and
gesture than training that includes speech only, replicating
Church et al.’s (2004) finding that gesture helps children
learn about conservation. If gesture confers the same
benefit in the objects absent conditions, we will have
evidence that gesture can stand on its own without props in
teaching children a new concept.

Method
Participants were 43 kindergarten students from Chicago
area public and private schools (average age 5.5 years).
There were 20 (45%) female and 23 (55%) male students.
Children participated individually in the experiment during
the normal school day. The experiment consisted of a
pretest, a training session, and a posttest. Children received
a small prize after participating in the experiment.
The pretest consisted of eight conservation tasks, two
each of liquid (volume), number, length, and mass. At the
beginning of each pretest trial, the child was presented with
two identical stimuli (e.g., two identical glasses with the
same amount of water inside) and was asked whether the
two were equal in amount. Once the child agreed that the
two were equal, one of the stimuli was transformed (e.g.,
water in a tall, thin glass was poured into a short wide dish),
and the child was again asked whether the two were equal in
amount. Regardless of the answer, the child was asked for a
reason. The stimulus was transformed back into its original
state, and the child was once again asked whether the two
were equal.
Each child was trained on liquid and number
conservation by a different experimenter from the one who
administered the pretest. The training session consisted of
three liquid training trials and three number training trials.
Liquid and number were presented in counterbalanced
blocks, and the three training trials were randomized within
these blocks. For each training trial, the experimenter first
gave instruction and then allowed the child to do a problem
with feedback. For example, in a liquid training trial, the
experimenter put up two identical glasses with the same
amount of water. She said, “I think these two have the same
amount of water.” Then she poured the liquid from one of
the glasses into a different shaped container and said, “I
think these two glasses have the same amount of water in
them.” In the objects present conditions, the objects stayed

676

to which the gestures and speech refer are visible to the
child.

and gesture were coded using criteria developed and used in
previous studies (e.g., Church & Goldin-Meadow, 1986).
Speech was coded without watching the gesture, and gesture
was coded on a second pass without listening to the speech.
In order to be coded as having answered a problem
correctly, the child had to produce a “same” judgment after
the transformation and give a correct strategy as
justification. The child’s score is the number of correct
answers on the posttest minus the number of correct answers
on the pretest. Since there are many correct strategies
children can use in these tasks, we also calculated the
number of correct strategies added from pretest to posttest
as a more sensitive measure of learning (cf. Church &
Goldin-Meadow, 1986).

2.50
Gesture + Speech
Number of correct strategies added

Speech Only

Results

1.00

0.50

Objects Present

Objects Absent

Figure 2: Number of correct strategies added from pretest
to posttest

Discussion
The present research reveals that gesture can help children
learn even when the gestures are not grounded in the
immediately visible physical world. We found that children
improved more from pretest to posttest when their
instruction included both gesture and speech than when it
included speech only. This was true whether or not the
objects to which the gestures referred were visible.
Children given gesture and speech instruction also added
more correct strategies from pretest to posttest than did
children given instruction in speech only. These findings
suggest that gesture may help children understand a problem
more deeply, even when the objects to which the gestures
refer are not present. In these instances, gesture appears
capable of doing more than simply “grounding” language in
the world, or connecting the spoken language with visible
objects.
However, it is still unclear what exactly gesture is doing
during the learning process. Recall that there were no
significant differences between the objects absent
conditions and the objects present conditions. Is gesture
working in the same way regardless of whether the objects
are visible? If so, then how is it working? It could be that
the gestures highlight the important aspects of the stimuli
and help the child create a representation of the problem that
includes the symbiotic relationship between gesture, speech,
and the visible environment, as seems to be true for learning
interactions among adults (Goodwin, 2003). For example,
the gestures and speech in the liquid training first
highlighted a height comparison between the objects and
then highlighted a circumference comparison (while
maintaining the difference in height). Thus, the gestures
could be pointing out the important comparisons to the child
and could be working because they were performed in
relation to the visible objects.

0.50

Gesture + Speech
Speech Only
Proportion pretest to posttest improvement

1.50

0.00

Pretest scores did not vary across the four conditions.
Children in each condition started out in the same
knowledge state, without any significant differences among
them. All data were analyzed as proportions and therefore
underwent arcsine transformations before analysis. Means
are presented as proportion correct unless otherwise
indicated.
We found that children given instruction in both gesture
and speech (regardless of presence or absence of objects)
improved their proportion of correct answers by .30
(SD=.36), whereas children given instruction in speech only
(regardless of presence or absence of objects) improved
their proportion of correct answers by only .11 (SD=.21), F
(1, 39) = 4.24, p < .05.

0.40

0.30

0.20

0.10

0.00
Objects Present

2.00

Objects Absent

Figure 1: Pretest to posttest improvement in correct
answers
Moreover, children who received gesture and speech
instruction added more correct strategies from pretest to
posttest than children who received instruction in speech
only (gesture + speech = 1.50, SD=1.60, vs. speech only =
.38, SD=.80), F (1, 39) = 8.33, p < .01. Importantly, there
were no main effects of objects being present or absent and
there were no interactions for improvement in scores
(Figure 1) or in the number of correct strategies added from
pretest to posttest (Figure 2). Gesture appears to be helping
children learn about conservation, whether or not the objects
677

Goodwin, C. (2003). The semiotic body in its environment.
In J. Coupland & R. Gwyn (Eds.) Discourses of the
Body (pp. 19-42). New York, NY, US: Palgrave/
Macmillan.
Kelly, S. D. (2001). Broadening the units of analysis in
communication: Speech and nonverbal behaviours in
pragmatic comprehension. Journal of Child Language,
28(2), 325-349.
Kelly, S. D. & Church, R. B. (1997). Can children detect
conceptual information conveyed through other
children’s nonverbal behaviors? Cognition &
Instruction, 15(1), 107-134.
Núñez, R. & Sweetser, E. (2006). With the future behind
them: Convergent evidence from Aymara language and
gesture in the crosslinguistic comparison of spatial
construals of time. Cognitive Science, 30(3), 1-49.
Núñez, R. (2004). Do real numbers really move? Language,
though, and gesture: The embodied cognitive
foundations of mathematics. In F. Iida, R. Pfeifer, L.
Steels, and Y. Kuniyoshi (Eds.) Embodied Artificial
Intelligence (pp. 54-73). Berlin, Germany: SpringerVerlag.
Parrill, F. & Sweetser, E. (2004). What we mean by
meaning: Conceptual integration in gesture analysis.
Gesture, 4(2), 197-219.
Perry, M., Berch, D., & Singleton, J. L. (1995).
Constructing shared understanding: The role of
nonverbal input in learning contexts. Journal of
Contemporary Legal Issues, 6, 213-236.
Perry, M., Church R. B., & Goldin-Meadow, S. (1988).
Transitional knowledge in the acquisition of concepts.
Cognitive Development, 3(4), 359-400.
Roth, W.-M. & Welzel, M. (2001). From activity to gestures
and scientific language. Journal of Research in Science
Teaching, 38(1), 103-136.
Singer, M. A. & Goldin-Meadow, S. (2005). Children learn
when their teachers’ gestures and speech differ.
Psychological Science, 16, 85-89.
Valenzeno, L., Alibali, M. A., & Klatzky, R. (2003).
Teachers’ gestures facilitate students’ learning: A
lesson in symmetry.
Contemporary Educational
Psychology, 28(2), 187-204.

But if this is the case, what then is gesture doing when
the objects are not present? It could be working in the same
way, albeit in relation to a mental image of the objects. Or,
the gestures could be working more abstractly, helping the
child grasp the compensation strategy at a level that is not
tied to the particular objects. Adults have been shown to
build embodied simulations of nonvisible entities (as
evidenced in their gestures) in situations ranging from
everyday conversation (Parrill & Sweetser, 2004) to math
lectures (Núñez, 2004) to talking about time (Núñez &
Sweetser, 2006). It is unclear when children are themselves
able to construct embodied simulations of this sort.
However, our data make it clear that children are able to
take advantage of simulations that have been constructed by
others. The open question is how.
In sum, these observations expand previous results
demonstrating that gesture helps children learn in situations
where its role is highly referential. We have shown that
gestures can help children learn even when the objects to
which they refer are not directly visible. Gesture is therefore
capable of playing more than merely a grounding referential
role, not only in conversations among adults, but also in
teaching situations involving young children. In future
research, our plan is to explore more explicitly the
mechanism(s) by which gesture helps children learn in these
contexts.

Acknowledgements
Thanks to Zac Mitchell for assistance in data collection,
Mary-Anne Decatur for help with data coding, and Fey
Parrill for input on the paper. Funded by NIH R01
HD047450 to SGM.

References
Alibali, M. W. & Goldin-Meadow, S. (1993). Gesturespeech mismatch and mechanisms of learning: What
the hands reveal about a child’s state of mind. Cognitive
Psychology, 25(4), 468-523.
Church, R. B., Ayman-Nolley, S., & Mahootian, S. (2004).
The role of gesture in bilingual education: Does
gesture enhance learning? International Journal of
Bilingual Education & Bilingualism, 7(4), 303-320.
Flevares, L. M. & Perry, M. (2001). How many do you see?
The use of nonspoken representations in first-grade
mathematics lessons. Journal of Educational
Psychology, 93(2), 330-345.
Goldin-Meadow, S. (2003). Hearing gesture: How our
hands help us think. Cambridge, MA, US: Harvard
University Press.
Goldin-Meadow, S., Alibali, M. W., & Church, R. B.
(1993). Transitions in concept acquisition: Using the
hand to read the mind. Psychological Review, 100(2),
279-297.

678

