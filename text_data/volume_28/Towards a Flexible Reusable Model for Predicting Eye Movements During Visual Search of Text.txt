UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Towards a Flexible, Reusable Model for Predicting Eye Movements During Visual Search of
Text
Permalink
https://escholarship.org/uc/item/2kz126z5
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Halverson, Tim
Hornof, Anthony J.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                 Towards a Flexible, Reusable Model for Predicting Eye Movements
                                                 During Visual Search of Text
                                             Tim Halverson (thalvers@cs.uoregon.edu)
                                           Anthony J. Hornof (hornof@cs.uoregon.edu)
                              Department of Computer and Information Science, 1202 University of Oregon
                                                         Eugene, OR 97403-1202 USA
                               Abstract                                   directly on a number of previous studies of structured, menu-
                                                                          like visual layouts. The purpose of this modeling effort is to
   Visual search is an integral component in many human                   further clarify and build a framework for understanding
   activities. The eye movements produced during such activities          (scientifically) and predicting (scientifically and for design
   can provide valuable information about people’s cognitive
                                                                          purposes) how people integrate perceptual, strategic and
   processes. This research investigates, with detailed eye
   movement data analysis and computational cognitive modeling,           motor processes in visual search. This paper describes the
   the perceptual, strategic, and oculomotor processes people use         evolution of a visual search model from a constrained,
   to visually search. A cognitive model is evolved in a principled       random search strategy into a robust and flexible model of
   manner based on eye movement data, past modeling efforts,              menu search that accounts for a wide variety of eye
   and recent psychological literature. In the model, re-usable,          movement data. We believe the resulting model, while
   parsimonious, local strategies interact with perceptual-motor          developed using data from one task, has been evolved by the
   constraints to predict the bulk of the eye movement data,              analysts with sufficiently few task-specific requisites. That is,
   including aspects of the data that appear to require task-specific     the model is flexible and reusable.
   global strategies in addition to fixation-to-fixation local
   strategies. The analysts evolve a base level model with a
   random strategy into a robust and reusable model with a                     Building on Previous Visual Search Models
   flexible strategy that could work with a wide range of visual           This research builds directly on previous research of menu
   stimuli.                                                                search. Hornof (2004) studied the visual search of layouts
                                                                           with and without a useful visual hierarchy. The task relevant
   Keywords: cognitive modeling; visual search; EPIC; eye                  to the current research is the visual search of layouts without
   movements
                                                                           a visual hierarchy. Figure 1 shows a sample layout from the
                                                                           experiment.
                           Introduction                                       Sixteen participants searched four different screen layouts
The visual search strategies people employ have a substantial              for a precued target object. Each layout contained one, two,
effect on the time it takes people to find a target in a visual            four, or six groups. Each group contained five objects. The
layout. A fair amount of research has been done on visual                  groups always appeared at the same physical locations on the
search strategies people use. For example, Shen, Reingold,                 screen. One-group layouts used group A. Two-group layouts
and Pomplun (2003) found that people tend to shift their                   used groups A and B. Four-group layouts used groups A
visual search strategy very quickly based on which visual                  through D.
feature is most informative for a given layout. Burke, et al.                 Each trial proceeded as follows: The participant studied and
(2005) found that people ignore the most salient objects that              clicked on the precue; the precue disappeared and the layout
do not relate to the task, flashing banner advertisements, in              appeared; the participant found the target, moved the mouse
simulated web pages.                                                       to the target, and clicked on the target; the layout disappeared
   One way to better understand what visual search strategies              and the next precue appeared.
people use, and why they use them, is through computational                   Hornof (2004) presented models that predicted and
cognitive modeling. The models instantiate the theory, make
testable numeric predictions, and facilitate identification of
unanswered questions. Several computational models of
visual search have been proposed (e.g. Pomplun, Reingold, &
Shen, 2003; Wolfe, 1994). For the most part, these
computational models of visual search account for one or two
of the perceptual, strategic, or oculomotor processes involved
in visual search, but not all three. Ideally, a model of visual
search would explain some aspect of each process involved in
visual search.
   This research proposes a flexible and reusable                         Figure 1. A 6-group layout. The precue, in the top left,
computational cognitive model of text search that builds                  would disappear when the layout appeared. The gray text
                                                                          did not appear during the experiment.
                                                                      1428

explained the search time data collected from the visual               The principled approach adopted here for building the
hierarchy task. Hornof and Halverson (2003) replicated the         model was to make gradual improvements based on “low-
study to collect eye movement data to verify the eye               level” eye movement data (for example, fixation duration and
movement strategies predicted by the models. In the model,         saccade distances). At each step in the evolution of the model,
the eyes moved down the first column of text, then down the        a sub-strategy was added or a perceptual parameter was
second column, and then down the third. Furthermore, the           changed to increase the fidelity of the model. Basic visual
eyes jumped over a carefully controlled number of items with       search research or previous computational modeling
each eye movement. This selection strategy resulted in a very      motivated each change. It should be noted that each strategy
plausible explanation for how people did the task. The model       or perceptual parameter change was considered “fixed” for
accounted for the reaction time and a fair number of eye           later iterations of the model.
movement measures, especially considering that the model               This model-building procedure resulted in gradual
was built without the eye movement data to guide its               improvements, which we believe results in a model that meets
development.                                                       our goal of a flexible, reusable model that accounts for how
   However, the model’s strategy is perhaps somewhat tuned         people search a visual layout. The following sections discuss
to aspects of this one visual task and layout. Aspects of the      four substantial steps made in the evolution of our cognitive
strategy, such as the strict use of the three columns, will not    model, starting with the motivation and explanation of the
be directly applicable to a wide range of visual layouts. The      baseline model.
original model might thus be characterized as somewhat
brittle, whereas a more flexible model might be more useful         Step 1: Start with the baseline model
for predicting human performance in a wider range of visual         This modeling endeavor started largely as an attempt to
search tasks.                                                       integrate two pre-existing visual search models—the best-
   This concern motivated a need for a more flexible model          fitting model for the (unlabeled) visual hierarchy layouts from
that would predict the eye movements with greater fidelity          Hornof (2004) and the best-fitting final “mixed density”
and would do so in a more general, task-independent manner.         models from Halverson and Hornof (2004). In an effort to
The data collected by Hornof and Halverson (2003) are used          integrate the two, we started by finding the common elements
in the current research.                                            between the best-fitting models for each of the visual search
                                                                    tasks. Interestingly, in the process of stripping down each of
The EPIC Cognitive Architecture                                     the models to find the common elements of both models so
A series of computational cognitive models described in this        that they could be merged, we ended up with pretty much the
study were built using the EPIC (Executive Process                  same purely random model promoted by Hornof (2004), and
Interactive Control) cognitive architecture (Kieras & Meyer,        the same purely random search strategy used in Halverson
1997). EPIC captures human perceptual, cognitive, and motor         and Hornof (2004). They were integrated and used to start
processing constraints in a computational framework that is         the exploratory modeling discussed here.
used to build cognitive models. Into EPIC, we encoded (a) a            The new purely-random baseline model started with a
reproduction of the task environment, (b) the visual-               strategy in which saccade destinations were selected at
perceptual features associated with each of the screen objects,     random from among potential targets. Beyond that, the
such as the text feature, and (c) the cognitive strategies that     model imposed a minimal number of constraints, primarily
guide the visual search, encoded as production rules. These         imposed by the EPIC cognitive architecture and task analysis,
components were added based on task analysis, human                 including:
performance capabilities, previous visual search model, and            (a) Search proceeded without replacement. In other words,
parsimony.                                                          objects were not selected as a saccade destination after their
   After these components are encoded into the architecture,        text had been identified. Analysis of our eye movement data
EPIC executes the task, simulates the perceptual-motor              suggested that people rarely fixated an object more than once.
processing and interactions, and generates search time and          A model with no memory for fixated locations or objects
eye movement predictions. EPIC simulates ocular-motor               would predict way too many fixations.
processing, including the fast ballistic eye movements known           (b) Saccades were initiated after the fixated objects are
as saccades, as well as the fixations during which the eyes are     identified. This was a feature of the “mixed density” model
stationary and information is perceived.                            from Halverson and Hornof (2004). In EPIC, the visual
                                                                    properties of objects are available at varying eccentricities.
           Evolving the Cognitive Strategy                          For the text property, the default availability radius is one
This paper presents the several steps in the principled             degree of visual angle from center of fixation. Once an object
evolution of a model of visual search. The motivation for           enters the availability region of a property, that property
creating the model is the need for a computational model that       enters working memory after an amount of time determined
is flexible enough to predict performance on a variety of           by two parameters: (i) transduction time (50 ms for text), the
menu-like visual layouts, and that can explicitly account for a     time it takes from the information to reach sensory memory,
wider range of eye movement measures than previous                  and (ii) recoding time (100 ms for text), the time it takes to
models.                                                             recognize the property. Given the strategy used in these
                                                               1429

        models, these constraints directly affect when the next     Direct visual inspection of hundreds of individual eye
        saccade is initiated.                                    movements made by participants revealed two clear patterns
                                                                 not accounted for by the Step 1 random model. First, once
           (c) EPIC’s oculomotor feature preparation time parameter
        was changed to zero. Recent progress with the EPIC       participants had finished dwelling on a group, they tended not
                                                                 to revisit that group until the remainder of the layout had been
        cognitive architecture has found that oculomotor preparation
        time may not be necessary or may occur in parallel with  searched (this was true 94% of the time).                Second,
        saccade destination decisions (Kieras & Meyer, 2005).    participants were more likely to saccade to nearby objects
        Movement feature preparation time was previously         rather than to distant objects. Step 2 introduces two
        determined based on shared features (e.g. direction and  modifications that account for these behaviors.
        extent) with the previous motor movement. Initiation and    To maintain forward progress in the search, a sub-strategy
        execution times are still required.                      was added to prohibit group revisits until all groups had been
                                                                 searched. If two contiguous fixations land on two different
           These three constraints persisted throughout all models
        discussed in this paper.                                 groups, then objects in the first of the two groups are no
           Combining these constraints with the baseline random  longer potential saccade destinations until the entire layout
        strategy, the resulting model predicted only one eye     had been searched. This sub-strategy uses layout-specific
                                                                 information, that objects are organized into groups, but we
        movement metric quite well, namely mean fixation duration.
                                                                 suspect that most visual layouts will have some sort of natural
        Figure 2 shows the predicted and observed fixation durations
                                                                 grouping that can be similarly used.
        by layout size. The model predicts the mean fixation duration
        with an average absolute error (AAE) of 7.8%. In that our   People do not search randomly. When searching, they are
                                                                 more likely to saccade to objects that are relatively nearby
        goal is an AAE of less than 10%, this is an acceptable error.
                                                                 rather than objects across the layout. In visual search, saccade
           The model did a poor job of predicting other eye movement
        data, including saccade distance, fixations-per-group,   destinations are based on proximity to the center of fixation
        fixations-per-trial, and scanpaths. Many of these        (e.g., Motter & Belky, 1998). Other models of visual search
        shortcomings result because the model does not accuratelyprefer nearby objects as saccade destinations (e.g., Barbur,
        predict trends in saccade destinations. Though a purely- Forsyth, & Wooding, 1990).
        random search strategy is good first approximation for      The Step 1 model was modified so that saccade
        predicting mean search times, a more refined strategy is destinations were selected based on proximity to the center of
                                                                 fixation. Objects in EPIC have a property, eccentricity, which
        needed for a robust, reusable, general purpose model of visual
        search.                                                  reflects the object’s distance (in degrees of visual angle) from
                                                                 the center of fixation. The random saccade destination
  Step 2: Refine the saccade destinations                        selection strategy was changed to select the potential target
  As discussed previously, the two models whose integration      with the least eccentricity. To account for variability in the
  initially motivated this research used either task-specific or human saccade distances, noise was also added to the
  purely random strategies. Step 2 pursued a more flexible       eccentricity to vary saccade distances, while at the same time
  strategy. To this end, Step 2 worked to improve the            preferring nearby objects.
  prediction of saccade destinations.                               Saccade destinations are thus selected as follows: (a) After
     Two metrics were used to determine saccade destinations:    each   saccade, the eccentricity property is updated based on
  mean saccade distance and mean fixations per group. Saccade    the  new  eye position. (b) The eccentricity property is scaled
  distance measures the distance between contiguous fixations.   by  the  eccentricity fluctuation factor, which has a mean of
  Fixations-per-group measures the number of contiguous          one and a standard deviation of 0.3. This scaling factor is
  fixations within one group in the layout.                      individually sampled for each object after each saccade. (c)
                                                                 Objects whose text has not been identified and that were in
      400
                                                      Observed   unvisited groups are marked as potential candidates for the
                                                                 saccade destination. (d) The candidate object with the lowest
 Fixation Duration (ms)
      300                                             Step 1     eccentricity property, after the scaling factor is applied, is
                                                                 selected as the next saccade destination.
                                                                    The standard deviation of the fluctuation factor was
      200
                                                                 determined by varying the fluctuation factor (by increments
                                                                 no smaller than 0.01) to find the best fit of both the mean
      100                                                        saccade distance and mean fixations per group. We
                                                                 recommend this parameter setting for future modeling.
                                                                    Figures 3 and 4 show the Step 1 and 2 model predictions
         0                                                       for mean saccade distance and mean fixations per group. As
              1         2        4        6
                                                                 can be seen, the Step 2 model predicts the data much better.
                  Number of Groups                               The two modifications made to the model dramatically
Figure 2. Fixation duration observed (solid line) and predicted decreased the error in the predicted eye movement data.
by the Step 1 model (dashed line). AAE = 7.8% Error bars are
too small to be visible (standard errors < 15)
                                                                     1430

                                10                                               suggests that the participants may be failing to recognize the
                                                                  Observed       target occasionally. It should be noted that it is unlikely that
  Saccade Distance (degrees)
                               7.5                                Step 1         the participants did not react to the target because they had
                                                                                 forgotten the target, as the participants eventually found the
                                                                  Step 2         target and completed the task successfully.
                                 5                                                  Previous modeling research suggests that people do
                                                                                 occasionally fail to recognize fixated text. In Halverson and
                               2.5                                               Hornof’s (2004) “mixed density” model, a perceptual
                                                                                 parameter was introduced to explain an increase in the
                                 0                                               likelihood of missing a target based as a function of the text
                                     1      2       4         6                  density. The modeling suggested that even in sparse text,
                                         Number of Groups                        people fail to recognize the target with approximately a 10%
                                                                                 probability.
Figure 3. Saccade distance observed (circle), predicted by                          The model was modified to include a text recoding failure
the Step 1 model (squares), and predicted by the                                 rate. Text recoding failure rate has only recently been added
Step 2 model (triangles).                                                        to EPIC, and the default value is zero (i.e. no chance of
Step 1 AAE = 112%, Step 2 AAE = 5.8%                                             failing to identify text). The parameter represents the
Error bars are too small to be visible (standard errors < .2)                    probability that the text property of fixated visual objects will
                               2.5                                               be unknown.
                                                                  Observed          This perceptual parameter was used in the current work for
 Fixations per Group
                                2                                 Step 1         two reasons. First, to explore ways to account for the
                                                                                 observation that participants missed the target occasionally.
                               1.5                                Step 2         Second, to potentially provide converging support for the
                                                                                 validity of using this parameter. If the current exploratory
                                1                                                modeling predicts observed eye movement data with a text
                                                                                 recoding failure rate similar to that used in the previous
                               0.5                                               modeling, this would not only support the use of the
                                                                                 parameter here, but also suggest a recommended default
                                0
                                     2          4         6                      value for the parameter for future modeling.
                                                                                    The text recoding failure rate was initially set 10%, the
                                         Number of Groups
                                                                                 value used in the previous modeling effort for sparse text
Figure 4. Fixations per group observed (circles), predicted                      (Halverson & Hornof, 2004). This failure rate was varied by
by the Step 1 model (squares), and predicted by the Step 2                       1% increments until the model predicted the mean number of
model (triangles). Step 1 AAE = 42%, Step 2 AAE = 4.6%                           fixations per trial. A value of 9% provided the best fit for the
Error bars indicate ±1 standard error.                                           number of fixations per trial, the eye movement measure used
  The improvements made to the model in this step have                           to evaluate “whole-task” level performance.
improved the fidelity of the model, while making the model                          Figure 5 shows the observed and predicted number of
more reusable and flexible. The model requires only one                          fixations per trial. As can be seen in the figure, the Step 2
directly-extractable, task independent object feature—                           model under-predicts the total number of fixations required to
location. However, the model still requires improvement. As
will be seen, the model still finds the target too quickly, even                                      12.5
                                                                                                                                      Observed
though the model correctly predicts how long people dwell in
                                                                                                       10                             Step 2
each group.
                                                                                Fixations per Trial
                                                                                                       7.5                            Step 3
Step 3: Account for whole-task performance
Our goal is to produce a model that accounts for multiple eye                                           5
movement measures. This includes accounting for eye
movements at multiple scales. The previous iteration of the                                            2.5
model accounted for the number of fixations per group, which
can be viewed as accounting for a sub-task (searching each                                              0
                                                                                                             1     2        4     6
group) of the whole task (searching the entire layout). We
                                                                                                                 Number of Groups
next investigated means of improving the model at the
“whole-task” level.                                                            Figure 5. Fixations per trial observed (circles), predicted by
  Again, a qualitative analysis of the participants’ eye                       the Step 2 model (squares), and predicted by the Step 3
movement behavior suggests what might be needed in the                         model (triangles). Step 2 AAE = 14.3%, Step 3 AAE = 4.2%
model. It was observed that the participants sometimes                         Error bars indicate ±1 standard error. Some error bars are
looked at or near the target but continued to search. This                     too small to be visible.
                                                                             1431

find the target by 14%. This is not a bad prediction, but an                    robustness of the model for predicting the frequency with
error of less than 5% would be ideal.                                           which various scanpaths are followed.
   As shown in Figure 5, the Step 3 model predicts the                             Figure 6 shows the number of fixations per trial as a
number of fixations per trial with an error of 4.2%. This is a                  function of target group. (Figure 1 identifies the six groups as
very good prediction. The decreased error and the similarity                    A through F.) There is a slight bump in the data when the
between the best fitting text recoding failure rate found here                  target is located in group C. The purely local strategy for
and the rate found in past research provides support for the                    selecting nearby objects as saccade destinations motivates the
use of this perceptual parameter here. This finding suggests                    model to reach group D before group C, which was not the
that future modeling of menu-like search tasks should use a                     case with people. Though the effect is slight (with an overall
text recoding failure rate of around 9-10%.                                     AAE of 8.1%), we believe this trend points to the need for
                                                                                some sort of global component to the strategy.
Step 3A: Increase visual working memory decay                                      In local strategies, saccade destinations are determined
An interesting interaction between small layouts and EPIC’s                     based on what is encountered during the course of the search.
visual working memory gave rise to a surprising prediction.                     In global strategies, saccade destinations are planned out in
Occasionally the model would search a small layout without                      advance based on the task and stimuli.
finding the target (due to text recoding failures introduced in                    A global component was added to the strategy such that the
Step 3) and stall. The model assumed that objects whose text                    model could develop a global “preference” for scanning
properties (regardless of a text recoding failure) existed in the               horizontally or vertically. A preferred scanning direction is
visual perceptual store were not candidate saccade                              established after the model, using the local strategy, starts
destinations. EPIC’s visual perceptual store retains the                        searching horizontally or vertically. Once a direction is
properties of objects for 500 ms after the eyes moves.                          established, it is preferred unless no more groups exist in that
Therefore, the text properties of all objects were known after                  direction.
the second fixation and there were no candidate destinations                       Figure 7 shows that the global component slightly
for a third saccade. A variety of solutions were pursued, but                   improved the model’s prediction of fixations per trial. Most
only one was consistent with recent literature and did not                      important, the bump in the data for group C is diminished.
worsen eye movement predictions.                                                   Figure 8 shows the three most frequently observed
   Woodman, Vogel, and Luck (2001) showed that when                             scanpaths, as well as the predictions of the Step 3 and Step 4
VWM is occupied, visual search remains efficient. When                          models. People tended to start by going either down the first
people are given a task that fills VWM with visual properties                   column or across the top. As shown in the predictions, the
like shape, and then perform a second task searching for a                      Step 3 model almost never goes across the top. However, the
shape, search rates are unaffected. One interpretation of these                 Step 4 model increased the frequency.
findings is that VWM decays quickly for goal-irrelevant                            The improvements made by adding the global strategy are
information, like non-targets.                                                                             15
                                                                                                                                             6 Groups Observed
   The model was modified by setting the perceptual store
property retaining-time parameter to 50 ms. We would                                                                                         4 Groups Observed
                                                                                     Fixations per Trial
recommend this setting for future visual search models that                                                10                                2 Groups Observed
include small layout conditions.                                                                                                             1 Group Observed
                                                                                                                                             6 Groups Predicted
Step 4: Add a global strategy                                                                              5
                                                                                                                                             4 Groups Predicted
Step 4 adds a global search component to improve the
                                                                                                                                             2 Groups Predicted
                                                                                                           0                                 1 Group Predicted
                                                                                                                A   B      C    D    E   F
                       15                                                                                               Target Group
                                                        6 Groups Observed
                                                        4 Groups Observed           Figure 7. Fixations per trial observed (solid lines) and
 Fixations per Trial
                       10                               2 Groups Observed
                                                                                    predicted by the Step 4 model (dashed lines).
                                                                                    AAE = 6.5%. Error bars indicate ±1 standard error.
                                                        1 Group Observed
                                                                                    Some error bars are too small to be visible.
                                                        6 Groups Predicted
                       5
                                                        4 Groups Predicted
                                                        2 Groups Predicted
                       0                                1 Group Predicted
                            A   B    C     D    E   F
                                Target Position
Figure 6. Fixations per trial observed (solid lines) and
predicted by the Step 3 model (dashed lines).
AAE = 8.1%. Error bars indicate ±1 standard error.                               Figure 8. The most commonly observed scanpaths in six-
Some error bars are too small to be visible.                                     group layouts and how often each path was taken by the
                                                                                 participants (observed) and the models (Step 3 and 4).
                                                                             1432

                                                               6 Groups Observed
                                                                                          The integration of recent, relevant psychological
 Search Time per Trial (ms)
                              4000                                                     phenomena benefits the continued integrative development of
                                                               4 Groups Observed
                                                                                       computational models and advances in basic psychological
                              3000                             2 Groups Observed
                                                                                       research, and thus for Cognitive Science in general.
                                                               1 Group Observed        Phenomena include general saccadic selection behavior
                              2000
                                                               6 Groups Predicted      (Motter & Belky, 1998), visual working memory (Woodman,
                              1000                             4 Groups Predicted      Vogel, & Luck, 2001), and the integration of both local and
                                                               2 Groups Predicted      global strategies. This work will continue with further
                                0                              1 Group Predicted       integration of cognitive models of visual search from various
                                     A   B   C     D   E   F
                                                                                       cognitive architectures.
                                          Target Group
         Figure 9. Search time per trial observed (solid lines) and                                        Acknowledgments
         predicted (dashed lines). AAE = 7.1%. Error bars
         indicate ±1 standard error. Some error bars are too small                      This research was supported by the Office of Naval Research
                                                                                        and the National Science Foundation.
         to be visible.
subtle, but they add to the fidelity of the model. However, the                                                 References
addition of the global strategy does not improve the                                   Barbur, J. L., Forsyth, P. M., & Wooding, D. S. (1990). Eye
quantitative fit of the model substantially and the addition                             Movements and Search Performance. In D. Brogan, A. Gale & K.
may be considered overfitting as the additional production                               Carr (Eds.), Visual Search 2. London: Taylor & Francis.
rules introduce additional free parameters. Therefore, the Step                        Burke, M., Hornof, A. J., Nilsen, E., & Gorman, N. (2005). High-
3 model may be a better candidate on which to build                                      cost banner blindness: Ads increase perceived workload, hinder
successive flexible, reusable models of visual search that                               visual search, and are forgotten. Transactions on Computer-
account for more factors.                                                                Human Interaction, 12(4), 423-445.
  Figure 9 shows the observed and predicted search times of                            Halverson, T., & Hornof, A. J. (2004). Explaining Eye Movements
the Step 4 model. The model predicts the observed search                                 in the Visual Search of Varying Density Layouts. Proceedings of
                                                                                         the Sixth International Conference on Cognitive Modeling, 124-
time quite well. This is a validation of the principled approach
                                                                                         129, Pittsburgh, Pennsylvania.
used to gradually improve the model using a variety of eye
                                                                                       Hornof, A. J. (2004). Cognitive Strategies for the Visual Search of
movement data. Moreover, it is gratifying to find that the
                                                                                         Hierarchical Computer Displays. Human-Computer Interaction,
model is able to make such accurate predictions without using                            19(3), 183-223.
the more brittle strategies of its predecessors.                                       Hornof, A. J., & Halverson, T. (2003). Cognitive strategies and eye
                                                                                         movements for searching hierarchical computer displays.
                                                Conclusion                               Proceedings of the Conference on Human Factors in Computing
A flexible and reusable model of visual search was developed                             Systems, 249-256, Ft. Lauderdale, FL.
that accounts for a wide variety of search data by (a)                                 Kieras, D. E., & Meyer, D. E. (1997). An overview of the EPIC
saccading to nearby objects when the fixated text is                                     architecture for cognition and performance with application to
recognized, (b) positing a partial inspection of some objects                            human-computer interaction. Human-Computer Interaction,
and an occasional failure to identify others, (c) remembering                            12(4), 391-438.
more-or-less where but not what’s been searched, and (d)                               Kieras, D. E., & Meyer, D. E. (2005). Epic Progress. Paper
accounting for people’s tendencies to follow regular                                     presented at the presented at the Office of Naval Research
scanpaths with an element of a global strategy. The model                                Cognitive Modeling Grantee Meeting, Carnegie Mellon
                                                                                         University, Pittsburg, PA.
explains the observed saccade distances, the number of
                                                                                       Motter, B. C., & Belky, E. J. (1998). The guidance of eye
fixations to each group in a layout, the total number of
                                                                                         movements during active visual search. Vision Research, 38(12),
fixations in a trial, the number of fixations to find an object
                                                                                         1905-1815.
based on the object’s location in the layout, the fixation                             Pomplun, M., Reingold, E. M., & Shen, J. (2003). Area activation: a
duration, and to a slightly lesser extent the scanpaths that                             computational model of saccadic selectivity in visual search.
people used. The prediction of such a wide variety of                                    Cognitive Science, 27(2), 299-312.
measures bodes well for a priori prediction of visual search.                          Shen, J., Reingold, E. M., & Pomplun, M. (2003). Guidance of eye
   The model is flexible and reusable. The strategy is not                               movements during conjunctive visual search: The distractor-ratio
tuned to the visual layout of the task. The only features                                effect. Canadian Journal of Experimental Psychology, 57(2), 76-
required by the model are the location and identification (text)                         96.
of the visual objects to be searched. If the visual layout is                          Wolfe, J. M. (1994). Guided Search 2.0: A revised model of visual
divided into clearly distinguishable groups, the model can                               search. Psychonomic Bulletin and Review, 1(2), 202-238.
utilize that information, but this division is not required. The                       Woodman, G. F., Vogel, E. K., & Luck, S. J. (2001). Visual Search
model is currently limited to the visual search of textual                               Remains Efficient When Visual Working Memory is Full.
layouts, but most aspects of the model are clearly                                       Psychological Science, 12(3), 219-224.
generalizable to other stimuli.
                                                                                    1433

