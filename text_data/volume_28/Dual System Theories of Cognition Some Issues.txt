UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Dual System Theories of Cognition: Some Issues

Permalink
https://escholarship.org/uc/item/76d4d629

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Author
Evans, Jonathan St.B.T.

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Dual System Theories of Cognition:
Some Issues
Jonathan St B T Evans (jevans@plymouth.ac.uk)
Centre for Thinking and Language, School of Psychology,
University of Plymouth, Plymouth PL4 8AA, UK

than answers. There are a number of significant issues that
need to be addressed if a fully coherent dual system theory
of cognition is to be developed that is consistent with the
available evidence. The purpose of this paper is to highlight
these issues.

Abstract
Theories positing dual cognitive systems have become
popular in cognitive and social psychology. Although these
theories have a lot of common features, close inspection of
the literature reveals a number of difficult and unresolved
theoretical issues. Issues discussed in this paper relate to the
age of evolution of the systems, consciousness and control,
domain specificity, individual differences methods and the
question of how many distinct systems there might be in the
mind.

Issue 1: Old system/new system
The idea that System 1 cognition is ancient and System 2
cognition is modern, in evolutionary terms, is a recurring
theme in dual-process theories. This is often linked to the
assertion that while System 1 cognition is shared with other
animals, System 2 cognition is uniquely human. The last
idea arises from its association with uniquely human
processes such as language and reflective consciousness and
the apparent ability to perform cognitive acts (such as
hypothetical simulation of future and counterfactual
possibilities) that are assumed to be beyond animals.
However, little if any direct reference is generally made to
literature on animal cognition.
In fact, there is evidence also for distinct cognitive
systems in animals. For example, in a recent survey of
cognition in a wide range of animal species, the biologist
Toates (in press) has claimed that there is a widespread
division between cognition that is stimulus-bound on the
one hand and involving higher order control on the other.
Stimulus-bound cognition includes conditioning and the
application of instinctively programmed behavior of a fixed
nature. However, he shows that higher-order cognition is
also present in many species and suggests that this
developed into consciousness in humans. If he is right, then
the assumption that the dual system distinction is unique to
humans may be wrong. At best we could say that System 2
was better developed in humans.
The description of System 1 as ancient may be
oversimplified also, as it is likely that System 1 really
includes a number of different forms of implicit cognitive
processing that evolved at different times (see also Issue 5).
What does appear to be ancient is associative learning, at
least in its most basic forms, since humans share this facility
with most other animals, including birds, reptiles and fish.
However, if our implicit system also includes cognitive
modules, predisposing us to develop cognitive abilities that
are encapsulated in specific domains, there is good reason to
believe that these evolved much later. The cognitive
archaeologist Mithen (1996) has argued from data in the
archaeological and anthropological record that ancient
hominids (in common with apes) relied heavily on general
learning, whereas early humans (such as Neanderthals and

Dual processing accounts of cognition have been developed
in a range of areas including learning (e.g. Reber, 1993),
attention (Schneider & Shiffrin, 1977), reasoning (Evans,
2003), decision making (Kahneman & Frederick, 2002) and
social cognition (Chaiken & Trope, 1999). In spite of a
considerable degree of independence in the formulation of
these accounts, they include a number of striking
similarities. Processes that are rapid, automatic and
effortless on the one hand are contrasted with those that are
slow, sequential and controlled on the other. These theories
typically characterize the two processes as independent
sources of control for behavior that may come into conflict
and competition.
A number of theorists have mapped these dual processes
on to two distinct cognitive systems. These systems have
been given various names including experiential-rational
(Epstein, 1994), heuristic-analytic (Evans, 1989; in press),
heuristic-systematic (Chen & Chaiken, 1999), implicitexplicit (Evans & Over, 1996; Reber, 1993), associative and
rule-based (Sloman, 1996) and the neutral System 1 and
System 2 (Stanovich, 1999).
Again the characteristics
attributed to these underlying systems show quite a large
degree of consensus across theories and domains of
application. For example, System 1 (using this as a generic
label for the fast, automatic system) is often described as
evolutionarily old, shared with other animals and
independent of individual differences in general
intelligence, whereas System 2 is by contrast evolutionarily
recent, uniquely human and related to heritable differences
in intelligence and working memory capacity.
Given this degree of consensus in dual system theories
developed across different cognitive domains, it is tempting
to conclude that the brain must indeed contain two systems
broadly as described. However, closer inspection of these
theories and the relevant literature reveals more questions

202

Stanovich, 1999). Hence, the function of such processes
relates to what other theorists are describing as knowledge
stored in the modern human system.
The paradigm case for dual-process theories of reasoning
is that of belief bias. In this method (Evans et al., 1983;
Klauer et al., 2000) participants are given logical arguments
to evaluate whose conclusions either follow or do not follow
logically, and are either consistent or inconsistent with
belief. The research repeatedly shows that both logic and
belief significantly affect decisions made but that the two
appear to be in conflict within individuals. Consistent with
dual-process theory, the ability to resolve belief-logic
conflict problems in favor of logic is known to be related to
individual differences in cognitive ability (Newstead et al.,
2004), to decline in old age (Gilinsky & Judd, 1994) and to
be impaired by instructions to respond rapidly (Evans &
Curtis-Holmes, 2005).
In a neuropsychological study of the belief-bias effect,
Goel and Dolan (2003) have shown that when belief-logic
conflict is resolved in favor of logic, brain areas associated
with executive control are recruited. However, the same
research also shows (unsurprisingly) that belief bias arises
in modern frontal brain areas associated with semantic
memory. Thus while these pragmatic processes have the
typical System 1 characteristics (rapid, parallel, automatic
etc), they are certainly not ‘ancient’ in origin. Nor are they
likely to be shared with non-human animals that lack an
explicit belief system. Thus while some cognitive biases
may be attributed to a mismatch between the function of
evolutionarily old cognitive systems and the much changed
environment of the current world (Stanovich, 2004) we
clearly need a different account for others, including belief
biases. As Evans (in press) demonstrates, cognitive biases
may also arise during analytic processing in System 2.

archaic Homo Sapiens) developed specialized intelligences
in social, technical, natural history and (eventually)
linguistic domains. Mithen’s arguments do, however,
support the view that System 2 evolved recently and
uniquely in modern humans. He describes the emergence of
a fluid intelligence, allowing cross-linkage between
specialized intelligences that facilitated the ‘big bang’ of
human culture c. 60,000 years ago, with the emergence of
art, religion and the ability rapidly to adapt the design of
artifacts to changing environmental demands (see also
Mithen, 2002).
Some dual-process accounts, particularly in the
philosophy of mind, talk as though the contrast to conscious
analytic thinking was primarily with modular cognition.
Fodor (1983) contrasted input modules, such as those
involved in vision and language with a general purpose
reasoning system in a form of dual process theory. The
processes of such modules were said to be encapsulated
within dedicated mechanisms and only the outputs of the
modules (for example, the represented meaning of a
sentence or some perceptual input) would be available to
general thinking and reasoning. Fodor laid out strict criteria
for modules including domain specificity, association with
specific brain areas, specific course of development, specific
patterns of impairment and so on. However, evolutionary
psychologists (Cosmides & Tooby, 1994; Tooby &
Cosmides, 1992; Pinker, 1997) later applied the concept of
domain-specific, information-encapsulated modules to
higher order cognitive processes in reasoning and decision
making, ignoring a number of these criteria in the process
(see Fodor, 2001 for a strong riposte).
The evolutionary psychology debate is relevant to dualprocess theorists as evolutionary psychologists initially
sought strongly to downplay the role of general purpose
cognition in favor of domain-specific modules as well as
that of heritable individual differences in general
intelligence (Tooby & Cosmides, 1992) thus apparently
allowing little if any role for System 2. Dual process
theorists have responding with strong criticisms of this
programme of work (Stanovich, 2004; Stanovich & West,
2003; Over, 2003). More recently, evolutionary
psychologists seem to have conceded that humans have
unique abilities to apply their reasoning across a broad range
of domains, albeit described in terms of ‘modules’ for metarepresentation or mental logic (Cosmides & Tooby, 2000;
Sperber, 2000).
The mapping of the old-new distinction on to the two
systems seems to work better in terms of knowledge
representation than in terms cognitive processing. It is often
claimed that there are two forms of knowledge, an old form
captured implicitly in neural networks and a modern human
form represented explicitly in a propositional belief system
(for example, Epstein & Pacini, 1999; Reber, 1993; Sun et
al. 2005). However, the application of the old-new
distinction to implicit and explicit reasoning systems (Evans
& Over, 1996; Stanovich, 1999) has a led to something of a
muddle. The problem is that one kind of implicit processing
that has greatly interested reasoning theorists are the
pragmatic processes which automatically contextualize
problems with prior belief and knowledge (Evans, in press;

Issue 2: Consciousness and control
Dual system theories clearly associate the unconsciousconscious distinction with the division by System 1 and 2.
System 1 represents the ‘cognitive unconscious’ (Reber,
1993) or ‘adaptive unconscious’ (Wilson, 2002) with
associated characteristics often described as rapid,
automatic, parallel etc. System 2 thinking is usually
described as slow and sequential and ‘controlled’, all
features of conscious thinking. Hence, research on dual
processes would appear to speak to the issue of what are the
cognitive correlates of consciousness. For example, Evans
and Over (1996) argue that all forms of hypothetical
thinking of necessity require explicit representation of
suppositions and are hence associated with System 2.
The difficult issue that is concerned here is that of the
notion of cognitive control. Some philosophers of mind
believe that folk psychology, or belief-desire psychology
can provide a convincing level of explanation of the human
mind (Haselager, 1997), although the need for this to be
incorporated within a dual-process framework has recently
been recognized (Frankish, 2004). Intentional level accounts
of the mind in terms of conscious expressed beliefs and

203

heavily contextualized in line with what he calls the
‘fundamental computational bias’ whereas System 2
thinking (which he strongly associates with heritable
individual differences in general intelligence) is capable of
abstract reasoning which can lead to normatively correct
solutions to problems in logical reasoning, statistical
judgment and decision making. Implicit cognition is
generally regarded as domain-specific whether acquired
through implicit learning (Berry & Dienes, 1993) or from
innate cognitive modules (Tooby & Cosmides, 1992).
A popular theory of reasoning holds that the mind includes
a mental logic comprised of abstract inferential rules
(Braine & O'Brien, 1998; Rips, 1994). The description of
deductive competence in terms of semantic processing of
mental models (Johnson-Laird & Byrne, 1991) can also be
regarded as a form of mental logic. If System 2 is abstract,
decontextualized and normative then it might be tempting to
equate it with some from of mental logic. However, the
notion of a mental logic seems too narrow to capture the
range of features attributed to System 2 cognition. Nor is it
even clear that logical ability should be a necessary part of
the definition of analytic reasoning. There is, in fact,
nothing in the concept of a process that is slow, conscious,
explicit and demanding of central working memory
resources that necessarily makes it abstract and
decontextualized, let alone logically competent. Nor do all
reasoning theorists accept that there is anything special
about logic (Evans, 2002). It can be argued that solving
logical reasoning problems is just one kind of strategic
thinking that can be undertaken successfully by System 2 by
those of sufficient cognitive ability who are appropriately
instructed (Evans, 2000).
It does, however, appear that knowledge acquired
experientially tends to remain captured in the domain of
experience while that acquired through explicit study and
instruction can be generalized to range of domains. An
example is the law of large numbers that can be acquired in
an implicit and domain-specific way (Nisbett et al., 1983) or
an explicit and domain-general way (Fong et al., 1986).
There is also extensive evidence that performance on
abstract reasoning problems is much more strongly related
to cognitive ability than is contextualized reasoning
(Stanovich, 1999). It may well be the case that abstract,
decontexualized reasoning cannot be achieved without use
of System 2, although I am not sure it is wise to describe
System 2 as ‘rule-based’ (Sloman, 1996) if only because it
implies that System 1 cognition does not involve rules.
Rules can be concrete as well as abstract and any automatic
cognitive system that can be modeled computationally can
in some sense be described as following rules.
I believe that thinking of System 2 as an abstract or
logical system is a mistake to be avoided. Recently,
researchers studying deductive reasoning have provided
dual processing accounts of kinds of reasoning that are
highly contextualized. In the case of conditional reasoning,
for example, belief could influence us in a System 1 manner
when we have an intuition of a degree of connection

goals do seem to give an account of aspects of human
behavior that would be intractable in terms of implicit
learning or modular processes as has been recognized by a
number of dual process theorists.
Dual process studies of reasoning and decision making
have drawn quite heavily upon individual differences
methods (see Issue 4). While individual differences in
cognitive ability (IQ, working memory capacity) have been
shown to be good predictors of analytic reasoning ability,
such research has also shown that residual variance can be
accounted for in terms of cognitive styles (Kokis et al.,
2002; Klaczynski, 2000; Stanovich, 1999). The importance
of a disposition to reason critically or analytically supports
the volitional nature of System 2. Such dispositions can be
induced by personality, instructional set or cultural context
(Nisbett et al., 2001). The notion that what is not implicit
and automatic is conscious and controlled also has
foundations in studies of attention and motor control
(Schneider & Shiffrin, 1977) which have been a major
influence on dual process theories of social cognition
(Chaiken & Trope, 1999).
The problem, however, is that it is far from clear the
extent to which conscious thinking really is ‘in control’ of
behavior. First, it seems that heuristic processes in System 1
will control our behavior by default unless a conscious
effort is made to override these by explicit effortful
reasoning (Evans, 2006; Kahneman & Frederick, 2002,
Stanovich, 1999, 2004). Such effort may, however, be
unsuccessful: for example, no amount of exhortation to
reason logically and ignore prior beliefs has yet been able to
remove (as opposed to simply weaken) belief biases in
reasoning (Evans et al., 1994). Just as our conscious level
cognition can lack control, so also – according to some
social psychologists – can unconscious level cognition
sometimes be intentional (see Hassin et al., 2005)
suggesting that the automatic-controlled distinction between
the Systems 1and 2 is far from clear cut.
The other problem, recognized by some dual process
theorists (Evans & Over, 1996; Stanovich, 2004) is that
analytic reasoning in System 2 can often be applied to the
rationalization of unconsciously controlled behavior and to
the confabulation of explanations. It seems we apply folk
psychology to explain our own behavior as well as that of
others. This problem has long been recognized as a source
of difficulty in the interpretation of introspective reports
(Nisbett & Wilson, 1977; see also Wilson & Dunn, 2004).
Thus our consciously experienced and expressed beliefs,
desires and intentions may sometimes provide an intentional
level account of behaviors controlled in System 2, but may
also provides mere rationalization of behaviors controlled in
System 1. To my knowledge, no methodological device
exists for reliably telling one from the other.

Issue 3: Domain specificity
The notion that System 1 cognition is domain-specific while
System 2 is domain-general is yet another recurring theme.
For example, Stanovich (1999) regards System 1 thinking as

204

between antecedent and consequent based on our beliefs.
However, it could also influence us in System 2 manner
when we consciously decide that a counterexample retrieved
from memory should block an inference that we would
normally make. Evidence that two such processes may
compete to control conditional reasoning in context has
recently been produced (De Neys et al., 2005) supporting a
dual process account that is independent of the concreteabstract distinction.

rapid, parallel etc) as belong to a single alternative system
(System 1, heuristic system, implicit system etc). I have
already shown earlier how this way of thinking has led to a
muddle in which automatic processes associated with the
modern human belief system have somehow been labeled as
ancient.
It seems clear to me that there are quite a number of
different kinds of implicit cognitive processes in the mind.
Experiential learning of various kinds, including low level
associative and conditioning processes is (at least) one kind.
There is at least some cognition that is modular in Fodor’s
sense, at the level of perceptual systems and quite probably
underlying language and our theory of mind. These
processes may be ancient and intermediate in evolutionary
terms respectively if Mithen’s (1996) arguments are
accepted. I have also referred here to pragmatic processes,
important in dual process theories of reasoning that retrieve
and apply relevant knowledge from explicit memory and
belief systems which are of recent evolution and associated
with the modern human mind. To these three types of
implicit processes, I can add a fourth: automated cognition.
In fact, the term ‘automatic’ process has a narrower sense
than that in which I have been using it, when applied to
processes that start off explicit under conscious control and
later become automated, an important concept in studies of
attention and motor control (Monsell & Driver, 2000).
Stanovich (2004) recognizes a similarly diverse range of
implicit cognitive systems and for this reason has preferred
to use the term TASS – the set of autonomous subsystems –
to the previous catch-all ‘System 1’. Unconscious
processing is also associated with multiple systems by
Wilson (2002).
It seems that there are implicit processes that were once
conscious, others that were never conscious but deliver a
product to consciousness, and still others that influence our
behavior without ever being conscious in any sense at all.
Does it make sense to classify all these together in ‘System
1’? Almost certainly not. All that really links dual process
theories together is the nature of System 2 and the way in
which implicit and automatic processes (of whatever kind)
appear to compete with it for control of our behavior. Our
knowledge of the underlying architecture of all this is next
to non-existent. It may be that the mapping of cognitive
functions on to neurological regions will help with this
enterprise, but that is far from clear at present (Goel, 2005).
For example, there is no a priori way to know whether
cognitive systems would be mapped on to brain systems in a
localized or distributed manner.

Issue 4: Individual differences
As mentioned earlier, there has been an explosion of interest
in the study of individual difference in cognitive ability as a
technique for investigating hypotheses about dual processes,
initiated by a series of studies by Stanovich and West (2000;
Stanovich, 1999). The logic of the method is that problems
requiring analytic reasoning should be better solved by
those high in cognitive ability, whereas those that can be
solved by application of belief based processes in System 1
should be independent of such measures. A classic example
is provided by the study of Stanovich and West (1998) who
showed that cognitive ability is much more strongly related
to performance on the abstract Wason selection task than to
that on concrete and deontic versions.
Some recent studies (e.g. Capon et al., 2003) have used
measures of working memory capacity that are known to be
closely related to general intelligence scores (Colom et al.,
2004). However, there is problem here in that the concept of
capacity and of executive control, or inhibition may be
confused. While dual process theorists (e.g. Evans, 2003;
Stanovich, 1999) have claimed that people of higher abilty
are better able to inhibit belief biases (implying executive
control) it is not clear that the data support this. While it is
true that people of higher ability can more successfully
resolve belief-logic problems in favor of logic, this method
is confounded. It is possible that logical performance
improves but that belief bias is no less marked in higher
ability participants as indeed recent studies suggest
(Newstead et al., 2004; Torrens et al., 1999).
The issue which needs to be resolved in this area is
whether higher ability participants are more likely to reason
analytically (as the inhibition hypotheses implies) or
whether they simply are more effective and normatively
correct when they do engage in such reasoning. It could be
that the tendency to apply analytic reasoning is entirely a
function of dispositional variables and independent of
cognitive ability.

Issue 5: Two systems or many?

Conclusions

The final issue that I will raise in this paper concerns the
number of cognitive systems in the mind and in particular
the coherence of the concept of System 1. System 2 which is
by definition a singular, sequential system requiring
conscious attention and access to a single central system of
working memory seems reasonably coherent. The problem,
however, arises in labeling all forms of cognitive processes
that are in not in System 2 (that is unconscious, automatic,

Dual process theories are widespread in psychology and
seem necessary to account for many cognitive tasks. The
difficulties identified in this paper arise from attempts to
map dual processes on to underlying cognitive systems.
Although it is striking that theorists in different areas have
proposed dual systems with broadly similar characteristics,
it is far from evident at present that a coherent theory based

205

on two systems is possible. For example, the equation of
automatic and controlled with unconscious and conscious
processing is fraught with difficulties. It also appears that
there are a number of different kinds of implicit cognition
and the underlying subsystems probably have quite distinct
evolutionary and neurological bases. We have little or no
understanding of the cognitive architecture that underlies
this.
The most perplexing issue in all this is how generally well
controlled, predictable and effective most of our behavior
actually is. Sane people, by and large, execute successfully
many parallel life plans of differing durations. Most people
manage to get up in the morning, go to work, manage their
domestic affairs, maintain relationships and utilize their
leisure time broadly in accordance with their goals.
Although system conflicts occasionally become manifest (as
when a person finds it difficult to lose weight, quit smoking
or give up gambling in accordance with a consciously
expressed intention) we generally breeze through life with
little awareness of the cognitive turmoil that is apparently
afflicting our minds. If the conscious, analytic system is at
best only partially in control and in competition with not
one but several implicit systems, how come everything
works so well? Understanding how generally adaptive
behavior can result from such an apparently chaotic
cognitive architecture is one of the great challenges for
cognitive science.

Cosmides, L. & Tooby, J. (1994). Beyond intuition and
instinct blindness: Toward an evolutionary rigorous
cognitive science. Cognition, 50, 41-77.
Cosmides, L. & Tooby, J. (2000). Consider the source: The
evolution of adaptations for decoupling and
metarepresentation.
In
D.Sperber
(Ed.),
Metarepresentations (pp. 53-115). Oxford: Oxford
University Press.
De Neys, W., Schaeken, W., & d'Ydewalle, G. (2005).
Working memory and everyday conditional reasoning:
Retrieval and inhibition of stored counterexamples.
Thinking & Reasoning, 11, 349-381.
Epstein, S. (1994). Integration of the cognitive and
psychodynamic unconscious. American Psychologist, 49,
709-724.
Epstein, S. & Pacini, R. (1999). Some basic issues regarding
dual-process theories from the perspective of cognitiveexperiential theory. In S.Chaiken & Y. Trope (Eds.),
Dual-process theories in social psychology (pp. 462-482).
New York: The Guildford Press.
Evans, J. S. B. T. & Curtis-Holmes, J. (2005). Rapid
responding increases belief bias: Evidence for the dualprocess theory of reasoning. Thinking & Reasoning, 11,
382-389.
Evans, J. St. B. T. (1989). Bias in Human Reasoning:
Causes and Consequences. Brighton: Erlbaum.
Evans, J. St. B. T. (2000). What could and could not be a
strategy in reasoning. In W.Schaeken, G. DeVooght, & A.
d. G. Vandierendonck (Eds.), Deductive Reasoning and
Strategies (pp. 1-22). Mahway, NJ.: Lawrence Erlbaum
Associates.
Evans, J. St. B. T. (2002). Logic and human reasoning: An
assessment of the deduction paradigm. Psychological
Bulletin, 128, 978-996.
Evans, J. St. B. T. (2003). In two minds: Dual process
accounts of reasoning. Trends in Cognitive Sciences, 7,
454-459.
Evans, J. St. B. T. (in press). The heuristic-analytic theory
of reasoning: Extension and evaluation. Psychonomic
Bulletin and Review.
Evans, J. St. B. T., Allen, J. L., Newstead, S. E., & Pollard,
P. (1994). Debiasing by instruction: the case of belief
bias. European Journal of Cognitive Psychology, 6, 263285.
Evans, J. St. B. T., Barston, J. L., & Pollard, P. (1983). On
the conflict between logic and belief in syllogistic
reasoning. Memory and Cognition, 11, 295-306.
Evans, J. St. B. T. & Over, D. E. (1996). Rationality and
Reasoning. Hove: Psychology Press.
Fodor, J. (1983). The Modularity of Mind. Scranton, PA:
Crowell.
Fodor, J. (2001). The mind doesn't work that way.
Cambridge, Mass.: MIT Press.
Fong, G. T., Krantz, D. H., & Nisbett, R. E. (1986). The
effects of statistical training on thinking about everyday
problems. Cognitive Psychology, 18, 253-292.

Acknowledgements
This work was supported by a research fellowship award
to the author by the Economic and Social Research Council
of the United Kingdom (RES-000-27-0184).

References
Berry, D. C. & Dienes, Z. (1993). Implicit Learning. Hove,
UK: Erlbaum.
Braine, M. D. S. & O'Brien, D. P. (1998). (Eds) Mental
logic. Mahwah, New Jersey: Lawrence Erlbaum
Associates.
Capon, A., Handley, S. J., & Dennis, I. (2003). Working
memory and reasoning. Thinking & Reasoning, 9, 203244.
Chaiken, S. & Trope, Y. (1999). (Eds.) Dual-process
theories in social psychology. New York: Guildford Press.
Chen, S. & Chaiken, S. (1999). The heuristic-systematic
model in its broader context. In S.Chaiken & Y. Trope
(Eds.), Dual-process theories in social psychology ( New
York: The Guildford Press.
Colom, R., Rebollo, I., Palacios, A., Juan-Espinosa, M., &
Kyllonen, P. C. (2004). Working memory is (almost)
perfectly predicted by g. Intelligence, 32, 277-296.

206

D.E.Over (Ed.), Evolution and the psychology of thinking:
The debate (pp. 121-144). Hove, UK.: Psychology Press.
Pinker, S. (1997). How the mind works. New York: Norton.
Reber, A. S. (1993). Implicit Learning and Tacit
Knowledge. Oxford: Oxford University Press.
Rips, L. J. (1994). The Psychology of Proof. Cambridge,
MA: MIT Press.
Schneider, W. & Shiffrin, R. M. (1977). Controlled and
automatic human information processing I: Detection,
search and attention. Psychological Review, 84, 1-66.
Sloman, S. A. (1996). The empirical case for two systems of
reasoning. Psychological Bulletin, 119, 3-22.
Sperber, D. (2000). Metarepresentations in an evolutionary
perspective. In D.Sperber (Ed.), Metarepresentations (pp.
117-138). Oxford: Oxford University Press.
Stanovich, K. E. (1999). Who is Rational? Studies of
Individual Differences in Reasoning. Mahway, NJ:
Lawrence Elrbaum Associates.
Stanovich, K. E. (2004). The robot's rebellion: Finding
meaning the age of Darwin. Chicago: Chicago University
Press.
Stanovich, K. E. & West, R. F. (1998). Cognitive ability and
variation in selection task performance. Thinking &
Reasoning, 4, 193-230.
Stanovich, K. E. & West, R. F. (2000). Individual
differences in reasoning: Implications for the rationality
debate. Behavioral and Brain Sciences, 23, 645-726.
Stanovich, K. E. & West, R. F. (2003). Evolutionary versus
instrumental goals: How evolutionary psychology
misconceives human rationality. In D.E.Over (Ed.),
Evolution and the psychology of thinking (pp. 171-230).
Hove, UK.: Psychology Press.
Sun, R., Slusarz, P., & Terry, C. (2005). The interaction of
the explicit and the implicit in skill learning: A dualprocess approach. Psychological Review, 112, 159-192.
Toates, F. (in press). A model of the hierarchy of behaviour,
cognition and consciousness. Consciousness and
Cognition.
Tooby, J. & Cosmides, L. (1992). The psychological
foundations of culture. In J.H.Barkow, L. Cosmides, & J.
Tooby (Eds.), The adapted mind: Evolutionary
psychology and the generation of culture (pp. 19-136).
New York: Oxford University Press.
Torrens, D., Thompson, V. A., & Cramer, K. M. (1999).
Individual differences and the belief bias effect: Mental
models, logical necessity, and abstract reasoning.
Thinking & Reasoning, 5, 1-28.
Wilson, T. D. (2002). Strangers to ourselves. Cambridge,
Mass.: Belknap Press.
Wilson, T. D. & Dunn, E. W. (2004). Self-knowledge: Its
limits, value and potential for improvement. Annual
Review of Psychology, 55, 493-518.

Frankish, K. (2004). Mind and supermind. Cambridge:
Cambridge University Press.
Gilinsky, A. S. & Judd, B. B. (1994). Working memory and
bias in reasoning across the life-span. Psychology and
Aging, 9, 356-371.
Goel, V. (2005). Cognitive neuroscience of deductive
reasoning. In K.Holyoak & R. G. Morrison (Eds.), The
Cambridge handbook of thinking and reasoning (pp. 475492). Cambridge: Cambridge University Press.
Goel, V. & Dolan, R. J. (2003). Explaining modulation of
reasoning by belief. Cognition, 87, B11-B22.
Haselager (1997). Cognitive science and folk psychology.
London: Sage.
Hassin, R. R., Uleman, J. S., & Bargh, J. A. (2005). (Eds)
The new unconscious. Oxford: Oxford University Press.
Johnson-Laird, P. N. & Byrne, R. M. J. (1991). Deduction.
Hove & London: Erlbaum.
Kahneman, D. & Frederick, S. (2002). Representativeness
revisited: Attribute substitution in intuitive judgement. In
T.Gilovich, D. Griffin, & D. Kahneman (Eds.), Heuristics
and biases: The psychology of intuitive judgement (pp.
49-81). Cambridge: Cambridge University Press.
Klaczynski, P. A. (2000). Motivated scientific reasoning
biases, epistemological beliefs, and theory polarization: A
two-process approach to adolescent cognition. Child
Development, 71, 1347-1366.
Klauer, K. C., Musch, J., & Naumer, B. (2000). On belief
bias in syllogistic reasoning. Psychological Review, 107,
852-884.
Kokis, J. V., MacPherson, R., Stanovich, K. E., Toplak, M.
E., & West, R. F. (2002). Heuristic and analytic
processing: Age trends and associations with cognitive
ability and cognitive styles. Journal of Experimental
Child Psychology, 83, 26-52.
Mithen, S. (1996). The prehistory of the mind. London:
Thames and Hudson.
Mithen, S. (2002). Human evolution and the cognitive basis
of science. In P.Carruthers, S. Stich, & M. Siegal (Eds.),
The cognitive basis of science (pp. 23-40). Cambridge:
Cambridge University Press.
Monsell, S. & Driver, J. (2000). Control of cognitive
processes. Cambridge, Mass.: MIT Press.
Newstead, S. E., Handley, S. J., Harley, C., Wright, H., &
Farelly, D. (2004). Individual differences in deductive
reasoning.
Quarterly
Journal
of
Experimental
Psychology, 57A, 33-60.
Nisbett, R., Peng, K., Choi, I., & Norenzayan, A. (2001).
Culture and systems of thought: Holistic vs analytic
cognition. Psychological Review, 108, 291-310.
Nisbett, R. E., Krantz, D. H., Jepson, D. H., & Kunda, Z.
(1983). The use of statistical heuristics in everyday
inductive reasoning. Psychological Review, 90, 339-363.
Nisbett, R. E. & Wilson, T. D. (1977). Telling more than we
can know: Verbal reports on mental processes.
Psychological Review, 84, 231-295.
Over, D. E. (2003). From massive modularity to
metarepresentation: The evolution of higher cogntion. In

207

