UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Conceptual Complexity and the Bias-Variance Tradeoff
Permalink
https://escholarship.org/uc/item/8pt7k31s
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Briscoe, Erica
Feldman, Jacob
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                         Conceptual Complexity and the Bias-Variance Tradeoff
                                                 Erica Briscoe (ebriscoe@rci.rutgers.edu)
                       Department of Psychology, Rutgers University - New Brunswick 152 Frelinghuysen Rd.
                                                             Piscataway, NJ 08854 USA
                                                Jacob Feldman (jacob@ruccs.rutgers.edu)
    Department of Psychology, Center for Cognitive Science, Rutgers University - New Brunswick, 152 Frelinghuysen Rd.
                                                             Piscataway, NJ 08854 USA
                                Abstract                                     (Ashby & Alfonso-Reese, 1995; Rosseel, 2002; Vanpaemel,
                                                                             Storms, & Ons, 2005) have pointed out how the two ap-
   In this paper we propose that the dichotomy between exemplar-             proaches may be seen as interrelated (see discussion below).
   based and prototype-based models of concept learning can be               In this paper, we suggest a new way in which prototype and
   regarded as an instance of the tradeoff between complexity and
   data-fit, often referred to in the statistical learning literature as     exemplar models may be regarded as formally related, tap-
   the bias-variance tradeoff. This continuum reflects differences           ping a very basic continuum drawn from statistical learning
   in models’ assumptions about the form of the concepts in their            literature, known as the bias-variance tradeoff. We then test
   environments: models at one extreme, here exemplified by                  this idea by teaching subjects concepts intended to favor one
   prototype models, assume a simple conceptual form, entailing              or the other end of the continuum—specifically, by varying
   high bias; models at the other extreme, exemplified by exem-
   plar models, entertain more complex hypotheses, but tend to               the level of complexity of the set of objects to be learned.
   overfit the data, with a concomitant loss in generalization per-          Our results suggest that human subjects tend to fall between
   formance. To investigate human learners’ place on this contin-            the extremes represented by the two historically influential
   uum, we had subjects learn concepts of varying levels of struc-           models, and more generally, that this is a fruitful new way of
   tural complexity. Concepts consisted of mixtures of Gaussian
   distributions, with the number of mixture components serving              looking at categorization strategies.
   as the measure of complexity. We then fit subjects’ responses
   to both a representative exemplar model and a representative                             The Bias-Variance Tradeoff
   prototype model. With moderately complex multimodal cate-
   gories, the exemplar model generally fit subjects’ performance            A key aspect of any learning model is the success with which
   better, due to the prototype models’ overly narrow (high-bias)            it forms generalizations from training data, as measured by
   assumption of a unimodal concept. But with high-complexity                its accuracy in classifying further data from the same source.
   concepts, the exemplar model’s overly flexible (high-variance)
   assumptions made it overfit concepts relative to subjects, al-            Somewhat counter-intuitively, this accuracy is not maximized
   lowing it to outperform subjects on highly complex concepts.              by modeling training data as accurately as possible. An ex-
   We conclude that neither strategy is uniformly optimal as a               tremely close fit to training data tends to generalize poorly to
   model of human performance.                                               future data, because such a fit inevitably entails fitting ran-
                                                                             dom (noise) aspects of the sample as well as regular, replica-
                                                                             ble trends, a phenomenon known as overfitting. On the other
                           Introduction                                      hand, a model that fits the training data too poorly will miss
Modern research on categorization has centered around two                    regular trends as well as noise, called underfitting. The crit-
general strategies for conceptual representation, termed pro-                ical variable modulating this phenomenon is the complexity
totype theories and exemplar theories. Prototype and exem-                   of the hypotheses entertained by the learner (for example, the
plar theories make strikingly different assumptions about how                degree of the polynomial used in fitting a sequence of numeric
learners use their past experience with category examples.                   data). More complex hypotheses (e.g. higher-degree polyno-
Prototype theories (e.g. Smith & Minda, 1998; Nosofsky,                      mials) can, by definition, fit the training data more closely,
1987) assume that learners induce from observed category                     while less complex ones may lack the flexibility to fit it well
members a central tendency, called the prototype, used as a                  enough. The tradeoff is referred to as “bias vs. variance”
composite against which newly encountered items are com-                     because at one extreme (simple hypotheses), the model im-
pared. New items judged sufficiently similar to the prototype                poses a strong expectation or “bias” on the data, sacrificing
are judged to be members of the category. By contrast, in                    fit, while at the other extreme (complex hypotheses), hypothe-
exemplar theories (e.g. Kruschke, 1992; Medin & Schaffer,                    ses are more flexible (i.e., exhibit greater variance), risking
1978; Nosofsky, 1987), no central tendency is computed. In-                  overfitting. The phenomenon can be seen schematically by
stead, the learner stores the attributes of observed examples                plotting generalization accuracy as a function of model com-
along with category labels, called exemplars. Category de-                   plexity; accuracy first rises to some optimum, but then de-
cisions are then made by comparing newly observed items                      clines (Fig. 1). This basic tradeoff arises in a wide variety of
to these stored exemplars, and objects are classified via their              settings, as it seems to be fundamental to the vary nature of
similarity to these memorized examples.                                      generalization of any data that involve an unknown mixture of
   Historically, prototype and exemplar strategies have been                 regular and random elements (Dietterich, 2003; Hastie, Tib-
regarded as qualitatively different, and often competing, ac-                shirani, & Friedman, 2001).
counts of categorization. More recently, several authors                         The bias-variance tradeoff is a useful way to understand the
                                                                         1038

                                                                         Figure 2: Schematic illustrations (contour plots) of the five concept
                                                                         types. Each concept consisted of a mixture of N Gaussian clouds in
                                                                         a two-feature space, with N ranging from 1 (left) to 5 (right).
                                                                         range of points on the bias-variance continuum by systemat-
Figure 1: A schematic illustration of generalization accuracy as a       ically manipulating the complexity of concepts presented to
function of model complexity, illustrating the bias-variance trade-      subjects. By confronting subjects with categories with vary-
off. (Note: model complexity here is schematic and differs from the      ing levels of structural complexity, we may empirically ex-
measure used in subsequent graphs.)                                      amine how each of the two historically influential strategies
                                                                         fares as a model of human performance, ranging parametri-
                                                                         cally between the zone tacitly assumed by prototype models
distinction between exemplar and prototype concept learning              (simple concepts) to that tacitly assumed by exemplar models
models. Along this continuum, prototype models exemplify                 (complex concepts). We were interested in the effect of con-
the “bias” end of the spectrum. With a very simple, con-                 ceptual complexity on human performance, and also, more
strained schema for categories (the prototype), such models              specifically, on the influence of complexity of the nature of
impose a strong bias on the observations, and thus will poorly           subjects’ learning strategies.
fit data not conforming to this schema. Highly disjunctive
or chaotic concepts, which are not well-described by a sin-                    Experiment: Manipulating Complexity
gle central tendency, will generally be underfit by a prototype
classifier. Data generated by a simple highly coherent source,           Accordingly, the strategy in our study was to confront sub-
by contrast, might be well fit by this strategy.                         jects with concepts of varying levels of complexity, and then
   Exemplar models, on the other hand, exemplify the “vari-              to fit a representative prototype model and a representative
ance” end of the spectrum. By using individual stored ex-                exemplar model to their classification responses. Our aim
emplars as classification standards, an exemplar model in ef-            was also to adopt a simple, theoretically neutral measure of
fect entertains a very complex decision surface, with as many            complexity. To this end we constructed concepts using two
bends and wrinkles as there are learned exemplars. Such a                continuous features, with the positive examples drawn from
system, by design, can learn arbitrarily complex collections             a probability density function that was a mixture of N Gaus-
of examples, as it imposes minimal expectations (bias) on                sian sources, with N varying from 1 to 5 (Fig. 2). N = 1
the structure they are liable to exhibit. Such a strategy al-           concepts are simple, unimodal Gaussian clouds. At the other
lows flexible learning but, of course, risks overfitting when           extreme, N = 5 concepts are highly heterogeneous mixtures
the concepts are simple and the observed complexities are ac-            with five distinct modes. The number N thus represents the
tually noise.                                                           complexity of the conceptual structure in a fairly transparent
   An ideal model of categorization would seek to balance               way.
bias and variance, finding an ideal level of hypothesis com-                A number of earlier studies (McKinley & Nosofsky, 1995;
plexity, and thus optimizing its ability to generalize. But such        Smith & Minda, 1998) have varied the structure of concepts
an ideal balance cannot, unfortunately, be determined a priori,         in attempts to probe subjects’ learning strategies, and indeed
because it depends on the nature of the classes to be learned.          concluded that the success of one strategy or the other de-
Specifically, it depends on the proportion of regularity and            pends on the “diffusion” or “differentiation” of the concepts
noise in the source that generates the observations, i.e. on the        on which performance was tested. Our study, we feel, takes a
complexity typical of the environment.                                  step forward by putting this intuition on a firmer footing, by
   In this light it may be seen that prototype and exemplar             varying conceptual structure in a more systematic way, and
models reflect different tacit assumptions about the nature of          by tying the resulting variations in learning success to a fun-
“natural” concepts in the human learner’s environment. Pro-             damental spectrum of strategies in learning.
totype models will be effective in an environment in which
natural classes tend to take the form of single, unimodal prob-
                                                                        Subjects
ability distributions in some feature space, and would be ex-           Thirteen undergraduates at Rutgers University received class
pected to perform poorly in more complex environments. Ex-              credit for participation.
emplar models, by contrast, tacitly presume a complex envi-
ronment in which each object might, in principle, act as a              Stimuli and Procedure
“class of its own.” Such a model represents an effective strat-         The objects observed by our subjects were parameterized by
egy in a complex environment, but in a simpler one may over-            two dimensions loosely adapted from (Ashby & Maddox,
fit spurious elements, literally committing to memory what              1990), who used semicircles with a spoke radiating from the
are actually random events.                                             center, with the two dimensions being the diameter of the cir-
   In the current paper we pursue a neutral, empirical ap-              cle and the orientation of the spoke. We embedded similar pa-
proach to evaluating human generalization performance in a              rameterized figures in depictions of flags flying from “ships,”
                                                                    1039

                                                                                           Details of Models
                                                                      Our more detailed analyses concerned the relative perfor-
                                                                      mance of prototype and exemplar models in accounting for
                                                                      performance as complexity is varied. We first provide further
                                                                      details of the models used in our analysis.
                                                                      Prototype Model
                                                                      The multiplicative prototype model, first used by Nosofsky
                                                                      (Nosofsky, 1987) allows for psychological similarity to de-
                                                                      crease exponentially with increasing distance. To compute
                                                                      similarity between a to-be-categorized item and a prototype,
                                                                      the values of the item and the prototype are compared along
                                                                      stimulus dimensions. The prototype is represented as the av-
Figure 3: Subject performance as a function of conceptual com-        erage of all exemplars seen from that category. Formally, the
plexity. Error bars indicated ± one standard error.                   scaled psychological distance between the to-be-categorized
                                                                      item i and prototype P is given by
                                                                                                d
                                                                                                                       !1/r
which the subjects were asked to classify as either hostile (pi-                              X
                                                                                                                     r
rate) or friendly (good guy) depending on the appearance of                        DiP =            wm |xim − Pm |                   (1)
the flag. Each ship floated in from off-screen, with a flag con-                              m=1
taining a black rectangle and a white sword. The width of the            The distance, DiP , is most commonly computed using a
rectangle (0 to 170 pixels) and the orientation of the sword         simple Euclidean metric (r = 2), where xim and Pm are the
(0-359◦ ) served as the two quasi-continuous dimensions.              values of the to-be-categorized item and prototype on dimen-
   For each concept, the positive examples were generated             sion m in d-dimensional space. A weighting variable for di-
from a probability density function in this two dimensional           mension m, represented as wm , is used to account for the in-
space. Each such distribution was a mixture of N bivariate           equality of attention on each dimension. This variable allows
circular Gaussians, with the number N of mixture compo-              for a magnification of the psychological space along more at-
nents in serving as the manipulation of conceptual complexity        tended dimensions and shrinkage along less attended dimen-
(Fig. 2). Negative examples were generated from the corre-           sions (Kruschke, 1992; Nosofsky, 1986).
sponding inverse distribution. To ensure that subjects gave              Similarity is then measured as a monotonically decreasing
their primary attention to the positive set, whose structure we      function of the psychological distance between the point rep-
were manipulating, the total area of the positive set (i.e. the      resentation of the stimulus and the prototype given by
integral of the positive probability density) was held constant
on all concepts at one fourth of the total. The means of the                                     siP = e−cdj                         (2)
Gaussian components were separated using a criterion rela-
tive to their standard deviations, to prevent them from over-         where c is a freely estimated sensitivity parameter. Higher
lapping and thus obscuring our quantification of complexity.          values of c “magnify” the psychological space, increasing the
Half of the trials were drawn from the positive set and half          differentiation between the prototypes within the psychologi-
from the negative, randomly intermixed within a concept,              cal space by increasing the steepness of the similarity gradient
with a total of 150 items per concept. Each subject saw one           around them. In order to make a decision as to which cate-
concept from each of the five complexity levels, in random            gory a particular item belongs, similarities are calculated be-
order, so all comparisons are within-subject.                         tween a to-be-categorized item and the prototype from each
   Subjects were presented with instructions indicating that          category. A guessing parameter, g, is used to represent the
on each trial, a ship would move onto the screen whose flag           probability the observer chooses at random between the two
he or she must look at in order to determine if the ship was          categories, resulting in a probability (1 − g) that the subject
a pirate or a “good guy.” Feedback was provided after each            uses the similarities for his decision. If, for example, there are
classification, from which the subject gradually learned the          two categories, A and B, then the similarity to prototype A is
correct classification. Each session consisted of 150 such tri-       divided by the sum of Prototype A and Prototype B similarity
als, taking about ten minutes. Each subject ran one such ses-         to generate the model’s predicted probability of a Category A
sion at each of the five complexity levels, in random order.          response to stimulus i:
                                                                                                                            
                                                                                                                     siPA
Results                                                                        p(RA |si ) = g/2 + (1 − g)                            (3)
                                                                                                                siPA + siPB
The most conspicuous aspect of the results is the steady de-
cline in subject performance as conceptual complexity in-             Exemplar Model
creases (Fig. 3), mirroring similar findings with other types         The generalized context model (GCM) (Nosofsky, 1986) as-
of stimuli and complexity measures (Feldman, 2000; Fass &             sumes that the evidence for a particular category is found by
Feldman, 2002). This trend, interesting in and of itself, re-         summing the similarity of a presented object to all category
flects a simplicity bias that is apparently ubiquitous in human       exemplars stored in memory. Items are represented as points
learning.                                                             in multidimensional psychological space, with the similarity
                                                                 1040

between objects i and j measured as a decreasing function of
their distance in that space,
                            sij = e−cdij                      (4)
(Shepard, 1987). Here, as in the prototype model, c is a sen-
sitivity parameter that describes how similarity scales with
distance. With large values of c, similarity decreases rapidly
with distance; with smaller values of c, similarity decreases
more slowly with distance. Distances are calculated similar
to that in the prototype model, here summed from the to-be-
categorized item and every exemplar, where xim is the value
of the to-be-categorized item i on dimension m and yjm is the
value of a category exemplar j on dimension m. As with the            Figure 4: Model fit to subject concept learning data as a function
prototype model, wm is used as an attentional weight granted          of conceptual complexity.
dimension m.
                          d
                                                 !1/r                 with a summed log–likelihood of –48.7, resulting in a fit close
                         X
                                               r                      to that of the prototype model, with a fit of –56.0.
               dij =          wm |xim − yjm |                 (5)
                        m=1                                              At complexity N = 2, the category generative model is
                                                                      a mixture of two Gaussian clouds. Though subjects’ perfor-
    To make a classification decision, similarities are calcu-        mance worsens, they are still well above chance, averaging
lated and summed between the to-be-categorized item and               around 80 percent correct. Here the probability distribution
the exemplars from each category. If, for example, there are          in psychological space created from the prototype model, be-
two categories, A and B, then summing across the category             cause it allows for only one central prototype, peaks in a re-
A exemplars and category B exemplars results in the total             gion that falls between the two actual generative distributions.
similarity of the item to category A members and category B           The prototype model cannot account as well for the data as
members. For category A, CA represents all exemplars in cat-          can the exemplar model, which is able to represent the simi-
egory A and CB represents all the exemplars in category B.            larity space as a distribution with two modes.
Using the similarity choice rule (Luce, 1963), the probability           The advantage provided to GCM at N = 2 reoccurs at
of category A response for stimulus i depends on the ratio of         N = 3, with GCM’s fit at −80.2 and the prototype model’s fit
i’s similarity to A to its total similarity to A and B,               at −95.2 At complexity levels N = 3 and 4, however, exem-
                                                                      plar and prototype performance begins to converge. At these
                                        P                   !         high complexities, subject performance drops near chance.
                                           j∈CA   sij
  p(RA |si ) = g/2+(1−g)         P               P            (6)     As their responses follow less of a discernible strategy, both
                                   j∈CA   sij +    j∈CB sij           the exemplar and prototype models are less able to approxi-
                                                                      mate their responses.
where again g is a guessing parameter previously described.
                                                                                        Model Fit to Concepts
                Model Fit to Subject Data                             The analysis above involved optimizing each model to fit sub-
To evaluate model performance, we first used parameter val-           jects’ data as well as possible. While this method puts each
ues that optimized each models’ log likelihood fit to subjects’       model in the best possible light, it is undesirable in that it
responses. Both models generally decrease in fit as complex-          entails setting each models’ parameters based on information
ity increases (Fig. 4). This simply reflects subjects’ poorer         that the model (and subject) could not, in principle, have ac-
performance with increasing complexity, meaning that their            cess to, namely the performance of the ensemble of subjects
responses become progressively more random and thus more              on the task. As a second analysis, we refit each model to the
unpredictable as complexity increases. At very high com-              data, this time setting the parameters in order to maximize the
plexity (N = 4 and 5), subject performance is very poor (see          log likelihood of the training examples observed so far at each
Fig. 3), so the two models begin to converge in their ability to      point in the experiment—that is, simply allowing each model
fit what are now substantially random responses.                      to learn the concepts as well as possible. This method in-
    But at lower complexity levels, especially N = 2 and 3,           evitably results in worse fit to the subject data, but illustrates
the fit of the exemplar model is substantially better than that       more accurately how each model would perform were it “left
of the prototype model. By design, the prototype model deter-         to its own devices” to learn the training data as presented to
mines similarity based on each exemplar’s distance from the           the subject.
prototype, an average of all previously seen exemplars. For              Fig. 6 shows the fit of each model to subject data using the
N = 1, this assumption closely matches the actual generating          settings optimized to the concept. These results are quite dif-
distribution, where there is one true center of the positive ex-      ferent from Fig. 4, and bring out in a very clear way the differ-
amples about which positive exemplars radiate outward and             ent places that the two models occupy along the bias-variance
the probability of a positive exemplar becomes exponentially          continuum. As before, both models generally decrease in fit
less likely as its distance from the center increases. The exem-      as complexity increases, reflecting the generally poorer per-
plar model also fits the data at this level of complexity well,       formance of subjects at high complexities. But the exem-
                                                                 1041

Figure 5: Model and subject performance as a function of concep-       Figure 6: Fit of the two models to subject data using parameters fit
tual complexity.                                                       to the training data.
                                                                                   Integrating the Two Approaches
plar model, with its inherent capacity to learn complex con-
cepts, does not diminish in “learning” performance nearly as           Many researchers have previously recognized the need to
quickly as the prototype model (Fig. 5). As a result, the exem-        combine the benefits of both prototype formation and exem-
plar model is able to “out-learn” both the prototype model and         plar memorization, leading to a number of “hybrid” mod-
subjects on concepts at the higher levels of complexity—and            els in the literature containing elements of both. In addi-
in this sense makes a poor model of subject performance at             tion, as mentioned, several previous concept-learning models
high levels of complexity. This failure is noticeable in Fig. 6,       have represented exemplar and prototype models in a unified
where now the exemplar model fits worse than the prototype             continuum in ways different from our approach. Ashby and
model. But in an exactly complementary way, the prototype              Alfonso-Reese (1995) emphasized the dichotomy between
model does not learn moderately complex multimodal con-                parametric (prototype) and non-parametric (exemplar) mod-
cepts (N = 2 and 3) as well as do subjects—its bias towards            els, seeing both as varieties of density estimation. More re-
unimodal concepts is too strong and insufficiently variant. In         cently, Vanpaemel et al. (2005) developed a categorization
other words, the results show that as complexity increases, the        model incorporating both prototype and exemplar type ele-
fits cross from one end of the bias-variance continuum to the          ments by placing them at the extremes of their varying ab-
other. Subjects’ “default” bias-variance setting is somewhere          straction model. In their model, the number of items to which
in the middle between the two models—more complex than                 a new item can be compared may vary, allowing the model
the unimodal assumption made by prototype models, but not              to form representations that lie between pure prototype and
as complex as the super-multimodal assumption embodied by              exemplar type structures. Rosseel (2002) explicitly adopts a
GCM.                                                                   mixture model, assuming a generalization space that, like our
                                                                       concepts, is a finite mixture of multivariate probability dis-
   It is worth noting that GCM, like other exemplar models,            tributions. By allowing the number of mixture components
includes a sensitivity parameter, c, that allows it to, in effect,     to vary, this model can mimic both parametric (prototype)
slide along the bias-variance continuum. Recall that c con-            and nonparametric (exemplar) performance. While we have
trols the rate of exponential decay of probability as a function       not yet fit this model to our data, we expect excellent perfor-
of dissimilarity from each exemplar. High values of c entail           mance, as its assumptions closely match the actual conditions
very narrow, “spiky” modes, and a more punctate decision               under which our concepts were generated.
surface, which in effect means a higher variance. Lower val-              All these approaches are clearly related to ours, but we
ues of c entail smoother, broader, and less numerous modes,            would argue that bias-variance analysis sheds a particularly
a simpler decision boundary, and in effect more prototype-             clear light on the historical dichotomy in the psychological
like performance. Hence sensitivity provides the potential for         literature, by connecting the various proposals to a tradeoff
GCM to fall at various points along the bias-variance con-             that is fundamental to statistical generalization regardless of
tinuum. Prototype models, while they also have a sensitivity           the specific form of the learning mechanism.
parameter, consistently possess a unimodal assumption, with
c controlling only how quickly the category typicality falls
off with distance from the prototype. In this sense, proto-
                                                                                                Conclusion
type models exhibit an inflexibly high bias that is definitely         A number of conclusions can be drawn from our study, some
not representative of subject performance in our study. Ex-            empirical, some more conceptual.
emplar models are not as firmly tied to a single fixed point in           First, prototype and exemplar approaches to categorization
the bias-variance continuum. Nevertheless, as the above re-            may fruitfully be regarded as points along a basic continuum
sults show, exemplar models do not necessarily automatically           of model complexity, reflecting a spectrum of possible as-
find the identical location along the continuum as do subjects         sumptions about the complexity of concepts in the environ-
when fit only to the training samples they have observed. En-          ment.
dowed with the capacity to overfit the data, they may well do             Second, conceptual complexity influences the degree to
so.                                                                    which each strategy accurately accounts for human perfor-
                                                                  1042

mance. At low but multi-modal levels of complexity (N =               Feldman, J. (2000). Minimization of Boolean complexity in
2, 3), prototype models underfit, but at high levels of com-                human concept learning. Nature, 407, 630–633.
plexity (N = 4, 5), exemplar models overfit relative to human         Hastie, T., Tibshirani, R., & Friedman, J. (2001). The ele-
learners. Human learners apparently make a more intermedi-                  ments of statistical learning: Data mining, inference,
ate assumption about conceptual complexity than does either                 and predicition. New York: Springer.
classical strategy, and possibly modulate between the two ex-
                                                                      Kruschke, J. (1992). ALCOVE: An exemplar-based con-
tremes in accordance with the observations. Considering a
range of complexity levels, neither strategy is consistently su-            nectionist model of category learning. Psychological
perior as a model of subjects.                                              Review, 99(1), 22–44.
   Speaking methodologically, when carrying out studies of            Luce, R. D. (1963). Detection and recognition. In R. D.
human learning, it is imperative to consider concepts with a                Luce, R. R. Bush, & E. Galanter (Eds.), Handbook of
range of complexity values. Our N = 1 concepts, which                       mathematical psychology. New York: Wiley.
resemble many concepts studied in the literature, elicited            McKinley, S. C., & Nosofsky, R. M. (1995). Investigations
very similar performance from prototype and exemplar mod-                   of exemplar and decision bound models in large, ill-
els, which might shed some light on the decades of uncer-                   defined category structures. J. Experimental Psychol-
tainty and controversy about the relative merits of the two ap-             ogy: Human perception and performance, 21(1), 128–
proaches. Clear differences between the two strategies only                 148.
emerged at complexity N = 2 and above. A more systematic              Medin, D. L., & Schaffer, M. M. (1978). Context model of
approach to varying complexity is necessary to paint a com-
plete picture of human generalization under arbitrary condi-                classification learning. Psychological Review, 85, 207–
tions.                                                                      238.
                                                                      Nosofsky, R. (1986). Attention, similarity, and the identifica-
                     Acknowledgments                                        tioncategorization relationship. Journal of Experimen-
Supported by NSF SBE-0339062.                                               tal Psychology: General, 115, 38–57.
                                                                      Nosofsky, R. (1987). Attention and learning processes in
                         References                                         the identification and categorization of integral stimuli.
Ashby, F. G., & Alfonso-Reese, L. A. (1995). Categorization                 Journal of Experimental Psychology: Learning, Mem-
       as probability density estimation. Journal of Mathe-                 ory, and Cognition, 13, 87–108.
       matical Psychology, 39, 216–233.                               Rosseel, Y. (2002). Mixture models of categorization. Jour-
Ashby, F. G., & Maddox, W. T. (1990). Integrating informa-                  nal of Mathematical Psychology, 46, 178–210.
       tion from separable psychological dimensions. Journal          Shepard, R. (1987). Toward a universal law of generalization
       of Experimental Psychology: Human Perception and                     for psychological science. Science, 237, 1317–1323.
       Performance, 16, 598–612.                                      Smith, J. D., & Minda, J. P. (1998). Prototypes in the mist:
Dietterich, T. G. (2003). Machine learning. In Nature ency-                 The early epochs of category learning. Journal of Ex-
       clopedia of cognitive science. London: Macmillan.                    perimental Psychology: Learning, Memory, and Cog-
Fass, D., & Feldman, J. (2002). Categorization under com-                   nition, 24, 1411–1436.
       plexity: a unified MDL account of human learning of            Vanpaemel, W., Storms, G., & Ons, B. (2005). A varying ab-
       regular and irregular categories. In S. Becker, S. Thrun,            straction model for categorization. In L. B. B. Bara &
       & K. Obermayer (Eds.), Advances in neural informa-                   M. Bucciarelli (Eds.), Proceedings of the 27th annual
       tion processing 15. Cambridge: MIT Press.                            conference of the cognitive science society. Hillsdale,
                                                                            NJ: Lawrence Erlbaum Associates.
                                                                 1043

