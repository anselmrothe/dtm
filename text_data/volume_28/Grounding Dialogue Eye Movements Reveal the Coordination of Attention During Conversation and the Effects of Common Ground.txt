UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Grounding Dialogue: Eye Movements Reveal the Coordination of Attention During
Conversation and the Effects of Common Ground
Permalink
https://escholarship.org/uc/item/5m48273p
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Dale, Rick
Richardson, Daniel C.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

 Grounding Dialogue: Eye Movements Reveal the Coordination of Attention During
                             Conversation and the Effects of Common Ground
                                              Daniel C. Richardson (dcr@ucsc.edu)
                                   Department of Psychology, University of Caifornia, Santa Cruz
                                             273 Social Sciences 2, Santa Cruz, CA 95064
                                                   Rick Dale (rad28@cornell.edu)
                                             Department of Psychology, Cornell University,
                                                     211 Uris Hall, Ithaca, NY 14853
                             Abstract                                   Monologues and visual common ground
                                                                        Richardson and Dale (2005) focused on cases in which
  When two people discuss something in front of them, what is
  the relationship between their eye movements? In Richardson           conversational partners are looking at a visual scene that is
  and Dale’s (2005) study, participants talked extemporaneously         the topic of the discussion. The situation is analogous to two
  about a TV show while viewing pictures of its cast members.           people discussing a diagram on a whiteboard, figuring out a
  Later, other participants listened to these monologues while          route on a map, or talking during a movie. In the first study,
  viewing the same screen. Cross-recurrence analysis revealed           the speech and eye movements of one set of participants
  that the coupling between speaker and listener eye-                   were recorded as they looked at pictures of six cast
  movements predicted how well the listener understood what             members of a TV sitcom (either ‘Friends’ or ‘The
  was said. In our current research, we extended these findings         Simpsons’). They spoke spontaneously about their favourite
  by studying the eye movements of two conversants engaged              episode and characters. One-minute segments were chosen
  in a live, spontaneous dialog. The participants talked to each
  other over the telephone while viewing identical visual
                                                                        and then played back unedited to a separate set of
  displays, and we tracked the eye movements of both                    participants. The listeners looked at the same visual display
  conversants simultaneously. In our first study, we found the          of the cast members, and their eye movements were
  conversants’ eye movements were coupled across several                recorded as they listened to the segments of speech. They
  seconds. In the second study we showed that this coupling             then answered a series of comprehension questions.
  increases if participants both heard the same background                 Listener and speaker eye movements were coded as to
  information prior to their conversation. Our results highlight        which of the six cast members was being fixated during
  the central role of grounding utterances in the visual context.       every 33ms time slice. Cross-recurrence analysis (Zbilut,
                                                                        Giuliani, & Webber, 1998) quantified the degree to which
                         Introduction                                   speaker and listener eye positions overlapped at successive
                                                                        time lags (see below for a brief explanation). This speaker X
Coordinating attention across a visual common ground is
                                                                        listener distribution of fixations was compared to a speaker
essential for successful communication (Clark, 1996; Clark
                                                                        X randomized-listener distribution, produced by shuffling
& Brennan, 1991; Schober, 1993). In collaborative tasks,
                                                                        the temporal order of each listener’s eye movement
conversants readily use gestures, actions and pointing to
                                                                        sequence and then calculating the cross recurrence with the
manipulate each other’s attention (Bangerter, 2004; Clark,
                                                                        speakers they had heard. This randomized series serves as a
2003; Clark & Krych, 2004), and the ability to manipulate
                                                                        baseline of looking ‘at chance’ at any given point in time,
joint attention is thought to emerge prelinguistically
                                                                        but with the same overall distribution of looks to each
(Baldwin, 1995). A burgeoning research area has
                                                                        picture as the real listeners (see Figure 1).
demonstrated that eye movements are tightly linked to the
                                                                           From the moment a speaker looks at a picture, and for the
time course of language comprehension (e.g., Allopenna,
                                                                        following six seconds, a listener was more likely than
Magnuson, & Tanenhaus, 1998; Brown-Schmidt, Campana,
                                                                        chance to be looking at that same picture. The breadth of
& Tanenhaus, 2004; Hanna & Tanenhaus, 2004; Hanna,
                                                                        this timeframe suggests that speakers and listeners may keep
Tanenhaus, & Trueswell, 2003; Henderson & Ferreira,
                                                                        track of a subset of the depicted people who are relevant
2004; Kamide, Altmann, & Haywood, 2003; Matlock &
                                                                        moment-by-moment (Brown-Schmidt et al., 2004). The
Richardson, in press; Tanenhaus, Spivey Knowlton,
                                                                        overlap between speaker and listener eye movements
Eberhard, & Sedivy, 1995) and language production (Griffin
                                                                        peaked at about 2000ms. In other words, two seconds after
& Bock, 2000; Meyer, Sleiderink, & Levelt, 1998). In the
                                                                        the speaker looked at a cast member, the listener was most
current studies, we used eye movements as a fine-grained
                                                                        likely to be looking at the same cast member. The timing of
index of how two conversants deployed their attention
                                                                        this peak roughly corresponds to results in the speech
within a visual ‘common ground’. This allowed us to
                                                                        production and comprehension literatures. Speakers will
investigate the temporal coupling between conversants’ eye
                                                                        fixate objects 800-1000ms (Griffin & Bock, 2000) before
movements and to examine how this coupling relates to
                                                                        naming them, and listeners will typically take 500-1000ms
communication.
                                                                        to fixate an object from the word onset (Allopenna et al.,
                                                                        1998). The coupling between speaker and listener eye
                                                                        movements was pervasive, suggesting that planning diverse
                                                                    691

                                                                                      Speaker - Listener
                        22
                                                                                      Speaker - Randomized listener
                        20
         % Recurrence
                        18
                        16
                        14
                        12
                         -4000   -2000    0         2000             4000         6000         8000        10000
                                                    Time of lag (ms)
        Figure 1. Richardson and Dale (2005). Eye movement recurrence at different time lag intervals in a monologue
types of speech will influence the speaker’s eye movements,          simultaneously, and the same cross-recurrence tools were
and a few seconds later, hearing them will influence the             used to quantify eye-movement couplings. Participants were
listener’s eye movements.                                            given a number of conversational tasks that allowed us to
   Importantly, this coupling of eye-movements between               investigate the relationship between visual attention and
speaker and listener was not merely an epiphenomenal by-             discourse processes.
product of conversation. It played a functional role in                 Our first study examined the effect that two way
comprehension. When the overall proportion of cross-                 interaction would have on the eye movement couplings
recurrence between individual speaker-listener pairs was             Richardson and Dale (2005) found with monologue
quantified, the strength of the relationship between speaker         communication. We presented participants with the same
and listener eye-movement patterns reliably predicted how            pictures of TV cast members and prompted similar
many of the comprehension questions the listener answered            conversations. Would the opportunity to interrupt and query
correctly. This correlation was supported by a follow-up             a speaker when misunderstandings arise mean that the
study that experimentally manipulated the relationship               listener no longer had a need to ground the speaker’s words
between speaker and listener eye movements. Examples in              in the visual display? In a dialogue, a listener can also plan
visual perception and problem solving (Grant & Spivey,               and produce her own utterances. Perhaps the eye movement
2003; Pomplun, Ritter, & Velichkovsky, 1996) show that a             patterns during this frequent alternation of speaker-listener
low-level perceptual cue can cause one person’s eye                  roles would differ from the eye movement couplings of a
movements to look like another’s, and as a consequence,              mute, obedient listener following the words and the gaze of
affect their cognitive state. We found that by flashing the          a speaker.
pictures in time with the speakers’ fixations (or a                     The alternative view is that communication is
randomized version) we caused the listeners’ eye                     fundamentally a joint activity (Clark, 1996). This view
movements look more (or less) like the speakers’, and                suggests that communication takes place on the basis of
influenced the listeners’ performance on comprehension               knowledge in the common ground, which includes the
questions.                                                           visual context that is shared. Therefore, in our dialogue
                                                                     study we will continue to find eye movement couplings, as
Dialogues and visual common ground                                   conversants ground their understanding in the visual scene
Our current studies concern two participants talking                 they have in common. Our second study investigates a
spontaneously over the telephone while looking at the same           further prediction of this view, that increasing the amount of
visual display. Both conversants were eye-tracked                    common ground knowledge participants possess will further
                                                                     increase their eye movement couplings.
                                                               692

                 Experimental methods                             of recurrent patterns of states between two time series
                                                                  (Shockley et al., 2003, Eckmann et al., 1987; Zbilut &
Two studies were carried out during a single session with         Webber, 1992).
the same pair of participants. We will explain the methods           Points of recurrence are simply the times at which the two
and data analysis techniques employed throughout, and then        data streams have the same value; in our case, this means
present the design and results from each study.                   that the two participants’ gaze is overlapping and they are
                                                                  fixating the same ROI. For a pair of time series, we can add
Methods                                                           up all the points recurrence and divide by the total number
Participants                                                      of possible to get a percentage. In our cross recurrence
Forty Stanford undergraduates participated in exchange for        analysis, one of the data streams is then lagged, so that 0ms
course credit. Participants were randomly assigned to pairs.      on one data stream is aligned with 33ms on the other. Again,
Four pairs were discarded because of problems calibrating         all the points of recurrence are calculated. This represents
the eye tracker to one of the participants. In study 2, an        the degree to which one participant is looking at the same
additional two pairs were excluded due to equipment               thing as the other participant 33ms later. A full cross
malfunction and experimenter error.                               recurrence analysis consists of calculating the recurrence for
Apparatus                                                         all possible alignments, or lag times, of the two data series.
We employed two eye tracking labs on different floors of a           Richardson and Dale (2005) employed this technique on
building. In the upstairs lab, an ASL 504 remote eye              their monologue data to find out exactly what temporal lag
tracking camera was positioned at the base of a 17” LCD           between the listener and the speaker would produce the
stimulus display. Participants were unrestrained, and sat         greatest degree of recurrence, or overlap, between the eye
approximately 30” from the screen. The camera detected            movement patterns. Figure 1 shows the average recurrence
pupil and corneal reflection position from the right eye, and     for 49 dyads at different lag times. As discussed above, this
the eye tracking PC calculated point-of-gaze in terms of          plot reveals that speaker and listener eye movements are
coordinates on the stimulus display. This information was         coupled at above chance levels from when they are
passed every 33ms to a PowerMac G4 which controlled the           synchronous, up to when the listeners’ lag 6000ms behind
stimulus presentation and collected looking time data. The        the speakers’.
downstairs lab used an identical set up, apart from the fact
that the display was a 36” x 48” foot screen that was back                                   Study 1
projected and participants sat 80” away (this lab was
designed for infants under a year old).                           In the first of our studies, we investigated how the
   There was an experimenter in each lab operating the eye        difference between a one way monologue and an interactive
tracking PC and the Mac running the experiment. The two           dialogue would play out in the eye movement couplings of
experimenters communicated to each other using iChat, an          the participants. The task and stimuli were identical to Study
instant messaging application. Participants’ communicated         1, Richardson and Dale (2005). Participants saw a picture of
to each other using the intercom feature on a set of 2.4Ghz       six cast members from the sitcom Friends or The Simpsons.
wireless phones. Each wore a hands-free headset with              (Figure 2) The participants were asked to discuss their
headphones and a small boom microphone. The speech of             favourite characters or episodes from the show. These were
both participants was recorded by microphones at the base         the same prompts used to elicit monologues from the
of the displays.                                                  speakers in Richardson and Dale (2005). The participants
Design                                                            were allowed to say as much as they liked, but typically,
Prior to the experimental session, the two experimenters          conversations lasted for 1 to 5 minutes.
each ran a 9 point calibration routine on their participants,        In the original monologue study there was a peak of
which typically took 1 or 2 minutes. At the beginning of a        recurrence when the listeners’ eye movements followed the
study, the experimenters agreed upon a time at which to           speakers at a lag of roughly 2000ms. We hypothesized that
start. This was entered into the Macs. Since each computer        in this dialogue study there would be a similar peak in eye
was synchronized with an external time server, this ensured       movement recurrence, reflecting a similar process of
that the study trials and data streams began simultaneously.      grounding language in the visual context. We predicted that
   In each study, the two participants were presented with        this peak would be centered around 0ms on average, since
exactly the same visual display. Regions of interest (ROIs)       this would reflect the that fact the participants would take
were predefined for each image.                                   turns in speaking, and consequently, in leading the eye
                                                                  movement coordination.
Data analysis
                                                                  Results and discussion
Our data consisted of two streams of data specifying which
(if any) ROI each participant was fixating every 33ms. Our        Figure 2 shows the average recurrence between
analyses concerned the degree to which the two participants       participants’ eye movements at different time lags, averaged
looking at the same thing at the same time. We quantified         over 16 dyads. As in Figure 1, the randomized baseline
this question by generating categorical cross-recurrence          provides a comparison of looks that are distributed equally
plots between the speaker and listener time series of             to participants’ eye movement, but have had the temporal
fixations (Dale & Spivey, in press; Richardson & Dale,            structure removed. And as in Figure 1, there is a window of
2005). These plots permit visualization and quantification        roughly six seconds in which participants eye movements
                                                              693

                                                                                                Conversants
                                                                 15
                                                                                                Randomized conversants
                                                                 14
                                                                 13
         % Recurrence
                                                                 12
                                                                 11
                                                                 10
                                                                   9
                                                                   8
                        -6000       -4000          -2000               0             2000            4000            6000
                                                            Time of Lag (ms)
                            Figure 2. Eye movement recurrence at different time lag intervals in a dialogue, Study 1.
are clearly coupled at above chance levels. Unlike the                       of common ground in knowledge between participants
monologue results though, in this dialogue data the peak in                  would affect their ability to coordinate their attention in the
recurrence occurs at around 0ms.                                             visual common ground.
  The differences between the dialogue and Richardson and                       Participants were required to talk about a painting by
Dale’s (2005) monologue data were demonstrated by                            Salvador Dali (Figure 3). Prior to their conversation, they
analyzing the results from the two experiments together. A                   were told that they would each hear a short discussion of
2 (monologue/dialogue) x 41 (lag times) mixed-effects                        Dali’s art. They were informed that they would either be
ANOVA (lag as a repeated-measures factor) revealed a                         hearing the same information, or that they would each hear
significant main effect of experiment (F(1,87)=20.5, p<.                     different information. Accordingly, the participants then
001) and a main effect of lag (F(40,3480)=8.3, p<.001).                      listened to 90 second passages that discussed either the
Most importantly, there was a significant interaction                        history, content and meaning of the specific painting (e.g.,
between the factors (F(40,3480)=4.2, p<.001), showing that                   “the still life objects in the original canvas have separated
the two way interaction in the dialogue experiment changed                   from the table and float in the air, and even the particles of
the temporal structure of the eye movement coupling.                         paint have broken loose from the canvas”), or Dali’s
  Though perhaps not surprising, the results from this first                 personality and theory (e.g. “the paranoiac critical method
study support our hypothesis that the eye movement                           entailed the creation of a visionary reality from elements of
coupling found in monologue communication extends to                         dreams, memories and psychological or pathological
dialogues. Even though in this case participants were able to                distortions. At times Dali would stand on his head to induce
verbally interact with each other, and could make use of all                 hallucinations.”). As we discuss below, the conditions varied
the common verbal back channels in communication that                        in that participants both believed they heard same/different
signal assent, understanding, or a need for more information                 information, and actually heard same/different information.
(Clark, 1996), participants were still visually coordinating                    Once more, the participants were allowed to talk for as
their attention as they conversed.                                           long as they required, during which time their gaze was
                                                                             recorded. ROIs were defined on Dali’s painting which
                                  Study 2                                    corresponded to six of the main objects or elements. Our
                                                                             prediction was that pairs of participants who had heard the
The term ‘common ground’ refers to much more than the
                                                                             same information about Dali would have a higher
visual context shared by conversational participants. It also
                                                                             recurrence between their eye movements than those who
describes the many beliefs, opinions and facts that
                                                                             heard different passages.
conversants share (Clark, 1996; Lee 2001). In the second
study we tested the hypothesis that manipulating the amount
                                                                       694

Results and discussion
For each of our dyads, we quantified the amount of
recurrence within a window of +/- 3000ms. In other words,
we looked at the overlap between participants’ eye
movements when they lagged each other by up to 3000ms.
A window of this size was chosen because in Richardson
and Dale (2005), study 1 and study 2 above, participants’
eye movements were coupled at above chance levels in a
roughly six second window. By restricting our analysis to
this window, we focus on times when the eye movements
are indeed coupled, and look specifically at the effects of the
common ground manipulation.
  A one way ANOVA was performed on the average
recurrence in each dyad within a window of +/- 3000ms.
There was a significant effect of common ground condition
(FI(1,12)=4.9. p <.05), such that dyads who heard the same
information had recurrence levels over a third higher than
those who heard different information (Figure 4). We                          Figure 3. Nature Morte Vivante by Salvador Dali
conclude that a simple manipulation changing the
information participants share about a painting directly                a lag of +/- 3000ms. In other words, the conversants were
affects the coordination of their visual attention.                     most likely to be looking at the same thing when one
                                                                        examines the same point in time in both their eye movement
                                       Conclusion                       recordings. However, if one picked any two points in their
                                                                        eye movement recordings that were within 3000ms, then
In spontaneous, natural dialogue relating to a common                   they would be more like than chance to be looking at the
visual scene, conversants’ visual attention is tightly coupled.         same thing.
This conclusion was suggested by Richardson and Dale’s                     Interestingly, this eye movement coupling is sensitive to
(2005) experiments on the causal role of eye movement                   the knowledge that conversants have prior to their
couplings during communication between a speaker and                    conversation. If they each hear the same background
listener. Their paradigm, however, excluded one of the most             information, rather than two different passages, then their
important features of verbal communication: two-way                     subsequent eye movements have a significantly tighter
interaction. The present studies provide a demonstration and            coupling with each other. This result provokes several
quantification of the eye movement couplings during                     interesting hypotheses which are the subject of our ongoing
interactive verbal communications. The recurrence, or                   research. Firstly, it could be that the shared information
overlap, between eye movement series was greatest when                  given to subjects supplies a vocabulary, or way in which
the series were aligned at 0ms, but was at above chance with            participants can refer to elements of the picture. Further
                                                                        experiments are addressing this issue by drawing on the
                                                                        notion of ‘conceptual pacts’ (Clark & Brennan, 1991) and
                            30                                          eye tracking participants during tasks where they generate
                                                                        novel referring expressions. Secondly, is the advantage of
Average % REC, +/- 3000ms
                            25
                                                                        our same condition due solely to the fact that participants
                                                                        actually know the same information, or is it also important
                                                                        that they know that they each know the same information?
                            20                                          Clark (1996) would suggest the latter, and since the current
                                                                        study conflates these these two possibilities, they will be
                            15                                          contrasted in future experiments.
                                                                           In all of our studies, eye movement couplings reveal an
                                                                        intimate relationship between discourse processes and visual
                            10                                          attention. Just as eye movements reflect the mental state of
                                                                        an individual, the coupling between a speaker’s and a
                             5                                          listener’s eye movements reflects the success of their
                                                                        communication. We conclude that looking around the
                                                                        common ground in step with each other is part of the
                             0                                          process of mutual understanding.
                                 Different          Same
                                  Common ground condition
 Figure 4. Average recurrence by common ground, Study 2
                                                                  695

                    Acknowledgments                                Hanna, J. E., & Tanenhaus, M. K. (2004). Pragmatic effects
                                                                     on reference resolution in a collaborative task: Evidence
The authors are indebted to Herbert H. Clark, Natasha                from eye movements. Cognitive Science, 28(1), 105-115.
Kirkham, Michael Ramscar and Michael Spivey for many               Hanna, J. E., Tanenhaus, M. K., & Trueswell, J. C. (2003).
inspiring discussions, and the members of the Kirkham                The effects of common ground and perspective on
Learning Lab who donated their time and talents to eye               domains of referential interpretation. Journal of Memory
tracking: Lisa Smythe, Carl Dambkowski, Sasha Filippova,             & Language, 49(1), 43-61.
Debbie Kim, Lauren Rimoin and Rosemary Reidy. Rick                 Henderson, J. M., & Ferreira, F. (Eds.). (2004). The
Dale was supported by a Paller-Dallenbach Fellowship from            integration of language, vision, and action: Eye
Cornell University.                                                  movements and the visual world. New York: Psychology
                                                                     Press.
                        References                                 Kamide, Y., Altmann, G. T. M., & Haywood, S. L. (2003).
Allopenna, P. D., Magnuson, J. S., & Tanenhaus, M. K.                The time-course of prediction in incremental sentence
   (1998). Tracking the time course of spoken word                   processing: Evidence from anticipatory eye movements.
   recognition using eye movements: Evidence for                     Journal of Memory & Language, 49(1), 133-156.
   continuous mapping models. Journal of Memory and                Lee, B. H. P. (2001) Mutual knowledge, background
   Language. 38(4), 419-439.                                         knowledge and shared beliefs: Their roles in establishing
Baldwin, D. A. (1995). Understanding the link between joint          common ground, Journal of Pragmatics, 33, pp 21-44.
   attention and language. In C. Moore & P. J. Dunham              Liversedge, S. P., & Findlay, J. M. (2000). Saccadic eye
   (Eds.), Joint attention: its origins and role in                  movements and cognition. Trends in Cognitive Science, 4
   development. Hillsdale, NJ: Lawrence Erlbaum.                     (6-14).
Bangerter, A. (2004). Using pointing and describing to             Meyer, A. S., Sleiderink, A. M., & Levelt, W. J. M. (1998).
   achieve joint focus of attention in dialogue. Psychological       Viewing and naming objects: Eye movements during
   Science, 15(6), 415-419.                                          noun phrase production. Cognition, 66(2), B25-B33.
Brown-Schmidt, S., Campana, E., & Tanenhaus, M. K.                 Pomplun, M., Ritter, H., & Velichkovsky, B. (1996).
   (2004). Real-time reference resolution by naïve                   Disambiguating complex visual information: Towards
   participants during a task-based unscripted conversation.         communication of personal views of a scene. Perception,
   In J. C. Trueswell & M. K. Tanenhaus (Eds.), World-               25(8), 931-948.
   situated language processing: Bridging the language as          Richardson, D.C & Dale, R. (2005). Looking To
   product and language as action traditions. Cambridge:             Understand: The Coupling Between Speakers’ and
   MIT Press.                                                        Listeners’ Eye Movements and its Relationship to
Clark, H. H. (1996). Using language. Cambridge:                      Discourse Comprehension. Cognitive Science, 29, 1045–
   Cambridge University Press.                                       1060.
Clark, H. H. (2003). Pointing and placing. In S. Kita (Ed.),       Richardson, D.C & Matlock, T. (in press). The integration of
   Pointing: Where language, culture, and cognition meet             figurative language and static depictions: An eye
   (pp. 243-268). Mahwah, NJ: Lawrence Erlbaum.                      movement study of fictive motion. Cognition
Clark, H. H., & Brennan, S. E. (1991). Grounding in                Tanenhaus, M. K., Spivey Knowlton, M. J., Eberhard, K.
   communication. In L. B. Resnick, J. M. Levine & S. D.             M., & Sedivy, J. C. (1995). Integration of visual and
   Teasley (Eds.), Perspectives on socially shared cognition         linguistic information in spoken language comprehension.
   (pp. 127-149). Washington, DC: APA.                               Science, 268(5217), 1632-1634.
Clark, H. H., & Krych, M. A. (2004). Speaking while                Schober, M. F. (1993). Spatial perspective-taking in
   monitoring addressees for understanding. Journal of               conversation. Cognition, 47(1), 1-24.
   Memory & Language, 50(1), 62-81.                                Shockley, K., Santana, M.V., & Fowler, C. A. (2003).
Dale, R. & Spivey, M.J. (in press). Unraveling the dyad:             Mutual interpersonal postural constraints are involved in
   Using recurrence analysis to explore patterns of syntactic        cooperative conversation. Journal of Experimental
   coordination between children and caregivers in                   Psychology: Human Perception & Performance, 29(2),
   conversation. Language Learning.                                  326-332.
Eckmann, J. P., Kamphorst, S. O., & Ruelle, D. (1987).             Zbilut, J. P., Giuliani, A., & Webber, C. L., Jr. (1998).
   Recurrence lots of dynamical systems. Europhysics                 Detecting deterministic signals in exceptionally noisy
   Letters, 5, 973-977.                                              environments using cross-recurrence quantification.
Grant, E. R., & Spivey, M. J. (2003). Eye movements and              Physics Letters, 246, 122-128.
   problem solving: Guiding attention guides thought.              Zbilut, J. P., & Webber, C. L., Jr. (1992). Embeddings and
   Psychological Science, 14(5), 462-466.                            delays as derived from quantification of recurrence plots.
Griffin, Z. M., & Bock, K. (2000). What the eyes say about           Physics Letters A, 171, 199-203.
   speaking. Psychological Science, 11(4), 274-279.
                                                               696

