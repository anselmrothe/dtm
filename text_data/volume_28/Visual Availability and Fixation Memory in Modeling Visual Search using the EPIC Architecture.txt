UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Visual Availability and Fixation Memory in Modeling Visual Search using the EPIC
Architecture
Permalink
https://escholarship.org/uc/item/8xq582jf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Kieras, David
Marshall, Sandra P.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                     University of California

                            Visual Availability and Fixation Memory in Modeling
                                    Visual Search using the EPIC Architecture
                                              David Kieras (kieras@eecs.umich.edu)
                           Electrical Engineering & Computer Science Department, University of Michigan
                                        2260 Hayward Street, Ann Arbor, Michigan 48109 USA
                                       Sandra P. Marshall (smarshall@sciences.sdsu.edu)
                                         Department of Psychology, San Diego State University
                                      6475 Alvarado Road, Suite 132, San Diego CA 92120 USA
                               Abstract                               of human vision as it works in natural environments and
                                                                      tasks, and thus has not developed the necessary theoretical
   A set of eye movement data from a visual search task using         components. These include the spatial non-homogeneity of
   realistically complex and numerous stimuli was modeled             the retina, which gives central and peripheral vision
   with the EPIC architecture, which provides direct support for      different roles, and the oculomotor mechanisms that move
   oculomotor constraints and visual availability constraints due     the eyes. The key cognitive activity in visual search is to use
   to retinal non-homogeneity. The results show how the
                                                                      peripheral vision information to decide which object should
   quantitative details of visual search can be explained within
   an architectural framework, and have useful practical,             be chosen to be the next target of central vision, and then to
   methodological, and theoretical implications.                      position the eyes accordingly, and repeat as needed.
                                                                         Thus retinal non-homogeneity leads to differences in what
                           Introduction                               properties of objects are currently visible as a function of
                                                                      their eccentricity and other properties, and are thus available
Many everyday and work activities involve visual search,              to cognition for use in guiding the visual search. In general,
the process of visually scanning or inspecting the                    the visual availability of a property of an object is a function
environment to locate an object of interest that will then be         not just of the eccentricity of the object, but also its size. An
the target of further activity. For example, one might search         example is Anstis (1974) who showed that a letter can be
the kitchen to locate a package of desired coffee beans               recognized even in peripheral vision if it is large enough. A
which will then be grasped. This work concerns computer               variety of other studies in the literature document similar
interaction tasks, in which a particular icon coded by color,         effects for other properties, such as color (e.g. Gordon &
shape, and other attributes is searched for on the screen and         Abramov, 1977). A third factor affecting availability is
is then clicked on using a mouse. In this domain, although            crowding; an object is less available if it is closely
the visual characteristics of the searched-for objects are            surrounded by other objects. Results by Bouma (1978) and
artificially simple compared to most everyday objects, the            others (e.g. Toet & Levi, 1994) show that the effects of
task is a natural one in the sense that such activities are very      crowding increase with eccentricity. However, these three
common in the use of modern technology; they are perhaps              factors combine in a complex way that appears to depend on
the major performance bottleneck in important systems such            the specific visual properties involved, and is not at all fully
as military workstations with which humans are expected to            documented.
monitor and comprehend displays containing hundreds of                   The EPIC architecture, which was developed to model
moving icons in time-stressed and potentially lethal                  humans in high-performance tasks, was perhaps the first
situations, and do so over extended periods of time. Hence            computational cognitive architecture to explicitly represent
analyzing such tasks in order to improve how well they can            visual availability and the time course of programming and
be done presents an opportunity to study real and important           executing eye movements, making it a natural framework
tasks that nonetheless involve relatively simple aspects of           for realizing models based on active vision concepts. The
vision.                                                               purpose of this paper is to present some recent results in
   A currently developing approach to the design of systems           which EPIC was used to model a complex realistic search
that support such complex and high-performance tasks is to            task. The model, while not yet fully refined, demonstrates
simulate human performance with a candidate design, using             some key features of visual search.
one of the computational cognitive architectures such as
EPIC (Kieras & Meyer, 1997; see also Kieras, 2003, and
Byrne, 2003). Any such effort will have to include
                                                                                 The EPIC Cognitive Architecture
reasonably accurate representations of the relevant aspects           The EPIC architecture for human cognition and
of human vision. In particular, the spatial and temporal              performance provides a general framework for simulating a
extent of the tasks makes eye movements mandatory, but as             human interacting with an environment to accomplish a
argued forcefully by Findlay and Gilchrist (2003) in their            task. Due to lack of space, the reader is referred to Kieras &
presentation of active vision, mainstream cognitive                   Meyer (1997), Meyer & Kieras (1997), or Kieras (2004) for
psychology has under-represented this most salient feature            a more complete description of EPIC. Figure 1 provides an
                                                                  423

                                                                                determine what visual properties of an object are available
                                         Long-Term                              given its size and eccentricity. Unfortunately, the research
                                           Memory             Cognitive
                                                             Processor          literature does not include studies from which one can
                                         Production         Production Rule
                                Auditory
                                          Memory               Interpreter      construct availability functions that include a range of object
                    Simulated
                    Interaction
                     Devices
                                 Input
                                                                                sizes and eccentricities for realistic and useful visual
                                                                                properties, even for the highly artificial but practically
                                          Auditory
                                         Processor
                                                        Working
                                           Visual
                                         Processor
                                                        Memory
                                                                                significant stimuli such as would be found on computer
            Task
        Environment              Visual                                         displays.
                                  Input
                                           Ocular
                                           Motor
                                                                                   The modeling work reported in this paper is part of an
                                         Processor
                                                                                effort to arrive at useful visual availability parameters by
                                         Vocal Motor
                                         Processor
                                                                                constructing models for several visual search tasks and
                                                       Tactile
                                                     Processor
                                                                                fitting them to the data, in hopes that the resulting parameter
                                           Manual
                                            Motor
                                                                                sets will be useful and generalizable. The data used in this
                                                                                work is a subset of the data described in St. John, Marshall,
                                          Processor
                                                                                Knust, & Binning (2006).
 Figure 1. The overall structure of the EPIC architecture.                                                  The Data
 Perceptual-motor peripherals surround a cognitive processor.                   The task. The experimental task required subjects to search
overview of the architecture, showing perceptual and motor                      for icons in a display that are identical to a probe icon. A
processor peripherals surrounding a cognitive processor; all                    sample display appears in Figure 2. A trial begins with a
of the processors run in parallel with each other. To model                     blank display and the appearance of the probe icon in the
human performance of a task, the cognitive processor is                         area at the left-hand edge of the display. After 2 sec, the to-
programmed with production rules that implement a strategy                      be-searched icons all simultaneously appear to the right of
for performing the task. When the simulation is run, the                        the probe icon. In Figure 2, there are 48 icons to be
architecture generates the specific sequence of perceptual,                     searched, two of which match the probe icon. The subject’s
cognitive, and motor events required to perform the task,                       task is to click on each of the two matching icons. Once the
within the constraints determined by the architecture and the                   second is clicked on, the display is blanked, and after an
task environment.                                                               inter-trial-interval of approximately 2 sec, the next trial
   EPIC’s visual system follows the usual breakdown into a                      starts with the appearance of the probe icon.
sensory store and a perceptual store, but there is also an eye                  Stimuli. The icons themselves are based on a new standard
processor that explicitly represents visual availability by                     symbology for military displays called MIL-STD-2525B
determining which visual properties of objects are available                    (Department of Defense, 1999), which is a military standard
in the sensory store as a function of the current position of                   icon set for designating the kinds of objects that would
the eye. The recognized objects and their relationships in the                  appear on a military radar or tactical display with redundant
perceptual store are then available to the cognitive processor                  coding for their militarily important properties. Each icon
to match the conditions of production rules, whose actions                      has a color, a shape, an internal symbol, and a “direction
can command the oculomotor processor to move the eyes.                          leader”. Because these are actual military symbols, the
   The eye processor applies availability functions to                          properties are not at all orthogonal, but rather represent
                                                                                redundant codings. A full description can be found in St.
                                                                                John, Marshall, Knust, & Binning (2006).
                                                                                   Color represents the Origin of the object: red is hostile,
                                                                                blue is friendly, yellow is unknown, and green is neutral.
                                                                                Shape is redundant with the origin, but a certain feature of
                                                                                the shape also connotes the object’s category: aircraft, ship,
                                                                                or submarine. Surface icons are shown as full shapes, air
                                                                                icons are truncated at the bottom, and subsurface icons are
                                                                                truncated at the top. Each specific shape appears in
                                                                                combination with one of eight correlated internal symbols
                                                                                that represents the kind of object, the Platform, such as
                                                                                cruiser, helicopter, aircraft carrier. For example, the bow-tie
                                                                                symbol represents a helicopter, and it appears in a shape that
                                                                                is missing its bottom, which means the object is a flying
                                                                                vehicle. The leader is a line segment commonly used on
 Figure 2. A sample display with 0% decluttering. The probe                     such displays to show the direction and speed of a moving
 is at the left. One of the matching targets is immediately to                  object. In these icons, it is always the same length and
 the right; the other is third from the left in the bottom row.                 appears in one of only four orientations to indicate Direction
                                                                                (N, S, E, W). Thus, three of the basic visual properties—
                                                                            424

color, overall shape, and internal symbol—are somewhat              or more in the same region was classified as a fixation on
confounded; a particular internal symbol can appear with            the display location. The location, start time, and end time
any color, but only with a certain shape for each color.            of each fixation in each trial was computed, and combined
Color and overall shape are highly correlated. Blue                 with coded identity of the icon (or gray dot) at that location.
(friendly) icons are curvilinear, red (hostile) icons are based     After eliminating trials whose data were missing or
on a diamond shape, yellow (unknown) icons are clover-              ambiguous, the 21 participants with nine trials per declutter
leafed, and green (neutral) icons are square.                       condition produced between 153 and 183 trials in each
   This data set thus has a serious disadvantage in that key        declutter condition. The fixations were then classified by
stimulus properties are not orthogonal, but a considerable          type of match to the probe (e.g. Origin match, Platform
advantage in that the stimuli are undoubtedly of realistic          match, Target (complete) match) and the mean number and
complexity and subtlety. The choice of color as the code for        duration of these classified fixations formed the basic data
the most important Origin property was based on long-               used in this study. Also calculated were mean latencies of
standing results in human factors on the effectiveness of           the two responses in each condition.
color coding in visual search; less salient properties are used
for coding information that would be useful once an icon                                     The Model
was fixated.
                                                                    Given the general machinery of the EPIC architecture,
   Stimuli were presented on a 17” color monitor with a
                                                                    building a model for this task is relatively simple; task
resolution of 1024 x 768. The stimulus display occupied an
                                                                    strategies and parameter values were explored iteratively to
12.5" by 8.75" area. There were 48 possible positions for the
                                                                    find one that fits the data reasonably well. Due to lack of
searched-for icons on the display, each occupying a 0.5" by
                                                                    space, details of this process are omitted, the task strategy
0.5" area (excluding directional leader), with the icon
                                                                    implemented by the model’s production rules will be only
positioned within the area in a randomized manner to avoid
                                                                    verbally summarized, and specific parameter values
forming a strict grid configuration. The probe position was
                                                                    mentioned only when especially important.
counted as a 49th position in the analysis.
                                                                       At the beginning of the trial, the model fixates the probe
   These data are a subset from a large study that compared
                                                                    position and waits for the probe to appear. It stores the color
different forms of display “decluttering” that should
                                                                    (Origin), shape and text label (Platform), and leader
improve visual search performance. Some of the icons were
                                                                    orientation (Direction) of the probe in working memory and
replaced with symbols that would be less distracting, but
                                                                    waits for the main display to appear. It then begins the
still informative. The subset of the data used here
                                                                    visual search process. This is implemented with sets of
represented a baseline condition in which the removed
                                                                    production rules that execute in two threads (see Kieras, in
symbols were replaced with an uninformative grey dot.
                                                                    press). The first nominates objects to look at in anticipation
Because the declutter manipulation was intended to be a
                                                                    of the next eye movement, and then moves the eye to a
realistic one in which irrelevant icons would be removed,
                                                                    chosen candidate object as soon as possible. In the
the icons remaining were relatively similar to the probe
                                                                    meantime, another thread evaluates the current candidate as
icon, having a specified number of features in common.
                                                                    soon as all of its necessary visual properties are available.
There were always three distractors that differed in only one
                                                                    An object is chosen as a candidate only if it has not been
of the three features from the probe. Most of the remaining
                                                                    checked yet, and in the following order of descending
distractors differed in two features, and the remainder
                                                                    priority: Encoding failed on a previous fixation on the
differed in all three. The four conditions were 75, 50, 25,
                                                                    object; an object that matches all of the probe attributes; an
and 0% of the icons being decluttered – removed -, leaving
                                                                    object that matches the probe color; an object chosen at
respectively 12, 24, 36, and 48 icons remaining to be
                                                                    random. After the candidate is chosen, the eye is moved to
searched, randomly distributed over the display. Figure 2 is
                                                                    it. When the properties of the candidate become fully
thus a 0% decluttered display containing 48 icons to be
                                                                    available, the candidate-choosing process is suspended, the
searched.
                                                                    candidate object is marked as checked, and then if it
Procedure. The eye-tracking system used to collect data
                                                                    matches the probe, a mouse point movement is launched,
was the EyeLink System (SR International), which consists
                                                                    followed by a button punch movement. The candidate-
of a lightweight headset with three cameras. Two cameras
                                                                    choosing process is then resumed. The result is that the
record left and right eye; the third camera monitors head
                                                                    model quickly and efficiently moves the eye from one
movement. Observations of eye movement and pupil
                                                                    candidate object to another, taking advantage of whatever
activity were sampled at 250 Hz, providing 15,000
                                                                    properties about the objects are currently available.
observations per minute for each eye. To record data, each
                                                                       The overall shape, Platform, and Direction information
undergraduate student participant underwent a short
                                                                    was assumed to be available only if the icon was foveated,
calibration procedure lasting 3-5 minutes, received
                                                                    but the color is available over an area up to several degrees
instructions, and then proceeded to work through the task.
                                                                    in radius, depending on the display density. A good fit was
   During a trial, the position of the eye was recorded every
                                                                    obtained with the availability of the icon color for the four
4 milliseconds, and classified in which of the 49 regions of
                                                                    levels of declutter set at 9, 8, 7.5, and 7 degrees radius
the display the current position was in. A duration of 80 ms
                                                                    respectively. Any single value that produced a good fit at
                                                                425

one declutter level produced gross misfits at the other levels.                                                                RT1
Thus color provided visual guidance depending on display                                       6000                            RT2
                                                                                                                               Pred. RT1
                                                                                                                                                                             30
density.                                                                                       5000
                                                                                                                               Pred. RT2
                                                                                                                               N. Fixations                                  25
   The model assumed a large and reliable memory for                                                                           Pred. N. Fixations
                                                                                                                                                                                   Number of Fixations
which objects have been previously fixated or checked. This                                    4000
                                                                                                                                                                             20
                                                                                   RT (ms)
was motivated by the results in older eye movement studies                                     3000
such as Barbur, Forsyth, & Wooding (1993) , who reported                                                                                                                     15
a very low rate of repeat fixations on objects during visual                                   2000
search, and similar newer results of Peterson, Kramer,                                         1000
                                                                                                                                                                             10
Ranxiao, Irwin, & McCarley (2001). Peterson et al.
explained these few repeat fixations as a result of occasional                                                         0
                                                                                                                       75%            50%               25%                0%
                                                                                                                                                                             5
encoding failures; with some small probability, the                                                                                     Declutter Condition
properties of an fixated object would fail to be encoded;                   Figure 3. Response latency (RT, left axis) and number of
when this was noticed, which tended to be quite soon, an                    fixations (right axis) for each decluttering condition.
eye movement would be made back to the object. The above
task strategy implements this suggestion in the model with              different types on non-target icons that have one or more of
an encoding failure probability for the most detailed                   the probe features for each declutter condition. The
property, Platform, of 0.1.                                             observed proportion of fixations on non-target icons of the
                                                                        same Origin increases with display density, and is quite
                           Results                                      high, at an average of 32% of the fixations; if fixations on
                                                                        Target icons were included, an average total of 66% of the
                                                                        fixations would be to objects that match on Origin.
Availability Effects
                                                                           However, the model overpredicts the proportion of non-
Figure 3 shows the observed and predicted response times                target Origin fixations by about 0.14 on the average; the
and number of fixations for each declutter condition; recall            color-based visual guidance in the model was too dominant
that decreasing declutter means increasing number of icons              compared to the data. However, the proportion of fixations
to be searched. In all graphs, observed points are plotted              on non-target icons that match on one or more of the other
with solid symbols and lines, predicted with open symbols               target attributes (e.g. Platform) is correctly predicted to be
and dashed lines; the vertical brackets are 95% confidence              low, about .12 on the average, and constant, showing that
intervals. The number of fixations is predicted very closely,           they do not guide the visual search significantly.
as is the time for the first response. Note that the fourfold              Figure 5 shows the proportion of fixations on objects that
increase in number of objects to be searched resulted in only           match none of the probe features. Although the model is
about a twofold increase in the number of fixations required,           fairly close for the gray dots, it clearly underpredicts the
and even less of an increase in the time required, especially           proportion of fixations on non-matching icons,
for the first response. The second response is consistently             corresponding to the too-frequent fixations on Origin
overpredicted, suggesting that some correction is needed in             matches.
the assumptions about how long the search for the second                   Also shown in Figure 5 is the proportion of fixations on
target must wait while the first response is being executed.            non-target objects that were previously fixated. The small
   As shown by the color availability parameter values, the             proportion, 5%, of repeat fixations corresponds to the
effect of a more cluttered display is to reduce somewhat the            above-cited results, increases only slightly with the number
area over which the most salient stimulus property is                   of icons, and is fairly accurately predicted.
available. Note that decreasing the density of a display
increases the average eccentricity between objects, making                                                             0.50
an object less available, but also decreases the average                                                               0.45
crowding, making an object more available. The two effects                                                             0.40
                                                                                             Proportion of Fixations
of density might partially cancel each other out, resulting                                                            0.35
the observed relatively small effect.                                                                                  0.30                                      Origin
                                                                                                                                                                 Platform
   An additional timing result unnecessary to show                                                                     0.25                                      Direction
                                                                                                                                                                 Pred. Origin
graphically is that the fixation durations on non-targets were                                                         0.20
                                                                                                                                                                 Pred. Platform
                                                                                                                                                                 Pred. Direction
accurately predicted to be about 250 ms and essentially                                                                0.15
                                                                                                                       0.10
constant over conditions; for targets, the duration was
                                                                                                                       0.05
substantially longer, because the icon would be pointed to,                                                            0.00
but the duration was not as long as would be expected from                                                                    75%           50%         25%           0%
                                                                                                                                           Declutter Condition
typical mouse movement times.
   For brevity, further results are mostly shown only for                  Figure 4. Observed and prediction proportions of fixations in
fixations on non-target objects, which are gray dots or icons              each declutter condition for icons matching on at least one of
that mismatch one or more features of the probe. Figure 4                  the probe features.
shows observed and predicted proportion of fixations of
                                                                  426

                                   0.50                                                                                10.00
                                   0.45         NoMatch
                                                GrayDot                                                                 9.00
                                                                                          Saccade Distance (Degrees)
                                   0.40         Repeats
         Proportion of Fixations
                                                Pred. NoMatch
                                   0.35         Pred. GrayDot                                                           8.00
                                                Pred. Repeats
                                   0.30
                                   0.25                                                                                 7.00
                                   0.20
                                                                                                                        6.00
                                   0.15                                                                                                                                 Origin
                                                                                                                                                                        Target
                                   0.10                                                                                                                                 Pred. Origin
                                                                                                                        5.00
                                                                                                                                                                        Pred. Target
                                   0.05
                                   0.00                                                                                 4.00
                                          75%     50%           25%    0%                                                                                 75%         50%        25%             0%
                                                 Declutter Condition                                                                                             Declutter Condition
   Figure 5. Observed and predicted proportions of fixations                       Figure 6. Observed and predicted saccade distances to
   on objects matching none of the probe features, and on                          arrive at Target icons or icons matching on Origin.
   objects previously fixated (Repeats).
   Figure 6 shows the saccade distance in degrees made to a                                                                                             16.00
fixation on icons that are a Target or match on Origin.                                                                                                 14.00
                                                                                                                           Saccade Distance (Degrees)
Except for the least dense condition, the model makes
saccades of about the same size as the data, reflecting how                                                                                             12.00
the availability of the color property in the model biases the                                                                                          10.00
next fixation to be nearby, where the color can be seen.
   However, the saccade distance to non-matching objects is                                                                                              8.00
seriously overpredicted, as shown in Figure 7. In these                                                                                                                             NoMatch
                                                                                                                                                                                    GrayDot
                                                                                                                                                         6.00
cases, the model has picked the next object at random from                                                                                                                          Pred. NoMatch
                                                                                                                                                                                    Pred. GrayDot
the whole display, while in the data, such saccades are only                                                                                             4.00
                                                                                                                                                                75%           50%          25%        0%
somewhat longer on average than color-guided ones. This                                                                                                                     Declutter Condition
suggests either that the selection should be biased by
distance, even though there is no limited-available property                         Figure 7. Observed and predicted saccade distances to
to guide it, or that objects out in the periphery can not be                         arrive at objects not matching any probe features.
distinguished well enough to act as a saccade target; in                          produced fairly accurate predictions of response times and
other words, contrary to what the architecture assumes,                           number of fixations (see also St. John, et al., 2006),
perhaps “objectness” is also subject to availability.                             suggesting that these overall measures are not adequate to
                                                                                  test different theories of visual search. But among other
Memory in visual search                                                           problems, the no-memory model predicted a 25% repeat
A key component of this visual search model is a memory                           fixation rate compared to the 5% observed in the data! This
for which objects have been previously fixated. Wolfe                             result disqualifies the no-memory model, meaning that a
(2003, Horowitz & Wolfe, 1998) has argued that visual                             reliable memory for fixated objects is a critical component
search has little or no memory, but rather than being based                       of a realistic model of visual search.
on eye movements, this claim was based on an RT paradigm
in which the display was modified during the search,                                                                                                               Conclusion
making memory useless even if present (see von Muhlenen,                          Practical conclusions. The data presented here are a useful
Muller, & Muller, 2003 for more discussion of the strategic                       case: although the stimulus properties are not ideally
aspects of the task). The present data shows that repeat                          orthogonal, they are realistically complex, and the
fixations occur at a very low rate, even for a large number of                    numerosity and density manipulations of the display are
objects and fixations, as also observed by Peterson et al.                        representative of the visual search problems in important
(2001), and the model used their suggestion that the                              practical tasks. Models based on a cognitive architecture
repeated fixations were due to stimulus encoding failures,                        that represents the visual availability and oculomotor
rather than an unreliable memory for previous fixations. To                       mechanisms involved in visual search can account well for
investigate the need for a reliable fixation memory, the                          many important features of this data, meaning that the
model was modified so that it had neither encoding failures                       specific parameter values and architecture can be used in
nor a memory for which objects had been previously                                approximate models of human visual search performance
fixated. However, it could not locate the targets in a                            for practical application in system design.
plausible amount of time or number of fixations unless color                      Methodological conclusions. The results suggest that
was available almost everywhere to provide guidance to the                        visual search researchers should focus more on accounting
search – in effect assuming a homogenous retina, contrary                         for details of the eye movements – the fact that the no-
to the active vision concept. Interestingly, this model
                                                                            427

memory model could do reasonably well in predicting RT             Bouma, H. (1978). Visual search and reading: Eye
and overall number of fixations, and even the present model          Movements and the functional visual field: A tutorial
could do so quite well, even though some specific aspects of         review. In J. Requin (Ed.), Attention and Performance
the fixations were incorrect, shows that these overall               VII. Hillsdale, NJ: Lawrence Erlbaum Associates. 115-
measures are not in fact sensitive enough to serve as a basis        148.
for testing theories of visual search.                             Department of Defense (1999). Department of Defense
Theoretical conclusions. The model predictions had                   interface standard: Common warfighting symbology:
enough quantitative detail that some aspects of the model            MIL-STD-2525B. Reston, VA: DISA/JIEO/CFS.
can be clearly identified as incorrect in ways that have           Findlay, J.M., & Gilchrist, I.D. (2003). Active Vision.
interesting implications for revisions to the architecture of        Oxford: Oxford University Press.
the visual system. But the most important theoretical              Horowitz, T.S. and Wolfe, J.M. (1998). Visual search has
implication is that the memory for previous fixations is             no memory. Nature, 394, 575–57
highly reliable and capacious; current cognitive theory has        Gordon, J., & Abramov, I. (1977). Color vision in the
to satisfactorily explain this long-observed but                     peripheral retina. II. Hue and saturation. Journal of the
unacknowledged memory system – it does not fit into any              Optical Society of America, 67(2), 202-207.
current cognitive architecture, at least not in any obvious        Kieras, D.E. (2003). Model-based evaluation. In Jacko, J.A.
way. In the present model, this memory was represented in a          & Sears, A. (Eds) The human-computer interaction
purely ad-hoc way; further work is needed to determine               handbook. Mahwah, New Jersey: pp. 1139-1151.
whether it could be represented as simply retention of the         Kieras, D.E. (2004). EPIC Architecture Principles of
properties of those objects that constantly remain in the            Operation.        Web         publication       available  at
visual field. For example, suppose that the foveally                 ftp://www.eecs.umich.edu/people/kieras/EPIC/EPICPrinOp.pdf
available properties of a fixated icon persisted in visual         Kieras, D. (in press). Control of cognition. In W. D. Gray
memory for a relatively long time after the eye was moved            (Ed.), Integrated models of cognitive systems. New York:
away, and the next saccade target is chosen from those with          Oxford University Press.
unknown values of these properties. The effect would be to         Kieras, D. & Meyer, D.E. (1997). An overview of the EPIC
eliminate repeat fixations without the need of a special-            architecture for cognition and performance with
purpose memory mechanism for which objects have been                 application to human-computer interaction. Human-
fixated.                                                             Computer Interaction., 12, 391-438.
                                                                   Meyer, D. E., & Kieras, D. E. (1997). A computational
                     Acknowledgments                                 theory of executive cognitive processes and multiple-task
                                                                     performance: Part 1. Basic mechanisms. Psychological
   This work was supported by the Office of Naval                    Review, 104, 3-65.
Research, under Grant No. N00014-00-0353 awarded to                von Muhlenen, A. Muller, H.J., & Muller, D. (2003). Sit-
Sandra Marshall at San Diego State University, and Grant             and-wait strategies in dynamic visual search.
Nos. N00014-03-1-0009 and N00014-06-1-0034 awarded to                Psychological Science, 14 (4), 309-314.
David Kieras at the University of Michigan.                        St. John, M., Marshall, S. P., Knust, S. R., & Binning, K. R.
                                                                     (2006). Attention Management on a Geographical
                           References                                Display: Minimizing Distraction by Decluttering
Anstis, S.M. (1974). A chart demonstrating variations in             (Technical Report No. 06-01). San Diego, CA: San Diego
   acuity with retinal position. Vision research, 14, 589-592.       State University, Cognitive Ergonomics Research Facility
Barbur, J.L., Forsyth, P.M., & Wooding. D.S. (1993). Eye           Peterson, M.S., Kramer, A.F., Ranxiao, F.W., Irwin, D.E.,
   movements and search performance. In D. Brogan, A.                & McCarley, J.S. (2001). Visual search has memory.
   Gale, & K. Carr (Eds.) Visual Search 2. London: Taylor            Psychological Science, 12(4), 287-292).
   & Francis. 253-264.                                             Toet, A. & Levi, D. M. (1992). The two-dimensional shape
Bouma, H. (1978). Visual search and reading: Eye                     of spatial interaction zones in the parafovea. Vision
   Movements and the functional visual field: A tutorial             Research, 32, 1349-1357.
   review. In J. Requin (Ed.), Attention and Performance           Wolfe, J.M. (2003). Moving towards solutions to some
   VII. Hillsdale, NJ: Lawrence Erlbaum Associates. 115-             enduring controversies in visual search. Trends in
   148.                                                              Cognitive Science, 7(2), 70-76.
Byrne, M. D. (2003). Cognitive architecture. In J. Jacko &
   A. Sears (Eds), Human-Computer Interaction Handbook.
   Mahwah, N.J.: Lawrence Erlbaum Associates. pp. 97-117.
                                                               428

