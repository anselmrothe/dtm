UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Discovering Hidden Dispositions and Situational Factors in Causal Relations by Means of
Contextual Independencies
Permalink
https://escholarship.org/uc/item/9qt8z0h1
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Neufeld, Eric
Sanscartier, Manon J.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

     Discovering Hidden Dispositions and Situational Factors in Causal
                     Relations by Means of Contextual Independencies
        Manon J. Sanscartier (mjs696@mail.usask.ca) and Eric Neufeld (eric@cs.usask.ca)
                     Department of Computer Science, University of Saskatchewan; 57 Campus Drive
                                          Saskatoon, Saskatchewan, Canada S7K 5A9
                           Abstract                               about individuals and how the discovered independencies
                                                                  will improve/change our believed causal model, by iso-
   Correspondent inferences in attribution theory deal with       lating situational factors and true dispositions, to distin-
   assigning causes to behaviour based on true dispositions       guish between the causal repercussions in both cases. For
   rather than situational factors. In this paper, we inves-
   tigate how knowledge representation tools in Artificial        the remainder of the paper, the terms factor and vari-
   Intelligence (AI), such as Bayesian networks (BNs), can        able will be used interchangeably. There are two kinds of
   help represent such situations and distinguish between         hidden variables, we will call them unmeasured-out and
   the types of clues used in assessing the behaviour (dispo-     unmeasured-in. The first type is present when the rele-
   sitional or situational). We also demonstrate how a dis-
   covery algorithm for contextual independencies can pro-        vant information is simply not in the model. Alternately,
   vide the information needed to separate a seemingly er-        information could be hidden inside a variable, typically
   roneous causal model (considering dispositions and situ-       by means of an independency that holds only in a par-
   ations together) into two more accurate models, one for        ticular context. We will call this scenario unmeasured-
   dispositions and one for situations.                           in. This context-specific independence (CSI) has been
                                                                  mainly studied in the context of reasoning with uncer-
                       Introduction                               tainty, and methods of inference for such independencies
                                                                  exist as well (Boutilier et al., 1996). The distinction be-
In the determination of causal attribution, we are inter-         tween the two classes of hidden variables is necessary for
ested in not only the true cause of behaviour, but also           making correct representational decisions in adult causal
in how we, as human adults, assign a cause to another             judgment when faced with seemingly erroneous data.
person’s behaviour, whether the inferred cause is true
or not. When seeking to understand another individ-                  We then focus on the class of unmeasured-in variables
ual’s behaviour, people generally make use of informa-            and show how statistical methods for discovering con-
tion that can be classified into two categories of causes,        textual independencies in Bayesian networks can help
namely situational factors, and dispositional causes. Sit-        us discover these hidden variables. Ignoring this kind of
uational factors explain actions in terms of a social set-        hidden variable results in incorrect inferences about par-
ting or environment, while dispositions are causes based          ticular subgroups of individuals. More interestingly, we
on characteristics of the person whose behaviour we seek          show that if the contextually hidden data is considered,
to understand. When attributing a cause to a person,              it will help us learn whether the attribution was based
it is very important that the inference comes from dis-           on a person’s true disposition or on situational factors.
positional factors, and not situational ones. Unfortu-            In addition, we may discover that two different causal
nately, the distinction between the two is often blurred          models should be used for the same scenario based on
in data. For example, a job applicant who fails to attend         the type of attribution that was made (dispositional or
a recruitment meeting may be perceived as anti-social or          situational). We present a method for correcting such
uninterested (disposition), when in reality, the individual       erroneous models by finding the hidden contextual vari-
lives out of province, and will only relocate if hired (sit-      ables.
uation). A more thorough examination of the context of               The remainder of this paper is organized as follows.
the situation painted by the available information may            First, we present some background information. We dis-
reveal hidden clues about the nature of the factors be-           cuss Correspondent Inferences in attribution theory, and
ing considered (situational or dispositional). Discovery          follow with the role of Bayesian networks and causal
of such clues (context-specific independencies) may yield         models as representation and inference tools. Then we
more accurate causal models to describe the situation at          give an example of a distribution containing hidden fac-
hand.                                                             tors that cannot be inferred without consideration of
   In the late 1990s, psychologists and educators began           context. We then discuss two types of hidden variables
to value the need for consideration of the natural con-           and how we distinguish between the two. Finally, we
text in which humans perform problem solving tasks.               discuss a method for discovering hidden variables from
This relatively new emphasis is refered to as situated            data, by means of contextual independencies. In our
cognition (Seifert, 1999). In this paper, we address how          conclusions, we outline some potential future direction
consideration of context can help uncover hidden factors          for this work.
                                                              2111

            Background Information                              one expects causal links to be directed from A and B to
                                                                C, as all other causal scenarios lead to logical errors.
In the introduction, we distinguished between true dis-
positions and situational factors. In this section, we          Causal Models
highlight particularities about each that motivate the
need for an understanding of subsets of the data used           Several authors express causal models in probabilistic
in making causal judgments. We then discuss Bayesian            terms because, as argued by Suppes (Suppes, 1970),
networks and how they are a useful representational tool        most causal statements in everyday conversation are a
for causal relations. Finally, we discuss causal models         reflection of probabilistic and not categorical relations.
and present an example.                                         For that reason, probability theory provides an adequate
                                                                framework for reasoning with causal knowledge (Good,
Correspondent Inferences in Attribution                         1983; Reichenbach, 1956). Pearl’s causal models provide
                                                                the mechanism and structure needed to allow for a rep-
As stated in the introduction, situational factors explain
                                                                resentation of causal knowledge based on the presence
actions in terms of a social setting or environment, while
                                                                and absence of probabilistic conditional independencies
dispositions are causes based on characteristics of the
                                                                (CIs) (Pearl, 1988).
person in question. Jones and Davis’ Correspondent In-
ference theory (Jones and Davis, 1965) suggests that we         Definition 1 A causal model (Pearl and Verma, 1991)
use information about the behaviour of a person as well         of a set of random variables R can be represented by
as effects of the particular behaviour to make a corre-        a directed acyclic graph (DAG), where each node corre-
spondent inference, in which the behaviour is either at-       sponds to an element in R and edges denote direct causal
tributed to a disposition or a situation, and is based on       relationships between pairs of elements of R.
a sole observation. This theory is interesting for hid-
den variable discoveries, as we have a single observation          The direct causal relations in the causal model can be
about each individual, and discover independencies be-         expressed in terms of CIs.
tween variables when we look at a group of individuals
performing a similar task.                                     Definition 2 Let R = {A1 , A2 , . . . , An } denote a finite
                                                               set of discrete variables, where each variable A ∈ R takes
Bayesian Networks and Causality                                on values from a finite domain VA . We use capital let-
                                                                ters, such as A, B, C, for variable names and lowercase
A Bayesian network (BN) (Pearl, 1988) is a directed             letters a, b, c to denote outcomes of those variables.
acyclic graph with a conditional probability distribution
                                                                   Let X and Y be two disjoint subsets of variables in R
associated with each node. The topology of the graph
                                                                and let Z = R − {X ∪ Y }. We say that Y and Z are
encodes the information that the joint distribution of all
                                                                conditionally independent given X, denoted I(Y, X, Z)
variables in the graph is equal to the product of the lo-
                                                               if, given any x ∈ Vx , y ∈ Vy , then for all z ∈ Vz
cal distributions. We can interpret the joint distribution
as being everything we know about a group of individ-
uals, and the local distributions as being a subset of in-
formation directly related to a particular inquiry about             p(y|x, z) = p(y|x), whenever p(x, z) > 0.
the group of users. BNs compactly represent joint prob-
ability distributions, and reason efficiently with those           With the causal model alone, we can express portions
representations. There is significant literature on infer-      of the causal knowledge based on the CIs in the model.
ence; (Pearl, 1988) is a good place to start.                   The conditional probabilities resulting from the CIs de-
   BN practitioners noticed early on that typical inde-         fined in the model can be formally expressed for all con-
pendence assumptions (unconditional independence of             figurations in the Cartesian product of the domains of
diseases, conditional independence of symptoms) in the          the variables for which we are storing conditional prob-
diagnosis domain, for example, tended to orient arcs            abilities.
in the direction of causality. Pearl and Verma (Pearl
and Verma, 1991) provided probabilistic definitions of          Definition 3 Let X and Y be two subsets of variables
causality that explained this phenomenon, but also pro-         in R such that p(y) > 0. We define the conditional prob-
vided algorithms for learning cause-effect relationships        ability distribution (CPD) of X given Y = y as:
from raw data.
   The definitions of Pearl and Verma are subtle, but                         p(x, y)
                                                                p(x|y) =              , implying p(x, y) = p(y) · p(x|y) (1)
the algorithm itself is simple, and works as follows. Al-                      p(y)
though covariance does not imply causation, covariance
implies the presence of causality. If A and B covary, then      for all configurations in Vx × Vy .
either A causes B, B causes A, or A and B have a com-
mon cause C. Thus, covariance implies a disjunction             Definition 4 A causal theory is a pair T =< D, θD >
of causal relations. Combinations of conditional inde-          consisting of a DAG D along with a set of CPDs θD
pendencies and dependencies in the data can eliminate          consistent with D. To each variable A ∈ R, there is
certain disjuncts. For example, if A and C covary, B and        an attached CPD p(Ai |Yi . . . Yn ) describing the state of
C covary, and A and B are unconditionally independent,         a variable Ai given the state of its parents Yi . . . Yn .
                                                           2112

Example of a Causal Model                                                  Classes of Hidden Variables
Company ABC is interested in better understanding                An important distinction needs to be made between
what type of applicant is likely to be a successful em-          types of hidden variables to allow for accurate consid-
ployee within the company. ABC is a large corporation            eration of context and correction of causal models. We
and receives applications from across the country. The           call a variable unmeasured-out when the relevant infor-
CEO likes to interview as many qualified applicants as           mation is simply not in the model. This type of omission
possible. However, although a large percentage of appli-         can yield a model erroneous in that the data may indi-
cants meet all the requirements, to reduce recruitment           cate a direct causal relationship between two variables,
cost the CEO would like to interview only a subset of the        when in reality the two variables are simply the effects
qualified applicants. The CEO would like to learn more           of a common cause. This type of false causal conclusion
about the employees of his company to understand what            is referred to as “spurious association”, and Pearl and
type of applicant would likely be successful in interview.       Verma’s (Pearl and Verma, 1991) Inductive Causality
   The causal model in Figure 1 describes the causal re-         (IC) algorithm can detect the presence of such associ-
lationship between 5 variables directly related to the po-       ations, although the algorithm cannot rectify the prob-
tential success in interview of a typical applicant, includ-     lem. The engine can’t provide the user with the factor
ing the success variable itself. For simplicity, we assume       or set of factors that is a common cause to the spurious
each variable is binary. The 5 variables are the follow-         association: “No causes in, no causes out” (Cartwright,
ing: (A)pplicant’s experience with dealing with the pub-         1989).
lic, (W)eekend outings organized by company regularly               The other type of hidden variable is unmeasured-in
to promote dynamics within personnel, (P)reparation for          and it is a genuine causal relationship that is hidden in-
interview, (R)esearch about company done by applicant            side a variable, typically by means of an independency
prior to interview, and finally (S)uccess in job interview.      that holds in a particular context. The causal relation-
                                                                 ships known about a particular domain are probabilis-
                         A         R                             tic conditional independencies (CIs) found in the data.
                                                                 For a CI to hold, it must be true for every configura-
                         W         P
                                                                 tion in the dataset. Whenever we find such truth in
                                                                 the data, we ensure there is no direct causal relationship
                              S                                  between the variable on which we condition, and the
                                                                 variable that is deemed independent. In such cases, we
                                                                 can remove the causal link from the causal model. Since
        Figure 1: Causal model for job interview.                this CI must hold for every value in a CPD to be con-
                                                                 sidered independent, any subset of values for which an
   According to the DAG, there is a direct causal re-            independence holds simply gets ignored. The distinc-
lationship between the applicant’s experience with the           tion between dispositional and situational factors can
public (A) and their interest in making their involvement        easily become blurred in a model that only admits CI
in the company a part of their social life (W ). There is        and result in the entire causal model seeming erroneous.
also a direct causal influence from A to P , the time and        Note that discovering unmeasured-in variables can pro-
effort spent on job interview preparation. Finally, the          vide clues on where unmeasured-out variables may need
last causal relationship emerging from A is clear, namely        to be considered.
that there is a relationship between A and a successful             We show how statistical methods for discovering con-
job interview (S). Researching the company prior to the          textual independencies in Bayesian networks can help us
job interview (R) is causally related to preparation for         discover these hidden variables. More interestingly, we
the interview (P ), which in turn is directly causally re-       show that if the contextually hidden data were consid-
lated to S, a successful interview. Finally, an interest in      ered, it would help us learn much about a particular type
socializing outside work hours (W ) is directly related to       of individual, based on the reason for their behaviour,
a successful job interview. The corresponding causal the-        namely a situation or a true disposition. We present a
ory attaches to variables A, R, P, W, and S respectively         method for correcting such erroneous models by finding
the following CPDs:                                              the hidden contextual variables.
p(A), p(R), p(P |A, R), p(W |A) and p(S|A, W, P ). (2)
                                                                          Discovery of Hidden Variables
                                                                 Since BNs operate on the general notion of CIs, it is diffi-
   Although the causal model in Figure 1 seems reason-           cult to consider hidden variables in the data or even to be
able and intuitive, we will see later that discovery of hid-     aware of their presence. In this section, we first instan-
den variables paints a different picture that can lead to        tiate a CPD from our running example, which is based
bad hiring decisions if left unattended. Although the no-        solely on CI. We then introduce context-specific inde-
tion of causation is frequently associated with concepts         pendence (CSI) and discuss how it allows us to consider
of necessity and functional dependence, “causal expres-          contexts and therefore have a starting point for finding
sions often tolerate exceptions, primarily due to miss-          hidden variables. We illustrate this with our running ex-
ing variables and coarse descriptions” (Pearl and Verma,         ample. Finally, we show how the discovery of CSIs helps
1991).                                                           refine and correct our existing causal model.
                                                             2113

Instantiation of a CPD                                             context. Discovery of CSI can help us build more specific
In his attempts to understand applicants and their po-             causal models instead of a single causal model ignoring
tential fit within the company, while not interviewing             particular subsets of values. CSI is defined as follows.
all qualified applicants, the CEO of ABC gathers factors           Definition 5 Let X, Y, Z, C be pairwise disjoint subsets
about the applicants that he feels are relevant indica-            of variables in R, and let c ∈ Vc . We say that Y and
tors of success. For every hiring session, he organizes an         Z are conditionally independent given X in context C =
informal social recruiting session specifically for the ap-        c (Boutilier et al., 1996), denoted IC=c (Y, X, Z) if,
plicants, and although not mandatory, he expects most
candidates to attend. Since this session is an indicator               p(y|x, z, c) = p(y|x, c), whenever p(x, z, c) > 0.
of motivation and interest, the CEO compiles the appli-
cations of those who didn’t attend the session to look for             Note that since we are dealing with partial CPDs, a
indicators of a lower applicant success rate, which is ex-         more general operator than the multiplication operator is
actly what one would expect. Based on the arrows in the            necessary for manipulating CPDs containing CSIs. This
causal model in Figure 1, the variables having a direct            operator, formalized by Zhang and Poole (Zhang and
relationship with successful interview S are A, P , and            Poole, 1999) is called the union-product operator and we
W . The associated CPD for p(S|A, W, P ) is presented              represent it with the symbol ⊙. Due to space limitations,
in Figure 2.                                                       we do not discuss the details of union-product here.
                    A  W  P   S  p(S|A, W, P )
                                                                   CSI Discovery
                    0  0   0  0      0.80                          The CEO of ABC did not consider context. In this sub-
                    0  0   0  1      0.20
                    0  0   1  0      0.10                          section, we see that a consideration of context changes
                    0  0   1  1      0.90                          the original model in Figure 1. We use a CSI detection
                    0  1   0  0      0.80
                    0  1   0  1      0.20
                                                                   method called Refine-CPD-tree (Butz and Sanscartier,
                    0  1   1  0      0.10                          2002a). The method is based on a tree representation of
                    0  1   1  1      0.90                          a CPD. Using this algorithm, we can see if a tree reduc-
                    1  0   0  0      0.15
                    1  0   0  1      0.85                          tion is possible. If such a reduced tree exists, the data
                    1  0   1  0      0.15                          contains a CSI, which is an indication of a hidden vari-
                    1  0   1  1      0.85
                    1  1   0  0      0.05                          able that could perhaps correct a faulty model that may
                    1  1   0  1      0.95                          otherwise appear correct. The detection method works
                    1  1   1  0      0.05
                    1  1   1  1      0.95
                                                                   as follows: Given a tree representation of a CPD, if all
                                                                   children of a node A are identical, then replace A by one
                                                                   of its offspring, and delete all other children of A.
             Figure 2: The CPD p(S|A, W, P ).                          In our running example, we have a CPD that contains
                                                                   all available information relevant to making a decision
   Based on the information in the distribution, we see            about the potential success of an interview by a job ap-
that some applicants who did not attend the session                plicant, as depicted in Figure 2. Recall that no variables
were very successful in interview while others were not.           can be removed from that distribution based on CI, since
There is no clear indication that not attending the re-            the independence would have to hold for all values in the
cruitment session had a direct impact on overall success.          distribution. The Refine-CPD algorithm can determine
If that were the case, all probability values in the distri-       if context-specific independencies reside in the data. The
bution would be quite low since none, or few of the ap-            CPD in Figure 2 can be represented as the CPD-tree in
plicants from this group would have had successful inter-          Figure 3.
views. Below, we see how a discovery method for hidden
variables reveals strong influences hidden in this seem-                                                          A
                                                                                                       0                   1
ingly inconclusive CPD, and revealing situational fac-
                                                                                         W                                                 W
tors about the individuals that are not to be attributed                            0           1                                     0           1
to true dispositions about the person, but rather to the                     P                         P                       P                         P
                                                                          0     1                   0     1                 0     1                   0     1
situation.
                                                                       S            S            S           S           S            S            S           S
                                                                     0   1        0   1       0    1       0   1       0   1        0   1       0    1       0   1
Context-Specific Independence (CSI)
                                                                  0.80   0.20 0.10    0.90 0.80    0.20 0.10   0.90 0.15   0.85 0.15    0.85 0.05    0.95 0.05   0.95
Boutilier et al. (Boutilier et al., 1996) formalized the no-
tion of context-specific independence. Without CSI, it is
only possible to establish a causal relationship between                     Figure 3: Initial CPD-tree for p(S|A, W, P ).
two variables if a certain set of CIs is absent for all values
of a variable in the distribution. With CSI, we can rec-               Running the Refine-CPD algorithm yields the refined
ognize CIs that hold for a subset of values of a variable in       CPD-tree in Figure 4. The variable W no longer appears
a distribution. Therefore, we can account for a situation          on the left side of the tree, in the context A = 0. In
of the individual that doesn’t reflect a true disposition          addition, on the right side of the tree, in context A =
of that person, without disregarding occasions when a              1, the variable P no longer appears. This suggests a
similar inference would be rightfully attributed to a true         hidden relationship in variable A in context A = 0 and
disposition. CSI is a CI that holds only in a particular           in context A = 1.
                                                               2114

                                     A                                                     AWPS   p(S|A=0,W,P)   APS   p(S|A=0,P)
                                0           1
                                                                      AWPS   p(E|A,W,P)     0000        0.80   →  000       0.80
                         P                         W                   0000      0.80       0001        0.20      001       0.20
                      0     1                   0     1
                                                                       0001      0.20       0010        0.10      010       0.90
                   S            S            S           S             0010      0.10       0011        0.90      011       0.10
                 0   1        0   1       0    1       0   1           0011      0.90       0100        0.80
                                                                       0100      0.80       0101        0.20
              0.80   0.20 0.10    0.90 0.15    0.85 0.05   0.95
                                                                       0101      0.20       0110        0.10
                                                                       0110      0.10   ր   0111        0.90
                                                                       0111      0.90
      Figure 4: Refined CPD-tree for p(S|A, W, P ).                    1000      0.15      AWPS   p(S|A=1,W,P)   AWS   p(S|A=1,W)
                                                                       1001      0.85   ց   1000        0.15      100       0.15
                                                                       1010      0.15       1001        0.85   →  101       0.85
                                                                       1011      0.85       1010        0.15      110       0.05
Uncovering Hidden Variables                                            1100      0.05       1011        0.85      111       0.95
                                                                       1101      0.95       1100        0.05
The previous subsection showed that a CSI discovery al-                1110      0.05       1101        0.95
gorithm can uncover hidden relationships in a CPD when                 1111      0.95       1110        0.05
no causal independencies can be inferred by consider-                                       1111        0.95
                                                                             (i)                   (ii)                (iii)
ing the entire dataset. The example showed that some
contexts of A may help explain the relevance of the ap-
plicants’ absence to the recruitment session. If we look            Figure 5: Variables S and W are conditionally inde-
again at Figure 2, and consider A = 0 and A = 1 sep-                pendent given P in context A = 0, while S and P are
arately, we can observe that removing W from the dis-               conditionally independent given W in context A = 1.
tribution in configurations where A = 0 doesn’t change
the likelihood of occurrence of S, whereas such a removal
would be impossible in the context A = 1. In A = 0,                 tant to keep W in the model for that second subset of
p(S|A = 0, P, W ) = 0.80 when P = 0 and S = 0, 0.20                 candidates since knowing W does change our belief in S.
when P = 0 and S = 1, 0.90 when P = 1 and S = 0,                    However, still in context A = 1, after running the discov-
and finally, 0.10 when P = 1 and S = 1. In context                  ery algorithm, variable P disappears. Recall that vari-
A = 1, saying p(S|A = 1, P, W ) = 0.15 when P = 0 and                able P dealt with preparation for the interview. Since P
S = 0, is not completely correct since it is also true that          doesn’t affect our belief in S in context A = 1, we can
in context A = 1, p(S|A = 1, P, W ) = 0.05 when P = 0                conclude that these individuals’ performance is not af-
and S = 0. In the first case of context A = 1, W = 0,                fected by whether they prepare for the interview or not.
while in the second case, W = 1. Therefore, the value of             Given that and the fact that they are eager to partici-
W does change the probability of successful interview in             pate in weekend outings, it is difficult to attribute their
context A = 1, so no removal is possible. We conclude                non-attendance to the recruiting session to a true dis-
that in context A = 0, variables S and W are indepen-                position. With this new knowledge acquired from the
dent given variable P . Such a separation is legal since             discovery of an unmeasured-in variable, we have enough
no information is lost due to the union-product operator.            information to believe that there is something particu-
From the resulting CPDs, we may now make more ade-                   lar about candidates who didn’t attend the session, but
quate judgments about the individuals. The CPD after                 yet have experience with the public and are eager to so-
refinement is presented in Figure 5.                                 cialize with co-workers. With this information, we can
   Isolation of contexts suggests different causal models            look at the applications of those particular applicants to
depending upon the value of A. An examination of the                 see if our unmeasured-in discovery leads us to discover
semantics of the reduction reveals that in context A = 0             that perhaps some important information has been left
(no experience with the public), variable W plays no role            out of the model (unmeasured-out), but for which we
in estimating the success of the candidate’s interview.              could not see the importance unless we discovered the
Recall that variable W dealt with the candidate’s inter-             unmeasured-in variable. In this case, we may discover
est in participating in company weekend outings. Since               that such candidates all live outside the city, and there-
this subset of candidates have no experience with the                fore could not attend the session despite their desire to
public and do not seem eager to participate in weekend               socialize. This new information would also coincide with
outings, we are lead to believe that their absence from              their desire for socializing with co-workers on weekends
the recruitment session was due to a true disposition                (moving to a new city for a job), and their experience
of the person. Therefore, in context A = 0, perhaps a                with the public would be a much better indicator of their
different set of variables may better explain what would             success in interview than their amount of preparation
cause these candidates’ interviews to be successful. How-            (unlike their A = 0 counterpart). In context A = 1,
ever, without the discovery of this CSI between S and               behaviour should clearly be attributed to the situation
W in context A = 0, we cannot make that conclusion.                 rather than a true disposition. From this analysis, it is
On the other hand, in context A = 1 (experience with                clear that different causal models should be used for the
the public), we notice that those who didn’t attend the             two groups, as the factors that would lead to a success-
recruiting session were influenced by the weekend out-              ful interview differ greatly between the two. We now
ings W . Their probability of success was higher when               see how we can correct the causal models based on the
the value of W was equal to 1. Therefore, it is impor-              discovered independencies.
                                                                2115

Correcting the Model                                             cause in the discounting principle. We are currently in-
Since there is no longer mention of variable W in con-           vestigating this problem. In addition, the type of con-
text A = 0, we can refine our causal model by removing           textual discovery of independencies we use in this pa-
the direct causal link between W and S, and similarly in         per (CSI) can be generalized to deeper contexts, such as
context A = 1 for variable P . With the uncovered hid-           contextual weak independencies (CWI) (Butz and San-
den contexts of variable A, when considering the prob-           scartier, 2002b).
ability of a successful job interview S, given all factors
that have a direct causal link with S, the initial causal                               References
model in Figure 1 can be represented by two more spe-            Boutilier, C., Friedman, N., Goldszmidt, M., and
cific causal models that account for differences between              Koller, D. (1996). Context-specific independence
the two groups. Those refined causal models are illus-                in bayesian networks. In Proceedings of the Twelfth
trated in Figure 6, where the left side represents the                Conference on Uncertainty in Artificial Intelligence,
refined model for context A = 0 (disposition), and the                pages 115–123.
right side represents the refined model for context A = 1
(situation).                                                     Butz, C. and Sanscartier, M. (2002a). A method for de-
                                                                      tecting context-specific independence in conditional
                                                                      probability tables. In Third International Confer-
              A       R                 A
                                                                      ence on Rough Sets and Current Trends in Comput-
                                                                      ing, pages 344–348.
                      P                 W
                                                                 Butz, C. and Sanscartier, M. (2002b). On the role of
                  S                         S                         contextual weak independence in probabilistic in-
                                                                      ference. In Fifteenth Canadian Conference on Arti-
                                                                      ficial Intelligence (AI), pages 185–194.
        Figure 6: Causal Models After Discovery
                                                                 Cartwright, N. (1989). Nature, Capacities and their
   Based on the more specific representations of the orig-            Measurements. Clarendon Press, Oxford.
inal causal model, it is now possible to categorize groups       Good, I. (1983). A causal calculus. British Journal for
of individuals. Candidates in the context A = 0, where                Philosophy of Science, 11.
S and W are independent given P , are likely to be indif-
ferent about the company’s weekend activities, as they           Jones, E. and Davis, K. (1965). From acts to dispo-
are disinclined to attend. Candidates in A = 1 are likely             sitions: The attribution process in person percep-
to be motivated by the idea of a social work culture,                 tion. In Berkowitz, L., editor, Advances in Exper-
since they would be moving to a new city if they were                 imental Social Psychology, volume 2, Orlando, FL.
hired. As for interview preparation, candidates in the                Academic Press.
context A = 0 are likely to spend more time and effort
on preparation so that they feel more comfortable dur-           Pearl, J. (1988). Probabilistic Reasoning in Intelligent
ing the interview by contemplating as many interview                  Systems: Networks of Plausible Inference. Morgan
scenarios as possible, due to their lack of interpersonal             Kaufmann, San Fransisco USA.
experience. Meanwhile, candidates in the context A = 1
are likely to spend less time preparing than those in con-       Pearl, J. and Verma, T. (1991). A theory of infered
text A = 0.                                                           causation. In Principles of Knowledge Represen-
   This example clearly indicates that the reason for at-             tation and Reasoning: Proceedings of the Second
tributing a cause to a particular individual differs greatly          International Conference, pages 441–452. Morgan
when we use clues about the situation surrounding the                 Kaufmann.
individual at the time of decision, rather than clues            Reichenbach, H. (1956). The Direction of Time. Univer-
about a true disposition of the individual. In addition,              sity of California Press, Berkeley.
the discovery of unmeasured-in hidden variables can help
in identifying elements surrounding a situation (based           Seifert, C. (1999). Situated cognition and learning. The
on what variables remain in a context, and which ones                 MIT Encyclopedia of the cognitive sciences, pages
disappear) to establish different causal models for dispo-            767–769.
sitions and situations.
                                                                 Suppes, P. (1970). A Probabilistic Theory of Causation.
         Conclusions and Future Work                                  North Holland, Amsterdam.
In attribution theory, the discounting principle and the         Zhang, N. and Poole, D. (1999). On the role of context-
covariation principle help determine the attributions                 specific independence in probabilistic reasoning. In
people make. In this paper, we have showed how consid-                Sixteenth International Joint Conference on Artifi-
ering context can help uncover true dispositions versus               cial Intelligence, pages 1288–1293.
situational factors as explanations for behaviour, with
the covariation principle. Contextual independencies can
also provide clues regarding consideration of the weaker
                                                            2116

