UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Using Phoneme Distributions to Discover Words and Lexical Categories in Unsegmented
Speech
Permalink
https://escholarship.org/uc/item/11c718v6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Christiansen, Morten H.
Hockema, Stephen A.
Onnis, Luca
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

            Using Phoneme Distributions to Discover Words and Lexical Categories
                                                    in Unsegmented Speech
                                           Morten H. Christiansen (mhc27@cornell.edu)
                                              Department of Psychology, Cornell University
                                                         Ithaca, NY 14853 USA
                                           Stephen A. Hockema (shockema@indiana.edu)
                                  Department of Psychological and Brain Sciences, Indiana University
                                                      Bloomington, IN 47405 USA
                                                    Luca Onnis (lo35@cornell.edu)
                                              Department of Psychology, Cornell University
                                                         Ithaca, NY 14853 USA
                              Abstract                                how words are put together to form meaningful sentences.
                                                                      An initial step in this direction involves determining what
   When learning language young children are faced with many          syntactic roles individual words may play in sentences.
   formidable challenges, including discovering words                 Several types of information may be useful for the discovery
   embedded in a continuous stream of sounds and determining
                                                                      of lexical categories, such as nouns and verbs, including
   what role these words play in syntactic constructions. We
   suggest that knowledge of phoneme distributions may play a
                                                                      distributions of word co-occurrences (e.g., Redington,
   crucial part in helping children segment words and                 Chater & Finch, 1998), frequent word frames (e.g., I X it;
   determining their lexical category. We performed a two-step        Mintz, 2003), and phonological cues (Kelly, 1992;
   analysis of a large corpus of English child-directed speech.       Monaghan, Chater & Christiansen, 2005). Indeed, merely
   First, we used transition probabilities between phonemes to        paying attention to the first and last phoneme of a word has
   find words in unsegmented speech. Second, we used                  been shown to be useful for predicting lexical categories
   distributional information about word edges—the beginning          across different language such as English, Dutch, French
   and ending phonemes of words—to predict whether the                and Japanese (Onnis & Christiansen, 2005).
   segmented words were nouns, verbs, or something else. These
                                                                         During the first year of life, infants become perceptually
   results indicate that discovering lexical units and their
   associated syntactic category in child-directed speech is
                                                                      attuned to the sound structure of their native language (see
   possible by attending to the statistics of single phoneme          e.g., Jusczyk, 1997; Kuhl, 1999, for reviews). We suggest
   transitions and word-initial and final phonemes.                   that this attunement to native phonology is crucial not only
                                                                      for word segmentation but also for the discovery of
                         Introduction                                 syntactic structure. Specifically, we hypothesize that
                                                                      phoneme distributions may be a highly useful source of
One of the first tasks facing an infant embarking on
                                                                      information that a child is likely to utilize in both tasks. In
language development is to discover where the words are in
                                                                      this paper, we test this hypothesis by carrying out a two-step
fluent speech. This is not a trivial problem because there are
                                                                      corpus analysis in which information about phoneme
no acoustic equivalents in speech of the white spaces placed
                                                                      distribution is used first in Experiment 1 to segment words
between words in written text. To find the words, infants
                                                                      out of a large corpus of phonologically-transcribed child-
appear to be utilizing several different cues, including
                                                                      directed speech and then in Experiment 2 to predict the
lexical stress (Curtin, Mintz & Christiansen, 2005),
                                                                      lexical category of these words (noun, verb, or other). The
transitional probabilities between syllables (Saffran, Aslin &
                                                                      results show that it is possible to get from unsegmented
Newport, 1996), and phonotactic constraints on phoneme
                                                                      speech to lexical categories with a reasonably high accuracy
combinations in words (Jusczyk, Friederici & Svenkerud,
                                                                      and completeness using only information about the
1993). Among these word segmentation cues, computational
                                                                      distribution of phonemes in the input.
models and statistical analyses have indicated that, at least
in English, phoneme distributions may be the single most
useful source of information for the discovery of word
                                                                                Experiment 1: Discovering Words
boundaries (e.g., Brent & Cartwright, 1996; Hockema,                  Infants are proficient statistical learners, sensitive to
2006), especially when combined with information about                sequential sound probabilities in artificial (Saffran et al.,
lexical stress patterns (Christiansen, Allen & Seidenberg,            1996) and natural language (Jusczyk et al., 1993). Such
1998).                                                                statistical learning abilities would be most useful for word
   Discovering words is, however, only one of the first steps         segmentation if natural speech was primarily made up of
in language acquisition. The child also needs to discover             two types of sound sequences: ones that occur within words
                                                                  172

and others that occur at word boundaries. Fortunately,
natural language does appear to have such bimodal                                                                   a
tendencies (Hockema, 2006). For example, in English /t g/
rarely, if ever, occurs inside a word and thus is likely to
straddle the boundary between a word ending in /t/ and
another beginning with /g/. On the other hand, the transition
/I / (the two phonemes making up –ing) almost always
occurs word internally. Here we demonstrate that sensitivity
to such phoneme transitions provides reliable statistical
information for word segmentation in English child-directed
speech.
Method
Corpus preparation. For our analysis we extracted all the
speech directed by adults to children from all the English
corpora in the CHILDES database (MacWhinney, 2000).
The resulting corpus contained 5,470,877 words distributed
over 1,369,574 utterances. Because most of these corpora                                                            b
are only transcribed orthographically, we obtained citation
phonological forms for each word from the CELEX
database (Baayen, Pipenbrock & Gulikers, 1995) using the
DISC encoding that employs 55 phonemes for English. In
the case of homographs (e.g., record), we used the most
frequent of the pronunciations. Moreover, recent detailed
analyses indicate that dual-category words are consistently
in one category only in child-directed speech (Jim Morgan,
personal communication). Another 9,117 nonstandard word
type forms (e.g., ain’t) and misspellings in CHILDES were
coded phonetically by hand. Sentences in which one or
more words did not have a phonetic transcription were
excluded.
Analyses. We first computed the probability of
encountering a word boundary between each possible
phoneme transition pair in the corpus. There were 3,025
(552) possible phoneme transition pairs (types). Transitions                                                        c
across utterance boundaries were not included in the
analyses. Having obtained the type probability of word
boundary between each pair of phonemes, we made another
pass over the CHILDES corpora phoneme stream and used
this information in a simple system that inserted word
boundaries in any transition token whose type probability
was greater than .5. That is, we went through the
unsegmented stream of phonemes and inserted a word
boundary whenever the probability of such boundary
occurring for a phoneme transition pair (token) was greater
than .5.
Results and Discussion
Of the 3,025 possible phoneme transition pairs, 954 (35%)          Figure 1: Distribution of phoneme transition pairs given
never occurred in the corpus. Figure 1.a provides a                the probability of encountering a word boundary between
histogram showing the distribution of phoneme transition           the two phonemes for types (a) and tokens (b), and a ROC
pairs as a function of how likely they are to have a word          curve (c) indicating the accuracy/completeness trade-off
boundary between them, given the proportion of                     when predicting lexical boundaries using tokens.
occurrences in our corpus for which a boundary was found.
The bar height indicates the percentage of phoneme                indicates the percentage of phoneme transition pairs that
transition pairs with a given probability of having a word        never occurred in the corpus. Figure 1.a clearly illustrates
boundary between them. The separate column on the right
                                                              173

that the distribution of used phoneme transition pairs was           been inserted within a word; e.g., the word picnic got split
strongly bimodal. Most phoneme transitions were either               into two fragments, /pIk/ and /nIk/) and combination words
associated only with a word boundary or occurred only                (“combo-words”, where a boundary had been missed
inside a word, but not both. Indeed, 61% of the used                 causing two words to be conjoined; e.g., the boundary
phoneme transition pairs were in the right- or leftmost bin.         between come and on was missed, yielding a single lexical
   These data, however, show the distribution of phoneme             unit, comeon). There were 558,707 fragments and 322,197
transition pairs independently of whether they occur only            combo-words.
once or many thousands of times. To get an idea of the                  These results replicate what was found in previous work
distribution of the phoneme transition pair tokens that a            (Hockema, 2006), this time using a larger alphabet of
child might actually come across in the input, we weighted           phonemes, a different lexicon for pronunciations, and an
each phoneme transition pair by its frequency of occurrence          even larger, more diverse corpus of child-directed speech:
across the corpus. Figure 1.b shows the distribution of              phoneme transitions contain enough information about word
phoneme transition pairs that a child is likely to hear has a        boundaries such that a simple model that attends only to
similar bimodal distribution as for the type analyses.               these can do well enough to bootstrap the word
   To assess the usefulness of this type of phoneme                  segmentation process. However, it is still an open empirical
distribution information for lexical segmentation, we                question as to how infants might actually make use of this
determined how well word boundaries can be predicted if              regularity. Previous research has speculated that infants may
inserted whenever the probability of boundary occurrence             attend to phoneme transition probabilities, with relatively
for a given phoneme transition pair is greater that .5. In all,      infrequent transitions indicating word boundaries. We
4,576,783 word boundaries were inserted. We used two                 evaluated the potential of this strategy by computing the
measures—accuracy and completeness—to gauge the                      correlation between bigram transition probabilities and the
reliability of the lexical boundary predictions. Accuracy is         actual probability of finding a word boundary across
computed as the number of correctly predicted boundaries             phoneme pairs. As expected, this was significantly negative
(hits) in proportion to all predicted word boundaries, both          (r = -.25), but perhaps not strong enough to wholly support
correct (hits) and incorrect (false alarms). Completeness is         the process, suggesting that infants relying on dips in
calculated as the number of correct boundaries (hits) in             transition probability to detect word boundaries would need
proportion to the total number of boundaries; that is, the           to supplement this strategy with other cues (such as
correct boundaries (hits) and the boundaries that the system         prosodic stress). This, however, does not rule out other
failed to predict (misses). Thus, accuracy provides an               strategies that could rely solely on pairwise phoneme
estimation of the percentage of the predicted boundaries that        statistics. For example, infants might bootstrap
were correct, whereas completeness indicates the percentage          segmentation by building a repertoire of phonemes that
of boundaries actually found out of all the boundaries in the        frequently occur on word edges (first learned perhaps from
corpus. Figure 1.c shows an ROC curve, indicating the                isolated words). Our data show that transitions among these
trade-off between accuracy and completeness given                    will very reliably indicate word boundaries. Note that for
different cut-off points for when to predict a word boundary.        phoneme transition statistics to be useful, infants do not
The asterisk denotes the .5 cut-off point used in the current        have to pick up on them directly, they just have to attend to
analyses, revealing an accuracy of 88% and a completeness            word edges, which, given the regularity we found in the
of 79% for predicted word boundaries.                                language, could be enough to bootstrap segmentation.
   Predicting lexical boundaries is not the same as
segmenting out complete words. We therefore used a                    Experiment 2: Discovering Lexical Categories
conservative measure of word segmentation in which a                 In Experiment 1, we presented a simple phoneme-based
word is only considered to be correctly segmented if a               model capable of reasonably accurate and complete
lexical boundary is predicted at the beginning and at the end        segmentation of words from unsegmented speech. However,
of that word without any boundaries being predicted word-            performance was not perfect as evidenced by the number of
internally (Brent & Cartwright, 1996; Christiansen et al.,           word fragments and combo-words. The question thus
1998). For example, if lexical boundaries were predicted             remains whether the imperfect output of our segmentation
before /k/ and after /s/ for the word /kæts/ (cats), it would be     model can be used by another system to learn about higher-
considered correctly segmented; but if an additional                 level properties of language. From previous work, we know
boundary was predicted between /t/ and /s/ the word would            that beginning and ending phonemes can be used to
be counted as missegmented (even though this segmentation            discriminate the lexical categories of words from pre-
would be useful for learning morphological structure).               segmented input (Onnis & Christiansen, 2005). This is
Using this conservative measure we computed segmentation             supported by evidence that both children (Slobin, 1973) and
accuracy and completeness for complete words. Overall, the           adults (Gupta, 2005) are particularly sensitive to the
model identified 70.2% of the words in our corpus                    beginning and endings of words. In Experiment 2, we
(completeness), while 74.3% of the words it identified were          explore whether such word-edge cues can still lead to
valid (accuracy). The missegmented words were classified             reliable lexical classification when applied to the noisy
into word fragments (where a boundary had erroneously                output of our word segmentation model. We hypothesized
                                                                 174

that missegmented phoneme strings may not pose as much                Children’s syntactic development is perhaps best
of a problem as one might expect because such phoneme              characterized as involving fragmentary and coarse-grained
sequences are more likely to have less coherent                    knowledge of linguistic regularities and constraints (e.g.,
combinations of word-edge cues compared to lexical                 Tomasello, 2003). In this respect, it seems more reasonable
categories such as nouns and verbs.                                to assume that the child will start assigning words to very
                                                                   broad categories that do not completely correspond to adult
Method                                                             lexical categories (Nelson, 1995). In addition, the first adult-
Corpus preparation. The segmented corpus produced by               like lexical categories will be the most relevant to successful
the segmentation model in Experiment 1 was used for the            communication. For example, noun and verb categories will
word-edge analyses. The lexical category for each word was         be learned earlier than mappings to conjunctions and
obtained from CELEX (Baayen et al., 1995). Homophones              prepositions (Gentner, 1982). Hence, the task of the
were assigned the most frequent lexical class in CELEX.            discriminant analysis was to classify the whole corpus into
Several words also had more than one lexical category.             three categories: Nouns, Verbs, and Other. This
Nelson (1995) showed that for these so-called dual-category        classification plausibly reflects the early stages of lexical
words (e.g., brush, kiss, bite, drink, walk, hug, help, and        acquisition, with Other being an amalgamated “super-
call) no specific category is systematically learned before        category” incorporating all lexical items that are not nouns
the other, but rather the frequency and salience of adult use      or verbs. Accordingly, the lexical category was derived
are the most important factors. Dual-category words were           from CELEX for all words. Words that had a lexical
therefore assigned their most frequent lexical category from       category other than noun or verb were assigned to Other,
CELEX. In total, there were 101,721 different lexical item         along with the combo-words and fragments.
types, of which 7,432 were words, and the remaining were              To provide the best measure of the classification problem
combo-words and fragments. Among words, 4,530 were                 that a child faces during language learning, each case—that
nouns, and 1,601 were verbs.                                       is, the 110-bit vector corresponding to each word, fragment,
Cue derivation. The CELEX DISC phonetic code used in               or combo-word—was weighted by its frequency. The
incorporates 55 phonemes to encode English phonology.              resulting token-based discriminant analysis thus takes into
Each lexical item was represented as a vector containing           account the frequency of occurrence of the lexical items in
110 (55 beginning + 55 ending) bits. If the word started and       the corpus.
ended with one of the English phonemes, then its relevant             In evaluating the true contribution of word-edge cues to
bit in the vector was assigned a 1, otherwise a 0. Thus, the       classification, it is important to take into account that a
encoding of each word in the corpus consisted of a 110-bit         certain percentage of cases could be correctly classified
vector with most bits having value 0 and two having value          simply by chance. To establish the chance-level of
of 1. These 110 bits formed the Independent Variables to be        performance, a baseline condition was therefore generated
entered in a discriminant analysis. The Dependent Variable         using Monte Carlo simulations. The file containing the data
was the lexical category of each item.                             from the corpus had 111 columns: the 110 columns of
   To assess the extent to which word-edge cues can be used        binary word edge predictors (Independent Variables), plus
for reliable lexical category classification, we performed a       one column that had dummy variable scores of 1, 2, or 3 for
linear discriminant analysis dividing words into Nouns,            the three lexical categories (Dependent Variable). This last
Verbs, or Other. Discriminant analyses provide a                   column contained 4,530 values of 1 (Noun), 1601 values of
classification of items into categories based on a set of          2 (Verb), and 95,590 values of 3 (Other). We randomly
independent variables. The chosen classification maximizes         rescrambled the order of the entries in that column while
the correct classification of all members of the predicted         leaving the other 110 columns (the word-edge predictors)
groups. In essence, discriminant analysis inserts a                unchanged. Thus, the new random column had the exactly
hyperplane through the word space, based on the cues that          same base rates as the old column in random order, while
most accurately reflect the actual category distinction. An        the first 110 columns were completely unchanged. The
effective discriminant analysis classifies words into their        rescrambling maintains information available in the vector
correct categories, with most words belonging to a given           space, but removes potential correlations between specific
category separated from other words by the hyperplane. To          word-edge cues and lexical categories, and thus represents
assess this effectiveness, we used a “leave-one-out cross-         an empirical baseline control. We created 100 different
validation” method, which is a conservative measure of             rescramblings for the Dependent Variable and tested the
classification accuracy, and works by calculating the              ability of the 110 word-edge cues to predict each one of the
accuracy of the classification of words that are not used in       rescramblings in 100 separate discriminant analyses. The
positioning the hyperplane. This means that the hyperplane         mean classification scores from the rescrambled analyses
is constructed on the basis of the information on all words        were then compared with the results from the word-edge
except one, and then the classification of the omitted word is     analysis using standard t-tests. In this way, it was possible to
assessed. This is then repeated for each word, and the             determine whether in the experimental condition there was a
overall classification performance can then be determined.         significant phonological consistency within nouns, within
                                                                   verbs, and within other words or whether a three-way
                                                               175

                            word edges                                                                            word edges
                            baseline                                                                              baseline
                         100%
                                          COMPLETENESS               ACCURACY
                                                                                                                                  100%      COMPLETENESS                ACCURACY
                                 90%                                                                                              90%
Percent Correct Classification                                                                   Percent Correct Classification
                                 80%                                                                                              80%
                                 70%                                                                                              70%
                                 60%                                                                                              60%
                                 50%                                                                                              50%
                                 40%                                                                                              40%
                                 30%                                                                                              30%
                                 20%                                                                                              20%
                                 10%                                                                                              10%
                                 0%                                                                                                0%
                                       TOTAL NOUNS VERBS OTHER   TOTAL NOUNS VERBS OTHER                                                 TOTAL NOUNS VERBS OTHER   TOTAL NOUNS VERBS OTHER
Figure 2: Classification completeness and accuracy of the                                         Figure 3: Classification performance of the model
lexical items from the segmentation model into lexical                                            generalizing word-edge cues from 50 nouns and verbs to
categories, based on first and last phoneme in each word.                                         101,565 novel lexical items.
classification of words randomly assigned to the three                                           supervised exposure to only a few words would allow for
categories would result in the same level of classification.                                     generalization to subsequent words using word-edge cues
                                                                                                 alone, we conducted additional discriminant analyses. We
Results and Discussion                                                                           used the top-50 most frequent nouns (19) and verbs (31)
Using the word-edge cues, 62.0% of the cross-validated                                           along with 106 additional lexical items from the Other
lexical tokens were classified correctly, which was highly                                       category with equally high frequency. This is meant to
significant (p < .001). In particular, 44.7% of Nouns, 38.8%                                     model the slow learning of the first approximately 50 words
of Verbs, and 70.5% of Other words were correctly                                                prior to the onset of the “vocabulary spurt” around 18
classified using word-edge cues. To test against chance                                          months (e.g., Nelson, 1973). These first words may be
levels 100 Monte Carlo discriminant analyses were run in                                         learned entirely through feedback and interactions with
the baseline condition where the 101,721 lexical item                                            caregivers. In this context, we are further assuming that
vectors were randomly assigned to one of the three                                               children would be sensitive to the repeated sound patterns of
categories, as described above. The baseline analyses                                            the Other items without necessarily having learned their
yielded a mean correct classification of 31.3% (SD=3.7%).                                        meaning. A supervised model was created using the 156
In particular, 33.3% (SD=3.9%) of nouns, 35.7%                                                   lexical items and predictions made for the remaining
(SD=3.8%) of verbs, and 31.2% (SD=4.0%) of other words                                           101,565 lexical item types, each weighted by frequency. We
were correctly cross-classified. Word-edge classification                                        additionally ran 10 baseline models using the same
was significantly higher than the baseline classification for                                    procedure as before.
nouns, verbs, and other items (p < .001).                                                           The accuracy and completeness of the classifications for
   The percentages reported above provide an estimate of the                                     both the word-edge and baseline analyses can be seen in
completeness of the classification procedure, i.e., how many                                     Figure 3. Classification based on word-edge cues was
words in a given category are classified correctly. We                                           significantly higher than baseline classifications across all
further measured the accuracy of the classifications for each                                    categories (p’s < .001). Based on supervised exposure to
of the three categories. Accuracy and completeness scores                                        only 50 nouns and verbs, the statistical model is able to
for both the word-edge and baseline analyses are shown in                                        generalize robustly to subsequent words based on word-
Figure 2. Both classification accuracy and completeness are                                      edge cues alone. This kind of partial bootstrapping may help
high for Other items, though the baseline is higher for                                          explain the vocabulary spurt: slow, supervised learning of
accuracy. This is not surprising, however, given the sheer                                       the relationship between word-edge cues and lexical
disproportion between Nouns (694,796 tokens) and Verbs                                           categories may be needed before it can be used to facilitate
(665,658 tokens) on the one side, and Other items                                                word learning. More broadly, the results not only compare
(3,216,329 tokens) on the other side. Nonetheless, the                                           well with those of Onnis and Christiansen (2005)—who
classification of Nouns and Verbs is both relatively accurate                                    used an optimally-segmented corpus as input—they also
and complete, indicating that word-edge cues are useful for                                      provide a first initial indication of how children might get
discovering the lexical categories of words.                                                     from unsegmented speech to lexical categorization.
   A downside of the current analyses is that they are
“supervised” in that the underlying discriminant analysis                                                                                          General Discussion
model is provided with both the word-edge cues and their                                         In this paper, we have presented a two-step analysis of the
lexical category when seeking to find the optimal mapping                                        usefulness of information about phoneme distributions for
from the former to the latter. To determine whether                                              the purpose of word segmentation and lexical category
                                                                                           176

discovery. To our knowledge, this is the first time that a          Curtin, S., Mintz, T.H. & Christiansen, M.H. (2005). Stress
combined approach has demonstrated how a single                       changes the representational landscape: Evidence from
cue—phoneme distributions—can be used to get from                     word segmentation. Cognition, 96, 233-262.
unsegmented speech to broad lexical categories. Crucially,          Gentner, D. (1982). Why nouns are learned before verbs:
both steps utilized very simple computational principles to           Linguistic relativity versus natural partitioning. In S.
take advantage of the phoneme distributional cues, requiring          Kuczaj (Ed.) Language development, Vol. 2. Hillsdale,
only sensitivity to phoneme transitions and word edges.               NJ: Erlbaum.
Importantly, these two sensitivities are in place in infants        Gupta, P. (2005). Primacy and recency in nonword
(transitional probabilities, see Saffran et al., 1996) and            repetition. Memory, 13, 318-324.
young children (word edges, see Slobin, 1973). Hence our            Hockema, S.A. (2006). Finding words in speech: An
                                                                      investigation of American English. Language Learning
analyses incorporate plausible developmental assumptions
                                                                      and Development, 2, 119-146.
both about low computational complexity and about the
                                                                    Jusczyk, P.W. (1997). The discovery of spoken language.
type of information that might be perceptually available to           Cambridge, MA: MIT Press.
infants and young children. The two experiments also                Jusczyk, P.W., Friederici, A.D. & Svenkerud, V.Y. (1993).
demonstrate that segmentation does not have to be perfect             Infants’ sensitivity to the sound patterns of native
for it to be useful for learning other aspects of language.           language words. Journal of Memory and Language, 32,
Indeed, because word fragments and combo-words are                    402–420.
likely to have less consistency in terms of their word-edge         Kelly, M.H. (1992). Using sound to solve syntactic
cues in comparison to nouns and verbs, missegmentations               problems: The role of phonology in grammatical category
may even facilitate lexical-category discovery.                       assignments. Psychological Review, 99, 349-364.
   Our analyses have underscored the usefulness and                 Kuhl, P.K. (1999). Speech, language, and the brain: Innate
potential importance of phoneme distributions for                     preparation for learning. In M.D. Hauser & M. Konishi
bootstrapping lexical categories from unsegmented speech.             (Eds.), The design of animal communication (pp. 419-
However, a complete model of language development                     450). Cambridge, MA: MIT Press.
cannot be based on this single source of input alone. Rather,       MacWhinney, B. (2000). The CHILDES project: Tools for
young learners are likely to rely on many additional sources          analyzing talk (3rd ed.). Mahwah, NJ: Erlbaum.
of probabilistic information (e.g., social, semantic, prosodic,     Mintz, T.H. (2003). Frequent frames as a cue for
word-distributional) to be able to discover different aspects         grammatical categories in child directed speech.
of the structure of their native language. Our previous work          Cognition, 90, 91-117.
has shown that the learning of linguistic structure is greatly      Monaghan, P., Chater, N., & Christiansen, M.H. (2005).
facilitated when phonological cues are integrated with other          The differential contribution of phonological and
types of cues, both at the level of speech segmentation (e.g.,        distributional cues in grammatical categorization.
                                                                      Cognition, 96, 143-182.
lexical stress and utterance boundary information,
                                                                    Nelson, K. (1973). Structure and strategy in learning to talk.
Christiansen et al., 1998; Hockema, 2006) and syntactic
                                                                      Monographs of the Society for Research in Child
development (e.g., word-distributional information,                   Development, 38, serial no. 149.
Monaghan et al., 2005). This suggests that the phoneme              Nelson, K. (1995). The dual category problem in the
distributional cues that we have explored here may in                 acquisition of action words. . In M. Tomasello & W.E.
further work be incorporated into a more comprehensive                Merriman (Eds.), Beyond names for things: Young
computational account of language development through                 children’s acquisition of verbs (pp. 223-249). Hillsdale,
multiple-cue integration.                                             NJ: Erlbaum.
                                                                    Onnis, L. & Christiansen, M.H. (2005). Happy endings for
                    Acknowledgments                                   absolute beginners: Psychological plausibility in
SAH was supported by a grant from the National Institute              computational models of language acquisition.
for Child Health and Human Development (T32 HD07475).                 Proceedings of the 27th Annual Meeting of the Cognitive
                                                                      Science Society (pp. 1678-1683). Mahwah, NJ: Erlbaum.
                                                                    Redington, M., Chater, N. & Finch, S. (1998). Distributional
                         References                                   information: A powerful cue for acquiring syntactic
Baayen, R.H., Pipenbrock, R. & Gulikers, L. (1995). The               categories. Cognitive Science, 22, 425-469.
   CELEX Lexical Database (CD-ROM). Linguistic Data                 Saffran, J.R., Aslin, R.N. & Newport, E.L. (1996).
   Consortium, University of Pennsylvania, Philadelphia,              Statistical learning by 8-month-old infants. Science, 274,
   PA.                                                                1926-1928.
Brent, M.R. & Cartwright, T.A. (1996). Distributional               Slobin, D.I. (1973). Cognitive prerequisites for the
   regularity and phonotactic constraints are useful for              development of grammar. In C.A. Ferguson & D.I. Slobin
   segmentation. Cognition, 61, 93–125.                               (Eds.), Studies of child language development. New York:
Christiansen, M.H., Allen, J. & Seidenberg, M.S. (1998).              Holt, Reinhart & Winston.
   Learning to segment speech using multiple cues: A                Tomasello, M. (2003). Constructing a language: A usage-
   connectionist model. Language and Cognitive Processes,             based theory of language acquisition. Cambridge, MA:
   13, 221-268.                                                       Harvard University Press.
                                                                177

