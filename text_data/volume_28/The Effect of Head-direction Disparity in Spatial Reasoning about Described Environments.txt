UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
The Effect of Head-direction Disparity in Spatial Reasoning about Described Environments

Permalink
https://escholarship.org/uc/item/5vr6591z

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Avraamides, Marios N.
Kyranidou, Melina-Nicole

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

The Effect of Head-direction Disparity in Spatial Reasoning about Described
Environments
Marios N. Avraamides (mariosav@ucy.ac.cy)
Melina-Nicole Kyranidou (se02km9@ucy.ac.cy)
Department of Psychology, University of Cyprus
P.O Box 20537, Nicosia CYPRUS

raises the possibility that processes specific to the response
mode itself might be responsible for the decrement in
performance associated with imagined headings. An
alternative explanation to the traditional spatial updating
account is that performance is worse from imagined
standpoints because pointing itself is more difficult to
perform from positions that are misaligned to the actual
heading of one’s body. The fact that in everyday life we
typically use pointing from our own standpoint and seldom,
if ever, from imagined standpoints suggests that it is
possible that pointing has become so strongly anchored unto
our bodies that it does not represent an ideal response mode
to be used in spatial cognition tasks.
The strong coupling of pointing with the body is
evidenced in studies that employ disorientation. In one
study, May (1996) had people point to target-objects of a
spatial layout under 3 conditions. In one condition, named
embodied repositioning, participants were allowed to turn
their bodies into the requested facing direction before
pointing to a target. In another condition, termed cognitive
repositioning, participants remained at their initial
standpoint and simply imagined adopting the requested
facing direction. Finally, the disoriented repositioning
condition was similar to cognitive repositioning with the
exception that participants were rotated to the left and right
for 5 seconds after having studied the layout. Results
revealed superior pointing performance for embodied
repositioning. More importantly, however, performance was
worse in the cognitive repositioning than in the disoriented
repositioning condition. Similar results are provided by
Waller, Montello, Richardson, & Hegarty (2002). This
experiment showed that the alignment effect -- that is, the
performance difference between trials in which the
imagined heading is aligned with the body’s actual
orientation and those that it was misaligned --was
diminished in a disorienting condition. The results by May
(1996) and Waller et al. (2002) suggest that performance in
perspective-taking tasks can be improved if the influence of
discrepant bodily cues is diminished through disorientation.
Recently, May (2004) has proposed the sensorimotor
hypothesis to explain why pointing performance suffers
when responding from imagined standpoints. According to
May, in order to point to the location of an object from an
imagined standpoint, a person has to overcome conflicts that

Abstract
The role of head-direction disparity was examined in one
experiment that compared verbal responding with pointing in
a task that entailed locating objects from imagined
perspectives. Participants studied text descriptions of spatial
scenes and then localized from memory objects in them after
adopting imagined perspectives (i.e., face x, find y).
Responses were made by selecting keys on the numerical
keypad marked with verbal labels or arrows pointing to the
four canonical directions. Results showed that performance
was equally accurate and fast for the two response modes.
When responding with arrows, however, accuracy was
substantially lower when the imagined heading was
misaligned with the learned heading.

Introduction
Studies in the field of spatial updating typically require
participants to first study a spatial scene and then localize
target-objects by pointing to them without vision from novel
standpoints adopted by imagination (e.g., Presson &
Montello, 1994; Rieser, Guth, & Hill, 1986). The typical
result is that, compared to pointing to targets from the
learning standpoint, pointing performance from imaginal
standpoints is inferior. This is especially the case when the
learning and imaginal standpoints are misaligned. For
example, Rieser (1989) has shown that latencies for
pointing to targets increased as a function of the angular
disparity of the imaginal standpoint from the initial learning
standpoint.
The inferior pointing performance from imaginal
standpoints in spatial updating studies has been often
attributed to the lack of vestibular and proprioceptive
information during imagined movement; these types of
information are believed to be important factors allowing
people to automatically update their spatial representations
during actual physical movement (Loomis, Klatzky,
Golledge, & Philbeck, 1999; Klatzky, Loomis, Beall,
Chance, & Golledge, 1998; Rieser, 1989). The finding that
performance does not suffer when the novel standpoint is
adopted by physically moving, instead of only imagining
the movement, corroborates the central role of vestibular
and proprioceptive information in spatial updating.
However, the fact that studies in spatial updating have
been predominantly using pointing as the response mode

997

difficult to understand how they should respond (see
Presson & Montello, 1994).
The results from Avraamides & Ioannidou (2005) suggest
that language might be a more flexible response medium for
use from imagined standpoints. Results from other studies
further support this hypothesis (e.g., Avraamides, Klatzky,
Loomis, & Golledge, 2004; DeVega & Rodrigo, 2001;
Wraga 2003).
To sum up, the results from studies using disorientation
have shown that performance on spatial tasks is prone to
interference from sensorimotor cues. Studies using language
have also suggested that language is more resilient to
sensorimotor conflicts. Based on May’s hypothesizing
(2004) there is no reason to expect that pointing and verbal
responding should differ in terms of object direction
disparity
effects.
However,
because
responding
linguistically does not make use of the human body during
the execution phase, no head-direction disparity influences
should be present with verbal responding. Therefore, the
advantage of verbal present in studies comparing verbal and
manual responses either directly (e.g., Avraamides et al.,
2004; Avraamides & Ioannidou, 2005) or indirectly (e.g.,
De Vega & Rodrigo, 2001; Wraga, 2003) could be only
attributed to head-direction disparity.
The goal of the present experiment is to examine whether
the two tasks differ in terms of head-direction disparity in
situations in which no object-direction disparity influences
are present. To eliminate object-direction disparity we use
tasks requiring spatial reasoning in environments that are
not immediate; that is, environments other than the one in
which the participant is present. Using non-immediate
environments allows the elimination of object-direction
disparity effects because no automatic activation of
sensorimotor codes can take place. In order to determine the
role of head-direction disparity we contrast pointing
performance with verbal responding. Any differences that
we might obtain between the two response modes can be
attributed to head-direction disparity.

are caused by the discrepant physical (sensorimotor) and the
imagined egocentric (i.e., relative to the imagined position)
locations of objects. May argues that sensorimotor codes
specifying the objects’ locations relative to the actual
position and orientation of the person are automatically
activated. Therefore, the person needs to suppress this
sensorimotor information in order to select the appropriate
response. Suggestive of these conflicts is May’s finding
that reaction times for pointing toward targets from
imagined standpoints vary as a function of object-direction
disparity (i.e., the angular difference between the
sensorimotor and the imaginal response vectors).
In addition to object-direction disparity, May proposes a
second source of interference. He argues that even when the
appropriate response vector is chosen, in order to be
executed by pointing, it needs to be specified from a
reference frame centered on and oriented with the person’s
body. This type of interference, termed head-direction
Disparity, explains why performance from imagined
standpoints suffers dramatically when adopting the
imagined standpoint entails performing mental rotations
instead of translations only.
In recent work, Avraamides & Ioannidou (2005)
examined the effects of head-direction disparity in a
perspective-taking task. Participants, in their experiment,
viewed displays of a rectangular table portraying 6 people
sitting around it in various arrangements. With the display
perceptually available at all times, they were then instructed
to adopt the perspective of one of the characters, and locate
from that perspective a second character (e.g., “imagine you
are person x, find person y”). Two conditions differing in
terms of the response mode were included in the
experiment. In the verbal response condition, participants
responded with the verbal label describing the relative
position of the target. In the pointing response condition,
they responded by selecting an arrow pointing toward the
desired direction. Results revealed faster and more accurate
performance with verbal responding than pointing with
arrows. Furthermore, the effect of imagined heading was
more severe in pointing. Accuracy for pointing was lower as
the angular deviation of the imagined heading from the
participant’s physical heading increased. Accuracy in the
verbal responding condition was equal for all levels of
imagined heading. In terms of latency, response times
increased with greater misalignment of the imagined
heading but the increase was substantially steeper in the
pointing response mode.
Based on these results, Avraamides and Ioannidou (2005)
argued that the problem of head-direction disparity is
present only with response modes that depend on the body.
Pointing, along with other manual responses, poses rather
complex and unnatural demands on participants in spatial
tasks because it requires from them to first ignore their body
location in order to determine the correct response vector
but then use their body to execute the response. It is not
surprising that participants in experiments often find it

Experiment
The purpose of the present experiment is to contrast
performance for locating targets in a remote environment
using either verbal labels or a response that depends more
strongly on the physical body. The experiment was very
similar to the experiments conducted by de Vega & Rodrigo
(2001). In contrast to de Vega & Rodrigo who focused
primarily on contrasting physical and imaginal rotations in
pointing (Exp.1) and verbal responding (Exp. 2), we are
more interested in directly comparing the two modes of
responding after imaginal rotations.
Participants in the experiment read descriptions of
fictitious environments, adopted imagined headings in them
and located target-objects. Responses were made by
pressing keys marked either with the initial of verbal labels
or arrows. This response procedure was adopted (instead of
real pointing and oral responding) to equate the motor
demands of the two response modes. Previous studies have

998

also implemented pointing and verbal responding in such a
manner (De Vega & Rodrigo, 2001).
If head-direction disparity influences pointing but not
verbal responding, we expect lower accuracy and longer
latencies when responding from imagined headings that are
misaligned with the learned heading. If head-direction
disparity is not present when reasoning about imagined nonimmediate environments performance should be either equal
for the two response modes or superior for pointing. Better
performance for pointing could occur because of some
difficulty that exists when mapping verbal labels (especially
the labels “left” and “right” to the appropriate regions of
space from misaligned headings (see Avraamides, 2003).

responded by describing the relative to their imagined
position location of the landmarks. This block of trials
stopped when the experimenter judged that the participant
was competent in responding from an imagined position.
Then, participants carried out a number of practice trials on
the computer which aimed at familiarizing them with using
the keys to select the appropriate response from the set of
alternatives. For the verbal response mode, arrows were
presented on the screen as probes and participants had to
respond as fast as possible by pressing the key with the
verbal label describing the pointing direction of the arrow.
Similarly, for the pointing mode, participants pressed they
key marked with arrow that pointed the same way with the
probe.
Practice trials were followed by 2 blocks of experimental
trials in the corresponding response mode. In each block a
narrative was presented and participants were given
unlimited time to study it, visualize themselves in it, and
remember the objects around them. After two filler
sentences were presented, 16 localization trials followed.
For each trial, the sentence “Face x, Find y” (where x and y
were objects from the narrative) was presented on the
screen. At this point, participants had to imagine facing
object x and locate object y relative to their imagined
heading. The 16 trials for each block were created by
presenting all possible combinations of the four objects as
referents for the imagined heading and as targets. Trials
were presented randomly for each participant. A total of 64
trials (32 in each response mode) were administered to each
participant.
In the verbal response mode blocks participants indicated
their response by pressing the key marked with the initial of
the appropriate verbal term. For the pointing mode blocks,
responses were indicated by pressing the key marked with
the arrow pointing to the appropriate direction.

Method
Participants Twenty-six (3 males) students from an
introductory Psychology class at the University of Cyprus
participated in the experiment in exchange of course credit
or small monetary compensation.
Materials. Four narratives were used in the present study.
The narratives were translations in Greek of the narratives
used by Avraamides (2003), which were originally adopted
from Franklin and Tversky (1990) and Bryant and Wright
(1999). The narratives were modified to include 4 instead of
6 objects (i.e., no objects were described above the head or
below the feet of the central character). Each participant
performed two blocks of trials in each response mode
(verbal responding and pointing). Therefore, for each
participant 2 narratives were randomly assigned to pointing
and 2 to verbal responding. Furthermore, half of the
participants performed the pointing blocks first while the
other half were given the reverse order. The narratives and
the test trials that followed were presented on a desktop
computer. The task was programmed and presented using EPrime (2000). For both response modes the arrow buttons of
the numeric keypad of the keyboard were used. For the
pointing mode, arrows pointing to the front, back, left, and
right were placed on the keys in the appropriate egocentric
arrangement. For the labeling mode, the keys were marked
with the greek letters Μ, Π, Α, Δ (initials of the greek
equivalents of the terms “front”, “back”, “left”, “right”).

Results
Practice Phase
The data from the practice trials were analyzed to examine
whether differences between the two response modes
existed before the experimental trials. In both response
modes participants responded to the orientation of a
presented arrow-probe using the same 4 keys. The keys
were marked with the initial of verbal labels or arrows
depending on the response mode to be used in the
succeeding experimental trials.
Because the practice phase involved no misaligned
imagined heading we expected that performance would be
either equal or superior for pointing. Pointing from one’s
actual perspective is a well-practiced task and is free of
determining labels for the various regions of space.
Accuracy was very high (95%), therefore, latencies
became the primary focus. A repeated-measures analysis of
variance (ANOVA) with response mode and order as factors

Design The experiment followed a 2 x 2 x 2 x 2 mixedfactorial design with response mode (verbal responding, vs.
pointing), imagined heading (aligned vs. misaligned), and
block (first vs. second) being the within-subject factors. The
order in which the pointing and labeling blocks were
administered was the between-subject factor.
Procedure Prior to the experimental trials for each response
mode, two types of practice trials were administered. First,
participants were asked to imagine being at specific
locations on campus or the nearby area and locate familiar
landmarks. Before the pointing blocks, participants
responded by extending their arm to point to the landmarks
from their imagined position. Before the verbal blocks, they
999

was used1. The only significant result was a main effect for
response mode, F(1,22)=22,04, MSE=389586, p<.001.
Participants were faster in the pointing (1134 ms) than in the
verbal response mode (1980 ms).

pointing task (89.4%) than the verbal task (86.4%) but this
difference was not statistically significant, p=.51.

100

Experimental Phase
Accuracy data and latencies for correct responses were
analyzed using a repeated-measures ANOVA with response
mode, imagined heading, and block as within-subject factors
and order as between-subject factors. Data from two
participants were discarded from all analyses because of
very low accuracy. Furthermore, trials in which latency
exceeded the mean latency in the response mode x block
cell of each participant by 2.5 standard deviations were
omitted from all analyses.
Accuracy
Overall accuracy was 87.4% and did not differ for the two
response modes, p=.32. A significant alignment effect was
observed, F(1,22)=6.75, MSE=.029, p<.05. Accuracy was
higher for the aligned (90.6%) than the misaligned (84.2%)
imagined heading. More importantly, however, a significant
response mode x imagined heading interaction was
obtained, F(1,22)=9.11, MSE=.02, p<.01. As seen in Figure
1 an alignment effect was present for the pointing mode but
not for the verbal response mode, t(23)=3.26, p<.01 and
t(23)=.31, p=.76 respectively.

100

Accuracy (%)

96
92
88

Pointing

84

Verbal

Accuracy (%)

96
92
88

Pointing

84

Verbal

80
76
72
Pointing-First

Verbal-First

Order

Figure 2: Mean Accuracy as a function of Response Mode
and Order.
Latency
Latency was longer for the pointing (4732 ms) than the
verbal (4454 ms) response mode but the difference was not
statistically significant, p=.44. As with the accuracy data,
the analysis of latency revealed an alignment effect, F(1,
22)=7.03, MSE=2287657, p<.05. Participants were faster
responding from aligned than misaligned perspectives.
However, the effect of imagined heading was present in
both response modes, as indicated by the lack of a
significant response mode x imagined heading interaction,
p=.85 (Figure 3). No other main effects or interactions were
significant.

7000

80

6500
Latency (ms)

76
72
Aligned

Misaligned

Imagined Heading

Figure 1: Mean Accuracy as a function of Response Mode
and Imagined heading.

6000
5500

Pointing

5000

Verbal

4500
4000
3500
3000
Aligned

A significant response mode x order interaction was also
obtained, F(1,22)=4.29, MSE=.04, p<.05. As seen in Figure
2, participants who performed the pointing task first were
significantly more accurate with the verbal response mode
(91.3%) than the pointing mode (82.5%). A pair-wise t-test
showed that this difference was statistically significant,
t(11)=2.41, p<.05. In contrast, participants who performed
the verbal task first, were somewhat more accurate in the

Misaligned

Imagined Heading

Figure 3: Mean Latency as a function of Response Mode
and Imagined heading.

1

As with accuracy, a significant response mode x order
interaction was obtained in the latency analysis,
F(1,22)=6.22, p<.05. As shown in Figure 4, when the
pointing task was completed first, pointing was particularly
slow compared to verbal responding. When the verbal task
was first, pointing was faster but the difference between the

Data from two participants eliminated from experimental-trial
analyses were also excluded from the practice-trial analyses.
1000

two response modes was smaller and in fact did not reach
statistical significance, p=.18.
In addition, a significant main effect for practice was
obtained, F(1,22)=13,82, p<.001. Performance was faster in
the second block of each response mode than the first. This
effect did not interact with any other variables. No other
main effects or interactions were present.
Finally, a separate ANOVA analyzed latencies for Spatial
Framework results. Latencies were shorter for objects in the
front (3172 ms), intermediate for objects in the back (5918
ms), and the longest for object on the left (7645 ms) and on
the right (7029 ms) of the imagined heading, F(3,69)=40.41,
MSE=4655321, p<.001. The unexpected difference between
left and right did not reach statistical significance, p=14.
The effect of target direction did not interact with the
response mode. This finding replicates the results of De
Vega & Rodrigo (2001) who found the spatial framework
pattern in both pointing and verbal responding provided that
physical rotations are not allowed.

7000

Latency (ms)

6500
6000
5500

Pointing

5000

Verbal

4500
4000
3500
3000
Pointing-First

Verbal-First

Order

Figure 4: Mean Latency as a function of Response Mode
and Order.

Discussion
The goal of the present experiment was to compare pointing
and verbal responding in a task that entailed adopting
imagined standpoints in remote environments. Reasoning
about remote environments is believed to be free of any
interference related to object-direction disparity.
In contrast to experiments with perceptual scenes
(Avraamides & Ioannidou, 2005), we found no difference in
the overall accuracy and latency between the two response
modes. While, one could hastily conclude that this was the
case because of the absence of any sensorimotor influence
due to the use of non-immediate environments, other
aspects of our results suggest that at least some interference
was present.
First, the accuracy for locating the targets from
misaligned headings was substantially lower for pointing
than verbal responding. For aligned headings, performance
was equally good for the two response modes. Furthermore,

an alignment effect (i.e., better performance for aligned than
misaligned trial) was present for pointing but not for verbal
responding.
This pattern of results is compatible with a sensorimotor
interference account positing interference due to headdirection disparity. Indeed, performance was less accurate
for pointing in the cases in which the response vectors from
the imagined and physical orientation were mismatched.
This suggests that head-direction disparity effects were
greater in the pointing response mode.
However, in contrast to the accuracy results, alignment
effects for both tasks were found in the latency data. This
result replicates findings from previous studies documenting
such effects with verbal responding (Avraamides, 2003) and
pointing (Hintzman, O’Dell, & Arndt, 1981). This could be
interpreted as evidence of head-direction disparity effects in
both tasks. Alternative explanations, however, exist.
A possible explanation comes from studies of spatial
memory. Studies in this field often require participants to
observe a spatial scene and then retrieve from memory
spatial relations such as relative direction (e.g., imagine you
are at x facing y, point to z). Many studies (e.g. Shelton &
McNamara, 1997) using this paradigm report superior
performance for cases in which the imagined heading is
parallel to the learned view. The conclusion often reached
for these alignment effects is that spatial memory is
viewpoint-dependent; that is, people represent scenes in
memory only from the view they experience during initial
learning. Recently, however, McNamara and colleagues
have provided convincing evidence that spatial memory is
organized in terms of intrinsic referent axes, with egocentric
experience being one of many possible cues, albeit the
dominant cue, that can be used to orient a spatial
representation in memory. Recently, Mou, Zhang, and
McNamara (2004) showed that this account also applies for
environments learned from text. Based on spatial memory
accounts then, better performance is expected when
adopting the studied viewpoint (or one parallel to it).
Another explanation is provided by Avraamides (2003).
Although verbal responding is free on any interference, the
mappings of egocentric terms such as front, back, left, and
right to the appropriate regions of space is determined by
the body orientation. As shown by Avraamides (2003; see
also Avraamides & Sofroniou, in press) the use especially of
the terms “left” and “right” is particularly difficult when it is
done from an imagined perspective.
The important result from the latency analysis is not the
presence of an alignment effect but that the size of the
alignment effect was equal for the two tasks. As already
mentioned, this was not the case for accuracy.
A second aspect of our findings suggesting a greater
head-direction disparity effect for pointing is the nature of
the interaction involving the order in which the two
response modes were performed. Those interactions showed
that the pointing response mode was particularly slow and
error-prone when it was performed first. Comparing the two
response modes and taking into consideration only the cases

1001

in which they were presented first, we can clearly see that
pointing was more difficult than verbal responding. In fact,
it seems the case that the absence of an overall effect of
pointing was due to the increased pointing performance that
was evidenced when verbal responding preceded the
pointing task.
One possible explanation for why pointing benefited so
much when it followed verbal responding is that participants
performed the pointing task in a verbally-mediated fashion.
That is, they first determined the verbal label describing the
position of the target and then selected the arrow pointing to
that direction. Our follow-up experiments will reduce the
possibility of using verbally-mediated pointing by adopting
between-subjects designs.
In summary, our accuracy results provide evidence that
head-direction disparity influences are greater for pointing
than verbal responding. The two tasks we have used were
identical except for the type of the required response. The
finding that performance from misaligned headings was less
accurate for pointing than labeling can be only interpreted as
evidence for a difference in the extent of the influence
exerted by head-direction disparity in the two tasks.
In closing, we should point out an important limitation of
our study. In the present study we have reduced pointing
and verbal responding to selecting arrows or verbal labels
on a computer keyboard. Although this is done in other
experiments as well, we should acknowledge that pointing
and verbal responding as used here differ a great deal -- at
least in terms of the motor demands they involve -- from
traditional pointing and verbal responding. Although we
actually believe that the effects of head-direction disparity
will be even greater with actual pointing than arrow
pointing, this remains to be assessed.

E-Prime 1.0 [Computer Software]. (2000). Pittsburgh, PA:
Psychology Software Tools.
Franklin, N., & Tversky, B. (1990). Searching imagined
environments. Journal of Experimental Psychology:
General, 119, 63–76.
Hintzman, D., O'Dell, C. & Arndt, D. (1981). Orientation in
cognitive maps. Cognitive Psychology, 13, 149-206.
Klatzky, R., L, Loomis, J., M, Beall, A., C, Chance, S., S, &
Golledge, R., G. (1998). Spatial updating of self-position
and orientation during real, imagined, and virtual
locomotion. Psychological Science, 9, 293-298.
Loomis, J. M., Klatzky, R. L., Golledge, R. G., & Philbeck,
J. W. (1999). Human navigation by path integration. In
R. G. Golledge (Ed.), Wayfinding: Cognitive mapping
and other spatial processes (pp. 125-151). Baltimore,
MD: Johns Hopkins University Press.
May, M. (1996). Cognitive and embodied modes of spatial
imagery. Psychologische Beiträge, 38, 418-434.
May, M. (2004). Imaginal perspective switches in
remembered environments: Transformation versus
interference accounts. Cognitive Psychology, 48, 163206.
McNamara, T. P. (2003). How are the locations of objects in
the environment represented in memory? In C. Freksa,
W. Brauer, C. Habel, & K. Wender (Eds.), Spatial
cognition III: Routes and navigation, human memory and
learning, spatial representation and spatial reasoning (pp.
174-191). Berlin: Springer-Verlag.
Mou, W, Zhang, K, & McNamara, T. P. (2004). Frames of
reference in spatial memories acquired from language. Journal
of Experimental Psychology: Learning, Memory, and
Cognition, 30, 171-180.

References

Presson, C. C, & Montello, D. R. (1994). Updating after
rotational and translational body movements: Coordinate
structure of perspective space. Perception, 23, 14471455.
Rieser, J. J. (1989). Access to knowledge of spatial structure
at novel points of observation. Journal of Experimental
Psychology: Learning, Memory, & Cognition, 15, 11571165.
Rieser, J. J, Guth, D. A, & Hill, E. W. (1986). Sensitivity to
perspective structure while walking without vision.
Perception, 15, 173-188.
Shelton, A. L., & McNamara, T. P. (1997). Multiple views
of spatial memory. Psychonomic Bulletin & Review, 4,
102-106.
Waller, D., Montello, D. R., Richardson, A. E., & Hegarty,
M. (2002). Orientation specificity and spatial updating of
memories for layouts. Journal of Experimental
Psychology: Learning, Memory, & Cognition, 28, 10511063.
Wraga, M. (2003). Thinking outside the body: An
advantage for spatial updating during imagined versus
physical self-rotation. Journal of Experimental
Psychology: Learning, Memory, & Cognition, 29, 9931005.

Avraamides, M. N. (2003). Spatial updating of
environments described in texts, Cognitive Psychology,
47, 402-431.
Avraamides, M.N., & Ioannidou, L. M. (2005).Locating
Targets from Imagined Perspectives: Labeling vs.
Pointing. Proceedings of the XXVII Annual Meeting of
the Cognitive Science Society, Stresa, Italy, July 2005.
Avraamides, M. N., Klatzky, R. L., Loomis, J. M., &
Golledge, R. G. (2004). Use of cognitive vs. perceptual
heading during imagined locomotion depends on the
response mode. Psychological Science, 15, 403-408.
Avraamides, M. N., & Sofroniou, S. G. (in press). Spatial
Frameworks in imagined navigation. Psychonomic
Bulletin & Review.
Bryant, D. J., & Wright, G. W. (1999). How body
asymmetries determine accessibility in Spatial
Frameworks. The Quarterly Journal of Experimental
Psychology, 52A, 487–508.
De Vega, M., & Rodrigo, M. J. (2001). Updating spatial
layouts mediated by pointing and labelling under
physical and imaginary rotation. European Journal of
Cognitive Psychology, 13, 369-393.

1002

