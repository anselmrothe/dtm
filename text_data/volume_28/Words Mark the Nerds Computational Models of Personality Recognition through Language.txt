UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Words Mark the Nerds: Computational Models of Personality Recognition through Language
Permalink
https://escholarship.org/uc/item/0285b37z
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Mairesse, Franc¸ois
Walker, Marilyn
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              Words Mark the Nerds: Computational Models
                                of Personality Recognition through Language
                                        François Mairesse (F.Mairesse@sheffield.ac.uk)
                                       Department of Computer Science, University of Sheffield
                                       211 Portobello Street, Sheffield S1 4DP, United Kingdom
                                        Marilyn Walker (M.A.Walker@sheffield.ac.uk)
                                       Department of Computer Science, University of Sheffield
                                       211 Portobello Street, Sheffield S1 4DP, United Kingdom
                             Abstract                                  ent parties involved. Personality traits influence many aspects
   User models in human-computer interfaces have focused on            of individual behaviour, such as the attitude toward machines
   various user characteristics, but there is little user modeling     (Sigurdsson, 1991), overall job performance (Furnham, Jack-
   of the most fundamental dimension of variation between hu-          son & Miller, 1999), as well as academic motivation (Komar-
   mans: personality traits. We explore here the possibility of        raju & Karau, 2005); this last finding suggests that training
   automatically acquiring such models by simply observing the
   user’s language. We automatically learn models for personality      systems would be more efficient if they could adapt to the
   recognition from different corpora and sources of personality       learner’s personality.
   evaluation. The models are completely transparent, i.e. they            Our goal is to develop models to recognize the user’s per-
   can run in the background evaluating the user at every con-         sonality, and use them to modify the output generation of a
   versational turn, and provide input for the system to adapt to      dialogue system. This paper presents non-linear statistical
   the user. Results show that recognition models based on ob-
   served personality perform significantly better than a baseline     models of the five most essential personality traits, learned
   of the average personality score, as well as better than mod-       automatically via machine learning on different sources of
   els using self-reports. An analysis of decision trees confirms      data. Results show that extraversion, emotional stability and
   previous findings linking language and personality, while re-       conscientiousness are easier to model, and recognition mod-
   vealing many new linguistic markers.
                                                                       els based on observed personality perform significantly bet-
                                                                       ter than a baseline returning the average personality score,
   Keywords: Personality; Statistical model; Machine learn-            as well as better than models using self-reports. An analysis
   ing; Language; Conversation; EAR; Big Five; Pragmatics;
   Five factor model; Dialogue systems                                 of decision trees confirms previous findings linking language
                                                                       and personality, while revealing many new linguistic markers.
                          Introduction                                             Personality traits and language
Many scientists have focused on how to optimize our inter-
actions with machines, by finding the best way to select and
                                                                       Trait identification
communicate information. However, because users behave in              Personality can be described as a set of attributes characteriz-
different ways, computer systems need to adapt to their con-           ing an individual. The number of those attributes seems to be
versational partner, as humans do (Funder & Sneed, 1993;               extremely large. Indeed, when talking about a close friend,
McLarney-Vesotski et al., in press); this is the purpose of user       one can usually come up with many adjectives describing his
models in dialogue systems (Zukerman & Litman, 2001).                  or her behaviour. To be able to reason about personality, psy-
One approach to user modeling is to elicit user preferences            chologists have tried to identify the most essential traits, re-
by asking the user (Linden, Hanks & Lesh, 1997), but other             ferred to as the Big Five (Norman, 1963):
work develops such models through observation, i.e. by ana-            • Extraversion (sociability, activity, assertiveness)
lyzing the user’s language. Rich (1979) successfully maps              • Emotional stability (as opposed to neuroticism)
user’s keywords to content selection and language genera-              • Agreeableness to other people
tion parameters, while Maloor & Chai (2000) estimate the               • Conscientiousness (discipline)
user’s expertise using dialogue features. Researchers have             • Openness to experience (intellect)
also learned user models from data, e.g. for sentence plan-            Such traits were obtained by doing a factor analysis over
ning (Mairesse & Walker, 2005) and dialogue management                 the adjectives used in personality description questionnaires.
(Litman et al., 2000).                                                 They are therefore based on the assumption that the most rel-
   Rather than modeling specific user preferences, we pro-             evant individual differences are encoded into the language,
pose modeling personality traits. By definition, personal-             and the more important the difference, the more likely it is
ity is the highest level variable characterizing individuals.          to be expressed as a single word. This is referred to as the
Computer users can detect a machine’s personality and pre-             Lexical Hypothesis.
fer working with a computer exhibiting the same personality                While there are known limits to the Big Five model
as theirs (Reeves & Nass, 1996). Personalities of real estate          (Eysenck, 1991; Paunonen & Jackson, 2000), we shall use
agents were used as a basis for the design of an e-commerce            it in our models, as it provides a very general framework for
website (Fuchs, 2001).                                                 reasoning about individual differences, and it has become a
   In addition, many studies have shown that the success of            standard in psychology as it was replicated many times (Nor-
interpersonal tasks depends on the personalities of the differ-        man, 1963; Peabody & Goldberg, 1989).
                                                                   543

Personality markers in language                                         mation about the type of interaction, location, activity, mood,
                                                                        language use (LIWC categories) as well as the participant’s
Many studies have identified cues associated with personal-
                                                                        personality. They found that all Big Five traits were predom-
ity at different linguistic levels, including acoustic parame-
                                                                        inantly expressed in the participants’ language use, although
ters (Smith et al. 1975), lexical categories (Pennebaker &
                                                                        they observed important gender differences. Interestingly, the
King, 1999) and more complex phrases (Gill & Oberlander,
                                                                        correlation between the LIWC variables and personality is
2002). The extraversion/introversion dimension has received
                                                                        usually much larger than with students’ essays. Moreover,
the most attention as it is the most important one for discrim-
                                                                        observers were found to significantly agree with self-reports
inating between people (Peabody & Goldberg, 1989).
                                                                        for all personality dimensions, with the largest effect size for
    A review by Furnham (1990) describes linguistic features
                                                                        extraversion (r = 0.41, p < 0.01).
linked to extraversion, emotional stability and other traits,
and Dewaele & Furnham (1999) review studies focusing on                                   Experimental method
the link between extraversion and both language learning and
speech production. Findings include that there is a higher              While previous work identified correlations between linguis-
correlation between extraversion and oral language, espe-               tic markers and personality ratings, none provide recognition
cially when the study involves a complex task. Extraverts talk          results on unseen data. Here we conduct a set of experiments
more and repetitively, with fewer pauses and hesitations, have          to examine whether automatically trained non-linear models
higher speech rates, shorter silences, higher verbal output and         provide better fits to the data, and whether these models can
a lower type/token ratio, while introverts use a broader vocab-         be used to recognize the personality of unseen subjects. Our
ulary. Extraverts also use more positive emotion words and              approach can be summarized in five steps:
informal style, and show more agreements and compliments               1.  Collect individual corpora;
than introverts. Extravert students learning French as a sec-          2.  Collect associated personality ratings for each participant;
ond language produce more back-channels, and have a more               3.  Extract relevant features from the texts;
implicit style and a lower lexical richness in formal situations.      4.  Build statistical models of the personality ratings based on
It seems that the more complex the task and the higher the                 the features;
level of anxiety, the easier it is to differentiate between intro-     5. Test the learned models on the linguistic outputs of unseen
verts and extraverts.                                                      individuals.
    Heylighen & Dewaele (2002) also noted that extraversion             The following sections describe each of these steps in more
is significantly correlated with contextuality, as opposed to           detail.
formality. Contextuality can be seen a high reliance on shared
knowledge between conversational partners, leading to the               Sources of language and personality
use of many deictic expressions such as pronouns, verbs, ad-            The first corpus contains 2,479 essays from psychology stu-
verbs and interjections, whereas formal language is less am-            dents (1.9 million words), who were told to write whatever
biguous and assumes less common knowledge.                              comes through their mind for 20 minutes. The data was col-
    Scherer (1979) showed that extraverts are perceived as              lected and analyzed by Pennebaker & King (1999); a sam-
talking louder and with a more nasal voice, and that Amer-              ple is shown in Table 1. Personality was assessed by asking
ican extraverts tend to make fewer pauses, while German ex-             each student to fill in the Five Factor Inventory questionnaire
traverts produce more pauses than introverts. Thus personal-            (John, Donahue & Kentle, 1991), which asks participants to
ity markers are culture-dependent, even among western soci-             evaluate how well their personality matches a series of de-
eties.                                                                  scriptions.
    Pennebaker & King (1999) identify many linguistic fea-                 The second source of data consists of conversation extracts
tures associated with each of the Big Five personality traits.          recorded using an Electronically Activated Recorder (EAR),
They use their Linguistic Inquiry and Word Count (LIWC)                 collected by Mehl, Golsing & Pennebaker (in press). To pre-
tool to count word categories of essays written by students             serve the participants’ privacy, only random bits of conver-
whose personality has been assessed using a questionnaire.              sation were recorded. This corpus is much smaller than the
The authors find small but significant correlations between             previous one (96 participants for a total of 97,468 words and
their linguistic dimensions and personality traits. Relevant            15,269 utterances). Moreover, only the participants’ utter-
word categories for extraversion include social words, emo-            ances were transcribed, making it impossible to reconstruct
tion words, first person pronouns, and present tense verbs.            whole conversations. Nevertheless, the conversation extracts
    Gill & Oberlander (2002) used content analysis tools and           are less formal than the essays, and as personality should be
n-gram language models to identify markers in extravert and            best observed in the absence of behavioral constraints, our
introvert emails. They replicated previous findings and iden-          hypothesis is that they have a larger potential for exhibiting
tified new personality markers such as first person singular           personality cues. Table 1 shows examples of conversations
pronouns (e.g. I don’t) and formal greetings (e.g. Hello) for          for two participants judged as introvert and extravert, respec-
introversion, while less formal phrases as Take care and Hi            tively.
characterize extraverts.                                                   For personality ratings, the EAR corpus contains both self-
    Mehl, Golsing & Pennebaker (in press) analyzed personal-           reports and ratings from 18 independent observers. As peo-
ity in its natural habitat, by using an Electronically Activated       ple’s self assessments might differ from what is observed
Recorder (EAR) to collect conversation extracts from the par-          through their behaviour, our second hypothesis is that ob-
ticipants’ daily life over 2 days. They transcribed each partic-       servers’ ratings produce better personality models than self-
ipant’s utterances and annotated them with subjective infor-           reports.
                                                                   544

Table 1: Extracts from the essays and EAR corpus, for participants rated as extremely introvert and extravert. Only the
participants’ utterances are shown.
     Introvert                                                          Extravert
     Stream of consciousness essays corpus:
     I’ve been waking up on time so far. What has it been, 5 days?      I have some really random thoughts. I want the best things
     Dear me, I’ll never keep it up, being such not a morning person    out of life. But I fear that I want too much! What if I fall
     and all. But maybe I’ll adjust, or not. I want internet access     flat on my face and don’t amount to anything. But I feel
     in my room, I don’t’ have it yet, but I will on Wed??? I think.    like I was born to do BIG things on this earth. But who knows...
     But that ain’t soon enough, cause I got calculus homework [...]    There is this Persian party today. My neck hurts.
     EAR corpus:
     - Yeah you would do kilograms. Yeah I see what you’re saying.      - That’s my first yogurt experience here. Really watery. Why?
     - On Tuesday I have class. I don’t know.                           - Damn. New game.
     - I don’t know. A16. Yeah, that is kind of cool.                   - Oh.
     - I don’t know. I just can’t wait to be with you and not have      - That’s so rude. That.
       to do this every night, you know?                                - Yeah, but he, they like each other. He likes her.
     - Yeah. You don’t know. Is there a bed in there? Well ok just...   - They are going to end up breaking up and he’s going to be like.
   Observers were asked to make their judgments by rating
descriptions of the Big Five Inventory (John & Srivastava,                Table 2: Examples of LIWC word categories and MRC psy-
1999) on a 7 point scale (from strongly disagree to strongly              cholinguistic features (Pennebaker & Francis, 2001; Colt-
agree), without knowing the participants. Observers were di-              heart, 1981). 1 indicates an MRC feature, which associates
vided into three groups, each rating one third of the partic-             each word to a numerical value.
ipants, after listening to each participant’s entire sound file.             Feature                     Example
Mehl et al. (in press) report strong inter-observer reliabilities            Anger words                 hate, kill, pissed
across all Big Five dimensions (intraclass correlations based                Metaphysical issues         God, heaven, coffin
on one-way random effect models: mean r = .84, p < .01).                     Physical state/function     ache, breast, sleep
For each participant’s transcribed text, the observers’ ratings              Inclusive words             with, and, include
                                                                             Social processes            talk, us, friend
were averaged, to produce the final scores used in our exper-                Family members              mom, brother, cousin
iments.                                                                      Past tense verbs            walked, were, had
                                                                             References to friends       pal, buddy, coworker
Feature selection                                                            Imagery of words1           Low: future, peace - High: table, car
We extracted a set of linguistic features from each essay and                Syllables per word1         Low: a - High: uncompromisingly
conversation transcript, starting with 88 word categories from               Concreteness1               Low: patience, candor - High: ship
the LIWC utility (Pennebaker & Francis, 2001). These fea-                    Frequency of use1           Low: duly, nudity - High: he, the
tures include both syntactic (e.g. ratio of pronouns) and se-
mantic information (e.g. positive emotion words). We also
added 14 additional features from the MRC Psycholinguistic                assertions. Table 3 summarizes the partition and the evalu-
database (Coltheart, 1981), which contains statistics for over            ation results for each speech act type. The feature value is
150,000 words, such as estimates of the age of acquisition,               the ratio of the number of speech acts to the total number of
frequency of use, and familiarity. To find the correct word               utterances in each text.
in the database among a set of homonyms, we pick the en-
try with the same stem and Part-of-Speech tag as the target
word. We computed the MRC feature values as the average                   Table 3: Partition of the speech acts automatically extracted
value over all the words that match an entry in the database.             from the EAR corpus, and classification accuracies on a sam-
Table 2 shows examples of LIWC word categories and MRC                    ple of 100 hand-labeled utterances.
scales.                                                                               Label          Fraction      Labeling accuracy
   We also introduced features characterizing the types of                            Assertion        73.0%               0.95
speech act produced. We automatically tagged each utterance                           Command          4.3%                0.50
of the EAR corpus with speech act categories from Walker &                            Prompt           7.0%                0.57
Whittaker (1990), using heuristic rules based on each utter-                          Question         15.7%               1.00
ance’s parse tree:                                                                    All              100%                0.88
• Command: utterance using the imperative form, a command verb
   (e.g. must, have to) or a yes/no second person question with a             As personality influences speech production (Dewaele &
   modal auxiliary like can;                                              Furnham, 2000; Scherer, 1979), we added prosodic features
• Prompt: single word utterance used for back-channeling (e.g.            based on the audio data of the EAR conversation extracts.
   Yeah, OK, Huh, etc.);
• Question: interrogative utterance which isn’t a command;
                                                                          As the EAR recorded the participants at anytime of the day,
• Assertion: any other utterance                                          it was necessary to remove any non-voiced signal. We used
                                                                          Praat (Boersma, 2001) to compute features characterizing the
   We evaluated the automatic tagger by applying it to a set              voice’s pitch and intensity (mean, extremas and standard de-
of 100 hand-labeled utterances randomly selected in the EAR               viation), and we added an estimate of the speech rate by di-
corpus. We obtain 88% of correct labels, which are mostly                 viding the number of words by the voiced time.
                                                                      545

   We included all the features mentioned in this section (117)                     Paired t-tests show that all regression models based on the
in the models based on the EAR corpus. Models computed                           essays corpus significantly improve over the baseline (two-
using the essays corpus contain only LIWC and MRC fea-                           tailed, p < 0.05), but the improvements are smaller than for
tures (102), as speech acts are only meaningful in dialogues.                    spoken language, confirming the results from Mehl et al. (in
                                                                                 press). Interestingly, modeling openness to experience pro-
Statistical model                                                                duces the best results (6.2% error decrease).
Depending on the adaptation capabilities of the target dia-                         Concerning the EAR corpus, we observe that linear regres-
logue system, we will need two different types of personality                    sion performs poorly for all traits, suggesting a highly non-
models. First, for the case where the output generation of the                   linear relationship between language and personality recog-
dialogue system can be varied continuously along particular                      nition. Regression tree models produce the best improvement
dimensions, we develop regression models of personality di-                      over the baseline: a paired t-test (two-tailed, p < 0.05) over
mensions as continuous variables. Second, for the case where                     the cross-validation folds shows that the error reduction is
the output generation is limited to a few points at extremes of                  significant for extraversion (76.8% relative error, i.e. 23.2%
a personality scale, such as introvert vs. extravert language,                   improvement), emotional stability (3.92% improvement), and
or neurotic vs. emotionally stable, we develop classification                    conscientiousness (14.75% improvement). Regression trees
models by splitting our subjects into two equal-size groups.                     for extraversion and conscientiousness are in Figures 1 and 2.
   We use the Weka toolbox (Witten & Frank, 2005) for train-                     On the other hand, self-reports of the EAR corpus are clearly
ing and evaluating the different statistical models. For each                    difficult to model: none of the models show significant im-
trait, we compare a baseline model returning the mean per-                       provement over the baseline.
sonality score with a linear regression model, an M5’ regres-
sion tree returning a linear model, regular M5’ and REP-                                                                 Word count
Tree decision trees, and a model based on Support Vector                                                       ≤ 675                        > 675
Machines (SMO). In order to evaluate models of personality
classification, we compare six different learning algorithms
against a baseline returning the majority class.                                                       M ean pitch                          Word count
                                                                                                  ≤ 231              > 231          ≤ 1299           > 1299
                                     Results
For each Big Five trait, we trained regression models using                              Intensity variation             3.23          3.83            4.24
the self-reports of the essays data, and we computed two ad-
ditional models based on the self-reports and observer ratings                          ≤ 6.39                > 6.39
of the EAR corpus. Regression results are summarized in Ta-
ble 4. The baseline is a model returning the mean of all per-                            2.86                 3.02
sonality scores in the training set. We use the relative error
for evaluation, which is the ratio between the model’s predic-                   Figure 1: M5’ regression tree for extraversion, computed us-
tion error and the error produced by the baseline. All results                   ing the EAR corpus. The target output ranges from 1 to 7,
are averaged over a 10 fold cross-validation.                                    where 7 means strongly extravert. The mean pitch value is
                                                                                 expressed in Hertz, and the intensity variation (standard devi-
                                                                                 ation) in decibels.
Table 4: Relative error for regression models, with observer
ratings (Obs) and self-reports (Self) of the EAR corpus, and
self-reports of the essays corpus (Essays). Models are lin-
ear regression (LR); M5’ regression tree with linear models
                                                                                 Table 5: Classification accuracy with two equal-frequency
(M5R); M5’ decision tree with regular leaves (M5D); REP-
                                                                                 bins on the EAR corpus, for observer ratings (Obs) and self-
Tree decision tree (REPT)2 .
                                                                                 reports (Self). Models are J48 decision tree (J48); Nearest
       Dataset       Trait          LR        M5R          M5D       REPT        neighbour (NN); Naive Bayes (NB); JRip rules set (JRIP);
       EAR-Obs       Extra      186.88        76.80•       83.49•     89.55•
       EAR-Obs       Emot       331.30        96.20        96.08•    102.84      AdaboostM1 (ADA); SMO support vector machine (SMO).
       EAR-Obs       Agree      264.99       105.16       100.06     109.48
       EAR-Obs       Consc      207.37        92.07•       85.25•     97.41        Data   Trait       J48         NN          NB           JRIP     ADA     SMO
       EAR-Obs       Open       318.69       117.44       106.66     104.48        Obs    Extra       67.26•      57.51       73.20•       64.86•   73.23•  65.48•
       EAR-Self      Extra      214.73       109.96       104.35     101.40        Obs    Emot        58.37       57.61       70.71•       59.00    58.47   62.79•
       EAR-Self      Emot       357.86       116.76       105.05     104.27        Obs    Agree       51.66       51.82       55.08        52.93    51.51   50.67
       EAR-Self      Agree      330.13       110.62       103.94     105.80        Obs    Consc       57.03       59.59•      65.68•       58.91•   60.13•  59.63•
       EAR-Self      Consc      181.63       118.14       103.95     103.75        Obs    Open        45.86       47.14       56.53        50.66    53.94   55.12
       EAR-Self      Open       372.30       121.47       103.21     106.68        Self   Extra       46.87       47.34       57.48•       53.78    50.94   51.74
       Essays        Extra        99.31•      99.42•                               Self   Emot        47.72       47.90       50.28        50.46    48.51   45.82
       Essays        Emot         97.25•      97.14•                               Self   Agree       48.21       50.33       59.92        56.20    56.99   54.68
       Essays        Agree        99.07•      99.03•                               Self   Consc       46.39       44.72       42.16        46.68    47.08   53.47
       Essays        Consc        98.78•      98.72•                               Self   Open        52.84       44.07       64.54•       50.96    57.82   55.50
       Essays        Open         93.81•      93.83•                                        • statistically significant improvement over the majority class
            • statistically significant improvement over the mean value                               baseline (two-tailed paired t-test, p < 0.05)
                    baseline (two-tailed paired t-test, p < 0.05)
                                                                                 M5’ tree models were computed with the essays corpus, due to the
                                                                                 large dataset size. The personality traits are extraversion (Extra),
    2
      SVM regression models aren’t included as they don’t perform                emotional stability (Emot), agreeableness (Agree), conscientious-
significantly better than the baseline. Only linear regression and               ness (Consc), and openness to experience (Open).
                                                                             546

                       S w ear w ords                                                           using the algorithm producing the best overall results (Naive
              ≤ 0.93                       > 0.93                                               Bayes) with each feature set. Table 6 shows that LIWC fea-
                                                                                                tures perform well for extraversion and emotional stability,
        P ronouns                         S exuality w ords                                     while MRC features are good indicators of extraversion and
                                                                                                conscientiousness. Prosodic features are useful for model-
≤ 16.7               > 16.7          ≤ 0.62                   > 0.62                            ing extraversion and especially openness to experience, and
                                                                                                speech acts are the best features for modeling agreeableness.
   4.01               3.63       C om m . w ords            S yllables per w ord
                            ≤ 1.46          > 1.46       ≤ 1.14             > 1.14
                                                                                                Table 6: Classification accuracies over a 10 fold cross-
                                                                                                validation using the Naive Bayes classifier, for different fea-
                              3.15          3.26           2.90       B ody states w ords
                                                                                                ture sets (the Acts column represents speech acts features).
                                                                ≤ 0.59             > 0.59          Feature set               Acts LIWC           MRC      Prosody
                                                                                                   Set size                     4       88         14          11
                                                                    2.96            2.98           Extraversion             49.11    70.97• 67.96•          69.62•
                                                                                                   Emotional stability 59.00         68.82• 61.04           61.88
Figure 2: M5’ regression tree for conscientiousness, com-                                          Agreeableness            57.14    53.26      56.60       48.82
                                                                                                   Conscientiousness        56.92    60.18• 65.76•          50.48
puted using the EAR corpus. The target output ranges from 1                                        Openness                 54.02    57.96      53.96       62.20•
to 7, where 7 means strongly conscientious (Comm. words is                                         • statistically significant improvement over the majority class
the ratio of words related to communication).                                                                baseline (two-tailed paired t-test, p < 0.05)
                                                                                                   Decision tree models can be easily understood, and can
                                                                                                therefore help to uncover new linguistic markers of person-
    Classification accuracies are in Table 5. The Naive Bayes                                   ality. Our models replicate previous findings, such as the link
algorithm produces the best result, significantly outperform-                                   between verbosity and extraversion (c.f. Word count node of
ing the baseline for extraversion (73.2% correct classifica-                                    Figure 3), but they also provide many new markers. Figure 1
tions), emotional stability (70.7%), and conscientiousness                                      shows that the voice’s pitch and variation of intensity play an
(65.7%). Extraversion is the easiest personality dimension                                      important role when modeling extraversion. Figure 2 shows
to model through spoken language, as accuracies for all clas-                                   that conscientious people use fewer swear words and content
sifiers except nearest neighbour are higher for this trait. The                                 related to sexuality, while preferring longer words. Given
J48 decision tree for extraversion is shown in Figure 3.                                        particular ranges for features characterizing word count and
                                                                                                the use of specific LIWC categories, the decision tree in Fig-
                                                  Word count
                                                                                                ure 3 classifies people using high-frequency words as intro-
                                        ≤ 1284                > 1284                            verts, contradicting previous hypotheses (Dewaele & Furn-
                                                                                                ham, 1999; Furnham, 1990). Our models contain many ad-
                                M etaphysical issues          E xtravert
                                                                                                ditional personality cues which were not identified through a
                                                                                                typical correlational analysis.
                            ≤ 0.25                 > 0.25
                                                                                                                             Conclusion
                      C om m as                       A rticles
                                                                                                We showed that personality can be recognized by computers
              ≤ 8.72             > 8.72       ≤ 3.51           > 3.51                           through language cues. To our knowledge, this is the first re-
                                                                                                port of experiments testing automatically trained models on
             E ating          E xtravert     E xtravert         S pace                          unseen subjects. The source of data is an essential factor: ob-
                                                                                                served personality is easier to model than self-reports. This
   ≤ 0.51             > 0.51                         ≤ 3.22               > 3.22
                                                                                                may be due to objective observers using similar cues as our
                       S ad                                           F requency of use
                                                                                                models, while the perception of one’s own personality is in-
  Introvert                                         E xtravert
                                                                                                fluenced by many other factors, such as the desirability of
             ≤ 0.15             > 0.15                          ≤ 6072                          the trait. Moreover, spoken language is easier to model than
                                                                                    > 6072
                                                                                                written texts, probably because the speed of oral production
            Introvert          E xtravert                       E xtravert        Introvert     prevents the cognitive system from doing the same amount of
                                                                                                control as in a writing task. In future work, we would like
Figure 3: J48 decision tree for binary classification of ex-                                    to improve these models and examine how well they perform
traversion, based on the EAR corpus.                                                            across dialogue domains. We need to test the models in our
                                                                                                intended application (dialogue system adaptation) to assess
                                                                                                whether the accuracies we achieve are high enough. Appli-
    Our models contain features characterizing many aspects                                     cations involving speech recognition will introduce noise in
of language production: speech acts, content and syntax                                         all features except for the prosodic features, probably reduc-
(LIWC), psycholinguistic statistics (MRC), and prosody. In                                      ing model accuracy, but since the EAR corpus is relatively
order to evaluate how each feature set contributes to the fi-                                   small, we expect that more training data would improve per-
nal result, we trained binary classifiers on the EAR corpus                                     formance.
                                                                                            547

                    Acknowledgements                                Litman, D., Kearns, M., Singh, S., & Walker, M. (2000). Au-
We would like to thank James Pennebaker and Matthias Mehl             tomatic optimization of dialogue management. In Pro-
for giving us access to their data and for their efficient and        ceedings of the 18th International Conference on Compu-
friendly collaboration.                                               tational Linguistics (COLING-2000), pp. 502–508.
                                                                    Mairesse, F. & Walker, M. (2005). Learning to personalize
                         References                                   spoken generation for dialogue systems. In Proceedings of
Boersma, P. (2001). Praat, a system for doing phonetics by            Interspeech’2005 - Eurospeech: 9th European Conference
   computer. Glot International, 5(9/10):341–345.                     on Speech Communication and Technology, pp. 1881–
Coltheart, M. (1981). The MRC psycholinguistic database.              1884.
   Quarterly Journal of Experimental Psychology, 33A:497–           Maloor, P., & Chai, J. (2000). Dynamic user level and utility
   505.                                                               measurement for adaptive dialog in a help-desk system. In
Dewaele, J.-M., & Furnham, A. (1999). Extraversion: the               Proceedings of the 1st SIGdial Workshop on Discourse and
   unloved variable in applied linguistic research. Language          Dialogue, pp. 94–101.
   Learning, 49(3):509–544.                                         McLarney-Vesotski, A. R., Bernieri, F., & Rempala, D. (in
                                                                      press). Personality perception: a developmental study.
Dewaele, J.-M., & Furnham, A. (2000). Personality and
                                                                      Journal of Research in Personality.
   speech production: a pilot study of second language learn-
                                                                    Mehl, M. R., Gosling, S. D., & Pennebaker, J. W. (in press).
   ers. Personality and Individual Differences, 28:355–365.
                                                                      Personality in its natural habitat: manifestations and im-
Eysenck, H. J. (1991). Dimensions of personality: 16, 5 or            plicit folk theories of personality in daily life. Journal of
   3? Criteria for a taxonomic paradigm. Personality and              Personality and Social Psychology.
   Individual Differences, 12(8):773–790.                           Norman, W. T. (1963). Toward an adequate taxonomy of per-
Fuchs, R. (2001). Personality traits and their impact on              sonality attributes: replicated factor structure in peer nom-
   graphical user interface design: lessons learned from the          ination personality rating. Journal of Abnormal and Social
   design of a real estate website. In Proceedings of the 2nd         Psychology, 66:574–583.
   Workshop on Attitude, Personality and Emotions in User-          Paunonen, S. V., & Jackson, D. N. (2000). What is beyond
   Adapted Interaction.                                               the Big Five? Plenty! Journal of Personality, 68(5):821–
Funder, D. C., & Sneed, C. D. (1993). Behavioral manifesta-           836.
   tions of personality: an ecological approach to judgmental       Peabody, D., & Goldberg, L. R. (1989). Some determinants
   accuracy. Journal of Personality and Social Psychology,            of factor structures from personality-trait descriptor. Jour-
   64(3):479–490.                                                     nal of Personality and Social Psychology, 57(3):552–567.
Furnham, A. (1990). Language and Personality. In H. Giles           Pennebaker, J. W., Francis, M. E., & Booth, R. J. (2001).
   & W. P. Robinson (Eds.), Handbook of Language and So-              LIWC: Linguistic Inquiry and Word Count.
   cial Psychology. Chichester: John Wiley & Sons.                  Pennebaker, J. W., & King, L. A. (1999). Linguistic styles:
Furnham, A., Jackson, C. J., & Miller, T. (1999). Personal-           language use as an individual difference. Journal of Per-
   ity, learning style and work performance. Personality and          sonality and Social Psychology, 77:1296–1312.
   Individual Differences, 27:1113–1122.                            Reeves, B., & Nass, C. (1996). The Media Equation. Uni-
Gill, A. J., & Oberlander, J. (2002). Taking care of the lin-         versity of Chicago Press.
   guistic features of extraversion. In Proceedings of the 24th     Rich, E. (1979). User modelling via stereotypes. Cognitive
   Annual Conference of the Cognitive Science Society, pp.            Science, 3:329–354.
   363–368.                                                         Scherer, K. R. (1979). Personality markers in speech. In
Heylighen, F., & Dewaele, J.-M. (2002). Variation in the              K. R. Scherer & H. Giles (Eds.), Social markers in speech.
   contextuality of language: an empirical measure. Con-              Cambridge University Press.
   text in Context, Special issue of Foundations of Science,        Sigurdsson, J. F. (1991). Computer experience, attitudes to-
   7(3):293–340.                                                      ward computers and personality characteristics in psychol-
                                                                      ogy undergraduates. Personality and Individual Differ-
John, O. P., Donahue, E. M., & Kentle, R. L. (1991). The
                                                                      ences, 12(6):617–624.
   ”Big Five” inventory: versions 4a and 5b. Technical report,
   Berkeley: University of California, Institute of Personality     Smith, B. L., Brown, B. L., Strong, W. J., & Rencher, A. C.
   and Social Research.                                               (1975). Effects of speech rate on personality perception.
                                                                      Language and Speech, 18:145–152.
John, O. P., & Srivastava, S. (1999). The Big-Five trait taxon-     Walker, M., & Whittaker, S. (1990). Mixed initiative in di-
   omy: history, measurement, and theoretical perspectives.           alogue: an investigation into discourse segmentation. In
   In L. A. Pervin & O. P. John (Eds.), Handbook of person-           Proceedings of the 28th Annual Meeting of the Association
   ality theory and research. New York: Guilford Press.               for Computational Linguistics, pp. 70–78.
Komarraju, M., & Karau, S. J. (2005). The relationship be-          Witten, I. H., & Frank, E. (2005). Data Mining: Practical
   tween the Big Five personality traits and academic motiva-         machine learning tools and techniques. Morgan Kauf-
   tion. Personality and Individual Differences, 39:557–567.          mann.
Linden, G., Hanks, S., & Lesh, N. (1997). Interactive as-           Zukerman, I., & Litman, D. (2001). Natural language pro-
   sessment of user preference models: the automated travel           cessing and user modeling: synergies and limitations. User
   assistant. In Proceedings of the 6th International Confer-         Modeling and User-Adapted Interaction, 11(1-2):129–
   ence on User Modeling, pp. 67–78.                                  158.
                                                                548

