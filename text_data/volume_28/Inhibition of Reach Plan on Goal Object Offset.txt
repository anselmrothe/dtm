UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Inhibition of Reach Plan on Goal Object Offset

Permalink
https://escholarship.org/uc/item/7d39x33w

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Ellis, Rob
Vainio, Lari
Tucker, Mike

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Inhibition of Reach Plan on Goal Object Offset
Lari Vainio (lari.vainio@plymouth.ac.uk)
School of Psychology, University Of Plymouth, Plymouth, PL4 8AA, UK

Rob Ellis (rellis@plymouth.ac.uk)
School of Psychology, University Of Plymouth, Plymouth, PL4 8AA, UK

Mike Tucker (M.R.Tucker-1@plymouth.ac.uk)
School of Psychology, University Of Plymouth, Plymouth, PL4 8AA, UK

or left hand button-press response to indicate whether the
graspable (everyday household) object was upright or
inverted. The objects were displayed in the orientations that
were compatible with a right-hand grasp or with a left-hand
grasp. The object orientation was observed to facilitate
responses of the hand most suited to perform a reach-andgrasp action on the object. This robust effect which has been
replicated in several laboratories (e.g. Grezes and Decety,
2002; Phillips and Ward, 2002), demonstrates that when
viewing an object the action that it evokes appears to be
activated independently of a persons’ intention to act. For
convenience, we shall call this observation “the objectorientation effect”. The object-orientation effect can be
triggered by an orientation of viewed (novel) cylinders and
an orientation of familiar mugs (Vainio, Ellis and Tucker, in
press).
The object affordance effect can be observed with
semantic information (i.e. names of objects) and purely
visual information (i.e. size of novel objects) of an object
(Tucker and Ellis, 2004; Vainio, Ellis, Tucker and Symes, in
press). Intuitively it may be assumed that object orientation
can also be derived from different object properties for
generating the object-orientation effect. The angle of an
object’s primary axis of elongation (visual affordance) or a
handle of an object (visual-semantic affordance) can both
offer orientation information.
In the case of visual-semantic affordance, an object needs
to be processed at the semantic level in order to extract
affordance information. How we grasp a familiar object and
how we use it effectively are profoundly related to each
other. Objects that have functional handle are usually
picked up by their handles. However, the object is rarely
picked up by the handle if individual is interfered with
semantic task while he is picking up the object (Creem and
Proffitt, 2001). In addition, research has shown that familiar
objects with handles, but not familiar objects without
handles or unfamiliar objects with handles, activate multiple
motor schemata based on semantic, pragmatic and
associative components (Sugio, Ogawa & Inui, 2003).
Functional properties of an object that are associated with its
handle are taken into account during transformation to
motor program (Petit, Pegna, Harris & Michel, 2006).
Therefore, we have evidence to claim that the objectorientation effect that is elicited by the location of a handle
of a mug involves at least some minimal semantic

Abstract
Previous research has shown that object’s orientation
facilitates responses of the hand that is compatible with the
orientation. We explored how this object-orientation effect
couples with reach planning and control. Experiment 1 used
left-right orientated cylinders as stimuli. The orientation of
these cylinders was observed to lead to more accurate
responses of the orientation compatible hand. When the object
disappeared on reach initiation, the reaching of the orientation
compatible hand was inhibited. Experiment 2 replicated
Experiment 1 with left-right orientated mugs. These objects
evoked the typical object-orientation effect in reaction times
and accuracy but reach control was not affected. This study
suggests that a sudden interruption in the transmission of
visual inputs for updating the motor program leads to
inhibition of the program. However, this motor control effect
depends on whether the motor plan is extracted from visual or
visual-semantic object affordance.
Keywords: motor control, motor planning, inhibition, visual
representation

Introduction
The visuomotor system has to extract information from the
visual array that is relevant for guiding current actions such
as reaching to grasp a branch. Similarly, it is important that
an organism respond rapidly to sudden changes in its
environment. For instance, the motor program for the reachto-grasp has to be quickly inhibited if the branch moves
away from its current position during the reach.
Behavioural studies have shown that a viewed graspable
object automatically activates a motor program associated
with an object’s affordance (i.e. action-relevant attributes of
objects) even when this information is irrelevant to the
current task demands (e.g. Craighero, Fadiga, Rizzolatti, &
Umiltá, 1999; Tucker and Ellis, 2001). In affordance effects,
the action relevant object attribute is automatically extracted
from the visual array to facilitate the motor program, which
would be required for the accurate reach-to-grasp action to
the object. This interplay between object affordances and
motor programming has been extensively examined and
evaluated (e.g. Grezes, Tucker, Armony, Ellis, &
Passingham, 2003; Fagg & Arbib, 1998).
Of most interest is the study presented by Tucker and
Ellis (1998). In their study, participants had to make a right
846

In the present study, we had two main objectives. In
Experiment 1, we investigated whether the sudden
interruption in the transmission of response-related visual
information triggers an inhibitory interrupt signal for
updating the reach plan. We predicted that the processing of
visual affordance information for online updating of the
reach plan would lead to inhibition of this motor plan if the
object were removed from view during reaching. In
Experiment 2, we explored whether the inhibition of a reach
plan on goal object offset depends on the source of
orientation affordance, that is, whether visual-semantic
orientation affordances have an effect on reach control in
the same way as purely visual affordances.

processing. In fact, the handle does not offer the most
convenient surface for grasping a mug when it has to be
simply grasped without having to take into account its
conventional function. It requires relatively precise and
highly learned motor programming effort to grasp a mug by
a handle.
In contrast, in the case of visual affordance, semantic
attributes of an object do not need to be processed to extract
the orientation affordance. Rather the angle of an object’s
axis of elongation affords a left- or right hand response by
virtue of the proximity of one end of the object to a
particular hand of the viewer (i.e. one end of the oriented
object is nearer to a particular hand of response). Motor
planning processes may rely dominantly on this sort of
visual affordance when affordance information has to be
extracted very rapidly from the object, when semantic
processing is interfered during the task, or when the object
does not offer any action relevant semantic information
(e.g., the target object is unfamiliar cylinder without any
handle component).
It has been suggested that motor planning (i.e., motor
processes that occur prior to action onset) and motor control
(i.e., motor processes that occur after action onset) utilize
distinct visual representations (Glover, 2004). According to
this planning-control model, the planning system has to take
into account a wide variety of visual and cognitive
information such as object semantics. In contrast, the
control system uses a limited but quickly updated visual
representation. It may be assumed that the control system is
capable of using purely visual affordances for online
guiding of actions.
The evidence presented above predicts that visual
orientation affordance would have a greater influence on
control rather than planning whereas semantic-visual
orientation affordance would have a greater influence on
planning rather than control. Previously the control
mechanisms of manual reaching have been explored, for
example, using a selective reaching paradigm (Tipper,
Lortie and Baylis, 1992). Pavese and Buxbaum (2002)
showed that the object affordances of distractor objects can
inhibit selective reaching. In their study, participants had to
grasp, or point to the target object (mug) that was presented
with a distractor object (a mug with or without a handle).
Distractors with handles caused greater interference than
those without handles, irrespective of whether the intended
action was pointing or grasping.
Moreover, Eimer and Schlaghecken (1998) showed that
motor inhibition effects are not only linked to situations of
imperfect attentional selectivity, but are also observed when
the activated motor program conflicts with sudden changes
in the environment. In this study, a masked prime arrow was
followed by a target arrow requiring a left-hand or righthand response. Responses were slower when the prime and
target arrows were compatible than when they were
incompatible. Eimer (1999) suggested that the sudden
interruption in the transmission of response-related visual
information triggers an inhibitory interrupt signal.

Experiment 1
Previous research has shown that an object orientation
facilitates motor planning (i.e. motor processes that occur
prior the movement onset) of the orientation compatible
hand. Experiment 1 investigates whether the orientation of a
target object influences the reach control (i.e. motor
processes that occur after the movement onset) of the
orientation compatible hand. The target object either
remained in the screen or was removed in the onset of the
reach towards the object. We hypothesized that reaching of
the orientation compatible hand would be inhibited when
the object is removed in the onset of the reach.

Method
Participants Twenty-two participants took part in the
experiment. All participants reported having normal or
corrected-to-normal vision and were naive as to the purpose
of the experiment. In addition, all participants signed the
participation form with their right-hand.
Materials Participants sat in a darkened room in the
reaching distance from a 14-inch touch screen monitor. The
standard keyboard was located between participant and the
monitor (the centre of the keyboard was approximately 30
cm away from the screen).
All stimuli were displayed on a white background. The
prime object stimuli that were displayed until the initiation
of the response consisted of two thick (length: 21.5 cm;
thickness measured from the object centre: 3.3 cm) and two
thin (computer generated) cylinder-shaped objects. Two
thick objects (length: 21.5 cm; thickness measured from the
object centre: 4.3) had a slightly different variation of a
natural brown wood colour and texture, they were orientated
to the right or left. The two thin objects had identical wood
colours and textures to the two thick ones. They were also
orientated to the right or left. A circle (positioned around the
centre of the object) was displayed with the object to
determine the area of the screen for touching. The stimuli
are displayed in Figure 1.
The stimuli that was displayed between onset of the
response (lifting the finger from the key) and touching the

847

orientation (left or right) and hand of response (left or right).
This analysis did not reveal any significant effects. The
absence of the the interaction between object orientation and
hand of response [F(1,21)=.001, p=.977, MSE=.23] can be
viewed in Table 1.
Errors Two participants did not make any errors. The
analysis revealed a statistically significant interaction
between orientation and hand of response, F(1,19)=8.83,
p=.008, MSE=38.18. This interaction, displayed in Table 1,
shows that the object-orientation effect can be observed in
the error data.
Movement times This analysis had one additional factor
(condition of prime presentation; 1=the prime remained in
the display; 2=the prime was removed from the display)
included to the design. The analysis revealed a significant
interaction between orientation and hand of response,
F(1,21)=15.57, p=.001, MSE=703.43. However, this
interaction differed in the two conditions of prime
presentation because the analysis also revealed a statistically
significant three-way interaction between orientation,
condition and hand of response, F(1,21)=6.71, p=.017,
MSE=277.73. The simple interaction effects analysis that
was carried out separately for the two conditions revealed a
significant interaction between object orientation and hand
of response in the condition 2 [F(1,21)=15.89, p<.001,
MSE=932.57] but not in condition 1, F(1,21)=1.74, p=.201,
MSE=48.58. The Figure 2 shows that the inhibition of the
object-orientation effect can be observed when the prime
object is removed from view in response initiation.

screen consisted of the same four prime objects with the
circle around the object’s centre (half of the trials), or the
same circle displayed without the object (half of the trials).

Figure 1. The upper object is an example of the thick
cylinder used in Experiment 1, and the lower object is an
example of the thin cylinder.
Procedure Each trial was initiated by displaying text ‘GET
READY’ in the centre of the screen. Participants were
instructed to press two keys down, one located on the right
and one on the left on the keyboard, when they saw this text.
When both keys were pressed, the text disappeared. A blank
screen was displayed for 2000 ms before the target object
appeared on the screen. Participants were instructed to
respond with their right-hand if the target cylinder was thin
and with their left-hand if it was thick. Half of the
participants were randomly assigned to the opposite handto-thickness arrangement. Participants were instructed to
touch the area inside the central circle after selecting the
hand of response. In half of the trials, the prime cylinder
disappeared from the display when the response key was
lifted. The new trial started after participant had touched
successfully the central circle. Error responses were
immediately followed by a short “beep”-tone from the
computer. Participants were timed out if they did not
respond within 3000 ms.

395

390

Left-hand

385

Right-hand

380

375
Left

Right

395

390
Left-hand

385

Right-hand

380

Results

375

Reaction times The experiment consisted of 320 trials.
5.6% of the raw data was discarded from the RT analysis,
including 2.5% of trials that were errors and 3.1% of trials
in which RTs were more than two standard deviations from
a participant’s overall mean. Condition means for the
remaining data were subjected to a repeated measures
ANOVA (every analyses in this article employed this
method) with the within participants factors of prime object

Left

Right

Figure 2. Mean movement times by object orientation and
hand of response in conditions 1 (upper) and 2 (lower) for
Experiment 1. In the condition 1, the cylinder remained in
view whereas in the condition 2, the cylinder was removed
from view (on response initiation).

848

Table 1. Mean RTs and Errors by object orientation and
hand of response for Experiment 1.

Orientation

Left
Right

Response
Left
544 (1.4)
543 (3.5)

Right
534 (2.9)
532 (2.2)

Experiment 2
Experiment 1 showed that 1) the orientation of the target
cylinder leads to more accurate responses of the orientation
compatible hand, 2) the reach control is not influenced by an
object orientation when the target object remains in view
while participant is reaching towards it, and 3) the reach
program, triggered by object’s orientation, is inhibited when
the target disappears in the movement onset. The third
finding is the most interesting and is therefore further
explored in Experiment 2. This experiment investigates
whether the reach program is inhibited by the target object
offset also when the program is triggered by visual-semantic
affordance. Therefore, in Experiment 2, the orientated
cylinders are replaced by the orientated mugs. Because
Experiment 2 investigates the reach program inhibition
associated with an interruption of the visual signal, the
condition in which the object remains in view is replaced by
condition in which the handle of the object disappears in the
movement onset. This manipulation was introduced to
explore whether the inhibitory effect that was observed in
Experiment 1 could be linked to disappearance of the entire
goal object, or to disappearance of action-relevant property
of the goal object.

Figure 3. The upper object is an example of the tall mug
used in Experiment 2, and the lower object is an example of
the short mug.

Results
Reaction times The experiment consisted of 320 trials.
5.9% of the raw data was discarded from the RT analysis,
including 2.3% of trials that were errors and 3.6% of trials
in which RTs were more than two standard deviations from
a participant’s overall mean. The analysis of reaction times
revealed
a
significant
object-orientation
effect,
F(1,22)=22.18, p<.001, MSE=1449.47. This interaction is
displayed in Table 2.
Errors One participant did not make any errors. Analysis of
the percentage error rates revealed a statistically significant
object-orientation
effect,
F(1,21)= 4.71,
p=.042,
MSE=34.71. The interaction is displayed in Table 2.
Movement times This analysis did not reveal any
significant effects. The absence of the inhibitory objectorientation effect of both conditions of object presentation
can be viewed in Figure 4.

Method
Participants Twenty-three participants took part in the
experiment. All participants reported having normal or
corrected-to-normal vision and were naive as to the purpose
of the experiment. In addition, all participants signed the
participation form with their right-hand.
Materials and Procedure All stimuli but the target objects
were the same as in the previous experiment. The target
objects were left-right orientated short or tall mugs.
Participants were instructed to respond with their right-hand
if the mug was short and with their left-hand if it was tall.
Half of the participants were randomly assigned to the
opposite hand-to-tallness arrangement. The other new
experimental manipulation compared to the first experiment
was that when the response key was lifted, in half of the
trials the mug disappeared and in half of the trials only
mug’s handle disappeared. The stimuli is displayed in
Figure 3.

Table 2. Mean RTs and Errors by object orientation and
hand of response for Experiment 2.

Orientation

849

Left
Right

Response
Left
509 (1.6)
517 (3.0)

Right
508 (2.5)
501 (1.4)

was relatively weak. It was only observed in errors.
Nevertheless, when the prime object was removed from
view in the reach onset, the negative object-orientation
effect was observed in reaching movement times. This
suggests that the motor program that is activated in the
action planning stage is the target of inhibition in the control
stage if the visual source for online updating of the motor
program disappears. In other words, our data suggest that
the same motor program that is activated prior to action
onset is inhibited in the control stage if a sudden
interruption in the transmission of response-related visual
information occurs.
Interestingly, the reach control was only influenced by
object orientation when the object was removed from view.
When the object remained in view, the reaching movement
times were not affected by the object’s orientation. We
propose that object orientation automatically facilitates the
selection of the reach plan for the orientation compatible
hand. This reach program is then continuously updated
during the reach execution by visual inputs from this object.
However, the updating of this reach program does not lead
to faster or slower reaching of the orientation compatible
hand. Rather we assume that the updating of this program
supports the reach coordination towards the object.
Experiment 2 suggested that visual affordance
information and visual-semantic affordance information
trigger different kinds of motor programs. When orientation
affordance was extracted from visual-semantic object
properties the action planning processes were greatly
influenced by the object’s orientation. This effect was
observed in reaction times and in errors. In contrast, when
orientation affordance was extracted from purely visual
object properties (Experiment 1), the object’s orientation
only had a slight affect on response accuracy. However, in
this experiment, visual affordance had a great affect on
reach control. This was observed in immediate inhibition of
the reach program of orientation compatible hand on prime
object offset. The same effect was not observed in
Experiment 2 when affordance extraction involved semantic
processing. This suggests that the motor program, triggered
by visual affordance, requires updating of the target object
during the reach whereas the motor program for visualsemantic affordance does not require such updating or if it
does, the updating mechanisms have a different nature (e.g.,
are slower). That is, the object offset in the movement onset
does not have time to lead to inhibition during the reach that
takes only 350 ms. Therefore, not only the reach program is
different in the two cases but also mechanisms that are
updating the program may be different.
In real world, adjustments of motor program in flight are
limited to the spatial characteristics of the target object (e.g.,
visual affordances), as these attributes are the most likely to
change during the movement. Those semantically weighted
properties of the object that are involved in triggering the
motor plan such as function are almost completely unlikely
to change during the movement. Our data is suggesting that
if the coding of motor program (that occurs prior to the

368
365
362

Left-hand

359

Right-hand

356
353
350
Left

Right

368
365
362

Left-hand

359

Right-hand

356
353
350
Left

Right

Figure 4. Mean movement times by object orientation and
hand of response in conditions 1 (upper) and 2 (lower) for
Experiment 2. In the condition 1, the mug remained in view
and the handle was removed (on response initiation)
whereas in the condition 2, the entire mug was removed
from view.
Cross-experimental ANOVA The condition means from
each experiment were subjected to two repeated measures
ANOVAs (one for RTs, one for movement times) in order
to establish the reliability of the differential affect of the
object-orientation on reach planning and control between
Experiments 1 and 2. The data from condition 2 was
included to the cross-experimental movement time analysis
because this condition was only observed to lead to the
inhibitory effect. The analysis for RTs revealed a significant
interaction between orientation, hand of response and
experiment [F(1,43)=4.29, p=.044, MSE=727.03] indicating
that the object-orientation effect was only observed in
Experiment 2. The analysis for movement times also
revealed a significant interaction between orientation, hand
of response and experiment, F(1,43)= 5.66, p=.022, MSE=
363.69. This suggested that the inhibition of reach plan on
goal object offset can be only observed when the initial
reach plan is triggered by visual affordance (Experiment 1).

General Discussion
In the present research, motor inhibition processes were
investigated in an experimental situation in which the source
of a reach plan activation was removed from view on reach
initiation. In Experiment 1, the visual orientation of the
target cylinder facilitated the reach initiation of the
orientation compatible hand even though this facilitation
850

electrophysiological evidence. Journal of Experimental
Psychology: Human Perception and Performance, 24,
1737-1747.
Eimer, M. (1999). Facilitatory and inhibitory effects of
masked prime stimuli on motor activation and
behavioural performance. Acta Psychologica, 101, 293313.
Fagg, A. H., & Arbib, M. A. (1998). Modeling ParietalPremotor Interactions in Primate Control of Grasping,
Neural Networks 11, 1277-1303.
Glover, S. (2004). Separate visual representations in the
planning and control of action. Behavioural Brain
Sciences, 27, 3-78.
Grezes, J. & Decety, J. (2002). Does visual perception of
object afford action? Evidence from a neuroimaging
study. Neuropsychologia, 40, 212–222.
Grezes, J., Tucker, M., Armony, J., Ellis, R., & Passingham,
R.E. (2003). Objects automatically potentiate action: an
fMRI study of implicit processing. European Journal of
Neuroscience, 17, 2735-2740.
Milner, A.D., & Goodale, M.A. (1995). The Visual Brain in
Action. University Press, Oxford.
Pavese, A., & Buxbaum, L.J. (2002). Action matters: The
role of action plans and object affordances in selection for
action. Visual Cognition, 9, 559-590.
Petit, L., Pegna, A., Harris, I., & Michel, C. (2006).
Automatic motor cortex activation for natural as
compared to awkward grips of a manipulable object.
Experimental Brain Research, 168, 120-130.
Phillips, J., & Ward, R. (2002). S-R Correspondence effects
of irrelevant visual affordance: Time-course and
specificity of response activation. Visual Cognition, 9,
540-558.
Sugio, T., Ogawa, K., & Inui, T. (2003). Neural correlates
of semantic effects on grasping familiar objects.
NeuroReport, 14, 2297-2301.
Tipper, S.P., Lortie, C., & Baylis, G.C. (1992). Selective
reaching: Evidence for action-centered attention. Journal
of Experimental Psychology: Human Perception and
Performance, 18, 891-905.
Tucker, M., & Ellis, R. (1998). On the Relations Between
Seen Objects and Components of Potential Actions.
Journal of Experimental Psychology: Human Perception
and Performance, 24, 830-846.
Tucker, M., & Ellis, R. (2001). The Potentiation of Grasp
Types during Visual Object Categorization. Visual
Cognition, 8, 769-800.
Tucker, M., & Ellis, R. (2004). Action priming by briefly
presented objects. Acta Psychologica, 116, 185-203.
Vainio, L., Ellis, R., & Tucker, M. (in press). The role of
visual attention in action priming. The Quarterly Journal
of Experimental Psychology.
Vainio, L., Ellis, R., Tucker, M., & Symes, E. (in press).
Manual asymmetries in visually primed grasping.
Experimental Brain Research.

movement onset) relies to any extent on semantic
information, the adjustments of this program are based on
different mechanisms compared to mechanisms that are
operating for purely visually triggered program. Our results
were in line with the predictions derived from the planningcontrol model (Glover, 2004). This model predicts that
visual-semantic object information would have a greater
influence on planning than control whereas visual
affordances would have a greater influence on control than
planning.
This study suggests that the same motor program that is
activated in the motor planning stage is updated for hand
coordination in the motor control stage. A sudden
interruption in the transmission of visual inputs for updating
the motor program leads to inhibition of the program.
However, purely visual affordances and visual-semantic
affordances lead to differential behavioural effects in
planning and control. It is possible that visual and visualsemantic affordances activate entirely different motor
programs.
Alternatively, it is possible that visual and visual-semantic
affordances activate the same motor program but the
pathway through which the program is planned and updated
is different in the two cases. In the case of visual
affordances, the motor program may be planned and
updated via the dorsal stream, which allows relatively rough
but fast processing of visual information for motor
processes (see Milner & Goodale, 1995 for a review of the
dorsal and ventral streams). In contrast, in the case of
visual-semantic affordances, an involvement of the ventral
stream, which processes higher-level characteristics of
visual stimuli, may be required for processing visualsemantic affordances (and changes in these kinds of
affordance information) during planning and control. These
different kinds of involvement of the dorsal and ventral
streams in processing affordance information for planning
and control may lead to different behavioural effects when
the extraction of orientation information requires or does not
require processing of semantic information.

Acknowledgements
This work was supported by ESRC research grant
RES000220942.

References
Craighero, L., Fadiga, L., Rizzolatti, G., & Umilta, C.A.
(1999). Action for perception: A motor-visual attention
effect. Journal of Experimental Psychology: Human
Perception and Performance, 25, 1673-1692.
Creem, S. H., & Proffitt, D. R. (2001). Grasping objects by
their handles: A necessary interaction between cognition
and action. Journal of Experimental Psychology: Human
Perception and Performance, 27, 218-228.
Eimer, M., & Schlaghecken, F. (1998). Effects of masked
stimuli on motor activation: Behavioural and

851

