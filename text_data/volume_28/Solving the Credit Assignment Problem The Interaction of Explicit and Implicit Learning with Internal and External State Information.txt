UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Solving the Credit Assignment Problem: The Interaction of Explicit and Implicit Learning with
Internal and External State Information
Permalink
https://escholarship.org/uc/item/6b560035
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Anderson, John R.
Fu, Wai-Tat
Publication Date
2006-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                     University of California

   Solving the Credit Assignment Problem: The interaction of Explicit and Implicit
                          learning with Internal and External State Information
                                                      Wai-Tat Fu (wfu@cmu.edu)
                                              Human Factors Division and Beckman Institute
                                                University of Illinois at Urbana-Champaign
                                                   1 Airport Road, Savoy, IL 61874, USA
                                                  John R. Anderson (ja+@cmu.edu)
                                                          Department of Psychology
                                                          Carnegie Mellon University
                                                              5000 Forbes Avenue
                                                          Pittsburgh, PA 15213 USA
                             Abstract                                     recognition of external state information (signs on the
                                                                          walls). Indeed, many have argued that real-world skills
  In most problem-solving activities, feedback is received at the         often involve the interplay between cognition (internal),
  end of an action sequence. This creates a credit-assignment             perception, and action (external) that the understanding of
  problem where the learner must associate the feedback with
                                                                          these interactive skills requires careful study of how internal
  earlier actions, and the interdependencies of actions require
  the learner to either remember past choices of actions
                                                                          (memory) and external information (cues in the
  (internal state information) or rely on external cues in the            environment) are processed in the learning processes
  environment (external state information) to select the right            (Ballard, 1997; Fu & Gray, 2000; 2004; Gray & Fu, 2004;
  actions. We investigated the nature of explicit and implicit            Larkin, 1989; Gray, Sims, Fu, & Schoelles, in press).
  learning processes in the credit-assignment problem using a                The navigation problem above is an example of one of the
  probabilistic sequential choice task with and without external          most difficult situations in skill learning: when the learner
  state information. We found that when explicit memory                   has to perform a sequence of actions but only gets feedback
  encoding was dominant, subjects were faster to select the               on their success at the end of the sequence (e.g., when the
  better option in their first choices than in the last choices;
                                                                          destination is reached). This creates a credit-assignment
  when implicit reinforcement learning was dominant subjects
  were faster to select the better option in their last choices than
                                                                          problem, in which the learner has to assign credits to earlier
  in their first choices. However, implicit reinforcement                 actions that are responsible for eventual success. When
  learning was only successful when distinct external state               actions are interdependent, either memory of previous
  information was available. The results suggest the nature of            actions or recognition of the correct problem state in the
  learning in credit assignment: an explicit memory encoding              external environment is required to properly assign credits
  process that keeps track of internal state information and a            to the appropriate actions. In this article, we present results
  reinforcement-learning process that uses state information to           from an experiment in which we study how people learn to
  propagate reinforcement backwards to previous choices.                  solve the credit-assignment problem in a simple but
  However, the implicit reinforcement learning process is
                                                                          challenging example of such a situation. Our focus is on the
  effective only when the valences can be attributed to the
  appropriate states in the system – either internally generated
                                                                          recent proposal that humans exhibit two distinct learning
  states in the cognitive system or externally presented stimuli          processes and we apply it to learning of action sequences
  in the environment.                                                     with delayed feedback: an explicit process (with awareness)
                                                                          that requires memory for actions and outcomes, and an
                          Introduction                                    implicit process (without awareness) that does not require
                                                                          such memory. We will first review research in some related
Consider a person navigating in a large office building. The
                                                                          areas that informed the design of our experiment.
person has to decide when to turn left or right at various
hallway intersections. The sequence of decisions is
                                                                                       Explicit and Implicit Learning
interdependent – e.g., turning left at a particular hallway
intersection will affect the decisions at the next                        Probability Learning and Classification
intersections. The person may therefore need to keep track                There have been numerous studies on the learning of the
of previous actions to inform what actions to take in the                 probabilistic relationship between choices and their
future. In reality, memory of previous actions (internal state            consequences. The simplest situation is the probability-
information) may not be necessary as people can explicitly                learning experiment in which subjects guess which of the
                                                                          alternatives occurs and then receives feedback on their
seek information in the environment (external state
                                                                          guesses (e.g., Estes, 1964). One robust finding is that
information) to know where one is located or which
                                                                          subjects often “probability match”; that is, they will choose
direction to go to reach a destination (Fu & Gray, 2006).                 a particular alternative with the same probability that it is
Learning to navigate is therefore likely to involve both the              reinforced (e.g., Friedman et al., 1964). This leads many to
retention of internal state information (memory) and the                  propose that probability matching is the result of an implicit
                                                                      238

habit-learning mechanism that accumulates information               Neither of these paradigms then reflects the complexity of
about the probabilistic structure of the environment (e.g.,         the credit-assignment problem that people frequently face in
Graybiel, 1995). One important characteristic of this kind of       real life. We combine research from both areas by studying
habit learning is that information is acquired gradually            how people learn to assign credits to different actions in a
across many trials, and seems to be independent of                  probabilistic sequential choice task, in which sequences of
declarative memory as amnesic patients were found to                actions are executed before feedback on whether they are
perform normally in a probabilistic classification task             correct or not is received, and a particular action sequence is
(Knowlton, Squire, Gluck, 1994). However, for non-                  correct only with a certain probability.
amnesic human subjects, it is difficult to determine whether        Reinforcement Learning
probabilistic classification is independent of the use of           Learning from delayed feedback often involves the temporal
declarative memory. Since declarative memory is dominant            credit-assignment problem in which learners must apportion
in humans, it has been argued that learners often initially         credit and blame to each of the actions that resulted in the
engage in explicit memory encoding in which they seek to            final outcome of the sequence. The temporal credit
remember sequential patterns even when there are none               assignment problem is often done by some form of
(Yellott, 1969). Researchers argue that true probabilistic          reinforcement learning (e.g., Sutton & Barto, 1998).
trial-by-trial behavior only appears after hundreds of trials –     Recently, psychological research have found that in many
perhaps by then subjects give up the idea of explicitly             learning situations, neural activities in the basal ganglia
encoding patterns and the implicit habit-learning process           correlate well with the predictions of reinforcement learning
becomes dominant (Estes, 2002; Vulkan, 2000).                       (e.g., Schultz, Dayan, & Montague, 1997). Elsewhere we
   Recent research on complex category learning has also            also show that it produces a wide range of behavioral data in
provided interesting results suggesting multiple learning           the probability-learning literature and in other delayed
systems (Allen and Brooks, 1991; Ashby, Queller, and                feedback learning situations (Fu & Anderson, in press). The
Berretty, 1999; Waldron and Ashby, 2001). For example,              role of the basal ganglia is also closely related to the habit-
Waldron and Ashby (2001) showed that while a concurrent             learning (procedural) system in which past response-
Stroop task significantly impaired learning of an explicit          outcome information is accumulated through experience
rule that distinguished between categories by a single              (e.g., Graybiel, 1995). Such learning is also believed to be
dimension, but did not significantly delay learning of an           distinct from the explicit memory (declarative) system (e.g.,
implicit rule that requires integration of information from         Poldrack, et al., 2001; Daw, Niv, & Dayan, 2005).
multiple dimensions.                                                   The basic prediction of reinforcement learning is that
Sequence Learning                                                   when feedback is received after a sequence of actions, only
The explicit/implicit distinction has also been investigated        the last action in the sequence will receive feedback but that
through a paradigm called sequence learning (e.g.,                  on later trials its value will then propagate back to early
Cleeremans & McClelland, 1991; Cohen, Ivry, Keele, 1990;            actions. By itself this mechanism cannot learn in cases
Curran & Keele, 1993; Mathews, et al., 1989; Nissen &               where success depends on the sequence of actions rather
Bullemer, 1987; Sun, Slusarz, Terry, 2005; Willingham,              than the individual actions. Memories of previous actions or
Nissen, & Bullemer, 1989). In a typical experiment subjects         observations are required to disambiguate the states of the
have to press a sequence of keys as indicated by a sequence         world (e.g., McCallum, 1995). This implies that the
of lights. A certain pattern of button presses recurs regularly     cognitive agent needs to explicitly adopt some forms of
and subjects give evidence of learning this sequence by             memory encoding strategies to retain relevant information in
being able to press the keys for this sequence faster than a        memory for future choices.
random sequence. Although there have been slightly                     In our experiment, we study the implicit reinforcement
different definitions to capture the details of the                 learning process and the explicit memory process in a
implicit/explicit distinction, the key factor seems to be the       probabilistic sequential choice task. The task is specifically
idea that implicit learning occurs as a facilitation of test        designed to distinguish between the two processes and we
performance without concurrent awareness of what is being           have strong predictions about the outcome in the two
learned (Reber, 1989; Sun, et al., 2005; Willingham, 1998,          condition:     When the implicit reinforcement learning
but see Shanks & St. John, 1994). However, there seems to           process is dominant, learning of items closer to the feedback
be a limit on what the implicit process can learn. For              will be faster than those farther away. When the explicit
                                                                    memory encoding process is dominant, learning of items
example, Cohen et al. (1990), found that when explicit
                                                                    presented earlier will be faster. We also predict that implicit
learning is suppressed by a distractor task, subjects could
                                                                    learning requires distinct state information to propagate
only learn simple pairwise transitions, but failed to learn         credits back to earlier choices. In other words, when state
higher order hierarchical structures in the sequence.               information is absence, implicit learning will fail to learn
   In neither probability learning nor the typical sequence-        the dependency between actions.
learning task is there any doubt about the correctness of a
single action. In probability learning there is a single action                           The Experiment
after which feedback is received. In the typical sequence
learning experiment there is a sequence of actions but there        A probabilistic sequential choice task is designed in which
is immediate feedback after each action and usually a               we predict different behavioral patterns when subjects are
                                                                    engaged in explicit and implicit learning processes.
deterministic relationship between response and correctness.
                                                                239

Subjects were told that they were in a room and they had to        from the third number, subjects had to press the control key
choose one of the two colors presented on the screen to go         on the keyboard if the number is identical to the numbers
to the next room. After making two choices, subjects would         two numbers before. For example, if they heard the numbers
either reach an exit or a dead-end. Subjects were instructed       0, 3, 2, 3, and 0, they had to press the control key the second
to choose the colors that would lead them to the exit as often     time they heard 3. The numbers were presented once every
as possible. Figure 1 shows an example of the task. In room        two seconds. Subjects had to maintain their performance at
1, if they chose “red” they would go to room 2 with                80% or better at the 2-back task while performing the
probability 0.8 and to room 3 with probability 0.2. The            probabilistic sequential task.
probabilities were reversed if “blue” was chosen. After the           From earlier discussion, the basic prediction of the
first choice, if subjects were in room 2, if they choose           implicit reinforcement-learning process is that actions close
“yellow” there was a 0.6 probability of going to an exit and       to the feedback will acquire value first and then their value
0.4 probability of going to a dead end. Again, the                 will propagate back to early actions. Thus, in contrast to the
probabilities were reversed if “green” was chosen. If              explicit memory encoding process, learning of the choices
subjects were in room 3, choosing “yellow” would lead to           closer to the feedback will be faster than earlier choices.
an exit with probability 0.2 and to a dead end with                However, in the probabilistic sequential choice task, since
probability 0.8. Choosing “green” would lead to an exit with       the choices were designed to be dependent, it was
probability 0.4 and that to a dead end with probability 0.6.       impossible to learn the second choice before learning which
Note that if “red” is chosen, “yellow” is more likely to lead      color was better in first choice. We therefore need to
to an exit than “green”; but if “blue” is chosen, “green” is       provide some external state information for subjects to learn
more likely than “yellow”. The choice of colors in the             to recognize their current state in the second choice (i.e.,
second choice is therefore dependent on the first choice.          whether they were in room 2 or room 3 in Figure 1), so that
                                                                   it is possible for them to learn the second choice before the
                     1    Red    Blue
                                                                   first choice as predicted by the implicit reinforcement
                       0.8          0.8                            learning process. In addition, since the implicit learning
                                                                   process does not require explicit memory encoding, the
          2 Yellow     Green       3 Yellow Green                  prediction is that subjects may be able to learn to choose the
                                                                   more likely colors without concurrent awareness of them.
            0.6       0.4             0.2      0.4                    To study the effect of external state information on the
                              Exit                                 learning of the two choices, we placed half of the subjects in
Figure 1. The probabilistic sequential task. The circled           the distinct condition and the other half to the ambiguous
numbers represent room numbers, and the numbers next to            condition. In the distinct condition, in addition to the two
the arrows represent transition probabilities. Note that in        colors, there was also a distinct object in room 2 and 3 (e.g.,
room 3, regardless of what is chosen, there is a higher            a computer in room 2 and a telephone in room 3). Subjects
probability that it will lead to a dead-end compared to room       did not see the object in the ambiguous condition. Our
2. The actual colors were randomly selected from eight             expectation was that in the distinct condition, the presence
colors (red, green, yellow, blue, brown, gray, magenta, and        of the object would help subjects to identify which room
orange) for each subject.                                          they were in. This would allow them to choose the more
   One strategy in this task was to conduct a “tree-               likely color in the second choice set even without explicit
searching” by explicitly encoding the choices in memory            memory of their first choice. In the ambiguous condition,
and observing their outcomes. In this task, the probabilities      choosing the more likely second color would require
were chosen such that, even if subjects randomly chose a           internal state information encoded by explicit memory.
color in the second choice, the probability that choosing
“red” would eventually lead to an exit was higher than that        Method
for choosing “blue” (it can be easily shown that the               52 subjects in the Carnegie Mellon University community
marginal probabilities were 0.46 and 0.34 for choosing             were recruited for the experiment. Four of the subjects could
“red” and “blue” respectively). On the other hand, if              not maintain the 2-back task performance at 80% and were
subjects randomly chose a color in the first choice, the           excluded. Subjects received a base payment of $8 plus a
probabilities that choosing “yellow” or “green” would lead         bonus payment of up to $7 depending on performance. Half
to an exit were equal (it can be shown that the marginal           of the remaining 48 subjects were assigned to the single-task
probability would both be 0.4). The task was designed such         group and the other half to the dual-task group; and subjects
that when engaged in explicit memory encoding and                  in each group were further divided into the distinct and
searching, the first choices would be learned faster than the      ambiguous conditions. Subjects started with an initial score
second choice, as it was more likely that the memory traces        of 10 points. When an exit was reached, 5 points would be
of the better first choice would be strengthened faster than       added to the final score; when a dead-end was reached, 1
those for the better second choice.                                point would be deducted from the final score. Subjects were
   To study the nature of the implicit learning process, we        paid one cent for each point in the total score for the bonus
introduced a “2-back” secondary task to suppress the               payment. Each subject finished 20 10-trial blocks. At the
otherwise dominant explicit memory encoding process. The           end of the experiment, subjects were asked to write down
secondary task required subjects to listen to a continuous         any strategy they used and whether they thought that any of
stream of numbers (from 0 to 9) from the speakers. Starting        the colors was more likely lead to the exit.
                                                               240

Results                                                             explained by the fact that, except the not-aware group in the
Subjects who could write down the more likely colors in all         ambiguous condition, subjects significantly increased their
three rooms (thus the choice dependency) were placed in the         choice proportions of the more likely colors across trials.
aware group; otherwise they were placed in the not-aware            Indeed, the last four blocks of both choices were
group (see Table 1). In the dual task condition, most of the        significantly above chance for all but the not-aware group in
subjects could not write down the more likely colors in any         the ambiguous condition.
of the rooms, while subjects in the single task condition              The results were consistent with the proposed distinct
could write down the more likely colors in at least two of          learning processes in the probabilistic sequential choice
the rooms (we chose not to include them in the aware group          task. As reflected by our awareness measure, in the single-
as they apparently were not aware of the choice dependency          task condition, most of the subjects explicitly remembered
between the two choices).                                           the outcomes of the choices and were aware of the choice
                                                                    dependencies. Consistent with our expectation, subjects in
Table 1. Number of subjects who wrote down the more                 the aware group presumably conducted a tree-searching
likely colors in each of the experimental condition. All = all      strategy, and learned the first choice faster than the second
rooms, none = none of the rooms, R1 = room 1 only, and R1           choice. In the dual-task condition, since the explicit
& R2 = room 1 and 2 only, etc. In the ambiguous condition,          encoding of past experiences was suppressed, most of the
subjects were not aware of the distinction of room 2 and 3.         subjects were not aware of the most likely colors.
                                                                    Nevertheless, in the distinct condition, subjects increasingly
                       Single                   Dual                selected the more likely colors, demonstrating learning of
  Rooms       Distinct    Ambiguous    Distinct  Ambiguous          the dependency between the choices1. Consistent with the
    All          9            7           2           1             reinforcement-learning mechanism, learning of the second
R1 & R2          2            4           0           1             choice was faster than the first choice, despite the
R1 & R3          0            1           0           0
                                                                    asymmetry of choice probabilities in the design of the task.
R2 & R3          1            0           2           1
                                                                    The result also suggests that reinforcement learning does not
    R1           0            0           0           0
    R2           0            --          1           --            require explicit memory encoding and concurrent awareness
    R3           0            --          0           --            to learn the choice dependency.
   none          0            0           7           9                In the ambiguous condition, the dependency between
                                                                    choices could only be learned if subjects remembered the
   A 2 (first/second choice) x 2 (awareness) x 2 (single/dual       first choice when making the second choice. Most subjects
task) x 2 (distinct/ambiguous condition) ANOVA on the               in the single-task condition were aware of the better colors
choice proportions on the more likely colors shows that the         in both choices and chose them increasingly often across
main effects of awareness and condition were significant            trials. This suggests that subjects in the aware group did
(F(1,40)=12.21, MSE=0.19, p<0.001; F(1,40)=5.33,                    learn the dependency of choices. Similar to the subjects in
MSE=0.19, p <0.05 respectively); learning was better in the         the aware group in the distinct condition, learning of the
aware group than the not-aware group, and was better in the         first choice was faster than the second choice. In the dual-
distinct condition than the ambiguous condition. There were         task condition, the suppression of the memory encoding of
significant choice x awareness x condition and choice x             the first choice significantly hampered the discovery of the
awareness interactions (F(1,40)=8.79, MSE=0.088, p < 0.01           dependency. Subjects failed to learn to choose the better
and F(1,40)=18.68, MSE=0.088, p < 0.001 respectively).              colors above chance level. Apparently, reinforcement
No other interaction involving choice was significant. Since        learning failed when the final states (i.e., room 2 and room
the main effect of task was not significant (F(1,40)=0.95,          3) were indistinguishable, as both internal and external cues
MSE=0.21, p=0.34), nor was any of its interaction, the              were not available. It suggests distinct states information is
results were collapsed across tasks in Figure 2, which shows        essential for the proper propagation of credits to earlier
the mean choice proportions of the more likely colors in            state-action pairs.
each 20-trial block. Consistent with our expectation, in the           .
distinct condition, subjects in the aware group learned the
first choice faster than the second choice while subjects in
the not-aware group learned the second choice faster than
the first choice. In the ambiguous condition, subjects in the
aware group also learned the first choice faster than the
second choice. However, in contrast to the distinct                 1
condition, subjects in the not-aware group were not                   Note that if subjects were not aware of the choice dependency
significantly above chance throughout the 10 20-trial blocks        and always chose one of the more likely colors in the second
                                                                    choice set (i.e., chose “yellow” in both room 2 and 3 using the
for, indicating that they failed to learn implicitly when state
                                                                    example shown in Figure 1), the choice proportion would have
information was absent.                                             been 80% of the choice proportion of the more likely color in the
   The main effect of blocks was significant (F(9,360)=6.86,        first choice (i.e., approximately 0.8 x 0.8 = 0.64 in the last 3
MSE= 0.019, p < 0.001). The blocks x awareness x                    blocks). Since the second choice proportions were higher than
condition interaction was significant (F(9,360)=3.70,               0.64, subjects had learned to choose the more likely colors in both
MSE=0.019, p < 0.001). No other interaction involving               room 2 and room 3 – i.e., they had learned the dependency
blocks was significant. The significant interaction could be        between the choices.
                                                                241

                      1.0                         Distinct                                 1.0                        Ambiguous
                      0.9                                                                  0.9
                      0.8                                                                  0.8
 Choice proportions
                      0.7                                                                  0.7
                      0.6                                                                  0.6
                      0.5                                                                  0.5
                      0.4                                                                  0.4
                                aware first                  aware second
                      0.3                                                                  0.3
                                not aware first              not aware second
                      0.2                                                                  0.2
                            1   2    3        4     5   6      7    8       9   10               1     2    3     4       5    6        7   8   9   10
                                              20-trial blocks                                                         20-trial blocks
Figure 2. Choice proportions of the colors that were more likely to lead to the exit in the distinct and ambiguous conditions in
each of the 20-trial blocks. Using the example shown in Figure 1, “first” would be the choice proportions of “red”, and
“second” would be the sum of the choice proportions of “yellow” and “green” in room 2 and room 3 respectively.
                                                                                           the full course of action is received. Solving the credit-
                                         Discussions                                       assignment problem is crucial for learning in this kind of
                                                                                           situation, as the delayed feedback has to propagate back to
The primary questions addressed by the study are (1)
                                                                                           the appropriate actions that are responsible for the desirable
whether there are explicit and implicit modes of learning in
                                                                                           or undesirable outcome. The reinforcement-learning process
probabilistic sequential choice tasks, as suggested by the
                                                                                           provides a straightforward explanation of how feedback
literature on probability learning and sequence learning, if
                                                                                           propagates back to earlier actions. Initially, only the action
so (2) whether the implicit learning process is consistent
                                                                                           that leads to outcome gets credit or blame. The next time
with the credit-assignment mechanism in reinforcement
                                                                                           some of that credit/blame propagates back to the previous
learning, and (3) whether explicit external state information
                                                                                           actions. Eventually, credit/blame can find its way back to
is required to propagate credits back to earlier actions when
                                                                                           critical early actions in a long chain of actions leading to a
the actions are interdependent as predicted by the
                                                                                           reward. The effectiveness of this process, however, depends
reinforcement learning process. Results from the experiment
                                                                                           on whether the effects of these actions are independent of
seem to answer all three questions in the affirmative.
                                                                                           each other. When the actions are interdependent, either
   In an uncertain environment, people learn to choose the
                                                                                           distinct external state information or memory of earlier
right actions by identifying states of the cognitive system
                                                                                           actions is required to ensure the proper assignment of credits
and the environment associated with positive and negative
                                                                                           for effective skill learning.
valence. In most situations, the states consist of
combinations of internally encoded responses and externally
presented stimuli. In most situations, the explicit, goal-                                                      Acknowledgment
directed tree-searching strategy seems dominant, which                                       The current work is supported by a grant from the Office
allows people to encode responses and their outcomes                                       of Naval Research (N00014-99-1-0097).
internally. The internally encoded state information then
guides future selection of actions. We found that in addition                                                     References
to this dominant explicit encoding process, an implicit
                                                                                           Ashby, F. G., Queller, S., & Berretty, P. M. (1999). On the
reinforcement learning process allows learning by
                                                                                             dominance of unidimensional rules in unsupervised
monitoring the outcomes of responses (positive or negative
                                                                                             categorization. Perception & Psychophysics, 61, 1178-
valences). However, this implicit reinforcement learning
                                                                                             1199.
process is effective only when the valences can be attributed
                                                                                           Allen, S.W., & Brooks, L. R. (1991). Specializing the
to the appropriate states in the system – either internally
                                                                                             operation of an explicit rule. Journal of Experimental
generated states in the cognitive system or externally
                                                                                             Psychology: General, 120, 3-19.
presented stimuli in the environment.
                                                                                           Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P. N.
    The probabilistic sequential choice task used in the
                                                                                             (1997). Deictic codes for the embodiment of cognition.
experiments,      although simple,       contains     essential
                                                                                             Behavioral and Brain Sciences, 20(4), 723-742.
components in interactive skill learning, in which a
sequence of actions are performed before reinforcement on
                                                                                     242

Cleeremans, A. & McClelland, J.L. (1991). Learning the           Knowlton, B. J., Squire, L. R., & Gluck, M. (1994).
  structure of event sequences. Journal of Experimental            Probabilistic classification learning in amnesia. Learning
  Psychology : General, 120, 235-253.                              and Memory, 1, 106-120.
Cohen, A., Ivry, R., & Keele, S. (1990). Attention and           Larkin, J. H. (1989). Display-based problem solving. In D.
  structure in sequence learning. Journal of Experimental          Klahr & K. Kotovsky (Eds.), Complex information
  Psychology: Learning, Memory, and Cognition, 16, 17–             processing: The impact of Herbert A. Simon (pp. 319–
  30.                                                              341). Hillsdale, NJ: Lawrence Erlbaum Associates.
Curran, T., & Keele, S. W. (1993). Attentional and               Mathews, R., Buss, R., Stanley, W., Blanchard-Fields, F.,
  nonattentional forms of sequence learning. Journal of            Cho, J., & Druhan, B. (1989). Role of implicit and
  Experimental Psychology: Learning, Memory, and                   explicit processes in learning from examples: A
  Cognition, 19, 189–202.                                          synergistic effect. Journal of Experimental Psychology:
Daw, N., Niv, Y., & Dayan, P. (2005). Uncertainty-based            Learning, Memory, and Cognition, 15, 1083–1100.
  competition between prefrontal and dorsolateral striatal       McCallum, A. K. (1995) Reinforcement Learning with
  systems for behavioral control. Nature Neuroscience, 8,          Selective Perception and Hidden State, PhD. Thesis,
  1704-1711.                                                       University of Rochester.
Estes, W. K. (1964). Probability learning. In A. W. Melton       Nissen, M., & Bullemer, P. (1987). Attentional
  (Ed.), Categories of human learning. New York:                   requirements of learning: Evidence from performance
  Academic Press.                                                  measures. Cognitive Psychology, 19, 1–32.
Estes, W. K. (2002). Traps in the route to models of             Poldrack, R., Clark, J., Pare-Blagoev, E., Shohamy, D.,
  memory and decision. Psychonomic Bulletin and Review,            Moyano, J., Myers, C., & Gluck, M. (2001). Interactive
  9 (1), 3-25.                                                     memory systems in the human brain. Nature, 414, 546-
Friedman, M. P., Burke, C. J., Cole, M., Keller, L.,               550.
  Millward, R. B., & Estes, W. K. (1964). Two-choice             Reber, A. S. (1989). Implicit learning and tacit knowledge.
  behavior under extended training with shifting                   Journal of Experimental Psychology: General 118, 219-
  probabilities of reinforcement. In R. C. Atkinson (Ed.),         235.
  Studies in mathematical psychology (pp. 250-316).              Schultz, W., Dayan, P., & Montague, P. R. (1997). A neural
  Stanford, CA: Stanford University Press.                         substrate of prediction and reward. Science, 275, 1593-
Fu, W. & Anderson, J. (in press). From recurrent choice to         1599.
  skill learning: A model of reinforcement learning. Journal     Shanks, D. R., & St. John, M. F. (1994). Characteristics of
  of Experimental Psychology: General.                             dissociable human learning systems. Behavioral and
Fu, W. & Gray, W. D. (2000). Memory versus Perceptual-             Brain Sciences, 17, 367-447.
  Motor Tradeoffs in a Blocks World Task. In Proceedings         Sun, R., Slusarz, P., & Terry, C. (2005). The interaction of
  of the 22nd Annual Conference of the Cognitive Science           the explicit and the implicit in skill learning: A dual-
  Society, Mahwah, NJ: Erlbaum.                                    process approach. Psychological Review, 112, 159-192.
Fu, W. & Gray, W. D. (2004). Resolving the paradox of the        Sutton, R. S., & Barto, A. G. (1998). Reinforcement
  active user: Stable suboptimal performance in interactive        learning: An introduction. Cambridge, MA: MIT Press.
  tasks. Cognitive Science, 28 (6).                              Vulkan N. 2000. An economist’s perspective on probability
Fu, W. & Gray, W. D. (2006). Suboptimal Tradeoffs in               matching. Journal of Economic Surveys, 14, 101–118
  Information-Seeking. Cognitive Psychology. 52 (3), 195-        Waldron, E., & Ashby, G. (2001). The effects of concurrent
  242.                                                             task interference on category learning: Evidence for
Gray, W. D., & Fu, W. (2004). Soft Constraints in                  multiple category learning systems. Psychonomic Bulletin
  Interactive Behavior: The Case of Ignoring Perfect               & Review, 8, 168-176.
  Knowledge In-The-World for Imperfect Knowledge In-             Willingham, D. (1998). A neuropsychological theory of
  The-Head .Cognitive Science, 28 (3), 359-382.                    motor skill learning. Psychological Review, 105, 558-584.
Gray, W. D., & Sims, C., Fu, W., Schoelles, M. (in press).       Willingham, D., Nissen, M., & Bullemer, P. (1989). On the
  The soft constraints hypothesis: A rational analysis             development of procedural knowledge. Journal of
  approach to resource allocation for interactive behavior.        Experimental Psychology: Learning, Memory, and
  Psychological Review.                                            Cognition, 15, 1047-1060.
Graybiel, A.M. (1995). Building action repertoires: memory       Yellott, J. L. (1969). Probability learning with
  and learning functions of the basal ganglia. Current             noncontingent success. Journal of mathematical
  Opinion in Neurobiology, 5, 733-741.                             psychology, 6, 541-575
Knowlton, B. J., Mangels, J. A., & Squire, L. R. (1996). A
  neostriatal habit learning system in humans. Science, 273,
  1399-1402.
                                                             243

