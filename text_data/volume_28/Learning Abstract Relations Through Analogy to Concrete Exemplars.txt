UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Learning Abstract Relations Through Analogy to Concrete Exemplars
Permalink
https://escholarship.org/uc/item/9m46t98s
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Love, Bradley C.
Tomlinson, Markus T.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

 Learning Abstract Relations Through Analogy to Concrete Exemplars
                                    Marc T. Tomlinson and Bradley C. Love
                                            [mtomlinson,love]@love.psy.utexas.edu
                                                University of Texas At Austin
                                                  1 University Station, A8000
                                                 Austin, TX 78712-0187 USA
                          Abstract                                 Category Learning
                                                                   Proposals for category representation are diverse, rang-
   We present a model that bridges work in analogy                 ing from exemplar-based (Medin & Schaffer, 1978) to
   and category learning. The model, Building Rela-                prototype-based (Smith & Minda, 1998) and include
   tions through Instance Driven Gradient Error Shift-             proposals between these two extremes (Love, Medin, &
   ing (BRIDGES), extends ALCOVE, an exemplar-based
   connectionist model of category learning (Kruschke,             Gureckis, 2004).
   1992). Unlike ALCOVE which is limited to featu-                    In the present work, we focus on exemplar-based
   ral or spatial representations, BRIDGES can appreci-            proposals. Exemplar-models of category learning hold
   ate analogical relationships between stimuli and stored         that all abstraction or generalization occurs through
   predicate representations of exemplars. Like ALCOVE,
   BRIDGES learns to shift attention over the course of            similarity-based activations of concrete examples. In ex-
   learning to reduce error and, in the process, alters its        emplar models, each experienced instance is stored in
   notion of similarity. A shift toward relational sources         memory. When a new item is encountered, the similar-
   of similarity allows BRIDGES to display what appears            ity between the item and each exemplar in memory is
   to be an understanding of abstract domains, when in
   fact performance is driven by similarity-based structural       calculated. The stimulus is predicted to belong in the
   alignment (i.e., analogy) to stored exemplars. Support-         category with the greatest sum of pairwise similarity.
   ive simulations of animal, infant, and adult learning are       Thus, exemplar models clearly link experienced events
   provided.                                                       to later generalization.
                                                                      The model of relational learning that we will de-
                                                                   velop here, BRIDGES, is an extension of Kruschke’s
                      Introduction                                 (1992) ALCOVE connectionist exemplar model of cate-
                                                                   gory learning. BRIDGES’s exemplar representation will
We live in a world of concrete experiences, yet we appre-          support the notion that analogy to stored experiences is
ciate seemingly abstract concepts. Category contrasts              sufficient to appreciate abstract relationships. Further-
like “same” or “different” and “predator” or “prey” are            more, by incorporating ALCOVE’s attentional shifting
not based on featural regularities. Instead, these con-            mechanisms into BRIDGES, we forward an explanation
cepts are relational in nature (e.g., two identical objects        of how perceived similarity can change over the course of
of any size, color, or shape are the same). How do we              learning as more predictive stimulus properties are ac-
acquire concepts that are not based on featural regular-           centuated. Such attentional shifts will prove useful in
ities?                                                             demonstrating how seemingly abstract understandings
   The category learning literature has focused on how we          can arise from concrete experiences.
acquire new concepts, but largely in domains in which                 Finally, ALCOVE has been a very successful model
the regularities are defined by distributions of features          of category learning and provides a strong foundation
(e.g., red objects are in one category, whereas blue ob-           for bridging the category learning and analogy litera-
jects are in the other category). In contrast, the analogy         tures. By virtue of containing ALCOVE as a special
literature has considered how people appreciate regulari-          case, BRIDGES accounts for a wide variety of prior hu-
ties defined by common relational structures, but has not          man learning studies examining how people acquire cat-
leveraged work in category learning detailing how people           egories determined by featural regularities.
integrate knowledge across examples and shift attention.
   Here, we extend an existing model of category learning          Analogy
to include a more sophisticated notion of similarity that          Analogical comparison can reveal non-obvious similar-
is sensitive to both featural and relational match. We             ities. For example, people can appreciate that the
propose that in many domains where performance ap-                 Rutherford atom is similar to the solar system because
pears to be governed by mental rules, it is actually driven        the planets revolve around the sun much like how the
by similarity-based activation of stored exemplars. This           electrons revolve around the atom’s nucleus (Gentner,
account is supported by simulations of how young infants           1983). The perceived similarity between the atom and
learn seemingly abstract grammars and how animals and              the solar system is not based on feature overlap, but on
people learn the distinction between same and different.           common relational structure.
                                                              2269

                                    Attention on Relation                           Attention on Features
                                Preserves Parallel Connectivity                   Preserves Featural Match
                              Left_of (   ,  ) map  Left_of(    , )          Left_of(   ,   ) map Left_of( , )
                                         Figure 1: Example of attention on mapping
   Numerous accounts of how people detect these ana-                    and prefers parallel connected mappings (Larkey & Love,
logical similarities exist. Transformational accounts hold              2003). Thus, BRIDGES’s approach to structural align-
that one analog is transformed over a series of steps until             ment will incorporate these two constraints on the ana-
it matches the other analog (Hahn, Chater & Richard-                    logical mapping process. As will be more fully discussed
son, 2003). The fewer the steps and the smaller their                   below, BRIDGES factors in both relational and featural
cost, the higher the resulting similarity is. The dominant              matches when determining mappings. When these two
account of detecting non-obvious similarities is structure              forces are at odds (as in Figure 1), learned attentional
mapping theory (Gentner, 1983). Although BRIDGES                        weightings determine the preferred mapping.
could utilize other frameworks to reach its ends, such
as transformational approaches, we adopt the structure                                 Overview of BRIDGES
mapping account because of the broad support it enjoys                  BRIDGES is an exemplar-based model of category learn-
in the analogy literature.                                              ing that can utilize structure mapping to appreciate ana-
   Structure mapping holds that people encode                           logical similarities. For any given comparison between
stimuli (e.g., objects, scenes, events) in terms                        a stimulus and a stored exemplar, BRIDGES considers
of predicate representations that capture rela-                         all possible one-to-one mappings. Models of analogical
tions among entities (e.g., Revolves(planets,sun)).                     alignment avoid this exhaustive search by using heuris-
Relations can serve as arguments to other rela-                         tics to guide the mapping process. BRIDGES could be
tions (e.g., Causes(GreaterMass(sun,planets), Re-                       extended to incorporate these shortcuts, but we do not
volves(planets,sun))). Structure mapping posits that                    do so here. Instead we focus on the basic ideas underly-
people align such structured representations to find                    ing BRIDGES.
the most satisfying correspondences.               In the solar            Out of all permissible mappings, BRIDGES chooses
system/atom example, this alignment would involve                       the mapping that minimizes a difference measure that
placing the sun in correspondence with the nucleus                      incorporates notions of featural and relational mismatch
and the planets in correspondence with the electrons.                   (see Figure 1). A relational mismatch of 1 occurs when
Sounder mappings lead to increased perceived similarity                 a relation does not exhibit parallel connectivity (see the
(Gentner & Markman, 1997).                                              right panel of Figure 1). A featural mismatch of 1 oc-
   Factors that influence the soundness of a mapping in-                curs when non-identical entities or entities containing
clude: 1) one-to-one correspondence 2) parallel connec-                 mismatching features are mapped to one another (see
tivity and 3) systematicity. One-to-one correspondence                  the right panel of Figure 1).
is a hard rule that cannot be violated. Corresponding                      Both types of mismatch are weighted by attention
entities and relations can map to at most one node in                   weights and the sum of these attention weighted mis-
the other structure. Parallel connectivity is a preference              matches yields an overall differences measure that is in-
for mapping arguments playing the same role within cor-                 versely proportional to similarity. The mapping that
responding predicates to one another. For example, par-                 maximizes similarity (i.e., minimizes attention weighted
allel connectivity is preserved for the revolves relation in            difference) is chosen. These exemplar similarity values
the atom/solar system example because the two revolves                  serve as exemplar unit activations and are passed across
predicates correspond and the arguments of these two                    association weights to category units (e.g., predator and
relations also map to the appropriate argument in the                   prey). The stimulus tends to be classified into the cate-
other predicate (i.e., mapping the sun to the electrons                 gory whose unit has the greatest activation.
would not preserve parallel connectivity). As Figure 1 il-                 After feedback is provided, attention weights and as-
lustrates with a simpler perceptual analogy, parallel con-              sociation weights between exemplars and category units
nectivity can be at odds with featural similarity. Finally,             are adjusted to reduce error. Changes in attentional
systamaticity is a preference for mappings that are com-                weights can lead to different future mappings.
plete and deep (i.e., contain embedded systems of rela-                    When attention shifts away from features and toward
tions). These principles have been successfully embodied                relations, parallel connectivity (i.e., analogical match) is
in the SME model of analogical alignment (Falkenheiner,                 stressed over featural similarity and BRIDGES demon-
Forbus, & Gentner, 1989).                                               strates abstract understanding of a domain. Conversely,
   More recent models within the structure mapping                      when featural matches lead to successful predictions, at-
framework have demonstrated that systematicity can                      tention shifts toward features and BRIDGES is governed
fall out of a system that enforces one-to-one mappings                  by featural similarity. When relational information is
                                                                    2270

not discriminative or present, BRIDGES reduces to the            where λα is the learning rate for attention weights. The
standard ALCOVE model.                                           parameter values used in the simulations reported here
                                                                 are λα = .007, λ= .001, c = .03, and φ = 6.1. These
             BRIDGES’s Formalism                                 values were chosen to maximize R2 in the second simu-
BRIDGES is a three-layer feed forward artificial neural          lation.
network. The input to BRIDGES contains both featural
and relational information in predicate argument form.
                                                                     Modeling Infant Grammar Learning
Each possible feature or relation has an associated at-          Marcus, Vijayan, Bandi Rao and Vishton (1999) found
tention weight. The activation (i.e., similarity) of each        that infants could discriminate between abstract pat-
exemplar j by stimulus s is                                      terns or grammars of speech sounds. Importantly, this
                                                                 discrimination could not be accomplished by any weight-
   hj = maxm∈m (exp[−c(
                           X
                                  αi · M ismatch(si ))]) (1)     ing of phonetic features. Because featural regularities
                                                                 could not be leverage to discriminate between grammars,
                              i
                                                                 Marcus et al. proposed that infants utilized variable
where m∈M is all possible one-to-one mappings between            binding in conjunction with algebraic rules to master
nodes (i.e., features, entities, and relations) forming          such learning tasks.
stimulus s and exemplar j, i ranges over nodes in stim-             In Marcus et al.’s (1999) study, seven-month-old in-
ulus s, αi is the attention weight associated with node          fants were exposed to sentences that followed either an
type si , and c is the specificity parameter that deter-         AAB pattern or an ABB pattern. The sentences were
mines the rate that similarity falls off with increasing         made up of simple monosyllable sounds (words) such as
mismatch. Mismatch is defined to be 1 for features or            “GA TI TI”. Each infant was trained for approximately
entities in stimulus s that map to non-identical nodes           2 minutes on one of the grammars. The 2-minute ses-
in exemplar j, otherwise 0. For relations, Mismatch is           sion contained three repetitions of 16 unique sentences.
defined to be 1 for relations in stimulus s not exhibiting       There was a 250 milliseconds pause between each word
parallel connectivity, otherwise 0.                              in the sentences and a one second pause between each
   Activation passes from exemplars to category unit ok :        sentence. The testing phase consisted of presentation
                                                                 of 12 sentences containing novel words. Half of the 12
                           X                                     sentences were from the same grammar used in training
                      ok =       wkj · hj                (2)
                                                                 and the other half were from the contrasting grammar.
                            j
                                                                 Fifteen of the 16 infants in the study had greater looking
                                                                 times during the presentation of the sentences from the
where wjk is the association weight between exemplar j
                                                                 novel grammar, indicating that the infants had habitu-
and category unit ok . The probability of selecting the
                                                                 ated to the abstract pattern.
category corresponding to category unit r is
                                    X                            BRIDGES’s Simulation BRIDGES was applied to
             P r(r) = exp(φor )/        exp(φok )        (3)     the Marcus et al. (1999) study. Each sentence (e.g., “GA
                                     k                           TI TI”) was represented as an exemplar. BRIDGES’s
                                                                 exemplar representation for “GA TI TI” is shown in Ta-
where φ is a decision parameter and k ranges over all            ble 1. Each syllable is represented as an entity. Each
category units.                                                  syllable’s position in the speech stream is encoded by
   Learning is accomplished via gradient descent error           a positional feature. These syllables have a number of
minimization. The target value for the category unit             phonetic features that are not represented in these simu-
corresponding to the correct category is set to 1 and            lations. Not including such features simplifies the simu-
other category nodes are set to 0. A “humble teacher”            lations (and follows Marcus et al.’s presumption that no
scheme is used so that category unit output values in            significant regularities exist across these features). More
the correct direction greater that 1 or less than 0 are not      importantly, not including these additional features pro-
penalized. The error function E minimized is                     vides a strong test of BRIDGES as there are no featural
                                                                 regularities that BRIDGES can rely on to discriminate
                         1X                                      between the grammars.
                    E=          (tk − ok )2              (4)
                         2
                           k
                                                                   Table 1: BRIDGES’s representation of “GA TI TI.”
where tk is the target value for ok . The association
weight wkj from exemplar j to output unit k is adjusted            Entities          Features              Relations
by                                                                 GA1         P osition(GA1 ) = 1    T ypeOf (GA1 , GA)
                   ∆wkj = λk (tk − ok )hj                (5)       T I1        P osition(T I 1 ) = 2  T ypeOf (T I 1 , T I)
where λw is the learning rate for association weights.             T I2        P osition(T I 2 ) = 3  T ypeOf (T I 2 , T I)
Attention weights are updated by
              XX                                                    Critically, relational information was included in
 ∆αi = −λα        [ (tk −ok )wkj ]hj ·c·M ismatch(si ) (6)      BRIDGES’s representations. BRIDGES makes a dis-
               j    k                                           tinction between tokens and types. In effect, we assume
                                                            2271

that infants in Marcus’s et al.’s study have developed              be discriminated by analogical mapping (even in simple
categories of speech sounds. These type relations allow             domains in which only the type relation is present) are
for abstract patterns to be uncovered through analogy               more encompassing than same/different. The analogical
to stored exemplars as one type of sound can mapped to              mapping process in these simulations aligned the current
another.                                                            stimulus to stored exemplars — BRIDGES did not label
   The training and test regimen followed the original              words within sentences as same or different nor did it
Marcus et al. (1999) study as closely as possible. Follow-          shift attention to a same feature. Abstract responding
ing Love et al. (2004), unsupervised learning was mod-              arose through analogy to stored exemplars and attention
eled by a network consisting of a single category output            shifting from concrete features to relations.
unit with a target value of 1 for all stimuli. In effect, this
category unit is a familiarity detector. Association and                 Modeling Same-Different Learning
attention weights in the model were adjusted to uncover
                                                                    BRIDGES holds that the basis for understanding ab-
the underlying regularities across the sentences to yield
                                                                    stract relations is similarity-based and therefore inher-
consistently high familiarity (i.e., high output values for
                                                                    ently graded. The design of the Marcus et al. study
the category unit). During habituation, the 16 unique
                                                                    did not touch on this possibility because stimuli were
sentences were presented three times each to BRIDGES
                                                                    either grammatical or ungrammatical. According to
and stored as exemplars. On each presentation, associa-
                                                                    BRIDGES, learners can both respond abstractly (i.e.,
tion and attention weights were updated. After training
                                                                    generalize to featurally novel stimuli) and show evidence
BRIDGES correctly responded to novel items from the
                                                                    for the influence of past examples. If BRIDGES is cor-
old grammar as familiar (output activation = 1.3) and a
                                                                    rect, category membership in relationally defined cate-
novel items from the new grammar as unfamiliar (output
                                                                    gories is graded as it is in natural categories (Rosch, &
activation = .95).
                                                                    Mervis 1975).
   Though not critical, we assumed that the saliency of                To evaluate BRIDGES’s predictions, we will consider
positional features is sufficiently great to constrain the          results from a series of studies exploring how pigeons
mapping process (i.e., words in sentences align tempo-              and humans learn notions of same and different. To illus-
rally). Besides position (which does not discriminate               trate how BRIDGES learns the concepts same and differ-
between grammars), no regularities across features or               ent, we will apply BRIDGES to Young and Wasserman’s
entities existed. However, parallel connectivity was per-           (1997) study of same/different discriminaton learning in
fect for members of the same grammar. For instance,                 pigeons. To foreshadow, Young and Wasserman’s results
“GA TI TI” is isomorphic to “LI NA NA” in that all                  indicate that pigeons can master a notion of same and
token and types in the type relation (see Table 1) can              different that cannot be explained by featural similarity.
be mapped to one another and preserve parallel connec-              At the same time, the pigeons are sensitive to the par-
tivity. This degree of perfect match caused BRIDGES                 ticular examples they experienced during training and
to shift attention to the type relation. This shift makes           display a graded notion of same and different. Although
BRIDGES sensitive to the underlying grammar, render-                fascinating, it would be easy to dismiss these results as
ing novel sentences following the original grammar some-            relevant to pigeon cognition, but not human cognition.
what familiar. Sentences not following the learned gram-            However, work by Young and Wasserman (2001) found
mar do not analogically match stored exemplars (parallel            the same pattern of performance with human subjects.
connectivity is violated), making these items less familiar         Humans as a group are slightly more deterministic than
and resulting in greater looking time as infants dishabit-          pigeons, but this group difference is within the range of
uate.                                                               individual differences. The bottom and top 20% of hu-
Discussion BRIDGES is able to discriminate between                  mans clearly bracket the mean performance of pigeons.
abstract patterns on the basis of analogical similarity.               In Young and Wasserman (1997), pigeons learned to
Storing concrete exemplars, shifting attention, and ana-            respond differentially to displays containing 16 identical
logical match are sufficient to show generalization to              and 16 different icons. On each trial, the 16 icons were
novel items. BRIDGES’s success calls into question Mar-             randomly placed within a 5 X 5 grid. The pigeons were
cus et al.’s (1999) claim that algebraic rules underly in-          reinforced for pushing a green button when presented
fant performance. However, BRIDGES’s success is at-                 with a same stimulus and a red button when presented
tributable to its ability to bind arguments to relations,           with a different stimulus. Training consisted of blocks
which supports Marcus et al.’s claim that infants bind              of 16 same stimuli and 16 different stimuli in a random
variables.                                                          order. An identical set of icons was used to form stimuli
   Marcus (1999) has criticized other accounts (e.g. Sei-           for both the same and different items, making it impos-
denberg & Elman 1999) of these results for includ-                  sible to correctly associate an icon or icon feature with a
ing a same/different detector within a learning mech-               response. Training continued until the pigeons reached
anism. The BRIDGES simulations do not explicitly la-                85% accuracy.
bel speech sounds as identical, rather the model assumes               The test phase consisted of intermediate stimuli
that infants can categorize speech sounds (Eimas, Sique-            that were somewhat similar to both the same and
land, Jusczyk, & Vigorito, 1971), as embodied by the                different stimuli experienced in the training phase.
type/token distinction. BRIDGES’s solution does not                 Examples of intermediate stimuli are shown in Figure 2.
hinge on a same detector. In fact, the patterns that can            These stimuli can be viewed as forming a continuum
                                                               2272

                                                                                                 the pigeons, was trained to an 85% accuracy threshold
                                                                                                 before initiating the test phase. BRIDGES reached this
                                                                                                 level of performance by discovering analogical mappings
                                                                                                 among presented stimuli and exemplars stored in mem-
                                                                                                 ory. For instance, a same stimulus aligns perfectly with
                                                                                                 same exemplars stored in memory. For example, con-
                          14-1-1                                      7-5-3-1                    sider aligning a stimulus containing 16 squares to an-
                                                                                                 other stimulus containing 16 triangles. Each triangle
                                                                                                 entity is put into correspondence with a square entity.
Figure 2: Two examples of intermediate stimuli are stim-                                         This results in a perfect feature mismatch, but parallel
uli are shown. The numerical code below each stimulus                                            connectivity is preserved. Within each type relation, the
indicates its experimental condition and is explained in                                         type triangle maps to the type square. This alignment
the main text.                                                                                   leads to attention shifting toward the type relation and
                                                                                                 away from the entities. In contrast, only 1 out of 16 type
                                                                                                 relations will exhibit parallel connectivity when aligning
between the pure same stimuli (all 16 icons identical)                                           a different stimulus with a same stimulus. Thus, it is
and the pure different stimuli (all 16 icons different)                                          straightforward for BRIDGES to discriminate between
used during the training phase. Eleven distinct con-                                             same and different stimuli in the absence of featural sup-
ditions of intermediate stimuli were used. The 11                                                port. In this regard, BRIDGES’s solution for these sim-
conditions can be characterized by their groupings of                                            ulations is the supervised learning analog to BRIDGE’s
identical icons. For example, in Figure 2, the right                                             discrimination of grammatical and ungrammatical sen-
most stimulus contains seven question marks, five                                                tences in the Marcus et al. (1999) simulations.
dominoes, three arrows, and one magnifying glass and                                                Strong support for BRIDGES’s similarity-based dis-
thus is an example of condition [7,5,3,1]. Adopting                                              covery of the same/different relation is found in its fit
this nomenclature, the eleven intermediate conditions                                            of the test phase. BRIDGES correctly orders the inter-
were [14,1,1], [8,8], [13,1,1,1], [12,1,1,1,1,1,1], [10,3,2,1],                                  mediate conditions (see Figure 3). BRIDGES correctly
[7,5,3,1], [4,4,4,4], [8,1,1,1,1,1,1,1,1], [2,2,2,2,2,2,2,2],                                    predicts the probability that pigeons respond “different”
[4,1,1,1,1,1,1,1,1,1,1,1],     [2,1,1,1,1,1,1,1,1,1,1,1,1,1,1].                                  in the intermediate conditions. Similarity-based activa-
The pigeon’s performance in these intermediate con-                                              tions are not all or none and these intermediate cases
ditions, as well BRIDGES’s predictions, are shown in                                             activate stored examplars to varying degrees, leading to
Figure 3 (with the data points ordered left to right in                                          the successful fit. For example, an intermediate stimu-
the order the conditions are introduced in the previous                                          lus containing 12 triangles and four squares is somewhat
sentence).                                                                                       analogous to a stimulus containing 16 circles — mapping
                                                                                                 the triangle type to the circle type preserves parallel con-
                           1                                                                     nectivity in 12 out of 16 relations. Along similar lines,
                          0.9
                                          Actual vs. Predicted                                   an item with two matching icons and 14 icons that are
                          0.8
                                                                                                 all different from one another better matches a pure dif-
         Average Pigeon
                            1.0
                          0.7
                          0.6
                             .8                                                                  ferent exemplar than a pure same exemplar.
                          0.5
                             .6
                             .4                                                                  Discussion
           p(different)
                          0.4
                          0.3
                             .2
                          0.2
                                    0                                  .75
                                                                                                BRIDGES learned the same/different relation and
                          0.1                  .25         .5                      1.0
                           0
                                                                                                achieved an excellent fit (R2 = .95) of the test results
                                0        0.2         0.4        0.6          0.8         1
                                                                                                involving intermediate stimuli. The simulations demon-
                                        BRIDGES p(different)
                                                                                                strate how abstract concepts can be acquired through
                                                                                                storage and analogy to concrete examples. BRIDGES’s
Figure 3: The results from Young and Wasserman’s                                                excellent fit of the intermediate conditions is a natural
                                                                                                consequence of similarity-based processing. Like natural
(1997) studies and BRIDGES’s predictions are shown.
                                                                                                categories, BRIDGES predicts relational categories have
The 11 intermediate conditions, forming a continuum                                             a graded structure.
between pure same and pure different stimuli, are de-
                                                                                                   Young and Wasserman (1997) offered an entropy ex-
scribed in the main text.                                                                       planation of their results. Pure different displays will
                                                                                                have maximum entropy (4 bits) whereas pure same dis-
BRIDGE’s Simulation Like the Marcus et al.                                                      plays have minimal entropy (0 bits). Like BRIDGES, the
(1999) simulations, we adopted a minimal approach to                                            entropy explanation provides an excellent fit of the test
stimulus representation. Each stimulus’s icon was repre-                                        results (R2 = .94). Advantages of BRIDGES’s account
sented as an entity. Each of the 16 entities participated                                       lie within its generality and ability to model learning
in a type relation as in the Marcus et al. simulations                                          data. BRIDGES can also predict additional phenom-
(see Table 1).                                                                                  ena that naturally follow from exemplar representations
   The training regimen mimicked the procedure used in                                          of categories: 1) When pigeons are transferred to new
the original study as closely as possible. BRIDGES, like                                        icons, performance remains above chance, but signifi-
                                                                                             2273

cantly declines, and 2) Increasing the discriminability of     Eimas, P.D., Siqueland, E.R., Jusczyk, P., & Vigorito, J.
stimuli improves overall performance (Young & Wasser-            (1971). Infant Speech Perception. Science, 171(3968),
man, 1997).                                                      303-306
                                                               Falkenhainer, B., Forbus, K., & Centner, D. (1989). The
                 General Discussion                              structure-mapping engine: Algorithm and examples.
By combining insights from the category learning and             Artificial Intelligence, 41, 1-63.
analogy literatures, BRIDGES provides an account of            Gentner, D (1983). Structure mapping: A theoretical
how people and animals can gain abstract understand-             framework for analogy. Cognitive Science, 7, 155-170
ings of domains based solely on experience with concrete
instances. BRIDGES’s power arises from using a no-             Gentner, D; & Markman, A.B. (1997). Structure Map-
tion of similarity informed by work in both analogy and          ping in Analogy and Similarity. American Psycholo-
category learning. Structural alignment processes allow          gist, 52(1), 45-56
BRIDGES to appreciate analogical similarities, while at-       Hahn, U., Chater, N., & Richardson, L.B. (2003). Simi-
tention shifting modifies BRIDGES notion of similarity           larity as Transformation. Cognition. 87, 1-32
over the course of learning. Integrating these mecha-
                                                               Kuehne, S.E.; Gentner, D.; and Forbus, K.D. (2003).
nisms allows BRIDGES to grasp abstract patterns by
                                                                 Modeling Infant Learning via Symbolic Structural
shifting attention to relations which drive the alignment
                                                                 Alignment. Proceedings of the Twenty-Second Annual
process.
                                                                 Conference of the Cognitive Science Society. Hillsdale,
   In the supportive simulations, BRIDGES offered an
                                                                 NJ: Lawrence Erlbaum Associates.
explanation of how infants become sensitive to abstract
grammers and how people and pigeons develop the con-           Kruschke, J.K. (1992) ALCOVE: An Exemplar-Based
cepts of same and different irrespective of a stimulus’s         Connectionist Model of Category Learning. Psycho-
features. Consistent with BRIDGES’s stance that ab-              logical Review 99(1), 22-44
stract concepts are similarity-based, the relational con-      Larkey, L.B.; & Love, B.C. (2003). CAB: Connectionist
cepts same and different displayed graded membership             Analogy Builder. Cognitive Science 27, 781-794
like natural categories.
   BRIDGES is not the first model to use analogical            Love, B.C.; Medin, D.L.; Gureckis, T.M. (2004) SUS-
alignment to support category learning. SEQL can ac-             TAIN: A Network Model Of Category Learning. Psy-
quire category structures through a process of repeated          chological Review 111(2), 309-332
abstraction of a structured category representation and        Marcus, G.F.; Vijayan, S.; Bandi Rao, S.; and Vish-
has been successfully applied to the infant grammar              ton, V.E. (1999) Rule Learning by Seven-Month-Old
learning studies considered here (Kuehne, Gentner &              Infants. Science 283,5398, 77-80
Forbus, 2003). While SEQL stresses building abstract           Marcus, G. F. (1999). Do infants learn grammar with al-
representations, abstraction in BRIDGES arises from ac-          gebra or statistics? Response to Seidenberg & Elman,
tivation of stored exemplars. More in depth comparisons          Eimas, and Negishi. Science. 284, 436-437.
between SEQL and BRIDGES are likely to recapitulate
debates in the category learning literature comparing          Medin, D.L., & Schaffer, M. (1978). Context theory of
prototype and exemplar models. Some relative strengths           classification learning.Psychological Review, 85, 207-
of BRIDGES are that it extends an existing model of cat-         238
egory learning (ALCOVE is a special case of BRIDGES)           Rosch, E. & Mervis, C.B. (1975). Family Resemblance:
and incorporates attentional mechanisms.                         Studies in the Internal Structure of Categories. Cog-
   One challenge for BRIDGES is incorporating new                nitive Psychology. 7, 573-605
relational information into its exemplar representa-           Seidenberg, M.S.,& Elman, J.L. (1999). Do Infants
tions. Although BRIDGES can learn relational con-                Learn Grammars with Algebra or Statistics? Science.
cepts, BRIDGES is not yet able to incorporate acquired           284, 5413, 433
relations directly into its exemplar representations (see
Doumas and Hummel, 2005, for an example of a predi-            Smith, J. D.,& Minda, J. P. (1998). Prototypes in the
cate discovery system).                                          mist: The early epochs of category learning.Journal of
                                                                 Experimental Psychology: Learning, Memory, & Cog-
                 Acknowledgements                                nition, 24, 1411-1436.
We thank Mike Young for providing access to his data.          Young, M.E., & Wasserman, E.A. (1997). Entropy de-
This work was supported by AFOSR grant FA9550-04-                tection by pigeons: Response to mixed visual displays
1-0226 and NSF CAREER grant 0349101 to B. C. Love.               after same-different discrimination training.Journal of
                                                                 Experimental Psychology: Animal Behavior Processes,
                       References                                23, 157-170
Doumas, L.A.A., & Hummel, J.E. (2005). A Symbolic-             Young, M.E., & Wasserman, E.A. (2001). Entropy and
   Connectionist Model of Relational Discovery. Proceed-         Variability Discrimination. Journal of Experimental
   ings of the Twenty-Seventh Annual Conference of the           Psychology: Learning, Memory and Cognition. 27(1),
   Cognitive Science Society. Hillsdale, NJ: Lawrence            278-293
   Erlbaum Associates.
                                                          2274

