UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Audio Speech Segmentation Without Language-Specific Knowledge
Permalink
https://escholarship.org/uc/item/2t93c70c
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Gold, Kevin
Scassellati, Brian
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                     Powered by the California Digital Library
                                                                       University of California

    Audio Speech Segmentation Without Language-Specific Knowledge
             Kevin Gold (kevin.gold@yale.edu) and Brian Scassellati (scaz@cs.yale.edu)
                                     Department of Computer Science, 51 Prospect Street
                                                  New Haven, CT 06520 USA
                           Abstract                               Using transcriptions of speech is convenient for the mod-
                                                                  eler, but they come at the price of assuming a “perfect”
   Speech segmentation is the problem of finding word             input processing module that can cluster and classify the
   boundaries in spoken language when the underlying vo-
   cabulary is still unknown. Here we show that a system          raw audio signal, turning a noisy signal into a flawless
   with no phonemic knowledge can find word boundaries.           symbolic representation.
   The system first subdivides an utterance by recursively           This initial classification of phonemes or syllables can
   clustering similar parts of the signal together until the
   cepstral coefficient variance is low within each new seg-      be difficult. Extensively trained neural networks can still
   ment. These segments are then used as inputs to a              perform quite poorly in classifying phonemes (Roy &
   perceptron-like algorithm that finds repeated segments         Pentland, 2002). A phoneme can be so influenced by the
   across utterances. With only a few sample utterances,          surrounding phonemes that the signal resembles a differ-
   and no previous linguistic knowledge, the system can           ent phoneme entirely; for example, the waveform of the
   find the words that were repeated across utterances and
   identify new utterances that contain those words. The          /I/ in “king” can more closely resemble that of the /u/
   findings show that the assumption of a phoneme classifi-       in “moves” than the /I/ in “bishop,” on account of the
   cation module is not necessary for a “minimum descrip-         nasality of the /N/ sound that follows (Jelinek, 1997).
   tion length” (Brent & Cartwright, 1996; de Marcken,            Professional speech recognition software solves the dif-
   1996) explanation of word segmentation.
                                                                  ficult phoneme-recognition problem by using contextual
                                                                  information to distinguish between words – for instance,
                       Introduction                               by noting that the probability of I need is much higher
                                                                  than that of I neat (Jurafsky & Martin, 2000). Such
The problems of infant speech segmentation and word
                                                                  contextual information is certainly not available to an
discovery have inspired many different modeling ap-
                                                                  infant if phoneme learning precedes word learning.
proaches, but some of the most promising have operated
under the principle of “minimum description length”                  Transcriptions can also omit important information
(MDL). Minimum description length approaches com-                 that is available from the audio signal. For instance,
bine aspects of exemplar and prototype theory to cre-             while it is a commonly accepted maxim in word seg-
ate a hierarchical language model that extends from               mentation models that the spaces we perceive between
phonemes all the way up to the phrase level (de Marcken,          words are simply an illusion, stops such as /t/ and /k/
1996; Brent & Cartwright, 1996). Essentially, a mini-             literally stop the flow of air briefly, making them natural
mum description length approach attempts to compress              delimiters. The knowledge that such consonants tend to
all the utterances it has encountered so far by adding            delimit words and syllables may be captured by adding
entries to a lexicon for any item that is repeated so often       “phonotactic constraints” to a segmentation algorithm,
that it warrants a kind of “mental shorthand.” The new            but this can obscure the difference between rules that
entry is only added if the cost of storage is less than the       must be learned and rules that follow naturally from the
cost of representing each instance of the item individu-          structure of the signal. Another cue for segmentation
ally. Shorthand can be used within the lexicon as well,           lost in phonetic annotation is syllable stress, which may
making for hierarchical compression: a phrase is repre-           play an important role in segmenting English (Jusczyk,
sented as a sequence of words, which are in turn repre-           1999; Cutler & Norris, 1988). The rule that each word
sented as a sequence of morphemes or syllables, which             in English can have at most one primary stress can do
are in turn sequences of phonemes. In MDL models,                 much of the work in segmenting child-directed speech,
word discovery is only a special case of recognizing com-         allowing easier segmentation of utterances with many
mon subsequences of input.                                        strongly stressed syllables (Yang, 2004).
   One gap in the minimum description length ap-                     Though the minimum description length approaches
proaches proposed so far is that they have all treated            proposed so far have all been demonstrated on phonetic
the segmentation problem as if it were being solved for           transcriptions, there is no reason why they cannot be
sequences of symbols (Brent, 1999). Usually, these sym-           extended all the way down to the sub-phoneme level.
bols represent transcriptions of either syllables (Brent &        The system presented here uses a minimum description
Cartwright, 1996; Brent, 1999) or the phonemes from               length approach to cluster the audio signal into self-
which the syllables are constructed (de Marcken, 1996).           similar parts. These parts are then shown to be usable
                                                             1370

to find words in utterances, assuming the existence of            logically, auditory “edge” detectors have been proposed
external cues that indicate which utterances contain a            for spectral information (Fishbach, Nelken, & Yeshurun,
target word. Since this approach works with the au-               2001), but the authors know of no studies that have at-
dio signal itself, several sources of information such as         tempted to find neurons responsive to the cepstrum or
volume, phonotactic information, and coarticulation are           its derivatives.)
naturally factored into the system’s segmentation deci-
sions. The system shows how a simple compression rule             Clustering
can take the place of multiple cue-specific rules, and sug-
                                                                  After preprocessing, an utterance is recursively clustered
gests a synthesis between MDL approaches and auditory
                                                                  as follows. First, the loudest 10ms sample of the utter-
cue-based explanations of infant word segmentation.
                                                                  ance is chosen as a seed for a new cluster. The selected
                                                                  vector of cepstral coefficients and their derivatives serves
                         Methods                                  as the first data point in the new cluster’s multivariate
Acoustic Data                                                     normal distribution. All the remaining samples of the
For our experiments, the auditory data is not pro-                utterance are treated as samples of a single multivariate
cessed in the time domain, but in the “cepstral” domain           background distribution. To ensure that the probabil-
(Schroeder, 1999). Since the audio signal can be seen as          ity density function of this distribution is always well-
the result of a source signal coming from the vocal tract         defined, only the diagonal of the covariance matrix is
convolved with the filter action of the mouth and tongue,         used.
the goal of the cepstral transformation is to extract the            A cluster is grown by tentatively adding the time slice
part of the signal corresponding to the mouth and tongue          immediately preceding it and the time slice immediately
while throwing out the variability of the individual vo-          following it to both the cluster’s distribution and the
cal tract. This is accomplished by taking the log of the          background distribution. (This ensures that the distri-
Mel-transformed frequency domain representation, then             butions are not too heavily biased toward their existing
taking another Fourier transform. Under these transfor-           states, and also results in each cluster having at least
mations, convolution in the time-domain becomes mul-              three points for calculating variance.) The probability
tiplication in the mel frequency domain, which then be-           density function (pdf) of each distribution is evaluated
comes addition by the logarithm, and the final Fourier            at both of these new points. If a time slice is determined
transform preserves this additivity while separating the          to be more likely to have been generated by the tentative
two parts of the signal. The parts of the cepstrum rele-          cluster than the background distribution, the slice per-
vant to phonetic information can then be characterized            manently remains in the new cluster and is removed from
by a feature set called the “Mel-Frequency Cepstral Co-           the background distribution. Otherwise, it is removed
efficients” (MFCCs).                                              from the cluster and remains in the background distri-
   Note that these coefficients do not represent any              bution. This process continues until the cluster ceases
language-specific features. They are a more or less ar-           to grow.
bitrary decomposition of the signal into coefficients that           This process produces the maximum likelihood clus-
could be used to reconstruct the spectral envelope that           tering of the data under two assumptions. The first is
characterizes the shape of the mouth (though the first            that the data was generated from two multivariate nor-
coefficient does correspond to overall power or volume).          mal distributions, one of which contains the loudest time
However, this representation does throw out the pitch             slice. This normality is only an approximation, but it is
and timbre information. Though we can justify this neu-           one that has proven successful in the past (Wilpon, Ra-
rologically with the finding that pitch appears to use a          biner, Lee, & Goldman, 1990). The second is that all
different neurological pathway from other aspects of lan-         examples of the louder distribution are contiguous.
guage (Baum & Pell, 1999), in truth we use the cepstral              Once this initial clustering has been performed, the
domain here mostly because automatic speech recogni-              clustering can be performed recursively on each of the
tion methods have had better success with it than not.            three new segments of speech. Should this recursion oc-
   For this study, 13 cepstral coefficients were used, a          cur indefinitely, each individual time slice would eventu-
common convention that corresponds roughly to the de-             ally receive its own cluster. Obviously, this would not
grees of freedom of the human mouth (Schroeder, 1999).            achieve any compression of the data, and the Minimal
The coefficients were estimated for 10ms intervals, using         Description Length principle (Rissanen, 1972; Grünwald,
freely available MATLAB code (Ellis, 2005).                       2005) dictates that good learning implies good compres-
   As a final, additional feature set, approximations to          sion and vice versa. Instead, a stopping criterion is re-
the derivative and second derivative of each cepstral             quired, so that the algorithm does not make useless dis-
coefficient were added, bringing the total number of              tinctions.
features to 39. The approximations used for these                    By the Minimal Description Length principle, an ideal
“delta” and “double-delta” coefficients were taken from           stopping criterion would determine the cost, in bits, of
the Sphinx speech recognition system (Walker et al.,              specifying a new multivariate distribution and all of the
2004): the “delta” feature for cepstral coefficient Cj at         data points belonging to it versus the cost of specify-
time i is given by the difference Cj (i + 2) − Cj (i − 2),        ing all of those time slices in an already defined distri-
and the double-delta coefficient is given by the formula          bution. (Bits are here being used in their information-
(Cj (i + 3) − Cj (i − 1)) − (Cj (i + 1) − Cj (i − 3)). (Neuro-    theoretic capacity; it does not limit the argument to ma-
                                                              1371

chine learning.) Since good compression implies good fu-        Learning across utterances
ture learning (Grünwald, 2005), the strategy that takes
fewer bits to specify would be better for future language       The clustering method outlined above segments an in-
learning.                                                       dividual utterance into a tree structure based on self-
                                                                similarity. Later utterances are divided into their own
   Determining the true cost in bits of a new multivari-        trees, but these need to be matched to earlier utterances
ate normal distribution is difficult. While it is possible      to find repeated words. Matching currently occurs at
to choose an arbitrary representation for the distribu-         the leaves of the recursion tree, corresponding roughly
tions and count the bits they use, this is not necessar-        to the phoneme level.
ily the most efficient encoding, which should take into            To find segments that are similar within two different
account the probabilities of each distribution’s parame-        utterances, pairwise comparisons are made between seg-
ters. Specifically, the desirable mathematical properties       ments in the two utterances to find matches for the new
of minimal description length representations are only          clusters among the old ones. This is done by taking the
guaranteed to hold when the cost of a given distribution        mean of a new cluster to be a sample point, and com-
D, in bits, is equal to 1/P (D), where P (D) is the prob-       puting the probability density function of each cluster in
ability of that distribution. The total cost of the encod-      the reference utterance for that point. The distribution
ing is then the sum of 1/P (Di ) for all distributions Di       with the highest probability density function is the most
plus the sum of 1/PD(j) (Sj ) for each sample Sj , where        likely match. This match is then compared to the null
PD(j) (Sj ) is the probability a sample Sj according to its     hypothesis that the new cluster matches no previously
assigned distribution D(j). (Even this “two-part encod-         established point, which is represented by a multivari-
ing” is not necessarily optimal; see (Grünwald, 2005) for      ate distribution of all data from both utterances. If the
details.) Though it is easy to calculate this second part       probability of the old cluster exceeds that of this null
of the equation, the cost of encoding a sample given a          hypothesis, the new cluster is classified as an instance
distribution, it is hard to determine the probabilities of      of the old one. (A lexicon independent of all utterances
the distribution parameters themselves.                         would have been more elegant than pairwise comparisons
                                                                between utterances, but this would have brought up en-
   Instead, the algorithm takes a shortcut here and uses        coding representation issues we do not wish to deal with
a variance threshold. Specifically, when the variance in        here.)
the first cepstral coefficient (volume) for a given segment        In the case of learning a specific word for an object,
is below a manually defined threshold, recursion stops.         associative learning can take place between the stimulus
The reason that this approximates an MDL criterion is           of the object and certain combinations of speech clusters.
that with a low variance, each individual segment can           To achieve this associative learning, the present imple-
be encoded using fewer bits. By varying the threshold           mentation used Winnow (Littlestone, 1988), an online
at which a new distribution is generated, the algorithm         learning algorithm that performs well when the num-
can mimic a higher or lower cost in bits of generating a        ber of input variables is large. Winnow is an online
new distribution, assuming that this cost is roughly uni-       perceptron-like algorithm that attaches linear weights to
form for most real-life distributions. Limiting the model       nonnegative input stimuli and “fires” if the sum of the
to a single parameter, volume variance, rather than a           weighted inputs passes a threshold. If a false positive
function of all 39 variances, is a tradeoff that reduces        occurs, the weights of all positive inputs are halved; if a
the number of model parameters that the modeler must            false negative occurs, the weights of all positive inputs
adjust in exchange for giving up some small amount of           are doubled. Since Winnow is an online algorithm, it
expressiveness. Volume variance is the most useful of           does not require multiple passes through the data. It is
the 39 features from a practical point of view because          only necessary to process each utterance once.
volume changes from phoneme to phoneme and from syl-               The Winnow weights can be interpreted as the
lable to syllable. Vowels are louder than the consonants        strength of association between the segments found by
that delimit them, and syllables can be stressed or un-         the segmentation algorithm and some external cue that
stressed. The overall approach is thus similar in spirit        the system determines to be a referent for the sentence.
to previous minimal description length approaches to the        For example, we assume that when the system hears
word segmentation problem (de Marcken, 1996; Brent &            “This is a dog” that somebody is directing the system’s
Cartwright, 1996; Brent, 1999), but it attempts to find         attention toward an actual dog, or at least is clearly
a minimal representation of the audio signal, instead of        talking about a dog, so that the segments found in the
a string of symbols. In the long term, existing entries         sentence can be associated with that external stimulus.
in the lexicon for distribution parameters would reduce         When Winnow fails to predict the referent of an utter-
the encoding length of most new incoming audio data,            ance (e.g., somebody is clearly talking about a dog but
with only unusual sounds requiring full encoding. The           the utterance was not identified as containing a word
means of these distributions in the lexicon could serve         about a dog), weights between the target concept and all
as prototypes for phonemes, and also serve as symbols           segments contained in the utterance are boosted. Like-
in an MDL-based lexicon for words.                              wise, if Winnow expects a certain referent given the seg-
                                                                ments in the sentence, but there is no external confir-
   See Appendix A for transcriptions of the output pro-         mation (e.g., the concept of “dog” was excited but the
duced by the self-similarity clustering step.                   speaker was clearly talking about something else), the
                                                            1372

weights to the excited segments are halved. For each tar-                  Target    Guess     Target    Guess
get concept, there is an instance of Winnow attempting                     bAl       bAl       kiz       i
to learn the word for it. (We set aside for more knowl-                    bUk       bUk       pEn       maI
edgeable scholars the question of if and how an infant                     kar       kar       fon       maIn
decides a concept needs a word.)                                           tSEir     DIs...eIr Su        Su
   In the results that follow, we abstract away the ex-                    dOgi      gi        spun      spu
ternal referents, and assume that the system has access
to reliable external cues that indicate which sentences        Table 1: Transcriptions of the “best guesses” generated
contain a word related to a target referent. This means        for each target word by Winnow.
utterances are labeled only as positive or negative ex-
amples for concepts and the words that correspond to
them.                                                                                             Recall    Precision
   Note that though this approach uses “utterances” as               Recursive clustering          40%        50%
a basis for learning, it does not require that the system            Non-recursive clustering      20%        33%
be able to segment sentences from one another. The as-               Hidden Markov Model           60%        32%
sumed paradigm here is that of examples of speech sepa-
rated by relatively long gaps. If the speech separated by      Table 2: Recall and precision for each of the methods
these gaps includes more than one sentence, this does not
                                                               implemented.
matter much, except that very long utterances will end
up conveying very little useful information. At any rate,
the emphasis here on “utterances” is more an artifact of
programming convenience than any theoretical justifica-        erate the speech signal. Table 1 shows the transcription
tion. The method should be extendable to a real-time           of the system’s output.
system that acts on a stream of input.                            To test the system’s ability to detect words in new ut-
   The system currently has no principled method of rep-       terances, the Winnow-trained word detectors were then
resenting cluster order; during production, it simply uses     employed on utterances that either contained the target
the order in which the reference clusters were first en-       word but were new to the system, or contained none of
countered. In principle, lexicon entries would contain         the target words. Each target word was contained in one
such information, but in this experiment this function-        test sentence, and five sentences that did not contain any
ality simply wasn’t implemented.                               target words were tested for each target word.
                                                                  Table 2 shows recognition results for three variants of
              Experimental Results                             the algorithm. The recursive variant is the one described
Thirty training utterances were recorded from a single         above. In the non-recursive variant, the clustering step
speaker at 22050 Hz. Ten target words for segmentation         is performed only once, so that the sentence is divided
were contained in three utterances each. For each target       into only three segments. The non-recursive method was
word, the utterances containing the word were treated          implemented to check whether fine distinctions in sound
as positive examples for Winnow, while the other utter-        were actually necessary for recognition, or if the over-
ances were negative examples. The list of utterances is        all vowel sound of the target word would be sufficient
given in Appendix A.                                           for classification; as the results show, the recursive de-
                                                               composition does aid recognition. Finally, the hidden
   Winnow initialized weights to all segments to 1, and
                                                               Markov model (HMM) implementation used the clusters
used a threshold of 1 instead of the standard n/2 to in-
                                                               generated from the self-similarity step to generate hid-
crease the usefulness of negative examples. A volume
                                                               den Markov models (Jurafsky & Martin, 2000) for each
variance threshold of 50 was used for segmentation re-
                                                               statement, then used the model that best described all
cursion.
                                                               three positive examples as a model for the target word.
   The three positive examples were each presented to the
                                                               The added complexity of performing expectation max-
system twice, while the twenty-seven negative examples
                                                               imization and the Viterbi algorithm did not appear to
were each presented once. The goal was to determine            afford much benefit over the simpler maximum likelihood
whether the system could learn to segment the target
                                                               matching described above.
words with a relatively small number of utterances, as a
child might.
   To probe the system’s representations, “best guesses”
                                                                                      Discussion
were generated for each target word by concatenating           The present work combines several previous approaches
cepstral sequences corresponding to the clusters with          to automated word segmentation. First, the clustering
the highest weight until their combined weight passed          method presented here to find segments is somewhat
the Winnow threshold. The cepstral sequences were not          similar to a method used by Tim Oates’ system PE-
generated randomly from the cluster distributions, but         RUSE to find recurring segments of audio (Oates, 2002),
preserved from the first utterance in which the cluster        though PERUSE was not an online algorithm. The min-
appeared. These cepstral sequences were then trans-            imum description length literature, on the other hand,
formed into spectral envelopes imposed over a white            has always used phonemes as its atomic units, and built
noise source, using software from (Ellis, 2005) to regen-      syllables, words and phrases from these (de Marcken,
                                                          1373

1996; Brent & Cartwright, 1996). Finally, the Winnow            one, suggesting that a binary tree, rather than the cur-
algorithm is here used to simulate association between          rent ternary structure, may be more appropriate for such
words and external concepts. Though no previously pro-          learning.
posed algorithm has used Winnow specifically, others               Self-similarity segmentation tends to split stop
have shown that mutual information between phonemes             phonemes down the middle, where the airflow is stopped.
and visual cues can aid segmentation (Roy & Pentland,           A human listener can clearly make out the phoneme both
2002).                                                          before and after the break because of coarticulation ef-
   The Winnow algorithm here acts as a somewhat                 fects, but only one side of the segmentation can be tech-
temporary measure that takes the place of a more                nically correct. The fact that the self-similarity algo-
MDL-based word learning approach. In theory, exter-             rithm was successful at learning words with consonants
nal meaning should be representable in an MDL fash-             that were divided in this way suggests that some conso-
ion, as should the higher levels of organization beyond         nants may be better thought of as auditory “edges,” a
phonemes (de Marcken, 1996). However, no MDL word               point suggested by quantal theory (Stevens, 1989).
segmentation algorithm to date has been an “online al-             Comparison with prior word segmentation methods is
gorithm,” as the major MDL approaches to date have              difficult because no previous method solved quite the
required multiple passes through the data (de Marcken,          same problem. PERUSE (Oates, 2002) reported suc-
1996; Brent & Cartwright, 1996). The Winnow per-                cessful segmentation of 65% of the most frequent words
ceptron algorithm is interesting because it is an online        it encountered, but it used an expectation maximiza-
algorithm that works very quickly to perform the nec-           tion procedure that required iterating repeatedly over
essary associations, and it provably functions well when        the entire data set, making it unlikely to scale. CELL
irrelevant features abound (Littlestone, 1988). Its lack        (Roy & Pentland, 2002), an online system, reported 54%
of a hidden layer also makes it more neurally plausible         segmentation accuracy on its highest-ranked word can-
than most neural networks, since the backpropagation            didates, compared to our algorithm’s 40% segmentation
algorithm is not required.                                      accuracy for our ten target words, but CELL used an ex-
   The minimum description length approach to word              tensively trained and hand-modified phoneme classifier
segmentation is attractive because it can take into ac-         as input to its segmentation module. To our knowledge,
count many disparate psychological findings and theories        no previous work has both avoided using a phoneme clas-
(Brent, 1999). Though infants have been interpreted             sifier and used a single-pass algorithm for segmentation.
as remembering phoneme transition probabilities (Saf-              The present data set is small, and is not entirely
fran, Aslin, & Newport, 1996), the same results may             representative of a broad range of words and circum-
be explained by positing the formation of lexicon en-           stances. The utterances were only produced by one
tries for the more common phoneme pairs. The existence          speaker, tended to have the target word in the final
of “episodic” memories for words (Goldinger, 1998) can          position, and only included one multisyllabic word and
be explained as the brain’s attempt to retain all possi-        no vowel-initial words in the production and recognition
ble information for compression; while a prototype ef-          tests. Future work will address these concerns; mean-
fect would result from encoding the mean of many clus-          while, we hope that Appendix A will convince the reader
tered words or sounds, individual instances should still        that even the samples used contained a fair amount of
be retrievable if it only requires a few more bits to spec-     diversity.
ify an instance – though if memory is scarce, the brain            Another question that would be worthwhile to address
may maintain a low error rate by discarding these few           is whether this system will reproduce some of the com-
bits. Unusual words or phrases may be more cheaply              mon mistakes or biases of children learning new words.
encoded in their entirety; hence the episodic memory for        For example, if unstressed syllables appear first in a sen-
the particular prosodic affect that accompanies Rosebud         tence’s final word, they may be incorrectly grouped with
or Stella (Goldinger, 1998).                                    the linking words and left unparsed until late in the re-
   One of the original hopes of this project was that           cursion. If the target word begins with a strong syllable,
the recursion tree might also provide a natural struc-          however, the remaining weak syllable is left relatively
ture for higher level MDL learning, with syllables clus-        high in the parse tree. A learning algorithm that takes
tered naturally into words by sound similarity and coar-        tree distance into account should therefore display the
ticulation effects. For instance, the self-similarity al-       bias of children for learning words that begin with strong
gorithm clusters “night rate” as [naIt]ret, separating          syllables more easily than those that begin with weak syl-
“night” from “rate” and then subdividing “rate” into            lables, as has been observed in children learning English
its constituent sounds, while “nitrate” is clustered as         at 7 12 months (Jusczyk, 1999).
naI[tre]t. The transcriptions in Appendix A reveal that            Though attempting to explain infants’ word segmen-
obtaining higher structure from the auditory signal is           tation abilities with one grand theory of everything may
often not so simple, as words can be spread across sev-          be an impossible task, a minimal description length ap-
eral subtrees. Still, in 25 of the 35 utterances, all parts      proach at all levels, from sentence to sub-phoneme, is
of the noun were clustered at the same level of recur-           appealing in its elegance. Implementing it and deter-
sion, which would mean Winnow learning on the higher             mining what effects it does and does not explain may
nodes of the tree may have proven useful. Some interior          be the best way to create a theory of word segmentation
nodes contained two related subtrees and an unrelated            that is itself both concise and general.
                                                            1374

          Appendix A: Transcriptions of                                                      References
                       Segmentations                               Baum, S. R., & Pell, M. D. (1999). The neural bases of
                                                                           prosody: Insights from lesion studies and neuroimag-
The following are phonetic transcriptions of the initial seg-              ing. Aphasiology, 13 (8), 581–608.
mentations that the system performs on the 35 utterances in         Brent, M. R. (1999). Speech segmentation and word discov-
the experiment before Winnow is applied, using only intra-                 ery: a computational perspective. Trends in Cognitive
utterance self-similarity measures. Straight brackets indicate             Sciences, 3 (8), 294–301.
the loudest part of the utterance, or top level of recursion;       Brent, M. R., & Cartwright, T. A. (1996). Distributional
parentheses indicate deeper levels of recursion. In places                 regularity and phonotactic constraints are useful for
where a phoneme sounds is split, the corresponding symbol                  segmentation. Cognition, 61, 93–125.
is repeated on either side of the split. All phonetic judg-         Cutler, A., & Norris, D. (1988). The role of strong syllables
ments were made post hoc for transcription only; the system                in segmentation for lexical access. Journal of Experi-
segmented audio without a phoneme classifier.                              mental Psychology, 14 (1), 113–121.
                                                                    de Marcken, C. G. (1996). Unsupervised language acquisition.
   DIs(s (Iz @) b)[bAl].                                                   Unpublished doctoral dissertation, MIT.
   y@ wAn2 p[pleI wI (D@ b)bAl]?                                    Ellis, D. (2005). PLP and RASTA (and MFCC, and
   tra(j) R@ (kA)tS D@ b[bAl]!                                             inversion) in Matlab using melfcc.m and invmelfcc.m.
   (test) I(z) [DæR @](bAl)?                                               http://www.ee.columbia.edu/ dpwe/resources/matlab/rastamat/.
   DIs iz @ b[bU]k.
   s(i)? Its @ b[bU]k!                                              Fishbach, A., Nelken, I., & Yeshurun, Y. (2001). Audi-
   y@ wAn[n@ r(id) D@ (bU)k?                                               tory edge detection: a neural model for physiologi-
   (test) Iz [Dæt @] b(bU)k?                                               cal and psychoacoustical responses to amplitude tran-
   Dæts @ (k)[kar]r.                                                       sients. Journal of Neurophysiology, 85, 2303–2323.
   s(i) D@ k[kar] ro(l)?                                            Goldinger, S. D. (1998). Echoes of echoes? An episodic
   [yæ], It(s @) k(ar)r!                                                   theory of lexical access. Psychological Review, 105 (2),
   (test) z (D æR @) k[kar]r?                                              251–279.
   DIs(s (I)z @ (tS))[eIr]r.                                        Grünwald, P. (2005). A tutorial introduction to the Min-
   pi(p)pl s(sIR) (In) tS[eIr]z.                                           imum Description Length principle. In P. Grünwald,
   w[eIr]z (yor (tS))eIr?                                                  I. J. Myung, & M. Pitt (Eds.), Advances in minimal de-
   (test) z [D æR @] (tS)eIr?                                              scription length: Theory and applications. MIT Press.
   Its @ d[dOgi]!                                                   Jelinek, F. (1997). Statistical methods for speech recognition.
   Dæt(s (r))(aIt), @ d[dOg]i!                                             MIT Press.
   y@ wan@ (pEt (D@ d))[dO]gi?                                      Jurafsky, D., & Martin, J. H. (2000). Speech and natural
   (test) s (D æR @) d[dO]gi?                                              language processing. Upper Saddle River, NJ: Prentice
   D[owz @r maI] k(ki)z.                                                   Hall.
   (y@ wan@) p[pleI wI] Dow(z k(i)z?                                Jusczyk, P. W. (1999). How infants begin to extract words
   aI (S)[r h æ]v @ lOt @ (k(i)z).                                         from speech. Trends in Cognitive Sciences, 3 (9), 323–
   (test) (ar) D[owz maI k](i)z?                                           328.
   DAts (maI) p[E]n.                                                Littlestone, N. (1988). Learning quickly when irrelevant
   ((si) D@) p[En]?                                                        attributes abound: a new linear-threshold algorithm.
   tr(aI) dr[raIN] s(@m)T(IN) (wI)T (DAP) (pE)n.                           Machine learning, 2 (4), 285–318.
   (test) Iz [D æR @] pEn?                                          Oates, T. (2002). PERUSE: An unsupervised algorithm for
   D æ(tS) (maI) f[o]n.                                                    finding recurring patterns in time series. In Proceedings
   y@ wAn@ (c (A))[Al] s2m(w@n On) m(aI) f(o)n?                            of the international conference on data mining (pp.
   (yæ, yu) k (æn)(pleI wI)T (maI) f[o]n.                                  330–337). IEEE.
   (test) Iz (Dæ) m[maI] f(o)n?                                     Rissanen, J. (1972). Modeling by shortest data description.
   [Dæ](ts 2 S)u.                                                          Automatica, 14, 465–471.
   s(i) [D@ Su]u?                                                   Roy, D. K., & Pentland, A. P. (2002). Learning words from
   [yæ], It(s (@) S)(u)u!                                                  sights and sounds: a computational model. Cognitive
                                                                           Science, 26, 113–146.
   (test) Iz Dæt @ S[u]?                                            Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996). Sta-
   [DIs Is]z @ (s)p(pun).                                                  tistical learning by 8-month-old infants. Science, 274,
   s(i)? (yu) it [TIN]z (wIT) @ (s)p(pun).                                 1926–1929.
   Dæt(s(r))[aI]... s(p)(pu)n.                                     Schroeder, M. R. (1999). Computer speech. Springer.
   (test) Iz [DæR 2] sp(pu)n?                                      Stevens, K. N. (1989). On the quantal nature of speech.
   (test) Iz (DæR En) E[r]p(le(in))?                                       Journal of Phonetics, 17, 3–45.
   (test) Iz D(DæR @) b[ARl]?                                       Walker, W., Lamere, P., Kwok, P., Raj, B., Singh, R., Gou-
   (test) z [DæR @] kU(k(i))?                                              vea, E., et al. (2004, Nov). Sphinx-4: A flexible open
   (test) Iz [D æR @] h(or)s?                                              source framework for speech recognition (Tech. Rep.
   (test) [Iz D æR @] (k(IRi))?                                            No. TR-2004-139). Sun Microsystems.
                                                                    Wilpon, J. G., Rabiner, L. R., Lee, C.-H., & Goldman, E. R.
                    Acknowledgments                                        (1990). Automatic recognition of keywords in uncon-
                                                                           strained speech using hidden Markov models. IEEE
The authors would like to thank the anonymous reviewers for                Transactions on Acoustics, Speech, and Signal Process-
their helpful and extensive feedback. Support for this work                ing, 38 (11), 1870–1878.
was provided by a National Science Foundation CAREER                Yang, C. (2004). Universal Grammar, statistics or both?
award (#0238334). Some parts of the architecture used in                   Trends in Cognitive Sciences, 8 (10), 451–456.
this work was constructed under NSF grants #0205542 (ITR:
A Framework for Rapid Development of Reliable Robotics
Software) and #0209122 (ITR: Dance, a Programming Lan-
guage for the Control of Humanoid Robots) and from the
DARPA CALO/SRI project.
                                                               1375

