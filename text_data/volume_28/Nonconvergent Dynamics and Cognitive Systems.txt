UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Nonconvergent Dynamics and Cognitive Systems
Permalink
https://escholarship.org/uc/item/1222d7z2
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Harter, Derek
Kozma, Robert
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                     Nonconvergent Dynamics and Cognitive Systems
                            Derek Harter (Derek Harter@TAMU-Commerce.edu)
                                  Department of Computer Science; Texas A&M University
                                                  Commerce, TX 75429 USA
                                      Robert Kozma (rkozma@memphis.edu)
                                  Department of Computer Science; University of Memphis
                                                   Memphis, TN 38152 USA
                           Abstract                              tant piece in the study of intelligent behavior. However,
                                                                 since the rejection of behaviorism and the rise of AI and
   The conditions and mechanisms for producing general           cognitive science, we have not only been interested in the
   intelligent action in agents are the focus of intensive
   study of cognitive science. Many positions have been          necessary behavioral characteristics that let us detect in-
   proposed, including symbolic and connectionist view-          telligence, but also in the types of internal mechanisms
   points. New points of view are beginning to emerge,           and processes that might be necessary and sufficient to
   such as embodied and dynamical cognition, but have            produce such observed behaviors. The opening up of the
   not yet been fully solidified into a single comprehensive     study of intelligence to include internal mechanisms has
   position. In this article we present one such new view-
   point that emphasizes the importance of nonconvergent         allowed us to attack the problem both from the outside
   dynamics to the production of general intelligent be-         in, and from the inside out.
   havior. This approach represents a fourth generation             Once we begin studying the possible mechanisms of
   of connectionist thought, and is informed from new re-
   sults in neuroscience and computational neurodynamics.        intelligence, it is natural to ask if there is any sim-
   We formulate the necessary and sufficient conditions for      plest set or category of mechanism that is both suffi-
   the production of intelligent behavior in this approach       cient and necessary for the production of general intel-
   to cognition and introduce one such model capable of          ligent behavior. Given that there are different levels of
   meeting these conditions.                                     intelligence, are different mechanisms needed to achieve
                                                                 these different levels, or can the same mechanisms be
                      Introduction                               used, only expanded to do more? Previous attempts to
                                                                 define such conditions have focused on things like the
What are the mechanisms by which biological organisms,
                                                                 ability of formal logic like symbol manipulations to per-
including human beings, produce general intelligent ac-
                                                                 form tasks we usually think of as intelligent, like playing
tions in order to survive, reproduce and thrive in their
                                                                 chess or planning a sequence of tasks to perform a goal
environment? This, in some form, is the basic ques-
                                                                 [Newell, 1980, Newell, 1990]. Another major movement
tions that lies at the heart of cognitive science. Vari-
                                                                 has focused on the power of simple non-linear process-
ous ideas have been put forward as possible answers to
                                                                 ing units to remember, recognize and complete patterns
this question. Metaphors of cognition have been inspired
                                                                 [Werbos, 1974, Rumelhart et al., 1986].
from the advanced technologies of the times, including
hydraulic, phone switchboard and computer metaphors                 Another way of discovering the constraints of intelli-
[Von Neumann, 1958]. Inspiration has been sought from            gence, besides psychological experimentation, is to di-
the realms of formal logic as the means of general intelli-      rectly observe the workings of the only known systems
gent action. Others have looked to abstracted models of          that are capable of general intelligent behavior, biologi-
how neural tissue functions as possibly holding the key          cal brains. These types of direct measuring of neurolog-
insights to the production of intelligent behavior.              ical functioning through such methods as EEG record-
   Intelligent behavior really lies on a continuum, from         ings and brain imaging techniques have provided us with
simple tropic behaviors of single celled organisms to tool       valuable further constraints on the possible sufficient and
and language use of human beings. We could imagine               necessary dynamics involved in cognition. Such under-
defining levels or categories of intelligence, each with         standing led directly to early connectionist modeling re-
an appropriate Turing-like behavioral test that could be         sults, and is leading us even further in new directions.
used to determine inclusion of a system in a category.              Biological brains are awash in complex, nonconvergent
Such tests would necessarily not be of language use, but         dynamics. Such complex dynamics have usually been
could test things like memory capacity (short, and long          abstracted away in connectionist models, with the as-
term), opportunistic vs. goal orientation and problem            sumption that they are not necessary to the production
solving in unique situations. Such tests would give us           of intelligent behavior. However, new ideas in nonlinear
the ability to state the necessary capacities and behav-         dynamical systems theories, both inside and outside of
iors that need to be present to include a system in a            cognitive science, have begun to understand the possible
certain level of intelligence.                                   important roles that aperiodic dynamics, such as chaos,
   Being able to define and detect levels of intelligence        may play in self-organizing systems.
through outward behavioral characteristics is an impor-             Some researchers in dynamical cognition and neuro-
                                                             1446

dynamics have speculated on the possibilities that more        prototypical member of a category. Probabilistic mod-
complex, chaotic like dynamics may play in the role            els show that thinking of intelligent behavior purely in
of adaptive behavior [Skarda and Freeman, 1987,                terms of logical deduction and manipulation of symbols
Freeman, 1999,                       Freeman et al., 2000,     is probably too limiting a viewpoint, and thus brings into
Kozma and Freeman, 1999, Kozma and Freeman, 2000,              question the sufficiency of purely formal logical symbol
Kozma and Freeman, 2001]. Chaotic dynamics have                manipulation. Moreover, probabilistic models are still
been observed in the formation of perceptual states of the     somewhat deficient, from a neurological standpoint, of
olfactory sense in rabbits [Skarda and Freeman, 1987].         bridging the gap between high-level cognitive processes
Skarda and Freeman have speculated that chaos may              and low level neuronal dynamics.
play a fundamental role in the formation of perceptual
meanings. Chaos provides the right blend of stability          Connectionist Systems
and flexibility needed by the system. Essentially, Skarda      A connectionist view of cognition provides an alternative
and Freeman believe that the normal background                 theory of mind to the symbolic approach. The connec-
activity of neural systems is a chaotic state. In the          tionist approach to cognition has existed for as long as
perceptual systems, input from the sensors perturbs            the symbolic approach. However, symbolic viewpoints of
the neuronal ensembles from the chaotic background,            cognition have dominated the field of cognitive science
and the result is that the system transitions into a new       until a resurgence of interest in connectionist models in
attractor that represents the meaning of the sensory           the mid ’80s.
input, given the context of the state of the organism and         The connectionist approach differs from the symbolic
its environment. But the normal chaotic background             paradigm in almost all major dimensions. Connection-
state is not like noise. Noise cannot be easily stopped        ist models offer a subsymbolic paradigm, where repre-
and started, whereas chaos can essentially switch              sentations are built from the changing contributions of
immediately from one attractor to another. This type           processing units that represent features below the nor-
of dynamics may be a key property in the flexible              mal level of human symbolic features. Connectionist
production of behavior in biological organisms.                models emphasize parallel processing, while symbolic
                                                               systems tend to process information in a serial fash-
   Theories and Conditions of Cognition                        ion. Connectionist representations are distributed over
Symbolic Systems                                               many units, while cognitivist symbols are static local-
                                                               ized structures. Connectionist models offer many at-
Symbolic systems are often equated with the machine
                                                               tractive features when compared with standard symbolic
metaphor of mind. In this viewpoint of cognition, the
                                                               approaches. They have a level of biological plausibility
brain is seen in some sense as a computer. The physical
                                                               absent in symbolic models that allows for easier visual-
brain represents the hardware of the system, and the
                                                               ization of how brains might process information. Paral-
mind represents the software. The machine metaphor is
                                                               lel distributed representations are robust, and flexible.
a very attractive position for many reasons. It explains
                                                               They allow for pattern completion and generalization
how the mind connects with and controls the body, the
                                                               performance comparable to biological organisms. They
old mind-body problem, in a way that does not resort to
                                                               are capable of adaptive learning. In short, connectionist
a form of dualism.
                                                               models are an attractive alternative model of cognition.
   The symbolic approach works well as a model of cogni-
                                                                  The connectionist hypothesis might be stated as:
tion, and is capable of modeling many impressive exam-
                                                               large-scale parallelism of (relatively simple) non-linear
ples of intelligent behavior in AI. However, challenges
                                                               processing units doing local processing and producing
to this viewpoint of cognition have appeared, both as
                                                               distributed representations are necessary and sufficient
practical criticisms of the performance of such systems
                                                               to the production of general intelligent behavior.
and more philosophical challenges to the physical-symbol
system hypothesis. For example, many tasks that seem           First Generation Clark [Clark, 2001] categorizes
almost effortless for biological brains, such as walking,      modern connectionism into three generations. The
moving, grasping, etc., have proved much more difficult        first-generation of connectionism, that began with
for symbolic systems to address than more constrained          the perceptron and the work of the cyberneticists
(but seemingly more impressive) domains such as play-          [Rosenblatt, 1958, McCulloch and Pitts, 1943], was re-
ing chess or diagnosing complicated diseases. However,         vived in the mid ’80s with the PDP research groups
symbolic systems that use probabilistic declarative struc-     work (among others) on parallel distributed processing
tures, and are often referred to as gradient models, seem      [Rumelhart et al., 1986]. First-generation connectionist
to have recently shown that such systems can behave            systems were typified by a multi-layer architecture (usu-
more flexibly. For example recent successes at long-           ally composed of two or three layers) with strictly feed-
range navigation in the DARPA grand challenge contests         forward connections. Backpropogation learning rules
demonstrate such systems can show impressive levels of         have been especially successful in the proliferation of
adaptation and flexibility. Such probabilistic models are      these models [Werbos, 1974]. Such architectures are very
motivated by psychological findings that membership in         familiar to practitioners of AI and Neural Network re-
human categories is often not black and white. Peo-            search. These connectionist models of cognition are very
ple have ideas on the degree to which a certain exam-          attractive and important for many reasons. They are bi-
ple belongs in a category, and they have notions of the        ologically plausible models with some of the flexibility of
                                                           1447

pattern-recognition and generalization exhibited by bio-         dynamics are necessary for general intelligent behavior.
logical organisms.
                                                                 Nonconvergent Dynamics for Perception
Second Generation Second-generation connection-
ism began to appear in the early ’90s. Second-generation         In their influential paper, Skarda and Freeman
connectionism extends first-generation networks to begin         [Skarda and Freeman, 1987] argued that chaos, as an
to deal effectively with dynamic spatio-temporal events.         emergent property of intrinsically unstable neural
First-generation networks displayed no real capacity to          masses, is very important to brain dynamics. In ex-
deal with time or order in the environment. Second-              periments carried out on the olfactory system of trained
generation connectionist systems added recurrent con-            rabbits, Freeman was able to demonstrate the presence
nections to the networks in order to expand these capa-          of chaotic dynamics in EEG recordings and mathemat-
bilities [Elman, 1990, Elman, 1991]. Recurrent connec-           ical models. In these experiments, Freeman and his as-
tions are connections that connect later layers in the net-      sociates conditioned rabbits to recognize smells, and to
work with earlier layers. So second-generation connec-           respond with particular behaviors for particular smells
tionist networks are no longer strictly feed-forward, they       (e.g. to lick or chew). They performed EEG recordings
contain recurrent connections. The addition of recurrent         of the activity in the olfactory bulb, before and after
connections allows for previous states of the network to         training for the smells.
affect decisions about the current input. In essence, re-           The EEG recordings revealed that in fact, chaotic dy-
current connections provide a type of short term memory          namics (as shown by the observed strange attractors)
that allows for the categorization of patterns extended          represented the normal state when the animal was at-
in time across the inputs of the network. This ability to        tentive, in the absence of a stimulus. These patterns
deal with spatio-temporally extended patterns in time is         underwent a dramatic (nonlinear) transition when a fa-
an important addition to the capabilities of connectionist       miliar stimulus was presented and the animal displayed
systems.                                                         recognition of a previously stored memory (through a
Third Generation Third-generation connectionism                  behavioral response). The pattern of activity changed,
is the most recent extension of the connectionist                very rapidly, in response to the stimulus in both space
paradigm. This generation of models is typified by even          and time. The new dynamical pattern was much more
more complex dynamic and time involving properties.              regular and ordered (very much like a limit cycle, though
These models use more complex, and biologically in-              still chaotic of a low dimensional order). The spatial pat-
spired architectures, along with various recurrent and           tern of this activity represented a well defined structure
hard-coded connections. So, for example, rather than             that was unique for each type of odor that was percep-
the simple multi-layer structure of first and second gener-      tually significant to the animal (e.g. conditioned to rec-
ations, third-generation networks may have many areas            ognize). After recognition, all of the EEG waves are fir-
that represent and reflect architectures and subsystems          ing in phase, with a common frequency (which Freeman
of biological brains. Because of the increasing emphasis         called the carrier wave). The pattern of recognition is en-
on dynamic and time properties, third-generation con-            coded in the heights (amplitude modulations) of the in-
nectionism has also been called dynamic connectionism.           dividual areas. The amplitude patterns, though regular,
                                                                 are not exact limit cycles and exhibit low dimensional
     Nonlinear Dynamics and Cognitive                            chaos. In other words, different learned stimuli were
                                                                 stored as a spatio-temporal pattern of neural activity,
       Systems: The Fourth Generation                            and the strange attractor characteristic of the attention
Biological brains exhibit aperiodic oscillations with a          state (before recognition) was replace by a new, more or-
much more rich dynamical behavior than fixed-point               dered attractor related to the recognition process. Each
and limit-cycle approximation allows. Early connec-              (strange) attractor was thus shown to be linked to the
tionist systems captured some of the flavor of neuronal          behavior the system settles into when it is under the
functioning, but abstracted away much of this rich dy-           influence of a particular familiar input odorant.
namical behavior in favor of simple fixed-point dynam-              Freeman suggests that “an act of perception consists of
ics [Hopfield, 1982, Grossberg, 1980, Kohonen, 1972,             an explosive leap of the dynamic system from the basin of
Anderson et al., 1977]. Second and third generation sys-         one (high dimensional, in the attentive state) chaotic at-
tems recapture some of the more complex dynamics be-             tractor to another (low dimensional state of recognition)
cause of recurrent connections and specialized architec-         [Freeman, 1991]. These results suggest that the brain
tures, but many are still parameterized to ultimately set-       maintains many chaotic attractors, one for each odorant
tle down to fixed-point attractors. The question of what         an animal or human being can discriminate. Freeman
use, if any, aperiodic dynamics may play in cognition            and Skarda speculate on many reasons why these chaotic
has largely been ignored, or its possible significance un-       dynamics may be advantageous for perceptual catego-
realized. The exploration of nonconvergent dynamics in           rization. For one, chaotic activity continually produces
cognitive processes may constitute the fourth generation         novel activity patterns which can provide a source of
of connectionist thought in its evolution towards captur-        flexibility in the individual. But since chaos is a ordered
ing more of the dynamics and functioning of biological           state, such flexibility is under control.
brains. In this section we will argue that, far from be-            As Kelso remarks, inherent fluctuations continuously
ing unnecessary noise of no use in cognition, aperiodic          probe the system, allowing it to feel its stability and pro-
                                                            1448

viding opportunities to discover new patterns. Another
advantage of chaos is that it allows for very rapid switch-
ing between attractors, which random activity is not able
to do. Excellent examples of synchronization and de-
synchronization of motor behavior between coupled indi-
viduals/oscillators are given in [Kelso, 1995], where sen-
sory/cognitive coupling provided the modulatory effect
that induced the transitions between metastable states.
Sufficient Conditions of Nonconvergent
Dynamical Viewpoint
Aperiodic dynamics play a significant role in the organi-
zation of perceptual mechanisms in biological organisms.
The presence of self-organizing critical states have also
been detected in other brain systems. These observa-
tions have led to the hypothesis that such dynamics are
ubiquitous in brains, and are necessary to the flexible
organization of biological behavior. Symbolic systems
provide little insight into how they may be connected            Figure 1: Agent morphology (bottom left) and environ-
with an environment and generatively construct knowl-           mental setup for hippocampal simulations.
edge about the world they experience. Looking at sym-
bolic systems as models of biological cognition, they are
also silent on why such aperiodic dynamics appear in bi-        agent, we demonstrate the formation of cognitive maps
ological brains. Classical connectionist systems have yet       as the agent explores the environment.
to explore the uses of aperiodic dynamics in memory and            In this experiment, we used the Khepera virtual en-
action.                                                         vironment simulator [Michel, 1996]. Figure 1 (bottom
   These observations of the possible significance of non-      left) shows the morphology of the Khepera agent. The
convergent dynamics in brains has led us to speculate on        Khepera robot is a simple agent that contains 8 infra-red
th sufficient conditions they suggest. Specifically:            and 8 light sensors. It has two independently controlled
                                                                wheels that allow it to move forward, backward, and
• Complex, nonconvergent dynamics are sufficient to the         turn left and right in place. The environment for this
   production of general intelligent behavior.                  experiment is shown in figure 1. In the environment we
                                                                place 8 light sources, which will be used as salient envi-
• An embodied system with appropriate environmen-
                                                                ronmental locations (i.e. they can be thought of as good
   tal/sensory coupling and internal structural systems
                                                                food sources for the agent in the environment). The light
   for handling the “what”, “where”, “why” and “how”
                                                                sources are detectable to the agent at a distance, and the
   functions of the agent are sufficient to the production
                                                                range where the food source is detectable is indicated in
   of general intelligent behavior.
                                                                Figure 1. In addition to the 8 salient environmental loca-
• The exploitation of nonconvergent dynamics by and             tions, there are 4 landmarks. The landmarks are always
   within such an appropriately embodied system are             detectable to the agent, and it knows the distance and
   necessary and sufficient for producing general intel-        direction to each of the 4 landmarks as part of its sensory
   ligent behavior.                                             information.
                                                                   The architecture of the simulated hippocampus is
   In essence we have proposed two conditions for the           shown in Figure 2. The portions of the architec-
production of general intelligent behavior. Aperiodic           ture that form the cognitive map of the environment
dynamics characteristic of critical states are necessary        are simulated by a KA-III [Harter and Kozma, 2004,
for the flexible self-organization of memory and behav-         Harter and Kozma, 2005]. These are the CA1, CA2 and
ior. The dynamics of the brain are strongly coupled             CA3 areas, and are based on biological evidence of the
with their environment. The interaction of brain dynam-         structure of the biological hippocampus. Each of the
ics with the environmental system produces behavior.            CA areas contains an 8x8 array of oscillatory units (for
We will explore these issues further in the next section,       a total of 64 units in each CA region). Each CA area is
where we describe one such model of cognition.                  connected to the other 2. The interconnection of these 3
                                                                CA regions via inhibitory and excitatory feedback forms
             Hippocampal Simulation                             a KA-III unit. The connections between CA regions will
                                                                be changed via Hebbian modification.
Experimental Architecture                                          Orientation beacons are fed into the hippocampal sim-
In this section we give an example application of noncon-       ulation through the DG region (Figure 2, left). The DG
vergent dynamics using Freeman’s K-sets in order to sim-        again contains an 8x8 matrix of KA-II units. Orientation
ulate the formation of cognitive maps in the hippocam-          signals from the 4 landmarks are fed into the DG units.
pus using aperiodic attractors. Using an autonomous             Each of the 4 landmarks has 8 units associated with the
                                                            1449

Figure 2: Architecture of the computational model of
hippocampal simulations
direction to the landmark, and 8 units associated with
the distance. Directions are broken into 8 cardinal units,      Figure 3: Example of AM Pattern formed in the CA3
North, NorthEast, East, SouthEast, South, SouthWest,           hippocampal region. In this figure we show a pattern
West and NorthWest. Units are sensitive to the direc-           from two different locations within an environmentally
tion of a particular landmark, though we use a graded           salient region (Top and Bottom). We show AM patterns
response with a normal distribution, instead of a simple 1      from environment regions E4 and E7. Similar AM pat-
unit is active and the others being inactive []. Similarly     terns are organized and exhibited when the agent is in
there are 8 cardinal distance values VeryClose, Close,         the same environmental region.
MediumClose, Medium, MediumFar, Far, VeryFar, Dis-
tant. Again a graded response with normal distribution
is applied to the units. The DG area connects with the         steps in our simulations. In our simulation 10 time steps
CA3 area, and the connections between these areas are          approximates 1 second of real world running time, there-
also subject to Hebbian modification.                          fore the totaled simulated time of an experiment is 1000
                                                               seconds.
Method
We use two types of learning in the simu-                      Results
lation,    Hebbian modification and habituation
[Kozma and Freeman, 2001].         Hebbian modification        Here we examine the amplitude modulation (AM) pat-
only occurs when the robot is within a certain range           terns produced by the hippocampal simulation. Figure
of a light source. Therefore the light sources provide a       3 shows examples of the AM patterns formed in the CA3
certain valence signal that acts as a stimulus to learn        hippocampal matrix for 2 different locations within en-
environmentally salient locations. When the robot is           vironmental regions 2, 4, 6 and 8 respectively. The AM
not within proximity to a light source, no reinforcement       patterns shown are from the CA3 hippocampal region.
signal is produced. During these times habituation of          This region has 8x8 units, for a total of 64 time series.
the stimulus occurs. This has the effect of lessening the      We measure the standard deviation of each of the 64
response of the simulated hippocampus to unimportant           units for a 50ms time window, and plot the results as an
regions in the environment.                                    8x8 contour map of the deviations of each of the units in
   The expected effect of this stimulation is to form 2        the area. The AM pattern contour plots, therefore, give
distinct types of dynamical patterns in the CA regions.        you an idea of which units are more highly stimulated
When the agent is out of range of an environmentally           (higher amplitudes in their activity) and which are less
salient location, the dynamics should be in the high-          so. As Figure 3 shows, the AM patterns are more sim-
dimensional chaotic state, receptive to input but not in-      ilar to those produced from locations within the same
dicative of recognizing a salient event. When in range         environmental region.
of a light source, the system should transition to a low           As a more complete test of the formation of unique AM
dimensional attractor, indicative of recognition of the        patterns, we feed the robot with input from randomly
important location. Further, the spatial amplitude mod-        selected locations, within the environmental food areas.
ulation patterns in the CA regions upon such recognition       AM patterns were collected for the randomly selected
should form 8 unique patterns, one for each of the rec-        regions and compared to one another by calculating the
ognized regions.                                               euclidean distance between each pattern. This testing
   The agent is allowed to roam in the environment, using      showed that, in fact, the patterns produced within a re-
a low level mechanisms to produce efficient, but random        gion are consistently more similar to one another, than
wandering. The agent roams for some time, 10,000 time          those produced in another environmental region.
                                                           1450

                      Conclusion                                [Hopfield, 1982] Hopfield, J. J. (1982). Neuronal net-
The hippocampal simulation described here forms dis-              works and physical systems with emergent collective
tinct AM patterns for the 8 salient environmental re-             computational abilities. Proceedings of the National
                                                                  Academy of Science, 81:3058–3092.
gions. These patterns are aperiodic spatio-temporal ac-
tivity in the CA regions. The characteristic activity           [Kelso, 1995] Kelso, J. A. S. (1995). Dynamic Patterns:
peaks in the AM patterns are examples of so called ’place         The Self-organization of Brain and Behavior. The
                                                                  MIT Press, Cambridge, MA.
cell’ formation. Here we see high activity among certain
regions correlated with being in a particular environmen-       [Kohonen, 1972] Kohonen, T. (1972). Correlation matix
tal location. For example, looking at the AM pattern for          memories. IEEE Transaction on Computers, C-
                                                                  21:353–359.
location 7 (Figure 3, right) you notice 3 peaks of activity     [Kozma and Freeman, 1999] Kozma, R. and Freeman,
among the units in the region. It is possible to interpret        W. J. (1999). A possible mechanism for intermittent
these peaks as being correlated with environmental lo-            oscillations in the KIII model of dynamic memories
cations, and therefore typical examples of the place cell.        - the case study of olfaction. In Proceedings IJCNN
   The self-organization of spatio-temporal patterns in           1999, pages 52–57.
nonlinear systems are essential to cognitive mechanisms         [Kozma and Freeman, 2000] Kozma, R. and Freeman,
in biological brains. We need to better understand how            W. J. (2000).        Encoding and recall of noisy
such mechanisms operate in order to build better models           data as chaotic spatio-temporal memory patterns
of cognition and smarter autonomous agents. This pa-              in the style of the brains. In Proceedings of the
per has demonstrated one such self-organizational mech-           IEEE/INNS/ENNS International Joint Conference
anism for the creation of AM patterns in a cognitive map          on Neural Networks (IJCNN’00), pages 5033–5038,
of an agents environment.                                         Como, Italy.
                                                                [Kozma and Freeman, 2001] Kozma, R. and Freeman,
                 Acknowledgments                                  W. J. (2001). Chaotic resonance - methods and ap-
This work was supported by NASA Intelligent Systems               plications for robust classification of noisy and vari-
Research Grant NCC-2-1244.                                        able patterns. International Journal of Bifurcation
                                                                  and Chaos, 11(6):1607–1629.
                      References                                [McCulloch and Pitts, 1943] McCulloch, W. S. and
[Anderson et al., 1977] Anderson, J. A., Silverstein,             Pitts, W. (1943). A logical calculus of the ideas im-
   J. W., Ritz, S. A., and Jones, R. S. (1977). Distinc-          manent in nervous activity. Bulletin of Mathematical
   tive features, categorical perception, and probability         Biophysics, 5:115–133.
   learning: Some applications of a neural model. Psy-          [Michel, 1996] Michel, O. (1996). Khepera simulator
   chological Review, 84:413–451.
                                                                  package version 2.0. Downloaded from WWW at
[Clark, 2001] Clark, A. (2001). Mindware: An Introduc-            http://wwwi3s.unice.fr/ om/khep-sim.html. Freeware
   tion to the Philosophy of Cognitive Science. Oxford            mobile robot simulator written at the University of
   University Press, Oxford, NY.                                  Nice Sophia-Antipolis.
[Elman, 1990] Elman, J. L. (1990). Finding structure in         [Newell, 1980] Newell, A. (1980). Physical symbol sys-
   time. Cognitive Science, 14:179–211.                           tems. Cognitive Science, 4:135–183.
[Elman, 1991] Elman, J. L. (1991). Distributed repre-           [Newell, 1990] Newell, A. (1990). Unified Theories of
   sentations, simple recurrent networks, and grammati-           Cognition. Harvard University Press, Cambridge, MA.
   cal structure. Machine Learning, 7:195–225.
                                                                [Rosenblatt, 1958] Rosenblatt, F. (1958). The percep-
[Freeman, 1991] Freeman, W. J. (1991). The physiology             tron: A probabilistic model for information storage
   of perception. Scientific American, 264(2):78–85.              and organization in the brain. Psychological Review,
[Freeman, 1999] Freeman, W. J. (1999). How Brains                 65:386–408.
   Make Up Their Minds. Weidenfeld & Nicolson, Lon-             [Rumelhart et al., 1986] Rumelhart, D. E., McClelland,
   don.                                                           J. L., and The PDP Research Group (1986). Par-
[Freeman et al., 2000] Freeman, W. J., Kozma, R., and             allel Distributed Processing: Explorations in the Mi-
   Werbos, P. J. (2000). Biocomplexity: Adaptive behav-           crostructure of Cognition. MIT Press, Cambridge,
   ior in complex stochastic dynamical systems. BioSys-           MA.
   tems, 59:109–123.                                            [Skarda and Freeman, 1987] Skarda, C. A. and Free-
[Grossberg, 1980] Grossberg, S. (1980). How does a                man, W. J. (1987). How brains make chaos in or-
   brain build a cognitive code? Psychological Review,            der to make sense of the world. Behavioral and Brain
   87:1–51.                                                       Sciences, 10:161–195.
[Harter and Kozma, 2004] Harter, D. and Kozma, R.               [Von Neumann, 1958] Von Neumann, J. (1958). The
   (2004). Aperiodic dynamics and the self-organization           Computer and the Brain. Yale University Press, New
   of cognitive maps in autonomous agents. In Proceed-            Haven, CT.
   ings of 17th International Florida Artificial Intelli-       [Werbos, 1974] Werbos, P. J. (1974). Beyond Regres-
   gence Research Society Conference (FLAIRS), pages              sion: New Tools for Prediction and Analysis in the Be-
   424–429, Miami Beach, FL.                                      havioral Sciences. Ph.D. thesis, Harvard, Cambridge,
[Harter and Kozma, 2005] Harter, D. and Kozma, R.                 MA.
   (2005).    Chaotic neurodynamics for autonomous
   agents. IEEE Transactions on Neural Networks. in
   press.
                                                            1451

