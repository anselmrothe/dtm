UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Grammar Induction Profits from Representative Stimulus Sampling
Permalink
https://escholarship.org/uc/item/59d6w832
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Charter, Nick
Poletiek, Fenna H.
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

               Grammar Induction Profits from Representative Stimulus Sampling
                                           Fenna H. Poletiek (poletiek@fsw.leidenuniv.nl)
                                        Department of Psychology, Leiden University, pobox 9555
                                                            Leiden, The Netherlands
                                                   Nick Chater (n.chater@ucl.ac.uk)
                                 Department of Psychology, University College London, Gower Street,
                                                            London, WC1E6BT, UK
                               Abstract                                   statistical associative properties of these sequences (Saffran,
                                                                          Aslin & Newport, 1996). Recently, another kind of
   Sensitivity to distributional characteristics of sequential            regularity in sequential information has been proposed to
   linguistic and nonlinguistic stimuli, have been shown to play a        affect segmentation: i.e. differences in variability between
   role in learning the underlying structure of these stimuli. A
                                                                          adjacent elements. For example, the word ‘walking’ consists
   growing body of experimental and computational research
   with (artificial) grammars suggests that learners are sensitive        of the highly variable part: (walk) and the invariant part
   to various distributional characteristics of their environment         ‘ing’. This difference in variability has been proposed to
   (Kuhl, 2004; Onnis, Monaghan, Richmond & Chater, 2005;                 serve as a cue for finding the boarders of linguistic units
   Rohde & Plaut, 1999). We propose that, at a higher level,              such as words (Gomez, 2002; Monaghan, Onnis,
   statistical characteristics of the full sample of stimuli on           Christiansen & Chater, submitted). Finally, semantic
   which learning is based, also affects learning. We provide a           regularities and associations are proposed to play a role in
   statistical model that accounts for such an effect, and                learning grammatical regularities (Rohde & Plaut, 1999):
   experimental data with the Artificial Grammar Learning                 some words are much more associated than others, for
   (AGL) methodology, showing that learners also are sensitive
                                                                          semantic reasons. E.g., he walks is more frequent than ‘he
   to distributional characteristics of a full sample of exemplars.
                                                                          city’, suggesting permissible and impermissible word
   Keywords: Artificial grammar learning; statistical learning;           (category) order.
   frequency distribution                                                    Besides the statistical characteristics regarding local
                                                                          transitions in a structured sequence,                statistical
                           Introduction                                   characteristics of the full stimulus sample of exemplars with
                                                                          which a learner is trained, may be informative for grammar
People seem naturally sensitive to structural characteristics
                                                                          induction as well (Poletiek, 2006). Consider a grammar G
of their environment, and they are able to use this
                                                                          producing exemplars varying in length. A random output of
knowledge adaptively. Such learning occasionally occurs
                                                                          such a grammar would be a sample containing short and
implicitly and without instruction. For example, learning
                                                                          long exemplars exemplifying all kinds of sequential rules
motor patterns like tying shoe laces and riding a bicycle,
                                                                          specified by the grammar, but not all rules in equal number.
and several aspects of social behavior involve implicit
                                                                          Indeed, such output would contain more exemplars
associative learning. However, learning the rules of
                                                                          exemplifying typical and highly frequent rules in the
language by children is probably the most striking example
                                                                          grammar, (for example, highly associated adjacent or non
of acquiring structure knowledge without apparent explicit
                                                                          adjacent elements) than exemplars with exceptional rules
awareness. Though it is currently debated to what extent an
                                                                          (Chater & Vitányi, submitted). Also, in a general case,
innate predisposition is responsible for this achievement or a
                                                                          short exemplars would occur more often than long ones.
general inductive learning capability, a growing number of
                                                                          The resulting frequency distribution of this random output
studies suggests that humans have a powerful and adaptive
                                                                          sample of G, may provide information to a learner for
sensitivity to the statistical properties of environmental
                                                                          inducing G. Thus, in addition to the distributional features
stimuli (Kuhl, 2004; Gomez & Gerken, 2000; Redington,
                                                                          (e.g., sounds, syllables and words in natural language)
Chater & Finch, 1998).
                                                                          within exemplars, the learner may benefit from
   In particular, studies on implicit sequence learning have
                                                                          distributional characteristics between exemplars of a full
revealed that statistical patterns can be picked up and used
                                                                          input sample (Poletiek, 2006).
in subsequent usage of the system. For example,
                                                                             In natural language, these high level distributional
distributional characteristics in linguistic materials have
                                                                          characteristics of the linguistic input are obvious. Some
been suggested to support syntactical category learning
                                                                          grammatical constructions are much more frequent than
(Onnis, Monaghan, Richmond, & Chater, 2005; Mintz,
                                                                          others. For example, sentences with three (levels of) self
2002). Infant studies suggest that babies segment a stream
                                                                          embedded relative clauses are rare as compared to sentences
of sounds (artificial words and syllables), on the basis of
                                                                     1968

with no self embedding or sentences with the sequence:             Gallego, 1997; Perruchet & Pacteau, 1990), but local
noun-verb-object, which occur often in every day spoken            transitional probabilities (Poletiek & Wolters, submitted)
language. If short sentences, and sentences with typical           and variability transitions have also been shown to be
rules and transitions, indeed occur more often in the output       involved in AGL (Onnis et al., 2004).
of a given language then we may expect this kind of                   We hypothesize that the statistical properties of the whole
exemplars to be overrepresented in input samples directed at       input set of stimuli contribute to performance in AGL. In
children.                                                          particular, the differential occurrences are a useful cue to the
   Studies on child directed speech have indeed shown that         learner of the grammar. In the following, this effect is
the sample of utterances a child is faced with systematically      accounted for. We first present the formal model specifying
differs from adult speech. Child directed speech (CDS)             the probabilities of each unique exemplar to be generated by
indeed includes more short sentences and typical sentences,        the grammar. This model allows deriving the frequency
and fewer complex sentences and subordinate clauses. Also,         distribution of a random output of a typical Finite State
it contains more exactly repeated sentences (Snow, 1972;           grammar used in AGL. Second, experimental data are
Philips, 1973; Pine, 1994). Whether these differences              presented that compare an AGL learning condition with
between child and adult directed speech in natural language        equally distributed exemplars, to a learning condition with
is functional for natural language learning and in what            exemplars unequally distributed according to their
sense, is still under debate (Gallaway & Richards, 1994).          probabilities to be generated by the grammar.
We propose that the frequency variations between different
kinds of exemplars in a random output sample generated by
a grammar, may not be vain but informative in the learning        The Probability Distribution of Exemplars of G
process.                                                          The probability of an exemplar to be generated by a
   In the present study, we propose an account for and a test      grammar can be calculated as the product of the path
of the learner’s sensitivity to higher order statistical           probabilities it ‘follows’ through the grammar. In Figure 1,
characteristic of the stimulus input. We use the Artificial        the scheme of grammar G (Meulemans & van der Linden,
Grammar Learning paradigm to test the hypothesis that the          1997) is displayed, with the path probabilities added (see
statistical properties of an input set are facilitative to the     also Poletiek, 2006).
learning. Specifically, we propose that when the unique
exemplars of a sample are distributed in accordance with
their probability to be generated by the grammar, learning is                                                                V 0.34
facilitated.
                                                                                                                                        OUT > 0.34
                                                                                              V 0.5                R 0.5
                                                                                        1                  4                  7
                                                                                               X 0.5
                                                                              M 0.5                          X 0.5               M 0.34
Artificial Grammar Learning                                           IN <
                                                                                        M 0.34                       R 0.34
                                                                                                                                        OUT > 1
In Reber’s (1967) now classic experimental paradigm of                      0    T 0.34 2      R 0.34      5                  8
Artificial Grammar Learning (AGL), implicit induction of                                                             T 0.34
                                                                                        V 0.34
sequential structure knowledge has been evidenced. In the                      V 0.5               M 0.5     V 0.5               X 0.34
first phase of the standard task, participants are presented                            3      X 0.5       6      T 0.5       9
                                                                                                                                        OUT > 0.34
with a number of exemplars from an artificial Finite State
grammar (a Markov grammar), without being informed                                                                          R 0.34
about the grammatical system. Next, participants are
informed that the exemplars satisfied a rule system. In the              Figure 1: Finite State Grammar G used in previous
second phase of the task, they categorize new sequences as          (Meulemans & van der Linden, 1997) and the present AGL
correct or incorrect according to the grammar. Typically,                                              study.
participants perform better than chance, though they are
unable to tell what exactly they learned. This is often            The values represent the probabilities that a path is ‘taken’
interpreted as evidence for implicit learning of the grammar;      when starting from the state it issues from. In Figure 1,
although authors disagree about what knowledge is                  these probabilities are unbiased. That is, all paths issuing
precisely induced. Better than chance performance in AGL,          from the same state are equally probable. The probability of
may either be explained by learning the rules of the               an exemplar to be produced by G, is the product of these
grammar, or by (e.g., Redington & Chater, 1996), mere              path probabilities. For example, the exemplar MVRM’s
encoding of local statistical patterns in the sequences.           probability to be generated by G is p(MVRM|G) =
   Statistical learning approaches of grammar induction in         .5x.5x.5x.34 = .0416
AGL propose that participants learn multiple kinds of                 Notice that the value p(exemplar|G) varies according to
regularities within the exemplars, and that they endorse new       two dimensions: the average probabilities of the paths it
strings that exhibit those regularities at test. Participants      takes and the length of the exemplars. Indeed, as a string is
might learn the frequencies of bigrams in a training set and       shorter, and therefore the product of the path probabilities
endorse new strings that exhibit those bigrams (Perruchet &        contains less probabilities to be multiplied, the product
                                                                   increases. The probabilities of the unique exemplars of G
                                                              1969

represent their frequency distribution in a random output of       strings. Their task was to remember them as well as
G: high p-value exemplars will be generated proportionally         possible. The order of presentations of the hundred strings
more often than low p-value (rare) exemplars (Chater &             was randomized. A group of four strings was shown for
Vitányi, submitted).                                               ten seconds. Afterwards, the participants were encouraged
   Notice that the p’s nicely model the characteristics of         to write down the strings, from memory, to help
child directed speech. Child directed speech is characterized      memorizing. The strings were shown again for three
by short utterances and simple typical grammatical rules           seconds and after a blank of two seconds a new set of
(high probability transitions), corresponding in our model to      strings appeared.
high p exemplars.                                                      At the beginning of the test phase, the participants were
   In the following study, we test whether presenting              told that there were rules determining the sequence of
exemplars in accordance with their frequency distribution in       letters in the strings they just tried to memorize.
a random output of the grammar, helps to induce this               Participants were further told that they would see new
grammar.                                                           strings, some of which followed these rules, while others
                                                                   did not. These strings would appear one by one, during a
                        Experiment                                 period of four seconds, followed by a blank of three
One group of participants in an artificial grammar learning        seconds. Their task was to classify each string as correct or
task was exposed to a learning set of exemplars of G (Figure       incorrect according to the rules of the learning phase. A
1) distributed in accordance with their probabilities to be        response form was provided, which they could use to
generated by the grammar. Another group was exposed to             indicate their answers. All groups received the same test
the same unique exemplars, all presented an equal number           items and the same test instructions.
of times: i.e. in a ‘flat’ frequency distribution. We
hypothesize that the distributional information in the             Results
stimulus set of the first group is used by the learner as a cue
for making sense of the underlying rules. Presumably, it           The mean number of correct categorizations was 15.3
allows the learner to separate ‘basic’ rules or most typical       (48%) (N=12; sd=3.8) for the participants trained with an
rules in G from rare, exceptional complex paths. This              equal distribution. Participants trained with an unequally
variability, we suggest, supports the inductive learning           distributed learning set of exemplars was 20.1(63%)
process by suggesting priorities in rules learning. Hence,         (N=12; sd=1.2). A t-test for independent samples (equal
higher performance is expected in the unequal frequencies          variances not assumed) was significant in the expected
than in the equal frequencies group.                               direction (t= -4.1;df=13.3; p=.001).
Method
                                                                                              Discussion
Participants 24 students of Leiden University participated         The participants trained with exemplars, unequally
in the experiment on a voluntary basis.                             distributed in frequencies according to their probabilities to
                                                                    be produced in a random generation of the grammar, learned
Materials A sample of 34 unique exemplars from G was                better than participants trained with the same unique
generated. These 34 exemplars were presented about 100              exemplars of G distributed equally. The effect was large.
times in total during training. In one condition, each unique       This result is in line with our hypothesis that learners exploit
exemplar was presented 3 times (the equal frequencies               the distributional characteristics of unique exemplars in the
condition), in the other condition, each exemplar was               learning input to induce the underlying structure. The
presented one or more times (varying from one to seven              frequency distribution of occurrence of exemplars they are
times) depending on its p-value. The appendix displays the          faced with, serves as a facilitative cue to make sense of the
training items, their p-value in G (p(exemplar|G)), and their       system producing the exemplars, as we predicted. What
frequency of occurrence in the training set under both              cognitive mechanism may underlie this effect of high order
conditions. In the equal frequencies condition, the total           statistical properties? In what sense is the frequency
number of stimuli at training sums up to 102, being a plural        distribution facilitative? Two links with previous findings
of 3 (see Appendix).                                                are explored.
   The test set was made of 32 strings, half of which were             Possibly, the G-representative distribution helps the
grammatical and half (16) ungrammatical.                            participant to learn fragments, i.e. bigrams. In other words,
                                                                    higher order statistical characteristics may be helpful to
Procedure Participants were run in groups of four to six.           learn lower order characteristics. Indeed, if participants
The stimuli were displayed on a video screen. Participants          proceed by learning distributional information about
were randomly assigned to the learning conditions (12 to            bigrams during training, then a distribution of exemplars
the Equal frequencies condition; 12 to the Unequal                  that is valid for the full language that is naturally generated
frequencies condition). The instructions were in line with          by the grammar, will also give more valid distributional
the implicit learning instructions in a standard AGL                information about the occurrence of the fragments in the full
procedure (Reber, 1976). Participants were told they were           output of the grammar. This was shown in a simulation
participating in a memory experiment and would see letter           study (Poletiek, 2006) in which the fragment knowledge of
                                                                    two learners were compared; one trained with a flat and
                                                               1970

another with a grammar-representative distribution of               grammaticality judgments task, the memory of every
exemplars. Hence, if the learning strategy is fragment based,       individual item was of no advantage.
then the unequal frequency distribution of the learning set            Pushing this line of reasoning a bit further, a relation may
provides the learner with more valid information about the          be sketched between the memorize task at training, the
occurrence of fragments in the grammar, which in turn can           grammaticality judgments task at test, and the stimulus
be expected to help for recognizing new stimuli satisfying          distribution. Unequal frequencies (rather than equal
the structure (Poletiek & Wolters, submitted).                      frequencies) conditions may specifically facilitate rule
   Another possible perspective on the present frequency            induction, if the unequal distribution models the grammar’s
distribution effect, relates to the recent proposal stressing       output, but not necessarily affect memorization (recall or
the importance of variability within the structured stimuli on      recognition) performance. Suppose that the learner learns to
learning regularities (Onnis et al., 2004). In this proposal,       discriminate between grammatical and ungrammatical items
differences in variability of both adjacent and non-adjacent        by building an approximate probabilistic model of the
elements in exemplars of the language have been shown to
                                                                    underlying distribution. We do not need to make any
help the learner to associate elements, and segment streams
                                                                    particular assumptions about the nature of this
of elements, into new unities. It seems that the differences in
frequencies and variance of consecutive elements in a               approximation -- it might be that the model is based on
stimulus input play an important role in structure induction.       induced rules, or bigrams, or transitional probabilities or
   Our results suggest that variability may play a role at a        information of any other type. This probabilistic model will
higher level as well:        Differences in frequencies of          be likely to be a good approximation to the true distribution,
occurrence between stimuli make it possible to differentially       if the frequencies of the stimuli correspond to their relative
strengthen sequential rules, rather than learn all rules            probabilities according to the underlying generating process
equally well without any priorities. Variability in                 (the Markov grammar). By contrast, to the extent that the
frequencies of occurrence of stimuli may tune the learner to        items are atypical, the underlying probability distribution
hierarchical learning. Indeed, if the frequently occurring          should be difficult to learn (for relevant formal analysis of
exemplars of the structure are simple and more typical for          typicality and learnability, see Vitányi & Li, 2000). In
the system than low frequent ones, then the basic                   particular, then, if items are repeated evenly rather than
grammatical constructions may be very thoroughly acquired           according to the generating Markov distribution, we might
due to their frequent presentation. Oppositely, more                expect learning of the probability distribution to be
exceptional rules exemplified in less frequently seen stimuli,      impaired.
may be mastered more superficially and acquired in a later             A different pattern of predictions arises, however, if we
stage of exposure. Variability, thus, may play a rather             assume that learning is purely determined by memory for
fundamental role at several levels of processing the input of       the individual items seen during training. Indeed, mere
structured sequential materials.                                    repetition of stimulus items during memorization, has been
   Though we could verify the predicted main effect of              shown to facilitate recollection in early memory research
frequency distribution in the present AGL study, a                  (Ebbinghaus, 1913), or as suggested by studies about
surprising observation was the poor performance by the
                                                                    presentation time effects (Roberts, 1972; Waugh, 1967).
participants in the condition with a flat frequency
                                                                    Hence, assuming rote memory during training, we may
distribution. We explore a number of explanations. First, the
low performance in the condition in which participants saw          expect either equal performance in both distribution
each exemplars repeated equally often may reflect a                 conditions (if we assume the process to be linear) or better
possible negative effect of the lack of variability. In other       performance in the equal distribution condition (if we
words, not only may variability in input have a positive            assume the process to be convex) on a pure recollection or
effect on learning, lack of variability may hamper the              recognition task. Of course, the implicit grammar learning
inductive learning process. Recent data from our lab                paradigm is interested in structure learning rather than
suggest that lack of variability may be more detrimental for        memory performance. Therefore, learners are tested on their
a learner than one may intuitively expect: participants             knowledge of the grammar by means of a categorization
presented with a sample of exemplars of a grammar                   task, yet after having been instructed to memorize the items
(potentially generating strings from differing lengths) all         at training (Reber, 1976).
having the same length, unexpectedly showed no learning.               In sum, the poor performance on the grammaticality
   A second tentative explanation is that the instruction to        judgments task in the equal frequencies condition may be
memorize the exemplars, though facilitating the recognition         related to interference between the task carried out at
of common rules and patterns of the grammar between                 training and the task carried out at test. A stimulus
exemplars in the unequal frequencies condition, has focused         distribution that is helpful for memorization may not be for
attention on the unique characteristics of individual               expressing grammar knowledge. Our research currently
exemplars equal frequencies condition, deviating attention          investigates this idea further.
from what the exemplars have in common. Thus, perhaps                  In conclusion, distributional sample characteristics of
these participants actually memorized very well individual          structured input, seems to affect structure learning in a
items, but this might have interfered with picking up               positive way. This is in line with learners’ sensitivity to
implicitly the structure common to all of them. Since the           lower order statistical regularities, which have been amply
participants were tested on completely new items and a              documented in the literature. Also, it catches the observation
                                                               1971

in natural language acquisition, that young language                 knowledge? Journal of Experimental Psychology:
learners are exposed more often to very typical and short            General, 119, 264-275
linguistic input in the period in which they learn the             Philips, J. R. (1973). Syntax and vocabulary of mothers’
language. In addition, the present study points at the               speech to young children: age and sex comparisons. Child
relevancy of simple experimentation with artificial stimulus         Development, 44, 182-185.
materials starting from parsimonious assumptions, to               Pine, J. M. (1994). The language of primary caregivers. In
understand our sensitivity to sample characteristics of              Gallaway, C.,& Richards, B.J. (Eds.) Input and
environmental stimuli, and how we exploit it to extract              interaction in language acquisition. Cambridge: CUP
useful structure knowledge.                                        Poletiek, F.H. (2006). Representative sampling in an
                                                                     artificial grammar learning task. In P.Juslin, & K.Fiedler
                    Acknowledgments                                  (Eds). Information sampling and adaptive cognition (pp.
                                                                     440-455). Cambridge: Cambridge University Press.
We would like to thank Gordon Brown for his input on the
                                                                   Poletiek, F.H., and Wolters, G. (submitted). A model for
relation between repetition and performance in rote
                                                                     grammaticality and chunk associativeness in Artificial
memory. Correspondence can be sent to Fenna Poletiek
                                                                     Grammar Learning.
poletiek@fsw.leidenuniv.nl
                                                                   Reber, AS (1967). Implicit learning of artificial grammars.
                                                                     Journal of Verbal Learning and Verbal Behavior, 6, 855-
                         References                                  863.
Chater, N.& Vitanyí, P.(submitted). A simplicity principle         Reber, A.S. (1976). Implicit learning of synthetic languages:
   for language acquisition. Re-evaluating what can be               The role of instructional set. Journal of Experimental
   learned from positive evidence.                                   Psychology: Human Learning and Memory, 2, 88-94.
Ebbinghaus, H. (1885). Über das Gedächtnis. Leipzig:               Redington, M. & Chater, N. (1996). Transfer in artificial
   Dunker. (Translation by H. Ruyer and C.E Bussenius                grammar learning: A reevaluation. Journal of
   (1913). Memory. New York: Teachers College)                       Experimental Psychology: General, 125, 123-138.
Gallaway, C., & Richards, B.J. (Eds.) (1994) Input and             Redington, M., Chater, N.,& Finch, (1998). Distributional
   interaction in language acquisition. Cambridge:                   information: a powerful cue for acquiring syntactic
   Cambridge University Press.                                       categories. Cognitive Science, 22, 425-269.
Gomez, R.L. (2002). Variability and detection of invariant         Roberts, W.A. (1972) Free recall of word lists varying in
   structure. Psychological Science, 13, 431-436                     length and rate of presentation: a test of total-time
Gómez, R.L. & Gerken, L.A. (2000). Artificial language               hypotheses. Journal of Experimental Psychology, 92,
   learning and language acquisition. Trends in Cognitive            365-372.
   Sciences, 4, 178-186.                                           Rohde, D.L.T., & Plaut, D.C. (1999). Language acquisition
Kuhl, P. K. (2004). Early language acquisition: Cracking the         in the absence of explicit negative evidence: how
   speech code. Nature Reviews: Neuroscience, 5, 831-843.            important is starting small? Cognition 72, 67-109.
Meulemans, T., & van der Linden, M. (1997). Associative            Saffran, J.R., Aslin, R.N., & Newport, E.L. (1996).
   chunk strength in artificial grammar learning. Journal of         Statistical learning by 8-month-old infants. Science, 274,
   Experimental Psychology: Learning, Memory and                     1926-1928.
   Cognition, 23 , 1007-1028.                                      Snow, C.E. (1972). Mothers’ speech to children learning
Mintz, T.H. (2002). Category induction from distributional           language. Child Development, 43, 549-65.
   cues in an artificial language. Memory & Cognition, 30,         Vitányi, P. M. B., & Li, M. (2000). Minimum Description
   678-686.                                                          Length Induction, Bayesianism, and Kolmogorov
Monaghan, P., Onnis, L., Christiansen, M., & Chater. N.              Complexity, IEEE Transactions in Information Theory,
   (submitted). The importance of being variable: Learning           IT-46, 446-464.
   nonadjacent dependencies in speech processing.                  Waugh, N.C. (1967) Presentation time and free recall.
Onnis, L., Monaghan, P., Christiansen, M.H., & Chater, N.            Journal of Experimental Psychology. 73, 39-44.
   (2004). Variability is the spice of learning, and a crucial
   ingredient for detecting and generalizing in nonadjacent
   dependencies. Proceedings of the 26th Conference of the
   Cognitive Science Society. Mahwah, NJ:Lawrence-
   Erlbaum.
Onnis, L., Monaghan, P., Richmond, K., & Chater, N.
   (2005). Phonology impacts segmentation in online speech
   processing. Journal of Memory and Language, 53,225-
   237
Perruchet,P. & Gallego, J. (1997). A subjective unit
   formation account of implicit learning. In D.C.Berry (Ed),
   How implicit is implicit learning? Debates in psychology
   (pp. 124-161). Oxford , England:Oxford University Press.
Perruchet,P. & Pacteau, C. (1990). Synthetic grammar
   learning: Implicit rule abstraction or explicit fragmentary
                                                              1972

                       Appendix
 Training stimuli with p-values and frequencies (f(ex.)) of
presentation in the unequally distributed learning set
condition, and the equally distributed        learning set
condition.
Exemplar                     p(ex.|G)   f (ex.)    f (ex.)
                                        (uneq.)    (eq.)
MVR                          0.04166    7          3
MVRM                         0.04166    7          3
MVRV                         0.01388    3          3
MVXRVM                       0.00462    2          3
MVXRVVV                      0.00051    1          3
MVXTX                        0.01388    3          3
MXR                          0.02777    5          3
MXRM                         0.02777    5          3
MXRMXRVMM                    0.00051    1          3
MXRTMXRVXTX                  0.00004    1          3
MXRV                         0.00925    3          3
MXT                          0.02777    5          3
MXTR                         0.00925    3          3
MXTRX                        0.00925    2          2
VMR                          0.02777    5          3
VMRMVRV                      0.00077    1          3
VMRV                         0.00925    2          3
VMRVM                        0.00925    3          3
VMT                          0.02777    4          3
VMTRR                        0.00308    2          3
VMTRRR                       0.00102    1          3
VMTX                         0.02777    5          3
VXT                          0.04166    7          3
VXTR                         0.01388    3          3
VXTRR                        0.00462    2          3
VXTRRX                       0.00462    2          3
VXTRX                        0.01388    3          3
VXTX                         0.04166    2          3
VXVR                         0.01388    3          3
VXVRM                        0.01388    3          3
VXVRTMXRV                    0.00008    1          3
VXVRTTVXVRVXVTR              0.000007   1          3
VXVRVMRMXRMVR                0.000003   1          3
VXVTRR                       0.001543   1          3
                                                            1973

