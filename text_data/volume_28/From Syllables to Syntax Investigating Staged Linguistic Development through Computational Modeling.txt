UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
From Syllables to Syntax: Investigating Staged Linguistic Development through
Computational Modeling
Permalink
https://escholarship.org/uc/item/2fc947zn
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Jack, Kris
Reed, Chris
Waller, Annalu
Publication Date
2006-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                                From Syllables to Syntax:
     Investigating Staged Linguistic Development through Computational Modeling
                                         Kris Jack (kjack@computing.dundee.ac.uk)
                                         Chris Reed (chris@computing.dundee.ac.uk)
                                     Annalu Waller (awaller@computing.dundee.ac.uk)
                                              Applied Computing, University of Dundee,
                                                     Dundee, DD1 4HN, Scotland.
                             Abstract                                 Modeling the Emergence of Syntax
   A new model of early language acquisition is introduced. The
                                                                      All natural languages employ syntax. Syntax allows
   model demonstrates the staged emergence of lexical and             individuals to both understand and produce novel utterances.
   syntactic acquisition. For a period, no linguistic activity is     Unlike non-formulaic language, syntactically produced
   present. The emergence of first words signals the onset of the     utterances are a function of their internal parts.
   holophrastic stage that continues to mature without syntactic         Elman (1993) finds that simple and complex linguistic
   activity. Syntactic awareness eventually emerges as the result     structures can be learned by a neural network, but only if the
   of multiple lexically-based insights. No mechanistic triggers      former are acquired before the latter. To ensure simple
   are employed throughout development.                               structures are learned first, the neural network's memory
   Keywords: Computational modeling; Emergence of Syntax;
                                                                      length is initially small, and increased during training. This
   Item-based Learning; Language Acquisition.                         'maturational' growth allows both types to be acquired
                                                                      without staged input.        Dominey and Boucher (2005)
                                                                      investigate developmental phenomena within a grounded
                          Introduction                                robot. A form of syntactic bootstrapping arises as grounded
Children acquire language in stages, first learning words and         <sentence, event> pairs are learned. The model, however,
later showing sensitivity to their syntactic properties.              employs a manual trigger that activates the syntactic
Processes that demonstrate distinct behaviors at different            component, an inadequate explanation for the emergence of
stages of development are difficult to model within a unified         syntax. Kirby (2001) considers language transmission from
system. As a result, lexical and syntactic processes are often        generation to generation through the Iterated Learning
modeled independently from one another. Bridging the gap              Model. He demonstrates that transmission bottlenecks, that
between these models will increase understanding of the               determine the amount of linguistic exposure a learner
behavioral shift that ushers in syntactic awareness.                  receives, have an important effect on the emergence of
                                                                      syntax. The bottleneck can be neither too narrow nor too
                          Background                                  wide for syntactic structures to be derived.
Modeling Word-to-meaning Mappings                                     Bridging the Gap between Words and Syntax
Children learn the meanings of a small number of words                None of these models show the developmental shift from
early in linguistic development. These first words are often          lexical to syntactic awareness reflected in child language
non-formulaic (Wray, 2002).             A non-formulaic word          development. Jack, Reed and Waller (2004) consider the
expresses a word-to-meaning relationship that is not a                transition from the one-word stage to the two-word stage. A
function of the word's internal parts.                                model is trained on <string, meaning> pairs, testing
   Siskind (1996) investigates word-to-meaning mappings               interpretation of strings at each training epoch. In early
using cross-situational analysis. Cross-situational analysis          training, a preference for non-formulaic (lexical)
takes advantage of word-meaning co-occurrences to                     interpretation emerges.         As training continues, this
establish relationships. His simulations show considerable            preference fades, giving way to formulaic (syntactic)
success, offering a robust solution to the problem under a            interpretations. The behavioral change is an emergent
variety of circumstances. Steels (2001) considers the                 property of the training process and not artificially triggered.
problem of establishing such mappings through language                Although a developmental shift is witnessed it appears very
games. Treating language as a complex adaptive system, he             early in the model and the purely lexical period is very short,
shows that social pressures to communicate, through games,            unreflective of natural child language development.
encourage the development of a self-organized lexicon.
Lexical acquisition is also studied within a developmental                      Modeling the Developmental Shift
framework. Regier (2005) shows that interesting lexical
                                                                      Children do not understand syntactically complex utterances
phenomena, such as fast-mapping, can arise without internal
                                                                      from birth. First words, produced at around 10-months-old
mechanistic changes.           Attentional learning plays an
                                                                      (Bates & Goodman, 1999), are non-formulaic, with no
important role in language acquisition.
                                                                      indication of syntactic properties. By around 18-months-
                                                                      old, syntactic awareness emerges (MacWhinney & Bates,
                                                                  375
                                                                  380

1989). An accurate model of language acquisition should             readability unless words share syllables e.g. low occurs in
reflect the development from the holophrastic stage (non-           lower and yellow, producing “low er” and “ ye low”.
formulaic) to the early multi-word stage (formulaic).                  Training data are randomly generated. Objects can have
                                                                    one of 10 colors and 10 shapes, allowing 100 objects. An
The Holophrastic Stage Specification                                object can appear in one of eight relative locations to one
During the holophrastic stage, the model shows no syntactic         another. This allows a total of 80,000 unique events (100
awareness. All successful string-to-meaning mappings are            objects x eight relative locations x 100 objects).
performed through non-formulaic interpretation i.e. given           Descriptions are generated through a grammar specification
the string “all gone”, the appropriate meaning is mapped            (Table 1). The grammar is instantiated when producing
directly without reducing the string to its individual parts,       training data alone and is not accessible by the model during
                                                                    learning. The grammar is supplied for reader's convenience.
“all” and “gone”.
                                                                               Table 1: The grammar specification for event
The Early Multi-word Stage Specification
                                                                                                   descriptions.
During the early multi-word stage, the model shows
syntactic awareness. Some successful string-to-meaning               S = NP1 REL NP2                           NP1 = a COLOR SHAPE
mappings are performed through formulaic interpretation i.e.
                                                                     NP2 = the COLOR SHAPE                     REL = REL1 | REL2
given the string “all gone”, it is reduced to its individual
                                                                     REL1 = a bove | be low | to the REL4      REL2 = REL3 REL4
parts, “all” and “gone”. Non-formulaic language persists.
   A symbolic model is implemented to investigate this               REL3 = to the u pper | to the low er      REL4 = right of | left of
developmental shift. The remainder of the paper describes            COLOR = red | blue | pink | green | white | black | ye low | gray | lime | pur
this model and discusses its behavior.                               ple
                                                                     SHAPE = cir cle | dia mond | heart | cross | tri ang gle | star | rec tang gle |
                                                                     square | pen ta gon | hex a gon
                         The Model
Training Data                                                       Overview
The Miniature Language Acquisition framework (Feldman,              The model is designed to investigate the appearance of
Lakoff, Stolcke, & Weber, 1990) allows language                     lexical and syntactic sensitivity. It is implemented as a
acquisition to be studied by coupling visual events with            symbolic system.              A set of training data (<event,
linguistic descriptions. Under this framework, a scene              description> pairs) are randomly generated and entered into
building game is played. An object appears in a scene and is        the model. Each pair is analyzed by the Lexical Analysis
described. The object always appears next to another                Unit. Lexical items are determined from data regularities
object. These <event, description> pairs are entered into the       through cross-situational analysis (Siskind, 1996). These
model as training data.                                             items are processed by the Syntactic Analysis Unit that
   Objects are expressed by a set of feature tuples. A              derives syntactic rules and phrasal categories. Syntactic
feature tuple expresses a value and an object identifier.           rules specify the interaction between phrasal categories.
Values are derived from simulated visual data, consistent
with computer vision technology capabilities. Object                The Lexical Analysis Unit
identifiers uniquely identify the object that the value belongs     Training data are entered into the model in the form of
to. Since there are always two objects in an event, they are        <event, description> pairs. Lexical items are derived based
numbered 1 and 2. 1 is the first object in the scene while 2        on these data. Given that strings are syllable-based, word
is the second. Objects vary in shape, color and position.           boundaries are not provided and must be derived. In some
The object {<red, (1)>, <circle, (1)>} reflects that the first      cases, these word boundaries overlap, increasing ambiguity.
object in the scene is a red circle. Object identification is       Meaning 'boundaries' must also be derived since not all
present in infants (Kellman, Gleitman, & Spelke, 1987).             feature tuple sets are singletons e.g. below can be
   Events are expressed by a set of feature tuples comprising       represented as {<below, (0)>, <even_horizontal, (0)>}. The
two objects and the relationship between them. The event            model must further derive how these strings and meanings
{<red, (1)>, <circle, (1)>, <pink, (2)>, <cross, (2)>,              are related to one another.
<above, (0)>, <right, (0)>} reflects that a pink cross                 The learning algorithm is best described by way of
appeared to the upper right of a red circle. Relative               example. The model contains pair (1). On the entry of pair
positions are expressed as binary relationships along               (2), the model checks if the pair has been encountered
horizontal and vertical planes, as suggested by infant              before. If so, then a count is kept of the number of times
interpretations of spatial locations (Quinn, 2003).                 that it has appeared and lexical analysis ends. If not, then a
   Descriptions are syllable-segmented strings. Descriptions        form of cross-situational analysis begins to identify event
are not word-segmented as fluent speech contains no known           and string equalities. It is assumed that words will co-occur
acoustic analog of the blank spaces in text (Brent & Siskind,       more often with their referents than with other meanings.
2001). A syllabic base is implemented as infants are likely         Regularities are extracted across events and descriptions
to represent sound based on a syllable covariant (Dehaene-          individually before recombining the results.
Lambertz & Houston, 1998; Mehler, Dupoux, Nazzi, &
Dehaene-Lambertz, 1996). Word spellings are retained for
                                                                376
                                                                380

1. <{<red, (1)>, <circle, (1)>, <pink, (2)>, <cross, (2)>,           meaning boundaries. Learning phenomena such as under-
    <above, (0)>, <right, (0)>},                                     generalization and mismatching are encountered. For
    “a pink cross to the u pper right of the red cir cle”>           example, the word “red” should be representative of redness
2. <{<green, (1)>, <cir cle, (1)>, <red, (2)>, <diamond, (2)         in any object but is sometimes under-generalized to a single
    >, <even_vertical, (0)>, <right, (0)>},                          one object. Mismatches such as <{<circle, (1)>}, “to the”>
    “a red dia mond to the right of the green cir cle”>              are also found. These phenomena are indicative of the
                                                                     holophrastic stage in learning.
   Event regularities are derived based on feature tuple
equality. Feature tuple comparisons are value sensitive and          The Syntactic Analysis Unit
identifier insensitive. That is, the feature tuple <red, (1)> is     Non adult-like lexical items can also express syntactic
equal to any feature tuple with the value red regardless of          relationships. Lexical item (9) is a formulaic function of
identifier value. All feature tuple equalities are extracted         lexical items (10) and (11). The Syntactic Analysis Unit is
over the two events, producing (3) and (4).                          responsible for discovering and encoding this relationship.
3. {<red, (1)>, <circle, (1)>, <right, (0)>}                         9. <{<red, (1, 2)>, <circle, (1, 2)>}, “red cir cle”>
4. {<cir cle, (1)>, <red, (2)>, <right, (0)>}                        10. <{<red, (1, 2)>}, “red”>
                                                                     11. <{<circle, (1, 2)>}, “cir cle”>
   Description comparisons are syllable form sensitive
reflecting infants' sensitivity to syllabic patterns (Houston,          Syntactic relationships are discovered within lexical item
Santelmann, & Jusczyk, 2004). Descriptions are aligned,              triples (such as (9)-(11)). One lexical item, (9), must be the
(5) and (6), and syllable lists are extracted, producing (7)         function of the two others items, (10) and (11). The lexical
and (8).                                                             items must satisfy both string and {feature tuple}
                                                                     relationships. Given two strings, the model must produce
5. “a pink cross to the u pper right of the red cir cle”             the third through string concatenation, i.e. string1 + string2 =
6. “a red dia mond to the right of the green cir cle”                string3. Also, given two {feature tuple}s, the model must
                                                                     produce the third through set union i.e. {feature tuple}1 U
7. “a”, “to the”, “right of the”, “red”, and “cir cle”               {feature tuple}2 = {feature tuple}3. {Feature tuple} equality
8. “a”, “red”, “to the”, “right of the”, and “cir cle”               is identifier insensitive, so identifiers need not match.
                                                                        Rules capture these relationships. They relate Phrasal
   Event and description regularities are recombined                 Categories (PCs) to one another by the application of
producing <{feature tuple}, string> pairs. All combinations          Transformations (Ts). Each new term is defined before the
of regularities from the first event and the first description       rule is presented.
produce some of co-occurrences (e.g. <{<red, (1)>, <circle,             Rules are expressed in the form PC1 = PC2(T1) PC3(T2),
(1)>, <right, (0)>}, “a”>), while second event and second            where PC1 is produced by combining the results of PC2,
description combinations produce the remainder. Each pair            being transformed by T1, and P3, being transformed by T2.
is re-entered into the model and activates the same process             Phrasal Categories are expressed as the pairing of a set
as the original training data.                                       of strings and a list of feature tuple identifiers, <{string},
   Often, more than one {feature tuple} accompanies each             (identifier)>. PCs are created to support rule relationships.
string after learning. To avoid ambiguity, each string must          There are two kinds of PCs; parent and child. Given the rule
be represented by only one {feature tuple}. Children                 PC1 = PC2(T1) PC3(T2), PC1 is a root, while PC2 and PC3 are
actively avoid synonymy during language learning,                    children. Root PCs acquire lexical item 1's data and
following a principle of mutual exclusivity (Markman &               identifier end points from T1 and T2. Child PCs are
Wachtel, 1988). Given the list of {feature tuple}s to which          populated with strings from the original lexical items that
a string is related, the {feature tuple} with the closest            they are derived and the appropriate T start point.
distribution to the string is selected. In some cases, a string         Transformations are expressed as a set of feature tuple
may be represented by two {feature tuple}s that are equal.           identifier pairs, {feature tuple identifier pair}. Feature tuple
For example, <{<red, (1)>}, “red”> means that “red” is               identifier pairs define the mapping from a start point to an
associated with the redness of object 1 and <{<red, (2)>},           end point, in transforming feature tuple identifiers, <start
“red”> means that “red” is associated with the redness of            identifier, end identifier>.
object 2. These relationships are combined and written as <             The Syntactic Analysis unit produces rule (12) from
{<red, (1, 2)>}, “red”>, representing the redness of either          lexical items (9)-(11).
object 1 or 2.
   Each <{feature tuple}, string> pair indicates a syllable          12. PC1 = PC2(T1) PC3(T2), where
set-to-meaning relationship. If more than one string is                         PC1 = <{“red cir cle”}, ((1, 2), (1, 2))>,
related to the same {feature tuple} then synonymy occurs.                       PC2 = <{“red”}, ((1, 2))>,
Synonymy is rare in natural language. The string with the                       PC3 = <{“cir cle”}, ((1, 2))>,
highest probability of being represented by each unique                         T1 = {<(1, 2), (1, 2)>} and T2 = {<(1, 2), (1, 2)>}.
{feature tuple} is selected. The most probable <{feature
tuple}, string> pairs are stored as lexical items in the model.         Rule (12) expresses a functional path to derive lexical
These items are not always representative of adult word-to-          item (9), using items (10) and (11). It specifies the mapping
                                                                 377
                                                                 380

from the meaning of items (10) and (11) to producing item            meaning, allowing it to be deconstructed and reconstructed
(9). Rule (12) shows how to generate a {feature tuple} that          with the application of other items. PC role (parent or child)
represents the string “red cir cle”. First, the model searches       and membership, therefore, is a better indicator of lexical
for lexical items that represent the child PCs. Lexical items        status than the lexical items themselves.
for “red” and “cir cle” are found; <{<red, (1, 2)>}, “red”>
and <{<circle, (1, 2)>}, “cir cle”> respectively. Each                                     Comprehension
lexical item is transformed based on its PC's T. The lexical         The model is tested for evidence of language acquisition
item for “red” is transformed by T1 and “cir cle” by T2. In          through comprehension tasks. Given a string, the model
this case <{<red, (1, 2)>}, “red”> becomes <{<red, (1, 2)            must derive a {feature tuple}. Following the example from
>}, “red”> (no change) and <{<circle, (1, 2)>}, “cir cle”>           the last section, assume that the model contains rule (16) and
becomes <{<circle, (1, 2)>}, “cir cle”> (no change). The             has never encountered the string “red dia mond” in training.
results are joined together through set union producing <               PC membership offers a better indication of lexical status
{<red, (1, 2)>, <circle, (1, 2)>}, “red cir cle”>.                   than lexical items. The model searches for the string in all
   The Syntactic Analysis Unit analyzes every combination            PCs. If the string appears in a PC then its lexical item
of lexical item triples and produces a rule for each group           representation is retrieved. If the string does not appear in a
that expresses a syntactic relationship. Rules can express           PC then the comprehension process continues regardless. In
similar relationships. Rules (13)-(15) all express the same          this case, the model has never encountered the string “red
relationship. Rule (13) is the short-hand version of rule (12)       dia mond”, so it not a member in any PC.
for improved readability. They state, that “red cir cle”,               The model contains rules that specify how to produce
“blue cir cle” and “pink dia mond” can each be produced by           meanings for a number of strings. These rules take two
applying the same transformation rules to their children. A          substrings as input. Using these rules, the string to parse is
transformation rule must have the same start point and end           dissected into two parts. Any string that contains more than
point to be considered equal.                                        one syllable can be dissected. The string “red dia mond” is
                                                                     dissected, by syllable boundaries, producing the pairs
13. {“red”}((1, 2) -> (1, 2)), {“cir cle”}((1, 2) -> (1, 2))         <“red”, “dia mond”> and <“red dia”, “mond”>. Each string
14. {“blue”}((1, 2) -> (1, 2)), {“cir cle”}((1, 2) -> (1, 2))        is recursively processed by the comprehension algorithm
15. {“pink”}((1, 2) -> (1, 2)), {“dia mond”}((1, 2) -> (1, 2))       detailed in this section. Taking <“red”, “dia mond”> first,
                                                                     the string “red” is processed discovering that it appears in
   When rules are found to express the same relationship,            PC1 and is associated with lexical item <{<red, (1, 2)>},
they are merged together. Merging rules (13)-(15) produces           “red”>. With similar success, “dia mond” is found to be a
(16). (16) has the generative capacity to produce 6 different        member of PC2 with associated lexical item <{<diamond,
strings; “red cir cle”, “blue cir cle”, “pink cir cle”, “red dia     (1, 2)>}, “dia mond”>. The string “dia mond” is further
mond”, “blue dia mond”, and “pink dia mond”.                         dissected and processed in the same recursive function.
                                                                     Neither “dia” nor “mond” appear in PCs. With results for
16. {“red”, “blue”, “pink”}((1, 2) -> (1, 2)), {“cir cle”, “dia      “red” (appears in PC1) and “dia mond” (appears in PC2), the
    mond”}((1, 2) -> (1, 2))                                         model searches for a rule that can combine members of
                                                                     these categories, discovering rule (16).          The rule is
   Rule (16) captures the English grammar rule, NP = Adj.            instantiated to yield <{<red, (1, 2)>, <diamond, (1, 2)>},
N, where the 'adjective' set contains “red”, “blue”, and             “red dia mond”>. A possible meaning for the entire string
“pink” and the noun set contains “cir cle” and “dia mond”.           “red dia mond” is, therefore, {<red, (1, 2)>, <diamond, (1,
The rule states, among other combinations, that when the             2)>}. The comprehension algorithm searches for additional
string “red” directly precedes the string “dia mond”, a red          results using the alternative dissection, <“red dia”, “mond”>.
diamond is being indicated. To emphasize, the rule does not          No further results are derived. The string “red dia mond” is
just indicate that there is redness in the scene, nor that there     correctly identified as {<red, (1, 2)>, <diamond, (1, 2)>}.
is diamond in the scene, but that there is an object in the             In some cases, more than one meaning is derived for a
scene that shares both the properties red and diamond.               single string. Each string can map to a non-formulaic result,
   From syllable segmented strings combined with feature             through no use of rules, as well as formulaic results, through
based meanings, English-like grammar rules are derived.              the use of rules. Comprehension reintroduces a form of
Each rule defines a mapping based not only on individual             homonymy into the model. “The red cross” can refer to the
lexical items, but groups of lexical items, or PCs, producing        Red Cross Foundation and “the red square” to the square in
syntactic units. These lexical items are established by              Moscow just as likely as their geometrically shaped
drawing word and meaning boundaries. The PCs are                     counterparts employed in this study. As long as multiple
established by drawing lexical item boundaries. The fixing           meanings provide plausible interpretations for strings, they
of these lexical item boundaries allows the model to treat           are useful. String interpretation should reduce the semantic
different words in a similar way and, ultimately, produce            burden in communication, not necessarily produce a single,
novel relationships such “red dia mond” in the previous              unambiguous interpretation.
example. Furthermore, the lexical item boundaries change                As training data are added to the model, lexical items,
the model's perception of lexical status. While lexical              rules, and PCs are derived. PCs often include lexical items
analysis produced items such as “red cir cle”, syntactic             that express English like PCs, found in (17)-(19). PC
analysis draws a boundary through the string and its related         membership grows as more training data are added. At
                                                                 378
                                                                 380

times, more than one PC appears to express the same string                For three epochs, there are no successful string
set membership, but at different stages of development. For             interpretations, creating a pre-linguistic period. The first
example, (17) represents the full set of colors available to            correct interpretation emerges at epoch four and is non-
the model, while (18) and (19) express subsets of (17).                 formulaic. This is the model's first word, signaling the onset
                                                                        of the holophrastic stage. Being non-formulaic, the word-to-
17. <{“red”, “blue”, “pink”, “green”, “white”, “black”, “ye             meaning mapping is representative of first words in child
    low”, “gray”, “lime”, “pur ple”}, ((1, 2))>                         language development. In one set of data, the model's first
18. <{“red”, “white”, “black”, “lime”}, ((1, 2))>                       word is “pen ta gon”, appropriately associated with
19. <{“ye low”, “gray”, “pur ple”}, ((1, 2))>                           {pentagon, (1, 2)}. For 10 epochs, lexical insights emerge
                                                                        with an increasing volume of correct non-formulaic string
   During comprehension, PCs are substitutable for one                  interpretations. All strings are representative of single
another if they appear to express the same string member                words, either colors or shapes, and never word
set, but at different stages of development. (17)-(19) are all          combinations. At epoch 14, the first non-formulaic word
considered substitutable for one another. Given the string              combination is accurately interpreted. This non-formulaic
“white”, PCs (17)-(19) are all representative; (17) and (18)            interpretation of a word combination spurs syntactic activity.
as “white” is a member of their string sets and (19) as it is a         The first formulaic interpretation is successfully derived at
subset of (17).                                                         epoch 14, signaling the onset of the early multi-word stage.
   PC substitutions allow abstract categories such as                   The emergence of syntax following a period of lexical
adjectives to form faster. During training, it is common for            activity is consistent with child language development.
PCs like (17)-(19) to form. Each of these PCs are created
through the derivation of different rules but all appear to
                                                                                                                                              Developmental Shift
suggest the inclusion of an adjective. Abstract categories
such as noun, adjective and verb are not necessarily present                                    25
in young language learners. Studies show that children
                                                                                                      Pre-linguistic           Holophrastic
                                                                                                                                                       Early
                                                                          No. corrects parses
acquire language in an item-based, piecemeal fashion                                            20
(Tomasello, 2000). Verb analysis, in particular, shows an                                       15
                                                                                                                                                       Multi-word
                                                                                                                                                                     Non-formulaic
uneven usage. For example, a child may only use the word                                                                                                             Formulaic
                                                                                                10
“cut” according to the sentence frame “cut ___”, while
“draw” may be used in a variety of manners such as “draw                                        5
___”, “draw ___ on ___”, “draw ___ for ___”, and “___                                           0
draw on ___”. This suggests that the abstract category of                                            0                 3   6           9      12 15 18 21 24 27 30
verb is not yet in place, since the verbs are employed with                                                            No. <event, description>s entered
different constraints. This model reflects a similar 'verb
island' formation but with adjectives and nouns. PC
substitutions allow the islands to be connected.                                                     Figure 1: Number of correct non-formulaic and
   The model is computationally expensive to implement in                                                      formulaic interpretations.
both learning and comprehension. Regularities in training
data are maximized through a small number of pattern                      This result demonstrates two emergent properties in the
matching mechanisms. Although pruning strategies have                   model; lexical and syntactic awareness. From the outset, the
been considered, none have been adopted due to lack of                  model shows no lexical or syntactic awareness. After a
success. The approach remains computationally expensive,                short period of inactivity, lexical awareness emerges,
a serious concern when the target language is scaled-up.                evidenced by the acquisition of first words.              The
                                                                        holophrastic stage continues unperturbed for a period before
                    Model Behavior                                      syntactic awareness emerges. Given a larger and more
The model is tested to investigate the emergence of the                 varied training set, that is representative of child linguistic
holophrastic and early multi-word stages. The first correct             exposure, the periods are predicted to lengthen.
non-formulaic (non rule-based) and formulaic (rule-based)
interpretations signal the beginning of the holophrastic and            Lexical and Syntactic Expressivity
early multi-word stages respectively. The model is trained              The model is tested for non-formulaic interpretation of 20
with 10 sets of 65 randomly generated <event, description>              strings (10 colors, 10 shapes), and formulaic interpretation
pairs. Results presented are an average over the 10 sets.               of 100 strings (color shape combinations). Each string
                                                                        interpretation yields a set of possible meanings. Correct
The Developmental Shift                                                 meanings are charted in Figure 2 depending upon how they
The model is tested for interpretation of 120 strings (10               are derived (non-formulaically, or formulaically).
colors, 10 shapes, and 100 color shape combinations). Each                 The distinction between non-formulaic and formulaic
string interpretation yields a set of possible meanings.                language is clear. The former makes no use of rules while
Correct meanings are charted in Figure 1 depending upon                 the latter does make use of rules. Formulaic language is
how they are derived (non-formulaically, or formulaically).             most expressive when rules are applicable to large sets of
                                                                        data i.e. phrasal category string membership is high. This
                                                                  379
                                                                  380

model identifies a formulaic relationship at epoch 14. The                                   Brent, M. R., & Siskind, J. M. (2001). The role of exposure
relationship is representative of the English grammar rule                                     to isolated words in early vocabulary development.
NP = Adj. N. On establishing this formulaic expression, the                                    Cognition, 81, 33-44.
PCs representing adjectives and nouns, constrain rule                                        Dehaene-Lambertz, G., & Houston, D. (1998). Faster
expressivity. A correlation between the percentage of                                          orientation latency toward native language in two-month-
lexical items acquired and the expressivity of the formulaic                                   old infants. Language and Speech, 41, 21-43.
expression exists. PC membership swells as subset and                                        Dominey, P. F., & Boucher, J.-D. (2005). Developmental
superset relationships are derived, allowing abstract                                          stages of perception and language acquisition in a
categories to form.                                                                            perceptually grounded robot. Cognitive Systems
                                                                                               Research, 6(3), 243-259.
                                                                                             Elman, J. L. (1993). Learning and development in neural
                                               Expressivity
                                                                                               networks: The importance of starting small. Cognition, 48
                     100
                                                                                               (1), 71-99.
                                                                                             Feldman, J. A., Lakoff, G., Stolcke, A., & Weber, S. H.
                     80                                                                        (1990). Miniature language acquisition: A touchstone for
  % correct parses
                     60                                                Non-formulaic
                                                                                               cognitive science. Proc. 12th Ann. Conf. Of CogSci Soc.
                                                                       Formulaic
                                                                                             Houston, D. M., Santelmann, L. M., & Jusczyk, P. W.
                     40
                                                                                               (2004). English-learning infants’ segmentation of
                     20                                                                        trisyllabic words from fluent speech. Language and
                      0                                                                        Cognitive Processes, 19(1), 97-136.
                           0   5 10 15 20 25 30 35 40 45 50 55 60 65                         Jack, K., Reed, C., & Waller, A. (2004). A computational
                                No. <event, description>s entered                              model of emergent simple syntax: Supporting the natural
                                                                                               transition from the one-word stage to the two-word stage.
                                                                                               Coling, 20th Conf on Comp. Ling., Geneva, Switzerland.
                     Figure 2: Percentage of correct formulaic and non-                      Kellman, P. J., Gleitman, H., & Spelke, E. S. (1987). Object
                                formulaic interpretations.                                     and observer motion in the perception of objects by
                                                                                               infants. Journal of Experimental Psychology - Human
  This result demonstrates that the expressive power of                                        Perception and Performance, 13(4), 586-593.
syntactic rules is correlated with the number of lexical items                               Kirby, S. (2001). Spontaneous evolution of linguistic
correctly identified in the model. As lexical membership                                       structure: An iterated learning model of the emergence of
increases, PC string membership expands, and rules become                                      regularity and irregularity. IEEE Transactions on
more expressive. This finding is consistent with child                                         Evolutionary Computation, 5(2), 102-110.
language acquisition. As phrasal categories form, they                                       MacWhinney, B., & Bates. (1989). The crosslinguisitic
become increasingly abstract and employed by a number of                                       study of sentence processing. New York: Cambridge
rules. Given more strict PC connectivity constraints,                                          University Press.
Tomasello's (2000) verb island effect is predicted.                                          Markman, E. M., & Wachtel, G. F. (1988). Children's use of
                                                                                               mutual exclusivity to constrain the meanings of words.
                                             Conclusion                                        Cognitive Psychology, 20(2), 121-157.
                                                                                             Mehler, J., Dupoux, T., Nazzi, T., & Dehaene-Lambertz, G.
The model demonstrates two behavioral shifts that are                                          (1996). Coping with linguistic diversity: The infant's
present in child language development. First, lexical                                          viewpoint. In J. L. Morgan & K. Demuth (Eds.), Signal to
awareness emerges as syllable combinations are recognized                                      syntax. Mahwah, N.J.: Lawrence Erlbaum.
as expressions of word-to-meaning mappings. This period                                      Quinn, P. C. (2003). Concepts are not just for objects:
persists in the absence of syntactic awareness. Second, word                                   Categorization of spatial relation information by infants.
combinations are recognized as expressions of syntactic                                        In D. H. Rakison & L. M. Oakes (Eds.), Early category
relationships. Syntax emerges and becomes increasingly                                         and concept development: Oxford University Press.
expressive as training continues. The item-based acquisition                                 Regier, T. (2005). The emergence of words: Attentional
strategy can acquire language in a child-like manner through                                   learning in form and meaning. Cognitive Science, 29(5).
exploiting a small number of cognitively general learning                                    Siskind, J. M. (1996). A computational study of cross-
mechanisms.                                                                                    situational techniques for learning word-to-meaning
                                                                                               mappings. Cognition, 61(1-2), 1-38.
                                       Acknowledgments                                       Steels, L. (2001). Language games for autonomous robots.
The first author is sponsored by a studentship from the                                        IEEE Intelligent systems, 16-22.
EPSRC, UK.                                                                                   Tomasello, M. (2000). The item-based nature of children’s
                                                                                               early syntactic development. Trends in Cognitive
                                             References                                        Sciences, 4(4), 156-163.
                                                                                             Wray, A. (2002). Formulaic language and the lexicon.
Bates, E., & Goodman, J. C. (1999). On the emergence of
                                                                                               Cambridge: Cambridge University Press.
  grammar from the lexicon. In B. MacWhinney (Ed.), The
  emergence of language.
                                                                                       380
                                                                                       380

