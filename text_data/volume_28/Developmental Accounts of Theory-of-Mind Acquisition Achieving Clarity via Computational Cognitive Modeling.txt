UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Developmental Accounts of Theory-of-Mind Acquisition: Achieving Clarity via Computational
Cognitive Modeling
Permalink
https://escholarship.org/uc/item/6dx609zg
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Bello, Paul
Cassimatis, Nicholas
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                       Developmental Accounts of Theory-of-Mind Acquisition:
                       Achieving Clarity via Computational Cognitive Modeling
                                                     Paul Bello (Paul.Bello@rl.af.mil)
                                          Air Force Research Laboratory - Information Directorate
                                                                 525 Brooks Rd.
                                                             Rome, NY 13441 USA
                                                  Nicholas Cassimatis (cassin@rpi.edu)
                                       Rensselaer Polytechnic Institute - Dept. of Cognitive Science
                                                                   110 8th St.
                                                              Troy, NY 12180 USA
                               Abstract                                    interpreted in variety of ways to suit different purposes. This
                                                                           has several important consequences for the theoretical impact
   People’s ability to predict and explain the beliefs, desires and        of ToM experiments:
   actions of others, often called their Theory of Mind (ToM) is an
   central component of cognition. There is ample experimental            1. Disagreement among various researchers concerning
   evidence suggesting a major developmental shift in children’s
   ToM somewhere between the ages of three and five (Wellman,                 the nature of mental states such as beliefs, desires, and
   Cross & Watson 2001). These results are often interpreted in               intentions have led to any number of interpretations for
   terms of children acquiring rich understanding of belief and               both performance and developmental data in accounting
   its representational nature. Both of these descriptors are am-             for them. Philosophers who have studied these problems
   biguous and controversial. This makes evaluating the evidence              for millennia cannot even agree upon precise meanings for
   of such a shift, and its implication about the knowledge and
   mechanisms underlying ToM more difficult. Computational                    these terms, and remain at odds over the general proper-
   cognitive models are precise by nature, and can help resolve               ties these states may possess. For example, do children
   many of these difficulties. We present Polyscheme/ToM, a                   actually represent the beliefs of other agents (i.e., do they
   computational model of human behavior in some important                    have specific beliefs about beliefs), or do they instead have
   ToM tasks. It uses a domain-general mechanism for repre-
   senting alternate states of affairs in order to represent the way          an overall representation of another person’s perspective
   other people view the world. We demonstrate that the model                 on the world without explicitly thinking about the individ-
   has several implications: 1) it is possible to succeed in false            ual beliefs that make up that representation, as researchers
   belief tasks without explicitly representing beliefs; 2) behav-            such as Josef Perner seem to suggest (Perner 1991).
   ior in experiments purporting to show success in false-belief-
   like tasks at earlier ages require significantly simpler mecha-        2. Disagreements over definition make experimental data
   nisms than success in the traditional false-belief task, and 3)            difficult to interpret. It is often assumed that the false-
   the shift from younger to older behavior in these tasks can be
   accounted for by small, but highly consequential changes in                belief task as presented in (Wimmer & Perner 1983) is
   cognitive mechanisms.                                                      the gold standard for determining whether a child has ac-
                                                                              quired the so-called representational theory of mind, and
    Problems in interpreting ToM experiments                                  thus a thorough understanding of beliefs. A meta-analysis
                                                                              conducted in (Wellman et al. 2001) strongly corroborates
Developmental psychologists have designed a number of                         success on these kinds of tasks with a relatively narrow
clever and important experiments to chart out the acquisi-                    age range (usually between 3.5 and 5.0 years old). How-
tion of so-called Theory of Mind (ToM) by young children                      ever, there are studies that suggest that younger children
(Liu & Wellman 2004). The central debate among theoretical                    (e.g., (Wellman & Bartsch 1988)) and even chimpanzees
frameworks for describing the acquisition and nature of ToM                   (Call, Hare, Carpenter & Tomasello 2004) have ToM abil-
is focused differing views on how children might be able to                   ities normally only ascribed to older human children.
predict the actions of other agents. For example, one these
theories characterizes children as “little scientists” who con-           3. Imprecision makes it difficult to assess the magnitude
struct theories of human behavior through connecting stim-                    of development. Without a specific and precise account
uli, mental states, and actions taken by observable human                     of cognition, both pre- and post- success on the false be-
agents. This framework is often called theory-theory (Gop-                    lief task, it is difficult to assess the magnitude of the de-
nik & Meltzoff 1997). Alternatively, proponents of simula-                    velopment in children’s thinking that the behavior shift in
tion theory subscribe to the assumption that children are able                these tasks represents. Theory-theorists are faced with a
to assume the perspective of other people, and use their own                  fundamental problem of accounting for the induction and
cognitive apparatus for dealing with their perspective of the                 adaptation of a large knowledge-base corresponding to a
world as a good first-approximation to that of the person to                  näive theory of human behavior. It is difficult to asses how
be simulated (Goldman 1989). The results of many different                    large of a problem this is without a more precise charac-
experiments have been used by proponents of both views to                     terization of these theories in both younger and older chil-
buttress support for their respective positions. However, these               dren. Simulation theorists aren’t faced with the problem of
results are often presented using terms such as representation,               a large theory, they face a more fundamental set of difficul-
belief, knowledge, simulation and model, all of which can be                  ties entailed by their own commitments, partially outlined
                                                                      1014

   in (Saxe 2005). Is it reasonable to assume that children ac-      we will only deal with two specialists, the “rule special-
   quire this large theory in a short period of time, or is the      ist” which represents propositions symbolically and reasons
   theory supplemented by mechanisms which allow for use             about them using standard rule-based techniques (modus po-
   of the child’s already-compiled knowledge? Precise instan-        nens and modus tollens), and the “temporal-perception spe-
   tiations of theory-theory and simulation theory would help        cialist,” which keeps track of when things are seen. Special-
   clarify these issues.                                             ists in Polyscheme communicate through a propositional lan-
                                                                     guage. These propositions have truth-values on the follow-
   We have set out to develop a computational model of chil-         ing scale: <Maybe, Likely, Very Likely, Certainly>. The
dren’s behavior in ToM tasks in hopes of shedding light on           truth value of a proposition is a tuple (x, y), where x repre-
these apparent confusions.                                           sents negative evidence in favor of the truth of the proposi-
                                                                     tion, and y represents the contrasting positive evidence. Spe-
            Common Themes in ToM Tasks                               cialists vote on propositions by simultaneously focusing on
We developed our model by first identifying some common              them, and forming opinions on their truth value. Propositions
(and commonly accepted) themes among some of the now                 are of the form R(x, y,t, w) and state that relation R holds over
classic “metarepresention” tasks in the literature. The more         entities x and y over temporal interval t in world w. When
well-known of these tasks are the appearance-reality distinc-        t =E, that relation holds over all time (eternity). The “real
tion (Flavell 1986), the smarties task in (Hogrefe, Wimmer           world,” or the world as it is seen by Polyscheme in a first
& Perner, 1986), and infamous false-belief task (Wimmer &            person sense, is denoted as R, so in the default case, w = R.
Perner 1983).                                                        Unless there is reason (i.e. perception or inference) to believe
                                                                     otherwise, specialists assume what is true in R is true in other
• Children must represent separate and potentially con-              worlds. For a more thorough overview, refer to (Cassimatis
   tradictory states of affairs. In the case of appearance-          2005).
   reality tasks, this corresponds to how objects appear versus
   how they actually are. In the false belief task children must                           Polyscheme/ToM
   separate the state of affairs they know to be true from the
   state of affairs which another person holds to be true, re-       Polyscheme/ToM is a Polyscheme model augmented to ac-
   gardless if there is a mismatch between the two. In the           count for behavior in theory-of-mind tasks. It is motivated by
   smarties task, children must distinguish between the state        the common themes in the metarepresentation tasks which
   of the affairs they currently hold to be the case from the        we highlighted in the last section. The following outlines
   state of affairs which they formerly held to be the case.         our model of children who normally succeed in these tasks,
                                                                     roughly corresponding to four-year-old behavior:
• Theories relating people to alternate states of affairs.
   The false belief and smarties tasks both require that these       • Alternate worlds represent states of affairs:
   alternate states of affairs must be associated with people.          Polyscheme/ToM can reason about alternate worlds.
                                                                        In our model, we use such worlds to represent the mind of
• Causal theories, which define the relationships between               other agents.
   the multiple states of affairs. For example, perceptual
   events have a causal impact on the state of affairs asso-         • The MindOf predicate captures the relation between
   ciated with another person’s perspective.                            states of affairs and people. Polyscheme/ToM imple-
                                                                        ments a special relation called MindOf, which holds over
   Two features of these common themes motivate our choice              a person and a world which represents their mind. For
of cognitive modeling framework. First is the need to rep-              example, if John thinks that chair is in front of the pi-
resent multiple states of affairs and the second is the need            ano, we say that MindOf w john t R + FrontOf chair
to combine perception and reasoning. For these reasons                  piano t w . Notice that while MindOf defines w as be-
we chose the Polyscheme cognitive architecture (Cassima-                ing related to John, the proposition FrontOf is indexed to
tis 2005) to implement our ToM model. Polyscheme is rare                John’s mind, which is being represented by w. This cap-
among cognitive architectures in that it has rich facilities for        tures the notion that other agents may view the world dif-
representing alternate worlds and perhaps is unique in being            ferently than Polyscheme/ToM does. While perception is
designed to combine this ability with mechanisms for natu-              always veridical for Polyscheme/ToM (that is, everything
rally integrating reasoning and perception.                             perceived in the real world is assumed to be certainly the
                                                                        case, this is not so for other agents. To account for the dis-
                          Polyscheme                                    crepancy, Polyscheme implements two different ways of
Polyscheme is a cognitive architecture which has been used              creating alternate worlds which we describe later.
to model phenomena as wide-ranging as reasoning with näive
theories of physics to syntactic parsing mechanisms (for En-         • Causal theories: Polyscheme/ToM contains a theory of
glish) using the same set of common functions (Cassimatis               perception, and its effect on producing representations
2005). A Polyscheme model consists of a sequence of in-                 in other minds. Particularly, Polyscheme/ToM knows
teracting modules called specialists that represent and make            that certain kinds of occlusion make certain perceptual
inferences about aspects of the world. Specialists are based            modalities unavailable. If Polyscheme/ToM is not blind-
on their specialized data structures and algorithms. Special-           folded, and John happens to be, then Polyscheme/ToM
ists are all able to represent and make inferences about al-            can modify the status of propositions in alternate world
ternate states of worlds. For the purpose of this discussion,           representing John’s mind by reasoning about them in
                                                                 1015

   terms of how (lack of) perception of unique objects and             Stating that “IF P wants OBJECT and P sees object at LO-
   their attributes impute selected mental states to John. The      CATION, THEN P will search for OBJECT at LOCATION.”
   rule corresponding to this is NOT CanPerceive ?person
   ?Attribute ?t R + MindOf ?w ?person E R ==>                      The difference in three- and four-year old models
   , Blocked perceptionRule ?Attribute ?t ?w .,                     To summarize, our model accounts for four-year old success
   stating that if a person can’t perceive a particular type        with two mechanisms: the ability to represent the state of
   of attribute, and the person’s mind is represented by the        affairs a person believes in with a world that is associated with
   world w, then we block perception of any proposition             that person using the MindOf predicate; and an action rule that
   corresponding to the attribute in question in the mind of        takes this state of affairs into account. That is the three-year
   this person. If John is blindfolded, he therefore doesn’t        old action rule merely makes reference to what the three-year
   have any solid conception concerning the location of his         old (not other people) believes is true about the world and
   coat if someone moves it out of the room while he can’t          what other people have seen. The four-year old desire-action
   see.                                                             rule makes reference to an alternate state of affairs associated
                                                                    with another person:
   MindOf works in the following way: by default, when
Polyscheme/ToM instantiates a world w, it inherits all propo-       • 3-year-old: ”IF P wants OBJECT and P perceives object
sitions in certain in R as being certain in w. We call this on-        at LOCATION, THEN P will search for OBJECT at LO-
tological inheritance. When w represents the mental state of           CATION.
a person, e.g., MindO f (w, Susan), only inherits propositions
into w as being likely. We call this epistemic inheritance. By      • 4-year-old: ”IF P wants OBJECT and in his mind the ob-
allowing things to be different in w than they are in the real         ject is at LOCATION, THEN P will search for OBJECT at
world, we allow Polyscheme/ToM to have a representation                LOCATION.”
about an external agent’s view of the world. MindOf allows
Polyscheme/ToM to keep these representations independent,                       Interpreting Conflicting Results
yet connected through causal theories.                              We will contrast the study of false-belief made famous
                                                                    in (Wimmer & Perner 1983) with the claim that children
Polyscheme/ToM: Action Prediction                                   younger than predicted by the age-range reported in the 1983
So far we have only described how our model decides to infer        experiment display some understanding of false belief, partic-
what another person believes to be the case. Our model uses         ularly as it is related to predicting action (Wellman & Bartsch
the following set of rules to predict what a person will do:        1988).
• Wants ?cat ?person ?tWanting ?w + Category                        Wimmer and Perner’s Experiment
   ?object ?cat E ?w + Location ?object ?loc                        The paradigmatic false-belief task involves two subjects, a
   ?tWanting ?w ==> , SearchesAt ?person ?loc                       child and another agent who are in a room with the exper-
   ?tWanting ?w .                                                   imenter. There are two cookie jars in the room, with both
                                                                    child and the agent knowing that there is a cookie in jar 1, but
• NOT CanPerceive ?person ?Attribute ?t R                           not in jar 2. The agent is asked to leave the room for a mo-
   + MindOf ?w ?person E R ==> , Blocked                            ment. While the agent is gone, the cookie is switched from jar
   perceptionRule ?Attribute ?t ?w .                                1 to jar 2. The agent is then reintroduced into the room, and
                                                                    the experimenter asks the child which jar the agent will look
   Which amounts to stating “IF P wants OBJECT (of a                in to find the cookie. A task of this type requires a notion of
certain category) and in his mind the object is at LOCA-            common knowledge, but also that the child understands that
TION, THEN P will search for OBJECT at LOCATION.”                   the agent can be in possession of faulty information (or false
This desire-action rule is preliminary and will need to be ex-      belief), which ultimately will have consequences for its be-
panded because it only deals with perception and location for       havior. As we’ve stated previously, a transition from failure
now. However, it outlines how we can predict what a per-            to success on this task is in the narrow range of 3.5 to 4.5
son will do based on the state of affairs that THEY, and not        years of age.
Polyscheme/ToM, finds to be the case.
                                                                    Bartsch and Wellman’s Experiment
Three-year old behavior
                                                                    Bartsch and Wellman describe a number of experimental re-
Our model of four-year old behavior explains how people can         sults in their 1988 paper which seem to indicate that children
succeed in metarepresentation tasks by relating the state of        have a rich understanding of belief before the age predicted
affairs that someone else believes in to the actions they take      by Wimmer and Perner’s 1983 experiments. We focus on
(using the world mechanism and MindOf predicate). We can            the third experiment presented in the paper. In the exper-
account for three-year old behavior by simply removing these        iment, children were presented with Susan, who is leaving
from the model. This would lead to the following rule:              her house for work in the morning. She sees a black magic
   Wants ?cat ?p ?tWanting R + Category ?o                          marker on the table in the kitchen on her way out. There is
   ?cat E R + Location ?o ?loc ?tWanting R +                        another marker in the house on the shelf in the living room.
   Perceive ?p ?loc ?tSeeing R + Before ?tSeeing                    The child is told that Susan hasn’t seen this particular marker.
   ?tWanting E R ==> , SearchesAt ?p ?loc                           Susan comes home, and wants to get the marker in order to
   ?tWanting R .                                                    write something down. The children are asked where Susan
                                                                1016

will look for the marker. This is not quite the same as the false     Time: 1
belief task in Wimmer and Perner, but it is very close. In the
false belief task, the object in question (the cookie) changes        NOT Blocked perceptionRule Location t1 R .
status. In this case, the marker on the shelf acts as a possible      NOT Blocked perceptionRule Location t4 R .
distracter for the child, giving the experimenter some confi-         NOT Blocked perceptionRule Location t6 R .
dence concerning whether or not the child is linking Susan’s
perception to her beliefs to her actions.                             Before t1 t4 E R .
                                                                      Before t1 t6 E R .
                     Model: False-Belief                              Before t4 t6 E R .
The task proceeds according to the following temporal se-
quence (from the standpoint of the subject):                          Perceive cookie t1 R .
                                                                      NOT Blindfolded susan t1 R .
• t1 : perceive the locations of the two cookie jars, the loca-
   tion of the cookie, and the status/location of susan, who          Time: 10
   is the agent that Polyscheme/ToM will make a judgment
   about.                                                             Blindfolded     susan   t2  R .
                                                                      Blindfolded     susan   t3  R .
• t2 : perceive that susan leaves the room. To simplify mod-          Blindfolded     susan   t4  R .
   eling, we say that susan is blindfolded.                           Blindfolded     susan   t5  R .
• t3 : perceive that the location of the cookie is changed from       Time: 20
   its original placement.
                                                                      Perceive cookie t4 R .
• t4 : perceive that susan has her blindfold removed.
                                                                      Time: 30
• t5 : infer what susan thinks about the location of the cookie.
• t5 : on the basis of this inference, predict what susan will do     NOT Blindfolded susan t6 R .
   if she wants the cookie.
   To model this scenario, we make three simplifying assump-          Time: 40
tions: first, that instead of leaving the room, susan is blind-
folded; secondly that both susan and Polyscheme/ToM are               MindOf w susan E R .
told the original location of the cookie; and finally, that hav-
ing cookie-jars or other occluders aside from the blindfold           Time: 50
doesn’t do anything but overcomplicate the essence of the
task. The Polyscheme input file describing the task looks like:       WONDER Location cookie p3 t1 w .
                                                                      WONDER Location cookie p3 t6 w .
  ###RULES                                                            WONDER Location cookie p4 t6 w .
Wants ?cat ?person ?tWanting ?w + Category                            Time: 60
?object ?cat E ?w + Location ?object ?loc                             Category cookie Cookie E R .
?tWanting ?w ==> , SearchesAt ?person ?loc                            Wants Cookie Sue t6 w .
?tWanting ?w .
                                                                          While we have previously given explanations for the first
NOT CanPerceive ?person ?Attribute ?t R                               two rules in our model, it behooves us to quickly de-
+ MindOf ?w ?person E R ==> , Blocked                                 scribe the operation of the rest of the model describing
perceptionRule ?Attribute ?t ?w .                                     Polyscheme/ToM’s näive theory of perception. The third rule
Blindfolded ?person ?t R + MindOf ?w ?person E                        in the model simply states that blindfolded people can’t per-
R ==> , NOT CanPerceive ?person Location ?t R .                       ceive locations, while the fourth rule states that if an ob-
                                                                      ject is perceived as being at a particular place at time t, it
Location ?object ?person ?t w + Before ?t1 ?t2                        is likely to be there at time t + 1. The remaining rules are
E R ∼∼> , Location ?object ?person ?t2 w .                            what we called perceptual rules, and defeasibly mediate be-
                                                                       tween perception and knowledge through the use of the re-
NOT Blocked perceptionRule Location t1 ?w +
                                                                       lation Blocked. When Blocked is true, perception doesn’t
Perceive ?object t1 ?w ==> , Location ?object
                                                                      lead to knowledge, however in the default case (where a per-
p3 t1 ?w .
                                                                      son isn’t blindfolded), Blocked is assumed to not be the case.
NOT Blocked perceptionRule Location t4 ?w +
Perceive ?object t4 ?w ==> , Location ?object                         False-Belief Task: Inference Trace
p4 t4 ?w .                                                            Extrapolating the inferential chain in the false-belief task al-
                                                                      lows us to present how our model is able to predict the be-
  ###INPUTS                                                           havior of another agent within the task. All propositions ref-
                                                                  1017

erenced to the real-world R in our input file are assumed to        Wants ?cat ?p ?tWanting R + Category ?o ?cat E
be certainly true by the Polyscheme/ToM model. As soon as           R + Location ?o ?loc ?tWanting R + Perceive ?p
the Polyscheme/ToM model simulates the mind of the other            ?loc ?tSeeing R + Before ?tSeeing ?tWanting E R
agent (by invoking MindOf with a world argument w), some            ==> , SearchesAt ?p ?loc ?tWanting R .
interesting inferences begin to be made:
                                                                      ###INPUTS
• By invoking MindOf, using it to bind w to susan,                  Time: 1
   and wondering about the location of the cookie in w;
   Polyscheme/ToM creates an alternate world w correspond-          Category markerTable Marker E R .
   ing to susan’s mind using epistemic inheritance, resulting       Category markerShelf Marker E R .
   in Location cookie p3 t1 w being considered “likely
   true” rather than certain.                                       Location     markerTable    pl:1-0-1     t1  R  .
                                                                    Location     markerTable    pl:1-0-1     t2  R  .
• Rule 3, which tells us that blindfolded people cannot per-        Location     markerTable    pl:1-0-1     t3  R  .
   ceive locations, matches, and given that Polyscheme/ToM          Location     markerShelf    pl:2-0-1     t1  R  .
   knows that the other person is blindfolded from t2 through       Location     markerShelf    pl:2-0-1     t2  R  .
   t5, it infers that the other person cannot perceive location     Location     markerShelf    pl:2-0-1     t3  R  .
   at those times.
                                                                    Perceive susan pl:1-0-1 t1 R .
• Now, given the fact that the other person cannot see from         NOT Perceive susan pl:2-0-1 t1 R .
   t2 through t5, Polyscheme/ToM infers that any perception-
   Rule referencing any time in the interval t2 through t5 is       Time: 10
   blocked.
• Recall that since Polyscheme/ToM assumes ontological in-
   heritance by default, Perceive cookie t4 R is considered to      Wants Marker susan t3 R .
   be true in w. But since the perceptionRule at t4 is blocked,     Before t1 t3 E R .
   no inference is made such that Location cookie p4 t4
   w is certainly true.                                             Time: 20
• When Polyscheme/ToM wonders about the location of the             WONDER SearchesAt susan ?loc t3 R .
   cookie from susan’s perspective at time t6, it applies the
   3rd rule to Location cookie p4 t4 w, but due to con-                It should be clear that performance can be modeled in this
   tradiction with Location cookie p3 t4 w it retracts its’         task with surprising less complexity. In fact, it is just a single
   belief, and re-assumes the last piece of true information        application of rule-matching. This is a perfect example of
   available, which corresponds to before susan was blind-          misconstruing a simple behavioral rule with a rule making
   folded.                                                          reference to Susan’s mind.
                Model: Action-Prediction                                                      Discussion
The action-prediction task in (Wellman & Bartsch 1988) pro-         Our work on other ToM tasks lends support to the gener-
ceeds according to the following temporal sequence (from the        ality of our claims here. We have used Polyscheme/ToM
standpoint of the subject):                                         to model the appearance-reality distinction, the so-called
                                                                    “Smarties task,” and the false belief task (Flavell 1986) us-
• t1 : perceive the locations of the markers on both the ta-        ing Polyscheme/ToM (Bello & Cassimatis, under review).
   ble and the shelf, and notice that susan only perceived the      Our model demonstrates how precise computational im-
   marker on the table.                                             plementations can limit and help to resolve confusions in
                                                                    the interpretation of behavior in ToM tasks. Specifically,
• t2 : perceive that susan wants the marker.                        Polyscheme/ToM makes the following contributions:
• t3 : wonder where susan will search to find it.                   • Explicit reasoning about beliefs is not necessary for suc-
                                                                       cess in false belief tasks. In our model, children can suc-
   The only difference between this model and the previous             ceed at false belief tasks about, say, a cookie’s location,
model (aside from obvious differences in task structure), is           without reifying (making explicit) the other person’s be-
that this task doesn’t make any reference at all to worlds rep-        lief about that cookie and associating it with the cookie in
resenting alternate states of affairs or to MindOf or its asso-        the world. In our model, children represent a state of af-
ciated machinery. This task also doesn’t have a fully cashed           fairs associated with Susan, but in that state of affairs the
out theory of perception (how blindfolding would affect the            cookie is a cookie, not a representation or belief about a
perception of location-changing, et cetera). It doesn’t need           cookie. It is just a cookie in a different location. In terms
one, although it would certainly be simple enough to recast            of theory-theory, this means that these experiments do not
this problem in terms of perceptual limitations.                       require that a four year old’s ontology includes beliefs. It
                                                                       merely requires that it includes states of affairs, objects in
 ###RULES                                                              the world denoted as persons, and a way of relating them.
                                                                1018

• Precision, in the form of computational models, can               Hogrefe, G. J., Wimmer, H., & Perner, J. (1986). Ignorance
   serve to clarify ambiguous experimental results. This              versus false belief: A developmental lag in attribution of
   is demonstrated by comparing our two models of action-             epistemic states. Child Development, 57, 567-582
   prediction in both the marker-finding (Wellman & Bartsch         Cassimatis, N. (2005a). Integrating cognitive models based
   1988) and cookie-finding scenarios (Wimmer & Perner                on different computational methods. Proceedings of the
   1983), and noting that the marker-finding task doesn’t re-         Tenth Annual Conference of the Cognitive Science Society.
   quire the special functionality that MindOf offers, whereas        Hillsdale, NJ: Lawrence Erlbaum Associates.
   the cookie-finding task does.
                                                                    Flavell, J. (1986). The development of children’s knowledge
• More precise assessment of the magnitude of the devel-              of the appearance-reality distinction. American Psycholo-
   opmental shift. Although the differences in our three-year         gist, 41, 418-425.
   old and four-year old models correspond to a significant         Bello, P., and Cassimatis, N. (under review). Some unify-
   shift in inferential power, they do so with surprisingly few       ing principles for computational models of theory-of-mind.
   changes in knowledge or mechanism. In addition to not              Submitted to the International Conference on Cognitive
   requiring specific cognition about beliefs, desires and rep-       Modeling.
   resenting, the “theory” component in our model which ex-
   plains performance on the false belief task is only one rule     Dias, M. & Harris, P. (1990). The influence of the imagi-
   about how what one perceives affects his mental state and          nation on reasoning by young children. British Journal of
   another rule about how such a mental state together with           Developmental Psychology, 8, 305318.
   desire leads to action. The four-year-old innovation is to
   apply the alternate world mechanism (for which there is in-
   dependent evidence (Dias & Harris, 1990) to representing
   other minds. No more sophisticated theoretical or concep-
   tual apparatus is required.
   ToM has been relatively unexplored in cognitive model-
ing. This work demonstrates that precise computable mod-
els can illuminate important issues in this literature. By pre-
cisely specifying what exactly constitutes children ToM, we
have therefore been able to reduce the problem of explaining
a broad shift in children’s behavior between three and four
years to the question of how they aquire/learn/develop one
rule, modify a second rule, and begin to apply an alternate
world mechanism they already possess toward representing
other minds.
                          References
Wellman, H.M., Cross, D., Watson, J. (2001). Meta-analysis
   of theory-of-mind development: The truth about false be-
   liefs. Child Development, 72(3), 655-684.
Wimmer H., and Perner, J. (1983). Beliefs about beliefs:
   Representation and constraining function of wrong beliefs
   in children’s understanding of deception. Cognition, 13,
   103-128.
Wellman, H.M., Bartsch, K. (1988). Young children’s rea-
   soning about beliefs. Cognition, 30(2), 239-277.
Perner, J. (1991). Understanding the Representational Mind.
   Cambridge, MA: MIT Press.
Gopnik, A. and Meltzoff, A. (1997). Words, Thoughts and
   Theories. Cambridge, MA: MIT Press.
Goldman, A. (1989). Interpretation psychologized. Mind and
   Language, 4, 161-185
Call, J., Hare, B., Carpenter, M., and Tomasello, M. (2004).
   Unwilling versus unable: chimpanzees understanding of
   human intentional action. Developmental Science, 7(4),
   488-498.
Saxe, R.,(2005). Against simulation: the argument from er-
   ror. Trends in Cognitive Science, 9(4), 174-179.
                                                                1019

