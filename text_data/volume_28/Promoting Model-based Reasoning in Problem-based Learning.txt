UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Promoting Model-based Reasoning in Problem-based Learning

Permalink
https://escholarship.org/uc/item/1v16m2v9

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)

Authors
Nersessian, Nancy J.
Newstetter, Wendy
Sun, Yanlong

Publication Date
2006-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Promoting Model-based Reasoning in Problem-based Learning
Yanlong Sun (yanlong@cc.gatech.edu) 1
Wendy Newstetter (wendy@bme.gatech.edu) 2
Nancy J. Nersessian (nancyn@cc.gatech.edu) 1
1

2

College of Computing, Georgia Institute of Technology, Atlanta, GA 30332-0280 USA
Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA 30332-0280 USA
Abstract

We have been observing a problem-based learning class (PBL)
in a biomedical engineering program (BME). The present
paper examines the learning trajectory in which students
attempted to solve a complex and genuine research problem
in BME, and attempts to unpack the dynamics of problembased learning, identify the links between different subcomponents in the problem-solving process, and document
specific instructional moves that would strengthen such links
by promoting model-based reasoning (MBR). We found that
through PBL students can successfully build skill in modelbased reasoning, a significant cognitive practice used in BME.
It is also critical to the learning process that the PBL
facilitator could speed up the learning process and help
students acquire skills of model-based reasoning by
scaffolding at the process but not the content level, and
constantly prompting students with a holistic and coherent
view of the models in the problem.

Introduction
Problem-based learning (PBL) was first designed to support
the development of hypothetico-deductive reasoning in
medical education. In PBL, students learn by reflecting on
their own experiences, conducting self-directed search,
integrating information from multiple disciplines, and
solving realistic but often ill-structured problems (Barrows,
1985; Barrows and Tamblyn, 1980; Cognition &
Technology Group at Vanderbilt 1994; Collins, Brown, &
Newman 1989; Hmelo-Silver, 2004). The success of PBL
has prompted researchers to systematically evaluate the
effectiveness of learning by identifying the unique
properties of PBL (compared to the traditional more passive
forms of instruction) and the conditions where learning
actually occurs (e.g., Capon & Kuhn, 2004; Cornelius &
Herrenkohl, 2004; Hmelo-Silver, 2004; Hmelo-Silver &
Azevedo, 2006; Polman, 2004).
Our primary interest in the present study is to unpack the
dynamics of problem-based learning, identify the links
between different sub-components in the problem-solving
process, and document specific instructional moves that
would strengthen such links by promoting model-based
reasoning (MBR), and to find out whether and how this
learning environment supports the development of modelbased reasoning in complex problem solving. As a growing
body of research in history and philosophy of science
establishes, model-based reasoning is a signature feature of
much research in the sciences, both in discovery and
application (Cartwright, 1983; Giere 1988; Hesse 1963;

Magnani, Nersessian, and Thagard 1999; Morgan and
Morrison 1999; Nersessian 1999, 2002, 2005)
By model-based reasoning, we mean constructing
representations (e.g., tables, diagrams, abstract hypothesis),
in the form of a model (e.g., physical models, mathematical
and statistical models) and deriving inferences through
manipulation of the model through abstraction, simulation,
adaptation, and evaluation. The examples of utilizing
model-based reasoning would include dimensions such as:
role of ideas, use of symbols, role of the modeler,
communication, testing models, and multiplicity (Grosslight
et al., 1999), and serve functions such as description of a
natural process, explanation and prediction, assessment of
the models by the empirical and conceptual criteria, and
guidance to future research (Cartier, Rudolph, & Stewart,
2001).
We have been studying several PBL classes in a
biomedical engineering (BME) program where students
learn to apply engineering principles and reasoning
strategies to complex, open-ended BME problems with the
support and guidance of a group tutor/facilitator. These
classes typically have around 100 to 160 students, who meet
once a week all together for lectures and twice a week in
small groups (8 to 9 students) for problem-solving. This
example we develop here is based on observation of one
PBL group for one semester (fifteen weeks). In the
following extended example, we examine the learning
trajectories, identify the distinct characteristics of the
learning process that demand model-based reasoning
strategies, and illuminate the reciprocal relationship
between problem-based learn and model-based reasoning.
Before we get to the problem, it is necessary to point out
that the unique role of the group facilitators as they assisted
students in developing versatile and informed model-based
practices and helped students learn both content and
thinking strategies, for instances, promoting the usages of
tables, diagrams, and matrices of comparisons whenever
appropriate (e.g., Newstetter, 2005). We observed the
facilitator supporting the development of MBR in all
dimensions mentioned above by scaffolding at the process
not the content level. Figure 1 illustrates the role of a
facilitator in problem-based learning, as compared to
teacher-driven instruction. In the conventional classroom,
the instructor teaches refined models to the students. In PBL,
students are encouraged to develop models and then refine
them, thereby learning how models explain phenomena,
clarify complicated concepts, work as hypotheses, and
integrate pieces of information from multiple disciplines.

2198

An “Ideal” Work Flow

Conventional classroom
Instructor

Refined
Model

Hmelo-Silver (2004) depicted a typical learning circle of
PBL, also known as the PBL tutorial process, in which
students formulate and analyze the problem by going
through stages of identifying facts, generating hypotheses,
identifying knowledge deficiencies, applying new
knowledge, abstraction, then going back to the initial stages
for evaluation. Given the fact that the nature of the
pedometer problem is experimental design and hypothesis
testing, a similar learning circle can be drawn as in Figure 2.

Students

Facilitator

PBL

Students

Crude
Models

Refined
Model

F

Fact
Identification

H

Hypothesis

E

Experimental
Design

D

Data
Collection

A

Analyses

Figure 1. The role of facilitator in PBL

Evaluation

The Pedometer Problem
The PBL class discussed here was redesigned to foster and,
demand the kind of utilization and engagement with models
that is found in both research practices and ideally in
learning. The class of mostly freshman in BME was divided
into small groups of eight/nine students. Each semester, the
groups are given three problems to solve, each lasting about
five weeks. At the beginning of each problem, the students
were given only minimal instructions besides the problem
statement. They were instructed to collaborate in groups, to
work out a solution or solutions to the problem, then,
present their findings to the entire class and the facilitators
who are the faculty members in BME. These small groups
meet twice weekly and each has a facilitator.
The data collected from the PBL class included problem
statements, video footage of the meeting sessions, images
captured on the whiteboard, handouts made by students and
facilitators, PowerPoint presentations by students, and the
final written report for each problem. It also included a preand post-questionnaire on recognizing instances of MBR
that we designed.
The following was an abstract of the second problem
given to the students during our observation:
… The 10,000 Steps Program … is designed to encourage
people to reach a daily goal of walking or running 10,000
steps. Program participants use a pedometer to monitor their
activities and get feedback. However, there have been
concerns over the accuracy, reproducibility and repeatability
of measurements made with pedometers.
Your group is challenged to develop a hypothesis for
identifying a factor, other than device malfunction or user
misuse, which contributes to one of a pedometer’s low
performance characteristics (e.g., accuracy, reproducibility
or repeatability). You will then develop an experimental
design to test that hypothesis. Your hypothesis should be
formed based on a thorough study of both the physiology
behind body measurements and the sensor technology
employed in your device. Your experimental study, to be
conducted with a pedometer purchased by your group, must
be designed to use the number of human subjects necessary to
produce statistically significant results.

2199

Figure 2 An ideal work flow
As stated in the problem, students first need to identify
the factors that affect the performance of the pedometer. In
terms of experimental design, it is to identify the appropriate
dependent variables and independent variables, then, to
formulate a hypothesis or hypotheses about the statistical
relationships between these variables. Then, the
experimental conditions are planned and experimental
protocols are developed. Once the experiment is carried out
and the data are collected, statistical analyses are conducted.
Apparently, the learning process depicted in Figure 2 is
only an idealization. In the actual PBL environment, such
process will never be completed in such a linear fashion.
Although it is depicted in a top-down single direction, every
building block in Figure 2 has to be supported or
constrained by the block below. For example, to be able to
efficiently identify relevant factors, students have to first
understand the purpose of a hypothesis, e.g., to identify the
correlational or causal relationships between those factors.
If the students do not have sufficient understanding of the
required statistical tools, experimental design would not be
completed in a single pass. It is very likely that after
spending some time in planning the experimental conditions,
students realize that they do not have an appropriate
hypothesis. Then the iteration would have to be started
again somewhere. As we can see in the next section, this is
exactly what we have observed in the class. In the following,
we lay out the actual learning trajectory that occurred during
our observation.

*11H: students realized that they did not have their
own independent variables and hypothesis yet;
12F: piezoelectricity (the electronic properties of
the pedometer);
13F: considering the other two dependent variables
(repeatability and reproducibility);
14H: hypothesis version 2: walking speed and
placement of the pedometer affect accuracy;
*15E: experiment design with control groups
(using clicker to count the actual steps);
…
*20H: hypothesis version 3: “speed has greater /
less effect on accuracy than irregular steps”;
*21E: a design with a missing condition;

Actual Problem Solving Trajectory
It took 10 meeting sessions for students to finally finish this
particular problem (they met twice a week and each meeting
lasted 90 minutes). After 6 sessions into the problem,
students gave a presentation on their experimental design to
the entire class and received feedback from facilitators. At
the end of the 10 meetings, students gave a presentation and
turned in a technical report. Due to the limited space of the
present paper, we cannot report all of the class activities
here. Instead, , we list a series of significant events or the
class discussion topics and encode them into one of the
building blocks in Figure 2: Fact Identification (F),
Hypothesis Formulation (H), Experimental Design (E), Data
Collection (D), and Analyses (A). We number these events
or topics as they occurred chronologically. For example, 1E
then 2A denote a discussion on experimental design
followed by a discussion on statistical analyses. Sometimes
a topic lasted only ten minutes, while sometimes a topic
could last the entire meeting session. Events with an asterisk
denote the place where the facilitation occurred.
There are several considerations for such encoding. First
it reflects the class activities as a group, not as individuals.
Whereas every individual participant contributed to the
discussion, only the events in which the entire group
participated are reported here. Furthermore, it is important
to note that sometimes a discussion served multiple
purposes. For instance, literature search can provide
information for both Fact Identification and Hypothesis
Formulation. In this case, only one of the categories was
labeled depending on the result of the discussion, for
example, whether the discussion merely led to a list of
factors (Fact Identification) or a statement in which the
statistical relationship between the variables was specified
(Hypothesis Formulation). Another fact that needs to be
considered is that the following trajectory leaves out many
trivial steps that are less relevant to our primary interest,
such as whether to buy the pedometer online, or where to
conduct the experiments.
The following is a partial list of encoded activities from
one of the PBL groups, where a code (such as 1E, 2A) is
followed by a brief description of the event or the discussion
topic:
1E: the number of human subjects needed;
2A: the meaning of statistical significance;
3F: criterion of selecting a pedometer;
*4F: What is accuracy, reproducibility or
repeatability?
5H: What is the null hypothesis (reviewing
statistics);
6F: potential factor (physiological characteristics,
stride length, body-mass index, …);
7F: mechanical properties of pedometer;
*8H: hypothesis, version 1: the more false
movements, the mover over-count;
9F: literature search: an existing study that looked
at the placement of pedometer (hip vs. thigh)
and body-mass index;
*10E: using a table to summarize experimental
conditions (mimicking the existing study);

F

3

6

5

H

E

4

1

7

9

8

12

11

10

D

A

2

Figure 3 Actual learning trajectory
Figure 3 illustrates the trajectory in which the first twelve
steps in the list are plotted sequentially. Compared to
Figure2, Figure 3 shows a significant contrast. From the
recorded activities, we have identified many interesting
characteristics of the learning process in this PBL group. In
the following, we discuss four of them. First of all, the final
solution to the entire problem was put together by very
small pieces like a big puzzle. The learning process started
with a most trivial detail that randomly emerged, rather than
from a systematically planned workflow. For instance, in 1E,
the number of human subjects needed in the experiments
appeared in the discussion at the very beginning. In a more
conventional instruction-driven classroom, or, if the
students were well prepared in experimental design before
the PBL class, this topic would have to come very late, at
least after a testable hypothesis is developed.
Second, the learning trajectory in Figure 3 is far from a
linear process as depicted in Figure 2. It was rare for a small
topic to be finished in a single pass. The discussion usually
did not follow a single direction, and it was common for the
topic to jump back and forth. Each time a small piece of
information was added, some of the previous sub-solutions
would be revisited and modified (for example, the iteration
between fact identification and hypothesis formulation in
Figure 3).
Third, some of the links appeared to the more difficult
than others. The most obvious example was the formulation

2200

of a hypothesis, which endured at least four major revisions
throughout the process. The experimental design also
suffered as a consequence of the ill-formed hypothesis (e.g.,
20H and 21E). As we will demonstrate below, a major
intervention had to be introduced to break out of the faulty
cycle.
The fourth feature we want to bring to readers’ attention
shows another significant contrast to the learning in the
traditional more passive forms of instruction. That is, partial
solutions were achieved not by starting with the most basic
concepts, but by using concrete examples and sometimes
mimicking existing solutions. For example, when
developing their own experimental design, students
borrowed the whole paradigm from an existing study (e.g.,
in 9F and 10E), including the original independent variables.
It was only in later stages that these “shell variables” were
replaced by the factors identified from their own findings.
We reasoned that this practice was because students had
little or no prior training in statistics and yet, this turned out
to be an effective way of learning as these “shell variables”
helped students carry out the discussion on other topics
(such as selecting a pedometer for the experiment) without
getting detoured in every detail.
Since the students did not possess a complete knowledge
structure for each of the components depicted in Figure 2
they had particular difficulties at the fact finding and
hypothesis formation stages. Figure 4 illustrates that to be
able to efficiently conduct Fact Identification, one has to
understand the purpose of the search: to identify the causal
relationships between the independent variables and the
dependent variable so that a feasible hypothesis could be
formulated. Learning occurs through multiple iterations
between these two stages until the structure in Hypothesis
Formulation is sufficient enough to support the search in
Fact Identification.
F

H

IV

IV

DV

back and forth, it is very hard for students to see the big
picture. Thus, from time to time, it is important for the
facilitators to prompt students with a holistic, coherent view
of the bigger model of the problem and to provide the links
or inter-locks between small pieces of sub-solutions, in a
sense, sub-models. Scaffolding for these inter-locks can be
provided in different ways. For example, one effective
strategy was to prompt students to draw cartoons, diagrams
or graphic depictions of phenomena they were trying to
understand and apply to the problem (i.e., produce a
qualitative model of the phenomena). They were
encouraged to articulate provisional hypotheses in the form
of statements or visual and graphical depictions of the
problem situation, as they understood it. Principles or
assumptions that seemed to be guiding their process were
explicitly written on the boards, and in many occasions were
summarized in tables and matrixes.
It is also important to note that this kind of facilitation
was sometimes provided more explicitly and sometimes
more implicitly. For example, the facilitator might ask, “can
you write an equation to operationalize the term
‘accuracy’?” Or, “why don’t you draw a picture on the
board
(to
show
the
mechanism
underlining
piezoelectricity)?” Or, “What is your hypothesis regarding
the walking speed and the performance of the pedometer?”
These explicit requests would have pushed students into the
desired path by pointing to the key components of the
holistic model, such as diagrams, equation, and hypothesis.
An example of implicit prompting was when the “shell
variables” have served their purposes (e.g., 9F and 10E) and
the facilitator felt the discussion should be moved to the
next level, she simply asked the students, “Have you
identified your own factors to be used as the independent
variables?” In this way, the facilitator “peeled off” the shells
and revealed that the true purpose of this part of the
discussion was to learn the nature of experiment design, not
to merely study the effects of body-mass index on the
accuracy of a pedometer. In the meantime, students were
given as much freedom as possible to search the problem
space by themselves, thus, both content and thinking
strategies would be more firmly grasped through the
learning process.

Figure 4 Fact Identification and Hypothesis Formulation

Thinking in Graphics

It is necessary to point out that the learning trajectory
depicted in Figure 3 might be unique for the particular PBL
group documented here. For example, not every group
would have the same starting path such as 1E – 2A –.
Nevertheless, it is common that for almost all of the groups
the formation of hypotheses would take multiple iterations
such as that depicted in Figure 4. This observation suggests
the essential role of the statistical models (Hypothesis
Formation) in the entire problem-solving process, which
demands effective facilitation at several different locations.
Given the large scale of the problem and the limited time
and resources, it is very challenging for the students to work
towards a solution and organize the obtained information at
the same time. When pieces of seemingly unconnected
information are gathered and the discussion topic jumps

To make our claim more convincing, we provide an
example where facilitation was achieved by prompting
students to draw graphs on board, or, “to think graphically,”
to represent the statistical model in problem-solving. In 20H
and 21E, students reached a stage where they had selected
the dependent variable (accuracy) and the independent
variables (walking speed and gait) but could not form the
hypothesis correctly thus could not render an experimental
design. Students were very clear that they wanted to study
the effects of speed and gait on the accuracy of the
pedometer. However, the hypothesis they had at that
moment was:
“Speed has greater / less effect on accuracy
than irregular steps.”
Note that without constraining those two independent
variables, speed and gait, into a comparable scale (for

2201

discussion. Without any further help from the facilitator,
students have learned to utilize this figure in identifying an
extra variable during the stage of data analyses. That is, they
first noticed some “outliers” that were inconsistent with the
main trend of the data, and most of these data points were
collected from female subjects. They then decided to plot
the interaction for male and female subjects separately, and
they obtained two very different figures (the one for the
female subjects showed significant interaction and the one
for the male subjects did not). Recalling that they have
observed more “hip-swings” on female subjects, they
speculated that gender, or the related “hip-swing” might be
another factor that affects the pedometer accuracy. Given
the limited time and the large scale of the problem, and the
minimal involvement of the facilitators, we believe that this
is a strong piece of evidence that the PBL learning has
indeed occurred effectively through model-based reasoning.

example, in a reasonable range of daily exercise), this
hypothesis was not much different from comparing apples
and oranges. Suffering from this ill-formed hypothesis, their
experimental design was also ill-structured as in Table 1:
Table 1: An ill-structured experiment design
Slow
Natural Irregular
Pedometer
Clicker
(control)

In-accuracy

Note that in Table 1, the condition “slow” meant “slow
speed and regular gait,” “natural” meant “normal speed and
regular gait,” and “Irregular” meant “normal speed and
irregular gait.” On the surface, students were trying to
follow the principle of “vary one variable at a time” whereas
there was in fact one experimental condition “slow speed
and irregular gait” missing. At this point, the facilitator
made several requests to speed up the learning process by
breaking out the faulty circle, both implicitly and explicitly.
The first question asked by the facilitator was,
“Can you draw a graph to predict the results
from your experiment?”,
to which the students responded with a bar graph with three
columns corresponding to the three conditions in Table 1. It
was the next several requests made by the facilitator that
helped the students realize that their experiment design
needed to be corrected:
“Can you use a line graph to show the effect of
slow speed?”
“Can you use a line graph to show the effect of
irregular gait?”
“Can you combine those two graphs into one
picture?”
After several trials and errors, the “combined” graph was
finally drawn by the students as shown in Figure 5, and the
missing condition “slow speed and irregular gait” was added
to the experiment design. Note that Figure 5 is in effect a
figure of interaction in a 2x2 factorial design, a fairly
advanced topic that appears in a typical statistics textbook
for undergraduate students. Students could have been better
prepared if they have taken statistics in a conventional
classroom. Nevertheless, we felt it is important for the
students to learn the knowledge acquiring strategies through
PBL, rather than merely content learning.

slow
fast
irregular

regular

Figure 5. Experiment prediction by line graphs
It is noteworthy that this “graphically thinking” technique
has benefited the students more than once on the same
problem. The similar figures were used several times in later

Improving MBR through PBL
Finally, we hypothesize that the benefits of learning modelbased reasoning in the content-specific problems of our PBL
classes might carry over to developing MBR as a general
thinking strategy. We attempted to develop more
quantitative evidence to show the correlations between
MBR and PBL by comparing students’ learning and
problem-solving capabilities at different time intervals. For
this purpose, we developed a questionnaire to survey the
PBL class at both of the beginning and the end of the class,
to assess whether and to what extent PBL might have
facilitated the acquiring of model-based reasoning abilities.
This line of study is still at its preliminary stage. In the
following, we only briefly discuss some of the issues.
The questionnaire was developed to reflect the multiple
dimensions of model-based reasoning, based on Grosslight
et al. (1999) and Cartier, Rudolph, & Stewart (2001) (see
the introduction section). The most important consideration
was the particular nature of the PBL environment and our
goal of evaluating the situatedness of model-based
reasoning. Thus, we used a cover story in which a
researcher was to solve a problem through a series of steps,
such as literature search, generating hypotheses, drawing
diagrams, building prototypes, and conducting simulations
and experiments. Students were asked to identify the
modeling techniques that were essential to problem solving.
Out of total 64 students being surveyed, in the pretest, 31%
of them reported that forming hypotheses was important at
the beginning stage of research and in the post-test, 51%
percent of them made the same identification (increased by
20%). Consequently, as to whether it is important to reevaluate the hypothesis through experiments, 11% and 30%
responded in the pre-test and post-test, respectively
(increased by 19%). We reason that these changes in
numbers reflected the changes in students’ perception of
modeling techniques in problem-solving, and particularly in
this case, about the importance of hypothesis and its
evaluation. This kind of change is consistent with the
practices of the facilitators we have observed.
However, we believe that recognizing instances of MBR
does not necessarily translate into being able to effectively
solve problems using model-based reasoning. Whereas the

2202

assessment by survey may provide quantitative evidence on
the students’ general perception of model-based reasoning,
to assess the actual usages of certain modeling skills, such
as hypothesis formulation, graphical thinking requires
relying more on the qualitative data collected from the real
learning environment.

Conclusion
Model-based reasoning is a process of constructing
representations in the form of a model (e.g., physical models,
mathematical models) and deriving inferences through
manipulation of the model, which requires a set of desired
knowledge acquiring skills. The continuous observations
over PBL classroom activities (group discussions, white
board activities, and project presentations) provide us with
unique insights into students’ capabilities and learning
processes in situated model-based reasoning in real world
problem solving. By unpacking the dynamics of problembased learning and identifying the links that demand modelbased reasoning among different sub-components in the
problem-solving process, one would be able to plan specific
instructional moves that would strengthen such links and
speed up problem-based learning.

Acknowledgements
We gratefully acknowledge the support of the NSF grant
ROLE/REC 0106773 / REC0450578. We thank Lisa
Osbeck, Kareen Malone, Christopher Patton, and Ellie
Harmon for their contributions to the research on this
project.

References
Barrows, H. (1985). How to design a problem-based
curriculum for the preclinical years. New York: Springer.
Barrows, H. S., and Tamblyn, R. (1980). Problem-based
learning: An approach to medical education, New York:
Springer.
Cartwright, N. (1983). How the laws of physics lie. Oxford:
Clarendon Press.
Capon, N., and Kuhn, D. (2004). What’s so good about
problem-based learning? Cognition and Instruction, 22(1),
61-79.
Cognition & Technology Group at Vanderbilt (1994). From
visual word problems to learning communities: Changing
conceptions of cognitive research. In K. McGilly (Ed.),
Classroom lessons: Integrating cognitive theory and

2203

classroom practice (pp. 157-200). Cambridge, MA: MIT
Press/Bradford Books.
Collins, A., Brown, J.S., & Newman, S.E. (1989). Cognitive
apprenticeship: Teaching the crafts of reading, writing
and mathematics. In L. B. Resnick (Ed.), Knowing ,
learning and instruction: Essays in honor of Robert
Glaser (pp. 453-494). Hillsdale, NJ: Lawrence Erlbaum
Associates.
Cornelius, L. L., and Herrenkohl, L. R. (2004). Power in the
classroom: How the classroom environment shapes
students’ relationships with each other and with concepts.
Cognition and Instruction, 22(4), 467-498.
Giere, R. N. (1988). Explaining Science: A Cognitive
Approach. Chicago: University of Chicago Press.
Hesse, M. (1963). Models and analogies in science. London:
Sheed and Ward.
Hmelo-Silver, C. E. (2004). Problem-based learning: What
and how do students learn. Educational Psychology
Review, Vol. 16, No.3, 235-266.
Hmelo-Silver, C. E., and Azevedo, R. (2006).
Understanding complex systems: Some core challenges.
The Journal of the Learning Sciences, 15(1), 53-61.
Magnani, L., N. J. Nersessian, and P. Thagard, (Eds.) (1999).
Model-based reasoning in scientific discovery. New York:
Kluwer Academic Publishers/Plenum.
Morgan, M. S., and M. Morrison, (Eds.) (1999). Models as
Mediators. Cambridge: Cambridge University Press.
Nersessian, N. J. (1999). Model-based Reasoning in
Conceptual Change. In Model-based reasoning in
scientific discovery, edited by L. Magnani, N. J.
Nersessian and P. Thagard. New York: Kluwer
Academic/Plenum Publishers.
Nersessian, N. J. (2002). The cognitive basis of modelbased reasoning in science. In The cognitive basis of
science, edited by P. Carruthers, S. Stich and M. Siegal.
Cambridge: Cambridge University Press.
Nersessian, N. J. (2005). Model-based reasoning in
distributed cognitive systems. Philosophy of Science, Vol.
72, no.5.
Newstetter, W. (2005). Designing cognitive apprenticeships
for biomedical engineering. Journal of Engineering
Education, April, 2005, 207-213.
Polman, J. L. (2004). Dialogic activity structures for
project-based learning environments. Cognition and
Instruction, 22(4), 431-466.

