UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Statistical Cross-Situational Learning to Build Word-to-World Mappings
Permalink
https://escholarship.org/uc/item/14t1g2b4
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 28(28)
Authors
Smith, Linda B.
Yu, Chen
Publication Date
2006-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

         Statistical Cross-Situational Learning to Build Word-to-World Mappings
                                                   Chen Yu (chenyu@indiana.edu)
                                 Department of Psychological and Brain Sciences, Indiana University
                                                      Bloomington, IN 47405 USA
                                               Linda B. Smith (smith4@indiana.edu)
                                 Department of Psychological and Brain Sciences, Indiana University
                                                      Bloomington, IN 47405 USA
                             Abstract                                there are two objects present and one has a known name, the
  There are an infinite number of possible word-to-world             child should map a novel name to the second object, solving
  pairings in naturalistic learning environments. Previous           the word-referent mapping problem in that moment. Does
  proposals to solve this mapping problem focus on linguistic,       this kind of constraint also contribute, perhaps in a graded
  social, representational constraints at a single moment. This      way, over multiple encounters with words and potential
  paper investigates a cross-situational learning strategy based     referents? Children could use broader statistical regularities,
  on computing distributional statistics across words, across        keeping track of the associations among many words and
  referents, and most importantly across the co-occurrences of
                                                                     referents across trials, using these, and adjusting these, as
  these two at multiple moments. We briefly exposed adults to a
  set of trials containing multiple spoken words and multiple        they encounter potential words and referents. The idea that
  pictures of individual objects with no information about word-     the learning system may effectively calculate broad cross-
  picture correspondences within a trial. Nonetheless, subjects      situational statistics is suggested by recent findings on
  learned over trials the word-picture mappings through cross-       statistical learning in infants (Saffran, Aslin, & Newport,
  trial statistical relations. Different learning conditions         1996). Infants (and children, adults, and nonhuman
  compared the degree of within-trial reference uncertainty, the     primates) readily learn transitional probabilities among
  number of trials and the length of trials. We also propose and     segments in a temporal stream of syllables, tones, or visual
  implement a computational model and feed it with the same          events (Saffran, Johnson, Aslin, & Newport, 1999; Hauser,
  training data used in different learning conditions in
                                                                     Newport, & Aslin, 2001; Newport & Aslin, 2004; Conway
  experimental studies, to shed light on the possible underlying
  mechanism of statistical learning. Overall, these results          & Christiansen, 2005). All these studies concerned
  suggest that statistical cross-situational learning may be one     sequential statistics in streams of repeating segments. Here
  of fundamental mechanisms to tackle the word-to-world              we examine a different kind of statistical learning – the
  mapping problem.                                                   mapping of units between a word and a referent stream.
                                                                          Because this is the first investigation of this kind of
                         Introduction                                statistical learning, we chose to study adult language
Children learn words in ambiguous contexts, with multiple            learners, asking whether they could compute such statistics
word candidates for any referent and multiple referent               over many potential words and referents and asking the
candidates for any word. For example, a child may see a              nature of the mechanisms that underlie such learning. We
boy, a bat, a ball, and a dog and hear “Look at the boy. The         first present 2 experiments examining the capacities and
dog wants his ball.” This is the word-to-world mapping               limits of this learning. We then present a simulation study
problem (e.g. Gleitman, 1990; Bloom, 2000; Smith, 2000).             that explicitly examines how internal constraints such as the
How could a learner who knows no words associate object              proposed mutual exclusivity assumption may be embedded
names with the right referents? Developmentalists have               in these statistical mechanisms.
studied a number of solutions to this problem, including
ways in which the mature partner limits words and referents                                 Experiment 1
and directs attention to the relevant referent (Baldwin, 1993;       The power of statistical learning to overcome the mapping
Tomassalo, 2000), and internal perceptual and conceptual             problem rests on the calculation of cross-situational
constraints (Genter, 1982). This paper is concerned with an          statistics -- not just tracking, for example, the co-
additional solution, cross-situational statistical learning, a       occurrences of ``ball" with ball or ``cup" with cup but the
process in which statistics are calculated across different          co-occurrences of ``ball" with a scene containing balls and
learning instances to determine across multiple experiences,         dogs, balls alone, cups, cups and dogs, and so forth. Is this
the most likely word-referent mappings. We are also                  kind of computational mechanism at all feasible for
interested in how internal constraints, such as whole object         humans? To answer this question, adult subjects were
assumption or mutual exclusivity, may be realized or                 exposed to multiple trials wherein they heard multiple
embedded in these mechanisms.                                        spoken words while looking at multiple pictures of objects.
   Prior research has concentrated on in-the-moment                  There is a perfect one-to-one mapping of words to referents
solutions to the mapping problem. For example, the mutual            such that each of the heard words maps to one of the
exclusivity constraint (Markman, 1990) is hypothesized to            objects. However, each trial consists of multiple words and
direct children to map novel words to unnamed referents. If          multiples pictures of objects and there is no information
                                                                 918

within a trial about the associations between words and              training time (summed over all trials) constant, we also
referents (including no spatial or temporal cues). We                varied, as shown in Table 1, the length of time of each trial.
manipulated the degree of ambiguity of each learning trial,          Table 1: three learning conditions in Experiment 1.
presenting in one condition 4 words and 4 possible referents            condit    #        of # of occ.# # of time per total
on each trial (16 potential associations), 3 words and 3                ion       total        per words trials trial           time
possible referents on each trial (9 potential associations), or                   words                              (sec)
2 words and 2 possible referents (4 possible associations).             2 × 2 18                     6        54          6      324
Method                                                                  3 × 3 18                     6        36          9      324
                                                                        4× 4       18                6        27          12     324
Participants. 38 undergraduate and graduate students at              Procedure. Visual stimuli were presented by 17 inch LCD
Indiana University were tested in the experiment. Subjects           flat panel screen and the sound was played by a pair of
received course credits or $7 for their participation.               speakers connected to the same Windows PC. Subjects were
Stimuli. Subjects were exposed to three learning conditions,         instructed to map the pictures of objects showed on the
each of which included 18 novel word-object pairs. In total,         computer screen onto the spoken words in a “nonsense”
stimuli consisted of 54 visual-audio pairs in three                  language. They were told that multiple words and pictures
conditions. The potential words were generated from a                co-occurred on each individual trial and their task was to
computer program to sample broadly from the space of                 figure out which word went to which picture across multiple
phonotactically probable English. These artificial words             trials. Subjects were asked to participate in three sessions
were then produced by a synthetic female voice, presented            sequentially that corresponded to the three learning
in a monotone. 54 pictures of uncommon objects served as             conditions. The order of sessions was counterbalanced.
the visual input. The training trials were generated by              After each training session, subjects received a four-
pairing each word with a single picture. For each training           alternative forced-choice test consisting of 18 trials. For
trial, some number (depending on condition) of word-                 each testing question, subjects heard one word and were
referent pairs were selected. Specifically, on each trial the        asked to select the corresponding picture from four options
referents were simultaneously presented on the screen. The           on the computer screen.
names were then presented; however, the temporal order of
the spoken names was not related in any systematic way to
the spatial location of the referents. This is illustrated for a
condition with 2 word-referent pairs and for a condition
with 4 word-referent pairs in Figure 1. A 1000 ms silence
was inserted between spoken words.
                                                                     Figure 2: The results of three learning conditions in Experiment 1.
                                                                     Error bars reflect standard errors.
                                                                     Results and Discussion
           bispit  bofe           spati  heca   pid   gidi           The three conditions present learners with different degrees
                                                                     of in-trial ambiguity but the same across trial (for a perfect
                                                                     statistical learner) certainty of word-referent pairings. The
      (a) 2 × 2 condition        (b) 4 × 4 condition
 Figure 1: Subjects saw multiple pictures while hearing multiple
                                                                     4 × 4 condition –with four labels and four candidate
 words on each trial, and were asked to find which spoken word       referents for each learning moment (and thus 16 potential
 is paired with which picture.                                       associations)– presents the greatest in-trial uncertainty, the
                                                                     3 × 3 condition next, and the 2 × 2 condition least. As shown
       In total, there were three conditions determined by the
                                                                     in Figure 2, in-trial uncertainty appears a relevant factor
number of words and referents presented on each trial: 2 × 2
                                                                     (ANOVA test, F(2,74)=76.069, p<0.001): Learners were
(2 words and their corresponding referents), 3 × 3 (3 words
                                                                     better able to discover the correct word-referent in the 2 × 2
and their corresponding referents), and 4 × 4 (4 words and
                                                                     condition (M=15.897, SD=2.506) and least able in the 4 × 4
their corresponding referents). In each condition, there were
                                                                     condition (M=9.461, SD=2.907) with performance in the
18 unique word-picture pairs, and each unique word and
                                                                     3 × 3 condition falling in between (M=13.692, SD=3.507).
corresponding unique referent were presented on a total of 6
                                                                     However, the most important result is that in all conditions,
training trials. This means, as shown in Table 1, that the
                                                                     including 4 × 4, subjects performed reliably above chance
total number of trials (of 2 pairs, 3 pairs or 4 pairs) is
                                                                     (t(37)=8.785,p<0.001, one-tailed, for 4 × 4). Given the in-
different over the three conditions. In order to keep the total
                                                                     trial ambiguity, they must be calculating statistics across
                                                                     trials.
                                                                 919

     There are a number of potential explanations of the
differences among the three conditions, including the central
variability of degree of in-trial uncertainty but also the
additional necessary confoundings of numbers of trials and
length of trial. We investigate these factors in Experiment 2.
                        Experiment 2
Experiment 2 was designed to replicate the findings in
Experiment 1 and further investigate under what
circumstances, subjects would be able to achieve
significantly better performance in the most ambiguous
condition of Experiment 1, the 4 × 4 condition in which each         Figure 3: the results in three conditions in Experiment 2. Error
trial offered 16 possible word-referent associations. In             bars reflect standard errors.
contrast to Experiment 1, and as summarized in Table 3, we          duplicable. The above two observations are quite in line
probe the nature of statistical learning by manipulating two        with what we expected.
aspects of the training regime: : (1) the number of                 However, as shown in Figure 3, in all three conditions,
repetitions of each word-referent pair and (2) the total            subjects –in terms of the proportion of word-referent pairs
number of word-referent pairs to be learned.                        to be discovered – performed equivalently (F(2,54) = 0.052;
Method                                                              p<0.001). A direct comparison between 18 words/6
Participants. 28 undergraduate students at Indiana                  repetions (M=0.534, SD=0.232) and 9 words/12 repetitions
University were tested in this experiment. None of them             (M=0.609, SD=0.176) conditions shows that they have the
participated in Experiment 1.                                       same number of trials, the same training time and the same
Stimuli. all three conditions in Experiment 2 use the 4 × 4         within-trial ambiguity. The only two different factors are:
presentation of 4 words and 4 pictures on each trial.               (1) the number of unique pairs and (2) the number of
However, in the 9 words, 8 repetitions condition, subjects          occurrences per pair, which was expected to make one
attempt to discover a total of 9 word-referent pairs each           condition easier than the other. However, the results in these
repeated 8 times over the course of training. In the 9 words,       two conditions are quite similar. An intuitive explanation is
12 repetitions condition, subjects attempt to discover 9            that the number of co-occurring pairs plays a dominant role
word-referent pairs but are given 4 additional repetitions of       in statistical word learning and other factors are not so
each word-referent pair. Finally, the third condition is a          important conditioned on that factor. But why is that? Our
replication of the 4 × 4 condition of Experiment 1; there are       following computational study provides a plausible answer
18 word-referent pairs to be learned and 6 repetitions of           to these behavioural data.
each. In contrast to Experiment 1, total viewing time per
slide was kept constant and thus the total number of trials                                     Simulation
and total length of the experiment varied across conditions.        The above two experiments document the performances of
Table 2 The statistics of the stimuli in 3 learning conditions.     adults in statistical word learning. We demonstrated what
   learning          # of # of occ.# # of          time total       they can do given cross-situational observations. The next
   condition         total      per        trial   per time         question to ask is how they do that -- the underlying
                     words word                    trial            computational mechanisms that support statistical word
   9 words/                                                         learning. Since there is no information at the beginnings to
   8 repetitions           9        8        18       12   216      guide them to discover correct word-referent pairs among
   9 words/                                                         all possibilities, they must start with randomly selecting
   12 repetitions          9        12       27       12   324      some hypothesized pairs and then gradually justify the
   18 words/                                                        correctness of those pairs later. Following this general
   6 repetitions         18         6        27       12   324      principle, the specific questions in statistical word learning
                                                                    are (1) how hypothesized pairs are selected and stored from
Procedure. The procedure is the same with that of Exp. 1.           a trial? (2) how subjects justify whether a word-object pair
Results and Discussion                                              is correct? (3) whether they use the mutual exclusivity
There were 4 words and 4 pictures in a single trial in the          constraint if two working hypothesized pairs are not
three conditions, which contained a high degree of                  compatible? and (4) whether they would use previously
ambiguity at each individual moment (trial). However,               learned pairs to help the learning of new pairs in subsequent
subjects in all conditions again discover more pairs than           trials? The following simulation study attempts to answer
expected by chance as shown in Figure 3 (t(27) > 6.4 in all         those questions by showing a dynamic picture of the real-
three conditions). In addition, the results in 18                   time learning when the simulated learner is fed with the
words/6repetions condition of this experiment (M=9.629,             same stimuli that subjects were exposed.
SD=3.076) are very similar to the same condition in
Experiment 1, suggesting that our results are reliable and
                                                                920

Training:                                                                                                                                                                                                                      ( pn2 , wm2 , c n2m2 ),......, ( p nk , wmk , c nk mk )} while         n j and   m j can be
-- Randomly select one pair from Trial #1 and store it in the                                                                                                                                                                  selected separately from 1 to 18, and cn m is the confidence
memory as the first hypothesized pairing.                                                                                                                                                                                                                                                         j   j
-- Repeat the following steps for Trial #i ( 2 ≤ i ≤ 27 ):                                                                                                                                                                     score of a pair. Thus, the equivalence of n j and m j indicates
 a. Check the pairs in the memory M and use those with a high                                                                                                                                                                  a correct pairing.
 confidence score cn m to filter the input of the current trial Ti .                                                                                                                                                              At the beginnings, the model randomly picks one word
                                                        j       j
                                                                                                                                                                                                                               and one picture from a trial and builds a hypothesized
 b. Randomly selection a new pair ( p new , wnew ) from Ti .
                                                                                                                                                                                                                               pairing. With more trials, more pairings are built and stored
 c. Comparing ( p new , wnew ) with the parings in M:                                                                                                                                                                          in the memory. Two additional mechanisms are utilized to
  if ( p new , wnew ) ∈ M                                                                                                                                                                                                      make this learning process more effective. First, one
     Increase the confidence score of the corresponding                                                                                                                                                                        important constraint in adding new pairs is to maintain the
                                                                                                                                                                                                                               consistency of hypothesized pairings so that one word can
pairing cn m .
            j       j                                                                                                                                                                                                          be associated with only one picture. This constraint
  else if pnew ∉ { pn , pn ,......, pn } and wnew ∉{wn , wn ,......, wn }                                                                                                                                                      explicitly encodes the proposals such as mutual exclusivity
                     1    2           k               1    2           k
     Add the pair into M as ( pn , wm , cn m ) and cn m = 1 .                                                                                                                                                                  (Markman, 1990) and contrast (Clark, 1987) into the
                                                                                                                k +1                    k +1       k +1   k +1                               k +1   k +1                       learning machinery and by doing so makes the learning
  else if pnew ∉{ pn , pn ,......, pn } and wnew ∈ {wn , wn ,......, wn }                                                                                                                                                      more efficient because the simulated learner would
                                            1               2                                           k                                                        1               2                         k
     Finding the pairing ( pn , wm ) in M while wm = wnew .                                                                                                                                                                    randomly select many conflicting (and therefore incorrect)
                                                                                            j                       j                                                        j
                                                                                                                                                                                                                               word-picture pairs across multiple trials without this
       If pn ∈ { pi , pi , pi , pi } then increase cn m by 1,                                                                                                                                                                  constraint. Second, the model keeps track of the confidence
                        j               1           2               3               4                                                                        j j
       Otherwise replace ( pn , wm , cn m ) with ( pnew , wnew ,1) .                                                                                                                                                           score of each pair. When the confidence score of a pair is
                                                                                                j                       j           j     j
                                                                                                                                                                                                                               above a certain threshold, this pair will be treated as a
  else if: pnew ∈ { pn , pn ,......, pn } and wnew ∉ {wn , wn ,......, wn }                                                                                                                                                    learned lexicon and then used to filter out the input in
                                                1                   2                                           k                                                    1               2                         k
    Finding the pairing ( pn , wm ) in M while pn = pnew .                                                                                                                                                                     subsequent trials, which can significantly simplify the
                                                                                            j                       j                                                    j
                                                                                                                                                                                                                               learning task. For instance, if a learned pair occurs in a new
     If wm ∈ {wi , wi , wi , wi } then increase cnjmj by 1,                                                                                                                                                                    trial, it will be removed from the stimuli to reduce a 4-4
                j               1           2               3               4
    Otherwise replace ( pn , wm , cn m ) with ( pnew , wnew ,1) .                                                                                                                                                              condition into a 3-3 condition. More importantly, subjects in
                                                                                    j                       j               j   j                                                                                              empirical studies informed experimenters that they used the
Testing:                                                                                                                                                                                                                       similar filtering strategy in the later part of the training
   For ith question {wi , pi , pi , pi , pi } ,                                                                                                                                                                                phase when they were confident that some word-picture
                                                                1               1                   2                   3           4
   If wi ∈ {wn , wn ,......, wn } , find the corresponding pair                                                                                                                                                                pairs were correct. The detailed learning algorithm is
            1                       1           2                                       k
                                                                                                                                                                                                                               described in Figure 4.
   ( pn , wm ) in M while wm = wi1 and check whether p n == pi ;
        j           j                                                                   j                                                                                                            j               1         Results and Discussion
   Otherwise,         among { pi , pi , pi , pi } , remove    those                                                                                                                                                            We applied the same training and testing data in the
                                                                                                1                       2       3              4
                                                                                                                                                                                                                               previous experiments to the simulated learner. For each
    pi ∈ { pn , pn ,......, pn } and randomly select an answer from
      1−4                   1           2                               k
                                                                                                                                                                                                                               condition, the simulation was run for 5000 times. Thus, we
   the left items.                                                                                                                                                                                                             had 5000 simulated subjects (with the same set of
    Figure 4: Statistical cross-situational learning algorithm.                                                                                                                                                                parameters) for each condition. Note that the fundamental
                                                                                                                                                                                                                               mechanism encoded in our model is to randomly select and
 Method                                                                                                                                                                                                                        store hypothesized pairs. Therefore, quite different results
 The 4 × 4 condition has been tested in both experiments and                                                                                                                                                                   were obtained on each run depending on what pairs were
 therefore is used as an example to show how the model                                                                                                                                                                         selected from trial to trial. We used 5000 simulated subjects
 works. The simulations on other conditions can be achieved
 by applying the corresponding stimuli to the same model. In                                                                                                                                                                                            1
                                                                                                                                                                                                                                                                                                  human subjects
 the 4 × 4 condition, the 18 novel word-picture pairs can be                                                                                                                                                                                                                                      simulated learners
 represented as {( p1 , w1 ), ( p2 , w2 ),......( p18 , w18 )} . In the ith trial,                                                                                                                                                                     0.8
                                                                                                                                                                                                                                  proportion correct
 the stimuli are                                            Ti = { pi1 , pi2 , pi3 , pi4 , wi1 , wi2 , wi3 , wi4 }                                                                                         while
                                                                                                                                                                                                                                                       0.6
 i1 , i2 , i3 and i4 can be selected from 1 to 18. And there is no
 information as to which picture goes with which name. We                                                                                                                                                                                              0.4
 also assume that the simulated learner maintains a list of
 hypothesized pairings as learned results from previous trials.                                                                                                                                                                                        0.2
 Moreover, the learner assigns a confidence score for each
 pair in his memory to indicate the likelihood that the pair is                                                                                                                                                                                         0
                                                                                                                                                                                                                                                             2x2   3x3           4x4            9 words/ 8      9 words/ 12
 correct. His lexical knowledge at the ith trial can be then                                                                                                                                                                                                                                    repetitions     repetitions
 represented as a list of pairs M = {( pn , wm , cn m ),
                                                                                                                                                                                         1          1          1 1
                                                                                                                                                                                                                                   Fig 5: A comparison of human subjects and simulated learners.
                                                                                                                                                                                                                         921

to ensure the statistical power of this simulation study and          Therefore, adult studies can be used as first steps and proof-
the results are shown in Figure 5.                                    of-concept before conducting infant studies (Saffran,
We observed that in general the results in simulation are             Newport, & Aslin, 1996; Newport & Aslin, 2004). In fact,
quite in line with those of human subjects, suggesting that if        our on-going studies on young children apply the same
subjects apply a simple statistical learning machinery like           experimental paradigm and the same visual-auditory stimuli
the one in our model, then that could explain their superior          used in the present study.
performances. Admittedly, different subjects may apply
different learning strategies and there is no way to encode           Key Factors in Cross-Situational Learning
all the possible strategies that they applied to the stimuli in a     The five learning conditions in two experimental studies
single model. Nonetheless, the current model intends to               provided different kinds of statistical regularities for
implement one learning device based on general principles.            learning. We will focus on two important factors discovered
The similarities of the results between human subjects and            through these manipulations.
simulated subjects are consistent not only in one condition              First, the dominating factor in the cross-situational
but among multiple conditions, indicating that the learning           learning is the number of co-occurring word-picture pairs, a
principles encoded in our model are plausible to be similar           result confirmed in both experiments and simulation. This
with those guiding the learning of human subjects. We will            factor determines the probability of selecting a correct pair
discuss why simulated learners couldn’t achieve a better              from a trial. Specifically, the probability of picking a correct
performance in the 9 pairs/12 repetitions condition in the            pair is 2 out of 4 in the 2 × 2 condition, 3 out of 9 in the 3 × 3
next section.                                                         condition, and 4 out 16 in the 4 × 4 conditions. Note that if
We also note that one reason for individual differences in            subjects select an irrelevant pair, there are two possible
this type of learning task is that if learners just randomly          consequences: (1) they select the corresponding correct pair
select pairs and justify them later based on distributional           later and based on the mutual exclusivity constraint, exclude
information, then the results obtained from different trials of       the wrong pair; (2) they never receive evidence to justify the
running the same model could be quite different. In some              pairing so based on their limited exposure, they could either
cases, simulated learners may happen to pick correct pairs in         believe that the pairing is correct or ignore this pair in
the first trials which will help subsequent learning through          testing. To sum up, whenever subjects select a wrong pair,
the filtering mechanism. In other cases, they might pick the          which is almost unavoidable, the pairing would either
wrong ones and have to justify and correct those pairs in the         require their justification in subsequent trials to correct it in
later trials. Thus, the randomness in pair selection may also         the best case or lead to wrong answers in testing in a worse
cause those human subjects, who apply the same learning               case. Therefore, the probability of selecting a correct pair
mechanism on the same data, to achieve quite different                plays a key role in learning, no matter what learning
results.                                                              algorithms are applied to those hypothesized pairs later.
                                                                          The second factor is the total number of unique pairs. We
                    General Discussion                                found that the 9 pairs/12 repetitions condition is not
Statistical Learning                                                  significantly better than the 18 pairs/6 repetitions condition.
The learning situations such as those used in the present             One plausible reason is that the probabilities of selecting a
experiments have generally been considered too complex                correct pair from a trial in these two conditions are the
for word learning. Yet the present results show that adults           same. With this low probability (=0.25), word learners
rapidly discover word-referent mappings in these contexts.            would be likely to randomly select a wrong pair from a trial
The only solution to the mapping problem is the                       and later have to exclude it. From our simulation, we also
distributional co-occurrence statistics between spoken                found that with 4-pair in a trial and 9 word-picture pairs in
words and pictures of objects. Our findings in statistical            total, it is more likely that two word-picture pairs (e.g. p1 -
word learning extend those of Saffran, Aslin, & Newport                w1 and p2 - w2 ) co-occur more frequently across multiple
(1996), and Newport and Aslin (2004) in word                          trials in the 9 pairs/12 repetitions condition compared with
segmentation, Gomez & Gerken (1999) in syntax learning,               selecting 4 out of 18 in the 18 pairs/6 repetitions condition.
and Conway & Christiansen, (2005) in visual and tactile
                                                                      If word learners happen to select a wrong pairing (e.g. p1 -
sequence learning by showing that statistical learning
broadly characterizes human learning, and that human                   w2 or p2 - w1 ) in multiple times from those trials, then they
learners can exploit cross-trial regularities over many               may “confidently” reach wrong conclusions. Thus, the
potential word and referent pairs.                                    fewer number of word-picture pairs in total causes irrelevant
  Conclusions relevant to development are limited by our              (false) word-referent pairs to repeatedly co-occur in multiple
use of adult subjects. Nonetheless, recent studies in word            trials, which may mislead word learners if they happen to
learning (e.g. Gillette, Gleitman, Gleitman, & Lederer,               pay attention to wrong pairings. This in fact makes the
1999; Snedeker & Gleitman, 2004) proposed a Human                     learning situation harder but not easier. The claim that more
Simulation Paradigm (HSP), suggesting the value of                    pairs are better than fewer in statistical learning sounds
examining potential general learning mechanisms in adults             quite controversial. This is somehow an intriguing and
as a way to study the potency of various cues to word                 compelling finding.
learning that might be available in the learning environment.
                                                                  922

Modeling Statistical Cross-Situational Learning                     studies to infants and young children to investigate how
Our model encodes a very fundamental (and rather simple)            well they could utilize statistical cues to tackle the word-to-
mechanism – building one hypothesized pair from a trial,            world mapping problem.
saving it in the memory, gradually adding more pairs,                                         References
justifying the correctness of a hypothesized pair in                Baldwin, D. (1993). Early referential understanding: Infant'  s
subsequent trials, and removing conflicting pairs if needed.           ability to recognize referential acts for what they are.
However, similar to adult learners, the model achieved quite           Developmental psychology (29), 832-843.
impressive performances in highly ambiguous learning                Bloom, P. (2000). How children learn the meanings of
conditions, suggesting that a powerful statistical learning            words. Cambridge, MA: The MIT Press.
capability can be achieved by a relatively simple learning          Conway, C. & Christiansen, M.H. (2005). Modality
mechanism. We also argue that this general learning                    constrained statistical learning of tactile, visual, and
principle has been applied more or less by human subjects.             auditory sequences. Journal of Experimental Psychology:
They may differ in the number of hypothesized pairs they               Learning, Memory & Cognition, 31, 24-39.
could select and memorize from a trial, or in the way to            Clark, E.V. (1987). The Principle of Contrast: a constraint
decide which pairs to be selected, or in how many                      on language acquisition. In B. MacWinney (Ed.),
hypothesized pairs could be saved in the memory, or in                 Mechanisms of language acquisition (pp. 1-33): Hillsdale,
                                                                       NJ: Lawrence Erlbaum Associates.
when and how to justify those hypothesized pairs in the
                                                                    Gentner, D. (1982). Why nouns are learned before verbs:
memory. Nonetheless, the general learning mechanism
                                                                       Linguistic relativity versus natural partitioning. In S. A.
could be quite similar to the model described above and all
                                                                       Kuczaj II (Ed.), Language development (Vol. 2).
those factors mentioned above can be treated as the                    Hillsdale, NJ: Erlbaum.
parameters of this general learning model. Two important            Gillette, J., Gleitman, H., Gleitman, L., & Lederer, A.
mechanisms that make the model work more effectively are               (1999). Human simulations of vocabulary learning.
(1) one-word-to-one-object constraint and (2) using learned            Cognition, 73, 135-176.
pairs to filter new input. We noticed that the one-to-one           Gleitman, L. (1990). The structural sources of verb
constraint is especially useful in learning. Compared with             meanings. Language Acquisition, 1 1-55.
previous studies, we demonstrate, both experimentally and           Gomez, R. L., & Gerken, L. (1999). Artificial grammar
computationally, the role of this constraint across multiple           learning by 1-year-olds leads to specific and abstract
trials (but not in a single moment), the learning situation            knowledge. Cognition, 70(2), 109-135.
that is more representative of naturalistic learning                Hauser, M. D., Newport, E. L., & Aslin, R. N. (2001).
environments that children are situated in. The fact that the          Segmentation of the speech stream in a non-human
mechanism encoding with this type of constraint achieved               primate: statistical learning in cotton-top tamarins.
similar learning performance with human subjects indicates             Cognition, 78(3), B53-64.
the plausibility that subjects utilize at least similar (if not     Markman, E. M. (1990). Constraints Children Place on
identical) constraints. Moreover, by feeding the model with            Word Learning. Cognitive Science, 14, 57-77.
the same stimuli that subjects were exposed in the training         Newport, E. L., & Aslin, R. N. (2004). Learning at a
phases and asking the model to do the same tests after                 distance I. Statistical learning of non-adjacent
training, we can demonstrate moment-to-moment changes                  dependencies. Cognitive Psychology, 48(2), 127-162.
in statistical learning processes that human subjects might         Saffran, J. R., Aslin, R. N., & Newport, E. L. (1996).
experience.                                                            Statistical learning by 8-month-old infants. Science,
                                                                       274(5294), 1926-1928.
                        Conclusion                                  Saffran, J. R., Johnson, E. K., Aslin, R. N., & Newport, E.
                                                                       L. (1999). Statistical learning of tone sequences by human
Previous studies show that statistical learning is applied in          infants and adults. Cognition, 70(1), 27-52.
various learning tasks, such as speech segmentation,                Saffran, J. R., Newport, E. L., & Aslin, R. N. (1996). Word
syntactic learning and visual processing. In light of this, we         Segmentation: The role of distributional cues. Journal of
study to what degree language learners can acquire word-to-            memory and language, 35, 606-621.
world mappings through statistical regularities in co-              Smith, L. B. (2000). How to learn words: An Associative
occurring visual-auditory streams. We showed that a                    Crane. In R. Golinkoff & K. Hirsh-Pasek (Eds.), Breaking
significant amount of lexical knowledge can be learned                 the word learning barrier (pp. 51-80): Oxford: Oxford
through statistical learning. Moreover, we systematically              University Press.
manipulated different statistical properties of the stimuli and     Snedeker, J., & Gleitman, L. (2004). Why it is hard to label
measure the learning capacities of adult learners in various           our concepts. In G. Hall & S. R. Waxman (Eds.),
learning conditions. To understand underlying learning                 Weaving a Lexicon. Cambridge,MA: MIT Press.
mechanisms, we developed a computational model that was             Tomasello, M. (2000). Perceiving intentions and learning
fed with the same stimuli of human subjects, and simulated             words in the second year of life. In M. Bowerman & S.
learners achieved similar performances as human learners.              Levinson (Eds.), Language acquisition and conceptual
In this way, we obtained a more complete picture of                    development (pp. 111-128): Cambridge University Press.
statistical word learning. Our next step is to extend current
                                                                923

