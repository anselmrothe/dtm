UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
A Computational Developmental Model of the Implicit False Belief Task
Permalink
https://escholarship.org/uc/item/69q7s0g6
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Berthiaume, Vincent G.
Onishi, Kristine H.
Shultz, Thomas R.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

          A Computational Developmental Model of the Implicit False Belief Task
                                 Vincent G. Berthiaume (Vincent.Berthiaume@McGill.ca)
                                        Department of Psychology, 1205 Dr. Penfield Avenue
                                                     Montreal, Qc, H3A 1B1 Canada
                                         Kristine H. Onishi (Kris.Onishi@McGill.ca)
                                        Department of Psychology, 1205 Dr. Penfield Avenue
                                                     Montreal, Qc, H3A 1B1 Canada
                                        Thomas R. Shultz (Thomas.Shultz@McGill.ca)
                       Department of Psychology and School of Computer Science, 1205 Dr. Penfield Avenue
                                                     Montreal, Qc, H3A 1B1 Canada
                             Abstract                                  years and eight months (Wellman, Cross, & Watson, 2001)
  Do children understand that others have mental
                                                                       will typically say that Sally will search in the box, an
  representations, for instance, mental representations of an          expectation that is consistent with an omniscient ToM – i.e.,
  object’s location? This understanding, known as a                    Sally will search in the actual location of the object. An
  representational Theory of Mind (ToM) has typically been             older child will instead typically say that Sally will search in
  studied using false-belief (FB) tasks. Standard, verbal FB           the basket, an expectation that is consistent with a
  tasks test whether a child can use protagonists’ beliefs to say      representational ToM – i.e., Sally will search for the object
  that they will search for objects where they last saw them.          in accord with her mental representation of its location.
  Whereas children under 3.5 years typically fail the task and
  expect protagonists to search where objects are (expectation            Recently, 15-month-olds were shown to solve a visual,
  consistent with an omniscient ToM), older children expect            implicit version of the task (Onishi & Baillargeon, 2005).
  protagonists to search where they last saw the objects               Because it avoids the complexities of language, the implicit
  (expectation consistent with a representational ToM).                task is more amenable to computational modeling. This
  Recently, 15-month-olds were shown to succeed at a visual,           paper introduces a connectionist model that learns to solve
  implicit version of the task. We present a sibling-descendant        the implicit false-belief task and that reproduces the
  cascade-correlation connectionist model that learns to succeed
                                                                       omniscient-to-representational ToM transition when training
  at an implicit FB task. When trained on twice as many true- as
  false-belief trials, our model reproduced the omniscient-to-         contained more true- than false-belief trials.
  representational transition observed in explicit tasks. That is,
  networks first had expectations consistent with an omniscient                    The Implicit False-Belief Task
  ToM, and after further training had expectations consistent
                                                                       Onishi and Baillargeon (2005) used a violation-of-
  with a representational ToM. Thus, our model predicts that
  infants may also go through a transition on the implicit task,       expectation paradigm to show that 15-month-olds could
  and suggests that this transition may be due in part to people       pass an implicit, language-free version of the false-belief
  holding more true than false beliefs.                                task. This paradigm uses looking time as a dependent
                                                                       measure of surprise. Infants – just like adults – look longer
  Keywords: False beliefs; theory of mind; connectionism.              at the unexpected.
                                                                          Infants were seated on their parent’s lap and watched an
                          Background                                   actor performing actions with two boxes (one green and one
                                                                       yellow) and an object (Onishi & Baillargeon, 2005). First in
Do children understand that others have mental                         familiarization trials, infants were shown the actor puting
representations, for instance, mental representations of an            the object in the green box, as if to hide it there. Then on
object’s location? This understanding – known as a                     two trials the actor searched in the green box as if to retrieve
representational Theory of Mind (ToM, Wimmer & Perner,                 the object (without actually revealing it) to convey to infants
1983) – has been found, using explicit false belief tasks, to          that she wanted it. Next, infants saw one of four belief-
go through a developmental transition between 3 and 4                  induction trials designed to cause the actor to hold either a
years of age.                                                          true belief (TB) or a false belief (FB) that the object was
  In this task, children see a puppet named Sally put a                either in the green or yellow box. For instance, in the TB-
marble in a basket that is next to a box. While Sally is gone,         yellow trial, infants saw the actor watching as the object
another puppet, Anne, moves the marble from the basket to              moved from the green box to the yellow box, thus causing
the box, thereby leaving Sally with the false belief that the          the actor to hold a TB that the object was in the yellow box.
marble is still in the basket. To predict that Sally will search       By contrast, in the FB-green trial, another group of infants
for the marble in the basket, children must understand that            saw, as the actor was absent from the scene, the object move
she has a mental representation of the scene that is not               from the green into the yellow box, thus causing the actor to
consistent with reality (Dennett, 1978). A child under three
                                                                   825

have a FB that the object was still in the green box. The TB-      coherence between concepts is what leads to poor
green and FB-yellow trials were constructed with similar           performance. In their model, the authors connected elements
manipulations, the actor watching or not as the object was         roughly corresponding to propositions from the explicit FB
moved from (or stayed in) the green box. Finally, each             task, e.g., “Sally puts marble in basket”, etc., with either
infant saw one of two test trials in which the actor searched      positive links between coherent elements or negative ones
in either the green or yellow box. As can be seen in Figure        between incoherent elements. Depending on which values
1, infants expected the actor to search according to her           the experimenters assigned to the connections, the model
belief, whether true or false, and looked reliably longer          made different predictions about where Sally would search.
when she did not do so. When the actor’s belief (true or           This model covered the pattern of data – predictions
false) suggested that the object was in the green box, infants     consistent with an omniscient ToM with some parameter
looked reliably longer when the actor searched in the yellow       values and predictions consistent with a representational
box (white bar is taller than gray bar in TB-green and in FB-      ToM with others. However, because the patterns of
green), while when the actor’s belief suggested the object         connectivity for the two sets of expectations were built in by
was in the yellow box, infants looked reliably longer when         the programmers, it is not really a developmental model.
the actor searched in the green than the yellow box (gray bar      The model did not go through the omniscient to
is taller than white bar in TB-yellow and FB-yellow).              representational ToM transition on its own.
                                                                   Triona, Masnick and Morris (2002)
                                                                   Triona, Masnick, and Morris’ (2002) model used the ACT-
                                                                   R production system (e.g., Anderson et al., 2004) to model
                                                                   failure and success on a FB task (Perner, Leekam, &
                                                                   Wimmer, 1987). Triona et al. (2002) reproduced the
                                                                   observed transition in children's responses “by manipulating
                                                                   … the probability that the production [output] would
                                                                   achieve the goal” (p. 1045). When the probability parameter
                                                                   was low, the output was wrong (e.g., predicting Sally would
                                                                   search in the box), but when the parameter was high, the
                                                                   output was correct (e.g., predicting Sally would search in
                                                                   the basket). Once again, this model covered the
                                                                   experimental data through parameter manipulation by the
                                                                   experimenters, and is thus not a model that undergoes an
                                                                   autonomous developmental transition.
   Figure 1: Infants’ mean looking time and SE bars for the        Goodman and colleagues (2006)
   implicit FB task in the eight task conditions (four belief-     Goodman et al. (2006) built two causal Bayesian networks
  induction by two test trials). From Onishi and Baillargeon       for the FB task. In the omniscient network, Sally’s belief
        (2005). Reprinted with permission from AAAS.               depended only on the marble’s location, whereas in the
                                                                   representational ToM network, Sally’s belief depended both
   In sum, this work showed that 15-month-olds can succeed         on the marble’s location and Sally’s visual access to the
at an implicit false-belief task involving an approach goal.       marble’s displacement. This difference made the omniscient
In contrast, not before 44 months are children able to             network fail the FB task and the representational one
reliably succeed at the verbal version of an approach task.        succeed, but the extra connection also made the
Because it avoids language, the implicit task is more              representational network more complex. Goodman et al.’s
amenable to computational modeling and it is the task we           model suggested that it would be parsimonious for children
chose to model. Before introducing our model, we review            to first use the simpler omniscient theory, but after
previous computational models of explicit FB tasks; no             accumulating evidence for its inadequacy, it would make
model of the implicit task has been proposed before.               sense to switch to the more complex representational theory.
Although the explicit and implicit tasks differ substantially,     The model learned the posterior probability distributions of
comparisons between our model and previous models of the           the search location from prior probability distributions,
explicit task are possible because those models did not            showed that expectations consistent with a representational
explicitly incorporate language.                                   ToM required more computational resources than do
                                                                   expectations consistent with an omniscient ToM, and
        Previous Models of False Belief Tasks                      switched from predictions consistent with an omniscient
                                                                   ToM to those consistent with a representational ToM.
O'Laughlin and Thagard (2000)                                      However, the architecture of both Bayesian networks were
O'Laughlin and Thagard’s (2000) model of the standard FB           built by the experimenters, and by choosing which networks
task was based on the hypothesis that the inability to find        to include in the model, the set of possible transitions was
                                                               826

restricted to only 2; simple to complex (as the model                of the object but not the other three locations. One input unit
selected) or complex to simple, thus showing an                      encoded whether the actor was watching or not as the object
autonomous transition but one that was highly constrained.           moved. The tenth and last input encoded experimental
   In sum, previous computational models typically required          context, a random value (between 0 and 1, selected from a
substantial experimenter manipulation and involved                   uniform distribution) used to facilitate the network’s
restricted or no autonomous development. These issues are            stochastic training. As explained below, networks were
naturally addressed by our model, because it uses                    trained on observations of behaviour that were not always
constructive neural networks.                                        correct in order to have training that is more like everyday
                                                                     observations. This type of stochastic training is problematic
                           Experiment                                for deterministic neural networks because they cannot match
We conducted an experiment using fifty-six neural networks           different outputs to the same input. By adding an input node
implementing the sibling-descendant cascade-correlation              encoding a value randomized for each trial, much like
(SDCC, Baluja & Fahlman, 1994) constructivist algorithm,             different contexts for human experiences (time of day, etc.),
which has been successful in modeling numerous                       our networks were able to learn the task.
psychological phenomena (e.g., Shultz & Bale, 2006). Our
model learns to succeed at the implicit false-belief task and
transitions from omniscient to representational ToM
expectations with additional training. It does not require
parameter manipulation to make that transition but does
require more true- than false-belief information in training.
In effect, most of the time, beliefs are true (Leslie, German,
& Polizzi, 2005), and this could potentially lead three-year-
olds to expect others to hold true beliefs by default. Also, it
may require more sustained attention to process or perceive
a false-belief situation simply because there are more pieces
of information to track for a longer time (previous location
of the object, actor not looking as the object moves, etc.)
compared to true-belief situations, in which infants could            Figure 2: Schematic of an initial network used to model the
simply rely on their own knowledge of the object’s location.          learning of false beliefs. In the displayed event, the actor is
For these reasons, networks were trained on twice as many               looking (eye is present in the middle bottom unit) as the
true- as false-belief trials. When equal numbers of true and          object moves from the fourth location to the third location.
false belief trials were included during training, our model
succeeded at the task without first going through a period of        Output Our model had 4 output nodes that represented in
omniscient expectations.                                             which, out of the 4 locations, the model predicted searching
                                                                     (see Figure 2). We simulated looking times by comparing
Method                                                               the outcome the model predicted to the outcome that would
Initial Network Structure In everyday life, there are                be expected with a representational ToM, with larger
almost always multiple locations that an object can be. We           discrepancy or error corresponding to longer looking times
trained networks using four locations. There is nothing              (Shultz & Bale, 2001).
special about four locations, but we wanted more than two               The output nodes encoded the probability (between 0 and
for increased realism. Figure 2 represents the model in its          1) that the actor would search in each location (asigmoid
initial state, i.e., with input and output units but without any     activation functions compressed the net input to an output
hidden units. Constructivist networks such as SDCC are               unit into the range 0-1). For instance, if a network’s output
initialised without any hidden units, but they recruit them as       was red = 0.10, yellow = 0.70, blue = 0.05, green = 0.15,
more computational power is required in training.                    this was interpreted as the network expecting search in red
                                                                     10% of the time, in yellow 70% of the time, in blue 5% of
Input The model’s inputs represent the critical factors that         the time, and in green 15% of the time.
govern searching behaviour and predictions made by an
observer about that behaviour. The inputs encoded: (1) the           Training In everyday life, people probably do not always
first location of the object, (2) the second location of the         search for objects where they last saw them, because they
object, (3) whether the actor was watching when the object           forget, were distracted, etc. Therefore, networks were
was moved and (4) experimental context.                              trained with observations of searching that were correct 18
   Four input units represented in which of the four locations       times out of 21, or 85.7% of the time, to increase training
the object started. These locations could be thought of as           realism. For example, if the actor should believe the object
red, yellow, blue, and green boxes. Another four inputs              was in blue, the network was trained 85.7% of the time on
represented where the object ended up. The object’s location         correct trials (search in blue) and 14.3% of the time on
for a given time step was encoded by activating the location
                                                                 827

incorrect trials (search in red, yellow or green, equally at           as in the infant experiment (Onishi & Baillargeon, 2005).
random).                                                               The mean network error on these 2 nodes was calculated as
   Before training, SDCC networks do not have any hidden               the sum of squared difference between the network output
units, but only have direct connections between input and              and the target location, for each condition of the infant
output units. During training, the network updates its                 experiment.
weights, reducing error at the output. When error fails to                For instance, in the infant study, 2 groups saw: object
decrease sufficiently, the network selects and recruits the            starts in green, moves to yellow, actor is not watching. One
one unit from a small number of potential hidden units that            of the groups then saw the actor search in green (expected)
most reduces output error.                                             and the other group saw her search in yellow (surprising).
   Training usually continues until the output error, i.e., the        Networks were treated in the same way. The input: object
absolute difference between output activation and target               starts in green, moves to yellow, actor is not watching, was
output value goes below the score threshold (ST) parameter             given to 2 groups of networks. For one group we measured
value (here kept at the default value of 0.4) for every output         how far from “search in green” (target output activation:
unit on every training pattern. However, since our networks            green = 1.0, yellow = 0.0) their output was and for the other
were trained on stochastic observations, the output error              group we measured the discrepancy from “search in
never went below the ST (unless ST was set to 0.5, in which            yellow”. How far the network was from predicting a search
case networks only focused on one of the output values and             in green was calculated as the mean squared difference
did not learn the full training probability distribution).             between its prediction and the actual location of search, as
Therefore, training was not terminated using the ST, but               in Equation 1;
instead it was stopped after networks learned the probability
distributions of search in training (18 correct searches out of            [(P − S ) + (P − S ) ]/ 2 = [(1 − .85 ) + (0 − .05 ) ]/ 2 = 0.0125
                                                                              g   g
                                                                                    2
                                                                                         y   y
                                                                                               2                  2            2
21 for any given belief-induction trial).
   Learning was assessed right before networks recruited
                                                                                                      Equation 1
each hidden unit, using chi-square ratios to test whether, for
each condition, expected and observed frequencies were
                                                                       where P represents the model’s prediction, S represents
significantly different. Expected frequencies were the
                                                                       searching in the test trial, and the subscripts g and y
frequencies used in training, i.e., 18/21 correct searches.
                                                                       represent the green and yellow boxes respectively. After
Observed frequencies were calculated by first converting the
                                                                       training, networks from both groups output approximately
average output activations for each condition into
                                                                       0.85 for green and 0.05 for the other nodes. In the “search in
probabilities using Luce’s choice axiom (Luce, 1959),
                                                                       green” trial, the outputs for the green and yellow locations
which states that the probability of choosing one output is
                                                                       were compared to the target: green = 1.0, yellow = 0.0,
that output’s activation divided by the sum of all output
                                                                       resulting in an error of 0.0125 (as shown in Equation 1).
activations. These probabilities were then used to define a
                                                                       The green and yellow target values were reversed for the
sub-interval for each location within the [0,1] interval. For
                                                                       “search in yellow” trial, yielding an error of approximately
instance, if calculated probabilities were red = 0.10, yellow
                                                                       0.8125. Thus, mean network error was greater for search in
= 0.70, blue = 0.05, and green = 0.15, the interval [0.0, 0.1[
                                                                       green than for search in yellow, quantifying the network's
was attributed to the red location, [0.10, 0.80[ to yellow,
                                                                       greater surprise.
[0.80, 0.85[ to blue, and [0.85, 1.0] to green. Finally, 21
                                                                           To assess whether networks underwent developmental
random numbers between 0 and 1 were obtained, and each
                                                                       changes they were tested at the end of each output phase,
number falling within a location’s sub-interval was counted
                                                                       that is, right before they recruited each hidden unit and once
as a search there. For example, the random value 0.23 would
                                                                       more at the end of training.
be counted as a search in yellow since it is in the sub-
interval [0.10, 0.80[. Training ended when networks’                   Results
observed frequencies of search were no longer significantly
different from the expected frequencies.                               Analyses of variance (ANOVAs) were performed after each
                                                                       output phase and at the end of training, with the factors
Testing By analogy with the infant experiment, each                    belief status (whether the actor’s belief was true or false),
network was tested in one experimental condition. Thus                 belief location (where the actor believed the object was),
seven networks were tested in each of the 8 conditions (2              and search location (whether search was in the yellow or
belief statuses x 2 belief locations x 2 search locations).            green box).
   In test, we gave an input to the network (corresponding to             If networks had expectations consistent with a
a belief-induction trial in the infant experiment, i.e., first and     representational ToM in both true and false beliefs trials, we
second location of the object, and whether the actor watched           predicted a significant interaction between belief-location
the object move) and measured how far the generated output             and search location and further, that this interaction would
was from the target output.                                            also be significant within each level of the belief factor (true
   Although networks were trained on four start and four end           and false). Further, we predicted that planned comparisons
locations, they were tested only on 2 start and end locations,         between the levels of search location would show lower
                                                                       error when search was in the location where the actor last
                                                                   828

saw the object (as in Equation 1) at every level of the belief               comparisons indicated that networks had lower error when
location by belief status interaction (TB-green, TB-yellow,                  search was in the last believed location of the object for all
FB-green, FB-yellow).                                                        levels of the belief location by belief status interaction
   If however, networks had expectations consistent with an                  Fs(1,12) > 8, ps < 0.02.
omniscient ToM, we predicted lower error for a search in                        Further, with three hidden units networks did learn the
the location of the object than for a search in the other                    probability distributions during training. The observed
location.                                                                    frequencies were not significantly different from the
   With 0 hidden units, networks displayed omniscient                        expected frequencies for all conditions, χ2s(3, N = 21) < .03,
expectations about searching, as shown in Figure 3.                          ps > 0.99.
Networks showed less error when search was in the location
of the object. The belief location by search location                                                1.0
                                                                                                                                    Actor search
interaction was significant overall, F(1,48) = 8380, p <
                                                                                                     0.8                             yellow-box
0.001 as well as within each belief status level, Fs(1,24) >
                                                                                Mean network error
1575, ps < 0.001. Planned comparisons indicated that                                                                                 green-box
networks had lower error when search was in the object’s                                             0.6
end location for all levels of the belief location by belief
status interaction, Fs(1,12) > 512, ps < 0.001.                                                      0.4
   With 0 hidden units, networks did not learn the
probability distributions of the training patterns. The                                              0.2
observed frequencies were significantly different from the
expected frequencies in each of the eight conditions, χ2s(3,                                         0.0
N = 21) > 22, ps < 0.05.
                                                                                                           TB-green TB-yellow FB-green FB-yellow
                        1.0                             Actor search          Figure 4: Mean network error and SE bars when networks
                                                         yellow-box            had three hidden units. Networks’ expectations were
                        0.8                                                  consistent with a representational ToM – error was lower
   Mean network error
                                                         green-box
                                                                             when search was in the last believed location of the object.
                        0.6
                                                                                                                    Discussion
                        0.4                                                  Our model went through the same developmental transition
                                                                             observed with older children tested with the explicit,
                        0.2                                                  standard false belief task. With insufficient hidden units,
                                                                             networks had expectations consistent with an omniscient
                        0.0                                                  ToM, but with three hidden units, networks had
                              TB-green TB-yellow FB-green FB-yellow          expectations consistent with a representational ToM.
                                                                             Further, with three hidden units, networks successfully
 Figure 3: Mean network error and SE bars when networks                      learned the probability distributions present in training.
had no hidden units. Networks’ expectations were consistent                  Therefore, our model suggests that infants’ expectations
with an omniscient ToM – error was lower when search was                     might also go through a similar transition. To obtain that
             in the end location of the object.1                             transition, more true- than false-belief observations had to
                                                                             be present in training, lending computational support to the
  With one and two hidden units, networks’ expectations                      idea that children’s (and infants’) expectations might go
continued to follow a pattern consistent with an omniscient                  through this transition because they develop the ability to
ToM. However, with three hidden units, networks showed                       override a default expectation of true belief (Leslie et al.,
less error when search was in the belief location, i.e., the                 2005). We have shown that this default could be a natural
location in which the actor last saw the object. The belief                  result of experiencing more true- than false-belief behavior.
location by search location interaction was significant
overall, F(1,48) = 215, p < 0.001, as well as within each                    Comparison with Other Models
belief status level, Fs(1,24) > 22, ps < 0.001 Planned                       By contrast with other computational models of false belief
                                                                             tasks, our model is a developmental model that learns to
   1
                                                                             solve the task without parameter manipulation.
     The greater difference between search locations in TB-green is            O'Laughlin and Thagard (2000) and Triona et al. (2002)
an artefact from the infant experiment, in which the object did not
                                                                             both covered the omniscient to representational
move in TB-green (starting and ending in green), but did move in
TB-yellow (starting in green and ending in yellow). This effect
                                                                             developmental transition by parameter manipulation.
disappeared when TB-yellow was implemented in the model with                 O'Laughlin and Thagard (2000) manipulated the excitatory
the object starting and ending in yellow. In networks, a moving              and inhibitory nature of the connections between the nodes,
object is more difficult to process than a stationary object.                whereas Triona et al. (2002) directly manipulated the
                                                                       829

probability that the model would solve the task. Our model                                 References
learns the implicit task and goes through the same
                                                                   Anderson, J. R., Bothell, D., Byrne, M. D., Douglass, S.,
developmental changes that children go through without
                                                                     Lebiere, C., & Qin, Y. (2004). An integrated theory of the
direct parameter manipulation.
                                                                     mind. Psychological Review, 111(4), 1036-1060.
   Goodman et al. (2006) showed that a Bayesian network
                                                                   Baluja, S., & Fahlman, S. E. (1994). Reducing network
having expectations corresponding to a representational
                                                                     depth in the cascade-correlation (Technical report No.
ToM was more computationally complex than another
                                                                     CMU-CS-94-209). Pittsburgh: Carnegie Mellon
Bayesian network having omniscient expectations.
                                                                     University.
However, their model was restricted by the fact that the
                                                                   Dennett, D. C. (1978). Beliefs about beliefs. Behavioral and
networks’ architectures were designed by the experimenters
                                                                     Brain Sciences, 1(4), 568-570.
and by the limited number of networks they implemented,
                                                                   Goodman, N. D., Baker, C. L., Bonawitz, E. B.,
which in turn limited the number of possible transitions the
                                                                     Mansinghka, V. K., Gopnik, A., Wellman, H., et al.
model could perform. Our model showed, in a single unified
                                                                     (2006). Intuitive theories of mind: A rational approach to
developmental system, that representational ToM
                                                                     false belief. In Proceedings of the Twenty-Eighth Annual
expectations do require more computational power;
                                                                     Conference of the Cognitive Science Society (pp. 1382-
networks required no hidden units to have expectations
                                                                     1387). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.
consistent with an omniscient ToM about others’ searching,
                                                                   Leslie, A. M., German, T. P., & Polizzi, P. (2005). Belief-
but required three hidden units to learn to have expectations
                                                                     desire reasoning as a process of selection. Cognitive
consistent with a representational ToM. Both omniscient
                                                                     Psychology, 50(1), 45-85.
and representational ToM expectations were developed
                                                                   Luce, R. D. (1959). Individual choice behavior: A
autonomously by the model, the later one building on the
                                                                     theoretical analysis. New York: Wiley.
earlier one.
                                                                   O'Laughlin, C., & Thagard, P. (2000). Autism and
                                                                     coherence: A computational model. Mind & Language,
Summary
                                                                     15(4), 375-392.
In sum, computational models are useful for providing              Onishi, K. H., & Baillargeon, R. (2005). Do 15-month-old
insights into psychological phenomena and can lead to                infants understand false beliefs? Science, 308, 255-258.
novel predictions or directions for experimental tasks. Our        Perner, J., Leekam, S. R., & Wimmer, H. (1987). Three-
model provides a novel computational insight as to why               year-olds' difficulty with false belief: The case for a
children go through a developmental transition on the                conceptual deficit. British Journal of Developmental
standard false belief task and predicts that infants’                Psychology, 5(2), 125-137.
expectations might go through a similar transition on the          Shultz, T. R., & Bale, A. C. (2001). Neural network
implicit task.                                                       simulation of infant familiarization to artificial sentences:
   Future directions could include an avoidance implicit FB          Rule-like behavior without explicit rules and variables.
task, in which the actor wants to avoid a noxious object,            Infancy, 2(4), 501-536.
instead of search for an attractive object. Indeed, only after     Shultz, T. R., & Bale, A. C. (2006). Neural networks
four years do children pass explicit FB tasks with avoidance         discover a near-identity relation to distinguish simple
goals, and expect an actor to correctly avoid a location when        syntactic forms. Minds and Machines, 16, 107-139.
she has a false belief about its content. However, no              Triona, L. M., Masnick, A. M., & Morris, B. J. (2002).
avoidance implicit FB task has been used with infants.               What does it take to pass the false belief task? An ACT-R
Would our model succeed an avoidance version of the                  model. In Proceedings of the Twenty-Fourth Annual
implicit task only after it succeeded the approach task?             Conference of the Cognitive Science Society (p. 1045).
Computational models such as ours are useful to understand           Mahwah, NJ: Lawrence Erlbaum Associates, Inc.
how cognition undergoes developmental transitions.                 Wellman, H. M., Cross, D., & Watson, J. (2001). Meta-
                                                                     analysis of theory-of-mind development: The truth about
                   Acknowledgments                                   false belief. Child Development, 72(3), 655-684.
This research was supported by a scholarship to V.G.B.             Wimmer, H., & Perner, J. (1983). Beliefs about beliefs:
from the Fonds Québécois de la Recherche sur la Nature et            Representation and constraining function of wrong beliefs
les Technologies, a grant to K.H.O. from the Fonds                   in young children's understanding of deception.
Québécois de la Recherche sur la Société et la Culture, as           Cognition, 13(1), 103-128.
well as a scholarship to V.G.B. and grants to K.H.O. and
T.R.S. from the Natural Sciences and Engineering Research
Council of Canada.
                                                               830

