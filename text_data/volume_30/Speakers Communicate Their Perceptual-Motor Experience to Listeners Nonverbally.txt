UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Speakers Communicate Their Perceptual-Motor Experience to Listeners Nonverbally
Permalink
https://escholarship.org/uc/item/4049n5r8
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Cook, Susan Wagner
Tanenhaus, Micheal K.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

           Speakers Communicate Their Perceptual-Motor Experience to Listeners
                                                             Nonverbally
                                       Susan Wagner Cook (swcook@bcs.rochester.edu)
                                Department of Brain and Cognitive Science, University of Rochester
                                                        Rochester, NY 14627 USA
                                       Michael K. Tanenhaus (mtan@bcs.rochester.edu)
                                Department of Brain and Cognitive Science, University of Rochester
                                                        Rochester, NY 14627 USA
                             Abstract                                  representations support production of iconic gesture, and (b)
   We explored the perceptual motor information expressed by
                                                                       to what degree the resulting gestures are spontaneously
   speakers, and encoded by listeners when engaged in                  encoded by listeners.
   naturalistic communication. After solving the Tower of Hanoi           We examined both of these issues using the Tower of
   task either with real objects or on a computer, speakers            Hanoi task. Speakers explained the task to listeners, after
   explained the Tower of Hanoi task to listeners. Speakers            solving the task either with real objects or on a computer.
   expressed properties of the objects that had been used to solve     Speakers’ hand gestures, but not their speech, reflected
   the task in their hand gestures, but not in their speech.           properties of the movements required to move the objects
   Moreover, listeners were sensitive to speaker’s prior
   experience. In one experiment, listeners who observed               when solving the task, demonstrating that, during language
   explanations from speakers who had previously solved the            production,     gestures    can    emerge      from     motor
   problem with real objects subsequently treated computer             representations. This finding suggests that listeners
   objects more like real objects; their mouse trajectories            incorporate some perceptual-motor information conveyed
   revealed that they lifted the objects in conjunction with           by the speaker’s gesture into the representations they
   moving them sideways. In a second experiment, listeners             construct during spoken language comprehension.
   were sensitive to the particular constraints imposed by the
   computer. These findings use the natural behavior of
   speakers and listeners to provide evidence that both speakers                                 Study 1
   and listeners spontaneously invoke perceptual-motor systems
   during human communication via spoken language.                     Methods
   Keywords: gesture; communication.
                                                                       Participants Fourteen pairs of participants were included in
When we reach for objects, the location and shape of our               the data analysis. Data from an additional two pairs in each
hands reveals information about the location and shape of              condition were eliminated due to irregularities in the
the object that is the goal of our actions. Surprisingly,              experimental procedure.
something similar happens when we express our thoughts.
When people talk, they gesture, changing the location and              Procedure Speakers first completed the Tower of Hanoi
shape of their hands in precise coordination with what they            problem-solving task. In this problem, a stack of disks,
say. Gestures can represent perceptual (e.g., size or shape)           arranged from the largest on the bottom to the smallest on
and motor (e.g., movement trajectory) information that is              top, is arranged on the leftmost of three pegs, and this stack
not included in the accompanying speech (Beattie &                     must be moved to the rightmost peg, moving only one disk
Shovelton, 1999; McNeill, 1992), including information that            at a time without placing larger disks on top of smaller
is not explicitly part of a speaker’s message (Church &                disks. Speakers solved the problem using either heavy metal
Goldin-Meadow, 1986; Goldin-Meadow, 1997). We used                     disks on wooden pegs or cartoon pictures on a computer
hand gesture as a tool for exploring the information                   screen. The real objects consisted of four weights (0.6, 1.1,
expressed by speakers and interpreted by listeners engaged             2.3 and 3.4 kilograms) on a 22.86 x 76.2 cm board with
in naturalistic communication.                                         pegs at 12.7, 38.1 and 63.5 cm. The computer objects were
   Human language has been assumed to involve the                      presented on a 45.72 cm computer monitor using screen
transmission of abstract and amodal representations (Fodor,            resolution 480 x 640. The real disks needed to be lifted up
1975; Pylyshyn, 2003; Pylyshyn, 2001). Indeed, an arbitrary            over the top of the pegs before they could be moved
relation between form and meaning is often considered a                sideways, whereas the computer disks could be dragged
defining feature of linguistic systems (Hockett, 1960,                 horizontally from one peg to another without being lifted
although see Shintel, Okrent & Nusbaum, 2006). In                      over the top of the peg.
contrast to speech, the gestures produced by speakers in                  After practice solving and explaining three three-disk
conjunction with speech often appear to express meaning                problems and one four-disk problem to the experimenter,
non-arbitrarily, although it is not known: (a) what sorts of           speakers solved the four-disk problem a second time. They
                                                                   957

then explained how to solve the four-disk problem to the                   (0/7 speakers), a pattern reliably different from that seen in
other participant, the listener. This explanation occurred in a            speakers interacting with real objects (χ2(1)=7.77, p=.005,
different room. After the explanation, listeners solved and                See Figure 2). Thus, speakers’ gestures reflected their actual
explained the four-disk problem twice in the original room.                motor experience, rather than a more abstract representation
All listeners solved the task on the computer, but speakers                of transfer. In contrast, reference to physical features of the
were not informed that the listener would be solving the task              objects in speech was relatively infrequent. Instead,
on the computer. In cases where the speaker had solved the                 speakers tended to refer to the relative size of the disk in
problem using the physical apparatus, a second                             their speech (e.g. “next smallest”) regardless of whether the
experimenter surreptitiously hid the apparatus during the                  disks were real or presented on the computer.2
explanation. Listeners’ mouse trajectories were tracked
while they solved the problem (Spivey, Grosjean, &
Knoblich, 2005).
Coding Speech and gesture from all participants was
recorded, transcribed and coded. We investigated encoding
of physical features of the objects in speech across the entire
explanation. We coded reference to physical features by
identifying all adjectives referring to physical properties of
the objects, including color, weight, and physicality. We
investigated encoding of physical features in gesture by
focusing on participants’ description of the movement of the
largest disk. We identified the spoken phrases referring to
movement of this disk, and subsequently classified the
accompanying gestures according to the number of hands
used.1 We chose this feature of gesture because physical
movement of the largest disk required two hands for
speakers who had solved the problem using real objects, but
not for speakers who had solved the problem using the
computer. Moreover, this feature of gesture could be
straightforwardly coded.
Control Study We conducted a control study to
independently assess how speakers expressed information
about the physical characteristics of the objects used. Eight
additional participants were informed about the
experimental manipulation, and asked to guess the
experimental condition of speakers after listening to the
speech without video, or observing the gesture without
audio. These participants provided judgments on video-
only and audio-only clips of 11 of the participants included
in Study 1.
Results
   All speakers (N=14) depicted the movement of the disks
using hand gestures in conjunction with speech. More
importantly, speakers’ hand gestures reliably reflected the                     Figure 1: Examples of single (Computer Condition) and
environment in which they had solved the problem.                            two-handed (Real Objects Condition) gestures referring to
Speakers who solved the problems with heavy disks                                           the movement of the largest disk.
generally used two grasping hands when describing
movement of the largest disk (5/7 speakers). These speakers
could easily have gestured the motion of the largest disk
with one moving hand, since they were not actually lifting                    2
                                                                                Three participants used the word “heaviest” to refer to the
this disk when gesturing, and they gestured movement of                    largest disk once. Two of these participants also used the word
the smaller disks using only one hand. In contrast, speakers               “lightest” to refer to the smallest disk once. However, use of mass
who solved the problem on the computer never used two                      to refer to the computer disks was not infelicitous; one listener also
hands when demonstrating movement of the largest disk                      used the word “heavy” when describing their solution to the
                                                                           computer task. Only one participant in the computer condition
                                                                           explicitly referred to the fact that the objects were on the computer
   1
     It is unlikely that this is the only feature of speakers’ gesture     screen. Thus, the failure to mention this fact in the real condition
that distinguished the two groups.                                         was also not infelicitous.
                                                                       958

The judgments of our informed raters listening to the audio
or viewing the video also suggested that information about
the physical features of the objects was available in the
gesture and not the speech. We compared the number of
correct judgments in each condition with the number that
would be expected given chance performance (50%) using a
binomial test. On the audio task, participants were not
reliably better than chance (48/88 (54%) correct judgments,
p=.45). In contrast, on the video task, participants were
reliably better than chance (54/88 (61%) correct judgments,
p=.04). Note that the high proportion of errors in the video
conditions suggests that the gesture cues were quite subtle,
and unlikely to be consciously noted by participants in the
primary study, who heard only one explanation, and unlike
the control subjects, were unaware of the manipulation.                     Figure 2: Mouse trajectories predicted using data from the
   In order to investigate whether listeners’ incorporated                first 15 moves, superimposed on the computer display. The
motor information that reflected the speaker’s experience,                            x and y axes are screen coordinates.
we examined the mouse trajectories produced by listeners
when they subsequently solved the problem. We analyzed
the trajectory of listeners’ mouse movements using a                     Interim Discussion
maximum likelihood mixed quadratic model to predict the                     The findings from Study 1 revealed that speakers’
height of a participants’ mouse, given the x-coordinate of               gestures iconicly represent their perceptual-motor
the mouse movement, the quadratic of the x-coordinate, and               experience, even when speakers are not encoding specific
the condition under which the speaker had solved the                     perceptual-motor experience in the accompanying speech.
problem. In order to compare height across moves with                    Moreover, listeners are sensitive to subtle differences in
different starting and ending points, we transformed the x-              perceptual motor information encoded in gesture.
coordinates on each move so that they ranged from 0 to 1.                   One alternative explanation for these findings is that
Data from the first 15 moves produced by each participant                differences in materials, rather than differences in
were included in the analysis, because at least 15 moves                 perceptual-motor experience, can account for the results,
were necessary to solve the problem. Data were analyzed                  given that one group used real objects and one group used
using a mixed model, with y-coordinate as the dependent                  virtual objects. Study 2 was designed to investigate this
measure, condition and solution as fixed factors, and                    possibility while replicating and extending the findings from
subject, x-coordinate, and the intercept as random factors.              Study 1.
There was a significant interaction between condition and
the quadratic of the x-coordinate (F(1,10,000)=176.21,
p<.0001). The function fitting the mouse trajectories had a
significantly larger parabolic component for those listeners
                                                                                                    Study 2
who had been instructed by speakers who used the real
objects in comparison with those listeners who had been
                                                                         Methods
instructed by speakers who used the computer (See Figure
3).3 4                                                                   Participants 24 pairs of individuals participated in this
                                                                         Study. Data from an additional four pairs were eliminated,
                                                                         two because of a data recording error, and two pairs where
                                                                         one participant had participated in prior versions of the
                                                                         study.
                                                                         Procedure The order of events used in Study 1 was also
                                                                         used in Study 2. However, the nature of the materials used
                                                                         was changed. Speakers again solved the problem using
                                                                         either heavy metal disks on wooden pegs or cartoon pictures
                                                                         on a computer screen. However, there were two groups of
   3
     Additional reliable fixed effects in the model were as follows:     speakers who completed the task on the computer. For one
There was a reliable quadratic component to the movements                group of computer users, the Computer No Constraints
(F(1,12)=2739.03,p<.0001), a reliable linear component to the            group, the disks could be moved as in Study 1, in that the
movements (F(1,12)=878.56,p<.0001), and the linear component             disks could be moved sideways without being lifted over the
interacted with condition (F(1,10,000)=67.99,p<.0001).
   4                                                                     top of the peg on which they were located. In contrast, for
      Listeners were equally facile at solving the task across
                                                                         the Computer Constrained group, the virtual disks exhibited
conditions. There was no difference in the number of moves
required for the first (Real: 23.9, Comp: 25.1, t(12)=.25) or second     the same sort of constraint as that inherent in the real
solution (Real: 39.1, Comp: 26.9, t(12)=.83).                            objects. For these participants, the disks needed to lifted
                                                                     959

above the top of the peg on which they were located before        quadratic model to predict the height of a participants’
they could be moved sideways.                                     mouse, given the x-coordinate of the mouse movement, the
   We also changed the nature of the computer disks the           quadratic of the x-coordinate, and the condition under which
listeners used. All listeners completed the tasks with the        the speaker had solved the problem. Because all listeners
constraint that the virtual disks needed to lifted above the      were solving the problem with virtual constraints, which
top of the peg on which they were located before they could       required production of arced trajectories, we focused on the
be moved sideways.                                                initial segment of the first move produced by listeners. In
Coding Speech and gesture from all participants was               particular, we included all data from the time participants
recorded, transcribed and coded as in Study 1.                    initiated the movement and the time that their mouse was
                                                                  halfway to the second peg. This eliminated reversals in the
Results                                                           trajectory that were produced when participants adjusted
All speakers again depicted the movement of the disks using       their movement to accommodate the constraint. Data were
hand gestures in conjunction with speech. Moreover, the           analyzed using a mixed model, with y-coordinate as the
differences in gesture production observed in Study 1 were        dependent measure, condition and solution as fixed factors,
replicated and extended. Speakers who solved the problems         and subject, x-coordinate, and the intercept as random
using real objects again used two hands to depict movement        factors. There was a significant interaction between
of the largest disk (6/7 speakers), while speakers who solved     condition and the quadratic of the x-coordinate
the problem on the computer only used one hand to depict          (F(2,495)=18.66, p<.0001). The function fitting the mouse
movement of the largest disk (16/17 speakers). Moreover,          trajectories had a significantly larger parabolic component
there also seemed to be a difference in the gestures              for those listeners who had been instructed by speakers who
produced by speakers who had solved the problem on the            used the real objects in comparison with those listeners who
computer with constraints, in comparison with those               had been instructed by speakers in the unconstrained
speakers who had solved the problem on the computer               computer condition (t(495)=6.00, p<.0001), replicating the
without constraints. These speakers produced gestures with        findings of Study 1. Moreover, the function fitting the
particularly large, arced trajectories, even when they were       mouse trajectories for those listeners who had been
not describing movement over the middle peg (see Figure           instructed by speakers who used the constrained virtual
3).5                                                              objects were also reliably different from those listeners who
                                                                  had been instructed by speakers who used the unconstrained
                                                                  virtual objects (t(495)=4.75, p<.0001). (See Figure 3).
                                                                  Thus, listeners’ movements were reliably affected by the
                                                                  perceptual and motor experience of the speaker that they
                                                                  observed.
   Figure 3: Example of a large, arced gesture produced by a
      speaker from the Computer Constrained condition.
                                                                     Figure 4: Mouse trajectories predicted using data from the
                                                                    first half of the first move, superimposed on the computer
   In order to investigate whether listeners’ incorporated                display. The x and y axes are screen coordinates.
speakers’ experience, we again examined the mouse
trajectories produced by listeners when they subsequently
                                                                     As a second window onto listeners’ uptake of
solved the problem. We analyzed the trajectory of listeners’
                                                                  information, we categorized participants’ first move as
mouse movements using a maximum likelihood mixed
                                                                  successful, or unsuccessful, based on whether or not
   5
                                                                  participants needed to reverse trajectory to account for the
     Consistent with study 1, we did not find differences in      constraint. Listeners who heard explanations from speakers
participants’ speech across conditions. Across conditions,        who had solved the problem on the computer with
participants used the same verb to describe the movements,        constraints implicitly adjusted for the constraint in their
and the same nouns to refer to the blocks.
                                                              960

initial move. Only one (1/9) of these listeners needed to           representations in listeners has been inferred from
correct their mouse trajectory on their initial move. In            decrements in performance on perceptual-motor secondary
contrast, all (8/8) of the listeners who heard explanations         tasks. However, these secondary tasks may themselves be
from speakers who had solved the problem without                    reorganizing processing by activating the very systems
constraints needed to correct their trajectory on their initial     under investigation. For example, moving one’s own body
move, a pattern of performance reliably different from the          can facilitate recognition of bodily postures in others, by
no constraints group (Fisher’s exact test, p=.0001).                activating aspects of one’s own body schema that would
Listeners who heard explanations from speakers who had              otherwise not be recruited (Reed & Farah, 1995). The
solved the problem using the real disks were inconsistent in        findings reported here provide evidence that perceptual-
their initial move (4/7 needed to correct their trajectory).        motor representations are activated during human
                                                                    communication using data from the natural behavior of
Discussion                                                          speakers and listeners.
   In Study 2, the effect of speakers’ prior experience on             These findings suggest that speakers and listeners are not
listeners’ subsequent actions was replicated and extended.          simply communicating abstract and amodal information.
Listeners reliably moved the disks differently even in the          Instead, information from the manual modality both reliably
two computer conditions where the materials were held               reflects speakers’ experience in the world and shapes how
constant. This suggests that the findings from Study 1 are          listeners encode a speaker’s message.
not an artifact of differences in materials across conditions.
Instead, it appears that speaker transmit information about                             Acknowledgments
the movement affordances of objects to their listeners, and            We thank M. Andrews, N. Cook, M. Hare, K. Housel,
that listeners incorporate this information.                        A.P. Salverda, and D. Subik for assistance in executing
                                                                    these experiments. This work was supported by NIH grant
                    General Discussion                              HD-27206.
   Speakers reflected physical properties of the objects that
had been used to solve the task in their hand gestures,                                      References
revealing activation of perceptual-motor representations in         Arbib, M. A., & Rizzolatti, G. (1996). Neural expectations:
service of communication. Furthermore, this information                       A possible evolutionary path from manual skills to
does not go unheeded, but rather is incorporated into                         language. Communication & Cognition, 29(3-4),
listeners’ interpretations. Gestures affected listeners’                      393-424.
interpretations, even when participants’ gesture was                Aziz-Zadeh, L., Wilson, S. M., Rizzolatti, G., & Iacoboni,
manipulated without direct instruction, was consistent with                   M. (2006). Congruent embodied representations for
speech, and was performed and processed spontaneously.                        visually presented actions and linguistic phrases
This suggests that listeners are also activating perceptual-                  describing actions. Current Biology, 16(18), 1818-
motor representations when interpreting a speaker’s                           1823.
meaning.                                                            Beattie, G., & Shovelton, H. (1999). Mapping the range of
   These findings are consistent with the hypothesis that                     information contained in the iconic hand gestures
gestures may reflect action simulations used by speakers                      that accompany spontaneous speech. Journal of
(Hostetter & Alibali, in press). Speakers in the current                      Language & Social Psychology, 18(4), 438-462.
study who had solved the problem with real objects reliably         Beattie, G., & Shovelton, H. (2001). An experimental
treated an imaginary disk as if it actually had mass when                     investigation of the role of different types of iconic
they communicated about moving that disk. This suggests                       gesture in communication: A semantic feature
that speakers were not only activating the goals of their                     approach. Gesture, 1, 129-149.
movement, which were expressed in the concurrent speech,            Church, R. B., & Goldin-Meadow, S. (1986). The mismatch
but also the specific motor plan that would accomplish these                  between gesture and speech as an index of
goals, which was expressed in the concurrent gesture.                         transitional knowledge. Cognition, 23(1), 43-71.
   Listeners in the current study treated virtual disks             Fodor, J. A. (1975). The language of thought. Cambridge,
differently, consistent with the perceptual-motor experience                  MA: Harvard University Press.
of the speaker that they observed. When interpreting                Glenberg, A. M., & Kaschak, M. P. (2002). Grounding
language, even abstract language, people appear to represent                  language in action. Psychonomic Bulletin &
perceptual and motor information that is irrelevant to task                   Review, 9(3), 558-565.
demands (Glenberg & Kaschak, 2002; Glover, Rosenbaum,               Glover, S., Rosenbaum, D. A., Graham, J., & Dixon, P.
Graham, & Dixon, 2004; Kaschak et al., 2005; Richardson,                      (2004). Grasping the meaning of words.
Spivey, Barsalou, & McRae, 2003; Zwaan, Stanfield, &                          Experimental Brain Research, 154(1), 103-108.
Yaxley, 2002). For example, after hearing a sentence about          Goldin-Meadow, S. (1997). When gestures and words speak
movement towards their own body, listeners are quicker to                     differently. Current Directions in Psychological
make a movement in the same direction (Glenberg &                             Science, 6(5), 138-143.
Kaschak, 2002). The activation of perceptual and motor
                                                                961

Goldin-Meadow, S., Kim, S., & Singer, M. (1999). What                       motor circuits. Journal of Cognitive Neuroscience,
         the teacher's hands tell the student's mind about                  17(2), 273-281.
         math. Journal of Educational Psychology, 91(4),             Zwaan, R. A., Stanfield, R. A., & Yaxley, R. H. (2002).
         720-730.                                                           Language comprehenders mentally represent the
Goldin-Meadow, S., & Singer, M. A. (2003). From                             shape of objects. Psychological Science, 13(2),
         children's hands to adults' ears: Gesture's role in the            168-171.
         learning process. Developmental Psychology,
         39(3), 509-520.
Hockett, C. F. (1960). The origin of speech. Scientific
         American, 203(3), 88–96.
Hostetter, A. B., & Alibali, M. W. (in press). Visible
         embodiment: Gestures as Simulated Action.
         Psychonomic Bulletin and Review.
Kaschak, M. P., Madden, C. J., Therriault, D. J., Yaxley, R.
         H., Aveyard, M., Blanchard, A. A., et al. (2005).
         Perception of motion affects language processing.
         Cognition, 94(3), B79-B89.
Krauss, R. M., Chen, Y., & Chawla, P. (1996). Nonverbal
         behavior and nonverbal communication: What do
         conversational hand gestures tell us? In M. P.
         Zanna (Ed.), Advances in experimental social
         psychology (Vol. 28, pp. 389-450). San Diego, CA,
         US: Academic Press.
McNeill, D. (1992). Hand and mind: What gestures reveal
         about thought. Chicago: The University of Chicago
         Press.
Pylyshyn, Z. (2003). Return of the mental image: are there
         really pictures in the brain? Trends in Cognitive
         Sciences, 7(3), 113-118.
Pylyshyn, Z. W. (2001). Visual indexes, preconceptual
         objects, and situated vision. Cognition, 80(1-2),
         127-158.
Reed, C. L., & Farah, M. J. (1995). The Psychological
         Reality of the Body Schema - a Test with Normal
         Participants. Journal of Experimental Psychology-
         Human Perception and Performance, 21(2), 334-
         343.
Richardson, D. C., Spivey, M. J., Barsalou, L. W., &
         McRae, K. (2003). Spatial representations
         activated during real-time comprehension of verbs.
         Cognitive Science, 27(5), 767-780.
Rizzolatti, G., & Arbib, M. A. (1998). Language within our
         grasp. Trends in Neurosciences, 21(5), 188-194.
Rizzolatti, G., Fadiga, L., Gallese, V., & Fogassi, L. (1996).
         Premotor cortex and the recognition of motor
         actions. Brain Res Cogn Brain Res, 3(2), 131-141.
Shintel, H., Nusbaum, H. C., & Okrent, A. (2006). Analog
         acoustic expression in speech. Journal of Memory
         and Language, 55, 167–177.
Spivey, M. J., Grosjean, M., & Knoblich, G. (2005).
         Continuous attraction toward phonological
         competitors. Proceedings of the National Academy
         of Sciences, 102(29), 10393-10398.
Tettamanti, M., Buccino, G., Saccuman, M. C., Gallese, V.,
         Danna, M., Scifo, P., et al. (2005). Listening to
         action-related sentences activates fronto-parietal
                                                                 962

