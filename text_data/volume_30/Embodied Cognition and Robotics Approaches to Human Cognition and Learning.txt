UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Embodied Cognition and Robotics Approaches to Human Cognition and Learning

Permalink
https://escholarship.org/uc/item/9xb7n5p7

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)

Authors
Yu, Chen
Scassellati, Brian

Publication Date
2008-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Embodied Cognition and Robotics Approaches to Human Cognition and Learning
Chen Yu (chenyu@indiana.edu)
Department of Psychological and Brain Sciences, and Cognitive Science Program,
Indiana University, Bloomington, IN, 47405 USA

Brian Scassellati (scaz@cs.yale.edu)
Department of Computer Science
Yale University, New Haven, CT 06520-8285 USA
Second, with the advances in computer vision, speech
processing and machine learning, now we have the
capabilities to process visual, audio and other sensory data
collected from real-world interactions (Yu, Ballard, &
Aslin, 2005). In this way, we can measure and analyze
physical and social regularities in real world. A better
understanding of the learning environment can provide
unique opportunities to study underlying mechanistic nature
of human cognition and learning.
Third, artificial systems (e.g. physical robots and virtual
humans) can interact with people in everyday contexts,
which not only provides a way to enrich experimental
methods but also has applied utilities. For example,
embodied models (e.g. baby robots) can learn from adults
(e.g. caregivers). For another example, teaching robots can
interact with young children to facilitate their learning.
This tutorial will bring a set of researchers from multiple
disciplines including computer science, cognitive science
and psychology. We will introduce various computational
techniques to study embodied cognition, from physical
robots to virtual reality techniques, and from cognitive
behavioral studies to computational modeling. The tutorial
will inspire more cognitive scientists to utilize state-of-art
computational and robot techniques to study human
cognition and learning.

Recent studies in both human learning and machine
intelligence show that the world and social signals encoded
in multiple modalities play a vital role in learning. For
example, young children are highly sensitive to correlations
among words and the physical properties of the world (see
an example in Smith, Jones and Landau, 1996). They are
also sensitive to social cues and are able to use them in ways
that suggest an understanding of speaker's intent (e.g.,
Tomasello, 1992). One problem with the hypothesis that
human learners utilize social-cognitive cues in everyday
learning is that the empirical evidence is based on macrolevel behaviors (e.g., head orientation or pointing) in
constrained
unnatural
contexts
(e.g.
laboratory
environments). To truly understand mechanisms of learning,
however, we may need to focus on more micro-level
behaviors (e.g., gaze and body position) as they unfold in
real time, for example, changes in eye gaze and shifts in
body position as they are linked to objects, events, and
actions of the social partner. The studies at the macro-level
demonstrated many intelligent behaviors in learning but
they have not as yet led to a formal account of the
underlying mechanisms. Thus, we want to know not only
that learners use social cues but also how they do so in terms
of the real-time processes in the real-time tasks in which
authentic learning must take place.
A new trend in Cognitive Science is the use of artificial
agents and systems to investigate learning and development
of complex natural organisms in natural environments
(Ballard, et al. 1997). Recent computational models, in
contrast with traditional AI, take into account principles of
neural function and development, elaborate afferent and
efferent potentials, and most importantly the interactions
between brain, body and environment, to test and falsify
formal theories about specific emerging cognitive functions,
and to measure and analyze a rich history of interaction in
real time and space within highly diverse environments.
The value of this approach can be summarized as three
research directions. First, one exciting line of inquiry in
embodied modeling is generating formal models of the
complexities of social and cognitive learning (Scassellati,
2002). By grounding high-level theories into robotic
systems, we can address different aspects of how socialcognitive capabilities, such as gaze following and face
preference, can be learned through sensorimotor
interactions.

References
Ballard, D. H., Hayhoe, M. M., Pook, P. K., & Rao, R. P. N.
(1997). Deictic codes for the embodiment of cognition.
Behavioral and Brain Sciences, 20 (4), 723-767.
Baron-Cohen, S. (1995). Mindblindness: an essay on autism
and theory of mind. Cambridge: MIT Press.
Scassellati, B. Theory of mind for a humanoid robot.
Autonomous Robots, vol. 12, p. 13-24, 2002.
Smith, L.B. & Breazeal, C. (2007) The dynamic lift of
developmental process. Developmental Science, 10, 6168.
Smith, L.B., Jones, S. &Landau, B. (1996) Naming in
young children: A dumb attentional mechanism?
Cognition 60, 143-171.
Tomaselo, M. (1992) The social bases of language
acquisition. Social Development 1(1), 67-87.
Yu, C., Ballard, D.H., & Aslin, R.N. (2005). The role of
embodied intention in early lexical acquisition. Cognitive
Science, 29 (6), 961â€“1005.

21

