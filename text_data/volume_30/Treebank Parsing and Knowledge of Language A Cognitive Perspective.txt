UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Treebank Parsing and Knowledge of Language: A Cognitive Perspective
Permalink
https://escholarship.org/uc/item/5b60s9jh
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Fong, Sandiway
Berwick, Robert C.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

           Treebank Parsing and Knowledge of Language: A Cognitive Perspective
                                          Sandiway Fong (sandiway@email.arizona.edu)
                       Departments of Linguistics and Computer Science, University of Arizona, Douglass 200E
                                                            Tucson, AZ 85721 USA
                                            Robert C. Berwick (berwick@csail.mit.edu)
                   Departments of EECS and Brain and Cognitive Sciences, MIT, 32D-728, 77 Massachusetts Ave.
                                                          Cambridge, MA 02139 USA
                               Abstract                                  to both grammaticality and performance. (See the discussion
   Over the past 15 years, there has been increasing use of linguis-     in Crocker and Keller (2006) and references cited therein.)
   tically annotated sentence collections, such as the Penn Tree-        Taking this line of reasoning further, (Bod, 2003) concludes:
   bank (PTB), for constructing statistically based parsers. While
   these parsers have generally been built for engineering pur-             “Language displays all the hallmarks of a probabilistic
   poses, more recently such approaches have been advanced as               system. Grammaticality judgments and linguistic uni-
   potentially cognitively relevant, e.g., for addressing the prob-         versals are probabilistic and stochastic grammars en-
   lem of human language acquisition. Here we examine this pos-
   sibility critically: we assess how well these Treebank parsers           hance learning. All evidence points to a probabilistic
   actually approach human/child language competence. We find               language faculty.”
   that such systems fail to replicate many, perhaps most, em-
   pirically attested grammaticality judgments; seem overly sen-            This paper takes such “cognitive fidelity” claims seriously.
   sitive, rather than robust, to training data idiosyncrasies; and
   easily acquire ”unnatural” syntactic constructions, those never       How closely do these systems replicate human acquisition
   attested in any human language. Overall, we conclude that             and knowledge of language rather than the standardly-used
   existing statistically based treebank parsers fail to incorporate     precision/recall information retrieval engineering metrics?
   much “knowledge of language” in these three senses.
                                                                         Roughly, we view this alternative as a kind of cognitive “Tur-
   Keywords: statistical parsing; psycholinguistics; language ac-
   quisition.                                                            ing test”: how well do these systems mirror the knowledge
                                                                         of language that we know adults and children possess? Note
                           Introduction                                  that we can approach this question and still strive to remain
Recently there has been considerable interest in advancing               neutral about linguistic theory: we need not adopt any par-
stochastic parsing systems, trained on Treebank corpora, as              ticular linguistic account, but rather draw on an empirically
putative solutions to cognitively relevant questions such as             valid list of behaviors that we know children and adults ex-
language acquisition and sentence processing. A representa-              hibit. While there are many conceivable tests to probe such
tive overview of this position is provided by Chater and Man-            abilities, to at least begin the investigation in this paper, we
ning (2006):                                                             consider three cognitively relevant ones: (1) the actual knowl-
   “Probabilistic methods are providing new explanatory                  edge of language attained; (2) extreme sensitivity to perturba-
   approaches to fundamental cognitive science questions                 tion in training data; and (3) acquisition of non-natural regu-
   of how humans structure, process and acquire language.                larities in training data. More precisely, we consider the fol-
   . . . Probabilistic models can account for the learning               lowing three evaluation dimensions:
   and processing of language, while maintaining the so-                1. Do such systems attain a cognitively plausible knowledge
   phistication of symbolic models.”                                        of language when trained on the standard dataset (in the
   Sproat and Lappin (2005) suggest:                                        language engineering field) of 39,832 sentences from the
   “. . . the proposal that general learning and induction                  Wall Street Journal (WSJ) section of the Penn Treebank
   mechanisms, together with minimal assumptions con-                       (PTB) (Marcus, Santorini, & Marcinkiewicz, 1994)? For
   cerning basic linguistic categories and rule hypothesis                  example, can they distinguish, as people do, between gram-
   search spaces are sufficient to account for much (per-                   matical and ungrammatical sentences in the form of known
   haps all) of the language acquisition task.”                             minimal pairs? Further, in the case of “ungrammatical”
                                                                            input, do they yield the “right” wrong parse as the most
   This basic position has been echoed by many authors since                probable analysis?1
nearly the beginning of the modern era of generative lin-
guistics; see, e.g., Suppes (1970) and Levelt (1974) among              2. Statistical models have been advanced as a way to avoid
many others for representative earlier statements; and Ab-                  the “brittleness” of symbolic systems (Abney, 1996). How-
ney (1996); Bod, Hay, and Jannedy (2003); Manning (2003);                   ever, all statistical language models must deal with sparse
and Lappin and Shieber (2007) for more recent claims along                  data to achieve robustness. Given this state of affairs, is it
these lines. Attempts have also been made to tie the con-                    1 We do not intend the term ungrammatical here to carry any par-
tinuum of probability scores accompanying the phrase struc-              ticular formal or theoretical weight. We use it simply as a familiar
ture recovered by such systems to “gradience” with respect               cover term. We discuss some of the subtleties of this position below.
                                                                     539

    in fact true that statistical models are robust, in the sense of         the right. Despite the preponderance of transitive over intran-
    being unaffected by minute perturbations in training data?               sitive verb frames in the PTB, the sentence length effect over-
    We note in passing that such sensitivity has typically not               whelmingly dominates the verb subcategorization difference
    been taken as reflecting the state of affairs in child lan-              (logprob scores given in parentheses, closer-to-zero number
    guage acquisition (see, e.g., Pinker (1984), among many                  referring to higher likelihood):4
    other sources).
                                                                                (1)     a.     The circus amused the children (−26.378)
3. Finally, one would expect a cognitively faithful model to                            b.   * The children amused (−20.951)
    have the property of being able to more easily acquire a nat-                       c.     The circus affected the children (−30.979)
    ural language than one that violates unnatural constraints,                         d.   * The children affected (−26.415)
    i.e. constraints not present in any natural language: for ex-
    ample, the artificially constructed language Epun (Smith,                   In the case of the psych-verb amuse, the (ungrammatical)
    Tsimpl, & Ouhalla, 1993), in which a particular emphatic                 inchoative form (1b) has a smaller negative magnitude log-
    form is based on counting rather than syntactic structure.               prob score, and thus a higher probability, than its causative
    Can Treebank systems acquire such non-natural languages                  counterpart (1a). A similar size logprob gap is also obtained
    easily, in contradistiction to human performance?                        for affect.5
                                                                                Given the structure of these systems, since the probabil-
    While this list plainly does not begin to exhaust the                    ity score assigned to a particular parse is typically constituted
 range of possible probes into the “competence” of statistical               from many thousands of individual decisions, their genera-
 parsers, this paper aims to stimulate discussion of additional              tive history, down to the level of individual words and their
 cognitively relevant stress testing beyond the simple PARSE -               frequency of occurrence in the PTB, it is quite challenging
 VAL -style evaluation, which scores parser output by counting               to control for all possible contrasts.6 However, for the pur-
 bracketing matches with respect to “gold standard” presumed                 poses of this initial study, in order to properly compensate
 ground-truth phrase structure from a human-vetted treebank.2                for this effect, we employed examples with the same number
                                                                             of words, or in the case of minimal pair comparisons involv-
                        Methods and Results                                  ing unequal sentence length, we point out cases where the
 In the following sections, unless otherwise noted all reported              sentence length effect has been unexpectedly neutralized or
 experiments have been performed using Bikel’s (2002) re-                    counteracted, e.g. in the case where an ungrammatical ex-
 implementation of Collins’s (2003) lexicalized, head-driven                 ample is scored lower than a corresponding grammatical (but
 statistical parser, henceforth abbreviated as B-Collins. We                 longer) counterpart.7 With this background in mind, we now
 make use of both the top-ranking parse output and the as-                   turn to some specific cases.
 sociated logprob score reported by parser for a given input
                                                                             Assessing Attained Knowledge of Language
 sentence.3 Parse results using the Berkeley parser (Petrov &
 Klein, 2007) are also reported for one experiment described                 Wh-Movement Consider the permutations shown in (2) for
 below. Both parsers have the critical property of having been               a wh-question counterpart to Bill will solve the problem.
 extensively trained on the same subset of the Wall Street Jour-             Highest logprob scores are given in the right-most column;
 nal (WSJ) portion of the Penn Treebank (PTB) dataset, hence-                the values shown are for the top-ranked parse only. (Note all
 forth, referred to simply as PTB.                                           sentences are of the same length; indeed, they contain exactly
                                                                             the same lexical items, just in different orders.)
 The Effect of Sentence Length
                                                                                (2)     a.     Bill will solve which problem? (−41.058)
 Care must be taken when comparing sentence probabil-
                                                                                        b.     Which problem will Bill solve? (−56.858)
 ity scores derived from the stochastic context-free grammar
 frameworks used by these systems. There is a strong inverse                            c.   * Which problem Bill will solve? (−53.381)
 correlation between probability and sentence length. For in-                    4 The verb form VB is immediately followed by a NP comple-
 stance, as illustrated in (1), with the logprob score given at              ment in 39% of the cases vs. 8% for no complement (Collins, 2003).
                                                                                 5 In the PTB amuse occurs less often but is scored higher than
     2 It is also clearly true that there are many aspects of “knowledge     affect (freq(amused)=1, freq(affected)=62) due to the fact that its
 of language” that such systems do acquire, viz., what they have been        frequency count falls below a predetermined threshold value for
 trained to learn, namely, high replicability of the PTB bracketing;         retention of frequency information (freq< 6) during training. Ac-
 aspects of predicate-argument structure, and the like. However, the         cordingly, amused is scored as an “unknown” word. Note that this
 goal in this paper is to focus on “stress tests” to where the systems       special “unknown” category is thus accorded more probability mass
 must be improved so as to be more cognitively plausible – and per-          than a verb that occurs 62 times, because so many more items oc-
 haps even improved from an engineering standpoint, since such an            curring fewer than 6 times will fall into this particular bin.
 approach has long been in the repertoire of standard software engi-             6 Bikel (2004) notes: “it may come as a surprise that the de-
 neering best practice.                                                      coder needs to access more than 219 million probabilities during the
     3 The term “logprob score” refers to the (natural) logarithm of the     course of parsing the 1,917 sentences of Section 00 [of the PTB].”
 calculated probability for the top-ranking parse. Probability values            7 As far as we have been able to determine, there is no straight-
 range from 0 to 1, and the corresponding logprob values scale from          forward mapping between logprob scores and some simple notion
 −∞ (zero probability) to 0 (absolute certainty, probability 1).             of grammaticality.
                                                                         540

           d.   * Bill solve which will problem? (−53.267)                           e.     Have the executors of the will read the paper?
           e.   * Which problem Bill solve will? (−62.3)                                    (red)
                                                                                      f.    Have the girls who will be on vacation next
   Not only is the wh-question (2b) dispreferred by B-Collins,                              week read the paper yet? (red)
it has the 2nd worst logprob score shown. In fact, in some
cases, the top-ranked parse is not what a native speaker might                       g.     Please have the girls read the paper. (reed)
have in mind. For example, B-Collins returns the parse shown                         h.     Have the girls read the paper? (red)
in Figure 1 for (2e) with the modal part of speech tag for will
re-tagged as a noun by the parser.8                                            It should be clear from the examples in (4) that a computer
                                                                            program needs to possess knowledge of the English auxil-
                                                                            iary/main verb system along with basic properties of sentence
                                                                            phrase structure in order to correctly carry out this task. The
                                                                            PTB assumes a part of speech tagset that identifies and distin-
                                                                            guishes among different forms of a verb as shown in Table 1,
                                                                            and these indeed ought to be sufficient, since these values suf-
                                                                            fice to fix a deterministic decision procedure to pronounce
                                                                            read correctly, as is evident.
                Figure 1: B-Collins parse for (2e).
                                                                                      Table 1: Penn Treebank (PTB) verb tagset.
Case Theory Consider the declarative and wh-question
pairs in (3) below, again with logprob scores on the right.                   Tag      Description                               Example
                                                                              VB       Verb, base form                           write
   (3)     a.     John is likely to win the race (−31.931)                    VBD      Verb, past form                           wrote
           b.   * John is likely will win the race (−45.355)                  VBG      Verb, gerund or present participle        writing
           c.     Who is it likely will win the race? (−45.251)               VBN      Verb, past participle                     written
                                                                              VBP      Verb, non-3rd person singular present     write
           d.   * Who is it likely to win the race? (−36.299)
                                                                              VBZ      Verb, 3rd person singular present         writes
   In the declarative raising case shown in (3a) and (3b), an
infinitival (but not a tensed) embedded clause is permitted.
                                                                               One might reasonably expect a stochastic parser trained on
However, exactly the reverse is true in the wh-question en-
                                                                            nearly 40,000 sentences to have acquired basic English sen-
vironment in (3c) and (3d) . The B-Collins parser exhibits
                                                                            tence structure and properties of the auxiliary and verbal sys-
a consistent preference for the infinitival environment, which
                                                                            tem, and thus be able to decode the examples in (4), correctly
works for the declarative case. Unfortunately, this also means
                                                                            identifying the appropriate tag for read in each case, thereby
that it ineluctably, and incorrectly, signals a preference for
                                                                            solving the “text reading machine problem” posed by Jack-
the embedded infinitival clause in the case of wh-questions.
                                                                            endoff. For example, the parse tree recovered by the Berkeley
It cannot succeed in both situations.
                                                                            parser in the case of (4b), correctly identifying read asVBN,
Tense-marking Jackendoff (1999) in a Linguistic Society                     is given in Figure 2. (In the case of read, only the VBD and
of America pamphlet considered a “text reading” puzzle as                   VBN forms should be pronounced as red.)
an example of what is impossible for a computer to accom-
plish without knowledge of language: in particular, the task
of determining the pronunciation of the orthographical form
read, which can be pronounced as red or reed depending on
context. The sentences considered by Jackendoff are repro-
duced in (4).
   (4)     a.     The girls will read the paper. (reed)
           b.     The girls have read the paper. (red)
           c.     Will the girls read the paper? (reed)
           d.     Have any men of good will read the paper?
                  (red)                                                                    Figure 2: Berkeley parse for (4b).
    8 It does not help to force B-Collins to retain the correct part of
                                                                               However, this does not seem to be true. Figure 3 illustrates
speech tag: the corresponding parse with will retaining its correct
modal part of specch tag has an even less favorable logprob score of        the corresponding parse for (4h). The sentence has been prop-
−64.695.                                                                    erly identified as an interrogative (category label SQ) but the
                                                                        541

                              Table 2: Berkeley and B-Collins results for the read pronunciation task.
                               Example       (4a)   (4b)      (4c)    (4d)     (4e)     (4f)     (4g)      (4h)
                               Berkeley      VB     VBN       VB      *VB      *VB      *VB      VB        *VB
                               B-Collins     VB     VBN       VB      *VB      *VB      VBN      *VBN      *VB
parser has failed to assign the correct VBN tag to read. (The
assigned tag VB will result in a pronounciation of reed.)
                                                                                         Figure 4: High attachment for (5a).
               Figure 3: Berkeley parse for (4h).
    We summarize the results of the read pronunciation task
in Table 2 (incorrectly tagged cases are starred (*)). As the
results indicate, both parsers get 4 out of a total of 8 cases
correct. For comparison, an assignment based purely on tag
frequency would yield a crude baseline of 3 out of 8 correct
on this task, as VB and VBN occur 45% and 19% of the time
in the training set for read.                                                            Figure 5: High attachment for (5b).
    One might properly ask here whether the “blame” for the
incorrect results is due to improper tagging or rather the
parser itself. We can control for this factor by forcing the             is exactly one sentence, reproduced in (6) below, where the
system to use the “ground truth” tags.                                   PTB contains PP-attachment information for milk:9
Robustness and Sensitivity to Perturbation                                  (6)    Borden even tested [NP [NP a milk] [PP with 4% but-
                                                                                   terfat]] in the South but decided the market was too
It is sometimes tacitly assumed that statistical systems are in-
                                                                                   small.
herently less brittle than symbolic models, in the sense that
they can assign parses to less-than-grammatical input, as well              It is straightforward to verify that this one example can
as being robust in the face of input “noise” equivalently, low           control low vs. high PP-attachment in the case of milk. For in-
sensitivity to small alterations in a large training set. It is this     stance, we performed an experiment in which the only change
latter property that it is explored below.                               to the PTB was that the PP with 4% butterfat in (6) was elim-
The Milk Example Consider the set of sentences in (5).                   inated from the training set. After re-training, the attachment
                                                                         preference was reversed, i.e. high attachment obtains for (5b).
    (5)   a.    Herman mixed the water with the milk                     Since the sentence in (6) is just one out of 39,832 training
          b.    Herman mixed the milk with the water                     examples, this experiment indicates that B-Collins shows a
                                                                         surprising sensitivity to perturbation.
          c.    Herman drank the water with the milk
                                                                            The true picture is actually even more unstable than de-
          d.    Herman drank the milk with the water                     scribed above. By cycling through combinations of verbs and
    Each of these sentences should receive the same basic                nouns, one can get a range of different PP-attachment behav-
parse, with the prepositional phrase (PP) headed by with at-             iors as shown in Table 3.
taching high, at the verb phrase (VP) level, as exhibited in                This merely hints at a much broader problem in the training
Figure 4 in the case of sentence (5a).                                   of such systems and the determination of high-low modifier
    However, in the case of both (5b) and (5d), in which the             attachment, a key problem that has drawn much psycholin-
order of milk and water is reversed, quite unexpectedly a low            guistic and computational attention over the years and which
attachment for the PP is preferred by the parser. (Figure 5                  9 Milk  occurs 24 times in the training set, 21 as a noun.
displays the corresponding B-Collins parse for (5b).) Why?                  10 The  frequency of drank is zero in the training set. The same
This bias is a property of the training set. It turns out there          result obtains with any unknown word, e.g. flubbed.
                                                                     542

                                                                       John ate the ice-cream while on the table but much less fre-
             Table 3: Attachment sensitivity of milk.
                                                                       quently, John ate while on the table the ice-cream. To mimic
        Verb        Noun          Attachment                           this effect, in this second experiment, we swapped the order
                                  Verb + milk with + noun /            of arguments and adjunct phrases for every other sentence in
                                  Verb + noun + with milk              the PTB, so that adjuncts become adjacent to the verb and
        drank10     water         high / high                          arguments therefore non-adjacent.
        mixed       water         low / high                           Experiment 3 The final experiment simply combines the
        mixed       computer      low / low                            transforms of the two prior experiments, resulting in ex-
                                                                       tremely “unnatural” sentence phrase structure, such as *the
                                                                       proposed changes also executives later and less often report
remains a source of a great deal of the error in parsing sys-          exercises of options allow would.
tems, no matter what metric is used. The problem is that                  After training and testing following standard methods, the
statistically-trained systems must inherently rely on sparse           experimental results are summarized in Table 4:12
data and smoothing. When examined more closely, we find
that many modifier relations – like the PP attachment example            Table 4: B-Collins evaluation on non-natural training data.
above – are learned on the basis of a single example, fixing an
alternative to some default attachment point. If the above ex-
periment is on the right track, then each of these cases would           Experiment                        Precision/Recall       F-measure
prove to be data-sensitive; indeed, as mentioned, this is pre-           Baseline (original data)          88.1 / 88.3            88.2
cisely one of the areas where current systems behave poorly.             (1) Verb complement               88.7 / 86.7            87.7
Deeper examination of such cases may reveal whether it will              (2) Adjunct argument              88.6 / 86.5            87.5
ever be possible to improve on modifier attachment without               (1) + (2)                         88.5 / 85.8            87.1
resort to additional data or resources.
Assessing Non-Natural Language Acquisition                                In each case, bracketing precision and recall are as de-
                                                                       fined in (Harrison & al, 1991) and was computed over the
In the following experiments we explore the question of how
                                                                       same set of held-out test sentences as in the original (unmod-
well Treebank-trained (and developed) parsers work when
                                                                       ified) dataset.13 It is evident that B-Collins appears to perform
faced with non-natural training data. The basic strategy we
                                                                       nearly as well after the training set is liberally sprinkled with
employed was to modify the PTB training set by applying a
                                                                       extremely unnaturally modified PTB data. One possible rea-
series of basic (yet clearly humanly unattested) phrase-order
                                                                       son for this may stem from the genre of the data employed:
transformations.
                                                                       despite the size of the Treebank, WSJ sentences are relatively
Experiment 1 Verb-complement constituent order can be                  self-similar.14
viewed as a basic parameter of natural language: for head-
initial languages such as English, verbs precede their com-                                         Discussion
plements; in head-final languages like Japanese, verbs fol-            Let us now revisit the three basic questions outlined earlier
low their complements. For some verb-second languages,                 and take stock of the results:
e.g. German, the verb must be the second phrase in matrix              (1) Have state-of-the-art statistical parsers attained “knowl-
clauses, but head-final in subordinate clauses. However, in            edge of language”?
no natural language we are aware of does a speaker utter one           Current state-of-the-art systems, such the B-Collins (and
sentence adhering to a head-initial parameterization, and then         Berkeley) parser reviewed in this paper, score close to the
in the next sentence follow head-final order, in some such             90%-level (on withheld PTB data) when evaluated on phrase
random fashion.11 To emulate this unattested situation, in             structure bracketing fidelity (Collins, 2003).15 However,
the following experiment we created a deliberately un-natural          merely being able to bracket sentences “accurately” evidently
training set: we inverted verb-complement order so that every          does not constitute full “knowledge of language.” Rather,
other sentence was verb-initial, and the intervening sentences
verb-final. We then re-trained on this transformed Treebank.              12 The F-measure is the harmonic mean of bracketing recall and
                                                                       precision.
Experiment 2 Another basic parameter of language often                    13 As is standard in the PTB literature, training is performed on
advanced is the constituent order of arguments and adjuncts.           WSJ sections 2–21 (nearly 40,000 sentences), and evaluation on sec-
For example, in English, VP adjunct phrases tend to respect            tion 23 (approx. 2500 sentences).
                                                                          14 Indeed, this self-similarity is also supported by cross-validation
verb-complement adjacency, and are consistently attached at            analysis that yields nearly the same F-scores with as little as 10%
the edge of the VP (following the complement); thus we find            of the training data; space does not permit the reproduction of these
                                                                       extensive results here.
   11 This individual stochastic behavior has sometimes been sug-         15 Bracketing is not the only possible evaluation metric. Predicate-
gested as an account of historical and/or idiolect variation, and,     argument and modifier-modifee (or dependency) relations are other
while logically possible, remains speculative.                         clear choices, as has been discussed in the literature.
                                                                   543

knowledge of language is multi-dimensional and cannot be                ing symbolic and statistical approaches to language (pp.
conveniently summarized in terms of a single number, an F-              1–26). Cambridge, Massachusetts: The MIT Press.
measure. Similarly, grammaticality cannot be described in             Bikel, D. M. (2002). Design of a multi-lingual, parallel-
terms of a simple logprob score. Such conclusions may seem              processing statistical parsing engine. In Proceedings of the
obvious from the outset, but the goal in applying the kinds             second international conference on human language tech-
of stress tests described in this paper is to discover exactly          nology research (pp. 178–182). San Francisco, CA, USA:
where these systems fail. As such, these experiments and                Morgan Kaufmann Publishers Inc.
test data are merely diagnostic aids. We have shown through           Bikel, D. M. (2004). Intricacies of Collins’ parsing model.
stress testing over wh-questions, subject raising, and auxiliary        Computational Linguistics, 30(4), 479–511.
fronting that these statistical parsing systems, despite access       Bod, R. (2003). Is there evidence for a probabilistic language
to 40,000 training examples, fail to learn many grammatical             faculty?
generalizations that all native speakers possess. The paper           Bod, R., Hay, J., & Jannedy, S. (Eds.). (2003). Probabilistic
focused on certain cases of syntactic and lexical relation ef-          linguistics. Cambridge, Massachusetts: MIT Press.
fects (as in PP attachment) because this has often been ad-           Chater, N., & Manning, C. D. (2006). Probabilistic models of
vanced as one of the strengths of such systems. (For reasons            language processing and acquisition. Trends in Cognitive
of space we have omitted many other similar constraints that            Sciences, 10, 335–344.
also fail.) Indeed, the challenge would seem to be to discover,       Collins, M. (2003). Head-driven statistical models for natural
out of the very long list of grammatical generalizations that           language parsing. Computational Linguistics, 29(4), 589–
linguists have accumulated over the past sixty years, some              637.
certainly more valid than others, which, if any of these con-         Crocker, M., & Keller, F. (2006). Probabilistic gram-
straints these parsers do capture. The challenge for future re-         mars as models of gradience in language processing. In
search is whether these (or other similar) diagnostics can be           G. Fanselow & et al (Eds.), Gradience in grammar: Gen-
exploited to advance the state-of-the-art in statistical parsing.       erative perspectives. Oxford: Oxford University Press.
(2) Are statistical parsers “robust”?                                 Harrison, P., & al et. (1991). Evaluating syntax performance
As the milk example illustrates, the modification of a single           of parser/grammars of English. In Proceedings of the work-
example can overturn high/low modifier attachment prefer-               shop on evaluating natural language processing systems.
ences. Thus, these systems can be extremely fragile despite             Association for Computational Linguistics.
their inherently statistical nature. One possible reason for          Jackendoff, R. (1999). Why can’t computers use English?
this stems from the size of the parameter estimation problem            New York: Linguistic Society of America (LSA) Publica-
for training. All statistical parsers must employ a variety of          tions.
smoothing methods to counteract the “sparse data problem”             Lappin, S., & Shieber, S. M. (2007). Machine learning theory
— methods for estimating phrase structure rule probabilities            and practice as a source of insight into universal grammar.
for which none, or very few, examples exist in the training             Journal of Linguistics, 43(2), 393-427.
set.                                                                  Levelt, W. J. M. (1974). Formal grammars in linguistics and
(3) Do statistical parsers mirror human limits on acquisition?          psycholinguistics (vol. 1): An introduction to the theory of
                                                                        formal languages and automata. The Hague: Mouton.
On the one hand, the fact that these systems often fail to ac-        Manning, C. (2003). Probabilistic syntax. In R. Bod, J. Hay,
quire generalizations of the sort discussed earlier points to           & S. Jannedy (Eds.), Probabilistic linguistics (pp. 289–
weaknesses in acquisition, despite state-of-the-art bracketing          341). Cambridge, Massachusetts: MIT Press.
fidelity; on the other hand, the fact that these systems can          Marcus, M. P., Santorini, B., & Marcinkiewicz, M. A. (1994).
perform robustly when constituent order parameterization is             Building a large annotated corpus of english: The penn
pseudo-randomized points to a non-human-like acquisition                treebank. Computational Linguistics, 19(2), 313–330.
ability. Thus these systems seem at the same time to be both          Petrov, S., & Klein, D. (2007). Learning and inference for
too weak and too strong. It is this lack of fit to human-like           hierarchically split PCFGs. In Aaai 2007 (nectar track).
abilities, a “cognitive gap,” that would seem most important          Pinker, S. (1984). Language learnability and language de-
to remedy if one indeed wants to take such systems seriously            velopment. Cambridge, MA: Harvard University Press.
as models for human language acquisition and cognition.               Smith, N., Tsimpl, I.-M., & Ouhalla, J. (1993). Learning
                                                                        the impossible: The acquisition of possible and impossible
                     Acknowledgments                                    languages by a polyglot savant. Lingua, 91, 279–347.
We thank Michael Coen, Ali Mohammed, and Beracah                      Sproat, R., & Lappin, S. (2005). Re: A challenge to the
Yankama for assistance and valuable suggestions.                        minimalist community. Linguist List 16.143.
                                                                      Suppes, P. (1970). Probabilistic grammars for natural lan-
                          References                                    guages. Synthese, 22, 95–116.
Abney, S. (1996). Statistical methods and linguistics. In
   J. Klavans & P. Resnik (Eds.), The balancing act: Combin-
                                                                  544

