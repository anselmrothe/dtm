UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Reinforcement Learning Leads to Risk Averse Behavior
Permalink
https://escholarship.org/uc/item/3fw7z536
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Author
Denrell, Jerker C.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                              Reinforcement Learning Leads to Risk Averse Behavior
                                             Jerker C. Denrell (denrell@gsb.stanford.edu)
                                     Graduate School of Business, Stanford University, 518 Memorial Way,
                                                          Stanford, CA 94305 USA
   Keywords: Reinforcement Learning; Risk Taking; Adaptation;                                                        S 2b
   Exploration.                                                                                        Exp[ Sμ i −            σ i2 ]
                                                                                                                   2( 2 − b )
                                                                                   lim t →∞ Pi ,t = N                                 ,
   Animals and humans often have to choose between                                                                      S 2b
options with reward distributions that are initially unknown                                       ∑     Exp[ Sμ j −
                                                                                                                     2( 2 − b )
                                                                                                                                σj] 2
and can only be learned through experience. Recent                                                  j =1
experimental and theoretical work has demonstrated that                  where μ i & σ i2 are the expected reward and the variance of
such decision processes can be modeled using                             alternative i.
computational models of reinforcement learning (Daw et al,                  This probability is an increasing function of the expected
2006; Erev & Barron, 2005; Sutton & Barto, 1998). In these
                                                                         reward, but a decreasing function of the variance. Moreover,
models, agents use past rewards to form estimates of the                 these choice probabilities are identical to that of a decision
rewards generated by the different options and the                       maker who knows the probability distributions, prefers
probability of choosing an option is an increasing function
                                                                         alternatives with high mean and low variance, and chooses
of its reward estimate. Here I show that such models lead to             between options according to a logit choice rule. Thus, the
risk averse behavior.                                                    learning model generates choice probabilities identical to a
   Reinforcement learning leads to improved performance                  random utility model assuming mean-variance preferences.
by increasing the probability of sampling alternatives with                 I prove that the result that reinforcement learning leads to
good past outcomes and avoiding alternatives with poor past
                                                                         risk averse behavior generalizes to a large class of
outcomes. Such adaptive sampling is sensible but introduces              probability distributions and several other belief-updating
an asymmetry in experiential learning. Because alternatives              rules and choice rules.
with poor past outcomes are avoided, errors that involve
                                                                            If the reward distributions are not symmetric, I show the
underestimation of rewards are unlikely to be corrected.                 learning model can generate behavior consistent with a
Because alternatives with favorable past outcomes are                    preference for alternatives with a reward distribution with
sampled again, errors of overestimation are likely to be
                                                                         low variance and positive skew. I also show that a modified
corrected (Denrell & March, 2001; Denrell, 2005; 2007;                   logit choice rule can generate behavior consistent with an s-
March, 1996). Due to this asymmetry, reinforcement                       shaped utility function.
learning leads to systematic biases in decision making (e.g.
Denrell, 2005; Denrell & Le Mens, 2007).
   In this paper I demonstrate formally that because of this
                                                                                                    References
asymmetry, reinforcement learning leads to risk averse                   Daw, N. D., O'Doherty, J. P., Dayan , P., Seymour, B., &
behavior: among a set of uncertain alternatives with                        Dolan, R. J. (2006). Cortical substrates for exploratory
identical expected value, the learner will, in the long run, be             decisions in humans. Nature, 441, 876-879.
most likely to choose the least variable alternative.                    Denrell, J. (2007). Adaptive learning and risk taking.
   In particular, suppose that                                              Psychological Review, 114, 177-187.
   1) In each period, the learner must choose one of N                   Denrell, Jerker. (2005). Why most people disapprove of me:
alternatives, each with a normally distributed reward, ri ,t .              Experience sampling in impression formation.
                                                                            Psychological Review, 112, 951-978.
   2) The learner uses a weighted average of past                        Denrell, J. and G. Le Mens (2007). Interdependent sampling
experiences to form a reward estimate, y i ,t , for each                    and social influence. Psychological Review, 114, 398-422.
alternative. Specifically, the reward estimate of alternative i          Denrell, J. & March, J. G. (2001). Adaptation as
                                                                            information restriction: The hot stove effect. Organization
is: y i ,t +1 = (1 − b) y i ,t + bri ,t +1 .                                Science, 12, 523-538.
   3) The learner chooses among alternatives according to a              Erev, I., & Barron, G. (2005). On adaptation, maximization,
logit choice rule: the probability that alternative i is chosen             and reinforcement learning among cognitive strategies.
                                     N                                      Psychological Review, 112, 912-931.
in period t is Exp ( Sy i ,t ) /[∑ Exp ( Sy j ,t )] .                    March, J. G. (1996). Learning to be risk averse.
                                    j =1
                                                                            Psychological Review, 103, 309-319.
   This model leads to risk averse behavior: asymptotically              Sutton, R. & Barto, A. G. (1998). Reinforcement Learning.
the probability that alternative i is chosen is                             Cambridge, MA: The MIT Press.
                                                                     113

