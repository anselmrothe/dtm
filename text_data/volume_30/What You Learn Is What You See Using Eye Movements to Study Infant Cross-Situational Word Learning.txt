UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
What You Learn Is What You See: Using Eye Movements to Study Infant Cross-Situational
Word Learning
Permalink
https://escholarship.org/uc/item/3rs333jd
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Yu, Chen
Smith, Linda B.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

       What You Learn is What You See: Using Eye Movements to Study Infant Cross-Situational
                                                             Word Learning
                                       Chen Yu and Linda B. Smith (chenyu@indiana.edu)
                Department of Psychological and Brain Sciences, and Cognitive Science Program, Indiana University
                                                        Bloomington, IN, 47405 USA
                               Abstract                                 of attention during individually ambiguous training trials
                                                                        and a simple associative model to predict individual
   Recent studies show both adults and young children possess
   powerful statistical learning capabilities to solve the word-to-     differences in learning.
   world mapping problem. However, it is still unclear what are           Cross-situational word learning has been proposed as a
   the underlying mechanisms supporting seemingly powerful              solution to the uncertainty inherent in trying to learn words
   statistical cross-situational learning. To answer this question,     from their co-occurrences with scenes (Siskind, 1996; Yu &
   the paper uses an eye tracker to record moment-by-moment             Smith; 2007). Scenes typically contain many possible
   eye movement data of 14-month-old babies in statistical              referents, with speakers talking about and shifting their
   learning tasks. A simple associative statistical learning is
   applied to the fine-grained eye movement data. The results
                                                                        attention rapidly among the potential referents. This
   are compared with empirical results from those young                 uncertainty is still considerable even if one assumes a
   learners. A strong correlation between these two shows that a        learner biased to link names to whole objects (e.g.,
   simple associative learning mechanism can account for both           Markman, 1990). For example, as illustrated in Figure 1, a
   behavioural data as a group and individual differences,              young learner may hear the words "bat" and "ball" in the
   suggesting that the associative learning mechanism with              ambiguous context of seeing both a BAT and BALL
   selective attention can provide a cognitively plausible model        without any information as to which word refers to which
   of statistical learning. The work represents the first steps to
   use eye movement data to infer underlying learning processes         scene element. However, although the learner may have no
   in statistical learning.                                             way of knowing from any such single learning situation
                                                                        which word goes with which referent, the learner could
   Keywords: word learning, language development, eye                   nonetheless determine the right mappings if the learner kept
   tracking, computational modeling
                                                                        track of co-occurrences and non-occurrences across
                                                                        situations, and evaluated the cross-situational evidence for
                            Introduction                                word-referent pairings in the proper way. Using the example
   There is growing interest in the idea of language learning           in Figure 1, if the learner viewed a second scene while
as a form of data mining. Structure that is not obvious in              hearing the words "ball" and "dog" and if the learner could
individual experiences or small bits of data is derivable from          remember and combine the conditional probabilities of co-
statistical analyses of large data sets (Landauer & Dumais,             occurrences from across the two situations, the learner could
1997; Li, Burgess & Lund, 2000; Steyvers & Tenenbaum,                   correctly infer that "ball" maps to BALL.
2005; see a review by Chater & Manning, 2006). These                        In a recent study, Smith and Yu (2008) showed that 12-
techniques have been shown to be powerful in capturing                  and 14-month old babies do this. They presented the infants
syntactic categories (Mintz, Newport, & Bever, 2002;                    with learning trials on which there were always two seen
Monaghan, Chater, & Christiansen, 2005), syntactic                      objects and two heard names but no information as to which
structures (Solan, Horn, Ruppin, & Edelman, 2005) and                   name went with which object. From such individually
word boundaries (Christiansen, Allen, & Seidenberg, 1998).              ambiguous learning trials, the infants learned the mappings
Also growing are suggestions (as well as relevant evidence)             of 6 names to 6 objects and did so in a learning experience
that infants and young children are powerful statistical                that lasted in total less than 4 minutes. The cross-trial word-
learners who make what seem to be sophisticated statistical             referent statistics were the only information available to
inferences from even limited data (Newport & Aslin, 2004;               disambiguate those word-referent pairings. Thus the infants
Tennebaum & Xu, 2000; etc).
  What is not so clear, however, is the nature of underlying
statistical learning mechanisms. The working assumption
seems to be that learners more or less passively accumulate
data and then apply special statistical computations to that
data. In this paper, we consider an alternative, that at least
one form of statistical learning shown by infants, is the
product of moment-by-moment attention, itself inherently
selective, dynamic, and via simple associative mechanisms,
dependent on and indicative of learning. We make this case
                                                                         Figure 1: The conditional association probabilities between words
in the context of infants’ cross-situational learning of names         and referents can be calculated across trials.
and referents; the approach is to use eye-tracking measures
                                                                    1023

must have combined the information across trials. The                                            Method
present question is the nature of the processes that underlie         Participants
this learning.                                                        The final sample consisted of 12 14-month-olds (7 boys, 5
   One possible learning process is Hebbian-like associative          girls), with a mean age of 14.3 (SD = 0.6) months. An
learning, a form of learning known to be fundamental to               additional 12 infants were tested but not included in the
many perceptual and cognitive capabilities. In the present            sample due to fussiness (n = 2), persistent inattention to the
case, the learner could simply store all associations between         display n=2), and mostly occasional excessive movement
words and references. For example, with respect to Figure             that prohibited the complete collection of continuous eye
1, if the system stored only associations between words and           movement data with the eye tracker (n = 8).
whole objects, there would be four associations formed on             Stimuli
trial one (bat to BAT, bat to BALL, ball to BAT, ball to              The 6 ‘‘words’’ bosa, gasser, manu, colat, kaki and regli,
BALL). On the second experience shown in the figure, one              were designed to follow the phonotactic probabilities of
of these (ball to BALL) would be strengthened more than               American English and were recorded by a female speaker in
the others. Across trials, the relative strengths of                  isolation. They were presented to infants over loudspeakers.
associations between words and their potential referents              The 6 ‘‘objects’’ were drawings of novel shapes, each was a
would come to reflect the correct word referent mappings.             unique bright color. There were 30 training slides. Each
Simple associative models such as this have been criticized           slide simultaneously presented two objects on the screen for
on the grounds (see Keil, 1989) that there are just too many          4 s; the onset of the slide was followed 500 ms later by the
possible associations across situations to store and to keep          two words – each said once with a 500 ms pause between.
track of.                                                             Across trials, the temporal order of the words and spatial
  This raises the key question for the present study, whether         order of the objects were varied such that there was no
learners do not actually store all co-occurrences, but only           relation between temporal order of the words and the spatial
some of them. Further, we ask whether infants’ attention to           position of the referents. Each correct word-object pair
and thus selective storage of word-referent pairs might be            occurred 10 times. The two words and two objects
guided by their previous experience. And if this is so, could         appearing together on a slide (and creating the within trial
a simple associative model explain not only infants’ success          ambiguities and possible spurious correlations) were
in learning in this task but also individual differences in that      randomly determined such that each object and each word
learning? The issue of individual differences is particularly         co-occurred with every other word and every other object at
critical if infants are not simply passive accumulators of            least once across the 30 training trials. The first four training
data but instead select among the available data. If infants          trials each began with the centered presentation of a Sesame
select some pairings over others to notice and store – and if         Street character (3 s) to orient attention to the screen. After
these pairings guide later selections – then individual               these first four trials, this attention grabbing slide was
learners may distort the regularities in the input both in            interspersed every 2–4 trials to maintain attention. The
ways that enhance learning of the right word-referent pairs           entire training – an effort to teach six word-referent pairs –
and in ways that hinder it.                                           lasted less than 4 min (30 training slides and 19 interspersed
    To answer this question in computational modeling, a              Sesame Street character slides). There were 12 test trials
model needs to be fed with the same input that individual             each lasting 8 seconds. Each test trial presented one word,
learners receive – that is, the information that individual           repeated 4 times with 2 objects – the target and a distracter –
learners attend to in cross-situational learning with multiple        in view. The distracter was drawn from the training set.
words and multiple referents. Our proposed solution is to             Each of the 6 words was tested twice. The distracter for
continuously track eye-gaze direction throughout learning.            each trial was randomly determined such that each object
The assumption here is when a learner associates a word               occurred twice as a distracter over the 12 test trials. This
with a referent among other simultaneously presented                  duration and structure of training and test trials was the
referents, the learner is likely to look at that referent (this is    same as in Smith and Yu (2008).
what it means to register the association). In this way,              Apparatus
different learners may attend to different referents in a             A learner’s eye gaze was measured by a Tobii 1750 eye
visual scene when hearing the same word, which leads to               tracker with an infant add-on (www.tobii.se). The principle
different learning results. Recent psycholinguistic studies           of this corneal reflection tracking technique is that an
already suggest that speech and eye movement are closely              infrared light source is directed at the eye and the reflection
linked in both language comprehension and production (e.g.            of the light on the corneal relative to the center of the pupil
Tanenhaus, Spivey-Knowlton, Eberhard, & Sedivy, 1995).                is measured and used to estimate where the gaze is fixated.
    In brief, we apply this eye-tracking paradigm in language         The eye tracking system recorded gaze data at 50Hz
learning and use eye movement, and the synchrony of those             (accuracy = 0.5°, and spatial resolution = 0.25°) as a learner
movements with respect to the heard object names as a                 watches an integrated 17 inch monitor with a resolution of
measure of moment-by-moment learning and as a clue to the             1280 x 1024 pixels.
internal state of the learner.
                                                                  1024

Procedure
Infants sat in a parent’s lap 60 cm from the 17’’ computer
monitor used to present the stimuli. Before the experiment a
calibration procedure was carried out. In preparation for the
calibration the experimenter adjusted the eye tracker to
make sure that the reflections of both eyes were centered in
the camera’s field of view. We used a procedure including
nine calibration points. The total duration of calibration
procedure was about 3 minutes before the training trials
start. Parents were instructed to look to the middle of the        Figure 2: A 6 x 6 association matrix built based on the synchrony
screen and not to interact with the child during the               between a subject’s eye movements and spoken words during
experiment.                                                        training. Each cell represents the association probability of a word-
Data                                                               object pair. The diagonal items are correct associations and other
The eye tracker outputs (x,y) coordinates on the computer          non-diagonal items are spurious correlation. Dark means low
display of the visual presentation at the sampling rate of         probabilities and white means high probabilities.
50Hz. There are in total 120 sec (4 sec/per trial x 30 trials)
during training and 96 sec (8 sec/per trial x 12 trials) during                                The Model
testing. Therefore, there are 6,000 data points in training and       The model is conceptually very simple. An associative
4,800 data points in testing, if the eye tracker works             learning mechanism strengthens the link between a word
perfectly. In practice, the tracking system occasionally           and a referent if these two co-occur regularly across
failed to detect the subject’s eye gaze either because the         multiple trials and weakens the link if the word and the
subject’s head and gaze moved outside of the tracking              referent do not co-occur. In the current experiment, infants
plane, or the eye tracker could not correctly infer the            were exposed to 6 words and 6 pictures in total. Therefore, a
subject’s eye movements for some other reasons. For the 12         6 by 6 association matrix shown in Figure 2 is used in
infants with good tracking results, the average tracking           modeling as a representation of all the possible associations
success is 76% in training and 71% in testing. Thus, on            that a learner may keep track of. In such an association
average, we collected 4,560 data points in training and            matrix, each cell corresponds to a particular word-referent
3,408 data points in testing per subject, which are used in        association. The diagonal cells are the 6 correct pairings
the following data analysis and modeling.                          while non-diagonal cells represent spurious correlations due
                                                                   to the ambiguity inherent in training trials. The association
                      Behavioral Results                           probability of each cell is updated trial by trial in real-time
   Infants were presented with 30 training trials (two words       learning. Given such an association matrix built through
and two objects) and then 12 test trials in which one target       training, the learner can make a decision during testing
word was played and two objects (the correct referent and          simply by looking at the referent more strongly associated
the distractor) were displayed. Infants’ preferential looking      referent with a tested word. In this way, a successful learner
on such test trials is used as a common measure of language        would be one who built a matrix in which most diagonal
comprehension in that infants systematically look at the           items were assigned with higher probabilities than those in
portion of the display that corresponds to what they are           non-diagonal cells. In contrast, an unsuccessful learner
hearing and this was the behavioral measure of learning            would be one who accumulated strong but wrong
used by Smith & Yu (2008). Accordingly, the first question         associations between words and referents, those not on the
we addressed was whether this study replicated the previous        diagonal. Thus the critical issue for learning is the specific
result: did infants during the test trials look longer at the      associations that are accumulated over trials.                     A
correct referent for the heard word than the distractor? The       nonselective (ideal) learner would just keep track of
answer is “yes,” t(11) = 3.28, p < .01; thus, this study           everything. However, the more psychologically correct
replicates the earlier finding that very young word learners       model may be one based on more selective attention and on
can learn word-referent pairings from individually                 attention that reflects current knowledge. Indeed, the very
ambiguous learning experiences by combining the                    method of preferential looking to sights that correspond to
information across those experiences. The main purpose of          heard words assumes that attention is so guided by
this study, however, is to examine the relation between            knowledge.
looking on the training trials and learning on the test trials.       To examine these possibilities, we suggest that the
To this end, we first present a simple associative model that      association matrix can be accumulated trial by trial as
takes the micro-structure of the eye-tracking data during          follows:
training as input and predicts individual performance on the                            1                  1   
                                                                                          1
                                                                                                               ∑   
test trials.
                                                                                          
                                                                   t is the trial number, and   refers to the association
                                                                   probability of the object i and the word j at the tth trial.
                                                                   Thus,   corresponds to one cell in the association
                                                               1025

matrix which is composed of two weighted parts. The first                timestamps of each fixation. Next, we segmented the whole
part    1 reflects the accumulated association                    set of eye fixations into individual trials by aligning eye
probability so far until the (t-1)th trial that is carried over to       fixations with the timing of training trials. Within each
the current trial. The second part (with two variables              learning trial, there are multiple eye fixations on the two
and ) updates the previous association probability based              objects on the computer screen that occur as the two words
on a learner’s eye movement in the current trial. More                   are sequentially presented. Assume that there are L fixations
specially, we suggest that the dynamics of a learner’s eye               , , , … ,   in the tth learning trial. For a fixation  ,
movements may reflect in two ways the learner’s internal                   is the object that was fixated on,   is the spoken
state during the current trial. First, rapid shifts of visual            word that the subject heard right before or during the
attention between possible objects after hearing a word may              fixation, and   is the fixation time. As shown in Figure
reflect the learner’s uncertainty (that is, the lack of one              3, all of the eye fixations generated between the 200 ms
stronger and one weaker association). In brief, we expect                after the onset of a spoken word and the onset of the next
that the learner is more likely to consistently fixate on the            spoken word (or the end of the current trial) are assigned to
corresponding referent to the degree that it is strongly                 be associated with that spoken word.
associated with the target word; this is, again, the very basis                , as an indicator of the learner’s uncertainty in the
of using preferential looking to measure word knowledge.                 current trial, can be encoded as how frequently the learner
This principle is encoded by  that measures the overall               moves his eyes between those objects after hearing a word.
degree of uncertainty in the tth learning trial from individual          Therefore, we use the entropy of a sequence of eye fixations
learners’ perspective. Second, the multimodal synchrony                  within the trial as a metric to characterize this factor:
                                                                                                  
between eye movements and spoken words may indicate the                                                              1
                                                                                                         
                                                                                                     ∑         / ∑  
strength of the registration of a certain word-referent
pairing, and the duration of such synchronized behaviours                                        
may indicate how strong that word-referent association is in             where L is the total number of eye fixations within the tth
the learner’s association matrix. This observation is                    trial.
captured by   that measures the possible association                   Moreover, the second variable   measures the
between a word i and an object j at the current trial based on           possible association between a word and an object, which is
eye movements. In the following, we explain exactly how to               composed of two parts. The first part estimates the
estimate  and  .                                                 probability of associating an object to a particular word
We first computed eye fixations from raw eye movement                    based on the amount of time of looking at that object
data and converted the continuous gaze data stream into a                (compared with other objects) after hearing that word.
set of eye fixations marked by the onset and ending                      Given multiple candidate objects, how likely is a heard
                                                                         word associated with each object. The second part estimates
                                                                         the probability based on comparing the looking time to the
                                                                         same object cross several spoken words. Given multiple
                                                                         candidate words, how likely is an object associated with
                                                                         each word. Formally,   can be represented as follows:
                                                                                         ∑  !"#,  $ !"%,  $
                                                                                 
                                                                                                 ∑  !"#,  $ 
                                                                                                     ∑  !"#,  $ !"%,  $
                                                                                                            ∑  !"%,  $ 
                                                                         where ! is the Kronecker delta function, equal to one when
                                                                         both of its arguments are the same and equal to zero
                                                                         otherwise. Thus, the denominator of the two parts is the
                                                                         same that accumulates the amount of fixations ( T(fm), etc.)
                                                                         on a certain object j (v(fm) == i) after hearing a certain word
                                                                         j (w(fm) == j). The numerator in each part just normalizes
                                                                         the above denominator either cross all the words or cross all
                                                                         the objects respectively. Thus, a learner’s visual attention in
                                                                         statistical learning is directly encoded in the association
                                                                         matrix the model built. Since individual infants generated
     Figure 3: we measure where the learner is fixating on after
  hearing a spoken word. For example, after hearing the word
                                                                         different eye fixation sequences, the model builds different
  “bosa”, there are 4 eye fixations on both left and right objects.      association matrices accordingly based on different inputs.
  Those fixations (and corresponding fixed objects) are associated       Results
  with the word “bosa”. The strength of the association between          Figure 2 shows an example of an association matrix built
  an object (left or right) and the word “bosa” is determined by the     based on a learner’s eye movements. In this example, some
  overall duration of fixations on that particular object.               strong associations are correct (e.g., the word manu with the
                                                                     1026

object manu) and others are not (e.g., the word colat with                           random and, as shown here in infants, is guided by what
the object regli). Two measurements are used to evaluate                             they already know. This means that statistical learning will
whether the associative model based on eye movements can                             dynamically build on itself with each co-occurrence
predict individual differences in statistical learning. First,                       attended to influencing the probability (if it should occur
we correlate the prediction of the number of learned words                           again) that it will be attended to again. This kind of a system
from the model with the number of learned words for each                             may both protect old learning and smartly direct attention to
                                                                                     nonspurious co-occurrences. This first step of statistical
                                                                                     learning from ambiguous contexts can play an important
                                                                                     role in the following learning by selecting the right
                                                                                     information and filter irrelevant data.          However, not
                             6
                                                                                     attending to the right co-occurrences could – at least
  results of human infants
                             5                                                       temporarily – distort learning, sending it down the wrong
                                                                                     path.
                             4
                                                                                           The second component of statistical learning is the
                             3                                                       learning mechanism itself. What kind of “computation” is
                                                                                     used to evaluate the accrued data? The learning mechanism
                             2
                                                                                     – as demonstrated here – could be as simple as associative
                             1                                                       learning that memorizes and keeps track of word-referent
                             0
                                                                                     co-occurrences, or it could be as complicated as Bayesian
                                 0       1      2      3      4       5      6
                                                                                     graphical models using probabilistic inferences (Tenebaum
                                     predicted results of the associative model
                                                                                     & Xu, 2000). Moreover, the representation of learning
                                                                                     results can be as straightforward as an association matrix or
                                                                                     as complicated as relational hierarchical structures.
Figure 4: the comparison of predicted results from the                                       The present results suggest that infant cross-trial
associative model and the actual results of human                                    learning of word-referent correspondences can be explained
learners indicates a strong correlation between these two.                           by a simple learning mechanism coupled to selective
individual learner. There is a strong correlation between                            attention. This contrasts with the more common approach to
these two (p=0.71). Second, we also found the correlation                            statistical learning which assumes sophisticated and
between the proportion of diagonal cells (the strength of                            powerful learning algorithms operating on messy data and
correct word-referent associations) in an association matrix                         most often running in a batch mode (e.g. Tenenbaum, etc.).
with the proportion of looking time (the degree of the                               Although these two accounts may be formally treated as
preference to look) at the correct referents during testing                          variants of the same learning framework (Yu, Smith, Klein,
(p=0.65). Figure 4 shows the correlation between the                                 & Shiffrin, 2007), a closer look also reveals the differences
model’s prediction and the results from the empirical study.                         between two. An associative learning mechanism with real-
The four example association matrices built based on young                           time attention treats the learning process as a dynamical
learners’ eye movements are quite different. Most diagonal                           system and focuses on how the learning system may
items (correct word-referent associations) in the top                                actively select the input based on real-time feedbacks from
association matrix are highlighted while the association                             the current learning states and by doing so remove a
probabilities between words and referents are more                                   significant amount of uncertainty from the data to facilitate
distributed in the bottom matrix. Critically, those matrices                         the following processing. In contrast, the batch mode
are built based on the same associative learning mechanism                           learning most often assumes that the learners perceive
but with different eye movement data generated by subjects                           unprocessed ambiguous data to start with and then rely on
in real-time training. Thus, individual differences in this                          the powerful learning machinery to infer meaningful
statistical learning task may be due to what infants attend to                       knowledge. The first approach offers a potentially deeper
moment by moment while they all apply the same learning                              and useful understanding of how learning progresses, how
strategy.                                                                            to promote, and how and why some learners are more
                                                    General Discussion               effective than others.
                                                                                       In the long run, we need models and theories of learning
For any learning mechanism to acquire knowledge from
                                                                                     that explain both information selection (as it dynamically
multiples instances separated in time, it needs to possess at
                                                                                     happens in real-time learning) and also the learning
least the following two components.
                                                                                     mechanism itself. The present work is built upon the recent
  The first is information selection. The mechanism needs
                                                                                     work in statistical word learning (Smith & Yu, 2008).
to accumulate data over multiple learning experiences. One
                                                                                     Nonetheless, we go beyond demonstrating behavorial results
option is to store nonselectively. If a learner did this, even
                                                                                     and instead provide new insights into the underlying
if the learner randomly sampled the available co-
                                                                                     learning mechanisms. We do this by studying infants’
occurrences, they would in the long run converge on an
                                                                                     attention during the course of learning, attention that is itself
accurate representation of the regularities in the world.
                                                                                     guided by learning. To achieve this goal, the current work
However, human learners’ attention is unlikely to be
                                                                                  1027

is motivated by and takes advantage of three recent                 Keil, F. C. (1989). Concepts, kinds, and cognitive
advances in cognitive science and psychology: (1)                     development. Cambridge, MA: MIT Press.
developmental psychology: using eye tracking techniques to          Landauer, T.K., & Dumais, ST. (1997). A solution to Plato's
measure moment-by-moment eye movement data from                       problem: The latent semantic analysis theory of the
infants (Aslin & McMurray, 2006); (2) psycholinguistics:              acquisition, induction, and representation of knowledge.
measuring the synchrony between visual attention and                  Psychological Review, 104, 211-140.
speech -- what are visually attended and what are heard             Li, P., Burgess C., Lund, K. (2000). The acquisition of word
(Tenanhaus, et al., 1999); and (3) computer science:                  meaning through global lexical co-occurrences. In
modeling the learning mechanisms using computational                  Proceeding of Thirtieth Stanford Child Language
techniques (Yu, Ballard, & Aslin, 2005). The work                     Research Forum, pp. 167-178.
represents the first attempts to use momentary eye                  Markman, E. (1990). Constraints children place on word
movement data as input to a computational model and by                meanings. Cognitive Science, 14(1), 57-77.
doing so to understand word learning processes. Indeed, our         Mintz, T. H., Newport, E. L., & Bever, T. G. (2002). The
present results already suggest two important aspects in              distributional structure of grammatical categories in
cross-situational learning. First, the results show that a            speech to young children. Cognitive Science, 26, 393-424.
simple associative learning mechanism can indeed work               Monaghan, P., Chater, N. & Christiansen, M.H. (2005). The
effectively and efficiently if the learner selectively registers      differential role of phonological and distributional cues in
the right statistical information at every moment. Second,            grammatical categorization. Cognition, 96, 143-182.
different results from different learners may simply due to         Newport, E. L., & Aslin, R. N. (2004). Learning at a
the fact that they attend to and select different statistical         distance: I. statistical learning of non-adjacent
information encoded in the same training trials. Both                 dependencies. Cognitive Psychology, 48,127-162.
observations are critical to understanding statistical learning     Saffran, J., Aslin, R., & Newport, E. (1996). Statistical
processes. Here we show that eye movements can be used a              learning by 8-month old infants. Science, 274, 1926-1928.
window to infer the statistical learner’s internal state, which     Siskind, J.M. (1996). A computational study of cross-
allows us to ask in the future work how selective attention           situational techniques for learning word-to-meaning
works in real-time learning. More specially, a generative             mappings. Cognition, 61, 39-61.
dynamic model of selection attention can be integrated with         Smith, L., & Yu, C. (2008). Infants rapidly learn word-
the associative learning model here to provide a more                 referent mappings via cross-situational statistics.
complete picture of the underlying mechanisms.                        Cognition, 106(3), pp 1558-1568.
Acknowledgments: We thank Juliette McNamara, Amara                  Solan Z., Horn H., Ruppin E., and Edelman S. (2002).
Stuehling, and Char Wozniak for collection of the data. This          Unsupervised learning of natural languages. Proceedings
research was supported by National Institutes of Health R01           of National Academic of Science, 102,11629-11634.
HD056029 and National Science Foundation Grant                      Steyvers, M. and J. B. Tenenbaum (2005). The Large-Scale
BCS0544995.                                                           Structure of Semantic Networks: Statistical Analyses and
                                                                      a Model of Semantic Growth. Cognitive Science, 29(1),
                                                                      41-78.
                          References
                                                                    Tanenhaus, M. K., Spivey-Knowlton, M., Eberhard, K., &
Aslin, R. N., & McMurray, B. (2004). Automated corneal-               Sedivy, J. (1995). Integration of visual and linguistic
   reflection eye tracking in infancy: Methodological                 information in spoken language comprehension. Science,
   developments and applications to cognition. Infancy, 6(2),         268, 1632-1634.
   155-163.                                                         Tenenbaum, J., & Xu, F. (2000). Word learning as Bayesian
Chater, N. and Manning, C.D. (2006) Probabilistic models              inference. In L. Gleitman & A. Joshi (Eds.), Proceeding
   of language processing and acquisition. Trends in                  22nd annual conference of cognitive science society (p.
   Cognitive Science, 10(7), 335-344.                                 517-522). Mahwah.NJ: ErIBaum.
Christiansen, M., Allen, J., & Seidenberg, M. (1998).               Yu, C., Ballard, D.H., & Aslin, R.N. (2005). The role of
   Learning to segment speech using multiple cues: A                  embodied intention in early lexical acquisition. Cognitive
   connectionist model. Language and Cognitive Processes,             Science, 29 (6), 961–1005.
   13, 221-268.                                                     Yu, C., & Smith, L. B. (2007). Rapid word learning under
Gomez, R. L., & Gerken, L. A. (1999). Artificial grammar              uncertainty via cross-situational statistics. Psychological
   learning by. one-year-olds leads to specific and abstract          Science, 18(5), 414-420.
   knowledge. Cognition, 70,. 109–135                               Yu, C., Smith, L. B., Klein, K., Shiffrin, R.M. (2007).
Fiser, J., & Aslin, R.N. (2001). Unsupervised statistical             Hypothesis Testing and Associative Learning in Cross-
   learning of higher-order spatial structures from visual            Situational Word Learning: Are They One and the Same?
   scenes. Psychological Science, 12, 499-504                         In McNamara & Trafton (Eds.), Proceeding 29nd annual
Kirkham, N. Z., Slemmer, J. A., & Johnson, S. P. (2002).              conference of cognitive science society (p 737-742).
   Visual statistical learning in infancy: Evidence for a             Mahwah.NJ: ErIBaum.
   domain general learning Mechanism. Cognition, 83, B35-
   B42.
                                                                1028

