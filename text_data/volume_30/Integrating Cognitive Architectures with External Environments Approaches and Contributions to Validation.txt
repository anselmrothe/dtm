UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Integrating Cognitive Architectures with External Environments: Approaches and
Contributions to Validation
Permalink
https://escholarship.org/uc/item/7nh2g1hm
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Gunzelman, Glenn
Pope, Art
Wray, Robert
et al.
Publication Date
2008-01-01
Peer reviewed
  eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                 Integrating Cognitive Architectures with External Environments:
                                Approaches and Contributions to Validation
                     Glenn Gunzelmann                                           Robert Wray (wray@soartech.com)
         (glenn.gunzelmann@mesa.afmc.af.mil)                                              Soar Technology, Inc.
                 Air Force Research Laboratory                            3600 Green Road Suite 600, Ann Arbor, MI 48105
             6030 South Kent St., Mesa, AZ 85212
                                                                              Bradley J. Best (bjbest@adcogsys.com)
              Art Pope (apope@setcorp.com)                                          Adaptive Cognitive Systems, LLC
                         SET Corporation                                   1942 Broadway St, Suite 305, Boulder, CO 80302
         1005 North Glebe Rd., Arlington, VA 22201
                                                                         J. Gregory Trafton (trafton@itd.nrl.navy.mil)
                                                                                        Naval Research Laboratory
                                                                           4555 Overlook Ave., SW, Washington, DC 20375
   Keywords: Computational Model; Virtual Environment;                          Moderator: Glenn Gunzelmann
   Interaction; Validation.                                          Potential applications of computational cognitive models
                                                                     include acting as synthetic teammates or adversaries in
                         Introduction                                virtual environments and training simulations, as well as
The history of cognitive architectures and computational             serving as intelligent tutors in such environments to provide
modeling is rooted in the kinds of tasks and environments            time-sensitive, individualized feedback and support to
that are typical of experimental psychology. For the last 10         individuals as they acquire new skills and knowledge. In all
years or more, cognitive models have been able to interact           these roles, computational models need the ability to reason
directly with small-scale tasks of this sort with relative ease.     in humanlike ways about the tasks that are being performed.
In contrast, enabling computational models to interact in            In complex real and virtual environments, this entails the
more complex environments requires more substantial                  ability to represent and process visuospatial information in a
effort. Models that have been developed successfully to              psychologically valid manner. This capability requires an
operate in such environments have demonstrated the                   infrastructure that provides models with information about
potential for computational cognitive models to provide              the environment in a form that is appropriate for human-
detailed explanations of human behavior in naturalistic              level encoding and reasoning about the visuospatial aspects
tasks. To further extend the theoretical breadth and                 of the space. In addition, models must be able to generate
cognitive plausibility of computational cognitive                    actions within the task environment in the same way as
architectures, however, they need to be able to interact             humans, so that those actions are appropriately constrained
easily with a wide variety of external environments, both            as well.
real and simulated. This capability would enable a wider               Ideally, this infrastructure would be a seamless and nearly
variety of testing of existing architectures, but would also         invisible part of the modeling activity. Unfortunately, virtual
allow a different class of problems to be explored.                  simulation environments are designed to maximize
   All of the panelists in this symposium have experience            processor efficiency rather than to facilitate integration with
with developing computational models and linking them to             cognitive architectures and models. This presents a
an external environment. They relate some of the issues              challenge – even a barrier – to cognitive modelers interested
involved in such efforts, and also discuss their approaches          in developing models that interact in such environments.
for developing a general infrastructure for integrating
computational models with complex real and virtual                                             Art Pope
environments. Tools providing this capability would greatly          We describe a framework for linking cognitive models with
decrease the time and effort required to develop models that         virtual environment simulations of the sort that are typically
interact within a variety of virtual and robotic environments.       used in military training applications. The framework, called
They would reduce the need to focus on the technical issues          Castle, is designed to accommodate a variety of different
of how to manage the interaction of the model within the             cognitive models and simulations. It supplies a cognitive
virtual environment, thereby allowing modelers to                    model with sensory information obtained from a simulation,
concentrate their efforts on understanding and integrating           and enacts cognitive model motor and other commands in
the cognitive mechanisms underlying human performance.               the simulation, while imposing human-like limitations on
Finally, these efforts promise to facilitate validation efforts      sensory information processing and control.
as well, by providing more naturalistic and realistic contexts         The framework is based on a formal analysis of
for demonstrating the capabilities of the models.                    requirements, including surveys of candidate simulations,
                                                                     cognitive architectures, and human performance data. It
                                                                     includes its own graphics and physics engines so that, where
                                                                     necessary, it can supplement an attached simulation in order
                                                                 913

to present cognitive models with complete and consistent           capabilities to interact in even a minimal way, and thus
phenomena. It is based on portable software and distributed        augmentation of spatial processing must also be addressed.
processing middleware, allowing the framework to operate              Our middleware design involves four key components: 1)
on and be accessed from many common computing                      a processing layer that abstracts the spatial layout of an
platforms and languages. Lastly, it includes logging,              entity's surroundings in a general VE agnostic way, 2) a
replication and monitoring mechanisms to facilitate                processing layer that constrains the information available by
experimentation.                                                   considering the limitations of human cognition, 3) a method
                                                                   for mapping entities in various VEs onto a common
                       Robert Wray                                 ontology, and 4) a spatial reasoning module to enable
   We are currently exploring how to standardize and               cognitive architectures without such capacities to function in
simplify the functional perception problem in virtual              spatial environments. The goal of developing this interface
environments. Because a virtual environment (VE) must              is to advance research exploring interactions of cognitive
already unambiguously identify individual objects and their        models with VEs. In addition, this interface will also be
positions in space, many challenges for realizing a                useful for applied research that requires embedding agents
complete, functional model of visual perception can be             based on cognitive architectures within VEs.
ignored or abstracted. Instead, representations of the
ground-truth visual scene can be provided to models,                                   J. Gregory Trafton
transformed and/or annotated in a manner consistent with           Most computational cognitive architectures are extremely
neuroscience and psychology.                                       limited in what they can “see” and “hear.” We have been
   We have prototyped a VE-model interface that defines 1)         working on creating a fully embodied agent that can see,
a standard, common scene format, which unifies the similar         hear, and communicate with others in a cognitively
but distinct data representations used to render visual scenes     plausible manner. Specifically, we have connected ACT-R’s
in virtual environments and 2) transformations of the              visual and auditory modules to a set of state-of-the-art
common format for flexible, psychologically-realistic input        vision and auditory AI systems. Our full system, ACT-R/E
at three different levels of precision. The interface includes     (ACT-R/Embodied) allows us to see and hear objects and
functions to support visual imagery and spatial reasoning as       actions in the external world as well as move around in the
well as visual perception. It builds on existing middleware        environment       using    cognitively    plausible      spatial
that simplifies syntactic integration of simulation and model
                                                                   representations. Allowing ACT-R/E to see and act upon the
components and directly supports the modeling process via
                                                                   world allows us to bring cognitive plausibility to a wide
logging, playback, and situation reconstruction.
   The existing prototype is being evaluated with a Soar-          range of interactive, communicative, and environmental
based model. However, the interface and supporting tools           tasks and situations.
are designed to support a range of models and modeling                Connecting ACT-R to the environment through sensors
architectures                                                      has not been a trivial job. First, many of the AI sensor
                                                                   systems are not perfect (though they are quite good). The
                                                                   imperfections in the sensor systems can lead to problems in
                      Bradley J. Best                              the modeling itself (e.g., if a sound or object is perceived
Development of a general purpose software interface                but not actually there). Second, the three dimensional world
between cognitive models and 3D virtual environments               provides a different set of problems than a simple 2D world.
(VEs) requires innovation in theoretically grounded                Third, how important is cognitive plausibility at the
cognitive abstractions and interfaces, as well as a thoughtful     perceptual or action level (i.e., how long it takes for the AI
application of software architecture and engineering               systems to execute)? In order to solve some of these issues,
principles. We are working to embed these cognitive                we use multiple simulators at different levels of fidelity.
abstractions in a middleware layer that offers "plug-and-             Our approach allows advantages from many different
play" operation for arbitrary pairings of cognitive                perspectives. From a cognitive science point of view, we
architectures and simulation environments, while supporting        can explore issues of embodiment, representation, and
potential future extensions to robotic environments. This          modeling. From a robotics point of view, we are able to
requires identifying the common ground between cognitive           facilitate interaction between people and robots because our
models and virtual environments both in terms of spatial           ACT-R/E system uses similar representations, strategies,
representations and in terms of supported spatial processing       and knowledge that people do. From an AI point of view,
within the cognitive architectures. In some cases, however,        we are striving toward building a robotic system with
cognitive architectures may lack sufficient processing             human-level intelligence.
                                                               914

