UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Motion Language Shapes People's Interpretation of Unrelated Ambiguous Figures

Permalink
https://escholarship.org/uc/item/9986c6c0

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)

Authors
Dils, Alexia Toskos
Boroditsky, Lera

Publication Date
2008-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Motion Language Shapes People’s Interpretation of Unrelated Ambiguous Figures
Alexia Toskos Dils (atoskos@psych.stanford.edu)
Department of Psychology, 450 Serra Mall, Bldg. 420
Stanford, CA 94041 USA

Lera Boroditsky (lera@psych.stanford.edu)
Department of Psychology, 450 Serra Mall, Bldg. 420
Stanford, CA 94041 USA
stationary stimulus will appear to drift downward (in the
direction opposite of adaptation). This same phenomenon
has been observed when subjects simply imagine motion in
one direction and are then tested on a real motion stimulus
(Winawer et al., 2005). Viewing still images that imply
motion (e.g., photos of sprinters in mid leap) also produces
such adaptation (Winawer, Huk, & Boroditsky, in press).
These results demonstrate that imagining motion activates
(and adapts) the very same direction-selective neurons as
are involved in normal motion perception.
In this paper we ask whether the representations derived
in the course of normal language processing also interact
with perceptual processing. When people hear a story that
describes motion, do they naturally form the same kinds of
representations as when asked to vividly imagine motion or
when simply inferring motion from a frozen-motion
photograph? In our study, people read a story that described
motion either upward or downward and then were asked to
interpret an unrelated ambiguous image. The figure (shown
in Figure 1) could be seen as a bird flying upward or
downward (the participants were simply asked to “draw a
worm in the bird’s beak”). Would reading a story
describing motion upward, for example, bias the way people
interpreted an unrelated ambiguous figure? And if so,
which way would the influence go?
Some researchers have suggested that language
processing involves simulating the visual scenes being
described (Barsalou, 1999; Bergen, Lindsay, Matlock, &
Narayanan, 2007; Gallese & Lakoff, 2005; Glenberg &
Kaschak, 2002; Matlock, Ramscar, & Boroditsky, 2005;
Richardson, Spivey, Barsalou, & McRae, 2003; Zwaan,
Madden, Yaxley, & Aveyard, 2004). The simulations on
this proposal re-enact the same neural patterns of firing
that would occur if the visual scene being described were
actually being perceived. On a very radical version of this
proposal, hearing a story about downward motion would
activate the same neurons in visual cortex as are involved
in seeing downward motion. In this case, downwardselective neurons in the motion-sensitive area MT, for
example, would be activated when reading about a
mudslide or a waterfall. On less radical versions of this
proposal, processing language might only partially reenact perceptual representations, or re-enact them at a
higher more abstract level of processing not necessarily
involving low-level visual processing areas.
An
alternative view is that representations created in the

Abstract
When we hear a story that describes motion, do we naturally
imagine the motion described? To what extent do the mental
images generated through language share processing
resources with perception? In our studies, people read a story
describing upward or downward motion and were later asked
to interpret an unrelated ambiguous figure. The figure could
have been seen as a bird flying upward or downward, and the
participants were simply asked to “draw a worm in the bird’s
beak”. People’s interpretations of the ambiguous figure
revealed a congruity effect when the stories depicted visual
motion of a real world object. Those who had read a story
describing upward motion were more likely to interpret the
ambiguous image as a bird flying up than those who read a
story describing downward motion. However, there was no
effect when the stories depicted metaphorical motion. These
findings suggest that more concrete linguistic descriptions of
motion do generate representations or mental states that
interact with perception. Further these studies provide hints
about the level at which representations generated by normal
language processing interact with perceptual processing.
Keywords: Embodiment; Simulation; Imagery; Language;
Perception; Motion

Introduction
Humans are able to quickly and easily translate between
visual and verbal representations. We can verbally describe
visual scenes, and we can construct mental or physical
images from linguistic descriptions. In this paper we are
interested in the extent to which the representations derived
in the course of normal language comprehension interact
with perceptual processes.
Previous research has demonstrated remarkable overlap
between the representations and processes that underlie
mental imagery and those used in the service of perception
itself. For example, imagining motion or inferring motion
implied in frozen motion photographs activates the same
motion sensitive regions of the brain (e.g., the visual area
MT) as actually perceiving motion (Goebel et al., 1998;
Kourtzi & Kanwisher, 2000). Further, imagining motion is
sufficient to produce a motion after-effect or waterfall
illusion (Winawer, Witthoft, Huk, & Boroditsky, 2005).
The motion after-effect (MAE) is the result of adaptation in
motion-sensitive direction-selective neurons in the brain.
Viewing motion upward, for example, serves to adapt
upward-selective neurons in MT, temporarily depressing
their firing rate. Following adaptation to upward motion, a

793

Language comprehension has not only been shown to
elicit what appears to be active perception in the absence
of any perceptual stimulus, but it has also been shown to
affect processing of perceptual stimuli that bear some
resemblance (either in gross structure or specific content)
to the described scene (e.g., Bergen et al., 2007;
Richardson et al., 2003; Meteyard, Bahrami, and
Vigliocco, 2007; Zwaan et al., 2004).
Listening to sentences appears to bring perceptual
mechanisms online to the extent that they can affect
concurrent perceptual processing. Does in-the-moment
perceptual
imagery
triggered
during
language
comprehension have lasting perceptual consequences?
Might these consequences, for example, affect perception
in subsequent tasks and on unrelated visual stimuli? And
if so, in what direction? Previous work makes two
opposite predictions.
One documented phenomenon regarding visual motion
is direction-specific priming (Pantle, Gallogly, & Piehler,
2000). Viewing apparent motion in one direction biases
participants to perceive a subsequent, ambiguously moving
stimulus as moving in that same direction. Moreover,
Bernstein and Cooper (1997) demonstrated that ambiguous
images that appear to move in a particular direction are
more likely to be disambiguated in a way that makes them
face the direction of motion. These results predict that an
ambiguous perceptual stimulus presented just after reading
a description of motion in a single direction might appear
to move and/or face that same direction.
Research on the motion after-effect on the other hand
might make the opposite prediction. Adapting to visual
motion in one direction causes an after-effect, such that a
stationary stimulus viewed following adaptation is seen as
moving in the opposite direction of the adapting motion.
Adapting to motion upward for example, will make a
subsequent stationary stimulus appear to drift downward.
This kind of motion adaptation has been found not only for
real and apparent motion, but also for implied and
imagined motion (Winawer et al., in press; Winawer et al.,
2005). If imagined motion can produce a motion aftereffect, then it is possible that increasingly abstract forms of
processing also have this capability.
If processing
linguistic descriptions of motion in a particular direction
creates the kind of mental images that produce a motion
after-effect, then perhaps reading about motion upward
would cause people to see the ambiguous figure as moving
downward.
Experiment 1 is designed to examine whether perceptual
phenomena, such as priming or adaptation, that result from
watching prolonged motion in a single direction also
emerge while understanding stories depicting literal
motion. Participants are first given a story to read,
followed by a perceptual task to perform. The story is
written from the perspective of the participant, and in it the
participant watches an elevator move either upward or
downward. The subsequent perceptual task requires
participants to visually interpret an ambiguous,

process of normal language comprehension do not
necessarily share processing with or interact with
perceptual states (Anderson, 1978; Fodor & Pylyshyn,
1988).
If mental images generated during normal language
comprehension share very low-level properties with
perception, then processing language about motion might
induce low-level visual phenomena such as visual motion
adaptation or the motion after-effect. If this is the case,
participants who read a story about downward motion may
become more likely to see the ambiguous image as moving
in the direction opposite of adaptation. Another possibility
is that mental images generated through language interact
with perceptual processing, but at a higher more abstract
level. If this is the case we may expect motion language to
bias people’s performance in perceptual tasks, but not
necessarily through low-level mechanisms like motion
adaptation.
The third possibility is of course that
processing motion language does not generate mental
images or at least not the sort that interact with or
influence perceptual processes.
The experiments
presented in this paper were designed to explore these
three possibilities.

Previous Evidence:
Previous research has suggested that people spontaneously
and non-consciously create mental images in everyday
interactions, and that these images share some of the same
properties as when people are explicitly asked to imagine
(Barsalou, 1999; Bergen et al., 2007; Gallese & Lakoff,
2005; Glenberg & Kaschak, 2002; Matlock et al., 2005;
Richardson et al., 2003; Zwaan et al, 2004). Language is
one domain in which mental imagery seems particularly
useful. People often talk about objects and events that are
not in the immediate environment, so having a mechanism
that enables perceptual simulation in the absence of any
sensory stimulus might help to increase the salience of
sparsely represented features or provide additional cues to
memory.
One line of evidence suggesting that people perceptually
simulate linguistic input comes from people’s spontaneous
eye movements during both language processing and
imagery. When imagining scenes or listening to stories
describing visual scenes, people spontaneously move their
eyes in ways that would be consistent with visually
exploring that kind of scene (Spivey & Geng, 2001; Spivey,
Tyler, Richardson, & Young, 2000). For example, when
hearing stories about canyons or skyscrapers people make
vertical eye-movements even in the absence of any visual
stimulus (Spivey & Geng, 2001). The same consistent
patterns of visual exploration have been found when people
are processing fictive motion language (e.g., the fence runs
through the field) where there is no literal motion
(Richardson & Matlock, 2007). Processing spatial meaning,
whether concrete or abstract, appears to recruit low-level
mechanisms of perceptual exploration.

794

Subjects were instructed: ‘Please read the following
paragraph:’ The paragraphs used are shown in Table 1.

monochromatic image of a bird (Tinbergen, 1951). The
figure can be seen as a goose flying in one direction or as a
hawk flying in the opposite direction. The bird in our
study is oriented vertically on the page so that one
interpretation of the image yields an upward-facing bird,
and the other interpretation of the image yields a
downward facing bird. The story participants read prior to
making the perceptual interpretation makes no mention of
any type of bird, but it does describe either upward or
downward motion. The question is whether reading a
story describing directional motion will increase the
likelihood of one perceptual interpretation versus another.
There are three ways in which reading a story about
motion could affect which direction the ambiguous bird
appears to face. One possibility is that language
processing will have no effect on perception. We might
expect such a null effect if language processing in this
case does not successfully evoke imagery, or if imagery
has no effect on orthogonal and/or non-concurrent
spatial tasks. Another possibility is that processing a
verbal description of motion will lead to a congruency
effect in the perceptual task. That is, the direction in
which the ambiguous image appears to face will match
the direction of motion described in the story. Such a
result might be obtained if higher-level perceptual
representations created by the story exert top-down
influence on the perceptual task (although there are
possible low-level mechanisms, such as sustained subthreshold activation of visual-motion areas from
language comprehension during the perceptual task).
The third possibility is that processing a verbal
description of motion will lead to an incongruency
effect in the perceptual task. That is, the direction in
which the ambiguous image appears to face will
mismatch the direction of motion in the story. Such a
result might be obtained if participants adapt to the
direction of motion depicted in the story, causing the
bird image to appear to move in the opposite direction.
The study was designed to establish whether and how
processing a verbal description of motion will affect the
visual interpretation of an unrelated stimulus.
The
direction of the effect will help inform our understanding
of which perceptual mechanisms, if any, might be
recruited during language comprehension.

Table 1: Stories read by participants in Experiment 1.
Upward Story
You are standing on the 29th floor of an artsy 57-story
building looking into a beautiful atrium. You notice a group
of third-grade children beginning a treasure hunt on the first
floor. They pile into the giant glass elevator across from you
with the first clue in hand. You watch as they solve the first
clue which sends them to the 9th floor for the next one. From
there, they have to rush to the 20th floor. From the 20th floor,
they follow the clue to the 29th floor. They solve the clue on
the 29th floor and then have to hurry to the 38th floor. From
the 38th floor, the clue sends them to the 49th floor. The final
clue sends them from the 49th floor all the way to the 57th
floor, where they excitedly collect their prize!
Downward Story
You are standing on the 29th floor of an artsy 57-story
building looking into a beautiful atrium. You notice a group
of third-grade children beginning a treasure hunt on the first
floor. They pile into the giant glass elevator across from you
with the first clue in hand. You watch as they solve the first
clue which sends them to the 49th floor for the next one.
From there, they have to rush to the 38th floor. From the 38th
floor, they follow the clue to the 29th floor. They solve the
clue on the 29th floor and then have to hurry to the 20th floor.
From the 20th floor, the clue sends them to the 9th floor. The
final clue sends them from the 9th floor all the way to the first
floor, where they excitedly collect their prize!

One story described upward motion while the other story
described downward motion. Each subject read only one
story. Both stories were written in the second person (i.e.
from the perspective of the observer). In both stories, the
participant was anchored at the middle floor of a tall
building where he or she watched an elevator move. In the
first story, the elevator started at the bottom of the building
and moved all the way to the top, passing the participant
along the way. In the second story, the elevator started at
the top of the building and moved all the way to the bottom,
passing the participant along the way. In both stories, the
elevator’s trajectory was depicted via changing floor
numbers only. As a result, neither directional prepositions
nor directional verbs were necessary to establish upward or
downward motion. Rather, the directionality of the story
emerged at the sentence level.
Both stories were followed by the same comprehension
question: ‘Do the children collect any prizes before the final
floor? YES NO’. This question was included to test for
basic story comprehension to make sure participants read
the story. Participants who incorrectly circled ‘no’ were
excluded from subsequent analyses.
On a separate page, participants saw an ambiguous figure,
centered on the page. The image could either be interpreted
as a hawk facing one direction or a goose facing the

Experiment 1: Literal Motion
Method
Participants
Four hundred and sixty-five undergraduate students from
Stanford University and University of California Merced
participated in the study for course credit.
Materials
Participants completed the task on paper as part of a large
questionnaire packet that contained many unrelated tasks.

795

That is, reading a story describing downward motion might
bias participants to see a downward facing bird. Another
possibility discussed was that language might have an
adaptation effect on perception. That is, reading a story
describing downward motion might adapt participants to
downward motion, hence biasing them to see an upward
facing bird. The results show a congruity effect and support
the “perceptual priming” prediction. Participants were
reliably more likely to perceive a bird to be facing the same
direction as the story they had just read.
One possible explanation for the bias in people’s
perceptual interpretation is that rising and falling numbers in
the stories are themselves capable of generating abstract
notions of “UP” or “DOWN”. Thus the priming effect
found in Experiment 1 might result without any description
of concrete motion in the stories. To better understand the
contributions of motion language and number, Experiment 2
tests increasingly abstract descriptions of motion while
keeping constant the rising and falling numbers in the
stories. Is number alone capable of interacting with
perception, or is some degree of linguistic motion required?
The extent to which linguistic descriptions need be
concrete in order to bias perception is another question left
unaddressed by Experiment 1. Participants brought with
them considerable visual experience with the movement of
the objects depicted by the stories. Perhaps our ability to
generate simulations of the type that prime perception is
limited to domains that we have direct sensory experience
with. Or perhaps even abstract domains evoke such
simulations. The linguistic descriptions in Experiment 2
describe the upward or downward movement of stock prices
– a domain which people have no visual experience with.
Hence, Experiment 2 is suited to test both whether linguistic
motion is sufficient and whether literal linguistic motion is
necessary for forming mental states that prime perception.

opposite direction. The figure was positioned vertically on
the page such that one could interpret it as a bird flying
either upward or downward. Whether the goose or the hawk
pointed upward was counterbalanced across participants and
across story types.

Figure 1: Ambiguous goose/hawk images.
Below the image of the bird were the instructions: ‘Please
draw a worm in the bird’s beak.’ This was done to avoid
explicitly asking subjects about their interpretation of the
ambiguous figure and to not draw attention to the
ambiguity. Participants who drew the worm at the top of
the image were coded as having made an ‘upward’
interpretation of the image, and participants who drew the
worm at the bottom of the image were coded as having
made a ‘downward’ interpretation of the image.

Results
87 participants either omitted or incorrectly answered the
comprehension question and were excluded from all
analyses. Of those remaining, 22 participants noticed that
the bird image had two possible interpretations (i.e. drew
worms in both beaks) and were also excluded.
Overall, participants were equally likely to interpret the
image as a goose or a hawk. Slightly more participants
(52%) made the goose interpretation than the hawk
interpretation (48%), but this difference was not reliable,
χ2(1,N = 356) = .55, p > .45. This manipulation check
confirms that the goose/hawk image is truly ambiguous.
There was an overall bias for participants to see a
downward facing bird (57%) rather than an upward facing
bird (43%), χ2(1, N = 356) = 7.60, p < .01.
Importantly, participants’ interpretation of the ambiguous
bird image was influenced by the direction of the story they
had just read. Participants were significantly more likely to
see a bird facing in the same direction as the motion in the
story (57%) than the opposite direction (43%), χ2(1, N =
356) = 7.02, p < .01

Experiment 2: Metaphorical Motion
In experiment 2, participants first read a story that described
either upward or downward metaphorical motion. The
stories included the same rising and falling numbers as used
in the elevator stories in Table 1, but, instead of describing
physical motion, the numbers described the moving price of
a stock (either increasing from 1 to 57, or decreasing from
57 to 1). After reading the story, participants were asked to
interpret the ambiguous goose/hawk image.

Method
Participants
Three hundred and forty-eight undergraduate students from
Foothill College (Los Altos Hills, CA) and University of
California Merced participated in the study for course credit.

Discussion
Participants in this study read stories describing upward or
downward literal motion prior to disambiguating an image
of a bird that could be perceived as upward facing or
downward facing. The goal of the study was to see whether
there would be any transfer from spatial language to spatial
perception, and, if so, in which way. One possibility was
that language might have a priming effect on perception.

Materials
The procedure for Experiment 2 was identical to that in
Experiment 1. The two experiments differed in the stories
people read prior to interpreting the ambiguous figure.
While participants in the first experiment read about a rising

796

or falling elevator, participants in the second experiment
read about rising or falling stock prices. The paragraphs
used are shown in Table 2.

made the goose interpretation than the hawk interpretation
(47%), but this difference was not reliable, χ2(1, N = 282) =
1.15, p > .25, again confirming the ambiguity of the image.
There was an overall bias for participants to see a
downward facing bird (60%) rather than an upward facing
bird (40%), χ2(1, N = 282) = 10.30, p < .01.
Importantly, participants’ interpretation of the ambiguous
goose/hawk image was not influenced by the direction of
the metaphorical story they had just read. Participants were
slightly less likely to see a bird facing in the same direction
as the motion in the story (48%) than the opposite direction
(52%), but this difference was not reliable, χ2(1, N = 282) =
7.02, p >.45. The pattern of results found in Experiment 2
differs reliably from the pattern found in Experiment 1,
χ2(1, N = 638) = 5.29, p < .05.

Table 2: Stories read by participants in Experiment 2.
Upward Story
It is your company's first day on the stock market and you
are watching carefully to see what happens with the price.
The stock opens at 1 dollar a share. Before you know it, the
price goes to 9 dollars. From there the price goes to 20
dollars. From 20 dollars, the stock rushes to 29 dollars.
From 29 dollars, the stock goes to 38 dollars. From 38
dollars, the price rushes to 49 dollars. Finally, the price goes
all the way to 57 dollars.
Downward Story
It is your company's first day on the stock market and you
are watching carefully to see what happens with the price.
The stock opens at 57 dollars a share. Before you know it,
the price goes to 49 dollars. From there the price goes to 38
dollars. From 38 dollars, the stock rushes to 29 dollars.
From 29 dollars, the stock goes to 20 dollars. From 20
dollars, the price rushes to 9 dollars. Finally, the price goes
all the way to 1 dollar.

Discussion
Participants in Experiment 2 read stories describing upward
or downward metaphorical motion prior to disambiguating an
image of a bird that could be perceived as upward facing or
downward facing. One goal of the study was to see whether
there would be any transfer from metaphorical spatial
language to spatial perception, suggesting that linguistic
descriptions need not refer to physical motion in order to
interact with perception. The results show no bias in
participants’ interpretation of the ambiguous stimulus as a
function of reading about metaphorical motion in a particular
direction. This finding is consistent with previous reports of
concrete linguistic information priming perception, while
abstract linguistic information does not (Bergen et al., 2007;
Boroditsky, 2000). Furthermore, these results suggest that
increasing and decreasing numbers alone are not sufficient to
produce the perceptual bias reported in Experiment 1.

Both stories in Table 2 were followed by the same
comprehension question: ‘In the story you just read, was it
your company’s first day on the market? YES NO’.
214 participants were tested on Version 1 of the
metaphorical stories (as seen in Table 2). These stories
contained no directional verbs and were designed to closely
mirror the literal stories from Experiment 1. 78 participants
were tested on a slightly different version (Version 2) of the
metaphorical stories in which the stock prices ‘plummeted’
or ‘skyrocketed’. These stories were designed with
additional cues to the depicted motion trajectory, with the
direction of motion encoded both at the verb and sentence
levels. 54 participants were tested on a third version of the
metaphorical stories adapted from Version 2. These stories
depicted rising or falling championship ratings, in which
low ratings were positive and high ratings were negative.
Ratings in Version 3 ‘plummeted’ from 49 to 57, whereas
stock prices in Version 2 ‘skyrocketed’ from 49 to 57.
These stories were designed to de-correlate the spatial
information provided by the verbs and numbers in version 2.

General Discussion
Together, Experiments 1 and 2 suggest that reading stories
describing literal visual motion (but not metaphorical
motion) generates representations that prime perception in a
subsequent, unrelated task.
Understanding the exact
mechanisms through which this priming takes place is the
subject of future work. One possibility is that reading a
story that describes upward motion simply activates an
abstract notion of “UP” which can then bias many aspects of
unrelated visual and other behavior. However, the abstract
notion of “UP” generated by the metaphorical stories in
Experiment 2 was insufficient in biasing perception.
Another possibility is that reading about upward motion
creates more perceptual representations, and the patterns of
activation create a bias in future perceptual processing.
The apparent recruitment of lower-level perceptual
processes in Experiment 1 but not Experiment 2 suggests
that the mechanisms that govern the comprehension of
literal versus metaphorical linguistic motion might differ in
some respect. An alternative possibility is that the same
mechanisms are recruited for simulating both literal and
metaphorical motion, but the simulations themselves have
different timecourses. Richardson and Matlock (2007)

Results
37 participants in Experiment 2 either omitted or incorrectly
answered the comprehension question and were excluded
from all analyses. 29 participants noticed that the bird image
had two possible interpretations (i.e. drew worms in both
beaks) and were also excluded.
The pattern of results did not significantly differ across
the three versions of Experiment 2, χ2(1, N = 282) = .260, p
> .80, so the data from all metaphorical stories were
combined for subsequent analyses.
Participants were equally likely to interpret the bird image
as a goose or a hawk. Slightly more participants (53%)

797

Fodor, J. & Pylyshyn, Z. (1988). Connectionism and
cognitive architechture: A critical analysis. Cognition, 28,
3-71.
Gallese, V., & Lakoff, G. (2005). The brain’s concepts: The
role of the sensory-motor system in conceptual knowledge.
Cognitive Neuropsychology, 22, 455-479.
Glenberg, A. M., & Kaschak, M.P. (2002). Grounding
language in action. Psychonomic Bulletin & Review, 9,
558-565.
Goebel, R., Khorram-Sefat, D., Muckli, L., Hacker, H., &
Singer, W. (1998). The constructive nature of vision: direct
evidence from functional magnetic resonance imaging
studies of apparent motion and motion imagery. European
Journal of Neuroscience, 10(5), 1563-1573.
Kourtzi, Z., & Kanwisher, N. (2000). Activation in human
MT/MST by static images with implied motion. Journal of
Cognitive Neuroscience, 12, 48-55.
Matlock, T., Ramscar, M., & Boroditsky, L. (2005). The
experiential link between spatial and temporal language.
Cognitive Science, 29, 655-664.
Meteyard, L., Bahrami, B., & Vigliocco, G. (2007). Motion
detection and motion verbs. Psychological Science, 18,
1007-1013.
Pantle, A. J., Gallogly, D. P., & Piehler, O. C. (2000).
Direction biasing by brief apparent motion stimuli. Vision
Research, 40(15), 1979-1991.
Richardson, D.C., & Matlock, T. (2007). The integration of
figurative language and static depictions: An eye
movement study of fictive motion. Cognition, 102(1), 129138.
Richardson, D. C., Spivey, M. J., Barsalou, L. W., & McRae,
K. (2003). Spatial representations activated during realtime comprehension of verbs. Cognitive Science, 27, 767–
780.
Spivey, M., & Geng, J. (2001). Oculomotor mechanisms
activated by imagery and memory: Eye movements to
absent objects. Psychological Research, 65, 235-241.
Spivey, M.J., Tyler, M.J., Richardson, D.C., & Young, E.E.
(2000). Eye movements during comprehension of spoken
scene descriptions. Proceedings of the Twenty- second
Annual Meeting of the Cognitive Science Society (pp. 487492) Mahwah, NJ: Erlbaum.
Tinbergen, N. (1951). The study of instinct. Oxford, England:
Oxford University Press.
Winawer, J., Huk, A. C., & Boroditsky, L. (in press). A
motion aftereffect from still pictures depicting motion.
Psychological Science.
Winawer, J., Witthoft, N., Huk, A., & Boroditsky, L. (2005).
Common mechanisms for processing of perceived,
inferred, and imagined visual motion. Journal of Vision,
5(8), 491.
Zwaan, R. A., Madden, C. J., Yaxley, R. H., & Aveyard, M.
E. (2004). Moving words: dynamic representations in
language comprehension. Cognitive Science, 28, 611-619.

demonstrated that figurative language takes longer to process
than literal language. This finding suggests that the length of
the delay between reading the story and the perceptual test
might differ for the literal and metaphorical stories in the
present study. Probing at just the right time might be critical
for obtaining an effect. Probing too early might interrupt an
ongoing simulation, and probing too late might risk excessive
decay of the prime. Furthermore, the point in the languageprocessing stream at which the perceptual probe is
administered might matter for whether perceptual adaptation
or perceptual priming is found. In the present studies, this
delay was not only unsupervised, but it was also modulated
by the time participants spent answering the comprehension
question. Ongoing studies explore whether varying this delay
might yield a response profile different from that observed in
the present studies.

Conclusions
Reading descriptions of literal motion, but not metaphorical
motion, affected the way people perceived an unrelated visual
image presented immediately after processing the motion
language. Specifically, participants showed a consistent bias
to interpret an ambiguous visual image as facing in the same
direction as the motion described in an unrelated story. This
congruity effect suggests that there is overlap between the
representations and processes involved in understanding
language and in interpreting visual images. The direction of
the effect and its interaction with the concreteness of the
language helps us rule out some candidate mechanisms. It
appears that people do generate mental images of a sort in the
course of normal language processing, and the outcomes of
language processing can interact with perception. Future
research will help us understand more about the nature of
these representations and how they interact.

Acknowledgments
Many thanks to Jonathan Winawer, Caitlin Fausey, and the
rest of the Cognation Research Laboratory for helpful
discussions regarding this work. This research was funded
by an NSF CAREER grant to Lera Boroditsky.

References
Anderson, J. R. (1978). Arguments concerning
representations for mental imagery. Psychological
Review, 85, 249–277.
Barsalou, L. W. (1999). Perceptual symbol systems.
Behavioral and Brain Sciences, 22, 577-660.
Bergen, B. K., Lindsay, S., Matlock, T., & Narayanan, S.
(2007). Spatial and linguistic aspects of visual imagery in
sentence comprehension. Cognitive Science, 31, 733-764.
Bernstein, L. J., & Cooper, L. A. (1997). Direction of
motion influences perceptual identification of ambiguous
figures. Journal of Experimental Psychology: Human
Perception and Performance, 23(3), 721-737.
Boroditsky, L. (2000). Metaphoric structuring: Understanding
time through spatial metaphors. Cognition, 75, 1-28.

798

