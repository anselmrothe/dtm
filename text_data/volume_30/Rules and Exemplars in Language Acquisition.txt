UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Rules and Exemplars in Language Acquisition
Permalink
https://escholarship.org/uc/item/15s4g0jf
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Bod, Rens
Borensztajn, Gideon
Freudenthal, Daniel
et al.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                Rules and Exemplars in Language Acquisition
               Rens Bod (rens@science.uva.nl)                         Carla L. Hudson Kam (clhudson@berkeley.edu)
    Gideon Borensztajn (gideon@science.uva.nl)                          Department of Psychology, University of California,
         Institute for Logic, Language and Computation                                      Berkeley, USA
              University of Amsterdam, Netherlands
                                                                             Alexander Clark (alexc@cs.rhul.ac.uk)
                      Daniel Freudenthala                                Department of Computer Science, Royal Holloway
              (d.freudenthal@liverpool.ac.uk)                                         University of London, UK
       Julian Pinea (julian.pine@liverpool.ac.uk)
   Fernand Gobetb (fernand.gobet@brunel.ac.uk)                           Willam G. Sakas (sakas@hunter.cuny.edu)
    a
      School of Psychology, University of Liverpool, UK                  Department of Computer Science, Hunter College
      b
        School of Social Sciences, Brunel University, UK                  The Graduate Center, City University of New York
Keywords: language acquisition, computational modeling                                        Speakers
rules, exemplars
                        Goals and Scope                            Daniel Freudenthal, Julian Pine and Fernand Gobet
                                                                   Simulating Language Acquisition in MOSAIC
There are two main views about the nature of language
                                                                   Many computational models of language acquisition focus
acquisition. Broadly put, the nativist view endorses that
                                                                   on showing that it is possible to learn certain aspects of
human language acquisition is guided by abstract innate
                                                                   language that have been identified as problematic for
rules (“Universal Grammar”), while the empiricist view
                                                                   general purpose learning mechanisms. That is, many
assumes that language acquisition is the product of
                                                                   modellers focus on solving particular learnability problems.
abstractions from stored exemplars. Despite the apparent
                                                                   In this talk we focus on a different approach, implemented
opposition between these two views, the essence of the
                                                                   in MOSAIC (Model of Syntax Acquisition in Children).
debate seems to lie in the relative contribution of abstract
                                                                   Key features of this approach include: learning from
prior knowledge and concrete linguistic experience in
                                                                   realistic, child-directed speech, an emphasis on simulating
learning a language (see Pullum and Scholz 2002; Yang
                                                                   cross-linguistic data using one, identical model, and a
2004).
                                                                   commitment to simulating actual corpora of child
  One of the major goals for computational models of
                                                                   utterances. These features make it possible to analyse the
language acquisition is then to establish the minimal prior
                                                                   output from one model with respect to several, seemingly
knowledge needed for language acquisition to take place.
                                                                   unrelated phenomena and to investigate how children’s
Yet there is surprisingly little agreement on what this
                                                                   early speech is shaped by the interaction between common
minimal knowledge should be: it ranges from a simple
                                                                   processing constraints and the distributional properties of
chunking mechanism (as in Freudenthal et al. 2007) to
                                                                   the input language. This has allowed us to show that several
rather complex grammar-induction procedures (Clark and
                                                                   key phenomena in child speech and their cross-linguistic
Eyraud 2007) up to the assumption of full-fledged
                                                                   patterning can be understood in terms of the distributional
constituent structure (Bod 2008).
                                                                   statistics of the input read through an utterance-final bias in
  This symposium aims to discuss differences and
                                                                   learning without the need to represent abstract rules over
convergences across a number of representative models of
                                                                   grammatical categories.
language acquisition in the context of recent results in
                                                                      While MOSAIC’s lack of abstract knowledge allows it to
human language learning (Hudson Kam et al. 2005). In
                                                                   identify those areas of the data where abstract knowledge is
particular, we want to contribute to a better understanding of
                                                                   not required, it does limit its ability to deal with
the interplay between prior knowledge and linguistic
                                                                   constructions like long-distance dependencies. Possible
experience in modeling language acquisition. We will
                                                                   ways of representing such dependencies are explored
compare rule-like and probabilistic behavior in language
                                                                   through the notions of frames and chunking in the
acquisition models with respect to a variety of phenomena:
                                                                   substitution of distributionally similar words.
optional infinitives (Freudenthal et al.), auxiliary fronting
(Clark; Bod and Borensztajn) and alternations (Clark). We
                                                                   Carla L. Hudson Kam
will discuss how far probabilistic tendencies may lead to
categorical behavior (Hudson Kam; Bod and Borensztajn),            Whence rules?
and to what extent distributional properties of the input          When children learn language from non-native speakers, as
language can overcome the need for abstract knowledge in           in cases of the emergence of new contact languages, they
dealing with complex facets such as long-distance and              impose consistency on input which contains only
cross-serial dependencies (Freudenthal et al.; Clark; Bod          probabilistic grammatical tendencies. This rapid emergence
and Borensztajn).                                                  of consistent grammatical structure languages is often used
                                                               911

as evidence for innate knowledge of language, either rules          Rens Bod and Gideon Borensztajn
or structures of particular types, or a more general constraint     From Exemplar to Grammar
on language structures as being consistent and rule-                While rules and exemplars are usually viewed as opposites,
governed. However, this is not the only possible explanation        the data-oriented parsing (DOP) approach argues that they
for the imposition of consistency or regularization by              are end points of the same distribution. By representing both
learners. In several experiments we exposed children and            rules and exemplars as (partial) trees, DOP takes into
adults to language input containing probabilistic                   account the fluid middle ground between the two extremes.
grammatical tendencies characteristic of non-native                 This insight is the starting point for a new theory of
speakers and assessed learning using production as well as          language learning, termed U-DOP, which is based on the
judgment measures. Results from production show that                following idea: if a language learner does not know which
generally, children seem to impose consistent rules on the          phrase-structure tree should be assigned to a sentence, s/he
language. Adults, however, sometimes replicate the                  initially allows implicitly for all possible trees and lets
probabilistic grammatical tendencies, but when complex              linguistic experience which is the ‘best’ tree for each
enough, adults too will speak the language in a way that is         sentence. The best tree is obtained by computing the most
more consistent than their input. However, judgment                 probable shortest derivation from the frequencies of subtrees
measures show that both children and adults who regularize          in the set of all possible (finite) trees of previous sentences.
are sensitive to the variation present in their input, despite      Thus U-DOP’s only prior knowledge is the existence of
their productions. Thus, the rule-like nature of the                constituent structure, and lets statistics do the rest.
productions may stem from aspects of the production                     By having learned the syntactic structures of sentences,
process itself, rather than from the imposition of rule-like        we have also learned the grammar implicit in these
representations. In this, these cases may provide less              structures, which can in turn be used to produce new
evidence for the existence of a formal or structural universal      sentences. We show that our model mimicks children’s
guiding acquisition (resulting in rules) than previously            language development from item-based constructions
thought.                                                            (‘holophrases’) to abstract constructions (‘rules’), and that
                                                                    the model can simulate some of the errors made by children
Alexander Clark                                                     in producing complex questions. It turns out that U-DOP
Hierarchical and non-hierarchical models of language                can learn the abstract rules for complex syntactic
Computational and theoretical analysis of the problem of            phenomena, such as agreement and auxiliary fronting, by
language acquisition can help cognitive science by                  statistical generalization over Eve’s utterances in the
providing a clear theoretical understanding of the minimal          Childes database. Finally, we will discuss in how far U-
prior knowledge needed for language acquisition to take             DOP’s statistical tendencies result in categorical behavior in
place. This minimal prior knowledge is generally assumed            the course of language learning.
to include a bias for hierarchically structured
representations. However, the notion of hierarchical                             Commentator: Willam G. Sakas
structure is never made clear and often confuses several
distinct properties: being context free, not being regular,                                  References
using tree structures or having transformational rules that
                                                                    Bod, R. (2008). From exemplar to grammar: Integrating
are sensitive to tree structure. Here we will discuss some of
                                                                        analogy and probability in language learning. Submitted
these ideas and present two arguments that call the
                                                                        ms (http://staff.science.uva.nl/~rens/analogy.pdf).
assumption of hierarchical structure into question.
                                                                    Clark, A. & Eyraud, R. (2007). Polynomial Identification in
    Prompted by learnability considerations we have
                                                                        the Limit of Substitutable Context-free Languages,
developed provably correct algorithms for grammatical
                                                                        Journal of Machine Learning Research , 8, 1725—1745.
inference of context free languages from positive data based
                                                                    Freudenthal, D. Pine, J., Aguado-Orea, J. & Gobet, F.
on the distributional approach of Zellig Harris, which use
                                                                        (2007). Modelling the developmental patterning of
associative rather than hierarchical structure. We show that
                                                                        finiteness marking in English, Dutch, German and
such algorithms can learn from an artificial data set the
                                                                        Spanish using MOSAIC. Cognitive Science, 31, 311-
correct rule for polar interrogatives with embedded relative
                                                                        341.
clauses. We also discuss the extent to which such non-
                                                                    Hudson Kam, C., & Newport, E. (2005). Regularizing
hierarchical models are needed to overcome the limitations
                                                                        Unpredictable Variation: The Roles of Adult and Child
of constituent structure as a representational formalism. In
                                                                        Learners in Language Formation and Change. Language
particular we will examine phenomena such as free word
                                                                        Learning and Development, 1, 151-195.
order, cross-serial dependencies, bracketing paradoxes in
                                                                    Pullum, G. and Scholz B. (2002. Empirical assessment of
morphology, certain forms of ellipsis and local phonological
                                                                        stimulus poverty arguments. The Linguistic Review 19,
effects such as the a/an alternation in English, and argue that
                                                                        9-50.
such phenomena are strong evidence for the use of models
                                                                    Yang, C. (2004). Universal Grammar, statistics or both?
that don't rely on a strict idea of hierarchical structure.
                                                                        Trends in Cognitive Sciences 8(10), 451-456.
                                                                912

