UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Sequential Causal Learning in Humans and Rats
Permalink
https://escholarship.org/uc/item/3w7509wp
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Lu, Hongjing
Rojas, Randall R.
Beckers, Tom
et al.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                               Sequential Causal Learning in Humans and Rats
                                                 Hongjing Lu (hongjing@ucla.edu)
                                                    Department of Psychology, UCLA
                                            Randall R. Rojas (rrojas@stat.ucla.edu)
                               Department of Statistics, UCLA; Raytheon, Space and Airborne Systems
                                         Tom Beckers (tom.beckers@psy.kuleuven.be)
                                                  Department of Psychology, K.U.Leuven
                                                 Alan Yuille (yuille@stat.ucla.edu)
                                 Departments of Statistics, Psychology, and Computer Science, UCLA
                              Abstract                                 Glautier, 2002). However, recent experiments by Beckers et
   Recent experiments (Beckers, De Houwer, Pineño, & Miller,
                                                                       al. (2005, 2006) indicate that apparent differences between
   2005;Beckers, Miller, De Houwer, & Urushihara, 2006) have           humans and rats in the conditions that promote blocking may
   shown that pretraining with unrelated cues can dramatically         reflect different assumptions about the cue-reward
   influence the performance of humans in a causal learning            relationship, rather than any basic difference in causal
   paradigm and rats in a standard Pavlovian conditioning              learning processes between species. For both species, Beckers
   paradigm. Such pretraining can make classic phenomena (e.g.         et al. showed that different pretraining conditions using
   forward and backward blocking) disappear entirely. We explain       unrelated cues could alter the learner’s assumptions and
   these phenomena by a new Bayesian theory of sequential causal
   learning. Our theory assumes that humans and rats have              thereby prevent or promote the occurrence of classic
   available two alternative generative models for causal learning     phenomena such as forward and backward blocking (leading
   with continuous outcome variables. Using model-selection            rats to behave more like humans, and vice versa).
   methods, the theory predicts how the form of the pretraining           The goal of this paper is to provide a computational
   determines which model is selected. Detailed computer               explanation for these experimental findings based on
   simulations are in good agreement with experimental findings.       Bayesian inference. Our theory proposes that experimental
   Keywords: Bayesian inference; model selection; sequential           subjects, whether rats or humans, have available multiple
   causal learning; animal conditioning                                models of cue integration appropriate for different situations
                                                                       (Waldmann, 2007; Lucas & Griffiths, 2007). From our
                          Introduction                                 computational perspective, pretraining influences the
For more than two decades, researchers in both animal                  probability that causal learners will select a particular
conditioning and human causal learning have identified                 integration model during a subsequent learning session with
significant parallels between the phenomena observed in the            different cues, and this choice in turn determines the
two fields (see Shanks, 2004). It has even been suggested that         magnitude of blocking effects.
rats in conditioning paradigms learn to relate cues to                    Most previous statistical theories of human causal learning
outcomes in a manner similar to the way a scientist learns             have focused on learning from summarized contingency data
cause-effect relations (Rescorla, 1988). At the same time,             based on binary variables (Cheng, 1997;Griffiths &
there have been strong disagreements about the theoretical             Tenenbaum, 2005). The computational theory described here
basis for both human causal learning and animal                        instead provides a trial-by-trial model of learning from
conditioning. On the one hand, conditioning models                     sequential data. For nonverbal animals, there is no obvious
(Rescorla & Wagner, 1972) have been applied to human                   way to present summarized data; often, humans also must
causal learning (Shanks, 1985); on the other, models of                learn from sequential data. In particular, sequential models
human causal learning have been applied to animal                      are required to account for influences of the order of data
conditioning (Blaisdell, Sawa, Leising, & Waldmann,                    presentation (Danks, Griffiths, & Tenenbaum, 2003;Dayan &
2006;Cheng, 1997).                                                     Kakade, 2000;Shanks, 1985). A computational theory should
   A phenomenon that has received particular attention in              enable beliefs to be dynamically updated by integrating prior
both the human and animal literatures is the blocking effect           beliefs with new observations in a trial-by-trial manner. In
(Kamin, 1969). Suppose that two cues, A and X, are                     addition, in conditioning experiments the outcomes (e.g., food
repeatedly and consistently paired with a particular outcome           reward) are generally continuous in nature (i.e., the
 O . X will be viewed as a weaker cause of O if A alone is             magnitude of the reward may vary). A computational theory
repeatedly paired with O either before (forward blocking) or           must therefore address continuous-valued as well as binary
after (backward blocking) pairings of the AX compound with             variables in order to integrate causal learning by humans with
                                                                       learning by other animals.
 O . Some evidence has suggested that blocking is less
pronounced in humans than in rats (De Houwer, Beckers, &
                                                                   185

       Bayesian Theory of Sequential Learning                                           value of R1 and R2. By contrast, as TÆ∞ the noisy-MAX
Within our theory of causal learning, each causal model                                 function approaches the average (R1+R2)/2.
corresponds to a different probabilistic model for generating                              For both models, the hidden effects of the individual causes
the data. For continuous-valued outcomes we use a linear-                               are assumed to follow a Gaussian distribution,
sum model (Dayan & Kakade, 2000), which has been used                                    P ( Ri | ωi , xi ) ∝ exp {− ( Ri − ωi xi ) 2 (2σ h2 )}, i = 1, 2. (5)
previously to explain many aspects of the blocking effect, and
a noisy-MAX model, proposed here for the first time. The
latter is a generalization of the noisy-OR model, which gives                                                                Figure 1.               An illustration of the
a good account of human causal learning about binary                                                                         generative models. The different models
                                                                                                                             combine R1 and R2 in different ways, a
variables based on summarized contingency data (Cheng,                                                                       linear-sum or a noisy-MAX, to yield the
1997;Griffiths & Tenenbaum, 2005; Lu et al, 2007). The
                                                                                                                             output effect O .
choice of model depends on the type of pretraining, and is
determined by standard Bayesian model selection. These
expectations based on pretraining carry over to influence the                           Causal Priors
learner’s judgments in the subsequent causal learning task,                             To perform Bayesian estimation we must specify prior
even though the specific cues differ from those used in the                             distributions on the weights P(ω1 ), P(ω2 ) , which we define
pretraining.                                                                            as Gaussians with 0 mean and small variance σ 2p . This prior
   We first introduce likelihood functions for the two different                        distribution expresses the default assumption that the weight
causal models assumed by our theory. We then describe the                               of both causes is close to zero before observing any data.
priors, the resulting full models, and model selection. Finally,                           For sequential presentation in a trial-by-trial dynamic
we report simulations of experimental data and discuss how                              manner, we also assume a temporal prior for the change of
the present theory relates to others.                                                   ω1 , ω 2 over time (i.e.,trials), as in Dayan and Kakade (2000).
Causal Generative Models as Likelihood Functions                                                                             {
                                                                                                P (ω it +1 | ω it ) ∝ exp − (ω it +1 − ω it ) 2 2σ T2 , i = 1, 2}                  (6)
We focus on the relationship between two binary-valued                                     These temporal priors imply that weights may be slowly
causes x1 , x 2 (i.e. xi = 1 if cause i is present, and xi = 0                          varying from trial to trial. The amount of variation is
                                                                                        controlled by the parameter σ T2 . As σ T2 Æ 0 the weight
otherwise) and a continuous-valued outcome variable O . We
                                                                                        becomes fixed over trials, thus effectively switching off the
define two continuous-valued hidden variables R1 , R2 . The
                                                                                        temporal prior. For larger σ T2 the weights can change
hidden variables correspond to internal states that reflect the
                                                                                        significantly over trials.
magnitudes of the effect generated by each individual cause.
Each such magnitude corresponds to the weight of the
                                                                                        Combining the Likelihood and Priors
corresponding cause, ω1 , ω 2 , analogous to causal strength
                                                                                        We use the standard technique for combining likelihoods with
(Cheng, 1997). The generative model of the data, as shown in                            temporal priors for sequential data (Ho & Lee, 1964). The
Figure 1, is given by                                                                   linear-sum model can be obtained from this formulation as
                                                            2
 P (O | ω , ω , x , x ) = dR dR P (O | R , R ) P ( R | ω , x ). (1)
          1    2   1   2    ∫     1 ∫      2       1   2 ∏            i    i  i
                                                                                        the special case in which the likelihood, prior, and temporal
                                                          i =1                          priors are Gaussian.
   The first generative model is called the linear-sum model                                                                                                          r
                                                                                           To simplify the notation, we write x = ( x1 , x 2 ),
because the output O can be expressed as the sum of R1 and                               r                                                      r
                                                                                        ω = (ω1 , ω 2 ). We write {Ot } and {xt } to denote the set of
R2 plus Gaussian noise with mean 0 and variance σ m2 ,                                  rewards and causes on all trials up to and including trial t, i.e.
                                      {
           P (Oi | R1 , R2 ) ∝ exp − (O − R1 − R2 ) 2 2σ m2 .  (        )}      (2)     {Ot } = (Ot , Ot −1 ,K, O1 ) .
   The second generative model, termed the noisy-MAX                                       The Bayesian formulation for updating the estimates of the
model, is motivated by the successful noisy-OR model for                                weights is given in two stages:
causal reasoning with binary variables by humans (Cheng,                                           r                r           r     r         r          r             r
                                                                                              P (ω t +1 | {Ot },{xt }) = ∫ dω t P (ω t +1 | ω t ) P (ω t | {Ot },{xt }), (7)
1997). To adapt the noisy-OR model for continuous outcome                                                                              r r                  r              r
variables, we express it as a noisy-MAX,                                                         r                 r         P(Ot +1 | ω t +1 , x t +1 ) P(ω t +1 | {Ot },{xt }) . (8)
                                                                                             P(ω t +1 | {Ot +1},{xt +1 }) =                                    r
       P (Oi | R1 , R2 ) ∝ exp {− (O − F ( R1 , R2 ; T )) 2 (2σ m2 )}.          (3)                                                    P(Ot +1 | {Ot },{xt +1})
                                                                                                                  r t +1 r t
where the function F ( R1 , R2 ; T ) is a noisy-MAX function of                         Here we set P (ω | ω ) = P (ω1t +1 | ω1t ) P (ω2t +1 | ω2t ) assuming
                                                                                        independence in the temporal prior.
 R1 , R2 specified by:                                                                                                                                   r
                                                                                           The process is initialized by setting P (ω 0 ) to equal the prior
                                     e R1 / T                    e R2 / T               (i.e., product of Gaussians with 0 means and variances σ 2p ).
     F ( R1, R2 ; T ) = R1                        +  R 2 R1 / T
                                                                                (4)
                              e R1 / T + e R2 / T        e         + e R2 / T                                                                                                   r
                                                                                        We use Eq. 7 to predict a distribution on the weights ω 1 at
The parameter T determines the sharpness of the noisy-MAX
function. As T Æ 0, the noisy-MAX function becomes                                      time t=1 (with the convention that {O0 } and {xr0 } are empty
identical to the MAX function, i.e., equal to the maximum
                                                                                    186

sets). Then we employ Eq. 8 to make use of the observed data                    Forward/Backward Blocking
                                                                     r
on trial 1, O1 , x1 , to update the estimate of the weights, ω 1 .              Conditioning paradigms provide a window to the
   Eqs. 7-8 correspond to prediction and correction for each                    investigation of natural inferences produced by causal
trial as a recursive estimator. That is, only the estimated                     learning. Two common paradigms, schematized in Table 1,
weight distribution from the previous trial t and the current                   are forward blocking (A+, AX+) and backward blocking
cue-outcome measurement, xt +1 , Ot +1 , are needed to compute                  (AX+, A+). In both, the common finding is acquisition of a
                                                                                weaker weight between X and reward O than that between
the weight estimate for the current trial,             ωt +1 .    Thus the
                                                                                A and reward O (Kamin, 1969; Shanks, 1985). Note that
model does not need to memorize cue-outcome pairs across                        backward blocking (typically weaker than forward blocking)
all trials. If all the probabilities are Gaussian, then updating                implies that the weight of the absent cue X is updated as a
the probability distributions using Eqs. 7-8 simply                             result of a series of A+ trials. Any successful sequential
corresponds to updating the means and covariance matrices                       learning model must explain the difference of weights
using the standard Kalman filter equations (Dayan & Kakade,                     associated with different cues in both blocking paradigms.
2000). In the case of the noisy-MAX model, Eqs. 7-8 are                              Blocking          Training         Training         test
applied directly in the distribution updating.                                       paradigm          phase 1          phase 2
                                                                                     forward           8A+              8AX+             A, X
Parameter Estimation and Model Selection                                             backward          8AX+             8A+              A, X
There are two types of inference that we can make from the                      Table 1: Design summary for a typical blocking experiment. The
posterior distributions P (ωr t | {Ot },{xrt }) . First, we can perform         numerical values indicate the number of trials, + indicates the
parameter estimation to estimate the weights ωr t , i.e., the                   presence of the outcome effect.
                                                                                   Figure 2 shows simulations of learning of weight for cue A
weights of causes after t trials. Second, we can evaluate how
                                                                                ( ω A , solid) and cue X ( ω X , dashed) as a function of trial
well each model fits the data and perform model selection
(i.e., choose between the linear-sum and noisy-MAX                              number in forward blocking (black) and backward blocking
models). As discussed by Lu et al. (2007), different                            (gray) designs. Figure 2A, B shows predictions based on the
experimental paradigms can be modeled as parameter                              linear-sum and the noisy-MAX model, respectively. Both
estimation or model selection.                                                  models predict the basic phenomena, as the weight associated
   Parameter estimation involves estimating the weight                          with cue X is weaker than the weight for A in both forward
                r                                                               and backward blocking paradigms, and more so in the former.
parameters ω t . In our simulations, these estimates are the
                                                                                However, the linear-sum model predicts a larger weight
means of weights with respect to the distribution:                              difference than does the noisy-MAX model in both
                      r          r       r           r      r
                     ω t = ∫ dω t P(ω t | {Ot },{xt })ω t .             (9)     paradigms. Furthermore, for the weight associated with cue
                                                                                X, the linear-sum model predicts a weaker weight in forward
   Model selection involves determining which model is more                     blocking (dashed black) than in backward blocking (dashed
likely to account for the observed sequence of data {Ot } and                   solid), which is an asymmetry between forward/backward
{xrt } . For each model (linear-sum or noisy-MAX), we                           blocking.        The noisy-MAX model also predicts an
compute:                                                                        asymmetry, although it diminishes as the number of trials
                            r       τ −1
                                                        r                       increases. A novel prediction from the noisy-MAX in forward
                 P({Oτ } | {xτ }) = ∏ P(Ot +1 | {Ot },{xt +1}),        (10)     blocking is that the weight associated with cue A is expected
                                    t =0
                                                                                to decrease to 0.5 after a large number of AX+ trials.
with the convention that
                              r            r        r r         r                 A                                   B
             P (O1 | {O0 }, { x1 }) = ∫ dω P (O1 | ω , x1 ) P (ω ).    (11)
         Simulation of Blocking Experiments
We first report our simulations of traditional
forward/backward blocking paradigms (Shanks, 1985) using
linear-sum and noisy-MAX models. These two blocking
effects provide a critical test for any sequential learning
model. We then apply our Bayesian approach, e.g. using                          Figure 2. Predicted mean weights of each cue as a function of
model selection, to a human experiment that employed                            training trials in two different blocking paradigms. (A) linear-sum
                                                                                model; (B) noisy-MAX model. The black lines indicate predictions
pretraining (Beckers et al., 2005), and a similar conditioning
                                                                                for forward blocking paradigm (A+, AX+); the gray lines indicate
experiment using rats (Beckers et al., 2006). The simulations                   predictions for backward blocking paradigm (AX+, A+). The solid
will illustrate how our approach accounts for human and rat                     lines are estimates of weights for cue A; the dashed lines are
performance based on model selection and parameter                              estimates of weights for cue X. The linear-sum model predicts a
estimation for sequential data.                                                 larger difference between ω A and ω X across the two blocking
                                                                                paradigms than does the noisy-MAX.
                                                                            187

Impact of Pretraining on Human Judgments                              in Figure 3. In the simulation we used model parameters
We simulated results of a pretraining study with humans by            σ h = 0.6,σ T = 0.3,σ m = 0.01, T = 0.4 . To perform model
Beckers et al (2005). Table 2 schematizes the experimental            selection, we need to impose a threshold on the log-likelihood
design. G and H indicate different food cues: + and ++                ratios. We set the threshold to be the log-likelihood ratio
indicate a moderate or a strong allergic reaction, respectively.      obtained when only the data G+, H+ had been shown (as the
As shown in Table 2, additive pretraining involved G+ trials          experimental subject would have no basis for a preference
followed by H+, and then followed by GH++. Sub-additive               between the two models at this stage). The simulation results
pretraining involved G+ trials followed by H+ trials, and then        (see Figure 3) show that the linear-sum model is selected if
followed by GH+ trials.                                               the pretraining is additive (i.e., G+, H+, GH++), because the
   The experiment included three phases: (a) pretraining, (b)         corresponding ratio is below the threshold, whereas the noisy-
elemental training, and (c) compound training. The elemental          MAX model is selected if the pretraining is sub-additive (i.e.,
and compound training were always the same but the                    G+, H+, GH+), because the corresponding ratio is above the
pretraining could be either additive or sub-additive for the          threshold
two groups. In both groups, standard forward blocking trials                                            Figure 3. Log-likelihood ratios
with different food cues (A+ followed by AX+) were                                                      for the noisy-MAX model
presented in phase 2 and 3. Note that the design used                                                   relative to the linear-sum model
completely different cues in the pretraining phase 1 (cues G,                                           for the additive group (black)
H) and phases 2 and 3 (cues A, X, K, and L). If blocking                                                and the sub-additive group
occurs, we would expect the weight of cue X to be reduced                                               (white) in human experiment by
                                                                                                        Beckers et al. (2005). The
by its pairing with cue A, due to the earlier elemental training
                                                                                                        dashed line indicates the
on A in phase 2. K and L served as control cues, which were                                             threshold for model selection.
only presented in phase 3 as KL+ trials.
   After completing these three phases, participants were                We then computed the mean weights, using Eq. 9, for the
asked to rate how likely each food cue separately would cause         models chosen by the model selection stage. These mean
an allergic reaction. As indicated by the human results shown         weights (see Figure 4B) constitute our simulation’s
in Figure 4A, cue X was blocked after additive pretraining but        predictions for the causal ratings. The simulation results are in
not after sub-additive pretraining. More precisely, additive          good agreement with the results for humans (Figure 4A). The
pretraining resulted in a lower rating for cue X than for the         linear-sum model generates accurate predictions for the
control cues, K and L, both of which in turn received                 additive group: the mean weight for X is much lower than
significantly lower causal ratings than cue A. In contrast, after     weights for the control cues K and L, indicating blocking of
sub-additive pretraining there was little difference among the        causal learning for cue X. In contrast, the noisy-MAX model
ratings for X, K, and L.                                              gives accurate predictions for the sub-additive group: the
                                                                      mean weight for X is about the same as the weights for the
Group            Phase 1:            Phase 2:      Phase 3:           control cues K and L, consistent with absence of blocking for
                 Pretraining         Elemental     Compound           X.
                                     Training      Training
                                                                           A                                  B
Additive         8G+/8H+/8GH++       8A+           8AX+/8KL+
                 /8I+/8Z-            /8Z-          /8Z-
Subadditive      8G+/8H+/8GH+        8A+           8AX+/8KL+
                 /8I++/8Z-           /8Z-          /8Z-
Table 2: Design summary for human pretraining experiment in
Beckers et al. (Exp. 2, 2005).
   The experimental design used by Beckers et al. (2005) can          Figure 4. Mean causal rating for each cue. (A) Human ratings in
be translated into the notation of our model as follows. G+,          Experiment 2 by Beckers et al (2005); see their Figure 3, p. 243.
H+, GH+ respectively correspond to ( x1 , x 2 ) = (1,0),              Black bars indicate the mean rating for additive pretraining group;
                                                                      white bars for sub-additive pretraining group. (B) Predicted ratings
(0,1), and (1,1) . The notation + and ++ correspond to O = 1          based on the selected model for each group. Black bars indicate the
and O = 2 , respectively. Using the pretraining trials in phase 1,    mean ω based on the linear-sum model, which gives a good fit for
we performed model selection to infer which model is more             the human means in the additive group. White bars indicate the mean
likely for the additive and sub-additive groups. With the             ω based on the noisy-MAX model, which give a good fit for the
models selected in the pretraining phase, we then used trials         human means in the sub-additive group.
in phases 2 and 3 to estimate the distribution of the weights
ω for each cue. The mean of each ω was computed to                    Impact of Pretraining on Rat Conditioning
provide a comparison with human ratings.                                 Now we compare the predictions of the models to the
   We employed trials in the pretraining phase to compute the         experimental findings for a conditioning experiment with rats
log-likelihood ratios for the noisy-MAX model relative to the         (Beckers et al., 2006). Animals were presented with cues that
linear-sum model using Eq. 10. The resulting plots are shown          were associated with shocks while the animals pressed a lever
                                                                  188

 for water. We focus on two conditions: sub-additive and                                                      Figure 5. Log-likelihood
 irrelevant element, as schematized in Table 3 (Beckers et al.,                                               ratios of noisy-MAX
 2006, Experiment 1). Animals in the experimental group                                                       model relative to linear-
 received forward blocking training (A+ followed by AX+);                                                     sum model for the
 control animals did not receive blocking training (B+                                                        subadditive condition
 followed by AX+). Before the actual blocking training (phase                                                 (white), and the irrelevant
 2 and phase 3), experimental and control animals in the sub-                                                 condition (gray) in the rat
                                                                                                              experiment (Beckers, et
 additive condition were exposed to a demonstration of two                                                    al., 2006, Exp. 1).
 effective cues, C and D, that had sub-additive outcomes (i.e.,
 C+, D+, CD+), or to an irrelevant pretraining (i.e. C+, D+,         Figure 6B shows the predictions of selected models for the
 E+). The number of lever-press responses to X after phase 3         two conditions tested by Beckers et al. (2006). Similar to the
 was measured for all animals.                                       results obtained when modeling the human data, the noisy-
                                                                     MAX model was selected for the sub-additive condition, and
  Condition and          Phase 1:          Phase 2:    Phase 3:
   group                 Pretraining       Elemental   Compound
                                                                     the linear-sum model for the irrelevant condition.
                                           Training    Training      Accordingly, the suppression ratio was estimated using the
Subadditive                                                          noisy-MAX model for the subadditive condition. The
   Experimental          4C+/4D+/4CD+      12A+        4AX+          suppression ratio in the irrelevant condition was computed by
   Control               4C+/4D+/4CD+      12B+        4AX+          the linear-sum, because the default model was assumed to
Irrelevant element                                                   favor the linear-sum given that irrelevant pretraining data did
   Experimental          4C+/4D+/4E+       12A+        4AX+          not provide clearly discriminative information for model
   Control               4C+/4D+/4E+       12B+        4AX+          selection. As shown in Figure 6B, there was no significant
 Table 3: Design summary for the rat pretraining experiment by       difference in the suppression ratio for the noisy-MAX model,
 Beckers et al. (Exp. 1, 2006).                                      in agreement with rat data showing no significant difference
    We used the same translation to the model notation as            between the experimental and control groups with sub-
 before. We set the threshold such that without any training,        additive pretraining. In contrast, suppression ratios differed
 the linear-sum model would be preferred over the noisy-             between experimental and control groups using the linear-
 MAX model, as evidence suggests that rats typically assume          sum model in agreement with the rat data showing a
 linear integration (Beckers et al., 2006, p. 98; see also           significant difference between the experimental and control
 Wheeler, Beckers, & Miller, 2008). We computed the log-             groups with irrelevant element pretraining.
 likelihood ratios for the pre-testing data, using Eq. 10, to             A                                B
 confirm that the noisy-MAX model was selected for the sub-
 additive condition and the linear-sum model for the irrelevant
 condition. The results are shown in Figure 5. We used model
 parameters σ h = 0.6,σ T = 0.6, σ m = 0.01, T = 0.3 in the
 simulations. Compared to the parameter set used for the
 human experiments, we increased the variance for the
 temporal prior to speed up causal learning of cues (perhaps         Figure 6. Mean suppression ratio for cue X in experimental and
 reflecting the high salience of electric shock as an outcome).      control groups by pretraining conditions in the subadditive condition
    Beckers et al. (2006) used the suppression ratio of cue X as     and irrelevant condition (Beckers, et al, 2006, Exp. 1). Black/white
 a measure of rats' causal judgment about cue X. A value of 0        bars indicate the experimental/control group, respectively. (A) Rat
 for the suppression ratio corresponds to complete suppression       results; (B) Suppression ratio predicted by the noisy-MAX model
                                                                     (matched to sub-additive experimental condition), and predicted by
 of bar pressing (i.e., high fear of cue X), and a value of 0.5
                                                                     the linear-sum model (matched to irrelevant element condition).
 corresponds to a complete lack of suppression (i.e., no fear of
 X). Figure 6A shows the mean suppression ratios for
 experimental and control animals in Experiment 1 of Beckers
                                                                                          General Discussion
 et al. (2006).                                                         The Bayesian theory of sequential causal learning
    We model the suppression ratio as a function of the              described in the present paper provides a unified explanation
 predicted mean weight of cue X, ω X with Eq. 9. Assuming            for important learning phenomena observed with both
                                                                     humans and rats. In particular, the theory accounts for
 that the mean number of lever presses in the absence of cue X
                                                                     influences of pretraining on subsequent learning with
 is N, the expected number of lever presses in the presence of
                                                                     completely different stimuli (Beckers, et al., 2005, 2006). The
 cue X will be N − Nω X . Accordingly, the predicted
                                                                     key assumption is that learners have available multiple
 suppression ratio can be computed as:                               generative models, each reflecting a different integration rule
                              N − Nω X     1− ωX     (12)            for combining the influence of multiple causes (cf. Lucas &
    suppression ratio =                  =
                            N − Nω X + N 2 − ω X                     Griffiths, 2007; Waldmann, 2007). When the outcome is a
                                                                     continuous variable, both humans and rats have tacit
                                                                     knowledge that multiple causes may have a summative
                                                                 189

impact on the outcome (linear-sum model). Alternatively, the            Cheng, P. W. (1997). From covariation to causation: A causal power
outcome may be effectively “saturated” at a level                         theory. Psychological Review, 104, 367-405.
approximated by the weight of the strongest individual cause            Cheng, P. W., & Holyoak, K. J. (1995). Complex adaptive systems
(noisy-MAX). Using standard Bayesian model selection, the                 as intuitive statisticians: Causality, contingency, and prediction.
learner selects the model that best explains the pretraining              In H. L. Roitblat & J.-A. Meyer (Eds.), Comparative approaches
data, and then employ the favored model in estimating causal              to cognitive sciences (pp. 271-302). Cambridge, MA: MIT Press.
weights with different cues during subsequent learning. Note            Danks, D., Griffiths, T. L., & Tenenbaum, J. B. (2003). Dynamical
that the information provided in Phases 2-3 is identical for              causal learning. In S. Becker, S. Thrun, & K. Obermayer (Eds.),
both groups; hence only Phase 1 (pretraining) is relevant to              Advances in neural information processing systems (Vol. 15, pp.
                                                                          67-74). Cambridge, MA: MIT Press.
model selection.
   A key component of the sequential learning theory is the             Dayan, P., & Kakade, S. (2000). Explaining away in weight space.
                                                                          In T. K. Leen et al., (Eds.), Advances in neural information
temporal prior, which controls dynamic updating of the
                                                                          processing systems (Vol. 13, pp. 451-457). Cambridge, MA: MIT
estimated weight of each cue in a trial-by-trial manner. The              Press.
temporal prior allows the theory to explain both forward and
                                                                        De Houwer, J., Beckers, T., & Glautier, S. (2002). Outcome and cue
backward blocking effects, and more generally captures the
                                                                          properties modulate blocking. Quarterly Journal of Experimental
influence of trial order on causal learning. Trial-order effects          Psychologyl A, 55, 965-985.
are outside the scope of models that only deal with
                                                                        Griffiths, T. L., & Tenenbaum, J. B. (2005). Structure and strength in
summarized data (e.g., Cheng, 1997; Griffiths & Tenenbaum,                causal induction. Cognitive Psychology, 51, 334-384.
2005; Lu et al., 2007).
                                                                        Ho, Y.-C., & Lee, R. C. K. (1964). A Bayesian approach to
   The present theory is also more powerful than previous
                                                                          problems in stochastic estimation and control. IEEE Transactions
accounts of sequential causal learning. The Rescorla-Wagner               on Automatic Control, 9, 333-339.
model (Rescorla & Wagner, 1972) and its many variants (see
                                                                        Kamin, L. J. (1969). Predictability, surprise, attention, and
Shanks, 2004) only update point estimates of causal strength,
                                                                          conditioning. In B. A. Campbell & R. M. Church (Eds.),
and thus are unable to represent degrees of uncertainty about             Punishment and aversive behavior (pp. 279-296): New York:
causal strength (Cheng & Holyoak, 1995). By adopting a                    Appleton-Century-Crofts.
Bayesian approach to learning probability distributions, the
                                                                        Lu, H., Yuille, A., Liljeholm, M., Cheng, P. W., & Holyoak, K. J.
present theory provides a formal account of how a learner’s               (2007). Bayesian models of judgments of causal strength: A
confidence in the causal strength of a cue will be expected to            comparison.       In D. S. McNamara & G. Trafton (Eds.),
change over the course of learning. The same limitation                   Proceedings of the Twenty-ninth Annual Conference of the
(updating point estimates of strength, rather than probability            Cognitive Science Society (pp. 1241-1246). Austin, TX: Cognitive
distributions) holds for a previous simulation of sequential              Science Society.
learning based on the noisy-OR generative model (Danks,                 Lucas C. G., & Griffiths, T. L. (2007). Learning the functional form
Griffiths & Tenenbaum, 2003). Most importantly, the present               of causal relationships. Poster presented in the Twenty-ninth
theory goes beyond all previous accounts of dynamical causal              Annual Conference of the Cognitive Science Society.
learning (e.g., Dayan & Kakade, 2000) in its core assumption            Rescorla, R. A. (1988). Pavlovian conditioning: It’s not what you
that learners, both human and non-human, are able to flexibly             think it is. American Psychologist, 43, 151-160.
select among multiple generative models that might “explain”            Rescorla, R. A., & Wagner, A. R. (1972). A theory of Pavlovian
observed data. The theory thus captures what appears to be a              conditioning: Variations in the effectiveness of reinforcement and
general adaptive mechanism by which biological systems                    nonreinforcement. In A. H. Black & W. F. Prokasy (Eds.),
learn about the causal structure of the world.                            Classical conditioning ii: Current theory and research (pp. 64-
                                                                          99): New York: Appleton-Century-Crofts.
                     Acknowledgments                                    Shanks, D. R. (1985). Forward and backward blocking in human
                                                                          contingency judgement. Quarterly Journal of Experimental
Preparation of this paper was supported by a Postdoctoral
                                                                          Psychology, 37, 1-21.
Fellowship and a Travel Grant from the Research Foundation
- Flanders (FWO Vlaanderen) to TB, and a grant from the W.              Shanks, D. R., & Dickinson, A. (1987). Associative accounts of
                                                                          causality judgment. In G. H. Bower (Ed.), The psychology of
H. Keck Foundation to AY.
                                                                          learning and motivation (Vol. 21, pp. 229-261). San Diego, CA:
                                                                          Academic Press.
                           References                                   Shanks, D. R. (2004). Judging covariation and causation. In D.
Beckers, T., De Houwer, J., Pineño, O., & Miller, R. R. (2005).           Koehler & N. Harvey (Eds.), Blackwell handbook of judgment
   Outcome additivity and outcome maximality influence cue                and decision making. Oxford, UK: Blackwell.
   competition in human causal learning. Journal of Experimental        Waldmann, M. R. (2007). Combining versus analyzing multiple
   Psychology: Learning, Memory, and Cognition, 31, 238-249.              causes: How domain assumptions and task context affect
Beckers, T., Miller, R. R., De Houwer, J., & Urushihara, K. (2006).       integration rules. Cognitive Science, 31, 233-256.
   Reasoning rats: Forward blocking in Pavlovian animal                 Wheeler, D. S., Beckers, T., & Miller, R. R. (2008). The effect of
   conditioning is sensitive to constraints of causal inference.          subadditive pretraining on blocking: Limits on generalization.
   Journal of Experimental Psychology: General, 135, 92-102.              Manuscript accepted for publication, Learning & Behavior.
Blaisdell, A. P., Sawa, K., Leising, K. J., & Waldmann, M. R.
   (2006). Causal reasoning in rats. Science, 311(5763), 1020-1022.
                                                                    190

