UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
An Empirical Study of Errors in Translating Natural Language into Logic
Permalink
https://escholarship.org/uc/item/66k15611
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Barker-Plummer, Dave
Cox, Richard
Dale, Robert
et al.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                   Powered by the California Digital Library
                                                                     University of California

        An Empirical Study of Errors in Translating Natural Language into Logic
             Dave Barker-Plummer (dbp@stanford.edu)                            Richard Cox (richc@sussex.ac.uk)
                           CSLI, Stanford University                      Department of Informatics, University of Sussex
                       Stanford, California, 94305, USA                            Falmer, E. Sussex, BN1 9QJ, UK
                  Robert Dale (rdale@ics.mq.edu.au)                      John Etchemendy (etch@csli.stanford.edu)
           Centre for Language Technology, Macquarie University               CSLI and Philosophy, Stanford University
                         Sydney, NSW 2109, Australia                               Stanford, California, 94305, USA
                              Abstract                                   LPL’s 748 exercises2 to The Grade Grinder (GG), a robust au-
                                                                         tomated assessment system that has assessed approximately
   Every teacher of logic knows that the ease with which a student       1.8 million submissions of work by more than 38,000 individ-
   can translate a natural language sentence into formal logic de-
   pends, amongst other things, on just how that natural language        ual students over the past eight years; this population is drawn
   sentence is phrased. This paper reports findings from a pilot         from approximately a hundred institutions in more than a
   study of a large scale corpus in the area of formal logic educa-      dozen countries. These submissions form an extremely large
   tion, where we used a very large dataset to provide empirical
   evidence for specific characteristics of natural language prob-       corpus of high ecological validity which we wish to exploit in
   lem statements that frequently lead to students making mis-           order (inter alia) to gain insights into cognitive processes dur-
   takes. We developed a rich taxonomy of the types of errors            ing formal reasoning (such as those associated with natural-
   that students make, and implemented tools for automatically
   classifying student errors into these categories. In this paper,      to-formal language translation and interpretation), to extend
   we focus on three specific phenomena that were prevalent in           our research on individual differences in reasoning (e.g. Sten-
   our data: Students were found (a) to have particular difficulties     ning & Cox, 2006), to improve logic teaching, and, eventu-
   with distinguishing the conditional from the biconditional, (b)
   to be sensitive to word-order effects during translation, and (c)     ally, to enrich the Grade Grinder’s feedback to students. Un-
   to be sensitive to factors associated with the naming of con-         derstanding the nature of students’ errors is central to these
   stants. We conclude by considering the implications of this           aims; the corpus offers considerable scope for analyses with
   kind of large-scale empirical study for improving an automated
   assessment system specifically, and logic teaching more gen-          this in mind.
   erally.                                                                  As a pilot study in how this rich data set might be used
   Keywords: errors; slips; misconceptions; natural language;            to inform logic teaching, we selected a single exercise in-
   e-learning; human reasoning; automated assessment; educa-
   tional data mining; first-order logic; propositional logic; Lan-      volving the translation of twenty sentences from English into
   guage, Proof & Logic                                                  propositional logic. We developed and validated a taxon-
                                                                         omy for categorising students’ translation errors and used it
                          Introduction                                   as the basis for an automated error-classification system. We
                                                                         analysed several thousand solutions to the exercise and sin-
It seems obvious that the difficulty students face in translating
                                                                         gled out three high-frequency types of error — antecedent–
natural language statements into formal logic will, at least in
                                                                         consequent reversals, substitutions of connectives, and sub-
part, be due to characteristics of the natural language state-
                                                                         stitutions of constants — for in-depth followup. All three
ments themselves. For example, we would expect it to be
                                                                         demonstrate how particular aspects of the form of a natural
relatively easy to translate a natural language sentence when
                                                                         language sentence impact on the ease with which students
the mapping from natural language into logical connectives is
                                                                         can translate this sentence into logic. Below, we describe this
transparent, as in the case of the mapping from and to ‘∧’, but
                                                                         analysis in detail, and provide some conclusions regarding the
harder when the natural language surface form is markedly
                                                                         implications of this work for improving an automated assess-
different from the corresponding logical form, as in the trans-
                                                                         ment system specifically, and logic teaching more generally.
lation of sentences of the form A provided that B. However,
evidence for this hypothesis is essentially anecdotal, and we                                        Sampling
have no quantitative evidence of which linguistic phenomena
                                                                         For the purposes of initial exploration we selected a natural
are more problematic than others.
                                                                         language (NL) to first-order logic (FOL) translation exercise
   This paper presents results from a pilot study using a large-
                                                                         of moderate difficulty, i.e. one that psychometrically discrim-
scale corpus in the area of first-order logic teaching at the un-
                                                                         inates between students. Exercise 7.12 from Chapter 7 (which
dergraduate level. The corpus consists of student-generated
                                                                         introduces conditionals) was selected by computing the num-
solutions to exercises in Language, Proof and Logic (LPL;
                                                                         ber of GG submissions per LPL exercise and rank ordering
Barwise, Etchemendy, Allwein, Barker-Plummer & Liu,
                                                                         them by the proportion of incorrect submissions of the exer-
1999), a courseware package consisting of a textbook to-
                                                                         cise. This exercise involves translating each of twenty En-
gether with desktop applications which students use to com-
                                                                         glish sentences into propositional logic (a subset of FOL). A
plete exercises.1 Students may submit answers to 489 of
                                                                             2 The other exercises require that students submit their answers
    1 See http://lpl.stanford.edu.                                       on paper to their instructors.
                                                                     505

 Translate the following English sentences into FOL. Your transla-             solution. A student submission of Tet(a) ∨ FrontOf(a, b)
 tions will use all of the propositional connectives.                          will be classified as a connective substitution of ‘∨’ for ‘→’,
 1. If a is a tetrahedron then it is in front of d.                            while it is equally plausible that the student was aiming at the
 2. a is to the left of or right of d only if it’s a cube.                     second answer, and committed the error of omitting the ‘¬’.
 3. c is between either a and e or a and d.                                       A framework, or set of guidelines, emerged following an
 4. c is to the right of a, provided it (i.e. c) is small.
                                                                               iterative, fairly systematic process based on the procedure ad-
 5. c is to the right of d only if b is to the right of c and left of e.
 7. If b is a dodecahedron, then it’s to the right of b if and only if it      vocated by Chi (1997) for developing protocols for the qual-
    is also in front of b.                                                     itative analysis of verbal data in educational research. We
10. At least one of a, c, and e is a cube.                                     identified, grouped and categorised broad classes of error
11. a is a tetrahedron only if it is in front of b.                            types, iteratively developed a coding scheme, and wrote op-
                                                                               erational definitions of the error types. These processes were
                                                                               cyclical and repeated at various levels of granularity. Eventu-
              Figure 1: An extract from Exercise 7.12                          ally, a taxonomy of 45 error types emerged. Each of these is
                                                                               identifiable in terms of surface-form characteristics: we also
                                                                               explored the categorisation of the different errors in terms of
 translation for a sentence (which we refer to here as a solu-
                                                                               their possible causes, but decided that this left too much scope
 tion) is considered correct if it is equivalent to a reference so-
                                                                               for subjectivity, and that a categorisation based on observable
 lution.3 Sample sentences from Exercise 7.12 are presented
                                                                               phenomena was most appropriate at this stage in the exer-
 in Figure ??.
                                                                               cise. We organised these 45 error types under three broad
    The reference solution for Sentence 1 in Figure ?? is
                                                                               categories, based on the representation of a FOL formula as a
 Tet(a) → FrontOf(a, d). The Grade Grinder’s response to an
                                                                               tree:
 erroneous submission of the form FrontOf(a, d) → Tet(a), a
 common error, takes the form:                                                1. Structural Errors: these are errors involving the structure
                                                                                  of the FOL tree—for example, switching of the antecedent
    *** Your first sentence, "FrontOf(a, d) ->                                    and consequent of an implication, or adding exclusivity
    Tet(a)", is not equivalent to any of the                                      (e.g. giving a sentence of the form (A ∨ B) ∧ ¬(A ∧ B) in-
    expected translations.                                                        stead of just (A ∨ B).
 Further information on the Grade Grinder, and samples of                     2. Connective Errors: errors involving labels on the interior
 feedback reports, can be found on the GG website.4                               nodes of the FOL tree: using one connective in place of
    A submission for Exercise 7.12 consists of a solution for                     another.
 all twenty sentences, and is considered erroneous if the stu-
 dent makes an error on at least one of the solutions. We                     3. Atomic Errors: errors involving the structure of an atomic
 examined the corpus of submissions of Exercise 7.12 made                         subformula; these are of two subtypes:
 by students during the calendar years 2000–2007 — more                         (a) Predicate Errors, where one predicate symbol is used
 than 74,000 submissions, of which 42,416 submissions (57%)                          in place of another; and
 were erroneous, with a total of 148,681 incorrect translation                  (b) Argument Errors, where one argument is used in place
 solutions.5 These submissions were made by 11,925 different                         of another, or the wrong number of arguments is present.
 students, representing an average of 12.47 incorrect transla-
 tions per student.                                                            Each of the categories cover a collection of different kinds of
                                                                               error. For example, Connective Errors can be the substitu-
       Method: Developing an Error Taxonomy                                    tion of a connective for any other (‘∧’ in place of ‘→’, say),
 We scrutinised a subsample of 296 erroneous solutions for                     for an out-of-vocabulary (unknown) symbol, or for the empty
 Sentence 1 in Exercise 7.12, and worked collaboratively to                    symbol (omission). For Argument Errors, we distinguish
 develop a coding scheme for annotating students’ solutions.                   the situation where a constant has been substituted for the
    The errors in a student’s answer are determined by com-                    correct symbol in the wrong orthographic case (‘A’ instead
 parison with the reference solution. Throughout this paper                    of ‘a’, say) from substitutions of one constant for another.
 we assume that this answer is the most natural solution, and                     Additional error types derive from stereotypical patterns of
 that it is this sentence that the student is aiming to produce.               lower-level errors. For example, a substitution of one con-
    The          sentences          Tet(a) → FrontOf(a, d)             and     stant for another throughout the formula is categorised as a
 ¬Tet(a) ∨ FrontOf(a, d) are equivalent, correct transla-                      ‘uniform’ substitution, while substitution in some places and
 tions for Sentence 1; here, the first of these is the reference               not others is categorised as ‘sporadic’. We also introduce a
                                                                               ‘waste-basket’ class covering cases where students have in-
     3 There are infinitely many correct answers for any sentence, so a
                                                                               troduced unnecessary or unmatching parentheses; inclusion
 theorem prover is employed to determine equivalence.
     4 See http://ggww2.stanford.edu/GUS/lpl/.                                 of periods at the end of strings; and examples so radically
     5 Some or all of the translations may be empty and therefore er-          different from the solution that it is not clear how to charac-
 roneous, but we ignore these null solutions in this paper.                    terise them.
                                                                           506

                          Table 1: Examples of errors, (n.b. ACREV = Antecedent-Consequent Reversal)
           #   Reference solution                     Errored solution                     Type    Subtype
           1   Tet(a) → FrontOf(a, d)                 FrontOf(a, d) → Tet(a)                 1     ACREV
           2   Tet(a) → FrontOf(a, d)                 FrontOf(a, b) → Tet(a)               1, 3ii  ACREV, Incorrect Constant
           3   Tet(a) → FrontOf(a, d)                 Tet(a) ∨ FrontOf(a, d)                 2     Disjunction for Conditional
           4   ¬Cube(e) → (Large(b) ∨ Large(d))       ¬Cube(e) → Large(b) ∨ Large(d)         1     Missing Parens
           5   Large(e) → Large(a)                    e → Large(a)                           2     Elided Predicate
           6   Tet(a) → FrontOf(a, d)                 Tet(a) → InFrontOf(a, d)               3i    Incorrect Predicate
           7   Tet(a) → FrontOf(a, d)                 Tet(a) → FrontOf(a, b)                3ii    Incorrect Constant
           8   Tet(a) → FrontOf(a, d)                 Tet(a) → FrontOf(d)                   3ii    Arity Error
   Table ?? shows examples of each of the higher-level er-
                                                                                          Table 2: Error frequencies
ror types, each labelled with the more specific error category
assigned in our taxonomy. Note that some solutions, as in                Error Type                              Count    %age of All
example 2 here, contain more than one error.                             Antecedent–Consequent Reversal         25084          25.86%
                                                                         Biconditional for Conditional          17518          18.06%
          Reliability of the Coding Scheme
                                                                         Conditional for Biconditional          11362          11.71%
For manageability in annotation, we identified and charac-               Negation Error                           8954          9.23%
terised eight error types that serve as intermediate nodes in the        Incorrect Scope                          5422          5.59%
error taxonomy between the three top level types and the 45              Failure to Scope                         4701          4.85%
leaf-node categories. Two independent annotators used this               Argument Error                           4474          4.61%
categorisation to code 296 student solutions to Sentence 1 of            Conjunction for Conditional              3187          3.29%
Exercise 7.12. Each solution contained between one and three             Conditional for Conjunction              2091          2.16%
errors. We computed Cohen’s kappa (κ) statistic for inter-               Biconditional for Conjunction            1514          1.56%
annotator reliability; kappa can be used to verify that agree-
ment exceeds chance levels (e.g. Viera & Garrett, 2005). κ
was computed separately for each of the categories; values             sion contains the wrong predicate (Incorrect Predicate error),
are shown in parentheses after each category: Antecedent–              we do not subsequently check that the arity of that predicate
Consequent Reversal (κ=.97); Incorrect Constants (κ=.98);              is correct (Arity Error).
Incorrect Predicates (κ=.74); Incorrect Connectives (κ=.94);
Parenthesis Errors (κ=.76); Case Errors (κ=.66); Arity Errors                     Applying the Taxonomy to Data
(κ=1.00); Other Errors (κ=.52). Kappa values all showed                We ran the student’s FOL translation solutions to the twenty
substantial, almost perfect or perfect agreement for all cat-          Exercise 7.12 sentences through the regular expression-based
egories except ‘Other’, for which there was only moderate              coding software. We first produced a list of frequencies of er-
agreement.                                                             rors for all 20 sentences, and focussed our attention on the 10
                                                                       most frequent errors for each sentence. The results of this
           Automating the Coding Process
                                                                       analysis are shown in condensed form in Table ??, which
We used the full taxonomy to inform the design of an au-               shows the number of instances of each of the ten most fre-
tomated solution coding system. We developed a simple                  quent error types across all 20 sentences, along with the per-
pattern-matching program, based on regular expressions, and            centage of total errors accounted for by these instances.
used it to classify automatically each of the sentences in the            Below, we illustrate the application of the taxonomy to the
complete corpus. The classifier identifies fragments of the            data with one example from each of the three broad categories
submitted answer that appear to correspond to the atomic sub-          mentioned earlier (Structural Errors, Connective Errors and
formulae of the reference sentence, and requires that the cor-         Atomic Errors): Antecedent–Consequent Reversal and Incor-
rect number of such subformulae are present before proceed-            rect Substitution of the Biconditional for the Conditional are
ing to classify the errors within the answer. This approach            the two most frequent errors overall, and Argument Errors are
allows us to analyse those answers which are syntactically             the most common Atomic Errors.
incorrect, although it does not have the flexibility that a tok-
enizer or chart-parser based analyser might have.                      Reversal of Antecedent and Consequent
   On average the classifier was able to classify 85% of the           Clement, Lochhead and Monk (1981) studied translation
submissions within the corpus. The classification rate var-            difficulties in mathematics. Students talked aloud as they
ied with sentence and ranged from 62% (Sentence 7) to 99%              worked on a simple algebra problem (“Write an equation:
(Sentence 11). The classifier was able to code for each of the         ‘There are six times as many students as professors at this uni-
errors in the taxonomy, but the presence of some errors pre-           versity.’ Use S for the number of students and P for the num-
vents the coding for some others. For example, if a submis-            ber of professors”.). The predominant error consisted of re-
                                                                  507

versing the variables in the equation. Of 150 ‘calculus level’
                                                                               Table 3: Biconditional for Conditional Errors
students, 37% manifested reversal errors of the form 6S = P.
The rate was 57% in another sample. Two sources for the er-                   Frequency     Percentage    Surface Form
ror were identified. The first was termed ‘word-order match-                      13214        75.43%     S only if S.
ing’ in which the student orders terms in their equation in a                       1777       10.14%     S unless S.
way that matches the order of keywords in the problem state-                        1146         6.54%    S provided S.
ment. The process is superficial and syntactic. Another strat-                       725         4.14%    S if S.
egy Clement et al. (1981) termed ‘static comparison’. This is                        367         2.09%    If S then if S then S.
one in which the student does not understand S as a variable                         289         1.65%    If S then S.
representing the number of students, but as a label attached
to a number, in this case ‘6’. The student places a multiplier
adjacent to the letter associated with the larger group. This er-     ficulties in distinguishing the biconditional from the condi-
ror is based on an interpretation of the equals sign as express-      tional, as discussed in the next section.
ing comparison or association rather than equality. Clement              In future studies we plan to look at correlations of error pat-
(1982) reports that the static comparison strategy is a ‘deep-        terns within and between students; this may help to establish
seated, intuitive symbolization strategy . . . ’ which can co-        the relative contribution of each phenomenon. Consequently,
exist with formally taught contradictory schemes and which            they provide an interesting means by which the effect of natu-
can ‘take over’ in some problem solving situations (p.28). We         ral language presentation upon connective substitution errors
were interested to investigate whether evidence for strategies        can be investigated.
akin to word-order matching and static comparison in word
algebra problem solving can also be found in the FOL domain.          Connective Substitutions
                                                                      Sentences 1 and 11 have quite different NL forms, but their
   There are two kinds of sentence for which element order-           FOL translations are identical modulo the use of a different
ing matters (i.e. where the connective is the non-commutative         constant.
‘→’). For some, the correct solution preserves the word or-           1. If a is a tetrahedron then it            is  in  front  of   d,
dering in the posed NL sentence (e.g. Sentence 1: If a is a              Tet(a) → FrontOf(a, d);
                                                                    11. a is a tetrahedron only if it            is   in  front  of   b,
tetrahedron then it is in front of d ≈ Tet(a) → FrontOf(a, d)).          Tet(a) → FrontOf(a, b)
For others, the correct solution requires re-ordering (e.g. Sen-
tence 4: c is to the right of a, provided it (i.e., c) is small          Of the 10 most common errors for these two sentences, six
≈ Small(c) → RightOf(c, a)). Twelve of our reference sen-             are shared by both: Antecedent–Consequent Reversal, Bicon-
tences involve implication; eight of them preserve word or-           ditional for Conditional substitution, Argument Reversal, In-
der and four do not. Our prediction was that Antecedent–              correct Argument, Incorrect Predicate, and Arity Error. The
Consequent Reversal would occur more frequently on sen-               frequency of occurrence of each of the six shared error types
tences for which the correct solution requires re-ordering than       were rank-ordered 1–6 separately for each of Sentences 1 and
would be observed for sentences that preserve the posed word          11.
order in the solution. We calculated the number of erroneous             Whereas for Sentence 1 Biconditional for Conditional sub-
solutions submitted to Grade Grinder which demonstrated               stitution ranked fourth out of the six and represented 12% of
Antecedent–Consequent Reversal for each sentence and ex-              1361 solutions, for Sentence 11 it ranked first — the most
pressed that as a fraction of the total number of solutions for       common error of all, with 58% of 8981 solutions of this kind.
that sentence. The total number of solutions submitted across         This strongly indicates that there is something about the sur-
the 12 sentences in the analysis ranged from 318 to 8361.             face structure of the two NL sentences that elicit very different
                                                                      error patterns from students. More generally, we can consider
   For the four sentences in which word order is not preserved
                                                                      the propensity for students to make the Biconditional for Con-
during translation from posed NL sentence to FOL solution,
                                                                      ditional substitution error when faced with a variety of differ-
the percentage of antecedent and consequent reversals was
                                                                      ent natural language renderings of the conditional. Table ??
66%. This means that one basis for the students’ error was a
                                                                      shows the number and percentage of Biconditional for Con-
tendency to preserve the original word order for this type of
                                                                      ditional errors per surface form across the 20 sentences. This
sentence. In contrast, for the eight sentences in which word
                                                                      demonstrates that students find it significantly more difficult
order is preserved during translation, the antecedent and con-
                                                                      to translate the only if form than other natural renderings of
sequent reversal rate was 43%. This difference was signif-
                                                                      the conditional.
icant under a directional hypothesis (i.e. that sentences re-
quiring re-ordering during translation would produce more             Substitution of Constants
Antecedent–Consequent Reversals).                                     Incorrect Constant errors, where one constant is substituted
   The t-test values were (t = 2.23, df(10), p = .05, 2-tailed).      for another, are a significant form of error for specific sen-
It therefore seems that word order in the NL posed sentence           tences. For example, four out of the top 10 error forms
does tend to ‘drive’ term order in the FOL translation for many       for Sentence 10 (At least one of a, c, and e is a cube ≈
students, though this effect is probably conflated with dif-          Cube(a) ∨ Cube(c) ∨ Cube(e)) involve this type of error:
                                                                  508

   Cube(a) ∨ Cube(b) ∨ Cube(c)            n = 758
                                                                       Table 4: Constant substitution errors as %s of all errors for
   Cube(a) ∨ Cube(b) ∨ Cube(e)            n = 227
                                                                       sentences in which first mentioned constant was/was not a vs.
   (Cube(a) ∨ Cube(b) ∨ Cube(c))          n = 53
                                                                       whether or not constant names were alphabetically adjacent
   Cube(a) ∨ Cube(c) ∨ Cube(b)            n = 45
                                                                       letters (‘gappyness’).
We noted that this kind of error seemed to interact with (1) the                                                     Mean constant
use of the constant a in a sentence; (2) whether the use of a             Begins with ‘a’?     Gappy?      N     substitution error (%)
as a constant was the first mentioned constant in the sentence;                   no               no      4               4.5%
and (3) whether or not the letters used as constant names were                    no              yes      8               11%
alphabetically adjacent (e.g. ha, b, ci) versus whether the sen-                 yes               no      2                2%
tence’s constant letters were alphabetically ‘gappy’ (e.g. hb,                   yes              yes      6               32%
e, di). Visual inspection of the data suggested at least two
trends: the first was for constant substitutions to be more fre-
quent when the letters used as constants were not alphabet-
                                                                       stants are named affect translation performance. In this sec-
ically adjacent, and the second was for this effect to appear
                                                                       tion we discuss the latter two features in more detail.
to be magnified when the letters used as constants were not
alphabetically adjacent and the first constant letter name men-        Connective Substitution
tioned in the sentence was a.                                          It seems plausible to suggest that the use of only if in Sen-
   To investigate these issues, we binary-coded each of the            tence 11 cues the phrase if and only if in the student’s mind.
sentences in terms of these factors (present/absent). These            The meaning of the term is introduced in the LPL textbook
were used as independent variables in analyses with the con-           (p.180) as follows: “. . . the expression only if introduces . . . a
stant substitution frequency data as the dependent variable.           necessary condition”. The text provides an illustration in-
An independent t-test comparing the normalised mean fre-               volving an instructor saying to the class that “you will pass
quencies of constant substitutions for ‘gappy’ versus ‘non-            the course only if you turn in all the homework assignments”,
gappy’ sentences revealed a highly significant difference (t =         pointing out that this does not imply that if all homework is
3.58, df(13.4), p < .005). Non-gappy sentences (n = 6) aver-           handed in passing is guaranteed. The biconditional is intro-
aged 4% constant substitution errors, whereas 20% of the er-           duced and illustrated in a similar vein. One source of the
rors on gappy sentences (n = 14) were constant substitution            difficulty that students appear to have with distinguishing the
errors, usually of the ha, bi for ha, di variety. On Sentence          conditional and the biconditional may stem from the way in
1, for example (see Figure ??), 85% of constant substitutions          which if is used in natural language. For example, Stenning
were of b for d, compared to only 25% for d for b substitu-            and van Lambalgen (2001), citing Geis and Zwicky (1971),
tions on Sentence 11.                                                  argue that conditionals are often naturally interpreted as bi-
   We also compared sentences in which the constant name               conditionals in everyday contexts especially where conditions
a was used with those in which it was not, and whether or              are implied or ultimatums are issued (deontics). They suggest
not it was mentioned as the first constant in the NL sentence.         that a statement such as “if you read this, I’ll buy you lunch”
The effect of this factor was also significant under a 1-tailed t-     ‘drops a heavy hint that no reading, no lunch’ (p. 287). Sten-
test (t = 2.00, df(8), p < .05). Twenty-four percent of errors         ning and van Lambalgen (2001) also point out that this kind
on sentences with a mentioned as first constant name were              of interpretation is akin to the Gricean maxim of relevance
constant substitution errors, compared to only 9% for other            (Grice, 1975) under which, if the hearer assumes that if his
sentences. The interaction of the gappy and ‘a-first’ factors          interlocutor was going to buy lunch anyway, then why would
approached statistical significance and suggested a tendency           she make the promise conditional upon the performance of
for the gap effect to be magnified in sentences in which a is          some task?
the first mentioned constant name (Table ??).
                                                                       Constant Substitution as a Capture Error
                          Discussion                                   We hypothesise that constant substitution is sometimes a slip6
                                                                       of the ‘capture error’ type, in which a more frequent be-
The results of the analyses presented here provide support for         haviour ‘captures’ a less frequent behaviour. For example,
the hypothesis that properties of the surface form of a natural        we sometimes might dial a frequently-dialled number when
language sentence negatively impact translation performance            we intended to dial a number beginning with the same prefix.
when the surface form differs markedly from the correspond-            Under our hypothesis, the more frequent behaviour is the use
ing logical form. As we have demonstrated, automated anal-             of alphabetical names in order: ha, b, c, . . .i, and that this be-
ysis of a very large data set allows the exploration of specific       haviour is capturing the required usage: ha, c, ei for Sentence
hypotheses regarding the effects of particular aspects of sur-         10. The data presented in table ?? support this hypothesis.
face form. We have shown that surface features such the or-            The presence of a as the initial constant appears to prime the
dering of antecedent and consequent terms (discussed above),
the use of particular connectives, and the way in which con-               6A term used in the human error literature. e.g. Reason (1990)
                                                                   509

familiar behaviour, which results in a high level of constant         those concerning the cooperative stance of natural language
substitution when ‘gaps’ too are present.                             vs. the more adversarial stance required in these more for-
                                                                      mal fields will have wide application. If educators are trained
Future Work                                                           to expect and recognize errors stemming from these causes,
Our initial explorations of this large data set have produced a       and have appropriate interventions available, then the quality
plethora of interesting directions to pursue.                         of education in these areas may be improved. The poten-
   In the foregoing, we have explored the correlation be-             tial value of greater understanding here is not limited to the
tween specific surface forms and specific error types. There          teaching of logic - it is also an important component of ‘com-
are more complex language-related aspects worthy of explo-            putational thinking’ (Wing, 2006). She defines it as ‘a univer-
ration. For example, we might characterise the NL sentences           sally applicable attitude and skill set that everyone . . . would
in terms of their ‘naturalness’ or ‘paraphrase distance’ from         be eager to learn and use” (p33); it includes, among many
their FOL translated form. Sentence 12 (b is larger than both         others, skills in problem decomposition and heuristic reason-
a and e) seems quite ‘everyday’ in its phrasing compared to           ing. An understanding of logic can facilitate these skills—
sentence 10 (at least one of a, c and e is a cube), for example.      abilities which are becoming ever more important if individ-
   We can also consider the complexity of the natural lan-            uals are to benefit from technological developments in the
guage forms in terms of factors such as: the number of clauses        modern world.
they contain; whether or not these clauses are embedded;
whether there is scope for ambiguity in pronominal reference                               Acknowledgements
resolution or the resolution of elided elements; whether the          RC gratefully acknowledges the support provided by an
sentences contain conjunction, negation, or other signals of          ESRC Teaching & Learning Research Programme (UK) and
syntactic complexity. A better understanding of the impact            SSRC (US) Visiting Americas Fellowship; RD gratefully ac-
of these factors on the difficulty of translation could lead, for     knowledges the support of the Australian Research Council.
example, to the automatic generation of natural language sen-         Albert Liu assisted with the collection of the data; Michael
tences that test a student’s specific weaknesses. We also seek        Murray and Dawit Meles helped with this pilot study.
to clarify what cognitive processes give rise to the types of
errors that we observe. The translation findings we report                                       References
represent comprehension processes rather than full deductive            Barwise, J., Etchemendy, J., Allwein, G., Barker-Plummer,
inferential processes. We feel that the theoretical implica-             D. & Liu, A. (1999) Language, Proof and Logic. CSLI
tions of our findings for abstract rule versus mental model              Publications and University of Chicago Press.
theories must await analyses of ‘deeper’ deductive inferen-             Clement, J. (1982) Algebra word problems: Thought pro-
tial reasoning (e.g. across several sentences), a focus of our           cesses underlying a common misconception. Journal for
current work.                                                            Research in Mathematics Education, 13(1), 16–30.
   Another aim is to investigate what interventions are most            Clement, J., Lochhead, J., & Monk, G.S. (1981) Translation
appropriate for instances of the different kinds of errors               difficulties in learning mathematics. The American Mathe-
within the taxonomy. Instead of responding to all incorrect              matical Monthly, 88(4), 286–290.
answers with a bald statement of fact as currently delivered            Chi, M. T. H. (1997) Quantifying qualitative analyses of ver-
by the Grade Grinder, we might instead report on the pres-               bal data. Journal of the Learning Sciences, 6(3), 271–315.
ence of substitution errors in a different way to antecedant–           Geis, M.C. & Zwicky, A.M. (1971) On invited inferences.
consequent reversal, for example.                                        Linguistic Enquiry, 2, 561-566.
   In addition to cross-subject analyses such as those pre-             Grice, H.P. (1975) Logic and conversation. In P. Cole & J.
sented here, the Grade Grinder error corpus affords us the               Morgan, (eds.), Syntax and Semantics: Vol 3. Speech Acts.
opportunity to examine within-subject effects, since we can              London: Academic Press.
identify sequences of attempts by a single student to solve an          Reason, J. (1990) Human Error. Cambridge, UK: Cam-
exercise, or sequence of exercises. As an intervention, we               bridge University Press.
may be able to present a student with a profile of the errors           Stenning, K. & Cox, R. (2006) Reconnecting interpretation
that they are prone to commit, together with appropriate ad-             to reasoning through individual differences. The Quarterly
vice for avoiding those errors.                                          Journal of Experimental Psychology, 59 (8), 1454–1483.
                                                                        Stenning, K. & van Lambalgen, M. (2001) Semantics as a
Conclusion                                                               foundation for psychology: A case study of Wason’s selec-
Our results have illustrated how it is possible to use empirical         tion task. Journal of Logic, Language and Information, 10,
data gathered on a large scale to gain insights into the diffi-          273–317.
culty that students have when learning to translate sentences           Viera, A.J. & Garrett, J.M. (2005) Understanding interob-
from FOL into NL. We believe that these insights can improve             server agreement: The kappa statistic. Family Medicine,
the standard of logic teaching (with or without the use of LPL,          37(5), 360–363.
or software support) and other related areas such as mathe-             Wing, J. (2006) Computational thinking. Communications
matics and computer science. General observations such as                of the ACM, 49(3), 33-35.
                                                                  510

