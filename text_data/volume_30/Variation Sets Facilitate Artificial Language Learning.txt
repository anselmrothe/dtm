UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Variation Sets Facilitate Artificial Language Learning
Permalink
https://escholarship.org/uc/item/321985fw
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Onnis, Luca
Waterfall, Heidi
Edelman, Shimon
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                    Powered by the California Digital Library
                                                                     University of California

                  Variation Sets Facilitate Artificial Language Learning
                 Luca Onnis (lo35@cornell.edu)                    Heidi Waterfall (he32@cornell.edu)1
                                        Shimon Edelman (se37@cornell.edu)
                                        Department of Psychology, Cornell University
                                                     Ithaca, NY 14853 USA
                           Abstract                               others change. Specifically, local alignment of (1b) and
                                                                  (2b) suggests that (1b) is composed of at least three el-
   Variation set structure — partial alignment of successive
   utterances in child-directed speech — has been shown           ements:
   to correlate with progress in the acquisition of syntax
   by children. The present study demonstrates that ar-           (1c) kedmalbu rafuloro pesai
   ranging a certain proportion of utterances in a train-         (2c) -------- rafuloro -----
   ing corpus in variation sets facilitates word segmenta-
   tion and phrase structure learning in miniature artifi-        Aligning the next pair yields new elements:
   cial languages by adults. Our findings have implications
   for understanding the mechanisms of L1 acquisition by          (2c) rafu loro -----
   children, and for the development of more efficient al-        (3c) mana loro pesai
   gorithms for automatic language acquisition, as well as
   better methods for L2 instruction.                             Further,
   Keywords: language acquisition, grammar inference,             (3c) -------- mana loro pesai
   artificial language learning, implicit learning, variation
   sets, child-directed speech.                                   (4c) kedmalbu mana loro pesai
                                                                  The property of sample (1b-4b) that afford this discov-
      Variation sets in language learning                         ery, which is absent from sample (1a-4a), is that its suc-
Imagine entering a room and overhearing the following             cessive utterances form partial self-repetitions, or varia-
round of conversation in an unfamiliar language:                  tion sets.
(1a)   kedmalburafuloropesai                                         Variation sets are a prominent feature of child-directed
(2a)   gianaber                                                   speech:2 about 20% of utterances in child-directed
(3a)   manadukbiunel                                              speech appear within variation sets, whose prevalence
(4a)   kiciorudanamjeisulcaz                                      and composition has been shown to facilitate lexical and
                                                                  syntactic development (Hoff-Ginsberg, 1986; Küntay and
Not surprisingly, you cannot even make out the individ-           Slobin, 1996; for recent reviews and results, see Water-
ual words in any of those utterances (represented here in         fall, 2007a,b). Indeed, our second example (1b-4b) comes
print by unbroken sequences of letters). Now, suppose             from a snippet of a real corpus — a variation set ad-
the utterances you overheard were these:                          dressed to a 14 month old child studied by Waterfall, in
(1b)   kedmalburafuloropesai                                      which we replaced the English words with nonce strings:
(2b)   rafuloro                                                   You got to push them to school.
(3b)   manaloropesai                                              Push them.
(4b)   kedmalbumanaloropesai                                      Push them to school.
Because these four utterances appear related to each              Take them to school.
other, this sample (unlike the previous one) affords a            You got to take them to school.
glimpse of some of the structures behind the unfamiliar              From a cognitive computational standpoint, the key
language. These structures are readily revealed by the            characteristic of variation sets is that the structure they
two computational operations proposed by Zellig Harris            contain can be revealed by a local mechanism that aligns
(1946) for language discovery: alignment of utterances            and compares adjacent utterances. This characteristic
and their subsequent comparison (when applied recur-              allows even memory-limited learners to discover struc-
sively along with statistical control over structure infer-       ture that they would miss, if the relatable utterances
ence, this approach proved effective in unsupervised lan-         were scattered over a longer exchange.
guage acquisition from raw corpora; Solan, Horn, Rup-                In addition to facilitating the segmentation of ut-
pin, and Edelman, 2005). In the present example, sim-             terances into lexical elements, variation sets can yield
ple, “local” alignment of successive utterances immedi-           higher-order structural properties of the language. For
ately reveals that some sequences of letters repeat, while
                                                                      2
                                                                        There are indications that variation sets are also preva-
    1
      Also with the Department of Psychology, University of       lent in adult conversations (Pickering and Garrod, 2004; Szm-
Chicago, Chicago, IL 60637 USA.                                   recsanyi, 2005).
                                                              1011

example, the material replicated across the first two            where A = {da, kozi, spinose}, B = {pera, kadro,
sentences, push them, is a verb phrase. Thus, align-             fama, zupa}, and C = {piu, prati, guklozi}. In this
ment and comparison would break the first sentence               miniature language, the classes A, B, and C can be
into three constituents, corresponding respectively to           conceived of as lexical categories containing respectively
the main clause (you got to), verb phrase (push them),           three, four, and three lexical items. A sample sentence
and participial phrase (to school).                              from this language, which consists of 3 × 4 × 3 = 36
   To assure safe generalization, any corpus-based infer-        unique sentences, is S → da pera guklozi.
ence about structure needs to pass a test of statistical sig-       The actual sound sequence presented to participants
nificance (Edelman and Waterfall, 2007). Given a vari-           in the learning phase was generated as follows. For
ation set, the null hypothesis is that of chance partial         each sentence, white spaces were removed (e.g., da pera
alignment of the utterances. The learner may test it by          guklozi → daperaguklozi) and each letter was mapped
comparing the dissimilarity between the utterances to a          into a single phoneme. We used the MBROLA speech
baseline value — e.g., the cumulative average dissimilar-        synthesizer (Dutoit, 1997) to convert the resulting se-
ity for the corpus at hand. A convenient measure of the          quences into sound files, using a constant length of 80 ms
dissimilarity between two strings of words is their Leven-       for consonants and 260 ms for vowels. We selected the
shtein (edit) distance, defined as the smallest number of        Italian diphone set of phonemes in MBROLA for two
(possibly individually weighted) elementary edit opera-          reasons. First, we intended to give participants the im-
tions — insertions, deletions, and substitutions of words        pression that they were engaged in a foreign language
— that transform one string into another.                        learning task. Second, the Italian diphone set appears
   In the present project, we set out to study the effects       to provide clearer and cleaner phonetic realizations of
of variation sets on language acquisition in a controlled        phonemes than the English one, when instantiated in
situation involving miniature artificial languages. Small-       flat-prosody artificial words like ours. All phonemes had
scale artificial languages generated by simple grammars          an equivalent phonemic realization in English and were
have long been used in controlled studies of language            thus familiar enough to English speakers.
acquisition (Reber, 1967; Miller, 1968). Because the ut-
                                                                    In this manner, the text-to-speech conversion proce-
terances generated by an artificial grammar from a nonce
                                                                 dure generated for each sentence a seamless stream of
lexicon are novel for the learners, who are also unaware
                                                                 phonemes in which no acoustic property signaled the
of the experimental manipulation, it is possible to gauge
                                                                 beginning and end of a word, except at the sentence
the learnability of various properties of the language af-
                                                                 boundaries, where 800 ms pauses were inserted. Sen-
ter a relatively brief exposure to samples drawn from it.
                                                                 tences were presented to the subject via headphones. A
This paradigm proved useful in studying aspects of in-
                                                                 total of 106 sentences were presented during the learn-
fant language learning, including segmentation (Saffran,
                                                                 ing phase. Because the A and C words varied in syllable
Aslin, and Newport, 1996), and sensitivity to the or-
                                                                 length (1-3 syllables), sentence length varied from a min-
dering or words and to abstract patterns (Gómez and
                                                                 imum of 4 syllables to a maximum of 10 syllables. This
Gerken, 2000). Moreover, neural signatures of gram-
                                                                 variability ensured that participants did not adopt seg-
matical violations in artificial languages are similar to
                                                                 mentation strategies based on perceiving words as regu-
those evoked by structural violations in natural language
                                                                 lar patterns of equal length.
(Christiansen, Conway, and Onnis, 2007).
   In the two experiments reported below, subjects                  In the test phase, we administered a forced-choice test
learned, respectively, to segment continuous utterances          between words and part-words, where part-words were
into word-like units, and to group these into phrasal cat-       defined as syllable sequences straddling word boundaries.
egories. We hypothesized that learning would be signifi-         A participant who succeeded to individuate the words in
cantly more efficient when some of the utterances in the         the learning phase should reliably prefer words over part-
learning phase are arranged in variation sets.                   words. As test words we used the four bisyllabic words
                                                                 that appeared always in the sentence-middle position
         Experiment 1: learning word                             (B words: {pera, kadro, fama, zupa}). As test part-
                     segmentation                                words, we chose 8 out of the 20 bisyllabic segments that
                                                                 straddled word boundaries. For instance, in the segment
Experiment 1 tested the subjects’ ability to segment con-
                                                                 kozipera, zipe was a part-word formed by the last syl-
tinuous speech into word-like units.
                                                                 lable of kozi and the first syllable of pera. Acoustically,
Participants and materials. The subjects, 31 Cornell
                                                                 both words and part-words were equally potentially good
students, were paid $4. In the learning phase, partici-
                                                                 word candidates, because (i) during the learning phase
pants listened to a sequence of utterances (“sentences”)
                                                                 they had been generated as a seamless chain of phonemes
consisting of concatenated “words.” The sentences were
                                                                 in each sentence, and (ii) both words and part-words
generated by a simple rewrite rule:
                                                                 were synthesized anew rather than being sliced up as
S→ABC                                                            fragment recombinations of syllables from the sentences.
                                                             1012

   Words and part-words had different statistical prop-                                                 Exp.1: Distances Between Successive Utterances
erties. Words had high word-internal transitional prob-
                                                                                              1
abilities between syllables (e.g., T P (ra|pe) = 1), while
part-words had low word-internal transitional probabili-
ties (e.g., T P (pe|zi) = 0.25). In addition, the test words
                                                                  normalized edit distance
                                                                                             0.8
had a much higher frequency (mean frequency = 25.75,
sd = 0.96) than the part-words (mean frequency = 8.5,
                                                                                             0.6
sd = 0.51). As suggested by the finding that both adults
and infants are sensitive to loci of high and low transi-
tional probability and use them to group syllables into                                      0.4
word-like units (Saffran et al., 1996), we anticipated that
the words in this language could be discovered and pre-
                                                                                             0.2
ferred over part-words because both their word-internal
TPs and raw frequencies were higher than those of part-
words.                                                                                        0
                                                                                                   0   10   20   30    40   50    60     70   80   90    100
   The four test words were presented twice in counter-                                                               utterance number
balanced order, each time with a different part-word:
one that contained the first syllable of the word, and         Figure 1: Edit distances dn between successive utter-
one that contained its second syllable. For instance, the      ances (n and n + 1) in the Varset training data of Ex-
word pera was paired with both zipe and ragu. For              periment 1, plotted P against n. Solid line: cumulative av-
each pair, participants had to chose which one was a                                   n
                                                               erage davg = (1/n) i=1 di . (·): pairs for which dn and
word.                                                          davg do not differ significantly according to a 2-sided t-
Procedure. Participants were told they were going to           test. (∗): dn < davg . (◦): dn > davg . (×) at the bottom
listen to a miniature language containing new words, a         of the plot denotes alignable pair. Note that the cumu-
situation akin to a child learning its first language, or to   lative statistics of the edit distance values reveal most
an adult trying to figure out a foreign language. They         of the alignments, where they exist, to be significant. A
were encouraged to listen attentively and find words in        learner can rely on this feature of the training corpus in
the speech. Participants were randomly and blindly as-         distinguishing between significant and spurious patterns
signed to one of two learning conditions, Varset and           in structure discovery.
Scrambled, which consisted of exactly the same sentences
that differed in the order of presentation. In the Scram-      kosizupaguklozi
bled condition, which served as the control, sentences         kosiperapiu
were presented in pseudo-random order such that no two         kosizupaguklozi
adjacent sentences shared any lexical items. This condi-       daperaprati (Scrambled block starts here)
tion established a baseline for how much learning would        kosifamapiu
take place in the absence of variation set structure. A        dazupaprati
sample of the sequence from the Scrambled condition            spinozekadroguklozi
appears below:
                                                                  An analysis of edit distances between successive sen-
kosifamapiu
                                                               tences in the training data in the Varset condition (Fig-
spinozeperaguklozi
                                                               ure 1) reveals that in almost every variation set, the
kosifamapiu
                                                               edit distance between the two sentences is significantly
daperaguklozi
                                                               smaller than the baseline provided by the cumulative av-
spinozefamaprati
                                                               erage. We note that a learner sensitive to this statistic
daperapiu
                                                               could use it to distinguish between significant and spu-
   In contrast, sentences in the Varset condition were         rious patterns in structure discovery.
pseudo-randomly ordered such that 20% of adjacent sen-            The learning phase lasted 5 minutes. Before the test,
tences contained one overlapping lexical item. The re-         participants were told that they would have to choose
maining 80% satisfied the same criterion as in the Scram-      between two sounds, one of which would be a word and
bled condition (i.e., no lexical overlap between adjacent      the other a part-word.
sentences). Varset and Scrambled sentences alternated          Results. The subjects’ performance in Experiment 1
in blocks: 6 blocks of 4 Varset sentences alternated with      is summarized in the form of a box-and-whiskers plot
6 blocks of 13 or 14 Scrambled sentences. A sample of          in Figure 2, left. Subjects in the Varset condition
the Varset condition is given below:                           preferred words over part-words on the average 5.74
daperapiu                                                      times out of 8, which is significantly better than chance
kosifamapiu (Varset block starts here)                         (t(18) = 6.34, p < .001). In contrast, subjects in the
                                                           1013

                   by Subject                by Item                 by Subject                by Item
                                                                                                                    the learning phase, subjects listened to sentences con-
             1.0                      1.0                      1.0                      1.0
                                                                                                                    taining pseudo-words. The sequences were generated by
                                                                                                                    the following phrase structure rules:
             0.8
                               ●
                                      0.8
                                                        ●
                                                               0.8
                                                                                 ●
                                                                                        0.8
                                                                                                          ●
                                                                                                                    S1 (.70)   → Phrase1 Phrase2 Phrase3
                                                                                                                    S2 (.25)   → Phrase1 Phrase2
Mean Score
                      ●                                                 ●                        ●
             0.6                      0.6
                                               ●
                                                               0.6                      0.6
                                                                                                                    S3 (.05)   → Phrase3 Phrase2 Phrase1
                                                                                                                    Phrase1    (.92) → A B
             0.4                      0.4                      0.4                      0.4
                                                                                                                    Phrase1    (.08) → G
                               ●
             0.2                      0.2                      0.2                      0.2
                                                                                                  ●
                                                                                                                    Phrase2    (1.0) → C D
                                                                                                                    Phrase3    (1.0) → E F
                   scrambled varset         scrambled varset         scrambled varset         scrambled varset         As in the description of Experiment 1, capital letters
                                                                                                                    stand for lexical categories containing one or three words
                                                                                                                    (A = {a1,a2,a3}, B = {b1,b2,b3}, C = {c1,c2,c3}, D
             Figure 2: distribution of mean scores by subject and by                                                = {d1,d2,d3}, E = {e1,e2,e3}, F = {f1,f2,f3}, and
             item in Experiments 1 (left two plots) and 2.                                                          G = {g1}).3        The resulting language consisted of
                                                                                                                    sentences with two or three phrases, with Phrase3
             Scrambled condition preferred words over part-words on                                                 being optional at the end of the sentence or being
             the average 4.47 out of 8 (t(16) = 1.19, p = .25, n.s.).                                               moved in first position. Phrase1 contained either two
             In addition, Varset scores were significantly better than                                              words from categories A and B, or a substituting word
             Scrambled (t(34) = 2.68, p = .011). This difference was                                                g1. Sentences and phrases were generated according
             confirmed by a nonparametric Kruskal-Wallis rank sum                                                   to the probabilities indicated in parentheses next to
             test, which yielded χ2 = 15.628, p < 0.000077.                                                         the each rule. Sentence length ranged from 3 to 6
                Because effects that turn out significant in separate                                               words. No feature of individual words other than their
             by-subject and by-item analyses may still be unreli-                                                   distribution in the sentences signaled their class mem-
             able when all the random effects are considered jointly                                                bership. The actual lexical items were the following 19
             (Baayen, 2006), we also fit a mixed linear model to the                                                monosyllabic pseudo-words: arv, bim, skiv, cree,
             data using the lme4 package (Bates, 2005). In addition                                                 dro, goz, heeb, irg, tood, kleep, kuhl, larp,
             to offering a more reliable picture of the data by accom-                                              mib, nerk, tiv, plam, yent, quive, roo, boont,
             modating crossed subject and item random effects, lmer                                                 silg, slar, smir, nork, vit, whap, plid, ziln,
             tolerates unbalanced data (as when the numbers of sub-                                                 ziz. Words for each participant were randomly assigned
             jects per condition differ), and also allows one to specify                                            to the lexical items a1, a2, . . . , g1, and were recorded
             a distribution other than normal. A binomial logit-link                                                by a trained female voice.
             mixed linear model fit to the scores yielded a significant                                                For the learning phase, we selected 365 sentences,
             effect of condition, z = 2.688, p < 0.00719, confirming                                                which were arranged differently in Scrambled and Varset
             the outcome of the t-tests reported above.                                                             conditions. As in Experiment 1, no adjacent sentences
                Thus, subjects failed to find words in unsegmented                                                  in the Scrambled condition shared any lexical item. In
             speech in the Scrambled condition, despite transitional                                                the Varset condition, 20% of sentences contained par-
             probabilities supporting segmentation. At the same                                                     tially overlapping lexical items that coincided with the
             time, in the Varset condition, in which 20% of the                                                     phrases:
             sentences formed variation sets in the learning phase,
             subjects performed significantly better, and better than                                               GCD
             chance.                                                                                                ABCD
                                                                                                                    ABCDEF
               Experiment 2: learning phrase structure                                                              EFABCD
                                                                                                                    GABCD
             Identifying word boundaries in continuous speech allows
                                                                                                                    ABCDG
             the learner to acquire the lexicon. This ability, in turn,
             sets the stage for discovering in sentences patterns such                                                 Between the first and second sentences in the above
             as phrase structure. In Experiment 2, we asked whether                                                 list, the classes ’C D’ (and their elements), which belong
             the presence of variation sets facilitates the learning of                                             to Phrase2, remain constant, while ’A B’ replaced ’G’,
             phrase structure. In particular, we were interested in                                                 which are both instantiations of Phrase1. There were
             testing whether the ability to discover phrases improves                                               10 blocks of variation sets interleaved with 10 blocks of
             when the partial lexical variation between adjacent sen-                                               sentences arranged in scrambled order. Each variation
             tences is consistent with phrasal constituency structure.                                                 3
                                                                                                                         In our notation, numbered lowercase letters are place-
             Participants and materials. The subjects, 29 Cor-                                                      holders for pseudo-words that were selected in a different or-
             nell students, were paid $6 for their participation. In                                                der by the software running the experiment.
                                                                                                                 1014

                                        Exp.2: Distances Between Successive Utterances            Learning lasted 18 minutes. In each trial, the subjects
                                                                                                  had to choose the stimulus that they deemed more likely
                              1
                                                                                                  to be a group or unit in the language.
                                                                                                  Results. The subjects’ performance in Experiment 2 is
                                                                                                  summarized in Figure 2. Subjects in the Varset condi-
  normalized edit distance
                             0.8
                                                                                                  tion preferred phrases over part-phrases with on the av-
                                                                                                  erage 9.07 times out of 12, which is significantly better
                             0.6
                                                                                                  than chance (t(14) = 6.35, p < 0.001). Subjects in the
                                                                                                  Scrambled condition preferred phrases over part-phrases
                             0.4                                                                  on the average 7.36 times out of 12, which is also better
                                                                                                  than chance (t(13) = 3.085, p < .01). In addition, learn-
                                                                                                  ing in the Varset condition was significantly better than
                             0.2
                                                                                                  in the Scrambled condition (t(27) = 2.60, p < 0.015).
                                                                                                  This difference was confirmed by a Kruskal-Wallis test,
                              0                                                                   χ2 = 16.37, p < 0.00052. Thus, while learning did occur
                                   0   10   20   30    40   50    60     70   80   90    100
                                                      utterance number                            in both conditions, it was significantly better when vari-
                                                                                                  ation sets were present in the learning phase. A binomial
Figure 3: The first 100 edit distances between successive                                         logit-link mixed linear model fit to the scores yielded a
utterances in Experiment 2 (for the legend, see Figure 1).                                        significant effect of condition, z = 2.678, p < 0.0074,
As in Experiment 1, the cumulative statistics of the edit                                         confirming this conclusion.
distance values indicate that the alignments, where they
exist, are significant, with a few exceptions.                                                                          Discussion
                                                                                                  Our results, obtained with miniature language learning
set contained 6 sentences, with only one change between
                                                                                                  environments, indicate that the presence of variation sets
any two adjacent sentences. Unlike in Experiment 1,
                                                                                                  in the learner’s input, in the same proportion as in real
words were now separated by 300 ms pauses; sentences
                                                                                                  child-directed speech (20%), facilitates the discovery of
were separated by 750 ms. Because all words were sep-
                                                                                                  linguistic structure at two different levels of analysis:
arated by the same pause length and were generated by
                                                                                                  finding words in continuous speech, and identifying the
the MBROLA synthesizer without prosody or phoneme
                                                                                                  phrasal constituents of sentences. Variation sets offer
lengthening, no acoustic feature signaled the presence of
                                                                                                  immediate and effective cues to linguistic structure by
phrase boundaries.
                                                                                                  making it possible for the learner to resort to local (hence
  The research question was whether participants in the                                           computationally inexpensive) and, crucially, statistically
Varset condition would exploit variation sets to carry                                            verifiable procedures based on alignment and compari-
out a primitive alignment and grouping of words into                                              son of successive utterances.
phrasal constituents, e.g., whether they would judge a                                               Current unsupervised computational approaches to
’C D’ pairing more likely than a ’D E’ pairing. Conse-                                            finding structure typically rely on global cues, in that
quently, the test phase was a forced-choice task consist-                                         they amass statistical evidence over the entire learning
ing of 12 trials, with three trials testing each of the three                                     experience (be it within an experimental session of six
phrase types (’A B’, ’C D’, ’E F’). A trial presented two                                         minutes, or over a sample corpus of language) to in-
pairs of words, one phrase pair (e.g., ’C D’) and one pair                                        fer the reliability of candidate structures. This is true
that was a legal sequence in the language but straddled                                           both in lexicon learning (e.g., Brent, 1999) and in syn-
a phrase boundary (e.g., ’D E’). As in Experiment 1, an                                           tax learning (e.g., Solan, Horn, Ruppin, and Edelman,
analysis of edit distances between successive sentences                                           2005). This makes global approaches computationally
in the training data in the Varset condition (Figure 3)                                           costly (for example, requiring a word learning algorithm
reveals that in most variation sets, the edit distance be-                                        to maintain all possible candidate segmentations), as
tween the two sentences is significantly smaller than the                                         well as cognitively implausible.
baseline provided by the cumulative average.                                                         Indeed, the lack of learning of our subjects in the
Procedure. Subjects were randomly assigned to either                                              Scrambled condition of Experiment 1 suggests that
the Varset or Scrambled condition. They were told that                                            global, combinatorially promiscuous alignment is not re-
they were participating in an experiment about learning                                           sorted to even for a small lexicon. Given the small lexi-
a new language, and that they should try to individuate                                           con in Experiment 1, spurious variation sets interleaved
the basic phrasal constituents of the sentences. As an                                            by one or two sentences were likely to occur, and yet
example, the English sentence “My brother plays Nin-                                              subjects did not seem to have used such non-local align-
tendo at night” was described as having the following                                             ments. In contrast, in the Varset condition, in which
grouping: “(My brother) (plays Nintendo) (at night).”                                             local alignment cues were present, learning did occur,
                                                                                               1015

even for words that did not participate in variation sets      Christiansen, M. H., C. Conway, and L. Onnis (2007).
in training. Presumably, once lexical candidates are re-         Neural responses to structural incongruencies in lan-
vealed in a variation set, they are also more recognizable       guage and statistical learning point to similar underly-
when they occur in other sentences, thus promoting in            ing mechanisms. In Proc. of the 29th Annual Meeting
turn the segmentation of novel words.                            of the Cognitive Science Society, pp. –.
   The results of our Experiment 2 may be compared             Dutoit, T. (1997). An Introduction to Text-To-Speech
to earlier work in artificial language learning that used        Synthesis. Dordrecht: Kluwer.
cross-sentential cues such as that of Morgan, Meier, and       Edelman, S. and H. R. Waterfall (2007). Behavioral and
Newport (1989). These researchers found that when                computational aspects of language and its acquisition.
an artificial grammar was augmented with substitution            Physics of Life Reviews 4, 253–277.
phrases and variations in order of permutation between         Gómez, R. L. and L. Gerken (2000). Infant artificial
phrases, learning improved with respect to a baseline            language learning and language acquisition. Trends in
condition that contained no such variations, and whose           Cognitive Sciences 4, 178–186.
adjacent sentences were merely repeated. The stimuli of        Harris, Z. S. (1946). From morpheme to utterance. Lan-
Morgan et al. (1989), which included visual cues to cat-         guage 22, 161–183.
egory membership, consisted of pairs of aligned written        Hoff-Ginsberg, E. (1986). Function and structure in ma-
sentences and geometrical figures on the screen. In our          ternal speech: their relation to the child’s development
experiments, in comparison, sentences were presented se-         of syntax. Developmental Psychology 22, 155–163.
quentially in their natural auditory modality.                 Küntay, A. and D. Slobin (1996). Listening to a Turkish
   In a recent study, Thompson and Newport (2007) ex-            mother: Some puzzles for acquisition. In D. Slobin and
amined the effects on syntax learning of partially over-         J. Gerhardt (Eds.), Social interaction, social context,
lapping material between sentences, presented in the au-         and language: Essays in honor of Susan Ervin-Tripp,
ditory modality. They did not, however, control the              pp. 265–286. Hillsdale, NJ: Erlbaum.
variation sets as such; rather, they constructed increas-      Miller, G. A. (1968). The psychology of communication:
ingly more complex languages that gave rise to more              Seven essays. Harmondworth, UK: Penguin Books.
variation sets, and were able to show that more complex        Morgan, J. L., R. P. Meier, and E. L. Newport (1989).
grammars could actually be easier to learn. In contrast,         Facilitating the acquisition of syntax with cross-
our experiments are the first ones to manipulate only            sentential cues to phrase structure. Journal of Memory
the order of presentation of the stimuli (the variation          and Language 28, 360–374.
sets), while maintaining the same complexity of the lan-       Pickering, M. J. and S. Garrod (2004). Toward a mech-
guage across learning conditions (indeed, the very same          anistic psychology of dialogue. Behavioral and Brain
sentences where used in both conditions in each experi-          Sciences 27, 169–225.
ment).                                                         Reber, A. S. (1967). Implicit learning of artificial gram-
   In summary, the positive effects of variation sets in         mars. Journal of Verbal Learning and Verbal Behav-
the two experiments reported here suggest that learners          ior 6, 855–863.
can reuse the same algorithmic building blocks — align-        Saffran, J. R., R. N. Aslin, and E. L. Newport (1996).
ment, comparison, and, presumably, significance assess-          Statistical learning by 8-month-old infants. Sci-
ment — at different levels of linguistic structure (here,        ence 274, 1926–1928.
lexical and phrasal units). We are presently extending         Solan, Z., D. Horn, E. Ruppin, and S. Edelman (2005).
our approach to investigate whether variation sets also          Unsupervised learning of natural languages. Proceed-
facilitate the learning of other core features of language,      ings of the National Academy of Science 102, 11629–
such as lexical categorization, long-distance dependen-          11634.
cies, and recursion.                                           Szmrecsanyi, B. (2005). Language users as creatures of
Acknowledgment. LO was supported by NICHD Grant                  habit: A corpus-based analysis of persistence in spo-
5R03HD051671-02.                                                 ken English. Corpus Linguistics and Linguistic The-
                                                                 ory 1, 113–149.
                                                               Thompson, S. P. and E. L. Newport (2007). Statistical
                      References
                                                                 learning of syntax: the role of transitional probability.
Baayen, R. H. (2006). Analyzing linguistic data: A prac-         Language Learning and Development 3, 1–42.
   tical introduction to statistics using R. Cambridge:        Waterfall, H. R. (2007a). Relation of variation sets to
   Cambridge University Press.                                   noun and verb development. Submitted.
Bates, D. (2005). Fitting linear mixed models in R. R          Waterfall, H. R. (2007b). Relation of variation sets to
   News 5, 27–30.                                                syntactic development. Submitted.
Brent, M. R. (1999). An efficient, probabilistically sound
   algorithm for segmentation and word discovery. Ma-
   chine Learning 34, 71–105.
                                                           1016

