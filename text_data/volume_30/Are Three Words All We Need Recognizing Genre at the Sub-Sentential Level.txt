UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Are Three Words All We Need? Recognizing Genre at the Sub-Sentential Level
Permalink
https://escholarship.org/uc/item/73s699d9
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
McCarthy, Philip M.
Briner, Stephen W.W.
Myers, John C.
et al.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

                                               Are Three Words All We Need?
                                 Recognizing Genre at the Sub-Sentential Level
                                            Philip M. McCarthy (pmmccrth@memphis.edu)
                                 Department of English, The University of Memphis, Memphis. TN 38152
                                              Stephen W. Briner (sbriner@depaul.edu)
                                   Department of Psychology, DePaul University, Chicago, IL 60614
                                                  John C. Myers (jcmyers@memphis.edu)
                                             Arthur C. Graesser (a-graesser@memphis.edu)
                                          Danielle S. McNamara (dsmcnamr@memphis.edu)
                               Department of Psychology, The University of Memphis, Memphis. TN 38152
                            Abstract                                    comprehension. If readers are indeed using different
Genre identification is a critical facet of text comprehension, but     strategies to process different genres of text, then it is
very little is known about the process and information                  important to understand this process and potential
constraints of classifying texts by genres. In this study, higher-      information constraints during the course of genre
skill and lower-skill participants read 210 sentences from three        identification.
genres. The words in the sentences were presented sequentially,              We ask five questions in the current study. First, how
one at a time. With each new word, participants decided whether         quickly (in terms of number of words) do readers identify
the sentences came from a narrative, science, or history text.          the genre of a text? Second, what types of errors (i.e.,
Both groups were able to correctly identify the genre by the            genre misclassifications) do readers make when
third word of the sentence. Higher-skilled readers made their
                                                                        identifying genres? Third, does the process of genre
genre decisions more quickly and more accurately, and were
also more precise in their selection of narrative texts. The study      identification depend on reading skill? Fourth, what
includes a computational model that uses text features from only        textual features (e.g., syntax, lexical choice) influence
the first three words of the sentences. The model reflects key          genre identification? And fifth, can a computational
features of the participants’ genre classifications.                    model categorize genre as humans do, using information
                                                                        available in only the initial words of sentences?
Keywords: genre recognition; reading skill; categorization                   In McCarthy and McNamara (2007), we conducted a
                                                                        pilot study to provide a preliminary answer to our first
                          Introduction                                  two questions. Three experts (i.e. published authors) in
Reading comprehension is greatly influenced by the genre                the psychology of discourse processing were asked to
of the text. Whether a text is a narrative, history, or                 identify the genre of isolated sentences culled from a
science text influences the characteristics of the text, how            corpus of narrative, history, and science texts. The experts
the text is read, and can have a substantial influence on               had high inter-rater agreement (min = 90%) and required
how well it will be understood (Bhatia, 1997; Graesser,                 less than half the words in the sentence to accurately
Olde, & Klettke, 2002; Zwaan, 1993). More skilled                       identify genres (accuracy as measured by F1, a standard
readers utilize different strategies depending on the genre             index that considers both recall and precision: Narrative =
of the text (van Dijk & Kintsch, 1983; Zwaan, 1993) and                 .82; History = .84; Science = .82). The results further
training readers to recognize text structure helps to                   showed that these experts often classified many history
improve their comprehension (Meyer & Wijekumar,                         and science sentences as narrative, suggesting that
2007; Oakhill & Cain, 2007; Williams, 2007). Once text                  expository texts tend to be composed of a notable number
genre is identified, it guides the reader’s memory                      of narrative-like sentences. On the other hand, science-
activations,      expectations,       inferences,      depth     of     like sentences were the least likely to be misclassified into
comprehension, evaluation of truth and relevance,                       other genres, suggesting the science-like sentences
pragmatic ground-rules, and other psychological                         seldom occur in the non-science genres.
mechanisms. For example, readers are more likely to                          The current study builds on the study conducted by
scrutinize whether an event actually occurred in a history              McCarthy and McNamara (2007) by including a larger
text, whereas that is not a particularly relevant                       sample of participants, an independent assessment of
consideration in most narrative fiction (Coleridge, 1985;               reading ability, a measure of time on task, and recording
Gerrig, 1993). In contrast, stylistic attributes are more               accuracy in terms of number of words used. We also
important in literary narratives than expository texts                  construct a computational model based on our results. We
(Zwaan, 1993).                                                          use the model to investigate what information could be
      Better understanding the nature of text genre and its             present in the initial words of sentences such that it can
effects on comprehension is important for theories of text              provide participants with sufficient information to make a
comprehension as well as interventions to improve                       genre evaluation. The question of whether or not we could
                                                                    613

build a computational model was important because if                Assessments. To assess reading skill, we used the Gates-
such relatively shallow features as syntax and word                 MacGinitie (GM) reading test, a multiple-choice test
frequency information are sufficient for readers to                 consisting of 48 questions designed to measure reading
distinguish genres, then it is reasonable to assume that (at        comprehension. We used the level 10/12 version of the test,
some level) readers are using this information to process           which has a reliability of .93 (MacGinitie et al, 2002).
and categorize input. Our computational model sheds                      Participants’ genre recognition was evaluated using a
light on the features of the text that most likely influences       Visual Basic program modified from McCarthy and
readers’ genre classifications.                                     McNamara (2007). The program consisted of three parts:
                                                                    instructions, practice examples, and testing. After
                          Corpus                                    viewing the instructions, participants were given six
The corpus (as used in McCarthy & McNamara, 2007)                   practice sentences. For the testing section, each
comprises 210 sentences including 70 sentences from each            participant evaluated 210 sentences presented in a random
genre (narrative, history, science). The sentences were             order. The program displayed the first word of the first
compiled using corpora from two prior studies (Duran et             sentence in a text window. Participants were required to
al., 2007; McCarthy et al., 2007), which included 23                select which genre they thought the sentence fragment
paragraphs each of 3, 4, and 5 sentences in length. Sentence        belonged to. Participants made their selection by clicking
selection from these paragraphs was guided by studies               on one of four on-screen buttons: Narrative, History,
indicating that topic sentences are processed differently           Science, and Don’t Know. The buttons’ position was
from other sentences in a paragraph (e.g., Kieras, 1978) and        randomized such that the genre choice could appear in
that topic sentences are more likely to occur in the                any of the four buttons. Upon selecting one of the buttons,
paragraph initial position (Kieras, 1978, McCarthy et al.,          the mouse cursor returned to a central position so that
2007). Thus, we sampled an equal number of paragraph-               each button was always equidistant from the start point of
initial sentences and paragraph-non-initial sentences. For          the cursor. As soon as a genre choice had been made, the
the latter, we used the third sentence of each paragraph            next word from the sentence appeared in the text window.
because all paragraphs contained a third sentence and               All punctuation was retained in the display and was
because third-sentences are presumably less closely related         attached to the word it adjoined (e.g., in the sentence
via co-reference and other semantic attributes to first-            fragment Yes, it was … the word Yes would appear as Yes
sentences than first-sentences are to second-sentences. To          + comma.) After 10 seconds, if the participant had not yet
ensure that participants viewed sentences of approximately          made a choice, a new word automatically appeared in the
equal length, we included sentences that were within one            text window along with a message informing the
standard deviation of the average length among 414                  participant of the new word. Three variables were
candidate sentences (M = 15.44 words; SD = 7.11). This              recorded: genre choice, accuracy, and time on task.
resulted in a corpus of 210 sentences, equally representing         Participants evaluated each word of each sentence until
the three genres and the initial/non-initial sentence               they had either given the same decision of the genre of the
dichotomy1. An example of a history sentence was Because            sentence three consecutive times (whether right or
of the fragmented nature of Mayan society, the different            wrong), or until all the words in the sentence had been
cities frequently went to war. An example of a narrative            presented. Thus, participants viewed a minimum of three
sentence was The sweat from my other hand reduced the               words.
answers on my palm to a blue smudge. An example of a                     One difference between the current study and
science sentence was Likewise, it's easier to express the           McCarthy and McNamara (2007) is the calculation of
concentration of a solution as the number of moles of               number of words used in the sentence by the participant to
material dissolved in it.                                           recognize genre. In the previous study, if five words were
                                                                    viewed then the number of words to make a decision was
                          Methods                                   considered five. That is, the final two words, which are all
                                                                    evaluated as the same genre, were also included in the
Participants. There were 22 participants (Male = 10,                count. However, in this study, the number of words is
Female = 12; M = 24.1 years old) who received $50 in                calculated based on the first time the participant makes a
exchange for participation. All participants were native            choice that is repeated three times. Thus, in the above
English speakers. Fifteen participants were undergraduate           case, the number would be three words. Because the final
students, five participants were graduate students, and two         two viewings merely repeat the participants’ decision, we
participants identified themselves as non-students.                 deemed it more accurate not to include the two extra
                                                                    viewings in the count of words needed to make a correct
                                                                    decision. As such, the McCarthy and McNamara (2007)
1
   We modified one science sentence that was a sentence             report of seven words as being sufficient for experts to
fragment, changing Taking no joy in life, looking forward to        accurately classify genres could be viewed as five words
nothing, wanting to withdraw from people and activities to          according to the method employed in the current paper.
Examples are taking no joy in life, looking forward to nothing,
wanting to withdraw from people and activities.
                                                                614

                          Results                                 narrative sentences as narratives. In other words, skilled
                                                                  readers know better when a sentence is not a Narrative.
Subject Analysis                                                  These readers’ greater accuracy may be because they are
Our results showed that participants typically needed only        prepared to use more words than the Lower-skilled
a sentence’s first three words to make their decision on          readers. However, a t-test revealed no significant
genre (overall words used: M = 3.35, SD = 1.50; words             differences between the number of words required by
used in correct assessments only: M = 3.33, SD = 1.45).           lower-skilled readers (M = 2.97; SD = 1.21) and higher-
The average accuracy of genre categorization was high             skilled readers (M = 3.85; SD = 1.68), t > 1.0, p > .1.
(Recall: 0.86; Precision: 0.71; F1: 0.77), and this accuracy      Despite the lack of a significant difference between the
was consistent across the three genres (see Table 1).             higher-skilled and lower-skilled readers in terms of words
These results are consistent with our previous study              used, the direction of the difference suggests that lower-
(McCarthy & McNamara, 2007).                                      skilled readers may too easily assume the direction or
     The magnitude of the correlation between reading             nature of the sentence discourse.
skill (GM) and words used was moderate (r = .37, p =                   The variable, time for the 3rd word in history
.09), as was the relationship between words used and              sentences, indicates the time on task for judging the third
accuracy (in terms of correlations with F1 participant            word of history sentences for correct decisions. Lower-
evaluations, Science: r = .43, p < .05; Narrative: r = .37, p     skilled readers took significantly more time on this word.
= < .09, History: r = .37, p < .09). We examined the              Indeed, time on task negatively correlated consistently
results more closely by dividing the participants into two        with GM reading skill across all three genres for both 2nd
groups based on a mean split of the Gates-MacGinitie test         words of sentences (Narrative: r = -.427, p = .05; History:
scores (M = 24.00; SD = 9.14). Using these values, 13             r = -.443, p = .04; Science: r = -.523, p = .01) and 3rd
participants were designated as lower-skill (LS) and 9            words of sentences (Narrative: r = -.596, p < .01; History:
participants were designated as higher-skill (HS).                r = -.606, p < .01; Science: r = -.500, p = .02). These
Differences in Gates-MacGinitie test scores were                  results suggest that higher-skilled readers may be able to
analyzed using Levene’s test for equality of error                more quickly integrate new information.
variances. No significant differences between groups                   Taken together, the results suggest that higher-skilled
were detected (p > 0.5), indicating that the groups are           readers are more able to quickly and accurately process
suitable for comparison.                                          sentential information, using as few as the first three
                                                                  words. This advantage appears most evident in two
                                                                  features: on the 3rd word of sentences (all other word
 Table 1: Accuracy of genre evaluation                            positions demonstrated weaker results); and in the
                                                                  accuracy of the precision of Narrative discourse. One
 Genre             Accuracy           Mean        SD              further variable of interest is that higher-skilled readers
 Narrative         Recall              0.86      0.09             may be prepared to use more words before making genre
                   Precision           0.71      0.12             decisions. This final point is supported by our previous
                   F1                  0.77      0.09             study (McCarthy & McNamara, 2007) in which expert
 History           Recall              0.71      0.14             readers (and therefore, presumably higher in ability than
                                                                  those who participated in this study) tended to use at least
                   Precision           0.76      0.09
                                                                  two more words than those who participated here.
                   F1                  0.72      0.11             However, caution should be taken with these conclusions
 Science           Recall              0.67      0.12             for two reasons. First, regarding word count, different
                   Precision           0.88      0.09             experiments cannot easily be compared; and second, a
                   F1                  0.75      0.11             step-wise multiple regression revealed that only the time
                                                                  on task for 3rd words of history sentences variable
     We conducted an exploratory Analysis of Variance             contributed to the model (adjusted R-square = .336). As
(ANOVA) to determine which of 22 variables best                   such, the results of this and our previous study can only
distinguished the reading skill groups. The analysis              indicate the direction of subsequent experiments, which
revealed that 7 variables significantly distinguished the         may shed more light on the relationship between reading
two skill groups (p < .05) and 4 variables were marginally        skill and genre recognition.
significant (p < .1). The most predictive variables were
narrative-precision (Lower skill: M = .66, SD = .12;              Item Analysis
Higher Skill: M = .79, SD = .08; F = 7.55, p = .01, η2 =          Of the 210 sentences in this study, only 4 (2%) failed to
.27) and time for third word in history sentences (Lower          be correctly evaluated by any of the participants. For
skill: M = 1.01, SD = .29; Higher Skill: M = .72, SD = .21;       instance, the history sentence “I had vainly flattered
F = 6.72, p = .02, P. η2 = .25).                                  myself that without very much bloodshed it might be
     The narrative-precision variable suggests that higher-       done” was evaluated by all participants as a narrative; and
skilled readers tend to be better at not classifying non-         the science sentence “Hindi is the most widely used, but
                                                              615

English is often spoken in government and business” was              words used and time on task were consistent across the
evaluated by 20 participants as history and by 2 as                  genres of Narrative (words: r = -.613, p < .001; time: r = -
narrative. A further 33 sentences (16%) were correctly               .466, p < .001); History (words: r = -.701, p < .001; time:
categorized by all the participants. For instance, the               r = -.404, p < .001); and Science (words: r = -.578, p <
narrative sentence “Why, I wouldn't have a child of mine,            .001; time: r = -.257, p = .034).
an impressionable little thing, live in such a room for                    Thus, consistent with the results reported by
worlds” resulted in no misclassifications. For over half             McCarthy and McNamara (2007), viewing more words
the sentences (55%) at least 19 of the 22 participants               does not lead to greater genre classification accuracy.
correctly evaluated the genre. For instance, the science             This result indicates that if a sentence does not contain
sentence “In areas with hard water, many consumers use               genre-specific features early in its structure, then it is also
appliances called water softeners to remove the metal                unlikely to contain those features later in its structure. The
ions” recorded only three misclassifications. Conversely,            results for time on task indicate that sentences that are
only 10% of the sentences received less than 6 correct               more accurately classified are also more quickly
evaluations, an example being the narrative “The Empress             classified. We can presume that the quicker the decision,
of Russia looked dressed for war, Igor thought.”                     the less the processing necessary to make the correct
     The item analysis also showed that the sentences that           decision. Thus, we did not observe a time/accuracy
received the highest accuracy in terms of categorization             tradeoff.
were likely to require fewer words for such categorization                Collectively, the results suggest that most sentences
to be made. Thus, there was a negative correlation                   from the three genres can be accurately categorized in
between the percentage of participants who correctly                 relatively few words and relatively little time. However,
evaluated a sentence and the number of words needed to               the variation within this accuracy suggests a continuum of
correctly categorize the sentence (r = -.639, p < .001). For         sentence-categorization difficulty. That is, the first few
example, “Chemical weathering processes change the                   words of sentences can often be sufficiently non-
chemical composition of rocks” was correctly identified              prototypical or ambiguous to reduce the likelihood of
as a science sentence by all of the participants and                 correct reader categorization. As such, it is feasible that
required an average of only 1.23 words to be identified. In          the construction of the initial aspects of a sentence may
contrast, “However, this process was too slow to satisfy             significantly affect sentence processing, with less
the Renaissance demand for knowledge and books” was                  prototypical constructions causing readers to activate non-
correctly categorized by only 27% (n = 6) of the                     optimal schema.
participants and required 10 words to be correctly
identified as a history sentence.                                    Computational Model
     The results of the time on task demonstrated similar            The results of our previous experiment (McCarthy &
results. Specifically, there was a negative correlation              McNamara, 2007) provided evidence that genre
between the percentage of participants who correctly                 identification could be accomplished with less than half
assessed a sentence and average time on task for                     the words of sentences. However, given such little
assessment (r = -320, p < .001). The results for both
Table 4: The 14 significant genre predictor variables with highest F-values for genres of Narrative, History, and Science
Dependent Variable                         Narrative              History               Science              F          Effect Size
Past tense verbs incidence              177.3 (168.12)        68.18 (136.01)        013.33 (65.98)       20.01***          0.23
Ratio pronouns/noun phrases            184.04 (167.93)        51.14 (119.51)        38.33 (105.42)       17.29***          0.20
Syllables incidence                        3.7 (0.86)           4.89 (1.54)          004.94 (1.46)       13.21***          0.16
Plural nouns incidence                   21.28 (82.36)         34.09 (97.31)       113.33 (173.14)        7.62**           0.10
Singular proper nouns incidence         70.92 (169.34)       136.36 (209.66)        020.00 (79.97)        6.22**           0.08
Age of Acquisition (content)            42.26 (107.92)        60.85 (146.39)       146.06 (201.49)        5.96**           0.08
Mean Meaningfulness                     362.35 (68.78)        305.48 (99.77)        312.42 (94.45)        5.72**           0.08
Nouns, singular/mass (incidence)        83.33 (144.34)        87.12 (144.85)       178.33 (214.29)         4.71*           0.06
Minimum Meaningfulness                 182.32 (204.01)       150.27 (199.39)       070.28 (155.74)         4.65*           0.06
Verbs: non-3rd person incidence          14.18 (68.01)         15.15 (70.24)        66.67 (134.69)         4.59*           0.06
Mean Imageability                       345.62 (68.56)       296.79 (92.52)         319.00 (79.45)         4.21*           0.06
Cardinal numbers incidence               14.18 (68.01)        53.03 (123.33)        006.67 (47.14)         4.00*           0.06
Verb, past participle incidence           0.00 (0.00)           0.00 (0.00)         026.67 (91.35)         3.87*           0.05
Verb phrases incidence                 253.19 (199.32)       147.73 (187.52)       168.33 (196.69)         3.82*           0.05
Note: *** p < .001; ** p <.010; * p < .050; SD appear in parentheses; effect sizes calculated as η2
                                                               616

discourse information, we examined whether a                        information to significantly distinguish genre. The result
computational model based on only lexical and syntactic             is particularly impressive when considering the many
features (i.e., the information used largely by participants)       constraints of the algorithm as opposed to those of the
provided similar results. If the model replicated the results       participants. First, the model is based on only the first
found with humans, then it potentially provides evidence            three words of each of the sentences, whereas the
that participants use such sentential features when                 accuracy of the participants includes the many instances
processing text. More specifically, if readers utilize              where more than three words were used (indeed, the
shallow features to identify genre, this would suggest that         higher-skill group averaged closer to four words, 3.85, to
readers may be making such categorization extremely                 correctly assess genre). Second, the algorithm included no
early in the sentence. Identifying where and how                    predictors of world knowledge, which we can assume the
participants are making their categorization thus informs           participants would have. Thus, when participants see a
theories of reading comprehension as well as research in            number such as 1776 they are presumably more able to
reading strategies.                                                 interpret this as an historical date. Third, even though
     To address our computational question, we conducted            word frequency was included as a predictor, the results
a number of basic assessments, suitable for sentence level          are based on frequencies in general rather than genre
analysis, using the first three words of each sentence in           specific. We can hypothesize that word information
the corpus. We selected the conservative size of the first          relevant to specific genres would enhance the accuracy of
three words of the sentences because this was the lowest            the prediction. For instance, we might assume that
average number of words for any of the groups: (i.e., the           participants have knowledge that cannon is a word
lower-skill group: M = 2.98 words, SD = 1.24). Our                  associated with history whereas nucleus is a word
computational assessments included word frequency                   associated with science.
values (from the Celex data base), word information                      While we cannot claim that the model matches
values (from the MRC data base), parts of speech                    human performance, it is worth noting that the narrative
frequency counts (based on the Charniak parser), and a              precision evaluation for the test set (.74), all data (.73),
syllable count.                                                     and for participants (.71) are highly similar. Given that
     To guard against issues of over-fitting and colinearity        the human narrative precision variable correlated highly
caused by applying multiple predictor variables, we                 with reading skill (r = .520, p = .002), it is reasonable to
followed established procedures of training and testing             assume that the computational model might reflect some
the algorithm (see Witten & Frank, 2005; McCarthy et al.,           aspects of reader strategy, at least in its propensity to
2007). The corpus was randomly divided into a training              correctly reject non-narrative decisions for narrative
set (67%) and a test set (33%). Using the training set, we          sentences. Additionally, the model’s false alarms for
conducted an ANOVA to identify and retain only those                narratives were similar to those decisions made by
variables that significantly distinguished the genre groups.        humans: that is, false alarms were less likely to be science
We then conducted correlations among these variables                decisions (History = 11; Science = 6).
and eliminated variables that presented problems of
colinearity using r > .7; the variable with the higher                                      Discussion
univariate F-value was retained and the lower eliminated.           In this study, 22 participants identified the sentence
Of the 16 remaining variables, the 14 with the highest              genres of 210 sentences. The results indicated that both
univariate F-values were used in a discriminate analysis;           higher- and lower-skilled readers used about three words
there was an item to predictor ratio of 10:1 (see Table 4,          to accurately identify genres. Two primary variables
above).                                                             related strongly to participants’ reading ability: Narrative-
     When the generated algorithm was applied to the test           precision and Time on Task for the 3rd word (i.e., typically
set data, the model significantly predicted accuracy (χ² =          the decision making word). Thus, higher-skilled readers
22.48, p < .001). The model also predicted the data set as          are less likely to think a sentence is a narrative when it is
a whole χ² = 88.20, p < .001 (see Table 5). The results of          not, and they also require less time to make their
the discriminant analysis suggest that the first three words        decisions.
of a sentence hold sufficient syntactic and word level
Table 5: Recall, precision, and F1 results for computational model (test set; all data) compared to participant’s performance
                                   Narrative                               History                                    Science
                         Recall    Precision     F1      Recall     Precision F1              Recall     Precision     F1
Test set                 0.61      0.74          0.67     0.23      0.33           0.27       0.60       0.38          0.46
All data                 0.67      0.73          0.70     0.46      0.52           0.49       0.71       0.59          0.65
Participants             0.85      0.71          0.77     0.71      0.76           0.72       0.68       0.87          0.76
                                                               617

     The results of this study combined with our pilot           Gerrig, R. (1993). Experiencing narrative worlds: On the
study (McCarthy & McNamara, 2007) provide intriguing                 psychological activities of reading. Cambridge, MA:
results. The results suggest 1) that a wide range of readers         MIT Press.
can accurately categorize genres at the sub-sentential           Graesser, A. C., Olde, B. A., & Klettke, B. (2002). How
level; 2) that as few as the first three words of a sentence         does the mind construct and represent stories? In M.
may be all that is required for that assessment to occur; 3)         Green, J. Strange, and T. Brock (Eds.), Narrative
that genre recognition may be indicative of reader ability;          Impact: Social and Cognitive Foundations. Mahwah:
and 4) that features such as time on task, accuracy, and             NJ: Erlbaum.
word count may be the indicators of reading ability.             MacGinitie, W. H., MacGinitie, R. K., Maria, K., &
Further, the computational modeling results suggest that             Dreyer, L. G. (2002). Technical report for the fourth
lexical and structural sentence features of just the first           edition, Gates-MacGinitie reading tests. Itasca, IL:
three words can also significantly classify sentences by             Riverside.
genre. This result may help better identify prototypical         McCarthy, P. M., & McNamara, D. S. (2007). Are seven
and non-prototypical sentences in text. Such a model                 words all we need? Recognizing genre at the sub-
would also be useful for various computational                       sentential level. In D. S. McNamara and G. Trafton
procedures such as text mining, automatic summarization,             (Eds.), Proceedings of the 29th annual conference of
and automatic web-genre classification.                              the Cognitive Science Society (pp. 1295-1300).
     The research presented here offers an interesting and           Cognitive Science Society.
promising direction toward a better understanding of how         McCarthy, P. M., Renner, A. M., Duncan, M. G., Duran,
genre knowledge is represented and subsequently                      N. D., Lightman, E. J., & McNamara. D. S. (in
activated. We plan to use this knowledge to better                   press). Identifying topic sentencehood. Behavior,
establish our genre identification paradigm as an                    Research and Methods.
assessment of reading skill, and even as a possible              Kieras, D. E. (1978). Good and bad structure in simple
intervention for reading development. This future                    paragraphs: Effects on apparent theme, reading time,
research will need to consider such aspects as prior                 and recall. Journal of Verbal Learning and Verbal
knowledge as well as consideration of which words in the             Behavior, 17, 13-28.
sentences are selected for assessment; that is, do sentence      Meyer, B. J. F., & Wijekumar, K. (2007). Web-based
endings have the same effect as sentence beginnings?                 tutoring of the structure strategy: Theoretical
While much remains to be done, the results presented here            background, design, and findings. In D. S.
offer an exciting new perspective on the nature of text and          McNamara (Ed.), Reading Comprehsion Strategies:
the possibilities of reading skill assessment.                       Theories, Interventions, and Technologies (pp. 347-
                                                                     375). Erlbaum.
Acknowledgements                                                 Oakhill, J., & Cain, K. (2007). Issues in causality in
This research was supported in part by the Institute for             children’s reading comprehension. In D. S.
Education Sciences (IES R305G020018-02) and in part                  McNamara (Ed.), Reading Comprehsion Strategies:
by Counter-intelligence Field Activity (CIFA H9c104-07-              Theories, Interventions, and Technologies (pp.47-
C-0014). The views expressed in this paper do not                    72). Erlbaum.
necessarily reflect the views of the IES or CIFA.                Van Dijk, T. A., & Kintsch, W. (1983). Strategies of
                                                                     discourse comprehension. New York: Academic
References                                                           Press.
                                                                 Williams, P. J. (2007). Literacy in the curriculum:
Bhatia, V. K. (1997). Applied genre analysis and ESP. In             Intergrating text structure and content area
     T. Miller (Ed.), Functional approaches to written               instruction. In D. S. McNamara (Ed.), Reading
     text: Classroom applications. Washington, DC:                   Comprehension Strategies: Theories, Interventions,
     USIA.                                                           and Technologies (pp. 199-220). Erlbaum
Coleridge, S. T. (1985). Biographia Literaria: Samuel            Witten, I. H., & Frank, E. (2005). Data mining: Practical
     Taylor Coleridge, H. J. Jackson (Ed.), Oxford.                  machine learning tools and techniques. San
Duran, N. D., McCarthy, P. M., Graesser, A. C., &                    Francisco, CA: Morgan Kaufmann Publishers.
     McNamara, D. S. (2007). Using temporal cohesion to          Zwaan, R. A. (1993). Aspects of literary comprehension.
     predict temporal coherence in narrative and                     Amsterdam: John Benjamins.
     expository texts. Behavior, Research and Methods.
     39, 212-223.
                                                             618

