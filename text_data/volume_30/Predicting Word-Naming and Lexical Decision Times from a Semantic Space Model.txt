UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Predicting Word-Naming and Lexical Decision Times from a Semantic Space Model
Permalink
https://escholarship.org/uc/item/7s0927cq
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Johns, Brendan T.
Jones, MIcheal N.
Publication Date
2008-01-01
Peer reviewed
  eScholarship.org                                Powered by the California Digital Library
                                                                    University of California

 Predicting Word-Naming and Lexical Decision Times from a Semantic Space Model
                                           Brendan T. Johns (johns4@indiana.edu)
                                Department of Psychological and Brain Sciences, 1101 E. Tenth St.
                                                     Bloomington, In 47405 USA
                                          Michael N. Jones (jonesmn@indiana.edu)
                                Department of Psychological and Brain Sciences, 1101 E. Tenth St.
                                                      Bloomington, In 47405 USA
                            Abstract                                organization of semantic memory. In a lexical decision task,
  We propose a method to derive predictions for single-word         a letter string is presented and the participant provides a
  retrieval times from a semantic space model trained on text       speeded response of whether the string is a word or not. In a
  corpora. In Experiment 1 we present a large corpus analysis       naming task, the participant’s task is to name the presented
  demonstrating that it is the number of unique semantic            word aloud as quickly as possible. Both measures produce
  contexts a word appears in across language, rather than           an index of a word’s identification latency. Orthographic
  simply the number of contexts or the frequency of the word,       and phonological factors are certainly large components of
  that is the most salient predictor of lexical decision and
  naming times. In Experiment 2, we develop a co-occurrence         both LDT and NT, but semantics plays a significant role as
  learning model that weights new contextual uses of a word         well, and co-occurrence models have yet to be extended to
  based on fit to what currently exists in the word’s memory        predicting reaction time variance for these single-word
  representation, and demonstrate this model’s superiority in       identification tasks.
  fitting the human data compared to models built using                Modeling of retrieval times is usually done by looking for
  information about the word’s frequency or number of               the best environmental correlates of LDT and NT (Adelman
  contexts. Finally, in Experiment 3 we find that building          & Brown, 2008). Some of the most influential models of
  lexical representations using semantic distinctiveness
  naturally produces a better-organized semantic space to make      retrieval times are based upon word frequency. Word
  predictions for semantic similarity between words.                frequency (WF) has been used to drive many different types
                                                                    of models, including serial-searched rank frequency models
  Keywords: Co-occurrence model; Lexical-decision; LSA;             (Murray & Forster, 2004), threshold activation models
  Contextual distinctiveness                                        (Coltheart, et al., 2001), and connectionist models
                                                                    (Seidenberg & McClelland, 1989).
                        Introduction                                   However, recent evidence suggests that word frequency
The last decade has seen remarkable progress with co-               may not drive retrieval times but, rather, the causal factor is
occurrence models of lexical semantics (e.g., Lund &                a word’s contextual diversity (Adelman, Brown, &
Burgess, 1996; Landauer & Dumais, 1997). These models               Quesada, 2006; Adelman & Brown, 2008). Contextual
learn semantic representations for words by observing               diversity (CD) is the number of different contexts that a
lexical co-occurrence patterns across a large text corpus,          word appears in, and is based on the rational analysis of
typically representing the words in a high-dimensional              memory (Anderson & Milson, 1989), particularly the
semantic space. This approach provides both an account of           principle of likely need (PLN). PLN states that the more
the semantic representation for words and an account of the         unique contexts a word appears in, the more likely the word
learning mechanisms humans use to build and organize                will be needed in any future context. Hence, a word with a
semantic memory. Co-occurrence models have seen                     high CD should be faster to retrieve under this principle.
considerable success at accounting for data in a wide variety          A word’s CD value is typically computed by simply
of semantic tasks, including TOEFL synonyms (Landauer &             counting the number of different documents in which it
Dumais, 1997), semantic similarity ratings and exemplar             appears across a text corpus. This measure has been shown
categorization (Jones & Mewhort, 2007), and free                    to be a better predictor of LDT and NT than WF (Adelman,
association norms (Griffiths, Steyvers, & Tenenbaum,                et al., 2006). However, operationalizing CD as the number
2007).                                                              of documents in which a word occurs may not be a fair
  To date, all applications of co-occurrence models have            instantiation of PLN. A word that appears in many
been to semantic similarity between two words or two                documents may have a high WF, but it should have a low
documents. The standard prediction of semantic similarity           CD if those documents are highly redundant, as is the case
in these models is some measure of the angle between two            with words that belong to a popular discourse topic for
vectors. However, co-occurrence models should, in theory,           which many documents exist. It is the number of different
contain sufficient information in the magnitude of their            contexts and the uniqueness of contexts that determines a
representations to make predictions about single word               word’s likely need. This calls for a measure of CD that
retrieval as well.                                                  considers the semantic uniqueness of documents that a word
  Lexical decision time (LDT) and word naming time (NT)             appears in. Based on PLN, it is reasonable to assume that if
are both important variables that offer insight into the            a word appears in a context it has never before occurred in,
                                                                279

then the context should be more important to its CD count.          signals how distinct the documents that a word occurs in are
A greater number of unique contexts should yield a higher           from each other. A word with a high SD value tends to
CD value than an equal number of redundant contexts. This           occur in documents that have a low amount of word overlap
interpretation of PLN has empirical support from                    (it is more contextually distinct), and a word with a low SD
experiments demonstrating that benefit from repeated                value tends to occur in documents that have a high amount
exposure to an item is strongest if the context changes as          of word overlap (it is less distinct).
well (Glenberg, 1979; Verkoeijen, Rikers, & Schmidt,                   However, as Adelman, et al. (2006) showed, the number
2004).                                                              of different contexts that a word appears in is a highly
   There is no principled reason why a co-occurrence model          important predictor of LDT and NT. These SD values do not
could not compute a WF or document count to make word-              take this important source of information into account.
specific LDT or NT predictions. Most co-occurrence models              To explore whether counting low similarity contexts as
begin with a word-by-document matrix, which contains the            being more important yields a better CD count, the weights
requisite information in the magnitude (sum) of a word’s            given to the value of a context were modified with
frequency distribution over documents. In Experiment 1, we          increasing specificity. This was done by creating
conduct a large corpus-based analysis to demonstrate that           increasingly more specific rules, based on the computed SD
number of unique contexts is a more important factor than a         values, to create the context value. The first iteration will be
simple document count or WF in predicting LDT and NT.               one rule – if the dissimilarity between two documents is
In Experiment 2 we develop a co-occurrence model that               greater than 0.0 (covering 100% of the SD data), then 1 is
learns from semantic distinctiveness and makes retrieval            added to the word’s count value (note that this is the same
predictions, and in Experiment 3 we demonstrate that in             as the standard document count that weights each document
addition to giving a better fit to the LDT and NT data than         equally). On the next iteration, there will be two rules – if
frequency or document count models, our model based on              the dissimilarity between two documents is greater than the
semantic uniqueness naturally produces better predictions of        median of the computed SD values, then the count gets two
semantic similarity between words as well.                          added to it, otherwise (i.e. if it is less than the median) then
                                                                    the count gets 1 added to it. Then on the third iteration, the
             Experiment 1: Corpus Analysis                          rules would increase in resolution:
                                                                       If dissim(docx, docy) < SD_33_percentile => count +=1
Semantic Distinctiveness                                               If dissim(docx, docy) < SD_66_percentile => count +=2
                                                                       If dissim(docx, docy) < SD_100_percentile=> count +=3
   To examine the influence of semantic distinctiveness, it is
necessary to create a measure of the coherence of                      This is done up to 10 rules (so the data would be split into
documents in which a word appears. Though there are many            tenths). By this method, we create a document count in
existing models of semantic representation (e.g., HAL or            which documents that have more unique contextual uses of
LSA), we did not want to approach the problem from a                the word (compared with the other documents that the word
specific theoretical orientation. Instead the measure that we       appears in) are weighted more strongly than documents that
use to assess the dissimilarity between two documents is            have more common contextual usages of the word,
based on the proportion of words that two documents have            consistent with PLN.
in common, or:
                                                                       Method
                                        | ∩|
        1,  2 = 1 −                             (1)         Our analyses are based on three corpora: 1) TASA (from
                                      | , |
                                                                    Touchstone Applied Sciences Associates), 2) a Wikipedia
    That is, document similarity is the intersection of the two     (WIKI) corpus, and 3) a New York Times (NYT) corpus.
sets of words, divided by the size of the smaller document.         The TASA corpus was composed of 10,500 documents,
This gives the proportion of word overlap between two               with each document having a mean length of 289 words.
documents. Function words (e.g. the, is, of, etc…) were             The Wikipedia corpus was composed of 9,755 documents,
filtered out of the set of words, so they do not impact the         with a mean document length of 391 words. The New York
similarity rating. Document dissimilarity is then just 1-           Times corpus is composed of 9,100 documents with a mean
similarity. We then define a word’s semantic distinctiveness        length of 250 words, drawn from the New York Times
(SD) as the mean dissimilarity of the set of documents that         during the year of 1994. These are smaller versions of the
contain it:                                                         full corpora, and the reduced size was necessary for
                                                                    practical reasons of computation time: The SD counts took,
                       ∑*    &
                        &() ∑'() !""!#i,j
                                                                    on average, 120 hours in parallel across 3 Sun Sparc IV+
             word =                                  (2)          CPUs for each corpus. LDT and NTs were attained from the
                               +,+- .+ /
                                                                    English Lexicon Project (Balota, et al., 2002). SD values
Where n is the number of documents that a word appears in.          were computed for 17,984, 22,673, and 14,609 words, for
Equation (2) is the average dissimilarity among all                 the TASA, WIKI, and NYT corpora, respectively.
documents that the word appears in, and this SD value
                                                                280

                                                                                             Table 2. Naming Time
Results
                                                                                                       Effect (∆R2 in %)
   Figure 1 shows the increase in R2 for LDT (top panel) and               Analysis                      TASA          WIKI        NYT
NT (bottom panel) as predicted by the SD weighted context                  Log_SD (After WF)             8.49          9.016       7.751
count over DC and WF. These figures show a large increase                  Log_CD (After WF)             3.98          2.654       0.0 n.s.
for the weighted SD counts over both WF and DC in                          Log_ SD (After CD)            6.511         11.718      13.235
predicting variance for word identification measures. As                   Log_WF (After CD)             0.217         0.0 n.s.    0.847
these figures illustrate, giving greater weight to a context               Log_CD (After SD )            0.471         5.468       6.617
that is more distinct given a word’s history of contexts can               Log_WF (After SD )            1.86          0.819       1.55
produce a better fit to the latency measures. In our                       Log_SD(After CD,WF)           6.511         12.403      13.868
                                                                           Log_WF(After SD, CD)          1.86          0.775       1.459
subsequent analyses, we will use a split of seven quantiles,
                                                                           Log_CD(After SD, WF)          0.465         5.833       6.569
since after this point there does not appear to be a significant
increase in variance predicted for any of the corpora.
                                                                        behavioral measures. Tables 1 and 2 show for LDT and NT,
                                                                        respectively, the unique variance predicted by each measure
                                                                        while the other measures are systematically partialled out.
                                                                        The results in Tables 1 and 2 are similarsimi to those attained
                                                                        with power and rank transformations. The SD_Count
                                                                        variable gives a better prediction of the latencies for every
                                                                        analysis, and wipes out the effect of WF just as well as the
                                                                        document count variable does
                                                                         Discussion
                                                                           Thee results of our corpus analysis clearly suggest that in
                                                                        order to make an accurate contextual diversity measurement
                                                                        one has to take into account the uniqueness of the contexts
                                                                        that a word appears in. Considering the semantic
                                                                        distinctiveness of the contexts that a word appears in, we
                                                                        were able to create a count that is significantly better than
                                                                        one that weights all documents as being equally unique.
                                                                           Next, we propose a simple process model to create a
        Figure 1. Increase in R2 over WF and document
                                                                        term-by-document
                                                                                  document matrix that incrementally weights new       ne
     count predicted by the weighted SD count for LDT
                                                                        contexts for words by considering how distinct a document
     (top panel) and NT (bottom panel).
                                                                        is at time t relative to the word’s current lexical
                                                                        representation      (which     represents        the    knowledge
                                                                        representation from documents 1...t-1).
                                                                                                            1...      We then show how
Adelman et al. (2006) found a small but reliable increase in            the representation magnitude can be used to predict LDT
variance predicted for LDT and NT by document count over                and NT, and how the weighted input matrix naturally
WF (using log or power transforms of both variables). We                produces a better semantic space as a byproduct of this
conducted a similar regression analysis using our                       implementation of PLN.
SD_Count, WF, and document count (DC) to predict the
                                                                                     Experiment 2: Learning Model
                    Table 1. Lexical Decision
                                                                        A Contextual Relatedness Episodic Activation Model
                                                (∆R2 in %)
                                         Effect (∆
  Analysis                         TASA           WIKI      NYT            We next wanted to create a co-occurrence
                                                                                                              occurrence model that can
  Log_SD (After WF)               5.501          6.417     6.282        learn semantic distinctiveness and compare predictions on
  Log_CD (After WF)               2.341          1.675     0.0 n.s.     LDT and NT to models that do not. In order to capture the
   Log_ SD (After CD)             3.87           6.807     11.557       results of the corpus analysis, a contextual relatedness
  Log_WF (After CD)               0.0 n.s.       0.382     1.123        episodic activation memory (CREAM) model was created.
   Log_CD (After SD )             0.645          2.094     5.025        Like in other co-occurrence
                                                                                             occurrence learning models, a word-by-
  Log_WF (After SD )              0.0 n.s.       0.0 n.s.  0.0 n.s.
                                                                        document matrix is built up to create a word’s
   Log_SD(After CD,WF)            4.487          7.731     11.881
  Log_WF(After SD, CD)            1.282          1.03      1.485
                                                                        representation. The modification that this model makes is
  Log_CD(After SD, WF)            0.641          3.108     5.445        the type of information   n that is added into the word-by-
                                                                                                                                 word
                                                                        document matrix: instead of raw frequency or occurrence,
                                                                    281

we will add a semantic distinctiveness value. The first step        Method
in computing this SD value is to create a ‘context’ or
                                                                    To predict LDT and NT, the magnitude of a word is
‘document’ vector, which we will simply call a composite
                                                                    computed by summing all of the entries in the word’s
context vector (CCV). Simply, for each word that occurs in
                                                                    context vector. This magnitude is used as a direct predictor
a document (W1,...,WN) we add each word’s vector into a
                                                                    of retrieval times. To judge this model’s ability to predict
composite vector representing the meaning of the document.
                                                                    both LDT and NT, a model comparison was undertaken.
Formally, this is:
                                                                    CREAM was compared against a WF model and a
                                                                    document count (DC) model. In the CREAM model, the λ
                      001 = ∑3  !4 2!      (3)                     parameter was fixed at 5.5. In the WF model the frequency
                                                                    that a word occurs in a document is the entry into the word-
   Where N is the set of words in the document, and Ti is the       by-document matrix. In the DC model a 1.0 is entered into
memory trace corresponding to word i. The next step is to           the matrix if the word occurs in that document. For all three
compute a similarity value (given by a vector cosine)               models, vector magnitude is used to predict latencies; the
between each word that occurs in the context and the                only difference is how the matrix is built.
context vector. Then this similarity value is transferred             This comparison was conducted for the same three
through an exponential probability density function, and the        corpora as specified in the corpus analysis. However, the
resulting value is entered into the new context slot in             models were trained on the full versions of each corpus:
memory:                                                             36,700 documents from TASA, with an average length of
                      = ℮.6∗"!+8          (4)                   121 per document, and 40,000 documents from the
    Where λ is a fixed parameter with a small positive value.       Wikipedia corpus, with an average document length of 279.
This exponential function has the effect of transforming a          The New York Times corpus was the same as specified in
low similarity value into a large SD value and a high               the corpus analysis. LDT and NT data were again attained
similarity value into a small SD value, as well as smoothing        from the Elexicon database (Balota et al., 2000). In the
the added value of uniqueness. The parameter λ is much like         analysis, latencies from 29,799, 35,518, and 20,744 words
the weighting scheme that we employed in the corpus                 were used for the TASA, WIKI, and NYT corpora,
analysis. With a small λ (<1), the transformation from a            respectively.
high to low value is almost linear (e.g. 0.9 to 0.1). However,                           Table 3. Lexical Decision
as we increase λ, it accentuates the difference in the value of
high vs. low similarity contexts. A document count model                                                        Effect (∆R2 in %)
can be considered to be nested within this model, with a λ                                              TASA          WIKI         NYT
set at 0. As in the corpus analysis, a context with a high SD           Log_CREAM (After WF)            3.048          1.81        5.461
                                                                        Log_DC (After WF)               1.274         0.786       0.0 n.s.
value means that the document is more distinct compared
                                                                        Log_ CREAM (After DC)           2.346         0.849        6.901
with the other contexts that a word has appeared in. This               Log_WF (After DC)              0.0 n.s.       0.364         1.07
gives greater salience to low similarity contexts, in terms of
                                                                        Log_DC (After CREAM )           0.511         0.141        0.462
the word’s magnitude, than high similarity contexts.                    Log_WF (After CREAM )          0.0 n.s.       0.704       0.0 n.s.
   When a word is first seen its context vector will be empty,          Log_CREAM(After DC,WF)          3.118         1.175        7.348
hence, the similarity between memory and the current                    Log_DC(After CREAM, WF)         1.327         0.149        2.001
context will be 0.0. Therefore, the SD value will always be             Log_WF(After CREAM, DC)         0.816           0.7        1.549
1.0 for the first document, and it will be encoded at maximal
strength. The second time a word is experienced, the                                      Table 4. Naming Time
similarity of this context is compared to the word’s current
lexical representation (which only contains the first context                                                 Effect (∆R2 in %)
so far). If this is a repetition of the first document, the new                                      TASA            WIKI          NYT
context will be encoded at minimal strength. If, however, it          Log_CREAM (After WF)             5.811         3.323         6.568
                                                                       Log_DC (After WF)               2.904          2.01        0.0 n.s.
is a context that is unique from the first, the new context
                                                                      Log_ CREAM (After DC)            4.984         1.213         7.791
will be encoded at maximal strength.                                   Log_WF (After DC)               0.119        0.0 n.s.        0.75
   In this fashion the word-by-document matrix has columns            Log_DC (After CREAM )            2.062        0.0 n.s.        0.72
added to it each time a new document is learned, with the              Log_WF (After CREAM )           0.386         0.132        0.0 n.s.
encoding strength for a document (for a particular word)              Log_CREAM(After DC,WF)           5.361         1.336         8.243
dependent on the lack of fit between what has been learned            Log_DC(After CREAM, WF)          2.163        0.0 n.s.       1.868
and what is being experienced. In a sense, the attention              Log_WF(After Sem, DC)            0.485         0.117         1.197
weight given to a new context is dependent on how unique
the context is relative to the word’s current memory                Results
representation. That is, creating a word’s representation in
memory is a dynamic interaction between what is in                  Table 3 shows the increase in R2 for the various models fit
memory and what is in the environment.                              to LDT, while controlling for the other models’ magnitudes.
                                                                    Table 4 shows the same data for NT. As the tables show, the
                                                                282

CREAM model performs significantly better then both the                produces semantic structure that is very similar to models
WF and DC model. As was suggested by the corpus                        such as LSA.
analysis, this comparison demonstrates that by weighting                  As with other co-occurrence models, Kwantes’ (2005)
the context for how unique it is to other contexts that the            model is able to account for the knowledge representation of
word has appeared in, we can create a better contextual                words. It is possible that by building the co-occurrence
diversity count that produces closer correspondence to the             matrix using semantic uniqueness we improved predictions
behavioral measures.                                                   of LDT and NT at the cost of semantic organization. Figure
                                                                       3 displays a two-dimensional scaling solution for a subset of
           Experiment 3: Semantic Space                                our space, illustrating that semantically similar words seem
                                                                       to be clustering in intuitive clusters, as is expected. In this
Since the word-by-document matrix is used to derive                    figure, we also display a color coding of the magnitude of
semantic representations in many co-occurrence models, we              word vectors (likely need) in addition to semantic
wanted to test the semantic organization constructed with              organization. From this figure, it does not appear that
the SD-weighted learning mechanism against those based on              learning magnitudes based on semantic distinctiveness has
raw frequency or document count. To this end, we adapted               sacrificed semantic organization.
the Constructed Semantics model of Kwantes (2005) to
derive a semantic space from our matrices. In Kwantes’
model a word-by-document matrix is constructed, with each
entry in the matrix being the frequency that a word occurs in
a specific context. This is the same matrix that both LSA
(Landauer & Dumais, 1996) and the Topics Model
(Griffiths et al., 2007) begin with. However, instead of
using a matrix reduction technique (LSA uses singular value
decomposition), the Constructed Semantics model retrieves
a word’s semantic representation using a retrieval process
borrowed from a well-known global memory model –
MINERVA 2 (Hintzman, 1986), with a few minor
adjustments. By Kwantes’ account, the raw instances of a
word’s context occurrences are stored in memory, and a
word’s meaning is constructed by the retrieval process,
much in the same way MINERVA 2 explains schema
abstraction tasks as retrieval from episodic memory
(Hintzman, 1986). The retrieval process works by receiving
                                                                       Figure 2. MDS plot depicting organization in a subset of
a probe P (which is a word’s context vector), and creating a
                                                                       the semantic space. The location of a point indicates its
composite vector from memory:
                                                                       semantic position, and the color indicates vector magnitude
                                                                       (used to predict LDT and NT).
                    0 i = ∑;94 2!9 ∗ :9 (5)
where M is the total number of traces in memory (number of                To get a quantitative test of semantic organization we
words in the word-by-document matrix), T is the current                compared the CREAM, WF, and DC models’ predictions of
trace, and A is activation of memory trace T.                          semantic distance in WordNet for pairs of words. We used
  The activation value is simply the vector cosine                     the well known Jiang-Conrath (JCN) semantic distance from
(normalized dot product) between the probe and a memory                WordNet that has been argued gives the best predictions of
trace. One modification of Kwantes’ (2005) model is that if            human judgments of semantic similarities (Maki, McKinley,
the similarity value is less than a criterion, then this vector is     & Thompson, 2004). To test the models, 730 word pairs
not added into the composite vector.                                   from Maki et al.’s (2004) database were created for each
   We use Kwantes’ (2005) model here because it is easy to             model by retrieving their semantic representations from
understand memory as the word-by-document matrix.                      memory, as in equation (5). The retrieval process is the
Typically this matrix is decomposed to determine the latent            same for all models, only the way in which the word-by-
factors that underlie the maximum amount of variance in the            document matrix is constructed differs. The results were
original matrix, and semantic similarities emerge as a                 also compared against the results of two established models
byproduct of this dimensional reduction. Semantic                      of semantic memory: LSA (Landauer & Dumais, 1997) and
similarity between words is determined by a measure of the             BEAGLE (Jones & Mewhort, 2007). The correlation matrix
angle between their vectors in this reduced space; for                 of this analysis is given in Table 5.
Kwantes’ model, this would be the cosine of the vectors
retrieved from memory for the two words, and this process
                                                                   283

            Table 5. WordNet Similarity Correlations
                                                                                             References
Variable        1.     2.      3.       4.        5.       6.        Adelman, J. S., & Brown, G. D. A. (2008). Modeling
1.JCN          -     -.207   -.332    -.237     -.273    -.287     lexical decision: The form of frequency and diversity
2. LSA                  -     .359    .579      .445      .281
3. BEAGLE                       -     .483      .540      .617       Adelman, J. S., Brown, G. D. A, Quesada, J. F. (2006).
4. WF                                    -      .836      .645     Contextual diversity, not word frequency, determines word-
5. DC                                              -      .857     naming and lexical decision time. Psychological Science,
6. CREAM                                                    -      17, 814-823.
                                                                     Anderson, J.R., & Milson, R. (1989). Human memory:
   The CREAM model, based on semantic distinctiveness              An adaptive perspective. Psychological Review, 96, 703-
co-occurrence counts, produced predictions that were               719.
significantly closer to the WordNet similarity values than           Balota, D.A., Cortese, M.J., Hutchinson, K.A., Neely,
the other models, with the exception of the BEAGLE model.          Nelson, D., Simpson, G.B., & Treiman, R. (2000). The
The size of this comparison was limited to 730 words due to        English Lexicon Project. Retrieved September 30, 2007,
the enormous computations required to create semantic              from http://elexicon.wustl.edu/.
representations using Kwantes’ (2005) model. However, it             Coltheart, M., Rastle, K., Perry, C., Langdon, R., &
cleanly demonstrates that a model based on semantic                Ziegler, J. (2001). DRC: A dual route cascaded model of
distinctiveness can produce better predictions of LDT and          visual word recognition and reading aloud. Psychological
NT from its vector magnitudes, and, as a byproduct,                Review, 108, 204-256.
uniqueness might also produce a better organized semantic            Glenberg, A.M. (1979). Component-levels theory of the
space.                                                             effects of spacing of recall and recognition. Memory &
   This comparison provides converging evidence for the            Cognition, 7, 95-112.
importance of uniqueness of a context (relative to memory)           Griffiths, T.L., Steyvers, M., & Tenenbaum, J.B. (2007).
when building a model of contextual co-occurrences, and it         Topics in Semantic Representation. Psychological Review,
proposes a simple process mechanism to build these                 114, 211-244.
representations that is based on likely need. The resulting          Hintzman, D.L. (1986). “Schema Abstraction” in a
space seems to produce a better approximation of semantic          multiple-trace memory model. Psychological Review, 93,
similarity, and the magnitude of a word’s vector can then be       411-428.
used to make direct predictions about LDT and NT.                    Jones, M.N., & Mewhort, D.J.K. (2007). Representing
                                                                   word meaning and order information in a composite
                   General Discussion                              holographic lexicon. Psychological Review, 114, 1-37.
                                                                     Kwantes, P.J. (2005). Using context to build semantics.
The results of Experiment 1 are consistent with the PLN            Psychonomic Bulletin & Review, 12, 703-710.
theme advanced by Adelman et al. (2006). However, they               Landauer, T.K., & Dumais, S.T. (1997). A solution to
clearly demonstrate that the semantic uniqueness of a              Plato’s problem: The latent semantic analysis theory of the
context is an important factor to weight when creating a           acquisition, induction, and representation of knowledge.
contextual diversity measure. Experiment 2 explored this           Psychological Review, 104, 211-240.
theme with confirmatory modeling by building a co-                   Lund, K., & Burgess, C. (1996). Producing high-
occurrence representation in which the novelty of                  dimensional semantic spaces from lexical co-occurrence.
information being learned was contrasted with existing             Behavior Research Methods, Instruments, & Computers, 28,
memory structure. It was demonstrated that by doing this           203-208.
the model produces better estimates of LDT and NT than               Maki, W.s., McKinley, L.N., & Thompson, A.G. (2004).
one based simply on frequency or document occurrence. Of           Semantic distance norms computed from an electronic
interest were the results of Experiment 3: building a              dictionary (WordNet). Behavior Research Methods,
semantic space from the superior uniqueness matrix actually        Instruments, & Computers, 36, 421-431.
seems to produce better semantic organization, a free lunch          Murray, W.S., & Forster, K.I. (2004). Serial mechanisms
we are pleased with, but were not explicitly trying to create.     in lexical access: The rank hypothesis. Psychological
   We believe that using the magnitude of a word’s vector to       Review, 111, 721-756.
predict LDT and NT is a step in the right direction for a            Seidenberg, M.S., & McClelland, J.L. (1989). A
unified class of co-occurrence learning models that have           distributed, developmental model of word recognition and
already proven success at accounting for a wealth of data.         naming. Psychological Review, 96, 523-568.
However, it is important to note that our current account is         Verhoeijen, P.P.J.L., Rikers, R.M.P.J., & Schmidt, H.G.
largely exploratory, and currently lacks a sufficient process      (2004). Detrimental influence of contextual change on
mechanism to explain the host of strategic effects that are        spacing effects in free recall. Journal of Experimental
seen as a function of SOA in lexical decision and naming           Psychology: Learning, Memory, and Cognition, 30, 796-
tasks.                                                             800.
                                                               284

