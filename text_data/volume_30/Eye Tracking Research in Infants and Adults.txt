UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Eye Tracking Research in Infants and Adults

Permalink
https://escholarship.org/uc/item/9zs8w7vm

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)

Authors
Richardson, Daniel C.
Johnson, Scott P.

Publication Date
2008-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Eye Tracking Research in Infants and Adults
Daniel C. Richardson (dcr@eyethink.org)
School of Psychology, Harry Pitt Building, University of Reading
Reading, Berkshire RG6 6AL UK

Scott P. Johnson (scott.johnson@ucla.edu)
Department of Psychology, Franz Hall, UCLA
Los Angeles, CA 90095 USA
Keywords: Eye movements, eye tracking, visual perception,
experimental methods, infants, adults

set amongst a large set of distracters (Amso & Johnson,
2006). Infants were also observed in a task designed to tap
perception of the unity of a partly occluded object. Those
infants who were more effective at target search also
provided evidence of unity perception; those infants who
were less proficient at target search tended not to perceive
unity. These results imply a link between visual scanning
behavior and early object perception skills.

Introduction
Eye movements are arguably the most frequent of all human
behaviors, and are the result of an intimate and constant
interaction between cognitive and perceptual processes.
They can provide insight into psychological processes such
as language comprehension, memory, social cognition and
decision making. The use of eye trackers by developmental
psychologists, for example, has dramatically altered
observational capacities, and made it possible to address
questions which could not be examined previously and thus
open up entirely new approaches and areas of inquiry.

Development of Oculomotor Behavior
Developmental psychologists have long been interested in
developments in oculomotor behavior. Newborn infants
scan the visual environment actively and their scanning
patterns are principled and somewhat organized (Haith,
1980). However, there are limits in certain kinds of eye
movement, such as smooth pursuit, that might reflect
maturation of underlying neural mechanisms (Johnson,
1990). Little is known about infants’ scanning behaviors in
real world environments, and how developments in
scanning patterns are related to other processes, though
progress is being made in addressing these questions (e.g.,
Johnson, Davidow, Hall-Haro, & Frank, in press).

Eye Tracking Research with Infants
Eye tracking studies with infants work best when the infant
is engaged as fully as possible with the stimulus. Methods
that involve frequent looks away from the stimulus, such as
habituation paradigms, may not work well, though there are
a few reports of successful eye tracking using such methods
(Johnson, Slemmer, & Amso, 2004).

Eye Tracking Research with Adults

Implications of Eye Movements for Perceptual and
Cognitive Development

Spatial Attention And Scene Perception

In reaction time studies, infants’ eye movements were
recorded upon the onset of a new stimulus or the location
where a stimulus was seen previously, to assess inhibition of
return or spatial negative priming of the location. Longer
reaction times to look at the new target location have been
proposed to indicate effects of inhibition of the location, a
location that was necessarily attended to covertly (Amso &
Johnson, 2005). In oculomotor anticipation studies, infants
are presented with stimuli in which an object repeatedly
moves behind an occluder and re-emerges, to assess the
extent to which the infant looks to the place of emergence.
Consistent anticipations toward this location have been
proposed to indicate a mental representation of the moving
object despite occlusion, perhaps an early form of object
permanence (Gredebäck & von Hofsten, 2004).
Eye movement patterns can also serve as an independent
variable, as in studies that classify infants as “efficient” or
“inefficient” in their scanning behaviors, and that analyze
other experimental outcomes in light of this grouping
variable. In one such study, infants were observed in a
visual search task with displays consisting of a single target

Spatial attention and saccade planning are closely coupled
during natural unconstrained eye movements, and are
determined by two components (Henderson, 2003). Firstly,
statistical properties of the image such as high spatial
frequency and local contrast have been found to be closely
correlated with fixation likelihood (Itti & Koch, 2000).
Secondly, there are “top-down” influences from knowledge,
memories, beliefs or goals that the viewer may bring to the
image (Yarbus, 1965).

Reading
The general characteristics of eye movements during
perception have been studied in great depth during the
process of reading. In general, eye fixations during reading
last approximately 200-250 milliseconds (Pollatsek, Rayner,
& Collins, 1984) and saccades span on average about 7 to 9
letter spaces. Eye movements also vary as a function of the
legibility of the text, syntactic difficulty and conceptual
difficulty (for a review, see Rayner, 1998).

23

Language In A Visual And Social Context

References

Language use generally occurs within rich visual contexts,
and the interplay between linguistic processes and visual
perception is of increasing interest to psycholinguists and
vision researchers (Henderson & Ferreira, 2004). For
example, when facing a display containing a bag of candy, a
candle, an envelope, and a spoon, and being instructed to
"Pick up the candy," subjects occasionally look first at the
candle (because of the overlap in the first few phonemes
between "candy" and "candle") (Spivey, Tanenhaus,
Eberhard, & Sedivy, 2002). This kind of real-time
interaction between visual and linguistic processing is also
seen during spoken language production (Griffin & Bock,
2000), and even natural unscripted conversation
(Richardson, Dale & Kirkham, 2007).

Amso, D., & Johnson, S. P. (2005). Selection and
inhibition in infancy: Evidence from the spatial negative
priming paradigm. Cognition, 95, B27-B36.
Amso, D., & Johnson, S. P. (2006). Learning by selection:
Visual search and object perception in young infants.
Developmental Psychology, 6, 1236-1245.
Antrobus, J. S., & Antrobus, J. S. (1969). Rapid eye
movements and rapid eye movement periods.
Psychophysiology.
Clark, H. (1916). Visual imagery and attention: an analytical
study. American Journal of Psychology, 27, 461-492
Gredebäck, G., & von Hofsten, C. (2004). Infants' evolving
representation of moving objects between 6 and 12
months of age. Infancy, 6, 165-184.
Griffin, Z. M., & Bock, K. (2000). What the eyes say about
speaking. Psychological Science, 11, 274-279.
Haith, M. M. (1980). Rules that babies look by: The
organization of newborn visual activity. Hillsdale, NJ:
Erlbaum.
Henderson, J. M. (2003). Human gaze control in real-world
scene perception. Trends in Cognitive Sciences, 7, 498504.
Henderson, J. M., & Ferreira, F. (Eds.). (2004). The
integration of language, vision, and action: Eye
movements and the visual world. New York: Psychology
Press.
Itti, L., & Koch, C. (2000). A saliency-based search
mechanism for overt and covert shifts of visual attention.
Vision Research, 40(, 1489-1506.
Johnson, M. H. (1990). Cortical maturation and the
development of visual attention in early infancy. Journal
of Cognitive Neuroscience, 2, 81-95.
Johnson, S. P., Davidow, J., Hall-Haro, C., & Frank, M. C.
(in press).
Development of perceptual completion
originates in information acquisition. Developmental
Psychology.
Noton, D., & Stark, L. (1971). Scanpaths in eye movements
during pattern perception. Science.
Pollatsek, A., Rayner, K., & Collins, W. E. (1984).
Integrating pictorial information across eye movements.
Journal of Experimental Psychology: General, 113, 426442.
Rayner, K. (1998). Eye movements in reading and
information processing: 20 years of research.
Psychological Bulletin, 124, 372-422.
Richardson, D.C., Dale, R. & Kirkham, N.Z. (2007). The art
of conversation is coordination: Common ground and the
coupling of eye movements during dialogue,
Psychological Science, 18, 407-413.
Spivey, M. J., Tanenhaus, M. K., Eberhard, K. M., &
Sedivy, J. C. (2002). Eye movements and spoken
language comprehension: Effects of visual context on
syntactic ambiguity resolution. Cognitive Psychology, 45,
447-481.
Yarbus, A. L. (1965). Role of eye movements in the visual
process. Oxford, England: Nauka.

Memory, Imagery, and Dreaming
Researchers have long been intrigued by the relationship
between eye movements during a perceptual experience and
the eye movements that occur when one remembers,
imagines, or dreams about that experience. Early empirical
investigations found that the frequency of eye movements
increases during mental imagery, particularly that of a
spatial nature (Clark, 1916); and an increase in rapid
fluttering of the eyes while sleeping correlates with
vividness of dreams (Antrobus & Antrobus, 1969).
‘Scanpath theory’ (Noton & Stark, 1971) holds that a
picture is recognized partially by replaying the memory of
this sequence of eye movements and visual stimulation and
comparing it the present stimulus.

Conclusion
Eye movements are driven both by properties of the visual
world and processes in a person’s mind. Uniquely poised
between perception and cognition, eye movements are an
invaluable tool for psychologists. Compared to the single
data point provided by a button-press reaction time, the eye
movements of a subject can provide researchers with a rich,
dynamic data source concerning the temporal dynamics and
psychological processes that led up to the response. These
properties are also of great value to designers and engineers,
as they allow for detailed measurements of how a user is
interacting with a device. Since the technology has become
highly efficient, such information can now be fed back into
devices in real time, and the movements of a user’s eyes can
be used to issue commands or tailor computational
processes. Although such applications are currently in their
infancy, this most frequent of all human behaviours could
turn out to provide the most fluid and expressive interface
between humans and computers.

Acknowledgments
Supported by grants from NSF (BCS-0418103) and NIH
(R01-HD40432).

24

