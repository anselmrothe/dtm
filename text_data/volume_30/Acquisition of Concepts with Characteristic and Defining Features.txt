UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Acquisition of Concepts with Characteristic and Defining Features
Permalink
https://escholarship.org/uc/item/1z17c313
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Shultz, THomas
Thivierge, Jean-Philippe
Laurin, Krisitn
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                  Powered by the California Digital Library
                                                                    University of California

                  Acquisition of Concepts with Characteristic and Defining Features
                                            Thomas R. Shultz (thomas.shultz@mcgill.ca)
               Department of Psychology and School of Computer Science, McGill University, 1205 Penfield Avenue
                                                       Montreal, QC H3A 1B1 Canada
                                           Jean-Philippe Thivierge (jthivier@indiana.edu)
                      Department of Psychological and Brain Sciences, Indiana University, 1101 East Tenth Street
                                                         Bloomington, IN 47408 USA
                                          Kristin Laurin (klaurin@artsmail.uwaterloo.ca)
                            Department of Psychology, University of Waterloo, 200 University Avenue West
                                                       Waterloo, ON N2L 3G1 Canada
                               Abstract                                 Such confusion would be particularly acute early in concept
   Concepts with defining features have sufficiently rigid
                                                                        acquisition when neither version of a concept is fully in place.
   boundaries that examples of one concept are rarely confused          Another problem with the dual view is difficulty in
   with another concept, whereas probabilistic concepts have            accounting for the developmental shift from probabilistic to
   vague boundaries, producing frequent misclassifications. It has      defining features. If defining and characteristic versions of
   been argued that, although neural learning might account for         concepts reside in different systems that are represented in
   probabilistic (or fuzzy) concepts, it is incapable of accounting     incompatible formats governed by distinct principles, how do
   for acquisition of concepts with defining features. Simulations      the two systems interact and how does one eventually
   reported here with encoder networks call this view into
   question. These sibling-descendant cascade-correlation               overtake the other? A similar issue played out in the area of
   networks account for a variety of phenomena with concepts            past-tense acquisition, where a dual view could not explain
   positioned along the probabilistic to defining-features              migration between regular and irregular verb classes over the
   continuum. Classification of exemplars by our networks was           history of English, a migration that was naturally simulated
   affected by both isolation of the concept in semantic feature        within a homogenous neural network (Hare & Elman, 1995).
   space and by dispersion of its examples around a prototype. The         In contrast to the dual-system approach, there may be a
   detection of defining features cured networks from the effects
                                                                        continuum of concept crispness, perhaps covered by a more
   of conceptual crowding and example dispersion. Simulations
   captured the developmental shift from characteristic to defining     unified theory. A concept could have many features,
   features in a natural way.                                           including some that are defining and others that are
                                                                        probabilistic. It would be parsimonious for both sorts of
   Keywords:        Characteristic-to-defining    shift;    concept
                                                                        features to be represented in the same fashion, with the
   acquisition; defining features; neural networks.
                                                                        likelihood of a feature appearing in any exemplar varying
                                                                        probabilistically. A defining feature appears in examples with
                           Introduction                                 a probability of 1, whereas a characteristic feature appears
A major dichotomy has been proposed between concepts with               with a still substantial probability of less than 1.
characteristic versus defining features. Concepts with                     It is reasonable to suppose that exemplar classification is
defining features have such rigid boundaries that exemplars             affected by both the isolation of concepts in a
of one are only rarely confused with another. In contrast,              multidimensional feature space and by the dispersion of
probabilistic concepts have vague and overlapping                       exemplars in this space. That is, fuzzier concepts would be
boundaries, often making exemplars difficult to classify.               characterized by residing in a relatively crowded region of
   It has been argued that, although neural learning might              feature space and by having more widely dispersed examples;
provide an adequate account of fuzzy concepts, it cannot                crisper concepts by residence in a relatively isolated region of
account for the acquisition and representation of concepts              feature space and by limited dispersion of examples.
with defining features, such as kinship terms (Armstrong,               Exemplars of an isolated concept are unlikely to be confused
Gleitman, & Gleitman, 1983; Pinker, 1997). Some suggest                 with those of other concepts, whereas exemplars of crowded
instead dualistic theories – a neural theory for probabilistic          concepts could easily be misclassified, particularly if they are
concepts and a symbolic theory for defining-feature concepts            loosely dispersed around their prototypes. This notion of
(Pinker & Prince, 1996). Moreover, there is an interesting              conceptual crowding is consistent with the idea that concepts
developmental shift from emphasis on characteristic to                  are not randomly distributed in a multidimensional feature
defining features (Keil & Batterman, 1984).                             space, but rather may cluster in regions (Pinker & Prince,
   The dual-theory approach has a number of problems that               1996), sometimes called consequential regions (Shepard,
have not been solved. One problem is that a person would not            1987).
likely know which concept to access, the defining-feature one              A psychologically-documented case of exemplar dispersion
or the probabilistic one, for any particular example or context.        concerns the difference between jars and bottles (Malt,
                                                                    531

Sloman, Gennari, Shi, & Wang, 1999). For both Spanish and            activations correlate most highly with network error. To
English speakers, different jars were tightly distributed            counter the natural tendency to recruit a descendant unit
around a jar prototype, whereas different bottles were quite         (because of its extra weights), descendant correlations are
widely dispersed around a bottle prototype. For instance, pill       penalized by a default multiplier of 0.8.
bottles, milk bottles, and water-cooler bottles each possess            We report three simulations with SDCC encoder networks
quite different feature values, exhibiting a diversity not found     learning to recognize examples of crisp and fuzzy concepts.
among jars.                                                          Simulation 1 examines the effects of concept crowding and
   We hypothesized that defining features could protect an           example dispersion with probabilistic concepts, simulation 2
otherwise fuzzy concept from the problems posed by                   assesses the protective effects of defining features against
conceptual crowding and example dispersion. Even if a                these problems, and simulation 3 focuses on the
concept resides in a crowded neighborhood and has widely             characteristic-to-defining developmental shift.
dispersed examples, its exemplars might be categorized
correctly if defining features are discovered. The discovery of            Simulation 1: Crowding and Dispersion
defining features, specifying necessary and sufficient               The purpose of this first simulation was to test the idea that
conditions for concept membership, projects a crowded                classification accuracy is disturbed by concept crowding and
concept into a possibly less crowded region of feature space         example dispersion.
by providing new and useful dimensions to that space.
   We report here on simulations of concept learning using a         Concept Coding
variant of cascade-correlation (CC) encoder networks. CC
networks resemble ordinary back-propagation (BP) networks            The concepts used in these simulations are abstract and have
in propagating activation from one layer to the next and             no particular semantic content, thus affording better
learning the values of their connection weights. But CC              experimental control and greater generality than with
networks differ from ordinary BP networks by: (a) training           semantically-laden concepts.
weights only one layer at a time, thus avoiding the                     For each network, we began with a random ten-
biologically improbable back-propagation of error signals, (b)       dimensional vector of binary values, either -0.5 or 0.5. Ten is
growing as well as learning, by recruiting new hidden units as       a psychologically realistic number of features because when
needed, thus simulating the process of synaptogenesis, (c)           people were asked to list features of common object concepts,
also employing cross-connections that bypass hidden-unit             they produced between 6 and 15 features (Rosch, Mervis,
layers, and (d) using curvature as well as slope information on      Gray, Johnson, & Boyes-Braehm, 1976). This random vector
the error surface in order to adjust connection weights more         was the prototype for a loner prototype concept occupying an
decisively (Fahlman & Lebiere, 1990). CC networks have               isolated region of the ten-dimensional feature space. Next we
been used to simulate a variety of phenomena in                      randomly selected another ten-dimensional vector from those
psychological development (Shultz, 2003; Shultz, Mysore, &           that are orthogonal to the loner prototype. Orthogonality was
Quartz, 2007).                                                       defined by having a normalized inner product (NIP) of 0 with
   As with standard BP learning, CC can be used in encoder           the loner concept. We created three additional prototypes in a
mode, encoding inputs onto hidden units and then decoding            crowded region of the feature space by flipping either 1 or 2
hidden-unit representations onto output units (Shultz, 2003).        values of the orthogonal vector, depending on experimental
This implements a kind of recognition memory that does not           condition. The 1 or 2 values flipped were randomly selected
require a separate teaching signal specifying target output          without replacement. Values were flipped from -0.5 to 0.5, or
activations. Because encoder solutions can be trivial when           from 0.5 to -0.5. This provided four concept prototypes, one
direct input-output connections are permitted, we followed           of which was isolated and a trio which were close together in
the convention of eliminating them in CC encoder networks.           the ten-dimensional feature space. This was our manipulation
Computational and mathematical details of both the BP and            of concept isolation vs. crowding.
CC algorithms can be found elsewhere (Shultz, 2003).                    For each of these four concept prototypes, we then created
   A variant of CC allows the algorithm to install a new             ten examples by flipping 1, 2, or 3 values of the prototype,
hidden unit either on the highest hidden-unit layer (as a            randomly selected without replacement, depending on
sibling) or on its own higher layer (as a descendant) (Baluja        condition and subject to three further constraints: (a) each
& Fahlman, 1994). Descendant units have input weights from           example had a unique combination of features to flip,
all input units and previously installed hidden units. Sibling       ensuring that each example was unique, (b) each feature was
units do not receive inputs from their siblings previously           flipped in at least one example, and (c) no feature was flipped
installed on the same highest level. Sibling-descendant              in every example. This ensured that no defining features were
cascade-correlation (SDCC) has so far yielded similar                inadvertently created and it constituted our manipulation of
psychological coverage to standard CC but with fewer                 exemplar dispersion.
connection weights, shallower networks, and greater
topological variety (Shultz et al., 2007). An example of an
                                                                     Network Training
SDCC network topology is shown in Figure 3. Four sibling             We trained 20 SDCC encoder networks in each of the six
candidates and four descendant candidates compete for being          experimental conditions (2 levels of prototype flips x 3 levels
recruited. As with CC, SDCC recruits the candidate whose             of example flips), each network starting with random
                                                                 532

connection weights and random concept prototypes, for 700
or fewer epochs, an epoch being a pass through all of the
training patterns. Training stopped early when a network’s
outputs were all within score-threshold of their target values
for all training patterns. We used the conventional score-
threshold value of 0.4, which provides for an uncertain range
between -0.1 and 0.1.
   These encoder networks learned to recognize examples, not
to classify them into their respective prototype concepts.
There was no explicit teaching signal to enable classification
learning. This is realistic because category labels are not
always provided in human concept learning.
                                                                                    Figure 1: Concept crowding effects.
Results
After learning, we assessed network classification ability by
presenting all 40 training exemplars and computing the NIP
between each output vector and each of the four concept
prototypes. An exemplar was considered to be classified into
the concept yielding the highest NIP. We tallied the number
of correctly classified examples out of ten possible for each of
the four concepts. The numbers of correct classifications were
subjected to a mixed ANOVA where the between-network
factors were prototype flips (1 or 2) and example flips (1, 2,
or 3), and the within-network factor was concept (with 4
levels: loner plus the trio of close concepts). We report only              Figure 2: Concept crowding and example dispersion
the largest significant effects.                                                                   effects.
   The importance of concept isolation was revealed by main
effects of concept, F(3, 342) = 67, p < .0001, and number of           Most of the 120 networks recruited all of their hidden units
prototype flips, F(1, 114) = 39, p < .0001, and an interaction       on the same level. Five networks created more than one level
between them, F(3, 342) = 5.8, p < .001. The means for these         of hidden units and each of them had two layers of hidden
main and interaction effects are shown in Figure 1.                  units. Figure 3 shows the topology of a network that recruited
Classification was more accurate with the loner concept than         three hidden units on one layer and four on a second layer.
with the three crowded concepts. Classification was also             The arrows in Figure 3 indicate full connectivity between
better when the crowded concepts were relatively less                layers. There is also a bias input unit (always with an input of
crowded (2 prototype flips versus 1 prototype flip). The             1.0 and not shown in the figure) connected with trainable
interaction reflects that fact that number of prototype flips        weights to all downstream units.
affected performance on crowded-concept exemplars more
than it affected performance on loner-concept exemplars. At
both levels of prototype flips, as assessed by paired-samples t-
                                                                                                 10 output units
tests, performance was better on the loner concept than on
each of three trio concepts, p < .0001, none of which differed
from each other. All means in Figure 1 were well above the                                                              4 hidden units
chance level of 2.5, computed as ¼ of the number of
examples per mean, p < .01. This is also true of all other
means throughout the paper. Comparisons of obtained means                                                        3 hidden units
to the theoretical mean of 2.5 were made using Dunnett’s
(1955) technique.
                                                                                                  10 input units
   There was also a main effect of example flips, F(1, 114) =
256, p < .0001, and an interaction between example flips and
concept, F(6, 342) = 3.6, p < .002. The relevant means,                  Figure 3: Topology of an SDCC network in the condition
illustrating both crowding and dispersion effects, are shown                    with 2 prototype flips and 1 example flip.
in Figure 2. Classification accuracy decreased with dispersion
of examples (number of example flips). The interaction               Discussion
reflects a larger influence of example dispersion with the           This simulation documented the expected importance of both
crowded trio concepts than with the isolated loner concept. At       concept crowding and example dispersion for classification of
each level of example flips, performance was better on the           exemplars of probabilistic concepts. Classification was more
loner than on each of three trio concepts, p < .0001, none of        accurate for an isolated concept than for crowded concepts
which differed from each other.
                                                                 533

and more accurate for tightly dispersed examples than widely
dispersed examples. Isolated concepts were less affected by
example dispersion than more crowded concepts were.
Goldstone (1996) reported a similar example-dispersion
effect in experiments where people were trained in
classification, rather than in recognition memory as here.
     Simulation 2: Effects of Defining Features
Simulation 2 was designed to test the idea that defining
features would protect otherwise probabilistic concepts
against the effects of concept crowding and example
dispersion obtained in simulation 1.                                        Figure 4: Defining features protect against concept
                                                                              crowding, implemented by concept position.
Concept Coding and Network Training
After coding concepts as in simulation 1, we gave each
concept two additional binary features that uniquely defined
the concept. Defining features for the four concepts were
coded as (-0.5 -0.5), (-0.5 0.5), (0.5 -0.5), or (0.5 0.5),
respectively, by random assignment without replacement of
these four binary codes to the four concepts. These defining
features were present in each example, and were unaffected
by the probabilistic feature flipping used for the other ten
features. As in simulation 1, we trained 20 networks in each
of the six conditions for 700 or fewer epochs.
Results                                                                     Figure 5: Defining features protect against concept
                                                                               crowding, implemented by prototype flips.
After learning, we assessed network classification ability as in
simulation 1. The numbers of correct classifications were
subjected to a mixed ANOVA that included the results of
simulation 1 and an additional between-network factor
representing the presence or absence of defining features. All
four main effects (defining features, prototype flips, example
flips, and concept) were significant, p < .0001, and defining
features interacted with each of the other three variables. As
shown in Figure 4, without defining features, the familiar
signatures of concept crowding were evident. Performance on
examples from the crowded trio concepts was worse than
performance on the isolated concept. With defining features,
performance was nearly perfect for every concept, interaction
of defining features by concept F(3, 684) = 45, p < .0001.                  Figure 6: Defining features protect against example
   There was also an interaction between defining features                                     dispersion.
and prototype flips, F(1, 228) = 25, p < .0001, the means for
which are given in Figure 5. Without defining features,              Discussion
performance was worse with one prototype flip than with two
                                                                     This simulation showed that defining features protected
prototype flips. With defining features, this effect of concept
                                                                     otherwise probabilistic concepts against the typical effects of
crowding was eliminated.
                                                                     concept crowding and example dispersion. Introduction of
   Defining features also dampened the effects of example
                                                                     defining features allowed the fairly precise classification that
dispersion, as revealed by the interaction between defining
                                                                     was supposed to be impossible for neural networks. By
features and number of example flips, F(2, 228) = 114, p <
                                                                     treating defining features in the same manner as probabilistic
.0001, shown in Figure 6. Without defining features,
                                                                     features, neural networks can use defining features effectively
performance deteriorated with an increase in example flips.
                                                                     to produce nearly perfect classification of examples. Defining
But with defining features, this effect of example dispersion
                                                                     features project concepts into new dimensions and thus less-
was diminished.
                                                                     crowded regions of feature space.
                                                                        There was not a systematic difference in perfect
                                                                     performance between concepts with and without defining
                                                                     features, as would presumably be predicted by dual theories.
                                                                 534

Instead, there was perfect performance in isolated
probabilistic concepts with tightly dispersed examples, and
less than perfect performance in all defining-feature concepts
with more widely dispersed examples. It would be interesting
to see how well these simulations predict human results in
these respects.
      Simulation 3: Developmental Shift from
          Characteristic to Defining Features
Here we examine whether these networks capture the
characteristic-to-defining developmental shift. Keil and
                                                                            Figure 7: Characteristic-to-defining features shift for
Batterman (1984) reported that, with increasing age, children
                                                                                             concept crowding.
shift from using characteristic features to defining features in
those concepts that have defining features. As far as we
                                                                        Similar results were obtained for example dispersion. There
know, this effect had never been computationally simulated,
                                                                     was a main effect of example flips, F(2, 228) = 131, p <
although Rogers and McClelland (2004) showed that neural
                                                                     .0001, and an interaction of that with maximum epochs, F(2,
networks can simulate the progressive differentiation of
                                                                     228) = 38, p < .0001. The means are presented in Figure 8. At
concepts (Keil, 1979) and the tendency for concepts to be
                                                                     100 epochs, example dispersion produced classification
organized around causal knowledge that explains correlations
                                                                     errors, but there was relative protection against example
of features (Keil, 1991).
                                                                     dispersion at 700 epochs due to mastery of the defining
   On the assumption that young children have less
                                                                     features.
experience with examples than do older children, we
simulated the characteristic-to-defining shift by comparing
networks early in training to networks late in training. As in
the studies with children, this was a cross-sectional, rather
than a longitudinal, research design.
Concept Coding and Network Training
Concepts were coded as with the defining-features concepts
of simulation 2, using 10 probabilistic features and 2 defining
features. Twenty networks in each of the six conditions were
trained up to a maximum of 100 epochs. These networks
were then compared to the more fully trained networks of                    Figure 8. Characteristic-to-defining features shift for
simulation 2.                                                                                example dispersion
Results                                                                 The mean number of hidden units recruited in the networks
Numbers of correctly-classified examples out of 10 were              stopped at 100 epochs was 1.95, with all but 5 of the 120
subjected to a mixed ANOVA in which maximum epochs                   networks recruiting two hidden units. All hidden units were
was added as a between-network factor. Number of defining            installed as siblings, on a single level.
features was dropped from the ANOVA because all concepts
here had defining features.                                          Discussion
   The ANOVA yielded main effects of concept, F(3, 684) =            This simulation shows that these networks can naturally
22, p < .0001, and maximum epochs, F(1, 228) = 1173, p <             capture the developmental shift from using characteristic to
.0001, and an interaction between them, F(3, 684) = 17, p <          defining features. Early in the learning of concepts with both
.0001. The relevant means are shown in Figure 7. At 100              defining and probabilistic features, effects of concept
epochs, there was a crowding effect, with more accurate              crowding and example dispersion are evident. Later, as the
classification of exemplars of the loner concept than of the         defining features are discovered, they protect classification
three crowded concepts. Here, as assessed by paired-samples          performance against these probabilistic effects. This
t-tests, performance was better on the loner concept than on         developmental change shows that defining features cure the
each of three trio concepts, p < .0001, none of which differed       earlier effects of crowding and dispersion rather than
from each other. At 700 epochs, there was good protection            immunize against them.
against concept crowding due to eventual mastery of the                 In many natural concepts, the number of defining features,
defining features.                                                   if there are any, is likely to be smaller than the number of
                                                                     probabilistic features. In a sea of probabilistic features, it may
                                                                     take considerable experience to eventually discover the
                                                                     defining features of a concept. The hypothesis of essentialism
                                                                 535

is that concepts with defining features may have an empty                                    References
place holder (Medin & Ortony, 1989). People may believe
                                                                     Armstrong, S. L., Gleitman, L. R., & Gleitman, H. (1983).
that a concept has an essence provided by its defining
                                                                        What some concepts might not be. Cognition, 13, 263-
features, but they may not yet know what that essence is.
                                                                        308.
Despite using probabilistic information to classify examples
                                                                     Baluja, S., & Fahlman, S. E. (1994). Reducing network depth
of the concept, people may remain willing to yield to more
                                                                        in the cascade-correlation learning architecture. (No.
expert opinion about defining features.
                                                                        Technical Report CMU-CS-94-209). Pittsburgh, PA:
   The basis for this developmental shift in networks is the
                                                                        School of Computer Science, Carnegie Mellon University.
inherent tendency of neural networks to reduce as much error
                                                                     Dunnett, C. W. (1955). A multiple comparison procedure for
as possible. This tendency, in turn, derives from a weight-
                                                                        comparing several treatments with a control. Journal of
adjustment rule specifying that the amount of weight change
                                                                        the American Statistical Association, 50, 1096-1121.
is proportional to the derivative of error with respect to
                                                                     Fahlman, S. E., & Lebiere, C. (1990). The cascade-correlation
weight. Because probabilistic features are more numerous
                                                                        learning architecture. In D. S. Touretzky (Ed.), Advances
than defining features, probabilistic features naturally capture
                                                                        in neural information processing systems 2 (pp. 524-532).
more initial attention from the weight-adjustment process. As
                                                                        Los Altos, CA: Morgan Kaufmann.
the networks learn to reduce error as much as possible from
                                                                     Goldstone, R. L. (1996). Isolated and interrelated concepts.
attending to ubiquitous probabilistic features, they eventually
                                                                        Memory & Cognition, 24, 608-628.
attend to the small number of defining features, yielding more
                                                                     Hare, M., & Elman, J. L. (1995). Learning and morphological
precise classification.
                                                                        change. Cognition, 56, 61-98.
                                                                     Keil, F. C. (1979). Semantic and conceptual development: An
                    General Discussion                                  ontological perspective. Cambridge, MA: Harvard
These simulations show that SDCC encoder networks can                   University Press.
capture sensible phenomena regarding both crisp and fuzzy            Keil, F. C. (1991). The emergence of theoretical beliefs as
concepts. Simulation 1 revealed that classification errors              constraints on concepts. In S. Carey & R. Gelman (Eds.),
increase as concepts become crowded in multidimensional                 The epigenesis of mind: Essays on biology and cognition.
feature space and as examples become more widely dispersed              Hillsdale, NJ: Lawrence Erlbaum.
in that space. Simulation 2 demonstrated that the eventual           Keil, F. C., & Batterman, N. (1984). A characteristic-to-
discovery of defining features can protect networks against             defining shift in the development of word meaning.
these concept-crowding and example-dispersion effects.                  Journal of Verbal Learning and Verbal Behavior, 23, 221-
Simulation 3 captured the developmental shift from                      236.
emphasizing characteristic to emphasizing defining features,         Malt, B. C., Sloman, S. A., Gennari, S., Shi, M., & Wang, Y.
in concepts that possess defining features. Initially, networks         (1999). Knowing versus naming: Similarity and the
learning concepts with defining features showed the crowding            linguistic categorization of artifacts. Journal of Memory
and dispersion effects seen with probabilistic concepts.                and Language, 40, 230-262.
Continued learning allowed eventual detection of the defining        Pinker, S. (1997). How the mind works. New York: Norton.
features and eliminated the earlier effects of concept               Pinker, S., & Prince, A. (1996). The nature of human
crowding and example dispersion. As with the work of                    concepts: Evidence from an unusual source.
Rogers and McClelland (2004), our results suggest that                  Communication & Cognition, 29, 307-362.
artificial neural-network models can cover and explain               Rogers, T. T., & McClelland, J. L. (2004). Semantic
important psychological findings on concept acquisition.                cognition: A parallel distributed processing approach.
   In current work, we are exploring whether our model can              Cambridge, MA: MIT Press.
also capture some other, well-known psychological                    Rosch, E., Mervis, C., Gray, D., Johnson, D., & Boyes-
phenomena in the concept-acquisition literature, namely                 Braehm, P. (1976). Basic objects in natural categories.
pattern completion and prototype and exemplar effects. Also             Cognitive Psychology, 3, 382-439.
of current interest is whether our model could account for the       Shepard, R. N. (1987). Toward a universal law of
conflicted literature on the relative developmental order of            generalization for psychological science. Science, 237,
exemplar and prototype effects.                                         1317-1323.
                                                                     Shultz, T. R. (2003). Computational developmental
                     Acknowledgments                                    psychology. Cambridge, MA: MIT Press.
This research was supported by a grant to TRS from the               Shultz, T. R., Mysore, S. P., & Quartz, S. R. (2007). Why let
Natural Sciences and Engineering Research Council of                    networks grow? In D. Mareschal, S. Sirois, G.
Canada, and a Doctoral Fellowship to JPT from the Fonds                 Westermann        &      M.      H.      Johnson    (Eds.),
Québéçois sur la Nature et les Technologies.                            Neuroconstructivism: Perspectives and prospects (Vol. 2,
                                                                        pp. 65-98). Oxford, UK: Oxford University Press.
                                                                 536

