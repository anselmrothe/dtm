UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
How Goals Shape Category Acquisition: The Role of Contrasting Categories
Permalink
https://escholarship.org/uc/item/3w32n871
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Authors
Davis, Tyler
Love, Bradley C.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

         How Goals Shape Category Acquisition: The Role of Contrasting Categories
                                          Tyler Davis (thdavis@mail.utexas.edu)
                                     Bradley C. Love (brad_love@mail.utexas.edu)
                                Department of Psychology, The University of Texas at Austin
                                                       Austin, TX 78712 USA
                            Abstract                                 category ideal (Barsalou, 1985). For example, the goal
                                                                     derived category foods to eat on a diet will have a graded
    Categories associated with goals are often organized             structure near 0 calories (e.g., celery). Ideals have also
   around ideals rather than central tendencies. In such real-       been shown to influence the graded structure of
   world categories, items that are extreme are often                taxonomic categories when groups or other cultures that
   perceived as being the most typical.            Here, we
   demonstrate similar effects with artificial categories
                                                                     have goals associated with the category are tested (e.g.,
   learned in the laboratory. Our experiment and simulations         Atran, 1999). For example, tree experts have been shown
   suggest that low-level learning mechanisms that seek to           to view trees as more typical to the extent that they
   minimize prediction error may be responsible for aspects          minimize weediness (Lynch, Coley, & Medin, 2000).
   of category idealization. To minimize error, category                The majority of explanations for how this idealization
   centroids are adjusted to both increase similarity to their       occurs suggest that these effects depend upon real-world
   members, as well as to minimize similarity to members of          and cultural influences that are not present in artificial
   contrasting categories. This learning dynamic distorts
   category representations away from contrasting categories,        categories commonly used in the laboratory. Thus, these
   leading to idealization.                                          findings are often depicted as being at odds with
                                                                     approaches to categorization that rely on laboratory
   Keywords: Category learning, category use, goals.                 techniques such as mathematical modeling. It is our
                                                                     perspective, however, that these methods are continuous
                        Introduction                                 with one another, and that they can be mutually
   Increasingly, research suggests that a learner’s goals            informative. Further, we’ll argue that lower level learning
within an environment place substantial constraints on the           mechanisms described by e.g., error-driven clustering
content of their category representations (for review see            models, provide at least a partial explanation for how
Markman & Ross, 2003). For example, categories                       goals affect graded structure, whilst making predictions
learned by classification lead to important differences              for how these effects may be demonstrated in the
between those learned from inference, even though the                laboratory.
two tasks are formally equivalent. These effects that goals
have on category representations provide a critical                                     A Formal Model
challenge for formal approaches to category learning, as                Clustering models can be used to place a different
many models do not contain ways in which a learner’s                 perspective on how idealization occurs in categories
goals can exert any influence over their representations             defined by goals. To illustrate, in the diet food example
(cf. Love, 2005). At the same time, because of this                  above, a clustering model would have separate clusters
challenge, goals offer a substantial opportunity for cross-          representing diet foods and non-diet foods that would
fertilization between fields such as those studying                  initially be centered on the mean number of calories in
expertise/cultural psychology and those studying formal              their respective categories.        However, since the
modeling/laboratory experimentation. In the following,               distributions of calories in these two categories are
we discuss ways in which goal related influences on                  continuous, and even somewhat overlapping, sometimes
representations can be studied using formal models, and              food from one category will highly activate the cluster of
design a novel experiment using predictions from the                 the other category leading to error.           Error-driven
model and previous results from the cultural/expertise               clustering models will compensate for this error by
literatures.                                                         moving the cluster means on the calorie dimension further
   One finding in the cultural, expertise, and goal-derived          away from each other. After some trials, the clusters will
category literatures is that categories associated with              tend to move further apart than the actual category means,
goals have a graded structure determined by ideals.                  producing a marked shift in the graded structure of the
Graded structure refers to the notion that members of a              categories. Whereas at the outset of learning category
category differ in terms of how typical they are for the             members that are near the statistical central tendency of
category to which they belong. Whereas many categories               the category will produce the strongest activation, at the
have a graded structure determined by the category’s                 end of learning, items that are more extreme (i.e., ideal)
statistical central tendency (Rosch, 1975), goal-derived             on the goal dimension will.
categories have a graded structure centered around the
                                                                101

 Figure 1- An example stimulus. The dimensions of
variation are the height and the position of the line
segment.
   To illustrate how this happens in an error-driven
clustering model, we will use a simple model that is able
to capture this overall pattern, but is not a full model of
category learning in and of itself. This will allow us to
describe a set of principles that underlie the entire class of
error-driven clustering models, without having to deal
with the added complexity of attentional learning and
cluster recruitment that necessarily accompany these
models in their more complete forms.
   Formally, the model represents each category as a
cluster that gives the category’s mean and the standard
deviation along each dimension for which it is defined.
Each time a stimulus is encountered, activations are
                                                                    Figure 2 – Category structure and conditions. The letters
computed for each cluster, and the strength of these
                                                                    in parentheses give the possible choices on a given type of
activations determines how the stimulus will be classified.
                                                                    trial within a condition.
Activation, a, for a given cluster i is given as a Gaussian
                                                                                                                     dij 2
function of the presented stimulus value j:                                                                        #
                                     dij 2
                                                                                     %E                xjm # xim     2si 2
                              1    # 2                                 "x im = #$        = $ (ti # ai) 3         e            (4)
                    ai =          e 2si                  (1)                         %M                si 2&
                          s i 2"
Where si is the cluster’s standard deviation (this value is         Where " is a learning rate for the cluster mean, ti is the
constant in the present application), and dij is the distance!      feedback to cluster i,
between! presented stimulus j and the position of cluster i
given by:                                                                      ti = max(alpha,ai ) , if the item is in the
                                                                 !            category corresponding to cluster i
                    dij =    # (x  jm " x im ) 2         (2)
                                                                               t i = min(0,ai ) , if the item is not in the
                                                                                                                              (5)
                              m
                                                                  !           category corresponding to cluster i.
Where xjm is the value of stimulus j on dimension m, and
xim is the mean of cluster i on dimension m.                        In the applications described below, alpha,      " , and si are
   Cluster                                                        ! all free parameters.
       ! means are learned by gradient descent on an
error, which is the mechanism that allows the graded
structure of the categories to approach the category ideals.                      Experiment and Predictions
Whenever the position of a cluster along a dimension                                                  !
                                                                       Translating the model’s predictions    into ones that can
causes the cluster to become too highly activated in                be tested using artificial categories in the laboratory, this
response to a non-category member, the following                    suggests that idealization occurs in cases that require
equation updates the mean along this dimension in                   discriminating between stimuli along particular
proportion to the magnitude of the error.                           dimensions (see also Goldstone, 1996). In this
                                                                    experiment, we create a category learning task that
                          1                                         mimics this property of the goal-derived categories
                    E = (t i " ai ) 2                    (3)        described above. The stimuli for this experiment vary
                          2
                                                                    along two continuous dimensions (see Figure 1), and are
                                                                    partitioned into four categories that are separated in
                                                                    different respects along these dimensions (see Figure 2).
       !
                                                               102

   Different discrimination goals are made salient in this       opposite from that predicted by error-driven clustering
experiment by varying, between conditions, the types of          models.
contrasts subjects use to learn the categories, while
keeping the categories themselves constant. In the two           Method
unidimensional conditions (labeled Line-segment and
Height in Figure 2), subjects learn the categories by            Subjects 188 students from the University of Texas at
contrasting those that vary on only a single dimension.          Austin participated for course credit.
On any given trial in these conditions, subjects will have
the option of choosing between categories that are               Stimuli Stimuli were blue rectangles that varied in terms
discriminable on only one of the two dimensions that the         of their height and the position of a vertical line segment
stimuli are defined on (e.g. A & B or C & D in the line-         along their lower base. The rectangles had a fixed width
segment condition or A & C or B & D in the height                of 60mm, and their height and line segment position were
condition). In two other conditions, both dimensions will        sampled on each trial from one of four category
be made relevant either by alternating between trials that       distributions (A, B, C, D). These distributions were
allow subjects to choose categories separated on either the      approximately normal with standard deviations of 2.4mm
line-segment or height position (label Mixed in Figure 2),       and centered on (15mm, 21mm), (21mm, 21mm), (15mm,
or allowing subjects to choose freely between all                15mm), (21mm, 15mm) from the left side of the rectangle
categories on a given trial (labeled Free in Figure 2).          and base respectively. To keep the absolute range a
   The model’s predictions for these conditions are              category was allowed to vary over constant and allow for
straightforward and analogous to the discussion of how           some overlap between categories, all stimuli were
the model would apply to diet/non-diet food contrasts. In        required to be within 2 standard deviations of their
any condition for which a dimension is relevant to               respective mean.
learning the categories, the clusters will move away from
each other on this dimension as a result of the error-driven     Design Subjects completed a category learning phase,
learning mechanisms. However, this will not be the case          followed by a reconstruction phase in which they
for the irrelevant dimension in these conditions. Since          produced the average of each category.
irrelevant dimensions do not help to discriminate between           The category learning phase required subjects to learn
the categories, the model will predict no shift in graded        four categories: A, B, C, and D (see Figure 2).
structure along these dimensions.                                Conditions differed in how they were required to learn
   To assess whether subjects’ graded structure for these        these categories in that subjects were given a restricted set
categories has changed as a result of this learning, we will     of possibilities on each trial for which category a stimulus
have them reconstruct average stimuli from each                  belonged. In the unidimensional conditions, subjects only
category, and provide typicality ratings for stimuli             had to decide between categories differing on the line
observed during the category learning task. If the graded        segment dimension (A&B or C&D) or on the height
structure of these categories has been affected by goals, as     dimension (A&C or B&D), but not both. The mixed
predicted by the model, these reconstructions should be          condition varied these two types of comparisons, and
shifted away from the true mean of the categories and            subjects in the free condition were allowed to decide
away from the categories that they have been contrasted          between all possible categories on every trial. Category
with. Similarly, the typicality ratings should show that         labels were randomized for each subject.
items that are further away from opposing categories on             In order to complete the category learning phase,
the dimensions that were contrasted during learning are          subjects were required to either achieve a criterion of 80%
more typical than items that are closer to the statistical       correct in a single block of 40 stimulus presentations (10
average of the category along these dimensions.                  from each category), or complete 5 blocks total. On each
   It is important to note that these predictions derived        trial a stimulus was sampled at random. The mean height
from the model are not predicted by clustering models            and line segment position of stimuli in a given category in
without error-driven learning (e.g., Anderson, 1991) or          a given block were required to equal the mean of the
classical Roschian accounts of graded structure (Rosch,          distributions that they were drawn from.
1975). These accounts predict that the reconstructed                In the reconstruction phase, subjects were asked to
category averages and typicality ratings will not depend         recreate the average member of each category. To do
on how the categories were contrasted during learning.           this, they used the arrow keys to adjust the height and line
Instead, all conditions would be expected to have the            segment position of a stimulus randomly drawn from the
same graded structure determined by the categories’              respective category distribution. This phase lasted for
statistical central tendency. Further, Bayesian accounts of      three blocks in which each category was queried once.
memory for stimulus magnitude predict that the                   Trial order was randomized with the constraint that the
reconstructed averages would actually distort toward the         same category could not appear twice in a row.
center of the overall category distribution (Huttenlocher,          In the typicality phase, subjects were asked to rate how
Hedges, & Vevea, 2000; Sailor & Miram, 2005). This is            typical each stimulus was on a continuous scale that was
                                                             103

presented in red below the stimulus. Stimuli for the
typicality phase were the same stimuli from the first two
blocks of the category learning phase.
Procedure Directions were displayed on the screen prior
to each phase. Subjects wore headphones to deliver
auditory feedback and dampen background noise.
   On each category learning trial a stimulus was
presented in the center of the screen along with a prompt
telling the subject which categories they could choose
from. After keying in their response, they were given
corrective feedback for 2000 ms followed by a blank
screen for 500 ms.
   On each trial of the reconstruction phase, a stimulus
was presented in the center of the screen along with a
prompt telling the subject which category average to
adjust the stimulus to resemble. The subject used the
arrow keys to continuously adjust the stimulus, and each
trial was self-paced. No feedback was given during               Figure 3- Reconstruction results by condition. I.
reconstruction.                                                  Unidimensional- relevant dimension II. Unidimensional-
   On each trial of the typicality phase, subjects were          irrelevant dimension III. Free IV. Mixed. Positive scores
prompted to rate the typicality of a given stimulus for the      are away from opposing categories and negative scores
category to which it belonged, by moving a red dot on a          are toward opposing categories.
line with the arrow keys between ends marked “Very
Typical” and “Not Typical.” Each trial was self pace, and        Reconstruction Reconstructions were scored as
no corrective feedback was given.                                distortions from the respective category mean, with
                                                                 negative scores depicting distortions toward the center of
Results and Discussion                                           the stimulus space (i.e., toward the opposing categories),
                                                                 and positive scores depicting distortions away from the
Category Learning In the present experiment, the                 center of the stimulus space (away from the opposing
category learning phase was meant to serve as the key            categories). Scores were calculated for each dimension
manipulation in predicting how subjects would respond in         for each individual subject. Because differences between
later portions of the experiment (i.e., the reconstruction       physical dimensions were not of interest, we pooled the
and typicality phases). As such, the category learning           reconstruction results into four data points: rule-relevant
data was not particularly important for any of the               dimension reconstructions in both unidimensional
hypotheses we discussed in the introduction in and of            conditions (line segment & height), irrelevant dimension
itself. Instead, we use the category learning data only as a     reconstructions, both dimensions in the mixed condition,
measure of which participants successfully learned the           and both dimensions in the free condition. See Figure 3
task, and should therefore be included in the analysis of        for reconstruction results.
the reconstruction and typicality data. Subjects were               In the unidimensional conditions on the relevant
excluded from the rest of the analyses if they failed to         dimension, the mean reconstruction was 1.738 mm. This
perform significantly better than chance in their final          represents a significant distortion away from the true
classification block. However, because the number of             mean of the category (0), t(76)=11.28,p<.01, and away
available choices on each trial differed between                 from the opposing categories. In contrast, on the
conditions, chance also differed. In conditions 1, 2, and 3      irrelevant dimension the mean reconstruction was -.735
subjects were excluded if they answered less than 62.5%          mm, indicating that subjects in the unidimensional
correct, and in condition 4 where four categories could be       conditions tended to distort in the opposite direction
chosen from on a given trial, subjects were excluded if          (toward the opposing categories), t(76)=3.46,p<.01. In
they answered less than 37.5% correct. These values              the other conditions, free and mixed, subjects distorted
were based on binomial distributions with p=.5                   away from the opposing categories slightly less than in
(conditions 1, 2 & 3) or p=.25 (condition 4), N=40, and          the unidimensional conditions with a mean reconstruction
95% confidence levels. This resulted in the removal of 12        of .963 mm in the free condition t(35)=5.68, p<.01, and
subjects in the line segment unidimensional condition, 5         .912 mm in the mixed condition t(36)=4.76, p<..01.
subjects in the height unidimensional condition, 11              These conditions both distorted away from the opposing
subjects in the mixed condition, 9 subjects in the free          categories significantly less than observed in the
condition. Removing these subjects did not affect the            unidimensional conditions (p<.01).
pattern of results.
                                                             104

   These data show that if a dimension is relevant in
learning a task, subjects’ reconstructed averages along
this dimensions shift away from opposing categories, and
are predicted from the current account of shifts in graded
structure arising from learning mechanisms. The negative
shifts (toward the center of the category distribution)
observed on the irrelevant dimension in the horizontal and
vertical conditions are not predicted by the present
framework. However, they would be predicted by models
of memory for stimulus magnitude that show that
subjects’ reconstructions are biased toward the overall
mean in tasks using single categories or where the
difference between categories is learned incidentally
(Huttenlocher, Hedges, & Vevea, 2000; Sailor & Miram,
2005).
Typicality For analysis of the typicality data, individual
stimuli were scored according to their distance from their
respective category mean (see reconstruction results) with
negative values depicting stimuli that are closer to the
center of the stimulus space on a given dimension,
positive values depicting stimuli that are closer to the
extremes on a given dimension, and zero representing the
actual category mean. Figure 4 shows typicality as a
function of the position of a stimulus within its respective
category for each condition. The typicality graph for the
unidimensional conditions are shown with the line
segment dimension as the relevant dimension, however
                                                                 Figure 4- Typicality in each condition as a function
the data used to construct the graph are averaged from
both the line segment and height conditions.                     of stimulus position.
   In order to quantify the differences that are apparent in
the graphs, we ran individual regression models on each          Model-Based Analysis
subject’s typicality data using the values of the stimuli           In this section, we illustrate how the error-driven
along both dimensions as predictors. Positive regression         clustering model that we introduced above is able to
slopes along a dimension indicate that as stimuli become         account for the data from the reconstruction phase of the
further away from opposing categories along this                 experiment. To accomplish this, the model was trained
dimension, the observed typicality increases, whereas            using the same general procedure as described above for
negative slopes indicate a decrease. Thus, significantly         human subjects, except that on each iteration it was
positive slopes along a dimension indicate that the graded       trained for the full five blocks and not cut-off upon
structure is shifted toward the ideals along this dimension.     reaching a criterion. The model’s predictions for
   Significantly positive slopes were observed in the            reconstruction were obtained by using the centered (see
unidimensional conditions for the relevant dimension             reconstruction results) final cluster positions, and hand
(.273) t(76)=14.04, p<.01, and the irrelevant dimension          fitting the model to the average reconstruction on the
(.047) t(76)=2.77, p<.01. While the irrelevant dimension         relevant dimension from the two unidimensional
was not predicted to have a significant impact on                conditions.
typicality scores, the slopes on this dimension were                As discussed above, idealization effects like those
significantly smaller t(76)=8.08, p<.01, showing that this       observed in the reconstruction and typicality data are an a
impact was less than with the relevant dimension. In the         priori prediction of error-driven clustering models. As
free condition typicality increased positively as the            such, there are no parameter settings at which results
observed value of the stimuli increased on both                  opposite those obtained could be predicted. Because of
dimensions (.186) t(35)=10.11, p<.01, and the same               this, fitting the model only served to calibrate the
occurred in the mixed condition (.196) t(35)=10.02,p<.01.        predicted cluster distortion to the level observed in the
   These data largely concur with those hypothesized             experiment, and also to examine how the model predicts
above for typicality ratings. If a dimension is relevant for     performance across conditions to differ.
learning the categories, as stimuli become more extreme             The model’s predictions were calculated using the
(i.e., ideal) along this dimension, they become more             average final cluster positions obtained from 10,000
typical.                                                         simulations with parameters set at: " =142.70, alpha=.05,
                                                                 and si= 5. The reconstruction predictions are 1.738 mm
                                                             105
                                                                                         !

for the unidimensional conditions on the relevant                  particular, only considers the statistics of the learning
dimension, ~0 mm for on the irrelevant dimension, 2.076            environment in forming representations, and would not
for both dimensions in the free condition, and 1.009 for           predict any of the observed shifts in graded structure, nor
both dimensions in the mixed condition.            The model       any of the differences in reconstructions between
therefore predicts all of the qualitative effects discussed in     conditions. Still, environmental statistics clearly place
the introduction and demonstrated in the reconstruction            important constraints on any categorization problem, and
data.                                                              researchers need to consider ways of incorporating the
   The model is able to capture the direction of the               effects of both into their models (cf. Love, 2005).
distortions along relevant dimensions in all of the present           In conclusion, we demonstrate that manipulating the
cases because of the error-driven learning mechanism.              goals of subjects within a task can cause the graded
By shifting the mean of a cluster along a relevant                 structure of artificial categories learned in the laboratory
dimension, the model can maximize its ability to                   to be organized around ideals. This is important for
discriminate between categories that are separated along           category learning modelers and those who focus on
this dimension. However, the model, in its current                 laboratory experiments because it helps to provide
formulation, is unable to capture the distortions toward           continuity between cultural and laboratory research. Like
the center of the category distribution observed on the            other findings regarding goal related influences on
irrelevant dimensions in the unidimensional conditions.            category representations, this also has implications for the
Instead, the model can only predict no distortion along            field of human categorization as a whole, because it offers
these dimensions because they don’t contribute to the task         additional support for the irreducible influence of
goal. Adding a bias term to reflect this tendency of               category use on category representations. Finally, the
subjects to distort toward the center of the category              modeling described above may help to motivate and
distribution would allow the model to predict these                inform future research in cross-cultural studies of concept
effects, and would be psychologically motivated given the          use, and thus open a broader dialog between research
findings from the literature on memory for stimulus                programs that are often isolated from each other within
magnitude discussed above.                                         the field.
                  General Discussion                               Acknowledgments
   The present experiment and simulations show that goals
can cause idealization in artificial categories learned in         This work was supported by AFOSR Grant FA9550-04-1-
the laboratory. When subjects only were required to                      0226 and NSF Grant 0349101 to Bradley C. Love
discriminate between categories using a single dimension,
their reconstructions scores showed that the graded                                        References
structure was determined by ideals on only this
dimension.       However, when subjects learned the                Anderson, J. R. (1991). The adaptive nature of human
categories using both dimensions, ideals determined the               categorization. Psychological Review, 98, 409-429.
graded structure on both dimensions. These results are an          Barsalou, L.W. (1985). Ideals, central tendency, and
a priori prediction of error-driven clustering models that            frequency of instantiation as determinants of graded
explain these effects as arising from simple learning                 structure of categories. Journal of Experimental
mechanisms.                                                           Psychology: Learning, Memory, and Cognition 11,
   One contribution of this research is in highlighting the           629-654.
continuity between category learning in the laboratory             Goldstone, R. L. (1996). Isolated and Interrelated
and more ecologically based studies of concept use. The               Concepts. Memory & Cognition, 24, 608-628.
present research suggests that it is important to consider         Huttenlocher, J., Hedges, L. V. & Vevea, J.L. (2000).
the role of simple learning mechanisms in producing                   Why do categories affect stimulus judgment? Journal
idealization effects, which are often described as requiring          of Experimental Psychology: General, 129, 1-22.
abstract theoretical knowledge. While we do not suggest            Love, B. C. (2005). Environment and goals jointly direct
that error-driven learning models are able to explain all             category     acquisition.    Current     Directions    in
occasions in which goals have an effect on graded                     Psychological Science, 14, 195-199.
structure, we do believe that they provide an important            Lynch, E. B., Coley, J. D., & Medin, D. L. (2000). Tall is
alternate description that may help to predict performance            typical: Central tendency, ideal dimensions and graded
inside and outside of the laboratory.                                 category structure among tree experts and novices.
   As with many findings that show differences in                     Memory and Cognition, 28, 41-50.
category representations arising from differences in               Sailor, K.M., Miriam, A. (2005). Is memory for stimulus
people’s goals, these results are problematic for                     magnitude Bayesian? Memory & Cognition, 33, 840-
approaches to category learning that do not allow task                851.
demands to influence category representations.
Anderson’s rational model (Anderson, 1991), in
                                                               106

