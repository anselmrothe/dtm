UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Categorizing Fragments of Exemplars: Experimental and Computational Results
Permalink
https://escholarship.org/uc/item/16059626
Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)
Author
Harris, Harlan D.
Publication Date
2008-01-01
Peer reviewed
 eScholarship.org                                 Powered by the California Digital Library
                                                                    University of California

 Categorizing Fragments of Exemplars: Experimental and Computational Results
                                             Harlan D. Harris (harlan.harris@nyu.edu)
                                                        6 Washington Place, 8th Floor
                                                          New York, NY 10003 USA
                              Abstract                                   uli on category learning (not categorization). Taylor and
   Analysis of the relative categorization accuracy of whole and         Ross (2007) found that learning with partial stimuli yields
   partial items may provide deeper insight into the nature of cat-      more extensive learning about category structure. Verguts et
   egorization processes. I compared several logical, mathemati-         al. (2004), in a paper focusing on problems with geometric
   cal and computational models of categorization (including the
   FLMP, KRES, and variants of the GCM), and ran an experi-              theories of similarity and the effects of redundant features,
   ment to get robust empirical data. The experiment showed a            also considered learning with partial stimuli. They described
   mixture of categorization strategies used by different subjects.      a version of the ALCOVE model (Kruschke, 1992) with an
   When known rule-based strategies were excluded, the remain-
   ing subjects responded more accurately than theoretically op-         additional parameter that allows it to fit their data, but do not
   timal to single feature stimuli. This result is inconsistent with     analyze this issue extensively.
   standard exemplar and connectionist models, and with theoret-            The work reported here was spurred by research consider-
   ical models of perceptual integration, but is consistent with an
   interactive model of categorization that allows top-down feed-        ing how changes in the number of dimensions affects learn-
   back to affect representations of partial stimuli.                    ing of family resemblance categories (e.g., Table 1, left).
   Keywords: concepts and categories; computer simulation;               Hoffman and Murphy (2006) and Hoffman, Harris, and Mur-
   human experimentation; mathematical modeling; neural net-             phy (2008) considered learning of such categories and found
   works                                                                 that more dimensions were learned when more dimensions
   Decades of work on the basic cognitive processes of                   were present, under a variety of conditions. As part of their
categorization has provided sophisticated information about              analysis, Hoffman et al. (2008) tested several computational
how stimuli are represented, how categories are stored, how              models of category learning. A standard independent-feature
similarity is computed, and how categorization choices are               recognition model, the Fuzzy Logical Model of Perception
made (Ashby & Maddox, 2005). Surprisingly, little work has               (FLMP, Oden & Massaro, 1978), predicts a precise relation-
considered how partial stimuli are categorized, and as far as            ship between Whole Item (WI) and Single Feature (SF) re-
I know, no work has investigated the mathematical relation-              sponse accuracy, with SF accuracy lower than was empiri-
ships between partial-item and whole-item categorization of              cally found. Other straightforward models had similar prob-
stimuli with more than two features.                                     lems. However, the Knowledge Resonance (KRES, Rehder &
   Should missing properties be ignored for the purposes of              Murphy, 2003) model was able to account for the relatively
categorization? Or, if only 20% of a representation is present,          high SF accuracy level, as well as other details of the experi-
perhaps we should be only 20% confident in a categoriza-                 mental results.
tion? Most physical objects that have to be categorized during              The results of Hoffman et al. (2008) raise as many ques-
our day-to-day lives are not fully visible, yet are categorized          tions as they answer, so this work moves beyond some of
quickly and accurately, as if the missing information were               that work’s limitations. First, I have extended the analysis
unimportant (Taylor & Ross, 2007). Different categorization              to consider exemplar models and Estes’ union and intersec-
models make different predictions about how partial stimuli              tion rules. Second, a new experiment expands testing to al-
are treated, so a better understanding of this process would             low analysis of individual subject strategies. Third, early test
constrain the set of viable theories.                                    phases allow investigation of responses throughout learning.
   Several studies have tangentially addressed categorization
of partial stimuli. Estes, Campbell, Hatsopoulos, and Hur-                               Models and Simulations
witz (1989), in a study about base-rate effects, considers cat-          The task given to the models (and the participants, below)
egorization of hypothetical diseases given unequally predic-             was to distinguish two categories of stimuli. The abstract
tive symptoms. Base-rate neglect was found during single-                category structure is shown in Table 1 (left). Each train-
feature tests, with accuracy higher than expected. (Here, I              ing stimulus was made up of four features that are predom-
examine the simpler case of non-probabilistic, equally-likely            inant in one category and one feature that is predominant in
categories, with equally predictive features.) Referencing this          the other category. All dimensions are equally predictive of
study, Estes (1994) notes that partial stimuli can be encoded            the category. There were three types of test items (Table 1,
in a model using either a union rule or an intersection rule.            right): whole items (D1-D5, K1-K5), prototypes (D0, K0),
In the former case, missing dimensions are treated as a mis-             and single-features (DF1-DF5, KF1-KF5).
match in the similarity computation; in the latter case, miss-
ing dimensions are treated as a match.                                   Rule-based Models
   Two recent papers (Verguts, Ameel, & Storms, 2004; Tay-               Learning can induce logical rules that describe the categories.
lor & Ross, 2007) have considered the effects of partial stim-           Different rules make different predictions about test item ac-
                                                                     409

               Table 1: Abstract Category Structure
                    Training                Testing
                Item Features       Item Features
                D1      10000       training items plus:
                D2      01000       D0        00000
                D3      00100       K0        11111
                D4      00010       DF1 0—-
                D5      00001       DF2 -0—
                K1      01111       DF3 –0–
                K2      10111       DF4 —0-
                K3      11011       DF5 —-0
                K4      11101       KF1 1—-
                K5      11110       KF2 etc.
Note. “-” symbol indicates no feature presented for the given dimen-     Figure 1: Relative accuracy of simple 1-layer network models
sion. In the experiment, items D0 and K0 were tested twice as often      on the whole-item and single-feature tests, over a range of
as the other items.                                                      parameters. Solid line is the predictions of the FLMP.
curacies. First, using a 1-D rule, four of the five dimensions
are ignored while one dimension is used as the cue to cat-                  W is the probability of responding correctly to a whole
egorization. Prototype accuracy would then be 100%, WI                   item, f is the probability of responding correctly to any sin-
accuracy would be 80% (reflecting the cue validity of each               gle feature, and n is the number of dimensions that make up a
dimension), and SF accuracy would be 60% (100% accuracy                  whole item. The inverse of this function predicts SF accuracy
on the attended-to dimension, averaged with 50% accuracy                 from WI accuracy. (Note that here, as the whole items such
on the other dimensions.)                                                as 11110 have four supporting features and one contradictory
   The simplest rule that always correctly categorizes whole             feature, n = 3 instead of n = 5.)
items is to attend to three of the five dimensions and use a 2-             A further equivalence is between the FLMP and a standard
of-3 rule. For example, if the stimulus is 11011, and the first          one-layer connectionist network (Cohen & Massaro, 1992;
three dimensions are those attended, then there are more 1s              Massaro & Friedman, 1990). This type of network has one
than 0s, and the appropriate response would be made. Under               output node per potential category response, where each node
this rule, prototype and WI accuracy would be 100%, while                computes the weighted sum of the stimulus representation,
SF accuracy would be 80% (100% on three dimensions, and                  then “squashes” the result through a sigmoidal function to
50% on two).                                                             get a response probability. The weights of the network can be
                                                                         changed according to a supervised learning rule. When only
FLMP/Bayes/Network Models                                                two category responses are possible, this sort of network will
Next, consider the FLMP, a commonly-used and successful                  make exactly the same predictions as the FLMP, for any stage
model of how independent sources of evidence may be com-                 of learning and any (non-degenerate) set of weights.
bined in recognition (Massaro, 1987; Massaro & Friedman,                    I implemented a one-layer network model with fixed
1990). The FLMP assumes that stimulus features are repre-                weights representing category prototypes, as if the model had
sented as the degree to which they support each of the cat-              been trained to perfection, and tested it on whole items and
egories, on a continuous scale from 0 (completely false), to             single features. Five input nodes were connected to a single
.5 (no evidence), to 1.0 (completely true). Category response            output node with all weights wi = 1. Whole item stimuli were
probabilities are then calculated using a standard choice rule:          of the form I = [1, 1, 1, 1, −1], while SF stimuli were of the
                                                 xk yk                   form I = [1, 0, 0, 0, 0]. The output node computed the function
                 P(Ak |X = Xi ,Y = Y j ) =      m         .      (1)     O = (1 + tanh(β I · w))/2, where β is a parameter indicat-
                                               ∑i=1 xi yi
                                                                         ing the sharpness of the sigmoid, and O was the probability
   The FLMP is a Bayesian rule for combining evidence, if                of responding consistently with the 11111 prototype. Note
the representation of the features is precisely equal to the cue         that imperfect learning would be represented in the model by
validity (Cohen & Massaro, 1992).                                        w < 1, which is mathematically equivalent in this case to scal-
   A mathematical property of the FLMP is that relative accu-            ing β, so varying β simulates testing the model with varying
racy of responses to whole stimuli can be predicted from the             amounts of training. Figure 1 shows the predictions of this
accuracy of responses to partial stimuli, or vice-versa. When            simple network model, with β ranging from 0 to 2, along
each dimension is equally predictive, as in the current cate-            with the curve defined by Equation 2. Clearly, the model’s
gory structure (Table 1), this is particularly easy to write:            simulated predictions exactly line up with the FLMP’s the-
                                                                         oretical predictions. Single feature accuracy is significantly
                           fn             ( f /(1 − f ))n                lower than the accuracy on the whole items, throughout the
             W=                     =                       ,    (2)     parameter space of the model.
                    f n + (1 − f )n     ( f (1 − f ))n + 1
                                                                     410

GCM
The Generalized Context Model (Nosofsky, 1986) is an ex-
emplar model of categorization, and so assumes that catego-
rizations are made by comparing the stimulus to stored exem-
plars, with responses based on a function of those similarity
computations (Medin & Schaffer, 1978). The equations that
describe the GCM are as follows:
                           m                    1/r
                          ∑ (wk |xik − x jk |)r
                        
                 di j =                              ,       (3)
                          k=1
                          −λdi j
                 si j = e        ,                           (4)     Figure 2: Relative accuracy of GCM models on the whole-
                 sic = ∑ si j ,                              (5)     item and single-feature tests, with γ = 1 and varying λ pa-
                        j∈c                                          rameter. Using r = 1 (city block) similarity metric, m had no
                            γ
                           sic                                       effect (black line). Using r = 2 (Euclidian) similarity metric,
                 θic =         γ .                           (6)     effect of m is shown by different colored lines.
                        ∑d sid
   The first equation describes the psychological distance be-               a             b               c               d
                                                                                X    Y         X    Y          X    Y          X    Y
tween stimuli i and j, the second describes the similarity be-
tween stimuli i and j, the third describes the similarity be-
tween stimulus i and category c (containing several exem-                      A1    B1       A1    B1       A1     B1       A1     B1
plars), and the fourth describes the decision rule. The r pa-                     A0   B0        A0   B0         A0   B0         A0   B0
rameter varies depending on the representation of the stimuli,                           input           input           input
and is typically set to r = 1 for separable dimensions, such
as are used here, or r = 2 for integral dimensions (but see
below). As all dimensions are equally salient, all weights           Figure 3: Process of top-down feedback on category activa-
wk = 1/n. λ (often called c) is a parameter that determines          tion in KRES. From (a) initial weak universal activation, (b)
the sharpness of the generalization or typicality gradient. γ is     input affects bottom-up activation of input (A1 and A0) and
a response scaling parameter that related category member-           category (X, Y) nodes, (c) feeds back from category node X
ship probabilities and response proportions; when γ = 1, the         to both presented and nonpresented input nodes, then (d) re-
model probability-matches (Ashby & Maddox, 1993).                    verberates back up to increase category activation further.
   As did Verguts et al. (2004), I added a parameter m to
the GCM that allows missing values to be dealt with during
similarity comparisons. Assuming the values of dimensions            categories that have associations are linked together by bidi-
are normally −1 or +1, missing dimensions from the stimu-            rectional weighted connections. Activation moves along the
lus are replaced by m times the value from the exemplar. If          links in top-down, bottom-up, and lateral directions, eventu-
m = −1, missing dimensions are treated as maximally differ-          ally converging to a pattern that represents the most consis-
ent from the point of view of the similarity calculation, ala        tent interpretation of the stimulus, given everything else the
Estes’ Union rule. If m = +1, missing dimensions are ig-             model has represented. (KRES features not used here include
nored from the point of view of the similarity calculation, ala      representations of prior knowledge, learnable connections be-
Estes’ Intersection rule. Intermediate values have intermedi-        tween nodes, and the use of exemplar nodes, Harris & Rehder,
ate effects on similarity calculations.                              2006.) KRES has been shown to account for a variety of ef-
   Figure 2 shows the results of simulating the GCM (+ m) on         fects in categorization, category learning, and the interaction
the test stimuli in Table 1, with the training stimuli as stored     of learning with prior knowledge (Rehder & Murphy, 2003;
exemplars. The λ parameter was varied over the range [0, 10],        Harris & Rehder, 2006; Hoffman et al., 2008).
while the γ and r parameters were set at either 1, their usual          The mathematics that describe the implementation of
values for this task, or 2. When r = 1, as is typically used         KRES are presented in Rehder and Murphy (2003), and are
when stimuli have separable dimensions, the GCM predicts             similar to other interactive activation models (McClelland &
SF accuracy slightly below the FLMP predictions. When                Rumelhart, 1981). A key property of KRES is that top-down
r = 2, however, SF accuracy can be higher than FLMP pre-             feedback can cause missing dimensions to be “filled in,” as if
dictions. Curves with γ = 2 are similar.                             a feature were actually present in the stimulus. Figure 3 il-
                                                                     lustrates the mechanism in a two-dimensional case. Stimulus
KRES                                                                 “1-” would be treated almost as if it were “11”.
The KRES model (Rehder & Murphy, 2003) is an interac-                   When the KRES model simulates the task (Table 1), SF
tive activation, constraint satisfaction model. Features and         response accuracies tend to be above the FLMP ratio (Fig-
                                                                 411

                                                                      Figure 5: Prototypes of the Dax and Kez categories used in
                                                                      the Experiment.
Figure 4: Relative accuracy of 5000 KRES models on the
whole-item and single-feature tests, with randomly varying
                                                                      of subjects were tested following blocks 2 and 8, 1/3 were
weight and activation parameters.
                                                                      tested following blocks 5 and 8, and the remaining 1/3 were
                                                                      tested only following block 8. This allowed an examination
ure 4). The model had five pairs of input units, connected to         of performance earlier in learning, when overall accuracy was
category prototype nodes with equally-weighted connections.           expected to be lower. Second, half the subjects did “sim-
The magnitude of fixed excitatory and inhibitory weights,             ple” test blocks, categorizing each of the 24 samples twice,
as well as a parameter describing the sharpness of node re-           while half of the subjects did “complex” test blocks, cate-
sponses, were varied randomly across a wide range. Each               gorizing each of the 24 samples only once, but also making
stimulus was provided to the input layer in turn (for the two         a frequency estimation that was expected to provide a more
feature nodes representing each dimension, 1 was encoded              continuous dependent measure.
as +1, −1, 0 was encoded as −1, +1, and - was encoded as
0, 0). Once the network settled, the category activations were        Method
converted into response probabilities.
                                                                      Participants and Design 49 NYU undergraduates partici-
   Three patterns are evident (Figure 4). In one pattern, accu-       pated in the experiment for course credit. Of these, the data
racy on whole items is relatively good yet SF accuracy is at          from 10 participants were not included due to equipment fail-
chance. Analysis showed that model parameters were large              ure (2), failure to reach a performance criterion (7), or fail-
in magnitude and the network was in an unstable part of its           ure to follow instructions (1). Participants were randomly as-
parameter space. In a second pattern, KRES performance is             signed to the two between-subjects factors, test blocks (2+8,
similar to that of the simple network, suggesting that some           5+8, or 8), and test type (simple, complex).
parameter settings yield little top-down feedback. (With only
bottom-up activation flow, KRES’s computations are nearly             Materials Stimuli were star-like “ceremonial symbols,” as
the same as those of the simple network.) In the third pattern,       used previously by Hoffman (2007) (see Figure 5). Partici-
KRES performance is significantly above the FLMP curve                pants learned to to distinguish the symbols from the “Dax”
once whole-item performance exceeds about 70%. Top-down               tribe from symbols from the “Kez” tribe. The abstract cat-
feedback enhances activation of both presented and nonpre-            egory structure is shown in Table 1 (left). All dimensions
sented features, using them to boost response accuracy above          were equally predictive, and pretesting by Hoffman (2007)
what would be expected from an independent feature model.             indicated that each dimension was about equally salient.
   These results show that the result observed by Hoffman et             During test phases, subjects responded to the training
al. (2008), a relatively high SF/WI ratio, could potentially be       items, plus additional test items (Table 1, right). Single-
accounted for by either the KRES model or by the GCM (but             feature stimuli were presented with only a single line of the
only if the stimuli are integral). To evaluate these predictions,     star visible. Prototype stimuli were presented twice as often
I now turn to empirical methods.                                      as other stimuli.
                                                                      Procedure Each participant performed eight blocks of
 Experiment: Whole Items and Single Features                          training and either one or two blocks of testing. Each train-
This experiment was designed to replicate and extend the              ing block consisted of a single training trial for each of the 10
Hoffman et al. (2008) result, and to test the computational           stimuli. Responses had no deadline, and feedback was pro-
models discussed above. As in the earlier experiment, sub-            vided for 4 s.
jects learned about stimuli with a family resemblance struc-             In the test blocks for the simple test condition, each test
ture (Table 1) and were then tested.                                  item was presented in random order twice, while for the com-
   The major factor of interest was a within-subjects contrast–       plex test condition, each item was presented once. In the com-
the relationship between WI and SF accuracy–but I varied              plex condition, following the categorization response, partic-
two factors between subjects to get a broader set of data. 1/3        ipants provided a frequency estimate: if they had found 100
                                                                  412

  Table 2: Average Test Accuracy and Frequency Estimates
                       Accuracy                 Frequency
                  Proto. WI        SF       Proto. WI        SF
       Test 2       .93     .75    .72        67      72     60
       Test 5       .93     .79    .72        72      72     54
       Test 8       .98     .91    .84        80      75     69
        2+8        1.00     .92    .86        85      83     81
        5+8         .97     .91    .82        83      76     63
        8           .96     .90    .84        68      64     63
Note. Proto. = Prototype; WI = Whole Item; SF = Single Fea-
ture. Frequency estimates are out of 100 items of the speci-
fied type. Last three rows show Test 8 accuracy for each test
blocks condition.                                                          Figure 6: Relationship between WI and SF accuracy on test
                                                                           phases. Data points are randomly jittered to reduce overlap.
                                                                           Blue line indicates theoretical FLMP performance. Circled
identical symbols, how many of them would be from the cul-                 areas indicate performance predicted by specific rules.
ture of their classification response?1
Results                                                                    However, on SF tests, subjects using this strategy should have
The two major concerns regarding the learning phase of the                 only 80% accuracy. Five learners had this accuracy pattern in
experiment are whether subjects learned to a reasonable level              test 8. Finally, some learners had perfect accuracy on both
of proficiently, and whether the presence of the early test                WI and SF tests. Any number of strategies would yield this
phases substantially impacted what was learned. Follow-                    result, and there is no way of distinguishing between them.
ing training, accuracy had increased from chance to .897,                  12 learners had perfect accuracy by the end of training.
and a mixed-design ANOVA2 with blocks, test type, and test                    The remaining 38 points on the graph represent test accu-
blocks as factors, showed the expected main effect of blocks,              racies of participants who (I conservatively assume) were not
F(7, 231) = 30.88 > 2.05, η2p = .48. As for the effect of                  using the 1-D or 2-of-3 strategies, and who did not have per-
the early test phases, the learning curves had somewhat dif-               fect performance. The mean of this subset of the data was
ferent shapes depending on when subjects performed tests.                  W I = .789, SF = .750. 35 tests were above the FLMP line,
Training accuracy increased somewhat more sharply follow-                  and only 3 were below the line. This was statistically signifi-
ing early test blocks, significantly so following the block 5              cant by a Wilcoxon sign test, χ2 (1) = 26.95 > 3.84.
test, F(1, 38) = 4.28 > 4.10, η2p = .10. However, by the fi-                  There are thus four patterns of test results. Participants
nal block of training, the accuracy differences had entirely               can use 1-D rules or 2-of-3 rules, they can respond perfectly,
disappeared. Additionally, the response patterns on test 8                 or they can respond imperfectly but with SF accuracy higher
were not affected by the presence or absence of earlier tests,             than predicted by independent feature models like the FLMP.
Fs(1, 36) < 1, as shown in Table 2 (left). These questions                    The final analysis is to consider the frequency estimates
answered, we may now proceed with the analysis of the key                  from the complex test phases. Mean frequency estimates are
data from the test blocks themselves.                                      shown in Table 2 (right). If subjects are frequency match-
   Figure 6 shows the relationship between WI and SF accu-                 ing, such that their response proportions are equal to their
racy during testing. Several clusters of points can be seen,               frequency estimates, then frequency should parallel accuracy.
representing participants using different strategies.                      Although the majority of sensical responses (16 of 23) were
   First, with W I = .8 and SF = .6, are subjects who may                  above the (frequency matching) FLMP predictions, examina-
be using a single dimensional rule to categorize. (See the                 tion of the data shows that many participants did not make
Rule-based Models section, above.) Four learners had this                  frequency estimates correctly. For example, several subjects
accuracy patterns in test 8. Second, with W I = 1.0 and SF =               gave frequency estimates below 50% (in two cases as low as
.8, are subjects who may be focusing on three dimensions and               20%), despite the fact that there were only two categories, and
ignoring the other two. The 2-out-of-3 rule discussed above is             a response below 50% would imply the opposite category re-
an optimal strategy for learning the whole items of this task.             sponse from what they actual gave. Therefore, the frequency
                                                                           estimation data should be treated with caution.
    1 A more traditional typicality rating would not be useful here,
as broken symbols were not typical of the training items, and the
quantitative relationship between single-feature estimated frequency                                Discussion
and whole-item estimated frequency is the measure in question.
    2 Statistics are reported by comparing the computed test statistic     Different models predict different patterns of SF/WI accuracy
with the threshold for significance, assuming p = .05, and reporting       ratios. The simple network, FLMP, and related models all
the partial eta-squared measure of effect size.                            predict a strict Bayesian relationship, with SF accuracy rel-
                                                                       413

atively low until WI accuracy is very high. Under some cir-            of the 28th Annual Conference of the Cognitive Science So-
cumstances, when stimulus dimensions are integral, the GCM             ciety (pp. 1440–1445). Mahwah, NJ: Lawrence Erlbaum
can predict higher SF accuracy. The KRES model predicts a              Associates.
high SF accuracy by virtue of its top-down feedback mecha-           Hoffman, A. B. (2007). Attention dynamics in category learn-
nism. An empirical test of these models found that individual          ing. (Unpublished doctoral dissertation, New York Univer-
subjects seemed to choose a variety of strategies, including           sity.)
simple decision rules, but that a substantial proportion did         Hoffman, A. B., Harris, H. D., & Murphy, G. L. (2008).
not use an identifiable strategy. These subjects almost always         Prior knowledge enhances the category dimensionality ef-
had a SF/WI ratio higher than predicted by the FLMP class of           fect. Memory & Cognition, 36, 256–270.
models. As the stimuli used in the experiment did not involve        Hoffman, A. B., & Murphy, G. L. (2006). Category dimen-
integral dimensions, but instead used very separable dimen-            sionality and feature knowledge: When more features are
sions, it seems unlikely that the GCM can account for the              learned as easily as fewer. Journal of Experimental Psy-
data. Only the KRES model and its top-down feedback has                chology: Learning, Memory, and Cognition, 32, 301–315.
the potential to account for the results.                            Kruschke, J. K. (1992). ALCOVE: An exemplar-based con-
   This work has two major consequences. First, it continues           nectionist model of category learning. Psychological Re-
a line of research that has shown that categorization may be           view, 99, 22–44.
more a process of constraint satisfaction, influenced by top-        Massaro, D. W. (1987). Categorical partition: A fuzzy logical
down, causal, and knowledge-related factors, than a simple             model of categorization behavior. In S. Harnad (Ed.), Cat-
similarity comparison (Harris & Rehder, 2006; Murphy &                 egorical perception. Cambridge, England: Cabridge Uni-
Medin, 1985; Rehder, 2003; Rehder & Murphy, 2003). Sec-                versity Press.
ond, it supports a novel new line of research that considers         Massaro, D. W., & Friedman, D. (1990). Models of integra-
partial stimuli as an important test of categorization theories        tion given multiple sources of information. Psychological
(Hoffman et al., 2008; Taylor & Ross, 2007; Verguts et al.,            Review, 97, 225–252.
2004). Critically, the work reported here (and (Hoffman et           McClelland, J. L., & Rumelhart, D. E. (1981). An interactive
al., 2008)) is the first to mathematically examine the relation-       activation model of context effects in letter perception: Pt.
ship between whole and partial item categorization accura-             1. An account of basic findings. Psychological Review, 88,
cies. Future experimental and theoretical work will further            375–407.
examine this issue, with a goal of identifying further con-          Medin, D. L., & Schaffer, M. M. (1978). Context theory
straints on models of categorization.                                  of classification learning. Psychological Review, 85, 207–
                                                                       238.
                      Acknowledgments                                Murphy, G. L., & Medin, D. L. (1985). The role of theories in
This work was supported by NIH grants F32MH076452 and                  conceptual coherence. Psychological Review, 92, 289–316.
MH041704. Thanks to Bob Rehder, Gregory Murphy, and                  Nosofsky, R. M. (1986). Attention, similarity, and the
Aaron Hoffman for helpful suggestions, and for Danielle                identification-categorization relationship. Journal of Ex-
Blinkoff and Renee Fultz for assistance running subjects.              perimental Psychology, 115, 39–57.
                                                                     Oden, G. C., & Massaro, D. W. (1978). Integration of featural
                           References                                  information in speech perception. Psychological Review,
Ashby, F. G., & Maddox, W. T. (1993). Relations between                85, 172–191.
   prototype, exemplar, and decision bound models of cate-           Rehder, B. (2003). Categorization as causal reasoning. Cog-
   gorization. Journal of Mathematical Psychology, 37, 372–            nitive Science, 27, 709–748.
   400.                                                              Rehder, B., & Murphy, G. L. (2003). A knowledge-resonance
Ashby, F. G., & Maddox, W. T. (2005). Human category                   (KRES) model of category learning. Psychonomic Bulletin
   learning. Annual Review of Psychology, 56, 149–178.                 & Review, 10, 759–784.
Cohen, M. M., & Massaro, D. W. (1992). On the similarity of          Taylor, E. G., & Ross, B. H. (2007). Classifying partial
   categorization models. In F. G. Ashby (Ed.), Multidimen-            exemplars: Seeing less and learning more. (Manuscript in
   sional models of perception and cognition (pp. 395–448).            preparation)
   Hillsdale, NJ: Lawrence Erlbaum Associates.                       Verguts, T., Ameel, E., & Storms, G. (2004). Measures of
Estes, W. K. (1994). Classification and cognition. New York:           similarity in models of cognition. Memory & Cognition,
   Oxford University Press.                                            32, 379–389.
Estes, W. K., Campbell, J. A., Hatsopoulos, N., & Hurwitz,
   J. B. (1989). Base-rate effects in category learning: A com-
   parison of parallel network and memory storage-retrieval
   models. Journal of Experimental Psychology: Learning,
   Memory, and Cognition, 15, 556–571.
Harris, H. D., & Rehder, B. (2006). Modeling category learn-
   ing with exemplars and prior knowledge. In Proceedings
                                                                 414

