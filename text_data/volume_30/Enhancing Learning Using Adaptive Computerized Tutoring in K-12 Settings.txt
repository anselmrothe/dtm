UC Merced
Proceedings of the Annual Meeting of the Cognitive Science
Society
Title
Enhancing Learning Using Adaptive Computerized Tutoring in K-12 Settings

Permalink
https://escholarship.org/uc/item/4p70m3pc

Journal
Proceedings of the Annual Meeting of the Cognitive Science Society, 30(30)

Authors
O'Donnell, Carol
Harwood, Robin
Gholson, Barry
et al.

Publication Date
2008-01-01
Peer reviewed

eScholarship.org

Powered by the California Digital Library
University of California

Enhancing Learning Using Adaptive Computerized Tutoring in K-12 Settings
Gautam Biswas1
(gautam.biswas@vanderbilt.edu)
Daniel Schwartz2 & Kefyn M. Catley3

Carol O’Donnell (Carol.O’Donnell@ed.gov)
& Robin Harwood
Institute of Education Sciences, U.S. Dept. of Education,
Washington, DC 20208

1

Department of Computer Science
Vanderbilt University, Nashville, TN 37240
2
School of Education, Stanford University
3
Department of Biology, Western Carolina University

Barry Gholson
(b.gholson@mail.psyc.memphis.edu)
Art Graesser & Scotty D. Craig

Stephanie Siler (siler@andrew.cmu.edu)

Department of Psychology
The University of Memphis, Memphis, TN 38152

Department of Psychology
Carnegie Mellon University
Pittsburgh, PA 15213

Wayne Ward1 (Wayne.Ward@Colorado.edu)
& Ronald Cole2

1

Center for Computational Language & Ed. Research,
University of Colorado, Boulder, CO 80309
2
Boulder Language Technologies

Keywords: Adaptive computerized tutoring; dialog; selfregulated learning; deep-level reasoning; science

AutoTutor to a learning environment called iDRIVE
(Instruction with Deep-level Reasoning questions in
Vicarious Environments). The iDRIVE system provided
vicarious learning in which students listened to and observed
the AutoTutor agent presenting the same course content, but
students did not adaptively interact with the materials. Results
from the first study indicate that 342 8th-11th grade students
showed greater learning gains in Newtonian physics and
computer literacy when assigned to the iDRIVE condition (in
which content sentences were each preceded by a deep-level
reasoning question) than those learners who were presented
with the same content offered in a monologue condition (no
deep-level reasoning questions). This finding in favor of
iDRIVE has implications for return on investment because it
is more costly to develop an interactive AutoTutor than to
script an exchange with iDRIVE.
Our first classroom comparison involved six classrooms of
8th graders (n = 160) randomly assigned to an iDRIVE
condition (computerized version), monologue condition
(computerized version), or standard pedagogy in which
students received standard instruction given by their teachers.
The iDRIVE software produced learning pretest to posttest
learning gains equal to or greater than those produced by
master classroom teachers on a variety of measures. A second
randomized intervention paired various conditions with
classroom instruction. iDRIVE software taught the
conceptual component of two units of high school physics,
used three vicarious conditions: standard monologue
condition, standard iDRIVE condition, and an iDRIVE
condition with an additional explanation. Findings indicate
that students in the two iDRIVE conditions performed better
than students in the monologue condition. Current findings
from these two studies appear to confirm results from our
laboratory experiments.

How do we individualize instruction and develop cognitive
skills to enhance learning? Computer tutors can provide
scalable interventions that tailor instruction to each student.
This symposium brings together cognitive scientists,
computer engineers, content specialists, and education
researchers to address adaptive computerized tutoring—a key
topic in both cognitive science and education. The papers
represent innovations in cognitive science research drawing
from discourse comprehension theory and theories of
metacognition. These theories are tested across several
cognitive skills (deep-level reasoning, self-regulated
learning), within multiple content domains (science, math,
computer literacy), and across a range of ages in authentic
classroom settings (elementary school to college). In her role
as discussant, Stephanie Siler will address the common theme
of these projects: finding ways to use intelligent tutoring
systems to improve learning through thinking and reasoning,
consistent with these theories. Carol O’Donnell, Program
Officer for the Cognition and Student Learning Research
Program at the Institute of Education Sciences, and Robin
Harwood will moderate this panel and facilitate discussion
throughout the symposium.

An Implementation of Vicarious Learning with
Deep-Level Reasoning Questions in Middle
School and High School Classrooms
The overarching goal of our research (Gholson, Graesser,
& Craig) is to expose deep-level reasoning questions in the
areas of computer literacy and Newtonian physics to middle
school and high school students and to show how they
support knowledge construction during vicarious learning.
We compared an interactive intelligent tutoring system called

695

Improving Science Learning through Tutorial
Dialogs

A Learning by Teaching Approach to Help
Students Develop Self-Regulatory Learning
Skills in Middle School Science Classrooms

In the 2002 National Assessment of Educational Progress
(NAEP), only 2% of U.S. students attained advanced levels of
mathematics or science achievement by Grade 12. We (Ward
& Cole) provide individualized instruction to students
through natural spoken dialogs with a virtual tutor that
behaves like an expert human tutor. By developing and
evaluating the integration of tutorial dialogs by human and
virtual tutors in elementary science curricula in large
classroom vs. small group settings, we can compare learning
gains of students who receive tutoring to students in control
conditions. This work is being implemented for children’s
science learning in schools that previously performed poorly
with FOSS (Full Option Science System), a structured
science program shown to work with many but not all
students. We will discuss our current development project
that uses dialogs based on Questioning the Author (QTA;
Beck & McKeown, 2006). QTA uses open-ended questions
to help students learn to integrate new concepts with what
they know to deepen and expand the knowledge that was
presented in class. QTA, shown to improve reading
comprehension nationally, uses systematic dialog interaction
to foster deep learning. The virtual tutoring system closely
resembles tutorial dialogs produced by human tutors trained
in the QTA method. Along with elementary teachers, FOSS
curriculum developers, QTA experts, and 3rd, 4th and 5th
graders in a large city school district in Colorado, we will
develop and refine the system using an iterative design
process. Students in classrooms will be randomly assigned to
receive either (a) standard classroom instruction and support,
(b) classroom instruction with support incorporating QTA
dialogs in a large group, (c) small-group tutoring with QTA
with a trained human tutor, or (d) small group interaction with
the computer-based QTA tutoring system.

To help students develop metacognitive self-regulatory
learning (SRL) skills in middle school classrooms, we
(Biswas, Schwartz, & Catley) implemented a computer-based
learning environment called Teachable Agents (TAs), where
students learn by teaching a computer agent called Betty.
Students monitor, assess, and reflect on their own learning by
asking Betty questions and observing her performance on
quizzes provided with the system. The belief that they help
their agent learn motivates the students and guides them
toward metacognitive activities that aid their learning.
Additional metacognitive support is provided by Betty’s
persona, who demonstrates the use of self-regulation
strategies in her interactions with her student teacher. In
Tennessee, we conducted several studies in 5th grade science
classrooms that measure student learning by the quality of the
students’ concept maps produced while teaching their agent.
We found that learning-by-teaching with metacognitive
support helped students learn about river ecosystems and
better prepared them for future learning on related topics. The
cover story of teaching an agent led to more complete and
interconnected concept maps. Learning outcomes were
strongest for students who also received metacognitive
feedback from Betty. These differences persisted during a
transfer phase in which students learned about a new domain
and taught their agent in the absence of most feedback and
prompts. We have also studied students’ activity patterns as
they teach their agent. Analysis shows that the quality of
students’ concept maps is paralleled by patterns in their
behaviors. SRL prompts from the agent seem to help students
engage in productive learning interactions. Unlike
conventional tutoring that provides feedback on domain
content, our tutoring tracks students’ activity patterns and, at
appropriate times, provides feedback on SRL strategies.
In experiments in California schools, classes were
randomly assigned to a Betty (TA) or Inspiration (commercial
concept mapping tool) condition. Over 11 days of the
curriculum, we introduced additional technology features
designed to enhance SRL and measure learning. Students
completed assignments using the online homework
environment. Pre-, post-, and midstream-learning measures
indicated that the Betty condition showed an increasing
advantage over the lesson units, particularly on items that
required long chains of inference. The largest benefit
occurred when the homework environment was introduced.
Betty students were also more prepared to learn from a new
unit without any technological support. These studies at
Vanderbilt and Stanford suggest the interventions are
valuable for improving learning and metacognition as seen in
increased abilities to learn in future contexts.

Discussant
Dr. Stephanie Siler is part of a team with David Klahr and
Mari Strand-Cary developing an intelligent tutor to improve
elementary and middle school students’ conceptual
understanding and procedural skills of designing and
interpreting scientific experiments.

Acknowledgments
Research reported here was supported by the Institute of
Education Sciences, U.S. Department of Education. The
opinions expressed are those of the authors and do not
represent views of the Institute or the U.S. Department of
Education.

Reference
Beck, I., & McKeown, M. (2006). Improving comprehension
with Questioning the Author: A Fresh and Expanded
View of a Powerful Approach. Scholastic.

696

