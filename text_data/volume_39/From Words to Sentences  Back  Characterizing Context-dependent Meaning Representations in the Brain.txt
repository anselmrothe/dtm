                                         From Words to Sentences & Back:
          Characterizing Context-dependent Meaning Representations in the Brain
                                        Nora Aguirre-Celis (naguirre@cs.utexas.edu)
                                                      ITESM, Monterrey, Mexico &
                                           Department of Computer Science, 2317 Speedway
                                                        Austin, TX 78712 USA
                                    Manuel Valenzuela-Rendon (valenzuela@itesm.mx)
                                                       ITESM, Monterrey, Mexico
                                           Risto Miikkulainen (risto@ cs.utexas.edu)
                                          Department of Computer Science, 2317 Speedway
                                                        Austin, TX 78712 USA
                              Abstract                               researchers to develop new componential approaches, where
                                                                     concepts are represented by a set of basic features, or
   Recent Machine Learning systems in vision and language            attributes, based on textual and perceptual input. (Bruni, et
   processing have drawn attention to single-word vector spaces,     al., 2012; Silberer & Lapata, 2014, Vinyals et. al., 2015).
   where concepts are represented by a set of basic features or      However, even with their multimodal embedding space,
   attributes based on textual and perceptual input. However,
   such representations are still shallow and fall short from
                                                                     such vector representations fall short from symbol
   symbol grounding. In contrast, Grounded Cognition theories        grounding.
   such as CAR (Concept Attribute Representation; Binder et             In contrast, embodiment theories of knowledge
   al., 2009) provide an intrinsic analysis of word meaning in       representation (Regier, 1996; Landau et al., 1998, Barsalou,
   terms of sensory, motor, spatial, temporal, affective and         2008) provide a direct analysis in terms of sensory, motor,
   social features, as well as a mapping to corresponding brain      spatial, temporal, affective, and social phenomena. Further,
   networks. Building on this theory, this research aims to          these theories can be mapped to brain networks. Recent
   understand an intriguing effect of grounding, i.e. how word
   meaning changes depending on context. CAR representations         fMRI studies helped identify a distributed large-scale
   of words are mapped to fMRI images of subjects reading            network of sensory association, multimodal and cognitive
   different sentences, and the contributions of each word           regulator systems linked with the storage and retrieval of
   determined through Multiple Linear Regression and the             conceptual information (Binder et al., 2009). This network
   FGREP nonlinear neural network. As a result, the FGREP            was then used as a basis for Concept Attribute
   model in particular identifies significant changes on the         Representation (CAR) theory, an embodiment theory that
   CARs for the same word used in different sentences, thus
                                                                     enumerates semantic features of concepts and grounds them
   supporting the hypothesis that context adapts the meaning of
   words in the brain. In future work, such context-modified         in brain networks (Binder et al., 2009, 2011 and 2016).
   word vectors could be used as representations for a natural          An intriguing challenge to such theories is that concepts
   language processing system, making it more effective and          are dynamic, i.e. word meaning depends on context and
   robust.                                                           recent experience (Pecher, Zeelenberg, & Barsalou, 2004).
   Keywords: Neural Networks; FGREP; Concept Attribute               For example, a pianist would invoke different aspects of the
   Representation theory; fMRI; Context; Meaning; Semantics;         word piano depending on whether he will be playing in a
   Embodied Cognition                                                concert or moving the piano. When thinking about a coming
                                                                     performance, the emphasis will be on the piano’s function,
                         Introduction                                including sound and fine hand movements. When moving
Recently, Deep Learning systems of vision and natural                the piano, the emphasis will be on shape, size, weight and
language processing (NLP) have drawn special attention               other larger limb movements.
into single-word vector spaces. They are able to extract low            This paper focuses on addressing these challenges based
level features in order to recognize concepts (e.g. cat), but        on the CAR theory. The main idea is that different attributes
they are incapable of forming an abstract notion of the              in CARs can be weighted differently depending on context,
concept (symbol). In general, these models build semantic            i.e. according to how important each attribute is in that
representations from text corpora where words that appear            context. More specifically, neutral CARs of words are first
in the same context are likely to have similar meanings              used to form an expected fMRI pattern of a subject reading
(Harris, 1970; Landauer & Dumais, 1997, Burgess, 1998;               a sentence. That pattern is compared to an actual fMRI
Baroni et. al., 2010). However, such representations lack            image. Two techniques, multiple linear regression and a
intrinsic meaning, which means sometimes even different              FGREP neural network, are then used to determine how the
concepts may appear similar. This problem has driven                 CARs would have to change to account for the actual fMRI
                                                                 1507

pattern. These changes represent the weighting in context; it           the word meaning. An example is shown in Figure 2. For a
is thus possible to track the dynamic meanings of words by              more detailed account of the attribute selection and
tracking how the weighting changes across contexts.                     definition see Binder et al. (2009, 2011 and 2016).
   Experiments with available fMRI data show that the
approach is feasible, demonstrating meaningful differences                        Data Collection and Preprocessing
for e.g. human communication vs. noise from a machine;                  Two existing data sets were used in this study: fMRI images
dangerous storm vs. dangerous person; live mouse vs. dead               of sentences and CARs obtained via Mechanical Turk.
mouse. These changes are principled and could be captured
e.g. by a neural network. It might then be possible to create           Neural Images
them dynamically, and form as a basis for a more robust and
                                                                        The stimuli shown to subjects consisted of a list of 240
grounded natural language processing system.
                                                                        every day written sentences prepared in the Knowledge
   The CAR theory is first reviewed below, and the sentence
fMRI and word representation data described. The methods                Representation in Neural Systems (KRNS) project
for determining semantic changes, i.e. multiple linear                  (Glasgow et al., 2016). The sentences are composed by
regression and FGREP, are then presented, followed by an                three to nine words from a set of 242 words (141 nouns, 39
analysis of the results.                                                adjectives and 62 verbs). Eleven subjects took part in this
                                                                        experiment producing 12 repetitions each. Participants
                                                                        viewed the sentences word by word while in the scanner.
                                                                        The data was acquired by the Center for Imagining Research
                                                                        of the Medical College of Wisconsin (Anderson et al.,
                                                                        2016). The fMRI data was preprocessed and transformed
                                                                        into a single sentence fMRI representation per participant
                                                                        (by averaging all the repetitions), with a final selection of
                                                                        396 voxels per sentence on a scale from 0.2-0.8, for further
                                                                        use in the computational models.
Figure 1: Perceptual Grounding. CARs are composed of a list of
known modalities that relate to specialized sensory, motor and
affective brain processes, systems processing spatial, temporal, and
casual information, and areas involved in social cognition. They
capture aspects of experience central to the acquisition of abstract
and concrete event as well as object concepts.
                                                                        Figure 2: Bar plot for CAR 66 semantic features. The attribute
Concept Attribute Representation Theory                                 ratings represent the basic features of chair. Given that this
CARs represent the basic components of meaning defined in               concept is an object, gets low weightings on human-related
terms of known neural processes and brain systems (Binder,              attributes: face, speech, social, and emotion and strong on visual,
2016). They relate semantic content to systematic                       shape, touch, manipulation, and some others.
modulation in neuroimaging activity. And are therefore not
limited to the classical sensory-motor dimensions of most               Semantic Vectors
embodied theories.                                                      The semantic attribute ratings were collected thru Amazon
   CARs are composed of a list of well-known modalities                 Mechanical Turk for each of the 242 words (e.g. family,
that correspond to specialized sensory, motor and affective             hospital, chair, small, green, laughed, listened, walked). In
brain processes, systems processing spatial, temporal, and              a scale of 0..6, the participants were asked to assign the
casual information, and areas involved in social cognition.             degree to which a given concept is associated to a specific
They capture aspects of experience central to the acquisition           type of neural component of experience (e.g. “To what
of event and object concepts (both abstract and concrete).              degree do you think of a chair as having a fixed location, as
   These attributes were selected after an extensive body of            on a map?”). Approximately 30 ratings (all attributes for
physiological evidence based on two assumptions: (1) all                each word) were collected. After averaging all the ratings
aspects of mental experience can contribute to concept                  and removing outliers, the final attributes were transformed
acquisition and consequently concept composition; (2)                   to unit length yielding a collection of 66-dimensional
experiential phenomena are grounded on neural processors                feature vector that captures the weights of association
representing a particular aspect of experience (Figure 1).              between each neural attribute and the 242 words. Note that
   These aspects of mental experience model each word as a              in this manner, the richness and complexity of
collection of a 66-dimensional feature vector that captures             representations is based on intrinsic meaning of each word,
the strength of association between each neural attribute and           and not on word co-occurrence (Figure 2).
                                                                    1508

Data Preparation
The data set did not include fMRI images for words in
isolation, a technique developed by Anderson et al. (2016)
was adopted to approximate them. The voxel values for
words were obtained by averaging all fMRI images for the
sentence where each word occurred. Thus, the vectors
include a combination of examples of that word along with
other words that appear in the same sentence (context).
Because of the limited number of combinations, some of
these became identical, and were excluded from the dataset.
   Given the final set of 237 sentences and 236 words (138
nouns, 38 adjectives and 60 verbs), the next step was to
identify pairs of sentences with differences on word
meanings such as live mouse vs. dead mouse, good soldier
vs. soldier fighting, built hospital vs. damaged hospital, and
playing soccer vs. watching soccer. This collection will               Figure 3: General System framework and data flow. Mapping
allow the computational models to evaluate distinctive                 CARWord to SynthWord (top). Then SynthWord is combined by
attribute representations and consequently adjust the base-            averaging to form SyntSent and to be compared to the actual
line meaning of a word to convey the effects of context and            fMRISent (middle). Invert the process to modify the CARWords
conceptual combination.                                                via SynthWord revised (bottom). The Revised CARWord includes
   A collection of 77 such sentences, with different shades            different word meaning across sentences.
of meaning for verbs, nouns and adjectives, as well as
different contexts for nouns and adjectives was assembled.             Multiple Linear Regression
This collection will be used as Words of Interest (WoI) for            At the word level, Multiple regression (LReg) is used to
the analysis of context in the experiments (Table 1).                  learn the mapping between CARWord and SynthWord
                                                                       voxels. The training set has attribute vectors of words as
Table 1: Contrasting Sentences. Eight sentences from the               independent variables and the corresponding SynthWord
collection of the 77 contrasting sentences. Here, for instance, the    vectors as the dependent variable, predicting one voxel at
verb kicked is used in two different contexts, playing with a ball     the time. Similarly, at the sentence level, the training
(as in Soccer) vs. breaking the door (as an aggressive behavior).
                                                                       contains assembled sentences (SynthSent) as independent
                                                                       and the corresponding Observed fMRISent as the dependent
                                                                       variable. Once the prediction error is calculated, LReg is
                                                                       inverted (which is possible because it is linear), to determine
                                                                       what the CARWord values should have been to make the
                                                                       error zero.
                                                                       Neural Network with FGREP
                                                                       It is possible that the linear prediction based on LReg is not
                                                                       powerful enough to account for the context effects.
                                                                       Therefore, a nonlinear approach based on neural networks is
                  Computational Models                                 tested as well. A neural network is trained to map
                                                                       CARWord to SynthWord, which are then averaged (as
A new technique is proposed in this section for analyzing              before) into a prediction of the sentence SynthSent (Figure
data imaging. It is grounded on the CAR theory and                     4). The prediction error is used (through backpropagation)
implemented using Multiple Linear Regression (LReg) and                to train the network.
the     FGREP         neural     network      (Forming      Global        After training, this network is used to determine how the
Representations with Extended BP; Miikkulainen & Dyer,                 CARWords should change to eliminate the error. That is,
1991). The main idea is to predict sentence fMRI by                    for each sentence, the CARWords are propagated and the
mapping CARWord to SynthWord (fMRI) (top of Figure 3).                 error is formed as before, but during backpropagation, the
The SynthWord is then combined by averaging to form                    network is no longer changed. Instead, the error is used to
SyntSent for the predicted sentence. Next, the SynthSent is            change the CARWords themselves (which is the FGREP
compared to the actual fMRISent (middle of Figure 3). The              method---Forming         Global     Representations     through
differences are included by modifying the SynthWord that               Extended backPropagation; Miikkulainen et al., 1991). This
map to fMRISent and by modifying the CARWord that map                  modification can be carried out until the error goes to zero,
to the modified SynthWord (bottom of Figure 3). The                    or no additional change is possible (because the CAR values
resulting CARWord indicate how word meaning change                     are already at their max or min limits).
across sentences.
                                                                   1509

Figure 4: The FGREP model to account for context effects. Propagate CARWord to SynthWord. Compose SynthSent by averaging the
words into a prediction of the sentence. Compare SynthSent against Observed fMRISent. Backpropagate the error with FGREP for each
sentence, freezing network weights and changing only CARWord. Repeat until error reaches zero.
   Training the neural network requires as input the 236            changes as shown, for sentences 89 and 92 in the right side
CARWord 66-dimensional vectors (W1, W2, W3) and as                  of Figure 5.
target, the equivalent corresponding 396-dimensional                   CARs in Sentence 89 presented salient activations in
SynthWord vector (W’1, W’2, W’3). The network then                  human-related attributes like Face, and Body, Audition, and
learns a general mapping of words across all sentences. This        Speech, as well as Human, Communication, and Cognition,
mapping is then utilized in the FGREP phase to change the           presumably denoting human verbal interaction. For
CARWord for each different sentence separately (Figure 4).          Sentence 92, high activations on Vision, Bright, Color,
As the last step, the changes in the semantic attributes are        Pattern, Large, Shape, Complexity, Touch, Temperature,
analyzed according to the CAR theory for each affected              Weight, Scene, Near, Harm, Unpleasant, Happy, and Angry
sentence. At this point, due to scarcity of data this is a          describe a loud and large object such as a television. These
manual process verifying that the changes made sense.               results suggest that the linear mapping that LReg performs
                                                                    is not powerful enough to capture context, but the nonlinear
                            Results                                 mapping of FGREP is. The following experiments therefore
The two approaches LReg and FGREP were evaluated in a               both used the FGREP method for this task.
preliminary experiment of distinguishing between the
different meanings of the verb listened. LReg was found to          Different contexts for the adjective “dangerous”
be inadequate in this task and therefore in two subsequent          This experiment compared the contrasting meanings of
experiments, focusing on the the adjective dangerous and in         NATURE vs. BAD PEOPLE for the word "dangerous", as
the noun mouse only the FGREP approach was used. The                expressed in 98: The flood was dangerous, 118: The
analysis was performed on the individual subjects for which         dangerous criminal stole the television. Figure 6 shows the
the fMRI data in general was most consistent.                       differences resulting from the FGREP method. As with the
                                                                    verb listened, context-dependent changes did emerge.
Different contexts for the verb “listened “                            CARs in Sentence 98 present changes on activation for
Both models were used in this experiment to compare the             Large, Motion, SOMS attributes Texture and Weight, and
contrasting meanings of HUMAN COMMUNICATION vs.                     event attributes Time, Short, and Caused, reflecting moving
NOISE FROM A MACHINE for the word listened as                       water. The attributes Toward, Harm, Unpleasant, and the
expressed in 89: The mayor listened to the voter, 92: The           emotion of Angry, represent the experiential and personal
lonely patient listened to the loud television. The left side of    nature of danger. Conversely, Sentence 118 shows high
Figure 5 shows the results for LReg between the original            activation for Vision, Complexity, Face, and Speech,
and transformed CARs. Although the CARs adjusted in all             because they represent human types and roles such as a
sentences, the changes were small and unprincipled, unable          criminal. Motor attribute Lower Limb as well as evaluation
to    characterize     the     difference    between     human      attributes Benefit, Angry, Disgusted, and Fearful can be
communication versus noise from a machine. In contrast,             associated with a dangerous act by a criminal. The FGREP
the outcome for FGREP resulted in context-dependent                 method, therefore, was largely able to differentiate between
                                                                1510

Figure 5: Results for the word listened in two contrasting sentences. LReg (left) did not capture context. All changes were insignificant to
characterizing the context-dependent representations. The green line shows the original CARs for comparison. FGREP (right) did grasp
context. The CARs for Sentence 89 have increased activations in human-related attributes like Face and Body, Auditory attributes, as well
as Human, Communication and Cognition. In contrast, Sentence 92 activations on Vision, Color, Large, Shape, Complexity, Touch
Temperature, High sound, and Unpleasant, depict a loud object such as a television.
the contrasting relevant dimensions of dangerous act of                   CARs in Sentence 56 have increased activation for
nature and humans.                                                      Vision, Motion, Complexity, High, and Sound, possibly
                                                                        suggesting animate properties of the live mouse. Upper
Different contexts for the noun “mouse”                                 Limb, spatial attributes Path and Away, and event attributes
This experiment compared the contrasting meanings of                    Time, Duration, Short, and Consequence, symbolize activity
DEAD vs. ALIVE for the word mouse as expressed in                       such as running. Emotions of Fearful and Surprised may
sentences 56: The mouse ran into the forest, 60: The man                well be associated with seeing a live mouse. In contrast,
saw the dead mouse. Figure 7 shows the differences                      Sentence 60 shows increased activation for Temperature,
resulting from the FGREP method, which are again                        Weight, and Smell, as well as emotions Sad, Angry,
systematic and meaningful.                                              Disgusted and Fearful, which may be associated to the dead
                                                                        mouse. These changes indicate different aspects of mouse in
                                                                        two contrasting contexts.
                                                                                     Discussion and Further Work
                                                                        The experiments in this paper suggest that different aspects
                                                                        of word meaning are activated in different contexts, and it is
                                                                        possible to see those changes in the corresponding fMRI
                                                                        images. These changes are likely to be nonlinear: The linear
                                                                        mapping approach (regression) tends to muddle them, but a
                                                                        nonlinear mapping (FGREP neural network) can tease them
                                                                        apart.
                                                                          This result is remarkable considering that the dataset was
                                                                        not originally designed to answer the question of dynamic
                                                                        meaning. In particular, having fMRI images for isolated
                                                                        words available, instead of having to synthesize them,
                                                                        should amplify the observed effects significantly. It should
                                                                        also be possible to include sentences with contrasting
                                                                        contexts systematically, thus increasing the number of
Figure 6: FGREP results for the adjective dangerous across two          possible observations, and making it possible to identify
contrasting sentences. CARs in Sentence 98 changed activation for       differences in a more comprehensive manner.
Large, Motion, Texture and Weight, Time, Short, and Caused,               With such a larger dataset, it should be possible to
reflecting moving water. The attributes Toward, Harm,                   characterize changes across multiple sentences. Different
Unpleasant, and Angry, represent the experiential nature of danger.
                                                                        kinds of changes may occur in nouns, adjectives, and verbs,
Sentence 118 shows high activation for Vision, Complexity, Face,
and Speech, because they represent human types and roles. Lower         and there are likely to be interactions between them.
Limb, Benefit, Angry, Disgusted and Fearful can be associated           Moreover, the semantic changes can vary from individual to
                                                                        individual. As the first step, only single subjects were
                                                                        analyzed in this paper. In the future, the analysis can be
                                                                   1511

extended to more subjects, identifying which changes are                                    Acknowledgments
consistent across subjects, and which ones are more                   We would like to thank Jeffery Binder (Medical College of
individualistic. For instance, the subject in experiment 3            Wisconsin), Rajeev Raizada and Andrew Anderson (University of
was Sad that the mouse was dead; another subject could                Rochester), Mario Aguilar and Patrick Connolly (Teledyne
show a different emotion.                                             Scientific Company) for their work and valuable help regarding
   After formulating such principles, the next step would be          this research. This work was supported in part by IARPA-FA8650-
to utilize them in building artificial natural language               14-C-7357 grant.
processing systems. It may be possible to train e.g. a neural
network to predict how meaning changes in context. Such a                                         References
network could be then used as a part of an engineered                 Anderson, A. J., Binder, J. R., Fernandino, L., Humpries C. J.,
natural language processing system, dynamically modifying                Conant L. L., Aguilar M., Wang X., Doko, S., Raizada, R. D.
the vector representations for the words to fit the context.             (2016). Perdicting Neural activity patterns associated with
Such a system should be more effective and more robust in                sentences using neurobiologically motivated model of semantic
its inference, and match human behavior better.                          representation. Cer. Cortex. 1-17. Doi:10.1093/cercor/bhw240.
                                                                      Baroni, M., Murphi, B., Barbu, E., Poesio, M. 2010. Strudel: A
                                                                         Corpus-Based Semantic Model Based on Properties and Types.
                                                                         Cognitive Science, 34(2):222-254.
                                                                      Barsalou, L. W. (2008). Grounded Cognition. Annual Review of
                                                                         Psychology, 59:617-845.
                                                                      Binder, J. R., Desai, R. H., Graves, W. W., Conant L. L. (2009).
                                                                         Where is the semantic system? A critical review and meta-
                                                                         analysis of 120 functional neuroimaging studies. Cerebral
                                                                         Cortex, 19:2767-2769.
                                                                      Binder, J. R., Desai, R. H. (2011). The neurobiology of semantic
                                                                         memory. Trends Cognitive Sci, 15(11):527-536.
                                                                      Binder, J. R., Conant L. L., Humpries C. J., Fernandino L., Simons
                                                                         S., Aguilar M., Desai R. (2016). Toward a brain-based
                                                                         componential semantic representation. Cog. Neuropsychology,
                                                                         33:3-4, 130-174.
                                                                       Binder, J. R. (2016). In defense of abstract conceptual
                                                                         representations. Psychonomic Bulletin & Review, 23.
                                                                      Burgess, C. (1998). From simple associations to the building
                                                                         blocks of language: Modeling meaning in memory with HAL
                                                                         model. Behavior Research Methods, Inst. & Com., 30, 188-198.
   Figure 7: FGREP results for the noun mouse across two              Burni, E., Tran, N., Baroni, M. (2014). Multimodal distributional
contrasting sentences. CARs in Sentence 56 increased activation          semantics. J. Artif. Intell. R. (JAIR), 49:1-47
for Vision, Motion, Complexity, High, and Sound, presumably to        Glasgow, K., Roos, M., Haufler, A. J., Chevillet, M., A., Wolmetz,
indicate the animate properties of the live mouse. Upper Limb,           M. (2016). Evaluating semantic models with word-sentence
Path, Away, Time, Duration, Short, and Consequence, suggest              relatedness. arXiv:1603.07253.
activity such as running. In contrast, Sentence 60 shows increased    Harris, Z. (1970). Distributional Structure. In Papers in Structure
activation for Temperature, Weight, and Smell, as well as Sad,           and Transformational Linguistics, 775-794.
Angry, Disgusted and Fearful, which can be associated to the dead     Landau, B., Smith, L., and Jones, S. (1998). Object Perception and
mouse. These changes indicate different aspects of mouse in two          Object Naming in Early Develop. Trends in CosSci 27:19-24.
contrasting contexts.                                                 Landauer, T.K., Dumais, S. T. (1997). A solution to plato’s
                                                                         problem: The latent semantic analysis theory of acquisition,
                          Conclusion                                     induction, and representation of knowledge. Psychological
                                                                         Review, 104, 211-240.
Concepts are dynamic; their meaning depends on context                Miikkulainen, R., Dyer, M., G. (1991). Natural Language
and recent experience. In this paper, word meaning was                   Processing with Modular PDP Networks and Distributed
represented as a collection of attributes (CARs), grounded               Lexicon. Cognitive Science, 15, 343-399.
in observed brain networks. Multiple Linear Regression                Pecher, D., Zeelenberg, R., Barsalou, L. W. (2004). Sensorimotors
analysis and a nonlinear FGREP Neural Network were used                  simulations underlie conceptual representations: Modality-
to understand how the CARs could change to construct the                 specific effects of prior activation. Psychonomic Bulletin &
                                                                         Review, 11, 164-167.
actual sentence representations seen in fMRI images.
                                                                      Regier, T. (1996). The Human Semantic potential. MIT Press,
Preliminary results suggest that there are indeed systematic             Cambridge, Massachusetts.
changes in CARs, and they make sense in each sentence                 Silberer, C., Lapata, M. (2014). Learning Grounded Meaning
context. These changes could only be seen in the FGREP                   Representations with Autoencoders. Proceedings of the 52nd
analysis, suggesting that they are likely to be nonlinear. In            Annual Meeting of the Association for Computational
the future, such changes could be characterized more fully               Linguistics, 721-732.
and used to make artificial natural language systems                  Vinyals, O., Toshev, A., Bengio, S., Erham, D. (2015). Show and
sensitive to context.                                                    Tell: A New Image Caption Generator. arXiv:1506.03134v2.
                                                                  1512

