                            Biases and labeling in iterative pragmatic reasoning
                                               Jon Scott Stevens (stevens.400@osu.edu)
                                           Department of Linguistics, The Ohio State University
                                                         Columbus, OH 43210 USA
                              Abstract                                   • We replicate the basic findings of Franke and Jäger (2016),
   This paper presents a series of reference game experiments               while improving their implementation of RSA by reducing
   (Frank and Goodman, 2012) and fits the results to a number               the number of free parameters required from four to one.
   of Bayesian computational models in order to explore the role         • We examine variation between items and uncover a possi-
   of linguistic and perceptual bias in iterative pragmatic reason-
   ing. We first discuss the modeling choices made by Franke and            ble effect of what we call labeling—an independently mo-
   Jäger (2016) and others who have used similar frameworks to             tivated mechanism for assigning possibly incomplete se-
   model reference game tasks. We introduce a space of different            mantic labels to potential referents based on salient pre-
   plausible Bayesian models based on this work, and compare
   models’ fit to new experimental data to replicate the basic find-        ferred properties. We show that by introducing labeling
   ings of Franke and Jäger (2016) regarding the strong role for           into the model, the fit between model predictions and em-
   perceptual salience (e.g., the primacy of color over shape as            pirical results is improved.
   a differentiating property for possible referents) and linguis-
   tic category (e.g., a preference for nouns over adjectives) in        Before diving into these results, we review prior work on ref-
   pragmatic reference resolution. We then uncover an additional
   possible effect of what we call labeling, whereby a hearer may        erence games, RSA models and bias in reference resolution.
   simply ignore non-salient, non-differentiating semantic prop-
   erties, in a manner similar to how an incremental algorithm                                     Prior work
   (Reiter and Dale, 1992) might ignore certain semantic proper-
   ties when generating referring expressions.                           A recent movement toward probabilistic pragmatics—the use
   Keywords: Iterative pragmatic reasoning; probabilistic prag-          of Bayesian, game-theoretic and other similar methods to
   matics; reference games; computational modeling; perceptual           model how non-literal meaning is conveyed by utterances
   bias; reference resolution
                                                                         in context— has been accompanied by an emphasis on us-
                           Introduction                                  ing computational models of pragmatic reasoning to explain
                                                                         empirical results (see Franke and Jäger, 2016, for a sum-
When someone says, “hold up your finger,” you are most
                                                                         mary). This includes the rational speech act (RSA) model
likely inclined, without much thought, to hold up your in-
                                                                         (Frank and Goodman, 2012; Franke and Jäger, 2016; Bergen
dex finger. This may seem unsurprising, as your index fin-
                                                                         et al., 2016, among many others) and its variants, as well
ger is particularly salient for a number of reasons. But, as
                                                                         as game-theoretic and decision-theoretic models (see e.g.
Franke and Degen (2016) point out, further reflection raises
                                                                         Franke, 2009; Stevens, 2016). These frameworks all tell a
the question of why the thumb—which is technically a finger,
                                                                         similar story at their core: pragmatic phenomena are largely
and which we might expect to be even more salient than the
                                                                         a byproduct of iterated reasoning of the form, ‘I expect that
index finger—is never a candidate for reference. The thumb
                                                                         she expects that I will say φ in context C,’ or some variant.
is a prime example of a pragmatic ‘blocking’ effect: though
it is indeed a finger, the existence of the more specific word
“thumb” tends to block it from reference by the word “fin-               Reference games A reference game task (Frank and Good-
ger”. Hence, there is a tension between salience and prag-               man, 2012) is a simple experiment which is designed to elicit
matic blocking in resolving the referent of “your finger”.               iterative pragmatic reasoning behavior. A speaker and a
   This paper presents an exploration of this kind of tension            hearer are presented with an array of colored and/or patterned
using reference games (Frank and Goodman, 2012; Franke                   shapes like the one seen in Fig.1. The speaker is assigned
and Degen, 2016, and others). Reference games are commu-                 one of the shapes and is tasked with choosing a single word
nicative tasks where subjects are asked to either produce or             to convey to the hearer which shape she has been assigned.
interpret short utterances, which are potentially ambiguous in           For Fig.1 the choices would be “circle,” “triangle,” “blue”
the context, to describe shapes on a screen. Reference games             and “red.” The hearer receives one of these words from the
are used as a test of models of iterative pragmatic reason-              speaker and tries to guess correctly what was meant. A simple
ing, whereby certain potential referents of an utterance are             game-theoretic model of Gricean pragmatic reasoning, such
blocked by the existence of a better, more informative alter-            as Franke’s (2009) iterated best response (IBR) model, makes
native utterance available to the speaker.                               categorical predictions about the interpretation of ambiguous-
   We further probe work begun in Franke and Jäger (2016)               in-context words (“triangle” and “blue” in this case). Quite
and Stevens (2016) by setting up reference games that favor              simply, the hearer should assume that the speaker would have
strong biases toward particular visually salient referents. We           used an unambiguous word if she could have, i.e. “red” for
test a range of different variants of the Rational Speech Act            the red triangle and “circle” for the blue circle, which leads to
(RSA) model of Frank and Goodman (2012) on our results.                  the conclusion that either “blue” or “triangle” alone should be
We come to two conclusions:                                              taken to refer to the blue triangle. But such categorical models
                                                                     3255

                                                                      We will use S1 to make predictions about production proba-
                                                                      bility and H2 to make predictions about interpretation proba-
                                                                      bility. We use empirically determined values of P(r).
                                                                         Franke and Degen (2016) also implement a variant of RSA
                                                                      that starts the iteration with the speaker instead of the hearer.
                                                                      That variant begins with a ‘literal speaker’, which we could
                                                                      call S0 , who randomly selects from among appropriate de-
                                                                      scriptions. Then H1 selects referents that maximize the prob-
                                                                      ability of having been referred to by S0 ’s utterance, and then
   Figure 1: Simple three-image setup for a reference game task.      a pragmatic speaker S2 chooses descriptions via Bayes’ rule
                                                                      taking H1 into account. We implement this variant as well.
are typically meant to be normative, and do not aim to reflect
the probabilistic nature of how people actually behave. The
                                                                      Biases and salience Cognitively oriented pragmatic mod-
RSA approach, which builds a Bayesian probabilistic com-
                                                                      els like RSA must take into account the prior biases that inter-
ponent into a bounded IBR-style reasoning model (Frank and
                                                                      locutors bring to the table. Two such biases factor into Franke
Goodman, 2012; Franke and Jäger, 2016) allows for compu-
                                                                      and Jäger’s model of reference games. Firstly, the authors use
tational models that more closely match experimental results.
                                                                      data from a prior elicitation task to show that hearers have
                                                                      a prior bias toward picking referents that are more visually
Rational speech acts The rational speech act (RSA) ap-                salient. For example, there is expected to be a bias toward the
proach to modeling pragmatic reasoning computes the prob-             red triangle in Fig.1 due to the pop-out effect that its unique
ability of a hearer choosing a referent r given a description         color creates. Secondly, the authors use production experi-
d via Bayes’ rule assuming the speaker chose their utterance          ment data to show that there is a prior bias toward using shape
rationally, which in this case means the speaker attempted to         nouns rather than color-denoting adjectives to describe an in-
maximize the chance of successful communication. We be-               tended object. These biases are built into their probabilistic
gin with a function encoding likelihood of referential success        model, the former being encoded in the prior probability dis-
of a description d given intended referent r assuming a naive         tribution over speaker intentions, and the latter being encoded
hearer—a hearer who randomly selects a referent consistent            as the bias parameter β which boosts production probability
with d’s denotation. Let’s call this function H0 .                    for shape terms. This allows a closer fit to experimental re-
                              1                                       sults when compared to more purely Gricean models.
               H0 (r|d) =          if r ∈ JdK, else 0          (1)
                            |JdK|                                        Investigating perceptual bias in the visual domain can shed
The probability of a rational speaker producing description           light on the role of salience in iterative pragmatic reasoning
d to describe intended referent r is taken to be a function of        more generally, given that parallels have been found between
H0 , namely a soft max function, which has the effect of ap-          visual salience and e.g., the use of definite referring expres-
proximately maximizing H0 by introducing a rationality pa-            sions (Duan et al., 2013). In this study we find evidence that
rameter, λ. The rationality parameter encodes the degree to           visual salience affects how hearers assign their own internal
which speakers behave as perfect reasoners. As the value of λ         semantic labels to the potential referents in a scene. Namely,
increases, this production probability—which we’ll call S1 —          behavior on certain experimental items suggests that hearers
asymptotically approaches an arg max of H0 . Similarly to             selectively consider properties of potential referents (i.e., the
Franke and Jäger (2016), we also posit that a bias function,         object’s color, shape, pattern, etc.) which serve to differenti-
β(d, r) is added to H0 , which encodes possible prior bias to-        ate them from their competitors. More specifically, we sug-
ward certain types of descriptions over others (e.g., a pref-         gest that hearers can generate sets of expected linguistic de-
erence for nouns over adjectives, empirically determined for          scriptions for each object using something like an incremental
our models). We’ll return to the exact nature of the bias func-       algorithm (Reiter and Dale, 1992; Krahmer and Van Deemter,
tion in the next section.                                             2012), which has been used to generate referring expressions
                                                                      in a psychologically plausible way. This algorithm is in-
                                 eλH0 (r|d)+β(d,r)                    formally sketched in Fig.2. To illustrate, consider the pic-
                  S1 (d|r) =               0     0             (2)
                              ∑ eλH0 (r|d )+β(d ,r)                   ture in Fig.1. Imagine that the most salient property type is
                              d0                                      COLOR . To label the red triangle, the algorithm takes its value
Finally, the production probability S1 (d|r) can be plugged in        for COLOR—‘red’—and checks whether there is at least one
to Bayes’ rule, where P(r) is the prior probability of refer-         member of the distractor set (the blue triangle and the blue
ent r being referred to, to obtain a pragmatically motivated          circle) which is not red. There is, and so ‘red’ gets added to
probability function for the hearer, which we will call H2 .          the label set, and both of the non-red items are removed from
                                                                      the distractor set. This leaves an empty distractor set, and
                                 S1 (d|r) × P(r)
                 H2 (r|d) =                                    (3)    so the algorithm halts on the singleton set of labels, {‘red’}.
                              ∑ S1 (d|r0 ) × P(r0 )                   The same algorithm will generate {‘blue’, ‘triangle’} for the
                              r0
                                                                  3256

                                                                                                    Uniform level 0      Empirical level 0
  • Given an object O in a set of objects Ω, let L be O’s label—a set of
     semantic properties (e.g., {‘red’, ‘triangle’}) to describe O. Let        S1 / H2 , no bias      F&G (2012)
     P∗ be an ordered sequence of property types which are ordered              S1 / H2 , S1 bias     F&J (2016)
     by salience (e.g. hCOLOR, SHAPEi, if color is more salient than           S2 / H1 , no bias      F&D (2016)
     shape). Let D be the set of distractors, i.e., Ω \ O
  • Initialize L to {}                                                         S2 / H1 , H1 bias
  • For P in P∗ :
     1. Let V be the value that O has for property P                       Table 1: Eight possible model variants based on the three questions
     2. Let Ω¬V be the set of objects that have a different value for P    posed, where three of the cells are occupied by examples of a model
        than V                                                             of that type—Frank and Goodman (2012), Franke and Jäger (2016)
     3. If D ∩ Ω¬V 6= {}, then add V to L and remove all members of
        Ω¬V from D                                                         and Franke and Degen (2016).
     4. If D = {}, return L
                                                                              among semantically appropriate actions, as opposed to se-
                                                                              lecting proportionally to the empirically determined prior?
 Figure 2: An informal presentation of an incremental algorithm for
 generating salient and informative semantic labels for referents.         There are a total of 23 = 8 possible combinations of yes/no
                                                                           answers to these three questions, each corresponding to a dif-
                                                                           ferent model variant. The variant we have described, based
 blue triangle and {‘blue’, ‘circle’} for the blue circle. The             on Franke and Jäger (2016), is the “yes/yes/yes” model.
 red triangle is simply labeled as the red thing, because ‘red’            That means that bias is implemented, we follow the trajec-
 is a preferred property that uniquely differentiates it, while            tory H0 → S1 → H2 rather than starting with a non-rational
 the other two shapes are labeled according to both color and              speaker, and H0 chooses a random semantically compatible
 shape.                                                                    meaning, ignoring the prior probability P(r). Table 1 lays out
                                                                           the possibilities and points to examples of a few of the models
                    Computational models                                   from the RSA literature.
 We implement a variety of models centered around the RSA                     We implemented all models with integer λ values between
 implementation of Franke and Jäger (2016), though we re-                 one and ten1 and used root mean square error (RMSE) as a
 duce the number of free parameters from four to one. The                  measure of overall difference between model predictions and
 first reduction comes from the choice to use a single value of            experimentally determined values.
 the rationality parameter λ to predict both speaker and hearer
 behavior, where Franke and Jäger (2016) fit two λ values sep-                                     Experiments
 arately. The second reduction comes from the use of empir-                Participants and materials We conducted four experi-
 ical data to determine values of β(d, r)—the observed bias                ments via Amazon Mechanical Turk, two experiments to de-
 toward nouns in production—where Franke and Jäger (2016)                 termine prior probabilities for referents and descriptions, and
 use a pair of fixed values that were tweaked for best perfor-             two reference game tasks, one where the Turker played the
 mance. Using a speaker norming task, as described in the                  part of the speaker and one where they played the part of the
 next section, we obtain a prior probability of noun vs. adjec-            hearer. For each experiment, 100 Turkers were assigned to
 tive for each experimental item we want to model. We then                 one of two lists containing nine experimental items, for a total
 set β(d, r) to be proportional to this prior probability.                 of 18 items. Each item was an array of three images similar
                                                                           to Fig.1, where one image was distinguished from the other
                               P(d)                                        two by its shape, another image was distinguished by another
             β(d, r) =                   if r ∈ JdK, else 0        (4)
                              ∑ P(d 0 )                                    salient attribute, and the third image was not distinguished
                        d 0 |r∈Jd 0 K
                                                                           along any dimension. The order of item presentation was ran-
 We now have a single-parameter RSA model that will make                   domized, as was the order in which the shapes were presented
 predictions about both production and interpretation rates in             on the screen. Items fell into one of three categories based on
 a reference game task, taking biases into account.                        which salient distinguishing attribute was used, with 6 items
                                                                           in each category:
    We implement a number of variants of this model to allow
 us to assess some of the modeling choices we and others have             1. Color: Red vs. blue, as in Fig.1
 made. In particular, we want to answer the following three               2. Pattern: Striped vs. solid (one striped and two solid)
 questions about our modeling choices:                                    3. Size: One shape bigger than the other two
1. Bias vs. no bias: Do we really need the β(d, r) term?                   Native language was assessed as part of a post-task question-
2. Naive hearer vs. literal speaker: Should we really start with           naire. Subjects were paid $0.70 for about 5 minutes of their
    a naive hearer H0 , as opposed to with a literal speaker S0 à         time. If any subject’s responses were incomplete, or if the
    la the variant in Franke and Degen (2016)?                                 1 The effect of λ on model performance is gradual enough, and
3. Uniform level-0 prior vs. empirical level-0 prior: Should               the differences between the different model variants large enough,
    the naive hearer and/or literal speaker select randomly from           that not much fine-tuning is required to make our point.
                                                                       3257

subject was not a native speaker of English, the data from                                                         Word
that subject was excluded from analysis.                                Image                 ATTR D      ATTR N       SHAPE N     SHAPE D
                                                                        ATTR D SHAPE N        .75 / 1     .00 / .00    .25 / .52   .00 / 0
                                                                        ATTR N SHAPE N        .00 / 0     .29 / .74    .71 / .48   .00 / 0
Experiment 1: Eliciting hearer priors Following Frank
                                                                        ATTR N SHAPE D        .00 / 0     .03 / .26    .00 / .00   .97 / 1
and Goodman (2012) and others, we use empirically deter-
mined values for the prior probabilities in our model. The
prior probability P(r) of choosing a referent r is taken to be        Table 2: Production of d given r (on the left, sum horizontally to 1)
a measure of the salience or ‘newsworthiness’ of a referent,          / selection of r given d (on the right in bold, sum vertically to 1) in
i.e., a general measure of how likely r is to be talked about. To     Experiments 3 and 4. Subscripts D and N mean ‘distinguishing’ and
elicit this experimentally, we asked subjects to select an im-        ‘non-distinguishing’, respectively, and ATTR stands for ‘attribute’.
age to describe, giving them no guidance on which images to
select, and then type a description of it. The point of this ex-
                                                                      reasoning being used to determine descriptions. For exam-
periment was not what the descriptions were, but rather which
                                                                      ple, for the items where an attribute term would uniquely dis-
shapes they chose to talk about. We took this as a proxy for
                                                                      tinguish the intended referent, shape terms nonetheless com-
the salience of the referent, and thus its prior probability of
                                                                      prised 60% of responses, more than double the shape-term
being referred to. We asked them to type descriptions as a
                                                                      response rate for Experiment 3, which was designed to elicit
secondary task in order to situate the shape selection within
                                                                      pragmatic reasoning.
a natural communicative setting. We used data from 97 sub-
jects after exclusions.
   For the color items we obtained similar results to Franke          Experiment 3: Reference game, speaker role Experi-
and Jäger (2016), where the red shape was picked much more           ments 3 and 4 instantiate the canonical reference game task
often (probability 0.5) than either of the blue shapes, and           described in the second section. Experiment 3 asks subjects
where the distinguished blue shape (e.g., the circle in Fig.1)        to play the role of the speaker in a reference game. Similarly
was picked more often (0.33) than the non-distinguished blue          to Experiment 2, subjects are assigned one of the three im-
shape (0.17). For the size items, we found that the distin-           ages and asked to give a one-word description. But for this
guished smaller shape had a high prior probability (0.5 vs.           experiment, they are explicitly told to select from a list of the
0.26 and 0.24 for the large and small competitors, respec-            relevant words (e.g., “red”, “blue”, “triangle”, “circle”). And
tively), and for the pattern items, the priors were closer to         unlike Experiment 2, the task is framed as a game. Subjects
equal for the striped and distinguished solid shapes (0.36            are told they are sending a message, and to assume that a “re-
and 0.40, respectively), and lowest for the non-distinguished         ceiver” will receive these descriptions and make a guess as to
shape (0.24).                                                         which image was assigned. The goal, they are told, is for the
                                                                      receiver to guess correctly as often as possible. Data from 79
                                                                      subjects was used.
Experiment 2: Eliciting speaker priors To empirically
determine whether and to what extent speakers are biased
toward nouns like ‘circle’ over adjectives like ‘red’, we ran         Experiment 4: Reference game, hearer role Experiment
an experiment just like Experiment 1, but with two impor-             4 asks subjects to play the role of the hearer, or the “receiver”.
tant differences: (i) subjects were assigned one of the three         For each item, a single word is displayed at the top of the
images to describe, rather than being asked to pick one them-         screen, which the subjects are told has been carefully selected
selves (image assignments were counterbalanced across lists           and sent to them by a sender who wants them to correctly
so that shape-distinguished, attribute-distinguished and non-         guess an image from a one-word description. Word selection
distinguished items were equally represented), and (ii) sub-          was counterbalanced across both lists. The subjects were re-
jects were told to limit their descriptions to a single word,         quired to select a single image for each item. Data from 91
in order to bring the task more in line with a reference game         subjects was used.
task. To discourage any kind of pragmatic reasoning, subjects
were asked to use the ‘first word that came to mind’ and not to       Results Our reference game experiment results are in line
overthink it. We analyzed data from 84 subjects after exclu-          with other reference game results in the literature, and are
sions, and only looked at items where either a shape-denoting         summarized in Table 2. Like Franke and Jäger (2016), we
noun or relevant attribute-denoting adjective was used (very          find that the expected propensity toward interpreting ambigu-
few did not fall into this category). The words were input            ous shape and attribute words (like “triangle” and “blue” in
as free text, and thus we hand-tokenized the responses to ac-         Fig.1) as referring to the non-distinguished shape (like the
count for spelling mistakes and superficial lexical differences       blue triangle) is dampened for the shape words, likely reflect-
(e.g., ‘big’ vs. ‘large’). We found an overwhelming prior bias        ing hearer knowledge of speakers’ prior noun bias, where the
toward nouns.Overall, shape terms were used two-thirds of             prior noun bias makes a shape term like “triangle” a less re-
the time. There is evidence that this task successfully elicited      liable signal that the non-distinguished referent is intended.
prior linguistic biases and limited the amount of pragmatic
                                                                  3258

                         Uniform level 0       Empirical level 0                            1.00
   S1 / H2 , no bias        .12 / .20             .14 / .23                                 0.75
   S1 / H2 , S1 bias        .06 / .18             .09 / .22
   S2 / H1 , no bias        .23/ .20              .23 / .20                          Real   0.50
   S2 / H1 , H1 bias        .25 / .22             .24 / .23                                 0.25
                                                                                            0.00
                                                                                                   0.00   0.25     0.50      0.75   1.00
Table 3: RMSE for speaker predictions (left) / hearer predictions                                                Predicted
(right). Best-case λ value used for each reported RMSE. Best model
results are in bold.
                                                                          Figure 3: Hearer predictions vs. observed values, averaged over
                                                                          subjects and items.
   Table 3 shows how our model variants line up with the em-
pirical results in terms of the root mean square error (RMSE),
which is a measure of overall difference between predicted                image—holds in all but two cases. These two cases are de-
and observed values obtained by calculating the mean of the               picted in Fig.4, where we see a deviation for (i) color items
square of the difference between each predicted vs. observed              when the hearer is sent an ambiguous color term and (ii) size
value and taking the square root. We used the difference in               items when the hearer is sent an ambiguous shape term. There
predicted vs. observed subject means for each experimental                is a pattern to these deviations. The pattern is that we see a
item (i.e., each array of images) to determine RMSE. Not                  shift away from the non-distinguished image only in cases
only is our refinement of Franke and Jäger (2016) the best               where the semantically ruled out referent (e.g., the red thing
model to predict these data, but our best-case value of the λ             if the description is “blue”) has a high prior (in both cases,
parameters (λ = 4) is the best-case value for both the speaker            ∼50%). Let’s break down what this means for the three item
and hearer model independently. That is to say, we would not              types. First, when the hearer receives “blue” for an item like
do a lot better by allowing for separate λ values for speaker             Fig.1, we find higher-than-expected selection of the unique
and hearer. We take this to be a nice replication of the basic            shape (the circle in Fig.1). This is the item type for which the
finding of Franke and Jäger (2016), obtained using only one              attribute-distinguished image (the red triangle) is maximally
free parameter that was only broadly tweaked.2                            salient according to Experiment 1. Second, when a hearer
   The numbers in Table 2 are somewhat closely replicated,                receives an ambiguous shape term for a size-distinguished
with every value being within three percentage points of the              item, we find higher-than-expected selection of the uniquely
real value. A plot of predicted vs. actual results from Table             large referent. This is the item type for which the shape-
2 is given in Fig.3. However, the numbers in Table 2 are av-              distinguished image is maximally salient according Experi-
eraged over all items, and tell us nothing about the range of             ment 1. Finally, the pattern-distinguished items fall entirely
variation of responses for different kinds of images. RMSE                in line with what we expect, and those are the items where the
gives us an overall assessment of error taking into account               priors for shape- and attribute-distinguished images are much
error at the level of each individual item. What the RMSE                 closer to each other.
values in Table 3 tell us is that the speaker model fits consid-             Qualitatively speaking, we would expect this if the refer-
erably better than the hearer model.                                      ents were labeled according to salient distinguishing proper-
   Why is the hearer model so noisy? Given the proximity of               ties along the lines of Fig.2, a well-established algorithm for
predicted to actual results on average in Fig.3, the source of            generating referring expressions, which we adapt for gener-
the noisiness must be coming from differences between item                ating hearer-internal labels for possible referents. Consider
types. An item-level investigation of the source of the higher-           Fig.1 one more time: for the ∼50% of subjects in Experi-
than-expected RMSE will lead us to posit that when there are              ment 1 who chose the red triangle, we can assume that COLOR
highly perceptually salient options, as in these experiments,             would be their primary salient property type for purposes of
hearers are inclined to label their options in a way that is sim-         Fig.2. This would generate the labels {‘blue circle’, ‘blue tri-
ilar to the output of an incremental algorithm (Fig.2).                   angle’, ‘red’}. Assuming these same priors for Experiment 4
                                                                          (as we have been) we could posit that on ∼50% of trials, the
                            Labeling                                      subject has this same labeling. In that case, upon hearing the
We now break down by-item behavior further, looking not                   description “blue”, the subject would be at chance between
only at whether the image array was shape- color- or size-                the two blue shapes, because under this labeling, the speaker
distinguished, but also at which word was sent to the                     could have used ‘triangle’ to uniquely describe the blue trian-
hearer. We find that the predicted qualitative pattern—that               gle and ‘circle’ to uniquely describe the blue circle, leaving
ambiguous descriptions (and only ambiguous descriptions)                  no principled way to interpret “blue” other than to guess.
should prompt a plurality of guesses of the non-distinguished                Labeling could explain the qualitative deviations, and even
    2 Franke and Degen (2016) also consider the combination S /           though the numbers are not perfect, it does indeed improve
                                                                    1
H1 , i.e., a non-iterative model. This would not do any better here, as   model fit to add a labeling component to the model. We can
we see in Table 3 that H1 never makes better predictions than H2 .        do this by substituting a new S1 function S10 into the H2 equa-
                                                                      3259

                         1.00                                                                              1.00
                         0.75                                                                              0.75
             Predicted
                                                                                                    Real
                         0.50                                                                              0.50                                                                        Item
                                                                                                                                                                                          Color, Ambiguous color term
                                                                                                                                                                                          Size, Ambiguous shape term
                         0.25                                                                              0.25
                         0.00                                                                              0.00
                                Attribute-distinguished   Non-distinguished   Shape-distinguished                  Attribute-distinguished   Non-distinguished   Shape-distinguished
                                                                Image                                                                            Image
     Figure 4: Predicted (left) and actual (right) referent selection for two combinations of item type and description type.
tion which takes labeling into account. Letting L be the set of                                                                Further work must also be done to probe the details of
labels for each possible referent, S10 can be defined as follows:                                                           exactly how labeling works in reference games, and what
                                                                                                                            the implications are for iterative pragmatic reasoning more
                                                            eλH0 (r|d,L )+β(d,r)
          S10 (d|r) = ∑ P(L ) ×                                       0        0                             (5)            generally. For example, it remains to be seen whether la-
                                     L                     ∑ eλH0 (r|d ,L )+β(d ,r)                                         beling should be seen as part of a rational process of prag-
                                                           d0
                                                                                                                            matic reasoning, or as something that competes with it, as
We introduce no new free parameters if we simply take P(L )                                                                 Stevens (2016) would suggest. Finally, future work will use
to be the prior probability of the shape-distinguished refer-                                                               online measures to probe the mechanisms that give rise to
ent for the L obtained when shape is primary, the prior of                                                                  the probabilities in our models. This would take us beyond
the attribute-distinguished referent for the L obtained when                                                                computational-level models, using such models only as a
attribute is primary, and the prior of the non-distinguished                                                                starting point to guide us toward a more fine-grained under-
shape for the ‘full’ L , which omits no information. Doing                                                                  standing of this behavior (see Yang, to appear).
this, we can reduce the RMSE from 0.18 to 0.15, and could
perhaps reduce it further if we could independently assess                                                                                                       Acknowledgments
how primary salient properties are chosen. Using multino-                                                                   This work was funded by the American Council of Learned
mial choice probabilities to determine log likelihood, we can                                                               Societies (ACLS). Thanks to Marie-Catherine de Marneffe,
show that the data from Experiment 4 are significantly more                                                                 Micha Elsner and the OSU psycholinguistics lab group.
likely under the model with labeling.3
                                                                                                                                                                         References
                                           Conclusion                                                                       Bergen, L., Levy, R., and Goodman, N. D. (2016). Pragmatic rea-
Using a variety of models and experimental items and tasks,                                                                   soning through semantic inference. Semantics and Pragmatics, 9.
                                                                                                                              Advance online publication.
we have replicated existing results regarding behavior in ref-                                                              Duan, M., Elsner, M., and de Marneffe, M.-C. (2013). Visual and
erence games, and potentially found a new one, an effect of                                                                   linguistic predictors for the definiteness of referring expressions.
labeling under conditions where certain referents have highly                                                                 In Proceedings of the 17th SemDial Workshop, Amsterdam.
                                                                                                                            Frank, M. C. and Goodman, N. D. (2012). Predicting pragmatic
salient properties. That it might matter how people inter-                                                                    reasoning in language games. Science, 336(6084):998.
nally label possible referents is not really a new idea, and                                                                Franke, M. (2009). Signal to Act: Game Theory in Pragmatics. PhD
is in fact in line with game-theoretic literature on coordina-                                                                thesis, Universiteit van Amsterdam.
                                                                                                                            Franke, M. and Degen, J. (2016). Reasoning in reference games:
tion (see e.g., Sugden, 1995). But it provides somewhat of                                                                    Individual-vs. population-level probabilistic modeling. PloS one,
a paradox. On the one hand, this and other studies find that                                                                  11(5).
speakers exhibit a bias toward noun descriptions in reference                                                               Franke, M. and Jäger, G. (2016). Probabilistic pragmatics, or why
games, across the board, and yet it seems as if hearers are as-                                                               Bayes’ rule is probably important for pragmatics. Zeitschrift für
                                                                                                                              Sprachwissenschaft, 35(1).
signing labels to potential referents that in some cases would                                                              Krahmer, E. and Van Deemter, K. (2012). Computational generation
lead them to expect the opposite (e.g., to expect “red” to de-                                                                of referring expressions: A survey. Computational Linguistics,
scribe the red triangle in Fig.1). Thus further work is war-                                                                  38(1):173–218.
                                                                                                                            Reiter, E. and Dale, R. (1992). A fast algorithm for the generation
ranted to probe whether such a mismatch between speaker                                                                       of referring expressions. In Proceedings of the 14th conference
behavior and hearer expectations is generally observable.                                                                     on Computational Linguistics, Volume 1, pages 232–238. ACL.
                                                                                                                            Stevens, J. (2016). When do we think strategically? Zeitschrift für
    3 Change in deviance between the two models, ∆D = 59.26,
                                                                                                                              Sprachwissenschaft, 35(1).
where deviance is -2 times log likelihood, follows a chi-square dis-                                                        Sugden, R. (1995). A theory of focal points. The Economic Journal,
tribution with degrees of freedom equal to the number of parameters                                                           105:533–550.
added to the more complex model. Six prior values must be specified                                                         Yang, C. (To appear). Rage against the machine: Evaluation metrics
to the labeling model—two each for color, shape and size items—                                                               in the 21st century. Language Acquisition.
yielding χ2 = 59.26, df = 6, p < 0.001.
                                                                                                                  3260

