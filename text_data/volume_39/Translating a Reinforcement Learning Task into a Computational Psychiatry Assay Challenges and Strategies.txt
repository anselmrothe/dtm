Translating a Reinforcement Learning Task into a Computational Psychiatry Assay:
                                                 Challenges and Strategies
                                               Peter Hitchcock (pfh26@drexel.edu)
                                 Clinical Psychology, Department of Psychology, Drexel University
                                          Angela Radulescu (angelar@princeton.edu)
                                            Department of Psychology, Princeton University
                                                   Yael Niv (yael@princeton.edu)
                                            Department of Psychology, Princeton University
                                              Chris R. Sims (chris.sims@drexel.edu)
                        Applied Cognitive & Brain Sciences, Department of Psychology, Drexel University
                            Abstract                                   signal (Sutton & Barto, 1998). Over the past twenty years,
  Computational      psychiatry     applies     advances     from
                                                                       computational models of RL have grown in sophistication
  computational neuroscience to psychiatric disorders. A core          and maturity (O’Doherty, Cockburn, & Pauli, 2017). In
  aim is to develop tasks and modeling approaches that can             addition, there has been a string of successful applications of
  advance clinical science. Special interest has centered on           RL modeling to clinical problems. These early successes may
  reinforcement learning (RL) tasks and models. However,               portend widespread use of RL assays in clinical science
  laboratory tasks in general often have psychometric                  (Maia & Frank, 2011).
  weaknesses and RL tasks pose special challenges. These                 Yet the history of converting laboratory tasks to clinical
  challenges must be addressed if computational psychiatry is to
  capitalize on its promise of developing sensitive, replicable
                                                                       assays suggests caution is warranted. Laboratory tasks tend
  assays of cognitive function. Few resources identify these           to have substantial (and often underappreciated)
  challenges and discuss strategies to mitigate them. Here, we         psychometric weaknesses (Lilienfeld, 2014). Consider the
  first overview general psychometric challenges associated with       example of the dot probe task, an attention paradigm
  laboratory tasks, as these may be unfamiliar to cognitive            introduced over 30 years ago (Bar-Haim, Lamy, Pergamin,
  scientists. Next, we illustrate how these challenges interact        Bakermans-Kranenburg, & Van Ijzendoorn, 2007). By 2007,
  with issues specific to RL tasks, in the context of presenting a     35 clinical studies using the task had been conducted. A meta-
  case example of preparing an RL task for computational
  psychiatry. Throughout, we highlight how considering                 analysis that year concluded the task reliably detects attention
  measurement issues prior to a clinical science study can inform      differences between anxious and non-anxious groups (Bar-
  study design.                                                        Haim et al., 2007). Dozens of studies subsequently tested
                                                                       “modification” variants of the task (which aim to retrain
  Keywords: computational modeling; reinforcement learning;
  measurement; psychometrics; computational psychiatry                 attention) (Hallion & Ruscio, 2011). Yet recent meta-
                                                                       analyses suggest modification training produces very small
A core aim of the emerging field of computational psychiatry           effects and that extant modification studies evince
is to translate tasks and modeling approaches from                     publication bias (e.g., Heeren, Mogoașe, Phillippbot, &
computational neuroscience into sensitive assays that can              McNally, 2015). These disappointing results prompted re-
advance clinical treatment, diagnosis, practice, and theory            examination of the evidence for reliable, stable group
(Hitchcock, 2017; Redish & Gordon, 2016). New assays may               differences per the original dot probe. Recent critiques, which
advance clinical science by facilitating early illness detection,      have referenced a slew of null findings since 2007, concluded
predicting illness progression, separating patients into               that the evidence for such differences is weak (Rodebaugh et
subgroups, predicting type and extent of treatment indicated,          al., 2016; Van Bockstaele, Verschuere, Tibboel, De Houwer,
and allowing measurement of the effects of emotion                     Crombez, & Koster, 2014).
regulation strategies (Huys, Maia, & Frank, 2016).                       What went wrong? It is noteworthy that, although
  The effort to develop laboratory tasks into assays has been          researchers have been employing the original dot probe since
ongoing for years, but the use of computational cognitive              the 1980s, the first examination of its test-retest reliability
models that describe the trial-by-trial behavior of subjects           was not published until 2005 (Schmukle, 2005). That study
(Daw, 2011) is newer to clinical science. In theory,                   and others (e.g., Price et al., 2015) found the dot probe
parameters derived from these models should compactly                  exhibits close to 0 test-retest reliability when analyzed using
describe individual or group differences by revealing aspects          standard methods. These results suggest it is not possible to
of cognitive processing that are obscured in behavioral                extract stable measures of differences in attention using the
measures (Huys et al., 2016). An especially promising                  standard versions/analyses of the task (Rodebaugh et al.,
domain in this regard is reinforcement learning (RL). RL               2016; Van Bockstaele et al., 2014).
refers to a broad class of trial-and-error learning tasks
wherein learning is driven mainly by a scalar reinforcement
                                                                   2217

                                                                       Figure 2. The Dimensions Task (Niv et al., 2015), designed
                                                                       to investigate the role of attention in reinforcement learning.
                                                                        depressive rumination—repetitive, negative, self-referential
                                                                        thinking—alters cognitive processing. This could be done by
Figure 1. Pipeline for a computational psychiatry assay
                                                                        asking depressed subjects to complete a laboratory task while
proposed by Paulus et al. (2016).
                                                                        under the effects of a rumination induction. Many past studies
                                                                        have experimentally induced rumination in this way but, as
Developing Computational Psychiatry Tasks with                          far as we are aware, none has asked subjects to ruminate on
Strong Psychometric Properties                                          more than one occasion. Indeed, it seems unreasonable and
                                                                        unrealistic to ask depressed subjects to undergo more than
The dot probe paradigm provides a cautionary tale about                 once a manipulation that—by design—provokes distress.
pushing too quickly from a lab paradigm to applied research.              The effects of random state variation can be mitigated
The computational psychiatry community can learn from this              through study design. For example, a researcher investigating
example. Fortunately, the community appears aware of the                the effects of rumination on some task might ask subjects to
challenges posed by laboratory tasks. For instance, Paulus,             perform the task once before and once while under the effects
Huys, and Maia (2016) proposed a pipeline (Figure 1) for                of rumination. Such a design should increase the ratio of
turning a task into an assay that can ultimately be used for            systematic variability (variability due to induced rumination)
assessment or as a treatment target in randomized control               to unsystematic variability (variability due to subjects being
trials (RCTs). The authors emphasize establishing                       in different states when they enter the lab) because it delivers
psychometric properties early in the pipeline—before relying            pre- as well as post-induction measures for each subject. A
on the task as a primary measure in RCTs.                               subject is unlikely to dramatically change the state she is in
   Yet researchers entering computational psychiatry from the           from pre- to post-induction (an unusually tired subject at
cognitive sciences may be unfamiliar with how the                       baseline will likely remain so while under the effect of
psychometric challenges of laboratory tasks interact with               rumination induction). Thus the within-subject design
clinical design issues. Thus, this paper offers an overview of          controls for some of the unsystematic variability due to state
the relevant issues. Specifically, the rest of paper is part            variation. However, note that individual differences in
theoretical overview and part annotated case example of                 susceptibility to the experimental perturbation (e.g.,
preparing a specific RL task for use in clinical science. We            propensity to ruminate upon receiving the induction) will be
begin with a theoretical issue that may be unfamiliar to many           affected by subjects’ states. Thus this approach is helpful in
in cognitive science.                                                   minimizing noise but does not solve the random state
General Psychometric Challenges Associated with                         variation problem.
Laboratory Tasks. A general—and formidable—challenge                      The random state variation problem entails that a subject’s
for extrapolating from laboratory task behavior is that                 parameter estimates in a laboratory measure will be corrupted
subjects naturally vary in the state that they are in (e.g., tired,     by noise with respect to the subject’s “true” parameter value,
distraught, cognitively taxed) when they arrive at the                  when the true parameter value is conceived of as a
laboratory. A classic solution to this random state variation           psychological variable akin to a trait. This noise will limit the
problem—a problem that confounded social and personality                predictive power of measures. Thus, when random state
psychologists for decades (Kenrick & Funder, 1988)—is to                variation is expected (e.g., when a design only permits
assess the same subject at many time points and average over            administering the task once or a few times), it is critical that
measurements. This approach can dramatically increase the               the psychometric properties of the task are strong so that
convergent validity of lab tasks with self-report measures,             other sources of noise are minimized. For a more general
presumably because an average over many time points yields              discussion of how computational modeling may help remedy
a more stable, trait-like measure than one-time measurement             the random state variation problem, see Hitchcock (2017).
(as the latter is often biased by state variation; Epstein, 1979).        In the rest of this paper, we give a case example of
   However, assessing a single subject at many time points can          preliminary efforts to establish the psychometric properties
be infeasible. First, much time is often needed to complete             of a multidimensional RL task known as the Dimensions Task
lab tasks, and thus repeating assessments on many occasions             (Niv et al., 2015; Leong, Radulescu, Daniel, DeWonskin, &
can substantially raise subject burden. Second, in some cases           Niv, 2017; Radulescu et al., 2016). The task itself is not the
it is unrealistic to ask subjects to complete the task more than        paper’s focus, but we briefly describe it, our approach to
once. For example, a researcher may wish to examine how                 modeling it, and its promise for clinical science in the next
                                                                    2218

section. The description will make subsequent sections, on          The decay parameter reflects the fact that subjects are
the task’s measurement properties and their relation to             selectively attending to (and learning about) few dimensions
modeling issues, easier to follow.                                  (Leong, Radulescu et al., 2017). The “forgetting” of the
The Dimensions Task. Trial-and-error learning in the real           weights of unchosen features allows the model to “undo”
world often requires learning about a small set of stimulus         learning about features not chosen on a trial.
features embedded in a milieu of irrelevant stimuli. Imagine          Finally, the model assumes that the subject’s probability of
telling (what you hope is) an amusing story to a friend and         choosing each stimulus is proportional to the estimate of the
attempting to learn about the effects of specific actions—          value of the stimulus, as defined by a softmax equation with
dramatic pauses, rhetorical flourishes, funny faces, etc.           a third free parameter, β
Learning about the effect of these actions requires attending                           p(choose Si)  eβV(Si)                     (4)
to just a few fleeting features on the face of and in the body
                                                                    The model thus has three free parameters: softmax action
language of your friend while ignoring many irrelevant
                                                                    selection noise β, learning rate η, and decay parameter d. See
features—pimples on your friend’s forehead, your computer
                                                                    Niv et al. (2015) for more details.
screen flickering behind you, your internal dialogue about
what to say next, etc. (Niv et al., 2015).                          Stage in the Assay Development Pipeline. With respect to
  The Dimensions Task was designed to study such a scenario         Paulus et al.’s (2016) pipeline (Figure 1), most prior studies
where only some aspects of the task are relevant and most can       using the Dimensions Task and fRL+decay model fall into
be ignored, as is so often required in the real world. Briefly      the Preclinical and Phase1a phases.
(see Niv et al., 2015 for details), on each trial of the task          Notably, Radulescu et al. (2016, study 2) also provided a
subjects must select one of three possible stimuli. Each            test of the task’s promise for measuring group differences.
stimulus is composed of 3 features defined on 3 stimulus            Radulescu and colleagues found older adults were less
dimensions (for example, color, shape, and pattern) (Figure         accurate (p = .001, g = .94) than younger adults. These
2). Subjects play a set of games that can vary in length from       behavioral results appeared to derive in part from differences
15-30 trials. Within a game, features of only one dimension         in the decay parameter (median = .52 v .42 for older vs.
(e.g., color) determine the probability of reward. Within this      younger adults, respectively), implying that differences in
relevant dimension, one target feature (e.g., red) leads to         this parameter may reflect meaningful differences in
reward with 75% chance whereas the other 2 features in the          selective attention. These results suggest the task has promise
dimension (e.g., yellow, green) lead to reward with 25%             as a sensitive measure of neuropsychological and clinical
chance. The target feature and relevant dimension change            differences. Per Paulus et al.’s (2016) pipeline, this study
every game. The start of a new game is signaled to subjects.        marks the entrance into Phase 1b: examining clinical validity
                                                                    (see Radulescu et al., 2016 for discussion).
Computational Model. Previous work (e.g., Niv et al. 2015;
                                                                       Although the task has promise as a computational
Radulescu et al., 2016) tested various computational models
                                                                    psychiatry assay, a number of modeling and psychometric
designed to reproduce subjects’ trial-by-trial behavior in the
                                                                    obstacles must first be overcome. In the following sections,
task and found that human behavior is well described by a
                                                                    we report on efforts to explore the properties of the
feature-level RL (fRL)+decay model. The fRL+decay model
                                                                    Dimensions Task and fRL+decay model using two previously
maintains weights reflecting the values of each of the 9
                                                                    collected datasets. The results have implications for the use
features. It linearly sums these weights to calculate the
                                                                    of the Dimensions Task in computational psychiatry and thus
estimated value of each (3-feature) stimulus
                                                                    are of specific interest to researchers interested in the
                    V(S) = W(f)        f  S             (1)      construct of attention learning in computational psychiatry.
                                                                    But the more general interest aim of the following sections is
For example, the model’s estimate of the value of yellow-           to use this case study to illustrate some of the issues that arise
waves-triangle in the above trial is equal to the sum of the        in translating RL tasks to computational psychiatry.
weights of yellow, waves, and triangle. Once a reward is
received (0 or 1 points), the weights of the 3 features of the      Methods
selected stimulus are updated based on the discrepancy
between the obtained reward, Rt, and the model’s estimate of        Datasets are from Niv et al. (2015; hereafter D1) and
the chosen stimulus’s value, V(SChosen), with update rate           Radulescu et al. (2016, study 2; hereafter D2).
controlled by a learning rate free parameter, η                     Specifications. In D1 (N = 22), subjects played 500 trials
                                                                    (number of trials per game was drawn from a Uniform(15,25)
   Wnew(f) = Wold(f) + η[Rt – V(Schosen)]  f  Schosen     (2)     distribution, for a total of M=22.27, SD=1.45 games per
For the other 6 features on a trial—those comprising the 2          subject). In D2 (N = 54), subjects played ~1400 trials
stimuli not selected—the model decays the associated                (M=46.43, SD=5.41 games; subjects stopped playing after
weights with a second free parameter, d                             exactly 40 min.; all games 30 trials).
          Wnew(f) = (1–d)Wold(f)     f  Schosen          (3)      Results
                                                                    Parameter Identifiability. A challenge in fitting RL
                                                                    parameters to individual subject behavior is that parameters
                                                                2219

can be coupled and thus not fully identifiable. In the
fRL+decay model, equations 1–4 show that the role of each
parameter depends on the settings of the other parameters.
Specifically, the values of the stimuli in equation 4 (in which
choice is governed by β) depend—via equation 1—on the
weights of the chosen and non-chosen stimuli. Those weights
are in turn respectively governed by the learning rate (η,
equation 2) and decay rate (d, equation 3).
   Coupling of the parameters modulating value estimation
and choice is characteristic of many RL algorithms (Daw,
2011; Gershman, 2016). Coupling comes in two flavors:
severe and moderate (Daw, 2011). Under severe coupling,
parameters can trade off; for example, increases in one
parameter can be perfectly compensated by decreases in
another. As a result, parameter values may not—even in
principle—be uniquely identifiable. Severe coupling can be
tested for by repeatedly run an off-the-shelf optimizer from
different initial parameter settings and checking whether
optimization converges on the same estimates every time. If
parameters are structurally coupled (i.e., there is no unique
set of estimates), the optimizer will find different estimates       Figure 3. Parameter estimates in D1 (blue) and D2 (green).
on different runs, provided initializations allow the optimizer      indicate identifiability issues. However, correlations should
to cover sufficient territory in likelihood space. In D1 and D2,     only be a first step in checking for identifiability issues, for a
an optimizer repeatedly converged on the same parameter              couple reasons. First, to the extent that the parameters reflect
estimates, suggesting identifiability issues are not too severe      meaningful psychological differences between individuals,
to prevent finding a unique optimum.                                 we should expect they will correlate to some degree, because
   However, there may still be more moderate identifiability         psychological variables often correlate within-subject
issues.    Intuitively,     this     is   because      maximum       (Lykken, 1968). Thus it can be difficult to determine whether
likelihood/maximum a posteriori (ML/MAP) estimates are               correlations reflect modeling noise or true correlations
tantamount to finding the highest point on the “hill” that           between parameters. Second, correlations will not detect non-
defines the parameter surface in likelihood/posterior                linear relationships between parameters or other subtle
probability space. Yet they do not reveal the shape of the hill      identifiability issues (Gershman, 2016). Still, correlations are
below: specifically, the shape of equal-likelihood ridges in         easily interpretable and a good place to start.
the 3D likelihood space. If these ridges are diagonally shaped,        Figure 3 shows that, in both D1 and D2, {d and β} and {d
they indicate covariance between the parameters. Intuitively,        and η} modestly correlate whereas {η and β} strongly
if changing a parameter in one direction (e.g., η from 0.08 to       correlate. In particular, in D2, {η-β} estimates are nearly
0.1) can be compensated for by changing another (e.g., β             perfectly collinear for many subjects. Note also that, for all
from 6.2 to 5.1), with only miniscule changes in the                 parameter pairs, the correlations are higher in D2, where there
likelihood, then one cannot safely draw conclusions from the         were more data, than in D1. In the test-retest reliability
point estimate of either parameter.                                  section below, we will present evidence suggesting that the
Identifiability      and       Computational         Psychiatry.     parameter estimates may be more reliable in D2 than D1. Yet
Identifiability poses a special challenge in the computational       the higher correlations may also suggest more identifiability
psychiatry domain, wherein the aim is often to derive                problems in D2. In fact, both possibilities—better parameter
parameters that can be used as predictors or outcome                 estimates and more identifiability problems—may be true. As
measures (Huys et al., 2016). Derived parameters whose               noted, the equations in which the parameters are embedded
point estimates have much uncertainty about them due to              dictate dependencies—and hence identifiability issues—
identifiability issues are unlikely to be useful for precision       between the parameters. If the true parameters are correlated,
applications, such as prediction or diagnostic subtyping.            then when the model does a better job of recovering their
Probing Identifiability. A first helpful step for probing            values from noisy behavioral data, the observed data will also
identifiability is to examine and visualize the Pearson              correlate more strongly. Thus, the increased correlations may
correlations between pairs of estimates. Figure 3 plots point        actually be good news from a parameter recovery
estimates for pairs of parameters in D1 and D2, with                 perspective. However, the {η-β} collinearity does mean we
regression lines drawn to aid visualization.                         should not treat these variables as independent.
  Sets of parameters can fall along an elliptical contour in the     Diagnosing Issues with Model Fit. Plots also allow
likelihood space if there are identifiability issues, in which       visualization of outlying values, which may reflect model fit
case the parameters will correlate. Thus, if parameter pairs         issues for specific subjects. For example, the arrows in the
closely correlate for most subjects in a dataset, this may           second row, second column plot in Figure 3 point to subjects
                                                                 2220

with outlying η values. Outlying values might indicate
fRL+decay does not well describe specific subjects’ choices
in some or all of the task. However, the points could also
reflect important individual differences, so additional checks
are necessary to make a differential diagnosis.
  We do not delve into model fit issues for individual subjects
(as such specifics would not generalize beyond the                          Table 1. Intraclass correlation coefficients of parameters.
samples/data in D1 and D2), but offer some general                          Table 1 presents test-retest reliability data for D1 and D2.
guidelines for probing these issues. First, another useful                These estimates were derived from splitting the data into
diagnostic is to plot likelihoods for each potentially                    approximately equal halves (specifically at the first game
problematic subject. For example, Daw (2011) provides an                  change after half of trials elapsed) and fitting the model to
example of a 2D heat map of likelihood values. A more                     each (approximate) half. The test-retest reliabilities for {d
quantitative assessment is the variance—covariance structure              and η} in D1 were quite low. This is likely because subjects
of parameter estimates; these structures can be examined by               only played 500 trials, and ~250—the approximate number
taking the inverse of the Hessian from optimization. On- and              of trials per half—may be too few trials to reliably estimate
off- diagonal elements of H–1 respectively give the variance              the parameters. In contrast, the D2 data suggest that ~700
and covariance of parameters. Large values indicate poor                  trials allows for better parameter estimation, as reflected in
parameter estimates (Daw, 2011). Finally, problematic                     the fact that test-retest scores for {d and η} are much higher.
subjects’ behavioral (and physiological, if available) data can                 Universal norms for intra-class correlation coefficients
be checked to see if these data are informative about the                 (ICCs) are arguably not justifiable (Weir, 2005) and at
source of outlying parameter values (e.g., if reaction times              present there are no ICC benchmarks for RL tasks. But, in all
were recorded, it can be useful to check if a subject responded           domains, uncertainties around parameters increase as ICCs
atypically quickly or slowly during a subset or all of the task).         decrease (Weir, 2005). Thus, the above data are relevant to
  Ultimately, if outlying parameter values for a subject do not           clinical science designs because they show how ICCs can
appear to be due to individual differences, but rather to issues          increase with more data (see also Hitchcock et al., 2017).
with model-fit, the researcher may wish to treat these                    Gathering this information before designing a computational
parameters as missing: Parameter estimates derived from a                 psychiatry assay is useful because computational psychiatry
model that poorly describes a subject’s behavior are                      designs must often balance competing goals. On one hand,
meaningless. However, such decisions should be made—then                  parameter estimates tend to improve with more trials. On the
adhered to—before inferential statistics, to avoid the “garden            other, it may be infeasible to have subjects complete too long
of forking paths” (Gelman & Loken, 2013).                                 a task. For instance, individuals with certain disorders may
Subject-Specific Model Fit Issues and Computational                       fatigue easily. Experimental manipulations (e.g., rumination
Psychiatry. Our identification of apparent model fit issues               inductions) may also quickly dissipate. Test-retest reliability
among subjects illustrates the value of collecting data under             data can help negotiate the tradeoff between optimizing
different tasks specifications prior to attempting to develop a           parameter estimates and keeping time on task feasible.
computational psychiatry assay. For instance, in the
Dimensions Task, the presence of multiple individuals with                                          Conclusions
apparently poor model fits suggests that some subjects in
                                                                          Computational psychiatry promises to improve measurement
future clinical science designs will likely have missing data
                                                                          and refine theory in clinical science (Hitchcock, 2017).
for model parameters (because, as noted, values from a model
                                                                          Ultimately it may advance understanding of psychiatric
that poorly describes participant behavior should not be
                                                                          disorders (Redish & Gordon, 2016). Yet there are significant
used). This is important information in the design phase of a
                                                                          barriers to developing computational psychiatry assays.
clinical science study, as it may influence factors such as
                                                                          These barriers are diverse; hence this paper was part
recruitment target, or collection of other data to aid
                                                                          theoretical overview and part case study. The overview part
estimation of anticipated missing values.
                                                                          of the paper first built motivation by discussing the dot probe
Test-retest reliability. As the cautionary tale of the dot probe          paradigm, a case in which failure to attend to measurement
task suggests, it is critical to establish the test-retest reliability    issues in a laboratory task had disastrous results. Dozens of
of potential outcome measures. High test-retest reliability               studies were conducted and vast resources were expended,
scores increase confidence that the measure is tapping a                  over decades, before the poor properties of the task measures
stable psychological construct (Hitchcock, Radulescu, Niv,                were realized. Next, we reviewed why laboratory tasks are so
& Sims, 2017). Establishing stability of a measurement is a               vulnerable to measurement issues: Task performance is often
prerequisite for computational psychiatry designs that seek to            skewed by random state variation. That is, behavior collected
use the measure to assess the effects of some experimental                only once or a few times from a single subject is often
perturbation or group or individual differences. Nevertheless,            corrupted by situational factors. These review parts of the
the basic requirement of establishing test-retest reliability             paper highlighted that minimizing noise in laboratory task
goes unmet with striking frequency in laboratory tasks                    measures is imperative. In the case study part of the paper,
(Lilienfeld, 2014).                                                       we overviewed modeling issues in RL tasks that can add
                                                                      2221

noise to parameter estimates, using two datasets for                Huys, Q. J., Maia, T. V., & Frank, M. J. (2016).
illustration. We concluded by presenting test-retest reliability     Computational psychiatry as a bridge from neuroscience to
data from the Dimensions Task, using this example to                 clinical applications. Nat. Neuro., 19(3), 404-413.
illustrate how time-on-task can improve reliability.                Kenrick, D. T., & Funder, D. C. (1988). Profiting from
    We should note that we have presented only some of the           controversy: Lessons from the person-situation
steps that should be taken when applying an RL task in               debate. American Psychologist, 43(1), 23-34.
clinical science. Other options include applying empirical          Leong, Y. C., Radulescu, A., Daniel, R., DeWoskin, V., &
priors (Gershman, 2016), using physiological data to aid             Niv, Y. (2017). Dynamic Interaction between
parameter estimation (e.g., Leong, Radulescu, et al, 2017),          Reinforcement         Learning      and       Attention       in
and employing hierarchical modeling to weight parameter              Multidimensional Environments. Neuron, 93(2), 451-463.
estimates by group statistics (Gelman & Hill, 2006), which          Lilienfeld, S. O. (2014). The Research Domain Criteria
can reduce the variance of parameter estimates (Daw, 2011).          (RDoC): an analysis of methodological and conceptual
As computational psychiatry develops, we predict that                challenges (pp. 13-14). Beh. Res. and Ther., 62, 129-139.
psychometric, study design, and parameter estimation issues         Lykken, D. T. (1968). Statistical significance in
will come increasingly to the fore.                                  psychological research. Psych. Bull., 70(3), 151-159.
                                                                    Maia, T. V., & Frank, M. J. (2011). From reinforcement
                    Acknowledgments                                  learning models to psychiatric and neurological
This work was supported by NSF research grant DRL-                   disorders. Nature Neuroscience, 14(2), 154-162.
1560829 (CRS) and ARO grant W911NF-14-1-0101 (YN).                  Niv, Y., Daniel, R., Geana, A., Gershman, S. J., Leong, Y.
                                                                     C., Radulescu, A., & Wilson, R. C. (2015). Reinforcement
                          References                                 learning in multidimensional environments relies on
                                                                     attention mechanisms. J. of Neurosci., 35(21), 8145-8157.
Bar-Haim, Y., Lamy, D., Pergamin, L., Bakermans-                    O'Doherty, J. P., Cockburn, J., & Pauli, W. M. (2017).
   Kranenburg, M. J., & Van Ijzendoorn, M. H. (2007).                Learning, Reward, and Decision Making. Annual Review of
   Threat-related attentional bias in anxious and nonanxious         Psychology, 68, 73-100.
   individuals: a meta-analytic study. Psych. Bull., 133(1), 1-     Paulus, M. P., Huys, Q. J., & Maia, T. V. (2016). A roadmap
   24.                                                               for the development of applied computational
Daw, N. D. (2011). Trial-by-trial data analysis using                psychiatry. Biological Psychiatry: Cognitive Neuroscience
   computational models (pp. 3-38). Decision making, affect,         and Neuroimaging, 1(5), 386-392.
   and learning: Attention and performance XXIII, 23.               Price, R. B., Kuckertz, J. M., Siegle, G. J., Ladouceur, C. D.,
Epstein, S. (1979). The stability of behavior: I. On                 Silk, J. S., Ryan, N. D., ... & Amir, N. (2015). Empirical
   predicting most of the people much of the time. Journal of        recommendations for improving the stability of the dot-
   Personality and Social psychology, 37(7), 1097-1126.              probe       task   in     clinical    research. Psychological
Gelman, A., & Hill, J. (2006). Data analysis using                   Assessment, 27(2), 365-376.
   regression and multilevel/hierarchical models. New York:         Radulescu, A., Daniel, R., & Niv, Y. (2016). The effects of
   Cambridge University Press.                                       aging on the interaction between reinforcement learning
Gelman, A., & Loken, E. (2013). The garden of forking                and attention. Psychology and Aging, 31(7), 747-757.
   paths: Why multiple comparisons can be a problem, even           Redish, A. D., & Gordon, J. A. (2016). Computational
   when there is no “fishing expedition” or “p-hacking” and          Psychiatry: New Perspectives on Mental Illness.
   the research hypothesis was posited ahead of time.                Cambridge, MA: MIT Press.
   Technical report, Department of Statistics, Columbia             Rodebaugh, T. L., Scullin, R. B., Langer, J. K., Dixon, D. J.,
   University, New York, NY.                                         Huppert, J. D., Bernstein, A., Zvielli, A., & Lenze, E. J.
Gershman, S. J. (2016). Empirical priors for reinforcement           (2016). Unreliability as a threat to understanding
   learning models. J. Mathematical Psychology, 71, 1-6.             psychopathology: The cautionary tale of attentional
Hallion, L. S., & Ruscio, A. M. (2011). A meta-analysis of           bias. Journal of Abnormal Psychology, 125(6), 840-851.
   the effect of cognitive bias modification on anxiety and         Schmukle, S. C. (2005). Unreliability of the dot probe
   depression. Psychological Bulletin, 137(6), 940-958.              task. European Journal of Personality, 19(7), 595-605.
Heeren, A., Mogoașe, C., Philippot, P., & McNally, R. J.            Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning:
   (2015). Attention bias modification for social anxiety: a         An introduction. Cambridge: MIT press.
   systematic review and meta-analysis. Clin. Psych.                Van Bockstaele, B., Verschuere, B., Tibboel, H., De Houwer,
   Rev., 40, 76-90.                                                  J., Crombez, G., & Koster, E. H. (2014). A review of
Hitchcock, P.F. (2017). Computational Modeling and                   current evidence for the causal impact of attentional bias on
   Reform in Clinical Science. [preprint; osf.io/mvxkf] OSF.         fear and anxiety. Psychological Bulletin, 140(3), 682-721.
Hitchcock, P.F., Radulescu, A., Niv, Y., Sims, C.R. (2017).         Weir, J. P. (2005). Quantifying test-retest reliability using the
   Assessing the Potential of Computational Modeling in              intraclass correlation coefficient and the SEM. The J. of Str.
   Clinical Science. In The 3rd Multidisciplinary Conference         & Cond. Res., 19(1), 231-240.
   on Reinforcement Learning and Decision-Making.
                                                                2222

