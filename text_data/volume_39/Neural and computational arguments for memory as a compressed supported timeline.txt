     Neural and computational arguments for memory as a compressed supported
                                                                 timeline
                                              Zoran Tiganj (zoran.tiganj@gmail.com)
                                         Karthik H. Shankar (kshankar79@gmail.com)
                                       Marc W. Howard (marcwhoward777@gmail.com)
                                                        Center for Memory and Brain
                                             Department of Psychological and Brain Sciences
                                                   Boston University, Boston, MA 02215
                              Abstract                                  constructed to account for these properties (Brown, Neath, &
                                                                        Chater, 2007; Howard, Shankar, Aue, & Criss, 2015; Donkin
   It is well known that, all things being equal, the accuracy of       & Nosofsky, 2012).
   mammalian timing and memory decays gradually with the pas-
   sage of time. The gradual decay of temporal accuracy is also            Neural mechanisms that could support the scale-invariance
   observed in single-unit neural recordings. Here we review re-
   cent modeling work describing a specific mechanism for tim-          of time and memory are still unclear. It has been argued
   ing and memory and relevant neural data. The model describes         that working memory is represented with persistent neural
   a neural mechanism that can give rise to a logarithmically com-      activity observed in different areas of the prefrontal cortex
   pressed representation of the recent past. We examine the spe-
   cific predictions of the model, in particular that the elapse of     (PFC) during for instance a delayed match to sample task
   time is represented by sequentially activated cells which fire       (P. S. Goldman-Rakic, 1991; P. Goldman-Rakic, 1995). Even
   for a circumscribed period of time. Such cells, called time          though such persistent activity can account well for the de-
   cells, have been observed in neural recordings from several
   brain regions in multiple species. As predicted by the model,        mands of a particular task, it is not clear how it could account
   the cells show accuracy that decreases with time.                    for a gradual decay of the memory representation. More re-
   Keywords: scale-invariance, memory, interval timing, time            cent studies have found that in some behavioral tasks a subset
   cells.                                                               of neurons activates sequentially, tiling the task relevant inter-
                                                                        val, typically lasting for several seconds (see e.g. Pastalkova,
                          Introduction                                  Itskov, Amarasingham, and Buzsaki (2008); MacDonald,
                                                                        Lepage, Eden, and Eichenbaum (2011) for the first reports
Behavioral experiments on humans and other animals have
                                                                        of such activity). These neurons that fire sequentially, each
demonstrated that the accuracy in estimating the duration of
                                                                        during a circumscribed period of time, are called time cells
a time interval decays gradually with the interval duration it-
                                                                        (Howard & Eichenbaum, 2015; Eichenbaum, 2013). It has
self. More specifically, the variability of the response is pro-
                                                                        been argued that time cells play important role in timing and
portional to the interval duration (Rakitin et al., 1998; Ivry &
                                                                        memory (MacDonald, Fortin, Sakata, & Meck, 2014; Howard
Hazeltine, 1995). For instance, in interval timing the response
                                                                        et al., 2014; Eichenbaum, 2014).
distributions appear to be scale-invariant: distributions corre-
sponding to different interval durations overlap when linearly             Time cells provide a direct readout of when the delay in-
scaled (Roberts, 1981; Smith, 1968). Furthermore, animal lit-           terval has started: there is no need for population decoding in
erature suggests that in conditioning paradigms, the number             a classical sense (Murray et al., 2016; Stokes, 2015). This is
of trials needed for an animal to learn the association between         because time cells activate sequentially effectively providing
conditioned and unconditioned stimuli scales with a ratio of            temporal basis functions and constituting an internal time-
the reinforcement latency and intertrial interval (Gallistel &          line. As we will discuss later, this timeline is compressed,
Gibbon, 2000), indicating again the scale-invariance in the             such that the temporal resolution gradually decays with the
animals’ behavior (Balsam & Gallistel, 2009; Shankar &                  elapsed time, just as expected given the behavioral findings
Howard, 2012; Gibbon, 1977).                                            on memory and timing we mentioned above. It is unclear,
   In addition to timing, scale-invariance has been argued to           however, what are the neural mechanisms that could give rise
be one of the key properties of memory. Gradual decay of                to such a compressed timeline.
memory without a characteristic scale has been observed in                 Here we utilize a computational model for compressed
a number of behavioral experiments (Anderson & Schooler,                scale-invariant dynamical memory representation introduced
1991; Chater & Brown, 2008; Wixted & Ebbesen, 1991) and                 in Shankar and Howard (2012). We compare specific pre-
it was often refereed to as power-law of forgetting. For ex-            dictions of the model with the neural recordings of sequen-
ample, Donkin and Nosofsky (2012) reported that in item                 tially activated time cells. The model provides a unique solu-
recognition task the strength of the memory was decaying                tion to constructing a scale-invariant memory representation
as a power law function of the lag between studied items                (Shankar, 2015). The model has been used to account for
and a test probe. It has been argued that scale-invariance              results of various timing and memory experiments including
should be thought of as universal law of cognition (Chater              judgment of recency and serial scanning in long and short
& Brown, 1999). A number of cognitive models have been                  term memory (Howard, Shankar, Aue, & Criss, 2015). Here
                                                                    1187

 a                                                                    b
                 1
                                                                                    10
                                                                                    20
                 10
        neuron
                                                                                    30
                                                                           Cell #   40
                 20
                                                                                    50
                                                                                    60
                      1    2     3     4     5     6     7     8                    70
                               time (sec)                                                0       1      2
                                                                                                        Time [s]
                                                                                                                   3        4
Figure 1: Examples of sequentially activated neurons from tetrode recordings in rat hippocampus (plot a.) and PFC (plot b.). On
both plots each row on the heatplot corresponds to a single cell and displays normalized firing rate averaged across trials during a delay interval
of a behavioral experiment. Red corresponds to high firing rate, while blue corresponds to low firing rate. The cells are sorted with respect
to their peak time. Despite the fact that both recordings are done during a rather different behavioral experiment, they both show similar
qualitative properties. In particular we point to two features related to the temporal accuracy: 1) time fields later in the delay are more broad
than time fields earlier in the delay (the central ridge is widening as the peak moves to the right); 2) peak times of the time cells are not evenly
distributed across the delay, with later time periods represented by fewer cells than early time periods (this is apparent from the curvature
of the central ridge; a uniform distribution of time fields would manifest as a straight line). a. Hippocampal CA1 neurons recorded during
object-delay-odor sequence task (reprint from MacDonald et al. (2011)). In order to obtain a reward the animals had to memorize the identity
of the stimulus during the delay interval and match it to the appropriate odor. b. PFC neurons recorded during a temporal discrimination task
(reprint from Tiganj et al. (2016), original data first reported in (Kim et al., 2013)). In order to obtain a reward the animals had to estimate
whether the presented delay interval was larger than some baseline duration and make a left or right turn accordingly following the delay.
we focus on the neural side, looking into specific predictions                some were done on head-fixed animals (MacDonald et al.,
about individual neural activity that can be derived from the                 2013; Modi et al., 2014; Naya & Suzuki, 2011; Adler et
model.                                                                        al., 2012) confirming that the results were not coming from
                                                                              position-related artifacts.
  Sequential activation as a neural correlate of                                 It is worth noting that sequentially activated time cells were
              timing and memory                                               observed in these studies despite the different cognitive de-
                                                                              mands on the animals, which included temporal discrimina-
Starting with a report from Pastalkova et al. (2008), a number
                                                                              tion (e.g. Tiganj et al. (2016)) or memory demands (e.g. Salz
of studies have reported sequential neural activation in dif-
                                                                              et al. (2016); MacDonald et al. (2011)). The duration of the
ferent timing and memory tasks from different brain regions:
                                                                              intervals where such cells were measured was ranging from a
hippocampus (MacDonald et al., 2011; Salz et al., 2016; Gill,
                                                                              couple of seconds up to 60 s (Mello et al., 2015).
Mizumori, & Smith, 2011; Kraus, Robinson, White, Eichen-
                                                                                 Several studies have observed decreasing temporal accu-
baum, & Hasselmo, 2013; MacDonald, Carrow, Place, &
                                                                              racy as a function of delay, due to spread in time field width
Eichenbaum, 2013; Modi, Ashesh, & Bhalla, 2014; Naya
                                                                              (Howard et al., 2014; MacDonald et al., 2011; Mello et al.,
& Suzuki, 2011), PFC (Tiganj et al., 2016) and the striatum
                                                                              2015; Adler et al., 2012; Kraus et al., 2013; Salz et al., 2016;
(Mello, Soares, & Paton, 2015; Adler et al., 2012) in a vari-
                                                                              Tiganj et al., 2016) and/or due to a non-uniform distribution
ety of behavioral tasks. This activity has been hypothesized
                                                                              of time fields (Kraus et al., 2013; Salz et al., 2016; Mello et
to be a neural basis for representation of memory and elapsed
                                                                              al., 2015; Tiganj et al., 2016). Two examples of neural repre-
time in a gradually decaying fashion (Howard, Shankar, Aue,
                                                                              sentation with decreasing temporal accuracy are provided in
& Criss, 2015; Howard & Eichenbaum, 2015; Eichenbaum,
                                                                              Figure 1.
2014, 2013). The studies were done on different animals,
including rats (MacDonald et al., 2011; Salz et al., 2016;                                   Computational model for compressed
Gill et al., 2011; Kraus et al., 2013; MacDonald et al., 2013;
Pastalkova et al., 2008; Mello et al., 2015; Tiganj et al., 2016),
                                                                                              scale-invariant dynamical memory
mice (Modi et al., 2014) and monkeys (Naya & Suzuki, 2011;                                              representation
Adler et al., 2012). Even though the majority of studies used                 The computational model reviewed here was initially intro-
tetrode recordings, Modi et al. (2014) used two-photon cal-                   duced in (Shankar & Howard, 2012). It consists of a two-
cium imaging minimizing the probability that the results were                 layer feedforward neural network with analytically derived
observed due to some sort of recording artifact. Most of the                  weights. Here we briefly describe the model and then focus
studies were done on animals that were allowed to move, but                   on its predictions regarding neural activity. Notice that below
                                                                       1188

we define the model as a model of memory, as it was initially
introduced in (Shankar & Howard, 2012). Its application in
timing is restricted to the stimulus that initiates the delay in-
terval, as the only stimulus that needs to be remembered.
   We first define an input vector f consisting of N elements                                                                          *
such that each of its elements corresponds to a unique stimu-
                                                                                                                                       *
lus. Thus observing for example stimulus A makes an element                        *
in f that corresponds to stimulus A, fA , equal to one for the                                                                         *
time A is presented and zero otherwise. Each element of the
input vector f has a two-layer dynamical compressed memory
representation. The first layer of the network implements an
approximation of an integral transform of the input (Laplace
transform, but as a function of a real rather than a complex                      *
                                                             ∗
variable). This means that nodes in the first layer, F(t, t), act
as leaky integrators (first order low-pass filters) with a spec-
                                                  ∗
trum of time constant defined with k/t, where k is positive              Figure 2: Constructing a scale-invariant compressed memory
integer (Figure 2):                                                      representation through an integral transform and its inverse.
                            ∗                                            A transient input stimulus f(t) (top row) is presented twice
                     F(t, t)        k        ∗                                                                             ∗
                                = − ∗ F(t, t) + f(t).            (1)     and feeds into a layer of leaky integrators F(t, t) with a spec-
                         dt         t                                                             ∗
                                                                         trum of time constants t constituting a discrete approximation
   Leaky integrators project to the second layer, f̃, through            of an integral transform (middle row). The transform is de-
fixed weights that implement an approximation of the inverse             noted as L since it is equivalent to the real part of the Laplace
                                                                                                                ∗
of the transform by applying a kth order derivative with re-             transform. Only three nodes in F(t, t) are shown. Each leaky
             ∗                         ∗                                                                                      ∗
spect to k/t, denoted as F(k) (t, t) (the inverse is derived based       integrator is characterized with its time constant, t. F projects
                                                                                    ∗
on Post’s inversion formula (Post, 1930), see Shankar and                onto f̃(t, t) through a set of weights defined with the opera-
Howard (2012, 2013) for further details on the derivation):              tor denoted as L−1 k which implements an approximation of
                                                                                                                                   ∗
                                       !k+1                              the inverse of the Laplace transform. Nodes in f̃(t, t) acti-
                        ∗           k                    ∗
                  f̃(t, t) = Ck     ∗          F(k) (t, t),      (2)     vate sequentially following the stimulus presentation creat-
                                    t                                    ing a memory representation. The width of the activation of
                                                                         each node scales with the peak time determined by the cor-
where Ck is a constant that depends only on k. The cells in                            ∗
the second layer constitute a dynamical memory representa-               responding t, making the memory scale-invariant. Logarith-
                                                                                               ∗
tion of the input signal. To understand the properties of the            mic spacing of the t assures that the memory representation
memory representation we consider an impulse response of a               is compressed.
cell in f̃. For fA (τ) = δ(τ = 0) the corresponding activation
of the cells in the second layer is:
                                             !k                          ported with a limited number of nodes, the memory repre-
                             ∗       1     t      −k ∗t                  sentation becomes an approximation of the past. The ap-
                     f˜A (t, t) = Ck ∗     ∗     e     t ,       (3)     proximation is scale-invariant (Figure 4) since the width of
                                      t    t                             the activation of each node scales with the peak time (this is
where Ck here is a different constant that depends only on k.            scale-invariant since rescaling the temporal axis rescales the
                                             ∗                           width of the activation by the same amount). In other words,
The activity of each node in f˜A (t, t) is the product of an in-         the accuracy of the memory representation decreases with the
                            k
creasing power term ∗t and a decreasing exponential term                 elapse of time since the stimulus presentation. With appropri-
                              t                                                             ∗
  −k ∗t                                           ∗                      ately distributed t the representation can be made logarithmi-
e     t . Consequently, each node in f˜A (t, t) has a peak that cor-     cally compressed.
                                                           ∗
                    ∗                                 ˜           ∗
responds to the t value of that node: d fAdt(t,t ) = 0 ⇒ t = t.             To establish biological plausibility of the model we have
Thus, following a transient input, cells in f˜A activate sequen-         shown that leaky integrators with a spectrum of time con-
tially in time constituting a dynamical memory representation            stants are biologically realistic (Tiganj, Hasselmo, & Howard,
of the input A (Figure 3).                                               2015; Tiganj, Shankar, & Howard, 2013). In addition, taking
                                                                                                          ∗
   This memory representation has perfect accuracy in the                derivatives with respect to k/t amounts to lateral inhibition,
limit when k → ∞. In a realistic biological or artificial neural         making it biologically plausible as well (Howard et al., 2014).
                                         ∗
network, where k is finite and t is a discrete variable sup-             To implement the derivative it is required that each neurons
                                                                     1189

    a                                               b                                                  invariance of the memory representation which was inspired
                                k=2                                             k = 16
                                                                                                       by the behavioral experiments on timing and memory. Exist-
                 20                                              20                                    ing neural data were thus far not sufficient to explicitly test
                 40                                              40                                    that prediction. However, the qualitative observations made
        Cell #                                          Cell #                                         here are consistent with the scale-invaraince prediction, but
                 60                                              60
                 80                                              80
                                                                                                       they are not sufficient to quantitatively verify it.
                 100                                             100
                                                                                                          In addition to the model described here, several other com-
                    0   2   4          6   8   10                   0   2   4          6   8   10
                                Time                                            Time                   putational models predict the qualitative properties found in
                                                                                                       the data. The common aspect of most of such models is the
Figure 3: Activity of the cells in the compressed memory                                               functional form that gives rise to time fields: as in the model
representation generated by the model. Analogous to the                                                described here, the activity increase is governed by a power-
heatmaps in Figure 1, each row corresponds to a single cell                                            law and then later attenuated by a damping exponential. In
and displays its normalized activity across time. The cells are                                        particular, Grossberg and Schmajuk (1989); De Vries and
sorted with respect to the peak time defined by their value of                                         Principe (1992); Machado (1997) propose different mecha-
∗
t. The two features observed in Figure 1 are fully captured                                            nistic solutions for achieving such form. However, unlike
by the model: the time fields later in the delay were more                                             in the model described here, rescaling the time axis in these
broad than the time fields earlier in the delay and the density                                        models would change the functional form of the representa-
                                                                                 ∗                     tion. Others (for instance Tank and Hopfield (1987); Ludvig,
of time fields decreased as a function of time (t was logar-
                                                                                                       Sutton, and Kehoe (2012)) directly used the functional form
tihmically spaced). This illustrates that the model can indeed
                                                                                                       that provides spreading temporal basis functions as seen here.
account for the firing dynamics of the sequentially activated
time cells that form a compressed representation of time. The                                             Experimental data allowed us thus far to verify some of the
two plots, a and b, show the activity of the cell ensemble                                             predictions computational models make regarding the com-
for two different values of parameter k. Increasing k makes                                            pressed representation of time. However, the model described
the firing fields more narrow and the memory representation                                            here makes specific predictions regarding how memory is
more precise. Notice that, from the biological perspective,                                            maintained in general. Here we assumed that the stimulus that
larger k is more difficult to obtain, since it requires higher or-                                     marks the onset of the delay interval is the only one that has
                                                        ∗                                              the memory representation. The model is designed to capture
der of derivative with respect to k/t. This requires broader
                                                                                                       a variety of stimuli and maintain an independent compressed
connectivity between the two layers.
                                                                                                       memory representation for each of them. In fact, associations
                                                                                                       between the independent representations allowed us to test
of the first layer only projects to the k neighboring neurons of                                       the model on a variety of memory tasks (Howard, Shankar,
the second layer. The connectivity pattern is the same across                                          Aue, & Criss, 2015). It is to be tested whether the neu-
the entire projection, since it always implements a derivative                                         ral representation indeed supports such independent, stimu-
                                 ∗
with respect to k/t. In addition, qualitative alignment of the                                         lus specific compressed memory representations (see Tiganj,
model with the sequential neural activity as shown in Figure 3                                         Cromer, Roy, Miller, and Howard (2017) for recent evidence
further supports its biological plausibility.                                                          of this).
                                                                                                          Maintaining temporal information through sequential acti-
                                           Discussion                                                  vation has a critical computational property in that it provides
We reviewed the predictions from a computational model                                                 a direct readout of the elapsed time. Notice that cells in the
for compressed scale-invariant memory representation and                                               first layer of the model (leaky integrators) contain the same
compared them to the results from recently-published neural                                            amount of temporal information as the cells in the second
recordings. The model maintains a dynamical representation                                             layer (sequentially activated neurons). Thus one could ap-
of the recent past through a set of sequentially activated neu-                                        ply population decoding techniques and extract the temporal
rons. Such sequential activation appears qualitatively similar                                         information from the first layer directly. In fact, this is ex-
to the data published in multiple studies over the past several                                        actly what the inverse transform is doing. However, instead
years including different regions of the brain including the                                           of training a classifier, which would be a common decoding
hippocampus, PFC and striatum.                                                                         procedure, it provides a simple form of linear readout using
   Several of the studies align with the model exhibiting com-                                         a mechanism analogous to lateral inhibition, which is known
pressed memory representation. In particular, the width of the                                         to exist in the nervous system. An additional advantage of
time fields increased with the peak time and more cells had                                            having such a mechanism is that it provides access to the real-
time fields earlier than later in the delay interval (notice the                                       value Laplace domain, where computations that are otherwise
common trend in the plots in Figure 1 and Figure 3). These                                             hard to achieve in a neural network become straightforward.
findings suggest that the model can indeed account for the                                             These in particular include addition and subtraction of prob-
neural representation of the elapsed time.                                                             ability distributions as well as temporal translation (Howard,
   The model makes specific prediction on the scale-                                                   Shankar, & Tiganj, 2015; Shankar, Singh, & Howard, 2016).
                                                                                                    1190

 a                                                          b                                                           c                                                            d
                            Scaling factor = 1                                        Scaling factor = 2                                            Scaling factor = 3                                         Scaling factor = 4
                                                                                                                                                                                                   500
                                                                                                                                        500
                200
                                                                          500                                                                                                                     1000
                                                                                                                                       1000
                400                                                                                                                                                                               1500
      Cell #                                                    Cell #                                                        Cell #                                                     Cell #
                                                                         1000                                                          1500                                                       2000
                600                                                                                                                                                                               2500
                                                                                                                                       2000
                                                                         1500                                                                                                                     3000
                800
                                                                                                                                       2500
                                                                                                                                                                                                  3500
               1000                                                      2000                                                          3000                                                       4000
                   0   20       40      60       80   100                    0   40       80      120      160   200                       0   60      120     180       240   300                    0   80      160     240       320   400
                                     Time                                                      Time                                                       Time                                                       Time
Figure 4: Illustration of scale-invariance in the compressed memory representation generated by the model. Scaling the number
of cells and the temporal duration by the same factor results in identical memory representation (plots a. to d. appear identical
                                                                                                                                                                                                     ∗
despite the fact that both x and y axes are rescaled on each plot). This property follows from Equations (3) since t and t appear only as a ratio
(except for the scaling factor in front that does not influence the functional form). Scale-invariance is consistent with behavioral experiments,
but it remains unclear whether neural data exhibits this property as well, even though the results shown in Figure 1 are consistent with
scale-invariance.
                                                 Conclusion                                                                   and long-term recognition. Psychological Science. doi:
We showed that a computational model for constructing com-                                                                    10.1177/0956797611430961
pressed dynamical representations of the recent past aligns                                                                 Eichenbaum, H. (2013). Memory on time. Trends in Cogni-
well with recent neural data showing sequential neural ac-                                                                    tive Sciences, 17(2), 81-8. doi: 10.1016/j.tics.2012.12.007
tivation. The sequential activation constitutes a compressed                                                                Eichenbaum, H. (2014). Time cells in the hippocampus: a
supported timeline, providing a mechanism for representing                                                                    new dimension for mapping memories. Nature Reviews
the elapse of time and potentially a mechanism for maintain-                                                                  Neuroscience, 15(11), 732–744.
ing a dynamical memory representation.                                                                                      Gallistel, C. R., & Gibbon, J. (2000). Time, rate, and condi-
                                                                                                                              tioning. Psychological Review, 107(2), 289-344.
                                       Acknowledgments                                                                      Gibbon, J. (1977). Scalar expectancy theory and Weber’s law
                                                                                                                              in animal timing. Psychological Review, 84(3), 279-325.
This work was supported by NIBIB R01EB022864, NIMH                                                                          Gill, P. R., Mizumori, S. J. Y., & Smith, D. M. (2011). Hip-
R01MH112169 and MURI N00014-16-1-2832.                                                                                        pocampal episode fields develop with learning. Hippocam-
                                                                                                                              pus, 21(11), 1240-9. doi: 10.1002/hipo.20832
                                                 References                                                                 Goldman-Rakic, P. (1995). Cellular basis of working mem-
Adler, A., Katabi, S., Finkes, I., Israel, Z., Prut, Y.,                                                                      ory. Neuron, 14, 477-85.
  & Bergman, H.          (2012).     Temporal convergence                                                                   Goldman-Rakic, P. S. (1991). Cellular and circuit basis
  of dynamic cell assemblies in the striato-pallidal net-                                                                     of working memory in prefrontal cortex of nonhuman pri-
  work. Journal of Neuroscience, 32(7), 2473-84. doi:                                                                         mates. Progress in brain research, 85, 325–336.
  10.1523/JNEUROSCI.4830-11.2012                                                                                            Grossberg, S., & Schmajuk, N. (1989). Neural dynamics of
Anderson, J., & Schooler, L. (1991). Reflections of the en-                                                                   adaptive timing and temporal discrimination during asso-
  vironment in memory. Psychological science, 2(6), 396–                                                                      ciative learning. Neural Networks, 2(2), 79–102.
  408.                                                                                                                      Howard, M. W., & Eichenbaum, H. (2015). Time and space
Balsam, P. D., & Gallistel, C. R. (2009). Temporal maps and                                                                   in the hippocampus. Brain research, 1621, 345–354.
  informativeness in associative learning. Trends in Neuro-                                                                 Howard, M. W., MacDonald, C. J., Tiganj, Z., Shankar,
  science, 32(2), 73–78.                                                                                                      K. H., Du, Q., Hasselmo, M. E., & Eichenbaum, H.
Brown, G. D. A., Neath, I., & Chater, N. (2007). A tempo-                                                                     (2014). A unified mathematical framework for cod-
  ral ratio model of memory. Psychological Review, 114(3),                                                                    ing time, space, and sequences in the hippocampal re-
  539-76.                                                                                                                     gion. Journal of Neuroscience, 34(13), 4692-707. doi:
Chater, N., & Brown, G. D. (1999). Scale-invariance as a                                                                      10.1523/JNEUROSCI.5808-12.2014
  unifying psychological principle. Cognition, 69(3), B17–                                                                  Howard, M. W., Shankar, K. H., Aue, W., & Criss, A. H.
  B24.                                                                                                                        (2015). A distributed representation of internal time. Psy-
Chater, N., & Brown, G. D. A. (2008). From universal laws of                                                                  chological Review, 122(1), 24–53. doi: 10.1037/a0037840
  cognition to specific cognitive models. Cognitive Science,                                                                Howard, M. W., Shankar, K. H., & Tiganj, Z. (2015).
  32(1), 36-67. doi: 10.1080/03640210701801941                                                                                Efficient neural computation in the laplace domain. In
De Vries, B., & Principe, J. C. (1992). The gamma mod-                                                                        Proceedings of the 2015th international conference on
  ela new neural model for temporal processing. Neural net-                                                                   cognitive computation: Integrating neural and symbolic
  works, 5(4), 565–576.                                                                                                       approaches-volume 1583 (pp. 61–68).
Donkin, C., & Nosofsky, R. M. (2012). A power-                                                                              Ivry, R. B., & Hazeltine, R. E. (1995, Feb). Perception and
  law model of psychological memory strength in short-                                                                        production of temporal intervals across a range of dura-
                                                                                                                       1191

  tions: evidence for a common timing mechanism. J Exp              Salz, D. M., Tiganj, Z., Khasnabish, S., Kohley, A., Sheehan,
  Psychol Hum Percept Perform, 21(1), 3-18.                           D., Howard, M. W., & Eichenbaum, H. (2016). Time cells
Kim, J., Ghim, J.-W., Lee, J. H., & Jung, M. W. (2013).               in hippocampal area ca3. The Journal of Neuroscience,
  Neural correlates of interval timing in rodent prefrontal           36(28), 7476–7484.
  cortex. Journal of Neuroscience, 33(34), 13834-47. doi:           Shankar, K. H. (2015). Generic construction of scale-
  10.1523/JNEUROSCI.1443-13.2013                                      invariantly coarse grained memory. In Australasian confer-
Kraus, B. J., Robinson, R. J., 2nd, White, J. A., Eichenbaum,         ence on artificial life and computational intelligence (pp.
  H., & Hasselmo, M. E. (2013). Hippocampal “time cells”:             175–184).
  time versus path integration. Neuron, 78(6), 1090-101. doi:       Shankar, K. H., & Howard, M. W. (2012). A scale-invariant
  10.1016/j.neuron.2013.04.015                                        representation of time. Neural Computation, 24, 134-193.
Ludvig, E. A., Sutton, R. S., & Kehoe, E. J. (2012). Evalu-         Shankar, K. H., & Howard, M. W. (2013). Optimally
  ating the TD model of classical conditioning. Learning &            fuzzy scale-free memory. Journal of Machine Learning Re-
  Behavior, 40(3), 305–319.                                           search, 14, 3753-3780.
MacDonald, C. J., Carrow, S., Place, R., & Eichenbaum, H.           Shankar, K. H., Singh, I., & Howard, M. W. (2016). Neu-
  (2013). Distinct hippocampal time cell sequences represent          ral mechanism to simulate a scale-invariant future. Neural
  odor memories immobilized rats. Journal of Neuroscience,            Computation, 28(12).
  33(36), 14607–14616.                                              Smith, M. C. (1968). CS-US interval and US intensity in
MacDonald, C. J., Fortin, N. J., Sakata, S., & Meck, W. H.            classical conditioning of rabbit’s nictitating membrane re-
  (2014). Retrospective and prospective views on the role of          sponse. Journal of Comparative and Physiological Psy-
  the hippocampus in interval timing and memory for elapsed           chology, 3, 679-687.
  time. Timing & Time Perception, 2(1), 51–61.                      Stokes, M. G. (2015). ’activity-silent’ working memory in
MacDonald, C. J., Lepage, K. Q., Eden, U. T., & Eichen-               prefrontal cortex: a dynamic coding framework. Trends in
  baum, H. (2011). Hippocampal “time cells” bridge the gap            Cognitive Sciences, 19(7), 394–405.
  in memory for discontiguous events. Neuron, 71, 737-749.          Tank, D., & Hopfield, J. (1987). Neural computation by con-
Machado, A. (1997). Learning the temporal dynamics of                 centrating information in time. Proceedings of the National
  behavior. Psychological review, 104(2), 241.                        Academy of Sciences, 84(7), 1896–1900.
                                                                    Tiganj, Z., Cromer, J. A., Roy, J. E., Miller, E. K., & Howard,
Mello, G. B. M., Soares, S., & Paton, J. J. (2015). A Scalable
                                                                      M. W. (2017). Compressed timeline of recent experience
  Population Code for Time in the Striatum. Current Biology,
                                                                      in monkey lpfc. bioRxiv, 126219.
  25(9), 1113–1122.
                                                                    Tiganj, Z., Hasselmo, M. E., & Howard, M. W. (2015). A
Modi, N. M., Ashesh, D. K., & Bhalla, S. U. (2014).
                                                                      simple biophysically plausible model for long time con-
  CA1 cell activity sequences emerge after reorgani-
                                                                      stants in single neurons. Hippocampus, 25(1), 27-37.
  zation of network correlation structure during asso-
                                                                    Tiganj, Z., Kim, J., Jung, M. W., & Howard, M. W. (2016).
  ciative learning.        eLife, 3(0).       Retrieved from
                                                                      Sequential firing codes for time in rodent mPFC. Cerebral
  http://dx.doi.org/10.7554/eLife.01982                    doi:
                                                                      Cortex(1-9). doi: 10.1093/cercor/bhw336
  10.7554/eLife.01982
                                                                    Tiganj, Z., Shankar, K. H., & Howard, M. W. (2013). Encod-
Murray, J. D., Bernacchia, A., Roy, N. A., Constantinidis,
                                                                      ing the laplace transform of stimulus history using mech-
  C., Romo, R., & Wang, X.-J. (2016). Stable population
                                                                      anisms for persistent firing. BMC Neuroscience, 14(Suppl
  coding for working memory coexists with heterogeneous
                                                                      1), P356.
  neural dynamics in prefrontal cortex. Proceedings of the
                                                                    Wixted, J. T., & Ebbesen, E. B. (1991). On the form of
  National Academy of Sciences, 201619449.
                                                                      forgetting. Psychological Science, 2, 409-415.
Naya, Y., & Suzuki, W. (2011). Integrating what and
  when across the primate medial temporal lobe. Science,
  333(6043), 773-776.
Pastalkova, E., Itskov, V., Amarasingham, A., & Buzsaki, G.
  (2008). Internally generated cell assembly sequences in the
  rat hippocampus. Science, 321(5894), 1322-7.
Post, E. (1930). Generalized differentiation. Transactions of
  the American Mathematical Society, 32, 723-781.
Rakitin, B. C., Gibbon, J., Penny, T. B., Malapani, C., Hinton,
  S. C., & Meck, W. H. (1998). Scalar expectancy theory and
  peak-interval timing in humans. Journal of Experimental
  Psychology: Animal Behavior Processes, 24, 15-33.
Roberts, S. (1981). Isolation of an internal clock. Journal of
  Experimental Psychology: Animal Behavior Processes, 7,
  242-268.
                                                                1192

