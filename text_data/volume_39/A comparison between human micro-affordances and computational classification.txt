A comparison between human micro-affordances and computational classification
     Arthur-Henri Michalland (Arthur-Henri.Michalland@univ-montp3.fr, Arthur.Michalland@lirmm.fr)
                      Epsylon Laboratory EA 4556, University Paul Valéry, Site Saint Charles, route de Mende
                                                          34190 Montpellier, France
             LIRMM: Laboratory of Informatics, Robotics, Microelectronics of Montpellier, University of Montpellier
                                                          CNRS, 860 rue de St Priest
                                                          34095 Montpellier cedex 5
                                         Denis Brouillet (Denis.Brouillet@univ-montp3.fr)
                      Epsylon Laboratory EA 4556, University Paul Valéry, Site Saint Charles, route de Mende
                                                          34190 Montpellier, France
                                            Philippe Fraisse (Philippe.Fraisse@lirmm.fr)
             LIRMM: Laboratory of Informatics, Robotics, Microelectronics of Montpellier, University of Montpellier
                                                          CNRS, 860 rue de St Priest
                                                          34095 Montpellier cedex 5
                               Abstract                                  action is part of objects’ memories and perception, as it is now
                                                                         established (Brouillet et al., 2015), which is of interest for
   This study aimed to assess how specific components of an ac-
   tion could be selected by a simple computational system. We           psychology and for robotics as they permit to gain insight into
   performed an experiment to test associations between grasps           the perception-action loop (Montesano et al., 2007, 2008).
   (precision or power grip) and several objects. We then ran               Yet, the link between perception and affordances needs fur-
   simulations using a naive bayes classifier to study to what ex-
   tent it could reproduce participants’ choice. This classifier had     ther investigation, as clues, or features, need to be extracted
   two learning matrices containing objects’ size associated with        from, or constructed on the basis of the environment. Such
   a grip by means of our experiment. When receiving a new               clues would facilitate the link between a rich perception and
   object’ size it computed the probability for each grip to be
   adapted. The highest probability was considered to represent          an adapted movement, and permit on line adaptation.
   which grip was associated with the object by the classifier. Re-         Our purpose was to test how adapted voluntary movements
   sults show that the classifier can reproduce participants’ choice
   depending on the size of its learning matrices, and can quickly       could be selected, by a very simple computational system, on
   select the right type of grip for a majority of trials, showing       the basis of clues extracted from perception. To do this we
   that micro-affordances (Ellis & Tucker, 2000) can be repro-           chose to test some specific components of an action: grasp-
   duced through naive bayesian classification.
                                                                         ing movements (Koester, Schack, & Westerholz, 2016). A
   Keywords: affordance; grip; bayesian method; classifier               lot of our interactions with the world depend on our abil-
                                                                         ity to grasp things around us in a proper way, for example
                          Introduction                                   using a power or a precision grip (i.e. with all fingers of
As Leonard de Vinci said : “movement is principle of life”.              the hand or with the thumb and index, respectively, see Fig-
The way people interact with the world through body move-                ure 1). These specific components of action (that doesn’t in-
ments is indeed a corner stone of psychology, and especially             clude walking, reaching etc...) are termed micro-affordances
of embodied psychology. As embodied psychology postu-                    by Ellis and Tucker (2000). These micro-affordances are sup-
lates that high-level cognitive processes are bodily rooted,             posed to emerge while looking at an object, and to facilitate
or at least that their result depends on bodily states (Wilson,          a specific grasp. We selected object size to be the feature of
2002), movements of the living body is a crucial point to at-            the environment that could be associated to a specific grasp,
tend. Yet how adapted body movements occur is not well                   in order to create a model that simulates a perceptually based
determined and several propositions are made, one of them                motor activity.
being particularly attractive for embodied cognitivists: the-               The computational system we used to infer specific grasps
ory of affordances (Gibson, 1979).                                       rely on bayesian probability (Jones & Love, 2011; Pearl,
   Affordance is a concept coined by Gibson (1979) that relies           1985). The bayesian approach appears to be promising when
on direct perception. Although it has many interpretations,              studying how humans can interact with the world in presence
we will rely on the definition of Chemero (2003) in which af-            of uncertainty (Perfors et al., 2011). It can apply to motor
fordances represent the relations between an animal’s capaci-            planning and control, estimation of context and motor learn-
ties and features of its environment. Abilities of an animal are         ing (Wolpert & Ghahramani, 2000; Wolpert, Ghahramani, &
functional properties, that depends on this animal’s history.            Flanagan, 2001), and can be easily used in its simplest ways
   This theory highlights the fact that voluntary actions are            (Robert, 2000). This approach rely on conditional probabil-
products of our perception of the situation, our abilities, and          ity and allows to determine the probability of a certain event
what we have learned. Moreover, this theory predicts that                (for example a particular grasp) knowing some information :
                                                                     2729

past experiences (e.g. earlier grasp in presence of an object)
or sensory inputs (e.g. object size) (Naı̈m et al., 2007).
   The particular model we chose is a naive bayes classifier.
This model has two learning matrices : one containing the
size of objects graspable with a power grip, and one contain-
ing the size of objects graspable with a precision grip, size
being represented by three parameters x, y, and z. Once it has
computed these matrices, it receives the size of a novel ob-
ject to be classified as graspable with a power grip or with a       Figure 1: A hand making a power grip (left picture), and a
precision grip. In order to do so, it selects the most probable      precision grip (right picture).
grasp, knowing the object size, to be the grasp to produce in
presence of this particular object.
   This approach of micro-affordances as naive bayesian clas-        Procedure
sification can be of interest for psychologists and roboticians,     All of eighty participants were received one by one in an ex-
as it can reduce the size of ontology, or databases, needed for      perimentation room, and sat in front of a computer Lenovo
an adapted system, and permits to infer micro-affordances in         17.3” with graphics card AMD radeon HD 8500M. They
a very simple way.                                                   were asked to grab, with their right hand, a device that con-
   In a first part we present the experiment to test micro-          strained them to make either a power or a precision grip. They
affordances with human beings and select objects that can            were instructed to look at the computer screen and make the
be associated with a precision or a power grip. In a second          more appropriate grip on the device when seeing an object
part we explain how the model categorizes objects as being           displayed on the screen. The twenty objects were then dis-
graspable with a precision or a power grip by means of naive         played randomly. When the twenty objects had been exposed,
bayesian classification, and show the results obtained with          a second random presentation was made, in order to ensure
this model. We then compare human’s and classifier’s perfor-         the grip selected by participants for each object.
mances and discuss the possible developments of such appli-
cations.                                                             Results
                                                                     Overall, the grips selected by means of the pre-experiment
     Selection and association of objects with a                     were respected, as shown in Table 1 and Table 2, and par-
               precision or a power grip                             ticipants showed stable grip for each object. All of which al-
Participants                                                         lowed us to classify each object as associated with a precision
                                                                     or a power grip.
Sixteen students were recruited for a pre-experiment in or-
der to select the objects used in our experiment and simula-
tion. Eighty students, different from the previous ones, were        Table 1: Percentage of responses for objects associated with
then recruited in order to select the appropriate grasp for each     a precision grip, a number was attributed to each object for
object (seven of them were not taken into account as they            further comparison.
changed their grasping for the same objects between trials and
differed drastically from the others). All participants freely       Objects              N     % power grip      %precision grip
signed a letter of consent, were right-handed, had normal or         grain of wheat       1           0.68              99.32
corrected to normal vision and over 18 years old, none had           tweezers              2          3.42              96.58
problems of motricity.                                               nut                  3           0.68              99.32
                                                                     radish               4          10.96              89.04
Materials                                                            smart card            5          1.37              98.63
Forty-four pictures of objects were used. Each picture was           screw                 6          0.00             100.00
modified to have the object being centered, vertically ori-          paper clip           7           0.00             100.00
ented, and a half of their real size when displayed on the com-      strawberry           8           6.85              93.15
puter screen.                                                        french beans         9           1.37              98.63
   These images were presented to sixteen students in a pre-         key                  10          2.74              97.26
experiment, with a hand near the object either making a
power grip or a precision grip (see Figure 1). Participants
had to indicate their level of agreement with the grip being                Simulation with a naive bayes classifier
displayed with the object. A high level of agreement with a
grip meant that it was a reasonable grip to pick up and use the      The naive bayes classifier
object.As a result, twenty objects were selected for the exper-      The second step of this work was to put the naive bayes clas-
iment, ten being graspable with a power grip and ten with a          sifier to the test. To do so, we had to implement the size of
precision grip.                                                      objects used in our experiment. We chose to represent size in
                                                                 2730

                                                                    ject, represented by a vector (xn , yn , zn ), was associated by the
Table 2: Percentage of responses for objects associated with a
                                                                    model to probabilities P(gripi |xn , yn , zn ) for i = 1 the preci-
power grip, a number was attributed to each object for further
                                                                    sion grip (grip1 = G1 ) and i = 2 the power grip (grip2 = G2 ).
comparison.
                                                                       The Bayes’ theorem permits to decompose these probabil-
Objects               N     % power grip      %precision grip       ities :
                                                                                                                   P(gripi , xn , yn , zn )
glass                 11         97.26             2.74                                 P(gripi |xn , yn , zn ) =                           (1)
hair clipper          12         91.10             8.90                                                                P(xn , yn , zn )
coconut               13        100.00             0.00             The probability P(gripi , xn , yn , zn ) can be written as :
apple                 14        99.32              0.68
corn                  15        95.89              4.11                                 P(gripi , xn , yn , zn ) = P(xn , yn , zn , gripi )
computer mouse        16         89.73            10.27
board wiper           17         92.47             7.53                                 = P(xn |yn , zn , gripi ) × P(yn , zn , gripi )
universal pliers      18         95.21             4.79                     = P(xn |yn , zn , gripi ) × P(yn |zn , gripi ) × P(zn , gripi )
pepper                19         95.21             4.79
deodorant             20         91.78             8.22              = P(xn |yn , zn , gripi )×P(yn |zn , gripi )×P(zn |gripi )×P(gripi )
                                                                                                                                            (2)
                                                                       Here, the naive assumption of conditional independence
a three dimensional cartesian coordinate system, representing       assumes that given the category gripi , xn , yn and zn are in-
height, width, and depth.                                           dependent, so that :
                                                                                           P(xn |yn , zn , gripi ) = P(xn |gripi )          (3)
                                                                    and
                                                                                            P(yn |zn , gripi ) = P(yn |gripi )              (4)
                                                                       Thus, using equations (1) (2) (3) and (4)
                                                                         P(gripi |xn , yn , zn ) =
     Figure 2: A computer mouse mesured on x, y and z.                      P(xn |gripi ) × P(yn |gripi ) × P(zn |gripi ) × P(gripi )
                                                                                                                                            (5)
                                                                                                        P(xn , yn , zn )
                                                                       The model then selected the adapted grip for the object
Table 3: Mean and Variance for objects associated with a pre-       (xn , yn , zn ) using :
cision grip or a power grip.
                                                                                       argmax[P(G1 |xn , yn , zn ); P(G2 |xn , yn , zn )]   (6)
Objects                          Mean (Variance)
                        x                 y               z            In concrete terms the naive bayes classifier had two learn-
precision            1.265              0.62            4.87        ing matrices of size ( j, 3), j being the number of objects in
                    (0.422)           (0.291)         (11.72)       the learning matrices, represented by their three coordinates
power                 6.76              5.27           13.92        (x j , y j , z j ). One matrix included the objects classified as gras-
                     (3.83)            (8.58)         (22.94)       pable with a precision grip (G1 ), the other included the ob-
                                                                    jects classified as graspable with a power grip (G2 ).
   We defined a rule to mesure our objects : z axis for the            The following calculations were applied similarly for G1
longest axis of the object, y axis for the shortest axis of the     and G2 , we will only present the calculations for parameter
object, and x the last one, following the right hand rule (e.g.     x in G1 for the sake of clarity. The classifier computed the
mesure of a computer mouse in centimeter: x = 6, y = 1.65,          probability for an object to be graspable with a precision grip
z = 11.50, see Figure 2).These rules were followed in order         (P(G1 ) = 2jj = 12 ).
to satisfy the concept of axis for grasping proposed in Michel         And the mean and variance of each parameter x, y,
(2006), we simplified Michel’s studies to reduce the natural        and z for a precision grip : µG1 (x), µG1 (y), µG1 (z) and
axis of prehension of an object to its longest side. Mean and       σ2G1 (x), σ2G1 (y), σ2G1 (z); and for a power grip, resulting in
variance of objects associated with a precision grip and ob-        µG2 (x), µG2 (y), µG2 (z) and σ2G2 (x), σ2G2 (y), σ2G2 (z).
jects associated with a power grip are presented in Table 3.           When a novel object with parameters (xn , yn , zn ) was pre-
                                                                    sented to the model, the classifier had to compute the proba-
Procedure                                                           bilities P(G1 |xn , yn , zn ) and P(G2 |xn , yn , zn ), using (5).
The model received an unknown object to be classified as               As measurements were on continuous variables, the new
graspable with a power grip or a precision grip. This ob-           parameters were computed given the known parameters
                                                                2731

of the model using a gaussian probability density func-                       learned). In addition we compared the results of the classi-
tion, in order to calculate P(xn |G1 ), P(yn |G1 ), P(zn |G1 ) and            fier to the results obtained with human participants.
P(xn |G2 ), P(yn |G2 ), P(zn |G2 ) with:                                          Simulation ran using j = 1 to 7 learned objects for each
                                                                              category (we always used the same number of learned objects
                                                  [xn −µG (x)]2
                                                −         1                   in the two categories : objects associated with a precision grip
                                     1               2σ2G (x)
                P(xn |G1 ) = q                 e         1                    and objects associated with a power grip).
                                 2πσ2G1 (x)                                       Objects that were not used in learning matrices were cate-
                                                                              gorized using the method described earlier.
   Then the model selected the highest probability (the appro-                    As learning order did not have any impact on classification,
priate grip), using (6).                                                      number    of trials was defined using the binomial coefficient
                                                                                N
   As gaussian probability density function could return 0 for                  j   with  N = 10 the total number of objects in each cate-
the probability of a parameter given a class gripi , we distin-               gory and j the number of objects learned in each category.
guished two cases. In the first case only one parameter of                    This binomial coefficient gives the number of combination
the novel object had a probability equal to zero, in this case                of learned objects without taking into account possibilities of
we did not change anything (we show in discussion why this                    permutation (learning order). The classifier was tested for ev-
case is a limit for this type of classification). In the second               ery possible combination of learning: for each combination of
case two parameters of the novel object, one for each class,                  precision grip’s learning, we tested all combinations of power
had a probability equal to zero (for example P(yn |G1 ) = 0                   grip’s learning. This way the results presented in Table 4 and
and P(zn |G2 ) = 0), we changed these probabilities to ε close                Table 5 show the proportion of correct classification for every
to zero , this changed P(G1 |xn , yn , zn ) and P(G2 |xn , yn , zn ) to       object over all possible learnings of our material.
                                                                                  For each object and each j we verified the grip selected by
                                                                              the classifier within each trial. For objects associated with
                               P(xn |G1 ) × ε × P(zn |G1 ) × P(G1 )           a precision grip by means of our experiment (see Table 1),
   P(G1 |xn , yn , zn ) = lim
                          ε→0                 P(xn , yn , zn )                classification was recorded as right when the classifier cal-
                                                                       (7)    culates a higher probability for precision grip than for power
and                                                                           grip. The reverse was made for objects previously associated
                               P(xn |G2 ) × P(yn |G2 ) × ε × P(G2 )           with a power grip (see Table 2). If probabilities for a preci-
   P(G2 |xn , yn , zn ) = lim                                                 sion grip and for a power grip were equal, we considered that
                          ε→0                 P(xn , yn , zn )
                                                                              classification was incorrect.
   As P(xn , yx , zn ) = P(xn , yn , zn , G1 ) + P(xn , yn , zn , G2 )
                                                                              Results
                                                                              Overall it took 1397.71 seconds (23 minutes and 29 seconds)
    P(xn , yn , zn ) =
                                                                              for the program to select learning matrices and make 1837440
                 P(xn |G1 ) × ε × P(zn |G1 ) × P(G1 )+                        classification. The classification of one object took in average
                  P(xn |G2 ) × P(yn |G2 ) × ε × P(G2 )                        7.61 × 10−1 ms.
                                                                                  When more than one parameter for one class was equal to
                                                                              zero (33 cases), or when P(xn , yn , zn ) was considered equal
                         = ε × [P(xn , zn , G1 ) + P(xn , yn , G2 )] (8)
                                                                              to zero due to very small probabilities (82 cases), classifi-
So that, using (7) and (8):                                                   cation was impossible. These particular numeric cases hap-
                                                                              pened rarely (115 objects impossible to classify over 1837440
                              P(xn |G1 ) × P(zn |G1 ) × P(G1 )                classified objects).
       P(G1 |xn , yn , zn ) =                                                     We computed the percentage of right classification for each
                                P(xn , zn , G1 ) + P(xn , yn , G2 )
                                                                              object and each j (number of learned objects before classifi-
   Thus the probability of a grip given the three parameters                  cation). The percentages of right classification are shown in
of the novel object became the probability of a grip given                    Table 4 (the percentage of right classification for objects con-
the two parameters of the novel object for which probability                  sidered as associated with a precision grip), and Table 5 (the
was not changed by ε, as the changes operated cancelled each                  percentage of right classification for objects considered as as-
other out.                                                                    sociated with a power grip).
                                                                                  A few things are to be discussed here. First, we can see
Simulation                                                                    that overall the classifier returned the right grip most of the
Simulation was performed using Matlab R2015a with a com-                      time, in all the conditions (92.86% of right classification).
puter running on Windows 7 with a CPU Intel Core i5-4258U                         Secondly we can see that classification was better for ob-
2.10GHz.                                                                      jects that were considered associated with a power grip than
   We aimed at assessing naive bayes classification by                        for the others.
analysing classifier’s performance with different learning                        Thirdly, we see that classification performance increased
matrices (different learned objects and number of objects                     as number of learned objects increased. This is because pa-
                                                                          2732

                                                                     rectly.
Table 4: Percentage of right classification for objects associ-
                                                                        The fact that object 4 was hardly well classified, instead
ated with a precision grip and for k objects learned.
                                                                     of being a real issue for naive bayesian classification, could
Objects                 Number of learned objects                    be an advantage when comparing the classifier’s performance
              2        3        4        5        6         7        and human classification: in our experiment object 4 reveals
1           85.22    95.95 99.60        100      100       100       the higher percentage of selection for the competing grip (see
2           76.62    86.97 95.57 99.21           100       100       Table 1).
3           88.39    96.83 99.90        100      100       100       Comparison of human and classifier’s performance
4           43.34    47.52 46.28 45.85 42.15              30.36
                                                                     To compare human’s and classifier’s performance we used a
5           82.93    93.91 98.81 99.73           100       100
                                                                     χ2 test of independence between variable object (object 1 to
6           84.07    95.37 99.43        100      100       100
                                                                     object 20) and variable responding entity (human participants
7           87.49    98.33     100      100      100       100
                                                                     or naive bayes classifier).
8           63.03    80.10 91.42 96.49 98.76               100
                                                                        When three, four, five and six objects of each category
9           52.78    56.54 63.03 67.64 73.39              80.37
                                                                     were put in the classifier’s learning matrices, we found that
10          86.63    94.98 99.26        100      100       100
                                                                     the two variables were independent (χ2 (19) = 25.22, p =
Mean        75.05    84.65 89.33 90.89 91.43              91.07
                                                                     0.15; χ2 (19) = 23.06, p = 0.23; χ2 (19) = 21.69, p =
                                                                     0.30; χ2 (19) = 22.71, p = 0.25, respectively), this meaning
                                                                     that classifier’s performance and human grip’s choice were
Table 5: Percentage of right classification for objects associ-      not significantly different.
ated with a power grip and for k objects learned.                       When two objects of each category were put in the clas-
                                                                     sifier’s learning matrices, we found that variables object
Objects                 Number of learned objects
                                                                     and responding entity were independent, but with a greater
               2        3         4        5        6       7
                                                                     difference between human’s and classifier’s performance
11          96.22     99.93      100      100      100     100
                                                                     (χ2 (19) = 29.26, p = 0.06).
12          86.66     96.26 99.52         100      100     100
                                                                        Finally, when seven objects of each category were put in
13          96.82     99.79      100      100      100     100
                                                                     the classifier’s learning matrices, it appeared that the two vari-
14          95.54     99.56      100      100      100     100
                                                                     ables were not independent anymore (χ2 (19) = 33.01, p <
15          94.21     98.77 99.82         100      100     100
                                                                     0.05), human’s and classifier’s performance became signifi-
16          92.29     98.75 99.96         100      100     100
                                                                     cantly different.
17          95.09     99.73      100      100      100     100
18          86.63     94.82 98.82 99.84 100                100                                 Discussion
19          96.97     99.76      100      100      100     100
                                                                     The results we obtained reveal that naive bayesian classifica-
20          94.04     99.30      100      100      100     100
                                                                     tion can reproduce the grip’s choice made by human partici-
Mean        93.45     98.67 99.81 99.98 100                100
                                                                     pants.
                                                                        A good association of a novel object and its adapted grip
                                                                     can be accomplished with a reduced database and few param-
rameters µ and σ were more representative of a class (power          eters. This may permit to determine quickly a subclass of
or precision grip) as number of learned objects increased.           grips belonging to the precision or power grip classes when
   What is counterintuitive is that classification of object         looking at an object, in other words to detect the possible
number 4 got worse and worse, it is because we put more              nested micro-affordances associated with the object (for ex-
objects different from object 4 in the precision grip’s learning     ample a precision grip could comprise several nested micro-
matrice as the simulation went on. Object 4 had its three pa-        affordances: a grip with the thumb and the index, a grip with
rameters close to boundaries of the precision grip space (rep-       the thumb, the index and the middle finger, with more or less
resented by its mean and variance for each parameter x, y and        strenght etc...). Quickness of the categorisation in precision
z). Thus, depending on the objects learned, increasing the           or power grip classes could then be an advantage for real-time
number of learned objects put object 4 out of the boundaries:        adaptation.
the more learned objects associated with a precision grip had           But some limitations are to be exposed. The calculation of
parameters close to the parameters of object 4, the more ob-         conditional probabilities through gaussian probability density
ject 4 was classified as part of precision grip’s objects. Con-      function implies that a parameter could have a zero probabil-
versely the more learned objects associated with a precision         ity given a certain grip class. This pulled the probability of
grip had parameters distant from object 4, the more it was           this grip to zero, while the probability of the competing grip
classified as part of power grip’s object. Compared to object        automatically became one, biasing the classification of the
4, other precision grip’s objects had one of their parameter         object. A second limitation is the ad hoc hypothesis that pa-
close to the boundaries of precision grip’s space, but not all       rameters are independent, which could induce errors for other
of their parameters, which made them easier to classify cor-         parameters than the ones we used.
                                                                 2733

   When seven objects of each category were learned by the            Hommel, B. (2015). The theory of event coding (TEC) as
classifier, the selection made by the classifier and human              embodied-cognition framework. Frontiers in Psychology,
choice became significantly different probably because clas-            6, 1318.
sifier’s selection only account for a calculation made on the         Jones, M., & Love, B. (2011). Bayesian fundamentalism or
basis of mean and variance of the three parameters represent-           enlightenment? on the explanatory status and theoretical
ing the objects. This calculation is always the same and as             contributions of bayesian models of cognition. BEHAV-
long as enough objects are learned the mean and variance of             IORAL AND BRAIN SCIENCES, 34, 169–231.
each class’ parameter began to show little variability no mat-        Koester, D., Schack, T., & Westerholz, J. (2016). Neurophys-
ter the learning matrices. This shows that the algorithm used           iology of grasping actions: Evidence from erps. Frontiers
with this classifier produces a rigid classification, and can-          in Psychology, 7, 1996.
not, at some point, reproduce the diversity created both by           Michel, C. (2006). Stratégie de saisie pour une main robo-
the complexity of our cerebral structures and the variations of         tisée à caractère anthropomorphique. Doctoral disserta-
embodiment between different human beings.                              tion, Robotics Department, University of Paris 6 Paris.
   Yet this classifier can reproduce, in the majority of cases,       Montesano, L., Lopes, M., Bernardino, A., & Santos-Victor,
human grip’s choice in a small amount of time, and with few             J. (2007). Affordances, development and imitation. In
parameters needed to be taken into account. This shows that             Development and learning, 2007. icdl 2007. ieee 6th inter-
micro-affordances could be reproduced in some way with a                national conference on. Piscataway, NJ: IEEE.
simple computational system using naive bayesian classifica-          Montesano, L., Lopes, M., Bernardino, A., & Santos-Victor,
tion, suggesting that some early stages of the processes linked         J. (2008). Learning object affordances: From sensory–
to human micro-affordance could be performed by some sim-               motor coordination to imitation. In Ieee transactions on
ple probabilistic mechanisms.                                           robotics (pp. 15–26). Piscataway, NJ: IEEE.
   Future studies should take more parameters for an object           Naı̈m, P., Wuillemin, P. H., Leray, P., Pourret, O., & Becker,
by cutting up the objects in three parts in order to deter-             A. (2007). Réseaux bayésiens. Paris, France: Eyrolles.
mine the type of grip and the position of the grip on the ob-         Pearl, J. (1985). Bayesian networks: a model of self-activated
ject (Faria et al., 2014), and introduce action’s consequences          memory for evidential reasoning. In Proceedings of the an-
(Hommel, 2015; Shin, Proctor, & Capaldi, 2010) through                  nual conference of the cognitive science society 1985 (pp.
tactilo-kinesthetic parameters (Pfister et al., 2014), like pres-       329–334). Irvine, UC: Cognitive Science Society.
sure induced by the weight of the object, or muscle tension,          Perfors, A., Tenenbaum, J. B., Griffiths, T. L., & Xu, F.
in order to permit an efficient grip with a simple classification       (2011). A tutorial introduction to bayesian models of cog-
algorithm. We should also investigate the classifier’s perfor-          nitive development. Cognition, 120, 302–321.
mance when an increased number of objects are learned and             Pfister, R., Janczyk, M., Gressmann, M., Fournier, L. R., &
classified.                                                             Kunde, W. (2014). Good vibrations? vibrotactile selfstim-
                                                                        ulation reveals anticipation of bodyrelated action effects in
                     Acknowledgments                                    motor control. Exp Brain Res, 232, 847–854.
We would like to thank Johan Briglia, Jean-Pierre Rivet and           Robert, C. (2000). L’analyse statistique bayésienne. Paris,
Firas Kaddachi for their contributions to this work. We also            France: Economica.
thank Epsylon’s DynaCSE team and LIRMM’s IDH team for                 Shin, Y. K., Proctor, R. W., & Capaldi, E. J. (2010). A review
welcoming us during our thesis, and Paul Valery University              of contemporary ideomotor theory. Psychological Bulletin,
for funding this thesis.                                                136, 943–974.
                                                                      Wilson, M. (2002). Six views of embodied cognition. Psy-
                          References                                    chonomic Bulletin Review, 9, 625–636.
Brouillet, D., Vagnot, C., Milhau, A., Brunel, L., Briglia, J.,       Wolpert, D. M., & Ghahramani, Z. (2000). Computa-
   Versace, R., & Rousset, S. (2015). Sensorymotor prop-                tional principles of movement neuroscience. Nature Neu-
   erties of past actions bias memory in a recognition task.            roscience, 3, 1212–1217.
   Psychological Research, 79, 678.                                   Wolpert, D. M., Ghahramani, Z., & Flanagan, J. R. (2001).
Chemero, A. (2003). An outline of a theory of affordances.              Perspectives and problems in motor learning. Trends in
   Ecological Psychology, 15, 181–195.                                  Cognitive Sciences, 5, 487–494.
Ellis, R., & Tucker, M. (2000). Micro-affordance : The po-
   tentiation of components of action by seen objects. British
   Journal of Psychology, 91, 451–471.
Faria, D. R., Trindade, P., Lobo, J., & Dias, J. (2014).
   Knowledge-based reasoning from human grasp demonstra-
   tions for robot grasp synthesis. Robotics and Autonomous
   Systems, 62, 794–817.
Gibson, J. J. (1979). The ecological approach to visual per-
   ception. Boston, MA: Houghton-Mifflin.
                                                                  2734

