     Grammar-Based and Lexicon-Based Techniques to Extract Personality Traits
                                                               from Text
                                         Maira B. Carvalho (m.brandaocarvalho@uvt.nl)
                                             Tilburg Center for Cognition and Communication
                                                             Tilburg University
                                                         Tilburg, The Netherlands
                                               Max M. Louwerse (mlouwerse@uvt.nl)
                                             Tilburg Center for Cognition and Communication
                                                             Tilburg University
                                                         Tilburg, The Netherlands
                              Abstract                                  of information about themselves: there is evidence to sug-
                                                                        gest that self-descriptions are heavily influenced by the social
   Language provides an important source of information to pre-
   dict human personality. However, most studies that have pre-         groups in which a person finds himself (McGuire & Padawer-
   dicted personality traits using computational linguistic meth-       Singer, 1976), and dissimulation can be a problem in self-
   ods have focused on lexicon-based information. We investigate        reports (Wright, 2014).
   to what extent the performance of lexicon-based and grammar-
   based methods compare when predicting personality traits. We            Automatic inference of personality offers the advantages of
   analyzed a corpus of student essays and their personality traits     being less intrusive and possibly more environmentally valid.
   using two lexicon-based approaches, one top-down (Linguis-
   tic Inquiry and Word Count (LIWC)), one bottom-up (topic             Indeed, a range of studies have investigated the extent to
   models) and one grammar-driven approach (Biber model), as            which personality traits can be predicted from user behavior.
   well as combinations of these models. Results showed that            The lion’s share of these studies use linguistic data as sources
   the performance of the models and their combinations demon-
   strated similar performance, showing that lexicon-based top-         of information, both language and speech (Beukeboom, Ta-
   down models and bottom-up models do not differ, and neither          nis, & Vermeulen, 2012; Gawda, 2009; Mairesse, Walker,
   do lexicon-based models and grammar-based models. More-              Mehl, & Moore, 2007; Mehl, Robbins, & Holleran, 2012;
   over, combination of models did not improve performance.
   These findings suggest that predicting personality traits from       Oberlander & Gill, 2006; Oberlander & Nowson, 2006). Lin-
   text remains difficult, but that the performance from lexicon-       guistic data has also shown to indirectly shed light on person-
   based and grammar-based models are on par.                           ality. For instance, linguistic cues have shown to be linked to
   Keywords: language; personality; traits; machine learning;           deception (Louwerse, Lin, Drescher, & Semin, 2010), and to
   computational linguistics; lexicon-based; grammar-based
                                                                        different registers of communication (Louwerse, McCarthy,
                          Introduction                                  McNamara, & Graesser, 2004). Furthermore, a person’s emo-
                                                                        tional state is reflected in language use (Tausczik & Pen-
In our daily interactions, we guide our behavior towards other          nebaker, 2009), not only by explicit lexical content but also by
people using information that is collected throughout these             implicit semantic associations (Recchia & Louwerse, 2014).
interactions, but also using knowledge about the world and
social groups (Rich, 1979). These judgments are oftentimes                 In considering the cognitive science literature that aims to
made unconsciously.                                                     extract behavioral information from linguistic data, two ap-
   Models of users’ behavior, thinking and feeling typically            proaches can be distinguished. On the one hand, studies
rely on the personality traits that can be identified (McCrae &         use lexical cues to extract information from text, for exam-
John, 1992). Trait theory is an approach to the study of human          ple emotional expression (Kahn, Tobin, Massey, & Anderson,
personality in which it is believed that humans exhibit habit-          2007), deception (Newman, Pennebaker, Berry, & Richards,
ual patterns of behavior, thought and emotion. It is presumed           2003), political orientation (Dehghani, Sagae, Sachdeva, &
that there is a relatively small number of dimensions that              Gratch, 2013), moral foundations (Graham, Haidt, & Nosek,
can be used to describe personality (O’Connor, 2002). Inde-             2009), romantic relationship outcomes (Ireland et al., 2011),
pendent analyses have consistently yielded five broad dimen-            among others. On the other hand, extracting behavioral in-
sions, called the Big Five (or Five Factor Model): openness             formation from explicit lexical information can be problem-
to experience, conscientiousness, extraversion, agreeableness           atic. First, in controlled experimental settings it is easy for
and neuroticism (McCrae & John, 1992).                                  participants to carefully monitor their semantic content. For
   Personality traits are generally identified on the basis of          instance, in deception studies participants might avoid using
data collected from the users who fill out standardized ques-           specific words. Second, sparsity issues may emerge if algo-
tionnaires. However, such an approach has certain draw-                 rithms detect specific word use.
backs. Firstly, it can be costly for the researcher and time-              An alternative approach lies in using grammar-based cues.
consuming for the user (Gauch, Speretta, Chandramouli, &                By performing a manual analysis of seven syntax markers,
Micarelli, 2007). Secondly, people are not reliable sources             Gawda (2009) identified an increased use of certain features
                                                                    1727

in emotional narratives written by individuals with antisocial        ing of n-grams extracted from the text and selected accord-
personality disorder. Current computational linguistic tools          ing to different levels of restriction. The same approach was
are able to extract many grammar-based linguistic features            later applied to a larger sample of bloggers (Iacobelli, Gill,
automatically and efficiently, and it is reasonable to assume         Nowson, & Oberlander, 2011). Argamon, Dhawle, Koppel,
that such features could also carry information about person-         and Pennebaker (2005) used SVMs and four sets of lexi-
ality. Biber (1988) conducted a study on linguistic variation         cal features to differentiate high and low extraversion and
across speech and writing, and computed the frequency of              neuroticism, using a corpus of around 2400 student essays
67 linguistic features (e.g. frequency of auxiliary verbs, pro-       and personality assessments, collected by Pennebaker and
nouns, main verbs, adjectives); he was able to identify differ-       King (1999). Mairesse et al. (2007) also worked on the
ent writing genres using naturally occurring word patterns.           same corpus, employing a series of classification and regres-
Graesser, McNamara, Louwerse, and Cai (2004) proposed                 sion techniques and features from both the Linguistic Inquiry
the tool Coh-Metrix, which allows the user to analyze texts           and Word Count (LIWC) and the Medical Research Council
on discourse, cohesion, and world knowledge. The Suite of             (MRC) Psycholinguistic Database. Their results confirmed
Linguistic Analysis Tools (SALAT) calculates scores for as-           previous findings and reveal new correlations between lin-
pects such as syntactic complexity (Kyle, 2016) and cohesion          guistic markers and personality, such as use of swear words
(Crossley, Kyle, & McNamara, 2015). These tools open up a             and use of pronouns. As for the accuracy of automatic clas-
range of possibilities for the investigation of the relationships     sification, the authors reported accuracies that are, according
between personality and language use.                                 to their evaluation, significantly above chance; however, it is
   In conclusion, two approaches can be identified in extract-        not clear whether these values are high enough to be useful in
ing personality traits from language use: a lexicon-driven ap-        real applications (Mairesse et al., 2007).
proach and a grammar-driven approach. As pointed above,                  Following the work by Mairesse et al. (2007), the task of
the majority of cognitive science literature has focused on           automatic identification of personality from text gained a lot
the lexicon-based approach. The question is to what extent            of attention from the research community, mostly due to the
the findings from a grammar-driven approach are comparable            Workshop on Computational Personality Recognition (Celli,
with the lexicon-driven approach that currently dominates the         Pianesi, Stillwell, & Kosinski, 2013). As part of a shared
literature. We address this question in the current work.             task, the organizers made available two datasets of text la-
                                                                      beled with the personality traits of the authors – including the
       Extracting personality traits from text                        Essay Corpus by Pennebaker and King (1999). As a result,
                                                                      many researchers tackled the problem with different learning
Most studies on extracting personality from text focused on
                                                                      algorithms (e.g. Naive Bayes, SVM, kNN, ensemble meth-
identifying words, collocations and general linguistic features
                                                                      ods, logistical regression) and using different features such as
that occur in texts produced by one group of people versus an-
                                                                      n-grams, LIWC, MRC, lexical nuances, part-of-speech tags,
other group, aiming to uncover which features are informative
                                                                      emotional values from the AFINN database, word intensity
when trying to differentiate the groups. Early attempts relied
                                                                      scale, sentiment analysis and word associations to emotions
on word counting and predefined dictionaries that sort words
                                                                      (Celli et al., 2013).
in categories (Tausczik & Pennebaker, 2009). This approach,
albeit basic, has been used in many studies that show links              Although the results from these attempts are encouraging,
between word usage and certain psychological processes and            it had been noted that top-down approaches based on lexical
personalities, e.g. Beukeboom et al. (2012), and Mehl et al.          resources seem to perform better than bottom-up approaches
(2012). Other researchers used bottom-up approaches to as-            based only on words or n-grams (Celli et al., 2013). Nev-
sociate linguistic features with personality types. Oberlander        ertheless, there are benefits in employing approaches that do
and Gill (2006) collected large corpora of text labeled with          not rely on pre-defined vocabularies, for example allowing
the personality of the author and performed stratified corpus         exploration of topics not previously considered, easier appli-
comparisons. Interesting findings included the fact that peo-         cation in different genres and languages, and saving the effort
ple who scored high in extraversion used more inclusive ex-           of creating the word lists (Schwartz et al., 2013).
pressions and connectives, while those with low score were               Schwartz et al. (2013) used a large dataset of Facebook
more tentative and used adjectives less frequently. The au-           posts (over 15.4 million Facebook messages collected from
thors also noted that people with high neuroticism scores had         75 thousand volunteers) to perform an open-vocabulary anal-
preference for multiple punctuation.                                  ysis of correlations between personality types and vocabulary
   Another approach is to treat the problem as a supervised           use. The goal of the work was to discover unexpected re-
classification task, employing machine learning techniques to         lationships that would not necessarily be evident from using
identify the personality of the author of a given text. Oberlan-      pre-defined word categories. Although the focus of the work
der and Nowson (2006) investigated a corpus of weblog posts           was mainly to explore and gain insights on the data, the au-
from 71 participants, who completed a personality question-           thors also used the approach to predict personality from text,
naire online as part of the study. The authors used Support           with results that are comparable to previous literature. Liu,
Vector Machine (SVM) classifiers and feature sets consist-            Wang, and Jiang (2016) also attempted to predict personality
                                                                  1728

 from text while avoiding to rely on predefined vocabularies.            words found in each pre-defined category, and a few struc-
 The authors proposed a model that expands latent Dirichlet              tural features such as word count and words per sentence.
 allocation (LDA) to include the assumption that topic distri-
 bution depends not only on the characteristics of the corpus        2) The 14 MRC features refer to word length, number of
 itself, but also on the five personality traits of writers. How-        syllables or phonemes, and values for frequency of use,
 ever, the topics identified by their model seem to be affected          imageability, concreteness, meaning, age of acquisition,
 disproportionally by individuals with less common person-               among others. The MRC features were calculated by aver-
 ality combinations, and for this reason the model must be               aging the scores of the essay words found in the database
 trained with a massive, representative corpus for which the             (as opposed to averaging over total word count).
 personality of the writers is known. Since obtaining such cor-
 pora is difficult, the applicability of their approach seems to      Lexicon-based, bottom-up For topic modeling, we pre-
 be limited.                                                          processed the corpus by lemmatizing the words using
                                                                      NLTK’s WordNet lemmatizer, and removing non-English
    In this paper, we investigate how we can predict user per-
                                                                      words (i.e. words that were not found in Wordnet). Given the
 sonality from written text by using features that do not rely
                                                                      relatively small size of the corpus, we did not filter out words
 on closed-vocabularies, and compare the results to the state
                                                                      based on frequency. Then, we trained three LDA models with
 of the art. In the next section, we describe our approach.
                                                                      different number of topics (30, 65 and 100). Each document
                           Procedure                                  in the dataset was converted to a vector that represents the
                                                                      proportion in which each topic appears in the document. To
 Dataset                                                              train the model, we used the library Gensim, with 10 passes
 We use the Essay Corpus (Pennebaker & King, 1999), which             and default hyperparameters.
 consists of 2468 essays, written by introductory psychology             To illustrate the topics found in the corpus, these are the ten
 students of the University of Texas as part of their course as-      most relevant words for each of the three most frequently ap-
 signments. The students also completed the Five Factor In-           pearing topics extracted by the 30-topic LDA model: “think,
 ventory personality questionnaire (John, Donahue, & Kentle,          go, get, really, like, write, minute, time, wonder, need”; “go,
 1991), so that all essays could be marked with five personal-        get, really, time, friend, home, want, much, like, miss”; and
 ity scores for each Big-5 trait (Openness to Experience, Con-        “life, people, thing, know, think, time, one, make, feel, way”.
 scientiousness, Extraversion, Agreableness, Neuroticism). In
 addition to the scores, the corpus contains binary values for        Grammar-based, top-down For this study, we use the
 each trait (high/low), which were obtained using a median            67 features selected by Biber (1988) to reflect the linguis-
 split over the scores. The class distribution of the binary val-     tic structure of the text. These features primarily operate
 ues is shown in Table 1.                                             at the word level, such as parts-of-speech, and fall into cat-
                                                                      egories such as tense and aspect markers, adverbials, pro-
                                                                      nouns, questions, nominal forms, passives, subordination fea-
               Table 1: Class distribution in dataset.                tures, prepositional phrases, coordinations and negations, and
               OPN       CON        EXT        AGR       NEU
                                                                      so on. These features were extracted from the text using soft-
                                                                      ware developed in-house.
   Low         1196      1214       1191       1158      1235
               (48.46%)  (49.19%)   (48.26%)   (46.92%)  (50.04%)     Combinations In addition to considering these models sep-
   High        1272      1254       1277       1310      1233         arately, we investigated the model combinations in order to
               (51.54%)  (50.81%)   (51.74%)   (53.08%)  (49.96%)
                                                                      determine their complementary value.
                                                                      Classifiers
 Features                                                             We trained five Support Vector Machine (SVM) classifiers
 We employed four groups of feature sets, which were cho-             with linear kernel, one for each personality trait. SVMs were
 sen to investigate to what extent the performance of lexicon-        chosen due to previous reports of them performing better on
 based and grammar-based computational linguistic methods             this task than other algorithms (Mairesse et al., 2007), and
 are comparable.                                                      linear kernels were employed to retain interpretability of the
    For the lexicon-based features, we used two main ap-              model. For the implementation, we used the machine learn-
 proaches: top-down (LIWC and MRC) and bottom-up (topic               ing library Scikit-learn, which in turn uses an implementation
 modeling with latent Dirichlet allocation (LDA)). For the            based on Libsvm. The classifiers were trained without param-
 grammar-based features, we selected the original Biber fea-          eter tuning (i.e. penalty parameter C=1.0).
 tures (Biber, 1988).
                                                                                                   Results
 Lexicon-based, top-down
                                                                      Reservations have been expressed by the scientific commu-
1) A total of 80 LIWC features were extracted using the               nity on the application of null-hypothesis statistical testing
    LIWC2007 software, which outputs relative frequencies of          for comparison of machine learning algorithms for many rea-
                                                                  1729

                 Table 2: Average accuracy, precision and recall for each classifier, with 95% confidence interval.
                                 Baseline      Lexicon, top-down                 Lexicon, bottom-up              Grammar         Combinations
                                                          C                                                                         IW C               (30)
                                     ajor           +MR                      (30)                       (100
                                         ity                    LIW                    (E)                  )     (G)            r+L            +TM
                                                                   C                       TM                         Bibe
                                               (B)                          TM
                                                                                              (65)     TM                      Bibe
                                  (A)              LIW         (C)                                                        r                (I) B
                                      M                                    (D)                       (F)                                        iber
                                                      C                                                                       (H)
  Openness               Acc        .515       .617±.006      .602±.006   .613±.005   .613±.006      .602±.006   .576±.007    .606±.006    .602±.006
                         P          .515       .634±.006      .617±.006   .633±.006   .630±.006      .603±.005   .586±.007    .619±.006    .615±.006
                         R           1.        .611±.010      .605±.010   .593±.010   .603±.010      .669±.009   .607±.010    .614±.009    .612±.010
  Conscientiousness      Acc        .508       .547±.006      .551±.006   .556±.007   .544±.006      .534±.006   .551±.006    .546±.006    .548±.007
                         P          .508       .550±.005      .553±.006   .553±.006   .546±.005      .536±.006   .554±.006    .550±.006    .551±.006
                         R           1.        .607±.009      .611±.010   .653±.011   .610±.010      .615±.011   .599±.010    .588±.010    .598±.009
  Extraversion           Acc        .517       .562±.007      .545±.006   .546±.006   .555±.006      .551±.006   .546±.007    .553±.007    .557±.007
                         P          .517       .570±.006      .554±.005   .544±.004   .551±.004      .550±.004   .553±.006    .562±.006    .563±.006
                         R           1.        .624±.010      .624±.010   .764±.009   .756±.010      .731±.011   .635±.010    .614±.010    .644±.010
  Agreeableness          Acc        .531       .545±.007      .552±.007   .557±.005   .548±.006      .542±.006   .549±.006    .552±.006    .553±.007
                         P          .531       .561±.006      .567±.005   .554±.003   .555±.004      .546±.004   .562±.005    .570±.005    .570±.006
                         R           1.        .651±.011      .664±.010   .843±.007   .758±.012      .821±.009   .678±.010    .636±.010    .649±.010
  Neuroticism            Acc        .500       .565±.007      .571±.006   .532±.007   .527±.007      .520±.006   .545±.006    .552±.006    .545±.007
                         P           0.        .563±.007      .571±.007   .529±.006   .527±.008      .519±.006   .545±.006    .552±.006    .544±.006
                         R           0.        .577±.012      .571±.011   .581±.014   .531±.012      .540±.011   .535±.010    .551±.011    .550±.011
sons, not the least of which the fact that any difference be-                proaches generally provide the best accuracies. The top-down
tween two algorithms, no matter how small, can be shown to                   approach proposed in the literature, which uses MRC features
be statistically significant, provided that enough data are used             in addition to LIWC, does provide a small added value for
(Japkowicz & Shah, 2011). For this reason, instead of tradi-                 classifying Extraversion and Openness to experience. Con-
tional hypothesis testing, we chose to adopt error-estimation                versely, for the other three traits, MRC features do not seem
techniques to obtain relatively robust estimates of the perfor-              to provide any real improvement.
mance of the algorithms, which in turn allows us to compare                     We note that bottom-up lexicon-based approaches can of-
the results considering their practical differences.                         fer comparable accuracies to top-down approaches, with per-
   Table 2 shows the performance scores of the classifiers                   formance being basically equivalent among top-down and
trained using the eight different sets of features discussed ear-            bottom-up over all traits but Neuroticism. Furthermore, the
lier. We focus our discussion around accuracy (Acc), but we                  number of topics matters, as accuracy degrades with 100 top-
also report precision (P) and recall (R) to give a better overall            ics (when the features are likely to become more sparse).
indication of the performance of the classifiers1 . The per-                    We can observe that a grammar-based approach on its own
formance of a simple majority classifier (i.e. it always pre-                seems to give a slightly worse accuracy than lexicon-based
dicts the class with the highest number of instances) is used                approaches for three of the five traits: around 2% less accu-
as baseline. We report the estimated mean of the scores, cal-                rate for Neuroticism and Extraversion, and 4% less accurate
culated by running 10 x 10-fold cross-validation, using all                  for Openness to experience. Nevertheless, for the other two
100 individual scores to estimate the mean and variance, and                 traits (Conscientiousness and Agreeableness), the accuracies
using 10 degrees of freedom to calculate the 95% confidence                  are basically the same.
interval, as suggested by Bouckaert (2003).
                                                                                Finally, combining grammar and lexicon approaches does
   As can be seen in Table 2, the performance scores of the
                                                                             not lead to significant improvements in accuracy. In fact, it
classifiers vary for different traits, with the best accuracies
                                                                             even seems to degrade the results of the top-down lexicon-
ranging from approximately 56% for Agreeableness and Con-
                                                                             based approach slightly.
scientiousness to 62% for Openness to experience (accuracies
are highlighted in the table, and the highest accuracy scores                   In summary, Table 2 shows that lexicon-based top-down
for each trait are marked in bold). Nevertheless, we can make                features and bottom-up features do not seem to differ in a
some general observations on the overall performance of the                  practical way, and while grammar-based features seem to
different sets of features, which we list below.                             have slightly worse accuracies than lexicon-based features,
   Confirming previous findings, top-down lexicon-based ap-                  the difference can be considered too small to be of practi-
                                                                             cal significance. Furthermore, the accuracies of our proposed
   1 Precision and recall scores consider the “high” class as positive       sets of features are on par with the results obtained by previ-
label.                                                                       ous studies.
                                                                          1730

                    General Discussion                                                     Acknowledgments
The differences in performance between the different algo-            We would like to thank James W. Pennebaker for providing us
rithms are very small. Using different feature sets yields simi-      access to the original personality scores of the Essay Corpus.
lar results, and combining different features does not improve
the performance in any meaningful way.                                                           References
   One possible reason could be a floor effect, in which the          Argamon, S., Dhawle, S., Koppel, M., & Pennebaker, J. W.
questionnaire used to assess personality traits in this corpus          (2005). Lexical predictors of personality type. In Proceed-
would not be able to distinguish reliably between subjects at           ings of the 2005 Joint Annual Meeting of the Interface and
the lower end of the scale. This is unlikely, since the test used       the Classification Society of North America.
in this corpus is a standardized questionnaire that has been          Beukeboom, C. J., Tanis, M., & Vermeulen, I. E. (2012).
validated and used in numerous studies (John et al., 1991).             The language of extraversion: Extraverted people talk
   It is also possible that the use of self-assessments of per-         more abstractly, introverts are more concrete. Journal of
sonality makes this task particularly difficult due to the poten-       Language and Social Psychology, 32(2), 191–201. doi:
tial unreliability of self-reports, as discussed in the introduc-       10.1177/0261927x12460844
tion. Future investigation could incorporate personality as-          Biber, D. (1988). Variation across speech and writ-
sessments made by human observers, to evaluate to which ex-             ing. Cambridge: Cambridge University Press. doi:
tent self-assessment and observed scores differ, and whether            10.1017/CBO9780511621024
the algorithms could match the performance of human judges.           Bouckaert, R. R. (2003). Choosing between two learning
Furthermore, replicating the study with other corpora could             algorithms based on calibrated tests. In Proceedings of
also indicate whether different text types could be more suit-          the 20th International Conference on Machine Learning
able for detecting certain personality traits.                          (ICML-03) (pp. 51–58).
                                                                      Celli, F., Pianesi, F., Stillwell, D., & Kosinski, M.
   In this study, we used a relatively limited set of non-top-          (2013). Workshop on computational personality recogni-
down features, namely the features proposed by Biber (1988)             tion (shared task). In Proceedings of the Workshop on Com-
and topic modeling. Future work could investigate whether               putational Personality Recognition.
applying other grammar-based and bottom-up lexicon-based              Crossley, S. A., Kyle, K., & McNamara, D. S. (2015). The
features (e.g. cohesion, syntactic complexity, n-grams, skip            tool for the automatic analysis of text cohesion (TAACO):
grams, Word2Vec, semantic similarities) would result in bet-            Automatic assessment of local, global, and text cohe-
ter performances. In addition, we could try to improve the              sion. Behavior Research Methods, 48(4), 1227–1237. doi:
models by using non-linear kernels, performing parameter                10.3758/s13428-015-0651-7
tuning, and employing ensemble machine learning methods               Dehghani, M., Sagae, K., Sachdeva, S., & Gratch, J. (2013).
for combining different sets of features.                               Analyzing political rhetoric in conservative and liberal
   However, the difficulty of identifying personality traits            weblogs related to the construction of the “ground zero
from text could signal a more fundamental issue. Mischel and            mosque”. Journal of Information Technology & Politics,
Shoda (1995) have argued that individual differences in social          11(1), 1–14. doi: 10.1080/19331681.2013.826613
behaviors are actually variable across different situations (sit-     Gauch, S., Speretta, M., Chandramouli, A., & Micarelli, A.
uationism), and not completely stable as it is proposed by trait        (2007). User profiles for personalized information ac-
theory. As such, if personality scales and textual analyses tap         cess. In The adaptive web (pp. 54–89). Springer. doi:
into different social situations, tasks that use questionnaire          10.1007/978-3-540-72079-9 2
scores as gold standard will not be able to achieve accept-           Gawda, B. (2009). Syntax of emotional narratives of
able performance. Further research is needed to investigate             persons diagnosed with antisocial personality.           Jour-
this hypothesis, and whether other stable patterns of behav-            nal of Psycholinguistic Research, 39(4), 273–283. doi:
ior could be used as gold standard for automatic personality            10.1007/s10936-009-9140-4
inferences.                                                           Graesser, A. C., McNamara, D. S., Louwerse, M. M., & Cai,
   The current study has used the most common personality               Z. (2004). Coh-metrix: Analysis of text on cohesion
traits classification, the Big Five, and the most commonly              and language. Behavior Research Methods, Instruments,
used corpus to identify personality traits, the Essay Corpus,           & Computers, 36(2), 193–202. doi: 10.3758/bf03195564
in order to compare the difference between top-down and               Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals
bottom-up lexicon-based and grammar-based computational                 and conservatives rely on different sets of moral founda-
linguistic techniques. Our findings show that no differences            tions. Journal of Personality and Social Psychology, 96(5),
were obtained between lexicon-based and grammar-based or                1029–1046. doi: 10.1037/a0015141
between top-down and bottom-up approaches, nor comple-                Iacobelli, F., Gill, A. J., Nowson, S., & Oberlander, J. (2011).
mentary advantages for combinations of models, despite the              Large scale personality classification of bloggers. In Affec-
fact that all methods were on par with the performance previ-           tive computing and intelligent interaction (pp. 568–577).
ously reported.                                                         Springer. doi: 10.1007/978-3-642-24571-8 71
                                                                  1731

Ireland, M. E., Slatcher, R. B., Eastwick, P. W., Scissors,          atic: Context-dependent linguistic markers of extraver-
   L. E., Finkel, E. J., & Pennebaker, J. W. (2011). Lan-            sion and neuroticism. Journal of Methods and Mea-
   guage style matching predicts relationship initiation and         surement in the Social Sciences, 3(2), 30–50.          doi:
   stability. Psychological Science, 22(1), 39–44. doi:              10.2458/azu jmmss v3i2 mehi
   10.1177/0956797610392928                                        Mischel, W., & Shoda, Y. (1995). A cognitive-affective
Japkowicz, N., & Shah, M. (2011). Evaluating learning algo-          system theory of personality: reconceptualizing situa-
   rithms: a classification perspective. Cambridge University        tions, dispositions, dynamics, and invariance in personal-
   Press.                                                            ity structure. Psychological Review, 102(2), 246–268. doi:
John, O. P., Donahue, E. M., & Kentle, R. L. (1991). The             10.1037/0033-295X.102.2.246
   Big Five inventory – versions 4a and 54. Berkeley, CA:          Newman, M. L., Pennebaker, J. W., Berry, D. S., & Richards,
   University of California, Berkeley, Institute of Personality      J. M. (2003). Lying words: Predicting deception from lin-
   and Social Research.                                              guistic styles. Personality and Social Psychology Bulletin,
Kahn, J. H., Tobin, R. M., Massey, A. E., & Anderson, J. A.          29(5), 665–675. doi: 10.1177/0146167203029005010
   (2007). Measuring emotional expression with the linguistic      Oberlander, J., & Gill, A. J. (2006). Language with character:
   inquiry and word count. The American Journal of Psychol-          A stratified corpus comparison of individual differences in
   ogy, 120(2), 263-286.                                             e-mail communication. Discourse Processes, 42(3), 239–
Kyle, K. (2016). Measuring syntactic development in L2               270. doi: 10.1207/s15326950dp4203 1
   writing: Fine grained indices of syntactic complexity and       Oberlander, J., & Nowson, S. (2006). Whose thumb is it
   usage-based indices of syntactic sophistication. Doctoral         anyway?: classifying author personality from weblog text.
   dissertation, Georgia State University.                           In Proceedings of COLING/ACL (pp. 627–634). Sidney,
Liu, Y., Wang, J., & Jiang, Y. (2016). PT-LDA: A la-                 Australia.
   tent variable model to predict personality traits of social     O’Connor, B. P. (2002). A quantitative review of the compre-
   network users. Neurocomputing, 210, 155–163. doi:                 hensiveness of the five-factor model in relation to popular
   10.1016/j.neucom.2015.10.144                                      personality inventories. Assessment, 9(2), 188–203. doi:
Louwerse, M. M., Lin, K.-I., Drescher, A., & Semin, G.               10.1177/1073191102092010
   (2010). Linguistic cues predict fraudulent events in a cor-     Pennebaker, J. W., & King, L. A. (1999). Linguistic styles:
   porate social network. In S. Ohlsson & R. Catrambone              language use as an individual difference. Journal of Per-
   (Eds.), Proceedings of the 32nd Annual Conference of the          sonality and Social Psychology, 77(6), 1296–1312. doi:
   Cognitive Science Society (pp. 961–966). Austin, TX: Cog-         10.1037/0022-3514.77.6.1296
   nitive Science Society.                                         Recchia, G., & Louwerse, M. M. (2014). Reproducing affec-
Louwerse, M. M., McCarthy, P. M., McNamara, D. S., &                 tive norms with lexical co-occurrence statistics: Predict-
   Graesser, A. C. (2004). Variation in language and cohesion        ing valence, arousal, and dominance. The Quarterly Jour-
   across written and spoken registers. In K. Forbus, D. Gen-        nal of Experimental Psychology, 68(8), 1584–1598. doi:
   tner, & T. Regier (Eds.), Proceedings of the 26th Annual          10.1080/17470218.2014.941296
   Conference of the Cognitive Science Society (pp. 843–848).      Rich, E.          (1979).       User modeling via stereo-
   Austin, TX: Cognitive Science Society.                            types.      Cognitive Science, 3(4), 329–354.          doi:
Mairesse, F., Walker, M. A., Mehl, M. R., & Moore, R. K.             10.1207/s15516709cog0304 3
   (2007). Using linguistic cues for the automatic recog-          Schwartz, H. A., Eichstaedt, J. C., Kern, M. L., Dziurzynski,
   nition of personality in conversation and text. Journal           L., Ramones, S. M., Agrawal, M., . . . Ungar, L. H. (2013).
   of Artificial Intelligence Research, 30, 457–500. doi:            Personality, gender, and age in the language of social me-
   10.1613/jair.2349                                                 dia: The open-vocabulary approach. PLoS ONE, 8(9). doi:
McCrae, R. R., & John, O. P. (1992). An introduc-                    10.1371/journal.pone.0073791
   tion to the five-factor model and its applications. Jour-       Tausczik, Y. R., & Pennebaker, J. W. (2009). The psycholog-
   nal of Personality, 60(2), 175–215. doi: 10.1111/j.1467-          ical meaning of words: LIWC and computerized text anal-
   6494.1992.tb00970.x                                               ysis methods. Journal of Language and Social Psychology,
McGuire, W. J., & Padawer-Singer, A. (1976). Trait salience          29(1), 24–54. doi: 10.1177/0261927x09351676
   in the spontaneous self-concept. Journal of Personality and     Wright, W. R. (2014). Personality profiling from text and
   Social Psychology, 33(6), 743–754.                                grammar. In User Modeling, Adaptation, and Personal-
Mehl, M. R., Robbins, M. L., & Holleran, S. E. (2012).               ization (pp. 502–507). Springer. doi: 10.1007/978-3-319-
   How taking a word for a word can be problem-                      08786-3 47
                                                               1732

