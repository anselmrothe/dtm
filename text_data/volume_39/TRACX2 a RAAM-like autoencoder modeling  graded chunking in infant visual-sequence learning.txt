                             TRACX2: a RAAM-like autoencoder modeling
                          graded chunking in infant visual-sequence learning
                                          Robert M. French1 & Denis Mareschal2
                   1
                     LEAD-CNRS UMR 5022, UBFC, Dijon, FR {robert.french@u-bourgogne.fr}
                        2
                          CBCD Birkbeck University of London, UK {d.mareschal@bbk.ac.uk}
                              Abstract                               is that the former argues that it is the probabilistic
Even newborn infants are able to extract structure from a            structure of the input sequence that is represented and
stream of sensory inputs and yet, how this is achieved remains       stored, whereas the later argues that specific co-
largely a mystery. We present a connectionist autoencoder            occurring elements are stored, rather than the
model, TRACX2, that learns to extract sequence structure by
gradually constructing chunks, storing these chunks in a
                                                                     overarching statistical structure. Ample evidence in
distributed manner across its synaptic weights, and                  support of both of these views has been reported.
recognizing these chunks when they re-occur in the input               We will argue that this is a false dichotomy: both
stream. Chunks are graded rather than all-or-none in nature.         transitional probability learning (statistical learning) and
As chunks are learned their component parts become more              chunking co-exist in one system that smoothly
and more tightly bound together. TRACX2 successfully                 transitions between these apparent modes of behaviour.
models the data from four experiments from the infant visual         The appearance of two modes of learning is an illusion
statistical-learning literature, including tasks involving low-      because only a single mechanism underlies sequential
salience embedded chunk items, part-sequences, and illusory          learning; namely, Hebbian-style learning in a partially
items. The model also captures performance differences
across ages through the tuning of a single learning rate
                                                                     recurrent distributed neural network. Such a system
parameter. These results suggest that infant statistical learning    encodes exemplars (typical of chunking mechanisms)
is underpinned by the same domain general learning                   while drawing on co-occurrence statistics (typical of
mechanism that operates in auditory statistical learning and,        statistical learning models). An important corollary of
potentially, in adult artificial grammar learning.1                  this approach is that chunks are graded in nature rather
                                                                     than all-or-none. Moreover, interference effects
                          Introduction                               between chunks will follow a similarity gradient typical
We live in a world in which events evolve over time.                 of other distributed neural network memory systems.
Consequently, our senses are bombarded with                            Chunks are most frequently thought of as all-or-
information that varies sequentially over time. One of               nothing items. Who thinks of "cups" and "boards" when
the greatest challenges for cognition is to find structure           they see the word "cupboard"? Or "foot" and "ball"
within this stream of experiences. Even newborn infants              when they encounter the word "football"? Indeed,
are able to do this (Teinonen, et al. 2009; Bulf, Johnson            chunks like these have essentially the same status as
& Valenza, 2011), and yet, how this is achieved remains              "primitive" words like "boat" or "tree", which are not
largely a mystery.                                                   made of component sub-words. But new chunks do not
  Two possibilities have been suggested (see Theissen,               suddenly appear ex nihilo in language. Rather, they are
et al., 2013 for a detailed discussion). The first,                  generally formed gradually, their component words
characterised as statistical learning, involves using                becoming more and more bound together with time and
frequency and transition probabilities to construct an               usage. For example, when we encounter the words
internal representation of the regularity boundaries                 "smartphone", "carwash", or "petshop", we still clearly
among elements encountered. The second possibility                   hear the component words. We hear them less in words
suggests that elements that co-occur are recalled and                like "sunburn" and "heartbeat". We hear them hardly at
simply grouped together – or chunked – into single                   all in "automobile." How long did it take for people to
units. Over time, these chunks can themselves be                     stop hearing "auto" and "mobile" when they heard or
grouped into super-chunks or super-units. According to               read the word "automobile"? Like "automobile", it is
this view behaviour is determined by the recognition of              likely that in a few years the current generation will no
these chunks stored in memory and associated with                    longer hear "smart" and "phone" when they hear the
particular responses. What distinguishes these accounts              word "smartphone". This simple observation involving
                                                                     the graded nature of chunks is at the heart of the
                                                                     chunking mechanism in TRACX2.
1 This article is an abridged, modified version of Mareschal, D.       These ideas were implicit in our initial presentation of
& French, R. M. (2017) TRACX2: a connectionist
                                                                     the TRACX model (French et al., 2011). In TRACX we
autoencoder using graded chunks to model infant visual
statistical learning. Phil. Trans. R. Soc. B 2017 372 20160057;      showed that a connectionist autoencoder, augmented
DOI: 10.1098/rstb.2016.0057.                                         with conditional recurrence, could extract chunks from
                                                                     a stream of sequentially presented symbols. TRACX
                                                                  1
                                                                 2031

had two banks of input units, which it learned to              learning paradigms involve showing infants sequences
autoencode onto two banks of identical output units.           of looming colored shapes with varying degrees of
Sequential information was encoded by presenting               statistical regularity embedded in the sequences. It was
successive elements of the sequence, first on the right        first developed as a visual analogue of the auditory
input bank, then on the left input bank on the next time       statistical learning experiments (Kirkham, Slemner &
step. Thus, the sequence of inputs was presented in a          Johnson, 2002) and has yet to be captured by any
successive series of right-to-left inputs, with learning       modeling paradigm.
occurring at each time step. However, if the output
autoencoding error was below some pre-set threshold                          The TRACX2 Architecture
value (indicating successful recognition of the current        TRACX2 was initially introduced by French and
pair of input elements), then, on the next time step,          Cottrell (2014). The key to understanding TRACX2 is
instead of the input to the right input bank being             to understand the flow of information within the
transferred to the left input bank, the hidden unit            network. Over successive time steps, the sequence of
representation was put into the left input bank. The next      information is presented item-by-item into the right-
item in the sequence was, as always, put into the right        hand bank (RHS) of input units. The left-hand bank
input bank. Weights were updated and the input                 (LHS) of input units is filled with a blend of the right-
sequence would then proceed as before. The result of           hand input and the hidden unit activations at the
this was that TRACX learned to form chunks of                  previous time step, as shown in the following equation:
elements that it recognised as co-occurring (see French          LHSt+1 = (1- tanh(Δt))*Hiddenst + (tanh(Δt))*RHSt
et al., 2011 for full details). TRACX successfully
captured a broad range of data from the adult and infant       where Δt is the absolute value of the maximum error
auditory statistical learning literature and outperformed      across all output nodes at time t, LHSt is the activation
existing models of both chunking, notably, PARSER              across the left-hand bank of input nodes, Hiddenst are
(Perruchet & Vinter, 1998) and statistical learning            the hidden-unit activations at time t, RHSt is the
(SRNs, Cleeremans & McClelland, 1991).                         activation across the right-hand bank of input nodes,
  TRACX2 (French & Cottrell, 2014), which we use in            and  is the sigmoid-"steepness" parameter, always set
this paper to segment and chunk sequential visual items,       to 1 in the simulations presented here. If at time t, Δt is
is an updated version of TRACX. TRACX2 removes                 small, this means that the network has learned that the
the use of an all-or-nothing error threshold that              items on input are frequently together (otherwise Δt
determines whether or not the items on input are to be         could not be small). The contribution to the left-hand
chunked. This effectively removes a conditional jump           bank of input units at time t+1 of the hidden-unit
(i.e. an if-then-else) statement from the model, jump          activations, which constitute the network's internal
statements of this kind not being natural to neural            representation of the two items on input at time t, is,
network computation. In TRACX2, the contribution of            therefore, relatively large and the contribution from the
the hidden-unit activation vector to the left bank of          right-hand inputs will be relatively small. Conversely, if
input units is graded and depends on the level of              Δt is large, meaning that the items on input have not
learning already achieved. TRACX (French et al., 2011)         been seen together often, the hidden-layer's contribution
and TRACX2 (French & Cottrell, 2014) were used to              at time t+1 to the left-hand input bank will be relatively
successfully model the segmentation of syllable (i.e.,         small and that from the right-hand inputs will be
auditory) streams. In the present article, we use              relatively large. At each time step, the weights are
TRACX2 to model four experiments from the infant               updated to minimise output error (Fig. 1).
visual statistical learning literature. Visual statistical       In layman's terms, this means that as you experience
  Figure 1. Architecture and information flow in TRACX2. In all simulations reported in this paper,  = 1. When
  Δ is large (items not recognized as having been seen together before on input), almost all contribution to LHS
  comes from RHS. When Δ is small (items recognized as having been seen together before on input), almost all
  contribution to LHS comes from the Hidden layer (Hid).
                                                            2
                                                           2032

items (visual, auditory, tactile) together over and over         Finally, we show that, like 8-month-olds (Slone &
again, these items become bound to each other more              Johnson, 2015), TRACX2 forms illusory conjunctions,
and more strongly into a chunk until we no longer               normally taken as evidence of a statistical learning
perceive its component parts.                                   mechanism, but also shows decreased salience of
                                                                embedded chunk items, normally taken as evidence of
       Modeling infant statistical learning                     chunking. It, therefore, reconciles two apparently
In this section we report on a total of four different          paradoxical behaviours within a single common
simulations using TRACX2 of infant visual statistical           mechanism.
learning behaviour. We used  (the learning rate) as a
proxy for development, with  set to 0.0005 for                 Visual statistical learning
newborns, 0.0015 for 2-month-olds, 0.0025 for 5-                Kirkham et al (2002) developed a visual analogue of
month-olds, and 0.005 for 8-month-olds. This is a               the auditory statistical learning tasks initially developed
typical parameter used to model age related differences         by Saffran et al. (1996) and Aslin et al. (1998). Instead
in early learning (e.g., Thomas & Johnson, 2006).               of listening to unbroken streams of sounds, infants were
There was a bias node on the input and hidden layers            shown continuous streams of looming colorful shapes
and momentum was always set to 0. The key                       in which successive visual elements within a “visual
developmental hypothesis here is that, with increasing          word” were deterministic, but transitions between
age, infants are progressively better at taking up              words were probabilistic (see Fig. 2, leftmost panel).
information from an identical environment. This is              Infants at three different ages were first familiarized to
consistent with the well-established finding that the           this stream of shapes, then presented with either a
average rate of habituation increases with increasing           stream made up of the same shapes but with random
age during infancy (e.g., Bornstein et al., 1988;               transitions between all elements, or a stream made up of
Colombo & Mitchell, 2009; Westermann & Mareschal,               the identical visual words as during habituation.
2013). Finally, as has been used repeatedly elsewhere,          Kirkham et al. found that infants from 2 months of age
we take network output error as a proxy for looking             subsequently looked longer at the random sequence
time in the infant (Mareschal & French 2000;                    than the structured sequence (even though elements are
Mareschal, French, Quinn, 2000; Mareschal, Quinn, &             identical between streams) suggesting that the infants
French, 2002; Mareschal & Johnson, 2002; French,                had learned the statistical structure of the training
Mareschal, Mermillod & Quinn, 2004; Westermann &                sequence.
Mareschal, 2013). The idea here is that the amount of            We modelled this experiment by training the model
output error correlates with the number of cycles               with a sequence of inputs containing the identical
required to reduce the initial error, which corresponds         probability structure to that used to train infants. The
to the amount of time or attention that the model will          training sequence was identical in length to that used by
direct to a particular stimulus.                                Kirkham. The transitional probability within a visual
  We begin by modeling the seminal Kirkham et al.               word was p=1.0, and between visual words p=.33.
(2002) visual statistical learning experiment                   Shapes were coded using localist, bipolar (i.e., -1, 1)
demonstrating that age-related effects in the efficacy of       orthogonal encodings in order minimize effects due to
learning can be accounted for by a simple and plausible         input similarity. The RHS and LHS input vectors were
parameter manipulation in TRACX2. We then show                  comprised of 12 units.
that TRACX2 can capture statistical learning in                  Network performance was evaluated by averaging
newborns, as well as their dependency on the                    output error over all three of the possible two
complexity of the information stream (Bulf et al., 2011).       image ”visual words" in the sequence. This was then
                                                                                               2                          Familiar     Novel
                                                                                              1.6
                                                                                              1.2
                                                                                      Error
                                                                                              0.8
                                                                                              0.4
                                                                                               0
                                                                                                    2-month-olds   5-month-olds      8-month-olds
                                                                                                                   Age group
 Figure 2. (leftmost panel) Illustration of visual sequences used to test infants (after Addyman & Mareschal,
 2013). (middle and rightmost panels) Left-hand panel: Infant performance reported in Kirkham et al. (2002) and,
 right-hand panel: TRACX2 performance with the familiar structured and novel non-structured sequences. (Error
                                                            3
                                                           2033

 is the maximum error of the network over all output units; SEM error bars.)
compared to the average output error for a set of three                   (LDC), there were two pairs of images, each made up
randomly selected two-image “visual non-words” that                       of two different images (i.e., a total of 4 separate
were neither words nor part-words, and, consequently,                     images). In the high-demand condition (HDC) there
occurred nowhere in the training sequence. This is                        were three pairs of images, each made up of two
analogous to the word/non-word testing procedure used                     different images (i.e., a total of 6 separate images). In
in auditory statistical learning studies (e.g., Saffran et                the simulation for both the high-demand and low-
al., 1996), and completely equivalent to testing the                      demand conditions, TRACX2 saw sequences of 120
networks with a structured sequence (from which they                      words. Statistics were averaged over 30 runs of the
would have extracted visual words) and a fully random                     program, with each run consisting of 10 simulated
sequence (in which no previous words or part-words                        subjects. Figure 3 shows both the infant data and the
exist). The model, like infants of all ages, looked longer                model results. As with the infants, TRACX2 did not
at the randomised sequence than the structured                            discriminate between the structured training sequence
sequence (Fig. 2, rightmost panel).                                       and the random sequence in the high demand condition
                                                                          (with the lower learning rate) but did discriminate
Visual statistical learning in newborns                                   between the two sequences in the low demand
Bulf, Johnson, and Villenza (2011) asked whether the                      condition.
sequence-learning abilities demonstrated by Kirkham et
al (2002) were present from birth. They tested                            Learning embedded and illusory items.
newborns (within 1 week of birth) on black and white                      One consequence of chunking is that elements within a
sequences of streaming shapes. In their “High Demand                      chunk become less salient as the chunks are
Condition”, the sequence had the same statistical                         increasingly consolidated. In contrast, statistical
structure as in Kirkham et al. That is, the sequences                     learning mechanisms predict that learners should form
were made up of 3 visual words, each made up of two                       illusory items from elements that accidentally appear
shapes with a constant transition probability of 1.0                      together on occasion. Slone & Johnson (2015) explored
defining the word, and transitional probabilities of .33                  whether infants’ learning mechanisms would lead to the
between words. They also introduced a “Low Demand                         reduced salience of embedded items or to the
Condition” in which the sequences were made up of                         emergence of illusory chunks, as a means of testing
only two words ( each consisting of two shapes with                       whether chunking or statistical learning underpins
internal transition probabilities of 1.0) leading to                      infant learning. To do this, they presented 8-months-
transition probabilities at word boundaries of 0.5                        olds with sequences structured as depicted in Figure 4a.
(instead of the .33 previously used). The reasoning here                  Infants in the “Embedded Pair Experiment” did not
was that newborns had more limited information                            differentiate embedded pairs from part-pairs that
processing abilities and may therefore struggle with a                    crossed word boundaries, but both were differentiated
more complex sequence, already proving to be a                            from the word pairs. Infants in the “Illusory Item
challenge for 2 month olds.                                               Experiment” did not differentiate the illusory triplets
                                                                          from the part triplets, but both were differentiated from
                                    1.7
                                                 Random sequence          the actual triplets. This is perplexing because one result
                                          n.s.
                                    1.6          Learning sequence        suggests that infants utilize chunking, whereas the other
                                    1.5                                   results suggests that they engage in statistical learning.
                                                       *
                                    1.4                                   TRACX2 captures both of these results well, with the
                            Error                                         caveat that the model is designed to produce the
                                    1.3
                                    1.2
                                                                          smallest error on the best learned patterns. (Figs. 4b, 4c).
                                                                          If we consider output error to be a measure of attention
                                    1.1
                                                                          (the higher the error, the more attention the infant pays
                                     1
                                          HDC         LDC                 to that item), then we can say that TRACX2 is designed
                                                                          to orient to novel test patterns most (i.e., shows a
Figure 3. Newborn performance as reported in Bulf &                       novelty preference). In short, when modeling a novelty
Johnson (2011) in left panel and TRACX2 performance                       preference, the greater TRACX2's Error on output, the
in right panel for familiar structured and novel non-                     longer the looking time for infants.
structured sequence.                                                        Familiarity preferences are, in some sense, the inverse
 Again, we modelled this study using TRACX2, in the                       of novelty preferences. This means that the smaller the
same way as above, but by (1) reducing the learning                       error for an item, the more attention the infant pays to
rate to 0.0005, and (2) creating both high-demand and                     that item. Thus, to model familiarity preferences we
low-demand sequences. In the low-demand condition                         subtract the error on output from the maximum possible
                                                                      4
                                                                     2034

error and call this "Inverse Error" (Fig. 4c). So, when                              previous models of these behaviours exist. As with the
modeling a familiarity preference, the greater TRACX's                               auditory learning behaviours, TRACX2 captures
Inverse Error, the longer the infants' looking time.                                 infants' apparent use of forward and backward
  Such shifts in orienting behaviour are common in                                   transitional probabilities, the diminishing sensitivity to
infant visual orienting, and have been related to the                                embedded items in the sequence, and the emergence of
complexity of the stimuli and the depth of processing                                illusory words. However, it is important to understand
(Roder, Bushnell, & Sassville, 2000; Hunter & Ames,                                  that TRACX2 is not simply internalising the overall
1988; see Sirois & Mareschal, 2004, for a process                                    statistical structure of the sequence, but encoding,
account of the familiarity-to-novelty shift in a neural                              remembering and recognizing previously seen chunks
network model of habituation). Thus, TRACX2                                          of information. This is a fundamentally different
captures both the reduced salience of embedded chunk                                 account of infant behaviours than has previously been
items and the appearance of illusory conjunctions                                    proposed (Krogh, Vlach & Johnson, 2013).
within a single mechanism, thereby reconciling                                         TRACX2 can use frequency of occurrence or
apparently paradoxical infant behaviours.                                            transitional probabilities equally well and fluidly to
                                                                                     learn a task (as is the case with 8-month-olds;
                       Discussion                                                    Marcovitch & Lewkowicz, 2009). This would suggest
TRACX2 (French & Cottrell, 2014) is an updated                                       that categorizing learning either as statistical or
version the TRACX architecture (French et al. 2011).                                 memory-based is a false dichotomy. Both can happen in
As in the original architecture, TRACX2 is a memory-                                 a single system, with different behaviours seeming to
based chunk-extraction architecture. Because it is                                   appear depending on the constraints of the task, the
implemented as a recurrent connectionist autoencoder                                 level of learning and the level of prior experience.
in the RAAM family of architectures (Pollack, 1989), it                              Moreover, the idea that infant looking time is
is also naturally sensitive to distributions statistics in its                       determined by the recognition of regularly re-occurring
environment. In TRACX2, we replace the arbitrary all-                                items (chunks or individual items) is consistent with the
or-none chunk-learning decision mechanism with a                                     recent evidence suggesting that local redundancy in the
smooth blending parameter. TRACX2 learns chunks in                                   sequences is the prime predictor of looking away in
a graded fashion as a function of its familiarity with the                           infant visual statistical learning experiments (Addyman
material presented. An implication of this is that chunks                            & Mareschal, 2013).
are no longer to be thought of as “all-or-none" entities.                                   TRACX2 also suggests that there are no
Rather, there is a continuum of chunks whose elements                                specialised mechanisms in the brain dedicated to
are bound together more or less strongly.                                            sequence learning. Instead, sequences emerge from the
 TRACX2 was used to model a representative range of                                  application of fairly ubiquitous associative mechanisms,
infant visual statistical learning phenomena. No                                     coupled with graded top-down re-entrant processing.
Figure 4 (a)
                                          1.4                                                                                      1.2
                                          1.2
                                                                                                                                    1
                                                                                                                   Inverse Error
                                           1
                                                                                                                                   0.8
                                  Error
                                          0.8
                                          0.6                                                                                      0.6
                                          0.4
                                                                                                                                   0.4
                                          0.2
                                                                                                                                   0.2
                                           0
                                                pair   part-sequence embedded pair                                                  0
                                                        Test type                                                                        triplet   part-sequence illusory triplet
                                 (b)                                                                         (c)                                     Test type
Figure 4. (a) Familiarisation and testing items for embedded pairs (left panel) and illusory items (right panel) (after
Slone & Johnson, submitted). (b) Infant data (left-hand side of figure, familiarity preference, Experiment 1) and
TRACX2 performance (right-hand side, SEM error bars). (c) Infant data (left-hand side of figure, novelty preference,
Experiment 2) and TRACX2 performance (right-hand panel, SEM error bars). (Figure (a) permission pending).
                                                                               5
                                                                            2035

    Although there may be differences in the
speed and richness of encoding across modalities, there                 categorization by 3- to 4-month old infants: Simulations
is nothing intrinsically different in the way TRACX2                    and data. JEP:G, 133, 382-397.
processes visual or auditory information. This suggests             Hunter, M. A. & Ames, E. W. (1988) A multifactor model of
than any modality-specific empirical differences                        infant preferences for novel and familiar stimuli.
                                                                        Advances in Infancy Research,5, 69-95.
observed can be attributed to encoding differences                  Kirkham, N., Slemmer, J.A., & Johnson, S. P. (2002). Visual
rather than core sequence-processing differences.                       statistical learning in infancy: evidence of a domain
  In conclusion, we believe that chunking cannot be                     general learning mechanism. Cognition, 83, B35-B42.
viewed as an all-or-nothing phenomenon. Chunks are                  Krogh, L., Vlach, H. A & Johnson, S. P (2013) Statistical
learned and over the course of being learned their                      learning across development: flexible yet constrained.
component parts become more and more tightly bound                      Frontiers in Psychology, 3, art. 598.
together. This is a fundamental principle of TRACX2.                Mareschal, D., Quinn, P. C. & French, R. M. (2002)
The results of the present paper suggest that infant                    Asymmetric interference in 3- to 4-month-olds' sequential
statistical learning is underpinned by the same domain                  category learning. Cognitive Science, 26, 377-389.
                                                                    Mareschal, D. & Johnson, S. P. (2002) Learning to perceive
general learning mechanism that operates in auditory                    object unity: A connectionist account. Developmental
statistical learning and, potentially, also in adult                    Science, 5, 151-172.
artificial grammar learning. TRACX2, therefore, offers              Mareschal, D., French, R. M. & Quinn, P. (2000) A
a parsimonious account of how infants find structure in                 connectionist account of asymmetric category learning in
time.                                                                   infancy. Developmental Psychology, 36, 635-645.
                                                                    Mareschal, D. & French, R. M. (2000) Mechanisms of
                    Acknowledgments                                     categorisation in infancy. Infancy, 1, 59-76.
This work was funded by a grant from the Agence                     Marcovitch, S. & Lewkowicz (2009) Sequence learning in
Nationale de la Recherche Scientifique (ANR), ANR-                      infancy: the independent contributions of conditional
14-CE28-0017, to the first author and an Economic and                   probability      and      pair     frequency     information.
Social Research Council Grant RES-360-25-056 to the                     Developmental Science, 12, 1020-1025.
second author. DM is further funded by a Royal Society              Perruchet, P., & Vinter, A. (1998). PARSER: A model for
Wolfson Research Merit Award.                                           word segmentation. J. of Mem. and Lang., 39, 246-263.
                                                                    Pollack, J. (1989) Implications of Recursive Distributed
                                                                        Representations. In David S. Touretzky (ed.) Advances in
                         References                                     Neural Information Processing Systems I (pp. 527-536).
Addyman, C. & Mareschal, D. (2013) Local redundancy                     Morgan Kaufmann, Los Gatos, CA.
    governs infants’ spontaneous orienting to visual-temporal       Roder, B.J., Bushnell, E.W., & Sassville, A.M. (2000). Infants’
    sequences . Child Development, 84, 1137-1144.                       preferences for familiarity and novelty during the course
Aslin, R. N., Saffran, J. R., and Newport, E. L. (1998).                of visual processing Infancy, 1, 491-507.
    Computation of conditional probability statistics by 8-         Saffran, J. R., Aslin, R. N., and Newport, E. L. (1996)
    month-old infants. Psychological Science, 9, 321-324.               Statistical learning by 8-month-old infants. Science, 274,
Bornstein, M. H., Pecheux, M.G, Lecuyer, R. (1988) Visual               1926-1928.
    habituation in human infants: development and rearing           Sirois, S. & Mareschal, D. (2004). An interacting systems
    circumstances. Psychological Research, 50, 130-133.                 model of infant habituation. J. Cog. Neuro, 16, 1352-62.
Bulf, H., Johnson, S. P., & Valenza, E. (2011) Visual               Slone, L. K. & Johnson, S. P. (2015) Statistical and chunking
    statistical learning in the newborn infant. Cognition, 121,         processes in infants’ and adults’ visual statistical learning.
    127-132.                                                            Poster presented and the Biannual Conf. of the SRCD,
Cleeremans, A. and McClelland, J. (1991). Graded state                  April 2015, Philadelphia, USA.
    machines: The representation of temporal contingencies in       Teinonen, T., Fellman, V., Näätänen, R., Alku, P., and
    simple recurrent networks. Machine Learning, 7, 161-193.            Huotilainen, M. (2009). Statistical language learning in
Colombo, J. & Mitchell, D. W. (2009) Infant visual                      neonates revealed by eventrelated brain potentials. BMC
    habituation. Neurobiology of Learning & Memory, 92,                 Neurosci. 10:21. doi:10.1186/1471-2202-10-21
    225–234.                                                        Thiessen, E. D., Kronstein, A. T., and Hufnagle, D. G. (2013).
French, R. M., Addyman, C. & Mareschal, D. (2011)                       The extraction and integration framework: A two-process
    TRACX: A recognition-based connectionist framework                  account of statistical learning. Psychological Bulletin, 139,
    for sequence segmentation and chunk extraction.                     792. DOI: 10.1037/a0030801
    Psychological Review, 118, 614-636.                             Thomas, M. S. C. & Johnson, M. H. (2006). The
French, R. M. and Cottrell, G. (2014). TRACX 2.0: A                     computational           modelling           of       sensitive
    memory-based, biologically-plausible model of sequence              periods. Developmental Psychobiology, 48, 337-344.
    segmentation and chunk extraction. In P. Bello, M.              Westermann, G. & Mareschal, D. (2013) From perceptual to
    Guarini, M. McShane and B. Scassellati (Eds.), Proc of              language-mediated categorization. Philosophical
    the 36th Annual Meeting of the Cognitive Science Society.           Transactions of the Royal Society B, 369: 201220391
    Austin, TX: Cognitive Science Society, 2016-2221.
French, R. M., Mareschal, D., Mermillod, M. & Quinn, P.
    (2004) The role of bottom-up processing in perceptual
                                                                 6
                                                                2036

