A computational decomposition of task-irrelevant perceptual learning
Angelo Pirrone (apirrone1@sheffield.ac.uk)
Department of Psychology & Department of Computer Science, University of Sheffield, UK

Tom Stafford (t.stafford@sheffield.ac.uk)
Department of Psychology, University of Sheffield, UK
Abstract

ily measured, RT and accuracy: (1) the difficulty of the
decision, (2) the decision criteria adopted by the participant, which can be more or less conservative, (3) the nondecision time, which includes time to encode the stimulus and to execute the motor response, (4) the bias towards a response, (5) across trials variation in the above
mentioned mechanisms. If the participant is performing
a task on many different days, since the experimenter is
interested in the effect of learning over different sessions,
it is reasonable to expect that all the above mechanisms
could also vary across different days on the basis of factors not related to the experiment (e.g., on one day the
participant could be more tired or less collaborative). In
some cases, an approach focusing only on RTs or accuracy has even been misleading in generating theories
from data (for a discussion and examples, see Ratcliff &
McKoon, 2008).

Change in motion discrimination was assessed after seven
days training on a rapid serial visual presentation training task, which included exposure to below-threshold coherent motion that was irrelevant to the task the participant was involved in. Post-training, participants had improved sensitivity for supra-threshold motion discrimination, which was specific to the direction exposed during
training. A computational decomposition of the effect
shows that the improvement is a combination of (i) an increase in rate at which participants accumulate evidence
for the direction to which they were exposed and (ii) a
decrease in their criterion for a response. Together with
these differences (consistent across participants) other
cognitive processes vary non-systematically between the
pre-test and the post-test session making an analysis only
based on accuracy or reaction times potentially misleading. Our analysis shows the benefits of isolating the different processes that are involved in perceptual decision
making and are affected by perceptual learning.
Keywords: task-irrelevant perceptual learning; drift diffusion model; speed-accuracy trade-off

Here, we use the Drift Diffusion Model (DDM; Ratcliff & McKoon, 2008) as a tool to isolate different components of the processes that contribute to a decision.
The DDM (Ratcliff & McKoon, 2008) is a computational
model of decision making that, over the years, has been
applied in a wide variety of tasks (for a review see Ratcliff & McKoon, 2008). In the DDM the decision maker
accumulates evidence supporting two alternatives until a
threshold for a decision is reached. In its arguably most
used formulation (Ratcliff & McKoon, 2008), the DDM
is composed of seven parameters. The first, denoted by
a, is the boundary separation and it describes the distance
between the two decision boundaries. This parameter is
related to the speed-accuracy trade-off. When the boundaries are near, the decision is faster but less accurate;
conversely, when the distance between the two boundaries increases, the decision is slower but more accurate.
The rate at which noisy information is accumulated over
time within a trial is defined by the drift rate, v. This
parameter reflects the difficulty of the task with respect
to the sensitivity of the observer, with easier conditions
(and/or more sensitive observers) resulting in faster and
more accurate decisions. When the decision maker starts
to integrate difference in evidence at an equal distance
from the two decision boundaries, the process is defined
as unbiased. However, the decision maker can start to integrate evidence nearer one of the two boundaries so that
a third parameter affect the decision, the starting point

Introduction
During task-irrelevant perceptual learning (TIPL), participants learn to better discriminate stimuli to which
they are merely exposed but that are irrelevant to the
purpose of the experiment (Watanabe et al., 2001; Seitz
& Watanabe, 2008). The first example of TIPL comes
from Watanabe et al. (2001), in which authors, after
testing participants on a motion discrimination task, exposed participants to many days of a rapid serial visual
presentation (RSVP) task, on the background of which
was presented a random-field motion stimulus with a below threshold coherence in a constant direction across all
days of training. Watanabe et al. (2001) found that participants showed an improvement in a post-test motion
discrimination task, only for the supra-threshold coherence level in the direction to which they were exposed.
Results from TIPL research suggest that the brain, even
in the presence of subliminal exposure, adapts to specific
features of the environment. As discussed in Watanabe
et al. (2001), this result has important implications for
modern everyday life in which we are constantly subject to high amounts of information that we try to ignore. TIPL research suggests that such ignored information could still affect our behaviour.
Focusing only on RT or accuracy for a perceptual task
has some limitations, since different components contribute to those aspects of the decision which can be eas-

955

of evidence accumulation, z. When the decision maker
is biased towards one of the two boundaries, fast RTs
for that boundary but slow RTs for the opposite boundary are predicted, and at the same time the decision is
more likely to end at the nearer boundary. The decision
time is the time required to cross one of the two boundaries; however, for each reaction time it is present also a
component that incorporates the non-decision time component of a decision, ter, which is the time to encode the
stimulus and execute the motor response (e.g., pressing
a button on the keyboard). Three further parameters of
the DDM are: inter-trial variability in drift rate defined
as eta, in the starting point, sz, and in the non-decision
time, st.
Despite widespread success in other domains, the
DDM has not been consistently applied in the domain
of perceptual learning. In Petrov et al. (2011), the authors performed a DDM decomposition of a fine motion
discrimination task. In their study, authors found that
perceptual learning was best explained by an increase in
drift rate, a decrease in boundary separation and a decrease in both the non-decision time component and its
inter-trial variability. In Liu & Watanabe (2012), participants performed a three day perceptual learning coherent motion direction task (i.e., is the random dot kinematogram all noise or is there some signal?) and authors
found an improvement in drift rate but with boundary
separation decreasing across the days of training. In Dutilh et al. (2009), participants performed a 5 days lexical
decision task and authors found that the learning led to
an increase in drift rate, a decrease in boundary separation, as well as a significant decrease in non-decision
time. As it is clear from these investigations, RTs and accuracy alone cannot give a full description of the cognitive processes that are most likely to have generated the
data. Considering both measures and their distribution
can lead to a better understanding of the cognitive processes involved in such tasks. In particular, if perceptual
learning is associated with a decrease in the boundary
separation, as other studies of task-relevant perceptual
learning have found, then assessing perceptual learning
via measurement of accuracy will systematically underestimate the true size of perceptual learning (since decreased boundary separation will tend to decrease accuracy, all other things being equal).
Although task-relevant perceptual learning has been
decomposed by using the DDM, to our knowledge, no
studies have focused on a DDM decomposition of TIPL.
In our study, we ran an experiment similar to that presented in Watanabe et al. (2001), and we performed a
DDM decomposition of TIPL. Because of the aforementioned multi-component nature of perceptual decisionmaking, our expectation is that use of the DDM will
allow a more accurate assessment of perceptual learn-

ing than attention to solely RT or accuracy. Further,
the DDM allows us to isolate the component of decision
making that reflects a true change to stimulus sensitivity
- a change in the drift rate parameter. Because of the potential for non-stimulus related parameters to alter across
sessions due to non-experimentally caused factors (such
as fatigue or motivation) and because, by their nature,
perceptual learning experiments involve testing participants on different days or even weeks, we isolate perceptual learning as an increase in the drift rate for the
exposed stimulus (for one participant also the drift of
the not exposed direction increased but the increase was
greater for the exposed stimulus than for the not exposed
stimulus). In this way, we use each participant as their
own control, testing them for changes in perceptual decision making for both exposed and not exposed stimuli
and thus accommodating non-training related changes in
decision parameters.

Material and methods
Participants Four right-handed healthy university students (2 females, ages: 30, 21, 20, 22 years), with no
history of neurological or psychiatric disorders, with normal vision and naı̈ve to the purpose of the study participated voluntarily in the experiment and received a compensation of £50 for their participation. The experiment
was approved by the University of Sheffield, Department
of Psychology Ethics Sub-Committee, and carried out in
accordance with the University and British Psychological Society ethics guidelines. Participants gave their informed consent.
Apparatus The stimuli were generated on a personal
computer using PsychoPy (Peirce, 2009). During the
whole experiment, participants had to put their head on
a chin rest at a viewing distance of 57 cm from a SONY
Multiscan CPD-200ES 17” monitor with a resolution of
1280 x 1024 pixels at a refresh rate of 60 Hz. The experiment was conducted under binocular viewing conditions
and participants used a keyboard to make a response.
Motion-Direction Stimuli We used stimuli similar to
those adopted by other studies on task-irrelevant perceptual learning (Watanabe et al., 2001; Seitz & Watanabe,
2008): on a grey background, within a black annulus
aperture of 1◦ - 10◦ , white dots with a size of 2x2 pixels
were moving with a speed of 6◦ /s and a density of 16.7
dots/deg2 /s on a black background. Signal dots were
randomly chosen in each frame, and on each frame, noise
dots had a random position. Dots had a limited lifetime
of three frames after which they were redrawn in random
locations. If any of the signal dots were to move out of
the annulus, they were replaced randomly in the stimulus field. The stimuli were generated in real time and two
non-cardinal directions were employed in this study, 45◦

956

and 135◦ .

tion stimulus in one of the two directions, constant across
all training sessions, at a coherence level 5% below their
chance level at pre-test, in order to ensure a level reasonably below threshold. For each participant, we computed
the motion strength at 50% accuracy by interpolating the
psychometric curve predicted by the model free estimation of the psychometric curve described in Zchaluk &
Foster (2009), and using MATLAB scripts made available by those authors. In each trial, a fixation cross in
the central circle was presented for 333 ms followed by
the presentation of the stimulus for 500 ms followed by
a grey screen and the text ‘Type in the two white letters’ presented on top of the screen until participants responded. Each test stage consisted of 10 blocks x 108
repetitions for a total of 1080 trials and took about 45
minutes to complete. No accuracy feedback was given to
the participants. After a block of 108 consecutive trials,
participants were required to take a self-paced break to
rest before continuing with this task.

Procedure The experiment consisted of nine sessions;
a pre-test to measure sensitivity for various strengths of
motion coherence in the two directions, then seven training sessions consisting of a RSVP task with on the background a random dot motion, and finally a post-test that
measured sensitivity for various coherence levels in the
two directions, that was equal to the pre-test. Participants
came on different days for each session, and could take a
maximum of three-days break between sessions.
Pre/post Motion-Direction Sensitivity Tests Participants were instructed to pay attention to the stimulus that
would be presented for 500 ms and then report as quickly
and accurately as possible if the coherent motion was towards up-left (45◦ on the left with respect to an imaginary vertical reference line) or up-right (45◦ on the right
with respect to a imaginary vertical reference line) by
button press. They were instructed to use their right hand
index finger to press left on the keyboard for ‘up-left’,
and their middle finger to choose ‘up-right’. Participants
were instructed that there was always a correct response
and were required to fixate the cross at the centre of the
screen during the whole task and minimise as much as
possible eye movements. In each trial, a fixation cross in
the central circle was presented for 333 ms, followed by
the presentation of moving dots for 500 ms, followed by
two arrows showing the possible direction of the dots and
the text ‘Answer:’ presented on top of the screen until
participants made a response. Each test stage consisted
of 10 blocks x 2 directions (45◦ and 135◦ ) x 10 motion
coherence levels (5%, 10%, 20%, 30%, 40%, 50%, 60%,
70%, 80%, 90%) x 9 repetitions for a total of 1800 trials and took about 1 hour to complete. Coherence levels
were chosen so that for each direction we would have accuracy levels that range from chance to ceiling based on
the results of previous pilot studies. During each block
the order of presentation of trials was randomised and no
accuracy feedback was given to the participants. After a
block of 180 consecutive trials participants were required
to take a self-paced break to rest before continuing with
this task.

Results
Behavioural analyses
The performance of participants in the RSVP was mostly
stable across the seven days of training. We did not perform any analysis on the RSVP task as our interest is in
the TIPL, hence in the change in performance between
pre-test and post-test for the exposed and not exposed directions.
For all analyses, both behavioural analyses and model
fitting, we removed, for each participant, the 2.5% of
slowest responses, given that a first inspection of data
showed the presence of extremely slow outliers. In the
following analyses, each subject is analysed separately.
Participants 1 and 2 were exposed to 45◦ while participants 3 and 4 were exposed to 135◦ . T-tests were conducted to investigate overall differences for each participant between the pre-test and the post-test in mean RT
and accuracy levels for the exposed and the not exposed
directions. Bonferroni corrections were applied on the
p-values.
All subjects had a significant decrease in RTs between
the pre-test and post-test, for the exposed and the not exposed direction (p < .001 in all cases). Participant 1 did
not have a change in accuracy for the exposed direction
between the pre-test and post-test (t(9) = -0.34, p = 1)
while all other participants had a significant increase (p
<.001 in all cases). Regarding accuracy of the not exposed direction, there was not a significant change between pre-test and post-test for any subject (p >.07 in all
cases).

Training sessions In the training sessions, participants
performed a RSVP character identification task and were
asked to report in order of presentation two white capital letters (height about .9◦ ) in a sequence of 10 capital
letters presented in the central circle. All letters of the alphabet were used. Distractors consisted of eight capital
black letters. The first and second white letters were presented in one of the first five serial positions and in one of
the second five serial positions, respectively. They were
determined randomly in each trial. Within the annulus
aperture of 1◦ - 10◦ participants were presented a mo-

Model fitting
For fitting the diffusion model to RT distributions and
proportion of correct and incorrect responses, we used

957

the Diffusion Model Analysis Toolbox (DMAT; Vandekerckhove & Tuerlinckx, 2007) for MATLAB. Parameters
were estimated by using as the objective function a multinomial likelihood function, which expresses the likelihood of observing a certain proportion of responses in a
given number of RT bins and is maximised in order to
find the parameter estimates. We decided to represent
the reaction time distributions of responses in terms of
the classical .1,.3,.5,.7 and .9 quantiles that divide the RT
distribution. For each participant we fitted a model in
which the drift rates were free to vary across all conditions while all other parameters were fixed across conditions within the pre-test and the post-test but could vary
between pre-test and post-test. In this way, for each session, a model with 26 parameters was fitted for each individual. However, the high number of parameters, rather
than over-fitting, reflects the high number of conditions
of this experiment. In fact, the only stimulus-contingent
parameter allowed to vary is the drift, which varies according to the difficulty of each coherence level and according to the direction (exposed vs not exposed). Since
participants were presented with trials in random order
they could not adjust their boundary separation or their
starting point of evidence accumulation before the presentation of each trial, hence the assumption of constant
boundary and starting point parameters within each session is reasonable, together with stimulus-independent
variability in starting point across trials. We assumed as
constant the non-decision time component (i.e., stimulus encoding and motor response) between the two directions since it is unlikely that subject would have higher
non-decision time (e.g., pressing a button on the keyboard) for one direction compared to the other. DMAT
allows to calculate estimates of the parameters’ standard
errors. For each participant, we performed Wald tests for
the difference in parameters between pre-test and posttest using the parameter estimates and their standard errors. Also here, results are presented by participant,
Figure 1. Here we focus on within-subjects variation,
hence for visibility we do not report consistent scaling
and range across the same parameters fitted to different
subjects.

exposed direction did not vary significantly between the
pre-test and the post-test (t(9) = -1.15, p= .56). Participant 3 had a significant decrease in boundary separation
(Z = -9.18, p<.001), an increase in non-decision time (Z
= 1.98, p = .02) and a decrease in starting point (Z = 5.46, p<.001). Between the pre-test and the post-test,
the drift of the exposed direction increased significantly
(t(9) = -4.83, p= .002) while the drift of the not exposed
direction stayed the same (t(9) = -1.61, p= .28). Participant 4 had a significant decrease in boundary (Z =
-5.81, p<.001), an increase in non decision time (Z =
2.33, p=.01) and a decrease in starting point. (Z = -1.37,
p=.08). The drift of the exposed direction increased significantly (t(9) = -6.25, p= <.001) as well as the drift
of the not exposed direction (t(9) = -3.85, p= .01). Although the drift rates for both directions increased between pre-test and post-test, the relative change between
pre-test and post-test for the exposed direction was significantly higher than the relative change between pretest and post-test for the not exposed direction (t(9) =
3.72, p= .01). None of the participants had a significant
change between the two sessions in the parameters capturing across trials variability in drift, starting point or
non-decision time. The goodness of fit of the model was
assessed graphically through quantile-probability plots
(not shown for brevity). The quantile probability plots
showed that the model on which our analyses are based
fits the data well and without mismatches.

Discussion
Here, using the DDM (Ratcliff & McKoon, 2008), we
have modelled for the first time the processes underlying
TIPL in healthy individuals. The results indicate that:
(i) TIPL affects the drift rate at which participants accumulate evidence for the exposed direction meaning that
their sensitivity for the exposed direction is increased,
(ii) TIPL affects the conservativeness of participants’ response (iii) non-systematic variations (i.e., the direction
of the change varied between subjects) in parameters between the two sessions (e.g., variations in non-decision
time, variations in starting point) do not allow a direct
comparison of the decision process only based on accuracy and/or RT.
These findings have important implications for the
interpretation of perceptual learning data, both taskrelevant and task irrelevant, and, we hope, for the analysis of data collected on different days or for which learning is involved. First, every decision is a mixture of different cognitive processes that can be isolated by this
analysis for a more principled interpretation of results.
Interpreting learning in terms of latent cognitive variables allows for a more precise investigation of its effect
and gives a proper measure of ‘true’ perceptual learning
- change in the drift rate which is related to the qual-

Participant 1 had a significant decrease in boundary
separation (Z = -7.38, p<.001), in non decision time
(Z = -11.46, p<.001) and in starting point (Z = -10.36,
p<.001). Regarding drift rates, t-tests showed an increase in drift for the exposed direction (t(9) = -2.75,
p= .045), while the drift of the not exposed direction did
not vary between pre-test and post-test (t(9) = -.42, p=
1). Participant 2 had a significant decrease in boundary
separation (Z = -13.14, p<.001), non-decision time (Z =
-6.64, p<.001) and starting point (Z = -7.15, p<.001).
This subject had an increase in drift for the exposed direction (t(9) = -3.36, p= .02), while the drift of the not

958

Figure 1: DDM parameters for each participant: top-left (Participant 1), top-right (Participant 2), bottom-left (Participant 3), bottom-right (Participant 4). For each participant, in order from top left to bottom right: boundary separation
(a), non decision time (ter), starting point (z) and drift rates (v). The x-axis for the drift rate reports, for both the
exposed and the not exposed directions, the 10 coherence levels by decreasing difficulty. Bars are standard errors of
parameters’ estimates.
ity of input information - while weighting for systematic
or random variations in other parameters. In particular,
caution should be exercised when comparing data across
different sessions. As in previous studies of perceptual
learning, participants in our study showed evidence of a
change in their speed-accuracy trade-off. Not taking this
factor into account can lead to wrong conclusions from
data. In theory, decreased boundary should result in decreasing accuracy for the not exposed direction. In our
investigation, participants had to view the stimuli for 500
ms before giving their response; given this constraint,
participants had a relatively long time window to make a
decision and as a consequence this might have obscured
a decrease in accuracy between the pre-test and the posttest that should result from a decreased boundary. For
future investigation, we recommend using a shorter presentation of the stimuli (e.g., 200 ms) that is more likely
to reveal stronger variations in accuracy and RTs of the
not exposed direction between the pre-test and the posttest.
Our results show the risk of directly comparing sessions performed on different days without considering
the role of each single parameter. Take for example participant 1: by testing for differences in accuracy, a researcher may be tempted to conclude that this subject
did not have any TIPL since there is not a difference be-

tween the accuracy of the first and second session both
for the exposed and the not exposed direction. However,
the model fitting shows that this participant had higher
drift rates for the exposed direction, which is likely to
be the signature of TIPL, which is accompanied by a decrease in boundary and variations in the bias towards a
response. An increase in drift (faster and more accurate responses) accompanied by a decrease in boundary
(faster and less accurate responses) can have as output
that accuracy levels stay the same.
Previous studies have shown that perceptual learning is associated with a decrease in boundary separation
(Petrov et al., 2011; Liu & Watanabe, 2012; Dutilh et al.,
2009) and we replicated this result also here for TIPL
showing consistency across four participants. It has been
proposed (Liu & Watanabe, 2012) that this decrease in
boundary separation is due to the fact that participants
are trying to maximise their reward rate, operatlionalised
as the proportion of correct responses divided by the average time between them. In other words, if the quality of information increases (i.e., hence the task becomes
‘easier’) participants can decrease the time spent on each
decision in order to finish the task sooner without sacrificing accuracy too much given the increase in drift rate.
To the best of our knowledge, this is the first study to report a DDM decomposition of TIPL and the first study

959

to show the systematic parameter variations associated
with TIPL. Regarding other parameters there is not consistency in the literature regarding the effects of learning,
and also here we do not observe a clear pattern across
participants. For example, regarding the non-decision
time component, in previous studies investigating perceptual learning, Petrov et al. (2011) and Dutilh et al.
(2009) found a decrease associated with learning, while
Liu & Watanabe (2012) found that, although not significant overall, some participants showed an improvement. Here we did not find a consistently decreasing
non-decision time component between the two sessions,
given that only two out of four participants have a decrease in non-decision time. Our only consistent result is
that of decreasing boundary related to learning and an effect on the drift; result that shares some similarities with
that by Liu & Watanabe (2012). Regarding the drift, we
show that there is an increase in the drift of the exposed
direction, compared to the pre-test, and compared to the
drift of the not exposed direction of the post-test when
the drift of the not exposed direction increases as well
in the post-test. Ideally, we would expect that the drift
of the not exposed direction would not vary between pre
and post-test. For one participant however the drift of
the not exposed direction varies as well; this is unlikely
to be an effect of TIPL but rather a random variation in
participants’ performance that further highlights the importance of a DDM decomposition of learning data.
Although the sample size (N = 4) is low, this is in line
with similar studies that have performed a DDM decomposition of learning data (e.g., Dutilh et al., 2009), and it
is common practice in perceptual learning research. Furthermore the consistency in results across participants reassures us about our conclusions. It is to be mentioned
that the training that our participants performed is relatively ‘short’ if compared with the usual TIPL training
of about 20 days, during which TIPL reaches its asymptotic level (Watanabe et al., 2001). Future work, employing more participants and longer training regimes is
clearly warranted in order to quantify the rate at which
each component is affected by learning, and to quantify
the distortion that focusing only on accuracy could lead
to; if the days of training increase, the effect on boundary and drift reported here might increase and have even
stronger consequences on accuracy and RT.
Here we used the DDM as a model of decision making and in order to analyse our data, but it is to be mentioned that other models of decision making could have
been applied (Bogacz et al., 2006). However, given the
model mimicry between models of decision making (Bogacz et al., 2006), we predict that our results are likely to
be replicated if another model is applied.
Overall, a consideration of the different components in
decision making shows that the two components which

are found to vary systematically all have independent effects on speed and/or accuracy. Whilst increased drift
will tend to increase speed and accuracy, decreased
boundary separation will tend to decrease both. For these
reasons, a decomposition of decision making from these
observed variables allows us not only to focus on the different effects of perceptual learning individually, but allows us a more accurate assessment of the extent of increased stimulus sensitivity in perceptual learning. Our
study is the first to show this increased sensitivity in taskirrelevant perceptual learning, and does so demonstrating that the other components of decision making are affected in a similar way to as in task-relevant perceptual
learning.

Acknowledgments
A.P. was supported by the University Studentship Network in
Neuroeconomics. This work appeared in an extended version
in A.P. PhD dissertation.

References
Bogacz, R., Brown, E., Moehlis, J., Holmes, P., & Cohen, J. D. (2006). The physics of optimal decision
making: a formal analysis of models of performance
in two-alternative forced-choice tasks. Psychological
review, 113(4), 700.
Dutilh, G., Vandekerckhove, J., Tuerlinckx, F., & Wagenmakers, E.-J. (2009). A diffusion model decomposition of the practice effect. Psychonomic Bulletin
& Review, 16(6), 1026–1036.
Liu, C., & Watanabe, T. (2012). Accounting for speed–
accuracy tradeoff in perceptual learning. Vision research, 61, 107–114.
Peirce, J. W. (2009). Generating stimuli for neuroscience
using psychopy. Frontiers in Neuroinformatics, 2, 10.
Petrov, A. A., Van Horn, N. M., & Ratcliff, R. (2011).
Dissociable perceptual-learning mechanisms revealed
by diffusion-model analysis. Psychonomic bulletin &
review, 18(3), 490–497.
Ratcliff, R., & McKoon, G. (2008). The diffusion decision model: theory and data for two-choice decision
tasks. Neural computation, 20(4), 873–922.
Seitz, A. R., & Watanabe, T. (2008). Is task-irrelevant
learning really task-irrelevant?
PloS one, 3(11),
e3792.
Vandekerckhove, J., & Tuerlinckx, F. (2007). Fitting the
ratcliff diffusion model to experimental data. Psychonomic bulletin & review, 14(6), 1011–1026.
Watanabe, T., Náñez, J. E., & Sasaki, Y. (2001). Perceptual learning without perception. Nature, 413(6858),
844–848.
Zchaluk, K., & Foster, D. H. (2009). Model-free estimation of the psychometric function. Attention, Perception, & Psychophysics, 71(6), 1414–1425.

960

