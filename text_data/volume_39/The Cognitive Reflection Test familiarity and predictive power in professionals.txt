     The Cognitive Reflection Test: familiarity and predictive power in professionals
                                            Matthew Brian Welsh1,2 & Steve H. Begg1
                                        ({matthew.welsh}{steve.begg} @adelaide.edu.au)
                                      1. Australian School of Petroleum, 2. School of Psychology
                                     University of Adelaide, North Tce, Adelaide, S.A., Australia
                              Abstract                                   Key questions remain, however. First, whether CRT
                                                                      familiarity extends beyond psychology students to people in
   The CRT is an increasingly well-known and used test of bias
   susceptibility. While alternatives are being developed, the        industries interested in bias reduction strategies. For
   original remains in widespread use and this has led to its         example, the oil and gas industry has a 4 decade long
   becoming increasingly familiar to psychology students              history of following the judgement and decision making
   (Stieger & Reips, 2016), resulting in inflated scores.             literature – beginning with Capen’s (1976) work on
   Extending this work, we measure the effect of prior exposure       overconfidence. With the success of popular science books
   to the CRT in a sample of oil industry professionals. These        like Kahneman’s (2011) Thinking Fast and Slow, which are
   engineers and geoscientists completed the CRT, seven bias
   tasks and rated their familiarity with all of these. Key results
                                                                      often taken up by managers, it seems likely that industry
   were that: familiarity increased CRT scores but tended not to      knowledge of the CRT will also expand. This could render
   reduce bias susceptibility; and industry personnel, even           it decreasingly useful as a means of distinguishing between
   without prior CRT exposure, scored very highly on the CRT -        individuals because people who have undertaken decision
   greatly reducing its predictive power. Conclusions are that the    making training may be increasingly likely to have
   standard CRT is not a useful tool for assessing bias               encountered the CRT or similar questions before.
   susceptibility in highly numerate professionals – and doubly          The second question relates to the degree of familiarity
   so when they have previously been exposed.
                                                                      required to undermine the CRT’s validity. For example, the
   Keywords: cognitive reflection test; familiarity; predictive       above bat-and-ball problem is memorable. Its format,
   power; bias; industry professionals.                               however, is nearly as memorable. That is, assume someone
                                                                      has seen the bat-and-ball question; when, then, asked:
                          Introduction                                   A jug and a cup together cost $2.20. The jug costs $2
The Cognitive Reflection Test (CRT), due to its impressive            more than the cup. How much does the cup cost?
predictive power for biases (Frederick, 2005; Toplak, West,
                                                                         It seems unlikely that anyone would fail to make the
& Stanovich, 2011), is widely used in bias research. Perhaps
                                                                      connection between the two. That is, despite not having
its most recognisable item is the following:
                                                                      seen the specific question before, recollection of the
   A bat and a ball together cost $1.10. The bat costs $1             question format could be sufficient to prime them for
more than the ball. How much does the ball cost?                      reflection on their answer. This would result in them scoring
   This question and its two companions have strongly                 higher on the CRT – not due to superior cognitive reflection
intuitive but incorrect answers – 10c in the bat-and-ball             but simple familiarity. Given the low score ‘ceiling’ of the
question’s case – such that answering the questions                   3-item CRT, this could reduce the CRT’s ability to predict
correctly implies greater reflection on one’s answer. Thus,           susceptibility to biases by truncating its range of scores.
the CRT yields a score from 0-3 with higher values
reflecting greater ‘cognitive reflection’, which has been             Hypotheses
linked to lessened bias susceptibility.                               1. Decision making training courses will increase familiarity
   Despite the CRT’s success, concerns have been raised               with bias questions and CRT.
about it. Firstly, it conflates numerical ability with                2. Familiarity will inflate CRT scores.
measurement of decision style (see, e.g., Primi et al., 2015;         3. This will reduce the CRT’s predictive power.
Weller et al., 2013; Welsh, Burns, & Delfabbro, 2013); and,           4. Familiarity will increase bias resistance.
secondly, consists of only three, quite memorable items.
   While these problems have been previously noted and                                           Method
attempts made to improve the CRT by inclusion of
additional items and attempts to reduce the mathematical              Participants
emphasis (Primi et al., 2015; Thomson & Oppenheimer,                  Participants were 116 personnel employed at Australian oil
2016; Toplak, West, & Stanovich, 2014), the original CRT,             companies. Of these, 93 completed all of the (below) tasks
due to its speed and ease-of-use, remains in widespread use.          in the allotted time. These included 70 males and 23
   This is problematic in that, once a person has been                females, with a mean age of 41.3 years (SD = 10.8) and an
exposed to the CRT, its usefulness may be compromised.                average of 16.4 years of industry experience (SD = 10.0).
Recent work by Stieger and Reips (2016), for example, has
shown that familiarity with CRT questions inflated CRT                Procedure
scores amongst psychology students.                                   Participants were recruited during several visits to oil
                                                                    3497

companies and tested in groups of 25-30. They were given         extent. That is, both options had an expected value of a 1/3
the pencil and paper battery of questions described below        reduction in the slick. Half of participants had these
and allowed 45 minutes to complete it.                           explained to them in terms of how much the oil would
                                                                 spread (negative frame) while the rest were told how much
Materials                                                        oil would be contained (positive frame) by each option.
The questionnaire asked demographic questions, Frederick’s          In line with Prospect Theory (Kahneman & Tversky,
CRT (spread throughout the questionnaire) and 10 bias            1979), the expectation is that having the problem framed
measurement tasks commonly seen in managerial decision           positively will tend to produce risk aversion – causing
making books/courses (see, e.g., Bazerman, 2002). Three of       participants to select the certain option – while a negative
these (base rate neglect, optimism and unpacking) were           frame tends to result in selecting the riskier option. A
included for separate analyses and are not discussed here.       participant’s response was, thus, scored as to whether they
The remaining biases were: anchoring, overconfidence,            conformed to the Prospect Theory prediction (0) or not (1).
framing, conjunctive/disjunctive events bias, sample size        Conjunctive/Disjunctive Events Bias
invariance, the Wason selection task and illusory                   This question asked participants to select which of three
correlations. Each, except for overconfidence, was tested        possible responses to a probability question was correct.
using a single item and all were scored in line with the CRT;    Specifically, which event was more likely of: a single 50%
that is, higher scores indicated less bias susceptibility. The   prospect finding oil; all of seven 90% prospects finding oil
specific tasks are described below.                              (~48%); or at least one of seven 10% prospects finding oil
Demographics.                                                    (~52%). As noted by Bar-Hillel (1973), people tend to
  Participants provided their age, gender, technical specialty   overestimate the likelihood of conjunctive events and
and years of industry experience. They also indicated            underestimate the likelihood of disjunctive events. Given
whether they had undertaken training courses in decision         this, participants were scored 1 if they correctly identified
making and when, where and with whom this was done.              the third option and 0 otherwise.
Anchoring.                                                       Sample Size Invariance.
  Participants were asked whether world proved oil reserves         This task asked whether a statistically unlikely result was
in 2009 were greater or less than an anchoring value prior to    more likely to occur in a larger or smaller sample – or be
being asked to make an estimate. The assumption here is          similarly likely. Specifically, participants were asked
that oil industry personnel, while unlikely to have a figure     whether, on a given day, it was more likely that 60% of oil
for this already in mind, would be capable of constructing a     wells would produce above their average rate in a larger (45
reasonable estimate from their industry knowledge but that,      well) or smaller (15 well) field. As noted by Tversky and
in line with the anchoring and adjustment heuristic (Tversky     Kahneman (1974), people can pay too little attention to the
& Kahneman, 1974), people’s estimates would tend towards         size of the sample and fail to realise that deviant results are
the anchor they had seen. Participants saw one of two            more likely in a smaller sample. Given this, selecting the
anchors –150% or 50% of the known true value, although           smaller option was scored correct (1) while any other
participants were unaware of this – and were assessed as         response was scored incorrect (0).
showing the bias if their estimate was closer to the anchor      Selection Task.
they saw (scored 0) than the unseen alternative (scored 1).         Based on Wason’s (1968) selection task, participants were
Overconfidence.                                                  asked which of four oil prospects needed to be retested with
  This task included 10 questions asking the participant to      an alternative tool in order to test a consultant’s claim that
generate an 80% confidence interval around an unknown            Tool 2 would always produce a positive result when Tool 1
quantity related to the oil industry – a task commonly           did. A correct response (scored 1) was to retest prospects
undertaken the oil industry but at which people are known        where the Tool 1 had given a positive result and those
to perform poorly (see, e.g., Lichtenstein, Fischhoff, &         where Tool 2 had given a negative result. Any other
Phillips, 1982; Welsh & Begg, 2016).                             combination of choices was deemed incorrect (scored 0).
   Performance was calculated as the proportion of               Illusory Correlations.
generated ranges that contained the true value. This was ten        The illusory correlations task (Chapman & Chapman,
converted to a 0 to 1 scale for easier comparison with the       1967), asked participants to examine a 2x2 contingency
other bias scores with 0 indicating the worst performance        table and determine whether the data supported a
and 1 the best as follows: Score = 1-|Hits/10 - .8|*1.25         relationship between two events: AVO anomalies (from
Framing.                                                         seismic data) and hydrocarbon presence. In fact, the data
  This question, adopted from Pieters (2004), asked              offered no support for this despite a preponderance of
participants to select between options for dealing with a        observations in the AVO present/HC present cell.
hypothetical oil spill – one certain to reduce it by a set       Participants were scored as correct (1) only if they correctly
amount (1/3) and one giving a 1/3 chance of containing it        identified there was no relationship in the data and that all
entirely but a 2/3 chance of it spreading to its maximum         four cells needed to be examined to establish this fact.
                                                               3498

Claiming that the data supported a relationship or that only        Table 2’s familiarity data also shows interesting results.
some cells needed to be examined resulted in a score of 0.       Specifically, while no familiarity scores are particularly
                                                                 high – recalling that a score of 1 would indicate definitely
Cognitive Reflection Test.                                       recalling an entire task – participants’ highest familiarity
  The three questions from Frederick’s (2005) CRT were           rating is observed for the CRT. The average (0.25) score
spread amongst the other tasks. A person’s score on this         here lies between what would be observed from participants
task is simply the number of questions answered correctly.       having recalled seeing one of the CRT’s actual questions
Familiarity.                                                     before (0.33) and having seen one similar one (0.17).
  At the end of the survey, participants were asked to look
back and, for each question, indicate whether they had:                 Table 2: Performance on bias and CRT measures.
                                                                                                 Score           Familiarity
  1) Never seen it prior to testing (score 0).                   Measure                    Mean         SD  Mean         SD
  2) Seen a similar question previously (score 0.5).             Anchoring                  0.27        0.45  0.23       0.27
  3) Seen that exact question previously (score 1).              Framing                    0.27        0.45  0.12       0.23
  Tasks involving more than one question (CRT and                Con/Disjunctive            0.32        0.47  0.14       0.24
overconfidence) had the familiarity scores for all composite     Sample Size                0.22        0.41  0.09       0.22
questions averaged to produce a single, familiarity score.       Selection Task             0.12        0.32  0.17       0.27
                                                                 Illusory Correlation       0.17        0.38  0.16       0.30
                           Results                               Overconfidence             0.49        0.31  0.20       0.25
                                                                 CRT                      2.42 / 3      0.88  0.25       0.27
Demographic Data                                                 Note: N = 93. The unshaded parts reflect tasks where the
                                                                 Mean value equals the proportion of correct responses.
In addition to the data described in the Method section,
several demographic questions were asked of participants.
                                                                 Training and Familiarity with Bias and CRT
Key observations from this are presented in Table 1.
                                                                 To test Hypothesis 1 – that industry courses in decision
          Table 1: Summary of demographic measures.              making would increase familiarity with bias and CRT
Measure                                                          questions - familiarity ratings of participants with and
Technical Area        32 Engineers, 52 Geoscientists, 8 Other    without such training were compared. Looking at Table 3,
Training*             38 trained, 55 untrained                   Hypothesis 1 is clearly supported by the data. In all cases,
Yrs since training Mean = 4.8 years, SD = 4.6                    participants who had undertaken training courses reported
* Training courses in decision making, heuristics and biases.    significantly higher familiarity with the bias and CRT
                                                                 questions. An interesting observation, however, is that the
Descriptive Statistics                                           CRT is an outlier amongst untrained personnel – its mean
                                                                 familiarity more than double that of any other question. This
Table 2 summarises participant performance on the various        may go some way to explaining the distribution of CRT
measures and their stated familiarity with the questions.        scores across the trained and untrained groups, shown in
Looking, first, at the scores in Table 2 a number of things      Figure 1, where three-quarters of the trained group score
are immediately clear. The first is that a majority of           3/3, but so do half of the untrained group.
participants display bias on each of the bias measures. On
the six which reflect a simple proportion correct, the highest         Table 3: Familiarity with bias and CRT measures by
mean is 0.32 for the Conjuntive/Disjunctive events bias –                                 training group.
which reflects chance performance on a three-option choice.
                                                                                      Trained Untrained        t(91)       p
On the other, single-item tasks, performance ranges from
                                                                 Anchoring               .45           .07     8.93     <.001
12% up to 27% correct - indicating a significant majority
                                                                 Overconfidence          .37           .08     6.69     <.001
displaying the expected biases. Overconfidence requires
                                                                 Framing                 .21           .05     3.46     <.001
more explanation as it indicates the proportion of generated
                                                                 Con/Disjuntive          .24           .07     3.47     <.001
ranges containing the true value compared to the expected
                                                                 Sample Size             .18           .03     3.59     <.001
number. Thus, the 0.49 average in Table 1 reflects a person
                                                                 Selection               .33           .05     5.56     <.001
achieving around half of their expected calibration – that is
                                                                 Illusory Corr.          .17           .05     5.12     <.001
~40% of their “80%” ranges containing the true value,
                                                                 CRT                     .35           .18     3.21      .002
which is a typically strong level of overconfidence.
                                                                 Note: p-values are two-tailed. Independent samples t-tests.
  Finally, the CRT scores are very high. Frederick’s (2005)
paper listed 11 samples with average CRT scores ranging
                                                                 CRT Familiarity and Score
from 0.57 to 2.18 (and an overall mean of 1.24). A 95% CI
around the industry sample’s mean CRT extends from 2.24          Hypothesis 2 held that familiarity with CRT questions
to 2.60 - excluding not just the overall average from            would inflate CRT scores. The correlation between CRT
Frederick’s results but that of the highest group as well.       scores and familiarity with CRT questions supported the
                                                                 hypothesis, showing a weak, significant effect, r(91) = 0.29,
                                                               3499

p = .004 (see Table 5). That is, participants who had seen              Table 5: Correlations between CRT, CRT familiarity and
CRT (or similar) questions before scored higher.                                            bias measures.
                                                                                1. CRT   2. CRT-Fam   3. Anchor   4. Overconf.   5. Framing   6. Con/Dis.   7. Sam. Size   8. Selection   9. Ill. Corr.
                                                                   1            -        .004         .351        .089           .355         .721          .645           .048           .305
                                                                   2            .29      -            .089        .028           .625         .016          .767           .267           .298
   Figure 1: Distribution of CRT scores by training group.
                                                                   3            .10      .18          -           .840           .708         .050          .040           .494           .022
  To better understand the magnitude of the effect, the CRT
scores of participants unfamiliar with all of the CRT              4            .18      .23          .02         -              .686         .045          .181           .704           .444
questions (i.e., CRT Familiarity = 0) were compared to
those who recalled at least one similar question. Looking at
Table 4, one sees that the familiar group scored more than         5            -.10     -.05         -.04        .04            -            .307          .361           .160           .426
half a mark higher on the CRT, which an independent
samples t-test confirmed as a significant difference.              6            .04      .25          .20         .21            -.11         -             .810           .760           .097
       Table 4: Mean CRT scores by familiarity group
                                                                                .05      -.03         .21         -.14           .10          -.03                         .625           .089
         CRT Familiarity                                           7                                                                                        -
   0 (n=41)           >0 (n=52)      t(91)     p(2-tailed)
2.12 (SD=1.08)     2.65 (SD=0.59)     3.0         .003             8            .21      .12          -.07        .04            -.15         .03           .05            -              .008
Predictive Power of CRT                                                         .11      .11                                     -.08
                                                                   9                                  .24         .08                         .17           .18            .27            -
Hypothesis 3 held that the inflation of CRT scores as a
result of familiarity would reduce the its predictive power –     Note: N=93. Values in the lower triangle are correlation
measured herein by correlations calculated between all bias       coefficients. Upper triangle data are two-tailed p-values.
measures, CRT and CRT familiarity, and shown in Table 5.          Bold results are significant. Italic results are significant as
   Looking at Table 5, one sees that the CRT has relatively       directional hypotheses. NB – for binary bias measures, the
little predictive power for the seven biases. It very weakly      correlations are equivalent to t-tests and used in preference
predicts better performance on the Selection task and on          for consistency and ease of display.
Overconfidence questions. This analysis, however, includes
participants familiar and unfamiliar with the CRT. To assess            Table 6: Correlations between CRT and biases in
the impact of familiarity on CRT’s predictive power,                    participants familiarity and unfamiliar with CRT.
correlations were calculated separately for participants                                       Correlation with CRT
familiar and unfamiliar with the CRT as seen in Table 6.                            Unfamiliar (n=41)        Familiar (n=52)
   Here, one sees that, the CRT does not significantly predict    Bias Task           r    p (2-tailed)      r    p (2-tailed)
bias for familiar or unfamiliar participants. The pattern of      Anchoring         .11       .512        .04       .787
results, however, is for the correlation to be higher in the      Overconf.         .04       .828        .26       .066
group familiar with the CRT (5 of 7 biases). While the            Framing           -.07      .647        -.11      .421
smaller samples resulting from dividing the group renders         Con/Dis. Bias -.12          .469        .09       .549
these non-significant, the correlations are higher than the       Sample Size       .05       .756        .07       .647
significant ones in the full dataset, suggesting prior CRT        Selection         .13       .416        .21       .144
familiarity may predict better performance on these biases.       Ill. Corr.        .02       .914        .21       .144
   Thus, while the overall result does not, technically,
support Hypothesis 3, it identifies the lack of predictive        Familiarity and Bias Resistance
power for the CRT in the industry sample that is unfamiliar       As noted above, the results suggest support for Hypothesis 4
with the CRT and suggests that what predictive power is           – that familiarity with bias questions would improve
observed in the group familiar with the CRT may result            performance. Data in Table 5 also show CRT Familiarity
from either prior CRT experience somehow priming people           has stronger relationships with bias performance than a
to be more aware of biases – or, more likely, that                participant’s CRT score. Given the likely co-occurrence of
participants with prior exposure to the CRT may also have         bias and CRT questions in decision training courses, the
experience with bias questions and thus perform better.           effect of familiarity on bias was thus also examined.
                                                                 3500

   To test this, χ2 tests were conducted for the six, binary-     CRT questions were, at 2.12, similar to the highest of the 11
scored biases. Given low numbers of participants recalling        groups tested by Frederick (2005) and much higher than his
seeing exact bias questions before, familiarity with a bias       average of 1.24.
was also treated as binary by combining groups who had               Part of this, we argue, must stem from the nature of our
seen the exact or a similar question together. Table 7 shows      sample. Rather than undergraduate students, we tested oil
the proportion of correct responses for each of these groups      industry professionals – primarily engineers and scientists.
for each bias and the results of the corresponding χ2 tests.      As such, our sample is likely to have much higher than
                                                                  typical numeracy scores and, consequently, higher CRT
Table 7: Proportion correct by bias question and familiarity.     scores (for discussions of the links between CRT and
                             Familiarity                          numeracy, see, e.g., Weller et al., 2013; Welsh et al., 2013).
Bias Task                 0              >0       χ2(1)      p       While this has made certain of our planned comparisons
Anchoring           0.23 (n=53) 0.33 (n=40) 1.13 .288             more difficult – effectively rendering our ‘control’ group of
Framing             0.28 (n=72) 0.24 (n=21) 0.13 .718             people unfamiliar with the CRT too similar to those who
Con/Dis             0.29 (n=68) 0.40 (n=25) 0.94 .333             had prior experience, the implications of this for the use of
Sample Size         0.22 (n=78) 0.20 (n=15) 0.02 .877             the CRT in expert samples are more troubling. It suggests
Selection           0.08 (n=65) 0.27 (n=22) 3.54 .060             that, even prior to their first exposure to the CRT, the
Illusory Corr.      0.16 (n=69) 0.21 (n=24) 0.30 .584             skewed scores seen in a sample of technical experts will
Overconfidence                  r(93) = 0.25               .016   limit the test’s ability to differentiate between individuals
   Note: p values are two-tailed. Overconfidence and its          and predict performance. Combined with the observation
corresponding familiarity are both non-binary, therefore a        that the CRT’s highest predictive power was observed
correlation is used rather than χ2.                               amongst people with prior experience on exactly those
                                                                  biases where prior experience aided the most – this argues
   Looking at Table 7, one sees that, participants familiar       against the CRT’s usefulness.
with bias questions do better in 5 of the 7 tasks but                While these concerns may be lessened when dealing with
significantly only on the Overconfidence and Selection            experts from less numerically-focussed fields, expert
tasks (given a directional hypothesis). That is, Hypothesis 4     decision making and forecasting tends towards exactly these
is supported for Overconfidence (r(93) = 0.25, p = .016) and      groups, meaning that the CRT may have limited utility.
the Selection Task (χ2(1) = 3.54, p = .060) – the two biases
showing the strongest relationships with CRT amongst              Bias vs CRT Familiarity
participants familiar with the CRT in Table 6.                    Analyses of familiarity with both biases and the CRT used
                                                                  to examine Hypothesis 4 found limited evidence of prior
                          Discussion                              experience with biases improving performance. Only for the
The results offer support for two hypotheses: that taking part    Overconfidence and the Selection Task did prior exposure
in decision making training courses increases the likelihood      lead to better performance – perhaps due to greater
of having seen the CRT or bias questions previously; and          memorability or that understanding these biases suggests a
that having seen CRT-style questions previously results in a      solution. For example, overconfidence implies too narrow
significant increase in CRT score – of more than half a mark      ranges, which immediately suggests widening ranges. Such
on the 0-3 scale. The fact that results (largely) failed to       awareness generally reduces but does not remove
support the other hypotheses has, along with observations         Overconfidence (Welsh, Begg, & Bratvold, 2006). Amongst
on the limited predictive power of the CRT herein,                the other biases, little evidence was seen of prior bias
implications for the use of the CRT, as expanded on below.        question experience enabling one to avoid those biases –
                                                                  even in an educated, highly numerate sample.
Predictive Power of the CRT                                          This is doubly important in light of familiarity’s effect on
                                                                  CRT. If CRT is inflated by prior exposure more than bias
As noted above, our third hypothesis was that the CRT’s           performance, then knowing who has been exposed to the
predictive power would be eroded by participant’s                 CRT-style questions becomes essential when interpretting
familiarity with CRT questions. The reasoning being that,         results. Adding to this is the fact that the CRT was more
given a limited set of memorable questions, prior exposure        familiar than the biases to people who had not completed
would push results towards ceiling, weakening the                 training, suggesting that these questions occur through other
relationship between CRT and the biases. Our results,             channels or that CRT questions are particularly memorable.
however, showed CRT having little predictive power to start          This seems likely to remain true even when ‘similar’ tasks
with. This lack of initial, predictive power in our sample        are used. The structures of CRT questions, once recognized
may have made it impossible to convincingly demonstrate           as ‘trick’ questions, may trigger greater scrutiny of intuitive
the impact of familiarity on CRT’s predictive power.              answers. Certainly, while few participants indicated having
   The reason for this lack of predictive power, however,         seen the exact CRT questions before, reporting having seen
seems to be the same as that prompting our Hypothesis 3 –         similar ones (for now, ignoring questions about the accuracy
that CRT scores are too close to ceiling. As noted above,         of their recall) also resulted in higher CRT scores.
even the CRT scores of participants with no familiarity with
                                                                3501

Future Research                                                 Frederick, S. (2005). Cognitive reflection and decision
Given the problems observed with CRT, an obvious next             making. Journal of Economic Perspectives, 19(4), 25-42.
step is to attempt a replication using one of the newer         Kahneman, D. (2011). Thinking, Fast and Slow. New York,
variants developed to have less reliance on numeracy and a        NY: Farrar, Straus, Giroux.
larger number of items (e.g., Primi et al., 2015; Thomson &     Kahneman, D., & Tversky, A. (1979). Prospect Theory: an
Oppenheimer, 2016; Toplak et al., 2014). Whether such a           analysis of decision under risk. Econometrica, 47(2), 263-
substitution will work depends on whether familiarity is          291.
highly specific for particular question types or simply         Lichtenstein, S., Fischhoff, B., & Phillips, L. D. (1982).
primes generic “I know this is a trick question” responses.       Calibration of probabilities: the state of the art to 1980. In
   Another necessary step is to look at biases discussed here     D. Kahneman, P. Slovic & A. Tversky (Eds.), Judgment
in greater detail. While a (mostly) single item per bias          under Uncertainty: Heuristics and biases. Cambridge:
approach is useful for an exploratory approach - allowing         Cambridge University Press.
multiple biases to be examined without overloading the          Pieters, D. A. (2004). The influence of framing on oil and
goodwill of participants - binary scoring is, of course, a        has decision making. Marietta, Georgia: Lionheart
crude measure of susceptibility to any bias. Research using       Publishing Inc.
a set of bias questions for each bias (and focusing on fewer    Primi, C., Morsanyi, K., Chiesi, F., Donati, M. A., &
biases so as to keep the total number of questions down)          Hamilton, J. (2015). The development and testing of a
would allow finer-grained measurement of susceptibility           new version of the cognitive reflection test applying item
and shed further light on the findings discussed herein (and      response theory (IRT). Journal of Behavioral Decision
allow more detailed discussion of the biases, their modes of      Making.
action and some of the controversies in the literature          Stieger, S., & Reips, U.-D. (2016). A limitation of the
regarding their nature - or even existence).                      Cognitive Reflection Test: familiarity. PeerJ, 4, e2395.
   Finally, the very high CRT scores we observed in our oil     Thomson, K. S., & Oppenheimer, D. M. (2016).
industry sample suggest that additional work should be            Investigating an alternate form of the cognitive reflection
conducted to determine how CRT scores vary in other fields        test. Judgment and Decision Making, 11(1), 99.
amongst both naïve and CRT-familiar personnel.                  Toplak, M. E., West, R. F., & Stanovich, K. E. (2011). The
                                                                  Cognitive Reflection Test as a predictor of performance
Conclusions                                                       on heuristics-and-biases tasks. Memory & Cognition,
                                                                  39(7), 1275-1289.
Our results have important implications for the use of the      Toplak, M. E., West, R. F., & Stanovich, K. E. (2014).
CRT as a bias susceptibility measure for decision making          Assessing miserly information processing: An expansion
research in professional settings. Our technical experts,         of the Cognitive Reflection Test. Thinking & Reasoning,
while susceptible to biases, have inflated CRT scores -           20(2), 147-168.
resulting from greater numerical ability as well as any prior   Tversky, A., & Kahneman, D. (1974). Judgment under
exposure to CRT-style questions. These effects result in the      uncertainty: Heuristics and biases. Science, 185, 1124-
original CRT retaining little to no predictive power.             1131.
   Given this, future work is required to see whether           Wason, P. C. (1968). Reasoning about a rule. The Quarterly
alternate versions of the CRT, developed to include more          journal of experimental psychology, 20(3), 273-281.
items and be less numerically-based, avoid such problems        Weller, J. A., Dieckmann, N. F., Tusler, M., Mertz, C. K.,
and can provide useful results in professional populations.       Burns, W. J., & Peters, E. (2013). Development and
                                                                  Testing of an Abbreviated Numeracy Scale: A Rasch
                    Acknowledgments                               Analysis Approach. Journal of Behavioral Decision
The authors thank Santos and Woodside for their support of        Making, 26, 198-212. doi: doi: 10.1002/bdm.1751
the CIBP group within the Australian School of Petroleum.       Welsh, M. B., & Begg, S. H. (2016). What have we learnt?
                                                                  Insights from a decade of bias research. APPEA Journal,
                        References                                56, 435-450.
Bar-Hillel, M. (1973). On the subjective probability of         Welsh, M. B., Begg, S. H., & Bratvold, R. B. (2006). SPE
   compound events. Organizational Behavior and Human             102188: Correcting common errors in probabilistic
   Performance, 9(3), 396-406.                                    evaluations: efficacy of debiasing. Paper presented at the
Bazerman, M. H. (2002). Judgment in managerial decision           Society of Petroleum Engineers 82nd Annual Technical
   making (5th ed.). New York: John Wiley and Sons.               Conference and Exhibition., Dallas, Texas, USA.
Capen, E. C. (1976). The difficulty of assessing uncertainty.   Welsh, M. B., Burns, N. R., & Delfabbro, P. H. (2013). The
   Journal of Petroleum Technology(August), 843-850.              Cognitive Reflection Test: how much more than
Chapman, L. J., & Chapman, J. P. (1967). Genesis of               Numerical Ability? In M. Knauff, M. Pauen, N. Sebanz &
   popular but erroneous psychodiagnostic observations.           I. Wachsmuth (Eds.), Proceedings of the 35th Meeting of
   Journal of abnormal psychology, 72(3), 193.                    the Cognitive Science Society (pp. 1587-1592). Austin,
                                                                  TX: Cognitive Science Society.
                                                              3502

