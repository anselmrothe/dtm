                           Towards a Computational Analogical Theory of Mind
                                          Irina Rabkina (irabkina@u.northwestern.edu)
                                          Clifton McFate (c-mcfate@northwestern.edu)
                                         Kenneth D. Forbus (forbus@northwestern.edu)
                                         Qualitative Reasoning Group, Northwestern University
                                             2133 Sheridan Road, Evanston, IL, 60208, USA
                                         Christian Hoyos (choyos@u.northwestern.edu)
                                           Department of Psychology, Northwestern University
                                             2029 Sheridan Road, Evanston, IL, 60208, USA
                               Abstract                                 improvements provided by training. We close with related
   Several theories about Theory of Mind (ToM) have been
                                                                        work and future directions.
   proposed. The most well-known of these are Theory Theory
   and Simulation Theory, although alternative and hybrid                                        Background
   theories do exist. One such theory, proposed by Bach (2011,          We base our model on the Structure-Mapping approach to
   2014), is based on the Structure-Mapping theory of analogy,
                                                                        Theory of Mind proposed by Bach (2011, 2014). Because
   which has been shown to play a key role in cognitive
   development. There is evidence that children are more likely to      understanding Structure-Mapping Theory (SMT; Gentner,
   pass false belief tasks when trained using stories that are easy     1983) is essential to understanding this theory and our model,
   to compare via structural alignment, as opposed to stories that      we describe it first. This is followed by a description of
   are difficult to compare in this way (Hoyos, Horton & Gentner,       Bach’s theory. Finally, we describe the computational
   2015). This paper shows how a computational model based on           models of SMT processes that we are using.
   Bach’s account can provide an explanation for the Hoyos et al.
   training study and proposes directions for future research on
   human subjects.
                                                                        Structure-Mapping Theory
                                                                        Structure-Mapping (Gentner, 1983) is a theory of analogy
   Keywords: analogy; theory of mind; false belief; structure-
   mapping; cognitive modeling
                                                                        and similarity. Under SMT, relational/structural similarity is
                                                                        emphasized over similarity based on features alone. Humans’
                          Introduction                                  ability to see these structural similarities across dissimilar
                                                                        cases is a key aspect of higher order cognition, which
The mechanisms behind Theory of Mind (ToM) have been                    suggests that structural similarity is used in everyday
hotly debated for decades. According to one popular theory,             reasoning. SMT proposes that comparison involves the
Theory Theory, children are little scientists who develop               alignment of elements between two cases, called a base and
theories about others’ beliefs (e.g. Gopnik & Wellman,                  a target.
1992). Another theory, Simulation Theory, suggests that                    Consider a common pedagogical analogy: “A cell is like a
children play out scenarios as if they were the agents involved         city. The city government controls the city. The nucleus
(e.g. Goldman, 1992). Other accounts include hybrid theories            controls all the cell’s activities. A power station provides
(e.g. Bach, 2011), which attempt to combine aspects of                  electricity. A mitochondrion is like the power station.”
Theory Theory and Simulation Theory (see Related Work).                 (Chang & Forbus, 2015). In this example, the cell acts as a
  Another important question is how ToM is learned and                  target and the city acts as a base. Structural representations of
when. Interestingly, several studies have shown that at least           the two are aligned to form a mapping. SMT predicts that the
some aspects of ToM can be improved via brief intervention              cell maps to the city, the nucleus maps to the government,
(e.g. Hoyos et al., 2015; Hale & Tager-Flusberg, 2003;                  control of the cell maps to control of the city, and the
Lohman & Tomasello, 2003). This paper considers one such                mitochondrion maps to the power station (Fig. 1). What about
study and models how analogical generalization may lead to              providing electricity? Because of the match between the
improved performance on the false belief tasks tested. The              mitochondrion and the power station, we can infer that the
model generates testable predictions for future work.                   mitochondrion does something like providing electricity.
  We begin by discussing the theories that underlie our                 This conclusion is called a candidate inference.
model, the Structure-Mapping Theory of analogy (SMT;                       SMT can be extended to include analogical generalization
Gentner, 1983) and Bach’s (2011) structure-mapping account              (Kuehne et al., 2000). As a person is exposed to alignable
of ToM, along with our computational models of analogical               cases, generalizations are formed. For example, we can form
matching and generalization used in the model. We then                  a generalization between the city and the cell. This would
summarize a ToM training study (Hoyos et al., 2015) and                 state that “Something like a city or cell has something like a
describe how our model explains the performance                         city government or nucleus that controls it and something like
                                                                    2949

                                                                    nested expressions have high scores. The score of a mapping
                                                                    is the sum of the scores of its constituents. Thus, mappings
                                                                    between cases that have high structural similarity receive
                                                                    higher scores. Mappings also include candidate inferences
                                                                    that project missing information from one case to the other.
                                                                       In this model, we deliberately do not model retrieval from
                                                                    long-term memory, to avoid the cost of providing enough
                                                                    distractors to make this challenging, and instead assume that
                                                                    retrieval finds reasonable autobiographical memories.
                                                                    However, we have proposed (Kandaswamy et al., 2014) that
                                                                    analogical generalization also occurs in working memory,
    Fig. 1: A visual representation of SMT. Entities are            what we call interim generalizations. The SAGE-WM
    shown as rectangles. Relationships are in diamonds.             model1 keeps a list of generalizations and recent examples.
    Dotted lines show correspondences between the two               Given a new example it uses SME to compute a score
    cases. Dashed lines show the candidate inference.               between the probe and each generalization in turn, ordered by
                                                                    recency. If the score is over a pre-determined threshold, the
a power station or a mitochondrion that gives it energy.”           probe is assimilated into the generalization. If no
Eventually, generalizations become abstract schemas that can        generalization is above threshold, the new example is
represent, for example, a single type of event. They can be         compared to each outlier in turn using SME, again ordered by
stored in long term or working memory.                              recency. If any mapping is above threshold, a new
                                                                    generalization is formed. Otherwise the probe becomes a new
SMT Theory of Mind                                                  ungeneralized example.
Bach (2011, 2014) has proposed that ToM is developed via
structure-mapping. He proposes that two forms of base                               Learning Theory of Mind
domains are used. The first are abstract schemas built up over
time. The second are events from autobiographical memory.           Several studies have shown that Theory of Mind can be
This provides a hybrid model: Mappings to the schema                acquired in part using experimental interventions (e.g.
domain correspond to theories as described in Theory Theory         Lohman & Tomasello, 2003; Hale & Tager-Flusberg, 2003;
models, and mappings to the autobiographical domain                 see Hofmann et al., 2016 for meta-analysis). However, most
correspond to simulation. For example, to decide whether a          of these studies involve extended training. On the other hand,
person who arrived 15 minutes late to a flight that was             there is evidence that ToM can be acquired much more
delayed by 10 or a person who arrived 15 minutes late to a          quickly when training examples are highly structurally
flight that left on time would be more upset, a person might        alignable. In particular, a study by Hoyos et al. (2015)
retrieve an abstract schema that says “people are very upset        showed that structurally alignable unexpected contents-style
when they narrowly miss their goal” or they might simulate          stories can improve children’s performance on false belief
how they would feel if they were the person in question by          tasks, given just three training examples. In this paper, we
mapping to an autobiographical memory. Bach argues that             examine and model the results of this experiment.
simulation tends to happen when the general heuristic has not
yet been formed, and involves complex combinations of
                                                                    Modeling Task
cases (see Bach, 2011 for specifics).                               In the Hoyos et al. (2015) study, children were first given a
   Because we do not attempt to model a complete Theory of          false belief pre-test containing one unexpected contents task
Mind in this paper, we assume a simplified version of Bach’s        (UC), one verbal false belief task (VFB), and one unexpected
theory. Our model focuses on the learning aspect, so we             location task (UL). In the UC task, a container (e.g. a cookie
assume that heuristic-like abstractions have not yet been           box) is shown to have unexpected contents (e.g. grass) and
formed. Thus, only concrete autobiographical memories are           participants are asked to predict what someone who has never
retrieved from long term memory. Generalizations are                seen inside would think the container contains. In VFB
formed in working memory, which we propose as a                     participants are told another child holds a false belief (that
mechanism by which schemas are learned.                             they think an item is somewhere it is not) and asked to predict
                                                                    where the child will look for the item. Finally, in UL,
SME and SAGE-WM                                                     participants are told a story where one child places an object
The Structure Mapping Engine (SME; Forbus et al., 2016)             in a location and leaves the room. Another child then moves
implements the analogical mapping process of SMT. SME               the object, and the participants are asked to predict where the
compares a base and target case, both represented in predicate      first child will look for the object when they return.
calculus, and computes one or more mappings that align                 Those who passed all three tests were excluded from the
statements and entities. Each mapped expression receives an         study. The remaining children were split into two groups:
initial score, which is propagated to its children. Thus, highly    high alignment and low alignment. Both groups were
1
  Sequential Analogical Generalization Engine, Working Memory
                                                                2950

presented with three stories in the style of an UC task, in a         Our Model
repetition-break pattern: the main character in the first two         A simplified English version of each training and testing
stories held a true belief (e.g. she thought that there was cereal    example from Hoyos et al. (2015) was semi-automatically
in a cereal box, and there really was cereal inside), while the       encoded using a natural language understanding system (EA
character in the last held a false belief (e.g. she thought there     NLU; Tomai & Forbus, 2009). Although syntax was
were crayons in the crayon box, but there were really rocks).         simplified, overall structure and word choices were
The difference was that the stories heard by children in the          consistent with the original stories. Figure 2 shows a partial
high alignment condition were very similar, in terms of both          representation of a true belief story. Events are represented in
structure and linguistic content. The stories heard by children       the neo-Davidsonian style: a reified event with role relations
in the low alignment condition, on the other hand, differed on        connecting it to other constituents. The conjunction of
both counts. Following training, all children were tested on          statements about an event participates in causal relations. In
the same three tasks (UC, VFB, UL) as before.                         English, Figure 2 states that because it is not the case that
   Hoyos et al. found that children in both conditions made           there is a seeing event in the box by Kim, Kim thinks that
significant gains from pre- to post-test. Importantly, they           there is a containment event wherein the box contains cereal.
found that the children in the high alignment condition made             During training, the appropriate examples were passed into
significantly higher gains than those in the low alignment            SAGE-WM in the order that the children in the corresponding
condition. Hoyos et al. concluded that structural alignment           condition saw them (true belief, true belief, false belief). The
aids false belief understanding. Furthermore, they, like Bach         threshold for whether or not a probe was generalized was set
(2011, 2014) postulated that analogical comparison is                 to 0.01. If the incoming example matched to an example
“instrumental in children’s understanding of mental states            already in working memory with a score greater than 0.01,
and their relation to the factual world.” In this paper, we           the model asked whether the match was correct. This
propose a mechanism for how structural alignment during               corresponds to feedback in the Hoyos et al. (2015)
learning can aid in false belief understanding and forming a          experiment. When told it was correct, the model assimilated
complete Analogical Theory of Mind.                                   the examples into a generalization. Its behavior when told it
                                                                      was incorrect, on the other hand, depended on its calculation
Learning Analogical Theory of Mind                                    of surprise. Surprise occurs when the model encounters an
The mean performance increase by children in the high                 incorrect match whose score is the same order of magnitude
alignment group was 0.75 out of 3 possible, with significant          as the previous correct match. We propose that this comes out
gains made in all three of the false belief tests. Yet few            of the repetition break structure of the story order (Hoyos et
children learned more than one. On the other hand, children           al., 2015; Loewenstein & Heath, 2009): the high similarity to
in the low alignment condition made an average of 0.23                the interim generalization leads to a strong expectation of
gains. Only gains in the UC task were significant. Since all          sameness, and the violation leads to a search for re-
of the training examples were variants of UC, it is not               categorization. When surprised, the model probes long term
surprising that this was the easiest task to learn. However,          memory for an alternative case to align with.
learning ToM requires the ability to transfer to other tasks, as         Figure 3 gives a visual representation of our model. In the
was the case with children in the high alignment condition.           high alignment condition (a), the first true belief story is
The process of making gains in UL and VFB tasks must, then,           stored in working memory. The second true belief story is
be different than the process of only gaining UC.                     then matched to the first, and an interim generalization is
    We argue that analogical comparison in working memory             formed. When the false belief story comes in, it too matches
alone leads to gains in the UC. That is, immediate recall of          to the generalization. Due to violated expectations, long term
the training examples themselves is sufficient to cause gains.
                                                                       (causes-Underspecified
In contrast, a generalization between a training example and             (not
an autobiographical memory retrieved from long term                        (and
memory leads to transfer to the other two tasks, VFB and UL.                 (inside-UnderspecifiedRegion see85118 box1)
The violation of expectation generated during training causes                (perceivedThings see85118
                                                                                (InsideOfSpaceRegionFn box1))
the child to probe long term memory for a case of similar                    (isa see85118 VisualPerception)
surprise. What exactly they find surprising about the                        (doneBy see85118 kim)))
training—that something other than what they expected was                (opinions kim
inside the box, that the character in the story was incorrect in           (and
                                                                             (containedObject contain84430 cereal84499)
her guess, or something else—affects the case that is                        (containingObject contain84430 box1)
retrieved from long term memory. This in turn affects which                  (isa cereal84499 BreakfastCereal)
of UL and VFB the child is able to answer.                                   (isa contain84430 ContainingSomething))))
                 A Computational Model                                 Fig. 2: A partial representation of a true belief story. This
                                                                       statement represents the phrase “Kim thinks that the box
Our model, like Bach’s theory, is based in SMT, using                  contains cereal because Kim has never seen inside the
SAGE-WM for reasoning and learning.                                    box”.
                                                                  2951

memory (dotted line) is probed. Long term memory is a                                           Results
collection of generalized and specific cases that represent
                                                                     The model behaved as predicted. In the high alignment
memories formed over time. If a case is retrieved, an interim
                                                                     condition, the model generalized the true belief cases with a
generalization between the match and the false belief case is
                                                                     normalized match score of 0.075. It then matched the false
created and stored in working memory (b).
                                                                     belief to the generalization with a score of 0.066, which
   In the low alignment condition (c), on the other hand, no
                                                                     corresponds to the child incorrectly predicting that the
generalization is formed between the two true belief cases.
                                                                     character in the story knows what is in the box. The model
This leads to them being stored as separate cases in working
                                                                     was then informed that this match was incorrect. Because the
memory. When the false belief case comes in, it matches to
                                                                     similarity scores it had encountered were within the same
the first true belief case, but no element of surprise is present
                                                                     order of magnitude, it searched long term memory for another
when the model is corrected. For this reason, long term
                                                                     match. It then retrieved one of two memory cases that
memory is never probed, and working memory consists of
                                                                     matched with a normalized score of 0.083 or 0.066, and
only the three training examples (d). The contents of working
                                                                     created an interim generalization between it and the false
memory during testing predict the questions that the child is
                                                                     belief case. We used stories intended to approximate a
able to answer.
                                                                     memory a child might have (e.g. thinking that a magician put
   Testing proceeded as follows: cases were again encoded
                                                                     a ball inside of a hat, only to find the hat empty) to model
semi-automatically using EA NLU. These cases were given
                                                                     what might plausibly be retrieved. Depending on the case
to the model which retrieved the most similar case from
                                                                     retrieved, the model was then able to answer VFB or UL.
working memory and generated candidate inferences by
                                                                     Correctness was evaluated based on the candidate inferences
analogy. The candidate inferences correspond to what the
                                                                     generated from the best mapping between the test case and
model predicts is missing from the test cases (e.g. what the
                                                                     the contents of working memory. For example, to correctly
agents will do). These candidate inferences were manually
                                                                     answer “Where is Nora going to look for her ball?” (UL) the
inspected to determine whether any could result in correctly
                                                                     mapping must produce a candidate inference stating that
answering the test questions.
                                                                     there might be a looking event, in which Nora looks for her
                                                                     ball in the appropriate location.
                                                                        In the low alignment condition, on the other hand, the
                                                                     second true belief case matched to the first with a very low
                                                                     similarity score of 0.0014, well below threshold. For this
                                                                     reason, the model did not form a generalization between
                                                                     them. When the false belief case was compared, it had a
                                                                     match score of 0.066 with the first true belief case. Similar to
                                                                     the high alignment condition, the model was informed that
                                                                     this was not a correct match.
                                                                        Because the previous match score was of a different order
                                                                     of magnitude, the model did not look into long term memory,
                                                                     and instead stored the false belief case alongside the two true
                                                                     belief cases. When the UC case came in, the false belief case
                                                                     was retrieved. The mapping generated a candidate inference
                                                                     that would allow the model to properly answer “What does
                                                                     she think is in the box?” This candidate inference stated that
                                                                     not having looked inside the cookie box would cause the
                                                                     agent to believe that it contained something analogous to
                                                                     crayons in the crayon box from the training example. That is,
                                                                     cookies.
                                                                        Note that this retrieval is due to recency in working
                                                                     memory: the UC test case lacks the explanation present in the
                                                                     training cases about why a person holds a certain belief (e.g.
                                                                     “Kim thinks that the cereal box contains cereal because Kim
  Fig. 3: A visual representation of our model of training in        has never looked inside the box.”), so the first true belief case
  the Hoyos et al. study. (a) shows training in the high             had the same match score. If that case had been retrieved, the
  alignment condition. (b) is a representation of working            model would not have been able to answer UC correctly.
  memory after high alignment training. (c) and (d) show
  low alignment training and the consequent working                                           Discussion
  memory, respectively. Cases that are structural matches to
                                                                     Our model gives one explanation for the results of the Theory
  the probe are bold.
                                                                     of Mind training study presented in Hoyos et al. (2015). It
                                                                     also suggests that an important step in ToM development is
                                                                     generalizing belief-state cases in long term memory. In the
                                                                 2952

training studies, understanding that the training cases can,      voluntary, their processing is fast, their outputs are shallow
and indeed should, be assimilated to long term memory with        and highly constrained, they are often located in a particular
belief-state interpretation cases is crucial. In other words,     region of the brain, and their processes may be impaired—
children may be accumulating experiences that require             and selectively impaired—by neural damage. Importantly,
reasoning about belief states in long term memory, but these      according to Scholl and Leslie, modularity theories “intend
memories remain inert until a surprising event—such the one       to capture only the origin of the basic ToM abilities” (1999).
experienced by the high alignment participants in the Hoyos       In this sense, modularity theories do not necessarily compete
et al. study—stimulates their retrieval and begins the process    with other theories of ToM discussed here.
of creating schemas that can be used in future ToM reasoning.        Hybrid Theories Several hybrid theories have been
This predicts that children in the high alignment condition of    proposed to bridge the gap between Theory Theory and
Hoyos et al. (2015) are more likely to retain what they have      Simulation Theory. Some, which Bach (2011) calls divided-
learned than the children in the low alignment condition: the     hybrid models, alternately assign aspects of Theory of Mind
children in the high alignment condition were more likely to      to simulation or theorizing, depending on which is better
access those experiences from long term memory and form a         supported by empirical data (e.g. Heal, 1996). This approach,
generalization with them.                                         as Bach notes, avoids discussion of acquisition. It is unclear
   In addition, our model predicts that reversing the order of    how a child learns to use simulation for some tasks and theory
training examples would cause children in both conditions to      for others, and how simulation and theory develop
fail. In the low alignment case, when the most recent training    concurrently. Other hybrid theories, which Bach (2011) calls
example is retrieved, children would match the UC task to a       dynamic-hybrid models, focus on continued development.
true belief scenario, and answer incorrectly. Children in the     Bach’s model falls under this category. Like other dynamic-
high alignment case would similarly fall back on retrieval of     hybrid theories, Bach’s allows for development and changes
the most recent case, as they would not experience the            to ToM not only throughout childhood, but into adulthood.
surprise caused by the repetition break structure.                This includes switching between theorizing and simulating to
   Previous studies (e.g. Hale & Tager-Flusberg, 2003;            complete the same tasks at different points in development.
Lohmann & Tomasello, 2003) have suggested that                    As psychologists continue to find evidence of ToM shifts
experience plays a role in ToM development. Our model             throughout adulthood (e.g. Hess, 2006), dynamic-hybrid
provides a concrete explanation for how these experiences         theories become more and more plausible.
might lead to ToM and provides further suggestions for
human subject experiments.                                        Computation Models of Theory of Mind
                                                                  Hiatt and Trafton (2010) implemented a model of Theory of
                       Related Work                               Mind using the ACT-R cognitive architecture (Anderson,
                                                                  2007) that learned to perform the Sally-Ann task. It extracted
Theories of Theory of Mind                                        facts out of the scenario and was asked several false belief
Here, we summarize the best-known ToM theories.                   questions about what it saw. It was rewarded for answering
   Theory Theory One of the most popular takes on ToM is          correctly and punished for answering incorrectly, leading it
Theory Theory, which views the child as a scientist with          over time to inhibit true belief responses, producing a
regard to interpreting other people’s mental states (e.g.         learning curve consistent with developmental data.
Gopnik & Wellman, 1994). The child begins with a naïve            However, unlike our model, the training they used did not
theory about others, sometimes referred to as a folk              follow from an empirical training study. We note that the
psychology, which she modifies and adapts as evidence that        children in the Hoyos et al. (2015) study were able to learn
supports or refutes the theory is observed. The theory            aspects of false belief after seeing just three examples, only
gradually develops from only understanding desire states, to      one of which actually was a false belief situation.
belief states, to how belief and desire states influence each        Goodman et al. (2006) modeled ToM via two Bayesian
other and behavior (Bartsch & Wellman, 1995).                     networks that respectively represent a naïve and expert theory
   Simulation Theory Under the Simulation Theory view, a          in a Theory Theory account. They propose the models as
child mentally simulates events in order to predict others’       competing hypotheses in the Sally-Anne task, and show how,
actions and beliefs (Goldman, 2006), and develops by              during training, the expert theory becomes preferred over the
improvement in simulation abilities (Flavell, 2004).              naïve theory. The need to hand-code both theories in the
Criticisms of Simulation Theory include that errors made by       system’s starting endowment makes it more of a
both children and adults are not consistent with those            computational level model (Marr, 1982), whereas we provide
predicted by Simulation Theory accounts (Saxe, 2005) and          a process-level model of learning. Furthermore, our model is
that simulation is not sufficient for describing observed         consistent with the evidence from the training study
developmental patterns (Perner & Howes, 1992).                    presented by Goodman et al. (2006), which shows that
   Modular Theories Another common account is that ToM            surprise can improve children’s ToM performance.
can be explained as a single cognitive module. Scholl and
Leslie (1999) list six characteristics of modules: they are
domain-specific, their behavior is, at least in part non-
                                                              2953

                    Future Directions                            Gopnik, A., & Wellman, H. (1994). The theory theory. In L.
                                                                   Hirschfeld & S. Gelman (Eds.), Domain specificity in
Our results provide evidence that structure-mapping is indeed
                                                                   culture and cognition. NY: Cambridge University Press.
a plausible process-level mechanism (Marr, 1982) for ToM
                                                                 Hale, C. M., & Tager- Flusberg, H. (2003). The influence of
and how it is learned. As such, our future work will look
                                                                   language on theory of mind: A training study.
toward developing a complete computational Theory of
                                                                   Developmental science, 6(3), 346-359.
Mind, including both the theory and simulation aspects of
                                                                 Heal, J. (1996) Simulation, Theory, and Content. In
Bach’s theory, using SAGE as the underlying mechanism.
                                                                   Carruthers, P. & Smith, K. (Eds.), Theories of theories of
                                                                   mind. Cambridge: Cambridge University Press.
                   Acknowledgments                               Hess, T. (2006). Adaptive aspects of social-cognitive
We thank Alissa Baker-Oglesbee and Dedre Gentner for their         functioning in adulthood: Age-related goal and knowledge
helpful comments. This research was supported by the Socio-        influences. Social Cognition, 24(3), 279-309.
Cognitive Architectures for Adaptable Autonomous Systems         Hiatt, L. M., & Trafton, J. G. (2010, August). A cognitive
Program of the Office of Naval Research, N00014-13-1-              model of theory of mind. In Proceedings of the 10th
0470.                                                              International Conference on Cognitive Modeling (pp. 91-
                                                                   96).
                        References                               Hofmann, S. G., Doan, S. N., Sprung, M., Wilson, A.,
Anderson, J. R. (2007). Using brain imaging to guide the           Ebesutani, C., Andrews, L. A., ... & Harris, P. L. (2016).
  development of a cognitive architecture. Integrated models       Training children’s theory-of-mind: A meta-analysis of
  of cognitive systems, 49-62.                                     controlled studies. Cognition, 150, 200-212.
Bach, T. (2011). Structure-mapping: Directions from              Hoyos, C., Horton, W., & Gentner, D. (2015). Analogical
  simulation to theory. Philosophical Psychology, 24(1), 23-       comparison aids false belief understanding in preschoolers.
  51.                                                              In CogSci.
Bach, T. (2014). A Unified Account of General Learning           Kandaswamy, S., Forbus, K., and Gentner, D. (2014).
  Mechanisms and Theory- of- Mind Development. Mind                Modeling Learning via Progressive Alignment using
  & Language, 29(3), 351-381.                                      Interim Generalizations. Proceedings of the Cognitive
Bartsch, K., & Wellman, H. M. (1995). Children talk about          Science Society.
  the mind. Oxford university press.                             Kuehne, S., Forbus, K., Gentner, D. and Quinn, B. (2000).
Chang, M.D. and Forbus, K.D. (2015). Towards                       SEQL: Category learning as progressive abstraction using
  Interpretation Strategies for Multimodal Instructional           structure-mapping. Proceedings of CogSci 2000, August.
  Analogies. Proceedings of the 28th International               Loewenstein, J., & Heath, C. (2009). The Repetition-Break
  Workshop on Qualitative Reasoning (QR2015).                      plot structure: A cognitive influence on selection in the
  Minneapolis, MN.                                                 marketplace of ideas. Cognitive Science, 33, 1-19.
Flavell, J. H. (2004). Theory-of-mind development:               Lohmann, H., & Tomasello, M. (2003). The role of language
  Retrospect and prospect. Merrill-Palmer Quarterly, 50(3),        in the development of false belief understanding. Child
  274-290.                                                         Development, 74(4), 1130 –1144.
Forbus, K. D., Ferguson, R. W., Lovett, A., and Gentner, D.      Marr, D. (1982). Vision. Freeman Publishers.
  (2016). Extending SME to handle large-scale cognitive          Perner, J., & Howes, D. (1992). ‘He Thinks He Knows’: And
  modeling. Cognitive Science, DOI: 10.1111/cogs.12377,            More Developmental Evidence Against the Simulation
  pp 1-50.                                                         (Role Taking) Theory. Mind & Language, 7(1- 2), 72-86.
Gentner, D. (1983). Structure-mapping: A theoretical             Saxe, R. (2005). Against simulation: the argument from error.
  framework for analogy. Cognitive Science, 7, 155–170.            Trends in Cognitive Sciences, 9(4), 174-179.
Goldman, A. I. (1992). In defense of the simulation theory.      Scholl, B. J., & Leslie, A. M. (1999). Modularity,
  Mind & Language, 7(1- 2), 104-119.                               development and ‘theory of mind’. Mind & Language,
Goldman, A. I. (2006). Simulating minds: The philosophy,           14(1), 131-153.
  psychology, and neuroscience of mindreading. Oxford            Tomai, E. and Forbus, K. (2009). EA NLU: Practical
  University Press.                                                Language Understanding for Cognitive Modeling.
Goodman, N. D., Baker, C. L., Bonawitz, E. B., Mansinghka,         Proceedings of the 22nd International Florida Artificial
  V. K., Gopnik, A., Wellman, H., ... & Tenenbaum, J. B.           Intelligence Research Society Conference. Sanibel Island,
  (2006). Intuitive theories of mind: A rational approach to       Florida.
  false belief. In Proceedings of the twenty-eighth annual
  conference of the cognitive science society (pp. 1382-
  1387).
Gopnik, A. & Wellman H. (1992). Why the child‟s theory of
  mind really is a theory. Mind and Language, 7, 145-171.
                                                             2954

