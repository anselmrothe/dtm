                Word Embedding Distance Does not Predict Word Reading Time
                                                Stefan L. Frank (s.frank@let.ru.nl)
                                            Centre for Language Studies, Radboud University
                                          P.O. Box 9103, 6500 HD Nijmegen, The Netherlands
                             Abstract                                 wt from its previous context. Otherwise, apparent effects of
                                                                      relatedness could in fact be due to word predictability in-
   It has been claimed that larger semantic distance between the
   words of a sentence, as quantified by a distributional seman-      stead. Frank and Willems (in press) recently showed that
   tics model, increases both N400 size and word-reading time.        N400 effects of semantic distance (as quantified by a dis-
   The current study shows that the reading-time effect disap-        tributional semantics model) remain when factoring out the
   pears when word surprisal is factored out, suggesting that the
   earlier findings were caused by a confound between semantic        words’ (un)predictability as quantified by their surprisal (i.e.,
   distance and surprisal. This absence of a behavioural effect       − log P(wt |w1 , . . . , wt−1 )), leaving no room for a confound
   of semantic distance (in the presence of a strong neurophysi-      between predictability and semantic distance. The current
   ological effect) may be due to methodological differences be-
   tween eye-tracking and EEG experiments, but it can also be         paper will show that the same is not true for reading times:
   interpreted as evidence that eye movements are optimized for       Effects of semantic similarity on reading times for naturalis-
   reading efficiency.                                                tic materials, of the type reported by Mitchell et al. (2010) and
   Keywords: reading; eye tracking; N400; distributional seman-       Pynte et al. (2008), disappear when surprisal is factored out,
   tics; semantic distance; word surprisal                            provided that surprisal is computed by a powerful enough lan-
                                                                      guage model. Hence, semantic similarity between the words
                          Introduction                                of a sentence or text affects N400 size but not reading time.
An open question in the study of human language process-
ing is to what extent mere semantic similarity among words                                            Method
within a sentence or text affects the comprehension process.          Eye-tracking Data
Results from controlled experiments are inconclusive. On the
one hand, there is ample evidence for effects on the N400             Word-reading times were extracted from two published sets
event-related brain potential (ERP) component: Reading a              of eye-tracking data: The UCL corpus (Frank, Monsalve,
word that is semantically related to words in the preced-             Thompson, & Vigliocco, 2013) and the English Dundee cor-
ing context decreases N400 size, relative to when the con-            pus (Kennedy & Pynte, 2005). The UCL corpus comprises
text words are not meaning related (Camblin, Gordon, &                data from 42 native English speakers reading 205 individ-
Swaab, 2007; Metusalem et al., 2012; Paczynski & Kuper-               ual sentences sampled from three unpublished novels; the
berg, 2012). A number of behavioural experiments, however,            Dundee corpus has 10 participants reading newspaper editori-
failed to find corresponding effects on word-reading time             als. Frank and Willems (in press) demonstrated strong N400
(Gordon, Hendrick, Johnson, & Lee, 2006; Traxler, Foss,               effects of semantic distance (over and above the effect of sur-
Seely, Kaup, & Morris, 2000). In contrast, two studies that           prisal) for the sentences of the UCL corpus. Mitchell et al.
analysed reading times on naturalistic texts (instead of tak-         (2010) reported reading-time effects of semantic distance in
ing a controlled experimental approach) did find that words           the Dundee data, and similar results by Pynte et al. (2008)
are read faster when they have stronger semantic relatedness          were based on the French part of the Dundee corpus, also
to earlier words in the text (Mitchell, Lapata, Demberg, &            comprising newspaper texts.
Keller, 2010; Pynte, New, & Kennedy, 2008). In those stud-               Four measures of reading time will be investigated: first-
ies, semantic relatedness measures were obtained from a dis-          fixation duration, first-pass duration (the sum of fixation du-
tributional semantics model, which assigns numerical vectors          rations on a word before the first fixation on any other word),
to words on the basis of the words’ co-occurrence patterns in         right-bounded reading time (the sum of fixation durations on
large text corpora. These vector representations are known as         a word before the first fixation on a later word), and go-past
word embeddings in the computational linguistics literature.          reading time (the sum of fixations on all words from the first
Words that tends to occur in similar contexts receive simi-           fixation on the current word until the first fixation on a later
lar embeddings. Consequently, distances between the words’            word). These four measures, in this order, have been argued
embedding vectors correspond to semantic distances between            to reflect increasingly late cognitive processes (Clifton Jr.,
the corresponding words.                                              Staub, & Rayner, 2007; Gordon et al., 2006).
   If semantically related words tend to co-occur, a word’s
occurrence can (to some extent) be predicted from the pres-
                                                                      Models
ence of related words. Consequently, if one wants to claim            Each content word of the UCL and Dundee corpora was as-
that the reading process on word wt is affected by the word’s         signed a measure of semantic distance to preceding content
semantic relatedness to the preceding words (w1 , . . . , wt−1 ),     words, as well as five estimates of word surprisal. The dis-
it is crucial to factor out any effect of the predictability of       tributional semantics and surprisal models were trained on
                                                                  385

the first slice of the ENCOW14 web corpus (Schäfer, 2015),                        with At as defined as in Equation 1 and |At | the number of
comprising 644.5M word tokens of 2.81M types.                                      words in At . P(wt |wi ) denotes the probability that wt occurs
                                                                                   within a distance of 15 words after occurrence of wi . That is,
Semantic Distance Word embeddings were generated by
                                                                                   the preceding content words wi ∈ At are taken as independent
the word2vec skipgram model (Mikolov, Chen, Corrado, &
                                                                                   cues to the occurrence of wt , whose skip-bigram probability
Dean, 2013), which is basically a feedforward neural net-
                                                                                   is computed by averaging over these individual cues.
work with one hidden layer. The network learns to associate
                                                                                      The required word-pair probabilities P(wi , wt ) are esti-
each input word wt to the k words immediately preceding and
                                                                                   mated from co-occurrence frequencies in the training corpus,
following (i.e., the sequence wt−k , . . . , wt−1 , wt+1 , . . . , wt+k ).
                                                                                   using the Simple Good-Turing smoothing method (Gale &
After training the network, the vector of connection weights
                                                                                   Sampson, 1995) to estimate the total probability of all unseen
from each input unit to the 300-unit hidden layer forms the
                                                                                   pairs. This total probability P0 is divided over the unseen
embedding for the word corresponding to the input unit. The
                                                                                   pairs (v, w) in proportion to P(v)P(w), that is, the probability
‘window size’ parameter was set to k = 5 in the current appli-
                                                                                   of each particular unseen pair (v, w) is given by:
cation of the model.
   As explained in the Introduction, the distance between two                                                     P0 P(v)P(w)
word vectors quantifies the semantic distance between the                                        P(v, w) =                                ,
                                                                                                            1 − ∑(v0 ,w0 )∈S P(v0 )P(w0 )
two words. A common distance measure used in distribu-
tional semantics is the cosine of the angle between the vec-                       where S is the set of all ordered word pairs observed in the
tors. Here, we require a measure for the distance between the                      training data within a 15-word distance from each other.
current word’s embedding w           ~ t and its entire previous context
(not just a single word). The vector representing the combi-                       Relation between semantic distance and surprisal Ta-
nation of content words from the previous context is defined                       ble 1 shows there indeed exists a positive confound between
as simply the sum of the words’ individual vectors. Thus, the                      surprisal and semantic distance, which grows stronger as the
relevant distance measure becomes                                                  language model is able to use words from further back in the
                                                          !                        context.
                                                                                      Frank and Willems (in press) interpolate the 5-gram and
                 semdist(t) = − cos w         ~t,  ∑ ~w      ,             (1)
                                                  w∈At                             skip-bigram models to minimize average surprisal over the
                                                                                   UCL corpus and show empirically that the semantic distances
where At is a collection of content words that precede wt in                       do not contain information that can be used to further improve
the sentence or text. For the individual sentences of the UCL                      this interpolated language model. Hence, if the semantic dis-
corpus, At contains all content words preceding wt in the sen-                     tances account for variance in human reading difficulty mea-
tence. For the full texts of the Dundee corpus, At contains the                    sures over and above what is already explained by the sur-
four content words immediately preceding wt in the text (if                        prisal values, this cannot be attributed to a confound between
wt is among the text’s first four content words, At will contain                   semantic relatedness and predictability but must be due to the
correspondingly fewer words). If At is empty, word wt has                          effect of semantic relatedness itself.
no semantic distance. Semantic distance values on the UCL
corpus were identical to those used by Frank and Willems (in                       Data Analysis
press) to analyse N400 ERP effects.                                                Linear mixed-effects regression models were fitted to the log-
Surprisal Word surprisal was computed by n-gram lan-                               transformed reading times using as covariates: word position
guage models, which simplify the full conditional probabil-                        in the sentence, word length (number of characters), word
ity P(wt |w1 , . . . , wt−1 ) to P(wt |wt−n+1 , . . . , wt−1 ), that is, only      log-frequency in ENCOW14, and a binary factor indicating
the n − 1 previous words are taken into account when esti-                         whether or not the previous word was fixated. To account for
mating the occurrence probability of wt . Model order n was                        the possibility that reading-time effects appear shortly after
varied from n = 2 to n = 5, and the model was generated by                         the point at which they originate (so-called spillover effects),
SRILM (Stolcke, 2002) with modified Kneser-Ney smooth-                             the previous word’s length and log-frequency were also in-
ing (Chen & Goodman, 1999).                                                        cluded. All two-way interactions between these six factors
   The semantic distance measure defined above is sensitive                        were also present.
to content words beyond the n − 1 previous words that matter
to an n-gram model. If semantic distance correlates with sur-
prisal, this could yield apparent effects of semantic distance                     Table 1: Correlation coefficients between semantic distance
that are in fact due to unpredictability resulting from words                      and surprisal values.
outside of the n-gram window. To control for this, a ‘skip-
bigram’ language model (SBLM) was used to obtain a fifth                                                         Language model
set of surprisal values:                                                             Data set     2-gram    3-gram 4-gram 5-gram              SBLM
                                                                                     UCL              .19       .26           .27         .27   .29
                         1                          1          P(wi , wt )
   Psblm (wt |At ) =           ∑     P(wt |wi ) =         ∑                ,         Dundee           .05       .18           .20         .21   .26
                        |At | wi ∈At               |At | wi ∈At P(wi )
                                                                               386

   The main factor of interest was the word’s semantic dis-                4-word context that is is taken into account when generating
tance measure. Separate analyses were run using the current                expectations about upcoming words. Rather, long-distance
and previous word’s semantic distance; the latter capturing                co-occurrence patterns between content words matter as well.
potential spillover.1 In addition to a control condition without              There are a few noticeable difference between the results
any surprisal measure in the regression, five separate analy-              for the UCL and Dundee data sets, which mirror differences
ses were run including n-gram surprisal with n = 2, 3, 4, 5, or            in the text materials of these two corpora. Surprisal effects
both 5-gram and SBLM surprisal (always for both the current                appear to be more reliable in the Dundee data, in that the zero
and previous word).                                                        point falls further outside the confidence intervals. This can
   Random effects in the regression model were the by-                     simply be explained by the Dundee data set being much larger
subject and by-word intercept, and by-subject slopes of se-                than the UCL data set (134,203 versus 18,178 data points).
mantic distance and any surprisal measure that was included                Interestingly, the UCL corpus results show larger effect sizes
as a fixed effect.                                                         (i.e., larger coefficients) which is probably due to these ma-
   Regression models were fitted to each of the four reading               terials having been specifically designed for language model
time measures from both data sets, making a total of 96 anal-              evaluation. Compared to the Dundee corpus texts, the UCL
yses: 4 reading time measures × 2 corpora × 2 semantic dis-                corpus sentences contain fewer low-frequency words (for
tance measures (of current or previous word) × (5 surprisal                which surprisal is hard to estimate reliably) and can com-
measures + 1 control). Words were excluded from analysis                   prehended more easily without relying on world knowledge
if they were not fixated, were attached to punctuation, con-               (which the language models do not incorporate). Finally, the
tained any non-letter or more than one capital letter, or were             fact that the SBLM model explained unique variance in read-
the first or last word on a line.                                          ing times from the Dundee corpus only can be explained by
                                                                           the fact that this corpus consists of full texts as opposed to the
                              Results                                      UCL corpus’s individual sentences. Compared to individual
Figure 1 displays the estimated regression coefficient (i.e., ef-          sentences, full texts will contain more content words outside
fect size) of the semantic distance predictor in each of the               of the 5-gram window, making the SBLM model more influ-
96 fitted regression models. Note that effect sizes cannot                 ential.
be compared between the analyses investigating the current
versus previous word’s semantic distance. This is because                                             Discussion
these analyses apply to different sets of words: All content
                                                                           Results on the Dundee corpus showed significant, positive ef-
words when the current word’s semantic distance is used, but
                                                                           fects of semantic distance on all four reading time measures
the words directly following content words (including many
                                                                           when surprisal was not taken into account. However, fac-
function words) when the previous word’s semantic distance
                                                                           toring out surprisal as computed by anything more powerful
is the variable under investigation. The same holds for the
                                                                           than a bigram model made the effects of semantic distance
estimated regression coefficients of the surprisal predictors,
                                                                           disappear. Apparently, these effects were due to a confound
plotted in Figure 2.2
                                                                           between semantic distance and surprisal, that is, a word is less
   For the UCL corpus, none of the semantic distance effects               likely to appear if it has weaker semantic relatedness to earlier
reach statistical significance. For the Dundee corpus, there is            words. It was actually a word’s unpredictability, rather than
a clear effect of semantic distance in the expected (i.e., pos-            its semantic content per se, that resulted in increased reading
itive) direction when surprisal is not factored out, and it re-            time.
mains present for later reading time measures when surprisal
                                                                              Indeed, the findings by Pynte et al. (2008) and Mitchell
takes only very local context into account (i.e., under a bi-
                                                                           et al. (2010), on the French and English Dundee corpus, re-
gram model).
                                                                           spectively, can be attributed to confounds between semantic
   As is clear from Figure 2, words with higher surprisal take
                                                                           relatedness and predictability. Pynte et al. (2008) did not fac-
longer to read, as is well known from the literature (e.g. Mon-
                                                                           tor out surprisal (or even simple transitional probabilities be-
salve, Frank, & Vigliocco, 2012; Smith & Levy, 2013). Sur-
                                                                           tween words) in their analysis of the effect of semantic dis-
prisal computed by the novel SBLM language model has
                                                                           tance. Mitchell and Lapata’s (2009) goal was to show that in-
an effect over and above 5-gram surprisal, at least for the
                                                                           corporating semantic distance measures from their own ‘sim-
Dundee corpus, which means that it is not merely the local,
                                                                           ple semantic space model’ (as well as from a Latent Dirichlet
    1 If both the current and previous word’s semantic distance had        Allocation Topics model; Griffiths, Steyvers, & Tenenbaum,
been included as factors in a single regression model, this would          2007) reduces perplexity of a combined n-gram and proba-
have greatly reduced the amount of usable data because both adja-          bilistic phrase-structure grammar. That is, taking these se-
cent words would have to be content words.
    2 The displayed coefficients for current (previous) surprisal come     mantic measures into account improves the language model.
from the regression model that includes current (previous) semantic        Consequently, the improved fit to reading time could be due
distance. Consequently, exactly the same set of words was involved         merely to more accurate next-word prediction rather than to
in estimating the coefficients for the surprisal and semantic distance
measures, even though surprisal (unlike semantic distance) is also         semantic similarity per se.
defined for function words.                                                   The UCL corpus results showed no effect of semantic dis-
                                                                       387

                      UCL, current sem.dist.                UCL, previous sem.dist.          Dundee, current sem.dist.    Dundee, previous sem.dist.
               0.04                               0.04                                   0.02                          0.02
               0.02                               0.02                                   0.01                                0.01
coefficient
                 0                                      0                                  0                                    0
              −0.02                              −0.02                                −0.01                                 −0.01
                                        no surprisal             2−gram         3−gram             4−gram         5−gram             5−gram + sblm
              −0.04                              −0.04                                −0.02                                 −0.02
                      FF FP RB GP                            FF FP RB GP                         FF FP RB GP                         FF FP RB GP
                      reading time measure                   reading time measure                reading time measure                reading time measure
Figure 1: Regression coefficients (with 95% confidence intervals) of semantic distance predictor, when factoring out different
measures of surprisal. The leftmost two panels display results on the UCL corpus; the Dundee corpus results are shown in the
rightmost panels. The 2nd and 4th panel show the coefficient of the previous word’s semantic distance. Reading time measures
are indicated by FF (first fixation), FP (first pass), RB (right-bounded), and GP (go-past).
                      UCL, current surprisal                UCL, previous surprisal             Dundee, current surprisal       Dundee, previous surprisal
                0.1                                0.1                                   0.05                                 0.05
               0.05                               0.05                                 0.025                                 0.025
coefficient
                 0                                      0                                   0                                   0
              −0.05                              −0.05                                −0.025                                −0.025
                                               2−gram            3−gram         4−gram              5−gram        5−gram*             sblm
               −0.1                               −0.1                                 −0.05                                 −0.05
                       FF FP RB GP                           FF FP RB GP                          FF FP RB GP                         FF FP RB GP
                      reading time measure                  reading time measure                 reading time measure                reading time measure
Figure 2: Regression coefficients (with 95% confidence intervals) of surprisal predictor, when factoring out semantic distance.
“5-gram*” refers to the effect of 5-gram surprisal when SBLM-surprisal is also included as a regressor, and “sblm” refers to
the effect of SBLM-surprisal over and above 5-gram surprisal. The leftmost two panels display results on the UCL corpus; the
Dundee corpus results are shown in the rightmost panels. The 2nd and 4th panel show the coefficient of the previous word’s
semantic distance. Reading time measures are indicated by FF (first fixation), FP (first pass), RB (right-bounded), and GP
(go-past).
                                                                                 388

tance on reading times whatsoever, even when surprisal was           tic word prediction (surprisal) and by semantic similarity to
not taken into account. This is remarkable considering that          earlier words (word embedding distance).
Frank and Willems (in press) found that N400 effects of the
very same semantic distance values are of similar size as –                                   Conclusion
and independent from – the effect of surprisal as computed           The current results failed to replicate earlier findings of a pos-
by an interpolated 5-gram and skip-bigram language model.            itive correlation between reading times on naturalistic data
This discrepancy between neurophysiological and behavioral           and semantic relatedness between words, as quantified by a
effects is consistent with findings from the controlled experi-      distributional semantics model. This apparent effect of se-
mental studies mentioned in the Introduction. But how can it         mantic relatedness appeared to be due to a confound with
be explained?                                                        word predictability. Of course, it is possible that an effect of
                                                                     semantic distance reappears when using a different distribu-
   One possible cause is the difference in stimuli presenta-
                                                                     tional semantics model, or a more sophisticated technique for
tion method. The eye-tracking methodology allows a natu-
                                                                     combining single word vectors into a sentence context vector
ral reading processes whereas in most EEG reading studies,
                                                                     (Equation 1). However, it is equally true that improved sur-
words are presented one at a time for an unnaturally long du-
                                                                     prisal models may undo the work of more sophisticated word
ration. The EEG data used by Frank and Willems (in press)
                                                                     embedding models. And crucially, the current distributional
came from a study with word-length dependent presentations
                                                                     semantics modelling choices were appropriate for predicting
durations of at least 627ms (Frank, Otten, Galli, & Vigliocco,
                                                                     reading times when surprisal was not taken into account, as
2015), which is much longer than fixation durations in natu-
                                                                     well as N400 sizes over and above surprisal, so they should
ral reading. Wlotko and Federmeier (2015) showed that us-
                                                                     also have sufficed for revealing reading time effects of seman-
ing more natural word presentation rates in an ERP reading
                                                                     tic distance that are independent from surprisal, if there had
study can remove particular effects of semantic relatedness
                                                                     been any.
on the N400. If semantic distance effects are delayed rela-
tive to surprisal effects, this could explain their absence in                           Acknowledgements
reading times: By the time they would have appeared, any
                                                                     The work presented here was funded by the Netherlands Or-
effect has already been washed out by the processing of sev-
                                                                     ganisation for Scientific Research (NWO) Gravitation Grant
eral other words. Although Figure 1 indeed shows a trend for
                                                                     024.001.006 to the Language in Interaction Consortium.
the semantic distance effect to be somewhat stronger for the
later reading time measures (as was also found by Pynte et                                    References
al., 2008), the same is true for the surprisal effect (Figure 2)
                                                                     Brouwer, H., Fitz, H., & Hoeks, J. C. J. (2012). Getting real
so this cannot explain why reading times are insensitive to
                                                                        about semantic illusions: Rethinking the functional role
semantic distance. Moreover, Frank and Willems (in press)
                                                                        of the P600 in language comprehension. Brain Research,
found fMRI effects of semantic distance (as quantified by dis-
                                                                        1446, 127–143.
tributional semantics) during normal speech comprehension,
                                                                     Camblin, C. C., Gordon, P. C., & Swaab, T. Y. (2007). The
indicating that the presence of a measurable neural response
                                                                        interplay of discourse congruence and lexical association
does not rely on unnaturally slow presentation rates.
                                                                        during sentence processing: Evidence from ERPs and eye
   An alternative, and possibly more interesting explanation            tracking. Journal of Memory and Language, 56, 103–128.
of the difference between N400 and reading time effects is           Chen, S. F., & Goodman, J. (1999). An empirical study of
that reading is optimized for speed (Smith & Levy, 2013).               smoothing techniques for language modeling. Computer
Being faster on more predictable (i.e., lower surprisal) words          Speech and Language, 13, 359–394.
increases overall efficiency, whereas there is no reason to          Clifton Jr., C., Staub, A., & Rayner, K. (2007). Eye move-
be faster on merely semantically related words. Hence, we               ments in reading words and sentences. In R. Van Gompel,
would expect reading times to display effects of surprisal but          M. Fisher, W. Murray, & R. L. Hill (Eds.), Eye movement
not of semantic distance. Other dependent variables from                research: A window on mind and brain (pp. 341–372). El-
eye-tracking, however, could show sensitivity to semantic               sevier, Oxford, UK.
distance, and this is exactly what Van den Hoven, Hartung,           Frank, S. L., Monsalve, I., Thompson, R. L., & Vigliocco, G.
Burke, and Willems (2016) found in a recent analysis of data            (2013). Reading time data for evaluating broad-coverage
from a Dutch narrative text reading eye-tracking study: Se-             models of English sentence processing. Behavior Research
mantic distance correlated with saccade distance and regres-            Methods, 45, 1182–1190.
sion probability but not with reading time after factoring out       Frank, S. L., Otten, L. J., Galli, G., & Vigliocco, G. (2015).
trigram surprisal. In contrast, the reason why the N400 shows           The ERP response to the amount of information conveyed
effects of both surprisal and semantic distance could be that           by words in sentences. Brain and Language, 140, 1–11.
it forms an index of the difficulty of retrieving lexical infor-     Frank, S. L., & Willems, R. M. (in press). Word predictabil-
mation from long-term memory (Brouwer, Fitz, & Hoeks,                   ity and semantic similarity show distinct patterns of brain
2012; Kutas & Federmeier, 2000). As Frank and Willems                   activity during language comprehension. Language, Cog-
(in press) argue, this difficulty is reduced both by probabilis-        nition and Neuroscience.
                                                                 389

Gale, W. A., & Sampson, G. (1995). Good-Turing frequency              dictability on reading time is logarithmic. Cognition, 128,
  estimation without tears. Journal of Quantitative Linguis-          302–319.
  tics, 2, 217–237.                                                 Stolcke, A. (2002). SRILM – an extensible language model-
Gordon, P. C., Hendrick, R., Johnson, M., & Lee, Y. (2006).           ing toolkit. In Proceedings of the International Conference
  Similarity-based interference during language comprehen-            on Spoken Language Processing (pp. 901–904). Denver,
  sion: Evidence from eye tracking during reading. Journal            Colorado.
  of Experimental Psychology. Learning, Memory, and Cog-            Traxler, M. J., Foss, D. J., Seely, R. E., Kaup, B., & Morris,
  nition, 32, 1304–1321.                                              R. K. (2000). Priming in sentence processing: intralexical
Griffiths, T. L., Steyvers, M., & Tenenbaum, J. B. (2007).            spreading activation, schemas, and situation models. Jour-
  Topics in semantic representation. Psychological Review,            nal of Psycholinguistic Research, 29, 581–595.
  114, 211–244.                                                     Van den Hoven, E., Hartung, F., Burke, M., & Willems, R. M.
Kennedy, A., & Pynte, J. (2005). Parafoveal-on-foveal effects         (2016). Individual differences in sensitivity to style during
  in normal reading. Vision Research, 45, 153–168.                    literary reading: Insights from eye-tracking. Collabra, 2,
Kutas, M., & Federmeier, K. D. (2000). Electrophysiology              25.
  reveals semantic memory use in language comprehension.            Wlotko, E. W., & Federmeier, K. D. (2015). Time for predic-
  Trends in Cognitive Sciences, 4, 463–470.                           tion? the effect of presentation rate on predictive sentence
Metusalem, R., Kutas, M., Urbach, T. P., Hare, M., McRae,             comprehension during word-by-word reading. Cortex, 68,
  K., & Elman, J. L. (2012). Generalized event knowledge              20-32.
  activation during online sentence comprehension. Journal
  of Memory and Language, 66, 545–567.
Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Effi-
  cient estimation of word representations in vector space. In
  Proceedings of the ICLR Workshop.
Mitchell, J., & Lapata, M. (2009). Language models based
  on semantic composition. In Proceedings of the 2009 Con-
  ference on Empirical Methods in Natural Language Pro-
  cessing (pp. 430–439). Singapore: Association for Com-
  putational Linguistics.
Mitchell, J., Lapata, M., Demberg, V., & Keller, F. (2010,
  July). Syntactic and semantic factors in processing diffi-
  culty: An integrated measure. In Proceedings of the 48th
  annual meeting of the association for computational lin-
  guistics (pp. 196–206). Uppsala, Sweden: Association for
  Computational Linguistics.
Monsalve, I. F., Frank, S. L., & Vigliocco, G. (2012). Lexical
  surprisal as a general predictor of reading time. In Proceed-
  ings of the 13th Conference of the European Chapter of the
  Association for Computational Linguistics (pp. 398–408).
  Avignon, France: Association for Computational Linguis-
  tics.
Paczynski, M., & Kuperberg, G. R. (2012). Multiple influ-
  ences of semantic memory on sentence processing: distinct
  effects of semantic relatedness on violations of real-world
  event/state knowledge and animacy selection restrictions.
  Journal of Memory and Language, 67, 426–448.
Pynte, J., New, B., & Kennedy, A. (2008). On-line con-
  textual influences during reading normal text: A multiple-
  regression analysis. Vision Research, 48, 2172-2183.
Schäfer, R. (2015). Processing and querying large web cor-
  pora with the COW14 architecture. In P. Bański, H. Biber,
  E. Breiteneder, M. Kupietz, H. Lüngen, & A. Witt (Eds.),
  Proceedings of the 3rd Workshop on the Challenges in the
  Management of Large Corpora (pp. 28–34). Mannheim,
  Germany: Institut für Deutsche Sprache.
Smith, N. J., & Levy, R. (2013). The effect of word pre-
                                                                390

