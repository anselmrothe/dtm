                            Generalized Representation of Syntactic Structures
                                                Reihane Boghrati (boghrati@usc.edu)
                                  Department of Computer Science, University of Southern California
                                                        Los Angeles, CA 90089 USA
                                                Kate M. Johnson (katejohn@usc.edu)
                                      Department of Psychology, University of Southern California
                                                        Los Angeles, CA 90089 USA
                                              Morteza Dehghani (mdehghan@usc.edu)
                Department of Psychology and Department of Computer Science, University of Southern California
                                                        Los Angeles, CA 90089 USA
                              Abstract                                   1999), socio-economics (Jahr, 1992), and emotional states
   Analysis of language provides important insights into the un-         and personality (Gawda, 2010).
   derlying psychological properties of individuals and groups.             Recently, several tools have been developed for automated
   While the majority of language analysis work in psychology            analysis of syntactic structures. For example, Lu’s (Lu, 2010)
   has focused on semantics, psychological information is en-
   coded not just in what people say, but how they say it. In            system analyzes fourteen different measures including the ra-
   the current work, we propose Conversation Level Syntax Simi-          tio of verb phrases, number of dependent clauses, and T-
   larity Metric-Group Representations (CASSIM-GR). This tool            units to calculate documents’ syntactic complexity. Similarly,
   builds generalized representations of syntactic structures of
   documents, thus allowing researchers to distinguish between           TAALES relies on several features such as frequency, range,
   people and groups based on syntactic differences. CASSIM-             academic language, and psycholinguistic word information to
   GR builds off of Conversation Level Syntax Similarity Metric          measure lexical sophistication (Kyle & Crossley, 2015). By
   by applying spectral clustering to syntactic similarity matrices
   and calculating the center of each cluster of documents. This         comparison, Coh-Metrix is a tool which provides measure-
   resulting cluster centroid then represents the syntactical struc-     ment for over 200 different facets of syntax (e.g. mean num-
   ture of the group of documents. To examine the effectiveness          ber of modifiers per noun phrase, mean number of high-level
   of CASSIM-GR, we conduct three experiments across three
   unique corpora. In each experiment, we calculate the cluster-         constituents per word, and the incidence of word classes that
   ing accuracy and compare our proposed technique to a bag-             signal logical or analytical difficulty) (Graesser, McNamara,
   of-words approach. Our results provide evidence for the ef-           Louwerse, & Cai, 2004).
   fectiveness of CASSIM-GR and demonstrate that combining
   syntactic similarity and tf-idf semantic information improves            While each of these tools provides different mechanisms
   the total accuracy of group classification.                           for measuring various syntactic features, they all rely on
   Keywords: Syntax; Text Clustering; Syntactic Similarity;              previously identified features of interest. More recently,
   Text Classification; CASSIM.
                                                                         we introduced ConversAtion Level Syntax Similarity Met-
                                                                         ric (CASSIM) to incorporate constituency parse trees when
                          Introduction                                   calculating the syntactic similarity of documents (Boghrati,
Language lies at the heart of human communication, and                   Hoover, Johnson, Garten, & Dehghani, 2017). CASSIM
analysis of language has been shown to be an essential lens              compares groups of documents based on underlying syntactic
for investigating and understanding many different psycho-               differences between groups of documents.
logical properties. Language analysis has provided insight                  There are some situations, however, where hypothesis test-
into depression (Ramirez-Esparza, Chung, Kacewicz, & Pen-                ing about predefined features or groups may not be the only
nebaker, 2008), moral values (Graham, Haidt, & Nosek,                    aim. Instead, researchers may wish to identify new groupings
2009; Dehghani et al., 2016), neuroticism and extraversion               of documents and the features which tie them together. These
(Mehl, Robbins, & Holleran, 2012), political orientations                group-level linguistic representations can lead to important,
(Dehghani, Sagae, Sachdeva, & Gratch, 2014), and cultural                novel discoveries about how a group communicates. Clus-
backgrounds (Maass, Karasawa, Politi, & Suga, 2006; De-                  tering techniques are widely used for this type of analysis.
hghani, Bang, et al., 2013) among many others.                           There is an extensive literature studying various text clus-
   Most of these studies, however, focus on quantifying word             tering approaches and their applications (Song, Li, & Park,
choice or semantics. While semantics undoubtedly play an                 2009; Sasaki & Shinnou, 2005; Lin, Jiang, & Lee, 2014).
important role in capturing psychological properties, it is vi-          This literature demonstrates that many linguistic features fa-
tal to also include analysis of syntax in this process. Prior            cilitate improvements in text clustering (T. Liu, Liu, Chen, &
research has shown that syntactic structures also capture in-            Ma, 2003; L. Liu, Kang, Yu, & Wang, 2005), some of which
dividuals and group differences for various demographic and              address the effect of synonymy, hypernymy, syntax, and part
psychological factors such as educational or regional back-              of speech tags on text clustering methods (Sedding & Kaza-
ground (Bresnan & Hay, 2008), gender (Vigliocco & Franck,                kov, 2004; Lewis & Croft, 1989; Lewis, 1992; Zheng, Kang,
                                                                     1648

                                                                𝑑" 𝑑# … 𝑑$
                                                                                                                                                 𝑐𝑙𝑢𝑠𝑡𝑒𝑟"
      N Documents
                      𝑑"
                                                           𝑑"
                                                                                                                                    k Clusters
                                 CASSIM                         Syntactic
                      𝑑#                                   𝑑#                                        Spectral                                    𝑐𝑙𝑢𝑠𝑡𝑒𝑟#
                                 Compare each pair         …    Similarity
                       …           of documents                                                     Clustering                                       …
                                                           𝑑$    Matrix
                      𝑑$
                                                                                                                                                 𝑐𝑙𝑢𝑠𝑡𝑒𝑟,
                                                        k: Number of clusters
                                                                                               k Similarity Scores
                                                  𝑐"
                                    k Centroids
                                                                                                                     𝑠" : similarity of 𝑑𝑖 to 𝑐1
                    Calculate                     𝑐#                   CASSIM                                        𝑠# : similarity of 𝑑0 to 𝑐#
                                                                                                                                                              Prediction
                                                                                                                                                            Assign 𝑑0 to the cluster
                                                                       Compare 𝑑𝑖 to 𝑐1
                    Centroids                     …                      through 𝑐𝑘                                               …                            with the highest
                                                                                                                                                               similarity score
                                                  𝑐,                                                                 𝑠, : similarity of 𝑑0 to 𝑐,
                                𝑑0 : A new document
                                                       Figure 1: CASSIM-Group Representation Process.
& Kim, 2009).                                                                             higher numbers indicate higher similarity between two doc-
   In the current paper, we introduce ConversAtion Level                                  uments. Using the syntactic similarity scores measured by
Syntax Similarity Metric-Group Representations (CASSIM-                                   CASSIM, we build a syntactic similarity matrix. With N doc-
GR), a tool that captures the generalized representation of                               uments in our corpus, the syntax similarity matrix is AN×N ;
syntactic structure used by individuals in a certain group.                               where Ai, j is the syntactic similarity of the two documents i
CASSIM-GR groups documents into separate clusters based                                   and j.
on their syntactic similarity scores, and uses the centroid of a
                                                                                             Next, spectral clustering (Shi & Malik, 2000) is used to
cluster as a generalized representation of the syntactic struc-
                                                                                          cluster documents into a pre-defined number of groups. It has
tures used in that cluster. These centroid syntax represen-
                                                                                          been shown that spectral clustering often outperforms tradi-
tation can then be used to understand within-group syntax
                                                                                          tional clustering algorithms (Von Luxburg, 2007). The gen-
similarities and between-group syntax variations. As we will
                                                                                          eral idea behind spectral clustering is to apply k-means clus-
show, these generalizations of syntactic structures can be use-
                                                                                          tering on eigenvectors of Laplacian matrix of A. The syntac-
ful when analyzing differences between documents written
                                                                                          tic similarity matrix A, which is constructed in the previous
by different individuals or groups.
                                                                                          step, and the number of clusters are provided as inputs to the
   This paper is structured as follows: First, we describe our                            spectral clustering method.
proposed approach, CASSIM-GR, in more detail. Next, we
validate the approach with a corpus of syntactically similar                                 Clustering documents leads us to an essential next step
documents. Then, we apply CASSIM-GR to two other cor-                                     which is extracting general attributes or representation of
pora: documents marked as dogmatic and non-dogmatic (Fast                                 clusters. One way to address this concern is to calculate a cen-
& Horvitz, 2016) and documents from conservative and lib-                                 troid for each cluster. Clusters’ centers facilitate researchers
eral weblogs (Dehghani, Sagae, Sachdeva, & Gratch, 2013)                                  to better understand and analyze the syntactic structures used
and evaluate the classification accuracy of CASSIM-GR com-                                by a group of people or under certain situations by only ana-
pared to tf-idf approach and a combination of the two ap-                                 lyzing center documents and without going through hundreds
proaches. Finally, we discuss limitation and future directions                            of documents. Hence, the third step in CASSIM-GR is calcu-
of our work.                                                                              lating a centroid for each cluster. We define a cluster’s center
                                                                                          as the document which has the highest syntactic similarity to
                                CASSIM-GR                                                 other documents in its cluster. To identify a cluster’s center,
                                                                                          we calculate average syntactic similarity of each document to
In this section we describe CASSIM-GR for clustering
                                                                                          other documents in its cluster and return the document with
groups of documents with similar syntactic structures.
                                                                                          the highest average similarity. Additionally, we may return
CASSIM-GR includes four general steps: 1. constructing the
                                                                                          the top n documents with the highest average syntactic sim-
syntactic similarity matrix, 2. applying spectral clustering, 3.
                                                                                          ilarity to other documents in a cluster as representative sam-
calculating the center of clusters, 4. classification. Figure 1
                                                                                          ples of that cluster.
demonstrates the steps involved in CASSIM-GR to compute
the generalized representation of syntactic structures.                                      Finally, we use cross-validation to test the accuracy and
   First, we use CASSIM (Boghrati et al., 2017) to calcu-                                 representativeness of the clusters’ centers. To cross-validate,
late the syntactic similarity between each pair of documents.                             our approach uses CASSIM to calculate the syntactic similar-
CASSIM relies on edit distance difference of constituency                                 ity of the left-out document to each centroid and assigns the
parse trees. It first generates parse trees for the sentences in                          document to a cluster with the highest similarity. This pro-
each document. Next, it calculates the edit distance between                              cess is repeated N times and an accuracy of classification is
each two sentences’ constituency parse trees and matches the                              reported by the method. In the following sections, we eval-
most syntactically similar sentences using Hungarian algo-                                uate CASSIM-GR by performing classification experiments
rithm. Finally, it provides a score between 0 and 1 where                                 on three different corpora.
                                                                                      1649

                          Experiments                                   ments in cluster j0 were from the same group (e.g. ‘liberals’).
                                                                        We averaged the syntactic similarity of document i to cen-
We conducted three experiments to validate CASSIM-GR
                                                                        ter of cluster j and the syntactic similarity of document i to
and to examine the representativeness of the cluster centroids.
                                                                        center of cluster j0. We repeated this procedure k times to
Additionally, we examined how well documents with similar
                                                                        measure the similarity of document i to all k clusters and as-
syntactic structures cluster together and demonstrate the im-
                                                                        signed document i to the cluster with highest similarity score.
portance of syntactic similarity in classification. Further, we
                                                                        If the cluster’s label and document i’s label were the same,
compare the accuracy of syntactic clustering to bag-of-words
                                                                        we would conclude that prediction was successful.
clustering. For this purpose, we use the tf-idf similarity ma-
trix as input to spectral clustering. Lastly, we combined tf-idf        Results Our results demonstrate that CASSIM-GR is able
and CASSIM-GR to see how including both sets of informa-                to accurately cluster the corpus. Following the instruc-
tion affect the classification accuracy. Below, we discuss the          tions discussed in above, we performed leave-one-out cross-
three experiments in detail.                                            validation on 272 documents. In each step, 271 documents
                                                                        were clustered in four groups and later the left-out document
Experiment One                                                          was assigned to one of the four clusters based on its similarity
Experiment one was conducted on a corpus of syntactically               to the center of clusters.
similar documents. The corpus was generated by Amazon                      Following this mechanism, CASSIM-GR yielded 95% ac-
Mechanical Turk participants and consists of four groups of             curacy while tf-idf approach was only 84.5% accurate. Run-
documents; each has high within-group syntactic similarity              ning a chi-squared test demonstrates that CASSIM-GR re-
and low between-group syntactic similarity.                             sults in significantly higher accuracy than tf-idf, X 2 (1) =
   We used CASSIM-GR along with tf-idf, to group docu-                  17.01, p < .001. Since the dataset consists of groups of syn-
ments into clusters. Further, we combined these two ap-                 tactically similar documents, it is not surprising that cluster-
proaches and calculated the overall accuracy. We first intro-           ing based on syntactic structures surpasses the word-based
duce the dataset and then report the results.                           approach and achieves a higher accuracy.
                                                                           Next, we combined the two approaches and obtained an ac-
Data 118 MTurk participants answered a set of four ques-                curacy of 97.8%. While this result is not significantly higher
tions. In each question they were asked to generate sentences           than CASSIM-GR accuracy, X 2 (1) = 2.67, p = .10, we may
with similar grammar rules to the sentence prompts in the               conclude that incorporating syntactic and semantic informa-
question. Each of the four prompts had a different syntac-              tion together could potentially improve clustering accuracy.
tic structure. Later, two independent coders, coded whether a
sentence generated by a participant was grammatically simi-             Experiment Two
lar to its prompt. Sentences which were identified as dissim-
ilar by both coders were excluded from the dataset. Finally,            In the second experiment, we used the Dogmatism Dataset
a total of 272 documents, 68 documents in each group, were              collected by Fast and Horvitz (2016). This dataset includes
collected. See Boghrati et al. (2017) for more details.                 comments from New York Times which are rated based on
   Since participants were asked to write sentences similar to          their level of dogmatism. As explained below, we first cat-
four different sets of prompts, the corpus is therefore divided         egorized the documents as dogmatic or non-dogmatic based
to four separate groups, each associated to a question and its          on this ratings. Next, we followed the procedure which was
responses. Documents which are in the same group are con-               explained in the first experiment and clustered the documents
sidered to have similar syntactic structures.                           using CASSIM-GR and the tf-idf approach. In the following
                                                                        subsections, we first introduce the dataset and then report the
Analysis We performed leave-one-out cross-validation for                results.
both of the clustering techniques. Namely, we ran the anal-
ysis on all the documents except for document i. Next, we               Data The Dogmatism Dataset includes comments from
labeled the clusters with the name of the group to which most           New York Times. Amazon Mechanical Turk participants
of the documents belong. Then, we calculated similarity of              were asked to rate the level of dogmatism of each of the col-
document i to each cluster’s center. Finally, document i was            lected comments on a 5-point Likert scale. More details on
assigned to the cluster with which it had the highest syntac-           the dataset and the annotation process are available at Fast
tic similarity. The classification was considered successful if         and Horvitz (2016).
the assigned cluster’s label and the document’s group were              Analysis Dogmatism is subjective, and consequently inter-
identical.                                                              annotator agreement is higher for comments in both extreme
   We used the following approach to combine tf-idf and                 sides of the spectrum. In other words, human coders tend
CASSIM-GR: First, we used CASSIM-GR and tf-idf ap-                      to agree more on posts rated as very high in dogmatism and
proach separately to cluster documents into k clusters. Clus-           posts rated as very low in dogmatism (Fast & Horvitz, 2016).
ter j, j ∈ [1, k] in tf-idf approach and cluster j0, j0 ∈ [1, k] in     Following the method used by Fast and Horvitz (2016), to
CASSIM-GR were labeled with the same name, that is, the                 have a representative and balanced dataset, we selected the
majority of documents in cluster j and the majority of docu-            top 250 and the bottom 250 documents based on the dogma-
                                                                    1650

                                                    Table 1: Corpora Overview.
                                 Experiment One                     Experiment Two                       Experiment Three
     Corpus                      Syntactically Similar Sentences    Dogmatism in New York Times          Political Weblog Posts
     Number of Groups            4                                  2                                    2
     Number of Documents         272                                500                                  452
                                       Table 2: Accuracy of approaches in three experiments.
                                                 Experiment One       Experiment Two       Experiment Three
                        CASSIM-GR                95%                  54.8%                69.9%
                        TF-IDF Approach          84.5%                61%                  64.4%
                        Combined Approach        97.8%                66.6%                71.9%
                                      Table 3: Comparison of approaches in three experiments.
                                                  Experiment One                Experiment Two              Experiment Three
  CASSIM-GR vs. TF-IDF Approach                   X 2 (1) = 17.01, p < .001     X 2 (1) = 3.94, p < .05     X 2 (1) = 3.13, p = .07
  TF-IDF Approach vs. Combined Approach           X 2 (1) = 29.61, p < .001     X 2 (1) = 3.39, p = .06     X 2 (1) = 5.89, p < .05
  CASSIM-GR vs. Combined Approach                 X 2 (1) = 2.67, p = .10       X 2 (1) = 14.59, p < .001   X 2 (1) = .43, p = .51
tism rating. We labeled the top 250 posts as dogmatic and            and were written in the time frame of the debate, were com-
the bottom 250 as non-dogmatic, hence the final dataset con-         plied. For more details about the dataset and the data collec-
tained 500 posts with 250 in each group.                             tion process please refer to Dehghani, Sagae, et al. (2013).
Results Following the instruction in Experiment 1, we per-           Analysis In this experiment, we randomly selected 250
formed leave-one-out cross-validation; we ran the cluster-           posts from conservative weblogs posts and 250 posts from
ing algorithm with 499 documents and left document i, i ∈            liberal weblogs posts, but due to encoding issues the final
[1, 500], out. Then, we predicted to which cluster document          dataset included 226 posts from each group (total of 452
i belonged. CASSIM-GR and tf-idf approach resulted in                posts).
55% and 61% accuracy respectively. Even though, the tf-idf
approach outperformed our approach significantly, X 2 (1) =          Results Similar to the previous experiments, we used the
3.94, p < .05, combining these two approaches resulted in a          leave-one-out cross-validation procedure described above.
higher accuracy of 66.6%, which is a marginally significant          Specifically, we trained the clustering algorithm on 451 doc-
improvement over the tf-idf accuracy, X 2 (1) = 3.39, p = .06.       uments and predicted to which cluster the left-out document
                                                                     belonged. This process was repeated 452 so that each docu-
   This result provides evidence for the importance of syn-
                                                                     ment was tested once.
tactic structure similarity in clustering documents. It demon-
                                                                        CASSIM-GR was able to successfully predict the correct
strates that not only what different groups of people say, but
                                                                     cluster for a document with 70% accuracy, while tf-idf was
also how they say what they say provide important informa-
                                                                     64.4% accurate. This difference is only marginally signifi-
tion about the characteristics of the group. This is evident by
                                                                     cant, X 2 (1) = 3.134, p = .0767. Next, we combined these
the fact adding syntactic similarity to word-level similarity
                                                                     two approaches as described in the Experiment section. The
can improve the clustering accuracy.
                                                                     total accuracy was 72% which is significantly more accurate
                                                                     than tf-idf approach alone, X 2 (1) = 5.8905, p = .0152.
Experiment Three
                                                                        These results demonstrated that, in some cases, syntac-
In this experiment, we applied CASSIM-GR on a corpus of              tic structures similarity may capture more crucial features
political discussions taken from a set of conservative and lib-      needed for clustering compared to tf-idf approach. However,
eral weblogs, and focus on the discussion about the Ground           there are some features that only tf-idf approach can pick up.
Zero Mosque (Dehghani, Sagae, et al., 2013).                         Thus, the combination of these two sets of features is needed
                                                                     for more accurate clustering.
Data The top five popular conservative and liberal news
blogs were selected according to www.blogs.com. Next, a
dataset of these weblogs posts which contained word mosque
                                                                1651

              Discussion and Future Work                              trees reveals the relationship between the words in a sentence.
                                                                      By incorporating this feature into CASSIM, researchers may
Across three studies, we presented and validated a new
                                                                      further use CASSIM-GR not only to generalize syntactic
approach called CASSIM-GR. CASSIM-GR clusters docu-
                                                                      structure of a group of documents, but also their dependency
ments into separate groups based on their syntactic similar-
                                                                      structures. This extension will help researchers study human
ity and calculates a generalized representation of group-level
                                                                      language in finer grained detail by looking at the relationship
syntax usage by performing four general steps: First, it cre-
                                                                      between words.
ates a syntactic structure similarity matrix of documents using
                                                                         In summary, we introduced a new method for computing
CASSIM. Second, it uses spectral clustering to group the doc-
                                                                      generalized representations of syntactic structures of docu-
uments into a pre-defined number of clusters using the syntac-
                                                                      ments, allowing researchers to distinguish between groups
tic similarity matrix generated in the previous step. Next, the
                                                                      of documents based on syntactic differences. Further, In the
algorithm selects the document which has the highest syntac-
                                                                      three experiments, we demonstrated the benefits of including
tic similarity to the other documents within each cluster and
                                                                      syntactic structure similarity scores in clustering documents.
identifies it as the centroid of that cluster. Finally, it can be
                                                                      In each experiment, we repeated a clustering procedure, once
used to classify unknown documents based on the document’s
                                                                      using CASSIM-GR and once using tf-idf similarity matrix.
syntactic similarity to the clusters’ centers.
                                                                      Then, we calculated clustering accuracy of each approach us-
   We applied CASSIM-GR to three unique corpora (Table 1)
                                                                      ing leave-one-out cross-validation mechanism. Finally, we
across three experiments to compare its accuracy to both a
                                                                      combined the results of these two approaches and calculated
bag-of-words approach and a combined approach incorporat-
                                                                      the accuracy when both sets of features were present. Our re-
ing tf-idf semantic information and CASSIM-GR. As Table 2
                                                                      sults support our assumption and demonstrated that syntactic
demonstrates, tf-idf and CASSIM-GR varied in their relative
                                                                      similarity scores capture different aspects of language com-
strength for clustering accuracy across studies. The combined
                                                                      pared to bag-of-words, and therefore help improve clustering
approach incorporating both syntactic (CASSIM-GR) and se-
                                                                      accuracy.
mantic (tf-idf) information resulted in the highest clustering
accuracy across all three experiments. While not a signifi-                                Acknowledgments
cant improvement beyond both single approaches, the com-
bination approach significantly outperformed tf-idf in two of         This research was supported in part by NSF IBSS Grant
the three experiments and CASSIM-GR in the second experi-             #1520031.
ment. Therefore, we may conclude that word-level similarity
and syntactic similarity capture different aspects of language,                                 References
and consequently, combining the two features’ similarities re-        Boghrati, R., Hoover, J., Johnson, K. M., Garten, J., & De-
sults in more accurate clusters.                                         hghani, M. (2017). Conversation level syntax similarity
   Our results indicate that methods assessing syntactic sim-            metric. Journal of Behavior Research Methods.
ilarity may more accurately cluster documents than methods            Bresnan, J., & Hay, J. (2008). Gradient grammar: An effect of
which rely on semantics alone. While there may be situations             animacy on the syntax of give in new zealand and american
in which groups use the same general words to discuss a topic,           english. Lingua, 118(2), 245–259.
syntactic similarity differences could still allow researchers to     Chalnick, A., & Billman, D. (1988). Unsupervised learning
distinguish between different subsets of individuals.                    of correlational structure. In Proceedings of the tenth an-
   More importantly, CASSIM-GR gives researchers an op-                  nual conference of the cognitive science society (pp. 510–
portunity to study syntactic differences between groups by               516). Hillsdale, NJ: Lawrence Erlbaum Associates.
analyzing the prototypical syntactic structures at the clusters’      Dehghani, M., Bang, M., Medin, D., Marin, A., Leddon, E.,
centers. The syntactic structures used by a cluster’s center             & Waxman, S. (2013). Epistemologies in the text of chil-
document is defined as a generalized representation of syn-              dren’s books: Native-and non-native-authored books. In-
tactic structures of the documents in that cluster. Assessing            ternational Journal of Science Education, 35(13), 2133–
differences in these structures may help to capture underly-             2151.
ing psychological differences between groups in the ways              Dehghani, M., Johnson, K., Hoover, J., Sagi, E., Garten, J.,
that they conceptualize a topic or how they communicate with             Parmar, N. J., . . . Graham, J. (2016). Purity homophily
each other.                                                              in social networks. Journal of Experimental Psychology:
   A vital component of CASSIM-GR is measuring syntactic                 General.
similarity among documents using CASSIM. As mentioned                 Dehghani, M., Sagae, K., Sachdeva, S., & Gratch, J. (2013).
previously, CASSIM’s general focus is on comparing con-                  Linguistic analysis of the debate over the construction
stituency parse trees. Building on CASSIM, we intend to                  of the ground zero mosque. Journal of Information
compare dependency parse trees among sentences and doc-                  Technology & Politics. Advance online publication. doi,
uments to add another syntactic similarity measurement to                10(19331681.2013), 826613.
CASSIM. Unlike constituency parse trees which posit the               Dehghani, M., Sagae, K., Sachdeva, S., & Gratch, J. (2014).
connection between part of speech tags, dependency parse                 Analyzing political rhetoric in conservative and liberal
                                                                  1652

  weblogs related to the construction of the ground zero              fornia, Santa Cruz.
  mosque. Journal of Information Technology & Politics,             Mehl, M. R., Robbins, M. L., & Holleran, S. E. (2012). How
  11(1), 1–14.                                                        taking a word for a word can be problematic: Context-
Fast, E., & Horvitz, E. (2016). Identifying dogmatism                 dependent linguistic markers of extraversion and neuroti-
  in social media: Signals and models. arXiv preprint                 cism. Journal of Methods and Measurement in the Social
  arXiv:1609.00425.                                                   Sciences, 3(2), 30–50.
Feigenbaum, E. A. (1963). The simulation of verbal learn-           Newell, A., & Simon, H. A. (1972). Human problem solving.
  ing behavior. In E. A. Feigenbaum & J. Feldman (Eds.),              Englewood Cliffs, NJ: Prentice-Hall.
  Computers and thought. New York: McGraw-Hill.                     Ohlsson, S., & Langley, P. (1985). Identifying solution paths
Gawda, B. (2010). Syntax of emotional narratives of per-              in cognitive diagnosis (Tech. Rep. No. CMU-RI-TR-85-2).
  sons diagnosed with antisocial personality. Journal of psy-         Pittsburgh, PA: Carnegie Mellon University, The Robotics
  cholinguistic research, 39(4), 273–283.                             Institute.
Graesser, A. C., McNamara, D. S., Louwerse, M. M., & Cai,           Ramirez-Esparza, N., Chung, C. K., Kacewicz, E., & Pen-
  Z. (2004). Coh-metrix: Analysis of text on cohesion and             nebaker, J. W. (2008). The psychology of word use in
  language. Behavior research methods, instruments, & com-            depression forums in english and in spanish: Texting two
  puters, 36(2), 193–202.                                             text analytic approaches. In Icwsm.
Graham, J., Haidt, J., & Nosek, B. A. (2009). Liberals and          Sasaki, M., & Shinnou, H. (2005). Spam detection using text
  conservatives rely on different sets of moral foundations.          clustering. In Cyberworlds, 2005. international conference
  Journal of personality and social psychology, 96(5), 1029.          on (pp. 4–pp).
Hill, J. A. C. (1983). A computational model of language ac-        Sedding, J., & Kazakov, D. (2004). Wordnet-based text doc-
  quisition in the two-year old. Cognition and Brain Theory,          ument clustering. In proceedings of the 3rd workshop on
  6, 287–317.                                                         robust methods in analysis of natural language data (pp.
Jahr, E. H. (1992). Middle-aged male syntax. International            104–113).
  Journal of the Sociology of Language, 94(1), 123–134.             Shi, J., & Malik, J. (2000). Normalized cuts and image seg-
                                                                      mentation. IEEE Transactions on pattern analysis and ma-
Kyle, K., & Crossley, S. A. (2015). Automatically assessing
                                                                      chine intelligence, 22(8), 888–905.
  lexical sophistication: Indices, tools, findings, and applica-
                                                                    Shrager, J., & Langley, P. (Eds.). (1990). Computational
  tion. TESOL Quarterly, 49(4), 757–786.
                                                                      models of scientific discovery and theory formation. San
Lewis, D. D. (1992). Feature selection and feature extraction
                                                                      Mateo, CA: Morgan Kaufmann.
  for text categorization. In Proceedings of the workshop on
                                                                    Song, W., Li, C. H., & Park, S. C. (2009). Genetic algorithm
  speech and natural language (pp. 212–217).
                                                                      for text clustering using ontology and evaluating the valid-
Lewis, D. D., & Croft, W. B. (1989). Term clustering of
                                                                      ity of various semantic similarity measures. Expert Systems
  syntactic phrases. In Proceedings of the 13th annual inter-
                                                                      with Applications, 36(5), 9095–9104.
  national acm sigir conference on research and development
                                                                    Vigliocco, G., & Franck, J. (1999). When sex and syntax go
  in information retrieval (pp. 385–404).
                                                                      hand in hand: Gender agreement in language production.
Lin, Y.-S., Jiang, J.-Y., & Lee, S.-J. (2014). A similarity           Journal of Memory and Language, 40(4), 455–478.
  measure for text classification and clustering. IEEE trans-       Von Luxburg, U. (2007). A tutorial on spectral clustering.
  actions on knowledge and data engineering, 26(7), 1575–             Statistics and computing, 17(4), 395–416.
  1590.                                                             Zheng, H.-T., Kang, B.-Y., & Kim, H.-G. (2009). Exploiting
Liu, L., Kang, J., Yu, J., & Wang, Z. (2005). A com-                  noun phrases and semantic relationships for text document
  parative study on unsupervised feature selection methods            clustering. Information Sciences, 179(13), 2249–2262.
  for text clustering. In Natural language processing and
  knowledge engineering, 2005. ieee nlp-ke’05. proceedings
  of 2005 ieee international conference on (pp. 597–601).
Liu, T., Liu, S., Chen, Z., & Ma, W.-Y. (2003). An evaluation
  on feature selection for text clustering. In Icml (Vol. 3, pp.
  488–495).
Lu, X. (2010). Automatic analysis of syntactic complexity in
  second language writing. International Journal of Corpus
  Linguistics, 15(4), 474–496.
Maass, A., Karasawa, M., Politi, F., & Suga, S. (2006). Do
  verbs and adjectives play different roles in different cul-
  tures? a cross-linguistic analysis of person representation.
  Journal of personality and social psychology, 90(5), 734.
Matlock, T. (2001). How real is fictive motion? Doctoral
  dissertation, Psychology Department, University of Cali-
                                                                1653

