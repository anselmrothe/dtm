      Evidence for overt visual attention to hand gestures as a function of redundancy
                                                     and speech disfluency
                                                    Amelia Yeo (ayeo@wisc.edu)
                                           Department of Psychology, 1202 W. Johnson Street
                                                        Madison, WI 53706 USA
                                          Martha W. Alibali (martha.alibali@wisc.edu)
                                           Department of Psychology, 1202 W. Johnson Street
                                                        Madison, WI 53706 USA
                              Abstract                                McGurk, 1978; Ekman, 2004). Hence, understanding how
   We investigated the effect of gesture redundancy and speech
                                                                      listeners allocate visual attention during the process of face-
   disfluency on listeners’ fixations to gestures. Participants       to-face comprehension is important for understanding the
   watched a speaker producing a redundant or non-redundant           mechanisms involved in the online process of interpersonal
   gesture, while producing fluent or disfluent speech. Eye           communication.
   movements were recorded. Participants spent little time on a          There is some evidence that listeners extend overt visual
   speaker’s gestures regardless of condition. Gesture                attention to a speaker’s gestures (Nobe, Hayamizu,
   redundancy and speech disfluency did not affect listeners’         Hasegawa, & Takahashi, 1997; 2000). In these studies, the
   percentage dwell time to a speaker’s gestures. However,
   listeners were more likely to fixate to a speaker’s gestures       authors presented participants with animations of a speaker
   when they expected the gesture to be non-redundant.                uttering short phrases while making hand gestures, and
   Listeners were also more likely to fixate to a speaker’s           recorded eye movements of the participants during the
   gestures when the speaker was disfluent. Thus, listeners           animations. Participants in the study were found to fixate to
   allocate overt visual attention based on the expected              gestures consistently on most of the videos presented,
   usefulness of a speaker’s gestures, although evidence does not     preferring to fixate to gestures that occurred more slowly. In
   suggest that they spend more time fixating on these gestures.
                                                                      the follow-up study (Nobe et al., 2000), participants were
   Furthermore, listeners are sensitive to disfluency in a
   speaker’s utterance and change how they attend to gestures         found to be able to complete gesture reproduction and
   based on qualities of the speech.                                  comprehension tasks without necessarily fixating to the
                                                                      specific gesture, suggesting that listeners indeed can encode
   Keywords: gesture; eye tracking; communication;
                                                                      aspects of speakers’ gesture without gaze fixations.
   multimodal information processing; spatial features
                                                                      However, this raises the question of why listeners would
                                                                      consistently fixate to speakers’ gestures if comprehension
                          Introduction                                can occur without fixation.
Speakers usually move their hands when conveying a                       In contrast, other studies of visual attention to gesture
message. It seems intuitive to suggest that speakers gesture          have found that listeners rarely fixated to a speaker’s
to communicate information to their audience. Indeed, at              gestures, even when those gestures were essential for
times speakers appear to produce gesture specifically for the         comprehension (i.e., listeners seldom fixated to gestures that
purpose of communicating with the listener (Alibali, Heath            offered information absent from, and thus, non-redundant,
& Myers, 2011).                                                       with speech). Listeners fixated overwhelmingly on the
   During the process of comprehension, listeners integrate           speaker’s face (Gullberg & Holmqvist, 1999, 2006;
speech and gesture (Willems, Özyürek, & Hagoort, 2007).               Gullberg & Kita, 2009; Beattie, Webster, Ross, 2010),
Since co-speech gestures can influence listeners’                     contrary to the findings by Nobe and colleagues (1997;
comprehension of messages, how then do listeners allocate             2000).
visual attention resources to speakers’ gestures? Some                   A possible explanation for the differences found in overt
researchers have argued that the content of gestures could be         visual attention to gestures in these studies is that the speech
perceived peripherally (Gullberg & Holmqvist, 1999). If               content of the speakers in the previous experiments was
true, this would negate the need for listeners to fixate to           vastly different. Some studies used stimuli that contained a
gestures during comprehension. However, gestures have                 narrative element, while other studies used shorter
also been shown to convey additional semantic content not             utterances without a story element, such as “let’s count
found in speech (e.g., McNeill, 1992; Alibali, Evans,                 fingers”. The difference in speech content could have
Hostetter, Ryan & Mainela-Arnold, 2009; Hostetter, 2011).             caused listeners to attend more to the face of the speaker due
Fixating to these gestures could help comprehension.                  to the expectation or existence of emotion cues in the
Communicating in everyday life is often a multimodal                  speaker’s face. Therefore, listeners might spend more time
process that involves auditory input from speech and visual           fixating to non-redundant gestures for speakers if the speech
input from the speaker’s face and body (i.e., MacDonald &             content does not contain a narrative element.
                                                                  3578

   In cases where listeners were found to fixate to a               task and spoke with either disfluency or without disfluency.
speaker’s gestures, numerous factors have been cited as             We hypothesize that listeners will be more likely to fixate to
potentially driving the fixations. These factors include            gestures that are non-redundant with speech. Participants are
whether the speaker fixated upon the gesture, the duration of       predicted to fixate at least once to gestures more often for
the post-stroke hold (i.e., an aspect of the “form” of the          trials with non-redundant gestures than for trials with
gesture) and the location of the gesture in the speaker’s           redundant gestures. Participants are also predicted to spend
gesture space (e.g., Gullberg & Holmqvist, 2006; Gullberg           more time fixating on these gestures. In addition, we also
& Kita, 2009). The focus in the literature has thus been on         hypothesize that listeners will be more likely to fixate to
particular physical features of gestures, with little research      gestures that accompany disfluent speech than to gestures
into the role of listener expectation on overt attention to         that accompany fluent speech. This experiment will also
gestures. Expectations, or predictions, that listeners hold         allow us to examine whether spatial speech free from
about the usefulness of a speaker’s gestures could influence        narrative content provides a context in which listeners
how they attend to the speaker’s gestures. In this study, we        attend less to the speaker’s face. However, if the narrative
examine a higher-level feature of gesture, expected                 nature of the stimuli used in previous studies was not the
redundancy. Keeping all other physical features constant,           reason for the little time listeners spent gazing at gestures,
we test whether the expected redundancy of a speaker’s              then we expect participants in this study will display
gestures will affect how listeners attend to those gestures. If     similarly low durations of fixations to gesture.
listeners do allocate attention differently to gestures
depending on whether they expect the gesture to be useful
for comprehension, then we should see listeners spend more                                    Method
time fixating to gestures and also be more likely to fixate to      Participants
a speaker’s gesture when the gesture offers disambiguating
                                                                    Participants were 30 undergraduate students, all of whom
information absent in speech.
                                                                    reported being native English speakers. They were recruited
   As mentioned above, previous studies that examined
                                                                    from an Introductory Psychology course in exchange for
visual attention to gestures have focused on how physical
                                                                    extra credit.
qualities of a gesture influenced listeners’ fixations. In
multimodal communication, however, elements of speech
can also influence how listeners attend to a speaker’s              Materials
gestures based on existing expectations. To date, no study to       There were two sets of stimuli: shape arrays and speaker
our knowledge has examined the role of speech disfluencies          videos. We created four pairs of shape arrangements using
on listeners’ fixations to a speaker’s gestures. Disfluencies       Microsoft PowerPoint, giving eight arrays in total. Each of
such as filled pauses cause a break in speech content and           these eight arrays was repeated twice in the experiment,
can occur at several points in speech (Ferreira & Bailey,           once paired with a speech-fluent video and once paired with
2004). A filled pause (i.e., um) that occurs in the middle of a     a speech-disfluent video. Thus, there were sixteen target
clause has been linked to the need for the speaker to select        trials in total.
an option for production from among several competing                  Each pair of shape arrays was identical in every aspect
choices (Clark & Fox Tree, 2002). Listeners were more               except for a single shape. In the arrays used for the gesture
likely to remember a word when it was preceded by a filled          redundant condition, only one triangle was present. In the
pause (Corley, MacGregor & Donaldson, 2007), suggesting             arrays used for the gesture non-redundant condition, two
that a filled pause could give rise to expectation in listeners     triangles were present. Thus, to create the arrays for the
that what is to follow is important, signaling listeners to         gesture non-redundant condition, one of the non-triangle
allocate more attentional resources to encode what follows          shapes in the arrays for the gesture redundant condition was
from it. When listeners hear an “um” from a speaker, they           replaced with a triangle (Fig. 1).
might also be more likely to fixate to the speaker’s gesture
space when the disambiguating information might be
produced in gesture as compared to a situation where there
is no need for disambiguation.                                         Figure 1. An example of a shape array in the gesture
   In this study, we examine the effect of gesture redundancy       redundant condition (left) and in the gesture non-redundant
(i.e., whether a gesture is useful for disambiguating between       condition (right).
two options) and speech disfluency on listeners’ visual
attention to gesture. To do this, we conducted a 2 by 2 fully          Next, we created eight videos, four featuring fluent
within-subjects      experiment,      manipulating      gesture     speech and four featuring disfluent speech. Each video
redundancy and speech disfluency. We recorded the gaze              lasted approximately six seconds and showed a speaker
fixation data (i.e., how long each participant fixated and          describing a triangle according to a script, while facing the
how many fixations) of each participant as they watched a           camera (Fig. 2). In the videos with fluent speech, the
video of a speaker on each trial. The speaker produced              speaker produced an utterance, such as “the triangle
either redundant or non-redundant gestures for a following          changed color and turned green”. In videos with disfluent
                                                                    speech, the speaker produced an utterance with the “um”
                                                                3579

disfluency, for example, “the, um, triangle changed color                 was about gesture or speech disfluency.
and turned green”. In the other of these eight videos, the                   During the experiment, each participant viewed 26 trials
actor produced exactly the same utterance except with a                   presented in random order using Experiment Builder from
different color (e.g., orange/red/yellow instead of green).               SR Research (Canada). Each trial contained a shape array
We created the videos such that there were fluent and                     that was presented onscreen for 5 seconds, followed by a
disfluent pairs containing the same utterance that differed               video of the speaker describing the color change occurring
only in the inclusion, or exclusion, of the disfluency “um”.              to a triangle in the array. The video was programmed to start
In addition, the speaker produced four types of gestures that             automatically. After the video, participants were presented
were paired with corresponding shape arrays. These                        with four options of shape arrays and were instructed to say
gestures referred to the triangle that was undergoing the                 aloud the option that fit the description of the speaker in the
color change. Thus, in the gesture non-redundant condition,               video. For example, if a trial presented the array in the
the gesture functioned to disambiguate the target triangle                gesture non-redundant, speech fluent condition (e.g., the
from the other triangle in the array. In each video, the                  array on the right in Fig. 1) followed by a video of the
speaker’s gesture depicted either the pointed tip of the                  speaker producing an upward-pointing gesture (Fig. 2)
triangle (pointing up or down), or the relative placement of              while saying, “the triangle changed color and turned green”,
the triangle in the shape array (located high in the array or             the correct option (in Fig. 3) to select would be option C.
located above a line). Each gesture was scripted such that                   The trials in the gesture non-redundant, speech disfluent
the actor began forming the gesture just before the word                  condition were identical except that the speaker produced a
“triangle” in the utterance and held the gesture for                      filled pause, for instance, “the um, triangle changed color
approximately 2 seconds before dropping her hands. In each                and turned green”. Thus, gesture redundancy was
video, the actor produced only one gesture and gazed at the               manipulated by having either one or two triangles in the
camera for the duration of the video.                                     shape array.
Figure 2. Screen capture of the speaker producing a gesture               Figure 3. Example of four response options in the gesture
of an upward-pointing triangle.                                           non-redundant conditions.
   We also created shape arrays and speaker videos for filler                An example of a trial in the gesture redundant, speech
trials. The purpose of the filler trials was to present the               fluent condition would be the left array in Figure 1 followed
participant with variation in the speaker videos so as to                 by a video of the speaker producing an upward-pointing
reduce the chances of the participant inferring the purpose               gesture (Fig. 2) while saying, “the triangle changed color
of the study. These filler trials contained an assortment of              and turned green”. The four response options would then
videos where the speaker did not gesture, or gestured while               contain the same shapes as in the original array but with the
producing a slightly different utterance, such as “the orange             single triangle colored in four different colors. The trials in
triangle changed color and turned green”. There were ten                  the gesture redundant, speech disfluent condition were
filler trials in total. The eight target trials and the filler trials     identical except that the speaker produced a filled pause, for
all contained the same actor wearing the same clothing.                   instance, “the um, triangle changed color and turned green”.
                                                                          Thus, gesture redundancy and speech disfluency were
Procedure                                                                 perfectly orthogonal.
Participants were tested individually. Each participant was                  Each participant’s verbal response for each trial was
seated in front of a computer screen and a desk-mounted                   recorded with a microphone that was clipped on to his or
Eyelink 1000 eye tracker camera. The eye tracker recorded                 her clothing. The verbal responses were recorded to audio
real-time fixations of each participant throughout the entire             files in the computer. At the end of the experiment,
experiment and was calibrated for each participant before                 participants were debriefed and asked if they could guess
the trials began.                                                         the purpose of the study. None of the participants correctly
   Before the experiment, participants were told that the                 stated the hypothesis about gesture redundancy or speech
speaker would always describe a color change of a triangle                disfluency on listeners’ fixation to a speakers’ gestures.
in the array. Thus, participants began the experiment                     Throughout the whole procedure, an experimenter sat in a
knowing that it would always be a triangle that changed                   corner in the room unobtrusively and had no interaction
color. They were not told that the speaker would gesture;                 with the participant. The whole experiment lasted for about
participants were not informed in any way that the study                  20 minutes.
                                                                      3580

Coding                                                               We analyzed these data using a binomial multilevel model
Each video was divided into interest areas for eye tracking       with gesture redundancy and speech disfluency as fixed
analysis. The speaker’s face was a separate interest area         effects and participant as a random effect. The dependent
from her gesture space. The fixations of interest for this        variable was whether the participant had fixated to the
study were those that occurred to the speaker’s gestures          speaker’s gesture space (yes/no). The mean proportion of
from the start to the end of her utterance, since her gestures    trials on which participants fixated at least once to the
always occurred as she was speaking. Fixation data that           speaker’s gesture space is displayed as a function of gesture
included each dwell time on each area and number of               redundancy (Fig. 4) and speech disfluency (Fig. 5).
fixations was then exported from Data Viewer (SR
Research) for analysis. For each trial, we thus obtained data
regarding how long a participant fixated to the speaker’s
face, how long a participant fixated to the speaker’s gesture
space, how many fixations a participant made to the
speaker’s face and how many fixations a participant made to
the speaker’s gesture space.
                           Results
Averaging across all conditions, participants spent the
majority of the time fixated on the speaker’s face, spending      Figure 4. Proportion of trials on which participants had at
only 9.3% of the time fixating on the speaker’s gestures.         least one fixation to the speaker’s gesture space as a
   Table 1 displays the average percentage dwell time spent       function of gesture redundancy. Error bars are ±SE.
by participants on the listeners’ gestures across conditions.
We conducted two-way within-subjects analysis of variance
on the average percentage dwell time spent fixating on the
speaker’s gestures as a function of gesture redundancy and
speech disfluency. There was no significant main effect of
gesture redundancy, F (1, 112) = 1.34, p = 0.25, nor was
there a significant main effect of speech disfluency, F < 1,
p = .66.
   There was also no significant interaction between gesture
redundancy and speech disfluency on participants’ dwell
time to speaker’s gestures, F (1, 112) = 2.30, p = .13. Even
though participants on average spent a higher percentage of
dwell time on non-redundant gestures, this difference was         Figure 5. Proportion of trials on which participants had at
not significant.                                                  least one fixation to the speaker’s gesture space as a
                                                                  function of speech disfluency. Error bars are ±SE.
Table 1. Average dwell time % to the speaker’s gestures as
   a function of gesture redundancy and speech disfluency.           Listeners were significantly more likely to fixate to the
                                                                  speaker’s gesture in the gesture non-redundant condition
                                   Gesture                        than in the gesture redundant condition, Wald’s z = 3.06, p <
         Speech          Redundant       Non-redundant            .01, odds ratio = 2.41. Additionally, listeners were
       Disfluent            7.33               10.1               significantly more likely to fixate to the speaker’s gesture in
         Fluent             9.02               10.8               the disfluent speech condition than in the fluent speech
                                                                  condition, Wald’s z = 2.21, p = .027, odds ratio = 1.88.
   Since participants overwhelmingly fixated to the               There was no significant interaction between gesture
speaker’s face in this experiment, we wanted to examine           redundancy and speech disfluency on the likelihood of
whether gesture redundancy and speech disfluency affected         participants fixating to a speaker’s gesture, Wald’s z = 1.35,
the likelihood of participants fixating at least once to the      p = .18. In sum, participants were more likely to fixate at
speaker’s gestures. To test whether participants were more        least once to non-redundant gestures, and they were also
likely to fixate to a speaker’s gestures as a function of         more likely to fixate at least once to the speaker’s gestures
gesture redundancy or speech disfluency, we classified            when the speaker was disfluent.
whether each participant fixated on the video speaker’s
gesture space at least once while the speaker was talking.                                  Discussion
Thus, the outcome variable for this analysis was                  The finding that participants spend little time fixating to a
dichotomous, i.e., whether or not the participant fixated at      speaker’s gestures reflects the results from some past
least once to the speaker’s gesture in each trial.                studies. For example, Gullberg and Kita (2009) reported that
                                                                  listeners fixated on gestures only 8% of the time, even
                                                              3581

though these gestures were first fixated by the speaker,            redundant conditions, our findings imply that top-down
showing that gesture fixation duration was low even                 factors such a redundancy can influence listeners’ visual
when there was social impetus (i.e., directed gaze) to fixate       attention to gestures beyond the physical characteristics of
at a gesture. Our findings align with this value. Listeners         those gestures. Few studies to date have explored the role of
fixated to gestures on average about only 10% of the time,          higher-level cognitive factors, such as expectations, on how
even for gestures that contained information not present in         listeners process gestures. For example, individuals could
the speaker’s utterance. These findings do not support the          hold expectations about the usefulness of gesture based on
hypothesis that the previously reported low fixation                an individual’s communicative fluency, or individual’s
durations on gestures were due to the narrative element in          communicative style. A further direction would be to
speech. Instead, listeners fixate overwhelmingly on the             examine how these factors influence how listeners attend to
speaker’s face even when the narrative element in speech is         gestures.
absent or greatly reduced.                                             In this study, we also found support for the hypothesis
   However, we do not yet know if listeners direct so little        that speech disfluency causes listeners to be more likely to
overt visual attention to gesture because of the                    attend to gestures during communication. These findings
communicative context. Past studies, including this one,            support the idea that disfluencies in speech can function as a
have featured speakers passively describing objects or              signal to listeners on how to direct their cognitive resources
actions. Although strengths of this paradigm are its                during comprehension. However, we did not find support
simplicity and ease of experimental control, a limitation is        for the hypothesis that listeners spent more time fixating to
that it tells us little about how people attend to each other’s     gestures that co-occurred with disfluent speech as compared
gestures when they are engaging in dialogue. During                 to gestures that occurred with fluent speech. Once again, it
dialogue, speakers gesture differently depending on the             is possible that listeners quickly obtained information from
feedback they receive from the listener (Holler & Wilkin,           gestures. If filled pauses in speech do indeed work as a
2011). This finding reflects observations of research               signal for cross-modal attention shifts, future work could
involving instructional gestures. In the classroom, teachers        examine if how other forms of speech disfluencies (e.g.,
have been found to gesture more when students lack                  false starts) influence visual attention to a speaker’s
understanding of the lesson (Alibali et al., 2013). Further         gestures.
research could explore how listeners attend to gestures in an          As with any investigation, there are some limitations to
instructional setting or in dialogue, using a wearable eye          this experiment. Due to convenience sampling, our sample
tracker.                                                            was comprised of college undergraduates. Undergraduates
   As predicted, participants were more likely to fixate to         could offer little variation in terms of cognitive skills as
non-redundant gestures than to redundant gestures. This             compared to the population at large. While little published
finding implies that listeners preferentially direct overt          research to date exists examining the role of individual
visual attention to gestures that they expect to be useful for      differences in cognitive skills on attention to gestures, there
comprehension. Listeners direct overt attention to a                is evidence suggesting that people produce gestures
speaker’s gestures more often when the gesture conveys              differently due to individual differences in spatial abilities
relevant information not present in speech, implying that           (Hostetter & Alibali, 2007; 2011). It may be the case that
listeners generate expectations about the perceived                 listeners with vastly different spatial skills could process a
importance of the speaker’s gestures and direct attention           speaker’s gestures differently. One way to address this
accordingly. However, we did not find support for the               would be to administer measures of verbal and spatial skills
hypothesis that listeners would spend more time fixating to         to undergraduate participants in future studies. Another way
a speaker’s gestures. While listeners were more likely to           to address this limitation would be to recruit participants
gaze at least once to the speaker’s non-redundant gestures,         outside of the undergraduate pool.
they did not spend more time dwelling on those gestures,               Our participants were English speakers in the Midwestern
implying that the additional fixations to non-redundant             USA, thus the results might not generalize to speakers of a
gestures occurred very quickly. A potential explanation for         different language or culture. Past studies on visual attention
this behavior is that visual information from fixated gestures      to gestures have sampled from English-speaking students in
is gleaned very quickly, making it unsurprising that fixation       the United Kingdom (Beattie, Webster & Ross, 2010),
durations across conditions did not differ significantly.           Dutch-speaking students (Gullberg & Kita, 2009) and native
   On the surface, it might be unsurprising that listeners are      Swedish speakers (Gullberg & Holmqvist, 2006).
less likely to fixate to gestures that are redundant. This          Consistently low fixation durations to gesture across these
study demonstrates that listeners are less likely to fixate to      samples appears to suggest that the effect is generalizable.
gestures that are redundant even when those gestures are            However, Nobe and colleagues (1997; 2000) sampled from
holds (i.e., the form of the gesture is held in a pause) and        Japanese speakers, raising the question of whether the
occur in the center of the speaker’s body, qualities that were      difference in attention to gestures of a speaker is partly due
reported to best attract listeners’ fixations (e.g., Gullberg &     to cultural norms.
Holmqvist, 1999; 2006) Since we controlled for these                   For instance, Graham and Argyle (1975) found that
features across the gesture redundant and gesture non-              Italian speakers were better able to decode shapes being
                                                                3582

described by the speaker when gesture was produced, in                  Clark, H. H. & Fox Tree, J. E. (2002). Using uh and um in
contrast to English speakers. If speakers’ gestures possess          spontaneous speaking. Cognition, 84, 73-111.
different utility value to listeners depending on the                   Corley, M., MacGregor, L. J. & Donaldson, D. I. (2007).
language, we might expect listeners to attend to gestures            It’s the way you, er, say it: Hesitations in speech affect
differently too. Further research should test the assumption         language comprehension. Cognition, 105, 658-668.
that listeners’ processing of speakers’ gestures is universal.          Ekman, P. (2004). Emotional and conversational
There are undoubtedly common processes involved in                   nonverbal signals. In Language, knowledge, and
multimodal communication across humans, but cultural                 representation (pp. 39-50). Springer Netherlands.
norms in communication or in the use of hand gestures                   Ferreira, F. & Bailey, K. G. D. (2004). Disfluencies and
could also influence how listeners process these gestures.           human language comprehension. Trends in cognitive
   Another limitation of this study involves the nature of           sciences, 8, 231-237.
scripted disfluencies. When disfluencies are produced                   Graham, J. A., & Argyle, M. (1975). A cross-cultural
naturally, they could be accompanied by changes in speech
rate, tone of voice, or changes in facial expression. Having         study of the communication of extra-verbal meaning by
an actor utter a statement with a scripted disfluency across         gestures. International Journal of Psychology, 10(1), 57-
multiple trials is unnatural. While this choice was made to          67.
reduce stimuli variability, further research could use videos           Gullberg, M., & Holmqvist, K. (1999). Keeping an eye on
of speakers conversing naturally and examine the gaze of             gestures: Visual perception of gestures in face-to-face
listeners when disfluency occurs naturally.                          communication. Pragmatics & Cognition, 7(1), 35-63.
   In conclusion, these findings provide another perspective            Gullberg, M., & Holmqvist, K. (2006). What speakers do
on the question of how listeners process gestures. We show           and what addressees look at: Visual attention to gestures in
that listeners are more likely to fixate to a speaker’s gestures     human interaction live and on video. Pragmatics &
when those gestures are non-redundant, after controlling for         Cognition, 14(1), 53-82.
physical properties of gesture that have been reported to               Gullberg, M., & Kita, S. (2009). Attention to speech-
capture the attention of listeners. We also demonstrate that         accompanying gestures: Eye movements and information
speech disfluencies can act as signals for listeners to shift        uptake. Journal of nonverbal behavior, 33(4), 251-277.
attention multimodally. These findings highlight the causal             Holler, J., & Wilkin, K. (2011). An experimental
role of expectations in how listeners attend to speakers’            investigation of how addressee feedback affects co-speech
gesture.                                                             gestures accompanying speakers’ responses. Journal of
                                                                     Pragmatics, 43(14), 3522-3536.
                     Acknowledgments                                    Hostetter, A. B., & Alibali, M. W. (2007). Raise your
We thank Maia Ledesma and Kayla Diffee for assistance                hand if you’re spatial: Relations between verbal and spatial
with production of stimuli, Youn Ku Choi for assistance              skills and gesture production. Gesture, 7(1), 73-95.
with data collection, and Mitchell Nathan and Virginia                  Hostetter, A. B. (2011). When do gestures communicate?
Clinton for assistance with the eye tracker. We also thank           A meta-analysis. Psychological bulletin, 137(2), 297.
Marianne Gullberg for helpful comments during                           Hostetter, A. B., & Alibali, M. W. (2011). Cognitive
presentation of a version of this work at the conference of          skills and gesture–speech redundancy: Formulation
the International Society for Gesture Studies in Paris.              difficulty or communicative strategy?. Gesture, 11(1), 40-
                                                                     60.
                                                                        MacDonald, J., & McGurk, H. (1978). Visual influences
                          References                                 on speech perception processes. Attention, Perception, &
   Alibali, M. W., Heath, D. C., & Myers, H. J. (2001).              Psychophysics, 24(3), 253-257.
Effects of visibility between speaker and listener on gesture           McNeill, D. (1992). Hand and mind: What gestures
production: Some gestures are meant to be seen. Journal of           reveal about thought. University of Chicago Press.
Memory and Language, 44(2), 169-188.                                    Nobe, S., Hayamizu, S., Hasegawa, O., & Takahashi, H.
   Alibali, M. W., Evans, J. L., Hostetter, A. B., Ryan, K., &       (1997, September). Are listeners paying attention to the
Mainela-Arnold, E. (2009). Gesture–speech integration in             hand gestures of an anthropomorphic agent? An
narrative: Are       children      less      redundant      than     evaluation using a gaze tracking method. In International
adults?. Gesture, 9(3), 290-311.                                     Gesture      Workshop (pp.     49-59).     Springer   Berlin
   Alibali, M. W., Nathan, M. J., Church, R. B., Wolfgram,           Heidelberg.
M. S., Kim, S., & Knuth, E. J. (2013). Teachers’ gestures               Nobe, S., Hayamizu, S., Hasegawa, O., & Takahashi, H.
and speech in mathematics lessons: Forging common                    (2000). Hand gestures of an anthropomorphic agent:
ground by resolving trouble spots. ZDM, 45(3), 425-440.              Listeners' eye fixation and comprehension. Cognitive
   Beattie, G., Webster, K., & Ross, J. (2010). The fixation         Studies, 7(1), 86-92.
and processing of the iconic gestures that accompany talk.              Willems, R. M., Özyürek, A., & Hagoort, P. (2007).
Journal of Language and Social Psychology, 29(2), 194-               When language meets action: The neural integration of
213.                                                                 gesture and speech. Cerebral Cortex, 17(10), 2322-2333.
                                                                 3583

