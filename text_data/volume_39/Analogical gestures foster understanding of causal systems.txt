Analogical gestures foster understanding of causal systems
Kensy Cooperrider (kensy@uchicago.edu)
Department of Psychology, 5848 S. University Avenue
Chicago, IL 60637 USA

Dedre Gentner (gentner@northwestern.edu)
Department of Psychology, 2029 Sheridan Road
Evanston, IL 60208 USA

Susan Goldin-Meadow (sgm@uchicago.edu)
Department of Psychology, 5848 S. University Avenue
Chicago, IL 60637 USA
Abstract

example, in a simple two-factor positive feedback system,
an increase in one causal factor causes an increase in a
second factor, which in turn causes an increase in the first
factor; in a negative feedback system, an increase in one
causal factor causes an increase in a second factor, which
then causes a decrease in the first factor. The challenge such
systems present for a learner are considerable: To notice, for
instance, the abstract causal likeness between human
perspiration and a flush toilet—i.e., that both involve
negative feedback—one has to look past a host of
visuospatial and sensory differences between the two. One
way that expertise in noticing such causal patterns comes
about is through repeated opportunities to compare
examples across domains, as happens over an extended
science education (Rottman et al., 2012). Indeed, such a
process can be induced in the laboratory by having learners
analogically compare disparate examples of causal systems
(Goldwater & Gentner, 2015), much as comparison can
promote relational learning more generally (Christie &
Gentner, 2010; Doumas & Hummel, 2013; Gentner,
Loewenstein, Thomspson, & Forbus, 2009; Gick &
Holyoak, 1983; Jung & Hummel, 2011; Kotovsky &
Gentner, 1996; Kurtz, Boukrina, & Gentner, 2013).
Here we explore a less-studied route through which it
may be possible to foster causal understanding: analogical
gestures. In previous work, we found that, people produce
gestures in abundance when explaining feedback systems
(Cooperrider, Gentner, & Goldin-Meadow, 2016). These
gestures were analogical in that they used space, not to
represent concrete spatial details, but to represent relational
structure: they used locations to distinguish causal factors,
motion to show increases and decreases to those factors and
causal relationships between them, and complex movements
to summarize the overall relational structure of the systems.
Strikingly, these gestures occurred in abundance even
though participants were explaining systems that were not
inherently spatial and were, by design, devoid of the kinds
of concrete details that usually prompt gestures. These
laboratory findings provide insights into how people express
spatial analogies in gesture, and also raise an important
further question: Might using such analogical gestures
during instruction foster understanding of causal patterns?

Sensitivity to the causal structure underlying phenomena is
critical to expert understanding. Fostering such understanding
in learners is therefore a key goal in education. We
hypothesized that observing analogical gestures—which
represent relational information in visuospatial format—
would lead learners to notice and reason about underlying
causal patterns, such as positive and negative feedback.
Participants watched brief video lectures about the human
body and the plant kingdom, which were delivered along with
gestures representing either: 1) visuospatial details (iconic
gesture condition); or 2) relational structure (analogical
gesture condition). In a subsequent classification task, relative
to participants who saw iconic gestures, participants who saw
analogical gestures were more likely to sort the phenomena
described in the videos—as well as novel phenomena—by
their causal structure (e.g., positive feedback). The results
suggest that analogical gestures can be harnessed to foster
causal understanding.
Keywords: analogy; relational reasoning; gesture; learning;
complex systems

Introduction
A deep understanding of any complex phenomenon—from
the ebb and flow of the tides, to the rise and fall of blood
pressure—requires an understanding of the causal structure
that gives rise to it (Lagnado, Waldmann, Hagmayer, &
Sloman, 2007; Mackie, 1980; Sloman, 2005). Yet this is no
trivial task. The causal relations that govern phenomena
throughout the physical and social world are often
embedded in a wealth of concrete, causally irrelevant
particulars (e.g., Rottman, Gentner, & Goldwater, 2012).
Thus a key question for cognitive scientists and educators
alike is: How do people come to understand causal
structure, and how can we foster this understanding?
We focus here on an important arena of causal
understanding: namely, causal systems—abstract patterns of
causation, such as positive and negative feedback, that occur
in a wide range of phenomena (Fernbach & Sloman, 2009;
Rottman, Gentner, & Goldwater, 2012; see also Day, Motz,
& Goldstone, 2015). Feedback systems can be found in the
human body, in household appliances, in economic markets,
and in plant physiology, to name just a few domains. For

240

Figure 1: A selection of gestures from one of the video explanations, describing the phenomenon of anxiety attacks. In the
version seen by participants in the iconic condition, all the gestures represented concrete aspects of the phenomenon (panels
a, b, and d); in the version seen in the analogical condition, the gestures represented the two causal factors (e) and the
pattern of increase and decrease to those factors (f and h). For all phenomena, the contrasting versions of the explanations
used the same number of gestures, included beat gestures in the same places (c and g), and used an identical audio track.
Gesture is ubiquitous in everyday conversation as well as
in the classroom (Goldin-Meadow, 2003). Despite being
more implicit than speech (McNeill, 1992), gesture is an
important medium for communicating ideas (Hostetter,
2011), including abstract ideas about relational structure
(Jamalian & Tversky, 2012). Moreover, gesture has been
found to boost learning in a range of content domains (Ping
& Goldin-Meadow, 2008; Singer & Goldin-Meadow, 2005;
Valenzeno, Alibali, & Klatzky, 2003). While prior studies
have focused on gesture’s consequences for young learners,
gestures conveying abstract concepts have also been attested
in lectures to older students, in disciplines ranging from
literary studies to mathematics (Corts, 2006; Mittelberg,
2008; Núñez, 2008).
Importantly,
the
gestures
used
in
everyday
communication and the classroom come in different
varieties, and may not all be equally effective in conveying
ideas about causal structure. A first type is iconic gestures.
These are produced in the course of explaining concrete,
visuospatially rich content, and are used to represent size
and shape, location, motion, and spatial relationships
(Alibali, 2005; Alibali & Hostetter, 2008; McNeill, 1992). A
second type of gesture is more abstract, using location,
motion, and spatial relationships to represent ideas and
relationships that are not inherently spatial. Such gestures
include those described in our prior work on explanations of
feedback systems (Cooperrider, et al., 2016), and also a
range of other content domains (Cienki & Muller, 2008;
Cooperrider & Goldin-Meadow, 2017; Goldin-Meadow,
2003). It is this latter type—analogical gestures—that we

predict would lead observers to notice and reason about
causal structure. Iconic gestures, by contrast, may have no
effect on causal understanding, or may even hinder it by
highlighting concrete particulars.
In the present study, we test the idea that analogical
gestures can be used to foster understanding of causal
systems—patterns which are often buried beneath concrete
particulars. To this end, we created two sets of short video
lectures: one in which an actor accompanies his
explanations of phenomena in the human body and plant
kingdom with iconic gestures that depict concrete
visuospatial details (iconic gesture condition); another in
which the actor accompanies his explanations with
analogical gestures depicting relational structure (analogical
gesture condition). We hypothesized that participants in the
analogical gesture condition would be more likely to notice
the underlying causal structure of the phenomena described
in the lectures and, moreover, that these participants would
be more likely to discern causal structure when
encountering novel phenomena.

Methods
Participants
60 undergraduate students from Northwestern University
participated in exchange for course credit. 15 participants
were eliminated for failing a video comprehension check
(described below), and two were eliminated for admitting
during debriefing that they listened to the audio but did not
watch the screen. In all, 43 participants (21 iconic condition,

241

22 analogical condition; 24 men; M age = 18.7 years) were
included in the analyses.

mutually exclusive: all four novel phenomena and two of
the familiar ones (blood pressure, bracken fern). The other
two familiar phenomena (anxiety, prayer plants) shared the
same combination of domain and causal structure as the
seed phenomena (e.g., anxiety attacks and blood clotting are
both in the domain of the human body and both positive
feedback systems).

Materials and procedure
Video Stimuli Drawing on materials from prior studies
(Rottman et al., 2012; Smith & Gentner, 2014), we
developed short descriptions of four phenomena: anxiety
attacks (a positive feedback system within the domain of the
human body); blood pressure regulation (negative feedback,
human body); bracken fern growth (positive feedback, plant
kingdom); and prayer plant cycles (negative feedback, plant
kingdom). The descriptions balanced concrete details (e.g.,
for the anxiety attacks description: the “heart feeling like it
is pounding”) with clues to causal structure (“this will lead
to even more intense symptoms”). We filmed an actor
delivering each of these (~45 sec) explanations in two
versions: one with iconic gestures depicting concrete aspects
of the phenomenon described, and one with analogical
gestures representing the causal factors involved in the
phenomenon and the behavior of those factors (Fig. 1). The
iconic gestures were based on the actor’s intuitions about
what would be most natural; the analogical gestures were
inspired by the gestures produced spontaneously by
participants when describing highly abstract versions of
feedback systems (Cooperrider et al., 2016). For each
phenomenon, the two versions had the same number of
target—i.e., iconic or analogical—gestures (5-7 per
explanation), as well as the same number of beat gestures
(2-3), which were included to make the explanation more
naturalistic. Finally, to control for differences in prosody,
the audio track of the actor speaking was identical in the two
versions. This was achieved by: 1) recording a primary
audio track, 2) filming the actor talk and gesture in sync
with the primary track while it played, 3) aligning the video
with the primary track and removing the secondary audio.

Other Assessments Participants completed two further
assessments of causal system understanding: a battery of
inference questions and a diagram task. Both concerned
only the four phenomena familiar from the videos. For the
inference battery, participants answered eight questions (two
per phenomenon) querying general behaviors of—and
predictions about—the systems described. For the diagram
task, participants were shown contrasting diagrams of
positive and negative feedback, with a detailed explanation
of the symbols used (e.g., plus and minus signs).
Participants were then asked to match each of the videos
seen previously to the correct diagram.
Procedure All video stimuli and assessments were
implemented in Qualtrics and displayed on a desktop
computer. The experiment started with a brief video
introduction by the lecturer, which was the same for both
conditions. Participants then watched the four videos in a
fixed order, in the versions corresponding to their condition
assignment, i.e., for a participant in the iconic condition, the
iconic gesture versions of all four explanations. After
watching each video, participants answered two multiplechoice questions about their basic content (e.g., which
symptoms of anxiety were mentioned). These questions
were intended as an attention check, and participants who
got one or more wrong were excluded.
After the final video, participants proceeded to the
classification task. The seed phenomena were presented as
fixed blocks of text on the screen; the to-be-classified
phenomena were presented, one at a time, on moveable
digital “cards.” Participants were instructed to: “Decide
which of the descriptions [i.e., the seed phenomena] the card
[i.e., the to-be-classified phenomenon] is most similar to,
and drag it to that pile.” The eight phenomena were
presented in a fixed order, with the four novel ones first,
followed by the four familiar ones. We had participants sort
the novel phenomena first to encourage them to think deeply
about the task, rather than sort by first impulse. After the
classification task, participants completed the inference
question battery and the diagram task, both in a fixed order,
and were debriefed. In all, the task took around 20 minutes.

Classification Task We developed a phenomenon
classification task inspired by the Ambiguous Sorting Task
(AST) used in prior studies (Rottman et al., 2012;
Goldwater & Gentner, 2015). Participants were first
presented with written descriptions of three new
phenomena: blood clots (positive feedback, human body);
spotted knapweed growth (negative feedback, plant
kingdom); and internet routers (common cause, technology).
These three phenomena served as the “seed” categories into
which further descriptions would have to be classified. The
central feature of the task, as with the AST variants used
previously, is that nature of the categories is up to the
participant to decide: the seed phenomena represent three
different domains as well as three different causal structures,
thus affording both kinds of classification.
After reviewing the seed phenomena, the participant
classified eight further written descriptions, one at a time.
Four of these were descriptions of novel phenomena; the
other four were written versions of the videos watched
earlier. Note that only six of the phenomena were “critical”
in that classifying by domain and by causal structure were

Results
Classification Task
Our primary measure was the mean proportion of
phenomena that participants classified by domain (human
body, plant kingdom, or technology), by causal structure
(positive feedback, negative feedback, or common cause),

242

Other assessments
Inference Question Battery Participants in both conditions
answered the majority of inference questions correctly and
at close to ceiling, with no difference between the
conditions (iconic: M = .90, SD = .12; analogical: M = .86,
SD = .13, t = -1.09, df = 41, p = .28).
Diagram Task Participants in both conditions answered the
majority of diagram questions correctly and at close to
ceiling, but with those in the analogical gesture condition
performing marginally better (iconic: M = .80, SD = .19;
analogical: M = .89, SD = .13, t = 1.82, df = 41, p = .08).

Discussion
The present study investigated the hypothesis that seeing
certain types of gestures would lead observers to notice and
understand causal structure. Specifically, we expected that
analogical gestures, which represent relational structure
spatially, would foster understanding of causal structure
better than would iconic gestures, which represent concrete
visuospatial details. This hypothesis was borne out.
Participants in the analogical gesture condition noticed the
causal structure of the phenomena described in videos, and
were also more likely to notice causal structure in entirely
new phenomena. Given the design of our classification task,
this was no easy feat. To classify by causal structure,
participants had to look past compelling differences of
content to find deeper similarities, or look past compelling
content similarities to discern deeper differences. Our prior
work showed that people spontaneously produce analogical
gestures when explaining causal systems; the current study
builds on these findings to show that such analogical
gestures have important consequences for learning.
Our leading interpretation of the present findings, again,
is that observing analogical gestures led participants to
notice and reason about causal structure. A second—and not
mutually exclusive—possibility is that the concrete gestures
in the iconic condition hindered participants from the
discerning the underlying relational structure by lavishing
them with vivid details. Follow-up studies with a “no
gesture” control condition would clarify whether our two
gesture conditions are indeed pulling observers in opposite
directions or, if not, which gesture type is driving the
observed pattern of results. This question is of clear
theoretical interest, but we also note that, in teaching
contexts, gesture is ubiquitous, perhaps even inevitable.
Thus, from a practical perspective, the important question is
not whether teachers should gesture about the phenomena
they are explaining, but how. Our results suggest that iconic
gestures, as natural as they are, may not always be the best
choice. It may be that the best instructors already intuit this,
using gestures that highlight relational structure when
possible.
By what specific mechanism(s) did analogical gestures
have their beneficial effects? We hypothesize that these
gestures helped convey the causal content of each
phenomenon by capturing it in schematic spatial form.

Figure 2: The mean proportion of critical phenomena
classified by domain, by causal structure, or by other
criteria in the two gesture conditions. Error bars represent
standard error of the mean.
or by other criteria. We first considered only the six critical
items—that is, those for which classification by domain or
by causal structure were mutually exclusive. Participants in
the iconic gesture condition classified a higher proportion of
the critical phenomena by domain than did participants in
the analogical gesture condition (iconic: M = .37, SD = .20;
analogical: M = .19, SD = .16; t = -3.2, df = 41, p = .003,
Cohen’s d = -0.98). Conversely, participants in the
analogical gesture condition classified a higher proportion
of the critical phenomena by causal structure than did
participants in the iconic gesture condition (analogical: M =
.64, SD = .18; iconic: M = .47, SD = .20; t = 3.02, df = 41, p
= .004, Cohen’s d = 0.92) (Fig. 2). Participants in the two
conditions sorted by some other criterion to the same extent
(iconic: M = .17, SD = .15; analogical: M = .17, SD = .15; t
< .001, df = 41, p = 1). Importantly, the same pattern of
significance holds when looking only at the four novel
phenomena (by domain: p = .01; by causal structure: p =
.01; by other: p = .88). Indeed, for all eight phenomena, a
higher proportion of participants in the analogical gesture
condition sorted by causal structure than did participants in
the iconic gesture condition.
To get a better sense of individual participants’
classification behavior, we also zoomed in on the two
critical phenomena that were featured in the videos: blood
pressure regulation and bracken fern growth. Note, again,
that to classify these by causal structure, participants had to
resist the temptation to group the blood pressure description
with the human body seed (blood clots) and the bracken fern
description with the plant kingdom seed (spotted
knapweed). Yet not a single participant in the analogical
gesture condition classified both these phenomena by
domain, compared to six participants in the iconic gesture
condition who did (two-tailed Fisher’s exact, p = .009)

243

Conclusion

Indeed, space is a familiar and intuitive format in which to
represent and reason about relational structure (e.g., Gattis,
2004; Tversky, 2011). But we think there may have also
been another important reason for the efficacy of analogical
gestures: namely, that they invited comparison and uniform
representation across the scenarios. Participants in the
analogical gesture condition viewed four videos, all
featuring qualitatively similar gestures. For example, all
four parsed the phenomena into causal factors by
establishing locations in space, and all showed the increases
and decreases to those factors as vertical movements. The
gestures in the iconic gesture condition also had some
commonalities across videos (e.g., the gestures in both
human body videos indexed body parts), but they were
hardly as schematic and alignable. Prior work has shown
that using the same words in superficially different contexts
prompts observers to compare those contexts (Clement,
Mawby, & Giles, 1994; Gentner, 2003), and using similar
gestures across different examples may have similar effects.
The idea that such a mechanism drives the current results is
consistent with earlier findings that prompting people to
compare examples of feedback systems fosters causal
understanding (Goldwater & Gentner, 2015). Thus, while
we refer to the abstract gestures in the present study as
“analogical” because they rely on a structured mapping
between spatial structure and relational structure
(Cooperrider et al., 2016), they are also “analogical” in
another sense: they invite observers to form analogies across
the different contexts in which they are used. Future studies
might assess these mechanisms by comparing a condition in
which the analogical gestures are qualitatively similar and
thus alignable across lessons—as in the present study—with
a condition in which the analogical gestures are more
heterogeneous and thus less alignable.
What makes the present findings perhaps surprising is that
co-speech gestures are largely implicit (Goldin-Meadow,
2003; McNeill, 1992). People seem to produce gestures
spontaneously and unreflectively, and do not always notice
the ones that others produce. Indeed, when we queried
participants at the end of the present experiment about what
they thought of the lecturer’s gestures, several participants
demurred, saying that they “didn’t notice them.” And yet,
despite this “under the radar” quality, these gestures have
clear consequences for learning (for a recent review, see
Novack & Goldin-Meadow, 2015). Another question for
further research is whether the implicit nature of gesture is
key to its benefits. Would the techniques that speakers use
to make gesture more salient—e.g., looking at their own
gestures (Cooperrider, 2017)—make gesture even more
powerful in instruction? And would more explicit forms of
visuospatial communication, such as diagrams (Novick,
2003; Tversky, 2011) or sketches (Forbus, Usher, Lovett, &
Wetzel, 2011), also be effective in fostering causal
understanding?

Sensitivity to causal structure is a hallmark of expert
understanding. Discovering how to foster such sensitivity is
an important goal for cognitive scientists and educators
across the natural and social sciences. Our results suggest
that a ubiquitous dimension of communication—gesture—
might be harnessed to this end. Analogical gestures like
those in the present study have been elicited in the lab
(Cooperrider et al., 2016), but their importance in
instruction has not been investigated. The present findings
offer first steps toward figuring out whether those gestures
have consequences for learners and, if so, why.

Acknowledgments
Funding for this study was provided by the NSF Spatial
Intelligence and Learning Center (SBE 0541957, Gentner
and Goldin-Meadow are co-PIs), the Office of Naval
Research (ONR (N00014-16-1- 2613 to Gentner), and
NICHD (R01-HD47450 to Goldin-Meadow).

References
Alibali, M. W. (2005). Gesture in Spatial Cognition:
Expressing, Communicating, and Thinking About Spatial
Information. Spatial Cognition & Computation, 5(4),
307–331.
Christie, S., & Gentner, D. (2010). Where hypotheses come
from: Learning new relations by structural alignment.
Journal of Cognition and Development, 11(3), 356–373.
Cienki, A., & Müller, C. (Eds.) (2008). Metaphor and
gesture. Philadelphia: John Benjamins.
Clement, C. A., Mawby, R., & Giles, D. E. (1994). The
Effects of Manifest Relational Similarity on Analog
Retrieval. Journal of Memory and Language, 33, 396–
420.
Cooperrider, K. (2017, in press). Foreground gesture,
background gesture. Gesture.
Cooperrider, K. & Goldin-Meadow, S. (2017, in press).
When gesture becomes analogy. Topics in Cognitive
Science.
Corts, D. P. (2006). Factors characterizing bursts of
figurative language and gesture in college lectures.
Discourse Studies, 8(2), 211–233.
Day, S. B., Motz, B. A., & Goldstone, R. L. (2015). The
cognitive costs of context: the effects of concreteness and
immersiveness in instructional examples. Frontiers in
Psychology, 6(Dec), 1–13. http://doi.org/10.3389/
fpsyg.2015.01876.
Doumas, L. A. A. & Hummel, J. E. (2013). Comparison and
mapping
facilitate
relation
discovery
and
predication. PLOS One, 8 (6).
Fernbach, P. M., & Sloman, S. A. (2009). Causal learning
with local computations. Journal of experimental
psychology: Learning, memory, and cognition, 35(3),
678.
Forbus, K., Usher, J., Lovett, A., & Wetzel, J.
(2011). CogSketch: Sketch understanding for Cognitive

244

Science Research and for Education. Topics in Cognitive
Science, 3(4), 648-666.
Gattis, M. (2004). Mapping relational structure in spatial
reasoning. Cognitive Science, 28, 589–610.
Gentner, D. (2003). Why we’re so smart. In D. Gentner &
S. Goldin-Meadow (Eds.), Language in mind: Advances
in the study of language and thought. Cambridge, MA:
MIT Press.
Gentner, D., Loewenstein, J., Thompson, L., & Forbus, K.
(2009). Reviving inert knowledge: Analogical abstraction
supports relational retrieval of past events. Cognitive
Science, 3, 1343-1382.
Gick, M. L., & Holyoak, K. J. (1983). Schema Induction
and Analogical Transfer. Cognitive Psychology, 15, 1–38.
Goldin-Meadow, S. (2003). Hearing gesture: How our
hands help us think. Cambridge, MA: Harvard U. Press.
Goldwater, M. B., & Gentner, D. (2015). On the acquisition
of abstract knowledge: Structural alignment and
explication in learning causal system categories.
Cognition, 137, 137–153.
Hostetter, A. B. (2011). When do gestures communicate? A
meta-analysis. Psychological Bulletin, 137(2), 297–315.
Hostetter, A. B., & Alibali, M. W. (2008). Visible
embodiment: Gestures as simulated action. Psychonomic
Bulletin & Review, 15(3), 495–514.
Jamalian, A., & Tversky, B. (2012). Gestures alter thinking
about time. In N. Miyake, D. Peebles, & R. P. Cooper
(Eds.), Proceedings of the 34th Annual Cognitive Science
Society. Austin, TX: Cognitive Science Society.
Jung, W., & Hummel, J. E. (2011). Progressive alignment
facilitates learning of deterministic but not probabilistic
relational categories. In L. Carlson, C. Hölscher, & T. F.
Shipley, Proceedings of the 33rd Annual Conference of
the Cognitive Science Society. Austin, TX: Cognitive
Science Society.
Kotovsky, L., & Gentner, D. (1996). Comparison and
categorization in the development of relational similarity.
Child Development, 67, 2797-2822.
Kurtz, K. J., Boukrina, O., & Gentner, D. (2013).
Comparison promotes learning and transfer of relational
categories. Journal of Experimental Psychology:
Learning, Memory, & Cognition, 39(4), 1303-1310.
Lagnado, D. A., Waldmann, M. R., Hagmayer, Y., &
Sloman, S. A. (2007). Beyond covariation: cues to causal
structure. In A. Gopnik & L. Schulz (Eds.), Causal
learning: Psychology, philosophy, and computation. New
York: Oxford University Press.
Mackie, J. L. (1980). Cement of the universe: A study of
causation. Oxford, England: Clarendon Press.
Mittelberg, I. (2008). Peircean semiotics meets conceptual
metaphor: Iconic modes in gestural representations of
grammar. In A. Cienki & C. Müller (Eds.), Metaphor and
gesture. Philadelphia: John Benjamins.
Novack, M. & Goldin-Meadow, S. (2015). Learning from
gesture: How our hands change our minds. Educational
Psychology Review, 27(3), 405-412.

Novick, L. R. (2001). Spatial diagrams: key instruments in
the toolbox for thought. In D. L. Medin (Ed.), The
psychology of learning and motivation (Vol. 40). San
Diego: Academic Press.
Núñez, R. (2008). A fresh look at the foundations of
mathematics: gesture and the psychological reality of
conceptual metaphor. In A. Cienki & C. Müller (Eds.),
Metaphor and gesture. Amsterdam: John Benjamins.
Ping, R., & Goldin-Meadow, S. (2008). Hands in the air:
Using ungrounded iconic gestures to teach children
conservation of quantity. Developmental Psychology,
44(5), 1277-1287.
Rottman, B. M., Gentner, D., & Goldwater, M. B. (2012).
Causal systems categories: Differences in novice and
expert categorization of causal phenomena. Cognitive
Science, 36(5), 919–32.
Singer, M. A., & Goldin-Meadow, S. (2005). Children learn
when their teachers’ gestures and speech differ.
Psychological Science, 16, 85-89.
Smith, L. A., & Gentner, D. (2014). The role of differencedetection in learning contrastive categories. In P. Bello,
M. Guarini, M. McShane, & B. Scassellati (Eds.),
Proceedings of the 36th Annual Meeting of the Cognitive
Science Society. Austin: Cognitive Science Society.
Sloman, S. A. (2005). Causal models: How people think
about the world and its alternatives. Oxford: Oxford
University Press.
Tversky, B. (2011). Visualizing thought. Topics in
Cognitive Science, 3(3), 499-535.
Valenzeno, Laura, Martha W. Alibali, and Roberta Klatzky.
2003. Teachers’ gestures facilitate students’ learning: A
lesson
in
symmetry. Contemporary
Educational
Psychology, 28, 187-204.

245

