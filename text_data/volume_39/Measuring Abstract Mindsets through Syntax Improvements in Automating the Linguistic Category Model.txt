Measuring Abstract Mindsets through Syntax: Improvements in Automating the
Linguistic Category Model
Kate M. Johnson
University of Southern California

Reihane Boghrati
University of Southern California

Cheryl Wakslak
University of Southern California

Morteza Dehghani
University of Southern California
Abstract: The Linguistic Category Model (LCM) was developed as a manual coding scheme for quantifying abstract mindsets
in human language. Previous attempts to computationally automate the LCM have relied primarily on pre-coded semantic
features, which fail to incorporate important contextual information integral to the LCM coding scheme. In this paper, we
introduce Syntax-LCM, a novel method for automating LCM coding using syntax and dependency tree features as predictors of
construal level. We compare the accuracy of Syntax-LCM to that of two previously used automated methods: LIWC LCM and
Brysbaert concreteness ratings. We find support that the Syntax-LCM approximates the hand-coded LCM with higher accuracy
compared to both the Brysbaert and the LIWC LCM. We also provide evidence that the syntactic features accounted for by
Syntax-LCM mirror the inclusion criteria in the original coding manual and support theoretical relationships between distance
and abstract thinking.

2320

