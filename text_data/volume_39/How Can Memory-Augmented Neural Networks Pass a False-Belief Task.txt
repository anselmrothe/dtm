        How Can Memory-Augmented Neural Networks Pass a False-Belief Task?
                                     Erin Grant, Aida Nematzadeh, and Thomas L. Griffiths
                                                       University of California, Berkeley
                                             {eringrant, nematzadeh, tom griffiths}@berkeley.edu
                               Abstract                                    state of the world but also that these representations are in-
                                                                           consistent: Sally believes that the milk is in the pantry while
   A question-answering system needs to be able to reason about            Ann thinks it is in the fridge.
   unobserved causes in order to answer questions of the sort that
   people face in everyday conversations. Recent neural network               Psychologists have used a task similar to this scenario –
   models that incorporate explicit memory and attention mecha-            termed the false-belief task – to examine children’s develop-
   nisms have taken steps towards this capability. However, these
   models have not been tested in scenarios for which reasoning            ment of theory of mind: the capacity to reason about the men-
   about the unobservable mental states of other agents is nec-            tal states of oneself and others (Premack & Woodruff, 1978).
   essary to answer a question. We propose a new set of tasks              Most 3-year-old children, after observing such a scenario, an-
   inspired by the well-known false-belief test to examine how
   a recent question-answering model performs in situations that           swer that Sally would search for the milk in the fridge because
   require reasoning about latent mental states. We find that the          they cannot infer Sally’s belief about the location of the milk,
   model is only successful when the training and test data bear           which is inconsistent with their own knowledge (e.g., Baron-
   substantial similarity, as it memorizes how to answer specific
   questions and cannot reason about the causal relationship be-           Cohen, 1989; Baron-Cohen, Leslie, & Frith, 1985). However,
   tween actions and latent mental states. We introduce an ex-             most older children are able to identify, correctly, that Sally’s
   tension to the model that explicitly simulates the mental rep-          belief is different from theirs in that she thinks that the milk
   resentations of different participants in a reasoning task, and
   show that this capacity increases the model’s performance on            is the pantry.
   our theory of mind test.                                                   To answer questions about situations like those that oc-
   Keywords: language understanding, question answering, the-              cur in a false-belief task, a model needs to use the observed
   ory of mind, false-belief test                                          actions in the scenario to infer the mental states of Sally
                                                                           and Ann. In this work, we investigate whether the End-to-
                           Introduction                                    End Memory Network (henceforth MemN2N), a recent neu-
                                                                           ral question-answering model (Sukhbaatar et al., 2015) that
Question answering poses difficulties to artificial intelligence
                                                                           solves most of the bAbi tasks, is able to answer questions
systems because correctly answering a query often requires
                                                                           of the same structure as a false-belief task. We formulate sce-
sophisticated reasoning and language understanding capaci-
                                                                           narios to capture different possible causal relations among ac-
ties, and so simply memorizing the answer or searching in
                                                                           tions and beliefs, and examine the performance of the model
a knowledge base is not enough. Despite this challenge,
                                                                           therein. We find that the MemN2N model performs well only
recent neural network models that make use of attention
                                                                           in the presence of strong supervision – when the training and
mechanisms in combination with an explicit external memory
                                                                           test data share the same casual structure. This result suggests
can successfully answer questions that require more complex
                                                                           that the model is able to memorize the training data but is un-
forms of reasoning than before (e.g., Sukhbaatar, Weston,
                                                                           able to learn to reason about mental states and how they cause
Fergus, et al., 2015; Henaff, Weston, Szlam, Bordes, & Le-
                                                                           and are caused by actions.
Cun, 2017). The benchmark dataset for such tasks has be-
                                                                              Furthermore, to simulate the (perhaps inconsistent) beliefs
come the Facebook bAbi dataset (henceforth, bAbi) (Weston,
                                                                           of the participants in a story, we extend the MemN2N model
Bordes, Chopra, & Mikolov, 2016), which is a collection
                                                                           to include a separate memory representation for each partic-
of question-answering tasks in the form of simple narrative
                                                                           ipant. We show that this extension improves model perfor-
episodes – termed stories – that are accompanied by ques-
                                                                           mance, suggesting that explicitly modeling agents’ knowl-
tions about the state of the world described in the stories. (See
                                                                           edge in a disentangled manner is in part sufficient for more
Figure 1 for an example story from this dataset.)
                                                                           human-like reasoning on a false-belief task.
   Although bAbi is a start towards enumerating the require-
ments for human-like reasoning capabilities, it lacks tasks for
                                                                                Theory of Mind and the False-Belief Task
testing the ability to reason about mental states, which is also
necessary for correctly answering questions of the sort that               A theory of mind is integral for an agent to predict and ex-
humans encounter regularly. Consider the following:                        plain the behavior that is caused by the mental representations
     Sally and Ann are in the kitchen.                                     of other agents, and therefore succeed on tasks such as the
     Sally placed the milk in the pantry.                                  false-belief task. For children, this capacity is acquired grad-
     Sally exited the kitchen.                                             ually over the course of development. In particular, children
     Ann moved the milk to the fridge.
                                                                           undergo several milestones before they develop an adult-like
For a model to correctly answer questions such as Where                    theory of mind: By age two, they can distinguish between ex-
would Sally/Ann search for the milk? it need not only rec-                 ternal states of the world and internal mental states possessed
ognize that Sally and Ann have mental representations of the               by cognitive agents (e.g., Meltzoff, Gopnik, & Repacholi,
                                                                      427

  Mary got the milk there.
  John moved to the bedroom.
                                                                                                         exp uTk mi
                                                                                                               
  Sandra went back to the kitchen.
                                                                                               pik =                    .                 (1)
                                                                                                        ∑ j exp uTk m j
                                                                                                                
  Mary traveled to the hallway.
  Q: Where is the milk?                  A: hallway
                                                                          This weight can be interpreted as an attention mechanism that
         Figure 1: An example task from the bAbi dataset.                 defines where in memory the model will look for information
                                                                          relevant to the given question.
                                                                             The model then produces an output representation by
1999). By age four, they can distinguish between consistent               way of a linear combination of its context representations,
and inconsistent mental states (e.g., Perner, Leekam, & Wim-              weighted by the attention computed in Equation (1):
mer, 1987), which allows them to identify a false belief.
                                                                                                      ok = ∑ pik ci .                     (2)
   Previous computational works have modeled human per-                                                      i
formance on the false-belief task. Some focus on modeling                 The output representation is combined with the query rep-
the development of theory of mind by instantiating a model                resentation and decoded by some function f to produce the
that initially fails but eventually passes the false-belief test          predicted answer â:
(Van Overwalle, 2010), while others study the settings in
which a model can succeed on the task by varying the input                                          â = f (ok + uk ).                    (3)
data or the model architecture (O’Laughlin & Thagard, 2000;
Triona, Masnick, & Morris, 2002; Goodman et al., 2006).                      Learning model parameters at training time is done by way
However, none of these models use natural language sen-                   of stochastic gradient descent in cross entropy error.
tences, despite the fact that the psychological false-belief task
is usually administered verbally in the form of a natural lan-
                                                                                      Simulation 1: MemN2N Model
guage reasoning problem.                                                  We evaluate the model introduced in the previous section on
   Furthermore, natural language is known to interact with the            a set of novel textual reasoning tasks inspired by the false-
development of theory of mind. For example, use of mental                 belief task. Our tasks take the form of a sequence of natural
state terms in child-directed speech (e.g., Slaughter & Gop-              language sentences – termed a story – and an associated ques-
nik, 1996), engagement in pretend play (Youngblade & Dunn,                tion about the story.
1995), storybook reading (Rosnay & Hughes, 2006), and re-                    Since we aim to create tasks that, for humans to solve, in-
flection on events in the child’s past (Nelson, 2007) serve to            volve reasoning about other agents’ beliefs, we design vari-
accelerate its developments, while, in turn, a greater grasp of           ous story templates that simulate how different actions give
theory of mind leads to increased linguistic ability (Milligan,           rise to different beliefs, and conversely how different beliefs
Astington, & Dack, 2007). In this work, we examine whether                result in different actions. These stories differ in whether or
a model can learn from natural language about the causal re-              not the agent who is the subject of the question has observed
lationship between actions and beliefs, in order to be able to            a change in the state of the world (i.e., the agent has a true
answer questions that require reasoning about mental states.              belief), or has not (i.e., has a false belief). The stories further
                                                                          differ in whether the belief is observable (i.e., the story ex-
                                                                          plicitly contains sentences such as Sally believes the milk is
                          Memory Networks                                 in the pantry) or whether only actions are observable. When
                                                                          the agent harbors a false belief, and the model is asked to pre-
The MemN2N model of Sukhbaatar et al. (2015) comprises                    dict the action of the agent without explicit reference to the
an external memory cache and mechanisms to read and write                 beliefs of the agent in the story, we recover a simulation of
to this memory. The model is trained to write a sequence                  the classic false-belief task.
of stories into its external memory and to answer questions                  With this experimental design, we aim to determine
about the stories by reading its memory and emitting the cor-             whether the MemN2N model can reason about how actions
rect vocabulary item. At test time, the model is evaluated by             cause beliefs and vice versa, and how much information
the extent to which it can correctly answer questions about a             needs to be revealed to enable the model to succeed.
held-out set of test stories.
   Formally, the model ingests a sequence of input sentences              Data Generation
(x1 , . . . , xn ) and produces, for each input item xi , both a mem-     To generate stories and corresponding questions, we emulate
ory representation mi and a context representation ci , which             the bAbi (Weston et al., 2016) dataset generation procedure.
are stored in memory. The model is then presented with a                  We define a world of entities, which are the people and ob-
question qk about the story, for which it produces an internal            jects described in the stories, and possible predicates that take
representation uk . To answer the question, the model com-                entities as subject and, optionally, object. Each entity has
putes a normalized association score pik between the question             properties that define the predicates of which it can be sub-
representation and each of its stored memory representations:             ject or object. For example, a world may contain Sally with
                                                                      428

                                 BA                                        AB                                        A(B)A
              Anne moved the milk to the fridge.        Sally placed the milk in the pantry.        Sally placed the milk in the pantry.
  True        Sally believes the milk is in the fridge. Anne moved the milk to the fridge.          Anne moved the milk to the fridge.
  Belief      Q: Where did Sally search for the milk?   Q: Where does Sally believe the milk is?    Q: Where did Sally search for the milk?
              A: fridge                                 A: fridge                                   A: fridge
              Sally believes the milk is in the pantry. Sally placed the milk in the pantry.        Sally placed the milk in the pantry.
              Sally exited the kitchen.                 Sally exited the kitchen.                   Sally exited the kitchen.
  False       Anne moved the milk to the fridge.        Anne moved the milk to the fridge.          Anne moved the milk to the fridge.
  Belief      Sally entered the kitchen.                Sally entered the kitchen.                  Sally entered the kitchen.
              Q: Where did Sally search for the milk?   Q: Where does Sally believe the milk is?    Q: Where did Sally search for the milk?
              A: pantry                                 A: pantry                                   A: pantry
Figure 2: Examples of the training data, with the predicates of interest underlined. Note that the true-belief and false-belief test
tasks are of the same form as the top and bottom items, respectively, in the last column.
the property is agent and apple with the property is object.             A(B)A, on the other hand, the question is about Sally’s action,
Our rules permit Sally to perform the action displace on the             which has been brought about by Sally’s unobserved belief.
apple.                                                                   True vs. False Belief In addition to the type of template, for
   In this work, we consider a restricted set of action and be-          each story we manipulate whether the agent about whom the
lief predicates. Our actions define simple interactions of an            question is asked (i.e., Sally) has a true belief or a false belief
agent with the world (e.g., place, move, enter, exit) and our            about the state of the world. In the case that the agent has a
beliefs correspond to mental state terms (e.g., believe, think),         true belief, the agent observes all changes in the state of the
inspired by the terms that children gradually learn to under-            world and thus their beliefs are consistent with the world. On
stand and use correctly over the course of development (e.g.,            the other hand, in the case that the agent has a false belief,
Bretherton & Beeghly, 1982; Johnson & Wellman, 1980).                    the agent does not observe one or more changes in the state
Our templates manipulate the order of action and belief pred-            of the world (because, for instance, Sally may exit the room),
icates to test how the model reasons about the causal relations          and thus has a belief that is inconsistent with the world.
between them.
                                                                         Training Conditions We have six possible story types as a
Experimental Conditions                                                  results of crossing the template types with the true and false
Story Template We define a set of templates that correspond              belief story types; examples of each of the story types are
to the type of story that we wish to generate. Each template             given in Figure 2. We sample from these story types to pro-
fixes a sequence of predicates and therefore puts constraints            duce our training conditions, in the following manner:
on the entities that may fill the template. For example, a tem-
plate could be the sequence (drop, pick up, exit). Completion            • When the training condition is such that p(false belief) =
of the template entails sampling valid entities from the world              0 or 1, we sample only stories with true beliefs or false
to fill the subject and object positions of the predicates, pro-            beliefs, respectively, and when p(false belief) = 0.5, we
ducing, for example, the story (Sally dropped the ball, Sally               sample half of our stories with true beliefs and half with
picked up the ball, Sally exited the room).                                 false beliefs.
   We consider three different template types:                           • We sample stories from five different possible groups of
• BA: observable beliefs (e.g., Sally believes the milk is in the           templates: BA, AB, AB+BA, A(B)Aand AB+BA+A(B)A.
   pantry) give rise to observable actions (e.g., Sally searches
   the pantry);                                                             The AB+BA and AB+BA+A(B)A conditions provide the
                                                                         model with training data that better approximates the variety
• AB: observable actions (e.g., Sally places the milk in the             of possible scenarios in the world. In these cases, the model
   pantry) give rise to observable beliefs (e.g., Sally believes         observes more ways in which actions and beliefs interact, and
   milk is in the pantry); and                                           thus we would expect it to be able to better generalize to new
                                                                         scenarios. Moreover, AB+BA provides the model with the
• A(B)A: observable actions (e.g., Sally places the milk in
                                                                         opportunity to learn transitive inference – given that an action
   the pantry) give rise to observable actions (e.g., Sally
                                                                         (e.g., placing milk in the pantry) results in a belief (e.g., the
   searches the pantry) by way of unobserved beliefs (e.g.,
                                                                         milk is in the pantry), and a belief (e.g., the milk is in the
   Sally believes the milk is in the pantry).
                                                                         pantry) can cause an action (e.g., searching for milk in the
Note that the AB and A(B)A conditions are different in that              pantry), a model that reasons about actions and beliefs could
in AB, the question explicitly asks about Sally’s belief; in             learn that an action (e.g., searching for milk in the pantry) is
                                                                    429

  Test       1                               1                            1                               1                                 1
            0.5                           0.5                          0.5                              0.5                              0.5
accuracy     0                               0                            0                               0                                 0
                    TB          FB                    TB        FB               TB          FB                     TB         FB                  TB          FB
                     BA Train                         AB Train                  A(B)A Train                    AB+BA Train                 AB+BA+A(B)A Train
Figure 3: Accuracy in Simulation 1. Test accuracies for the true-belief (TB) and false-belief (FB) tests across training condi-
tions in Simulation 1. We report results for p(false belief) = 0.5, since varying this parameter did not affect results except in
the few cases discussed in the text.
  Test       1                               1                            1                               1                                 1
            0.5                           0.5                          0.5                              0.5                              0.5
accuracy     0                               0                            0                               0                                 0
                    TB          FB                    TB        FB               TB          FB                     TB         FB                  TB          FB
                     BA Train                         AB Train                  A(B)A Train                    AB+BA Train                 AB+BA+A(B)A Train
Figure 4: Accuracy in Simulation 2. Test accuracies for the true-belief (TB) and false-belief (FB) tests across training condi-
tions in Simulation 2. As in Figure 3, we report results only for p(false belief) = 0.5.
Attention     1                                                   1                                                        1
            0.5                                                 0.5                                                      0.5
 weight       0                                                   0                                                        0
                  oracle / Anne / Sally oracle / Anne / Sally         oracle / Anne / Sally oracle / Anne / Sally              oracle / Anne / Sally oracle / Anne / Sally
                          TB                     FB                           TB                    FB                                 TB                    FB
                                BA Train                                            AB Train                                               A(B)A Train
Figure 5: Attention in Simuation 2. Visualisation of the attention weighting over memory caches for the true-belief (TB)
and false-belief (FB) tests. We omit the visualization for the BA+AB and BA+AB+A(B)A training conditions because the test
accuracy distribution in Simulation 2 for these conditions is very similar to the A(B)A training condition (see Figure 4).
a consequence of an unobservable belief brought about by a                              Results
preceding action (e.g., placing milk in the pantry).
   Crossing template types BA, AB, A(B)A, AB+BA,                                        As noted by Sukhbaatar et al. (2015), the MemN2N model
AB+BA+A(B)A with p(false belief) = {0.0, 0.5, 1.0} pro-                                 exhibits large variance in performance across simulations,
duces our 15 training conditions. We run 10 simulations for                             and so we show performance by plotting the distribution of
each training condition and for each configuration of param-                            test accuracies in boxplot format. In Figure 3, we report ac-
eter settings of the MemN2N model.1                                                     curacy on both test conditions (the true-belief (TB) and false-
                                                                                        belief (FB) tasks) across the training conditions, for p(false
Test Conditions We aim to evaluate the model on tasks that                              belief) = 0.5. The results for p(false belief) ∈ {0, 1} were
require reasoning about latent mental states, in analogy to the                         similar except in the case of the AB story template; we com-
classic false-belief task; however, such a capacity should ap-                          pare this case with the BA condition in Figure 6 and discuss
ply not only in cases when an agent has a belief that is incon-                         in the following. Note that success at test time corresponds to
sistent with the state of the world (i.e., a false belief) but also                     achieving 1.0 accuracy in both the TB and FB test conditions.
when they have a true belief about the world. We therefore
consider two test conditions: a true-belief (TB) and a false-                           Training Condition BA: Beliefs to Actions The model fails
belief (FB) task. All examples in both of these test conditions                         on the TB task in the BA training condition, while succeed-
share the A(B)A template type, but the conditions differ in                             ing on the FB task. This is true no matter the value of p(false
that the true-belief task contains only examples with true be-                          belief) (as depicted in Figure 6). To understand why this oc-
liefs (i.e., p(false belief) = 0), and the false-belief task con-                       curs, consider the following example of a BA training story
tains only false belief examples (i.e., p(false belief) = 1).                           when the false belief occurs:
   1 We
                                                                                        Sally believes the milk is in the pantry. Sally exited the
         vary the dimensionality of the memory and word embed-                          kitchen. Anne moved the milk to the fridge. Sally entered
ding, the number of computational hops (accesses to the memory
cache to answer a single question), the number of training and test-                    the kitchen.
ing examples (1000 vs. 10000), and the size of the world from which
the dataset of stories is generated (5 vs. 10 vs. 30 entities per entity                Additionally, consider the BA training story when the false
type, which correspond to the objects, container, etc. in the story).                   belief does not occur:
                                                                                  430

Anne moved the milk to the fridge. Sally believes the milk is                                 (a)   p(false belief) = 0 in training.
in the fridge.
   To answer the training question Where did Sally search for                        Test        1                          1
                                                                                               0.5                        0.5
the milk? the model seems to learn that it should look for the
sentence containing Sally and a container entity (i.e., Sally                      accuracy      0                          0
                                                                                                        TB       FB                 TB    FB
believes the milk is in the fridge).
                                                                                                         BA Train                   AB Train
   This strategy works for the false-belief test (see Figure 2,
last column, bottom row), because Sally believes that the milk
                                                                                         (b)    p (false belief) = 0.5 in training.
is in the pantry – the location in which she originally placed
it – and thus the sentence containing Sally and the identity of
a container always proviedes the correct answer. However,                            Test        1                          1
                                                                                               0.5                        0.5
this strategy fails on the true-belief test (again, see Figure 2,                  accuracy      0                          0
last column, top row), because Sally observes that the milk                                             TB       FB                 TB    FB
has been moved, and so no longer believes that the milk is in                                            BA Train                   AB Train
fridge. This suggests that the model is unable to infer that an
observable action changes the mental state of Sally.                                          (c)   p (false belief) = 1 in training.
Training Condition AB: Actions to Beliefs The model is
unable to achieve good performance on both the TB and FB                             Test        1                          1
tests in the AB condition. When the model performs better, it                                  0.5                        0.5
is in cases where the test is very similar to the training condi-                  accuracy      0                          0
tion, i.e., the false-belief test with p(false belief) = 1 in train-                                    TB       FB                 TB    FB
ing and true-belief test with p(false belief) = 0 in training.                                           BA Train                   AB Train
Training Condition AB+BA: Transitive Inference The
                                                                             Figure 6: From Simulation 1. The test accuracy in the AB
model fails on both test tasks in the AB+BA training condi-
                                                                             condition is dependent on the value of p(false belief), but not
tion. This is evidence that the model cannot reason about the
                                                                             in the BA condition.
causal relationships between actions and beliefs to perform
transitive inference.
Training Condition A(B)A: Equivalent to TB/FB Test The                          Formally, for a story of N input items that describes a sit-
model achieves best performance on A(B)A in the p(false                      uation with M agents, we provide the model with an N-by-
belief) = 0.5 condition. This again happens because the test                 (M + 1) observer annotation matrix S such that Si j = 1 if in-
and training conditions are similar: the model observes exam-                put item xi is observable to agent j and 0 otherwise, where we
ples of both the FB and TB test tasks in training, and thus re-              assign the oracle observer (who observes all input items) to
ceives supervision to give the correct answer at test. However,              the first index. These annotations are used to mask the input
the model performs well only on the TB task in the p(false                   such that M +1 (possibly different) stories are produced, each
belief) = 0, and on the FB task in the p(false belief) = 1 con-              of which corresponds to the story that a particular agent ob-
dition. This is because the model does not observe examples                  serves. Memory representations, attention over each memory
like one or the other test condition at training time.                       cache, and output representations are computed separately
   Notably, the performance is not high even in the p(false                  for each observer, and so M + 1 output representations are
belief) = 0.5 condition (the median is approximately 55% on                  computed, each corresponding to the output of a distinct ob-
both test tasks), despite the fact that the model is given test-             server’s memory.
like examples at training time. It is therefore not clear that                  The model then computes an attention weighting over each
the model is robustly able to solve a conditional reasoning                  of the observer memory caches (cf. Equation (1)):
task in which the correct answer is dependent on whether or                                               exp uTk ok`
                                                                                                             
not the observer sees the movement of the object and thus                                        rk` =                  .                (4)
                                                                                                        ∑n exp uTk okn
                                                                                                               
has a false or true belief. This, along with the model’s failure
in the other training scenarios, motivates an extension to the               This attention over memory caches is used to compute a
model, which we consider in the next section.                                weighted combination of the output representations that cor-
                                                                             respond to the memory cache for each agent (cf. Equa-
     Simulation 2: Multiple-Observer Model                                   tion (3)):
We now propose a model that is given information about
whether each agent in the story observes each sentence in the                                           â = f (uk + ∑ rk` ok` ).              (5)
story. In general, this must also be inferred from context, but                                                       `
here we assume such annotations are available to the model as                Note that the model considered in Simulation 1 is exactly this
we simply attempt to investigate the effect of this information              model extension with rk0 = 1 and rkm = 0, ∀m 6= 0 (i.e., atten-
on the model’s predictions.                                                  tion is given only to the oracle memory cache).
                                                                       431

   In this extension, the model is given explicit information         knowledge that agents have (perhaps conflicting) observa-
about which observations in a story are available to each             tions about the story in order to answer the question. We
agent, by way of the annotation matrix S. However, it must            could interpret this as analogous to the development of theory
learn to reason about this information in order to arrive at the      of mind in that, when a child is able to reason about others’
correct answer, as before with how to write to memory and             knowledge of and beliefs about the world, the child succeeds
read from memory, and now with how to select over which               on tests of theory of mind such as the false-belief task. A fur-
observer’s knowledge of the story is relevant to answer the           ther direction of research could investigate whether manipu-
question.                                                             lating variables in the training data (e.g., frequency of men-
                                                                      tal state terms) affects the model’s performance in a manner
Results                                                               similar to how a child’s developmental trajectory would be
We report results of the model extension on the TB and FB             affected.
tests in Figure 4, as well as a visualization of the attention
weights in Figure 5. Our simulated data is composed of sce-
                                                                                                   References
                                                                      Baron-Cohen, S. (1989). The autistic child’s theory of mind: A
narios with only two agents, and therefore the extended model            case of specific developmental delay. J. of Child Psychology &
attends over three memory caches (one for the oracle that                Psychiatry, 30(2), 285–297.
observes everything, one for Anne, and one for Sally, about           Baron-Cohen, S., Leslie, A. M., & Frith, U. (1985). Does the autistic
                                                                         child have a theory of mind? Cognition, 21(1), 37–46.
whom the question is asked).                                          Bretherton, I., & Beeghly, M. (1982). Talking about internal states:
   The extended model achieves higher accuracy across all                The acquisition of an explicit theory of mind. Developmental Psy-
training conditions. Notably, the model performs near                    chology, 18(6), 906.
                                                                      Goodman, N. D., et al. (2006). Intuitive theories of mind: A rational
perfectly (i.e., both TB and FB are close to 1) in the                   approach to false belief. In Proceedings of Cog. Sci. (pp. 1382–
AB+BA+A(B)A case, meaning that the model can learn to                    1387).
ignore irrelevant training stimuli. This suggests that aware-         Henaff, M., Weston, J., Szlam, A., Bordes, A., & LeCun, Y. (2017).
                                                                         Tracking the world state with recurrent entity networks. In Pro-
ness of agent’s knowledge about the state of the world helps             ceedings of ICLR.
in a task of reasoning about latent mental states.                    Johnson, C. N., & Wellman, H. M. (1980). Children’s develop-
   Furthermore, the attention plots show that the model learns           ing understanding of mental verbs: Remember, know, and guess.
                                                                         Child Development, 1095–1102.
to attend to the memory representation of Sally in the FB test,       Meltzoff, A. N., Gopnik, A., & Repacholi, B. M. (1999). Toddlers’
which contains the information about how to answer ques-                 understanding of intentions, desires and emotions: Explorations
tions about Sally’s actions and beliefs. On the other hand, in           of the dark ages. In P. Zelazo, J. Astington, & D. Olson (Eds.),
                                                                         Developing theories of intention: Social understanding and self
the TB test, the model does not attend differently to the dif-           control (pp. 17–41). Erlbaum.
ferent memory caches, because the observations stored in all          Milligan, K., Astington, J. W., & Dack, L. A. (2007). Language and
caches are the same.                                                     theory of mind: meta-analysis of the relation between language
                                                                         ability and false-belief understanding. Child develop., 78(2), 622–
                                                                         646.
                         Conclusions                                  Nelson, K. (2007). Young minds in social worlds: Experience,
                                                                         meaning, and memory. Harvard University Press.
We investigated whether a recent language learning model              O’Laughlin, C., & Thagard, P. (2000). Autism and coherence: A
that succeeds on a suite of textual reasoning tasks is able to           computational model. Mind & Language, 15(4), 375–392.
                                                                      Perner, J., Leekam, S. R., & Wimmer, H. (1987). Three-year-
succeed in a task that requires reasoning about latent men-              olds’ difficulty with false belief: The case for a conceptual deficit.
tal states. We found that the model is unable to succeed in              British Journal of Developmental Psychology, 5(2), 125–137.
a set of simulated true-belief and false-belief tasks unless it       Premack, D., & Woodruff, G. (1978, Dec). Does the chimpanzee
                                                                         have a theory of mind? Behavioral and Brain Sci., 1(4), 515–526.
has observed at training time situations that have the same           Rosnay, M., & Hughes, C. (2006). Conversation and theory of
structure as the test tasks, even if the diversity of the data is        mind: Do children talk their way to socio-cognitive understand-
increased. This strongly suggests that the model is not rea-             ing? British Journal of Developmental Psychology, 24(1), 7–37.
                                                                      Slaughter, V., & Gopnik, A. (1996). Conceptual coherence in the
soning about the state of the world, nor about mental repre-             child’s theory of mind: Training children to understand belief.
sentations thereof, but is simply memorizing its input. As a             Child development, 67(6), 2967–2988.
consequence, the model will not be able to succeed in a task          Sukhbaatar, S., Weston, J., Fergus, R., et al. (2015). End-to-end
                                                                         memory networks. In Proceedings of NIPS (pp. 2440–2448).
of reasoning that differs greatly from the situations that it has     Triona, L. M., Masnick, A. M., & Morris, B. J. (2002). What does it
observed at training time. This is in contrast to the the novelty        take to pass the false belief task? An ACT-R model. In Proceed-
of situations that people encounter regularly, in which they             ings of Cog. Sci. (p. 1045).
                                                                      Van Overwalle, F. (2010). Infants’ teleological and belief infer-
must reason about the causal relationship between events in              ence: A recurrent connectionist approach to their minimal repre-
the world and latent mental states.                                      sentational and computational requirements. NeuroImage, 52(3),
   However, incorporating a simple mechanism that informs                1095–1108.
                                                                      Weston, J., Bordes, A., Chopra, S., & Mikolov, T. (2016). Towards
the model that there may be multiple observers with differ-              AI-complete question answering: A set of prerequisite toy tasks.
ing representations of the story allows the model to achieve             In ICLR.
higher performance on the simulated false-belief and true-            Youngblade, L. M., & Dunn, J. (1995). Individual differences in
                                                                         young children’s pretend play with mother and sibling: Links to
belief tasks. Under this modification, the model does not                relationships and understanding of other people’s feelings and be-
simply memorize the training data but also learns to use                 liefs. Child Development, 66(5), 1472–1492.
                                                                  432

