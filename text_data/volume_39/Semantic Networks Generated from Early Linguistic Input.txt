                      Semantic Networks Generated from Early Linguistic Input
                                                   Andrei Amatuni, Elika Bergelson
                                     Department of Psychology and Neuroscience, Duke University
                                                  417 Chapel Dr. Durham, NC 27708 USA
                                                {andrei.amatuni, elika.bergelson}@duke.edu
                               Abstract                                    (here equivalent to scale-free distributions), has been found
   Semantic networks generated from different word corpora                 in many cognitive domains and diverse natural phenomena; it
   show common structural characteristics, including high de-              is argued to be a general unifying principle of cognitive orga-
   grees of clustering, short average path lengths, and scale free         nization (Kello et al., 2010).
   degree distributions. Previous research has disagreed about
   whether these features emerge from internally- or externally-              Barabási and Albert (1999) suggest that graphs with degree
   driven properties (i.e. words already in the lexicon vs. regu-          distributions that follow power laws imply constraints on the
   larities in the external world), mapping onto preferential at-          processes which formed them. Their model for generating
   tachment and preferential acquisition accounts, respectively
   (Steyvers & Tenenbaum, 2005; Hills, Maouene, Maouene,                   such networks relies on incremental growth and a process of
   Sheya, & Smith, 2009). Such accounts suggest that inherent              “preferential attachment” (hereafter PAT), whereby existing
   semantic structure shapes new lexical growth. Here we ex-               nodes with many connections are preferentially “chosen” by
   tend previous work by creating semantic networks using the
   SEEDLingS corpus, a newly collected corpus of linguistic in-            new nodes. While their resulting graphs display power law
   put to infants. Using a recently developed LSA-like approach            degree distributions, they did not find small world connec-
   (GLoVe vectors), we confirm the presence of previously re-              tivity of the kind found in semantic networks, such as those
   ported structural characteristics, but only in certain ranges of
   semantic similarity space. Our results confirm the robustness           generated from WordNet and Roget’s Thesaurus. Building on
   of certain aspects of network organization, and provide novel           this, Steyvers and Tenenbaum (2005) proposed a model for
   evidence in support of preferential acquisition accounts.               incrementally growing semantic networks similar to Barabási
   Keywords: semantic networks; word learning; preferential ac-            and Albert (1999), which indeed resulted in both small world
   quisition
                                                                           and scale free structures. Their growth process centered on
                           Introduction                                    semantic differentiation, i.e. new words that are more con-
A word functions as an atomic unit of meaning, in principle                trastive with existing words are preferentially incorporated
carrying independent semantic content. In practice though, it              into the graph; they include a frequency parameter as well.
occurs with its fellow words, as humans produce language.                  The resulting semantic graphs showed degree distributions
From this word-stream, infants begin to understand words by                which reflected the relative time at which a particular node
6-9 months (Bergelson & Swingley, 2012), and to produce                    was added to the network: age-of-acquisition (AoA) norms
them soon thereafter. Here we aim to shed light on how these               for words corresponded to the relative number of connec-
semantic atoms are organized in the mental lexicon, and the                tions in these graphs. PAT-based graphs inherently bias nodes
degree to which this representational structure is reflective of           which are added earlier to have higher degree.
the conceptual order found “out there” in the world.                          Steyvers and Tenenbaum (2005) suggest that the structure
   To explore this, we turn to semantic networks, an idea dat-             of internal representations guides the selection process of
ing back nearly a century (Trier, 1931). Given that words                  new words or concepts. In contrast, Hills et al. (2009) pro-
are related along semantic dimensions, characterizing these                pose that the connectivity of words in the external environ-
relations is a first step towards understanding their represen-            ment plays a guiding role in the acquisition of new words.
tational structure. Previous research on semantic networks                 In this alternative, dubbed preferential acquisition (hereafter
generated from word corpora have shown small-world con-                    PAQ), the relative salience between unlearned words directs
nectivity (i.e. any given word node is not very many nodes                 new node integration into the lexicon. Under PAQ, the struc-
away from any other), as well as scale free degree distribu-               ture of the external semantic ground is itself scale-free, clus-
tions (i.e. a few nodes serve as ‘hubs’, and node distribu-                tered, and small world, leading internal representations to
tion follows a power law such that probability(k) ≈ k−α ,                  mirror this structure as lexical items are added. This con-
for a node with degree k, and scaling parameter α) (Sigman                 trasts with PAT, which suggests that the structuring is a conse-
& Cecchi, 2002; Steyvers & Tenenbaum, 2005; Hills et al.,                  quence of incremental semantic network growth. Under PAQ,
2009). This suggests that semantic information may be in-                  the higher a word’s contextual variety, the more interactions
herently structured in nonrandom, clustered, and highly or-                it has with other elements in the external ground. This results
ganized ways, which internal representations may mirror or                 in more neighbors in semantic network space, making it more
exploit1 (Todd, Hills, & Robbins, 2012). Scale invariance                  linguistically salient to the learner. Indeed, evidence by Hills,
                                                                           Maouene, Riordan, and Smith (2010) suggests a role for con-
    1 Graphs   with high clustering coefficients and low average path      textual variety and associative density in noun lexical devel-
lengths, as in small-world networks, are efficient to search and relay
information through, while scale invariance allows a single algo-          opment in particular. In the present work, we build on these
rithm to operate across seemingly disparate representational frames.       previous results, combining approaches that suggest network
                                                                       1538

properties arise from incremental generative processes with           node addition, suggesting that internal structures mirrors ex-
networks that are definitively non-generative, as a window            ternal structure, which may be scale-free, small-world, or
into how external and internal semantic spaces may influence          not. Because our networks are built using the GloVe vectors,
the growing noun lexicon.                                             they are, by definition, non-generative and non-incremental:
   One limitation of previous work concerns operationaliz-            showing scale free and small world behavior in our networks
ing semantic relatedness, generally achieved through hand-            would suggest this structuring might exist without PAT’s as-
tagged features or word associations (Steyvers & Tenenbaum,           sumed incremental generative growth processes.
2005; Hills et al., 2009). Hand-tagged features may not re-              As a proxy for AoA, we make use of parent-reported
flect the underlying semantic organization given that they            vocabulary norms from WordBank (Frank, Braginsky,
stem from an overt metalinguistic task. Indeed such fea-              Yurovsky, & Marchman, 2016), a compilation of the
tures do not produce scale free graphs or predict AoA. Word           MacArthur-Bates Communicative Developmental Inventory
association data lead to directed networks, which may ob-             (CDI.) We assume words known by more infants at a given
scure inherent transitivity between word pairs (unless both           age have been in the lexicon longer. Here we attempt to
words have the other as their associative target). It’s not clear     replicate network structure and AoA correlations originally
whether this directedness is inherent in the lexicon. While           presented as evidence for PAT, while violating PATs assump-
asymmetry is conspicuous in human similarity judgments                tion of incremental growth. If successful, it would imply that
(Tversky, 1977), this may be a function of task rather than           scale-free structure does not itself depend on PAT.
underlying semantic representations. In the present work, we             We also test for evidence of PAQ, by determining whether
rely on neither hand-tagged features nor directed associations        words that go from being poorly-known to well-known over
in building our semantic graphs.                                      time have more connections in the externally-based network
   Given the goal of explaining how semantic structure                than those that remain poorly known over time. That is, we
emerges, a further limitation of previous work lies in the con-       test PAQ’s proposal that high degree nodes in networks gen-
stituent word nodes in the semantic networks, which used e.g.         erated from external linguistic input are acquired earlier than
free associations, Roget’s Thesaurus, and WordNet, rather             lower degree nodes in those same networks. Notably, PAQ
than child-directed corpora. In this paper, we make use of a          models do not depend on power law distributions or scale
new corpus of words from infant-caretaker interactions. This          free behavior, but rather on children selectively integrating
allows us to examine whether scale free distributions, small          salient (more densely connected) words from all possible lex-
world connectivity, and links to lexical development trajecto-        ical items they’re exposed to. If adult sampling is also inher-
ries are limited by corpus origin, and thus whether using a full      ently biased to those words which have high degree in seman-
range of concrete nouns children are exposed to in naturalistic       tic network space, then we expect too that highly frequent
settings renders different results.                                   words have higher connectivity relative to all child-directed
   Here we extend previous work and begin to address these            words. Because our corpus is generated from a large sam-
limitations by building ecologically valid semantic graphs of         ple of child-directed speech, we can further compare word
early linguistic input. We use modern vector space methods            frequency statistics with degree distributions generated using
to calculate undirected semantic relations, resulting in a gra-       the same set of words.
dient of networks parameterized by degree of similarity. We
limit network nodes to only those which infants’ hear and em-                                    Method
bed them in a space which approximates a common semantic              Data
ground shared by infants and adults alike. We also investigate
                                                                      The SEEDLingS corpus (Bergelson, 2016a, 2016b) comes
links between word frequency in the corpus, and connectivity
                                                                      from home recordings of 44 infants from upstate New York,
rank in network space.
                                                                      followed from 6 to 17 months. Each month, a daylong au-
                                                                      dio recording and hour-long video recording were collected.
                        Present Study
                                                                      All videos and 3-10 hours of each audio recording were man-
We generate networks using a new model of semantic relat-             ually tagged for concrete nouns directed to and/or attended
edness: vectors trained with GloVe (Pennington, Socher, &             by the child, creating tags of several thousand hours of nat-
Manning, 2014). We first determine whether our networks re-           uralistic interactions between infants and caregivers. We ex-
produce previously reported small world structure, and scale          clude utterances made by the child, resulting in a final dataset
invariance (i.e. power law distributions). Such structures are        of 4359 unique noun-types (194204 tokens). Plurals and
consistent with PAT or PAQ. However, only PAT proposes                diminutives were consolidated into a “basic level” proxy for
that such structures arise due to incremental growth mecha-           word lemmas for each recording. These nouns were used
nisms (Barabási & Albert, 1999). PAT suggests that words al-         to generate the SEEDLingS-All graphs. We also generate
ready in the internal lexicon guide new word selection: early         graphs for 6 month recordings alone (1855 types, 29289 to-
words have higher degree than later-added words, i.e. new ad-         kens; SEEDLingS-6mo) and a 16/17 month combined set
ditions “prefer” to attach to words with higher degree. In con-       (1708 types, 26969 tokens; SEEDLingS-16+17mo), to con-
trast, PAQ proposes that external network connectivity drives         trast networks generated from speech to pre-verbal infants
                                                                  1539

and speech to newly verbal toddlers; the SEEDLingS net-                  displayed analogous and in some cases even stronger pat-
works are our model of the external linguistic environment.              terns than the current results.4 This to us suggests consis-
We generated an additional network (WordBank), using only                tency in the linguistic manifestation of word meaning (and
the 369 nouns on the CDI; this serves as our internal semantic           perhaps their concomitant cognitive processes) at both large-
network, given that it only includes words that (some) 16-30-            and narrow-sampling scales.
month-olds produce.                                                         Similar to LSA, GloVe learns vector representations of
   As our measure of relative AoA, we used by-word sum-                  words from co-occurrence matrices built from large text cor-
mary data from the online WordBank repositories (Frank et                pora. It instantiates the distributional hypothesis of linguis-
al., 2016). This data includes productive vocabularies for               tics, famously articulated by Firth (1957): “you shall know
children aged 16 to 30 months (reported productive vocab-                a word by the company it keeps”. Because the GloVe vec-
ulary is generally more reliable than reported receptive vo-             tors encode co-occurrence statistics derived from natural lan-
cabulary.2 We make the assumption that words said by more                guage, our similarity measures also indicate the degree to
children at a given age entered the lexicon earlier. Indeed,             which two words share contextual coherence. I.e., the more
the age at which a word is produced by 50% of children, the              connections a word has in the semantic network, the more
AoA metric used by Hills et al. (2010), is significantly in-             words it shares this coherence with. Given this high dimen-
versely correlated with the percentage of production at 16, 23,          sional encoding space, we can use a continuous metric of sim-
and 30 months (r = −0.78, −0.97, and −0.88 respectively;                 ilarity. Iterating through similarity thresholds, we create a
all p < 0.005). Furthermore, AoA measures correlate with                 gradient of networks to study.
children’s elicited naming rates (Morrison, Chappell, & Ellis,
1997). We use WordBank norms rather than the SEEDLingS                   Generating Semantic Networks
infants’ own productions, as an independent and extremely                We generate graphs across a range of similarity thresholds
large-n (n = 5450, for English) estimate of children’s knowl-            (ε). Our similarity measure is the cosine between two GloVe
edge for each word in our networks, removing potential de-               vectors. The cosine function also normalizes for word fre-
pendencies in our analyses.                                              quency (to some degree) since dot products are divided by
                                                                         their vector norms. For each corpus, for each word, we cal-
GloVe Vectors                                                            culate cos(θ) between it and every other word in the set.
Since our dataset is not tagged with semantic features, and                 We give an undirected edge between two words if their co-
since results with hand-engineered features have been mixed,             sine is above a threshold ε. Since generating each graph is
we chose to follow a method described by Steyvers and                    a quadratic operation we normalize the vectors to unit length
Tenenbaum (2005) and use semantic vector space models to                 before calculating cosines. We iterate ε from 0 to 0.99 (step
generate edges between any nodes above a given similarity                size=0.01), generating a graph for each similarity threshold.
threshold. We build on their use of Latent Semantic Analysis             Further methods of edge generation are left for future re-
(LSA) vectors. In that work, LSA vectors (which along with               search. Our code and IPython notebooks are on Github5,6 .
other geometric methods, are non-incremental) did not gen-
erate scale free networks; this result was used to suggest that                            Results and Discussion
such approaches are incompatible with incremental growth
                                                                         Correlations Between Node Degree and Production
and PAT. To generate our graphs, we use pre-trained word
vectors produced by GloVe, a recently developed algorithm                We generated 100 graphs for each corpus, one for each value
for word embedding (Pennington et al., 2014). Using this al-             of ε. We calculated Spearman’s rank correlation coefficients
gorithm, we can investigate whether we find scale free and               between each word’s number of connections and productive
small world graphs; if so, the original failure to do so might           vocabulary norm (for the 369 CDI nouns), for each network
be LSA-specific, and not a necessary consequence of PAT, as              and similarity threshold, at 16, 23 and 30 months. Under
the authors suggested.                                                   both PAT and PAQ, we would expect to see that words with
   GloVe has been demonstrated to have higher perfor-                    more connectivity have higher CDI production rates. Indeed,
mance on many different word similarity tasks compared to                we find robust and significant correlations between the degree
word2vec and matrix factorization methods using SVD. Here,               of a word in the network, and the percent of toddlers who
we opted to use vectors trained on the Common Crawl cor-                 produced it, for a range of ε, across corpora and ages; Fig.1.
pus with 42 billion tokens, resulting in 300 dimensional vec-               More specifically, we find similar behavior across all net-
tors for 1.9 million unique words.3 In some sense this ’full’            works, with a global peak in correlation for ε = 0.12-0.19. All
dataset provides word similarity proxy based on the target               peak correlation values had Spearman’s ρ = 0.43-0.52, with
(i.e. adult) meanings the child is acquiring. Further analy-             p < 10−5 , showing consistent behavior across networks and
ses using vectors trained on CHILDES (MacWhinney, 2000),                 ages . This suggests that both the parent’s word choice given
    2 SEEDLingS networks contain many more nouns than the                     4 We omit these due to space, but thank an anonymous reviewer
WordBank network (resulting in different connectivity patterns), but     for this suggestion; they will be presented at CogSci.
AoA data is only available for the 369 CDI nouns for all networks             5 https://github.com/andreiamatuni/wordgraph
    3 http://nlp.stanford.edu/projects/glove/                                 6 https://github.com/BergelsonLab/semspace
                                                                     1540

a child’s age, and the child’s responsiveness to external se-      networks. At these higher thresholds a word’s neighbors
mantic density across time are roughly constant. This range        are semantically very close, similar to other semantic graphs
of ε where the correlation is at a maximum is relatively low,      which have shown scale free distributions (e.g. Roget’s The-
allowing very loose semantic associations to result in edges.      saurus), suggesting this property might depend on connec-
In Figure 2 we show a subgraph from the SEEDLingS-All              tions’ high semantic proximity. See Figure 3.
network, centered around the node “baby.”
                                                                                                        SEEDLingS All ε = 0.68
    0.5                                                                                                 SEEDLingS 6 mo ε = 0.66
                                                                                                        WordBank ε = 0.6
                                                                                    100
                                                                       # of nodes
    0.4
ρ
    0.3
                     CDI month
                      16                                                             10
                      23
                      30
                Corpus
    0.2          SEEDLingS 16+17 mo
                 SEEDLingS 6 mo
                 SEEDLingS−All                                                                               10
                 WordBank                                                                      degree (k)
          0.0         0.2             0.4   0.6         0.8
                                        ε
                                                                   Figure 3: Sample networks showing degree distributions with
Figure 1: Correlation coefficients (ρ) between number of           power law behavior (α=3.1-3.2; SE=.1, p < 0.001; similar
edges and CDI production rate across words, as a function          behavior found across networks for 0.60 ≤ ε ≤ 0.73). Distri-
of similarity threshold ε (all ρ are significant at p < 0.005).    butions are plotted on a log-log scale with logarithmic spac-
Color indicates which corpus created the network, shape in-        ing between points, which represent the edges of bins. Power
dicates which month of CDI norms was used to calculate ρ.          law distributions appear linear on this scale.
Vertical lines indicate the range in which we find scale free
degree distributions (0.6-0.73). (For thresholds ε > 0.75 there       PAT models presuppose power law distributions (indeed,
were very few (or no) edges being created, explaining the dis-     PAT was initially proposed after observing scale free distri-
continuity and lack of points towards the end of the scale.)       butions in semantic networks, and arguing that this limits the
                                                                   kinds of mechanism which could have created them). We thus
                                                                   further analyze the range of ε where our networks display
                                                                   power law behavior. Again, networks showing this distribu-
                                                                   tion are critical for PAT (and thus our CDI-based Wordbank
                                                                   networks’ proxie of an internal network), but incidental for
                                                                   PAQ, which makes no claims about power-law distributions.
                                                                      Limiting our focus to these ranges (between the vertical
                                                                   lines in Figure 1,) we see that the degree of a given word
                                                                   in the SEEDLingS-All network has uniformly higher correla-
                                                                   tion with productive vocabulary norms compared to that same
                                                                   node in the internal (i.e. WordBank) networks. (To be clear,
                                                                   we can only calculate ρ for words we have CDI norms for, but
                                                                   the SEEDLingS networks contain all the nouns infants heard,
                                                                   while the WordBank networks contain only CDI word nodes).
                                                                   This pattern is consistent with PAQ, where more densely con-
Figure 2: “Baby” subgraph from the SEEDLingS-All net-              nected words in the environment are preferentially incorpo-
work at the similarity midpoint (ε = .5), where “baby” has         rated into the learner’s lexicon. The correlation between AoA
40 neighbors.                                                      and node degree for the WordBank networks, along with their
                                                                   scale-free organization, suggest that PAT is not a necessary
                                                                   condition for this behavior, since these graphs were generated
Power Law Degree Distributions                                     using GloVe. The presence of these same correlations for our
Surprisingly, at the values of ε where the correlation is max-     other networks (which serve as a proxy of an externally-based
imal, we did not find power law distributions. We did how-         network) in this same range of ε, are also scale-free, and pro-
ever find them at higher thresholds: at ε = 0.68 we can fit a      vide new support for PAQ.
power law function with α = 3.2 ± 0.1, with a log likelihood          This pattern validates our method of generating graphs us-
ratio in favor of power law over exponential fit (R = 115.73,      ing GloVe vectors: both the WordBank and our SEEDLingS
p = 2.337 × 10−21 ). Indeed, at ε = 0.63 − 0.75 we find power      networks display behavior consistent with previous accounts
law distributions (α =2.39-3.73) characteristic of scale free      (i.e. scale free distributions in internal lexical networks
                                                                1541

and node degrees correlated with AoA). If anything, the
SEEDLingS networks show the predicted structure more                            Corpus                      ε      C        L
strongly, suggesting the nouns infants actually hear may                        SEEDLingS All               0.13   0.594    1.749
form a better representation than limiting the space to lex-                    SEEDLingS 6 mo.             0.16   0.669    1.739
ically simple, early-learned nouns alone. Our current anal-                     SEEDLingS 16+17 mo.         0.12   0.726    1.534
ysis suggests that scale-free and small world structure can                     WordBank                    0.13   0.895    1.202
be produced without an incremental growth process, since                        Erdős-Renyi                -      0.049    1.950
our graphs were generated using a vector space model (i.e.                      Watts-Strogatz              -      0.634    3.013
GloVe). If words are to be incorporated using PAQ, this ex-
ternal structure would necessarily be mirrored in the internal           Table 1: Clustering coefficients (C) and average shortest path
lexical network. However, it remains possible that PAT and               lengths (L) of the largest connected subgraph at peak values
PAQ could both be at play during infant lexical development,             from Figure 1. Generated Erdős-Renyi (n=6404, p=0.05) and
perhaps with PAQ supplementing PAT by providing a struc-                 Watts-Strogratz graphs (n=6404, k=64, p=0.05) are listed for
tured sampling space for new word selection.                             comparison.
Clustering Coefficients and Path Lengths
We next examined whether our semantic networks, based on                 model comparison of simple linear models, we find that in-
natural language to children, exhibited two key small-world              cluding both word frequency and node degree as predictors
properties found in previous research: low average path-                 of word production (at 16, 23, and 30 months) accounts for
length (L), and high clustering coefficients (C). We found that          significantly more variance than either alone (all p < .01; in-
the SEEDLingS networks generally had lower C and higher                  teraction term significantly improved model fit for months 23
L than the WordBank networks. In Table 1 we list C and                   and 30 only, both p < .01).9
L of each network at their respective peak from Figure 1.                   Finally, to better understand whether our semantic net-
We also generated Erdős-Renyi and Watts-Strogratz graphs                works find support for PAT and PAQ models, we tested one
for comparison (Watts & Strogatz, 1998; Erdős & Rényi,                 specific prediction of each. For PAT, we tested whether words
1960); Erdős-Renyi gives us a baseline measure of a compa-              that had been known longer (i.e. by proxy, were said by
rably sized graph built using a random process, while Watts-             more children) had more connections than those that had
Strogatz provides a prototypical example of a small world                not. Indeed, conducting a median split on words’ produc-
graph, with low L and high C. The SEEDLingS networks                     tion rates at each age (16, 23, and 30 months), we find that
clearly showed higher clustering coefficients and smaller av-            better known words have higher degree than less well known
erage path lengths compared to the Erdős-Renyi graph, and               words (p < 0.005 by Wilcoxon Test). For PAQ, we tested
comparable behavior to the Watts-Strogatz graph. This small              whether the words that went from less-well-known to better-
world organization is indicative of hub structures in the net-           known over 16-30 months had higher degree than those that
work, where a few very densely connected nodes establish                 remained poorly known. Indeed, for words produced below
routes between a large proportion of the graph, keeping the              the median rate at 16 months, those below the median at 30
average shortest path length low. This is also a defining fea-           months had significantly lower degree than those above it
ture of networks with power law distributions, even though               (p < .005 by Wilcoxon Test.) This supports PAQ’s proposal
the networks we’ve listed in Table 1 do not fit that criteria.           that high degree nodes in networks generated from external
This small world organization, even in the absence of power              linguistic input are acquired earlier than lower degree nodes
law distributions,7 supports previous findings in other seman-           in those same networks.
tic networks and suggest that even in child-directed natural
language input we see these structures.
                                                                                                   Conclusions
                                                                         Our results suggest there is inherent semantic structure
AoA as a Function of Frequency and Connectivity                          present in the early linguistic environment, and that both the
The SEEDLingS corpus contains word frequency counts,                     caregivers and their children are likely sensitive to this non-
a particularly powerful predictor of word acquisition                    uniform distribution of semantic information. Because the
(Goodman, Dale, & Li, 2008), allowing us to examine the                  SEEDLingS corpus provides a uniquely rich dataset of early
relationship between word frequency and network connectiv-               linguistic input, we were able to construct ecologically valid
ity.8 A positive relationship would suggest that densely con-            networks and study differences in their structure across time
nected words are preferentially sampled in adult speech di-              for a constant set of infants. Our present findings support
rected towards children. As shown above, more highly con-                previous work addressing semantic network structure. Us-
nected words were said by more toddlers, across our networks             ing a modern semantic vector space model to generate our
(at peak ε, all ρ > .51, all p < .0001; see Fig. 1). Using               graphs, we were able to confirm the presence of scale free de-
    7 Scale free networks are inherently ultrasmall (Cohen & Havlin,
                                                                         gree distributions in our networks, as well as high clustering
2003)                                                                        9 Node degrees are from the SEEDLings-All network at peak
    8 Phonological neighborhood effects are saved for future work        similarity threshold of ε = 0.13
                                                                     1542

coefficients and low average path lengths. This method for         Cohen, R., & Havlin, S. (2003). Scale-free networks are
generating semantic networks avoids the need for hand en-            ultrasmall. Physical review letters, 90(5), 058701.
gineered features and sidesteps the limits of free-association     Erdős, P., & Rényi, A. (1960). On the evolution of random
data, providing a potentially more advanced measure of se-           graphs. Publ. Math. Inst. Hung. Acad. Sci, 5(1), 17–60.
mantic relatedness compared to the original work on PAQ.           Firth, J. R. (1957). {A synopsis of linguistic theory, 1930-
   That said, the process that generated the GloVe vectors           1955}.
here is not the same as that generating any human’s lexi-          Frank, M. C., Braginsky, M., Yurovsky, D., & Marchman,
con; further work is needed to strengthen and test links be-         V. A. (2016). Wordbank: An open repository for develop-
tween these representations. Moreover, the GloVe model               mental vocabulary data. Journal of child language.
does not speak to the origin of token distributions in natu-       Goodman, J. C., Dale, P. S., & Li, P. (2008). Does frequency
ral language. It does, however, encode a geometric projec-           count? parental input and the acquisition of vocabulary.
tion of a meshwork of causal substructures present in the ex-        Journal of child language, 35(03), 515–531.
ternal world. Future research will explore the link between        Hills, T. T., Maouene, J., Riordan, B., & Smith, L. B. (2010).
these structures and their grounding in cognitive processes.         The associative structure of language: Contextual diversity
While we have taken a few steps towards examining network            in early word learning. Journal of memory and language,
growth over time (finding little difference in our 6mo. and          63(3), 259–273.
16+17mo. SEEDLingS networks, or over 16, 23, and 30mo.             Hills, T. T., Maouene, M., Maouene, J., Sheya, A., & Smith,
CDI norms), more work is needed to better understand not             L. (2009). Longitudinal analysis of early semantic net-
only whether PAT and/or PAQ-compatible processes are at              works preferential attachment or preferential acquisition?
play, but how the interplay between input and uptake changes         Psychological Science, 20(6), 729–739.
as the learner grows.                                              Kello, C. T., Brown, G. D., Ferrer-i Cancho, R., Holden, J. G.,
   In their original work, Hills et al. (2009) were not able         Linkenkaer-Hansen, K., Rhodes, T., & Van Orden, G. C.
to produce scale free graphs using their hand made features,         (2010). Scaling laws in cognitive sciences. Trends in cog-
but were able to do so using adult free association data. In         nitive sciences, 14(5), 223–232.
our own graphs we saw that the scale free property only            MacWhinney, B. (2000). The childes project: The database
manifested at relatively high values of ε, where only very           (Vol. 2). Psychology Press.
closely related words (often synonyms) were connecting to          Morrison, C. M., Chappell, T. D., & Ellis, A. W. (1997). Age
each other. Because our measure of similarity was parame-            of acquisition norms for a large set of object names and
terized, we were able to produce a gradient of networks and          their relation to adult estimates and other variables. The
study their behavior across a range of thresholds, focusing at       Quarterly Journal of Experimental Psychology: Section A,
different ranges of the scale as needed. By generating scale         50(3), 528–559.
free networks using a non-incremental procedure, we lend           Pennington, J., Socher, R., & Manning, C. D. (2014).
support to the hypothesis that this structuring may be an in-        Glove: Global vectors for word representation. In Empir-
herent feature in the external environment, rather than a con-       ical methods in natural language processing (emnlp) (pp.
sequence of how it’s integrated into internal representations.       1532–1543). Retrieved from http://www.aclweb.org/
Building on Firth: our results suggest that words may indeed         anthology/D14-1162
become known by the company they keep, and that the rele-          Sigman, M., & Cecchi, G. A. (2002). Global organization of
vant neighbors may be both those inside the lexicon, and in          the wordnet lexicon. Proceedings of the National Academy
the as-yet unknown external world of words.                          of Sciences, 99(3), 1742–1747.
                                                                   Steyvers, M., & Tenenbaum, J. B. (2005). The large-scale
                    Acknowledgments                                  structure of semantic networks: Statistical analyses and a
                                                                     model of semantic growth. Cognitive science, 29(1), 41–
We thank the SEEDLingS team, and NIH DP5-OD019812.
                                                                     78.
                                                                   Todd, P. M., Hills, T. T., & Robbins, T. W. (2012). Cognitive
                         References
                                                                     search: Evolution, algorithms, and the brain. MIT press.
Barabási, A.-L., & Albert, R. (1999). Emergence of scaling        Trier, J. (1931). Der deutsche wortschatz im sinnbezirk des
   in random networks. science, 286(5439), 509–512.                  verstandes: die geschichte eines sprachlichen feldes. 1. von
Bergelson, E. (2016a). Bergelson seedlings homebank cor-             den anfängen bis zum beginn des 13. jahrhunderts. Winter.
   pus.                                                            Tversky, A. (1977). Features of similarity. Psychological
   doi: 10.21415/T5PK6D                                              review, 84(4), 327.
Bergelson, E. (2016b). Seedlings corpus. Retrieved 2017-01-        Watts, D. J., & Strogatz, S. H. (1998). Collective dynamics
   29, from https://nyu.databrary.org/volume/228                     of ‘small-world’networks. nature, 393(6684), 440–442.
Bergelson, E., & Swingley, D. (2012). At 6–9 months, hu-
   man infants know the meanings of many common nouns.
   Proceedings of the National Academy of Sciences, 109(9),
   3253–3258.
                                                               1543

