                        PACKER: An Exemplar Model of Category Generation
                                              Nolan Conaway (nconaway@wisc.edu)
                                          Joseph L. Austerweil (austerweil@wisc.edu)
                                          Department of Psychology, 1202 W. Johnson Street
                                                         Madison, WI 53706 USA
                              Abstract                                known categories to infer the structure of new ones. They
   Generating new concepts is an intriguing yet understudied          found that the hierarchical Bayesian model provided the
   topic in cognitive science. In this paper, we present a novel      strongest account of the behavioral results.
   exemplar model of category generation: PACKER (Producing              In this paper, we introduce a novel exemplar-based ap-
   Alike and Contrasting Knowledge using Exemplar Representa-
   tions). PACKER’s core design assumptions are (1) categories        proach to category generation, PACKER (Producing Alike
   are represented as exemplars in a multidimensional psycholog-      and Contrasting Knowledge using Exemplar Representa-
   ical space, (2) generated items should be similar to exemplars     tions), which creates categories by balancing two constraints:
   of the same category, and (3) generated categories should be
   dissimilar to existing categories. A behavioral study reveals      (1) new categories should be different from known cate-
   strong effects of contrast- and target-class similarity. These     gories (minimizing between-class similarity), and (2) new
   effects are novel empirical phenomena, which are directly pre-     categories should be internally coherent (maximizing within-
   dicted by the PACKER model but are not explained by existing
   formal approaches.                                                 class similarity). As such, PACKER is a significant departure
   Keywords: Categorization, exemplar models, category gener-         from previous accounts of generation – rather than propos-
   ation, creative cognition, computational modeling.                 ing that people create categories by abstracting and re-using
                                                                      knowledge of related categories, PACKER first considers how
                          Introduction                                the generated category should differ from related categories.
The creation of new concepts and ideas is among the most              Further, it does so using the well-studied mechanics of exem-
interesting – yet infrequently studied – capabilities of human        plar representations and therefore possesses a rich connection
cognition. This paper focuses on one topic within the broader         to the wider body of research on category learning.
field of creative cognition: category generation. Foundational           In the sections below, we formally describe the PACKER
work on this topic (e.g., Smith, Ward, & Schumacher, 1993;            model and explore its predictions in a behavioral experiment.
Ward, 1994, 1995; Ward, Patterson, Sifonis, Dodds, & Saun-            We compare its performance to copy-and-tweak and hierar-
ders, 2002) has focused on the role of prior knowledge in gen-        chical Bayesian models by examining their fits to aggregate
erating novel concepts. A core phenomenon is that people              results and individual differences.
generate categories with similar distributional properties as
existing categories. For example, Ward (1994) asked partici-                          PACKER: An Exemplar Model
pants to generate species of plants and animals that might ex-        The PACKER model is an extension of the Generalized Con-
ist on other planets. Generation was strongly constrained by          text Model of category learning (GCM; Nosofsky, 1984). It
prior knowledge of Earth species: People generated species            assumes that each category is encoded by a set of exemplars
with the same features as those found on Earth (e.g., eyes,           within a k-dimensional psychological space, and that genera-
legs, wings) and possessing the same feature correlations ob-         tion is constrained by both similarity to members of the target
served on Earth (e.g., feathers co-occur with wings).                 category (the category in which a stimulus is being generated)
   Recent work has proposed and tested formal models to ex-           as well as similarity to members of other categories.
plain these observations. Jern and Kemp (2013) trained par-
                                                                         As in the GCM, the similarity between two examples,
ticipants on experimenter-defined categories composed of ex-
                                                                      s (xi , x j ), is an inverse-exponential function of distance:
emplars within an artificial three-dimensional domain. Af-
ter a short training phase, participants were asked to generate                                            (                   )
exemplars from a new category. Participants were provided                               s (xi , x j ) = exp −c ∑ xik − x jk wk       (1)
with a set of scales to adjust the feature values of each gen-                                                 k
erated stimulus, and were given unlimited time to create each
example. As in the classic Ward (1994) experiment, Jern and           where wk is the attention weighting of dimension k (wk ≥ 0
Kemp (2013) found that generated categories possessed the             and ∑k wk = 1), accounting for the relative importance of each
same feature variance and correlations as the experimenter-           dimension in similarity calculations, and c (c > 0) is a speci-
defined categories in the domain.                                     ficity parameter controlling the spread of exemplar general-
   Jern and Kemp (2013) tested several different computa-             ization. For simplicity, our simulations will use uniform at-
tional models on their data. Most relevant to the present in-         tention weights, except when otherwise noted.
vestigation, they tested a ‘copy-and-tweak’ model that gen-              To generate a new example, the model considers both the
erates items by copying and changing previous observations,           similarity to examples from contrast categories as well as the
and a hierarchical Bayesian model that uses the structure of          similarity to examples (if any exist) in the target category.
                                                                  1812

            (a) Contrast Influence                 (b) Target Influence               (c) Combination
                                                                                                                        Greatest
                                                                                                                        Probability
                          B                                    B                                  B
                    A                                     A                                  A
                                                                                                                        Lowest
                                                                                                                        Probability
             {c = 1, γ = 0, θ = 3}                 {c = 1, γ = 1, θ = 3}            {c = 1, γ = 0.5, θ = 3}
Figure 1: PACKER generation of a category ‘B’ example, following exposure to one member of category ‘A’ and category ‘B’.
The panels differ in how the trade-off between within- and between-category similarity is managed (via the γ parameter).
The aggregated similarity a between generation candidate y                 The main difference is that PACKER aggregates positive-
and stored exemplars x is:                                                 and negative-valued similarities, rather than only aggregat-
                                                                           ing positive-valued similarities. In later sections, we will ex-
                      a(y, x) = ∑ f (x j )s(y, x j )                (2)    plore the unique predictions yielded by these design princi-
                                  j                                        ples. First, however, we contrast PACKER with other cate-
 where f (x j ) is a function specifying the extent to which each          gory generation models.
exemplar contributes to the generation. A negative value for
 f (x j ) produces a ‘repelling’ effect (items are less likely to be           Previous Accounts of Category Generation
generated nearby x j ), and a positive value produces an ‘at-              Previous models of category generation focus on capturing
tracting’ effect (items are more likely to be generated nearby             the tendency for people to produce new categories that have
x j ). When f (x j ) = 0, the exemplar does not contribute to              similar distributional properties to existing categories. To the
generation.                                                                best of our knowledge, Jern and Kemp (2013) were the first
     PACKER sets f (x j ) depending on exemplar j’s category               to evaluate computational models of generation. Based on
membership: f (x j ) = γ if x j is a member of the target cat-             their work, we describe two alternative models: a formaliza-
egory, and f (x j ) = γ − 1 if x j is a member of a contrast               tion of the Path of Least Resistance hypothesis (later termed
category. γ is thus a free parameter (0 ≤ γ ≤ 1) controlling               copy-and-tweak, see Jern & Kemp, 2013), and the hierarchi-
the trade-off between within- and between-category similar-                cal sampling hypothesis (Jern & Kemp, 2013).
ity. PACKER’s core proposal is that new categories should
be different from existing categories, and same-category ex-               Copy-and-Tweak
emplars should be similar to one another. This is realized                 The copy-and-tweak model, based broadly on the earlier Path
when γ assumes an intermediate value: For example, when                    of Least Resistance view (Ward, 1994, 1995), proposes that
γ = 0.5, f (x j ) = 0.5 for members of the target category and             participants generate categories by retrieving an observation
 f (x j ) = −0.5 for members of other categories; thus, the                of the target class from memory, and then tweaking it to make
model is likely to generate items that are similar to members              something new. Jern and Kemp (2013) interpreted this pro-
of the target category but are not similar to members of other             posal in terms of an exemplar model using the GCM (Nosof-
categories. However, more extreme values can be used to                    sky, 1984). Formally, their model is equivalent to PACKER
produce different behavior, see Figure 1.                                  with γ = 1 (see Figure 1). In this case, f (x j ) = 1 for members
     The probability that a given candidate y will be generated            of the target category and f (x j ) = 0 for members of other
is evaluated using an Exponentiated Luce (1977) choice rule.               categories; thus, the model considers only target-class simi-
Candidates with greater values of a are more likely to be gen-             larity, and when no members of the target class are known,
erated than candidates with smaller values:                                the model generates items at random.
                               exp(θ · a(y, x))                               In our work we provide simulations from the copy-and-
                      p(y) =                                        (3)    tweak account, realized as a variant of PACKER with a fixed
                              ∑i exp(θ · a(yi , x))
                                                                           γ parameter. Formalizing a model family where PACKER
where θ (θ ≥ 0) controls response determinism.                             and copy-and-tweak are different parameterizations within
                                                                           the same framework is useful because comparison between
Summary                                                                    the models provides a test of the explanatory value of the con-
The proposed PACKER model suggests people generate cat-                    trast mechanism: The account provided by copy-and-tweak
egories by minimizing between-category similarity and max-                 will only equal that of PACKER if the contrast mechanism
imizing within-category similarity. The underlying processes               does not offer an advantage (i.e., if γ < 1 significantly im-
assumed by PACKER are highly similar to those in the GCM.                  proves model fits).
                                                                       1813

Hierarchical Sampling                                                                      Bottom                     Middle
Based on several results inconsistent with the copy-and-tweak
account, Jern and Kemp (2013) advocated a hierarchical
Bayesian model. Exemplars of each category were gener-                                                                  A A
ated from a multivariate Normal distribution over the dimen-                                 A A                        A A
sions of stimulus space. The mean of each category was                                       A A
independently generated, but the covariance matrix (encod-
ing feature variances and correlations) was generated from a
common prior distribution. New categories are produced by                    Figure 2: Conditions tested in the behavioral experiment.
generating a new mean (uniform over stimulus space) and co-
variance matrix from the common prior distribution. Because
the shared prior distribution’s parameters were unobserved, a
                                                                           ture of categories, but they do not make any assumptions
hierarchical Bayesian model uses information from the pre-
                                                                           about the role of between-category contrast. Indeed, when
vious categories (their feature variances and correlations) to
                                                                           there are no known examples of the target category, both
generate the covariance matrix of the new category.
                                                                           models assume that generation is random. PACKER is thus
   Each category’s exemplars are assumed to be a multivari-
                                                                           unique in its prediction that contrast categories should influ-
ate Normal distribution with parameters (µ, Σ). Each cate-
                                                                           ence both the structure and location of generated categories.
gory’s covariance matrix is assumed to be inverse-Wishart
                                                                           The behavioral experiment described below was designed to
distributed with parameters (v, κ, and ΣD ).1 ΣD is the co-
                                                                           test this key prediction.
variance matrix shared between categories. We assume the
shared covariance matrix ΣD is generated from a Wishart dis-                  The experiment follows the paradigm developed by Jern
tribution (for conjugacy) with parameters v0 , κ0 , and Σ0 . We            and Kemp (2013): first, participants learn members of a
set ν0 = 4, and Σ0 = λI, where λ is a free parameter control-              known category (‘Alpha’, or ‘A’), and are then asked to gen-
ling the expected variance of dimensions (dimensions of the                erate exemplars belonging to a new category (‘Beta’, or ‘B’).
shared covariance matrix are expected to be uncorrelated) and              We developed two Alpha categories (see Figure 2): the ‘Bot-
I is the identity matrix.                                                  tom’ Alpha category is a tight cluster in the bottom-center of
   To simplify the model predictions, we used maximum a                    the space, and the ‘Middle’ Alpha category is identical except
posteriori (MAP) estimates for the hidden parameters and                   that it lies in the center of stimulus space.
then generated new categories based on those estimates. Due                   Although our manipulation is minimal, the PACKER
to conjugacy, the MAP estimate for the shared covariance ma-               model predicts strong between-condition differences. Ac-
trix ΣD = Σ0 + ∑c Cc , where Cc is the empirical covariance                cording to PACKER, the nature of the space not occupied by
matrix of category c. The MAP estimate of the covariance                   the Alpha category should determine where members of the
matrix for the target category B is                                        Beta category are likely to be generated. Thus, the lower ar-
                                                                         eas of the stimulus space should be less frequently used for
                          κnB
 ΣB = ΣD ν +CB +                (x¯B − µB )(x¯B − µB )T (ν + nB )−1        generation in the Bottom condition compared to the Middle
                        κ + nB                                             (as these areas possess greater similarity to the Bottom Alpha
                                                                  (4)      category). Conversely, the upper areas of the stimulus space
where ν (ν > k − 1) is an additional free parameter (from the              should be used for generation more frequently in the Bottom
Inverse-Wishart prior on ΣB ) weighting the importance of ΣD .             condition compared to Middle.
When the target category has no members (i.e., nB = 0), items
                                                                              More generally, PACKER proposes that the probability a
are generated at random.
                                                                           stimulus y will be generated is a function of its similarity to
   Generated exemplars are drawn from a multivariate Nor-
                                                                           contrast categories and to members of the target category.
mal distribution specified by (µB , ΣB ). Thus, p(y) is
                                                                           Two more general predictions (not specific to either condi-
                         exp(θ · Normal(y; µB , ΣB ))                      tion) follow from this proposal: (1) the location of Beta exam-
              p(y) =                                              (5)
                       ∑i exp(θ · Normal(yi ; µB , ΣB ))                   ples should be positively related to distance from the Alpha
                                                                           category, and (2) Beta examples should be more similar to
where θ is a response determinism parameter and                            one another than they are to members of the Alpha category.
Normal(y; µ, Σ) denotes a multivariate Normal density
evaluated at y.                                                            Participants & Materials We recruited 122 participants
                                                                           from Amazon Mechanical Turk from the US equally assigned
                   Behavioral Experiment                                   to each condition. Stimuli were squares varying in color
The copy-and-tweak and hierarchical sampling models were                   (grayscale 9.8%-90.2%) and size (3.0–5.8cm). The assign-
designed to explain effects of prior knowledge on the struc-               ment of perceptual features (color, size) to axes of the domain
                                                                           space (x, y) was counterbalanced across participants.
    1 Note that Jern and Kemp (2013)’s model is slightly different, as
they used a non-conjugate model. Their model acts very similar to          Procedure Participants began the experiment with a short
our version of it and receives comparable fits.                            training phase (3 blocks of 4 trials), where they observed ex-
                                                                       1814

   B          B                              B
                                             B                                         Table 1: Behavioral results.
       A A             A A           A A             A A
       A A             A A           A A             A A                    Middle               Used top row      No top row
                                                   B
                                             B   B                          Used bottom row                  28              18
   B          B      B   B BB                B  BB
                                                                            No bottom row                    11               4
   B          B   B          B   B              BB B
                  B          B                   B
                                   B                                        Bottom               Used top row      No top row
       A A             A A       B   A A             A A                    Used bottom row                  16               8
       A A             A A       B   A A             A A                    No bottom row                    31               6
   B          B
           Figure 3: Sample generated categories.
                                                                     number of exemplars produced at different distances to the
                                                                     center of the Alpha category. These data (Figure 4 left) reveal
                                                                     a strong preference for stimuli that are dissimilar to the Alpha
emplars belonging to the ‘Alpha’ category. Participants were         category members: maximally distant items were by far the
instructed to learn as much as they can about the Alpha cat-         most frequently generated.
egory, and that they would answer a series of test questions
                                                                        Finally, we computed for each participant the average dis-
afterwards. On each trial, a single Alpha category exemplar
                                                                     tance between exemplars belonging to the same and opposite
was presented, and participants were given as much time as
                                                                     categories. These data (Figure 4 right) show that, as observed
they desired before moving on. Exemplars were randomly or-
                                                                     by Ward (1994), most people generated Beta categories in
dered within each block. Participants were shown the range
                                                                     which members are closer to one another than they are to
of possible colors and sizes prior to training.
                                                                     members of the Alpha category (i.e., more between- than
   Following the training phase, participants were asked to          within-category distance). We did however, observe a no-
generate four examples belonging to another category called          table subset of individuals with greater within-class distance.
‘Beta’. Participants were instructed that members of the Beta        These individuals tended to adopt a ‘corners’ approach, in
category could be quite similar or different depending on            which Beta examples were placed almost exclusively in the
what they think makes the most sense for the category, but           corners of the space.
that they were not allowed to make the same example twice.
As in Jern and Kemp (2013), generation was completed using           Summary
a sliding-scale interface. Two scales controlled the features of     Our results support PACKER’s predictions: People tend to
the generated example. An on-screen preview of the example           generate items that are dissimilar from the contrast category
updated whenever one of the features was changed. Partic-            and similar to the target category. We observed considerable
ipants could generate any example along an evenly-spaced             differences in generation between the Middle and Bottom
9x9 grid, except for any previously generated Beta exemplars.        conditions: Participants in the Bottom condition were less
Neither the members of the Alpha category nor the previously         likely to use the bottom row of the stimulus space for gen-
generated Beta examples were visible during generation.              eration, and participants in the Middle condition were more
Results Several sample Beta categories are depicted in Fig-          likely to create categories spanning the entire y-axis (utiliz-
ure 3. Because the conditions differ only in their location          ing the top and bottom row of the space). This latter result
along the y-axis, we first focus on how Beta exemplars are           is especially interesting as it conflicts with previous results:
generated above and below the contrast category. As is ev-           Qualitatively different types of categories were generated, de-
ident in Figure 3, we observed broad individual differences          pending only on the location of the Alphas.
in generation strategy: Whereas some participants generated             Some aspects of the results described above are somewhat
all four Beta examples within a narrow y-axis range, others          commonsense: They demonstrate that the location of existing
generated Beta examples along a wide range.                          categories imposes constraints on generation because people
   To evaluate the key predictions of PACKER, we deter-              tend to generate examples in areas not occupied by existing
mined the number of participants in each condition who               categories. This principle, however, is novel and not pre-
placed at least one Beta exemplar on the top and bottom              dicted by existing models of generation – these models were
‘rows’ of the space (the maximum and minimum possible y-             designed to explain distributional correspondences between
axis value, respectively). The resulting contingencies data are      generated and existing categories, not effects of contrast.
shown in Table 1. Fisher’s Exact Tests reveal that more Mid-
dle participants generated a Beta exemplar in the bottom row                             Model Evaluation
, p < 0.001, but the conditions did not differ in use of the top     To obtain an overall sense of each model’s ability to ex-
of the space, p = 0.16. More Middle participants placed Beta         plain our results, we fit each model by maximizing the log-
exemplars in the top and bottom rows, p = 0.038.                     likelihood of the model’s predictions of the human results.
   To evaluate PACKER’s other predictions, we computed the           The c, γ, and θ parameters were fitted for PACKER; c, and θ
                                                                 1815

                            30
 Generations Per Stimulus                               Between-Class Distance
                                        Bottom                                                                              Table 2: Model-fitting results.
                            25
                                        Middle
                            20                                                                                     PACKER         Copy & Tweak        Hierarchical
                            15                                                                                                                        Sampling
                                                                                                                   AIC = 3474     AIC = 3914          AIC = 3972
                            10
                                                                                                                   c = 0.565      c = 4.894           κ < 0.001
                             5                                                                                     γ = 0.469      γ = 1 (fixed)       ν = 4.660
                             0                                                                                     θ = 6.632      θ = 3.712           λ = 0.423
                                 Min   Distance   Max                            Within-Class Distance                                                θ = 2.771
Figure 4: Behavioral results. Left: Frequency of exemplar
generation as a function of distance from the Alpha cate-                                                   gregating over these range differences yields a gradient de-
gory normalized by the maximum possible distance. Right:                                                    scribing how categories tended to distributed for each stimu-
Within- vs. between-category distance for every participant.                                                lus. These data (Figure 5) reveal a systematic relationship be-
                                                                                                            tween category structure and location. Whereas column-like
                                                                                                            categories more often include stimuli to the left or right of
were fitted for the copy-and-tweak model (γ was fixed at 1),                                                the Alpha class, row-like categories appear above and below
and κ, λ, ν, and θ were fitted for the hierarchical sampling                                                the Alpha class. Thus, participants modify the distributional
model. Note that each model possess a θ parameter fulfilling                                                structure of new categories to the maximize distance from the
the same role (response determinism). Attention in PACKER                                                   contrast category.
and copy-and-tweak was set uniformly. Parameters were not                                                      To simulate this finding, we set the attention weight param-
allowed to vary between participants or conditions – the goal                                               eters in PACKER and copy-and-tweak per participant. The
was to obtain the best-fitting values to our entire dataset.                                                other free parameters were set as in Table 2. While there ex-
   Each model’s best-fitting parameterization is shown in Ta-                                               ist methods to find the optimal attention weights for a given
ble 2. Overall, PACKER outperformed copy-and-tweak and                                                      classification (see Vanpaemel & Lee, 2012), for simplicity we
the hierarchical sampling model by a considerable margin                                                    approximated the weights using proportionally to inverse of
(∼ 11% improvement in log-likelihood). The parameter set-                                                   each feature’s range: Thus, the Alpha and Beta categories
tings associated with PACKER’s best fit are exactly as ex-                                                  are assumed to be distinct along dimensions that the Betas do
pected: a strong preference for items that are similar to mem-                                              not vary on. To simulate the hierarchical sampling model we
bers of the target category but are dissimilar to members of                                                set the domain covariance prior, Σ0 , proportional to the range
the contrast category. A similar pattern of results was ob-                                                 (not inverted) of each feature: Thus new categories were dis-
tained when we only considered the second to fourth exem-                                                   tributed more widely along the features that each participant
plars generated by each participant.                                                                        used more widely. We then simulated 50 Beta categories with
   Our model-fitting results make sense given the assumptions                                               each participant’s weighting scheme to obtain a sense of how
made by each model. As the copy-and-tweak and hierarchical                                                  the relative importance of each dimension affects what types
sampling models are not influenced by the location of contrast                                              of categories are generated and where they are generated. The
categories within the space, they do not capture the broad ten-                                             results of these simulations are depicted in Figure 5.
dency for generated items to be dissimilar to existing classes.
                                                                                                               When the x-axis is weighted more, PACKER creates col-
Relation Between Category Structure & Location                                                              umn categories to the sides of the Alphas. Conversely, when
Generally, our behavioral results showed that members of                                                    the y-axis is weighted more, PACKER creates row categories
generated categories are dissimilar to opposite categories, and                                             above and below the Alphas. This behavior falls out from
similar to members of their own category. However, we also                                                  the nature of selective attention: Dimensions weighted more
observed a great deal of individual differences in generation                                               have a sharper similarity gradient. For example, when the x-
style. Manually inspecting the data reveals four typical pat-                                               axis is weighted more, PACKER favors Beta categories with
terns (see Figure 3): ‘corners’ categories with one Beta exam-                                              more within-class similarity (less range), and less between-
ple in each corner of the space, tight clusters, ‘column’-like                                              class similarity along the x-axis, resulting in column-like cat-
categories, and ‘row’-like categories. This informal inspec-                                                egories that differ from the Alphas along the x-axis.
tion also reveals that each of these category types tended to                                                  Although differentially weighting the features results in
be generated into distinct regions of the domain, suggesting a                                              different types of categories from the hierarchical sampling
link between category location and distributional structure.                                                and copy-and-tweak models, the location of the Alpha cate-
   To more systematically evaluate this possibility, we com-                                                gory does not affect where items will be generated by these
puted, for each stimulus in the domain, the difference in range                                             models. Thus, row- and column-like categories are not sys-
between the features (range(size) − range(color)) across ev-                                                tematically generated in different areas of the stimulus space,
ery generated category that had the stimulus as member. Ag-                                                 resulting in the uniform predictions shown in Figure 5.
                                                                                                         1816

          Behavioral             PACKER                Copy and Tweak Hierarchical Sampling
                                                                                                                  Horizontally
                                                                                                                  Aligned
 Middle
            A A                     A A                       A A                        A A                      Category
            A A                     A A                       A A                        A A
 Bottom     A A                     A A                       A A                        A A
            A A                     A A                       A A                        A A
                                                                                                                  Vertically
                                                                                                                  Aligned
                                                                                                                  Category
Figure 5: Generated category structure as a function of location. Orange areas in each gradient correspond to stimuli that were
commonly generated into category possessing greater y-axis range (columns). Purple areas correspond to categories possessing
greater x-axis range. White areas correspond to equal range along both features (or infrequent generation).
                        Discussion                                                      Acknowledgments
                                                                     Support for this research was provided by the Office of the
                                                                     VCRGE at the UW - Madison with funding from the WARF.
The creative use of conceptual knowledge is a fascinating yet        We thank Kenneth Kurtz for helpful comments, and Alan Jern
understudied topic in categorization. In this paper, we pre-         and Charles Kemp for providing code and data.
sented a novel exemplar-based approach to explaining cat-
egory generation. The PACKER model proposes that cate-                                      References
gories are represented as a collection of exemplars stored in        Jern, A., & Kemp, C. (2013). A probabilistic account of ex-
memory, and that members of generated categories should be                 emplar and category generation. Cognitive Psychology,
similar to one another, yet dissimilar to members of opposing              66(1), 85–125.
categories. Exemplar models can be viewed as Importance-             Luce, R. D. (1977). The choice axiom after twenty years.
Sampling approximations of Bayesian models (Shi, Griffiths,                Journal of mathematical psychology, 15(3), 215–233.
Feldman, & Sanborn, 2010). So, PACKER can be viewed as               Nosofsky, R. M. (1984). Choice, similarity, and the context
a rational process model, approximating the expected density               theory of classification. Journal of Experimental Psy-
of a new category based on a contrast category.                            chology: Learning, Memory, & Cognition, 10(1), 104.
                                                                     Shi, L., Griffiths, T. L., Feldman, N. H., & Sanborn, A. N.
   In a behavioral study and subsequent formal modeling, we                (2010). Exemplar models as a mechanism for perform-
found broad support for the PACKER model. Participants                     ing Bayesian inference. Psychonomic Bulletin & Re-
in our study more frequently generated items that are distant              view, 17(4), 443-464.
from members of contrast categories, and they tended to gen-         Smith, S. M., Ward, T. B., & Schumacher, J. S. (1993). Con-
erate categories with more within-class than between-class                 straining effects of examples in a creative generation
similarity. Likewise, we found that the location of contrast               task. Memory & Cognition, 21(6), 837–845.
categories (as opposed to their structure) shapes generation by      Vanpaemel, W., & Lee, M. D. (2012). Using priors to for-
imposing constraints on the areas of space that remain avail-              malize theory: Optimal attention and the generalized
able for a new category. Formal simulations reveal that exist-             context model. Psychonomic Bulletin & Review, 19(6),
ing models (see Jern & Kemp, 2013), making no assumptions                  1047–1056.
about category-contrast, do not account for these effects.           Ward, T. B. (1994). Structured imagination: The role of
   The PACKER model is, in general, highly expressive in its               category structure in exemplar generation. Cognitive
performance. Under different parameter settings it is capa-                Psychology, 27(1), 1–40.
ble of generating tightly clustered or highly distributed cate-      Ward, T. B. (1995). Whats old about new ideas. The creative
gories, and adjusting the distribution of categories along each            cognition approach, 157–178.
feature. Future work will focus on exploring the broad de-           Ward, T. B., Patterson, M. J., Sifonis, C. M., Dodds, R. A., &
gree of individual differences we observed in generation, and              Saunders, K. N. (2002). The role of graded category
whether PACKER can explain previous results in the field                   structure in imaginative thought. Memory & Cognition,
(Jern & Kemp, 2013; Ward, 1994).                                           30(2), 199–216.
                                                                  1817

