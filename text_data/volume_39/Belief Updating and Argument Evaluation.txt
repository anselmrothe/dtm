                                    Belief Updating and Argument Evaluation
                                            Megan D Bardolph (mbardolph@ucsd.edu)
                                      Department of Cognitive Science (0515), 9500 Gilman Drive
                                                         La Jolla, CA 92093 USA
                                                 Seana Coulson (scoulson@ucsd.edu)
                                      Department of Cognitive Science (0515), 9500 Gilman Drive
                                                         La Jolla, CA 92093 USA
                              Abstract                                  is reason to suspect the source or validity of the evidence,
   Studies of how evidence affects beliefs sometimes show be-
                                                                        Bayesian normative accounts still require that people update
   lief polarization in response to mixed evidence. However, the        their prior beliefs in the direction of the evidence. This up-
   nature of the mental processes leading to change in opinion is       dating can be small, but it cannot be in the opposite direction.
   up for debate. Different accounts of how people process evi-         If such a shift occurs, it should be viewed as a violation of
   dence and then update their beliefs make different predictions,
   especially about one-sided evidence, which is rarely examined.       normative updating under this model.
   We presented subjects with multiple text arguments regarding            Alternatively, differential rating of information (evidence)
   socio-political topics as one-sided or mixed evidence. Partici-
   pants rated arguments differently according to their extant be-      may be due to motivated, or hot cognition processes (Kunda,
   liefs, which is consistent with accounts of motivated reason-        1990; Ditto & Lopez, 1992). Under motivated accounts, ev-
   ing. They did not polarize afterward, instead showing evi-           idence compatible with an extant opinion is accepted, while
   dence of belief updating according to Bayesian principles: be-
   lief change is sensitive to prior opinions and to the direction      incompatible evidence creates negative emotions and is there-
   and quality of the evidence presented. These data support re-        fore critically examined and judged more negatively because
   thinking some of the mental processes underlying incorpora-          of its incompatibility. This difference in judgement can lead
   tion of evidence into a personal belief structure.
                                                                        to attitude polarization, or belief polarization.
   Keywords: cognitive science; decision making; reasoning;
   language and thought; psychology; motivated reasoning; ra-              Lord, Ross, and Lepper (1979) suggested that attitude po-
   tionality                                                            larization occurs because people with opposing views can
                                                                        come to opposite conclusions from the very same set of ev-
                           Introduction                                 idence. In a classic study, the authors queried participants
As people navigate a world filled with information, they must           about their views on capital punishment, and then revealed
make decisions in order to accomplish various goals. The be-            the results of two studies, one which suggested the death
liefs that individuals hold provide a structure in which new            penalty deters crime, and one which suggested the opposite
information is evaluated and potentially integrated with ex-            conclusion. Participants were asked to rate the quality of
isting beliefs. Different models explain how people evaluate            each study, and then to recharacterize their views on the death
information and use that information to update their beliefs,           penalty. The authors found that proponents of capital pun-
leading to potentially different implications about human ra-           ishment rated the study showing the deterrent effect of the
tionality (Oaksford & Chater, 2007; Klayman & Ha, 1987).                death penalty to be superior to that showing that the death
   Information from the world can be thought of as data, or             penalty did not affect crime levels, and subsequently adjusted
evidence, supporting or disconfirming a hypothesis. The ev-             their beliefs to more strongly favor capital punishment. By
idence may be accepted without examination or it may be                 contrast, opponents of capital punishment favored the study
judged before it is used to update one’s beliefs, or a hy-              that showed the death penalty had little effect on crime, and
pothesis (Nisbett & Ross, 1980; Pyszczynski & Greenberg,                subsequently adjusted their beliefs to more strongly oppose
1987). From a Bayesian perspective, evidence is judged ac-              capital punishment. So-called biased assimilation is the phe-
cording to existing hypotheses about the world along with               nomenon by which participants’ prior beliefs impact the way
data that has already been observed. Bayes’ rule provides               they evaluate novel evidence, and it would seem to undermine
a general model for constructing a posterior probability,               the possibility of achieving consensus (Lord, Ross, & Lepper,
P(hypothesis|data), as a function of prior beliefs and ob-              1979).
served evidence: P(hypothesis) ∗ P(data|hypothesis).                       Taber and Lodge (2006) suggest that “primacy and auto-
   People’s prior hypotheses about the world may differ de-             maticity of affect kick-start the processes that spark moti-
pending on the data they have observed. Furthermore, the                vated biases when citizens encounter attitudinally contrary
nature of people’s hypothesis space for a given topic is not            information.” Taber and colleagues (2009) found evidence
always easy to define (Tenenbaum, Kemp, Griffiths, & Good-              of an attitude congruency bias, where people evaluate ar-
man, 2011; Jern, Chang, & Kemp, 2014). Accounts of                      guments and evidence that supports their prior opinions as
Bayesian updating explicitly allow for evidence to be treated           stronger than nonsupporting information; and attitude polar-
differently depending on whether it is in agreement with one’s          ization, where this bias leads to polarization with exposure to
prior beliefs (Gerber & Green, 1999). However, unless there             the same set of information.
                                                                    1586

   The present study aims to clarify the differences between        attitude measurement.
processing compatible and incompatible evidence, separating            Strength measurements: For each issue, participants were
the effects of the two types of evidence. To do this, we will       given four questions with a 9-point Likert scale to indicate
examine evidence rating for both mixed evidence (as used            how much they cared about, and had thought about, that issue.
in prior studies) and one-sided evidence (previously miss-          These four questions were combined to form a measure of
ing from much of the literature). Studies using mixed evi-          strength of conviction.
dence imply that participants process congruent and incon-             Arguments: Using text from the websites, 6 supporting
gruent information using different processes; for example,          (Pro) and 6 opposing (Con) arguments were selected for each
readily accepting compatible arguments while spending more          issue. Arguments were generally matched for content (i.e.,
time and mental resources to undermine incompatible argu-           if a Pro and a Con argument addressed the same point, both
ments (Edwards & Smith, 1996; Taber, Cann, & Kucsova,               arguments were usually selected), and for length (mean argu-
2009). It is not clear whether compatible and incompatible          ment length = 120 words, sd = 11). To create arguments of
arguments must be presented together to activate these pro-         similar length, portions of longer arguments were omitted.
cesses or whether they apply to congruent and incongruent
arguments due to the nature of the evidence alone. The inclu-       Procedure
sion of mixed and non-mixed (one-sided) evidence allows for         The study included three phases: initial collection of attitude
examination of potential differences.                               and conviction strength measurements, the presentation and
   This study further aims to examine whether belief updat-         rating of arguments, and the subsequent collection of attitude
ing behavior supports a motivated reasoning account or a            and strength measurements.
Bayesian account of belief updating. This will be assessed by          Initial collection of attitude and strength measurements
testing whether participants’ beliefs change as a function of       proceeded one issue at a time, as participants first rated their
biased assimilation of the evidence, dependent on their prior       attitude on the issue, and then responded to the questions re-
beliefs, or whether belief change depends on the direction          garding the strength of their convictions on that issue. The
and/or merits of the evidence.                                      presentation order of the six issues was randomly determined.
                                                                       Following the collection of attitude and strength measure-
                          Methods                                   ments, each participant was asked to read and rate arguments
                                                                    for three randomly chosen issues from the original set of six.
Participants
                                                                    For these three issues, one was randomly designated as the
Participants were 124 students (75 female) enrolled in Psy-         Pro condition, such that the participant read and rated six ar-
chology, Linguistics, or Cognitive Science courses at the Uni-      guments in support of the original position; one was randomly
versity of California, San Diego (UCSD) participating as part       designated as the Con condition, such that the participant read
of a course requirement. All participants provided informed         and rated six arguments against the original position; and one
consent, and procedures were approved by the Institutional          was randomly designated as the Mix condition, such that the
Review Board (IRB) at UCSD. Participants were between 18            participant read and rated three arguments in support of the
and 35 years old, with a mean age of 21. An additional two          original position, and three arguments against. The order
participants completed the survey, but their results were not       of the issues was randomized, as was the order of the argu-
included, either because their responses suggested they did         ments presented within each issue. Treatment thus included
not understand the rating scale (n=1), or because their age         four treatment conditions: Pro, Con, Mix, and None, with the
was greater than 35 years (n=1).                                    None condition comprising four issues for which participants
                                                                    were not presented any argument text.
Materials
                                                                       After reading all arguments, participants were again asked
The study concerned six socio-political issues: abortion,           to rate their positions on all six issues. Next, participants
animal testing, assisted suicide, climate change, the death         completed a brief political knowledge quiz to assess their
penalty, and school uniforms. These issues were among               political sophistication, and two questions to assess open-
the most popular topics covered on two debate websites,             mindedness. Finally, they read a debriefing page that ex-
www.procon.org and idebate.org.                                     plained the goal of the study and provided links to the web-
   Attitude measurements: For each issue, a single policy           sites used for the argument texts.
statement was chosen for participants to rate in terms of how
much they agree or disagree (e.g., “Animal testing should be        Analysis
banned.”). This was followed by four position statements for        Opinions were scaled from -5 to 5, with -5 representing the
each issue selected from two headings under “Points for” on         opinion most against the issue and 5 representing the opinion
the idebate.org archive, and two from “Points against.” Partic-     most in favor of the issue (each issue is framed as a statement,
ipants responded to all five of these position statements, and      e.g. “The death penalty should be banned.”). Items where
these responses formed the initial attitude measurement. Af-        participants spent too long reading the argument text (more
ter the experimental treatment, participants again responded        than 153 seconds, 3 standard deviations from the mean) were
to five position statements per issue to form the subsequent        removed from analysis (28 items out of 2232).
                                                                1587

   Participants’ prior opinions and strength of conviction were
analyzed to ensure uniform representation across conditions,
since within each issue, experimental conditions (Pro, Con,
Mix, or None) were varied between subjects. A linear model
of prior opinion as a function of treatment condition and is-
sue showed that although opinions varied by issue, there were
no significant differences among conditions (Pro, Con, Mix,
None), nor was there any interaction of issue and condition.
Similarly, strength of conviction did not vary as a function of
treatment condition.
   Models of argument rating were analyzed with a linear
mixed effects regression (LMER) model using the lme4 pack-
age in R (Bates, Maechler, Bolker, Walker, et al., 2014; R
Core Team, 2015). All experimental factors were allowed to
interact initially; more complex models were compared with
more parsimonious models using model ANOVA in R. Mod-
els were fit with random intercepts for subjects and items (viz.
arguments). The reported models are those that included sta-
tistically significant predictors of argument rating and are not
statistically different from more complex models (using cut-
off p < .01).                                                        Figure 1: Average argument rating as a function of prior opin-
   Models of belief updating were analzed with a linear model        ion (-5 most opposed, 5 most in favor of the issue). Green
in R. Again, all experimental factors were allowed to in-            lines represent Pro arguments presented in the Pro and Mix
teract initially; more complex models were compared with             conditions; Red lines represent Con arguments presented in
more parsimonious models using model ANOVA in R. This                the Con and Mix conditions.
is equivalent to selecting all predictors with a significant p
value (p < .01) in the model ANOVA.
                                                                     larity (Pro or Con), prior opinion, strength of conviction, is-
                             Results                                 sue, and political sophistication. Argument polarity is coded
                                                                     separately from Condition and represents Pro and Con argu-
The present study was designed (i) to replicate patterns of ar-
                                                                     ments irrespective of which experimental condition they were
gument evaluation shown in other studies (Lord et al., 1979;
                                                                     presented in. The goal of this variable coding procedure was
Edwards & Smith, 1996; Taber et al., 2009) and (ii) to crit-
                                                                     to separate potential effects of experimental condition from
ically examine whether biased argument rating leads to be-
                                                                     effects of argument polarity.
lief updating, as suggested by a motivated account of reason-
                                                                        Our model selection procedure revealed that experimental
ing, or whether belief change can be better explained by a
                                                                     condition per se was irrelevant. The best model predicts ar-
Bayesian account in which participants are sensitive to the
                                                                     gument rating as a function of prior opinion and argument
merits of the evidence.
                                                                     polarity only. There was a trending further interaction with
   The motivated cognition account explains attitude polar-
                                                                     strength of conviction, with the slope of the rating x prior
ization as resulting from a biased assimilation of the evidence,
                                                                     opinion line being steeper for participants with high strength
such that evidence compatible with participants’ initial posi-
                                                                     of conviction (p = .015 for the 3-way interaction). Other
tions is weighted more heavily than incompatible evidence,
                                                                     experimental variables did not show main effects or interact
and consequently has a disproportionate impact on the way
                                                                     with experimental variables. The mixed effects linear model
participants update their beliefs. We first assessed whether
                                                                     includes random subject intercepts and individual argument
participants evaluated the arguments in a biased manner by
                                                                     intercepts. See Equation 1 and Table 1 for model results.
analyzing whether their ratings of these arguments differed
systematically as a function of their prior beliefs. Next, we
assessed the factors that influenced belief change in response
                                                                        Argument rating ∼ prior opinion ∗ argument polarity (1)
to these arguments.
Argument Rating
As noted above, our first question was whether participants                      Table 1: Model results for Equation 1.
rated evidence differentially as a function of its compatibility                Factor                       df F value
with their initial attitudes about the relevant issue. To exam-                 Prior opinion                1      1.5
ine this question, we began by modeling participants’ argu-                     Argument polarity            1      0.3
ment ratings with a linear mixed effects model with predic-                     Prior x Argument polarity 1        125.1
tors of treatment condition (Pro, Con, or Mix), argument po-
                                                                 1588

   Figure 1 shows how argument ratings differ as a function
of participants’ prior opinions, with separate green regression
lines shown for supporting arguments presented in the Pro
condition and in the Mix condition, and separate red regres-
sion lines for opposing arguments presented in the Con con-
dition and in the Mix condition. The positive slope of both
green lines reflects the fact that the more participants support
the issue, the higher they rate the Pro arguments compatible
with their position. The similarity in the slope of the Mix and
the Non-Mix line indicates that participants’ ratings of these
arguments were similar, regardless of whether they were pre-
sented in the context of other Pro arguments, or with a mix-
ture of Pro and Con arguments. Likewise, the negative slope
of both red lines reflects systematic bias in the ratings of op-
posing arguments, with opponents (-5 on the x-axis) rating
those arguments higher than supporters (+5 on the x-axis), ir-
respective of whether opposing arguments were presented in
a Con or a Mix block.
Belief Updating
We are interested in what factors lead to belief updating,           Figure 2: Average opinion change for each treatment condi-
or opinion change, after participants read and rate the ar-          tion. Lines represent standard error.
guments. Specifically, experimental condition might inter-
act with participants’ prior opinions, showing that belief up-
dating due to different types of evidence (i.e., that presented      participants’ opinions were more in favor of an issue after
in the Pro, Con, and Mixed conditions) differs as a function         viewing and rating arguments in the Pro condition; more op-
of their original position regarding that issue. Strength of         posed to the issue after viewing and rating arguments in the
conviction may also influence opinion change if participants         Con condition; and unchanged after viewing arguments in the
whose beliefs are stronger are either more motivated to de-          Mix condition.
fend their position or rely on a greater body of knowledge to           Overall, participants shifted their opinion toward a more
form their prior opinion. Because participants may change            moderate point of view (and also in the direction of the evi-
their opinions differently by issue, issue is also included as       dence), with participants more in favor of an issue changing
a predictor. Finally, we included a measure of political so-         their opinion to be less in favor, and those opposed changing
phistication because previous studies have suggested that so-        their opinion to be more in favor. This center-trending behav-
phisticated individuals are more likely to engage in motivated       ior is represented in the negative coefficient of prior opinion
reasoning (Taber et al., 2009).                                      in the model. Prior opinion further interacts with strength
   Opinion change was modeled as a function of treatment             of conviction such that participants with lower strength show
condition (Pro/Con/Mix), prior opinion, strength of convic-          more center-trending than do those with higher strength of
tion, issue, and political sophistication. Linear models as de-      conviction.
scribed in the Analysis section were created to investigate the         The prior opinion x strength interaction is shown in Figure
effects of these factors on opinion change. The best model to        3. Values for opinion change were baseline corrected by sub-
predict opinion change is shown in Equation 2.                       tracting prior opinion * opinion change slope for the None
                                                                     condition to show how much opinion changed when partic-
                                                                     ipants viewed and rated arguments. This visually removes
  Opinion change ∼ condition + prior opinion ∗ strength (2)
                                                                     the overall center-trending pattern observed for all conditions.
                                                                     Participants with high strength of conviction did not show a
                                                                     difference in opinion change compared to baseline. Those
             Table 2: Model results for Equation 2.
                                                                     with low strength of conviction show an additional center-
    Factor              df Estimate F value p value
                                                                     trending pattern, with participants more in favor of an issue
    Condition            2                  19.4     < .001          changing to be more opposed, and participants more opposed
    Prior opinion        1       -.41       96.2     < .001          to an issue becoming more in favor.
    Strength             1      -0.02       0.78       .38
                                                                        Finally, we were interested in whether participants’ argu-
    Prior x Strength 1          0.03        7.55      < .01
                                                                     ment ratings would influence their beliefs in addition to the
                                                                     other factors. Motivated cognition accounts would predict
   The effect of experimental condition on opinion change is         that participants who exhibit biased rating behavior will be
shown in Figure 2. On average, independent of prior beliefs,         more likely to polarize, updating their beliefs in the direction
                                                                 1589

Figure 3: Interaction of prior opinion and strength. The blue         Figure 4: Interaction of argument rating and argument polar-
line represents participants with low strength of conviction          ity. The red line represents average opinion change for Con
for a given issue, and the pink line represents those with high       arguments in the Con or Mix condition; the green line repre-
strength of conviction. Values have been corrected to remove          sents average opinion change for Pro arguments.
the center-trending slope of the None condition to show their
difference from baseline.
                                                                      3 suggests that the relationship between argument rating and
                                                                      opinion change was independent of participants prior beliefs.
of their initial opinion. By contrast, Bayesian updating pre-         That is, whether or not participants initially agreed with the
dicts that participants will rely only on the evidence. Conse-        policy embraced in a given argument, they changed their po-
quently, they will either move in the direction of the evidence       sitions to be more congruent with the arguments, especially
(irrespective of their prior beliefs), or maintain their original     for highly rated arguments.
point of view.
   Model comparison revealed that when participants’ aver-                                     Discussion
age argument rating was included as a predictor, the most par-
simonious account of opinion change is given by the factors           Argument rating
in Equation 3. As in Equation 2, the main effect of treat-            Participants rated arguments that were compatible with their
ment condition and the interaction between prior opinion and          prior policy opinions as objectively better than arguments that
strength of conviction were present. In addition to the previ-        were incompatible with those opinions. Moreover, this bias
ous predictors, opinion change is further predicted by an in-         scaled linearly with participants’ prior opinions, as those at
teraction of argument polarity and argument rating. As shown          either end of the scale showed the greatest bias in argument
in Figure 4, this interaction term results because participants’      ratings. This argument rating bias is consistent with previ-
opinions on average change to be more congruent with the po-          ous findings, potentially supporting the motivated reasoning
sition of those arguments that participants rated highly. The         account. However, these findings are also consistent with a
higher a given participant rated Pro arguments, the more their        Bayesian reasoning account in which participants at the ends
opinion changed in the positive direction. The higher they            of the scale are assumed to assign a high prior probability
rated Con arguments, the more their opinion changed in the            to their own position, and naturally assess the likelihood of
negative direction.                                                   congruent evidence to be higher than that of incongruent evi-
                                                                      dence. To dissociate motivated from Bayesian reasoning, it is
                                                                      necessary to examine the opinion change data.
   Opinion change ∼ condition + prior opinion ∗ strength
                                                                      Belief updating
                   + argument polarity ∗ argument rating      (3)
                                                                      The belief updating data provide support for a Bayesian ac-
   Figure 4 shows this interaction of argument rating x ar-           count and show that even in the presence of biased argument
gument polarity (Pro/Con). The occurrence of prior opinion            ratings, participants changed their beliefs in response to the
and argument ratings in separate, additive terms in Equation          evidence. The final model of opinion change suggested that
                                                                  1590

for any given issue, participants’ beliefs at the end of the ex-     Kunda, Z. (1990). The case for motivated reasoning. Psy-
periment depended on three independent factors: treatment              chological bulletin, 108(3), 480.
condition, an interaction between prior opinion and strength         Lord, C. G., Ross, L., & Lepper, M. R. (1979). Biased assim-
of conviction, and an interaction between argument polarity            ilation and attitude polarization: The effects of prior theo-
and argument rating. Whereas a motivated reasoning account             ries on subsequently considered evidence. Journal of per-
predicts that treatment condition will interact with prior opin-       sonality and social psychology, 37(11), 2098.
ion, we instead found that condition had an independent ef-          Nisbett, R. E., & Ross, L. (1980). Human inference: Strate-
fect. Participants who read Pro arguments adjusted their be-           gies and shortcomings of social judgment. Englewood
liefs in a positive direction, those who read Con arguments            Cliffs, NJ: Prentice-Hall.
adjusted their beliefs in a negative direction, and those in the     Oaksford, M., & Chater, N. (2007). Bayesian rationality:
Mix condition made almost no adjustment to their beliefs.              The probabilistic approach to human reasoning. Oxford
   Further, while prior opinion was highly relevant for be-            University Press.
lief change, we found no evidence for the polarization phe-          Pyszczynski, T., & Greenberg, J. (1987). Toward an integra-
nomenon predicted by motivated reasoning. In fact, partici-            tion of cognitive and motivational perspectives on social
pants with weaker convictions moved a small amount away                inference: A biased hypothesis-testing model. Advances in
from their original positions, while those with strong convic-         experimental social psychology, 20, 297–340.
tions tended to maintain their existing beliefs.                     R Core Team. (2015). R: A language and environment for
   Finally, the relationship between argument ratings and be-          statistical computing [Computer software manual]. Vienna,
lief change was more consistent with a Bayesian account than           Austria.
the biased assimilation process predicted by motivated rea-          Taber, C. S., Cann, D., & Kucsova, S. (2009). The moti-
soning. That is, with motivated reasoning we would expect              vated processing of political arguments. Political Behavior,
both highly-rated congruent arguments and low-rated incon-             31(2), 137–155.
gruent ones to lead to opinion change in the direction of par-       Tenenbaum, J. B., Kemp, C., Griffiths, T. L., & Goodman,
ticipants’ prior opinions. Instead, we saw that highly-rated           N. D. (2011). How to grow a mind: Statistics, structure,
arguments, regardless of their congruency with participants’           and abstraction. Science, 331(6022), 1279–1285.
prior beliefs, were associated with movement in the direction
of the arguments themselves. This is strong evidence in favor
of a Bayesian account and shows that even in the presence of
biased argument rating, belief change seems to be based on
the quality of the evidence itself.
                     Acknowledgments
This research was supported by a grant from the Frontiers of
Innovation Scholars Program (FISP) at UC San Diego.
                         References
Bates, D., Maechler, M., Bolker, B., Walker, S., et al. (2014).
   lme4: Linear mixed-effects models using eigen and s4. R
   package version, 1(7).
Ditto, P. H., & Lopez, D. F. (1992). Motivated skepticism:
   Use of differential decision criteria for preferred and non-
   preferred conclusions. Journal of Personality and Social
   Psychology, 63(4), 568.
Edwards, K., & Smith, E. E. (1996). A disconfirmation bias
   in the evaluation of arguments. Journal of Personality and
   Social Psychology, 71(1), 5.
Gerber, A., & Green, D. (1999). Misperceptions about per-
   ceptual bias. Annual review of political science, 2(1), 189–
   210.
Jern, A., Chang, K.-M. K., & Kemp, C. (2014). Belief po-
   larization is not always irrational. Psychological review,
   121(2), 206.
Klayman, J., & Ha, Y.-W. (1987). Confirmation, disconfir-
   mation, and information in hypothesis testing. Psychologi-
   cal review, 94(2), 211.
                                                                 1591

