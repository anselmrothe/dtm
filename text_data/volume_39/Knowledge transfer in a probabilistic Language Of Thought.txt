                    Knowledge transfer in a probabilistic Language Of Thought
                                               Samuel J. Cheyette, Steven T. Piantadosi
                                                   {scheyett, spiantad} @ ur.rochester.edu
                                                Department of Brain and Cognitive Sciences
                                            University of Rochester, Rochester NY, 14627 USA
                               Abstract                                   predicate logic, the components of which are either objects,
   In many domains, people are able to transfer abstract knowl-           relations, or attributes. The goal of a learner when presented
   edge about objects, events, or contexts that are superficially         with two situations is to make a mapping between these com-
   dissimilar, enabling striking new insights and inferences. We          ponents by finding structural correspondences, and then infer-
   provide evidence that this ability is naturally explained as the
   addition of new primitive elements to a compositional mental           ring facts about one situation from the mapping to the other.
   representation, such as that in the probabilistic Language Of             A commonality among SME and other theories of analogi-
   Thought (LOT). We conducted a transfer-learning experiment             cal transfer is their assumption of static knowledge represen-
   in which participants learned about two sequences, one after
   the other. We show that participants’ ability to learn the second      tations. But structure only captures a limited subset of human
   sequence is affected the first sequence they saw. We test two          knowledge. Other kinds of knowledge, such as learned pro-
   probabilistic models to evaluate alternative theories of how al-       cesses or algorithms are untouched by these theories. In the
   gorithmic knowledge is transferred from the first to second se-
   quence: one model rationally updates the prior probability of          poker example above, the algorithm of shuffling or bluffing
   the primitive operations in the LOT based on what was used in          may be transferred whole cloth to a new kind of poker. These
   the first sequence; the other stores previously likely hypotheses      abilities may be borrowed and incorporated into the algo-
   as new primitives. Both models perform better than baselines
   in explaining behavior, with the human subjects appearing to           rithms that reason strategically. This kind of reuse would be
   transfer entire hypotheses when they can, and otherwise updat-         much more like a programming language library—a location
   ing the prior on primitives.                                           from which pieces of algorithms can be copied and reused—
   Keywords: Knowledge transfer; Concepts; Language Of                    than just a recognition of a correspondence of pieces. Indeed,
   Thought; One-shot learning
                                                                          in the same way that SME allows for powerful new infer-
                           Introduction                                   ences based on structure, transfer of algorithmic pieces could
                                                                          be part of the answer to how children eventually acquire al-
One of the most remarkable capabilities of human cognition
                                                                          gorithmically sophisticated representations: learners who can
is the ability to rapidly create algorithms that are applicable
                                                                          transfer algorithmic pieces need not construct entirely new
to a new situation. For instance, an adult can quickly pick up
                                                                          representations each time they encounter a new domain.
a new card game, absorbing the rules and intuiting the strat-
egy. Yet even the simplest card game is complex: it requires                 Here, we experimentally and computationally test transfer
knowledge of basics like moves and turns; and it requires                 of algorithmic components of representations by modeling
complex reasoning abilities, such as general-purpose strategic            concept learning as program induction over compositional
maneuvers in games. It seems more generally that humans’                  functions, a system often called a “Language Of Thought”
capacity to infer a lot from sparse data must be undergirded              (Fodor, 1975). Under the LOT, a learner’s job is to in-
by a flexible array of useful concepts about many domains                 duce simple generative programs from primitive functions
developed over a lifetime. For example, knowing about strat-              that match their observations of the world. In essence, this
egy in Texas Hold ‘Em makes it possible to quickly pick up                model treats learning as programming: there are a small set
many other types of poker without reverting to a novice level,            of “built in” operations that must be composed correctly in or-
because requisite concepts across types of poker share simi-              der to express richer algorithmic knowledge. This family of
larities – betting, bluffing, winning hands. Yet this still leaves        models has successfully been applied to explain human be-
open the question: what are the representations and computa-              havior in many rule-learning domains (Piantadosi & Jacobs,
tions that make such effective transfer of abstract knowledge             2016), including kinship and taxonomies (Kemp et al., 2008;
in this and myriad other domains possible?                                Katz et al., 2008; Mollica & Piantadosi, 2015), number (Pi-
   Part of humans’ adeptness in learning about new domains                antadosi et al., 2012), causality, (Goodman et al., 2011), and
quickly may lie in their ability to map old conceptual struc-             words (Siskind, 1996; Piantadosi et al., 2008), among others.
tures to new ones, allowing them to infer abstract knowledge.                Unlike structure mapping theories, LOT models are able
This relational reasoning ability has often been characterized            to account for concept learning without requiring a signifi-
as “analogical” in nature (Markman, 1997), and many theo-                 cant amount of pre-developed knowledge. On the other hand,
ries of analogical inference have been proposed on this ba-               LOT models do not provide an account of humans’ ability
sis (e.g. Gick & Holyoak, 1980; Gentner, 1983; Holyoak &                  to transfer abstract knowledge between already-learned con-
Thagard, 1989; Hummel & Holyoak, 1997). Gentner’s 1983                    cepts. In general, it is an open question how LOT models
theory of “structure-mapping”, formalized later as the “Struc-            can adapt their inductive biases and primitive representations
ture Mapping Engine” (SME) (Falkenhainer et al., 1989), is                through experience.
an influential framework for describing analogical inference.                One possibility is that primitives are weighted in their prior
On this account, situations or facts are given descriptions in            according to their past utility as in the “Rational Rules” model
                                                                      222

(Goodman et al., 2008). On this account, the prior is com-
puted integrating out the production probabilities, allowing
for a reduction in the penalty for repeated use of the same pro-
duction rule. Among other things, this model has been used
to explain selective attention effects, the finding that people
tend to focus on as few features as possible to explain an ob-
servation.
   Another possible way of explaining knowledge transfer in          Figure 1: Example of display participants saw in the experi-
a LOT model is that upon learning a useful program, people           ment.
store that program as a primitive for later re-use. This ap-
proach seems potentially more powerful than only updating
priors over primitives themselves, as it could provide a ba-         Method
sis for building increasingly complex, hierarchical conceptual
                                                                     Design The task involved a repeated binary choice, in
structure. Indeed, Dechter et al. (2013) demonstrated how
                                                                     which participants had to pick between two colored sym-
program recombination and re-use can facilitate and improve
                                                                     bols (orange and blue) 15 times in learning both the train-
learning in the domains of both arithmetic and Boolean logic,
                                                                     ing and transfer sequence. There were a total of 12 stimuli
using program induction over combinatory logic expressions.
                                                                     of which 6 were designated training sequences and 6 were
Others have explored models of sub-program re-use in Prob-
                                                                     designated transfer sequences. The manipulation was a full-
abilistic Context Free Grammars, such as adaptor grammars
                                                                     factorial between-subjects design with respect to the stimuli,
(Johnson et al., 2006) and fragment grammars (O’Donnell et
                                                                     so every possible combination of these sequences was tested,
al., 2011). However, it has yet to be determined empirically
                                                                     with only two shown to any given subject. An example of
if any of these models can explain human transfer of knowl-
                                                                     the display shown to participants is given in Figure 1. Note
edge.
                                                                     that every participant in both conditions saw the exact same
   We ran a sequence-learning experiment to test human               training sequences — the differences in stimuli between con-
knowledge transfer, training people on one sequence and then         ditions were only in the transfer sequence (the second of the
testing them on a transfer sequence. We manipulated the con-         two).
gruity of the sequence pairs, corresponding to the abstract
similarity of the training and transfer sequences. The re-           Stimuli The particular stimuli we chose were partly de-
sults from our experiment suggest that having seen a con-            signed to allow for differing levels of compression in encod-
gruous sequence in the past has a significant beneficial ef-         ing in the LOT model. Some pairs of stimuli involve very
                                                                                                           N                N
fect on accuracy. We modeled participants’ learning curves           simple repetitions, e.g. ((A2 B) ) and ((A3 B) ) 1 , which in
in a probability-matching model and three probabilistic LOT          our model are expressible in short hypotheses. Other patterns
models: a Rational Rules-type model that updates the prior of        are not as efficiently compressible in our model, such as the
production rules in previously useful concepts; a model that         repetition of ((AB)2 B). But, more importantly, they were de-
adds previously useful concepts in full to its set of production     signed such that the congruous pairs had abstract similarity,
rules; and a baseline model LOT model that does not update           such that learning the first might help with learning the sec-
between training and transfer sequences. We compared the             ond. For instance, a congruous counterpart of the sequence
fit of each model to human data from our experiment. We              (A2 B3 )N is the sequence (A2 B4 )N , since a simple change to
found that the LOT model that re-uses high probability hy-           the description of one would result in the other. Every se-
potheses from training provides the best fit to the data in the      quence in the first set had a congruous counterpart in the sec-
congruous condition, and the Rational Rules model provides           ond set. The full set of stimuli is shown in Table 1, with
the best fit in the incongruous condition. These findings sug-       congruous pairs adjacent.
gest that learners transfer entire concepts when they can, and       Procedure Participants each saw two sequences, one after
otherwise prefer previously used primitives.                         the other. Starting with no information about each sequence
                                                                     and ending with the entire sequence displayed on the screen,
                         Experiment                                  participants chose the symbol they thought was most likely
We used a one-shot transfer learning paradigm in which par-          given the previous values of the sequence they could see. Af-
ticipants were shown pairs of sequences which could either           ter each guess, feedback appeared on the screen as to whether
have come from similar LOT programs or not. To determine             or not they were correct, and the correct symbol was placed at
effects of knowledge transfer, we tested whether participants’       the end of the sequence on the screen. After participants com-
overall accuracy on the the second sequence varied as a func-        pleted the first sequence, it was erased from the screen, and
tion of the first.                                                   they then completed the same task for the second sequence,
                                                                     starting from the beginning.
Participants 360 participants were recruited from Amazon
Mechanical Turk, whose ages varied from 20 to 67. They                   1 ((A2 B)N )            N
                                                                                      and ((A3 B) ) are, in full, N repetitions of AAB and
were paid 50 cents to complete the experiment, which took            AAAB, respectively. In general X N means the symbol or sequence
roughly 3-5 minutes.                                                 X repeated N times.
                                                                 223

           1.00
           0.75
Accuracy
                                                                                                                                   Incongruous
           0.50
                                                                                                                                   Congruous
           0.25
           0.00
                    0     1      2     3     4      5     6       7            8     9     10     11     12     13     14
                                                                 Trial
Figure 2: This plot shows participants’ accuracy in the transfer sequence over all 15 trials in the congruous (blue) and incon-
gruous (red) conditions. The dots on top and bottom represent participants responding correctly or incorrectly at that trial,
respectively. The decreasing transparency of squares of dots on top shows increasing numbers of correct responses, and the
fact that the blue squares on top are less transparent than the red squares on top represents better learning in the congruous
than incongruous condition. The two curves are the best-fit logistic regression predictions for the congruous and incongruous
conditions.
                                                                               The fits from this analysis are shown in Figure 2, with the
           Training                    Transfer
                   N                           N                               curves representing the best-fit regression lines for the con-
           (A2 B3 )                    (A2 B4 )                                gruous (blue) and incongruous (red) conditions.
           B5 (AB)N                    A4 (BA)N                                   Collapsing over all sequences and sequence steps in the
                 N                           N
           (A2 B)                      (A3 B)                                  transfer sequence, and just considering the average correct
                     N                           N                             response given condition, those in congruous condition re-
           (ABAB2 )                    (BABA2 )
           B6 AN                       A4 BN                                   sponded correctly more often (M = 0.75) than those in the
           BA2 BA3 BA4 ... BAi−1 BAi   ABAB2 AB3 ... ABi−1 ABi                 incongruous condition (M = 0.61). The lack of interaction
                                                                               between congruity and sequence step implies that there is a
Table 1: The full set of stimuli in our experiment is comprised of             lingering but constant beneficial learning effect in the con-
the first 15 symbols of each of these sequences. The congruous pairs           gruous condition compared to the incongruous condition, but
are adjacent, and any non-adjacent pair is considered incongruous.
                                                                               that the speed of learning in the two conditions is roughly the
The notation X N used here can be understood as N repetitions of se-
quence X. The bottom-most congruous pair is not as easily express-             same.
ible in this way, but can be understood as incrementally increasing
runs of one symbol interspersed by the other.                                                             Model
                                                                               The general modeling framework we used is a probabilistic
                                                                               Language Of Thought. In this approach there are a set of
   Participants were instructed to make their best guess about                 primitive, typed, and compositional operations, analogous to
the next value of each sequence, even if they were unsure.                     the statements that define programming languages (e.g. for
They were told nothing about whether the two sequences                         Python ’if’, ’elif’, ’while’, ’True’, etc... would be consid-
were related, only that they both involved strings of colored                  ered primitive operations). The set of operations defines the
symbols.                                                                       “grammar”, and the allowed rules for composing them are
                                                                               the rules for a Probabilistic Context Free Grammar (PCFG).
Results                                                                        The list of all possible compositions of production rules de-
Our primary concern in analysis is to determine both the ef-                   fines the entire hypothesis space. Since the number of pos-
fect of sequence step and the effect of congruity on learning                  sible hypotheses produced in our grammar is infinite, we use
the transfer sequence. To determine both in a single analysis,                 Metropolis-Hastings, a Markov Chain Monte Carlo (MCMC)
we ran a logistic regression with both factors as fixed effects                sampling method, to provide a finite approximation to the en-
as well as random subject and sequence intercepts.                             tire space.
   The results of this analysis revealed both a main effect of                    Each hypothesis H can be assigned a probability for any
sequence step (β = 0.12, z = 15.8, p < 0.001) and congruity                    observed data D, which is computed via Bayesian inference:
(β = 0.70, z = 4.69, p < 0.001). The interaction between con-                  P(H|D) ∝ P(D|H)P(H). The likelihood, P(D|H) is deter-
gruity and sequence step was not significant (z = −0.12).                      mined by how well the output of the hypothesis matches the
                                                                         224

data. The prior probability P(H) is computed according to            implemented a unigram model of the sequence to compare
the prior rule for PCFGs, which is the product of the prior          against the LOT models. The LOT models all started with
probability of each primitive production rule R composing            the same production rules, which we assumed to have a uni-
H: P(H) = ∏R∈H P(R). The highest posterior probability hy-           form prior probability. All models were implemented using a
pothesis is therefore the most concise one that fits the data.       freely available software package called LOTlib (Piantadosi,
   In the likelihood, we assume that hypotheses’ output may          2014).
be slightly noisy, giving each digit in the output sequence          Non-Updating Model In the baseline model, the primitives
a 0.01 chance of being flipped. This likelihood formulation          and their priors were fixed between the first and second se-
weights generated sequences higher in the likelihood in pro-         quence, and did not change.
portion to their similarity with the observed data. In addition      Rational Rules Model We implemented a version of the
to the intuitive plausibility of a similarity-weighting likeli-      Rational Rules model (Goodman et al., 2008), which up-
hood metric, this likelihood helps MCMC learn correct hy-            dates the priors over primitives according to their posterior-
potheses by providing a graded (non-modal) posterior space.          weighted production rule count. This corresponds to a
We performed no model fitting, and all parameters were used          Dirichlet-Multinomial model, in which counts of each pro-
“out-of-the-box”.                                                    duction rule in the Maximum A Posteriori (MAP) hypothe-
   We ran a Metropolis-Hastings sampler for 100,000 steps            sis from the training sequence are summed and subsequently
and stored the top 100 hypotheses with the highest posterior         used in computing the primitives’ priors when learning the
found on each incremental prefix of the sequence.                    transfer sequence. Since a higher count corresponds to a de-
                                                                     creased penalty for use in a tree, this is essentially a way of
Hypotheses                                                           increasing the prior for primitive production rules useful in
In our model, hypotheses output binary sequences, corre-             learning the training sequence. We assumed a uniform prior
sponding to the binary colored symbols in the experiment.            over production probabilities in the training sequence.
The production rules — which are the same across models —            Re-Use Model Upon learning a concept, people may store
are themselves operations on sequences and integers that re-         and re-use this concept as a primitive. The way we captured
turn sequences. The production rules we chose were simply            this idea in our model was by placing the MAP hypothesis
chosen to roughly be the minimal set necessary to concisely          from the end of the training sequence as a primitive for gen-
represent the sequences humans saw:                                  erating hypotheses in the transfer sequence. The hypothesis
                                                                     space over primitives was re-normalized such that the primi-
• A∞ . Returns the symbol A repeating unboundedly.
                                                                     tives retained a uniform prior probability after this primitive
• B∞ . Returns the symbol B repeating unboundedly.                   was added.
                                                                     Unigram Model We implemented a unigram model that re-
• Alternate(INT1 , INT2 ). Returns the sequence of alterna-          sponds proportionally to the probabilities of previous sym-
                                                             ∞
   tions of INT1 and INT2 . E.g. Alternate(2, 3) ⇒ (A2 B3 ) .        bols. More specifically, we modeled this as a beta-binomial
                                                                     over the counts of the digits with a uniform prior. The counts
• Increment(INT1 ). Returns the sequence of alternating rep-
                                                                     were updated starting on the first sequence and continued
   etitions of increasing length, starting from length INT1 .
                                                                     through the second sequence. This is a baseline compari-
   E.g. Increment(2) ⇒ A2 B3 A4 B5 ...AN−1 BN ....
                                                                     son, as it implements (smoothed) probability matching with-
• Append(SEQ1 , SEQ2 ). Returns SEQ2 on SEQ1 .              E.g.     out taking into account any contingency.
   Append(A2 , B2 ) ⇒ A2 B2 .
• Weave(SEQ1 , SEQ2 ). Returns SEQ2 weaved between                   Results
   SEQ1 . E.g. Weave(A2 , B2 ) ⇒ (AB)2 .
                                                                     Figure 3 shows the model’s performance (with human data
• Take(SEQ1 , INT1 ). Returns the first INT1 items from
                                                                     for comparison) at each step, collapsed over all sequences.
   SEQ1 . E.g. Take((AB)5 , 2) ⇒ AB.
                                                                     The top panels display performance in the congruous con-
• Invert(SEQ1 ). Returns the inversion of SEQ1 .            E.g.     dition and the bottom four show performance in the incon-
   Invert(B3 A) ⇒ A3 B.                                              gruous condition. It’s worth noting again that these are pre-
                                                                     dictions made with no model parameter tuning, but the rank-
   In these rules, INT could expand to the integers 1...10.          order speed of learning between models is unlikely to be af-
                                                                     fected by this. The first interesting thing to note is how well,
Models of Learning                                                   and how quickly, each of the models learns in the congruous
We implemented three different LOT models to test various            and incongruous conditions. The Re-Use model shows the
possibilities about human concept learning from experience:          greatest disparity between conditions, guessing accurately on
a baseline model which does not update; a model that updates         average 66% of the time in congruous case and 54% of the
the prior of primitives; and a model that adds previous high-        time in the incongruous case, a difference of 12%. This is
posterior programs to its set of primitives. Each model was          substantially higher than the difference in the Rational Rules
run on all 36 conditions in the experiment. Additionally, we         model (4%), the unigram model (1%), and the no-updating
                                                                 225

                                                  No−Updating                    Rational Rules                     Re−Use                       Unigram
                                  1.00
                                  0.75
                                                                                                                                                                       Congruous
Proportion Responding Correctly
                                  0.50
                                  0.25
                                  0.00                                                                                                                                               Human
                                  1.00                                                                                                                                               Model
                                  0.75
                                                                                                                                                                       Incongruous
                                  0.50
                                  0.25
                                  0.00
                                         0 1 2 3 4 5 6 7 8 9 1011121314 0 1 2 3 4 5 6 7 8 9 1011121314 0 1 2 3 4 5 6 7 8 9 1011121314 0 1 2 3 4 5 6 7 8 9 1011121314
                                                                                                  Sequence Step
Figure 3: Overall model correctness overtime in the congruous (top) and incongruous (bottom) conditions, collapsed overall all
sequences. The human data is shown in red in each plot, as comparison. The dashed line is the just the constant of y=0.5, for
comparison.
                                     Condition                  Analysis                                 No Update        Rat. Rules       Re-Use          Unigram
                                     Congruous                  Mean Squared Error (x10)                 0.57             0.37             0.17            0.65
                                     Congruous                  R2                                       0.60             0.70             0.72            0.13
                                     Congruous                  Log Likelihood                           −853             −796             -736            −870
                                     Incongruous                Mean Squared Error (x10)                 0.16             0.12             0.13            0.23
                                     Incongruous                R2                                       0.67             0.75             0.75            0.56
                                     Incongruous                Log Likelihood                           −4322            -4268            -4280           −4412
Table 2: Overall performance measured in Mean Squared Error, R2 , and Log Likelihood, for each of the models in both the
congruous and incongruous condition. The best fit for each metric is bolded. Note that the log likelihoods can be compared
like AIC values since there are no free parameters.
model (0%). This difference in the re-use model is most sim-                                                  though still not quite as large in the gap in human perfor-
ilar to humans, who responded correctly 75% of the time in                                                    mance between conditions (12% versus humans’ 14%). In-
the congruous congruous and 61% of the time in the incon-                                                     terestingly, the models display much more similar learning
gruous condition, a change of 14%.                                                                            curves in the incongruous case. This means that the dispar-
    To more precisely compare the model and human fits for                                                    ity in performance in the two conditions may be entirely due
each sequence, we report the Mean Squared Error (MSE), R2 ,                                                   to the relative benefit of congruous experience – insofar as
and Log Likelihood to aggregate human responses, for each                                                     it changes primitives or their priors beneficially – but not as
sequence and condition in Table 2. In both conditions, all the                                                much to hindrance from incongruous experience. If true, this
LOT models were significantly better fits than the unigram                                                    would predict that humans would perform about as well on
model. In the congruous condition, the Re-Use model was                                                       the transfer sequence with no training sequence at all as with
clearly a better fit than any other LOT model or the unigram                                                  an incongruous training sequence.
model. The reason it out-performs all the other models in this                                                   To understand the Re-Use model’s performance, it is in-
case is primarily that none of the others learn the sequences                                                 formative to look at the actual representations that allow it to
fast enough. In the incongruous condition, the LOT models in                                                  learn more quickly than the other models in the congruous
this case perform more similarly than in the congruous con-                                                   condition. For each sequence, the MAP hypothesis from the
dition, but the Rational Rules model provides a slightly better                                               first sequence is used in the MAP representation of the sec-
fit of the three according to each metric.                                                                    ond sequence by the final step. Indeed, it is often orders of
                                                                                                              magnitude higher in the posterior than any other hypothesis.
Discussion                                                                                                    For instance, consider the case where the model sees:
The fact that the Re-Use model has the highest accuracy in                                                                                           3
the congruous condition (and closest to human-level) sug-                                                                                ((AB)2 B)
gests that it is a better model of how humans’ inferences ben-                                                as training followed by:
efit from helpful experience. The Re-Use model also displays
                                                                                                                                                  3
the greatest disparity in accuracy between the two conditions,                                                                           ((BA)2 A)
                                                                                                        226

as transfer. The MAP hypothesis for the training sequence is                  on existing production rules is the best fit in the incongruous
displayed in orange in Figure 4.                                              condition. This provides evidence that people spontaneously
    This hypothesis gets added as a primitive, which we can                   transfer knowledge of both whole programs and their sub-
call MAP1 . The shortest program on the transfer sequence                     components when learning.
that fits the data by the final step (and before), is simply
                                                                              Acknowledgements We would like to thank Jenna Regis-
invert(MAP1 ), which is the entirety of the tree in Figure 4.
                                                                              ter, Fred Callaway, Frank Mollica, and colala for helpful com-
This, of course, generates the inverse sequence generated by
                                                                              ments and conversations.
MAP1 , which is a simple and low-cost transformation when
treating MAP1 as a primitive. The tree representing the MAP                                               References
hypothesis for the transfer sequence in the Re-Use model is                   Dechter, E., Malmaud, J., Adams, R. P., & Tenenbaum, J. B. (2013).
much higher in the prior than the MAP representation both                        Bootstrap learning via modular concept discovery. In 23rd in-
the Rational Rules model and the No-Update model con-                            ternational joint conference on artificial intelligence. Beijing,
                                                                                 China.
struct, since it only uses two primitives, compared to their
                                                                              Falkenhainer, B., Forbus, K. D., & Gentner, D. (1989). The
use of eight.                                                                    structure-mapping engine: Algorithm and examples. Artificial
                                                                                 intelligence, 41(1), 1–63.
                                                                              Fodor, J. A. (1975). The language of thought. Harvard University
                                                                                 Press.
                                                                              Gentner, D. (1983). Structure-mapping: A theoretical framework
                                                                                 for analogy. Cognitive Science, 7(2), 155 - 170.
                                                                              Gick, M. L., & Holyoak, K. J. (1980). Analogical problem solving.
                                                                                 Cognitive Psychology, 12(3), 306 - 355.
                                                                              Goodman, N. D., Tenenbaum, J., Feldman, J., & Griffiths, T. (2008).
                                                                                 A rational analysis of rule-based concept learning. Cognitive Sci-
                                                                                 ence, 32, 108-154.
                                                                              Goodman, N. D., Ullman, T. D., & Tenenbaum, J. B. (2011). Learn-
                                                                                 ing a theory of causality. Psychological review, 118(1), 110.
                                                                              Holyoak, K. J., & Thagard, P. (1989). Analogical mapping by con-
                                                                                 straint satisfaction. Cognitive science, 13(3), 295–355.
                                                                              Hummel, J. E., & Holyoak, K. J. (1997). Distributed representa-
Figure 4: The Re-Use model’s MAP hypothesis for generating rep-                  tions of structure: A theory of analogical access and mapping.
etitions of ((BA)2 A) in the congruous condition. The part in or-                Psychological review, 104(3), 427.
ange is the MAP hypothesis from learning the training sequence                Johnson, M., Griffiths, T. L., & Goldwater, S. (2006). Adaptor
((AB)2 )B, and the blue is a transformation on it, treating it as a prim-        grammars: A framework for specifying compositional nonpara-
itive production rule.                                                           metric bayesian models. In Advances in neural information pro-
                                                                                 cessing systems (pp. 641–648).
    It is also interesting that the Rational Rules model provides             Katz, Y., Goodman, N. D., Kersting, K., Kemp, C., & Tenenbaum,
                                                                                 J. B. (2008). Modeling semantic cognition as logical dimension-
the best fit in the incongruous condition, closely followed by                   ality reduction. In Proceedings of the cognitive science society
the Re-Use model. This suggests that even when people can’t                      (Vol. 30).
transfer a whole concept, they still prefer using primitives of               Kemp, C., Goodman, N., & Tenenbaum, J. (2008). Learning and
                                                                                 using relational theories. In Advances in neural information pro-
past hypotheses. One possibility to explore in the future is                     cessing systems (Vol. 20, p. 753-760).
combining the Rational Rules and Re-Use models. Another                       Markman, A. B. (1997). Constraints on analogical inference. Cog-
potentially powerful model could account for partial sub-tree                    nitive science, 21(4), 373–418.
re-use. This would reflect the possibility that people not only               Mollica, F., & Piantadosi, S. (2015). Towards semantically rich and
store useful programs in their entirety, but store useful sub-                   recursive word learning models. In Proceedings of the cognitive
                                                                                 science conference (Vol. 37).
programs. This added flexibility in recombination has been                    O’Donnell, T. J., Snedeker, J., Tenenbaum, J. B., & Goodman, N. D.
modeled using adaptor grammars (Johnson et al., 2006) and                        (2011). Productivity and reuse in language. Proceedings of the
fragment grammars (O’Donnell et al., 2011). But inference in                     33rd Annual Conference of the Cognitive Science Society.
these models is substantially more complicated than models                    Piantadosi, S.         (2014).      LOTlib: Learning and Infer-
                                                                                 ence in the Language of Thought.                   available from
considered in this paper, and the extent of human flexibility                    https://github.com/piantado/LOTlib.
in this regard remains an open question.                                      Piantadosi, S., Goodman, N., Ellis, B., & Tenenbaum, J. (2008). A
                                                                                 Bayesian model of the acquisition of compositional semantics. In
Conclusion                                                                       Proceedings of the cognitive science society (Vol. 30).
Our experiment showed that people benefit in learning a se-                   Piantadosi, S., & Jacobs, R. (2016). Four problems solved by the
                                                                                 probabilistic language of thought. Current Directions in Psycho-
quence given prior experience with an abstractly congruous                       logical Science, 25(1), 54–59.
sequence. By considering congruity as a function of similar-                  Piantadosi, S., Tenenbaum, J., & Goodman, N. (2012). Bootstrap-
ity in LOT program-space, we can understand human knowl-                         ping in a language of thought: a formal model of numerical con-
edge transfer as changes in the representations and biases of                    cept learning. Cognition, 123, 199-217.
                                                                              Siskind, J. M. (1996, Oct-Nov). A computational study of cross-
LOT models. We showed that a LOT model that treats pre-                          situational techniques for learning word-to-meaning mappings.
viously learned programs as primitive rules is the best fit to                   Cognition, 61(1-2), 1-38.
human data in the congruous condition. On the other hand,
we found that the LOT model that rationally updates the prior
                                                                          227

