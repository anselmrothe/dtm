             Decomposability and Frequency in the Hindi/Urdu Number System
                                   Chundra Aroor Cathcart (chundra.cathcart@ling.lu.se)
                                                Department of Linguistics and Phonetics
                                                            Lund University
                              Abstract                                among numbers of lower magnitude. Since these forms are
   Hindi/Urdu (HU) numbers 10–99 are highly irregular, unlike         highly frequent, this state of affairs is compatible with a dual-
   the transparent systems of most languages. I investigate the       route account of processing. I find that in general, the model
   morphological decomposability of HU numbers using a series         faces difficulties in capturing relationships between simplex
   of computational models. While these models classify most
   forms accurately, problems are encountered in high-frequency       (i.e., monomorphemic) forms (e.g., /@ssi/ ‘80’) and their
   forms of low cardinality, suggesting that some HU numbers are      complex counterparts (e.g., /cOrAsi/ ‘84’), where a more so-
   more transparent (i.e., morphologically decomposable) than         phisticated model of phonology might succeed. These results
   others. These results are compatible with a dual-route access
   model proposed for the processing of numeral forms.                provide an important baseline for future investigations into
   Keywords: numerals; computational modeling; Bayesian
                                                                      mental representations of HU numerals.
   learning; Hindi/Urdu; phonology; morphology
                                                                                               Background
                          Introduction                                The full list of numerals (taken from Comrie, n.d.) is given in
Hindi/Urdu (HU, officially considered separate languages but          Table 1. When encountering a datum like /b@jAlis/ ‘42’, lis-
differing in little other than orthography and high-register vo-      teners must infer the value of the TENS and DIGITS place with
cabulary) and most other modern Indic languages are unusual           the aid of cues in the input, and must be able to contend with
in that the numbers through 99 are highly opaque and irreg-           highly noisy allomorphy: TENS{40} and DIGITS{2} have
ular, undoubtedly posing difficulties in production and pro-          multiple surface realizations. In some cases, this allomor-
cessing for language users. This phenomenon is understud-             phy is suppletive (i.e., variants bear no phonological resem-
ied, and raises interesting questions regarding the design prin-      blance to each other). Listeners may possess the knowledge
ciples of cross-linguistic number systems, as well as the pro-        that HU is head-final, and that higher-order numerical infor-
cessing of complex morphological forms by language users.             mation generally occurs closer to the root (Hurford, 1987),
   In this paper, I investigate the mechanisms by which HU            i.e., to the right. For some numerals, it seems plausible that
users extract structure and meaning from HU number terms.             high frequency facilitates access; for instance, HU /sola/ ‘16’
I address this issue using a series of unsupervised computa-          is quite unlike other numerals with the feature DIGITS{6}, all
tional models designed to approximate HU users’ process-              of which are /ch /-initial. This is a diachronic artifact; /sola/
ing of the numerals 10–99. While it is generally agreed that          faithfully continues Sanskrit s.od.aśa-, while other forms with
number terms are acquired as individual lexical items, there          DIGITS {6} contain reflexes of an unattested dialectal variant
is good reason to hypothesize that many numbers above a cer-          *ks.(v)at.- of attested Sanskrit s.as.- ‘6’ (Turner, 1962–1966).
tain threshold of frequency are not accessed as individual lex-       It is also the only member of the teens which shows /l/ in
emes during processing, but rather via their component parts,         its allomorph of /d@s/ ‘ten’. All the same, it may be used
in line with a dual-route model of lexical storage and access         frequently enough that this twofold suppletion does not pose
(cf. Baayen, 1993). I expect that despite the irregularity of the     problems to speakers and listeners.
HU number system, users can find regular patterns in various             A major attempt to explore synchronic regularities among
cues to numerical identity in the input, particularly in low-         HU numbers is that of Bright (1969), who concludes that
frequency numbers, thus facilitating easier comprehension.            despite a lack of economy, implicit rules governing the sys-
   My methodology investigates the extent to which HU                 tem are available to language users. Berger (1992) outlines
numbers can be morphologically decomposed. Brysbaert                  the complex historical development of HU numbers; spo-
(2005) tentatively proposes a dual-route access model for En-         radic phonological reduction, analogy, and language contact,
glish numeral storage, hypothesizing that frequent, opaque            among other phenomena, have resulted in a highly irregu-
items like twelve are accessed directly, while morphologically        lar and opaque system compared to the relatively transpar-
transparent numbers of lower frequency (e.g., eighty-nine) are        ent numbers of Sanskrit, HU’s ancestor. These works aside,
processed through decomposition. In line with this view, I            many aspects of the HU numeral system remain untreated.
predict that less frequent HU numbers can be segmented and
labeled more accurately by a computational model, indicating
                                                                                        Representational issues
greater morphological transparency.                                   Abstract representation of HU numerals
   I find that a model using n-grams as phonological features         Above, I adopt the canonical abstract numerical representa-
successfully assigns most HU numeral forms to the proper              tion found in much of the literature, where each surface form
TENS / DIGITS cohort, but that, rather unsurprisingly, some           comprises two underlying factors corresponding to the TENS
highly opaque forms are misclassified. Major errors occur             and DIGITS place. I make the assumption that DIGITS{0}
                                                                  1733

                        Table 1: HU numbers 1–99; rows represent the tens place, columns the digits place
                 0        1         2          3         4          5            6           7          8          9
             0   —        ek        do         tin       cAr        pÃc         ch E        sAt        Aúh        nO
            10   d@s      gjAr@     bAr@       ter@      cOd@       p@ndr@       sol@        s@tr@      @úh Ar@    Unnis
            20   bis      Ikkis     bAis       teis      cObis      p@ccis       ch @bbis    s@ttAis    @úúAis     Untis
            30   tis      Ik@ttis   b@ttis     tæ̃tis    cÕtis     pæ̃tis       ch @ttis    sæ̃tis     @ótis      UntAlis
            40   cAlis    IktAlis   b@jAlis    tæ̃tAlis  c@VAlis    pæ̃tAlis     ch IjAlis   sæ̃tAlis   @ótAlis    UncAs
            50   p@cAs    IkjAV@n   bAV@n      tIrp@n    c@uV@n     p@cp@n       ch @pp@n    s@ttAV@n   @úúh AV@n  Uns@úh
            60   sAúh     Iks@úh    bAs@úh     tIrs@úh   cÕs@úh    pæ̃s@úh      ch IjAs@úh  s@rs@úh    @ós@úh     Unh@tt@r
            70   s@tt@r   Ikh@tt@r  b@h@tt@r   tIh@tt@r  cOh@tt@r   p@ch@tt@r    ch Ih@tt@r  s@th@tt@r  @úh h@tt@r UnjAsi
            80   @ssi     IkjAsi    b@jAsi     tIrAsi    cOrAsi     p@cAsi       ch IjAsi    s@ttAsi    @úúh Asi   n@VAsi
            90   n@Ve     IkjAnVe   bAnVe      tIrAnVe   cOrAnVe    p@cAnVe      ch IjAnVe   s@ttAnVe   @úúh AnVe  nInjAnVe
does not map to any overt phonological information. Ad-                in complex forms of /s@tt@r/ ‘70’ < Sanskrit saptatı́-, but not
ditionally, for forms such as /UntAlis/, there is a mismatch           in complex forms of /sAúh / ‘60’ < Sanskrit s.as..ti-; however,
between the abstract representation TENS{3} DIGITS{9} and              the latter decade’s complex forms contain a reduced vowel
the phonological form, since the morpheme representing the             /@/, alternating with /A/. The short vowel and geminate con-
tens place closely resembles /cAlis/ ‘40’, not /tis/ ‘30’; this        sonant found in /@ssi/ ‘80’ alternate with a long vowel and
suggests an intermediate calculation TENS{4} DIGITS{−1}.               singleton consonant in derived /-Asi/, but the short vowel
I assume that the representation DIGITS{−1} is an integral             found in /n@Ve/ does not appear in derived forms.
part of HU numerical computation and is reflected explicitly              Despite these challenges, listeners should be able to form
in the morphology.                                                     a probability distribution over possible morphemes contained
                                                                       in a complex input datum. HU’s highly fusional phonology
Surface representation of HU numerals                                  notwithstanding, listeners should be able to approximate the
Brysbaert hesitates to draw a categorical distinction be-              location of morpheme boundaries. This question is a key
tween transparent and opaque English numerals, citing semi-            part of this paper’s computational inference, and should be of
transparent forms like thirteen. Along these lines, I seek to          broad interest to phonological theory, as it has the potential to
situate HU numerals along a cline between mild and extreme             incorporate a number of strategies for morphological bound-
opacity. I quantify a number’s transparency or decomposabil-           ary detection. The models introduced in this paper draw mor-
ity via the performance of a computational model designed to           pheme boundaries on the basis of what is most likely under
segment and label HU numbers, both in terms of (1) accuracy            the current parameters of the model, and are dependent on
of the labeling and (2) low posterior uncertainty.                     distributional information found in other numerals. This task
   At the outset, I lack a principled means of separating sup-         is easier than that of many types of unsupervised segmenta-
pletive and non-suppletive allomorphy found in the system.             tion in that at most one boundary must be located per input
Numbers 11–18 exhibit three allomorphs for TENS{1}, /-d@/,             datum; however, the model must contend with a wider distri-
/-r@/ and /-l@/, all from the diachronic source -daśa-, though        bution of allomorphs which must be unified. This model does
synchronic /d/ ∼ /r/ ∼ /l/ alternations are not well known             not use external distributional information for the purpose of
in HU. Numbers 49–58 show multiple bases for TENS{5},                  segmentation (as do Harris, 1955; Saffran et al., 1996).
all descended from Sanskrit pañcāśat- ‘50’ but formally very           A question relevant to this paper concerns the types of mor-
dissimilar. I make no a priori assumptions about the status of         phological segmentation that should be permitted. Cross-
suppletive allomorphy in the morphological system, and al-             linguistically, a morphological segmentation of the type
low the model to simply group together forms according to              [b][@jAlis] might be permissible, but non-inflectional mor-
the configuration it infers. I do, however, treat DIGITS{−1}           phemes in HU tend to consist minimally of a unit with
as a separate morpheme, given its systematic occurrence.               prosodic weight. As such, I restrict the proposal distribu-
Nonparametric models (which assume an unbounded number                 tion for segmentations of HU numbers to exclude morpheme
of underlying morphological labels) may alleviate some of              boundaries following the first and penultimate segments; this
the problems that result from forcing suppletive allomorphs            additionally speeds up inference and ensures that short forms
to be classified together, which I set aside for future work.          like /bis/ ‘20’ will be treated as monomorphemic.
   A model of HU numerical processing should character-
ize the morphological structure of the data encountered. HU            Phonological features
numbers are highly fusional, exhibiting the effects of millen-         The methodology developed in this paper must capture al-
nia of phonological and morphological change. As Bright                lomorphy in the HU numeral system, inferring that differ-
reports, no economical set of rules helps to derive the surface        ent surface strings such as /-jAlis/ and /cAlis/ correspond
representations from their morphological bases. There is of-           to the same underlying morpheme, TENS{4}. I cluster al-
ten unpredictable allomorphy between simplex and complex               lomorphs together on the basis of phonological features us-
forms of a given decade: for instance, /s/ alternates with /h/         ing essentially the same likelihood formula used in unsuper-
                                                                  1734

vised Naı̈ve Bayes/Dirichlet-Multinomial classifiers, popular                                             DIGITS {2}
in bag-of-words models of document classification. This is a                                                     &
model of convenience which I find fairly effective, though it                                                         b@j|Alis
is admittedly crude; it is insensitive to positional information                                                              -
and alternations, and does not strongly penalize the absence                                                                  TENS {4}
of potentially crucial morpheme-level information.
   The model described in this paper lends itself to the use         Figure 1: Schema of a proposed morphological segmentation,
of different types of phonological features, and provides op-        tens classification, and digits classification for form /b@jAlis/
portunities to investigate model performance under features
with differing degrees of abstraction. In this paper, I limit
myself to domain-general string-based features, namely n-
grams. In many contexts, I expect segmental bigrams to
fare well in assigning cohort membership. However, there             the input) matrix ΩT (specifying a prior over feature distri-
are some cases where I fear that bigrams may fail to capture         butions associated with each label of the DIGITS and TENS
alternations caused by (among other things) deletion or in-          place, respectively), as well as a word-level vector µ repre-
sertion, as between the base /n@Ve/ ‘90’ and /-nVe/, found           senting a prior over morpheme boundary locations. I initial-
in complex forms. A unigram model will be sensitive to the           ize these matrices with symmetric concentration parameters
co-occurrence of /n/ and /V/, whereas a representation con-          αT αD , αµ , set to .1 in order to encourage sparseness, such
sisting solely of bigrams will not (on the use of separate au-       that unshared features from unrelated labels are not clumped
tosegmental tiers for consonants and vowels, see Goldsmith           together. The generative model draws probability simplices
& Riggle, 2012). I attempt to circumvent this problem with a         φDj ∼ Dirichlet(ωDj ), φTi ∼ Dirichlet(ωTi ) representing the fea-
phonological representation that uses both unigrams and bi-          ture distributions associated with levels j and i of the DIGITS
grams (though this technically violates the independence as-         and TENS place, and assumes that for every word w,
sumption of Naı̈ve Bayes). This allows the model to capture
some similarities between paradigmatically related forms that          ς ∼ Dirichlet(µ) (a simplex of morpheme boundary proba-
would otherwise be lost in a strict bigram model.                        bilities is drawn, including the probability p(m = 0),                                   / i.e.,
                                                                         the probability that there is no morpheme boundary)
                             Model                                     m ∼ Categorical(ς) (a morpheme boundary is drawn from ς)
Here, I introduce the core model employed in this paper, de-           If m = 0,    /
signed to approximate a HU speaker’s recognition of numbers                 D
                                                                           zj = 0
10–99 (I assume that 1–9 are primitives). When encountering                for each feature f ∈ w
a numerical form, the listener must determine whether it is                     f ∼ Categorical(φTi ), i ∈ {1, ..., 9}
simplex or complex. If simplex, the value of the TENS place            If m 6= 0,   /
must be inferred; if complex, the DIGITS place must be as
                                                                           For each feature f ∈ w1,...,m (through index m)
well. The model assumes that a complex form is generated
by independent draws from two mixtures, a DIGITS mixture                        f ∼ Categorical(φDj ), j ∈ {−1, 1, ..., 9}
(the labels of which correspond to the values {−1, 1, ..., 9})             For each feature f ∈ wm+1,...,|w| (from index m+1 through
and a TENS mixture (the labels of which correspond to the                    the end of the word)
values {1, ..., 9}). Because HU morphology is generally con-                    f ∼ Categorical(φTi ), i ∈ {1, ..., 9}
catenative, I make the simplifying assumption that phonolog-
                                                                     I marginalize out the parameters ς, φTi , φDj to ob-
ical elements generated by a given mixture are adjacent to
                                                                     tain         collapsed                  Dirichlet-Categorical                      updates      for
one another — i.e., that a morpheme boundary can be lo-
                                                                     p(m|µ), p(zT |ΩT ), p(zD |ΩD ). For a given word, this yields
cated somewhere in a complex form, however approximately.
                                                                     the following conditional probability if m = 0/ (adopted from
I make the assumption that the lefthand morpheme is gen-
                                                                     Yin & Wang, 2014):
erated by the digits mixture and the righthand morpheme is
                                                                                                                                                T     D
generated by the tens mixture; this convention essentially in-                        P(m = 0,         / zTi , zD = 0|zT−i , zD    −0 , Ω , Ω , µ) ∝
corporates Hurford’s insight that higher numerical elements                                                                    c( f )
                                                                                                                     ∏ f ∈w ∏n=1w c( f )−w     zT
                                                                                                                                                   + αT + n − 1      (1)
occur closer to the root, which in turn can be interpreted as                                                                                    j
                                                                                                                           |w|
prior knowledge of a morphosyntactic headedness parameter.                                                               ∏k=1 c(·)−w   T
                                                                                                                                      zj
                                                                                                                                            + FαT    +k−1
This system of numerical classification is schematized in Fig-
ure 1.                                                               If m 6= 0:  /
Inference                                                                                                     P(m, zTi , zDj |zT−i , zD               T    D
                                                                                                                                            − j , Ω , Ω , µ) ∝
                                                                                      c( f ) l                                        c( f ) r
This paper’s basic model of numeral classification assigns                ∏ f ∈λl ∏n=1
                                                                                            λm
                                                                                                 c( f )−w + αD + n − 1 ∏ f ∈λr ∏n=1λm c( f )−w          + αT + n − 1 (2)
                                                                                m                      zD
                                                                                                        j                       m                    zT
each form to one or two mixtures, given a 10 × F matrix                           m           −w
                                                                               ∏k=1 c(·)zD + FαD + k − 1
                                                                                                                       ·        |w|−m
                                                                                                                                                      i
                                                                                                                             ∏k=1 c(·)−w                T
                                                                                                                                                 T + Fα + k − 1
ΩD and a 9 × F (where F is the number of feature types in                                      j                                                zi
                                                                 1735

Above, c( f )−w zT
                   denotes the number of instances of f currently                             Inference procedure
                 i
associated with label    zTi , and c(·)−w
                                       zTi
                                           the number of instances        Inference is carried out via Markov chain Monte Carlo. I run
                                                                          different versions of the model on three chains for 10000 iter-
of any item currently       associated with label zTi    (both terms
                                                                          ations, discarding the first half of samples as burn-in. Each
exclude any instances      contributed by w); c( f )σ   signifies the
                                                                          chain is initialized by randomly segmenting and assigning
number of instances of f in element σ. For simplicity, I write
                                                                          each item to a TENS and DIGITS label. Parameters are up-
λlm for w1,...,m and λrm for wm+1,...,|w| . Once new values of
                                                                          dated via Gibbs Sampling; for each number in 10–99, a mor-
m, zTi , zDj are chosen for word w, counts for the features in λlm        phological segmentation m, a TENS label zT and if relevant,
(if m 6= 0) / and λrm can be allocated to zDj and zTi , respectively.     a DIGITS label zD are drawn conditional on the labels cur-
                                                                          rently assigned to all other data points (see eqq. 1–2). I use a
Priors on morphological segmentation
                                                                          simulated annealing procedure, raising each vector of update
For this paper’s most basic inference procedures, the prior               probabilities to the power of a constant 1γ , with γ decreasing
over morpheme boundaries is symmetric, with equal proba-                  from 10 to 1 over the course of the burn-in. Code can be
bility allocated to all possible segmentations of word w. In              found at github.com/chundrac/HUnumerals.
certain inference regimes, I employ one of two priors on seg-                I carry out an inference procedure using only bigrams as a
mentation incorporating the principle of Minimum Descrip-                 phonological feature representation (2g); this is followed by
tion Length, popular in unsupervised morphological segmen-                a regime using unigrams and bigrams (1+2g). I modify the
tation (Goldsmith, 2001; Creutz & Lagus, 2007); these priors              1+2g procedure to incorporate an MDL prior sensitive to the
favor the insertion of morpheme boundaries which minimize                 length of the current list of morph types (MDL1), followed by
the length of the code that generates the data. There are a               an MDL prior sensitive to the sum of their lengths (MDL2).
number of ways to interpret this principle. Most intuitively,             I attempted to see how the MDL1 prior (which showed better
the “code” can be construed as the list of morph types, or al-            performance) affected the bigram model. Additionally, I ran
ternatively, the sum of the lengths of morph types. Hence, an             a simulation which augmented the 1+2g/MDL1 model with a
MDL or exponential prior on morphological segmentations                   prior over component membership designed to keep clusters
disfavors analyses that add to the list, or the sum of (string)           uniform (denoted by U).1
lengths of types in the list.
   The first prior (MDL1), designed to keep the list of an-                                             Results
alyzed morphs short, assigns probability to a morphologi-                 I use the overall F-measure (Fung et al., 2003) and the V-
cal segmentation for word w proportional to the inverse of                measure (Rosenberg & Hirschberg, 2007), two evaluation
the number of morph types as currently analyzed, including                metrics designed to quantify the similarity between two clas-
the proposed segmentation for w; under the second approach                sifications, in order to monitor convergence and measure
(MDL2), the prior probability is inversely proportional to the            overall accuracy (convergence was also assessed via chain
sum of lengths of current morph types. I have employed these              log-likelihoods). I compute pairwise F- and V-measures be-
priors due to the importance of MDL in the literature on unsu-            tween the maximum a posteriori (MAP) configuration of each
pervised segmentation, but remain somewhat skeptical as to                chain to assess the degree to which chains return the same
whether HU numeral morphology can be rendered compact                     classification, interpreting values greater than .9 as a token
in the same manner as the morphology traditionally analyzed               of convergence between two chains. I evaluate each chain’s
with MDL priors (e.g., of English, Finnish, Turkish, etc.),               accuracy by computing the F- and V-measures between the
given the noisy allomorphy seen.                                          chain’s MAP configuration and the true classification of the
Priors on cluster membership                                              numbers. These values are found in Table 2. In general, MDL
                                                                          priors do not appear to improve inference for bigrams, and do
Readers may note that the above formulae depart from tradi-
                                                                          not significantly improve inference for 1+2grams.
tional Dirichlet-Multinomial mixture models in that the Chi-
                                                                             Table 3 displays the MAP configuration for the top
nese Restaurant Process prior (a rich-get-richer scheme) over
                                                                          chain (2) in the regime with highest overall accuracy
cluster membership is excluded. This prior, which makes it
                                                                          (1+2g/MDL1/U). To measure the ACCURACY with which
more likely for an item to be assigned to a cluster that al-
                                                                          this regime decomposes individual numbers, I calculate the
ready has many data points, seems inappropriate for this pa-
                                                                          F-scores for each number’s MAP TENS and DIGITS classifica-
per’s model, which iterates over one token of each number,
                                                                          tions with respect to its true TENS and DIGITS classifications,
and should learn classes of roughly equal size. In one sam-
                                                                          averaging these values. The resulting values are then aver-
pling regime, I place an exponential prior on TENS and DIG -
                                                                          aged across chains. I calculate POSTERIOR UNCERTAINTY
ITS label membership, inversely proportional to the number
of items currently assigned to the label in question (plus a                  1I  also experimented with a procedure that excluded any
concentration parameter). The intention here is to introduce              TENS / DIGITS  pairs from the proposal distribution for a given form
                                                                          that were assigned to any previous forms within a window of arbi-
a pressure toward clusters of uniform size.                               trarily chosen size. However, this exacerbated the label-switching
                                                                          problem (a trivial issue); less trivially, it was difficult to motivate a
                                                                          window size which plausibly paralleled working memory.
                                                                      1736

by averaging the entropy of the posterior sample (comprising                                                1.0    71
                                                                                                                     93
                                                                                                                     69
                                                                                                                    91
                                                                                                                     61
                                                                                                                       63
                                                                                                                       72
                                                                                                                       78
                                                                                                                        82
                                                                                                                       76
                                                                                                                        66
                                                                                                                         9262
                                                                                                                          59
                                                                                                                         83
                                                                                                                            73
                                                                                                                           98
                                                                                                                            68 426575
                                                                                                                                    96             13 12
                                                                                                                                                  18
                                                                                                                                                                                                                  70
                                                                                                                  79  8664
                                                                                                                     94
                                                                                                                     74
                                                                                                                    77
                                                                                                                  8784
                                                                                                                            95
                                                                                                                           43
                                                                                                                           97
                                                                                                                          8188
                                                                                                                             53
                                                                                                                             39
                                                                                                                             58
                                                                                                                               52
                                                                                                                               41
                                                                                                                               46
                                                                                                                              5185 4832 45      17 14      15                       1.0
                                                                                                                      57 56     5455
                                                                                                                                  47
                                                                                                                                 3836      29
                                                                                                                                          35 31
blocked draws of m, zT , zD ) for each chain.                                                               0.8          67
                                                                                                                                34
                                                                                                                                               23
                                                                                                                                            6026 22        10
                                                                                                                                                                                                                         21
                                                                                                                                                                                                                          23
                                                                                                                                                                                                                         1922   25
                                                                                                                                                                                    0.8
                                                                                                                                                                posterior entropy
                                                                                                                                              21 24
   I extract numeral frequencies from the EMILLE Hindi                                                                    89 37
                                                                                                                               99 33          19
                                                                                                                                                     11
                                                                                                                                                        30
                                                                                                                                                                                                                         27
                                                                                                 accuracy
                                                                                                            0.6                                 28
                                                                                                                                              2740
                                                                                                                                                     2520
                                                                                                                                                                                    0.6                      33
                                                                                                                                                                                                                                11
Webnews corpus (Baker et al., 2002). For each number, ac-                                                                  49         90
                                                                                                                                       70
                                                                                                                                       80                                                       82
                                                                                                                                                                                                  43
                                                                                                                             44                                                                   49
curacy and posterior uncertainty are plotted according to fre-                                              0.4                                                                     0.4                                  26
                                                                                                                                                  16                                             81 99                                10
                                                                                                                                                                                              8667 44                  3128
                                                                                                                                                                                                                                      15
quency in Figure 2, along with correlation coefficients and                                                 0.2                                                                     0.2   79    66 56 47   55
                                                                                                                                                                                                                 80        40
                                                                                                                                                                                                                            241650 20
                                                                                                                                                                                                                              14
                                                                                                                                                                                                      37    36              18
                                                                                                                                                                                                        42
p-values. Both correlations are significant (albeit noisy), pro-                                                                                                                    0.0      91
                                                                                                                                                                                             94
                                                                                                                                                                                            77 63
                                                                                                                                                                                                6489
                                                                                                                                                                                                   985846
                                                                                                                                                                                                    88
                                                                                                                                                                                                     39 34   96
                                                                                                                                                                                                            753290 45
                                                                                                                                                                                                                    35
                                                                                                                                                                                                                     2960 1713 12
                                                                                                            0.0                                    50                                       84
                                                                                                                                                                                          877157
                                                                                                                                                                                              93
                                                                                                                                                                                             61
                                                                                                                                                                                              69
                                                                                                                                                                                             74 83
                                                                                                                                                                                               76
                                                                                                                                                                                               78
                                                                                                                                                                                               7292
                                                                                                                                                                                                  62
                                                                                                                                                                                                  97
                                                                                                                                                                                                 59  5354
                                                                                                                                                                                                    68
                                                                                                                                                                                                    73
                                                                                                                                                                                                    9551  3848
                                                                                                                                                                                                         265
                                                                                                                                                                                                       541
                                                                                                                                                                                                        85                         30
viding support for the idea that the HU numbers can be pro-
                                                                                                                  4.0        5.0        6.0            7.0                                4.0          5.0             6.0      7.0
cessed via a dual-route model. As seen in the lefthand plot,
                                                                                                                              log frequency                                                            log frequency
the majority of HU numbers occupy a quasi-Pareto frontier,
indicating an efficient trade-off between decomposability and
frequency. Several numbers in the teens (seen in the upper                                        Figure 2: Log frequency as a predictor of model accuracy
righthand corner of the plot) are both highly frequent and de-                                    (ρ = −.55, p < .001) and post. uncertainty (ρ = .38, p < .001)
composable. These outliers in no way contradict the dual-
route model, since a form’s decomposability does not pre-
clude the possibility that it is stored whole. However, a hand-
ful of numbers are found beneath the frontier (near the lower
lefthand corner), meaning that they are both relatively infre-                                    poorly. Forms containing the TENS{5} allomorphs /-p@n/ ∼
quent and difficult to parse. These items can be viewed as                                        /-V@n/ are grouped together, due to their agreement in two out
vulnerable points in the grammar of HU numbers, and may                                           of three segments. Surprisingly, /sol@/ ‘16’ was recognized
be prone to “leakage” or analogical restructuring.                                                as a member of the teens, despite the unique allomorph /-l@/;
   Table 2: F-/V-measures for different inference regimes                                         however, the model failed to properly classify it according
                    TEN         DIG             TEN      DIG            TEN          DIG          to its digits place. Other forms with highly suppletive allo-
 convergence            chain 1–2                chain 1–3                  chain 2–3
 2g                .88/.87     .77/.74      .86/.86     .81/.78        .92/.91      .95/.93       morphy (e.g., /UncAs/ ‘49’) were misclassified. Additionally,
 2g,/MDL1          .77/.80     .86/.82      .78/.81     .85/.84        .87/.84      .90/.88       many simplex forms were not analyzed as monomorphemic,
 1+2g              .88/.86     .89/.88      .90/.88     .90/.89        .99/.98      .99/.99
 1+2g/MDL1         .93/.89     .95/.95      .94/.91     .95/.95        .99/.98         1/1        unless only a monomorphemic analysis was permitted under
 1+2g/MDL2         .94/.92     .95/.94      .94/.92     .95/.94           1/1         1/1
 1+2g/MDL1/U       .88/.87     .92/.92      .89/.89     .92/.92        .97/.96         1/1        the proposal distribution.
 over. accuracy          chain 1                  chain 2                     chain 3                As stated above, my results show that the HU numeral sys-
 2g                .81/.81     .76/.74      .82/.84     .86/.84        .87/.88      .92/.89
 2g/MDL1           .78/.79     .82/.80      .80/.82     .89/.88        .80/.81      .85/.83       tem’s design is largely compatible with a dual-route model of
 1+2g              .87/.86     .89/.87      .91/.91     .90/.88        .91/.91      .92/.89
 1+2g/MDL1         .90/.89     .88/.86      .91/.91      .9/.88        .91/.91       .9/.88       access. In general, high-frequency items were more difficult
 1+2g/MDL2         .88/.87     .90/.88      .91/.91      .9/.87        .91/.91       .9/.87       for a computational model to decompose, indicating greater
 1+2g/MDL1/U       .91/.89       .9/.9      .93/.91     .92/.89         .91/.9      .92/.89
                                                                                                  opacity. (Berger shows that many of these numbers were his-
Table 3: MAP configuration for 1+2g/MDL1/U, chain 2.                                              torically subject to erosion and evidently resistant to analog-
Rows represent tens classification; columns represent digits                                      ical changes that would otherwise make them more transpar-
classification. Numbers are represented by cardinality for                                        ent and perceptually distinct.) At the same time, there are ex-
readability. Asterisks (∗) mark numbers where the numerical                                       ceptions to this generalization: certain high-frequency items
representation TENS{i}, DIGITS{9} maps to the representa-                                         in the teens showed high accuracy, though this does not rule
tion TENS{i + 1}, DIGITS{−1}                                                                      out the possibility that they are stored whole. Additionally,
 35           34      31                 29∗      32    36        38                 30           some problematic items are more opaque than would be ex-
 75    77,    74      71      73         69∗      72    76        78
       70                                                                                         pected, given their low frequency. It is likely that such vul-
 15    17,    14              13                  12              18        11       10
       16                                                                                         nerable forms cause problems in planning and production.
 65    67     64      61      63         59∗      62    66        68                 60              The EMILLE Spoken Hindi corpus contains intrigu-
 44,   47,    40      41      43         39∗,     42    46        28,
 45    27                                49∗                      48                              ing numeral variants (e.g., /iúh jAnVe/ ‘91’ by speaker
 25    37     24      21      33,        19∗      22    26                           20
                              23                                                                  ehinsp041, /sIntIjAnVe/ ‘97’ by ehinsp035, /UnAnVe/ ‘89’ by
 95    97     94      91      93                  92    96        98        90,                   ehinsp044), though the data are too sparse to serve as the
                                                                            99
 55    57     54      51      53                  52    56        58                              basis of a rigorous quantitative study. Many numbers are
 50,   87     84      81      83         79∗      82    86        88,       89
 85                                                               80                              missing in the corpus; furthermore, the variation observed
                                                                                                  may stem from sources other than production difficulty, in-
                               Discussion                                                         cluding transcriber error, multilingualism (with another In-
The models presented in this paper show that although HU                                          dic language; for example, speaker ehinsp017 utters the form
numerals 10–99 are morphologically irregular, a large num-                                        /bAvis/ ‘22’, standard in Marathi but not HU), and stylis-
ber can be classified according to their component parts.                                         tic factors. Studies of variability in the production of HU
However, quite a few forms are difficult to decompose, most                                       numerals — either in experimental contexts or naturalistic
of them of low magnitude and high frequency. In general, the                                      speech — will serve as a valuable research direction, par-
models handled some types of allomorphy well, and others                                          ticularly with an eye to whether vulnerable forms (i.e., sub-
                                                                                              1737

optimal forms with higher opacity than expected relative to                  Berger, H. (1992). Modern Indo-Aryan. In J. Gvoz-
frequency) are subject to greater instability.                                 danović (Ed.), Indo-European numerals (Vol. 57, p. 243-
                                                                               287). Berlin: Walter de Gruyter.
                            Conclusion                                       Bright, W. (1969). Hindi numerals. Working Papers in Lin-
In this paper, I have employed a simple and somewhat crude                     guistics (University of Hawaii), 9, 29-47.
model of allomorphy, inspired in part by bag-of-words mod-                   Brysbaert, M. (2005). Number recognition in different for-
els used in document classification and intended to serve as a                 mats. In J. I. Campbell (Ed.), Handbook of mathematical
baseline for future work. A goal of this study was to test the                 cognition (p. 23-42). New York, Hove: Psychology Press.
limits of a simple mixture model in a HU numerical recogni-                  Comrie, B. (n.d.). Typology of numeral systems. Avail-
tion task. A more sophisticated model of phonological pro-                     able at https://mpi-lingweb.shh.mpg.de/numeral/
cesses may relate potential allomorphs to each other in terms                  TypNumCuhk 11ho.pdf. Accessed 1 October 2016.
of edits, as has been done in some MDL approaches (Virpioja                  Creutz, M., & Lagus, K. (2007). Unsupervised models for
et al., 2010). However, while such models can contend with                     morpheme segmentation and morphology learning. ACM
or recover relatively regular allomorphy, no model has been                    Transactions on Speech and Language Processing, 4, 1-
designed, to my knowledge, to capture the highly noisy allo-                   34.
morphy found in the HU numeral system.                                       Fung, B. C. M., Wang, K., & Ester, M. (2003). Hierarchical
   A true test of any computational model’s value is in how                    document clustering using frequent itemsets. In Proceed-
well it agrees with human performance. A future direction for                  ings of the SIAM International Conference on Data Min-
this work will involve carrying out experimental research to                   ing.
see how HU speakers process and produce numerical forms.                     Goldsmith, J. (2001). Unsupervised learning of the mor-
It will serve us well to see how model inaccuracy fares as                     phology of a natural language. Computational Linguistics,
a predictor of greater response latency in psycholinguistic                    27(2), 153-198.
tasks. A joint approach which considers limitations in both                  Goldsmith, J., & Riggle, J. (2012). Information theoretic
experimental performance and computational simulation will                     approaches to phonological structure: the case of Finnish
help us identify weak points in this and other complex mor-                    vowel harmony. Natural Language and Linguistic Theory,
phological systems that can potentially (though not obligato-                  30, 859-896.
rily) undergo analogical change.                                             Harris, Z. S. (1955). From phoneme to morpheme. Language,
   I have shown that frequency may facilitate the processing                   31(2), 190-222.
of more opaque HU numbers, but the question remains as                       Hurford, J. R. (1987). Language and number: The emergence
to why most Indic number systems are on average more ir-                       of a cognitive system. Oxford: Blackwell.
regular than exact number systems found in other languages.                  Rosenberg, A., & Hirschberg, J. (2007). V-measure: A con-
Sociocultural factors may be partially responsible,2 and their                 ditional entropy-based external cluster evaluation measure.
role in shaping cross-lingustic number systems should be                       In Proceedings of the 2007 Joint Conference on Empiri-
taken into account along with that of functional need (cf. Xu                  cal Methods in Natural Language Processing and Compu-
& Regier, 2014).                                                               tational Natural Language Learning (p. 410-20). Prague:
                                                                               Association for Computational Linguistics.
                      Acknowledgements                                       Saffran, J. R., Newport, E. L., & Aslin, R. N. (1996). Word
I am grateful to Stephan Meylan, Terry Regier, and three                       segmentation: The role of distributional cues. Journal of
anonymous reviewers for helpful comments. All errors and                       Memory and Language, 35, 606-21.
infelicities are my own responsibility.                                      Turner, R. L. (1962–1966). A comparative dictionary of the
                                                                               Indo-Aryan languages. London: Oxford University Press.
                             References                                      Virpioja, S., Kohonen, O., & Lagus, K. (2010). Unsupervised
Baayen, R. H. (1993). On frequency, transparency and pro-                      morpheme analysis with Allomorfessor. In C. Peters et al.
   ductivity. In G. Booij & J. van Marle (Eds.), Yearbook of                   (Ed.), CLEF 2009 Workshop, Part I (Vol. 6241, p. 609-
   morphology 1992 (p. 181-208). Dordrecht: Kluwer.                            616). Heidelberg: Springer.
Baker, P., Hardie, A., McEnery, T., Cunningham, H., &                        Xu, Y., & Regier, T. (2014). Numeral systems across lan-
   Gaizauskas, R. (2002). EMILLE, a 67-million word corpus                     guages support efficient communication: From approxi-
   of Indic languages: Data collection, mark-up and harmon-                    mate numerosity to recursion. In P. Bello, M. Guarini,
   isation. In Proc. LREC 2002 (p. 819-825).                                   M. McShane, & B. Scassellati (Eds.), Proceedings of the
                                                                               36th annual meeting of the Cognitive Science Society.
    2 It is well known that South Asia is home to rigid societal hierar-
                                                                             Yin, J., & Wang, J. (2014). A Dirichlet Multinomial Mix-
chies, and historically, exact number systems may have been the pre-
serve of elite groups, while marginal groups relied on an alternative          ture Model-based approach for short text clustering. In
system (prior to language standardization). While this theory is bla-          KDD ’14: Proceedings of the 20th ACM SIGKDD Interna-
tant speculation, it is worth briefly noting that Sinhala, an Indic lan-       tional Conference on Knowledge Discovery and Data Min-
guage whose speakers chiefly practice Buddhism (which preaches a
doctrine of egalitarianism), developed a transparent number system.            ing (p. 233-242). New York: ACM.
                                                                         1738

