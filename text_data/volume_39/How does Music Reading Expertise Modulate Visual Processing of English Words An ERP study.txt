How does Music Reading Expertise Modulate Visual Processing of English Words?
An ERP study
Tze Kwan, Li (saralis@hku.hk)
Hei Yan Veronica, Chan (veron919@connect.hku.hk)
Luhe Li (rhys@connect.hku.hk)
Janet H. Hsiao (jhsiao@hku.hk)
Department of Psychology, University of Hong Kong
627 Jockey Club Tower, Pokfulam Road, Hong Kong SAR
Abstract
Music notation and English word reading have similar visual
processing requirements. It remains unclear how the two
skills influence each other. Here we investigated the modulation of music reading expertise on visual processing of English words through an ERP study. Participants matched English real, pseudo, and non-words preceded by musical segments or novel symbol strings in a sequential matching task.
Musicians showed smaller N170 amplitude in response to
English non-words preceded by musical segments than by
novel symbol strings in the right hemisphere. This effect was
not observed in real or pseudo-words, or in any of nonmusicians’ responses. Similar to English non-words, musical
segments do not have morphological rules or semantic information, giving rise to this modulation effect. This finding
suggested a shared visual processing mechanism in the right
hemisphere between music notation and English non-word
reading, which may be related to serial symbol processing as
suggested by previous studies.
Keywords: Music reading expertise; EEG; event-related potential (ERP); English word reading

Introduction
Recent research has shown that different perceptual expertise domains can influence each other. For example, car
perception was interfered by concurrent face perception in
car experts (presumably also face experts) but not in car
novices, suggesting shared neural processing mechanisms
between car and face recognition expertise (Gauthier, Curran, Curby & Collins, 2003). In an ERP study, Rossion,
Kung, and Tarr (2004) showed that expertise with Greebles
led to a decrease in N170 in response to faces with concurrent Greeble presentation, suggesting competition between
expertise domains in early perceptual processing.
Similarly, music notation and English word reading expertise may influence each other due to their similarities in
visual processing. For example, both music notation and
English word reading involve decomposing visual input into
components (i.e., letters or notes) for mapping to components in sounds (i.e., phonemes or pitches; Brown, Martinez
& Parsons, 2006; Hsiao & Lam, 2013). The requirement of
grapheme-phoneme conversion in English word reading has
been suggested to lead to a strong left hemisphere (LH) lateralization. For example, a right visual field (RVF)/LH advantage has been found in word naming (e.g. Brysbaert &
d’Ydewalle, 1990). Consistent with these findings, fMRI
studies have shown a region inside the left fusiform area

responding selectively to words (e.g. McCandliss, Cohen, &
Dehaene, 2003). ERP studies showed that English words
elicited larger N170 amplitude in the LH than the RH in a
repetition detection task (Maurer, Brandeis & McCandliss,
2005). This LH lateralization may be attributed to the leftlateralized phonological processing (Rumsey et al., 1997).
Similarly, in music notation processing, Segalowitz, Bebout, and Lederman (1979) reported a RVF/LH advantage
in chord playing, which may be related to the requirement
of mapping individual notes to different pitches/fingerings.
Indeed, music notation and English word reading are shown
to have shared neural mechanisms in the LH. For example,
musicians with brain lesions in the LH showed difficulties
in both music and English word reading (Hébert & Cuddy,
2006). Also, both English and music notations are read from
left to right, and thus letters and music notes are recognized
in the RVF more often than the left visual field (LVF) during reading, resulting in a similar RVF processing advantage due to perceptual learning (Wong & Hsiao, 2012).
While the LH is shown to play an important role in English word and music notation reading, the RH is also involved, particularly in visual form processing of words and
notes. For example, in a lexical decision priming task, English word processing in the LVF/RH was shown to benefit
from orthographically similar primes, whereas that in the
RVF/LH benefitted from phonologically similar primes.
This result suggested that the RH and the LH had differential advantages in orthographic and phonological processing
of English words (Lavidor & Ellis, 2003). Consistent with
this finding, English word processing in the RH has been
reported to be more sensitive to variations in visual word
forms. For example, the word length effect in English lexical decisions (i.e., faster and more accurate responses to
shorter words) was only observed when words were presented in the LVF/RH but not the RVF/LH, suggesting that
RH word processing involves more letter-by-letter recognition/serial processing than that in the LH (Lavidor & Ellis,
2001). Similarly, in music note processing, a right lateralized or bilateral visual processing mechanism has been observed. For example, fMRI studies have shown that the right
occipitotemporal region was associated with music sightreading (Schön, Anton, Roth & Besson, 2002). Bilateral
activations in the fusiform and inferior occipital gyri in musicians were also reported in a note selection task.
(Proverbio, Manfredi, Zani & Adorni, 2013). In a divided

2561

visual field study, no lateralization effect was observed in
sequential matching of notes and chords (Li & Hsiao, 2015).
Although previous research has suggested similarities between English word and music notation reading processes, it
remains unclear how they influence each other. We have
previously found that, whereas non-musicians showed a
typical RVF/LH advantage in naming English words, musicians showed an LVF/RH advantage and responded significantly faster than non-musicians when words were presented in either the LVF or the center position (Li & Hsiao,
2015). This effect suggested a facilitation of RH English
word processing due to music reading experiences. This
phenomenon may be due to shared neural mechanisms between the two expertise domains in the LH that lead to resource competition, consequently making musicians rely
more on RH processing for English word recognition. It
may also be the similarities between music notation and
English word reading processes in the RH accommodate
each other, making the relevant processes more efficient and
consequently facilitating RH English word processing.
While English word and music notation reading share
similar visual processing requirements, they differ significantly in their involvement in lexical processing. More specifically, English words follow morphological and orthographic rules with clearly defined segment boundaries and
lexical representations, whereas musical segments do not
follow as strict sequencing rules as words and are not associated with specific semantic representations (Chan &
Hsiao, 2016). Since previous research has suggested that LH
English word processing is more relevant to phonological
processing of English words whereas RH English word processing is more sensitive to variations in visual word forms,
the modulation of music reading experience on visual processing of English words is likely to be mainly due to a
shared processing mechanism in the RH. In addition, this
modulation may be stronger in English non-word processing
than the processing of real or pseudo-words, since nonwords do not follow morphological rules or have meanings,
similar to musical segments. To test these hypotheses, here
we conduct an EEG study to examine how music reading
expertise influences visual processing of English stimuli. A
sequential matching task is used to focus on visual processing of English words. Following Rossion et al. (2004),
here we examine how N170 responses to English words are
influenced by the processing of music notes in musicians
and non-musicians. We expect that musicians will have a
stronger reduction in N170 response to English stimuli under the processing of music notes than non-musicians in the
RH, particularly for English non-words.

Methods
Participants
Participants were 60 Cantonese (L1)-English (L2) bilinguals
from Hong Kong, whose ages ranged from 18 to 29 (M =
21, SD = 2.8). They had similar language and college education backgrounds, with normal or corrected to normal vi-

sion. They were categorized as 30 musicians (14 males, 16
females) and 30 non-musicians (12 males, 18 females).
Musicians were well-trained pianists, who started music
training at age 3-8 (M = 5.33, SD = 1.47). All of them were
either piano teachers, music major students, or frequent piano players. They had attained grade 8 or above in the graded piano examinations of the Associated Board of The Royal Schools of Music (ABRSM), with 8-25 year experience
in piano playing (M = 15.03, SD = 3.89) and regular music
reading hours per week (M = 7.16, SD = 12.33). Musicians
outperformed non-musicians in musicality, as assessed by
the Goldsmiths Musical Sophistication Index (Müllensiefen,
Gingras, Musil, & Stewart, 2014; t(58) = 9.97, p < .001). In
contrast, non-musicians did not receive any music training.
Aside from their music background, musicians and nonmusicians were closely matched in handedness and language exposure. Most participants were right-handed, which
was assessed using the Edinburgh Handedness Inventory
(Oldfield, 1971; M: 54.33, 3th right decile; NM: 64.33, 3rd
right decile, n.s.). All participants started learning English as
a second language at age 3, and have similar self-reported
English reading hours (M: 27.48; NM: 18.77; n.s.). No participants had experience with the Tibetan language.

Materials
Materials consisted of 3 types of English words (real, pseudo, and non-words with 4-6 letters) as target stimuli and two
types of comparable pre-/post-stimulus masks: musical
segments with 4 random notes without clefs (n = 1323)
ranging from D4 to G5 and Tibetan letter strings with 4 random letters (n = 1323). Tibetan letter strings, a novel stimulus type that no participants had any experience with, were
included as a control condition.
English real words (n = 126) were selected from the
SUBTLEX-US corpus (Brysbaert, New & Keuleers, 2012)
and Wuggy (a word generator, Keuleers & Brysbaert, 2010).
To control information distribution within a word, the same
number of high-frequency words and low-frequency words
were selected within the informative beginning and informative end subsets in Bryden, Mondor, Loken, Ingleton
& Bergstrom (1990). Word frequency was closely matched
between ‘same’ and ‘different’ trials in the matching task
and between music and Tibetan conditions. For ‘same’ trials,
two target stimuli were identical. For ‘different’ trials, half
trials had shared beginnings (e.g. banker, banner), while the
other half had shared ends (e.g. salary, notary).
English pseudo-words (i.e. non-existing words with legal
letter strings at the word beginning and word end, n = 126)
were created by extracting and recombining word beginnings and ends from our English real word list. This is to
control information distribution at the word beginnings and
ends between real and pseudo-word stimuli. For ‘same’ trials, two target stimuli were identical. For ‘different’ trials,
half trials had shared beginnings (e.g. banher, banord),
while the other half had shared ends (e.g. saliew, supiew).
English non-words (i.e., illegal letter strings, n = 126)
were created by re-ordering the letters in the word begin-

2562

nings and word ends from our English pseudo-word list
such that the letter combinations do not follow morphological rules in English. This is to closely match the letters used
in all conditions. For ‘same’ trials, two target stimuli were
identical. For ‘different’ trials, half trials had shared beginnings (e.g. nbaerh, nbaodr), while the other half had shared
ends (e.g. alsiwe, spuiwe). The non-words were checked
against the morphologically ambiguous syllables in the
ARC Nonword database (Rastle, Harrington, & Coltheart,
2002) to ensure their suitability for our task.

pants’ response. Accuracy (ACC) and response time (RT)
were recorded by Eprime with EEG recording.	  
Prior to the English word sequential matching task, a demographic and music background questionnaire, the Goldsmiths Musical Sophistication Index (Müllensiefen et al.,
2014) and Edinburgh Handedness Inventory (Oldfield,
1971) were conducted to assess participants’ language, music background, and handedness.

Design
To focus on visual processing of English words, a sequential
matching task similar to Gauthier et al. (2003) was used.
The design consisted of 2 within-subject variables: English
word type (real/pseudo/non-words), stimulus mask (musical
segments vs. Tibetan letter strings), and 1 between-subject
variable: group (musicians vs. non-musicians). In the ERP
data analysis, an additional variable hemisphere (LH vs.
RH) was included. Participants completed the task with
English real, pseudo, and non-word stimuli with either musical segment or Tibetan letter string masks (Fig. 1). For
each mask type, 36 ‘same’ and 36 ‘different’ trials were
included for each word type condition. Half of the stimulus
pairs in ‘same’ and ‘different’ trials were different in the
two mask conditions to avoid practice effects.
English words were displayed in Courier (a serif font with
fixed width) to ensure constant center-to-center spacing
between letters. Under the viewing distance 50 cm, each
English word subtended a horizontal and vertical visual angle of 4.06° x 0.95° (4 letters), 5° x 0.95° (5 letters) and
6.35° x 0.95° (6 letters). Musical segments with 4 random
notes in crotches (1 beat) with the five-line staff subtended a
horizontal and vertical visual angle of 6.90° x 1.62°. Tibetan
letter strings with 4 random letters were presented in Himalaya font and subtended a horizontal and vertical visual angle of 6.90° x 1.62°. All stimuli were presented in black
with a white background on a CRT monitor. Experiments
were conducted using E-Prime v2.0 with 64-channel ANT
EEG recording. A chinrest was used to reduce head movement. The block and trial orders were randomized.

Procedure
Each trial started with a central fixation with a randomly
determined presentation duration between 400-600 ms. A
pre-stimulus mask (a musical segment or a Tibetan letter
string) was presented for 600 ms, followed by an 800 ms
presentation of the first target stimulus (a real/pseudo/non
word). Then, a post-stimulus mask (a musical segment or a
Tibetan letter string) was presented for 600 ms, followed by
an 800 ms presentation of the second target stimulus (a
same or different real/pseudo/non-word; Fig. 1). All stimuli
were presented at the center of the screen. Participants
judged whether the two target stimuli were the same or not
by pressing buttons with both hands. The trial did not proceed to the 800ms ‘blink’ period until receiving partici-

Fig. 1. Procedure of the English word sequential matching

Results
In the English word sequential matching task, no significant
difference was observed between musicians and nonmusicians in ACC and RT of matching real (M: 97.27%,
606.02 ms; NM: 94.31%, 774.41 ms), pseudo (M: 97.04%,
619.90 ms; NM: 93.29%, 698.58 ms) and non-words (M:
95.88%, 598.58 ms; NM: 91.20%, 727.38 ms), suggesting
that they had a similar performance level in the task.
The 64-channel EEG data were analyzed using EEGLAB (Delorme & Makeig, 2004) and ERPLAB (LopezCalderon & Luck, 2014) in MATLAB. Bin-based epochs
were extracted from -100 ms to 600 ms of the stimulus onset and corrected from baseline deviations using a prestimulus window of 99 ms. The analyses of the N170 component were based on the electrode pairs with the largest
N170 amplitude from the grand average data. Accordingly,
electrodes PO7 (LH) and PO8 (RH) were selected for the
analysis of N170 response to the pre-stimulus masks (musical segments vs. Tibetan letter strings), while electrodes P7
(LH) and P8 (RH) were selected for N170 responses to the
first presentation of the English real, pseudo, and non-words
preceded by musical segments or Tibetan letter strings, using repeated measures ANOVA. Note that we only analyzed
the N170 responses to the first presentation of the English
word stimuli since the EEG responses to the second stimulus may be contaminated by button responses..

  
Figure 2. Average N170 amplitude at PO7 and PO8 in response to musical segments and Tibetan letter strings (error
bars = +/- 1 SE; *** p < .001, * p < .05).

2563

In the ERP response to the pre-stimulus mask, a significant interaction between mask type (music vs. Tibetan) ×
group (musicians vs. non-musicians) was observed, F(1, 52)
= 31.80, p < 0.001: musicians had a larger N170 amplitude
than non-musicians in response to musical segments, t(52) =
-2.07, p = .044 (Fig. 2), whereas no difference was observed
between the two groups in response to Tibetan letter strings.
When we split the data by group, musicians had a larger
N170 amplitude in response to musical segments than to
Tibetan letter strings, F (1, 27) = 68.98, p < 0.001 (Fig. 2),
whereas non-musicians did not show any significant differences in response to musical segments and Tibetan letter
strings. These findings were consistent with the perceptual
expertise literature showing that visual expertise increases
the N170 amplitude in response to the stimuli in experts as
an expertise marker (Rossion et al., 2004). No main effects
or interactions with hemisphere were observed (Fig. 3).

Figure 3. N170 amplitude in response to musical segments
and Tibetan letter strings between musicians and nonmusicians in PO7 (LH) and PO8 (RH).

For N170 responses to English words (the first target
stimulus), a significant four-way interaction, mask type
(music vs. Tibetan) x word type (real vs. pseudo vs. nonwords) x hemisphere (LH vs. RH) x group (musicians vs.
non-musicians), was observed, F(2, 53) = 3.32, p = .044. To
better understand this interaction, we examined the N170
amplitude in response to real, pseudo, and non-words separately (Fig. 4). A significant interaction among mask type,
hemisphere, and group was found in English non-words, F
(1, 54) = 6.27, p = .015, but not in real or pseudo-words.
This three-way interaction suggested that musicians and
non-musicians had different N170 amplitudes in response to
non-words preceded by musical segments and Tibetan letter
strings in the LH and the RH. This effect was not found in
real or pseudo-words.
When we examined the data of non-words in two participant groups separately, musicians showed a significant interaction between mask type (music vs. Tibetan) and hemisphere (LH vs. RH), F(1, 26) = 10.60, p = .003, whereas
non-musicians did not. When we examined musicians’ data
in the two hemispheres separately, a significant main effect
of mask type (music vs. Tibetan) was observed, F (1, 26) =
9.004, p = .006: musicians had a smaller N170 amplitude in
response to English non-words preceded by musical segments (-2.17µV, SD = 3.88, Fig. 5) than those preceded by
Tibetan letter strings in the RH (-4.11 µV, SD = 2.11). This
mask type effect was not observed in the LH. Note that this
mask type effect was also not observed in either participants’ N170 responses to real and pseudo-words, or nonmusicians’ N170 responses to non-words. This phenomenon
demonstrates a modulation of musicians’ musical segment
processing on English non-word processing in the RH.

Figure 5. Musicians had a greater reduction in N170 amplitude in response to non-words preceded by musical segments than that preceded by Tibetan letter strings in the RH.
No reduction effect was observed in the LH or in nonmusicians. (error bars = +/- 1 SE; ** p < .01).

Discussion

Figure 4. N170 amplitude in response to English (a) real, (b)
pseudo and (c) non-words preceded by musical segments
and Tibetan letter strings between musicians and nonmusicians in P7 (LH) and P8 (RH) in sequential matching.

Here we examined how music reading expertise influences
visual processing of English stimuli. Since music notation
reading does not involve semantic processing as English
word reading does, we hypothesized that the modulation of
music reading experience on English word processing
would be mainly in the RH, which is shown to be important
for visual form processing of English words. In addition, the
modulation would likely be stronger in English non-word
processing than the processing of real or pseudo-words,
since similar to musical segments, non-words do not follow
morphological/orthographic rules. Consistent with our hy-

2564

potheses, we showed that musicians had a reduced N170
amplitude in response to English non-words preceded by
musical segments as compared with that preceded by novel
symbol strings in the RH, whereas non-musicians showed
no difference in N170 response to non-words preceded by
either musical segments or Tibetan letter strings. In addition, this reduction in N170 in musicians was only observed
in non-words, but not in real or pseudo-words. This result
suggests a shared neural mechanism between English nonword and musical segment processing in the RH.
The RH N170 modulation effect of musical segments in
musicians was only observed in English non-words but not
in real or pseudo-words. This effect suggests that the interaction between visual English word and music notation processing depends on the similarities of the cognitive processes involved. More specifically, in contrast to English real
and pseudo-words, non-words and musical segments do not
follow any morphological or orthographic rules (Chan &
Hsiao, 2016). Given that they share similar global forms,
containing components of similar sizes arranged horizontally, their recognition may both rely on component by component serial processing, giving rise to the modulation effect. Consistent with this speculation, a RH advantage in the
perception of global forms has been consistently reported
(Sergent, 1982). English word processing in the RH is also
shown to be more sensitive to variations in visual word
forms than the LH, such as words in case alternation (Lavidor & Ellis, 2001). In particular, Lavidor and Ellis (2001)
found that the word length effect in English lexical decisions (i.e., faster responses to shorter words) was observed
only when words were presented in the LVF/RH but not in
the RVF/LH. However, when words in MiXeD CaSe were
used, encouraging letter-by-letter processing, the word
length effect was observed in both visual fields. These results suggest a letter-by-letter, serial processing engaged in
the RH word recognition, in contrast to a left-lateralized
automated, whole-word lexical processing unaffected by
word lengths (see also Lavidor, Ellis, & Pansky, 2002).
Similarly, patients with LH lesions retained letter-by-letter
reading ability, suggesting that the nature of RH word processing involves letter-by-letter recognition (Cohen et al.,
2004). Our results here were consistent with these findings,
suggesting that RH English word processing was modulated
by music notation reading experience due to their similarity
in letter-by-letter or note-by-note visual processing. Consistent with our finding, in an fMRI study, Proverbio et al.,
(2013) reported that musicians recruited the right fusiform
gyrus and the right inferior occipital gyrus in an orthographic letter recognition task, whereas non-musicians showed
activations at the corresponding regions in the LH. This
finding again suggests that music reading expertise modulates English word reading in the RH.
This RH modulation effect of music reading expertise was
also consistent with our recent study showing that musicians
named English words faster than non-musicians when
words were presented in the LVF/RH (Li & Hsiao, 2015).
More specifically, this LVF/RH advantage in word naming

in musicians may be due to the facilitation of shared neural
information processing mechanisms in the RH between music notation and English word reading, resulting in a transfer
effect from music note to English word processing in the
RH. Note that in the current study, the lack of the N170
modulation effect in real and pseudo-words does not necessarily mean that this modulation from music notation reading experience does not affect real word and pseudo-word
processing. English word recognition involves the processing of visual word forms, phonology, and semantics.
While the LH is shown to involve critically in lexical processing, the RH is reported to be important for the processing of visual word forms. Our current results suggest
that the modulation of music experience is mainly in the
RH. Since the processing of real and pseudo-words involves
both visual word form and lexical/sublexical processing,
these lexical effects may also influence N170 amplitudes
measured in both hemispheres. Indeed, Ziegler et al. (1997)
showed that real and pseudo-words elicited more negative
early visual ERPs than non-words in bilateral posterior regions in a lexical decision task, with this difference appearing earlier in the LH than the RH. Thus, the RH N170 modulation effect of music reading expertise may have been
contaminated by lexical/sublexical effects in real and pseudo-word processing. It is also possible that the lack of the
modulation effect in real and pseudo-word processing is
because random musical segments were used. Future work
will examine whether musical segments from real musical
pieces (motifs) will have different modulation effects.
Note also that the current results do not rule out possible
modulation effects of music reading experience on phonological processing of English words, since our task, sequential matching, involved mainly visual word processing. Previous studies have reported benefits of music training on the
phonological processing of English words, as shown in
phonological skill training (Degé & Schwarzer, 2011).
Thus, musicians’ LVF/RH advantage in English word naming over non-musicians observed in our previous study (Li
& Hsiao, 2015) could also be related to modulation effects
of music reading experience on English phonological processing in the LH. Future work will examine this possibility.
In short, here we show that music notation and English
non-word processing share similar neural mechanisms in the
RH, as demonstrated in the reduced N170 responses to English words under the processing of musical segments. This
effect was not observed in real or pseudo-words. Similar to
English non-words, musical segments do not follow orthographic rules. Their processing may rely on serial processing of horizontally arranged components of similar sizes, giving rise to the modulation effect. This effect demonstrates that the interaction between different perceptual expertise domains depends on the similarities of the cognitive
processes involved. Future work may use Korean Hangul
stimuli, in which letters are arranged into a square shape
instead of horizontally, to examine whether the modulation
effect of music reading expertise in the RH was restricted to
words with a global form similar to music notations (i.e.,

2565

components of a similar size arranged horizontally) or could
be applied to words in alphabetic languages in general.

Acknowledgments
We are grateful to the Research Grant Council of Hong
Kong (ECS scheme project # HKU 758412H to J.H. Hsiao).

References
Brown, S., Martinez, M. J., & Parsons, L. M. (2006). Music
and language side by side in the brain: a PET study of the
generation of melodies and sentences. Eur. J. Neurosci.,
23, 2791-2803.
Bryden, M. P., Mondor, T. A., Loken, M., Ingleton, M. A.,
& Bergstrom, K. (1990). Locus of information in words
and the right visual field effect. Brain Cognition, 14, 4458.
Brysbaert, M., & D'Ydewalle, G. (1990). Tachistoscopic
presentation of verbal stimuli for assessing cerebral dominance: Reliability data and some practical recommendations. Neuropsychologia, 28, 443-455.
Brysbaert, M., New, B., & Keuleers, E. (2012). Adding
part-of-speech information to the SUBTLEX-US word
frequencies. Behav. Res. Methods, 44, 991-997.
Chan, A. B., & Hsiao, J. H. (2016). Information distribution
within musical segments. Music Perception, 34, 218-242.
Cohen, L., Henry, C., Dehaene, S., Martinaud, O., Lehéricy,
S., Lemer, C., & Ferrieux, S. (2004). The
pathophysiology
of
letter-by-letter
reading. Neuropsychologia, 42, 1768-1780.
Degé, F., & Schwarzer, G. (2011). The effect of a music
program on phonological awareness in preschoolers.
Front. Psychol., 2, 7-13.
Delorme, A., & Makeig, S. (2004). EEGLAB: an open
source toolbox for analysis of single-trial EEG dynamics
including independent component analysis. J. Neurosci.
Meth., 134, 9-21.
Gauthier, I., Curran, T., Curby, K. M., & Collins, D. (2003).
Perceptual interference supports a non-modular account
of face processing. Nat. Neurosci., 6, 428-432.
Hébert, S., & Cuddy, L. L. (2006). Music-reading deficiencies and the brain. Adv. Cogn. Psychol., 2, 199-206.
Hsiao, J. H., & Lam, S. M. (2013). The Modulation of Visual and Task Characteristics of a Writing System on
Hemispheric Lateralization in Visual Word Recognition—A Computational Exploration. Cognitive Sci., 37,
861-890.
Keuleers, E., & Brysbaert, M. (2010). Wuggy: A multilingual pseudoword generator. Behav. Res. Methods, 42,
627-633.
Lavidor, M., & Ellis, A. W. (2001). Mixed-case effects in
lateralized word recognition. Brain Cognition, 46, 192195.
Lavidor, M., & Ellis, A. (2003). Orthographic and phonological priming in the two cerebral hemispheres. Laterality, 8, 201-223.
Lavidor, M., Ellis, A. W., & Pansky, A. (2002). Case alter
nation and length effects in lateralized word recognition:

Studies of English and Hebrew. Brain Cognition, 50, 257271.
LI T.K. & Hsiao J.H. (2015). Music Reading Expertise
Modulates Hemispheric Lateralization in English Word
processing but not in Chinese Character Processing. CogSci 2015 proceedings, 1344-1349.
Lopez-Calderon, J., & Luck, S. J. (2014). ERPLAB: an
open-source toolbox for the analysis of event-related potentials. Front. Hum. Neurosci., 8, 213.
Maurer, U., Brandeis, D., & McCandliss, B. D. (2005). Fast,
visual specialization for reading in English revealed by
the topography of the N170 ERP response. Behav. Brain
Funct., 1, 1.
McCandliss, B. D., Cohen, L., & Dehaene, S. (2003). The
visual word form area: expertise for reading in the fusiform gyrus. Trends Cogn. Sci., 7, 293-299.
Müllensiefen, D., Gingras, B., Musil, J., & Stewart, L.
(2014). The musicality of non-musicians: an index for assessing musical sophistication in the general population. PloS one, 9, e89642.
Oldfield, R. C. (1971). The assessment and analysis of
handedness:
the
Edinburgh
inventory. Neuropsychologia, 9, 97-113.
Proverbio, A. M., Manfredi, M., Zani, A., & Adorni, R.
(2013). Musical expertise affects neural bases of letter
recognition. Neuropsychologia, 51, 538-549.
Rastle, K., Harrington, J., & Coltheart, M. (2002). 358,534
nonwords: The ARC nonword database. Q. J. Exp. Psychol.- A, 55, 1339-1362.
Rossion, B., Kung, C. C., & Tarr, M. J. (2004). Visual expertise with nonface objects leads to competition with the
early perceptual processing of faces in the human occipitotemporal cortex. Proc. Natl. Acad. Sci. U.S.A., 101,
14521-14526.
Rumsey, J. M., Horwitz, B., Donohue, B. C., Nace, K., Maisog, J. M., & Andreason, P. (1997). Phonological and orthographic components of word recognition. A PET-rCBF
study. Brain, 120, 739-759.
Schön, D., Anton, J. L., Roth, M., & Besson, M. (2002). An
fMRI study of music sight-reading. Neuroreport, 13,
2285-2289.
Segalowitz, S. J., Bebout, L. J., & Lederman, S. J. (1979).
Lateralization for reading musical chords: Disentangling
symbolic, analytic, and phonological aspects of reading. Brain Lang., 8, 315-323.
Sergent, J. (1982). The cerebral balance of power: Confrontation or cooperation? J. Exp. Psychol.: Human, 8, 253272.
Wong, Y. K., & Hsiao, J. H. W. (2012). Reading direction is
sufficient to account for the optimal viewing position in
reading: The case of music reading. CogSci 2012 proceedings, 2540-2545.
Ziegler, J. C., Besson, M., Jacobs, A. M., Nazir, T. A., &
Carr, T. H. (1997). Word, pseudoword, and nonword processing: A multitask comparison using event-related brain
potentials. J. Cognitive Neurosci., 9, 758-775.

2566

