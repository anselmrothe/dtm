       Learning to See People Like People: Predicting Social Impressions of Faces
                                                  Amanda Song (mas065@ucsd.edu) †
                                                       Department of Cognitive Science
                                              University of California, San Diego, CA 92093
                                                    Li Linjie (li2477@purdue.edu)†
                                           Department of Computer Science, Purdue University
                                                 610 Purdue Mall, West Lafayette, IN 47907
                                                    Chad Atalla (catalla@ucsd.edu)
                                            Department of Computer Science and Engineering
                                              University of California, San Diego, CA 92093
                                                  Garrison Cottrell (gary@ucsd.edu)
                                            Department of Computer Science and Engineering
                                              University of California, San Diego, CA 92093
                              Abstract                                   in faces (Falvello, Vinson, Ferrari, & Todorov, 2015; Eisen-
                                                                         thal, Dror, & Ruppin, 2006). This indicates that faces contain
   Humans make complex inferences on faces, ranging from ob-             high-level visual cues for social inferences, therefore making
   jective properties (gender, ethnicity, expression, age, identity,
   etc) to subjective judgments (facial attractiveness, trustworthi-     it possible to model the inference process computationally.
   ness, sociability, friendliness, etc). While the objective as-        Social judgments, as an important part of people’s daily inter-
   pects of face perception have been extensively studied, rela-         actions, have a significant impact on social outcomes, ranging
   tively fewer computational models have been developed for
   the social impressions of faces. Bridging this gap, we de-            from electoral success to sentencing decisions (Oosterhof &
   velop a method to predict human impressions of faces in 40            Todorov, 2008; Willis & Todorov, 2006).
   subjective social dimensions, using deep representations from
   state-of-the-art neural networks. We find that model perfor-             Are deep learning models, which are successful in vari-
   mance grows as the human consensus on a face trait increases,         ous visual tasks, also capable of predicting subjective social
   and that model predictions outperform human groups in cor-            impressions of faces? Even before the advent of deep learn-
   relation with human averages. This illustrates the learnability
   of subjective social perception of faces, especially when there       ing, there have been models using traditional computer vi-
   is high human consensus. Our system can be used to decide             sion algorithms and simulated faces to model the perception
   which photographs from a personal collection will make the            of facial attractiveness (Thornhill & Gangestad, 1999; Eisen-
   best impression. The results are significant for the field of so-
   cial robotics, demonstrating that robots can learn the subjective     thal et al., 2006; Kagian et al., 2008; Gray, Yu, Xu, & Gong,
   judgments defining the underlying fabric of human interaction.        2010), trustworthiness (Falvello et al., 2015; Todorov, Baron,
   Keywords: social impression; deep learning; face perception           & Oosterhof, 2008), sociability, aggressiveness (Mignault
                                                                         & Chaudhuri, 2003), familiarity (Peskin & Newell, 2004),
                          Introduction                                   and memorability (Bainbridge, Isola, & Oliva, 2013; Khosla,
With the huge success of deep learning techniques, current               Bainbridge, Torralba, & Oliva, 2013). Recently, there has
state-of-the-art computer vision algorithms have approached              been work on modeling the “big five ” personality traits per-
or exceeded human ability in recognizing a face (Taigman,                ceived by humans when viewing another person in video clips
Yang, Ranzato, & Wolf, 2014; Stewart, Andriluka, & Ng,                   (Escalera et al., 2016).
2016) and identifying the objective properties of a face, such              In this paper, we examine human social perceptions of
as age and gender estimation, (Guo, Fu, Dyer, & Huang,                   faces in 40 dimensions extensively and systematically. We
2008). However, humans not only read objective properties                evaluate the human consistency and correlation in 40 social
from a face, like expression, age, and identity, but also form           features (20 relevant pairs) that are typically studied by social
subjective impressions of social aspects of a face (Todorov,             psychologists (Todorov, Said, Engell, & Oosterhof, 2008),
Olivola, Dotsch, & Mende-Siedlecki, 2015) at first sight,                and relevant to social interactions (Todorov et al., 2015;
such as facial attractiveness (Thornhill & Gangestad, 1999),             Oosterhof & Todorov, 2008), and use state-of-the-art deep
friendliness, trustworthiness (Todorov, Baron, & Oosterhof,              learning algorithms to model all 40 of them. Using the in-
2008), sociability, dominance (Mignault & Chaudhuri, 2003),              ternal representations learned from the deep learning models,
and typicality. In spite of the subjective nature of social per-         our model can successfully predict human social perception
ceptions, there is often a consensus among human in how                  whenever human have a consensus. We further visualize the
they perceive attractiveness, trustworthiness, and dominance             key features defining different social attributes to facilitate a
                                                                         understanding of what makes a face salient in a certain social
    † These authors contributed equally.                                 dimension.
                                                                     1096

                           Methods                                     to compute smoothness and skin color are highlighted in the
                                                                       right subplot of Figure 2. The skin color feature is extracted
Dataset
                                                                       from the same region as smoothness, converted from RGB
To predict human social impressions of faces, we use a public          to HSV. However, regressing on these handcrafted features
dataset (Bainbridge et al., 2013) consisting of 2,222 face im-         alone is not enough to capture the richness of geometric de-
ages and annotations for 40 social attributes. Each attribute          tails in a face. We therefore use a computer vision library
is rated on a scale of 1-9 by 15 subjects. We take the aver-           (dlib, C++) to automatically label 68 face landmarks (see Fig-
age rating from all raters as a collective estimation of human         ure 2) for each face, and then compute distances and slopes
judgment for the social features of each face.                         between any two landmarks. Combining 29 handcrafted geo-
   The 40 social attributes consist of 20 pairs of related traits:     metric features, smoothness, color and the distance-slope fea-
(attractive, unattractive), (happy, unhappy), (friendly, un-           tures, we obtain 4592 features in total. Since the features are
friendly), etc. Some of these traits are highly correlated and         highly correlated, we apply PCA to reduce dimensionality.
predictable from others, especially within the trait pairs. To         Again, the PCA dimensionality is chosen by cross-validating
understand the human-perceived correlations between these              on the hold out set separately for each facial attribute. Then
traits, we compute the Spearman’s rank correlation between             a ridge regression model is applied to predict social attribute
the average human ratings of every pair of social features and         ratings of a face. The hyper-parameter of ridge regression is
show their correlations in a heatmap (Figure 1(a)). We order           selected by leave-one-out validation within the training set.
traits in the map based on similarity and positive or nega-
tive connotation. From the figure, we see that negative social         Regression on CNN Features
features such as untrustworthy, aggressive, cold, introverted,         Previous studies have shown that pretrained deep learning
and irresponsible form a correlated block. Likewise, the most          models can provide feature representations versatile for re-
positive features such as attractive, sociable, caring, friendly,      lated tasks. We therefore extract image features from pre-
happy, intelligent, interesting, and confident are highly cor-         trained neural networks, choosing from six architectures with
related with each other. Although we choose 20 pairs of op-            different original training goals: (1) VGG16, trained for ob-
posite features, they are not completely complementary and             ject recognition (Simonyan & Zisserman, 2014), (2) VGG-
redundant. Principal Component Analysis of the covariance              Face, trained for face identification (Simonyan & Zisser-
matrix shows that it takes 24 principal components to cover            man, 2014), (3) AlexNet, trained for object classification
95% of the variance.                                                   (Krizhevsky, Sutskever, & Hinton, 2012), (4) Inception from
                                                                       Google, trained for object recognition (Szegedy et al., 2015),
Regression Model for Social Attributes                                 (5) a shallow Siamese neural network that we train from
After averaging human ratings, each face receives a continu-           scratch to cluster faces by identity, (6) a state of the art
ous score from 1 to 9 in all social dimensions. We model these         VGG-derived network (Face-LandmarkNN) trained for the
social scores with a regression model. We propose a ridge              face landmark localization task.
regression model on either features from deep convolutional               To find the best CNN features among the six networks, we
neural networks (CNN) or traditional face geometry based               first find the best-performing feature layers of each network
features, and present results from both feature sets. Such vi-         in the ridge regression prediction task. Before the ridge re-
sual features are usually high-dimensional, so we first per-           gression, we perform PCA and pick the PCA dimensionality
form Principal Component Analysis (PCA) on the extracted               that gives best results on the validation set. Then, we compare
features of the training set to reduce dimensionality. The PCA         the results among networks to select the best features overall.
dimensionality is chosen by cross-validation on a validation
set, separately for each trait. The PCA weights are saved and                                      Results
further used in fine-tuning our CNN-regression model.                  After comparing all 6 networks, we find that the conv5 2
                                                                       layer of VGG16 (trained for object classification) lead to the
Regression on Geometric Features                                       best results. This set of features significantly outperforms
Past studies have found that facial attractiveness can be in-          the three networks trained solely on faces, while also slightly
ferred from the geometric ratios and configurations of a face          outperforming AlexNet and Inception networks. These best-
(Eisenthal et al., 2006; Kagian et al., 2008). We suggest that         performing CNN features also exceed the prediction corre-
other social attributes can also be inferred from geometric            lation of the geometric features in most attributes. Figure 3
features. We compute 29 geometric features based on defi-              compares prediction performance of the CNN model and the
nitions described in (Ma, Correll, & Wittenbrink, 2015), and           geometric feature model.
further extract a ’smoothness’ feature and ’skin color’ feature           We speculate that the poor performance from the face
according to the procedure in (Eisenthal et al., 2006; Kagian          recognition networks can be attributed to their optimization
et al., 2008). The smoothness of a face was evaluated by ap-           for specific facial tasks. Learning face landmark configura-
plying a Canny edge detector to regions from the cheek and             tions and differences between faces that define identity may
forehead areas (Eisenthal et al., 2006). The more edges de-            not correlate well with the task at hand, which looks for com-
tected, the less smooth the skin is. The regions we chose              monalities behind certain social features beyond identity. The
                                                                   1097

                                  (a)                                                                (b)
                    Figure 1: Correlation heatmaps among social features. (a): human; (b): CNN-based model.
                                                                       ture based regression), model performance grows as the con-
                                                                       sensus on a social trait increases.
                                                                          Since a change in expression would produce a change in
                                                                       landmark locations, it is not surprising that landmark-based
                                                                       geometric features achieve comparable or slightly higher cor-
                                                                       relation with the CNN model when predicting social at-
                                                                       tributes which are highly related to expressions (such as
                                                                       ’happy’, ’unhappy’, ’cold’ and ’friendly’ etc). For other so-
Figure 2: 68 face landmarks labeled by dlib software auto-             cial attributes, the CNN model performs better, by about 0.04
matically. The gray regions are used for computing smooth-             higher in correlation on average. This implies that CNN fea-
ness and skin color.                                                   tures encode much more information than landmark-based
                                                                       features. It is useful to visualize such features to understand
                                                                       what aspects make them powerful enough to predict social
landmark networks should presumably give results similar to            attributes.
the geometric features, but did not learn features correspond-
ing to all of the features we manually extracted.                      Evaluating Against Human Consensus
   We also try fine-tuning the best performing CNN model               An important gauge of model success is quantitative com-
with back propagation but do not observe further improve-              parison between the subjective social features predicted by
ment in performance. Hence our reported results are without            our best performing model and those perceived by humans.
fine-tuning.                                                           We take our model predictions, compute the Spearman cor-
   To evaluate model performance, we did a random                      relation between every pair of traits, and display them in a
train/validation/test split 50 times, with a ratio of 64/16/20 re-     heatmap (see Figure 1 (b)). The resulting heatmap shares
spectively. The prediction performance of our model is eval-           similar patterns with the figure generated from average hu-
uated using Pearson’s correlation with the average human rat-          man ratings (see the left panel in Figure 1). Pearson Correla-
ings on the test set. For each social attribute, we also compute       tion between the upper triangle of the two similarity matrices
human group consistency as an index of the strength of learn-          (human and model prediction) is 0.9836. This suggests that
ing signal.                                                            our model successfully preserves human-perceived relation-
   Among the social attributes, human subjects agree most              ships between traits.
about ’happy’ and disagree most about ’unfamiliar.’ For both              Since these social impressions are subjective ratings, it is
regression models (CNN based regression and geometric fea-             informative to examine the extent with which people agree
                                                                   1098

                                        Figure 3: Model comparison on 40 social features.
with each other on these judgments. To calculate human              an example, but the same method can be applied to the other
group consistency, we perform the following procedure 50            social features.
times for each attribute and then average the results: (1) For
each face, we randomly split the 15 raters into two groups of          To identify visual features that ignite attractiveness percep-
7 and 8. (Note: The raters assigned to each face are generally      tion, we find the top 9 units of highest influence on attractive-
different sets). (2) We calculate the two groups’ average rat-      ness at conv5 2 as follows. First, we compute a product of
ings for each face, obtaining two vectors of length 2,222 (the      three terms: (1) A unit’s activation from conv5 2, (2) that
number of faces in the dataset). (3) Finally, we calculate the      unit’s weight to the following fc PCA layer, (3) the fc PCA
Pearson correlation between the two vectors. We find that hu-       unit’s weight to the output unit. We then sort all conv5 2
man agreements covary with model performance and observe            units’ average products of these three terms and identify the
an extremely high correlation, as illustrated in Figure 4.          top 9 neurons that contribute to the output neuron for the cor-
                                                                    responding social feature. Then we employ the method de-
                                                                    scribed in (Yosinski, Clune, Nguyen, Fuchs, & Lipson, 2015;
                                                                    Zeiler & Fergus, 2014) to find top-9 input images that cause
                                                                    high activations in each of the top-9 conv5 2 neurons. Also
                                                                    we use deconvolution to create an image of the features acti-
                                                                    vating that unit for each face, with varying levels of success.
                                                                       Figure 5 captures the features that are important for pre-
                                                                    dicting the attractiveness of a face. The feature importance
                                                                    descends from left to right and top to bottom. The impor-
                                                                    tant features identified by our model are related to eyes, hair
                                                                    with bangs, high nose-bridges, high cheeks, dark eyebrows,
                                                                    strong commanding jawlines, chins, and red lips. Note that
                                                                    among the 9 cropped input image patches, not all the faces
                                                                    are perceived as attractive overall; despite having a feature
                                                                    that contributes to attractiveness. An attractive face needs to
                                                                    activate more than one of these features in order to be consid-
                                                                    ered attractive. This observation agrees with our intuition that
                                                                    attractiveness is a holistic judgment, requiring a combination
                                                                    of multiple features.
Figure 4: Human within group consistency vs. model’s cor-
relation with human average. Pearson correlation ρ = 0.98,             It also seems that several attractiveness features include re-
p < 10−5                                                            lationships between different facial features. For example,
                                                                    while the first feature in the upper left of the figure empha-
                                                                    sizes the eye, it also includes the nose. This is also true of
Feature Visualization                                               the upper right feature. Additionally, smiling is important in
Here, we visualize features from our model which are impor-         perceived attractiveness, as emphasized by the feature in the
tant for social perceptions. We choose facial attractiveness as     lower left of the figure.
                                                                1099

Figure 5: Visualization of features in the pretrained-VGG16 regression network. For conv5 2 layer, we show the top 9 acti-
vations of the top 9 neurons that maximally activate the attractiveness neuron across the training data, projected down to pixel
space using the deconvolutional network approach (Zeiler & Fergus, 2014) and their corresponding cropped image patches.
Best viewed in electronic form, and zoomed in.
                         Conclusion                                  the presence of a signal to be recognized.
We have shown that a deep network can be used to predict                Furthermore, we have shown, yet again, that a machine can
human social perception of faces, achieving high correlation         recognize attractiveness. For this dataset, our deep network
with the average human ratings. As far as we know, this is           correlates with average human ratings at 0.75. This provides
the widest exploration of social judgment predictions, show-         a new benchmark for this dataset. This is one of a few areas
ing human-like perceptions on 40 social dimensions. Reflect-         where the deep network significantly outperforms the geo-
ing previous work in recognizing facial expressions, where           metric features, as skin texture is likely to matter.
happiness is the easiest to recognize, our highest correlation          Many of these features are redundant. For example,
is on the happy feature. However, previous work in this area         friendly and happy are highly correlated (see Figure 1, and
tends to classify a face as happy or not, rather than the degree     the red block indexed by happy and friendly). Similarly, ag-
of rated happiness. By predicting this as a continuous value,        gressive and mean are highly correlated, which presumably
rather than categorical data, the subjective nature of human         requires not smiling. Meanwhile, it is also noteworthy that
judgment is modeled smoothly, along with the subjective face         some traits considered to be “opposite” in this list are not sim-
trait landscape.                                                     ply the inverse of one another. For example, there is a large
   We find that, for attributes which are recognized via facial      difference in human agreements on “sociable” (0.74) versus
actions, such as happy, unhappy, or aggressive (probably as-         “introverted” (0.50), suggesting they are not opposites.
sociated with anger) or lack of facial action, such as cold or          We also examined some of the features from the deep net-
unemotional, a simple regression model based on the place-           work. It is notable that these are difficult to verbalize, which
ment of facial landmarks works well, although the deep net-          is quite different from geometric features.
work performs nearly as well.                                           These results are significant for the field of social robotics.
   Of greater significance is our model’s correlations with hu-      While a robot should not purely judge a human on appear-
man judgments for traits such as trustworthiness, responsible-       ance, much of human interaction is dictated by the underlying
ness, confidence, and intelligence, which correspond to more         fabric of social impressions. Thus, it is important for a robot
static features of the face. In this area, the deep network,         to be aware of this subjective social fabric, opening the door
which responds to facial textures and shape, has superior per-       to useful knowledge such as whether humans might judge a
formance. While these judgments do not correspond to the             person to be trustworthy. These judgments may happen sub-
traditional notion of “ground truth”, they are descriptions for      consciously for humans, while a robot can be more objective,
which humans have a fair amount of agreement, suggesting             predicting these judgments and objectively choosing when to
                                                                 1100

consider them in a decision. A robot need not treat an attrac-      Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). Im-
tive or unattractive person differently for its own purposes,         agenet classification with deep convolutional neural net-
but this knowledge could affect how interactions are made for         works. In Advances in Neural Information Processing Sys-
the sake of the human, knowing in advance how that person             tems (pp. 1097–1105).
may feel that they fit into the social landscape.                   Ma, D. S., Correll, J., & Wittenbrink, B. (2015). The chicago
   Expansions on this work may include investigating the              face database: A free stimulus set of faces and norming
image properties that determine high level social features,           data. Behavior Research Methods, 47(4), 1122–1135.
beyond the attractiveness features we display in Figure 5.          Mignault, A., & Chaudhuri, A. (2003). The many faces of
Additionally, social trait prediction may benefit from a sin-         a neutral face: Head tilt and perception of dominance and
gle model with a shared representation, while this paper ap-          emotion. Journal of Nonverbal Behavior, 27(2), 111–132.
proaches each attribute as a separate regression task.              Oosterhof, N. N., & Todorov, A. (2008). The functional basis
                                                                      of face evaluation. Proceedings of the National Academy
   For future work, we aim to develop a generative model
                                                                      of Sciences, 105(32), 11087–11092.
which can automatically modify a face’s attributes (either ob-
                                                                    Peskin, M., & Newell, F. N. (2004). Familiarity breeds at-
jective or subjective) while preserving its realism and iden-
                                                                      traction: Effects of exposure on the attractiveness of typical
tity. Practically speaking, such a model could improve a
                                                                      and distinctive faces. Perception, 33(2), 147–158.
face’s perceived social features in positive ways (e.g. make
                                                                    Simonyan, K., & Zisserman, A. (2014). Very deep convo-
a face look more sociable, trustworthy). More importantly, it
                                                                      lutional networks for large-scale image recognition. arXiv
would enable psychologists to quantify human biases during
                                                                      preprint arXiv:1409.1556.
the formation of social impression in a precise and systematic
                                                                    Stewart, R., Andriluka, M., & Ng, A. Y. (2016, June). End-
manner. Psychologists could generate variants of a real face
                                                                      to-end people detection in crowded scenes. In The IEEE
differing in age, gender, race, and explore how various factors
                                                                      Conference on Computer Vision and Pattern Recognition
separately and jointly affect the social impressions of faces.
                                                                      (CVPR-2016).
                                                                    Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
                         References                                   Anguelov, D., . . . Rabinovich, A. (2015). Going deeper
Bainbridge, W. A., Isola, P., & Oliva, A. (2013). The intrinsic       with convolutions. In Proceedings of the IEEE Conference
   memorability of face photographs. Journal of Experimen-            on Computer Vision and Pattern Recognition (CVPR-2015)
   tal Psychology: General, 142(4), 1323.                             (pp. 1–9).
                                                                    Taigman, Y., Yang, M., Ranzato, M., & Wolf, L. (2014).
Eisenthal, Y., Dror, G., & Ruppin, E. (2006). Facial attrac-
                                                                      Deepface: Closing the gap to human-level performance in
   tiveness: Beauty and the machine. Neural Computation,
                                                                      face verification. In Proceedings of the IEEE Conference
   18(1), 119–142.
                                                                      on Computer Vision and Pattern Recognition (CVPR-2014)
Escalera, S., Torres Torres, M., Martinez, B., Baró, X.,
                                                                      (pp. 1701–1708).
   Jair Escalante, H., Guyon, I., . . . others (2016). Chalearn
                                                                    Thornhill, R., & Gangestad, S. W. (1999). Facial attractive-
   looking at people and faces of the world: Face analysis
                                                                      ness. Trends in Cognitive Sciences, 3(12), 452–460.
   workshop and challenge 2016. In Proceedings of the IEEE
                                                                    Todorov, A., Baron, S. G., & Oosterhof, N. N. (2008). Evalu-
   Conference on Computer Vision and Pattern Recognition
                                                                      ating face trustworthiness: a model based approach. Social
   Workshops (pp. 1–8).
                                                                      Cognitive and Affective Neuroscience, 3(2), 119–127.
Falvello, V., Vinson, M., Ferrari, C., & Todorov, A. (2015).        Todorov, A., Olivola, C. Y., Dotsch, R., & Mende-Siedlecki,
   The robustness of learning about the trustworthiness of            P. (2015). Social attributions from faces: Determinants,
   other people. Social Cognition, 33(5), 368.                        consequences, accuracy, and functional significance. An-
Gray, D., Yu, K., Xu, W., & Gong, Y. (2010). Predicting facial        nual Reviews of Psychology, 66(1), 519.
   beauty without landmarks. In The European Conference on          Todorov, A., Said, C. P., Engell, A. D., & Oosterhof, N. N.
   Computer Vision (ECCV-2010) (pp. 434–447). Springer.               (2008). Understanding evaluation of faces on social dimen-
Guo, G., Fu, Y., Dyer, C. R., & Huang, T. S. (2008). Image-           sions. Trends in Cognitive Sciences, 12(12), 455–460.
   based human age estimation by manifold learning and lo-          Willis, J., & Todorov, A. (2006). First impressions making up
   cally adjusted robust regression. IEEE Transactions on Im-         your mind after a 100-ms exposure to a face. Psychological
   age Processing, 17(7), 1178–1188.                                  science, 17(7), 592–598.
Kagian, A., Dror, G., Leyvand, T., Meilijson, I., Cohen-Or,         Yosinski, J., Clune, J., Nguyen, A., Fuchs, T., & Lipson, H.
   D., & Ruppin, E. (2008). A machine learning predictor of           (2015). Understanding neural networks through deep visu-
   facial attractiveness revealing human-like psychophysical          alization. arXiv preprint arXiv:1506.06579.
   biases. Vision Research, 48(2), 235–243.                         Zeiler, M. D., & Fergus, R. (2014). Visualizing and under-
Khosla, A., Bainbridge, W. A., Torralba, A., & Oliva, A.              standing convolutional networks. In European Conference
   (2013). Modifying the memorability of face photographs.            on Computer Vision (ECCV-2014) (pp. 818–833).
   In International Conference on Computer Vision (ICCV-
   2013) (pp. 3200–3207).
                                                                1101

