                  A Formal Approach to Modeling the Cost of Cognitive Control
                                    Kayhan Özcimder 1,2,∗ , Biswadip Dey2,∗ , Sebastian Musslick1,∗ ,
                            Giovanni Petri3 , Nesreen K. Ahmed4 , Theodore L. Willke4 , Jonathan D. Cohen1
                         1 Princeton Neuroscience Institute, Princeton University, Princeton, NJ 08540, USA.
            2 Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ 08544, USA.
                                         3 ISI Foundation, Via Alassio 11/c, 10126 Torino, Italy.
                                                4 Intel Labs, Santa Clara, CA 95054, USA.
                                 ∗ Equal Contribution, Corresponding Author: ozcimder@princeton.edu
                               Abstract                                  & Baumeister, 1998)) or in terms of an opportunity cost re-
                                                                         flecting the allocation of a limited resource (Kurzban, Duck-
   This paper introduces a formal method to model the level of de-
   mand on control when executing cognitive processes. The cost          worth, Kable, & Myers, 2013). Elsewhere (Feng, Schwem-
   of cognitive control is parsed into an intensity cost which en-       mer, Gershman, & Cohen, 2014; Musslick et al., 2016), we
   capsulates how much additional input information is required          have proposed that limitations in the capacity for control-
   so as to get the specified response, and an interaction cost
   which encapsulates the level of interference between individ-         dependent processing reflect the purpose of control to di-
   ual processes in a network. We develop a formal relationship          minish interference rather than any intrinsic limitation in the
   between the probability of successful execution of desired pro-       mechanism responsible for control. This view suggests that
   cesses and the control signals (additive control biases). This
   relationship is also used to specify optimal control policies to      the architecture of the processing system as a whole con-
   achieve a desired probability of activation for processes. We         strains the opportunities for control-dependent processing, re-
   observe that there are boundary cases when finding such con-          sulting in opportunity costs associated with allocating control
   trol policies which leads us to introduce the interaction cost.
   We show that the interaction cost is influenced by the relative       to any particular task(s).
   strengths of individual processes, as well as the directionality         Here, we build on a closely related proposal, by Koechlin
   of the underlying competition between processes.                      and Summerfield (2007), to define the cost of control in terms
                                                                         of internal representational requirements to insure that a given
Keywords: cognitive control; multi-tasking; intensity; iden-
                                                                         stimulus (or a set of stimuli) produces the desired response
tity
                                                                         (or a set of responses), given the intrinsic architecture of the
                           Introduction                                  system. Their work focused on a single task. Here, we ex-
                                                                         tend this to consider an arbitrary number of tasks and thus
A long standing focus in cognitive research has been to-
                                                                         accommodate their possibility for, and costs of, multitasking
wards understanding the ability to execute tasks/processes1
                                                                         (i.e.parallel processing of task pathways). To do so, we follow
that demand cognitive control. In this context, cognitive con-
                                                                         the framework proposed by Shenhav, Botvinick, and Cohen
trol is defined as the set of mechanisms required to pursue
                                                                         (2013) that distinguishes two components of control signals:
a goal, especially when distraction or strong competing re-
                                                                         intensity and identity. Specifically, Shenhav et al. (2013) de-
sponses (interferences) must be overcome (Posner & Sny-
                                                                         fined the intensity of a control signal as the strength of the sig-
der, 1975; Shiffrin & Schneider, 1977; Cohen, Dunbar, &
                                                                         nal needed to insure performance of a particular task, and the
McClelland, 1990). Earlier work (Posner & Snyder, 1975;
                                                                         identity as which control signal should be selected to achieve
Shiffrin & Schneider, 1977; Cohen et al., 1990; Botvinick &
                                                                         a desired objective given environmental conditions. Here we
Cohen, 2014) has argued that the processes demanding con-
                                                                         build on that distinction to define two corresponding com-
trol can be distinguished from automatic processes in terms
                                                                         ponents of the cognitive control costs - a cost associated with
of the strength of the associations in the pathways underlying
                                                                         intensity, and a cost associated with interaction. Furthermore,
processing: automatic processes are characterized by path-
                                                                         we define the interaction cost to capture the level of interfer-
ways with associations strong enough to resist interference
                                                                         ence between the processes in a network.
from competing processes, whereas controlled processes are
weaker, and therefore rely on input from control mechanisms                 In this paper, we begin by introducing formal constructs
to support their execution against interference.                         for intensity and interaction costs by using the graph theoretic
   Another longstanding observation is that the allocation of            representation of a neural network and terms/notions adopted
cognitive control is costly (often discussed in terms of “men-           from probability theory. We describe an intensity cost that
tal effort” (Posner & Snyder, 1975; Botvinick & Braver,                  represents the control signals (as biases infused into a neural
2015; Shenhav et al., 2017)). This cost has been interpreted in          network), above and beyond the specified strength of the sig-
physical terms (such as metabolic demands (Muraven, Tice,                nal (stimulus) itself. This is achieved by developing a formal
                                                                         relationship between the probability of successful execution
    1 A task/process/input-output mapping is defined as a unique         of desired processes and the control signals. In turn, this de-
mapping from all possible vectors in the input subspace to corre-        fines an optimization problem, which can then be solved to
sponding vectors in the output subspace, that is independent of the
mappings for all other combinations of input and output components       find optimal control signals that achieve a specified activa-
in the network.                                                          tion for desired processes. However, we observe that there
                                                                     895

                                                                       2016), we consider a single-layered, feed-forward network
                                                                       with N input and M output layer components to formalize the
                                                                       notion of intensity cost in a cognitive control context (Fig. 1
                                                                       shows a simple example of such a network). In this frame-
                                                                       work, each component represents an input/stimulus or out-
                                                                       put/response dimension (vector subspace), and the connec-
                                                                       tion from an input to an output component constitutes the
                                                                       processing pathway for a given task. This allows us to de-
                                                                       fine an abstraction of the network as a directed bipartite graph
                                                                       GB = (V , E ), wherein the set of vertices V can be partitioned
                                                                       into two disjoint sets Vin and Vout , representing the input and
                                                                       output layer components respectively. Moreover, a directed
                                                                       edge (i, j) ∈ E ⊆ Vin × Vout represents a connection from the
                                                                       vertex i in the input layer to vertex j in the output layer (i.e.,
                                                                       a task). In this setting, we represent the processing pathway
                                                                       by introducing a weight matrix W with elements wi j . As we
                                                                       will see later, this abstraction plays an important role in for-
                                                                       malizing the interaction cost of cognitive control.
Figure 1: Illustration of a single-layered, feed-forward network          In this setting, we assume that control signals bias the pro-
with 3-input and 3-output layer components, wherein the individual
features are scalar in nature.                                         cessing of a stimulus towards a specified response at two
                                                                       different levels, i.e. gi and b j , which we refer to as pre-
are boundary cases in which this optimization problem can              interaction and post-interaction control biases, respectively.
not be solved. These cases reflect situations in which the si-         This complies with early computational models of cognitive
multaneous execution of the processes is not feasible due to           control in which control signals act as an increase in gain of
interference. Hence, interaction cost analysis motivates an            non-linear processing units (Cohen et al., 1990; Botvinick et
additional investigation towards finding a proper metric that          al., 2001) and allows us to treat such control biases as key
continuously measures the level of interference between pro-           contributing factors towards the intensity cost for cognitive
cesses. To achieve this we introduce the definition of inter-          control. It is worth noting here that for simplicity the only
action cost associated with process mappings in a network              sources of nonlinearity in this setting are the logistic2 acti-
configuration. Specifically, it measures the level of interfer-        vation functions which act upon the linearized output vec-
ence introduced by competing processes that interfere with             tor ỹ = [Ỹ1 , Ỹ2 , . . . , ỸM ]. Without loss of generality, in what
the tasks of interest. In their study, Koechlin and Summer-            follows we consider the individual features to be scalar, and
field (2007) have already used information theoretic terms to          carry out a formal investigation on how these control biases
measure cognitive control. However, in order to apply these            g = [g1 , . . . , gN ] and b = [b1 , . . . , bM ] influence the response
metrics to neural networks while considering parallelism, we           from this cognitive architecture. In our formulation, the cor-
augment some of these measures, and through simulations we             responding magnitude, i.e. kgk2 + kbk2 , can be treated as a
will demonstrate how interaction cost can be used to predict           measure of control intensity applied to the system, and there-
interference in neural network architectures. Finally, we will         fore the cost for cognitive control.
discuss general research directions revealed by the analysis
                                                                          We begin our analysis by assuming the vector of fea-
presented here.
                                                                       tures s = [S1 , S2 , . . . , SN ] to be an N-dimensional multivariate
               Intensity: the cost of control                          Gaussian random variable with mean µS and covariance ΣS .
                                                                       (The assumption of Gaussianity is motivated by the technical
Cognitive control is defined as the underlying mechanism
                                                                       tractability). With this assumption, the vector [X1 , X2 , . . . , XN ]
that biases the processing of a task in order to maximize the
                                                                       becomes an N-dimensional multivariate Gaussian random
reward (Botvinick, Braver, Barch, Carter, & Cohen, 2001;
                                                                       variable with a shifted mean and same covariance. Further-
Botvinick, Cohen, & Carter, 2004; Bogacz, Brown, Moehlis,
                                                                       more, as all the transformations (before the nonlinear logis-
Holmes, & Cohen, 2006; Botvinick, 2007). Here, we adapt
                                                                       tic activation function) are linear in nature, [Y1 ,Y2 , . . . ,YN ]
the notion of intensity cost from Shenhav et al. (2013) as a
                                                                       also remains a multivariate Gaussian random variable whose
function of the amount of control bias that cognitive con-
                                                                       mean and covariance are given by µY = W (µS + g) and ΣY =
trol applies to the system. However, Shenhav et al. (2013)
                                                                       W ΣSW T , respectively. Similarly, the vector of linearized out-
described this function in qualitative rather than quantitative
                                                                       puts [Ỹ1 , Ỹ2 , . . . , ỸN ] is also a multivariate Gaussian, with a
terms. In this work we provide an explicit characterization
                                                                       shifted mean and the same covariance.
of the cost of cognitive effort in terms of a set of physically
meaningful parameters, which allow the manipulation of the                 2 Although we are restricting ourselves to logistic functions with
response of a cognitive architecture.                                  unit steepness, in a more general setting one can use the steepness
   Following earlier works (Feng et al., 2014; Musslick et al.,        as another design parameter.
                                                                   896

   Hence, each individual linearized output Ỹi is itself a Gaus-      at the expense of a limited amount of cognitive control. How-
sian random variable with                                              ever, as one might expect, this optimization problem can have
                                                                       an empty solution set under certain values of the interaction
                                    N
                            µỸi =                                     weights and activation thresholds, meaning that certain net-
                  mean:            ∑ w ji (µ j + g j ) + bi            work configurations strictly prohibit successful multitasking
                                   j=1
                                    N     N                            performance (Musslick et al., 2016). Before approaching this
           and variance: σỸii =   ∑ ∑ w ji wki σk j ,                 computation in detail, it would be beneficial to investigate
                                   j=1 k=1                             how the interaction structure influences the solution space,
                                                                       and that leads us to our next section wherein we introduce the
where µ j is the mean of stimulus Sk and σk j is the covariance        notion of interaction cost.
between stimuli Sk and S j . As a consequence, the correspond-
ing output (response) will have a logit-normal distribution,                       Interaction: the cost of mapping
and this leads us to our key result in this section.
   As outlined by Shenhav et al. (2013), the response Oi               In this section, we will introduce a detailed formalism of the
should overcome a specified threshold in order to execute              interaction cost associated with process mappings in a net-
the corresponding process (task). Then, by letting αi ∈ (0, 1)         work configuration to accommodate the possibility for multi-
represent this activation threshold associated with output Oi ,        tasking. In our earlier work (Musslick et al., 2016), we have
the corresponding probability of task execution (probability           formalized three distinct types of interference (Fig. 2).
of the output Oi surpassing the threshold αi ) is expressed as             Convergent interference (Fig. 2a) occurs when two in-
                                                                     puts/stimuli (e.g. S1 and S2 ) compete to determine a common
                                                      N              output (e.g. O1 ). We also consider divergent interference in
                                   αi
                          log 1−αi − bi − ∑ w ji (µ j + g j )        our analysis (Fig. 2b). Although this does not pose an im-
               1 1                                    j=1       
P[Oi ≥ αi ] = − erf               s                             .    pediment to performance, i.e. it is possible to generate two
               2 2                       N N
                                                                 
                                       2 ∑ ∑ w ji wki σk j
                                                                      distinct outputs (e.g. O1 and O2 ) to the same input (e.g. S1 ),
                                          j=1 k=1                      it represents a restriction on the number of independent stim-
                     |                           {z              }     uli (and therefore the number of tasks) that the system can
                                       f (αi ,bi ,w,µ,g,ΣS )
                                                                       process at once, and thus was treated formally as a type of
Here we have exploited the monotonicity of the logistic func-          interference due to this dependency in our analysis of paral-
tion to compute its inverse. Then the result follows from the          lel processing capability. Finally, we consider a third, indi-
cumulative distribution function of Ỹi .                              rect interference that supervenes on the first two (shown in
   We characterized the activation probability of a given net-         Fig. 2c and Fig. 2d). In this case, the two tasks with strengths
work in terms of the pre-interaction and post-interaction con-         w11 and w22 in question do not directly interfere with one
trol biases. This is crucial because it provides new directions        another. However, their simultaneous execution would nec-
to incorporate the cost of control into the design of a cognitive      essarily engage a third task with strength w21 (also possibly
network architecture. For example, the problem of allocating           a fourth task with strength w12 ) that would produce interfer-
a limited amount of cognitive control into different compo-            ence in output O1 (and O2 ). While Musslick et al. (2016)
nents of the network to maximize the associated probability            treated these three types of interference identically in terms
of activation can be formulated as an optimization problem in          of their effect on the overall parallel processing capability of
which the goal becomes minimizing f (αi , bi , w, µ, g, ΣS ) over      a network, the proposed interaction cost will also distinguish
                                       N                      M        between these three types of interference.
g and b subject to the constraints ∑ g2i ≤ Cg and ∑ b2i ≤ Cb ,             In interaction cost analysis, we will assume that a stimulus
                                      i=1                    i=1
where Cg and Cb define the maximum amount of control that              is of value 1 when it is active, and 0 otherwise. Moreover, to
can be applied. Alternatively, in this setting, we can also ap-        increase tractability, we will consider linear activation at the
proach the problem of minimizing the cost of control, while            output level, which also implies that without loss of general-
still maintaining a desired value of probability of activation.        ity the pre- and post-interaction biases can be assumed to be
   One can consider the joint distribution of the processes of         zero. A more detailed version of the interaction cost analysis,
interest to incorporate the effects of interaction between tasks.      involving the strength of stimuli, as well as the nonlinear acti-
To be consistent with (Feng et al., 2014; Musslick et al.,             vation function, will be discussed in subsequent publications.
2016), it is reasonable to begin with a focus narrowed to the
situation where the choice of interaction weights and the prior            To introduce the interaction cost, we take an approach sim-
distribution of the stimuli render the interactions undesirable.       ilar to the one adopted by Koechlin and Summerfield (2007).
Then the effect of multitasking can measured by introducing            In their work, Koechlin and Summerfield (2007) proposed a
a suitable distance metric (for example, the Kullback-Leibler          metric for selecting a single action among multiple alterna-
divergence (Ortega & Braun, 2013)) between the joint distri-           tives. Here, we will refine this metric to introduce the inter-
butions of relevant processes and the product of correspond-           action cost for neural network architectures. Towards this ob-
ing marginals, and one can attempt to minimize this distance           jective, we first leverage the assumptions discussed earlier in
                                                                   897

                                                                                   Equation 1 implies the P[a j = i] = 1 when only the rel-
                                                                               evant stimulus Si associated with task i j is activated in the
                                                                               network. Hence the interaction cost is computed as Ψ(a j =
                                                                               i) = 0 which implies that there is no interaction cost. More-
                                                                               over, when multiple processes are competing due to the ac-
                                                                               tivation of multiple stimuli, P[a j = i] → 0 as the compe-
                                                                               tition increases, and as a consequence the interaction cost
                                                                               Ψ(a j = i) → ∞.
                                                                                   We further extend equation 1, to encapsulate the proba-
Figure 2: The illustration of convergent, divergent, asymmetric,               bility associated with parallel processing of task pathways
and symmetric interference.
                                                                               in the network. Thus, we introduce the joint probability
the section, and abstract out the network configurations pre-                  of distinct output components responding to a set of stim-
sented in Fig. 2 from the network shown in Fig. 1. We also                     uli. For instance, let us consider the parallel processing of
assume that the strength of a task i j from stimulus Si to output              tasks with strength w11 and w21 in Fig. 2a, and calculate
O j is represented by its non-negative weight wi j ≥ 0.                        P[a1 = 1, a1 = 2]. This is the probability of output compo-
    Let us first consider the case shown in Fig. 2a. It is obvious             nent O1 responding to both S1 and S2 , and by definition we
that the response in the output component O j is completely                    know that this probability is zero. For the case illustrated in
determined by the stimulus if either S1 or S2 is activated in                  Fig. 2b, the joint probability P[a1 = 1, a2 = 1] = 1 since ac-
the network (executing a single process). However, activating                  tivation of S1 will activate both processes with strengths w11
both stimuli S1 and S2 simultaneously creates a conflict, since                and w12 , and there is no competition in outputs O1 and O2 .
the output can not respond to two distinct stimuli simultane-                  This result is parallel to the observation made by (Musslick
ously (as the activations are linear, the network will always                  et al., 2016), who stated that divergent interference is not ac-
have a response in the output level). In order to measure the                  tually an interference but a dependency on the stimuli.
level of this competition between stimuli, we define a random                      Now let us consider the case introduced in Fig. 2c which
variable a1 associated with the output O1 such that a1 ∈ {1, 2}                can be thought of as the composition of the two cases pre-
(Fig. 2a). This implies that a1 = 1 or a1 = 2 when the out-                    sented in Fig. 2a-b. We compute the interaction cost of paral-
put O1 is driven completely by S1 or S2 , respectively. Since a                lel processing the tasks with strengths w11 and w22 . This re-
stronger task will have a higher probability of being selected                 quires simultaneous activation of S1 and S2 , which indirectly
to generate the response, we consider the relative strengths of                engages the task with strength w21 , and initiates a competition
the task pathways (with associated strengths w11 and w21 ) in                  in the output O1 . Thus, the interaction cost of parallelism be-
order to define the probability of the possible outcomes, i.e.                 tween tasks represented by w11 and w22 is given by
the probability of a1 = 1 and a1 = 2 when both S1 and S2
activated. Hence, we compute the probability as                                   Ψ1 (a1 = 1, a2 = 2) = − log(P[a2 = 2] · P[a1 = 1|a2 = 2])
                                                                                                                              
                          w11                                   w21                                                    w11
   P[a1 = 1] =                    ,      and, P[a1 = 2] =              .                              = − log 1 ·                .
                      w11 + w21                              w11 + w21                                             w11 + w21
    Next, we extend this framework to consider networks                        Here P[a2 = 2] = 1 since task with weight w22 is not compet-
with N stimuli and M outputs, wherein an output O j , j ∈                      ing with any other process in the output O2 . The competition,
{1, . . . , M} responds to a set of stimuli. Let us assume that                however, takes place in O1 , and the interaction cost associ-
there are n ≤ N incoming edges to a particular output O j ,                    ated with w11 for this case has already been computed when
and each edge is originated from a distinct stimulus Si , i =                  we discussed the case in Fig. 2a.
i1 , . . . , in , where ik ∈ {1, . . . , N}. Then the probability of the           In a similar way, we can compute the interaction cost
event that output O j is responding to stimulus Si is given by,                of parallelism between tasks represented by w11 and w22 in
                                                                               Fig. 2d, and we have
                                             wi j 1(Si )
                         P[a j = i] =      n               ,           (1)
                                           ∑ wik j 1(Sik )                        Ψ2 (a1 = 1, a2 = 2) = − log(P[a2 = 2] · P[a1 = 1|a2 = 2])
                                          k=1
                                                                                                                                        
                                                                                                                    w11          w22
                                                                                                      = − log               ·              .
where 1(Si ) is the indicator function that represents the ac-                                                   w11 + w21 w22 + w12
tivation of stimulus Si such that 1(Si ) = 1 if stimulus Si is
                                                                               In this case, simultaneous activation of S1 and S2 causes com-
active and 1(Si ) = 0, otherwise. Then, by building upon the
                                                                               petition in both outputs O1 and O2 . Thus, by revealing further
ideas proposed by (Koechlin & Summerfield, 2007), we de-
                                                                               insight about the strength and directionality of interference,
fine the interaction cost as
                                                                               the interaction cost serves as an extension of the interference
                       Ψ(a j = i) = − log(P[a j = i]),                 (2)     definition presented by (Musslick et al., 2016). For instance,
                                                                               for the same values of w11 , w21 , w22 ≥ 0 in both configura-
where the logarithm is with respect to base 2.                                 tions in Fig. 2c-d, and given w12 ≥ 0 for the configuration in
                                                                           898

Fig. 2d, it is obvious that                                            ing from task (S2 : O1 ). However, for the case of interfer-
                                                                       ence illustrated in Fig. 3c, the response patterns for both tasks
           Ψ1 (a1 = 1, a2 = 2) ≤ Ψ2 (a1 = 1, a2 = 2).                  (S1 : O1 ) and (S2 : O2 ) are impaired as observed by the activa-
                                                                       tion patterns. These simulation results reflect the influence of
Neural Network Simulation                                              the directionality of interference between tasks as predicted
In order to investigate the effect of directionality for the third     by the proposed interaction cost.
indirect interference during parallel processing, we imple-
mented a synthetic neural network simulation3 identical to
our earlier work (Musslick et al., 2016). The neural net-
work used for this simulation maps stimulus input encoded
at a stimulus layer via a non-linear associative layer to non-
linear response layer. A separate task input layer encodes
the current task to be performed with respect to that stimulus
and projects to both the associative layer and response layer.
Units in the stimulus layer were grouped into six stimulus di-
mensions with three units per dimension. Similarly, units in           Figure 3: This figure illustrates the performance of a task-pair for a
                                                                       given interference pattern. Each tasks maps a subset of three stimu-
the response layer was grouped into six response dimensions            lus input units onto three response units (see text). The orange color
with three units per dimension. The network was trained on             in the bar plots indicates unit activation of response units relevant to
12 tasks, where each task corresponds to a one-to-one map-             the depicted tasks, while gray indicates desired response pattern of
                                                                       those units.
ping between a subset of three input features in a stimulus
layer to a subset of three response units in an output layer.
                                                                                General Discussion and Conclusion
   We then used the methods described in Musslick et al.
(2016) to extract a bipartite task graph from single represen-         In this study, we have introduced two new measures to de-
tations encoded at the associative layer. The representations          termine costs associated with intensity and interaction for the
associated with each task can be characterized by calculating,         demand on control. First, we quantify the intensity cost as
for each unit in the associative and output layers, the mean of        a function of the amount of control bias that is supplemen-
its activity over all of the stimuli for a given task; this mean       tary to stimulus-specific processing in order to achieve a de-
pattern of activity can then be used as a representation of the        sired response from the network. Doing so, we formalize
task. Correlating these patterns of activity across tasks yields       the probability of achieving a desired task given the stim-
a task similarity matrix that can be examined separately for           ulus, weights and biases infused to the network. Since the
the associative and output layers of the network. This can             stimuli and weights are considered as network properties, the
then be used to assess the extent to which different tasks rely        intensity cost to achieve desired response is defined as the
on similar or different representation within each layer of the        amount (value) of control biases required to be injected to the
network. Tasks that have similar representations over the as-          input and output components of the network. The detailed
sociative layer can be inferred to rely on the same input di-          analysis of intensity cost revealed an interesting optimization
mension that is, they share an input component in the bipar-           problem to maximize the probability of surpassing a speci-
tite graph representation of the network and tasks that are            fied activation for a given budget of resources (i.e. an upper
similar at the output layer can be inferred to share an output         bound on the control biases). The existence of a solution of
component. Accordingly, a bipartite graph can be constructed           this optimization problem implicitly reveals whether the de-
by measuring the patterns of activity observed in the network          sired objective is feasible. However, as it can be foreseen that
while it performs each individual task.                                under certain circumstances the solution does not exist due to
   The extracted bipartite graph can be used to extract inter-         interference between the involved processes. Such boundary
ference patterns between pairs of tasks (cf. Fig. 2). We use           conditions motivated the second metric introduced in our pa-
this to extract all possible learned task-pairs involving no in-       per in which we formalize the interaction cost to measure the
terference case (Fig. 3a), and two distinct cases of interfer-         level of interactions/interference between processes by means
ence as shown in Fig. 3b and Fig. 3c from single-task repre-           of their type of connections and weights.
sentations. Fig. 3 shows the activation patterns of the output            With the introduced characterization of intensity and inter-
units for the simultaneous execution of two tasks, averaged            action costs, it is possible to formally define whether a pro-
across the patterns of all task pairs for a given interference         cess is considered a reflex, automatic or controlled. Con-
structure. That is, no interference (Fig. 3a) leads to very ac-        cretely, a process is considered a reflex if the underlying
curate response patterns (i.e. the current activation shown in         weight guarantees a successful execution. In other words, a
orange) is very close to the desired activation pattern shown          reflex can be successfully executed without any intensity or
in grey). For the case in Fig. 3b, the response pattern of task        interaction costs. We assume that the execution of both con-
(S1 : O1 ) is primarily impaired due to the interference aris-         trolled and automatic processes carries with it an intensity
                                                                       cost as some amount of control bias is needed to elicit a re-
    3 Simulation details are omitted due to space constraints.         sponse. However, unlike the former, controlled processes are
                                                                   899

subject to interference and thus yield interaction costs large        Botvinick, M. M., Cohen, J. D., & Carter, C. S. (2004). Con-
than zero.                                                              flict monitoring and anterior cingulate cortex: an update.
   The metrics proposed here can also be used towards fur-              Trends in Cognitive Sciences, 8(12), 539–546.
ther understanding cognitive effort as well as synthetic neu-         Cohen, J. D., Dunbar, K., & McClelland, J. L. (1990). On the
ral networks designed to achieve goal-driven tasks. By using            control of automatic processes: a parallel distributed pro-
the intensity cost, which reveals the interrelationship between         cessing account of the stroop effect. Psychological Review,
control bias and probability of achieving a desired objective,          97(3), 332–361.
we will investigate the limitations of any given neural net-          Feng, S. F., Schwemmer, M., Gershman, S. J., & Cohen, J. D.
work architecture by allocating a budget of control bias. The           (2014). Multitasking vs. Multiplexing: Toward a norma-
intensity cost can also be used to investigate the feasibility of       tive account of limitations in the simultaneous execution of
achieving a desired objective defined by the set of processes           control-demanding behaviors. Cognitive, Affective, & Be-
of interest in a network.                                               havioral Neuroscience, 14(1), 129-146.
   In the interaction cost analysis, we have assumed that there       Koechlin, E., & Summerfield, C. (2007). An information the-
exist a response in the output for any stimulus activation and          oretical approach to prefrontal executive function. Trends
this may not be the case for a nonlinear activation in the out-         in Cognitive Sciences, 11(6), 229–235.
put components. Hence, one major research direction is the            Kurzban, R., Duckworth, A., Kable, J. W., & Myers, J.
detailed analysis for the classification of processes with non-         (2013). An opportunity cost model of subjective effort
linear activation in output. Another possible direction for fu-         and task performance. The Behavioral and Brain Sciences,
ture work is to further analyze the interaction cost in order to        36(6), 661–679.
capture the properties of the overall network (not only a sub-        Muraven, M., Tice, D. M., & Baumeister, R. F. (1998). Self-
set of tasks of interest). This will allow one to use the inter-        control as a limited resource: Regulatory depletion pat-
action cost as an objective function for network training. An-          terns. Journal of Personality and Social Psychology, 74(3),
other possible direction is to explore the interrelationship be-        774-789.
tween intensity and interaction cost. In our work (Musslick et        Musslick, S., Dey, B., Özcimder, K., Patwary, M. M. A.,
al., 2016), we noticed a fundamental trade-off between shared           Willke, T. L., & Cohen, J. D. (2016). Controlled vs. Au-
representations in a network and its parallel processing ca-            tomatic Processing: A Graph-Theoretic Approach to the
pability (separated representations). Intuitively, we envision          Analysis of Serial vs. Parallel Processing in Neural Net-
this separation will decrease interaction cost while increasing         work Architectures. In Proceedings of the 38th Annual
the likelihood of successful execution for a given budget of            Conference of the Cognitive Science Society (pp. 1547–
control bias.                                                           1552). Philadelphia, PA.
                                                                      Ortega, P. A., & Braun, D. A. (2013). Thermodynamics as
                    Acknowledgements                                    a theory of decision-making with information-processing
                                                                        costs.     Proceedings of Royal Society A, 469(2153),
We would like to thank Zahra Aminzare, Adam Charles,
                                                                        20120683.
Jonathan Pillow and Vaibhav Srivastava for their help in the
                                                                      Posner, M. I., & Snyder, C. R. R. (1975). Attention and
formalism of the problem.
                                                                        cognitive control. In R. L. Solso (Ed.), Information Pro-
                                                                        cessing and Cognition: The Loyola Symposium (p. 55-85).
                          References
                                                                        Lawrence Erlbaum.
Bogacz, R., Brown, E., Moehlis, J., Holmes, P., & Co-                 Shenhav, A., Botvinick, M. M., & Cohen, J. D. (2013). The
   hen, J. D. (2006). The physics of optimal decision                   expected value of control: an integrative theory of anterior
   making: A formal analysis of models of performance in                cingulate cortex function. Neuron, 79(2), 217–240.
   two-alternative forced-choice tasks. Psychological Review,         Shenhav, A., Musslick, S., Lieder, F., Kool, W., Griffiths,
   113(4), 700–765.                                                     T. L., Cohen, J. D., & Botvinick, M. M. (2017). Toward
Botvinick, M. M. (2007). Conflict monitoring and decision               a rational and mechanistic account of mental effort. (sub-
   making: Reconciling two perspectives on anterior cingu-              mitted to Annual Reviews of Neuroscience)
   late function. Cognitive, Affective, & Behavioral Neuro-           Shiffrin, R. M., & Schneider, W. (1977). Controlled and auto-
   science, 7(4), 356–366.                                              matic human information processing: II. Perceptual learn-
Botvinick, M. M., & Braver, T. (2015). Motivation and Cog-              ing, automatic attending and a general theory. Psychologi-
   nitive Control: From Behavior to Neural Mechanism. An-               cal Review, 84(2), 127-190.
   nual Review of Psychology, 66(1), 83–113.
Botvinick, M. M., Braver, T. S., Barch, D. M., Carter, C. S.,
   & Cohen, J. D. (2001). Conflict monitoring and cognitive
   control. Psychological Review, 108(3), 624–652.
Botvinick, M. M., & Cohen, J. D. (2014). The computational
   and neural basis of cognitive control: Charted territory and
   new frontiers. Cognitive Science, 38(6), 1249–1285.
                                                                  900

