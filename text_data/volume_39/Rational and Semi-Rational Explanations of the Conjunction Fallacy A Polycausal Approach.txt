Rational and Semi-Rational Explanations of the Conjunction Fallacy:
A Polycausal Approach
Momme von Sydow (momme.von-sydow@urz.uni-münchen.de)
University of Munich (LMU), Munich Center for Mathematical Philosophy (MCMP),
Ludwigstr. 31, D-80539 München, Germany
and probability theory (Kolmogorov’s axiomatization).
According to these extensional approaches, two sets are
identical if they have the same elements (the same extension). Such an approach entails that any logically stronger
(more specific) proposition implies any more general proposition (e.g., A∧B => A∨B); and that any more specific hypothesis can never be more probable than a more general one.
Extensional logic and extensional probabilities have been
proposed to provide universal criteria of rational predication. Predication attributes a predicate or logical combination of predicates to a subject. First, valid (assertive) predication of general logical relationships has traditionally
often been linked to a logical truth-table definition of connectives (Frege, Russell, Whitehead, and Wittgenstein)
(Table 1). Accordingly, if a conjunction A∧B is true in a
universe of discourse (X), no cases in X fall outside of the
corresponding set (the intersection) and the truth of the conjunction implies, for instance, the truth of the affirmation A
as well as of the disjunction A∨B (Table 1).

Abstract
Conjunction fallacies (CF) have not only been a major
obstacle in justifying the rationality of a Bayesian theory of
belief update; they have also inspired a variety of theories on
probability judgment and logical predication. Here we provide
an overview of Bayesian logic (BL) as rational formulation of
a pattern-based class of conjunction fallacies. BL is described
here as a generalization of Bayesian Occam’s razor. BL
captures the idea that probabilities are sometimes used not
extensionally but intensionally, determining the probabilistic
adequacy of ideal logical patterns. It is emphasized that BL is
a class of models that depend on representations and the meanings of logical connectives. We discuss open questions and
limits of BL. We also briefly discuss whether other theories of
the CF may be good supplementary theories of CFs (and
predication) as well, if linked to functional explanations.
Keywords: probability judgments; biases; conjunction
fallacy; inclusion fallacy; inductive logics; intensional logics;
Bayesian logics; predication; strong sampling; categories;
Lockean Thesis; rationality debate; Bayesian Occam’s razor

Extensional vs. Intensional Probabilities

Table 1: Truth tables of some dyadic logical connectives:
conjunctions, exclusive disjunctions, affirmations, and
inclusive disjunctions

Extension vs. Intension

Figure 1: (A) Extensions as elements and intensions demarcated by set boundaries. (B) Characterization of extensional
and (C) intensional probabilities (cf. McKay, 2003, 28).
Although less known to the psychologist than to the
philosopher or logician, the notions of extension and intension (≠ “intention”) have a tradition going back to Leibniz,
Carnap, and Stegmüller; with several analogous terms
proposed by others, such as ‘meaning’ and ‘denotation’
(Russell) or ‘Sinn’ and ‘Bedeutung’ (Frege). Extension
refers to the elements of a set, and intension to the meaning,
which may be symbolized by the area determined by the set
boundaries (Figure 1A). Correspondingly, a set can be
described extensionally by specifying its elements or
intensionally by specifying one or several defining features.

Extensional narrow norms of predication
Extensional approaches have long dominated set theory
(Zermelo–Fraenkel set theory), logic (propositional logic),

A

B

A∧B

A >-< B A

A∨B

T

T

T

F

T

T

T

F

F

T

T

T

F

T

F

T

F

T

F

F

F

F

F

F

Assertive, contingent sentences, such as “Members of
Species X are aggressive (A) AND curious (B)” (von Sydow
& Fiedler, 2012) (in predicate logic: ∀x A(x) ∧ B(x)), can
thus be falsified by a single observation (Popper, 1934; but
see Oaksford & Chater, 2007). One problem in using (extensional) logic as adequacy criterion of contingent general
predications is that they often involve exceptions (von
Sydow, 2013). The problem of exception refers to the
phenomenon that we seem to employ general sentences, like
ravens are black, even if there are known exceptions, such
as albino ravens. One solution to this problem is to replace
the logical criterion of adequate predication by a high-probability criterion (P(Assertion) > ϕ > .5) (Schurz, 2001; cf.
Adams, 1986; Oaksford & Chater, 2007, Pfeiffer, 2013; BL
makes use of this idea, but for intensional probabilities).
Second, Kahneman & Tversky (1983) argued that any
deviation from the probabilistic extensional conjunction
rule, P(A∧B) ≤ P(A), involves a conjunction ‘fallacy’, even
in the context of predication. It is argued that extensional
logic and extensional probability are narrow norms (cf.
Gigerenzer, 1996; Fiedler & von Sydow, 2013) if applied as

3472

adequacy criterion for rational predication (von Sydow,
2011, 2016). One problem of a direct application of an
extensional probability criterion to predication is sample
size. That is, (extensional) relative frequencies do not
distinguish between 1/1 and 1000/1000 confirmative ravens.
However, the main problem with extensional probability
is that predicates referring to subsets can never yield a
higher probability than those referring to supersets.
However, it should be possible do deem more specific hypotheses to be more adequate; otherwise one could never prefer a more specific hypothesis. And it seems absurd, if, for
instance, “X are aggressive AND curious” (A∧B) could
never be more probable and hence more adequate than “X
are aggressive OR curious or both” (A∨B). Likewise, the
tautology (or ‘verum’) “X are aggressive or not, and they are
curious or not” (ATB) by definition (with a maximal extensional probability of 1) could never be less adequate than a
more suitable, specific hypothesis, independent of empirical
evidence. Therefore a universal extensional high-probability
criterion fails the requirement to be empirically informative.

applying basic Bayesian Occam’s razor (without noise) to
real predications presumably explains why the predominant
view holds that Bayesian accounts cannot rationally account
for CFs (Fisk, 1996; Gigerenzer, 1998; Neace et al., 2008).

BL as Generalized Bayesian Occam’s Razor
Bayesian logic (BL, von Sydow, 2011, 2016; cf. von
Sydow, 2013; von Sydow & Fiedler, 2012) addresses the
problem of exception together with the problem of
inclusion. Thus BL can be understood as using the ‘natural’
implications of Bayesian Occam’s Razor together with the
assumption that people are not interested in deterministic
logical hypotheses but rather in noisy-logical hypotheses
that are still similar to the deterministic hypotheses.

Intensional Probabilities of Bayesian Logic
Bayesian Occam’s Razor
The basic idea of a Bayesian Occam’s razor already offers a
partial solution to the problem of inclusion (Jeffreys &
Berger, 1992; Tenenbaum & Griffiths, 2001; McKay, 2003;
cf. Navarro et al., 2012). If a consequential region of hypotheses H1 is a subset of a consequential region of a hypothesis H2 (Figure 1C), even a subjective Bayesian account
may be extensional in the sense of requiring that the more
specific hypothesis can never be more probable than a more
general one (this is sometimes called ‘weak sampling’).
However, if one treats the nested hypotheses nonetheless as
alternative explanatory patterns (hypotheses) whose consequence regions may each have produced the data, the size of
the consequential regions matters (sometimes called ‘strong
sampling’). In this case, data coherent with the specific (and
also the general) hypothesis (cf. Figure 1C) is more likely to
occur based on the more specific hypothesis: P(data|H1) >
P(data|H2). If one additionally assigns an equal prior to
these alternative hypotheses, P(H1) = P(H2), one can indeed
get a higher posterior for the more specific hypothesis,
P(H1) > P(H2). For extensional probabilities, by contrast, a
more specific hypothesis could never obtain a higher
probability than a more general one (inclusion rule). We
even treat this rule as the defining feature of extensional
probabilities. Since Bayesian Occam’s razor (strong sampling) violates this rule, we may thus call it an ‘intensional’
probability. For intensional probabilities, actually both the
size of the extension and that of the intension matter.
However, such a basic application of Bayesian Occam’s
razor does not allow for exceptions. A hypothesis is still
falsified by a single disconfirmatory instance. But predications about contingent facts often allow for exceptions (von
Sydow, 2013b). Otherwise one still could never prefer a
more specific predication over a tautology. This problem of

Figure 2: BL model sketch in 5 steps (cf. main text)
Step 1 of the model (Figure 2) turns deterministic truth
tables into ideal (and still in some sense deterministic)
probability tables (PTs). In the PTs above dark shadings
represent a high probability (up to 1) and light shadings a
low probability (down to 0). Step 1 only constructs PTs with
noise level r = 0. Here, cells of a PT that correspond to
logically false truth values (F) are assigned the value 0.
Logically confirmatory cells (T) in these ideal
representations, however, are assumed to be equi-probable
(Johnson-Laird, Legrenzi, Girotto, Legrenzi, & Caverni,
1999). Step 1 (combined with Steps 3 and 4) already
provides a basic Occam’s razor solution. However, here,
connectives are still falsified by single disconfirmatory
events.
Step 2 addresses the problem of exceptions and constructs
ideal noisy PTs (with r > 0) by adding noise to each cell of
the ideal patterns from Step 1 and then renormalizing the
PTs.
There may be alternatives for modelling
noise/acceptance levels (e.g., von Sydow, 2014), but as long
as they yield similar results and address the problems of
inclusion and exception simultaneously this seems a
predominantly technical issue, and they should be seen as
variants of the same computation model class of BL. Note
that the PTs here are still ideal explanatory hypotheses
composed of four cell probabilities adding up to 1 and a
(second order) probability representing the belief in this PThypothesis (also adding up to 1, but now over all PThypotheses). We normally assume a flat prior distribution

3473

over all PTs (implying a flat prior distribution for both
connectives and noise levels).
Step 3. The likelihood of each explanatory 2×2 PT (for i×j
PTs, with i modelled connectives and j modelled equidistant
noise levels) given the data, P(PT |D), can be calculated by
a multinomial distribution. The data are i.i.d. observations in
a 2×2 contingency matrix (A vs. non-A, B vs. non-B).
Step 4 uses Bayes’ theorem to derive the posterior probabilities PI(PT|D) from the likelihoods P(D|PT) and priors.
Step 5 sums up the posterior probabilities of all PTs
created based on a particular logical hypothesis (over all j
noise levels). This results in (intensional and noise-tolerant)
posterior probabilities for each of the i connectives.

Figure 3. Intensional probabilities of logical hypotheses for
11 noise levels for a given 2× 2 data contingency matrix
with the cells a, b, c, d, here [7, 3, 2, 0], and a flat prior.
Figure 3 shows resulting intensional probabilities for all
modeled connectives at different noise levels (Step 4). If
one assumes no additional weighting for particular noiselevels (Step 5) the marginal probabilities provide the intensional posteriors for the connectives. In the example,
Pi(A∧B), Pi(A), and Pi(A∨B) have the highest overall probability. The intensional probabilities entail Pi(A∧B) >
Pi(B), although the extensional conjunction rule requires
PE(A∧B) > PE(B). ‘A or B (or both)’ (A∨B) is (intensionally)
most probable at low levels of noise, but ‘A and B’ is most
likely at higher levels of noise. Thus noise priors – for
instance a belief in deterministic relationships – may change
the intensional probability assessment.

Findings Corroborating Standard Dyadic BL
Bayesian Logic, in its outlined main version, is an inductive
logic providing intensional probabilities of dyadic logical
connectives. The connectives relate two dichotomous
events, and the model input are priors or frequencies (or
equivalent Dirichlet-distributed, degrees of belief). BL
provides a rational reconstruction of a class of pattern-based
conjunction fallacies in line with Bayesian updating (cf.
Hartmann, & Meijs, 2012, for another rational Bayesian
model of CFs, based on source reliability). BL in a way

detects the noisy-logical pattern that is most ‘similar’ to the
data (actually P(PT|D)).
Some comments may be appropriate: First, if participants
must rank the probability of two nested logical connectives
(e.g., a conjunction and one of its conjuncts; Tversky &
Kahneman, 1983), using intensional probabilities, PI, instead
of extensional ones, PE, is not fallacious; both are probabilities. We here continue to speak of conjunction ‘fallacies’
only for reasons of convenience. If the previous argument is
correct, it is even reasonable, in the context of predication
and looking for the most adequate connective, to apply
intensional probability, since it serves a reasonable function
(providing an empirically informative probabilistic adequacy criterion for predication). Second, the intensional probabilities only supplement extensional probabilities. BL is
likewise based on the standard extensional axioms of
probability (Kolmogorov’s axioms), but applies these
axioms not on the level of extensions, but on that of
probabilities of alternative logical hypotheses. (Similarly, in
Bayes nets one may apply hypotheses probabilities to
graphs without invalidating the underlying joint probability
matrix. 1) Third, BL is formulated not only as a normative
but also as a descriptive (computational-level) theory of
probability judgments concerning logical predications.
However, the claim is, of course, not that people have a
deliberate analytic understanding of BL. Their judgments
may be roughly reasonable, as our perception system makes
reasonable inferences without requiring conscious calculations. Moreover, people may merely be using something
similar to intensional probabilities; and it needs to be
explored whether they perhaps use some roughly related
heuristic that only approximates BL.
One major finding that seems unique to pattern-based CFs
advocated by BL, was BL’s various predictions for conjunction fallacies. For instance, von Sydow (2011) showed
that CFs occurred even with clearly defined subsets, clear
logical hypothesis formulations, and data transparently
presented in a contingency table (cf. Sloman et al., 2003).
Moreover, the results confirmed predicted conditions of a
dominant occurrence of a high proportion of double CFs,
sample-size effects, and the results for negated propositions.
A second group of corroborations of BL concerns the
generalization of (pattern-based) conjunction fallacies to
other logical inclusion fallacies (von Sydow, 2009, 2013b,
2016; von Sydow & Fiedler, 2012). Figure 4 illustrates that
logically there are many more logical inclusion relations
than those involved in CFs, and thus many possible
inclusion ‘fallacies’. For instance, von Sydow (2016) corroborated that there is a more general system of inclusion
fallacies broadly in line with BL, and that this system could
not be explained by other major theories. Von Sydow &
Fiedler (2012) applied this idea to sequential learning and
repeated judgments, and von Sydow (2013b) has shown the
1

Actually an analogous model of subjective belief update of the
cell probabilities (using Dirichlet distributions) which is then compared to ideal patterns yields the same results (not elaborated here).

3474

applicability of a pattern account even if numbers were not
provided explicitly.

posterior belief-distribution extending from 0, .5, or 1, in
order to formalize the alternative hypotheses ‘A’, ‘A or
non-A’, and ‘non-A’ (Figure 6, red marks).

Figure 4. Inclusion relations between all 16
combinatorically possible dyadic logical connectives.

BL as Model Class and
Future Avenues of Research

Figure 6. Monadic BL and example for prior, likelihood,
posterior, and the red integrals.

Monadic Dichotomous BL and Conjunctions as
Combination of Marginals
This section supports the view that polysemous meanings
of ordinary-language connectives play an important role in
the CF debate, that this is compatible with BL, and that intensional BL even offers additional differentiations.
The intensional idea of BL (or the ‘pattern idea’) can also
be applied to the simpler representation of monadic logic
(thereby linking to the literature on generics). Whereas
standard dyadic logic concerns all possible bivariate, twovalued (T, F) patterns in a 2 × 2 matrix (cf. Fig. 4), monadic
logic concerns a single event only (a 2 × 1 matrix). The formalized intensional monadic BL (von Sydow, 2014, cf
Tessler, & Goodman, 2016) predicts inclusion ‘fallacies’:
e.g., our example (Figure 5, Panel A), PI(A) > PI(A Tautology non-A), or formulated as P(People in this group are
artists) > P(… are artists or non-artists) (von Sydow, 2015).

Figure 5. Illustration of representations modelled in
(dichotomous) monadic BL and (polytomous) monadic BL
The model starts with a Beta prior, a binomial
likelihood, and therefore continues with a Beta posterior
(Figure 6). We pursued a slightly different approach of
modelling noise levels here (without changing the pattern
idea). We used integrals of the same size over parts of the

Based on monadic BL (Figure 5A, 6) a new meaning of
the AND-connective based on two marginal probabilities
has been proposed (Figure 7B, von Sydow, 2014).

Figure 7. Dyadic and marginal meaning of ‘AND’.
This meaning is in line with the approach that the
ordinary language “and” is logically polysemous and may
refer to the dyadic conjunction, the disjunction or the sum
(Hertwig et al., 2008; von Sydow, 2015). The conjunction of
monadic affirmations (von Sydow, 2014a) actually refers to
the same cells as the inclusive-disjunction interpretation
proposed earlier, whereas this proposal intensionally makes
different predictions. Note that it seems possible to link the
dyadic and marginal interpretation (Figure 7) to different
formulations favouring a more dyadic (“the pub is visited by
people who are young and (also) male”) or a more marginal
interpretation (“the pub is visited by young people and is
visited by male people”). Additionally, we supported
already known usages of AND as an addition of classes in
an intensional polytomous context (von Sydow, 2015).

Polytomous Monadic BL
Figure 5 (Panel B) points to a further interesting perspective
suggested by an approach that looks at not only (relative)
cardinality of extensions (e.g., relative frequencies) but also

3475

the size of the (represented) intension. For the data shown in
Panel B, both extensional and here also intensional (dichotomous) monadic BL would not allow to predict P(… are A) >
P(are Non-A). However, polytomous monadic BL, which
here assumes polytomous representations for the negation,
predicts even this. Moreover, it predicts, for instance, P(…
are A) > P(are A∨D∨E). Von Sydow (2015) elaborated a
model in other regards analogous to standard BL, tested
many patterns, and contrasted the predictions of BL with a
confirmation account (Tentori et al., 2013). The results
clearly corroborated BL (in some examples even independently of the various measures of confirmation). More
generally, this account emphasizes that BL assigns high intensional probabilities to patterns most adequately describing a situation, in the sense of having a relatively high
probability while taking intension-size into account.

Some Further Open Questions
(1) Variants of BL. The relation of two kinds of variants
of BL needs further elaboration and scrutiny. First, BL has
been shown to be an intensional model class for logical
predication that depends on dyadic versus monadic, and
dichotomous versus polytomous representations. Second,
we actually used different model variants to model noise (cf.
von Sydow, 2007 (cf. 2011), 2014, 2016; and there may be
further variants). Despite impressive fits of all models (and,
as far as I can see, only minor differences between them),
one may design experiments to differentiate between these
second kinds of model variants as well.
(2) BL and Conditionals: One may apply the idea of BL
to further representations. For instance, von Sydow (2014)
proposed an intensional model of conditionals, building on
additional representational assumptions about conditionals.
Inspired by mental model theory, it was suggested to
differentiate between basic conditionals based on
conditional probability alone, and full models based on
Delta p (or causal Power). In an intensional setting, when
the probability of conditionals is compared with the
probability of other logical connectives, the intensional
version of this model requires testing. The Bayesian logic of
conditionals may also throw light on the paradoxes of
implication (cf. von Sydow, 2009).
(3) BL and Reasoning: Here BL is presented as an
inductive logic only, not directly applicable to reasoning
without further assumptions. However, only a few assumptions may be needed to make BL fruitful in this field as
well. Extensional or intensional premises may simply
change the joint probability matrix (or frequency matrix),
and the update may be based on standard conditionalization,
Jeffry conditionalisation, or Kullback-Leibler distancereduction. Based on resultant joint probability distribution
(or the equivalent frequency distribution), one may infer
intensional probabilities for resulting connectives using BL.
The inferences would be based on prior beliefs and on the
logical form of the added premise (cf. dual process theories;
e.g., Singermann, Klauer, & Beller., 2016). The variety of
advocated representations (extensional, intensional; dyadic,

monadic; dichotomous and polytomous, etc.) and
alternations between these modes needs future attention. For
instance, one may intensionally believe in the dyadic hypothesis “(normally) A and B”. In line with Foley (1992; cf.
the Lockean thesis) this does not need to imply a high probability of the composing single (dyadic) hypotheses A (“A
and B or A and non-B”). In contrast, the monadic hypothesis
A, in such situations, would always have a high probability
as well (cf. von Sydow, 2014).
These suggestions demand further elaboration, but the
prior confirmation of the BL and its variants suggests that
they may be helpful in this domain as well.

Other Theories of CFs:
Polycausal Semi-Rational Suggestions
It has been shown repeatedly that the results confirming BL
could not be explained by other major theories of the CF
(von Sydow, 2011, 2015, 2016). This does not entail that
these theories do not have a reasonable domain of application. There may well be several causes of CFs or, more
generally, of inclusion fallacies (IFs; cf. von Sydow, 2016).
BL itself is ‘polycausal’ in the sense that the modelling
depends on the representation. One should use different
formalizations for different scales and sampling
assumptions (von Sydow, 2015, cf. Tessler & Nelson,
2016). In particular, representation of classes matters due to
intensionality, with different results for dichotomous and
polytomous events. Moreover, BL is consistent with various
interpretations, for instance, of the ordinary conjunctions
(Hertwig et al., 2008; von Sydow, 2015) and even adds new
candidates to this list (von Sydow, 2014).
There are further theories of CFs claiming that the target
measure P(H|D) is substituted by other measures, such as
inverse probability, confirmation, or averaging (cf. also
Costello & Watts, 2014). The predictions of these theories
are thus more difficult to defend from a rational point of
view. BL’s substitution of P(H|D) by intensional PI(H|D)
rather than by extensional PE(H|D) involves no substitution
at all, only a specific interpretation, and, as outlined before,
a reasonable one. In contrast, replacing P(H|D) by P(D|H),
as suggested by an inverse-probability account, or by, for
instance, P(H|D)-P(H|D), as in a confirmation account
(Lagnado & Shanks, 2003; Tentori et al., 2013), seems less
rational, since this involves an illicit replacement.
Nonetheless, if this replacement would be linked to a
functional explanation why and when this replacement
should occur, this may be seen as semi-rational as well. An
interest in adequately describing a logical relationship
between given features, provides a BL context. An interest
in a particularly high probability of a feature given a class
may provide a context for inverse probabilities (or an
inverse pattern account). And an interest in the surprisingness of a feature may be a context for a confirmation
account (or a pattern-confirmation account). Although
functional explanations and application conditions are
currently still often missing in these theory presentations,
they may be reformulated as semi-rational accounts of the

3476

CF as well. These theories may exist in unproblematic
cohabitation with the even more rational account of BL and,
perhaps, like BL, with an extensional usage of probabilities.

Summary
Whereas previous presentations of BL were mainly
concerned with presenting specific empirical findings, the
present account tries to provide more of an overview. BL is
presented here in an overview as an intensional account that
generalizes Bayesian Occam’s razor in the field of logical
predications. BL is posited not as a specific model but rather
as a model class sensitive to representation, open to further
extensions, and predicting many still unexplored effects.
Furthermore, it was emphasized that BL is in line with
theories assuming various meanings of connectives while
fostering new proposals and opening up many new avenues
of research. Finally, it was argued that the disconfirmation
of other theories when testing BL does not at all rule out the
adequacy of other accounts of CFs. It was suggested that
some other accounts, if they would more clearly specify
functional explanations, may count as semi-rational theories
of CFs. Theories that pretend to provide a single algorithmic
account of CFs underestimate the contextuality and goal dependence of such judgments. In the future, a polycausal
theory of CFs needs to be elaborated, including rational
accounts, involving BL in its various versions (relating to
different representations), the mentioned semi-rational
accounts (as well as a noise + probability account), and,
perhaps, completely irrational accounts.

Acknowledgments
This work was supported by the Grant Sy111/2-1 from the
Deutsche Forschungsgemeinschaft (DFG) as part of the
priority program New Frameworks of Rationality (SPP
1516). I am grateful to Martha Cunningham and Linda
McCaughey for corrections and to many others, including
some anonymous reviewers, for inspiration and discussions.

References
Adams, E. W. (1986). On the logic of high probability. Journal of
Philosophical Logic, 15, 255-279.
Costello, F. and Watts, P. (2014). Surprisingly rational: Probability
theory plus noise explains biases in judgment. Psychological Review,
121(3):463–480.
Fiedler, K. & von Sydow, M. (2015). Heuristics and Biases: Beyond
Tversky and Kahneman's (1974) Judgment under Uncertainty (pp. 146151). In: M. W. Eysenck & D. Groome. Cognitive Psychology:
Revisiting the Classical Studies. Los Angeles, London: Sage.
Fisk, J. E. (1996). The conjunction effect: Fallacy or Bayesian inference?
Organizational Behavior and Human Decision Processes, 67, 76–90.
Foley, R. (2009). Beliefs, Degrees of Belief, and the Lockean Thesis. In: F.
Huber, C. Schmidt-Petri (eds.), Degrees of Belief, Synthese Library 342,
Heidelberg: Springer.
Gigerenzer, G. (1996). On narrow norms and vague heuristics.
Psychological Review, 103, 592-596.
Gigerenzer, G. (1998). Ecological intelligence: An adaptation for
frequencies. In D. D. Cummins & C. Allen (Eds.), The evolution of
mind. New York: Oxford University Press.
Hartmann, S., & Meijs, W. (2012). Walter the banker - the conjunction
fallacy reconsidered. Synthese, 184, 73–87.
Hertwig, R., Benz, B., & Krauss, B. S. (2008). The conjunction fallacy and

the many meanings of and. Cognition, 108, 740-753.
Johnson-Laird, P. N., Legrenzi, P., Girotto, V., Legrenzi, S. M., & Caverni,
J.-P. (1999). Naive probability: A mental model theory of extensional
reasoning. Psychological Review, 106, 62–88. DOI:10.1037/0033295X.106.1.62
Lagnado, D. & Shanks, D. (2003). The influence of hierarchy on
probability judgments. Cognition, 89, 157–178.
MacKay, D. J. C. (2003). Information Theory, Inference, and Learning
Algorithms. Cambridge University Press.
Navarro, D., Dry, M. J., & Lee, M. (2012). Sampling Assumptions in
Inductive Generalization. Cognitive Science, 36(2), 187–223.
Neace, W. P., Michaud, S., Bolling, L., Deer, K., & Zecevic, L. (2008).
Frequency formats, probability formats, or problem structure? A test of
the nested-sets hypothesis in an extensional reasoning task. Judgment
and Decision Making, 3, 140-152.
Oaksford, M., & Chater, N. (2007). Bayesian rationality. The probabilistic
approach to human reasoning. Oxford: Oxford University Press.
Pfeifer, N. (2013). The new psychology of reasoning: A mental probability
logical perspective. Thinking & Reasoning, 19(3-4), 329-345.
Schurz, G. (2001). Normische Gesetzeshypothesen und die wissenschaftsphilosophische Bedeutung des nichtmonotonen Schliessens. Journal for
General Philosophy of Science, 32, 65-107.
Sloman, S. A., Over, D., Slovak, L., & Stibel, J. M. (2003). Frequency
illusions. Organizational Behavior and Human Processes, 91, 296-309.
Singmann, H., Klauer, K. C., & Beller, S. (2016). Probabilistic Conditional
Reasoning: Disentangling Form and Content with the Dual-Source
Model. Cognitive Psychology, 88, 61-87.
doi:10.1016/j.cogpsych.2016.06.005
Tenenbaum, J. & Griffiths, T. (2001a). Generalization, similarity, and
Bayesian inference. Behavioral and Brain Sciences, 24(4), 629-640.
Tentori, K., Crupi, V., & Russo, S. (2013). Determinants of the conjunction
fallacy: Confirmation versus probability. Journal of Experimental
Psychology: General, 142, 235-255.
Tessler, M. H. & Goodman, N. D. (2016). Communicating generalizations
about events. In Proceedings of the Thirty-eighth Annual Conference of
the Cognitive Science Society (1655–1660). Austin, TX: Cognitive
Science Society.
Tversky, A., & Kahneman, D. (1983). Extensional versus intuitive
reasoning: The conjunction fallacy in probability judgment.
Psychological Review, 90, 293-315.
von Sydow, M. (2011). The Bayesian Logic of Frequency-Based
Conjunction Fallacies. Journal of Mathematical Psychology, 55(2), 119139. doi:10.1016/j.jmp.2010.12.001
von Sydow, M. (2009). On a General Bayesian Pattern Logic of FrequencyBased Logical Inclusion Fallacies. In Proceedings of the Thirty-First
Annual Conference of the Cognitive Science Society (pp. 248-253). Austin,
TX: Cognitive Science Society.
von Sydow, M. (2013a). System implemented by a processor controlled
machine for inductive determination of pattern probabilities of logical
connectors. United States Patent (Issued), No. US 8,463,734 B2.
von Sydow, M. (2013b). Logical Patterns in Individual and General
Predication. In M. Knauff, et al. (Eds.), Proceedings of the Thirty-Fifth
Annual Conference of the Cognitive Science Society (pp. 3693-3698).
Austin TX: Cognitive Science Society.
von Sydow, M. (2014a). Is there a Monadic as well as a Dyadic Bayesian
Logic? Two Logics Explaining Conjunction ‘Fallacies’. Proceedings of
the Thirty-Sixth Annual Conference of the Cognitive Science Society (pp.
1712-1717). Austin TX: Cognitive Science Society.
von Sydow, M. (2014b). Bayesian Mental Models of Conditionals.
Cognitive Processing, 15 (Special Issue: Proceedings of the 12th
Biannual Conference of the German cognitive science society), 148-151.
doi:10.1007/s10339-014-0632-2.
von Sydow, M. (2015). Pattern Probabilities for Non-Dichotomous Events:
A New Rational Contribution to the Conjunction Fallacy Debate.
Proceedings of the 37th Annual Conference of the Cognitive Science
Society (pp. 2511-2516). Austin, TX: Cognitive Science Society.
von Sydow, M. (2016). Towards a Pattern-Based Logic of Probability
Judgements and Logical Inclusion “Fallacies”. Thinking & Reasoning,
22(3), 297-335. doi:10.1080/13546783.
von Sydow, M. & Fiedler, K. (2012). Bayesian Logic and Trial-by-trial
Learning. Proceedings of the 34th Annual Conference of the Cognitive
Science Society (1090 - 1095). Austin TX: Cognitive Science Society.

3477

