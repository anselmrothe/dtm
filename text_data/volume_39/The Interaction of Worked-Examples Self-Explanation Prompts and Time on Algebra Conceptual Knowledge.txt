The Interaction of Worked-Examples/ Self-Explanation Prompts and Time on
Algebra Conceptual Knowledge
Kelly M. McGinn (kelly.mcginn@temple.edu)
Temple University, Department of Psychological Studies in Education, 1301 Cecil B. Moore Ave.
Philadelphia, PA 19122 USA

Julie L. Booth (julie.booth@temple.edu)
Temple University, Department of Psychological Studies in Education, 1301 Cecil B. Moore Ave.
Philadelphia, PA 19122 USA

Laura K. Young (laura.young@temple.edu)
Temple University, Department of Psychological Studies in Education, 1301 Cecil B. Moore Ave.
Philadelphia, PA 19122 USA
Abstract
Success in Algebra I often predicts whether or not a student
will pursue higher levels of mathematics and science.
However, many students enter algebra holding persistent
misconceptions that are difficult to eliminate, thus, hindering
their ability to succeed in algebra. One way to address these
misconceptions is to implement worked-examples and selfexplanation prompts, which have been shown to improve
students’ conceptual knowledge. However this effect seems to
be greater after a delay. The current study sought to explore
such time-related effects on algebra conceptual knowledge. In
a year-long random-assignment study, students either studied
worked-examples and answered self-explanation prompts (n =
132) or solved typical isomorphic problems (n = 140). A
three-way mixed ANCOVA (pre-algebra knowledge x
condition x time) found a significant condition by time effect.
The growth of algebra conceptual knowledge was greater for
students studying worked-examples than for those solving
typical problems.
Keywords: worked-examples; self-explanation prompts;
algebra; conceptual knowledge

Introduction

misconceptions such as believing that the equals sign is an
indicator of operations to be performed (Baroody &
Ginsburg, 1983; Kieran, 1981; Knuth Stephens, McNeils, &
Alibali, 2006), that the negative sign represents only the
subtraction operation and does not modify terms (Vlassis,
2004), that subtraction is commutative (Warren, 2003), and
that variables cannot take on multiple values (Booth, 1984;
Knuth et al., Kuchemann, 1978) are all thought to be
critical. Holding such misconceptions have been shown to
hinder students’ success in problem solving (Booth &
Koedinger, 2008).
A large body of research supports the notion that
eliminating mathematics misconceptions is not an easy task.
In fact, many students continue to hold these
misconceptions after traditional classroom instruction
(Booth, Koedinger & Siegler, 2007; Vlassis, 2004). Often in
order to challenge a student’s misconception, one must
directly draw out and confront the faulty thinking (Donovan
& Bransford, 2005). A combination of worked-examples
and self-explanation prompts has been used to do just that.

Algebra I is often considered to be a gate-keeper course,
meaning that a student’s success in the course often
determines whether he or she will continue on to a higher
level mathematics or science course (U.S. Department of
Education, 1997). Furthermore, students in the United
States tend to struggle mastering algebra concepts,
potentially contributing to the lower enrollment of U.S.
college students in mathematics and science related majors
compared to competing countries.

Worked-examples, which are mathematics problems with
worked-out solutions, provide the opportunity to point out
common misconceptions to students. Some textbooks offer
a small number of worked-examples, often at the beginning
of a chapter or section. However, research indicates that
interleaved worked-examples, alternating between workedexamples and problems for students to solve, are more
beneficial to learning (Clark & Mayer, 2003; Sweller &
Cooper, 1985).

The newly implemented Common Core State Standards
(CCSSI, 2010) stresses the importance of both procedural
and conceptual knowledge of mathematics content.
However, especially when it comes to algebra, students hold
persistent misconceptions, which hinder their ability to
master the content. In fact, students often enter Algebra I
holding strong misconceptions that may impact their
success mastering algebra content (Brown, 1992; Chiu &
Liu, 2004; Kendeou & van den Broek, 2005). For instance,

Furthermore, the benefit of worked-examples can be
improved with the inclusion of self-explanation prompts,
which are questions that prompt students to explain their
reasoning. When students self-explain, they are able to
integrate various pieces of knowledge, fill gaps in their own
knowledge, and make new knowledge explicit (Chi, 2000;
Roy and Chi, 2005). Students at all ability levels who are

2687

prompted to self-explain learn more than those who do not
self-explain (Chi, de Leeuw, Chiu & Lavancher, 1994).

socioeconomically diverse, with 52% coming from families
who qualified for the Free or Reduced Lunch program
(FRL).

Often if a textbook uses a worked-example, it displays a
correct problem solution. However, incorrect workedexamples have also shown benefits to learning. In empirical
laboratory students, students who are asked to explain the
errors in incorrect solutions, as well as explain effective
strategies in correct examples, learn more than students who
are asked to only explain correct examples (Durkin & RittleJohnson, 2009; Siegler & Chen, 2008).

Due to the restrictions of repeated-measures ANOVA, only
students who completed all four quarterly exams were
included in the analysis. Due to natural attrition (i.e.
students leaving the school or absence on the day of the
quarterly exam) the sample was reduced to 272; 51%
female, 61% URM, 50% FRL.
Classrooms were randomly selected to either complete
problem- or example-based worksheets yielding 14
problem-based (n=140) and 14 example-based (n=132)
classrooms. Of the 12 teachers, eight taught one class of
each condition; however, two teachers instructed two
classes of the problem-based condition and one class of the
example-based condition, while two others instructed two
example-based classes and one of the problem-based class.

While the use of worked-examples and self-explanation
prompts have been shown to improve learning, often there is
a delayed-effect, meaning that the effect is larger on a
delayed post-test rather than immediately after the
intervention. For instance, Adams and colleagues (2014)
found that while students solving isomorphic problems with
feedback and students studying incorrect examples did not
differ significantly at immediate posttest, students in the
incorrect example group scored significantly better on a
delayed posttest compared to the problem-solving group.
This suggests that the worked-example/self-explanation
effect may improve over time.

Procedure

Current Study
This study applies previous laboratory research supporting
the use of both correct and incorrect worked-examples
paired with self-explanation prompts to the classroom.
While highly controlled laboratory studies are necessary
when developing theories, applied studies are needed in
order to investigate the limits of generalization.
We explore the effects of studying worked-examples and
answering self-explanation prompts compared to solving
typical isomorphic problems on students’ algebra
conceptual knowledge. We hypothesize that students who
study worked examples and answer self-explanation
prompts will have less algebra misconceptions and,
therefore, will have higher conceptual knowledge compared
to those who solve traditional isomeric problems.
Finally, the current study will explore students’ conceptual
knowledge growth over the course of a full school year,
extending the evidence to support a delayed effect by
providing
longitudinal
evidence
from
repeated
interventions.

Methods
Participants
Participants included 562 Algebra I students from 28
classrooms (12 teachers) from five school districts across
the United States. The sample was 49% female. Students
were classified as underrepresented minority (URM; Black,
Hispanic, biracial) or non-URM (White, Asian); 65% of the
students were classified as URM. Participants were also

Intervention During the school year, teachers taught the
algebra content using their own typically teaching methods;
however, they were asked to sporadically assign the 42
study-worksheets at times they deemed appropriate during
the year. Teachers did not have to assign the worksheets if
they did not cover that material in their curriculum. On
average, teachers assigned 27 worksheets (ranging from 15
to 40) throughout the year. There was no significant
difference in the number of worksheets assigned between
groups, with the problem-based group completing an
average of 28 worksheets and the example-based group
completing an average of 26 worksheets, p >.05. Teachers
were given the freedom to assign the worksheets in any
order and were told to treat the assignments as they would
any other assignment in their class; however they were
instructed to have students complete the assignments during
the class period, not for homework. Students were allowed
to work together if the teacher typically permitted that
behavior. Each assignment took about 20 minutes to
complete.
The worksheets of both conditions contained four problemsets (with two math problems similar to each other per set).
The problem-based worksheets contained four regular
problem-sets where students were asked to simply solve
each problem, similar to a typical math worksheet. The
example-based worksheets replaced one math problem
within each set with a worked-example and self-explanation
prompt(s). Students in this group were instructed to study
the worked-example, answer the self-explanation prompt,
and complete the second math problem on their own. Each
example-based worksheet contained two correct workedexamples and two incorrect worked-examples. See Figure 1
for sample problem- and example-based problem sets.

2688

study-worksheets. This exam covered content necessary for
the success in an algebra course, such as the understanding
of equality and difference between coefficient and constant.
This exam consisted of 11 items with 71 sub-items. Prealgebra knowledge scores were calculated by dividing the
total number of correctly answered items by 71.

a.) Problem-based set

Teacher Reports At the end of the year, teachers were
administered a survey about their experience in the study. In
one item, they were asked about the frequency with which
they reviewed study assignments in class. Teachers
responded by selecting one of the following options: 0-20%
of the time, 20-40% of the time, 40-60% of the time, 6080% of the time or 80-100% of the time. Teachers’
responses were recoded into a 1 (0-20%) to 5 (80-100%)
scale.

b.) Example-based set

All measures were scored and coded by two researchers,
checking for internal and external consistency.

Figure 1. Sample problem- and example-based problem sets.
Assessment At the beginning of the school year, all students
were given a pre-test assessing their pre-algebra knowledge.
Throughout the school year, students were given four
quarterly exams. The four exams contained the same 18
items, however teachers were asked to only assign the test
items taught to date; therefore, students were not answering
items containing content they were not already taught. This
exam assessed both procedural and conceptual algebra
knowledge. At the conclusion of the year, students were
given a post-test, consisting of 10 Algebra I standardizedtest release items.
At the end of the school year, each school provided the
researchers with student demographic information, such as
gender, ethnicity, and free or reduced lunch qualification.
Finally, teachers completed a survey answering questions
about their use of the worksheets. The survey contained
questions such as “How often did you review the
worksheets with the students after completion?”

Measures
Algebra Conceptual Knowledge The quarterly benchmark
exams consisted of 18 items, each of which had multiple
parts, yielding a total of 71 sub-items. Of these 71 subitems, 46 measured students’ conceptual knowledge of
algebra content. We operationally define conceptual
knowledge as an understanding of the core features in
problems for a given topic (e.g. Booth, 2011). Algebra
conceptual knowledge scores were calculated for each
quarter by dividing the number of correctly answered items
by 46. This score does not take into account the number of
items attempted since each teacher assigned a different
number of items each quarter.

Results
The following analysis explores the effects of time, prealgebra knowledge and condition on students’ algebra
conceptual knowledge. Pre-algebra knowledge was included
in the model because student’ prior-knowledge is known to
greatly influence their future learning. While other outcome
measures (i.e. procedural knowledge and standardized test
release items) were collected, they are beyond the scope of
this study focused on conceptual knowledge growth. The
other measures will or are presented in other reports.
Finally, URM status and rate of teacher review were
included as covariates because differences were found
between conditions.
A three-way mixed ANCOVA was run to understand the
effects of pre-algebra knowledge, condition, and time on
algebra conceptual knowledge. The rate of review and
minority status were included as covariates. Using
Greenhouse-Geisser estimates, the interaction between
condition, pre-algebra knowledge and time was not
statistically significant; however, there was a statistically
significant two-way interaction between time and all
between-subject variables. See Table 1 for results.

Pre-algebra Knowledge The pre-algebra exam was given
at the start of the school year before students completed any

2689

Table 1. Greenhouse-Geisser estimates for 3-way ANCOVA
for algebra conceptual knowledge.
F
10.826
4.333

p
<.001
.008

partial
η2
.055
.023

2.513

17.900

<.001

.088

201.058

1.482

<.001

.389

2.513

3.991

118.121
467.459

.957

.012
.608

Conceptual Knowledge Score

Quarter
Quarter x URM
Quarter x Rate
of Review
Quarter x Prealgebra
Quarter x
Condition
Quarter x
Condition x
Pre-algebra
Residual

df
2.513
2.513

Estimated Marginal Means

.021

Quarter
1
2
3
4

Mean
.179
.321
.435
.516

SE
.008
.011
.012
.016

Examplebases

1
2
3
4

.169
.332
.447
.568

.008
.011
.012
.017

95% CI
Lower Upper
.163
.195
.299
.343
.413
.458
.484
.548
.153
.310
.423
.535

.186
.354
.470
.601

0.45
0.4
0.35
0.3
0.25
0.2
0.15
2

3

4

Quarter

See Table 2 and Figure 2 for condition by time estimated
marginal means. At quarter 1, the example-based group
scored slightly lower than the problem-based group;
however, by quarter 4, the example-based group outscored
the problem-based group.

Condition
Problembased

0.5

1

.195

Table 2. Condition by time estimated marginal means with
95% confidence intervals.

0.6
0.55

Problem

Example

Figure 2. Condition by time estimated marginal means.

Discussion
Due to the nature of the quarterly exams, it was expected
that students would score better over time. As mentioned in
the procedure section, the conceptual knowledge portion of
the quarterly exam consisted of 46 sub-items. However,
students only attempted to answer the items in which they
were familiar with. Therefore, students attempted to answer
more items as they covered additional content over the
course of the school year, leading to potential increased
scores over time. However, we were more interested in the
interaction between treatment and time. It was hypothesized
that there would be differences in the rate of algebra
conceptual knowledge growth between the example-based
and problem-based groups.
As predicted, this analysis revealed a significant condition
by time interaction. At the end of quarter 1, students solving
typical algebra problems, in the problem-based group,
scored slightly better than students in the example-based
condition. However by the end of quarter 2, the opposite
occurred. Students studying worked-examples and
answering self-explanation prompts scored slightly higher
than those in the problem-based group. This gap continued
to widen throughout the remainder of the school year. By
quarter 4, example-based students scored an average of 5
percentage points higher on the algebra conceptual
knowledge test than the problem-based students, which is
supported by previous studies finding a delayed effect (i.e.
Adams et al., 2014).
The limitations of this study include a sample restricted to
those present for all four quarterly exams. In addition,
although a within-teacher design controlled for teacher-

2690

related variables, it is possible that there was some
contamination across classrooms. For instance, some
teachers reported using a few of their own worked-examples
with their problem-based classroom. The current analysis
was based on linear growth; further studies should consider
using a more robust analysis in order to account for possible
quadratic or cubic growth curves.
This analysis adds to the current body of research by
providing evidence from the classroom to support laboratory
findings. It also extends our understanding of the short-term
benefits of worked-examples and self-explanation prompts
by offering longitudinal data. Our findings emphasize the
need to measure learning over longer time intervals.
Based on these findings, it is suggested that teachers
interleave worked-examples and self-explanation prompts
with traditional algebra problems. In order to receive
maximum benefit, students should be exposed to this
approach consistently throughout the entire school year, not
just in a single instance. Furthermore, such interventions
should be interleaved in algebra textbooks, rather than
simply displaying a few correct worked-examples at the
beginning of a section. Finally, both correct and incorrect
worked-examples should be used in the classroom to
promote maximum benefit.
As previously noted, success in Algebra I is a known
gatekeeper to later mathematics and science success.
However, many students enter algebra with persistent
misconceptions that obstruct their achievement in algebra.
The findings from this study suggest that using workedexamples combined with self-explanation prompts as
classroom practice materials can improve student’s
conceptual knowledge, consequently decreasing their
misconceptions. The findings from this study are
particularly exciting as they come from a study that took
place in actual classrooms and not research laboratories.
Due to the setting of the current study, our findings illustrate
that even when precision, like that provided in a laboratory,
cannot be guaranteed the positive effect of using workedexamples paired with self-explanation prompts is still seen.

Acknowledgments
Thanks are due to the participating school districts; without
their interest this type of applied research would not be
possible. The research reported here was supported by the
Institute of Education Sciences, U.S. Department of
Education, through Grant R305A150456 to the Strategic
Education Research Partnership (SERP) Institute. The
opinions expressed are those of the authors and do not
represent views of the Institute or the U.S. Department of
Education.

References
Adams, D. M., McLaren, B. M., Durkin, K., Mayer, R. E.,
Rittle-Johnson, B., Isotani, S., & Van Velsen, M. (2014).

Using erroneous examples to improve mathematics
learning with a web-based tutoring system. Computers in
Human Behavior, 36, 401-411.
Baroody, A., & Ginsburg, H. (1983). The effects of
instruction on children’s understanding of the equals sign.
The Elementary School Journal, 84, 199–212.
Booth, J. L. (2011). Why can’t students get the concept of
math? Perspectives on Language and Literacy, 37, 31-35.
Booth, J. L., & Koedinger, K. R. (2008). Key
misconceptions in algebraic problem solving. In B. C.
Love, K. McRae, & V. M. Sloutsky (Eds.), Proceedings
of the 30th Annual Cognitive Science Society (pp. 571–
576). Austin, TX: Cognitive Science Society.
Booth, J. L., Koedinger, K. R., & Siegler, R. S. (2007,
August). The effect of prior conceptual knowledge on
procedural performance and learning in algebra. Poster
presented at the 29th annual meeting of the Cognitive
Science Society, Nashville, TN.
Booth, L. R. (1984). Algebra: Children’s strategies and
errors. Windsor, UK: NFER-Nelson.
Brown, D. E. (1992). Using examples and analogies to
remediate misconceptions in physics: Factors influencing
conceptual change. Journal of Research in Science
Teaching, 29, 17–34.
Chi, M. T. H. (2000). Self-explaining expository texts: The
dual processes of generating inferences and repairing
mental models. In Glaser, R. (Ed.), Advances in
instructional psychology (pp. 161–238). Mahwah, NJ:
Lawrence Erlbaum Associates.
Chi, M. T. H., de Leeuw, N., Chiu, M., & Lavancher, C.
(1994).
Eliciting
self-explanations
improves
understanding. Cognitive Science, 18, 439–477.
Chiu, M. H., & Liu, J. W. (2004). Promoting fourth graders’
conceptual change of their understanding of electric
current via multiple analogies. Journal of Research in
Science Teaching, 42, 429–464.
Clark, R. C., & Mayer, R. E. (2003). e-Learning and the
science of instruction: Proven guidelines for consumers
and designers of multimedia learning. San Francisco, CA:
Jossey-Bass.
Common Core State Standards Initiative (2010). Common
Core State Standards for Mathematics. Washington, DC:
National Governors Association Center for Best Practices
and the Council of Chief State School Officers.
Donovan, M. S., & Bransford, J. D. (Eds.). (2005). How
students learn: History, mathematics, and science in the
classroom. Washington, DC: National Academy Press.
Durkin, K. L. & Rittle-Johnson, B. (2009, April).
Comparison of correct and incorrect examples when
learning decimal fractions. Poster presented at the annual
meeting of the Society for Research in Child
Development, Denver, CO.

2691

Kendeou, P., & van den Broek, P. (2005). The effects of
readers’ misconceptions on comprehension of scientific
text. Journal of Educational Psychology, 97, 235–245.
Kieran, C. (1981). Concepts associated with the equality
symbol. Educational Studies in Mathematics, 12, 317–
326.
Knuth, E. J., Stephens, A. C., McNeil, N. M., & Alibali, M.
W. (2006). Does understanding the equal sign matter?
Evidence from solving equations. Journal for Research in
Mathematics Education, 37, 297–312.
Kuchemann, D. (1978). Children’s understanding of
numerical variables. Mathematics in School, 7, 23–26.
Roy, M., & Chi, M. T. H. (2005). Self-explanation in a
multi-media context. In R. Mayer (Ed.), Cambridge
handbook of multimedia learning (pp. 271–286). New
York, NY: Cambridge Press.
Siegler, R. S., & Chen, Z. (2008). Differentiation and
integration: Guiding principles for analyzing cognitive
change. Developmental Science, 11, 433–448.
Sweller, J., & Cooper, G. A. (1985). The use of worked
examples as a substitute for problem solving in learning
algebra. Cognition and Instruction, 2, 59–89.
U.S. Department of Education. (1997). Mathematics Equals
Opportunity. White paper prepared for the U.S. Secretary
of Education, Richard W. Riley.
Vlassis, J. (2004). Making sense of the minus sign or
becoming flexible in ‘negativity.’ Learning and
Instruction, 14, 469–484.
Warren, E. (2003). The role of arithmetic structure in the
transition from arithmetic to algebra. Mathematics
Education Research Journal, 15, 122–137.

2692

