              Causal learning from interventions and dynamics in continuous time
                     Neil R. Bramley1 (neil.bramley@nyu.edu), Ralf Mayrhofer2 (rmayrho@gwdg.de)
                      Tobias Gerstenberg3 (tger@mit.edu), David A. Lagnado4 (d.lagnado@ucl.ac.uk)
                                         1 Department of Psychology, NYU, New York, NY, 10003, USA
                             2 Department   of Psychology, University of Göttingen, Gosslerstr. 14, 37073, Germany
                               3 Department of Brain and Cognitive Sciences, MIT, Cambridge, MA 02139, USA
                                   4 Department of Experimental Psychology, UCL, London, WC1H 0DS, UK
                               Abstract                                                        The learning problem
    Event timing and interventions are important and intertwined               We explore the general problem of how people learn about
    cues to causal structure, yet they have typically been studied         a causal system by interacting with it in continuous time. We
    separately. We bring them together for the first time in an ex-
    periment where participants learn causal structure by perform-         focus on abstract causal “devices” made up of 3–4 compo-
    ing interventions in continuous time. We contrast learning in          nents (cf. Figure 1). For causally related components, we
    acyclic and cyclic devices, with reliable and unreliable cause–        assume each activation of a cause will tend to bring about
    effect delays. We show that successful learners use interven-
    tions to structure and simplify their interactions with the de-        a single subsequent activation of its effect after a paramet-
    vices and that we can capture judgment patterns with heuristics        ric delay (described below). For example, Figure 1a shows a
    based on online construction and testing of a single structural        learner’s interactions with a B ← A → C Fork during which
    hypothesis.
    Keywords: causal learning; intervention; time; causal cycles;          time they perform four interventions. Activations of both B
    structure induction; dynamics.                                         and C succeed the interventions on A but with some variabil-
                                                                           ity in delays.
    In a dynamically unfolding world, using actions to uncover                 We focus on situations where components never sponta-
causal relationships requires good timing. It is hard to tell              neously activate, but where causal relations work stochasti-
whether a new medication is effective if you take it with oth-             cally (e.g., are successful with probability wS ). Any pair of
ers, or just as you start to feel better. Likewise, it is hard             components can be connected in either, neither or both direc-
to tell whether a new law lowers crime if it is introduced                 tions resulting in a hypothesis space S of 64 possible struc-
just after other reforms or before a major election. Such in-              tures for devices made up of three components, and 4096
ferences, having to do with delayed effects and an evolving                for four components. Learners can intervene on the devices
causal background, can be particularly tough in cyclic sys-                by directly activating any component at any moment of their
tems in which feedback loops make prediction difficult even                choosing. Interventions are always successful in that they in-
with complete knowledge (Brehmer, 1992). Thus, for inter-                  stantaneously activate the targeted component. The down-
ventions to be effective tools for unearthing causal structure             stream causal effects of intervened-on components are the
it is important to time and locate them carefully, paying close            same as those of components that were activated by other
attention to the temporal dynamics of surrounding events and               components. Thus, we model the consequences of interven-
the possibility of feedback loops.                                         tions in analogy to the Do(.) operator introduced by Pearl
    Previous work has shown that people make systematic use                (2000), such that interventions provide no information about
of temporal information, taking event order as a strong cue                the causes of the intervened-on component.
to causal order (Bramley, Gerstenberg, & Lagnado, 2014),
and making stronger attributions when putative cause–effect                Choosing interventions
delays are in line with expectations (Buehner & McGregor,                      Seeing the effects of one’s interventions in continuous time
2006) and have low variance across instances (Greville &                   provides rich information for causal inference. On the flip
Buehner, 2010). Recent work has also developed frameworks                  side, there are also no completely independent trials. For in-
for probabilistic causal inference from event timings based                stance, in Figure 1a, the early interventions on C and B might,
on parametric assumptions about cause–effect delays (Bram-                 in principle, be responsible for the observed effects that hap-
ley, Gerstenberg, Mayrhofer, & Lagnado, submitted; Pacer &                 pen shortly after the intervention on A. In general, one can-
Griffiths, 2015).                                                          not rule out the possibility something that happened earlier
    A distinct line of work has shown that people are adept                is still exerting its influence, or that an effect is yet to reveal
at inferring causal structure from interventions — idealized               itself. Fortunately, interventions provide anchor points. We
actions that set variables in a system (e.g., Bramley, Dayan,              know that events due to interventions weren’t caused by any-
Griffiths, & Lagnado, 2017; Coenen, Rehder, & Gureckis,                    thing else, and that these events only affect the future but not
2015). This work has not explored the role of temporal in-                 the past (Lagnado & Sloman, 2004). This means that by in-
formation however. While researchers have speculated about                 tervening, learners can recreate some of the advantages that
the close relationship between temporal and interventional in-             come with a discrete trial structure. For example, by wait-
ference (e.g., Lagnado & Sloman, 2004), our paper is the first             ing long enough between interventions to be confident prior
to explore interventional causal learning in continuous time.              effects have dissipated, an otherwise confusing event stream
                                                                       150

a) Spread out interventions
                                                                                       Sloman, Love, & Ahn, 1998). While there are ways of adapt-
          A
                                 A
                                 A                      +               +              ing the causal Bayes net formalism to capture cycles (Re-
                         Component
                                                                                       hder, 2016), these generally simplify the problem to influ-
                   B
                  Time
                                 BB                +
                                                                                       ences between fixed time steps (e.g. Rottman & Keil, 2012),
   Time   C
          True device
                                 C
                                 C        +                                            or just to the long-run equilibrium distribution (e.g. Lauritzen
                                      0       10       20          30       40
                                                            Time                       & Richardson, 2002). However, by focusing on continuous
b) Clustered interventions                                                             time and developing a representation capable of modeling
                                                                                       causal dynamics, we are able to directly compare learning in
          A
                                 A
                                 A
                                                       + +
                         Component
                                                                                       acyclic and cyclic causal systems.
                   B
                  Time
                                 B
                                 B                       +                                Dynamic systems can be hard to predict even with per-
   Time   C
          True device
                                 C
                                 C                     +                               fect knowledge. Positive feedback loops can lead to sensitive
                                      0       10       20          30       40
                                                            Time                       dependence on initial conditions with very different behav-
c) Interventions on structure with feedback loop
                                                                                       ior resulting from small perturbations in starting conditions
                                 A
                                 A
                                          +                                            (e.g., Gleick, 1997). Figure 1c gives an example of interven-
                         Component
          A
                 B
                  Time
                                 BB                            +                       tions on a cyclic causal system (assuming that the connections
          C                      C
                                 C                                      +              work 90% of the time). Interventions initialize looping be-
          True device
                  Time
                                      0       10       20          30       40
                                                                                       havior because of the bidirectional relationship A ↔ B (e.g.,
                                                            Time
                                                                                       A → B → A → B . . .) leading to many subsequent activations
Figure 1: Examples of using real-time interventions to infer causal                    of both the loop components and the output component C,
structure. Left: True generative causal model with subplots showing                    continuing until either the A → B or B → A connection fails.
delay distributions. Right: Timelines showing an active learners’ in-
teractions with each system with a row for each component A (top),                     Based on simply looking at the timeline, it seems likely that
B (middle) and C (bottom), and white circles indicating their acti-                    it will be easier to identify which components are either di-
vations over 45 seconds (x-axis). “+” symbol and incoming hand                         rectly involved in cycles, or outputs from cyclic components
icon indicate interventions. Dashed gray lines indicate the actual
cause–effect relationships.                                                            (due to their recurrent activations), but harder to identify the
                                                                                       exact causal relationships (e.g. whether it is A or C that causes
becomes more palatable and informative about the underly-                              B in this example since both tend to recur shortly before B).
ing structure. Figure 1b gives an example of interventions
                                                                                       Normative inference
that are not well chosen. The learner performs four inter-
ventions in the same locations as Figure 1a but does so in                                As a benchmark, we developed a Bayesian n     model of causal o
                                                                                                                                           (1)      (n)
close succession. It is hard to attribute causal responsibility                        structure inference. We consider the data dτ dX , . . . , dX
for these activations, since there are so many similarly plausi-                       to be made up of all activations (with events indexed in
ble candidates. Consequentially, this data is considerably less                        chronological order and X indicating the activated com-
informative.                                                                           ponent)
                                                                                       n             conditioned
                                                                                                           o     upon the set of interventions iτ =
   In discrete-trial interventional learning, participants exhibit                        (1)          (m)
                                                                                         iX , . . . , iX . Both dτ and iτ are restricted to the interval
a positive testing strategy — they prefer to intervene on root                         between the beginning of the clip and time τ, which we as-
variables that bring about many effects (Coenen et al., 2015).                         sume to be the moment at which the learner makes the infer-
While often not leading to the most globally informative                               ence. For instance, one might interact with a causal device for
choice, a positive testing strategy is an effective way of as-                         5000 ms, performing interventions on components A and B at
sessing the adequacy of one’s current working hypothesis,                                                                              (1)         (2)
                                                                                       100 ms and 1200 ms respectively: i5000 = {iA = 100, iB =
making it a manifestation of confirmatory testing (Nicker-                                                                                         (1)
son, 1998). Many other components will be affected if one’s                            1200}, and observing two activations of C: d5000 = {dC =
                                                                                               (2)
hypothesis is right, and few if it is wrong. Repeated posi-                            1500, dC = 2800}.
tive testing might be more justifiable in the continuous time                            Normative Bayesian structure inference involves updat-
context because cause–effect delays may play out differently                           ing a prior over structure hypotheses P(S) with the likeli-
each time, and potential temporal reversals between variable                           hood p(dτ |S; iτ , w) to get a posterior belief over structures
activations will help to rule out candidate structures (Bram-                          P(S|dτ ; iτ , w) given the set of parameters w:1
ley et al., 2014). For example, in Figure 1a the second in-
tervention on A leads to B and C occurring in reversed order,                                        P(S|dτ ; iτ , w) ∝ p(dτ |S; iτ , w) · P(S)       (1)
allowing the learner to rule out a A → B → C Chain structure.
                                                                                          An immediate issue with calculating the likelihood of an
Causal cycles                                                                          observed set of activations given a candidate model is that
  The vast majority of causal learning studies have focused                            there are likely to be multiple potential paths of actual causa-
on acyclic causal systems in which causal influences flow                              tion that could have produced the data (Halpern, 2016), each
only in one direction, never revisiting the same component.                                1 In this specific case, we assume the parameters (i.e., causal
However, many natural processes are cyclic and people fre-                             strength wS , expected length of delays µ, and delay variability α)
quently report cyclic relationships when allowed to do so (e.g.                        to be known which is consistent with the setup of the experiment.
                                                                                 151

           a)             Acyclic 1                         Acyclic 2                   Acyclic 3                        Acyclic 4                     Acyclic 5                      Acyclic 6
                                A                               A                              A                        A              B               A              B               A              B
                                                                                                                                                                                                                                          2.15
                                            Ints: 5.1                       Ints: 4.8                       Ints: 5                        Ints: 5.5                      Ints: 5.3                      Ints: 5.6
                                                                                                                                                                                                                     N interventions
                                            Acc: 92%                        Acc: 87%                       Acc: 73%                        Acc: 91%                       Acc: 77%                       Acc: 73%
                                                                                                                                                                                                                                          1.79
         Reliable
                         C              B               C               B               C              B                D              C               D              C               D              C
                                                                                                                                                                                                                                          1.42
                             Cyclic 1                        Cyclic 2                       Cyclic 3                        Cyclic 4                       Cyclic 5                       Cyclic 6
                                A                               A                              A                        A              B               A              B               A              B                                    1.06
                                            Ints: 3.2                       Ints: 4.3                      Ints: 4.5                       Ints: 3.8                      Ints: 4.2                      Ints: 3.7
                                            Acc: 63%                        Acc: 77%                       Acc: 60%                        Acc: 78%                       Acc: 67%                       Acc: 62%                          0.7
                         C              B               C               B               C              B                D              C               D              C               D              C
           b)             Acyclic 1                         Acyclic 2                   Acyclic 3                        Acyclic 4                     Acyclic 5                          Acyclic 6
                                A                               A                              A                        A              B               A              B               A              B
                                                                                                                                                                                                                                    100%
                                            Ints: 5.5                       Ints: 5.5                      Ints: 5.3                       Ints: 5.5                      Ints: 5.5                      Ints: 5.8
                                                                                                                                                                                                                     Proportion correct
                                            Acc: 78%                        Acc: 70%                       Acc: 58%                        Acc: 86%                       Acc: 72%                       Acc: 50%
         Unreliable
                                                                                                                                                                                                                                          75%
                         C              B               C               B               C              B                D              C               D              C               D              C
                                                                                                                                                                                                                                          50%
                             Cyclic 1                        Cyclic 2                       Cyclic 3                        Cyclic 4                       Cyclic 5                       Cyclic 6
                                A                               A                              A                        A              B               A              B               A              B                                    25%
                                            Ints: 3.8                       Ints: 4.5                      Ints: 4.5                       Ints: 4.1                      Ints: 4.7                      Ints: 4.5
                                            Acc: 50%                        Acc: 68%                       Acc: 47%                        Acc: 64%                       Acc: 55%                       Acc: 52%                          0%
                         C              B               C               B               C              B                D              C               D              C               D              C
Figure 2: Devices tested and results from experiment in a) reliable and b) unreliable delay conditions. Node shading: Intervention choice
prevalence by component. Edge shading: accuracy. Note: Ints = average number of interventions performed; Acc = mean accuracy.
of which implying a different likelihood. For example, if the                                                                (see Figure 2). Half of the devices were acyclic (top; no feed-
true structure is a A → C ← B Collider, the data above might                                                                 back loops) and half were cyclic (bottom; contained a feed-
be produced in two ways. A could have caused the first acti-                                                                 back loop). Participants were able to activate any of the com-
                               (1)     (1) (1)     (2)                                                                       ponents by clicking on them. We were interested in how par-
vation of C and B the later (iA → dC , iB → dC ). Alterna-
tively, A could have caused the later activation of C and B the                                                              ticipants chose where to intervene and when. We examined
          (1)     (2) (1)
earlier (iA → dC , iB → dC ).
                              (1)                                                                                            two delay conditions between subjects, one in which the true
   However, as there can only be one true path of actual cau-                                                                cause–effect delays were reliable (Gamma distributed with
sation in the set of possible paths Zs , we can sum over these                                                               α = 200, M ± SD 1.5 ± 0.1 seconds) and one where they were
to get the likelihood of the data given a candidate model s ∈ S:                                                             unreliable (α = 5, M ± SD 1.5 ± 0.7 seconds). Following
                                                                                                                             Greville and Buehner (2010), we expected that performance
                                                                                                                             would be better when causal delays were reliable. We also
                      p(dτ |s; iτ , w) =                ∑     p(dτ |z0 ; iτ , w)                             (2)
                                                   z ∈Zs0                                                                    predicted that complex dynamics would lead to worse perfor-
                                                                                                                             mance when the true structure was cyclic, and that success-
   We assume that the actual causal delays (in Zs ) are Gamma                                                                ful participants would spread their interventions widely over
distributed (see also Bramley et al., submitted) with a known                                                                time, thus minimizing the ambiguity of resulting patterns of
expected duration µ and shape α (i.e., variability). The likeli-                                                             effects.
hood of the data given a specific path z0 , then, is the product
                                                                                                                             Methods
of the (Gamma) likelihoods of the observed delays and causal
strength wS combined with the likelihoods of (non-)events,                                                                   Participants Forty participants (14 female, aged 32 ± 9.0)
the occurrence of which failed either due to the 1 − wS causal                                                               were recruited from Amazon Mechanical Turk (yielding 20
failure rate or due to the effect potentially occurring after τ                                                              subjects in each delay-reliability condition) and were paid
(i.e., some time in the future).                                                                                             between $0.50 and $3.20 ($2.06 ± 0.39) depending on per-
   With these ingredients the posterior belief over causal                                                                   formance (see Methods section). The task took around 20
structure hypotheses can be determined. However, it is only                                                                  minutes.
feasible to enumerate all possible paths of actual causation for                                                             Materials and procedure Each device was represented with
a sufficiently small number of events. While for a large num-                                                                a circle for each component and boxes marking the locations
ber of events the calculations become intractable, we were                                                                   of the potential connections (see Figure 3a).3 Trials lasted for
able to compute the posteriors in the described manner for                                                                   45 seconds during which components activated if clicked on
the data from the current experiment, resorting only in rare                                                                 or if caused by the activation of another component, with de-
cases to an approximation.2                                                                                                  lay and probability governed by the true underlying network
                                                                                                                             (Figure 3b). Causal relationships worked 90% of the time
                                    Experiment                                                                               (i.e., causal strength wS = 0.9) and there were no spontaneous
  Participants’ task was to discover the causal connections                                                                  activations. Activated components turned yellow for 200ms,
between the components of several devices in limited time                                                                    and intervened-on components were additionally marked by
                                                                                                                             a “+” symbol. Initially, all components were inactive and no
   2 Where necessary, we ruled out paths that implied an implausibly
high number of failed connections, or extreme cause–effect delays,                                                              3 Try the task https://www.ucl.ac.uk/lagnado-lab/el/it
until the number of possible paths fell below 100, 000.                                                                      or watch a trial https://www.ucl.ac.uk/lagnado-lab/el/itv.
                                                                                                                       152

  a) Intervening                       b) Example timeline               c) Making judgments                   d) Getting feedback
     Time
     remaining : 45s
                     +   Interventions
                         remaining : 6
                                                                            Time
                                                                            remaining : 25s
                                                                                                 Interventions
                                                                                                 remaining : 5
                                                                                                                  Time
                                                                                                                  remaining : 0s
                                                                                                                                   You got 1 out
                                                                                                                                   of 3 correct
                                             +
                                                              e
                                                           Tim
Figure 3: Experimental procedure. a) Up to 6 interventions could be performed by clicking on the components during the 45 second trial. b)
This would lead to subsequent activations determined by causal connections and delays in the true model. c) Participants marked their beliefs
about the structure during the trials by clicking on the edges. d) At the end of each trial they received feedback. Broad gray arrows: ground
truth, Green = correct, Red = incorrect.
connections were marked between them.                                       guishing looping from output components.
   Prior to the inference tasks, participants were trained on the              Ideal Bayesian inference based on the evidence generated
delays in their condition and how to register structure judg-               by participants predicts a different pattern. While reliable de-
ments through interaction with an an example device. They                   lays allow greater accuracy than unreliable ones, F(1, 38) =
then had to correctly answer comprehension check questions                  24.3, p < .001, there is no predicted difference in accuracy
and complete a practice problem, before facing the 12 test                  between acyclic and cyclic devices, F(1, 38) = 0.43, p = .5.
devices in random order with randomly orientated and unla-                  In fact, posterior uncertainty over all possible models, mea-
beled components.                                                           sured by Shannon entropy, was generally lower for evidence
   In the test phase, participants could perform up to 6 in-                generated by a cyclic .74 ± 1.26 than an acyclic 1.95 ± 1.29
terventions on each trial and register/update their judgments               devices, F(1, 38) = 109, p < .001.
about the causal structure as often as they liked until the 45              Timing of interventions We hypothesized that spacing in-
seconds for a device ran out (for details see Figure 3). At the             terventions out in time would be important for successful
end of each trial, they were given feedback showing the true                learning. Participants waited 7.3 ± 2.8 seconds between in-
relationships and which of them they had correctly identified.              terventions on average. In a regression including delay con-
To incentivize proper judgments, bonuses were paid based on                 dition and total number of interventions as covariates, leav-
connections participants had registered at a randomly chosen                ing longer intervals between interventions was positively
point during each trial.                                                    associated with accuracy, F(1, 36) = 14.0, β = 0.04, η2p =
Results                                                                     .26, p = .001, with no interaction with condition. The
                                                                            variability of these gaps — measured by their coefficient
   We analyze participants’ judgments by first comparing
                                                                            of variation CV = σµ — was also inversely related to ac-
their accuracy by delay-reliability condition (between sub-
jects: reliable vs. unreliable) and device type (within subject:            curacy, F(1, 36) = 7.9, β = −0.5, η2p = .18, p = .008 and
acyclic vs. cyclic). We then analyze the timing and spacing                 this effect was stronger in the unreliable delay condition,
of participants’ interventions and how these relate to the evi-             F(1, 35) = 4.5, η2p = .11, p = .04. We also assessed the
dence and judgments.                                                        intervals participants left after the most recently preceding
Accuracy Participants updated and confirmed their judg-                     event (whether this was an intervention or an effect) be-
ment about the structure M±SD 1.6 ± 1.2 times per trial                     fore performing their next intervention. Again larger inter-
on average. Judgment time was not significantly related                     vals, F(1, 36) = 7.7, β = 0.06, η2p = .18, p = .008, and less
to accuracy, but within trials, final judgments were slightly               variation, β = −.25, F(1, 36) = 5.0, η2p = .12, p = .03, was
more accurate than initial judgments, with participants cor-                associated with accuracy with neither measure interacting
rectly identifying 69% ± 30% (chance performance would be                   with delay condition. Both larger intervals between interven-
25%) compared to 65% ± 28% of the connections, t(479) =                     tions, and between interventions and the most recently pre-
5.2, p < .001 (remember that bonuses incentivised making                    ceding effect were also associated with lower posterior en-
judgments early). Only 4% of judgment updates decreased                     tropy, with β = 0.05, F(1, 36) = 9.9, η2p = .22, p = 0.003 and
the number of connections, 24% resulting in the same num-                   β = 0.09, F(1, 36) = 8.1, η2p = .18, p = 0.007, respectively.
ber as before, and 72% increasing the number of connections.                However, there was no evidence for a relationship between
   Focusing on final judgments, participants correctly identi-              entropy and the variability of either interval type.
fied [reliable,acyclic]: 82% ± 29%, [reliable,cyclic]: 68% ±                Positive testing We found evidence of a preference for posi-
28%, [unreliable,cyclic]: 69% ± 29%, [unreliable,cyclic]:                   tive testing, with participants performing 1.2 ± 0.5 times as
56% ± 29% of the connections. A repeated measures anal-                     many interventions per root component than per non-root
ysis revealed a significant effect of delay-reliability condi-              component t(59) = 3.9, p < .001. This preference was as-
tion, F(1, 38) = 4.6, p = .04, and cyclicity, F(1, 38) = 39, p <            sociated with higher accuracy after accounting for condition,
.001, but no interaction, with unreliable delays and cyclic                 F(1, 37) = 21, η2p = 0.37, p < .001, and did not interact with
structures associated with lower accuracy. Figure 2 shows                   condition. Degree of root preference, however, was not sig-
that participants found the Cyclic 3, 5 and 6 structures hard-              nificantly related to posterior uncertainty from the perspective
est to identify on average, struggling in particular with distin-           of an ideal Bayesian learner.
                                                                       153

 Adaptation to cycles While participants performed fewer                    tion in dτ ). If the currently held model hypothesis b(t−1)
 interventions on cyclic (4.1 ± 1.1) compared to acyclic (5.4 ±             does not contain a respective edge, b(t−1) is augmented
 0.7) devices, t(39) = 8.7, p < .001 (see Figure 2), they still             with an edge to make b(t) . Figure 4a gives an example of
 experienced far more effects in the cyclic systems (29.3 ± 10)             this. Starting from b(t−1) with a single D → B connection,
 compared to the acyclic ones (4.7 ± 1.1), t(39) = 15.5, p <                the heuristic connects A to B upon observing B’s activation
 .001. This was due to the reciprocal relationships sustaining              straight after activating A, and then B to C when C activates
 activations until one of the links failed. Thus while there was            shortly after.
 normatively more evidence available in the cyclic trials — as
                                                                        2. Time Sensitive (TS) TS is like OO but with sensitivity to
 reflected by the generally lower posterior uncertainty — the
                                                                            the expected cause–effect delays. It attributes activations
 large number of events resulted in more ambiguous evidence,
                                                                            to the (previous) event such that the respective delay would
 with many candidate causes per effect and a large number of
                                                                            be most likely given the knowledge of the true causal de-
 potential actual causal pathways.
                                                                            lay distribution, and augments b(t−1) with an edge, if there
 Summary Participants were better at identifying causal re-                 is none yet, to form b(t) . In the example (Figure 4b), C’s
 lations from interventions when delays were reliable and the               activation time is most consistent with C being caused by
 true structure was acyclic. Meanwhile, ideal learner accuracy              the intervention on A, thus the model adds an A → C con-
 was affected by reliability by not cyclicity. Successful par-              nection, rather than a B → C connection, going into b(t+1) .
 ticipants spread their interventions out more in time, waited
 longer after previous events, distributed them more evenly             3. Structure + Time Sensitive (STS) STS is like TS, but it
 and favored root components. Participants frequently updated               first checks if there is already an adequate explanation in
 their models by adding additional connections but rarely re-               the current model b(t−1) . Concretely, it compares the like-
 moved connections.                                                         lihood of the most likely explanation that is already a cause
                                                                            in b(t−1) to the most likely explanation overall (i.e., the one
              Modeling heuristic inferences                                 selected by TS). Where these differ, it only adds an edge if
    Participants’ deviations from the prediction of an ideal                the respective delay is substantially more likely than the
 Bayesian learner suggests that they relied on simpler learn-               delay implied by the best existing explanation in b(t−1) ,
 ing strategies. In this section we compare judgment patterns               where we assume that “substantially more likely” means
 to several heuristic models inspired by work on order–driven               a likelihood ratio > 20 1 . Figure 4c gives an example. Un-
 (e.g., Bramley et al., 2014) and incremental causal structure              like TS, this heuristic does not add an A → C connection
 learning (e.g., Bonawitz, Denison, Gopnik, & Griffiths, 2014;              going into b(t+1) because C’s activation can be explained
 Bramley et al., 2017).                                                     well enough by the existing connection D → C. While an
                                                                             (2)     (1)                                        (1)      (1)
    Several papers have proposed that human causal learn-                   iA → dB delay is slightly more probable than a iD → dB
 ing is based on the adaptation of a single global hypothe-                 delay, the difference is not substantial enough to warrant
 sis (Bonawitz et al., 2014), which might be achieved incre-                the addition of another connection.
 mentally through making local changes as data is observed
 (Bramley et al., 2017). This seems particularly applicable in a         Model comparison procedure
 continuous-time context, where normative inference is tough                To compare the heuristics to participants’ judgments, we
 and the evidence arrives continuously. People may learn lo-             simulated belief trajectories bs for all the heuristics based on
 cally, ignoring dependence on beliefs about surrounding rela-           the evidence generated by all participants, starting each trial
 tionships (e.g. Fernbach & Sloman, 2009), or use their current          with an unconnected model at t = 0. For TS and STS, we as-
 model as a basis, comparing observations against predictions,           sumed knowledge of true µ, α and wS as participants had been
 only adding new connections to explain events that cannot               trained on these during the instructions. We predicted partici-
 easily be accommodated by their existing model (Bramley et              pants’ judgments based on what the simulated belief trajecto-
 al., 2017).                                                             ries looked like at judgment time. We then assessed their ac-
    The idea that learners might construct their causal hypothe-         curacy in the task (e.g. the proportion of connections marked
 ses incrementally can be combined with different degrees of             correctly) and accordance rate (the proportion of connections
 sensitivity to timing as well as the predictions of their current       marked the same as the matched participant’s). Addition-
 structure hypothesis. This suggests several potential heuris-           ally, we also compared participants to a Random baseline that
 tics that adapt a single model belief b as events are experi-           marked a new random causal structure on every judgment,
 enced. The result in each case is a single structural belief that       and an Ideal learner that always selects the max P(M|dτ ; iτ , w)
 evolves as events occur (we write b = {b(0) , . . . , b(n) }, where     according to the Bayesian inference model.
 the sequence of belief indices correspond to the event indices          Modeling results
 in dτ ):
                                                                            The results of these simulations are reported in Table 1.
1. Order Only (OO) Heuristic OO attributes each new effect               Overall, STS was the most closely accordant with participants
    to the most recently preceding event at any different com-           but individually participants were almost evenly split between
    ponent (either the most recent intervention in iτ or activa-         STS and OO, both for all judgments and restricted to the final
                                                                     154

                                                                                 bounded learning system.
            A                      +                                                In light of this, we considered several heuristic learning
                                                                                 models. Participants’ judgments were best explained by as-
    Component
            B
                                                                                 suming that they added connections to a single evolving can-
            C
                                                                                 didate hypothesis as they observed events. Some subjects ap-
                                                                                 peared to rely on a simple order heuristic (OO) whereas oth-
            D                  +                                                 ers displayed sensitivity to the delays between events (TS)
                                                                                 and whether events were predicted by existing structure be-
                                        Time                                     liefs (STS). Participants rarely removed connections during
                           A       B           A   B          A    B
                                                                                 the trials. Given more time to learn, however, it seems likely
   a) Order only                                                                 that they would also sometimes prune connections from their
   (OO)                    D       C           D   C          D    C             models — e.g., when events predicted by their current model
                           A       B           A   B          A    B
                                                                                 repeatedly fail to occur. In general, positive testing of one’s
   b) Time sensitive                                                             current hypothesis is an effective way for learners that are
   (TS)                    D       C           D   C          D    C             limited to a single global hypothesis to test its predictions
                           A       B           A   B          A    B
                                                                                 against reality, and tune, refine, or or even abandon it, if nec-
   c) Structure + time                                                           essary.
   sensitive (STS)         D       C           D   C          D    C                In sum, rather than grappling with an unmanageable space
                                                                                 of possible structures and causal paths, participants seem to
                                                                                 naturally follow Yogi Berra’s advice: “You don’t have to
Figure 4: Example where proposed heuristics’ predictions diverge.                swing hard [to hit a home run]. If you got the timing, it’ll
b(t−1) : the learner’s belief at the start of the period depicted in the         go.”
                              (t)
timeline. After observing dB the models update b(t−1) to form b(t) .             Acknowledgments TG was supported by the Center for Brains, Minds
                          (t+1)                                                  & Machines (CBMM), funded by NSF STC award CCF-1231216. RM
Then after observing     dC ,they update to form        b(t+1) .
                                                         Blue lines
                                                                                 is supported by a DFG grant (Ma 6545/1-2) as part of SPP 1516 “New
indicate probability density for cause–effect delays starting from
each event, used to determine the most likely cause of each event                Frameworks of Rationality”.
(TS), and whether it is sufficiently more likely than any existing                                               References
causes (STS).
                                                                                 Bonawitz, E. B., Denison, S., Gopnik, A., & Griffiths, T. L. (2014). Win-stay,
judgments. Participants accuracy (0.65 ± 0.19) was closest to                       lose-sample: A simple sequential algorithm for approximating Bayesian infer-
that of the simplest heuristic OO. Mean participant accuracy                        ence. Cognitive Psychology, 74, 35–65.
                                                                                 Bramley, N. R., Dayan, P., Griffiths, T. L., & Lagnado, D. A. (2017). Formalizing
by trial was correlated with that of all three heuristics rOO =                     Neurath’s ship: Approximate algorithms for online causal learning. Psycho-
.83, rTS = 0.92, rSTS = 0.61, but negatively correlated with                        logical Review, 123(3), 301–338.
                                                                                 Bramley, N. R., Gerstenberg, T., & Lagnado, D. A. (2014). The order of things:
Ideal judgments rIdeal = −.45. Like participants but unlike the                     Inferring causal structure from temporal patterns. In Proceedings of the 36th
Ideal learner, all three heuristics were less accurate at cyclic                    Annual Meeting of the Cognitive Science Society (pp. 236–242).
                                                                                 Bramley, N. R., Gerstenberg, T., Mayrhofer, R., & Lagnado, D. A. (submitted).
than acyclic structures OO: t(39) = 9.5, p < .001, TS:t(39) =                       The role of time in causal learning.
10.6, p < .001, STS: t(39) = 4.5, p < .001.                                      Brehmer, B. (1992). Dynamic decision making: Human control of complex
                                                                                    systems. Acta Psychologica, 81(3), 211–241.
                       General Discussion                                        Buehner, M. J., & McGregor, S. (2006). Temporal delays can facilitate causal
                                                                                    attribution: Towards a general timeframe bias in causal induction. Thinking &
   In our experiment, people used interventions to learn about                      Reasoning, 12(4), 353–378.
the causal structure of devices whose dynamics unfolded in                       Coenen, A., Rehder, R., & Gureckis, T. M. (2015). Strategies to intervene on
                                                                                    causal systems are adaptively selected. Cognitive Psychology, 79, 102–133.
continuous time. As we predicted, cyclic structures were                         Fernbach, P. M., & Sloman, S. A. (2009). Causal learning with local computa-
harder to learn than acyclic ones even though this was not                          tions. Journal of Experimental Psychology: Learning, Memory & Cognition,
                                                                                    35(3), 678.
reflected in the evidence available for an ideal learner, sug-                   Gleick, J. (1997). Chaos: Making a new science. Open Road Media.
gesting that the evidence produced by cyclic devices, involv-                    Greville, W. J., & Buehner, M. J. (2010). Temporal predictability facilitates causal
                                                                                    learning. Journal of Experimental Psychology: General, 139(4), 756–771.
ing many activations and potential causal paths, was harder                      Halpern, J. Y. (2016). Actual causality. MIT Press.
for human learners to process. We found that the observed                        Lagnado, D. A., & Sloman, S. A. (2004). The advantage of timely interven-
                                                                                    tion. Journal of Experimental Psychology: Learning, Memory & Cognition,
determinants of successful learning – equal spacing of inter-                       30, 856–876.
ventions in time and a preference to intervene on root vari-                     Lauritzen, S. L., & Richardson, T. S. (2002). Chain graph models and their causal
ables — made structure inference easier for a heuristic and                         interpretations. Journal of the Royal Statistical Society, 64(3), 321–348.
                                                                                 Nickerson, R. S. (1998). Confirmation bias: A ubiquitous phenomenon in many
                       Table 1: Model comparison                                    guises. Review of General Psychology, 2(2), 175.
                                                                                 Pacer, M. D., & Griffiths, T. L. (2015). Upsetting the contingency table: Causal
 Model          Accuracy (%)           Accordance (%)    N best (/40)               induction over sequences of point events. In Proceedings of the 37th Annual
                All     Final          All    Final      All      Final             Meeting of the Cognitive Science Society.
                                                                                 Pearl, J. (2000). Causality. New York: Cambridge University Press (2nd edition).
 Random 25.0          25.0     25.0    25.0       0        0                     Rehder, R. (2016). Reasoning with causal cycles. Cognitive Science, to appear.
 OO         66.2      64.7     67.2    64.9       16       17                    Rottman, B. M., & Keil, F. C. (2012). Causal structure learning over time: obser-
 TS         79.7      78.9     67.3    65.5       4        5                        vations and interventions. Cognitive psychology, 64(1), 93–125.
 STS        87.9      90.9     69.3    69.2       15       13                    Sloman, S. A., Love, B. C., & Ahn, W.-K. (1998). Feature centrality and concep-
                                                                                    tual coherence. Cognitive Science, 22(2), 189–228.
 Ideal      91.0      95.3     66.1    68.9       5        5
Note: “N Best” = the highest according model for each participant.
                                                                           155

