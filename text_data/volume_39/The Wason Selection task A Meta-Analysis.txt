                                  The Wason Selection Task: A Meta-Analysis
                                        Marco Ragni (ragni@informatik.uni-freiburg.de)
                      Cognitive Computation Lab, University of Freiburg, 79110 Freiburg, Germany
                                            Ilir Kola (kola@informatik.uni-freiburg.de)
                           Cognitive Computation Lab, University of Freiburg, 79110 Freiburg, Germany
                                            P. N. Johnson-Laird (phil@princeton.edu)
            Princeton University, Princeton NJ 08540 USA           and New York University, New York, NY 10003, USA
                              Abstract
   In Wason’s selection task, participants select whichever of
   four cards could provide evidence about the truth or falsity of
   a conditional rule. As our meta-analysis of hundreds of ex-
   periments corroborates, participants tend to overlook one of
   the cards that could falsify the rule. 15 distinct theories aim
   to explain this phenomenon and others, but many of them
   presuppose that cards are selected independently of one an-
   other. We show that this assumption is false: Shannon’s en-
   tropy for selections is reliably redundant in comparison with
   those of 10,000 simulated experiments using the same four
   individual probabilities for each real experiment. This result          Figure 1. The four cards in Wason’s selection task. Each
   rules out those theories presupposing independent selections.         has a number on one side and a letter on the other side. The
   Of the remaining theories, only two predict the frequencies            participants’ task is to select just those cards that, if turned
   of selections, one (due to Johnson-Laird & Wason, 1970a)                 over, would show whether or not the rule shown above
   provides a better fit to the experimental data than the other          holds for the four cards. The letters p, q, etc. are added for
   (due to Klauer et al., 2007). We discuss the implications of
                                                                           illustrative purposes as the rule is of the sort, if p then q.
   these results.
   Keywords: Conditional reasoning; Entropy; Falsity, Selec-             with “every” in place of “if” (Wason & Johnson-Laird,
   tion task; Mental models.                                             1969; Wason & Shapiro, 1971), cards with all the infor-
                                                                         mation on one side but partly masked, choices of just two
                          Introduction                                   cards (e.g., Johnson-Laird & Wason, 1970b), or choices of
   Human beings are able to evaluate whether assertions are              multiple cards, with repetitions of one or more cards (e.g.,
true, and to select evidence relevant to such evaluations.               Oaksford & Chater, 1994). But, two main versions elicited
The late Peter Wason (1968) carried out a paradigmatic                   better performance than abstract rules, such as the one in
study to test whether naive individuals grasped the rele-                Fig. 1. One version used everyday rules, such as one about
vance of falsification. In his original “selection” task, the            destinations and modes of transport (Wason & Shapiro,
experimenter explains to the participants that there is a pack           1971). The other version switched the task around so that
of cards in which each card has a letter on one side and a               participants had to select those cards representing individu-
number on the other side. Four cards are taken at random                 als who might be violating a deontic rule (e.g., Griggs &
from the pack, and placed in front of the participant (see               Cox, 1982), such as:
Fig. 1). The experimenter then presents the rule:                            If a person is drinking beer, then the person must be
   If there is a D on one side of a card, then there is a 3 on               over 19 years of age.
   the other side.                                                       The efficacy of some deontic rules, such as one about the
The participants’ task is to select just those cards that, if            amount of postage on letters (Johnson-Laird, Legrenzi, &
turned over, would show whether or not the rule is true or               Legrenzi, 1972), depended on the participants’ familiarity
false of the four cards. The task is a demonstration, not an             with them, but not all do so.
experiment, because it has no independent variable.                        As the number of experimental studies grew, so too did
   Participants tend to select the D card alone, or the D and            the number of theories. By our reckoning, there are at least
3 cards, but rarely the D and 7 cards. Yet, if the 7 has D on            15 distinct theories of the selection task including ones
its other side, the rule would be false. This failure to falsify         based on the meaning of conditionals, on formal rules of
was shocking. Perhaps as a consequence more than 300                     inference for them, on heuristics such as “matching” in
experiments investigating the task have been published                   which participants merely select those cards referred to in
over the last 50 years.                                                  the rule (Evans, 1977), on content-specific rules of infer-
   In order to try to understand performance, psychologists              ence, and on the probabilities with which the various items
developed various versions of the task. They explored rules              on the cards occur in reality (Oaksford & Chater, 1994).
of different sorts, such as disjunctions and rules framed                Given that the selection task has been under investigation
                                                                     980

for half a century, the existence of 15 theories about it is       1985; Oaksford & Chater, 1994). Correlations, however,
embarrassing for cognitive science. Our aim in what fol-           are only among pairs of cards in selections. A better as-
lows is therefore to describe meta-analyses of the experi-         sessment would take into account each selection as a whole
ments that aimed to eliminate as many theories as possible.
                                                                     Table 2. The percentages of each of the four canonical se-
                       Meta-analyses                                         lections for the three sorts of selection task
The reliability of the results
                                                                                                  The canonical selections
   We searched the literature for experiments on the selec-
                                                                                             p         pq         pqq       pq
tion task with the proviso that they used a conditional rule
                                                                          Abstract          36         39          5        19
of the sort: if p then q, and that they reported at least the             Everyday          23         37          11       29
frequencies of the four canonical selections of p, pq,                     Deontic          13         19          4        64
pqq, and pq, which the early studies had reported. Hence-
forth, we abbreviate selections in the preceding way, stating      and all the selections made in an experiment. We therefore
which of the 4 cards they included, e.g., pq denotes a selec-      introduced a new procedure that combines Shannon’s
tion of the p and q cards (see Fig. 1). We divided the result-     measure of entropy (or informativeness) with the computer
ing experiments into three categories according to the na-         simulation of thousands of experiments. The underlying
ture of the rule they used: abstract, everyday, or deontic.        intuition is straightforward. Suppose the selections in an
We also classified them according to whether they reported         experiment are more redundant – more predictable – than a
the frequencies of only the 4 canonical selections and a           prediction made solely from the frequencies of selecting
category of “other” selections, or the frequencies of all 16       each of the four individual cards in the experiment. It fol-
possible selections. The studies can be found at                   lows that the cards in selections are, not independent of one
http://www.cc.uni-freiburg.de/data.                                another, but interdependent. And some aspect in the pro-
   Because the first studies were carried out half century         cess of selecting cards yields the redundancy.
ago and subsequent ones in many countries, their results               The first step in our procedure is to compute the amount
might be too heterogeneous for an informative test of the          of information in the selections in an experiment, i.e., the
theories. We assessed the overall homogeneity of the re-           difficulty of predicting them. We use Shannon’s measure of
sults for the three categories of task from the reliability of     entropy:
the rank orders of the frequencies of their canonical selec-
                                                                                            H = - Σ Pi log2Pi
tions. Table 1 reports Kendall’s coefficient of concordance,
W, which ranges from 0 for no consensus to 1 for perfect           for the set of selections, where Pi denotes the probability of
consensus, for the three categories of task. The results show      the i-th selection, and log2 denotes a logarithm to the base
a reasonable and robust consensus over the experiments.            2. In general, the greater the number of different selections,
Table 2 presents the overall percentages of each of the four       and the more evenly distributed the frequencies over them,
canonical selections for the three sorts of selection task. It     so the value of H increases, and it is harder to predict the
shows why the deontic task yielded a greater concordance,          selections. If participants chose each card independently of
W: the majority of participants selected cards denoting po-        the others, the value of H for the experiment would not
tential violations of the rule.                                    differ reliably from its value for selections derived from
                                                                   sampling according to the four probabilities for selecting
    Table 1. The concordance across different experiments          each card. But, if the value of H for the selections in the
   examining the three main sorts of selection tasks as as-        experiment is reliably smaller than this theoretical value,
  sessed with Kendall’s coefficient of concordance, W, and         then we can reject the null hypothesis of independent selec-
                  stating its χ2 and p values.                     tions. In other words, the redundancy reflected in a smaller
                                                                   value of H reflects interdependence in the selections.
Three sorts of      Number of      Kendall’s   χ2 and p value
                                                                       As an illustrative example, consider the selections in
selection task     experiments                                     Experiment 2 of Stahl et al. (2008), which we choose be-
     Abstract           104        W = .34     107, p < .001       cause of its large number of participants: 351. Here are the
    Everyday             44        W = .25      33, p < .001       frequencies of the selections, in which 6 participants select-
     Deontic             80         W= .54      29, p < .001       ed none of the cards:
                                                                      p 92, pq 99, pqq 2, pq 20, ppqq 19, pq 6, ppq 2,
The redundancy of the selections                                      pqq 2, q 18, pq 22, pp 7, qq 6, p 7, q 43, none 6.
   Many studies of the selection task report only the four         They show that the probabilities of selecting each of the
separate probabilities with which participants selected each       four cards were as follows:
of the cards (e.g., Evans, 1977). These results, however,              p 0.69, q 0.49, q 0.26, p 0.19.
make sense only if the selection of each card is independent       The value of H for the selections in the experiment is 2.8
of the others. Some investigations have reported this inde-        bits. Could this value have occurred by chance? We used a
pendence (e.g., Evans, 1977). But, others have refuted it by       resampling procedure to find out its chance probability
establishing correlations between the selections (Pollard,         (see, e.g., Good, 2001). We ran a computer program to car-
                                                                   ry out 10,000 simulated experiments based both on the
                                                               981

number of participants in the original study and on its prob-                      Theories of the selection task
abilities above of selecting the four individual cards. The              Some theories of the selection task are informal and
resulting mean value of H was 3.13, which shows that the              make only qualitative predictions about selections (e.g.,
observed selections in the experiment have a redundancy of            Wason, 1968). Some predict only whether the correlations
0.33. More important, however, is that not one of the simu-           between selecting the possible pairs of cards are positive or
lated experiments yielded an entropy as low as 2.8 bits, and          negative (Oaksford & Chater, 1994). Some predict only the
so the difference is statistically significant (p < .0001). The       probabilities of selecting each of the four cards (Evans,
redundancy in the original experiment did not occur by                1977; Hattori, 2002; Oaksford & Wakefield, 2003). We
chance. In summary, a statistically significant degree of             discount all of these theories as insufficiently powerful to
redundancy in selections in an experiment is evidence for             make quantitative predictions about the frequencies of the
their interdependence.                                                canonical selections, let alone all 16 possible selections.
   We programmed an algorithm based on the same idea. Its             There remain just two theories, which we now outline.
key difference from our analysis of Stahl’s data above is
that it concerns only the four canonical selections. This             The insight model
constraint is necessary because so many experimental re-                 The first algorithms to model the mental processes under-
ports state the results only for them. Four selections have a         lying the selection task were due to Johnson-Laird and Wa-
maximum entropy of 2 bits if they are each equiprobable.              son (1970a). Their principal algorithm posits three levels of
The mean over the 228 experiments (in Table 1) is 1.27 bits           insight into the importance of falsification: no insight,
(with a standard deviation of 0.48). The input to the pro-            which implies that reasoners select only cards referred to in
gram states the number of participants and the frequencies            the rule – an anticipation of “matching” bias (Evans, 1972);
of the four selections for each experiment in the set. Its            partial insight, which implies that reasoners consider all the
main steps are as follows. For each experiment:                       cards, adding any further cards that verify the rule, or, fail-
                                                                      ing that, that falsify the rule; and complete insight, which
    1.   Compute N, the number of participants, and the               implies that reasoners select only cards that can falsify the
         probabilities with which each of the 4 cards oc-             rule. The algorithm was published as a flow chart, but not
         curred in the experiment’s selections.                       implemented, because of a lack of access to a main-frame
   2.    Compute Shannon’s entropy H for the experiment.              computer. We recently programmed it, replacing its use of
   3.    Carry out 10,000 simulated experiments based on              truth tables with mental models and fully explicit models,
         the probabilities of selecting each card, assigning a        simplifying its processes, but keeping its original function-
         selection to each of the N participants.                     ality so the program makes the identical predictions to the
   4.    Return the number of simulated experiments with a            original version.
         higher entropy than the actual experiment and the               Given a rule of the sort if p then q, the program begins by
         number of them with the same or a lower entropy.             compiling a list of cards to select, and its first step is to
                                                                      scan its mental model of the conditional, and as a result to
    Table 3. The mean entropies (in bits) of 228 experiments          put p on this list. If the program also scans the model in the
  on three sorts of selection task, the mean entropies of sets        opposite direction, it adds q to the list. With no insight into
 of 10,000 simulations of each experiment, and Wilcoxon’s             the task, these selections verify the rule. However, the pro-
  tests (W, and its p-value) of the difference between them.          gram implements two interrelated levels of insight. Partial
                                                                      insight is to assess all the cards, and to add any further card
  The three       Mean entropy Mean entropy     Wilcoxon’s            that verifies the rule, or, if none does, to add any that falsi-
  sorts of selec- of experiments of sets of     W and p-value
                                                                      fies the rule. So, if q is already in the list, partial insight
  tion task                      simulations
  Abstract              1.32          1.42      W = 469, p < .001
                                                                      adds q, because it can falsify the rule, yielding the selection
                                                                      pqq. Complete insight is to select only cards that can falsify
  Everyday              1.51          1.66      W = 28, p < .001
  Deontic               1.06          1.21      W = 68, p < .001      the rule, and yields the selection pq. Complete insight oc-
                                                                      curs only if all the cards are examined. An explicit bicondi-
   Table 3 presents the mean entropies of the 228 experi-             tional as an input yields a selection of all four cards in cer-
ments investigating the three sorts of selection task, the            tain cases, e.g., when it scans its model in both directions
mean entropies of each of their 10,000 simulations, and the           with partial insight.
results of Wilcoxon’s W test and its p-value comparing the               Fig. 2 presents, not the algorithm, but a tree diagram
pairs of means. These results allow us to reject the null hy-         summarizing its parameters and its predictions for condi-
pothesis of independent selections. The redundancy shown              tionals and biconditionals. As it illustrates, the algorithm
in the smaller entropies of real experiments over simulated           produces the same selections as a result of different pro-
ones shows that the cards in selections are not selected in-          cesses, and it is not deterministic, i.e., nothing in the algo-
dependently of one another. They are selected in an inter-            rithm determines the level of insight (pace Evans, 1977,
dependent way. This result eliminates any theory that pre-            who took the algorithm to be deterministic). The predic-
dicts that selections are independent.                                tions in Fig. 2 explain why selections should be interde-
                                                                      pendent, e.g., verifying cards include q only if they include
                                                                      p and falsifying cards include q if and only if they include
                                                                  982

p. The only exceptions to the algorithm’s outputs should be              2. The probability that the inference is forwards from the
the result of guessing or haphazard errors. In fact, these            if-clause: modus ponens (MP) or denial of the antecedent
exceptions occur at a rate less than chance in the 288 exper-         (DA), as opposed to backwards from the then-clause: mo-
iments.                                                               dus tollens (MT) or affirmation of the consequent (AC).
                                                                         3. Given the biconditional interpretation, the probability
                                                                      that the interpretation is bidirectional, if p then q & if q then
                                                                      p, as opposed to a case distinction, if p then q & if not-p
                                                                      then not-q. With the bidirectional interpretation, the distinc-
                                                                      tion between forwards and backwards inferences does not
                                                                      apply – both are made, but with a case distinction interpre-
                                                                      tation, the distinction still applies.
                                                                         4. The probability that an inference from a conditional or
                                                                      a bidirectional biconditional is a sufficient one as opposed
                                                                      to a necessary one. Normally, p is judged sufficient to infer
                                                                      q from if p then q, but sometimes p is judged necessary to
                                                                      infer q, as when the conditional is interpreted as stating an
                                                                      enabling condition akin to only if p then q. A forward suffi-
                                                                      cient inference is MP, whereas a forward necessary infer-
   Figure 2. The predictions of the insight model (Johnson-
                                                                      ence is DA; and a backward sufficient inference is AC,
 Laird & Wason, 1970a) as a binary decision tree. Each de-
                                                                      whereas a backward necessary inference is MT.
   cision is controlled in its recent implementation by a pa-
                                                                         5. The probability that inferences are made only about
  rameter (see text). Participants with no insight select only
                                                                      the visible sides of cards as opposed to the invisible sides of
 cards referred to in the rule. Those with partial insight con-
                                                                      cards too, i.e., individuals can envisage items on them.
 sider all cards, selecting any further card that can verify the
                                                                         The model contains 10 parameters but the data are the
   rule, or, failing that, that can falsify it. Participants with
                                                                      frequencies of the four canonical selections. Hence, to en-
  complete insight select only cards that can falsify the rule.
                                                                      sure that the process of fitting model to data converges and
                                                                      does not overfit the data, we implemented a restricted in-
   Our implementation of the algorithm contains three
                                                                      ference-guessing model that makes the four canonical se-
probabilistic parameters in the unit interval from 0 to 1. The
                                                                      lections. Fig. 3 summarizes the predictions of this restricted
first parameter, c, is the probability of scanning the model
                                                                      inference-guessing model. The reasoning component in the
in both directions as opposed to scanning in only one direc-
                                                                      original model makes no more than two inferences on a
tion. The second parameter, e, is the probability of examin-
                                                                      trial, and so it cannot make the canonical selection of three
ing all four cards, and if the result fails to add any card that
verifies the rule, adding any card that falsifies it. This cor-       cards: pqq. We therefore changed the original guessing
responds to partial insight. The third parameter, f, is the           component to make this selection.
probability of complete insight, which makes only a falsify-
ing selection.
The inference-guessing model
    Klauer et al. (2007) proposed a set of related theories,
including one with a heuristic component allowing for
guessing, and an inferential component. There is no algo-
rithm the implements the theory’s underlying processes, but
its predictions were modeled in a binary tree. This model
has 10 parameters, which are each the probability that one
sort of process occurs rather than another, and so each is in          Figure 3. A restricted version of the binary decision tree of
the unit interval from 0 to 1. The model’s first parameter is          the inference-guessing model (Klauer et al., 2007) for the 4
the probability that the inference governs the selection as             canonical selections. Each decision is controlled by a pa-
opposed to guessing. The guessing component makes inde-                                      rameter (see text).
pendent selections of each of the four cards according to
four parameters that are the respective probabilities of se-             The two models are based on the only theories that we
lecting each of them independently as a result of guessing            could find in the literature that can be programmed with
or any heuristic factor such as “matching” (Evans, 1977).             parameters that fit data about the frequencies of selections.
The theory assumes that selections are governed, not by the
meaning of the rule, but by inferences from the rule. The                        An evaluation of the two models
particular inferences depends on five parameters:                        We evaluated the insight model with 3 parameters (John-
   1. The probability that the rule, if p then q, is interpreted      son-Laird & Wason, 1970a) and the restricted inference-
as a conditional as opposed to a biconditional.                       guessing model with 4 parameters (cf. Klauer et al., 2007).
                                                                      Their respective predictions can be represented as trees of
                                                                  983

binary decisions (see Fig. 2 and Fig. 3). Both models in-           pq, except when they violate a deontic rule Table 2). The
voke alternative sequences of processes depending either            four canonical selections (p, pq, pqq, and pq) are reliably
on three decisions in the insight model or four decisions in        redundant in most experiments in comparisons of each ex-
the inference-guessing model. Because each model’s pre-             periment’s entropy (informativeness) with the entropy of its
dictions correspond to a tree of decisions, we evaluated
each of them as a multinomial processing tree (MPT) in                Table 4. The insight model’s and the restricted inference-
which the probability of a particular cognitive state is esti-      guessing model’s goodness of fit with the individual canon-
mated from the observed frequencies of selections (Riefer           ical selections for 288 experiments overall and for the three
& Batchelder, 1988). A program fitted each of the two                sorts of selection task: the root mean square errors (RMSE)
models to the frequencies of the canonical selections of the            for their predictions, their Bayesian information criteria
three sorts of selection task: 104 experiments with the ab-            (BIC), and the Bayes factors for the better-fitting model.
stract task, 44 experiments with everyday task, and 80 ex-            The 3 sorts                              Bayesian
periments with deontic task (see Tables 1-3 above). We                               Cognitive                              Bayes
                                                                      of the sele-                 RMSE       Information
used the maximum-likelihood method from the R-package                                  model                                factor
                                                                      ction task                            Criterion (BIC)
for multinomial processing trees (the MPTinR of Singmann              Overall        Insight        2.69          27.7
& Kellen, 2012). We calculated three measures to compare                             Inference-    19.35          37.0        99.5
the goodness of fits of the two theories:-                                           guessing
                                                                      Abstract       Insight        1.97          25.7
• The root mean square errors (RMSEs) of the fits.                                   Inference-     3.28          34.3        73.7
                                                                                     guessing
• The Bayesian information criterion (BIC), which indicates           Everyday       Insight         1.7          23.2
                                                                                     Inference-     2.18          30.9         47
how much information is lost when a model represents the
                                                                                     guessing
process that generates the data, taking into account both its
                                                                      Deontic        Insight         0.8          23.5
goodness of fit and its number of parameters. It penalizes                           Inference-     1.05          31.4        49.4
models according to the number of their parameters, and                              guessing
the smaller its value, the better the fit between a model and
the data.                                                           10,000 simulations based on its four probabilities of select-
                                                                    ing each card (Table 3). Not all experiments yield redun-
• The Bayes factor (BF; Schwarz, 1978), which is a Bayesi-          dant selections, but the vast majority do. This result ruled
an method to compare different models. It uses an approx-           out theories that imply that selections of cards are inde-
imation of the difference between the BIC value of model 1          pendent of one another. Above all, theories therefore need
and BIC value of model 2 as computed by MPTinR. The                 to predict the frequencies of the canonical selections. Per-
higher its value between 30 and 100, the stronger the sup-          haps surprisingly, this criterion rules out nearly all the re-
port for model 1 over model 2 (Wagenmakers et al., 2011).           maining theories. Klauer et al. (2007) had programmed an
                                                                    MPT of their inference-guessing model using 10 parame-
   Table 4 presents the three measures for each of the two          ters to make predictions for the frequencies of all 16 possi-
models. As it shows, the insight model with three parame-           ble selections – most of which do not occur more often than
ters has a closer fits, and lower BIC values, than the re-          chance. More than twice as many experiments reported the
stricted inference-guessing model. The Bayesian factor              frequencies only of the four canonical selections than re-
likewise shows stronger evidence for the insight model than         ported them for all 16 selections. Hence, we produced an
for the restricted inference-guessing model. The insight            MPT for a restricted version of the model that used four
model has the advantage of fewer parameters. As a theory,           parameters to predict the frequencies of the canonical selec-
it is simpler because it relies on the meaning of the rule          tions. To do so, we reduced the original parameters for
rather than inferences from it, and because it has no ma-           guessing to one, which made a selection of three cards,
chinery to account for selections that occur at a rate less         otherwise impossible for the model to select. For the insight
than chance. But, it is not a paragon, and we explain why           model, we programmed an algorithm that carried out its
below.                                                              processes (Johnson-Laird & Wason, 1970a), and we used it
                                                                    to construct an MPT model with three parameters. The
                    General Discussion                              insight model yielded a better fit with fewer parameters
  Half a century of research and over 300 articles should           (Table 4).
have led to a single unique theory of a cognitive task rather           The story of the selection task does not end here. But, the
than to 15 different theories. That was the situation for Wa-       success of the insight theory tells us that we have returned
son’s selection task. The present research, however, has            to how it was conceived after only a handful of studies.
eliminated all but one theory. And it did so using the fol-         Naive individuals focus on those cards mentioned in the
lowing strategy. It established a large but representative set      rule, and select them if they can verify the rule. With a little
of experiments investigating rules of the sort if p then q that     bit of insight, they consider all the cards, and may select
had a reliable concordance in their results (Table 1).              additional cards. With complete insight, they select only
These results established the rarity of falsifying selections,      cards that can falsify the rule (Johnson-Laird & Wason,
                                                                984

1970a). We now know that various factors – the compe-               Good, P. I. (2001). Resampling methods: A practical guide
tence of participants, the contents of the rule, and the fram-        to data analysis. NY: Birkhauser Boston.
ing of the task – can all enhance insight. An account along         Griggs, R. A., & Cox, J. R. (1982). The elusive thematic
these lines seems to be correct, except perhaps when exper-           materials effect in Wason's selection task. British Journal
iments implicate probabilities in their contents or framing           of Psychology,73(3), 407-420.
(e.g., Oaksford & Chater, 1994).                                    Hattori, M. (2002). A quantitative model of optimal data
   The excellent fit of the insight model must be viewed              selection in Wason's selection task. Quarterly Journal of
with caution. The number of parameters in a model is a                Experimental Psychology: Section A, 55, 1241-1272.
measure of our ignorance. Those for guessing seem to be             Johnson-Laird, P. N. (1983). Mental models. Cambridge,
dispensable. Indeed, some selections are very odd, as we              MA: Harvard University Press.
saw earlier in our analysis of the results from Stahl et al.        Johnson-Laird, P. N., Legrenzi, P., & Legrenzi, M. S.
(2008). They are so odd that they must count as irrational            (1972). Reasoning and a sense of reality. British Journal
on any criterion: the participants erred or guessed. Introduc-        of Psychology, 63, 395-400.
ing parameters to model guessing has no theoretical value           Johnson-Laird, P. N., & Wason, P. C. (1970a). A theoreti-
other than to index the difficulty of a task. The insight theo-       cal analysis of insight into a reasoning task. Cognitive
ry has three essential parameters, and the original infer-            Psychology, 1, 134-148.
ence-guessing model has five. The difference reflects an            Johnson-Laird, P. N., & Wason, P. C. (1970b). Insight into
crucial distinction: whether people determine the truth val-          a logical relation. Quarterly Journal of Experimental
ue of an assertion based on its meaning (the insight model)           Psychology, 22(1), 49-61.
or based on inferences from it (the inference-guessing              Klauer, K. C., Stahl, C., & Erdfelder, E. (2007). The ab-
model). Therein may lie the advantage of the insight model.           stract selection task: new data and an almost comprehen-
But, we are bound to ask what mechanisms might replace                sive model. Journal of Experimental Psychology: Learn-
its parameters. We now know that the insight to make falsi-           ing, Memory, and Cognition, 33, 680-703.
fying selections depends on various factors, including intel-       Oaksford, M., & Chater, N. (1994). A rational analysis of
lectual ability (e.g., Stanovich & West, 1998). Hence, it             the selection task as optimal data selection. Psychologi-
may be feasible to replace the parameter for the probability          cal Review, 101, 608-631.
of complete insight with a measure of ability. It is even           Oaksford, M., & Wakefield, M. (2003). Data selection and
conceivable that the parameter of partial insight might re-           natural sampling: Probabilities do matter. Memory &
flect a lesser but above average intellect. The parameter for         Cognition, 31(1), 143-154.
scanning a model of the conditional in both directions is           Pollard, P. (1985). Nonindependence of selections on the
more problematic. It may depend on the processing capaci-             Wason selection task. Bulletin of the Psychonomic Socie-
ty of working memory. These speculations in no way rule               ty, 23(4), 317-320.
out the possibility of some quite different theory of the se-       Riefer, D. M., & Batchelder, W. H. (1988). Multinomial
lection task outperforming the insight model.                         modeling and the measurement of cognitive processes.
   If our research has any general moral, it is an old one:           Psychological Review, 95, 318-339.
cognitive theories should be effective procedures (Johnson-         Schwarz, G. (1978). Estimating the dimension of a mod-
Laird, 1983, p. 6). They should be programmable.                      el. The annals of statistics, 6(2), 461-464.
                                                                    Singmann, H., & Kellen, D. (2012). MPTinR: Analysis of
                   Acknowledgements                                   multinomial processing tree models in R. Behavioral Re-
This research was supported by a DFG-Heisenberg fellow-               search Methods, 45, 560–575.
ship DFG RA 1934/3-1, and DFG projects RA 1934/2-1                  Stahl, C., Klauer, K.C., & Erdfelder, E. (2008). Matching
and 4-1. We thank Linden Ball, Ruth Byrne, Nick Chater,               bias in the selection task is not eliminated by explicit ne-
Jonathan Evans, Keith Holyoak, Sangeet Khemlani, Ken                  gations. Thinking & Reasoning, 14, 281-303.
Manktelow, Mike Oaksford, Klaus Oberauer, Lance Rips,               Stanovich, K. E., & West, R. F. (1998). Cognitive ability
Carlos Santamaría, Walter Schaeken, Walter Schroyens,                 and variation in selection task performance. Thinking &
Dan Sperber, Christoph Stahl, and Valerie Thompson, for               Reasoning, 4, 193-230.
their help. We thank Christoph Klauer for his advice and            Wagenmakers, E. J., Wetzels, R., Borsboom, D., & van der
sending us his algorithm,. We dedicate this paper to the              Maas, H. L. (2011). Why psychologists must change the
memory of Peter Wason (1924-2003), a unique and most                  way they analyze their data: the case of psi: comment on
extraordinary researcher.                                             Bem (2011). Journal of Personality and Social Psychol-
                                                                      ogy, 100, 3, 426–432
                        References                                  Wason, P. C. (1968). Reasoning about a rule. The Quarter-
                                                                      ly Journal of Experimental Psychology, 20, 273-281.
Evans, J. S. B. (1972). Interpretation and matching bias in a       Wason, P. C., & Johnson-Laird, P. N. (1969). Proving a
   reasoning task. The Quarterly Journal of Experimental              disjunctive rule. Quarterly Journal of Experimental Psy-
   Psychology, 24, 193-199.                                           chology, 21, 14-20.
Evans, J. S. B. (1977). Toward a statistical theory of rea-         Wason, P. C., & Shapiro, D. (1971). Natural and contrived
   soning. Quarterly Journal of Experimental Psychology,              experience in a reasoning problem. Quarterly Journal of
   29, 621-635.                                                       Experimental Psychology, 23, 63-71.
                                                                985

