  You can take a noun out of syntax...: Syntactic similarity effects in lexical priming
                                          Nicholas A. Lester (nlester@umail.ucsb.edu)
                                                         Department of Linguistics,
                                              University of California, Santa Barbara, USA
                                          Laurie B. Feldman (lfeldman@albany.edu)
                                Haskins Laboratories, New Haven, CT, & Department of Psychology,
                                           State University of New York, Albany, NY, USA
                           Fermín Moscoso del Prado Martín (fmoscoso@linguistics.ucsb.edu)
                                                         Department of Linguistics,
                                           University of California, Santa Barbara, CA, USA
                              Abstract                                  and syntactic structures, are potentially interconnected on the
                                                                        basis of one’s experience with language (e.g., Diessel, 2015).
  Usage-based theories of syntax predict that words and
  syntactic constructions are probabilistically interconnected. If      Let us refer to this position as the probabilistic network
  this is true, then words that occur in similar distributions of       hypothesis. Results such as those reported by Novick et al.
  syntactic constructions should prime each other. These effects        (2003) are easily accounted for under this framework. To use
  should be fine-grained; even small differences between the            the connectionist metaphor, connections between lexical and
  syntactic distributions of pairs of words of the same                 syntactic nodes are tuned as a function of their frequency of
  grammatical category should cause variation in priming. Prior         distinctive co-activation (e.g., Gries & Stefanowitsch, 2004).
  research from production suggests that this prediction should
  hold even in tasks without any syntactic requirement. In this
                                                                        Stronger connections are processed more efficiently. Further
  study, we introduce a measure of the similarity between the           support for this hypothesis comes from work on word
  syntactic contexts in which two nouns occur. We show that this        production: the probability distributions of words in
  similarity measure significantly predicts visual lexical decision     particular syntactic structures influence picture naming
  priming magnitudes between pairs of nouns. This finding is            latencies (Lester & Moscoso del Prado Martín, 2016).
  consistent with the predictions of usage-based theories where            Direct, probabilistic relationships between words and
  fine-grained similarity of syntactic usages between                   syntactic structures are not universally accepted across
  prime-target pairs affects decision latencies, over and above
  any effects attributable to semantic similarity.                      linguistic models. Many models argue that syntax only enters
                                                                        the lexicon through general categorical specifications (i.e.,
   Keywords: syntax; priming; usage-based linguistics; visual           most generative approaches to syntax). Accordingly, words
   lexical decision; information theory                                 may have a feature indicating the part-of-speech category to
                                                                        which they belong (noun, verb, adjective, and so on). More
                          Background                                    recent work in this vein has expanded the syntactic content of
Lexical priming experiments have a long history in                      the lexicon to include more fine-grained syntactic categories.
psycholinguistic research. Though the bulk of this research             For example, in current mainstream generativist syntax (the
has focused on semantic and orthographic effects, some                  Minimalist Program; Chomksy, 1995), words contain
studies have considered the role of syntax (henceforth                  information about the syntactic frames with which they can
grammatical priming). Early work looked at the effects of               combine as functional head (sometimes called
inflectional congruity across word classes. For example, in             subcategorization or c-selection; for a similar approach, see
Serbian, inflected nouns are recognized faster when primed              Bresnan, 2001). Crucially, these syntactic specifications
by case-appropriate adjectives (e.g., Gurjanov, Lukatela,               represent categorical constraints on the possible distributions
Moskovljević, Savić, & Turvey, 1985). More recent work                  of words. We will call this the categorical constraint
has looked at contextualized reading effects. Nouns and                 hypothesis. Under this account, probabilistic relationships
verbs that are biased to occur in congruent syntactic                   are simply not available to the grammar. Any effects of
constructions (e.g., direct-object vs. subordinate clause               probability are designated “extra-grammatical” (Stabler,
continuations; I need some coffee/to go to the market)                  2013) and are instead usually attributed to relationships in
facilitate processing of later content (Novick, Kim, &                  other mental systems, such as the Conceptual-Intentional
Trueswell, 2003). Thus, accessing a noun primes                         system.
expectations about its syntactic context. Congruity effects                This theoretical distinction leads to different predictions
have been interpreted as evidence for robust, probabilistic             about the nature of grammatical priming. The probabilistic
syntactic specifications for lexical items.                             network hypothesis predicts that probabilistic information
  The empirical evidence outlined so far is complemented by             about the semantic and syntactic similarity of words should
work in theoretical linguistics. Usage-based linguistic                 produce independent priming effects. The categorical
theories argue that all facets of grammar, including words              constraint hypothesis predicts that probabilistic effects
                                                                    2537

should only arise for semantic similarity (as the syntactic          relations as defined within Dependency Grammar
system does not encode such relationships). We test this             formalisms (e.g., Mel'čuk, 1988; Nivre, 2005). Dependency
contrast using a simple lexical priming paradigm.                    Grammars model only relations (dependencies) between
   Research on grammatical priming has largely relied on             pairs of words. These relations are asymmetric: each extends
syntactic or pseudo-syntactic contexts (e.g., using an               from a head (the syntactic and conceptual core word) to a
adjective as a prime for a noun). However, the predictions of        modifier (whose syntactic role is contingent on the head).
usage-based theory, along with recent evidence from                  Each dependency is labeled to reflect its syntactic function.
production (e.g., Lester & Moscoso del Prado Martín, 2016),          For example, the and waffle in the noun phrase the waffle
suggest that syntactic information –all of it– should be             would be bound by the det relation, which attaches a
automatically activated every time a word is accessed. This          determiner (the, the modifier) to a noun (waffle, the head).
should be true even when the word is presented in isolation          Other examples include the nsubj relation, which binds a
for purposes of the task, as in visual lexical decision (see also    noun (modifier) to a verb (head) as its subject, and the pobj
Durán and Pillon, 2011). We therefore use a simple overt             relation, which binds a noun (modifier) to a preposition (head)
lexical priming paradigm with visual lexical decision. We            as its object. A further detailed description and discussion
restrict our analysis to nouns to guard against intercategorical     of Dependency Grammar formalism is beyond the scope of
effects. We predict RTs based on the similarity of semantic          this study. We adopt the dependency formalism implemented
and syntactic distributions across a range of words words.           in the spaCy parser (Honnibal & Johnson, 2015), one of the
The probabilistic network hypothesis would be supported by           fastest and most accurate dependency parsers available.
evidence of priming for similar syntax and semantics,                   We define the syntactic space for nouns as the set of
independently. The categorical constraint hypothesis would           dependencies for which at least one noun from our sample of
be supported by priming only in the domain of semantics.             SPP primes and targets has been attested either as head or as
                                                                     modifier. For each noun in our dataset, we extracted all
                           Methods                                   sentences containing that noun from the BNC. We
                                                                     conditioned the search to include only sentences in which the
Data                                                                 word form was indeed tagged as a noun. Those sentences
We used the response latencies contained in the Semantic             were parsed using spaCy. We then compute the frequency
Priming Project (SPP; Hutchison, et al., 2013). The SPP              distribution of each noun across the dependencies for which
contains response times and accuracies, along with a host of         it serves as head or modifier. To increase the reliability of our
norming data, that were collected using a visual lexical             frequency estimates, we discard vectors for all nouns that
decision task with overt orthographic priming. On each trial,        occurred in fewer than 100 sentences in the BNC (~1 per
participants were shown a centered fixation cross for 500 ms,        million words). The total syntactic space is defined as a
followed by a prime word (all caps) for 150 ms. The prime            vector in which each column reflects one among the set of
was followed by a blank screen lasting either 50 or 1050 ms.         unique dependencies occurring across all nouns. Finally, we
The target word was displayed (all lowercase) until a either         merge the individual frequency distribution of each noun into
decision was made or 3,000 ms elapsed, at which point the            the total syntactic space, creating a matrix of n rows by m
experiment would advance to the next trial.                          columns, where n = the number of total unique dependency
   We used only those trials containing primes and targets           types (46) and m = the number of unique SPP/BLP nouns
that also appear both in the British Lexicon Project (BLP;           (1,241). The result is therefore a uniform syntactic space for
Keuleers, Lacey, Rastle, & Brysbaert, 2012) and the age of           all nouns, where individual nouns may or may not be attested
acquisition      norming       database       of     Kuperman,       in each possible dependency. In theoretical terms, we treat
Stadthagen-Gonzalez, & Brysbaert (2012). We limit the data           these vectors as reflecting the statistical connectivity between
in this way to take advantage of the additional lexical              each noun and the syntactic structures in which it takes part,
controls afforded by these databases. To ensure that all             as is proposed in the usage-based literature. Psycholinguistic
stimuli were understood primarily as nouns, we further               support for this treatment comes from an earlier study
limited the trials to include only those in which both prime         showing that these and similar dependency vectors affect
and target received majority noun tags in the British National       processing latencies in noun production over and above the
Corpus (BNC). In this way, we obtained a dataset consisting          effects of other known factors (Lester & Moscoso del Prado
1,305 unique primes and 821 unique targets (a total of 1,670         Martín, 2016).
unique nouns).
                                                                     Measuring syntactic similarity
Syntactic space                                                      We are interested in the possibility that pre-activation of
To measure the relationship between the noun-pairs in the            shared syntactic representations will affect the speed of word
syntactic system, we first need to operationalize the syntactic      recognition. Therefore, we need some measure of the
system itself. Decades of research have failed to produce an         similarity between the syntactic distributions of primes and
exhaustive list of the syntactic constructions of English (let       targets in our behavioral data. Note that similarity in
alone any other language), and we do not presume to offer            syntactic space outlined above does not reduce solely to
such a list here. Instead, we rely on the set of low-level           shared types of dependencies. For example, consider two
                                                                 2538

words, w1 and w2, that occupy the same set of 20                   measure may actually reflect semantic similarity, which is
dependency types. Suppose that w1 and w2 have roughly              well known to affect priming magnitudes (e.g., Neely, 1991).
equivalent overall frequencies and that those frequencies are      Moreover, the contrast between the probabilistic network and
distributed equally across the dependency types for both           categorical constraint hypotheses depends on a direct
words. In this case, we would call them syntactically similar,     comparison of syntactic and semantic sources of similarity.
and consider the number of overlapping types as an                 Fortunately, the SPP contains annotation of the degree of
appropriate measure of the strength of their similarity. Now       semantic similarity between prime and target, indicated by
suppose that the two words have similar overall frequencies,       cosine similarities in Latent Semantic Analysis space (LSA).
but that these frequencies are distributed over                    LSA measures the extent to which words occur in similar
complementary sets of the dependencies that they share, such       texts, with higher cosine values indicating greater similarity
that w1 has a frequency of 1 wherever w2 has a                     (Landauer & Dumais, 1997). We transformed the cosine
frequency >100 and vice versa. In this case, we would call         similarities into distances (i.e., 1-cos).
them dissimilar. For this, we need to simultaneously account          Figure 1 plots the relationship between the syntactic
for shared types, as well their probability distributions. One     distances (JSD) between pairs of words as a function of their
measure well suited to this task is the Jensen-Shannon             semantic distances (LSA) values. As one would expect, there
Divergence (JSD; Lin, 1991). JSD is a symmetric variant of         is a significant positive (linear) 1 correlation between both
the Kullback-Leibler Divergence (KLD). The KLD between             measures, meaning that words that are similar in meaning
two probability distributions P and Q is defined in Eq. 1.         tend to occur in similar syntactic contexts. However, an
                                                                   important feature of Figure 1 is the triangular shape of the
                                                            (1)    variance: words that are very close in meaning vary only
                                                                   slightly in syntactic similarity, while words that are distant in
                                                                   meaning vary more widely. This relationship supports the
This measure captures the average amount of additional             account of Jackendoff (2013), who argues for the existence
information that one would need in order to recode an event        of syntactic generalizations (i.e., constructions) that allow
from distribution P as if it belonged to distribution Q.           structural inheritance among sets of semantically
Importantly, KLD(P||Q) ≠ KLD(Q||P), meaning that one               heterogeneous sub-constructions. In other words, nouns that
must decide a priori in which direction to take the distance.      are extremely similar in meaning (e.g., synonyms) will
JSD provides a solution to the asymmetry problem by taking         always appear in extremely similar syntactic contexts.
the midpoint between the two distributions, then taking the        However, there is large variability in the syntactic similarities
mean distance of the distributions to the midpoint. Formally,      of words with different meaning (or there is large variability
JSD is expressed as follows (Eqs. 2 and 3).                        in the semantic similarity between pairs of words that appear
                                                                   in very different syntactic contexts). This suggests that
                                                            (2)    syntax and semantics are not as tightly coupled as some
                                                                   would argue (e.g., Goldberg, 1995), and their contributions
where                                                              can indeed be considered separately.
                                                            (3)
This measure has the advantage of being both symmetrical
[JSD(P||Q) = JSD(Q||P)] and bounded (0 ≤ JSD ≤ 1).
   JSD measurements depend on estimates of the probability
distributions of events within a distribution, rather than on
their actual probability distributions. Maximum-likelihood
estimates of information-theoretical measures are known to
be biased. To guard against this bias we apply a
bias-reducing frequency correction to our syntactic vectors,
using the plug-in James-Stein shrinkage estimator (Hausser
& Strimmer, 2009).
   The methods above provide an operationalization of
syntactic similarity between primes and targets. For each
prime—target pair in the sample, we compute the JSD                     Figure 1: Relationship between syntactic and semantic
between their syntactic vectors. A value of 0 indicates                                   distance measures
identity; a value of 1 indicates complete independence.
According to usage-based theories, (at least the bulk of)
syntactic structure is meaningful– that is, directly linked to        1
                                                                        The linear nature of this relation was confirmed using a
semantic representations in the same way as words (e.g.,
                                                                   Generalized Additive Model with penalized spline-based
Diessel, 2015). This means that any effect we uncover for our      smoothers.
                                                               2539

   To disentangle the purely syntactic aspects of lexical                                        Results
similarity from what can be attributed to similarity in
                                                                     We fitted a linear mixed-effect regression model predicting
meaning, we residualized the semantic measure out of the
                                                                     response latencies from the SPP primed lexical decision
syntactic measure. This was achieved by fitting a linear
                                                                     database as a function of the variables outlined above. In
regression predicting the JSDs as a function of the LSA
                                                                     addition to the fixed effects, we included random effects for
distances, and using the residuals of this regression as our
                                                                     participants and prime-target pairs (i.e., random slopes). We
measure of syntactic difference. This measure captures the
                                                                     discarded 6.7% of all trials as outliers (all latencies falling
information in JSD that is not attributable to semantics (cf.,
                                                                     below 400 ms or 2 standard deviations above the mean). In
Hendrix, Bolger, & Baayen, 2017; responding to the
                                                                     addition, we corrected for a strong positive skew in the
concerns expressed by Wurm & Fisicaro, 2014).
                                                                     response times by taking the logarithm of RTS (as suggested
                                                                     by a Box-Cox power analysis; Box & Cox, 1964). Visual
Further controls
                                                                     inspection of the model residuals with and without the
A number of other factors are known to impact recognition            corrections confirmed the adequacy of these steps.
latencies in the primed lexical decision paradigm. These fall           All main effects for the control predictors besides OLD20
into three categories: effects related to recognizing individual     surfaced as significant at the α=.05 level, and in the expected
words, (other) effects based on the relationship between             direction. The model also revealed a significant (p<.001)
prime and target, and effects related to the nature of the task      effect of the two-way interaction between LD and ISI: at 50
itself. From the first set, the most important predictor is the      ms ISI, LD had a negative impact on response times (-2.5 ms
surface frequency of the target: i.e., more frequent words are       per unit increase in LD), with no effect at 1050 ms.
recognized faster. We use the SUBTLEX-UK frequencies,                Importantly, the model revealed a significant interaction
which are based on movie subtitles and known to outperform           (p<.01) between ISI and LSA distance, consistent with what
estimates drawn from other corpora, including the BNC (van           one would expect. Response latencies increased by about 5
Heuven, Mandera, Keuleers, & Brysbaert, 2014). We also               ms per .1 increase in cosine distance at a short ISI. At a long
include a measure of the density of the orthographic                 ISI, this effect was reduced to ~3 ms per .1 increase. As
neighborhood of the target known as OLD20 (Yarkoni,                  semantic distance between prime and target increased, so did
Balota, & Yap, 2008). The more similar the spelling of the           target recognition latencies, with stronger effects at the
word to its closest neighbors, the faster it is recognized.          shorter ISI.
Another predictor that has been proposed is age of                      Over and above the effects of the controls, and crucially
acquisition: the earlier a word is acquired in the lifespan, the     over that of semantic similarity, the model revealed a
faster it is recognized (e.g., Kuperman et al., 2012). Less          statistically independent significant main effect (p<.001) of
important, but nevertheless known to exert an effect, is the         the residualized syntactic distance. For every .1 increase in
orthographic length of the word: longer words take longer to         residualized syntactic distance, response latencies were
recognize (New, Ferrand, Pallier, & Brysbaert, 2006).                increased by ~4 ± ~3 ms. As predicted by the probabilistic
   Besides our residualized syntactic measure, we included           network hypothesis, the less related the prime and target in
two additional predictors relating the prime and target: We          syntactic space, the longer it takes to recognize the target.
included semantic distance (i.e., the LSA distances), as             There was also a marginal interaction of JSD with ISI (p=.07).
semantic similarity is known to facilitate access to targets         The trend resembled that observed for LSA: longer ISIs lead
(i.e., semantic priming). In addition, we considered the             to an attenuated contribution of syntactic similarity. However,
Levenshtein distance (LD; Levenshtein, 1966; van der Loo,            given the marginal status of the effect, we do not interpret it
2014) between prime and target to account for possible               further.
effects of orthographic relatedness. We expect
orthographically similar prime-target pairs to result in slower                               Discussion
recognition latencies (cf., Adelman, et al., 2014). In addition
                                                                     The present study finds a relatively strong effect of syntactic
to these main effects, we tested two-way interactions
                                                                     similarity on lexical priming magnitudes. In fact, the effect
between the inter-stimulus interval (ISI) on the one hand, and
                                                                     was similar in strength –if anything stronger– to that of
LSA distance, LD, and residualized JSD on the other. This
                                                                     semantic similarity. To our knowledge, this study is the first
was done to account for the possibility that priming effects
                                                                     to demonstrate that pre-activating a word's syntactic space
might change with the different offsets between prime and
                                                                     affects access to that word in a prima facie non-syntactic task.
target.
                                                                     This effect provides support for the probabilistic network
   Finally, we included the (log) sequential position of each
                                                                     hypothesis, which predicts that words and syntactic
trial in the overall experimental order of presentation. As
                                                                     structures are interdependent, and that these connections are
participants move through the trials, we expected some
                                                                     forged and tuned by experience. Crucially, these probabilistic
degree of fatigue to set in (each participant performed over
                                                                     relationships are at the core of the grammatical apparatus –
800 trials).
                                                                     they are not simply attributable to the extra-grammatical
                                                                     conceptual system. If that were the case, we should have
                                                                     found no effect of syntactic similarity once semantics was
                                                                     accounted for.
                                                                 2540

    The data we rely on here do not provide us with a                 for by a more fine-grained measure of semantic relatedness
non-primed baseline, meaning that we cannot distinguish a             or similarity than that provided by LSA.
facilitation effect of syntactic similarity from an inhibitory           Another possible limitation concerns the morphological
effect of syntactic dissimilarity. We therefore leave this            structure of the words in our study. While we only included
question for further research. However, the similarity in             monosyllabic and disyllabic nouns, some of the tokens
shape between the syntactic and semantic effects suggest that         contained derivational morphology (e.g., actor). Morphology
syntax –as is argued for semantics (e.g., Lam et al, 2015)–           is known to interact with priming from other domains (e.g.,
constrains the set of lexical candidates prior to the lexicality      semantics; Feldman et al., 2015). Therefore, it remains
judgment. Furthermore, it suggests that syntax, like                  unclear to what extent morphology was contributing to both
semantics, is obligatorily accessed as soon as lexical forms          the shapes of the distributions we computed from the corpus
become active. Crucially, the relationships between words             and/or aspects of the priming relationship. In future research,
and syntax become active even when (overt) syntactic                  it will be necessary to account for possible derivational
structure is not built into the stimuli and not really necessary      relationships between target and prime, and to explore how
for performing the task. Recent psycholinguistic work on              morphological structure impacts syntactic diversity.
single-word production has echoed this point. For example,              The interaction between our measure and the temporal
Lester and Moscoso del Prado Martín (2016) report                     offset between the prime and the target was only marginally
chronometric       findings     suggestive     of     large-scale     significant. The SPP contains only two such offsets:
interactivation between syntax to lexicon in a bare-noun              extremely fast and extremely slow. We suspect that a more
picture-naming task. Other studies have found that syntactic          robust interaction might arise if one considers offsets
category information is likewise obligatorily activated in            intermediate between these extremes. Furthermore, by
non-syntactic production tasks (e.g., Durán and Pillon, 2011).        incrementally increasing the offset between 50 and 1050 ms,
The present study extends these findings from production to           we would allow considering the ISI as the numerical
comprehension, from spoken language to written language,              magnitude it is (cf., Feldman et al., 2015), rather than as a
and from a simple to a primed paradigm. Hence, the                    bi-valued factor.
converging evidence suggests that obligatory syntactic                    In sum, our results suggest that, in line with the
access, along with bi-directional activation between syntax           predictions of usage-based theories of grammar, the
and lexicon, is a general, modality-independent property of           representation of words is inextricably tied to the
language processing.                                                  grammatical contexts in which these words are encountered.
   These data also speak to linguistic representation.                The results indicate that even the extremely fine-grained
Branigan and Pickering (in press) argue that, in order for            differences in syntactic use that can be found between words
priming to take place, some common connection must exist              of a single class (nouns) have detectable effects on their
between the prime and target on the one hand, and the                 processing and representation. This is true even in tasks
representations underlying the measurement of their                   –such as visual lexical decision– that do not to involve any
similarity. This notion is applied to the relationship between        explicit involvement of the syntactic system. In other words,
words and conceptual content in the semantic priming                  in comprehension, the activation of the syntactic properties
literature (e.g., Lam, Dijkstra, & Rueschemeyer, 2015).               of a word is automatic. The word comes with its whole
Likewise, our results can be interpreted as reflecting that           syntactic baggage. Furthermore, this syntactic baggage goes
each noun's representation is explicitly connected to the set         well beyond mere grammatical category information, and
of syntactic structures in which it participates and that these       includes a rich, fine-grained account of the syntactic contexts
representations are shared across words. Moreover, the                in which each particular noun is used.
probabilistic nature of our measure suggests that connection
weights –not just the set of shared syntactic types– are                                        References
represented in the lexico-syntactic network, exactly as               Adelman, J. S., Johnson, R. L., McCormick, S. F., McKague,
predicted by usage-based models of linguistic representation             M., Kinoshita, S., Bowers, J. S., Perry, J. R., Lupker, S. J.,
(Diessel, 2015) and as evidenced in sentence-reading                     Forster, K. I., Cortese, M. J., Scaltritti, M., Aschenbrenner,
paradigms (Novick et al., 2003). Importantly, these findings             A., J., Coane, J. H., White, L., Yap, M. J., Davis, C., Kim,
are not consistent with modular-syntactic models (e.g.,                  J., & Davis, C. J. (2014). A behavioral database for masked
Chomsky, 1995), which posit only categorical relationships               form priming. Behavioral Research Methods, 46,
between words and syntax. Adapting the old adage, “you can               1052-1067.
take the noun out of syntax, but you can't take the syntax out        Box, G. E. P., & Cox, D. R. (1964). An analysis of
of the noun.”                                                            transformations. Journal of the Royal Statistics Society,
   A possible limitation is that we used Latent Semantic                 Series B (Methodological), 26, 211-252.
Analysis as a proxy for semantic related when 'cleaning' our          Branigan, H. & Pickering, M. (in press). An experimental
syntactic measure of its semantic component. It remains                  approach to linguistic representation. Behavioral and
possible –albeit, in our opinion, unlikely– that part, or even           Brain Sciences.
all, of the effects of syntactic similarity could be accounted        Bresnan, J. (2001). Lexical Functional Syntax. Oxford:
                                                                         Blackwell Publishers.
                                                                  2541

Chomsky, N. (1995). The minimalist program. Cambridge:            Landauer, T. K., & Dumais, S. T. (1997). A solution to
  MIT Press.                                                        Plato's problem: The latent semantic analysis theory of
Diessel, H. (2015). Usage-based construction grammar. In E.         acquisition, induction, and representation of knowledge.
  Dabrowska and D. Divjak (Eds.), Handbook of Cognitive             Psychological Review, 104, 211-240.
  Linguistics (pp. 295-321). Boston: De Gruyter.                  Lester, N. A. & Moscoso del Prado Martín, F. (2016).
Duràn, C. P. & Pillon, A. (2011). The role of grammatical           Syntactic flexibility in the noun: Evidence from picture
  category information in spoken word retrieval. Frontiers in       naming. In A. Papafragou, D. Grodner, D. Mirman, & J. C.
  Psychology, 2, 1-20.                                              Trueswell (Eds.), Proceedings of the 38th Annual
Feldman, L. B., Milin, P., Cho, K. W., Moscoso del Prado            Conference of the Cognitive Science Society (pp.
  Martín, F., & O'Connor, P. (2015). Must analysis of               2585-2590). Austin, TX: Cognitive Science Society.
  meaning follow analysis of form? A time course analysis.        Levenshtein, V. I. (1966). Binary codes capable of correcting
  Frontiers in Human Neuroscience, 11, 1-19.                        deletions, insertions, and reversals. Doklady Akademii
Goldberg, A. E. (1995). Constructions: A Construction               Nauk SSSR, 163, 845-848.
  Grammar approach to argument structure. Oxford:                 Lin, J. (1991). Divergence measures based on the Shannon
  Oxford University Press.                                          Entropy. IEEE Transactions on Information Theory, 37,
Gries, S. Th. & Stefanowitsch, A. (2004). Extending                 145-151.
  Collostructional Analysis: A corpus-based examination of        Mel'čuk, I. (1988). Dependency syntax: Theory and practice.
  ‘alternations.’ International Journal of Corpus Linguistics,      Albany: The SUNY Press.
  9, 97-129.                                                      Neely, J. H. (1991). Semantic priming effects in visual word
GurJanov, M., Lukatela, G., Moskoljević, J., Savić, M. &            recognition: A selective review of current findings and
  Turvey, M. T.. (1985). Grammatical priming of inflected           theory. In D. Besner & G. W. Humphreys (Eds.), Basic
  nouns by inflected adjectives. Cognition, 19, 55-71.              processes in reading: Visual word recognition (pp.
Hausser, J. & Strimmer, K. (2009). Entropy inference and the        264-336). Hillsadale, NJ: Erlbaum.
  James-Stein estimator, with application to nonlinear gene       New, B., Ferrand, L., Pallier, C., & Brysbaert, M. (2006).
  association networks. Journal of Machine Learning                 Reexamining the word length effect in visual word
  Research, 10, 1469-1484.                                          recognition: New evidence from the English Lexicon
Hendrix, P., Bolger, P. and Baayen, R. H. (2017). Distinct          Project. Psychonomic Bulletin and Review, 13, 45-52.
  ERP signatures of word frequency, phrase frequency, and         Nivre, J. 2005. Dependency grammar and dependency
  prototypicality in speech production. Journal of                  parsing. Technical Report MSI report 05133, Växjö
  Experimental Psychology: Learning, Memory, and                    University: School of Mathematics and Systems
  Cognition, 43, 128-149.                                           Engineering.
Honnibal, M. & Johnson, M. (2015). An improved                    Novick, J. M., Kim, A., Trueswell, J. C. (2003).Studying the
  non-monotonic transition system for dependency parsing.           grammatical aspects of word recognition: Lexical priming,
  In Proceedings of the 2015 Conference on Empirical                parsing, and syntactic-ambiguity resolution. Journal of
  Methods in Natural Language Processing (pp. 1373-1378).           Psycholinguistic Research, 32, 57-75.
  Lisbon, Association for Computational Linguistics.              Stabler, E. P. (2013). Two models of minimalist, incremental
Hutchison, K.A., Balota, D.A., Neely, J.H., Cortese, M.J.,          syntactic analysis. Topics in Cognitive Science, 5,
  Cohen-Shikora, E. R., Tse, Chi-Shing, Yap, M. J.,                 611-633.
  Bengson, J. J., Niemeyer, D., & Buchanan, E. (2013). The        Stefanowitsch, A. & Gries, S. Th. (2003). Collostructions:
  Semantic Priming Project. Behavior Research Methods, 45,          Investigating the interaction of words and constructions.
  1099-1114.                                                        International Journal of Corpus Linguistics, 8, 209-243.
Jackendoff, R. (2013). Constructions in the parallel              van der Loo, M. P. J. (2014). The stringdist package for
  architecture. In T. Hoffmann & G. Trousdale (Eds.), The           approximate string matching. The R Journal, 6, 111-122.
  Oxford Handbook of Construction Grammar (pp. 70-92),            Van Heuven, W.J.B., Mandera, P., Keuleers, E., & Brysbaert,
  Oxford: Oxford University Press.                                  M. (2014). Subtlex-UK: A new and improved word
Keuleers, E., Lacey, P., Rastle, K., & Brysbaert, M. (2012).        frequency database for British English. Quarterly Journal
  The British Lexicon Project: Lexical decision data for            of Experimental Psychology, 67, 1176-1190.
  28,730 monosyllabic and disyllabic English words.               Wurm, L. H., & Fisicaro, S. A. (2014). What residualizing
  Behavior Research Methods, 44, 287-304.                           predictors in regression models does (and what it does not
Kuperman, V., Stadthagen-Gonzalez, H., & Brysbaert, M.              do). Journal of Memory and Language, 72, 37-48.
  (2012). Age-of-acquisition ratings for 30 thousand English      Yarkoni,T., Balota, D., & Yap, M. (2008). Moving beyond
  words. Behavior Research Methods, 44, 978-990.                    Coltheart's N: A new measure of orthographic similarity.
Lam, K. J. Y., Dijkstra, T., & Rueschemeyer, S-A. (2015).           Psychonomic Bulletin and Review, 15, 971-979.
  Feature activation during word recognition: action, visual,
  and associative-semantic priming effects. Frontiers in
  Psychology, 6, 1-8.
                                                              2542

