                               Objections to Computationalism. A Short Survey
                                         Marcin Miłkowski (mmilkows@ifispan.waw.pl)
                                          Instytut Filozofii i Socjologii PAN, ul. Nowy Świat 72,
                                                           00-330 Warszawa, Poland
                              Abstract                                    1984, pp. xiv–xvi), a stronger version of computationalism,
                                                                          which claims that cognition literally involves computation.
   In this paper, I review the objections against the claim that
   brains are computers, or, to be precise, information-
   processing mechanisms. By showing that practically all the             Software is not in the head
   popular objections are based on uncharitable (or simply                   This objection is that there is no simple way to understand
   incorrect) interpretations of the claim, I argue that the claim is     the notions of software and hardware as applied to
   likely to be true, relevant to contemporary cognitive
   (neuro)science, and non-trivial.
                                                                          biological brains. But the software/hardware distinction,
                                                                          popular as in the slogan “the mind to the brain is like the
   Keywords: computationalism; computational theory of mind;              software to hardware” (Block, 1995; Piccinini, 2010), need
   representation; computation; modeling                                  not be applicable to brains at all for computationalism to be
                                                                          true. There are non-program-controllable computers: they
          Computationalism and Objections                                 do not load programs from external memory to internal
   The computational theory of mind, or computationalism,                 memory in order to execute them. A mundane example of
has been fruitful in cognitive research. The main tenet of the            such a computer is a logical AND gate. In other words,
computational theory of mind is that the brain is a kind of               while it may be interesting to inquire whether there is
information-processing mechanism, and that information-                   software in the brain, even if there were none,
processing is necessary for cognition; it is non-trivial and is           computationalism could still be true.
generally accepted in cognitive science. The positive view
will not be developed here, in particular the account of                  Computers are just for number-crunching
physical computation, because it has already been                            Another intuitive objection, already stated (and defeated)
elucidated in book-length accounts (Fresco, 2014;                         in the 1950s, is that brains are not engaged in number-
Miłkowski, 2013; Piccinini, 2015). Instead, a review of                   crunching, while computers compute over numbers. But if
objections is offered here, as no comprehensive survey is                 this is all computers do, then they don’t control missiles or
available.                                                                send documents to printers. After all, printing is not just
   The survey suggests that the majority of objections fail               number crunching. The objection rests therefore on a
just because they make computationalism a straw man.                      mistaken assumption that computers can only compute
Some of them, however, have shown that stronger versions                  numerical functions. Computer functions can be defined not
of the computational theory of mind are untenable, as well.               only of integer numbers but also of arbitrary symbols
Historically, they have helped to shape the theory and                    (Newell, 1980), and as physical mechanisms, computers can
methodology of computational modeling. In particular, a                   also control other physical processes.
number of objections show that cognitive systems are not
only computers, or that computation is not the sole condition             Computers are abstract entities
of cognition; no objection, however, establishes that there
                                                                             Some claim that because symbols in computers are, in
might be cognition without computation.
                                                                          some sense, abstract and formal, computers—or at least
                                                                          computer programs—are abstract as well (Barrett, 2015;
Computer metaphor is just a metaphor
                                                                          Barrett, Pollet, & Stulp, 2014; Lakoff, 1987). In other
Computational descriptions are sometimes described as a                   words, the opponents of computationalism claim that it
computer metaphor (cf., e.g., Ekman, 2003; Karl, 2012, p.                 implies ontological dualism (Searle, 1990). However,
2101). The use of the term suggests that the proposed                     computers are physical mechanisms, and they can be
description is rough and highly idealized, and cannot be                  broken, set on fire etc. These things may be difficult to
treated literally. However, by using the term, others suggest             accomplish with a collection of abstract entities. Computers
that no computational model may be treated seriously; all                 are not just symbol-manipulators. They do things, and some
are mere metaphors (Daugman, 1990).                                       of the things computers do are not computational. In this
   A defender of computationalism might concede this and                  minimal sense, computers are physically embodied, not
weaken their position. But the position is also tenable in the            unlike mammal brains. It is, however, a completely different
stronger version. This is because computer metaphors                      matter whether the symbols in computers mean anything.
cannot really be tested and rejected, whereas computational
models can. For this reason, in this paper, I will adopt, along           People are organisms, computers are not
with other theorists (Newell & Simon, 1972, p. 5; Pylyshyn,
                                                                             Barrett (2015), among others, also presses the point that
                                                                          people are organisms. It’s trivially true but irrelevant:
                                                                      2723

physical computers are physical, and they may be built in         technical terms of computability theory, neither can they be
various ways. A computer may be built of DNA strands              reduced to such. However, processing of semantic
(Zauner & Conrad, 1996), so why claim that it’s                   information is still processing of information; hence,
metaphysically impossible to have a biological computer?          computation is necessary for manipulation of cognitive
                                                                  representation.
Symbols in computers mean nothing                                    Computationalism was strongly connected to cognitive
   One of the most powerful objections formulated against         representations by the fact that it offered a solution to the
the possibility of Artificial Intelligence is associated with     problem of what makes meaning causally relevant. Many
John Searle’s Chinese Room thought experiment (Searle,            theorists claim that because the syntax in computer
1980). Searle claimed to show that running a computer             programs is causally relevant (or efficacious), so is the
program is not sufficient for semantic properties to arise,       meaning. While the wholesale reduction of meaning to
and this was in clear contradiction to what was advanced by       syntax is implausible, the computational theory of mind
proponents of Artificial Intelligence, who assumed that it        makes it clear that the answer to the question includes the
was sufficient to simulate the syntactic structure of             causal role of the syntax of computational vehicles. Still, the
representations for the semantic properties to appear. As         fact that it does not offer a naturalistic account of meaning is
John Haugeland quipped: “if you take care of syntax, the          not an objection to computationalism itself. That would
semantics will take care of itself” (Haugeland, 1985, p.          indeed be too much. At the same time, at least some
106). But Searle replied: one can easily imagine a person         naturalistic accounts, such as Millikan’s and Dretske’s, can
with a special set of instructions in English who could           be used to solve the SGP (see Miłkowski 2013, chap. 4).
manipulate Chinese symbols and answer questions in
Chinese without understanding it at all. Hence,                   Computers can only represent with all detail
understanding is not reducible to syntactic manipulation.            The debate over meaning in computers and animals
While the discussion around this thought experiment is            abounds in red herrings, however. One recent example is
hardly conclusive (Preston & Bishop, 2002), the problem           Robert Epstein’s (2016) popular essay. His most striking
was soon reformulated by Stevan Harnad (1990) as “the             mistake is the assumption that computers always represent
symbol grounding problem” (SGP): How can symbols in               everything with arbitrary accuracy. Epstein cites the
computational machines mean anything?                             example of how people remember a dollar bill, and assumes
   If the SGP makes sense, then one cannot simply assume          that computers would represent it in a photographic manner
that symbols in computers mean something just by being            with all available detail. This is an obvious mistake:
parts of computers, or at least they cannot mean anything         representation is useful mostly when it does not convey
outside the computer so easily (even if they contain              information about all properties of the represented target. If
instructional information (Fresco & Wolf, 2013)).                 Epstein is correct, then there are no JPEG files in
Representational properties do not necessarily exist in           computers, as they are not accurate, because they are based
physical computational mechanisms (Egan, 1995; Fresco,            on lossy compression. Moreover, no assumption of the
2010; Miłkowski, 2013; Piccinini, 2008). So, even if Searle       computational theory of mind says that memory should be
is right and there is no semantics in computers, the brain        understood in terms of the von Neumann architecture, and it
might still be a computer, as computers need no semantics         is controversial to suggest that it should (Gallistel & King,
to be computers. Perhaps something additional to                  2010).
computation is required for semantics.
   There is an important connection between the                   People don’t process information
computational theory of mind and the representational                Ecological psychologists stress that people do not process
account of cognition: they are more attractive when both are      information, they just pick it up from the environment (cf.
embraced. Cognitive science frequently explains cognitive         Chemero, 2003; Gibson, 1986). Thus, to understand this,
phenomena by referring to semantic properties of                  one should make more explicit the meaning of information
mechanisms capable of information-processing (Shagrir,            processing in the computational theory of mind. What kind
2010a). Brains are assumed to model reality, and these            of information is processed? The information in question
models can be utilized in computations. While this seems          need not be semantic, as not all symbols in computers are
plausible to many, one can remain computationalist without        about something. The minimal notion that could suffice for
assuming representationalism (the claim that cognition            our purposes is one of structural information: a vehicle can
requires cognitive representation). At the same time, a           bear structural information in the event that it has at least
plausible account of cognitive representation cannot be           one degree of freedom, that is, it may vary its state
couched merely in computational terms as long as one              (MacKay, 1969). The number of degrees of freedom, or yes-
assumes that the symbol grounding problem makes sense at          no questions required to exactly describe its current state, is
least for some computers. To make the account plausible,          the amount of structural information. As long as there are
most theorists appeal to notions of teleological function and     vehicles with multiple degrees of freedom and they are part
semantic information (Bickhard, 2008; Cummins & Roth,             of causal processes that cause some other vehicles—just like
2012; Dretske, 1986; Millikan, 1984), which are not               some models of computation describe these processes
                                                              2724

(Miłkowski, 2014)—there is information processing. This is          Computer models ignore time
a very broad notion, as all physical causation implies                 Proponents of dynamical accounts of cognition stress that
information transfer and processing in this sense (Collier,         Turing machines do not operate in real time. This means
1999).                                                              that this classical model of computation does not appeal to
   The Gibsonian notion of information pickup requires              real time; instead, it operates with the abstract notion of a
vehicles of structural information as well. There needs to be       computation step. There is no continuous time flow, just
some information out there to be picked up, and organisms           discrete clock ticks in a Turing Machine (Bickhard &
have to be structured so as to be able to change their state in     Terveen, 1995; Wheeler, 2005). This is true. But is this an
response to information. Gibsonians could, however, claim           objection against computationalism?
that the information is not processed. It is unclear what is           First, some models of computation appeal to real time
meant by this: for example, Chemero seems to imply that             (Nagy & Akl, 2011), so one could use such a formalism.
processing amounts to adding more and more layers of                Second, the objection seems to confuse the formal model of
information, like in Marr’s account of vision (Chemero,             computation with its physical realization. Physical
2003, p. 584; cf. Marr, 1982). But information processing           computers operate in real time, and not all models of
need not require multiple stages of adding more                     computation are made equal; some will be relevant to the
information. To sum up: the Gibsonian account does not              explanation of cognition, and some may only be useful for
invalidate computationalism at all.                                 computability theory. A mechanistically-adequate model of
                                                                    computation that describes all relevant causal processes in
Consciousness is not computational                                  the mechanism is required for explanatory purposes
   Some find (some kinds of) consciousness to be utterly            (Miłkowski, 2014).
incompatible with computationalism, or at least,
unexplainable in purely computational terms (Chalmers,              Brains are not digital computers
1996). The argument is probably due to Leibniz’s thought               Universal Turing machines are crucial to computability
experiment in Monadology (Leibniz, 1991). Imagine a brain           theory. One could, however, maintain that brains are not
as huge as a mill, and enter it. Nowhere in the interplay of        digital computers (Edelman, 1992; Lupyan, 2013).
gears could you find perceptions, or qualitative                       But computationalism can appeal to models of analog
consciousness. Hence, you cannot explain perception                 computation (e.g., Siegelmann, 1994), or even more
mechanically. Of course, this Leibnizian argument appeals           complex kinds of computation (Piccinini & Bahar, 2013), if
only to some physical features of mechanisms, but some              required. These models are still understood as
still seem to think that causation has nothing to do with           computational in computability theory, and some theorists
qualitative consciousness.                                          indeed claim that the brain is an analog computer, which is
   The argument, if cogent, is applicable more broadly, not         supposed to allow them to compute Turing-incomputable
just to computationalism; it is supposed to defeat reductive        functions. Thus, one cannot dismiss all kinds of
physicalism or materialism. For this reason, this objection         computationalism by saying that the brain is not a digital
might be dismissed as attacking any scientific project that         computer. There are analog computers, and an early model
explains consciousness reductively.                                 of a neural network, Perceptron, was analog (Rosenblatt,
   Virtually all current theories of consciousness are              1958). The contention that computers have to be digital is
computational, even the ones that appeal to quantum                 just dogmatic.
processes (Hameroff, 2007). For example, Bernard Baars
offers a computational account in terms of the global               Genuine artificial intelligence is impossible
workspace theory (Baars, 1988; cf. also Dennett, 2005),
David Rosenthal gives an account in terms of higher-level              There are a number of arguments of a form:
states (cf. Cleeremans, 2005; Rosenthal, 2005), and Giulio
Tononi explains in terms of minimal information integration               People ψ.
(Tononi, 2004). Is there any theory of consciousness that is              Computers will never ψ.
not already computational?                                                So, artificial intelligence        is  impossible     (or
   John Searle, however, suggests that only a non-                  computationalism is false).
computational theory of consciousness can succeed. His
claim is that consciousness is utterly biological (Searle,             This argument is enthymematic, but the conclusion
1992). How does this contradict computationalism given              follows with a third assumption: if artificial intelligence is
that there might be biological computers? Moreover, Searle          possible, then computers will ψ. The plausibility of the
fails to identify the specific biological powers of brains that     argument varies from case to case, depending on what you
make them conscious. He just passes the buck to                     fill for ψ. For years, it was argued that winning in chess is ψ
neuroscience, which often offers computational accounts.            (Dreyfus, 1979), but it turned out to be false. So, unless
                                                                    there is a formal proof, it’s difficult to treat premise 2
                                                                    seriously.
                                                                2725

   What could be plausibly substituted for ψ? There are            different kinds (and levels) of computation, and brains do
many properties of biological organisms that simply seem           not execute all kinds of computation at the same time
irrelevant to this argument, including exactly the same            (Miłkowski, 2007). So not just any computation but some
energy consumption, having proper names, spatiotemporal            non-trivial kind of computation is specific to brains. Only
location, etc. The plausible candidate for substitution is         the kind of pancomputationalism that assumes that
some capacity for information-processing. If there is such a       everything computes all kinds of functions at the same time
human capacity that computers do not possess, then the             is catastrophic, as it makes physical computation indeed
argument is indeed cogent.                                         trivial (Putnam, 1991; Searle, 1992).
Only people can see the truth A classical anti-
computational argument points to the human ability to              There are no computers
recognize the truth of logical statements that cannot be              Another more radical move is to say that computers do
proven by a computer (Lucas, 1961; Penrose, 1989). It is           not really exist; they are just in the eyes of beholder.
based on the alleged ability of human beings to understand         According to John Searle, the beholder decides whether a
that some statements are true, which is purportedly                given physical system is computational, and therefore may
impossible for machines (this argument is based on the             make this decision for virtually everything. Nothing
Gödel proof of incompleteness of the first-order predicate         intrinsically is a computer. But the body of work on
calculus with basic arithmetic). The problem is that this          physical computation in the last decade or so has been
human understanding has to be non-contradictory and                focused on showing why Putnam and Searle were wrong in
certain. But Gödel has shown that in general it cannot be          some sense (Chalmers, 2011; Chrisley, 1994; Copeland,
decided whether a given system is contradictory or not. So         1996; Miłkowski, 2013; Piccinini, 2015; Scheutz, 1996;
either it’s mathematically certain that human understanding        Shagrir, 2010b). The contemporary consensus is that
of mathematics is non-contradictory, which makes the               computational models can be used to adequately describe
argument inconsistent as it cannot be mathematically certain       causal connections in physical systems, and that these
because it’s undecidable; or the argument just assumes non-        models can also be falsely ascribed. In other words,
contradiction of human understanding, which makes the              computational models are not different in kind from any
argument unsound because people make contradictions                mathematical model used in science. If they are mere
unknowingly (Krajewski, 2007; Putnam, 1960).                       subjective metaphors and don’t describe reality, then
                                                                   mathematical models in physics are subjective as well
Common sense cannot be formalized Another similar                  (McDermott, 2001).
argument points to common sense, which is a particularly              Intuitively, arguments presented by Searle and Putnam are
difficult capacity. The trouble with implementing common           wrong for a very simple reason: why buy a new computer
sense on machines is sometimes called (somewhat                    instead of ascribing new software to the old one? We know
misleadingly, cf. (Shanahan, 1997)) the frame problem              that such ascriptions would be extremely cumbersome.
(Dreyfus, 1972, 1979; Wheeler, 2005). Inferential capacities       Therefore, there must be a flaw in such arguments, and even
of standard AI programs do not seem to follow the practices        if the technicalities involved are indeed interesting, they fail
known to humans, and that was supposed to hinder progress          to establish a conclusion.
in such fields as high-quality machine translation (Bar-
Hillel, 1964), speech recognition (held to be immoral to                                    Conclusion
fund (Weizenbaum, 1976)), and so on. Even if IBM Watson
                                                                      In this paper, I have listed and summarized a number of
wins in Jeopardy!, one may still think it’s not enough.
                                                                   arguments against computationalism. The only objection
Admittedly, common sense is a plausible candidate in this
                                                                   that seems to be plausible at first glance is the one stating
argument.
                                                                   that common sense is impossible or extremely difficult to
   Even if the proponent of computationalism need not
                                                                   implement on a machine. However, more and more
require that genuine AI be based on a computer simulation
                                                                   commonsensical capacities are being implemented on
of human cognitive processes, he or she still must show that
                                                                   machines.
human common sense can be simulated on a computer.
                                                                      The point is that there's no good reason to think that the
Whether it can or not is still a matter of debate.
                                                                   brain is not a computer. But it isn’t a mere computer: It is
Computers are everywhere                                           physically embedded in its environment and interacts
                                                                   physically with its body, and for that, it also needs a
   At least some plausible theories of physical                    peripheral nervous system (Aranyosi, 2013) and cognitive
implementation of computation lead to the conclusion that          representations. Yet there’s nothing that denies
all physical entities are computational (this stance is called     computationalism         here.     Most       criticisms     of
pancomputationalism, (cf. Müller, 2009)). If this is the case,     computationalism therefore fail, and sticking to them is
then the computational theory of mind is indeed trivial, as        probably a matter of ideology rather than rational debate.
not only brains are computational, but also cows, black
holes, cheese sandwiches etc. are all computers. However, a
pancomputationalist may reply by saying that there are
                                                               2726

                    Acknowledgments                             Daugman, J. (1990). Brain metaphor and brain theory. In E.
                                                                  L. Schwartz (Ed.), Computational Neuroscience (pp. 9–
  The work on this paper was funded by a National Science
                                                                  18). Cambridge, Mass: MIT Press.
Centre (Poland) research grant under the decision DEC-
                                                                Dennett, D. C. (2005). Sweet Dreams. Philosophical
2014/14/E/HS1/00803. The author wishes to thank Tomasz
                                                                  Obstacles to a Science of Consciousness. Cambridge,
Korbak, Martin Hughes, Panu Raatikainen, Błażej
                                                                  Mass.: MIT Press.
Skrzypulec, and anonymous reviewers for their comments.
                                                                Dretske, F. I. (1986). Misrepresentation. In R. Bogdan (Ed.),
                                                                  Belief: form, content, and function (pp. 17–37). Oxford:
                         References                               Clarendon Press.
Aranyosi, I. (2013). The peripheral mind: philosophy of         Dreyfus, H. (1972). What Computers Can’t Do: A Critique
  mind and the peripheral nervous system. New York, NY:           of Artificial Reason. New York: Harper & Row,
  Oxford University Press.                                        Publishers.
Baars, B. J. (1988). A cognitive theory of consciousness.       Dreyfus, H. (1979). What computers still can’t do: a
  Cambridge / New York: Cambridge University Press.               critique of artificial reason. Cambridge Mass.: MIT Press.
Bar-Hillel, Y. (1964). A Demonstration of the                   Edelman, G. M. (1992). Bright air, brilliant fire: on the
  Nonfeasibility of Fully Automatic High Quality                  matter of the mind. New York, N.Y.: BasicBooks.
  Translation. In Language and Information (pp. 174–179).       Egan, F. (1995). Computation and Content. The
  Reading, Mass.: Addison-Wesley.                                 Philosophical          Review,      104(2),       181–181.
Barrett, L. (2015). Why Brains Are Not Computers, Why             https://doi.org/10.2307/2185977
  Behaviorism Is Not Satanism, and Why Dolphins Are Not         Ekman, P. (2003). Emotions revealed: recognizing faces
  Aquatic Apes. The Behavior Analyst, 1–15.                       and feelings to improve communication and emotional
  https://doi.org/10.1007/s40614-015-0047-0                       life. New York: Times Books.
Barrett, L., Pollet, T. V., & Stulp, G. (2014). From            Epstein, R. (2016, May 18). The empty brain. Retrieved
  computers to cultivation: reconceptualizing evolutionary        December 28, 2016, from https://aeon.co/essays/your-
  psychology. Frontiers in Psychology, 5, 867–867.                brain-does-not-process-information-and-it-is-not-a-
  https://doi.org/10.3389/fpsyg.2014.00867                        computer
Bickhard, M. H. (2008). The interactivist model. Synthese,      Fresco, N. (2010). Explaining Computation Without
  166(3), 547–591. https://doi.org/10.1007/s11229-008-            Semantics: Keeping it Simple. Minds and Machines,
  9375-x                                                          20(2), 165–181. https://doi.org/10.1007/s11023-010-
Bickhard, M. H., & Terveen, L. (1995). Foundational issues        9199-6
  in artificial intelligence and cognitive science: Impasse     Fresco, N. (2014). Physical Computation and Cognitive
  and solution. North-Holland.                                    Science. Berlin, Heidelberg: Springer Berlin Heidelberg.
Block, N. (1995). The mind as the software of the brain. In     Fresco, N., & Wolf, M. J. (2013). The instructional
  D. Osherson, L. Gleitman, & S. Kosslyn (Eds.), An               information processing account of digital computation.
  Invitation to Cognitive Science. Cambridge, Mass.: MIT          Synthese,                  191(7),              1469–1492.
  Press.                                                          https://doi.org/10.1007/s11229-013-0338-5
Chalmers, D. J. (1996). The conscious mind: in search of a      Gallistel, C. R., & King, A. P. (2010). Memory and the
  fundamental theory. New York: Oxford University Press.          Computational Brain. Chichester: Wiley-Blackwell.
Chalmers, D. J. (2011). A Computational Foundation for the      Gibson, J. J. (1986). The Ecological Approach to Visual
  Study of Cognition. Journal of Cognitive Science, (12),         Perception. Hove: Psychology Press.
  325–359.                                                      Hameroff, S. R. (2007). The Brain Is Both Neurocomputer
Chemero, A. (2003). Information for perception and                and Quantum Computer. Cognitive Science, 31, 1035–
  information processing. Minds and Machines, 13, 577–            1045.
  588.                                                          Harnad, S. (1990). The symbol grounding problem. Physica
Chrisley, R. L. (1994). Why everything doesn’t realize            D, 42, 335–346.
  every computation. Minds and Machines, 4(4), 403–420.         Haugeland, J. (1985). Artificial intelligence: the very idea.
  https://doi.org/10.1007/BF00974167                              Cambridge, Mass.: MIT Press.
Cleeremans, A. (2005). Computational correlates of              Karl, F. (2012). A Free Energy Principle for Biological
  consciousness. Progress in Brain Research, 150, 81–98.          Systems. Entropy (Basel, Switzerland), 14(11), 2100–
  https://doi.org/10.1016/S0079-6123(05)50007-4                   2121. https://doi.org/10.3390/e14112100
Collier, J. D. (1999). Causation is the transfer of             Krajewski, S. (2007). On Gödel’s Theorem and Mechanism:
  information. In H. Sankey (Ed.), Causation, natural laws        Inconsistency or Unsoundness is Unavoidable in any
  and explanation (pp. 279–331). Dordrecht: Kluwer.               Attempt to “Out-Gödel” the Mechanist. Fundamenta
Copeland, B. J. (1996). What is computation? Synthese,            Informaticae, 81(1), 173–181.
  108(3), 335–359.                                              Lakoff, G. (1987). Women, fire, and dangerous things: what
Cummins, R., & Roth, M. (2012). Meaning and Content in            categories reveal about the mind. Chicago: University of
  Cognitive Science. In R. Schantz (Ed.), Prospects for           Chicago Press.
  Meaning (pp. 365–382). Berlin & New York: de Gruyter.
                                                            2727

Leibniz, G. W. (1991). The monadology. (R. Latta, Trans.).      Piccinini, G., & Bahar, S. (2013). Neural computation and
  Raleigh, N.C.; Boulder, Colo.: Alex Catalogue ;                 the computational theory of cognition. Cognitive Science,
  NetLibrary.                                                     37(3), 453–88. https://doi.org/10.1111/cogs.12012
Lucas, J. (1961). Minds, Machines and Gödel. Philosophy,        Preston, J., & Bishop, M. (2002). Views into the Chinese
  9(3), 219–227.                                                  room: new essays on Searle and artificial intelligence.
Lupyan, G. (2013). The difficulties of executing simple           Oxford; New York: Clarendon Press.
  algorithms: Why brains make mistakes computers don’t.         Putnam, H. (1960). Minds and machines. In S. Hook (Ed.),
  Cognition,                  129(3),               615–36.       Dimensions of Mind. New York University Press.
  https://doi.org/10.1016/j.cognition.2013.08.015               Putnam, H. (1991). Representation and Reality. Cambridge,
MacKay, D. M. (1969). Information, mechanism and                  Mass.: The MIT Press.
  meaning. Cambridge: M.I.T. Press.                             Pylyshyn, Z. W. (1984). Computation and cognition:
Marr, D. (1982). Vision. A Computational Investigation into       Toward a foundation for cognitive science. Cambridge,
  the Human Representation and Processing of Visual               Mass.: MIT Press.
  Information. New York: W. H. Freeman and Company.             Rosenblatt, F. (1958). The perceptron: A probabilistic
McDermott, D. V. (2001). Mind and Mechanism.                      model for information storage and organization in the
  Cambridge, Mass.: MIT Press.                                    brain.    Psychological     Review,    65(6),   386–408.
Miłkowski, M. (2007). Is computationalism trivial? In G. D.       https://doi.org/10.1037/h0042519
  Crnkovic & S. Stuart (Eds.), Computation, Information,        Rosenthal, D. (2005). Consciousness and mind. Oxford,
  Cognition – The Nexus and the Liminal (pp. 236–246).            New York: Oxford University Press.
  Newcastle: Cambridge Scholars Press.                          Scheutz, M. (1996). When Physical Systems Realize
Miłkowski, M. (2013). Explaining the Computational Mind.          Functions…. Minds and Machines, 9(2), 1–34.
  Cambridge, Mass.: MIT Press.                                    https://doi.org/10.1023/A:1008364332419
Miłkowski, M. (2014). Computational Mechanisms and              Searle, J. R. (1980). Minds, brains, and programs.
  Models of Computation. Philosophia Scientae, 18(18–3),          Behavioral and Brain Sciences, 3(3), 1–19.
  215–228.                                                        https://doi.org/10.1017/S0140525X00005756
  https://doi.org/10.4000/philosophiascientiae.1019             Searle, J. R. (1990). Is the Brain’s Mind a Computer
Millikan, R. G. (1984). Language, thought, and other              Program? Scientific American, (January), 26–31.
  biological categories: new foundations for realism.           Searle, J. R. (1992). The Rediscovery of the Mind.
  Cambridge, Mass.: The MIT Press.                                Cambridge, Mass.: MIT Press.
Müller, V. C. (2009). Pancomputationalism: Theory or            Shagrir, O. (2010a). Brains as analog-model computers.
  metaphor? In R. Hagengruber (Ed.), The relevance of             Studies In History and Philosophy of Science Part A,
  philosophy for information science. Berlin: Springer.           41(3),                                          271–279.
Nagy, N., & Akl, S. (2011). Computations with Uncertain           https://doi.org/10.1016/j.shpsa.2010.07.007
  Time Constraints: Effects on Parallelism and                  Shagrir, O. (2010b). Towards a Modeling View of
  Universality. In C. Calude, J. Kari, I. Petre, & G.             Computing. In G. Dodig-Crnkovic & M. Burgin (Eds.),
  Rozenberg (Eds.), Unconventional Computation (Vol.              Information and Computation. Singapore: World
  6714, pp. 152–163). Springer Berlin / Heidelberg.               Scientific Publishing.
  Retrieved from http://dx.doi.org/10.1007/978-3-642-           Shanahan, M. (1997). Solving the frame problem: a
  21341-0_19                                                      mathematical investigation of the common sense law of
Newell, A. (1980). Physical symbol systems. Cognitive             inertia. Cambridge, Mass.: MIT Press.
  Science: A Multidisciplinary Journal, 4(2), 135–183.          Siegelmann, H. (1994). Analog computation via neural
  https://doi.org/10.1207/s15516709cog0402_2                      networks. Theoretical Computer Science, 131(2), 331–
Newell, A., & Simon, H. A. (1972). Human problem                  360. https://doi.org/10.1016/0304-3975(94)90178-3
  solving. Englewood Cliffs, NJ: Prentice-Hall.                 Tononi, G. (2004). An information integration theory of
Penrose, R. (1989). The emperor’s new mind. London:               consciousness.        BMC         Neuroscience,      5(1).
  Oxford University Press.                                        https://doi.org/10.1186/1471-2202-5-42
Piccinini, G. (2008). Computation without Representation.       Weizenbaum, J. (1976). Computer power and human
  Philosophical        Studies,       137(2),      205–241.       reason: from judgment to calculation. San Francisco:
  https://doi.org/10.1007/s11098-005-5385-4                       W.H. Freeman.
Piccinini, G. (2010). The Mind as Neural Software?              Wheeler, M. (2005). Reconstructing the Cognitive World.
  Understanding Functionalism, Computationalism, and              Cambridge, Mass.: MIT Press.
  Computational       Functionalism.     Philosophy     and     Zauner, K.-P., & Conrad, M. (1996). Parallel computing
  Phenomenological        Research,      81(2),    269–311.       with DNA: Toward the anti-universal machine. In H.-M.
  https://doi.org/10.1111/j.1933-1592.2010.00356.x                Voigt, W. Ebeling, I. Rechenberg, & H.-P. Schwefel
Piccinini, G. (2015). Physical computation: a mechanistic         (Eds.), Parallel Problem Solving from Nature - PPSN IV
  account. Oxford: Oxford University Press.                       (Vol. 1141, pp. 696–705). Springer Berlin / Heidelberg.
                                                            2728

